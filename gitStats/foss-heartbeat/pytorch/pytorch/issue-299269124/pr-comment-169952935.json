{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169952935", "pull_request_review_id": 98558442, "id": 169952935, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2OTk1MjkzNQ==", "diff_hunk": "@@ -0,0 +1,109 @@\n+import subprocess\n+import os\n+import socket\n+from argparse import ArgumentParser, REMAINDER\n+\n+import torch\n+\n+def parse_args():\n+    \"\"\"\n+    Helper function parsing the command line options\n+    @retval ArgumentParser\n+    \"\"\"\n+    parser = ArgumentParser(description=\"PyTorch Exec is a helper utiliy that \"\n+            \"spawns up multiple distributed training processes. The utility \"\n+            \"can be used in single-node distributed training that each \"\n+            \"distributed process will be operating on a single GPU. (for \"\n+            \"well-improved performance reasons). \"\n+            \"In this case, this utilily will launch a given number of \"\n+            \"processes per node (nproc_per_node) , while this number needs to \"\n+            \"be smaller than the number of GPUs (n_gpus) on the current system,\"\n+            \" and each process will be operating on a single GPU from GPU 0 to \"\n+            \"GPU nproc_per_node - 1. \"\n+\n+            \"This utility can be further used for multi-node \"\n+            \"distributed training by spawning up multiple processes per node \"\n+            \"for well-improved distributed performance as well. This will \"\n+            \"especially be benefitial for systems with multiple Infiniband \"\n+            \"interfaces since all of them can be utilized for aggregated \"\n+            \"communication bandwidth. Please note that this utilty and \"\n+            \"multi-process/node distributed single node or multi-node \"\n+            \"training currently only supports the NCCL distributed backend. \"\n+            \"This utilty helper will require that training script is able to \"\n+            \"parse --device=X as an argument since it will be injected by this \"\n+            \"utility. \"\n+\n+            \"In your training program, other than parsing --device=X as \"\n+            \"argument.device, you should also use the following three function \"\n+            \"calls: \"\n+            \"torch.distributed.init_process_group(backend=\\\"nccl\\\", \"\n+            \"init_method=\\\"env://\\\"), torch.cuda.set_device(arg.device), and \"\n+            \"model = torch.nn.parallel.DistributedDataParallel(model, \"\n+            \"device_ids=[arg.device]) in order to use this utility.\")\n+\n+    parser.add_argument(\"--num_node\", type=int, default=1,\n+            help=\"The number of nodes to use for distributed training\")\n+    parser.add_argument(\"--rank_node\", type=int, default=0,\n+            help=\"The rank of the node for multi-node distributed training\")\n+    parser.add_argument(\"--nproc_per_node\", type=int, default=1,\n+            help=\"The number of processes to launch on each node\")\n+    parser.add_argument(\"--master_addr\", default=\"127.0.0.1\", type=str,\n+            help=\"Master node (rank 0)'s address, should be either the IP \"\n+            \"address or hostname of node 0, for single node, IP can simply be \"\n+            \"127.0.0.1\")\n+    parser.add_argument(\"--master_port\", default=29500, type=int,\n+            help=\"Master node (rank 0)'s free port that needs to be used for \"\n+            \"communciation in distributed training\")", "path": "tools/distributed/pytorch_dist_exec.py", "position": null, "original_position": 56, "commit_id": "03b219badb2cbdbe3bbfb6df7dddaf3d70f1088e", "original_commit_id": "82a4e859be4ced77f0a08cd86ecbdbe9967bc355", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Forcing people to manually specify those parameters when we have multiple alternatives that are much more convenient is quite limiting. I'm ok with making those optional, but you should never require them", "created_at": "2018-02-22T13:24:35Z", "updated_at": "2018-11-23T15:39:50Z", "html_url": "https://github.com/pytorch/pytorch/pull/5348#discussion_r169952935", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5348", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169952935"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5348#discussion_r169952935"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5348"}}, "body_html": "<p>Forcing people to manually specify those parameters when we have multiple alternatives that are much more convenient is quite limiting. I'm ok with making those optional, but you should never require them</p>", "body_text": "Forcing people to manually specify those parameters when we have multiple alternatives that are much more convenient is quite limiting. I'm ok with making those optional, but you should never require them"}