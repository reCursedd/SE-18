{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/170051585", "pull_request_review_id": 98678650, "id": 170051585, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MDA1MTU4NQ==", "diff_hunk": "@@ -0,0 +1,109 @@\n+import subprocess\n+import os\n+import socket\n+from argparse import ArgumentParser, REMAINDER\n+\n+import torch\n+\n+def parse_args():\n+    \"\"\"\n+    Helper function parsing the command line options\n+    @retval ArgumentParser\n+    \"\"\"\n+    parser = ArgumentParser(description=\"PyTorch Exec is a helper utiliy that \"\n+            \"spawns up multiple distributed training processes. The utility \"\n+            \"can be used in single-node distributed training that each \"\n+            \"distributed process will be operating on a single GPU. (for \"\n+            \"well-improved performance reasons). \"\n+            \"In this case, this utilily will launch a given number of \"\n+            \"processes per node (nproc_per_node) , while this number needs to \"\n+            \"be smaller than the number of GPUs (n_gpus) on the current system,\"\n+            \" and each process will be operating on a single GPU from GPU 0 to \"\n+            \"GPU nproc_per_node - 1. \"\n+\n+            \"This utility can be further used for multi-node \"\n+            \"distributed training by spawning up multiple processes per node \"\n+            \"for well-improved distributed performance as well. This will \"\n+            \"especially be benefitial for systems with multiple Infiniband \"\n+            \"interfaces since all of them can be utilized for aggregated \"\n+            \"communication bandwidth. Please note that this utilty and \"\n+            \"multi-process/node distributed single node or multi-node \"\n+            \"training currently only supports the NCCL distributed backend. \"\n+            \"This utilty helper will require that training script is able to \"\n+            \"parse --device=X as an argument since it will be injected by this \"\n+            \"utility. \"", "path": "tools/distributed/pytorch_dist_exec.py", "position": null, "original_position": 34, "commit_id": "03b219badb2cbdbe3bbfb6df7dddaf3d70f1088e", "original_commit_id": "82a4e859be4ced77f0a08cd86ecbdbe9967bc355", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "I was initially using CUDA_VISIBLE_DEVICES and found NCCL doesn't work for this purpose and had to switch to something else.\r\n\r\nSynced with NVIDIA NCCL folks,  CUDA IPC needs to see all the devices, that is the reason why NCCL doesn't support this.  Looks like the only known way (according to NCCL team) is to set the device using cudaSetDevice in the code :|", "created_at": "2018-02-22T18:32:11Z", "updated_at": "2018-11-23T15:39:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/5348#discussion_r170051585", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5348", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/170051585"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5348#discussion_r170051585"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5348"}}, "body_html": "<p>I was initially using CUDA_VISIBLE_DEVICES and found NCCL doesn't work for this purpose and had to switch to something else.</p>\n<p>Synced with NVIDIA NCCL folks,  CUDA IPC needs to see all the devices, that is the reason why NCCL doesn't support this.  Looks like the only known way (according to NCCL team) is to set the device using cudaSetDevice in the code :|</p>", "body_text": "I was initially using CUDA_VISIBLE_DEVICES and found NCCL doesn't work for this purpose and had to switch to something else.\nSynced with NVIDIA NCCL folks,  CUDA IPC needs to see all the devices, that is the reason why NCCL doesn't support this.  Looks like the only known way (according to NCCL team) is to set the device using cudaSetDevice in the code :|", "in_reply_to_id": 169950633}