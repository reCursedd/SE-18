{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5348", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5348/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5348/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5348/events", "html_url": "https://github.com/pytorch/pytorch/pull/5348", "id": 299269124, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcwNjkwMjUy", "number": 5348, "title": "Added torch.distributed.launch module for easier multi-proc/node distributed job launching", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-02-22T09:00:58Z", "updated_at": "2018-11-23T15:48:20Z", "closed_at": "2018-03-13T11:04:39Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5348", "html_url": "https://github.com/pytorch/pytorch/pull/5348", "diff_url": "https://github.com/pytorch/pytorch/pull/5348.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5348.patch"}, "body_html": "<p>A helper module to launch multi-process distributed jobs either on a single-node or multiple-node</p>\n<pre><code>$python -m torch.distributed.launch --help\nusage: launch.py [-h] [--num_node NUM_NODE] [--rank_node RANK_NODE]\n                 [--nproc_per_node NPROC_PER_NODE] [--master_addr MASTER_ADDR]\n                 [--master_port MASTER_PORT] [--dist_backend DIST_BACKEND]\n                 training_script ...\n\nPyTorch distributed training launch helper utilty that will spawn up multiple\ndistributed processes\n\npositional arguments:\n  training_script       The full path to the single GPU training\n                        program/script to be launched in parallel, followed by\n                        all the arguments for the training script\n  training_script_args\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --num_node NUM_NODE   The number of nodes to use for distributed training\n  --rank_node RANK_NODE\n                        The rank of the node for multi-node distributed\n                        training\n  --nproc_per_node NPROC_PER_NODE\n                        The number of processes to launch on each node\n  --master_addr MASTER_ADDR\n                        Master node (rank 0)'s address, should be either the\n                        IP address or the hostname of node 0, for single node\n                        multi-proc training, the --master_addr can simply be\n                        127.0.0.1\n  --master_port MASTER_PORT\n                        Master node (rank 0)'s free port that needs to be used\n                        for communciation during distributed training\n</code></pre>\n<p>can be used with</p>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"299264374\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/examples/issues/306\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/examples/pull/306/hovercard\" href=\"https://github.com/pytorch/examples/pull/306\">pytorch/examples#306</a></p>\n<p>For example: single node multi-process training:</p>\n<pre><code>python -m torch.distributed.launch ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl''\n</code></pre>\n<p>Multi-node multi-process training would be similar using</p>\n<pre><code>python -m torch.distributed.launch --num_node=2 --rank_node=0 --nproc_per_node=2 --master_addr=devfair033 ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl'\n</code></pre>", "body_text": "A helper module to launch multi-process distributed jobs either on a single-node or multiple-node\n$python -m torch.distributed.launch --help\nusage: launch.py [-h] [--num_node NUM_NODE] [--rank_node RANK_NODE]\n                 [--nproc_per_node NPROC_PER_NODE] [--master_addr MASTER_ADDR]\n                 [--master_port MASTER_PORT] [--dist_backend DIST_BACKEND]\n                 training_script ...\n\nPyTorch distributed training launch helper utilty that will spawn up multiple\ndistributed processes\n\npositional arguments:\n  training_script       The full path to the single GPU training\n                        program/script to be launched in parallel, followed by\n                        all the arguments for the training script\n  training_script_args\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --num_node NUM_NODE   The number of nodes to use for distributed training\n  --rank_node RANK_NODE\n                        The rank of the node for multi-node distributed\n                        training\n  --nproc_per_node NPROC_PER_NODE\n                        The number of processes to launch on each node\n  --master_addr MASTER_ADDR\n                        Master node (rank 0)'s address, should be either the\n                        IP address or the hostname of node 0, for single node\n                        multi-proc training, the --master_addr can simply be\n                        127.0.0.1\n  --master_port MASTER_PORT\n                        Master node (rank 0)'s free port that needs to be used\n                        for communciation during distributed training\n\ncan be used with\npytorch/examples#306\nFor example: single node multi-process training:\npython -m torch.distributed.launch ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl''\n\nMulti-node multi-process training would be similar using\npython -m torch.distributed.launch --num_node=2 --rank_node=0 --nproc_per_node=2 --master_addr=devfair033 ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl'", "body": "A helper module to launch multi-process distributed jobs either on a single-node or multiple-node\r\n\r\n```\r\n$python -m torch.distributed.launch --help\r\nusage: launch.py [-h] [--num_node NUM_NODE] [--rank_node RANK_NODE]\r\n                 [--nproc_per_node NPROC_PER_NODE] [--master_addr MASTER_ADDR]\r\n                 [--master_port MASTER_PORT] [--dist_backend DIST_BACKEND]\r\n                 training_script ...\r\n\r\nPyTorch distributed training launch helper utilty that will spawn up multiple\r\ndistributed processes\r\n\r\npositional arguments:\r\n  training_script       The full path to the single GPU training\r\n                        program/script to be launched in parallel, followed by\r\n                        all the arguments for the training script\r\n  training_script_args\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  --num_node NUM_NODE   The number of nodes to use for distributed training\r\n  --rank_node RANK_NODE\r\n                        The rank of the node for multi-node distributed\r\n                        training\r\n  --nproc_per_node NPROC_PER_NODE\r\n                        The number of processes to launch on each node\r\n  --master_addr MASTER_ADDR\r\n                        Master node (rank 0)'s address, should be either the\r\n                        IP address or the hostname of node 0, for single node\r\n                        multi-proc training, the --master_addr can simply be\r\n                        127.0.0.1\r\n  --master_port MASTER_PORT\r\n                        Master node (rank 0)'s free port that needs to be used\r\n                        for communciation during distributed training\r\n```\r\ncan be used with\r\n\r\nhttps://github.com/pytorch/examples/pull/306\r\n\r\nFor example: single node multi-process training:\r\n\r\n```\r\npython -m torch.distributed.launch ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl''\r\n```\r\n\r\n\r\nMulti-node multi-process training would be similar using \r\n```\r\npython -m torch.distributed.launch --num_node=2 --rank_node=0 --nproc_per_node=2 --master_addr=devfair033 ./main.py -j 0 -a resnet18 --print-freq 1 --batch-size 32 --dist-url 'env://' /datasets01/imagenet_full_size/061417/ --epochs 1 --dist-backend 'nccl'\r\n```"}