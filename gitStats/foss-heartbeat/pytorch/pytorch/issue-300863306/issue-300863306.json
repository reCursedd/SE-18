{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5448", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5448/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5448/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5448/events", "html_url": "https://github.com/pytorch/pytorch/issues/5448", "id": 300863306, "node_id": "MDU6SXNzdWUzMDA4NjMzMDY=", "number": 5448, "title": "[Feature request] device_as", "user": {"login": "ruotianluo", "id": 16023153, "node_id": "MDQ6VXNlcjE2MDIzMTUz", "avatar_url": "https://avatars2.githubusercontent.com/u/16023153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruotianluo", "html_url": "https://github.com/ruotianluo", "followers_url": "https://api.github.com/users/ruotianluo/followers", "following_url": "https://api.github.com/users/ruotianluo/following{/other_user}", "gists_url": "https://api.github.com/users/ruotianluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruotianluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruotianluo/subscriptions", "organizations_url": "https://api.github.com/users/ruotianluo/orgs", "repos_url": "https://api.github.com/users/ruotianluo/repos", "events_url": "https://api.github.com/users/ruotianluo/events{/privacy}", "received_events_url": "https://api.github.com/users/ruotianluo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-28T02:04:32Z", "updated_at": "2018-04-24T20:14:52Z", "closed_at": "2018-04-24T20:14:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Can we can we a function behave like this:</p>\n<pre><code>a = torch.arange(10).long() # torch.LongTensor\nb = torch.randn(10).cuda() # torch.cuda.FloatTensor\n\na.device_as(b) # torch.cuda.LongTensor\n</code></pre>\n<p>I'm currently doing <code>a.type_as(b).long()</code></p>", "body_text": "Can we can we a function behave like this:\na = torch.arange(10).long() # torch.LongTensor\nb = torch.randn(10).cuda() # torch.cuda.FloatTensor\n\na.device_as(b) # torch.cuda.LongTensor\n\nI'm currently doing a.type_as(b).long()", "body": "Can we can we a function behave like this:\r\n\r\n```\r\na = torch.arange(10).long() # torch.LongTensor\r\nb = torch.randn(10).cuda() # torch.cuda.FloatTensor\r\n\r\na.device_as(b) # torch.cuda.LongTensor\r\n```\r\n\r\n\r\nI'm currently doing `a.type_as(b).long()`\r\n"}