{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11785", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11785/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11785/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11785/events", "html_url": "https://github.com/pytorch/pytorch/pull/11785", "id": 361124543, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE2MTc0NzI3", "number": 11785, "title": "Replace float16 with at::Half in caffe2", "user": {"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-09-18T03:45:15Z", "updated_at": "2018-11-23T15:51:39Z", "closed_at": "2018-09-21T01:56:35Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11785", "html_url": "https://github.com/pytorch/pytorch/pull/11785", "diff_url": "https://github.com/pytorch/pytorch/pull/11785.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11785.patch"}, "body_html": "<p>Summary: The first commit uses at::Half as a replacement for caffe2::float16. float16 conversions and arithmetic removed to make use of Half equivalents. Also, as a side effect, aten_op works for gpu half now.</p>\n<p>The second commit is a codemod (caffe2::float16 -&gt; at::Half). Notable changes: <code>caffe2/perfkernels/embedding_lookup.cc</code>, the macro was changed because at::Half can't be in a function name. Same thing for the codegen in <code>hp_emblookup_codegen.py</code>.</p>\n<p>Differential Revision: D9892158</p>", "body_text": "Summary: The first commit uses at::Half as a replacement for caffe2::float16. float16 conversions and arithmetic removed to make use of Half equivalents. Also, as a side effect, aten_op works for gpu half now.\nThe second commit is a codemod (caffe2::float16 -> at::Half). Notable changes: caffe2/perfkernels/embedding_lookup.cc, the macro was changed because at::Half can't be in a function name. Same thing for the codegen in hp_emblookup_codegen.py.\nDifferential Revision: D9892158", "body": "Summary: The first commit uses at::Half as a replacement for caffe2::float16. float16 conversions and arithmetic removed to make use of Half equivalents. Also, as a side effect, aten_op works for gpu half now.\r\n\r\nThe second commit is a codemod (caffe2::float16 -> at::Half). Notable changes: `caffe2/perfkernels/embedding_lookup.cc`, the macro was changed because at::Half can't be in a function name. Same thing for the codegen in `hp_emblookup_codegen.py`.\r\n\r\nDifferential Revision: D9892158\r\n"}