{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13162", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13162/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13162/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13162/events", "html_url": "https://github.com/pytorch/pytorch/issues/13162", "id": 374281814, "node_id": "MDU6SXNzdWUzNzQyODE4MTQ=", "number": 13162, "title": "circular module reference raises RecursionError", "user": {"login": "juniorrojas", "id": 2767767, "node_id": "MDQ6VXNlcjI3Njc3Njc=", "avatar_url": "https://avatars3.githubusercontent.com/u/2767767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juniorrojas", "html_url": "https://github.com/juniorrojas", "followers_url": "https://api.github.com/users/juniorrojas/followers", "following_url": "https://api.github.com/users/juniorrojas/following{/other_user}", "gists_url": "https://api.github.com/users/juniorrojas/gists{/gist_id}", "starred_url": "https://api.github.com/users/juniorrojas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juniorrojas/subscriptions", "organizations_url": "https://api.github.com/users/juniorrojas/orgs", "repos_url": "https://api.github.com/users/juniorrojas/repos", "events_url": "https://api.github.com/users/juniorrojas/events{/privacy}", "received_events_url": "https://api.github.com/users/juniorrojas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-26T08:37:54Z", "updated_at": "2018-10-29T17:41:49Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Run the following code snippet</li>\n</ol>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ModuleA</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.bs <span class=\"pl-k\">=</span> nn.ModuleList()\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ModuleB</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">a</span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.a <span class=\"pl-k\">=</span> a\n\na <span class=\"pl-k\">=</span> ModuleA()\na.bs.append(ModuleB(a))\na.to(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>)</pre></div>\n\n<h2>Expected behavior</h2>\n<p>Running the code snippet raises <code>RecursionError</code> due to the circular reference. In this particular case, <code>a.to(\"cpu\")</code> should have no effect because there are no tensors to move, but in general, it should move all tensors to the corresponding device without raising any error. See <code>additional context</code> for an explanation of why a circular reference like this might be useful in practice.</p>\n<h2>Environment</h2>\n<pre><code>PyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: 7.5.17\nGPU models and configuration: GPU 0: GeForce GTX 1080\nNvidia driver version: 384.130\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] pytorch                   0.4.1            py37ha74772b_0  \n</code></pre>\n<h2>Additional context</h2>\n<p>A particular case where a circular reference is useful is when <code>ModuleB.forward</code> computes something based on attributes of <code>ModuleA</code>, and <code>ModuleA.forward</code> computes the sum of <code>ModuleB.forward</code> for every module in its <code>ModuleList</code>. A workaround to avoid the <code>RecursionError</code> is to pass all the attributes explicitly to the constructor of <code>ModuleB</code>, but it becomes impractical when many parameters are involved and it's particularly problematic for mutable shared state like numbers that get passed by value. For example, consider the following code snippet:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ModuleA</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">123</span>\n        <span class=\"pl-c1\">self</span>.bs <span class=\"pl-k\">=</span> nn.ModuleList()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.0</span>\n        <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>.bs:\n            output <span class=\"pl-k\">+=</span> b(x)\n        <span class=\"pl-k\">return</span> output\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ModuleB</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">a</span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.a <span class=\"pl-k\">=</span> a\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.a.n <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">100</span>:\n            <span class=\"pl-k\">return</span> x\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">return</span> x <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n\na <span class=\"pl-k\">=</span> ModuleA()\na.bs.append(ModuleB(a))\nx <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>)\n<span class=\"pl-c1\">print</span>(a(x)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 0</span>\na.n <span class=\"pl-k\">=</span> <span class=\"pl-c1\">99</span>\n<span class=\"pl-c1\">print</span>(a(x)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1</span></pre></div>\n<p>This code snippet has a circular module reference and works without problems, but <code>a.to(device)</code> will result in infinite recursion. A workaround to avoid infinite recursion when calling <code>a.to(device)</code> is to make the constructor of <code>ModuleB</code> accept <code>n</code> as an argument rather than <code>a</code>, and store it as an attribute, but changes in <code>a.n</code> won't have the desired effect since it's no longer shared.</p>", "body_text": "\ud83d\udc1b Bug\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nRun the following code snippet\n\nimport torch\nimport torch.nn as nn\n\nclass ModuleA(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bs = nn.ModuleList()\n\nclass ModuleB(nn.Module):\n    def __init__(self, a):\n        super().__init__()\n        self.a = a\n\na = ModuleA()\na.bs.append(ModuleB(a))\na.to(\"cpu\")\n\nExpected behavior\nRunning the code snippet raises RecursionError due to the circular reference. In this particular case, a.to(\"cpu\") should have no effect because there are no tensors to move, but in general, it should move all tensors to the corresponding device without raising any error. See additional context for an explanation of why a circular reference like this might be useful in practice.\nEnvironment\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: 7.5.17\nGPU models and configuration: GPU 0: GeForce GTX 1080\nNvidia driver version: 384.130\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] pytorch                   0.4.1            py37ha74772b_0  \n\nAdditional context\nA particular case where a circular reference is useful is when ModuleB.forward computes something based on attributes of ModuleA, and ModuleA.forward computes the sum of ModuleB.forward for every module in its ModuleList. A workaround to avoid the RecursionError is to pass all the attributes explicitly to the constructor of ModuleB, but it becomes impractical when many parameters are involved and it's particularly problematic for mutable shared state like numbers that get passed by value. For example, consider the following code snippet:\nimport torch\nimport torch.nn as nn\n\nclass ModuleA(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.n = 123\n        self.bs = nn.ModuleList()\n\n    def forward(self, x):\n        output = 0.0\n        for b in self.bs:\n            output += b(x)\n        return output\n\nclass ModuleB(nn.Module):\n    def __init__(self, a):\n        super().__init__()\n        self.a = a\n\n    def forward(self, x):\n        if self.a.n > 100:\n            return x\n        else:\n            return x + 1\n\na = ModuleA()\na.bs.append(ModuleB(a))\nx = torch.zeros(1)\nprint(a(x)) # 0\na.n = 99\nprint(a(x)) # 1\nThis code snippet has a circular module reference and works without problems, but a.to(device) will result in infinite recursion. A workaround to avoid infinite recursion when calling a.to(device) is to make the constructor of ModuleB accept n as an argument rather than a, and store it as an attribute, but changes in a.n won't have the desired effect since it's no longer shared.", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the following code snippet\r\n```py\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass ModuleA(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.bs = nn.ModuleList()\r\n\r\nclass ModuleB(nn.Module):\r\n    def __init__(self, a):\r\n        super().__init__()\r\n        self.a = a\r\n\r\na = ModuleA()\r\na.bs.append(ModuleB(a))\r\na.to(\"cpu\")\r\n```\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nRunning the code snippet raises `RecursionError` due to the circular reference. In this particular case, `a.to(\"cpu\")` should have no effect because there are no tensors to move, but in general, it should move all tensors to the corresponding device without raising any error. See `additional context` for an explanation of why a circular reference like this might be useful in practice.\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 7.5.17\r\nGPU models and configuration: GPU 0: GeForce GTX 1080\r\nNvidia driver version: 384.130\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] pytorch                   0.4.1            py37ha74772b_0  \r\n```\r\n\r\n## Additional context\r\n\r\nA particular case where a circular reference is useful is when `ModuleB.forward` computes something based on attributes of `ModuleA`, and `ModuleA.forward` computes the sum of `ModuleB.forward` for every module in its `ModuleList`. A workaround to avoid the `RecursionError` is to pass all the attributes explicitly to the constructor of `ModuleB`, but it becomes impractical when many parameters are involved and it's particularly problematic for mutable shared state like numbers that get passed by value. For example, consider the following code snippet:\r\n\r\n```py\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass ModuleA(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.n = 123\r\n        self.bs = nn.ModuleList()\r\n\r\n    def forward(self, x):\r\n        output = 0.0\r\n        for b in self.bs:\r\n            output += b(x)\r\n        return output\r\n\r\nclass ModuleB(nn.Module):\r\n    def __init__(self, a):\r\n        super().__init__()\r\n        self.a = a\r\n\r\n    def forward(self, x):\r\n        if self.a.n > 100:\r\n            return x\r\n        else:\r\n            return x + 1\r\n\r\na = ModuleA()\r\na.bs.append(ModuleB(a))\r\nx = torch.zeros(1)\r\nprint(a(x)) # 0\r\na.n = 99\r\nprint(a(x)) # 1\r\n```\r\nThis code snippet has a circular module reference and works without problems, but `a.to(device)` will result in infinite recursion. A workaround to avoid infinite recursion when calling `a.to(device)` is to make the constructor of `ModuleB` accept `n` as an argument rather than `a`, and store it as an attribute, but changes in `a.n` won't have the desired effect since it's no longer shared."}