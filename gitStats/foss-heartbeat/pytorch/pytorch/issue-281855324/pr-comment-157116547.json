{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157116547", "pull_request_review_id": 83708015, "id": 157116547, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NzExNjU0Nw==", "diff_hunk": "@@ -93,6 +95,52 @@ def __len__(self):\n         return self.num_samples\n \n \n+class EnlargeLabelShufflingSampler(Sampler):\n+    \"\"\"\n+        label shuffling technique aimed to deal with imbalanced class problem\n+        without replacement, manipulated by indices.\n+        All classes are enlarged to the same amount, so classes can be trained equally.\n+        argument:\n+        indices: indices of labels of the whole dataset\n+        \"\"\"\n+\n+    def __init__(self, indices):\n+        # mapping between label index and sorted label index\n+        sorted_labels = sorted(enumerate(indices), key=lambda x: x[1])\n+        count = 1\n+        count_of_each_label = []\n+        tmp = -1\n+        # get count of each label\n+        for (x, y) in sorted_labels:\n+            if y == tmp:\n+                count += 1\n+            else:\n+                if tmp != -1:\n+                    count_of_each_label.append(count)\n+                    count = 1\n+            tmp = y\n+        count_of_each_label.append(count)\n+        # get the largest count among all classes. used to enlarge every class to the same amount\n+        largest = int(np.amax(count_of_each_label))\n+        self.count_of_each_label = count_of_each_label\n+        self.enlarged_index = []\n+\n+        # preidx used for find the mapping beginning of arg \"sorted_labels\"\n+        preidx = 0\n+        for x in range(len(self.count_of_each_label)):\n+            idxes = np.remainder(torch.randperm(largest).numpy(), self.count_of_each_label[x]) + preidx", "path": "torch/utils/data/sampler.py", "position": null, "original_position": 44, "commit_id": "08354a2e6327a92a0919747d15f0fcc5578c2ae6", "original_commit_id": "82d23bb2f45815b9408c3364407383c9d9d50835", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Use torch.remainder", "created_at": "2017-12-15T03:14:03Z", "updated_at": "2018-11-23T15:37:24Z", "html_url": "https://github.com/pytorch/pytorch/pull/4153#discussion_r157116547", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4153", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157116547"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4153#discussion_r157116547"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4153"}}, "body_html": "<p>Use torch.remainder</p>", "body_text": "Use torch.remainder"}