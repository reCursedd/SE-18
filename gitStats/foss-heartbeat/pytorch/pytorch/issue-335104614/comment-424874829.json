{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/424874829", "html_url": "https://github.com/pytorch/pytorch/issues/8823#issuecomment-424874829", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8823", "id": 424874829, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDg3NDgyOQ==", "user": {"login": "Spandan-Madan", "id": 21960611, "node_id": "MDQ6VXNlcjIxOTYwNjEx", "avatar_url": "https://avatars0.githubusercontent.com/u/21960611?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Spandan-Madan", "html_url": "https://github.com/Spandan-Madan", "followers_url": "https://api.github.com/users/Spandan-Madan/followers", "following_url": "https://api.github.com/users/Spandan-Madan/following{/other_user}", "gists_url": "https://api.github.com/users/Spandan-Madan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Spandan-Madan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Spandan-Madan/subscriptions", "organizations_url": "https://api.github.com/users/Spandan-Madan/orgs", "repos_url": "https://api.github.com/users/Spandan-Madan/repos", "events_url": "https://api.github.com/users/Spandan-Madan/events{/privacy}", "received_events_url": "https://api.github.com/users/Spandan-Madan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-26T21:24:40Z", "updated_at": "2018-09-26T21:24:40Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a> I have the same error. Tried with <code>num_workers=0</code> and still got the CUDA error. Here's the stack  trace:-</p>\n<pre><code>Traceback (most recent call last):\n  File \"train.py\", line 235, in &lt;module&gt;\n    train(cfg, writer, logger)\n  File \"train.py\", line 135, in train\n    outputs = model(images)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 123, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 133, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\n    raise output\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\n    output = module(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/pytorch-semseg/ptsemseg/models/fcn.py\", line 333, in forward\n    score = self.classifier(conv5)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n    input = module(input)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: CUDA error: out of memory\n\n</code></pre>\n<p>Any leads?</p>", "body_text": "@yf225 I have the same error. Tried with num_workers=0 and still got the CUDA error. Here's the stack  trace:-\nTraceback (most recent call last):\n  File \"train.py\", line 235, in <module>\n    train(cfg, writer, logger)\n  File \"train.py\", line 135, in train\n    outputs = model(images)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 123, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 133, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\n    raise output\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\n    output = module(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/pytorch-semseg/ptsemseg/models/fcn.py\", line 333, in forward\n    score = self.classifier(conv5)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n    input = module(input)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: CUDA error: out of memory\n\n\nAny leads?", "body": "@yf225 I have the same error. Tried with `num_workers=0` and still got the CUDA error. Here's the stack  trace:-\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 235, in <module>\r\n    train(cfg, writer, logger)\r\n  File \"train.py\", line 135, in train\r\n    outputs = model(images)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 123, in forward\r\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 133, in parallel_apply\r\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\r\n    raise output\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\r\n    output = module(*input, **kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/pytorch-semseg/ptsemseg/models/fcn.py\", line 333, in forward\r\n    score = self.classifier(conv5)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\r\n    input = module(input)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/afs/csail.mit.edu/u/j/janaka/anaconda2/envs/fcn/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 301, in forward\r\n    self.padding, self.dilation, self.groups)\r\nRuntimeError: CUDA error: out of memory\r\n\r\n```\r\n\r\nAny leads?"}