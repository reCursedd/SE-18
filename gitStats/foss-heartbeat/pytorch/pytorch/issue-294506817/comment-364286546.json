{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/364286546", "html_url": "https://github.com/pytorch/pytorch/issues/5057#issuecomment-364286546", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5057", "id": 364286546, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDI4NjU0Ng==", "user": {"login": "eickenberg", "id": 1306635, "node_id": "MDQ6VXNlcjEzMDY2MzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1306635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eickenberg", "html_url": "https://github.com/eickenberg", "followers_url": "https://api.github.com/users/eickenberg/followers", "following_url": "https://api.github.com/users/eickenberg/following{/other_user}", "gists_url": "https://api.github.com/users/eickenberg/gists{/gist_id}", "starred_url": "https://api.github.com/users/eickenberg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eickenberg/subscriptions", "organizations_url": "https://api.github.com/users/eickenberg/orgs", "repos_url": "https://api.github.com/users/eickenberg/repos", "events_url": "https://api.github.com/users/eickenberg/events{/privacy}", "received_events_url": "https://api.github.com/users/eickenberg/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-08T23:40:44Z", "updated_at": "2018-02-08T23:40:44Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Ah yes, good point. Makes sense.\nIf the padding is applied before the convolution (which is what I think the\ndocs are saying)\n\nThanks!</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Feb 8, 2018 at 10:42 AM, Tongzhou Wang ***@***.***&gt; wrote:\n In fact the output and input shapes of convs are many-to-one, given the\n input parameters. For example, in test_convolution_adjointness((32, 32),\n (3, 3), 2), both (32, 32) and (31, 31) map to (15, 15). That's why we\n have the output_padding option for conv transpose. I tried adding\n output_padding=1 for this case and the test passes. :)\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"294506817\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5057\" href=\"https://github.com/pytorch/pytorch/issues/5057#issuecomment-364208532\">#5057 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABPwC-XnTFxnxUJt3l9-jRbFAxL-RjNPks5tSz_-gaJpZM4R58SC\">https://github.com/notifications/unsubscribe-auth/ABPwC-XnTFxnxUJt3l9-jRbFAxL-RjNPks5tSz_-gaJpZM4R58SC</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Ah yes, good point. Makes sense.\nIf the padding is applied before the convolution (which is what I think the\ndocs are saying)\n\nThanks!\n\u2026\nOn Thu, Feb 8, 2018 at 10:42 AM, Tongzhou Wang ***@***.***> wrote:\n In fact the output and input shapes of convs are many-to-one, given the\n input parameters. For example, in test_convolution_adjointness((32, 32),\n (3, 3), 2), both (32, 32) and (31, 31) map to (15, 15). That's why we\n have the output_padding option for conv transpose. I tried adding\n output_padding=1 for this case and the test passes. :)\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#5057 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABPwC-XnTFxnxUJt3l9-jRbFAxL-RjNPks5tSz_-gaJpZM4R58SC>\n .", "body": "Ah yes, good point. Makes sense.\nIf the padding is applied before the convolution (which is what I think the\ndocs are saying)\n\nThanks!\n\nOn Thu, Feb 8, 2018 at 10:42 AM, Tongzhou Wang <notifications@github.com>\nwrote:\n\n> In fact the output and input shapes of convs are many-to-one, given the\n> input parameters. For example, in test_convolution_adjointness((32, 32),\n> (3, 3), 2), both (32, 32) and (31, 31) map to (15, 15). That's why we\n> have the output_padding option for conv transpose. I tried adding\n> output_padding=1 for this case and the test passes. :)\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pytorch/pytorch/issues/5057#issuecomment-364208532>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABPwC-XnTFxnxUJt3l9-jRbFAxL-RjNPks5tSz_-gaJpZM4R58SC>\n> .\n>\n"}