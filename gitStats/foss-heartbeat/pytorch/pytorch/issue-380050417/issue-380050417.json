{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13882", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13882/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13882/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13882/events", "html_url": "https://github.com/pytorch/pytorch/issues/13882", "id": 380050417, "node_id": "MDU6SXNzdWUzODAwNTA0MTc=", "number": 13882, "title": "torch.masked_select result in out of memory when using cuda", "user": {"login": "HyacinthJingjing", "id": 17040205, "node_id": "MDQ6VXNlcjE3MDQwMjA1", "avatar_url": "https://avatars1.githubusercontent.com/u/17040205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HyacinthJingjing", "html_url": "https://github.com/HyacinthJingjing", "followers_url": "https://api.github.com/users/HyacinthJingjing/followers", "following_url": "https://api.github.com/users/HyacinthJingjing/following{/other_user}", "gists_url": "https://api.github.com/users/HyacinthJingjing/gists{/gist_id}", "starred_url": "https://api.github.com/users/HyacinthJingjing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HyacinthJingjing/subscriptions", "organizations_url": "https://api.github.com/users/HyacinthJingjing/orgs", "repos_url": "https://api.github.com/users/HyacinthJingjing/repos", "events_url": "https://api.github.com/users/HyacinthJingjing/events{/privacy}", "received_events_url": "https://api.github.com/users/HyacinthJingjing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-13T04:04:23Z", "updated_at": "2018-11-13T04:38:50Z", "closed_at": "2018-11-13T04:38:49Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"question\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/2753.png\">\u2753</g-emoji> Questions and Help</h2>\n<h3>Please note that this issue tracker is not a help form and this issue will be closed.</h3>\n<p>We have a set of <a href=\"https://pytorch.org/resources\" rel=\"nofollow\">listed resources available on the website</a>. Our primary means of support is our discussion forum:</p>\n<ul>\n<li><a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">Discussion Forum</a><br>\nHere are my source codes:<br>\ndef forward(self, prob, target, reward):<br>\n\"\"\"<br>\nArgs:<br>\nprob: (N, C), torch Variable<br>\ntarget : (N, ), torch Variable<br>\nreward : (N, ), torch Variable<br>\n\"\"\"<br>\nN = target.size(0)<br>\nC = prob.size(1)<br>\none_hot = torch.zeros((N, C))<br>\nif prob.is_cuda:<br>\none_hot = one_hot.cuda()<br>\none_hot.scatter_(1, target.data.view((-1,1)), 1)<br>\none_hot = one_hot.type(torch.ByteTensor)<br>\none_hot = Variable(one_hot)<br>\nif prob.is_cuda:<br>\none_hot = one_hot.cuda()<br>\nloss = torch.masked_select(prob, one_hot)<br>\nloss = loss * reward<br>\nloss =  -torch.sum(loss)<br>\nreturn loss<br>\nWhen N=2000 and C=240755, once the line \"loss = torch.masked_select(prob, one_hot)\" runs, the memory of GPU seems doubled. Is this phenomena normal and how to prevent it?</li>\n</ul>", "body_text": "\u2753 Questions and Help\nPlease note that this issue tracker is not a help form and this issue will be closed.\nWe have a set of listed resources available on the website. Our primary means of support is our discussion forum:\n\nDiscussion Forum\nHere are my source codes:\ndef forward(self, prob, target, reward):\n\"\"\"\nArgs:\nprob: (N, C), torch Variable\ntarget : (N, ), torch Variable\nreward : (N, ), torch Variable\n\"\"\"\nN = target.size(0)\nC = prob.size(1)\none_hot = torch.zeros((N, C))\nif prob.is_cuda:\none_hot = one_hot.cuda()\none_hot.scatter_(1, target.data.view((-1,1)), 1)\none_hot = one_hot.type(torch.ByteTensor)\none_hot = Variable(one_hot)\nif prob.is_cuda:\none_hot = one_hot.cuda()\nloss = torch.masked_select(prob, one_hot)\nloss = loss * reward\nloss =  -torch.sum(loss)\nreturn loss\nWhen N=2000 and C=240755, once the line \"loss = torch.masked_select(prob, one_hot)\" runs, the memory of GPU seems doubled. Is this phenomena normal and how to prevent it?", "body": "## \u2753 Questions and Help\r\n\r\n### Please note that this issue tracker is not a help form and this issue will be closed.\r\n\r\nWe have a set of [listed resources available on the website](https://pytorch.org/resources). Our primary means of support is our discussion forum:\r\n\r\n- [Discussion Forum](https://discuss.pytorch.org/)\r\nHere are my source codes:\r\n    def forward(self, prob, target, reward):\r\n        \"\"\"\r\n        Args:\r\n            prob: (N, C), torch Variable\r\n            target : (N, ), torch Variable\r\n            reward : (N, ), torch Variable\r\n        \"\"\"\r\n        N = target.size(0)\r\n        C = prob.size(1)\r\n        one_hot = torch.zeros((N, C))\r\n        if prob.is_cuda:\r\n            one_hot = one_hot.cuda()\r\n        one_hot.scatter_(1, target.data.view((-1,1)), 1)\r\n        one_hot = one_hot.type(torch.ByteTensor)\r\n        one_hot = Variable(one_hot)\r\n        if prob.is_cuda:\r\n            one_hot = one_hot.cuda()\r\n        loss = torch.masked_select(prob, one_hot)\r\n        loss = loss * reward\r\n        loss =  -torch.sum(loss)\r\n        return loss\r\nWhen N=2000 and C=240755, once the line \"loss = torch.masked_select(prob, one_hot)\" runs, the memory of GPU seems doubled. Is this phenomena normal and how to prevent it?"}