{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13080", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13080/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13080/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13080/events", "html_url": "https://github.com/pytorch/pytorch/pull/13080", "id": 373697544, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI1NTY2NzI4", "number": 13080, "title": "Move stream to thread local", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-24T22:11:37Z", "updated_at": "2018-11-23T15:53:42Z", "closed_at": "2018-10-26T07:05:55Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/13080", "html_url": "https://github.com/pytorch/pytorch/pull/13080", "diff_url": "https://github.com/pytorch/pytorch/pull/13080.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/13080.patch"}, "body_html": "<p>Summary:<br>\nThis is the first step to untangle this logic:</p>\n<ul>\n<li>moves stream id to thread local mechanically</li>\n<li>relies on the fact that the value of thread local is valid in conjunction with CUDAContext only until the next SwitchToDevice is called - we should move to proper RAII in the following diffs</li>\n</ul>\n<p>Follow up diffs are going to move more stuff outside of CUDAContext (by making gpu_id thread local too) and simplify the CopyFrom.</p>\n<p>The only expected change in behavior is that before CopyFrom would do copy on stream logical id 0 if the context was created on the fly and now it'd do so on the current stream. Since it'd block explicitly, I don't think it matters much.</p>\n<p>Also, observers were semi-broken by waiting on the potentially wrong stream. It can be fixed later - I renamed the method to avoid abuse.</p>\n<p>Differential Revision: D10525134</p>", "body_text": "Summary:\nThis is the first step to untangle this logic:\n\nmoves stream id to thread local mechanically\nrelies on the fact that the value of thread local is valid in conjunction with CUDAContext only until the next SwitchToDevice is called - we should move to proper RAII in the following diffs\n\nFollow up diffs are going to move more stuff outside of CUDAContext (by making gpu_id thread local too) and simplify the CopyFrom.\nThe only expected change in behavior is that before CopyFrom would do copy on stream logical id 0 if the context was created on the fly and now it'd do so on the current stream. Since it'd block explicitly, I don't think it matters much.\nAlso, observers were semi-broken by waiting on the potentially wrong stream. It can be fixed later - I renamed the method to avoid abuse.\nDifferential Revision: D10525134", "body": "Summary:\nThis is the first step to untangle this logic:\n- moves stream id to thread local mechanically\n- relies on the fact that the value of thread local is valid in conjunction with CUDAContext only until the next SwitchToDevice is called - we should move to proper RAII in the following diffs\n\nFollow up diffs are going to move more stuff outside of CUDAContext (by making gpu_id thread local too) and simplify the CopyFrom.\n\nThe only expected change in behavior is that before CopyFrom would do copy on stream logical id 0 if the context was created on the fly and now it'd do so on the current stream. Since it'd block explicitly, I don't think it matters much.\n\nAlso, observers were semi-broken by waiting on the potentially wrong stream. It can be fixed later - I renamed the method to avoid abuse.\n\nDifferential Revision: D10525134\n"}