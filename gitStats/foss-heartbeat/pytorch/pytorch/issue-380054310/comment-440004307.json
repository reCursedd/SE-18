{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/440004307", "html_url": "https://github.com/pytorch/pytorch/issues/13883#issuecomment-440004307", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13883", "id": 440004307, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDAwNDMwNw==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-19T19:00:09Z", "updated_at": "2018-11-19T19:00:09Z", "author_association": "MEMBER", "body_html": "<p>repeating a message from Olexa on slack, closing this as wontfix::</p>\n<pre><code>@Amir, when I wrote in #general that CUDA is totally incompatible with forking, I meant this in the most serious and literal sense of those words possible.\n\nThis simply *cannot* be fixed in CUDA, PyTorch or anyone else. The problems inherent in `fork()`'ing *any* _multithreaded_ program are fundamentally unsolvable, and simply beyond the power of anyone to fix, at least not until a revolution in OS design happens.\n\nI can only plead that you accept the general difficulty of safely forking within a multithreaded program and try to do things another way.\n\nThere's several blogs out there discussing why it's dangerous to fork in a multithreaded program, such as https://thorstenball.com/blog/2014/10/13/why-threads-cant-fork/\n\nThe gist of it is that when a thread `fork()`'s, *in the child process, all other threads _die instantly._* It doesn't matter what they were doing, they're _gone_.\n\n- If they had locked a mutex, that mutex will never be unlocked again.\n- If they were modifying a data structure, that data structure might be invalid.\n- If they `malloc()`'ed some memory, that memory might never be deallocated, and `malloc()` may use locks and data structures anyways.\n- If a thread was doing useful work, that work will never be complete, because the threads no longer exist.\n- You can't join these non-existent threads.\n- `pthread_atfork()` is a function meant to solve the problems above, but it's simply incapable of doing what it was meant to do safely, and that's why the POSIX.1 standard explicitly says that this function may be formally deprecated in the next version of the standard. It was a mistake.\n\nSo almost the only safe thing to do if you `fork()`'ed from a multi-threaded process is to call `exec()`. That's what `spawn` does.\n\nBecause the CUDA runtime uses threads to implement its runtime and asynchronous streams, once the CUDA runtime is initialized, it's insanely dangerous to `fork()`. Don't do it.\n</code></pre>", "body_text": "repeating a message from Olexa on slack, closing this as wontfix::\n@Amir, when I wrote in #general that CUDA is totally incompatible with forking, I meant this in the most serious and literal sense of those words possible.\n\nThis simply *cannot* be fixed in CUDA, PyTorch or anyone else. The problems inherent in `fork()`'ing *any* _multithreaded_ program are fundamentally unsolvable, and simply beyond the power of anyone to fix, at least not until a revolution in OS design happens.\n\nI can only plead that you accept the general difficulty of safely forking within a multithreaded program and try to do things another way.\n\nThere's several blogs out there discussing why it's dangerous to fork in a multithreaded program, such as https://thorstenball.com/blog/2014/10/13/why-threads-cant-fork/\n\nThe gist of it is that when a thread `fork()`'s, *in the child process, all other threads _die instantly._* It doesn't matter what they were doing, they're _gone_.\n\n- If they had locked a mutex, that mutex will never be unlocked again.\n- If they were modifying a data structure, that data structure might be invalid.\n- If they `malloc()`'ed some memory, that memory might never be deallocated, and `malloc()` may use locks and data structures anyways.\n- If a thread was doing useful work, that work will never be complete, because the threads no longer exist.\n- You can't join these non-existent threads.\n- `pthread_atfork()` is a function meant to solve the problems above, but it's simply incapable of doing what it was meant to do safely, and that's why the POSIX.1 standard explicitly says that this function may be formally deprecated in the next version of the standard. It was a mistake.\n\nSo almost the only safe thing to do if you `fork()`'ed from a multi-threaded process is to call `exec()`. That's what `spawn` does.\n\nBecause the CUDA runtime uses threads to implement its runtime and asynchronous streams, once the CUDA runtime is initialized, it's insanely dangerous to `fork()`. Don't do it.", "body": "repeating a message from Olexa on slack, closing this as wontfix::\r\n\r\n```\r\n@Amir, when I wrote in #general that CUDA is totally incompatible with forking, I meant this in the most serious and literal sense of those words possible.\r\n\r\nThis simply *cannot* be fixed in CUDA, PyTorch or anyone else. The problems inherent in `fork()`'ing *any* _multithreaded_ program are fundamentally unsolvable, and simply beyond the power of anyone to fix, at least not until a revolution in OS design happens.\r\n\r\nI can only plead that you accept the general difficulty of safely forking within a multithreaded program and try to do things another way.\r\n\r\nThere's several blogs out there discussing why it's dangerous to fork in a multithreaded program, such as https://thorstenball.com/blog/2014/10/13/why-threads-cant-fork/\r\n\r\nThe gist of it is that when a thread `fork()`'s, *in the child process, all other threads _die instantly._* It doesn't matter what they were doing, they're _gone_.\r\n\r\n- If they had locked a mutex, that mutex will never be unlocked again.\r\n- If they were modifying a data structure, that data structure might be invalid.\r\n- If they `malloc()`'ed some memory, that memory might never be deallocated, and `malloc()` may use locks and data structures anyways.\r\n- If a thread was doing useful work, that work will never be complete, because the threads no longer exist.\r\n- You can't join these non-existent threads.\r\n- `pthread_atfork()` is a function meant to solve the problems above, but it's simply incapable of doing what it was meant to do safely, and that's why the POSIX.1 standard explicitly says that this function may be formally deprecated in the next version of the standard. It was a mistake.\r\n\r\nSo almost the only safe thing to do if you `fork()`'ed from a multi-threaded process is to call `exec()`. That's what `spawn` does.\r\n\r\nBecause the CUDA runtime uses threads to implement its runtime and asynchronous streams, once the CUDA runtime is initialized, it's insanely dangerous to `fork()`. Don't do it.\r\n```"}