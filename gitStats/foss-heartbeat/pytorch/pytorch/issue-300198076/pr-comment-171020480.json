{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171020480", "pull_request_review_id": 99800578, "id": 171020480, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTAyMDQ4MA==", "diff_hunk": "@@ -456,7 +457,163 @@ def trace(*args, **kwargs):\n         >>> def f(x):\n         >>>     return x * 2\n     \"\"\"\n-    return lambda func: torch._C.GraphExecutor(func, args, kwargs.pop('optimize', True))\n+    def wrapper(func):\n+        executor_options = {'optimize': True}\n+        for name in executor_options:\n+            executor_options[name] = kwargs.pop(name, executor_options[name])\n+        if isinstance(func, torch.nn.Module):\n+            captures = list(func.state_dict(keep_vars=True).values())\n+            # TODO: support shared parameters\n+            if len(set(map(id, captures))) != len(list(map(id, captures))):\n+                raise ValueError(\"TracedModules don't support parameter sharing between modules\")\n+            executor = torch._C.GraphExecutor(func, args, captures=captures, **executor_options)\n+            return TracedModule(func, executor)\n+        else:\n+            return torch._C.GraphExecutor(func, args, **executor_options)\n+    return wrapper\n+\n+\n+class TracedModule(torch.nn.Module):\n+    __class_cache = {}\n+    __frozen = False\n+\n+    def __new__(cls, orig, executor=None, root=None):\n+        orig_type = type(orig)\n+        if cls is TracedModule:\n+            if orig_type not in TracedModule.__class_cache:\n+                compiled_type = type('Compiled' + type(orig).__name__,\n+                                     (TracedModule, type(orig)),\n+                                     {})\n+                # NB: we don't block methods of subclasses. They are sometimes necessary\n+                # as helpers (e.g. for indexing in Sequential), and we block any writes\n+                # to attributes. The only way someone could mess with the logic here is\n+                # by modifying _parameters, but this is a private attribute, and we'll never\n+                # block this fully anyway.\n+                TracedModule.__class_cache[orig_type] = compiled_type\n+            else:\n+                compiled_type = TracedModule.__class_cache[orig_type]\n+            # XXX: we call __new__ instead of cls(), because the returned object will be\n+            # an instance of TracedModule, and so we don't want Python to call __init__ again.\n+            return compiled_type.__new__(compiled_type, orig, executor, root)\n+        return super(TracedModule, cls).__new__(cls)\n+\n+    def __init__(self, orig, executor=None, root=None):\n+        Module.__init__(self)  # Skip initialization of the user class\n+\n+        if not ((executor is None) ^ (root is None)):\n+            raise ValueError(\"Exaclty one of executor or root has to be specified\")\n+\n+        self.training = orig.training\n+        for name, param in orig._parameters.items():\n+            if param is not None:\n+                self._parameters[name] = param\n+        for name, buf in orig._buffers.items():\n+            if param is not None:\n+                self._buffers[name] = buf\n+        self._orig_class = type(orig)\n+\n+        for name, submodule in orig._modules.items():\n+            self._modules[name] = TracedModule(submodule,\n+                                                 root=root if root is not None else self)\n+\n+        if orig._backward_hooks or orig._forward_hooks or orig._forward_pre_hooks:\n+            raise ValueError(\"Modules that have hooks assigned can't be compiled\")\n+\n+        if executor is not None:\n+            self._is_root = True\n+            self._executor = executor\n+            self._recompute_captures()\n+        else:\n+            self._is_root = False\n+            self._root = weakref.ref(root)\n+\n+        self.__frozen = True\n+\n+    def __setattr__(self, name, value):\n+        if not self.__frozen:", "path": "torch/jit/__init__.py", "position": null, "original_position": 107, "commit_id": "b02df12699d14cb04dbff311dc363d43e6abae5a", "original_commit_id": "d8c1a075b4cbe38900687adf3e74327bf8a638e9", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We want to allow arbitrary assignments within `__init__`. Once it's completed we freeze the attributes", "created_at": "2018-02-27T18:27:56Z", "updated_at": "2018-11-23T15:40:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/5409#discussion_r171020480", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5409", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171020480"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5409#discussion_r171020480"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5409"}}, "body_html": "<p>We want to allow arbitrary assignments within <code>__init__</code>. Once it's completed we freeze the attributes</p>", "body_text": "We want to allow arbitrary assignments within __init__. Once it's completed we freeze the attributes", "in_reply_to_id": 170763732}