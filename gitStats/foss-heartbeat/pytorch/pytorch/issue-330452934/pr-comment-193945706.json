{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193945706", "pull_request_review_id": 127023779, "id": 193945706, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5Mzk0NTcwNg==", "diff_hunk": "@@ -0,0 +1,323 @@\n+#pragma once\n+\n+#include \"Exceptions.h\"\n+\n+#include \"miopen-wrapper.h\"\n+#include <ATen/ATen.h>\n+#include <ATen/TensorUtils.h>\n+#include <cuda.h>\n+\n+/*\n+Note [cuDNN dropout descriptor initialization]\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+In most cases, setting descriptors in cuDNN is cheap (e.g.,\n+cudnnSetTensorNdDescriptor).  However, this is not the case for\n+cudnnSetDropoutDescriptor: in cuDNN 6/7 (and possibly others) it does an\n+expensive precomputation to initialize the random number generator states.  In\n+cuDNN 6, this is the ONLY official mechanism to initialize a dropout descriptor,\n+which means that law-abiding clients were expected to generate a dropout\n+descriptor once and cache it.  However, our ATen interface is (1) stateless (so\n+we can't cache the descriptors) and (2) does not accept arbitrary user types in\n+its interface (so we can't pass the descriptor in).  This puts us in a pickle.\n+\n+In cuDNN 7, a new function, cudnnRestoreDropoutDescriptor was added, which\n+forgoes the expensive initialization process, and can initialize the\n+descriptor with a pre-initialized state CUDA tensor.  This is great, because\n+it means we can simply pass in the state tensor and then initialize the\n+descriptor internally.  Unfortunately, this function is not available in\n+cuDNN 6.\n+\n+To work around this, we break the cuDNN abstraction barrier, and have\n+the struct layout of the underlaying dropout descriptor.  With this struct,\n+we can reimplement cudnnRestoreDropoutDescriptor from scratch. Great!\n+*/\n+\n+namespace at { namespace native {\n+\n+// TODO: Add constructors for all of the descriptors\n+\n+inline int dataSize(miopenDataType_t dataType)\n+{\n+  switch (dataType) {\n+    case miopenHalf: return 2;\n+    case miopenFloat: return 4;\n+    default: return 8;\n+  }\n+}\n+\n+// The stride for a size-1 dimensions is not uniquely determined; in\n+// fact, it can be anything you want, because the fact that the\n+// tensor is size 1 at this dimension means that you will never actually\n+// try advancing your pointer by this stride.\n+//\n+// However, CuDNN has a much more stringent requirement on strides:\n+// if you are passing a contiguous input, it better be the case\n+// that the stride for dim i is the product of the sizes of dims\n+// i+1 to the end.  This stride is indeed uniquely determined.  This\n+// function modifies 'stride' in place so this invariant holds.\n+static inline void fixSizeOneDimStride(int dim, const int *size, int *stride) {\n+  int64_t z = 1;\n+  for(int d = dim-1; d >= 0; d--)\n+  {\n+    if (size[d] == 1) {\n+      stride[d] = z;\n+    } else {\n+      z *= size[d];\n+    }\n+  }\n+}\n+\n+template <typename T, miopenStatus_t (*dtor)(T*)>\n+struct DescriptorDeleter {\n+  void operator()(T* x) {\n+    if (x != nullptr) {\n+      MIOPEN_CHECK(dtor(x));\n+    }\n+  }\n+};\n+\n+// A generic class for wrapping cuDNN descriptor types.  All you need\n+// is to give the underlying type the Descriptor_t points to (usually,\n+// if it's miopenTensorDescriptor_t it points to miopenTensorStruct),\n+// the constructor and the destructor.  Subclasses are responsible\n+// for defining a set() function to actually set the descriptor.\n+//\n+// Descriptors default construct to a nullptr, and have a descriptor\n+// initialized the first time you call set() or any other initializing\n+// function.\n+template <typename T, miopenStatus_t (*ctor)(T**), miopenStatus_t (*dtor)(T*)>\n+class Descriptor\n+{\n+public:\n+  // TODO: Figure out why const-correctness doesn't work here\n+\n+  // Use desc() to access the underlying descriptor pointer in\n+  // a read-only fashion.  Most client code should use this.\n+  // If the descriptor was never initialized, this will return\n+  // nullptr.\n+  T* desc() const { return desc_.get(); }\n+  T* desc() { return desc_.get(); }\n+\n+  // Use mut_desc() to access the underlying desciptor pointer\n+  // if you intend to modify what it points to (e.g., using\n+  // miopenSetFooDescriptor).  This will ensure that the descriptor\n+  // is initialized.  Code in this file will use this function.\n+  T* mut_desc() { init(); return desc_.get(); }\n+protected:\n+  void init() {\n+    if (desc_ == nullptr) {\n+      T* raw_desc;\n+      MIOPEN_CHECK(ctor(&raw_desc));\n+      desc_.reset(raw_desc);\n+    }\n+  }\n+private:\n+  std::unique_ptr<T, DescriptorDeleter<T, dtor>> desc_;\n+};\n+\n+class TensorDescriptor\n+  : public Descriptor<miopenTensorDescriptor,\n+                      &miopenCreateTensorDescriptor,\n+                      &miopenDestroyTensorDescriptor>\n+{\n+public:\n+  TensorDescriptor() {}\n+  explicit TensorDescriptor(const at::Tensor &t, size_t pad = 0) {\n+    set(t, pad);\n+  }\n+\n+  // Note [CuDNN broadcast padding]\n+  // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+  // pad specifies the minimum dimensionality of the tensor descriptor\n+  // we produce (it doesn't have anything to do with, e.g., convolution\n+  // padding).  If 't' is lower-dimensional than 'pad', the remaining\n+  // dimensions (on the right) are padded with ones.  This doesn't\n+  // affect the underlying data layout.  This is particularly useful for\n+  // dealing with a pecularity of the CuDNN API, which is that broadcasting in CuDNN is\n+  // done in two steps: first, the client code is expected to pad out\n+  // (the dimensions) input tensors to be the same dimension as the\n+  // target broadcast, and then second, CuDNN takes of actually\n+  // broadcasting size 1 dimensions.\n+\n+  void set(const at::Tensor &t, size_t pad = 0);\n+  void set(miopenDataType_t dataType, IntList sizes, IntList strides, size_t pad = 0);\n+\n+  void print();\n+\n+private:\n+  void set(miopenDataType_t dataType, int dim, int* size, int* stride) {\n+    fixSizeOneDimStride(dim, size, stride);\n+    MIOPEN_CHECK(miopenSetTensorDescriptor(mut_desc(), dataType, dim, size, stride));\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream & out, const TensorDescriptor& d);\n+\n+class FilterDescriptor\n+  : public Descriptor<miopenTensorDescriptor,\n+                      &miopenCreateTensorDescriptor,\n+                      &miopenDestroyTensorDescriptor>\n+{\n+public:\n+  void set(const at::Tensor &t, int64_t pad = 0);\n+\n+private:\n+  void set(miopenDataType_t dataType, int dim, int* size, int* stride) {\n+    MIOPEN_CHECK(miopenSetTensorDescriptor(mut_desc(), dataType, dim, size, stride));\n+  }\n+};\n+\n+struct ConvolutionDescriptor\n+  : public Descriptor<miopenConvolutionDescriptor,\n+                      &miopenCreateConvolutionDescriptor,\n+                      &miopenDestroyConvolutionDescriptor>\n+{\n+  void set(miopenDataType_t dataType, int dim, int* pad, int* stride, int * upscale /* aka dilation */, int groups) {\n+    miopenDataType_t mathType = dataType;\n+    if (dataType == miopenHalf) mathType = miopenFloat;\n+    //?????????????? What the fuck? It's asking for the stride for the height & stride for the width seperately....!\n+    MIOPEN_CHECK(miopenInitConvolutionDescriptor(mut_desc(), miopenConvolution, *pad, *pad, *stride, *stride, 1, 1));\n+#if 0\n+    CUDNN_CHECK(cudnnSetConvolutionGroupCount(mut_desc(), groups));\n+    CUDNN_CHECK(cudnnSetConvolutionMathType(mut_desc(), CUDNN_DEFAULT_MATH));\n+    if(dataType == CUDNN_DATA_HALF)\n+      CUDNN_CHECK(cudnnSetConvolutionMathType(mut_desc(), CUDNN_TENSOR_OP_MATH));\n+#endif\n+  }\n+};\n+\n+struct SpatialTransformerDescriptor\n+  : public Descriptor<miopenSpatialTransformerStruct,\n+                      &miopenCreateSpatialTransformerDescriptor,\n+                      &miopenDestroySpatialTransformerDescriptor>\n+{\n+  void set(miopenDataType_t dataType, int dim, int* size) {\n+    //?????????????? This function doesn't even exist!", "path": "aten/src/ATen/miopen/Descriptors.h", "position": 196, "original_position": 196, "commit_id": "f483f7f5be6b4c1f978136eda606996dc29bfe12", "original_commit_id": "a59acd623ced715e840278fae8e856250aa9fe71", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "What function?", "created_at": "2018-06-08T03:39:09Z", "updated_at": "2018-11-23T15:45:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/8257#discussion_r193945706", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8257", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193945706"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8257#discussion_r193945706"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8257"}}, "body_html": "<p>What function?</p>", "body_text": "What function?"}