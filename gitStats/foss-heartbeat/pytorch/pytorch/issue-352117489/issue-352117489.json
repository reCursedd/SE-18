{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10681", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10681/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10681/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10681/events", "html_url": "https://github.com/pytorch/pytorch/issues/10681", "id": 352117489, "node_id": "MDU6SXNzdWUzNTIxMTc0ODk=", "number": 10681, "title": "nn.DataParallel hangs with Pytorch 0.4.1 and CUDA 9.1.85 on TITAN V", "user": {"login": "liren2515", "id": 23461830, "node_id": "MDQ6VXNlcjIzNDYxODMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23461830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liren2515", "html_url": "https://github.com/liren2515", "followers_url": "https://api.github.com/users/liren2515/followers", "following_url": "https://api.github.com/users/liren2515/following{/other_user}", "gists_url": "https://api.github.com/users/liren2515/gists{/gist_id}", "starred_url": "https://api.github.com/users/liren2515/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liren2515/subscriptions", "organizations_url": "https://api.github.com/users/liren2515/orgs", "repos_url": "https://api.github.com/users/liren2515/repos", "events_url": "https://api.github.com/users/liren2515/events{/privacy}", "received_events_url": "https://api.github.com/users/liren2515/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-08-20T12:42:14Z", "updated_at": "2018-10-15T17:35:25Z", "closed_at": "2018-09-05T19:14:31Z", "author_association": "NONE", "body_html": "<p>Hi guys,<br>\nI tested a simple example with nn.DataParallel() to use multiple GPUs, but got a hang.</p>\n<pre><code>epochs  = 2000\nlr = 1e-3\nmomentum = 0\nw_decay = 1e-5\n\ntrain_data = torch.randn(288,2)\ntrain_label = torch.zeros([288], dtype=torch.long)\n\nnum_gpu = list(range(torch.cuda.device_count()))\nmodel = nn.DataParallel(MyNet().cuda(0), device_ids = num_gpu)#.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = w_decay)\n\nprint \"Starting training\"\n\nmodel.train()\nfor epoch in range(epochs):\n\toptimizer.zero_grad()\n\tinputs = Variable(train_data.cuda(0))\n\tlabels = Variable(train_label.cuda(0))\n\toutputs = model(inputs)\n\tloss = criterion(outputs, labels)\n\tloss.backward()\n\toptimizer.step()\n\tprint(\"epoch{}, loss: {}\".format(epoch, loss.data.item()))\n</code></pre>\n<p>It hangs when I try to forward the data to the model. nvidia-smi gives</p>\n<pre><code>Thu Aug 16 09:56:56 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.67                 Driver Version: 390.67                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN V             Off  | 00000000:1B:00.0 Off |                  N/A |\n| 28%   39C    P8    25W / 250W |   1087MiB / 12066MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN V             Off  | 00000000:1C:00.0 Off |                  N/A |\n| 28%   41C    P2    39W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN V             Off  | 00000000:1D:00.0 Off |                  N/A |\n| 31%   45C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN V             Off  | 00000000:1E:00.0 Off |                  N/A |\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  TITAN V             Off  | 00000000:3D:00.0 Off |                  N/A |\n| 28%   39C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  TITAN V             Off  | 00000000:3E:00.0 Off |                  N/A |\n| 28%   41C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  TITAN V             Off  | 00000000:3F:00.0 Off |                  N/A |\n| 28%   40C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  TITAN V             Off  | 00000000:40:00.0 Off |                  N/A |\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   8  TITAN V             Off  | 00000000:41:00.0 Off |                  N/A |\n| 29%   43C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    131331      C   python                                      1076MiB |\n|    1    131331      C   python                                      1076MiB |\n|    2    131331      C   python                                      1076MiB |\n|    3    131331      C   python                                      1076MiB |\n|    4    131331      C   python                                      1076MiB |\n|    5    131331      C   python                                      1076MiB |\n|    6    131331      C   python                                      1076MiB |\n|    7    131331      C   python                                      1076MiB |\n|    8    131331      C   python                                      1076MiB |\n+-----------------------------------------------------------------------------+\n\n</code></pre>\n<p>I have tried the solution in <a href=\"https://github.com/pytorch/pytorch/issues/1637#issuecomment-338268158\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1637/hovercard\">this</a>, but it didn\u2019t work.</p>\n<p>I use</p>\n<ul>\n<li>CUDA 9.1.85</li>\n<li>Pytorch 0.4.1 (installed by pip)</li>\n<li>Python 2.7.13</li>\n<li>Debian 4.9.110-3+deb9u1 (2018-08-03) x86_64 GNU/Linux</li>\n<li>TITAN V cards</li>\n</ul>\n<p>Any ideas to solve this issue? Or I should let NVIDIA\u2019s folks see this issue?</p>", "body_text": "Hi guys,\nI tested a simple example with nn.DataParallel() to use multiple GPUs, but got a hang.\nepochs  = 2000\nlr = 1e-3\nmomentum = 0\nw_decay = 1e-5\n\ntrain_data = torch.randn(288,2)\ntrain_label = torch.zeros([288], dtype=torch.long)\n\nnum_gpu = list(range(torch.cuda.device_count()))\nmodel = nn.DataParallel(MyNet().cuda(0), device_ids = num_gpu)#.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = w_decay)\n\nprint \"Starting training\"\n\nmodel.train()\nfor epoch in range(epochs):\n\toptimizer.zero_grad()\n\tinputs = Variable(train_data.cuda(0))\n\tlabels = Variable(train_label.cuda(0))\n\toutputs = model(inputs)\n\tloss = criterion(outputs, labels)\n\tloss.backward()\n\toptimizer.step()\n\tprint(\"epoch{}, loss: {}\".format(epoch, loss.data.item()))\n\nIt hangs when I try to forward the data to the model. nvidia-smi gives\nThu Aug 16 09:56:56 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.67                 Driver Version: 390.67                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN V             Off  | 00000000:1B:00.0 Off |                  N/A |\n| 28%   39C    P8    25W / 250W |   1087MiB / 12066MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN V             Off  | 00000000:1C:00.0 Off |                  N/A |\n| 28%   41C    P2    39W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN V             Off  | 00000000:1D:00.0 Off |                  N/A |\n| 31%   45C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN V             Off  | 00000000:1E:00.0 Off |                  N/A |\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  TITAN V             Off  | 00000000:3D:00.0 Off |                  N/A |\n| 28%   39C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  TITAN V             Off  | 00000000:3E:00.0 Off |                  N/A |\n| 28%   41C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  TITAN V             Off  | 00000000:3F:00.0 Off |                  N/A |\n| 28%   40C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  TITAN V             Off  | 00000000:40:00.0 Off |                  N/A |\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   8  TITAN V             Off  | 00000000:41:00.0 Off |                  N/A |\n| 29%   43C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0    131331      C   python                                      1076MiB |\n|    1    131331      C   python                                      1076MiB |\n|    2    131331      C   python                                      1076MiB |\n|    3    131331      C   python                                      1076MiB |\n|    4    131331      C   python                                      1076MiB |\n|    5    131331      C   python                                      1076MiB |\n|    6    131331      C   python                                      1076MiB |\n|    7    131331      C   python                                      1076MiB |\n|    8    131331      C   python                                      1076MiB |\n+-----------------------------------------------------------------------------+\n\n\nI have tried the solution in this, but it didn\u2019t work.\nI use\n\nCUDA 9.1.85\nPytorch 0.4.1 (installed by pip)\nPython 2.7.13\nDebian 4.9.110-3+deb9u1 (2018-08-03) x86_64 GNU/Linux\nTITAN V cards\n\nAny ideas to solve this issue? Or I should let NVIDIA\u2019s folks see this issue?", "body": "Hi guys,\r\nI tested a simple example with nn.DataParallel() to use multiple GPUs, but got a hang.\r\n\r\n```\r\nepochs  = 2000\r\nlr = 1e-3\r\nmomentum = 0\r\nw_decay = 1e-5\r\n\r\ntrain_data = torch.randn(288,2)\r\ntrain_label = torch.zeros([288], dtype=torch.long)\r\n\r\nnum_gpu = list(range(torch.cuda.device_count()))\r\nmodel = nn.DataParallel(MyNet().cuda(0), device_ids = num_gpu)#.cuda()\r\ncriterion = nn.CrossEntropyLoss()\r\noptimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = w_decay)\r\n\r\nprint \"Starting training\"\r\n\r\nmodel.train()\r\nfor epoch in range(epochs):\r\n\toptimizer.zero_grad()\r\n\tinputs = Variable(train_data.cuda(0))\r\n\tlabels = Variable(train_label.cuda(0))\r\n\toutputs = model(inputs)\r\n\tloss = criterion(outputs, labels)\r\n\tloss.backward()\r\n\toptimizer.step()\r\n\tprint(\"epoch{}, loss: {}\".format(epoch, loss.data.item()))\r\n```\r\nIt hangs when I try to forward the data to the model. nvidia-smi gives\r\n\r\n```\r\nThu Aug 16 09:56:56 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.67                 Driver Version: 390.67                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN V             Off  | 00000000:1B:00.0 Off |                  N/A |\r\n| 28%   39C    P8    25W / 250W |   1087MiB / 12066MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN V             Off  | 00000000:1C:00.0 Off |                  N/A |\r\n| 28%   41C    P2    39W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN V             Off  | 00000000:1D:00.0 Off |                  N/A |\r\n| 31%   45C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN V             Off  | 00000000:1E:00.0 Off |                  N/A |\r\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  TITAN V             Off  | 00000000:3D:00.0 Off |                  N/A |\r\n| 28%   39C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  TITAN V             Off  | 00000000:3E:00.0 Off |                  N/A |\r\n| 28%   41C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  TITAN V             Off  | 00000000:3F:00.0 Off |                  N/A |\r\n| 28%   40C    P2    38W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  TITAN V             Off  | 00000000:40:00.0 Off |                  N/A |\r\n| 31%   45C    P2    40W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   8  TITAN V             Off  | 00000000:41:00.0 Off |                  N/A |\r\n| 29%   43C    P2    41W / 250W |   1087MiB / 12066MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0    131331      C   python                                      1076MiB |\r\n|    1    131331      C   python                                      1076MiB |\r\n|    2    131331      C   python                                      1076MiB |\r\n|    3    131331      C   python                                      1076MiB |\r\n|    4    131331      C   python                                      1076MiB |\r\n|    5    131331      C   python                                      1076MiB |\r\n|    6    131331      C   python                                      1076MiB |\r\n|    7    131331      C   python                                      1076MiB |\r\n|    8    131331      C   python                                      1076MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n```\r\nI have tried the solution in [this](https://github.com/pytorch/pytorch/issues/1637#issuecomment-338268158), but it didn\u2019t work.\r\n\r\nI use\r\n\r\n- CUDA 9.1.85\r\n- Pytorch 0.4.1 (installed by pip)\r\n- Python 2.7.13\r\n- Debian 4.9.110-3+deb9u1 (2018-08-03) x86_64 GNU/Linux\r\n- TITAN V cards\r\n\r\nAny ideas to solve this issue? Or I should let NVIDIA\u2019s folks see this issue?"}