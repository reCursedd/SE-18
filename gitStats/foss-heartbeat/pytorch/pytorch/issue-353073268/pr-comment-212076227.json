{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212076227", "pull_request_review_id": 148631785, "id": 212076227, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjA3NjIyNw==", "diff_hunk": "@@ -0,0 +1,192 @@\n+#include \"ATen/native/cpu/ReduceOpsKernel.h\"\n+\n+#include <numeric>\n+#include <iterator>\n+#include <algorithm>\n+\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/Parallel.h\"\n+#include \"ATen/core/optional.h\"\n+#include \"ATen/cpu/vec256/vec256.h\"\n+\n+namespace at { namespace native { namespace {\n+\n+template<typename scalar_t>\n+struct PDist {\n+\n+  static inline scalar_t sign(scalar_t val) {\n+    return (0 < val) - (val < 0);\n+  }\n+\n+  static scalar_t zdist_calc(const scalar_t * a, const scalar_t * b, const int64_t size, const int64_t stride, const double p) {\n+    scalar_t result = 0.0;\n+    for (int64_t i = 0; i != size; i += 1, a += stride, b += stride) {\n+      result += *a != *b;\n+    }\n+    return result;\n+  }\n+\n+  static scalar_t odist_calc(const scalar_t * a, const scalar_t * b, const int64_t size, const int64_t stride, const double p) {\n+    scalar_t result = 0.0;\n+    for (int64_t i = 0; i != size; i += 1, a += stride, b += stride) {\n+      result += std::abs(*a - *b);\n+    }\n+    return result;\n+  }\n+\n+  static scalar_t tdist_calc(const scalar_t * a, const scalar_t * b, const int64_t size, const int64_t stride, const double p) {\n+    scalar_t result = 0.0;\n+    for (int64_t i = 0; i != size; i += 1, a += stride, b += stride) {\n+      scalar_t diff = *a - *b;\n+      result += diff * diff;\n+    }\n+    return std::sqrt(result);\n+  }\n+\n+  static scalar_t pdist_calc(const scalar_t * a, const scalar_t * b, const int64_t size, const int64_t stride, const double p) {\n+    scalar_t result = 0.0;\n+    for (int64_t i = 0; i != size; i += 1, a += stride, b += stride) {\n+      result += std::pow(std::abs(*a - *b), p);\n+    }\n+    return std::pow(result, 1.0 / p);\n+  }\n+\n+  static scalar_t idist_calc(const scalar_t * a, const scalar_t * b, const int64_t size, const int64_t stride, const double p) {\n+    scalar_t result = 0.0;\n+    for (int64_t i = 0; i != size; i += 1, a += stride, b += stride) {\n+      result = std::max(result, std::abs(*a - *b));\n+    }\n+    return result;\n+  }\n+\n+  template <scalar_t (*F)(const scalar_t *, const scalar_t *, const int64_t, const int64_t, const double)>\n+  static void run_parallel(Tensor& result, const Tensor& self, const double p) {\n+    auto res_ = result.data<scalar_t>();\n+    auto self_ = self.data<scalar_t>();\n+    int64_t n = self.size(0);\n+    int64_t m = self.size(1);\n+    int64_t ns = self.stride(0);\n+    int64_t ms = self.stride(1);\n+\n+    int64_t combs = n * (n - 1) / 2;\n+    parallel_for(0, combs, 1, [=](int64_t k, int64_t end) {\n+      float n2 = n - .5;\n+      // The -1 accounts for floating point truncation issues\n+      int64_t i = (int64_t) ((n2 - std::sqrt(n2 * n2 - 2 * k - 1)));", "path": "aten/src/ATen/native/cpu/DistanceOpsKernel.cpp", "position": null, "original_position": 75, "commit_id": "0d26aa6f1e62e3c44da085ecff3f94883cb56d21", "original_commit_id": "88025fe7776fbcfbbb87a0df1f7249348100020b", "user": {"login": "erikbrinkman", "id": 858926, "node_id": "MDQ6VXNlcjg1ODkyNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/858926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erikbrinkman", "html_url": "https://github.com/erikbrinkman", "followers_url": "https://api.github.com/users/erikbrinkman/followers", "following_url": "https://api.github.com/users/erikbrinkman/following{/other_user}", "gists_url": "https://api.github.com/users/erikbrinkman/gists{/gist_id}", "starred_url": "https://api.github.com/users/erikbrinkman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erikbrinkman/subscriptions", "organizations_url": "https://api.github.com/users/erikbrinkman/orgs", "repos_url": "https://api.github.com/users/erikbrinkman/repos", "events_url": "https://api.github.com/users/erikbrinkman/events{/privacy}", "received_events_url": "https://api.github.com/users/erikbrinkman/received_events", "type": "User", "site_admin": false}, "body": "The only other solutions I can think of are to ahead of time:\r\n```\r\nvector<int64_t> lookup();\r\nlookup.reserve(combs);\r\nfor (int64_t i = 0; i != n - 1; ++i) {\r\n  for (int64_t j = i + 1; j != n; ++j) {\r\n    lookup.push(i);\r\n  }\r\n}\r\n```\r\n\r\nand then later `int64_t i = lookup[k]`.\r\n\r\nalternatively, we can ignore the startup time and memory for an O(n) computation:\r\n```\r\nint64_t kc = k;\r\nint64_t i = 0;\r\nfor (int64_t kc = k, step = n - 1; kc >= step; i += 1, kc -= step, step -= 1) {}\r\n```\r\n\r\nThis might be faster than the sqrt, but it's unclear. If you have a preference I can change it, but I doubt this is ever a bottleneck.", "created_at": "2018-08-22T19:17:55Z", "updated_at": "2018-11-23T15:49:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/10782#discussion_r212076227", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10782", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212076227"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10782#discussion_r212076227"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10782"}}, "body_html": "<p>The only other solutions I can think of are to ahead of time:</p>\n<pre><code>vector&lt;int64_t&gt; lookup();\nlookup.reserve(combs);\nfor (int64_t i = 0; i != n - 1; ++i) {\n  for (int64_t j = i + 1; j != n; ++j) {\n    lookup.push(i);\n  }\n}\n</code></pre>\n<p>and then later <code>int64_t i = lookup[k]</code>.</p>\n<p>alternatively, we can ignore the startup time and memory for an O(n) computation:</p>\n<pre><code>int64_t kc = k;\nint64_t i = 0;\nfor (int64_t kc = k, step = n - 1; kc &gt;= step; i += 1, kc -= step, step -= 1) {}\n</code></pre>\n<p>This might be faster than the sqrt, but it's unclear. If you have a preference I can change it, but I doubt this is ever a bottleneck.</p>", "body_text": "The only other solutions I can think of are to ahead of time:\nvector<int64_t> lookup();\nlookup.reserve(combs);\nfor (int64_t i = 0; i != n - 1; ++i) {\n  for (int64_t j = i + 1; j != n; ++j) {\n    lookup.push(i);\n  }\n}\n\nand then later int64_t i = lookup[k].\nalternatively, we can ignore the startup time and memory for an O(n) computation:\nint64_t kc = k;\nint64_t i = 0;\nfor (int64_t kc = k, step = n - 1; kc >= step; i += 1, kc -= step, step -= 1) {}\n\nThis might be faster than the sqrt, but it's unclear. If you have a preference I can change it, but I doubt this is ever a bottleneck.", "in_reply_to_id": 212067042}