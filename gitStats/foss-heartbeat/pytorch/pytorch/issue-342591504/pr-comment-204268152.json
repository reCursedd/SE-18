{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204268152", "pull_request_review_id": 139315819, "id": 204268152, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDI2ODE1Mg==", "diff_hunk": "@@ -156,10 +153,55 @@ void PropagateShapeOnNodeByRunningIt(Node* node, const std::vector<TensorType*>&\n \n   JIT_ASSERT(stack.size() == node->outputs().size());\n   for (size_t i = 0; i < stack.size(); ++i) {\n-    node->outputs()[i]->inferTypeFrom(stack[i].toTensor());\n+    // some ops may have mixed tensor/primitive outputs\n+    // for primitives, we don't need to change the type because it is already\n+    // its most constrained form.\n+    if(stack[i].isTensor())\n+      node->outputs()[i]->inferTypeFrom(stack[i].toTensor());\n   }\n }\n \n+// is it ok to try to run the op\n+// If an input is a constant, then we assume that the input is valid\n+// and we can try to run it.\n+// Otherwise:\n+// Integral typed _inputs_ are often an indicator that we're indexing into\n+// a tensor, so we should special-case these ops in the shape propagation.\n+// Additionally, passing in a zero representative tensor into an integer\n+// division op causes divide-by-zero errors\n+// _Outputs_ must be tensors or primtives\n+// We will call inferTypeFrom on the tensors, and ignore the primitives.\n+// However, we allow primitive returns because we want to support mixed\n+// primitive/tensor outputs.\n+\n+bool isValidArgumentForRunning(Value* v) {\n+  // allow constants\n+  if(toIValue(v))\n+    return true;\n+  if(TensorType* tt = v->type()->cast<TensorType>()) {\n+    return !at::isIntegralType(tt->scalarType());\n+  }\n+  return v->type()->isSubtypeOf(*FloatType::get());\n+}\n+bool isValidReturnForRunning(Value* v) {\n+  return v->type()->isSubtypeOf(*DynamicType::get()) ||\n+      v->type()->isSubtypeOf(*NumberType::get());", "path": "torch/csrc/jit/passes/shape_analysis.cpp", "position": 195, "original_position": 195, "commit_id": "6a9e59de5c6c7e7821e48863cd70d8fee3fc1870", "original_commit_id": "63bc34a152d3d9259c71b5c2318e335b2f6c25db", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "It is a whitelist, so as not to do something silly when we add a new type.", "created_at": "2018-07-23T02:13:09Z", "updated_at": "2018-11-23T15:47:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/9584#discussion_r204268152", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9584", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204268152"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9584#discussion_r204268152"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9584"}}, "body_html": "<p>It is a whitelist, so as not to do something silly when we add a new type.</p>", "body_text": "It is a whitelist, so as not to do something silly when we add a new type.", "in_reply_to_id": 204263011}