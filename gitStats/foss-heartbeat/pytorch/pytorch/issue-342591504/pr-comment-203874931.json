{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203874931", "pull_request_review_id": 138839907, "id": 203874931, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzg3NDkzMQ==", "diff_hunk": "@@ -102,8 +112,55 @@ void PropagateShapeOnNodeByRunningIt(Node* node, const std::vector<TensorType*>&\n \n   JIT_ASSERT(stack.size() == node->outputs().size());\n   for(size_t i = 0; i < stack.size(); ++i) {\n-    node->outputs()[i]->inferTypeFrom(stack[i].toTensor());\n+    // some ops may have mixed tensor/primitive outputs\n+    // for primitives, we don't need to change the type because it is already\n+    // its most constrained form.\n+    if(stack[i].isTensor())\n+      node->outputs()[i]->inferTypeFrom(stack[i].toTensor());\n+  }\n+}\n+\n+// is it ok to try to run the op\n+// whitelist for certain ops where we know it is always ok\n+// Integral typed _inputs_ are often an indicator that we're indexing into\n+// a tensor, so we should special-case these ops in the shape propagation.\n+// Additionally, passing in a zero representative tensor into an integer\n+// division op causes divide-by-zero errors\n+// _Outputs_ must be tensors or primtives\n+// We will call inferTypeFrom on the tensors, and ignore the primitives.\n+// However, we allow primitive returns because we want to support mixed\n+// primitive/tensor outputs.\n+\n+bool isValidArgumentForRunning(Value* v) {\n+  if(TensorType* tt = v->type()->cast<TensorType>()) {\n+    return !at::isIntegralType(tt->scalarType());\n   }\n+  return v->type()->isSubtypeOf(*FloatType::get());\n+}\n+bool isValidReturnForRunning(Value* v) {\n+  return v->type()->isSubtypeOf(*DynamicType::get()) ||\n+      v->type()->isSubtypeOf(*NumberType::get());\n+}\n+\n+bool canPropagateShapeByRunningIt(Node* node) {\n+  static std::unordered_set<Symbol> whitelist = {\n+    aten::type_as,", "path": "torch/csrc/jit/passes/shape_analysis.cpp", "position": null, "original_position": 88, "commit_id": "6a9e59de5c6c7e7821e48863cd70d8fee3fc1870", "original_commit_id": "d185b8f5c2bc76ff588b66d28a20e268cf4e91f5", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "`type_as` shape inference is really simple, and I have it implemented in my PR", "created_at": "2018-07-19T21:16:04Z", "updated_at": "2018-11-23T15:47:45Z", "html_url": "https://github.com/pytorch/pytorch/pull/9584#discussion_r203874931", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9584", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203874931"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9584#discussion_r203874931"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9584"}}, "body_html": "<p><code>type_as</code> shape inference is really simple, and I have it implemented in my PR</p>", "body_text": "type_as shape inference is really simple, and I have it implemented in my PR"}