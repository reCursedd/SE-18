{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13566", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13566/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13566/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13566/events", "html_url": "https://github.com/pytorch/pytorch/issues/13566", "id": 377353681, "node_id": "MDU6SXNzdWUzNzczNTM2ODE=", "number": 13566, "title": "[jit] Have a way to trace custom ops with std::vector<Tensor>", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-05T11:15:54Z", "updated_at": "2018-11-09T14:25:32Z", "closed_at": "2018-11-09T14:25:32Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"rocket\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f680.png\">\ud83d\ude80</g-emoji> Feature</h2>\n<p>Sometimes, you want to have a list of tensors in a custom op.<br>\nThis works with JIT script by using the <code>List[Tensor]</code> type, but apparently not with tracing (which doesn't like lists, but only tuples).</p>\n<h2>Motivation</h2>\n<p>I found this while working on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"374238665\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/facebookresearch/maskrcnn-benchmark/issues/27\" data-hovercard-type=\"issue\" data-hovercard-url=\"/facebookresearch/maskrcnn-benchmark/issues/27/hovercard?comment_id=435789228&amp;comment_type=issue_comment\" href=\"https://github.com/facebookresearch/maskrcnn-benchmark/issues/27#issuecomment-435789228\">facebookresearch/maskrcnn-benchmark#27 (comment)</a><br>\nGenerally many operations have lists of tensors as arguments, and so there should be a good JIT path for them.</p>\n<h2>Pitch</h2>\n<p>I should be able to trace the custom op here somehow:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.jit\n<span class=\"pl-k\">from</span> typing <span class=\"pl-k\">import</span> List, Tuple\ncsrc <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">#include &lt;torch/extension.h&gt;</span>\n<span class=\"pl-s\">#include &lt;torch/script.h&gt;</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">using namespace at;</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">Tensor test(std::vector&lt;Tensor&gt; inps) {  </span>\n<span class=\"pl-s\">  return inps[0] * 2; // not terribly safe!</span>\n<span class=\"pl-s\">}</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">static auto registry =</span>\n<span class=\"pl-s\">  torch::jit::RegisterOperators()</span>\n<span class=\"pl-s\">    .op(\"mytest::test\", &amp;test);</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {</span>\n<span class=\"pl-s\">  m.def(\"test\", &amp;test, \"super test!\");</span>\n<span class=\"pl-s\">}</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n\n<span class=\"pl-k\">import</span> torch.utils.cpp_extension\n\next <span class=\"pl-k\">=</span> torch.utils.cpp_extension.load_inline(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test<span class=\"pl-pds\">\"</span></span>, [csrc], <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                                            <span class=\"pl-v\">extra_ldflags</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>-ltorch<span class=\"pl-pds\">'</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>-lcaffe2<span class=\"pl-pds\">'</span></span>,\n                                                           <span class=\"pl-s\"><span class=\"pl-pds\">'</span>-L<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">+</span>os.path.join(os.path.dirname(torch._C.<span class=\"pl-c1\">__file__</span>), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>lib<span class=\"pl-pds\">'</span></span>) ])\ntorch.ops.load_library(ext.<span class=\"pl-c1\">__file__</span>)\n\nt <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">print</span>(torch.ops.mytest.test([t])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> works</span>\n\n<span class=\"pl-en\">@torch.jit.script</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">test_wrapper</span>(<span class=\"pl-smi\">ts</span> : List[torch.Tensor]): <span class=\"pl-c\"><span class=\"pl-c\">#</span> need to do list!</span>\n    <span class=\"pl-k\">return</span> torch.ops.mytest.test(ts)\n\n<span class=\"pl-c1\">print</span> (test_wrapper([t])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> works</span>\n\n<span class=\"pl-c1\">print</span> (test_wrapper((t,))) <span class=\"pl-c\"><span class=\"pl-c\">#</span> works</span>\n\n<span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>doesn't work<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c1\">print</span> (torch.jit.trace(test_wrapper, ((t,),)))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> doesn't work</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> and I cannot be make it work</span>\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> the canonical way to do Tuples of arbitrary lengths (?)</span>\n<span class=\"pl-en\">@torch.jit.script</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">test_wrapper2</span>(<span class=\"pl-smi\">ts</span> : Tuple[torch.Tensor, <span class=\"pl-c1\">...</span>]): <span class=\"pl-c\"><span class=\"pl-c\">#</span> doesn't work</span>\n    <span class=\"pl-k\">return</span> torch.ops.mytest.test(ts)\n</pre></div>\n<h2>Context</h2>\n<p>Maybe the easiest way is to accept tuples into lists while tracing, but I didn't check in detail.</p>", "body_text": "\ud83d\ude80 Feature\nSometimes, you want to have a list of tensors in a custom op.\nThis works with JIT script by using the List[Tensor] type, but apparently not with tracing (which doesn't like lists, but only tuples).\nMotivation\nI found this while working on facebookresearch/maskrcnn-benchmark#27 (comment)\nGenerally many operations have lists of tensors as arguments, and so there should be a good JIT path for them.\nPitch\nI should be able to trace the custom op here somehow:\nimport os\nimport torch\nimport torch.jit\nfrom typing import List, Tuple\ncsrc = \"\"\"\n#include <torch/extension.h>\n#include <torch/script.h>\n\nusing namespace at;\n\nTensor test(std::vector<Tensor> inps) {  \n  return inps[0] * 2; // not terribly safe!\n}\n\nstatic auto registry =\n  torch::jit::RegisterOperators()\n    .op(\"mytest::test\", &test);\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n  m.def(\"test\", &test, \"super test!\");\n}\n\"\"\"\n\nimport torch.utils.cpp_extension\n\next = torch.utils.cpp_extension.load_inline(\"test\", [csrc], verbose=True,\n                                            extra_ldflags=['-ltorch','-lcaffe2',\n                                                           '-L'+os.path.join(os.path.dirname(torch._C.__file__), 'lib') ])\ntorch.ops.load_library(ext.__file__)\n\nt = torch.randn(5)\nprint(torch.ops.mytest.test([t])) # works\n\n@torch.jit.script\ndef test_wrapper(ts : List[torch.Tensor]): # need to do list!\n    return torch.ops.mytest.test(ts)\n\nprint (test_wrapper([t])) # works\n\nprint (test_wrapper((t,))) # works\n\nprint (\"doesn't work\")\n\nprint (torch.jit.trace(test_wrapper, ((t,),)))  # doesn't work\n# and I cannot be make it work\n\n\n# the canonical way to do Tuples of arbitrary lengths (?)\n@torch.jit.script\ndef test_wrapper2(ts : Tuple[torch.Tensor, ...]): # doesn't work\n    return torch.ops.mytest.test(ts)\n\nContext\nMaybe the easiest way is to accept tuples into lists while tracing, but I didn't check in detail.", "body": "## \ud83d\ude80 Feature\r\n\r\nSometimes, you want to have a list of tensors in a custom op.\r\nThis works with JIT script by using the `List[Tensor]` type, but apparently not with tracing (which doesn't like lists, but only tuples).\r\n\r\n## Motivation\r\n\r\nI found this while working on https://github.com/facebookresearch/maskrcnn-benchmark/issues/27#issuecomment-435789228\r\nGenerally many operations have lists of tensors as arguments, and so there should be a good JIT path for them.\r\n\r\n## Pitch\r\n\r\nI should be able to trace the custom op here somehow:\r\n```python\r\nimport os\r\nimport torch\r\nimport torch.jit\r\nfrom typing import List, Tuple\r\ncsrc = \"\"\"\r\n#include <torch/extension.h>\r\n#include <torch/script.h>\r\n\r\nusing namespace at;\r\n\r\nTensor test(std::vector<Tensor> inps) {  \r\n  return inps[0] * 2; // not terribly safe!\r\n}\r\n\r\nstatic auto registry =\r\n  torch::jit::RegisterOperators()\r\n    .op(\"mytest::test\", &test);\r\n\r\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\r\n  m.def(\"test\", &test, \"super test!\");\r\n}\r\n\"\"\"\r\n\r\nimport torch.utils.cpp_extension\r\n\r\next = torch.utils.cpp_extension.load_inline(\"test\", [csrc], verbose=True,\r\n                                            extra_ldflags=['-ltorch','-lcaffe2',\r\n                                                           '-L'+os.path.join(os.path.dirname(torch._C.__file__), 'lib') ])\r\ntorch.ops.load_library(ext.__file__)\r\n\r\nt = torch.randn(5)\r\nprint(torch.ops.mytest.test([t])) # works\r\n\r\n@torch.jit.script\r\ndef test_wrapper(ts : List[torch.Tensor]): # need to do list!\r\n    return torch.ops.mytest.test(ts)\r\n\r\nprint (test_wrapper([t])) # works\r\n\r\nprint (test_wrapper((t,))) # works\r\n\r\nprint (\"doesn't work\")\r\n\r\nprint (torch.jit.trace(test_wrapper, ((t,),)))  # doesn't work\r\n# and I cannot be make it work\r\n\r\n\r\n# the canonical way to do Tuples of arbitrary lengths (?)\r\n@torch.jit.script\r\ndef test_wrapper2(ts : Tuple[torch.Tensor, ...]): # doesn't work\r\n    return torch.ops.mytest.test(ts)\r\n\r\n```\r\n\r\n## Context\r\n\r\nMaybe the easiest way is to accept tuples into lists while tracing, but I didn't check in detail."}