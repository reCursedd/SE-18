{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12647", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12647/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12647/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12647/events", "html_url": "https://github.com/pytorch/pytorch/issues/12647", "id": 370122150, "node_id": "MDU6SXNzdWUzNzAxMjIxNTA=", "number": 12647, "title": "Upsample ONNX op uses wrong mode", "user": {"login": "ahirner", "id": 6055037, "node_id": "MDQ6VXNlcjYwNTUwMzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6055037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahirner", "html_url": "https://github.com/ahirner", "followers_url": "https://api.github.com/users/ahirner/followers", "following_url": "https://api.github.com/users/ahirner/following{/other_user}", "gists_url": "https://api.github.com/users/ahirner/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahirner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahirner/subscriptions", "organizations_url": "https://api.github.com/users/ahirner/orgs", "repos_url": "https://api.github.com/users/ahirner/repos", "events_url": "https://api.github.com/users/ahirner/events{/privacy}", "received_events_url": "https://api.github.com/users/ahirner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-15T11:38:29Z", "updated_at": "2018-10-16T00:15:57Z", "closed_at": "2018-10-16T00:15:57Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Current <code>torch.onnx.symbolic.upsample_bilinear2d</code> specifies mode <code>bilinear</code>. ONNX-7 defines only two modes where <code>linear</code> <a href=\"https://github.com/onnx/onnx/blob/master/docs/Operators.md#Upsample\">includes</a> bilinear and trilinear.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<pre><code>import torch\nimport torch.nn.functional as F\nimport onnxruntime as rt\n\nclass Upsample(torch.nn.Module):\n    def forward(self, x):\n        return F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n\nm = Upsample()\nv = torch.randn(1,3,128,128, dtype=torch.float32, requires_grad=False)\n\ntorch.onnx.export(m, v, \"test.onnx\")\nsess = rt.InferenceSession(\"test.onnx\")\n</code></pre>\n<p>onnxruntime errors on:</p>\n<pre><code>---&gt; 13 sess = rt.InferenceSession(\"test.onnx\")\n\n~/miniconda3/envs/fat-ml/lib/python3.6/site-packages/onnxruntime/capi/session.py in __init__(self, path_or_bytes, sess_options)\n     26 \n     27         if isinstance(path_or_bytes, str):\n---&gt; 28             self._sess.load_model(path_or_bytes)\n     29         elif isinstance(path_or_bytes, bytes):\n     30             self._sess.read_bytes(path_or_bytes)\n\nRuntimeError: [LotusError] : 1 : GENERAL ERROR : Exception during initialization: /data/ubuntu/vstsagent/_work/39/s/cmake/../onnxruntime/core/providers/cpu/tensor/upsample.h:43 onnxruntime::UpsampleBase::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const string&amp;) mode attribute is bilinear. It can only be nearest(default) or linear.\n</code></pre>\n<h2>Expected behavior</h2>\n<p>Mode for ONNX op should be <code>linear</code>, the correct dimensionality should be encoded into <code>scale_f</code>.</p>\n<h2>Environment</h2>\n<pre><code>PyTorch version: 1.0.0.dev20181012\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.11.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.1.85\n\nVersions of relevant libraries:\n[conda] torch-nightly             1.0.0.dev20181012           &lt;pip&gt;\n\n</code></pre>", "body_text": "\ud83d\udc1b Bug\nCurrent torch.onnx.symbolic.upsample_bilinear2d specifies mode bilinear. ONNX-7 defines only two modes where linear includes bilinear and trilinear.\nTo Reproduce\nSteps to reproduce the behavior:\nimport torch\nimport torch.nn.functional as F\nimport onnxruntime as rt\n\nclass Upsample(torch.nn.Module):\n    def forward(self, x):\n        return F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n\nm = Upsample()\nv = torch.randn(1,3,128,128, dtype=torch.float32, requires_grad=False)\n\ntorch.onnx.export(m, v, \"test.onnx\")\nsess = rt.InferenceSession(\"test.onnx\")\n\nonnxruntime errors on:\n---> 13 sess = rt.InferenceSession(\"test.onnx\")\n\n~/miniconda3/envs/fat-ml/lib/python3.6/site-packages/onnxruntime/capi/session.py in __init__(self, path_or_bytes, sess_options)\n     26 \n     27         if isinstance(path_or_bytes, str):\n---> 28             self._sess.load_model(path_or_bytes)\n     29         elif isinstance(path_or_bytes, bytes):\n     30             self._sess.read_bytes(path_or_bytes)\n\nRuntimeError: [LotusError] : 1 : GENERAL ERROR : Exception during initialization: /data/ubuntu/vstsagent/_work/39/s/cmake/../onnxruntime/core/providers/cpu/tensor/upsample.h:43 onnxruntime::UpsampleBase::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const string&) mode attribute is bilinear. It can only be nearest(default) or linear.\n\nExpected behavior\nMode for ONNX op should be linear, the correct dimensionality should be encoded into scale_f.\nEnvironment\nPyTorch version: 1.0.0.dev20181012\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.11.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.1.85\n\nVersions of relevant libraries:\n[conda] torch-nightly             1.0.0.dev20181012           <pip>", "body": "## \ud83d\udc1b Bug\r\n\r\nCurrent `torch.onnx.symbolic.upsample_bilinear2d` specifies mode `bilinear`. ONNX-7 defines only two modes where `linear` [includes](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Upsample) bilinear and trilinear. \r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\nimport onnxruntime as rt\r\n\r\nclass Upsample(torch.nn.Module):\r\n    def forward(self, x):\r\n        return F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\r\n\r\nm = Upsample()\r\nv = torch.randn(1,3,128,128, dtype=torch.float32, requires_grad=False)\r\n\r\ntorch.onnx.export(m, v, \"test.onnx\")\r\nsess = rt.InferenceSession(\"test.onnx\")\r\n```\r\n\r\nonnxruntime errors on:\r\n```\r\n---> 13 sess = rt.InferenceSession(\"test.onnx\")\r\n\r\n~/miniconda3/envs/fat-ml/lib/python3.6/site-packages/onnxruntime/capi/session.py in __init__(self, path_or_bytes, sess_options)\r\n     26 \r\n     27         if isinstance(path_or_bytes, str):\r\n---> 28             self._sess.load_model(path_or_bytes)\r\n     29         elif isinstance(path_or_bytes, bytes):\r\n     30             self._sess.read_bytes(path_or_bytes)\r\n\r\nRuntimeError: [LotusError] : 1 : GENERAL ERROR : Exception during initialization: /data/ubuntu/vstsagent/_work/39/s/cmake/../onnxruntime/core/providers/cpu/tensor/upsample.h:43 onnxruntime::UpsampleBase::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const string&) mode attribute is bilinear. It can only be nearest(default) or linear.\r\n```\r\n\r\n## Expected behavior\r\n\r\nMode for ONNX op should be `linear`, the correct dimensionality should be encoded into `scale_f`.\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.0.0.dev20181012\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.11.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.1.85\r\n\r\nVersions of relevant libraries:\r\n[conda] torch-nightly             1.0.0.dev20181012           <pip>\r\n\r\n```"}