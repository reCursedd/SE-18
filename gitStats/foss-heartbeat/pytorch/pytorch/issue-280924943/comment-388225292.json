{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/388225292", "html_url": "https://github.com/pytorch/pytorch/issues/4107#issuecomment-388225292", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4107", "id": 388225292, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODIyNTI5Mg==", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-11T00:34:32Z", "updated_at": "2018-05-11T00:44:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17520413\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wasiahmad\">@wasiahmad</a> I found this trick when using <code>Conv2dTranspose</code> with 1-channel in &amp; 1-channel out.</p>\n<p>CUDNN's <code>Conv2dTranspose</code> (which is basically the backward of <code>Conv2d</code>) seems to hate 1-channel input/output. So just add some dummy input&amp;output channels.<br>\nTiny tricks:<br>\n<code>groups=2</code> would use depthwise conv, which should minimize the extra cost that u need, and make sure that the 1st out-channel is not related to the 2nd in-channel at all.<br>\n<code>[:,:1,:,:]</code> slicing would keep the dimension while <code>[:,0,:,:]</code> won't.</p>\n<p>To talk about <code>repeat</code>, I guess it is faster than concating a new zero or un-initialized tensor. But I haven't tested it.</p>", "body_text": "@wasiahmad I found this trick when using Conv2dTranspose with 1-channel in & 1-channel out.\nCUDNN's Conv2dTranspose (which is basically the backward of Conv2d) seems to hate 1-channel input/output. So just add some dummy input&output channels.\nTiny tricks:\ngroups=2 would use depthwise conv, which should minimize the extra cost that u need, and make sure that the 1st out-channel is not related to the 2nd in-channel at all.\n[:,:1,:,:] slicing would keep the dimension while [:,0,:,:] won't.\nTo talk about repeat, I guess it is faster than concating a new zero or un-initialized tensor. But I haven't tested it.", "body": "@wasiahmad I found this trick when using `Conv2dTranspose` with 1-channel in & 1-channel out.\r\n\r\nCUDNN's `Conv2dTranspose` (which is basically the backward of `Conv2d`) seems to hate 1-channel input/output. So just add some dummy input&output channels. \r\nTiny tricks:\r\n`groups=2` would use depthwise conv, which should minimize the extra cost that u need, and make sure that the 1st out-channel is not related to the 2nd in-channel at all.\r\n`[:,:1,:,:]` slicing would keep the dimension while `[:,0,:,:]` won't.\r\n\r\nTo talk about `repeat`, I guess it is faster than concating a new zero or un-initialized tensor. But I haven't tested it."}