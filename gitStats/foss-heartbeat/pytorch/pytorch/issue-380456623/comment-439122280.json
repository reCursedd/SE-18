{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/439122280", "html_url": "https://github.com/pytorch/pytorch/pull/13933#issuecomment-439122280", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13933", "id": 439122280, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTEyMjI4MA==", "user": {"login": "igormq", "id": 623536, "node_id": "MDQ6VXNlcjYyMzUzNg==", "avatar_url": "https://avatars0.githubusercontent.com/u/623536?v=4", "gravatar_id": "", "url": "https://api.github.com/users/igormq", "html_url": "https://github.com/igormq", "followers_url": "https://api.github.com/users/igormq/followers", "following_url": "https://api.github.com/users/igormq/following{/other_user}", "gists_url": "https://api.github.com/users/igormq/gists{/gist_id}", "starred_url": "https://api.github.com/users/igormq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/igormq/subscriptions", "organizations_url": "https://api.github.com/users/igormq/orgs", "repos_url": "https://api.github.com/users/igormq/repos", "events_url": "https://api.github.com/users/igormq/events{/privacy}", "received_events_url": "https://api.github.com/users/igormq/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T17:27:16Z", "updated_at": "2018-11-15T17:28:10Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=582713\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nairbv\">@nairbv</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>, I think that I know what might be causing the exception.</p>\n<p>In <a href=\"https://github.com/pytorch/pytorch/blob/a14623f50b6fa20eb708f99074117c3b283f88c6/aten/src/ATen/native/PackedSequence.cpp#L33\">Line 33</a>, we have:</p>\n<div class=\"highlight highlight-source-c++\"><pre>at::Tensor <span class=\"pl-c1\">batch_sizes_t</span> = at::empty(lengths[<span class=\"pl-c1\">0</span>], _lengths.options());</pre></div>\n<p>If the parameter <code>lengths</code> is not sorted, <code>lengths[0]</code> does not have the maximum length, so you guys are probably allocating <code>batch_sizes_t</code> with the wrong size, which could explain the exception in Line 67.</p>\n<p>So this code should be something like (I have no skill using the ATEN library :( )</p>\n<div class=\"highlight highlight-source-c++\"><pre>at::Tensor <span class=\"pl-c1\">batch_sizes_t</span> = at::empty(at::max(lengths), _lengths.options());</pre></div>\n<p>(I do no if <code>at::max</code> exists, but it gives you the idea)</p>\n<p>am I right? Does it make sense for you guys? I did not test anything, just pass my eyes through the code, so the probability of my analysis is wrong is really high. Hope I could help.</p>", "body_text": "Hi @nairbv and @apaszke, I think that I know what might be causing the exception.\nIn Line 33, we have:\nat::Tensor batch_sizes_t = at::empty(lengths[0], _lengths.options());\nIf the parameter lengths is not sorted, lengths[0] does not have the maximum length, so you guys are probably allocating batch_sizes_t with the wrong size, which could explain the exception in Line 67.\nSo this code should be something like (I have no skill using the ATEN library :( )\nat::Tensor batch_sizes_t = at::empty(at::max(lengths), _lengths.options());\n(I do no if at::max exists, but it gives you the idea)\nam I right? Does it make sense for you guys? I did not test anything, just pass my eyes through the code, so the probability of my analysis is wrong is really high. Hope I could help.", "body": "Hi @nairbv and @apaszke, I think that I know what might be causing the exception.\r\n\r\nIn [Line 33](https://github.com/pytorch/pytorch/blob/a14623f50b6fa20eb708f99074117c3b283f88c6/aten/src/ATen/native/PackedSequence.cpp#L33), we have:\r\n```c++\r\nat::Tensor batch_sizes_t = at::empty(lengths[0], _lengths.options());\r\n```\r\n\r\nIf the parameter `lengths` is not sorted, `lengths[0]` does not have the maximum length, so you guys are probably allocating `batch_sizes_t` with the wrong size, which could explain the exception in Line 67.\r\n\r\nSo this code should be something like (I have no skill using the ATEN library :( )\r\n```c++\r\nat::Tensor batch_sizes_t = at::empty(at::max(lengths), _lengths.options());\r\n```\r\n(I do no if `at::max` exists, but it gives you the idea)\r\n\r\nam I right? Does it make sense for you guys? I did not test anything, just pass my eyes through the code, so the probability of my analysis is wrong is really high. Hope I could help."}