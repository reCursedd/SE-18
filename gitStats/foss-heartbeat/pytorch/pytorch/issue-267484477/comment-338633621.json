{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/338633621", "html_url": "https://github.com/pytorch/pytorch/issues/3223#issuecomment-338633621", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3223", "id": 338633621, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODYzMzYyMQ==", "user": {"login": "ptrblck", "id": 11662379, "node_id": "MDQ6VXNlcjExNjYyMzc5", "avatar_url": "https://avatars3.githubusercontent.com/u/11662379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptrblck", "html_url": "https://github.com/ptrblck", "followers_url": "https://api.github.com/users/ptrblck/followers", "following_url": "https://api.github.com/users/ptrblck/following{/other_user}", "gists_url": "https://api.github.com/users/ptrblck/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptrblck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptrblck/subscriptions", "organizations_url": "https://api.github.com/users/ptrblck/orgs", "repos_url": "https://api.github.com/users/ptrblck/repos", "events_url": "https://api.github.com/users/ptrblck/events{/privacy}", "received_events_url": "https://api.github.com/users/ptrblck/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-23T11:48:28Z", "updated_at": "2017-10-23T11:50:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You can add this code to test it on your machine:</p>\n<pre><code>print(timeit.timeit('size_splits(tensor=torch.randn(200, 10, 2, 2), split_sizes=[5]*40, dim=0)',\n              setup='from __main__ import size_splits\\nimport torch', number=10000))\nprint(timeit.timeit('torch.split(tensor=torch.randn(200, 10, 2, 2), split_size=5, dim=0)',\n              setup='import torch', number=10000))\n</code></pre>\n<p>This yields for<br>\nsize_splits: 6.991s<br>\ntorch.split: 6.704s</p>\n<p>I'm comparing equally sized chunks, since that is what <code>torch.split</code> is doing.</p>\n<p>EDIT: Any suggestion for speed improvement is welcome!</p>", "body_text": "You can add this code to test it on your machine:\nprint(timeit.timeit('size_splits(tensor=torch.randn(200, 10, 2, 2), split_sizes=[5]*40, dim=0)',\n              setup='from __main__ import size_splits\\nimport torch', number=10000))\nprint(timeit.timeit('torch.split(tensor=torch.randn(200, 10, 2, 2), split_size=5, dim=0)',\n              setup='import torch', number=10000))\n\nThis yields for\nsize_splits: 6.991s\ntorch.split: 6.704s\nI'm comparing equally sized chunks, since that is what torch.split is doing.\nEDIT: Any suggestion for speed improvement is welcome!", "body": "You can add this code to test it on your machine:\r\n\r\n    print(timeit.timeit('size_splits(tensor=torch.randn(200, 10, 2, 2), split_sizes=[5]*40, dim=0)',\r\n                  setup='from __main__ import size_splits\\nimport torch', number=10000))\r\n    print(timeit.timeit('torch.split(tensor=torch.randn(200, 10, 2, 2), split_size=5, dim=0)',\r\n                  setup='import torch', number=10000))\r\n\r\nThis yields for \r\nsize_splits: 6.991s\r\ntorch.split: 6.704s\r\n\r\nI'm comparing equally sized chunks, since that is what `torch.split` is doing.\r\n\r\nEDIT: Any suggestion for speed improvement is welcome!"}