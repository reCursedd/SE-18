{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184935098", "pull_request_review_id": 116224323, "id": 184935098, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDkzNTA5OA==", "diff_hunk": "@@ -125,49 +197,51 @@ __global__ void cunn_SpatialSoftMaxForward(\n       // I didn't want to thread an extra template parameter, and nvcc\n       // seems to be smart enough to hoist the if outside of the loops.\n       ////////////////////////////////////////////////////////////\n+ \n       if (blockDim.x > 1) {\n-        T max_input = THCNumerics<T>::min();\n+        accscalar_t max_input = THCNumerics<accscalar_t>::min();\n         for (uint32_t d = threadIdx.x; d < dim_size; d += blockDim.x) {\n-          const T value = input[data_offset + d * dim_stride];\n-          max_input = THCNumerics<T>::ge(max_input, value) ? max_input : value;\n+          const accscalar_t value = scalar_cast<accscalar_t>(input[data_offset + d * dim_stride]);\n+          max_input = Max<accscalar_t>()(max_input, value);\n         }\n-        max_input = ScalarConvert<AccumT, T>::to(\n-            spatialBlockReduceX<AccumT, Max>(smem.getPointer(),\n-                                        ScalarConvert<T, AccumT>::to(max_input)));\n+        max_input = spatialBlockReduceX<accscalar_t, Max>(sdata,max_input);\n \n-        AccumT sum = 0;\n+        accscalar_t sum = 0;\n         for (uint32_t d = threadIdx.x; d < dim_size; d += blockDim.x)\n-          sum += THCNumerics<T>::exp(input[data_offset + d * dim_stride] - max_input);\n-        sum = spatialBlockReduceX<AccumT, Add>(smem.getPointer(), sum);\n+          sum += THCNumerics<accscalar_t>::exp(scalar_cast<accscalar_t>(input[data_offset + d * dim_stride]) \n+                 - max_input);\n+        sum = spatialBlockReduceX<accscalar_t, Add>(sdata, sum);\n \n-        Epilogue<T, AccumT> epilogue(max_input, sum);\n+        Epilogue<scalar_t, accscalar_t> epilogue(max_input, sum);\n         for (uint32_t d = threadIdx.x; d < dim_size; d += blockDim.x)\n           output[data_offset + d * dim_stride] = epilogue(input[data_offset + d * dim_stride]);\n       } else {\n-        T max_input = THCNumerics<T>::min();\n-        for (uint32_t d = 0; d < dim_size; d++) {\n-          const T value = input[data_offset + d * dim_stride];\n-          max_input = THCNumerics<T>::ge(max_input, value) ? max_input : value;\n+        accscalar_t max_input = THCNumerics<accscalar_t>::min();", "path": "aten/src/ATen/native/cuda/SoftMax.cu", "position": 200, "original_position": 200, "commit_id": "204cae713bcf6bd0e8f2efe62551f97befa3d9db", "original_commit_id": "fcc6f8898ee435f1279833bd34a4fb98ed9d8a98", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Same here", "created_at": "2018-04-30T08:43:59Z", "updated_at": "2018-11-23T15:43:25Z", "html_url": "https://github.com/pytorch/pytorch/pull/6786#discussion_r184935098", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6786", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184935098"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6786#discussion_r184935098"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6786"}}, "body_html": "<p>Same here</p>", "body_text": "Same here"}