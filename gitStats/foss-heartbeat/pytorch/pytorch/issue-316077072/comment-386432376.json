{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386432376", "html_url": "https://github.com/pytorch/pytorch/pull/6786#issuecomment-386432376", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6786", "id": 386432376, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjQzMjM3Ng==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T20:50:23Z", "updated_at": "2018-05-03T20:50:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Interestingly, I can make adagrad fail on master by commenting out integration.cpp from test_api sources (because I was too lazy to wait for mnist training), in this case adagrad goes for 3000 epochs with loss stuck at 0.48.</p>\n<pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ntest_api is a Catch v2.2.1 host application.\nRun with -? for options\n\n-------------------------------------------------------------------------------\noptim\n  adagrad\n-------------------------------------------------------------------------------\n/raid/pytorch/test/cpp/api/optim.cpp:56\n...............................................................................\n\n/raid/pytorch/test/cpp/api/optim.cpp:64: FAILED:\n</code></pre>\n<p>Optimizer tests seem kind of flaky</p>", "body_text": "Interestingly, I can make adagrad fail on master by commenting out integration.cpp from test_api sources (because I was too lazy to wait for mnist training), in this case adagrad goes for 3000 epochs with loss stuck at 0.48.\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ntest_api is a Catch v2.2.1 host application.\nRun with -? for options\n\n-------------------------------------------------------------------------------\noptim\n  adagrad\n-------------------------------------------------------------------------------\n/raid/pytorch/test/cpp/api/optim.cpp:56\n...............................................................................\n\n/raid/pytorch/test/cpp/api/optim.cpp:64: FAILED:\n\nOptimizer tests seem kind of flaky", "body": "Interestingly, I can make adagrad fail on master by commenting out integration.cpp from test_api sources (because I was too lazy to wait for mnist training), in this case adagrad goes for 3000 epochs with loss stuck at 0.48. \r\n```\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntest_api is a Catch v2.2.1 host application.\r\nRun with -? for options\r\n\r\n-------------------------------------------------------------------------------\r\noptim\r\n  adagrad\r\n-------------------------------------------------------------------------------\r\n/raid/pytorch/test/cpp/api/optim.cpp:56\r\n...............................................................................\r\n\r\n/raid/pytorch/test/cpp/api/optim.cpp:64: FAILED:\r\n```\r\nOptimizer tests seem kind of flaky"}