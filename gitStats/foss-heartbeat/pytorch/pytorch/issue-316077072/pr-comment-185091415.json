{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185091415", "pull_request_review_id": 116414436, "id": 185091415, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTA5MTQxNQ==", "diff_hunk": "@@ -125,49 +197,51 @@ __global__ void cunn_SpatialSoftMaxForward(\n       // I didn't want to thread an extra template parameter, and nvcc\n       // seems to be smart enough to hoist the if outside of the loops.\n       ////////////////////////////////////////////////////////////\n+ \n       if (blockDim.x > 1) {\n-        T max_input = THCNumerics<T>::min();\n+        accscalar_t max_input = THCNumerics<accscalar_t>::min();", "path": "aten/src/ATen/native/cuda/SoftMax.cu", "position": 170, "original_position": 170, "commit_id": "204cae713bcf6bd0e8f2efe62551f97befa3d9db", "original_commit_id": "fcc6f8898ee435f1279833bd34a4fb98ed9d8a98", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "body": "1) comparison operators for half work on floats only anyway, so there will be conversions. Might as well convert in the beginning and keep intermediates in float\r\n2) reduced max will still have to be converted to accscalar in epilogue, either when epilogue is constructed or for every call, so there's also nothing to be gained by keeping it in scalar", "created_at": "2018-04-30T19:54:33Z", "updated_at": "2018-11-23T15:43:27Z", "html_url": "https://github.com/pytorch/pytorch/pull/6786#discussion_r185091415", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6786", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185091415"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6786#discussion_r185091415"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6786"}}, "body_html": "<ol>\n<li>comparison operators for half work on floats only anyway, so there will be conversions. Might as well convert in the beginning and keep intermediates in float</li>\n<li>reduced max will still have to be converted to accscalar in epilogue, either when epilogue is constructed or for every call, so there's also nothing to be gained by keeping it in scalar</li>\n</ol>", "body_text": "comparison operators for half work on floats only anyway, so there will be conversions. Might as well convert in the beginning and keep intermediates in float\nreduced max will still have to be converted to accscalar in epilogue, either when epilogue is constructed or for every call, so there's also nothing to be gained by keeping it in scalar", "in_reply_to_id": 184935065}