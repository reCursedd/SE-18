{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183349206", "pull_request_review_id": 114327841, "id": 183349206, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MzM0OTIwNg==", "diff_hunk": "@@ -1909,6 +1909,41 @@ def _test_diagonal(self, dtype, device):\n     def test_diagonal(self):\n         self._test_diagonal(self, dtype=torch.float32, device='cpu')\n \n+    @unittest.skipIf(not TEST_NUMPY, 'Numpy not found')\n+    def test_diagonal_multidim(self):\n+        x = torch.randn(10, 11, 12, 13)\n+        xn = x.numpy()\n+        result = torch.diagonal(x, 2, 2, 3)\n+        expected = xn.diagonal(2, 2, 3)\n+        self.assertEqual(expected.shape, result.shape)\n+        self.assertTrue(np.allclose(expected, result.numpy()))\n+        result = torch.diagonal(x, 2)\n+        expected = torch.diagonal(x, 2, 0, 1)\n+        self.assertEqual(expected, result)\n+        result = torch.diagonal(x, -2, 1, 2)\n+        expected = xn.diagonal(-2, 1, 2)\n+        self.assertEqual(expected.shape, result.shape)\n+        self.assertTrue(np.allclose(expected, result.numpy()))\n+        result = torch.diagonal(x, 0, -2, -1)\n+        expected = xn.diagonal(0, -2, -1)\n+        self.assertEqual(expected.shape, result.shape)\n+        self.assertTrue(np.allclose(expected, result.numpy()))\n+        # test non-continguous\n+        xp = x.permute(1, 2, 3, 0)\n+        result = torch.diagonal(xp, 0, -2, -1)\n+        expected = xp.numpy().diagonal(0, -2, -1)\n+        self.assertEqual(expected.shape, result.shape)\n+        self.assertTrue(np.allclose(expected, result.numpy()))\n+        # test that the backward requires grad\n+        # we do this is because diagonal_backward uses inplace\n+        # operations and gradgradcheck does not catch whether\n+        # they works as expected", "path": "test/test_torch.py", "position": null, "original_position": 32, "commit_id": "71eb0d5b7ce223c63deed433516d7bf6ace9762f", "original_commit_id": "67d2734ecd6f748d7639efeab4270205313a227f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Why isn't `gradgradcheck` enough? I don't really understand the comment, but `test_torch` shouldn't check anything related to differentiation", "created_at": "2018-04-23T10:41:18Z", "updated_at": "2018-11-23T15:42:58Z", "html_url": "https://github.com/pytorch/pytorch/pull/6718#discussion_r183349206", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6718", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183349206"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6718#discussion_r183349206"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6718"}}, "body_html": "<p>Why isn't <code>gradgradcheck</code> enough? I don't really understand the comment, but <code>test_torch</code> shouldn't check anything related to differentiation</p>", "body_text": "Why isn't gradgradcheck enough? I don't really understand the comment, but test_torch shouldn't check anything related to differentiation"}