{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14119", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14119/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14119/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14119/events", "html_url": "https://github.com/pytorch/pytorch/issues/14119", "id": 381751278, "node_id": "MDU6SXNzdWUzODE3NTEyNzg=", "number": 14119, "title": "FP16 results in \"Floating point exception\"", "user": {"login": "ngoyal2707", "id": 7836935, "node_id": "MDQ6VXNlcjc4MzY5MzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/7836935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngoyal2707", "html_url": "https://github.com/ngoyal2707", "followers_url": "https://api.github.com/users/ngoyal2707/followers", "following_url": "https://api.github.com/users/ngoyal2707/following{/other_user}", "gists_url": "https://api.github.com/users/ngoyal2707/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngoyal2707/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngoyal2707/subscriptions", "organizations_url": "https://api.github.com/users/ngoyal2707/orgs", "repos_url": "https://api.github.com/users/ngoyal2707/repos", "events_url": "https://api.github.com/users/ngoyal2707/events{/privacy}", "received_events_url": "https://api.github.com/users/ngoyal2707/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-16T20:37:30Z", "updated_at": "2018-11-19T18:35:18Z", "closed_at": "2018-11-19T18:35:18Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>FP16 results in \"Floating point exception\" with following minimal example. See example below.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from torch import nn\n&gt;&gt;&gt; x = torch.rand(1, 1, 188, 621).cuda().half()\n&gt;&gt;&gt; conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda().half()\n&gt;&gt;&gt; conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda().half()\n&gt;&gt;&gt; loss = conv2(conv1(x))\n&gt;&gt;&gt; loss.sum().backward()\nFloating point exception\n</code></pre>\n\n<h2>Expected behavior</h2>\n<p>It works correctly on <code>fp32</code> calculation as following:</p>\n<pre><code>&gt;&gt;&gt; x = torch.rand(1, 1, 188, 621).cuda()\n&gt;&gt;&gt; conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda()\n&gt;&gt;&gt; conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda() \n&gt;&gt;&gt; loss = conv2(conv1(x))\n&gt;&gt;&gt; loss.sum().backward()\n&gt;&gt;&gt;\n</code></pre>\n\n<h2>Environment</h2>\n<pre><code>PyTorch version: 1.0.0.dev20181115\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.88\nGPU models and configuration: \nGPU 0: Tesla V100-SXM2-16GB\nGPU 1: Tesla V100-SXM2-16GB\nGPU 2: Tesla V100-SXM2-16GB\nGPU 3: Tesla V100-SXM2-16GB\nGPU 4: Tesla V100-SXM2-16GB\nGPU 5: Tesla V100-SXM2-16GB\nGPU 6: Tesla V100-SXM2-16GB\nGPU 7: Tesla V100-SXM2-16GB\n\nNvidia driver version: 396.51\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip3] numpy (1.15.1)\n[pip3] torch-nightly (1.0.0.dev20181115)\n[pip3] torchvision (0.2.1)\n[pip3] torchvision-nightly (0.2.1)\n[conda] magma-cuda92              2.3.0                         1    pytorch\n[conda] torch-nightly             1.0.0.dev20181115           &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n[conda] torchvision-nightly       0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "\ud83d\udc1b Bug\nFP16 results in \"Floating point exception\" with following minimal example. See example below.\nTo Reproduce\nSteps to reproduce the behavior:\n>>> import torch\n>>> from torch import nn\n>>> x = torch.rand(1, 1, 188, 621).cuda().half()\n>>> conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda().half()\n>>> conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda().half()\n>>> loss = conv2(conv1(x))\n>>> loss.sum().backward()\nFloating point exception\n\n\nExpected behavior\nIt works correctly on fp32 calculation as following:\n>>> x = torch.rand(1, 1, 188, 621).cuda()\n>>> conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda()\n>>> conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda() \n>>> loss = conv2(conv1(x))\n>>> loss.sum().backward()\n>>>\n\n\nEnvironment\nPyTorch version: 1.0.0.dev20181115\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.88\nGPU models and configuration: \nGPU 0: Tesla V100-SXM2-16GB\nGPU 1: Tesla V100-SXM2-16GB\nGPU 2: Tesla V100-SXM2-16GB\nGPU 3: Tesla V100-SXM2-16GB\nGPU 4: Tesla V100-SXM2-16GB\nGPU 5: Tesla V100-SXM2-16GB\nGPU 6: Tesla V100-SXM2-16GB\nGPU 7: Tesla V100-SXM2-16GB\n\nNvidia driver version: 396.51\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip3] numpy (1.15.1)\n[pip3] torch-nightly (1.0.0.dev20181115)\n[pip3] torchvision (0.2.1)\n[pip3] torchvision-nightly (0.2.1)\n[conda] magma-cuda92              2.3.0                         1    pytorch\n[conda] torch-nightly             1.0.0.dev20181115           <pip>\n[conda] torchvision               0.2.1                     <pip>\n[conda] torchvision-nightly       0.2.1                     <pip>", "body": "## \ud83d\udc1b Bug\r\n\r\nFP16 results in \"Floating point exception\" with following minimal example. See example below.\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n>>> import torch\r\n>>> from torch import nn\r\n>>> x = torch.rand(1, 1, 188, 621).cuda().half()\r\n>>> conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda().half()\r\n>>> conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda().half()\r\n>>> loss = conv2(conv1(x))\r\n>>> loss.sum().backward()\r\nFloating point exception\r\n```\r\n\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nIt works correctly on `fp32` calculation as following:\r\n\r\n```\r\n>>> x = torch.rand(1, 1, 188, 621).cuda()\r\n>>> conv1 = nn.Conv2d(1, 64, kernel_size=1, bias=False).cuda()\r\n>>> conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False).cuda() \r\n>>> loss = conv2(conv1(x))\r\n>>> loss.sum().backward()\r\n>>>\r\n```\r\n\r\n \r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n```\r\nPyTorch version: 1.0.0.dev20181115\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.88\r\nGPU models and configuration: \r\nGPU 0: Tesla V100-SXM2-16GB\r\nGPU 1: Tesla V100-SXM2-16GB\r\nGPU 2: Tesla V100-SXM2-16GB\r\nGPU 3: Tesla V100-SXM2-16GB\r\nGPU 4: Tesla V100-SXM2-16GB\r\nGPU 5: Tesla V100-SXM2-16GB\r\nGPU 6: Tesla V100-SXM2-16GB\r\nGPU 7: Tesla V100-SXM2-16GB\r\n\r\nNvidia driver version: 396.51\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.15.1)\r\n[pip3] torch-nightly (1.0.0.dev20181115)\r\n[pip3] torchvision (0.2.1)\r\n[pip3] torchvision-nightly (0.2.1)\r\n[conda] magma-cuda92              2.3.0                         1    pytorch\r\n[conda] torch-nightly             1.0.0.dev20181115           <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n[conda] torchvision-nightly       0.2.1                     <pip>\r\n"}