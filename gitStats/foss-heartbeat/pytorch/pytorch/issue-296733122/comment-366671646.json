{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/366671646", "html_url": "https://github.com/pytorch/pytorch/issues/5212#issuecomment-366671646", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5212", "id": 366671646, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjY3MTY0Ng==", "user": {"login": "ptrblck", "id": 11662379, "node_id": "MDQ6VXNlcjExNjYyMzc5", "avatar_url": "https://avatars3.githubusercontent.com/u/11662379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptrblck", "html_url": "https://github.com/ptrblck", "followers_url": "https://api.github.com/users/ptrblck/followers", "following_url": "https://api.github.com/users/ptrblck/following{/other_user}", "gists_url": "https://api.github.com/users/ptrblck/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptrblck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptrblck/subscriptions", "organizations_url": "https://api.github.com/users/ptrblck/orgs", "repos_url": "https://api.github.com/users/ptrblck/repos", "events_url": "https://api.github.com/users/ptrblck/events{/privacy}", "received_events_url": "https://api.github.com/users/ptrblck/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-19T12:05:44Z", "updated_at": "2018-02-19T12:05:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for reporting this issue <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1092464\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Diego999\">@Diego999</a>.<br>\nI haven't thought of a use case with splits &lt; dim.</p>\n<p>What do you think the appropriate solution would be?<br>\nDiscarding the additional slices or return a separate split?</p>\n<p>E.g.:<br>\n<code>x = torch.randn(10, 20) torch.split(x, [5, 2], 0)</code><br>\nIn your use case, should it return two Tensors of size <code>[5, 20]</code> and <code>[2, 20]</code> or another with <code>[3, 20]</code>?</p>", "body_text": "Thanks for reporting this issue @Diego999.\nI haven't thought of a use case with splits < dim.\nWhat do you think the appropriate solution would be?\nDiscarding the additional slices or return a separate split?\nE.g.:\nx = torch.randn(10, 20) torch.split(x, [5, 2], 0)\nIn your use case, should it return two Tensors of size [5, 20] and [2, 20] or another with [3, 20]?", "body": "Thanks for reporting this issue @Diego999.\r\nI haven't thought of a use case with splits < dim.\r\n\r\nWhat do you think the appropriate solution would be?\r\nDiscarding the additional slices or return a separate split?\r\n\r\nE.g.:\r\n``\r\nx = torch.randn(10, 20)\r\ntorch.split(x, [5, 2], 0)\r\n``\r\nIn your use case, should it return two Tensors of size `[5, 20]` and `[2, 20]` or another with `[3, 20]`?"}