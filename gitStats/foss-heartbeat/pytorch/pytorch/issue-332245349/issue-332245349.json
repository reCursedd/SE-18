{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8473", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8473/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8473/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8473/events", "html_url": "https://github.com/pytorch/pytorch/issues/8473", "id": 332245349, "node_id": "MDU6SXNzdWUzMzIyNDUzNDk=", "number": 8473, "title": "RuntimeError: /pytorch/torch/csrc/jit/tracer.h:117: getTracingState: Assertion `var_state == state` failed.", "user": {"login": "tom888888", "id": 33222288, "node_id": "MDQ6VXNlcjMzMjIyMjg4", "avatar_url": "https://avatars2.githubusercontent.com/u/33222288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tom888888", "html_url": "https://github.com/tom888888", "followers_url": "https://api.github.com/users/tom888888/followers", "following_url": "https://api.github.com/users/tom888888/following{/other_user}", "gists_url": "https://api.github.com/users/tom888888/gists{/gist_id}", "starred_url": "https://api.github.com/users/tom888888/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tom888888/subscriptions", "organizations_url": "https://api.github.com/users/tom888888/orgs", "repos_url": "https://api.github.com/users/tom888888/repos", "events_url": "https://api.github.com/users/tom888888/events{/privacy}", "received_events_url": "https://api.github.com/users/tom888888/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-06-14T04:11:10Z", "updated_at": "2018-11-21T02:44:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I did train Resnet152 model and I want to export onnx.<br>\nthis error occurs<br>\nI did run programming with GPU on jupyter</p>\n<h2>Error message</h2>\n<pre><code>RuntimeErrorTraceback (most recent call last)\n&lt;ipython-input-15-f5f241afd3b5&gt; in &lt;module&gt;()\n----&gt; 1 torch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/__init__.py in export(*args, **kwargs)\n     23 def export(*args, **kwargs):\n     24     from torch.onnx import utils\n---&gt; 25     return utils.export(*args, **kwargs)\n     26 \n     27 \n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten)\n     82             as ATen ops.\n     83     \"\"\"\n---&gt; 84     _export(model, args, f, export_params, verbose, training, input_names, output_names)\n     85 \n     86 \n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_type)\n    132     # training mode was.)\n    133     with set_training(model, training):\n--&gt; 134         trace, torch_out = torch.jit.get_trace_graph(model, args)\n    135 \n    136     if orig_state_dict_keys != _unique_state_dict(model).keys():\n\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs, nderivs)\n    253     if not isinstance(args, tuple):\n    254         args = (args,)\n--&gt; 255     return LegacyTracedModule(f, nderivs=nderivs)(*args, **kwargs)\n    256 \n    257 \n\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    487             hook(self, input)\n    488         if torch.jit._tracing:\n--&gt; 489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n    491             result = self.forward(*input, **kwargs)\n\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    465     def _slow_forward(self, *input, **kwargs):\n    466         input_vars = tuple(torch.autograd.function._iter_tensors(input))\n--&gt; 467         tracing_state = torch.jit.get_tracing_state(input_vars)\n    468         if not tracing_state:\n    469             return self.forward(*input, **kwargs)\n\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_tracing_state(args)\n     33     if not torch._C._is_tracing(args):\n     34         return None\n---&gt; 35     return torch._C._get_tracing_state(args)\n     36 \n     37 \n\nRuntimeError: /pytorch/torch/csrc/jit/tracer.h:117: getTracingState: Assertion `var_state == state` failed.\n\n</code></pre>\n<h2>this is my export onnx code</h2>\n<pre><code>dummy_input = Variable(torch.randn(1, 3, 224, 224))\ntorch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\n</code></pre>\n<h2>this is my training model code</h2>\n<pre><code>def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc &gt; best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nuse_gpu = torch.cuda.is_available()\n\n# get model and replace the original fc layer with your fc layer\nmodel_ft = torchvision.models.resnet152(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 3) \n\nif use_gpu:\n    model_ft = model_ft.cuda()\n\n# define loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nmodel_ft = train_model(model=model_ft,\n                           criterion=criterion,\n                           optimizer=optimizer_ft,\n                           scheduler=exp_lr_scheduler,\n                           num_epochs=2)\n</code></pre>\n<p>I want training a resnet model to predict threes classes</p>\n<p>I use pip to install pytorch<br>\nGPU : GeForce GTX 1080 Ti<br>\nPython  3.6.3<br>\nPytorch  0.4.0<br>\nCUDA Version  9.0.176<br>\nGCC Version  5.4.0<br>\nCmake version 3.5.1</p>\n<p>Could you please advice how to solve out this error<br>\nThank you</p>", "body_text": "I did train Resnet152 model and I want to export onnx.\nthis error occurs\nI did run programming with GPU on jupyter\nError message\nRuntimeErrorTraceback (most recent call last)\n<ipython-input-15-f5f241afd3b5> in <module>()\n----> 1 torch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/__init__.py in export(*args, **kwargs)\n     23 def export(*args, **kwargs):\n     24     from torch.onnx import utils\n---> 25     return utils.export(*args, **kwargs)\n     26 \n     27 \n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten)\n     82             as ATen ops.\n     83     \"\"\"\n---> 84     _export(model, args, f, export_params, verbose, training, input_names, output_names)\n     85 \n     86 \n\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_type)\n    132     # training mode was.)\n    133     with set_training(model, training):\n--> 134         trace, torch_out = torch.jit.get_trace_graph(model, args)\n    135 \n    136     if orig_state_dict_keys != _unique_state_dict(model).keys():\n\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs, nderivs)\n    253     if not isinstance(args, tuple):\n    254         args = (args,)\n--> 255     return LegacyTracedModule(f, nderivs=nderivs)(*args, **kwargs)\n    256 \n    257 \n\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    487             hook(self, input)\n    488         if torch.jit._tracing:\n--> 489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n    491             result = self.forward(*input, **kwargs)\n\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    465     def _slow_forward(self, *input, **kwargs):\n    466         input_vars = tuple(torch.autograd.function._iter_tensors(input))\n--> 467         tracing_state = torch.jit.get_tracing_state(input_vars)\n    468         if not tracing_state:\n    469             return self.forward(*input, **kwargs)\n\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_tracing_state(args)\n     33     if not torch._C._is_tracing(args):\n     34         return None\n---> 35     return torch._C._get_tracing_state(args)\n     36 \n     37 \n\nRuntimeError: /pytorch/torch/csrc/jit/tracer.h:117: getTracingState: Assertion `var_state == state` failed.\n\n\nthis is my export onnx code\ndummy_input = Variable(torch.randn(1, 3, 224, 224))\ntorch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\n\nthis is my training model code\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nuse_gpu = torch.cuda.is_available()\n\n# get model and replace the original fc layer with your fc layer\nmodel_ft = torchvision.models.resnet152(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 3) \n\nif use_gpu:\n    model_ft = model_ft.cuda()\n\n# define loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nmodel_ft = train_model(model=model_ft,\n                           criterion=criterion,\n                           optimizer=optimizer_ft,\n                           scheduler=exp_lr_scheduler,\n                           num_epochs=2)\n\nI want training a resnet model to predict threes classes\nI use pip to install pytorch\nGPU : GeForce GTX 1080 Ti\nPython  3.6.3\nPytorch  0.4.0\nCUDA Version  9.0.176\nGCC Version  5.4.0\nCmake version 3.5.1\nCould you please advice how to solve out this error\nThank you", "body": "I did train Resnet152 model and I want to export onnx.\r\nthis error occurs\r\nI did run programming with GPU on jupyter \r\n## Error message\r\n```\r\nRuntimeErrorTraceback (most recent call last)\r\n<ipython-input-15-f5f241afd3b5> in <module>()\r\n----> 1 torch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/onnx/__init__.py in export(*args, **kwargs)\r\n     23 def export(*args, **kwargs):\r\n     24     from torch.onnx import utils\r\n---> 25     return utils.export(*args, **kwargs)\r\n     26 \r\n     27 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten)\r\n     82             as ATen ops.\r\n     83     \"\"\"\r\n---> 84     _export(model, args, f, export_params, verbose, training, input_names, output_names)\r\n     85 \r\n     86 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_type)\r\n    132     # training mode was.)\r\n    133     with set_training(model, training):\r\n--> 134         trace, torch_out = torch.jit.get_trace_graph(model, args)\r\n    135 \r\n    136     if orig_state_dict_keys != _unique_state_dict(model).keys():\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs, nderivs)\r\n    253     if not isinstance(args, tuple):\r\n    254         args = (args,)\r\n--> 255     return LegacyTracedModule(f, nderivs=nderivs)(*args, **kwargs)\r\n    256 \r\n    257 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    487             hook(self, input)\r\n    488         if torch.jit._tracing:\r\n--> 489             result = self._slow_forward(*input, **kwargs)\r\n    490         else:\r\n    491             result = self.forward(*input, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\r\n    465     def _slow_forward(self, *input, **kwargs):\r\n    466         input_vars = tuple(torch.autograd.function._iter_tensors(input))\r\n--> 467         tracing_state = torch.jit.get_tracing_state(input_vars)\r\n    468         if not tracing_state:\r\n    469             return self.forward(*input, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py in get_tracing_state(args)\r\n     33     if not torch._C._is_tracing(args):\r\n     34         return None\r\n---> 35     return torch._C._get_tracing_state(args)\r\n     36 \r\n     37 \r\n\r\nRuntimeError: /pytorch/torch/csrc/jit/tracer.h:117: getTracingState: Assertion `var_state == state` failed.\r\n\r\n```\r\n## this is my export onnx code\r\n```\r\ndummy_input = Variable(torch.randn(1, 3, 224, 224))\r\ntorch.onnx.export(model_ft, dummy_input, \"resnet152.onnx\",export_params=True)\r\n```\r\n\r\n## this is my training model code\r\n```\r\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\r\n    since = time.time()\r\n\r\n    best_model_wts = copy.deepcopy(model.state_dict())\r\n    best_acc = 0.0\r\n\r\n    for epoch in range(num_epochs):\r\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n        print('-' * 10)\r\n\r\n        # Each epoch has a training and validation phase\r\n        for phase in ['train', 'val']:\r\n            if phase == 'train':\r\n                scheduler.step()\r\n                model.train()  # Set model to training mode\r\n            else:\r\n                model.eval()   # Set model to evaluate mode\r\n\r\n            running_loss = 0.0\r\n            running_corrects = 0\r\n\r\n            # Iterate over data.\r\n            for inputs, labels in dataloaders[phase]:\r\n                inputs = inputs.to(device)\r\n                labels = labels.to(device)\r\n\r\n                # zero the parameter gradients\r\n                optimizer.zero_grad()\r\n\r\n                # forward\r\n                # track history if only in train\r\n                with torch.set_grad_enabled(phase == 'train'):\r\n                    outputs = model(inputs)\r\n                    _, preds = torch.max(outputs, 1)\r\n                    loss = criterion(outputs, labels)\r\n\r\n                    # backward + optimize only if in training phase\r\n                    if phase == 'train':\r\n                        loss.backward()\r\n                        optimizer.step()\r\n\r\n                # statistics\r\n                running_loss += loss.item() * inputs.size(0)\r\n                running_corrects += torch.sum(preds == labels.data)\r\n\r\n            epoch_loss = running_loss / dataset_sizes[phase]\r\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n\r\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n                phase, epoch_loss, epoch_acc))\r\n\r\n            # deep copy the model\r\n            if phase == 'val' and epoch_acc > best_acc:\r\n                best_acc = epoch_acc\r\n                best_model_wts = copy.deepcopy(model.state_dict())\r\n\r\n        print()\r\n\r\n    time_elapsed = time.time() - since\r\n    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n        time_elapsed // 60, time_elapsed % 60))\r\n    print('Best val Acc: {:4f}'.format(best_acc))\r\n\r\n    # load best model weights\r\n    model.load_state_dict(best_model_wts)\r\n    return model\r\n\r\ndata_transforms = {\r\n    'train': transforms.Compose([\r\n        transforms.RandomResizedCrop(224),\r\n        transforms.RandomHorizontalFlip(),\r\n        transforms.ToTensor(),\r\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n    ]),\r\n    'val': transforms.Compose([\r\n        transforms.Resize(256),\r\n        transforms.CenterCrop(224),\r\n        transforms.ToTensor(),\r\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n    ]),\r\n}\r\n\r\ndata_dir = 'data'\r\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n                                          data_transforms[x])\r\n                  for x in ['train', 'val']}\r\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\r\n                                             shuffle=True, num_workers=4)\r\n              for x in ['train', 'val']}\r\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\r\nclass_names = image_datasets['train'].classes\r\n\r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n\r\nuse_gpu = torch.cuda.is_available()\r\n\r\n# get model and replace the original fc layer with your fc layer\r\nmodel_ft = torchvision.models.resnet152(pretrained=True)\r\nnum_ftrs = model_ft.fc.in_features\r\nmodel_ft.fc = nn.Linear(num_ftrs, 3) \r\n\r\nif use_gpu:\r\n    model_ft = model_ft.cuda()\r\n\r\n# define loss function\r\ncriterion = nn.CrossEntropyLoss()\r\n\r\n# Observe that all parameters are being optimized\r\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\r\n\r\n# Decay LR by a factor of 0.1 every 7 epochs\r\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\r\n\r\nmodel_ft = train_model(model=model_ft,\r\n                           criterion=criterion,\r\n                           optimizer=optimizer_ft,\r\n                           scheduler=exp_lr_scheduler,\r\n                           num_epochs=2)\r\n```\r\nI want training a resnet model to predict threes classes\r\n\r\nI use pip to install pytorch\r\nGPU : GeForce GTX 1080 Ti\r\nPython  3.6.3\r\nPytorch  0.4.0\r\nCUDA Version  9.0.176\r\nGCC Version  5.4.0\r\nCmake version 3.5.1 \r\n\r\nCould you please advice how to solve out this error\r\nThank you"}