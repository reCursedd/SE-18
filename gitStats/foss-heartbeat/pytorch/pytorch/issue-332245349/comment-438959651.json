{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/438959651", "html_url": "https://github.com/pytorch/pytorch/issues/8473#issuecomment-438959651", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8473", "id": 438959651, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODk1OTY1MQ==", "user": {"login": "savourylie", "id": 5828418, "node_id": "MDQ6VXNlcjU4Mjg0MTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5828418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/savourylie", "html_url": "https://github.com/savourylie", "followers_url": "https://api.github.com/users/savourylie/followers", "following_url": "https://api.github.com/users/savourylie/following{/other_user}", "gists_url": "https://api.github.com/users/savourylie/gists{/gist_id}", "starred_url": "https://api.github.com/users/savourylie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/savourylie/subscriptions", "organizations_url": "https://api.github.com/users/savourylie/orgs", "repos_url": "https://api.github.com/users/savourylie/repos", "events_url": "https://api.github.com/users/savourylie/events{/privacy}", "received_events_url": "https://api.github.com/users/savourylie/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T08:35:12Z", "updated_at": "2018-11-15T08:36:59Z", "author_association": "NONE", "body_html": "<p>Same message here.</p>\n<p>My code:</p>\n<pre><code>x = torch.rand((64, 3, 32, 32))\n\ninput_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\noutput_names = [ \"output1\" ]\n\nmodel.eval()\n\ntorch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n</code></pre>\n<p>The error message:</p>\n<pre><code>RuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-14-fc8a34f94803&gt; in &lt;module&gt;()\n      4 model.eval()\n      5 \n----&gt; 6 torch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py in export(*args, **kwargs)\n     24 def export(*args, **kwargs):\n     25     from torch.onnx import utils\n---&gt; 26     return utils.export(*args, **kwargs)\n     27 \n     28 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\n     92         operator_export_type = OperatorExportTypes.ONNX\n     93     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n---&gt; 94             operator_export_type=operator_export_type)\n     95 \n     96 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\n    224                                                training, input_names,\n    225                                                output_names, operator_export_type,\n--&gt; 226                                                example_outputs, propagate)\n    227 \n    228     # TODO: Don't allocate a in-memory string for the protobuf\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _model_to_graph(model, args, f, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate)\n    175             raise RuntimeError('\\'forward\\' method must be a script method')\n    176     else:\n--&gt; 177         graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\n    178         params = list(_unique_state_dict(model).values())\n    179 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _trace_and_get_graph_from_model(model, args, training)\n    142     # training mode was.)\n    143     with set_training(model, training):\n--&gt; 144         trace, torch_out = torch.jit.get_trace_graph(model, args)\n    145 \n    146     if orig_state_dict_keys != _unique_state_dict(model).keys():\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs)\n     75     if not isinstance(args, tuple):\n     76         args = (args,)\n---&gt; 77     return LegacyTracedModule(f)(*args, **kwargs)\n     78 \n     79 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    473             hook(self, input)\n    474         if torch.jit._tracing:\n--&gt; 475             result = self._slow_forward(*input, **kwargs)\n    476         else:\n    477             result = self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    463         tracing_state._traced_module_stack.append(self)\n    464         try:\n--&gt; 465             result = self.forward(*input, **kwargs)\n    466         finally:\n    467             tracing_state.pop_scope()\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in forward(self, *args)\n    107         _tracing = True\n    108         trace_inputs = _unflatten(all_trace_inputs[:len(in_vars)], in_desc)\n--&gt; 109         out = self.inner(*trace_inputs)\n    110         out_vars, _ = _flatten(out)\n    111         _tracing = False\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    473             hook(self, input)\n    474         if torch.jit._tracing:\n--&gt; 475             result = self._slow_forward(*input, **kwargs)\n    476         else:\n    477             result = self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    451     def _slow_forward(self, *input, **kwargs):\n    452         input_vars = tuple(torch.autograd.function._iter_tensors(input))\n--&gt; 453         tracing_state = torch.jit.get_tracing_state(input_vars)\n    454         if not tracing_state:\n    455             return self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_tracing_state(args)\n     34     if not torch._C._is_tracing(args):\n     35         return None\n---&gt; 36     return torch._C._get_tracing_state(args)\n     37 \n     38 \n\nRuntimeError: /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/torch/csrc/jit/tracer.h:143: getTracingState: Assertion `var_state == state` failed.\n</code></pre>\n<p>I didn't train my network tho. Just initialized it, exported, and got this.</p>", "body_text": "Same message here.\nMy code:\nx = torch.rand((64, 3, 32, 32))\n\ninput_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\noutput_names = [ \"output1\" ]\n\nmodel.eval()\n\ntorch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n\nThe error message:\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-14-fc8a34f94803> in <module>()\n      4 model.eval()\n      5 \n----> 6 torch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py in export(*args, **kwargs)\n     24 def export(*args, **kwargs):\n     25     from torch.onnx import utils\n---> 26     return utils.export(*args, **kwargs)\n     27 \n     28 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\n     92         operator_export_type = OperatorExportTypes.ONNX\n     93     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n---> 94             operator_export_type=operator_export_type)\n     95 \n     96 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\n    224                                                training, input_names,\n    225                                                output_names, operator_export_type,\n--> 226                                                example_outputs, propagate)\n    227 \n    228     # TODO: Don't allocate a in-memory string for the protobuf\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _model_to_graph(model, args, f, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate)\n    175             raise RuntimeError('\\'forward\\' method must be a script method')\n    176     else:\n--> 177         graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\n    178         params = list(_unique_state_dict(model).values())\n    179 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _trace_and_get_graph_from_model(model, args, training)\n    142     # training mode was.)\n    143     with set_training(model, training):\n--> 144         trace, torch_out = torch.jit.get_trace_graph(model, args)\n    145 \n    146     if orig_state_dict_keys != _unique_state_dict(model).keys():\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs)\n     75     if not isinstance(args, tuple):\n     76         args = (args,)\n---> 77     return LegacyTracedModule(f)(*args, **kwargs)\n     78 \n     79 \n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    473             hook(self, input)\n    474         if torch.jit._tracing:\n--> 475             result = self._slow_forward(*input, **kwargs)\n    476         else:\n    477             result = self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    463         tracing_state._traced_module_stack.append(self)\n    464         try:\n--> 465             result = self.forward(*input, **kwargs)\n    466         finally:\n    467             tracing_state.pop_scope()\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in forward(self, *args)\n    107         _tracing = True\n    108         trace_inputs = _unflatten(all_trace_inputs[:len(in_vars)], in_desc)\n--> 109         out = self.inner(*trace_inputs)\n    110         out_vars, _ = _flatten(out)\n    111         _tracing = False\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    473             hook(self, input)\n    474         if torch.jit._tracing:\n--> 475             result = self._slow_forward(*input, **kwargs)\n    476         else:\n    477             result = self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\n    451     def _slow_forward(self, *input, **kwargs):\n    452         input_vars = tuple(torch.autograd.function._iter_tensors(input))\n--> 453         tracing_state = torch.jit.get_tracing_state(input_vars)\n    454         if not tracing_state:\n    455             return self.forward(*input, **kwargs)\n\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_tracing_state(args)\n     34     if not torch._C._is_tracing(args):\n     35         return None\n---> 36     return torch._C._get_tracing_state(args)\n     37 \n     38 \n\nRuntimeError: /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/torch/csrc/jit/tracer.h:143: getTracingState: Assertion `var_state == state` failed.\n\nI didn't train my network tho. Just initialized it, exported, and got this.", "body": "Same message here.\r\n\r\nMy code:\r\n```\r\nx = torch.rand((64, 3, 32, 32))\r\n\r\ninput_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\r\noutput_names = [ \"output1\" ]\r\n\r\nmodel.eval()\r\n\r\ntorch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\r\n```\r\n\r\nThe error message:\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-14-fc8a34f94803> in <module>()\r\n      4 model.eval()\r\n      5 \r\n----> 6 torch.onnx.export(model, x, \"neuralcell.onnx\", verbose=True, input_names=input_names, output_names=output_names)\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py in export(*args, **kwargs)\r\n     24 def export(*args, **kwargs):\r\n     25     from torch.onnx import utils\r\n---> 26     return utils.export(*args, **kwargs)\r\n     27 \r\n     28 \r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in export(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\r\n     92         operator_export_type = OperatorExportTypes.ONNX\r\n     93     _export(model, args, f, export_params, verbose, training, input_names, output_names,\r\n---> 94             operator_export_type=operator_export_type)\r\n     95 \r\n     96 \r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\r\n    224                                                training, input_names,\r\n    225                                                output_names, operator_export_type,\r\n--> 226                                                example_outputs, propagate)\r\n    227 \r\n    228     # TODO: Don't allocate a in-memory string for the protobuf\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _model_to_graph(model, args, f, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate)\r\n    175             raise RuntimeError('\\'forward\\' method must be a script method')\r\n    176     else:\r\n--> 177         graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n    178         params = list(_unique_state_dict(model).values())\r\n    179 \r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py in _trace_and_get_graph_from_model(model, args, training)\r\n    142     # training mode was.)\r\n    143     with set_training(model, training):\r\n--> 144         trace, torch_out = torch.jit.get_trace_graph(model, args)\r\n    145 \r\n    146     if orig_state_dict_keys != _unique_state_dict(model).keys():\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_trace_graph(f, args, kwargs)\r\n     75     if not isinstance(args, tuple):\r\n     76         args = (args,)\r\n---> 77     return LegacyTracedModule(f)(*args, **kwargs)\r\n     78 \r\n     79 \r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    473             hook(self, input)\r\n    474         if torch.jit._tracing:\r\n--> 475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n    477             result = self.forward(*input, **kwargs)\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\r\n    463         tracing_state._traced_module_stack.append(self)\r\n    464         try:\r\n--> 465             result = self.forward(*input, **kwargs)\r\n    466         finally:\r\n    467             tracing_state.pop_scope()\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in forward(self, *args)\r\n    107         _tracing = True\r\n    108         trace_inputs = _unflatten(all_trace_inputs[:len(in_vars)], in_desc)\r\n--> 109         out = self.inner(*trace_inputs)\r\n    110         out_vars, _ = _flatten(out)\r\n    111         _tracing = False\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    473             hook(self, input)\r\n    474         if torch.jit._tracing:\r\n--> 475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n    477             result = self.forward(*input, **kwargs)\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py in _slow_forward(self, *input, **kwargs)\r\n    451     def _slow_forward(self, *input, **kwargs):\r\n    452         input_vars = tuple(torch.autograd.function._iter_tensors(input))\r\n--> 453         tracing_state = torch.jit.get_tracing_state(input_vars)\r\n    454         if not tracing_state:\r\n    455             return self.forward(*input, **kwargs)\r\n\r\n/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py in get_tracing_state(args)\r\n     34     if not torch._C._is_tracing(args):\r\n     35         return None\r\n---> 36     return torch._C._get_tracing_state(args)\r\n     37 \r\n     38 \r\n\r\nRuntimeError: /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/torch/csrc/jit/tracer.h:143: getTracingState: Assertion `var_state == state` failed.\r\n```\r\n\r\nI didn't train my network tho. Just initialized it, exported, and got this.\r\n"}