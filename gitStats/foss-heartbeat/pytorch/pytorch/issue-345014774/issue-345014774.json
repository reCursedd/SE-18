{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9906", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9906/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9906/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9906/events", "html_url": "https://github.com/pytorch/pytorch/issues/9906", "id": 345014774, "node_id": "MDU6SXNzdWUzNDUwMTQ3NzQ=", "number": 9906, "title": "[ppc64le pytorch] Failure when running test_c10d.py  on CPU only server", "user": {"login": "avmgithub", "id": 9083746, "node_id": "MDQ6VXNlcjkwODM3NDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9083746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avmgithub", "html_url": "https://github.com/avmgithub", "followers_url": "https://api.github.com/users/avmgithub/followers", "following_url": "https://api.github.com/users/avmgithub/following{/other_user}", "gists_url": "https://api.github.com/users/avmgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/avmgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avmgithub/subscriptions", "organizations_url": "https://api.github.com/users/avmgithub/orgs", "repos_url": "https://api.github.com/users/avmgithub/repos", "events_url": "https://api.github.com/users/avmgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/avmgithub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-26T21:38:13Z", "updated_at": "2018-09-26T15:18:56Z", "closed_at": "2018-09-26T15:18:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>when building pytorch master from July 25,   I'm getting failure described below.<br>\nI'm building on CPU only system.</p>\n<p>Possibly caused by <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"343279516\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9670\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9670/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9670\">#9670</a></p>\n<p>Maybe just add a check to see if a GPU is available if not skip the test.<br>\nI do have CUDA libraries installed but it is just running on a system without a GPU.</p>\n<p>here is the build log :  <a href=\"https://powerci.osuosl.org/job/pytorch-master-nightly-py3-linux-ppc64le/386/\" rel=\"nofollow\">https://powerci.osuosl.org/job/pytorch-master-nightly-py3-linux-ppc64le/386/</a></p>\n<p>The error messages</p>\n<p>FAIL: test_allreduce_ops (<strong>main</strong>.ProcessGroupGlooTest)<br>\nTraceback (most recent call last):<br>\nFile \"test_c10d.py\", line 205, in wrapper<br>\nself._join_processes(fn)<br>\nFile \"test_c10d.py\", line 250, in _join_processes<br>\nself._check_return_codes()<br>\nFile \"test_c10d.py\", line 263, in _check_return_codes<br>\nself.assertEqual(first_process.exitcode, 0)<br>\nFile \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual<br>\nsuper(TestCase, self).assertLessEqual(abs(x - y), prec, message)<br>\nAssertionError: 6 not less than or equal to 1e-05 :</p>\n<p>FAIL: test_broadcast_ops (<strong>main</strong>.ProcessGroupGlooTest)<br>\nTraceback (most recent call last):<br>\nFile \"test_c10d.py\", line 205, in wrapper<br>\nself._join_processes(fn)<br>\nFile \"test_c10d.py\", line 250, in _join_processes<br>\nself._check_return_codes()<br>\nFile \"test_c10d.py\", line 263, in _check_return_codes<br>\nself.assertEqual(first_process.exitcode, 0)<br>\nFile \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual<br>\nsuper(TestCase, self).assertLessEqual(abs(x - y), prec, message)<br>\nAssertionError: 6 not less than or equal to 1e-05 :</p>\n<p>The logs also show<br>\ntest_allreduce_ops (<strong>main</strong>.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nFAIL<br>\ntest_broadcast_ops (<strong>main</strong>.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version<br>\nterminate called without an active exception<br>\nFAIL</p>", "body_text": "when building pytorch master from July 25,   I'm getting failure described below.\nI'm building on CPU only system.\nPossibly caused by #9670\nMaybe just add a check to see if a GPU is available if not skip the test.\nI do have CUDA libraries installed but it is just running on a system without a GPU.\nhere is the build log :  https://powerci.osuosl.org/job/pytorch-master-nightly-py3-linux-ppc64le/386/\nThe error messages\nFAIL: test_allreduce_ops (main.ProcessGroupGlooTest)\nTraceback (most recent call last):\nFile \"test_c10d.py\", line 205, in wrapper\nself._join_processes(fn)\nFile \"test_c10d.py\", line 250, in _join_processes\nself._check_return_codes()\nFile \"test_c10d.py\", line 263, in _check_return_codes\nself.assertEqual(first_process.exitcode, 0)\nFile \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual\nsuper(TestCase, self).assertLessEqual(abs(x - y), prec, message)\nAssertionError: 6 not less than or equal to 1e-05 :\nFAIL: test_broadcast_ops (main.ProcessGroupGlooTest)\nTraceback (most recent call last):\nFile \"test_c10d.py\", line 205, in wrapper\nself._join_processes(fn)\nFile \"test_c10d.py\", line 250, in _join_processes\nself._check_return_codes()\nFile \"test_c10d.py\", line 263, in _check_return_codes\nself.assertEqual(first_process.exitcode, 0)\nFile \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual\nsuper(TestCase, self).assertLessEqual(abs(x - y), prec, message)\nAssertionError: 6 not less than or equal to 1e-05 :\nThe logs also show\ntest_allreduce_ops (main.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nFAIL\ntest_broadcast_ops (main.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\nterminate called without an active exception\nFAIL", "body": "when building pytorch master from July 25,   I'm getting failure described below.\r\nI'm building on CPU only system.\r\n\r\nPossibly caused by #9670\r\n\r\nMaybe just add a check to see if a GPU is available if not skip the test.\r\nI do have CUDA libraries installed but it is just running on a system without a GPU.\r\n\r\nhere is the build log :  https://powerci.osuosl.org/job/pytorch-master-nightly-py3-linux-ppc64le/386/\r\n\r\nThe error messages\r\n\r\nFAIL: test_allreduce_ops (__main__.ProcessGroupGlooTest)\r\nTraceback (most recent call last):\r\n  File \"test_c10d.py\", line 205, in wrapper\r\n    self._join_processes(fn)\r\n  File \"test_c10d.py\", line 250, in _join_processes\r\n    self._check_return_codes()\r\n  File \"test_c10d.py\", line 263, in _check_return_codes\r\n    self.assertEqual(first_process.exitcode, 0)\r\n  File \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual\r\n    super(TestCase, self).assertLessEqual(abs(x - y), prec, message)\r\nAssertionError: 6 not less than or equal to 1e-05 : \r\n\r\nFAIL: test_broadcast_ops (__main__.ProcessGroupGlooTest)\r\nTraceback (most recent call last):\r\n  File \"test_c10d.py\", line 205, in wrapper\r\n    self._join_processes(fn)\r\n  File \"test_c10d.py\", line 250, in _join_processes\r\n    self._check_return_codes()\r\n  File \"test_c10d.py\", line 263, in _check_return_codes\r\n    self.assertEqual(first_process.exitcode, 0)\r\n  File \"/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/test/common.py\", line 362, in assertEqual\r\n    super(TestCase, self).assertLessEqual(abs(x - y), prec, message)\r\nAssertionError: 6 not less than or equal to 1e-05 : \r\n\r\n\r\nThe logs also show\r\ntest_allreduce_ops (__main__.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nFAIL\r\ntest_broadcast_ops (__main__.ProcessGroupGlooTest) ... THCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nTHCudaCheck FAIL file=/home/jenkins/workspace/pytorch-master-nightly-py3-linux-ppc64le/pytorch/aten/src/THC/THCGeneral.cpp line=74 error=35 : CUDA driver version is insufficient for CUDA runtime version\r\nterminate called without an active exception\r\nFAIL"}