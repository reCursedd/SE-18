{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166192714", "pull_request_review_id": 94229418, "id": 166192714, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjE5MjcxNA==", "diff_hunk": "@@ -3629,22 +3629,32 @@ TENSOR_IMPLEMENT_LOGICAL(ne,!=)\n     ptrdiff_t r_Size = THTensor_(nElement)(r_);               \\\n     int r_Contig = THTensor_(isContiguous)(r_);               \\\n     int tContig = THTensor_(isContiguous)(t);                 \\\n-    int inOMP = omp_in_parallel();                            \\\n-    if( (r_Size > TH_OMP_OVERHEAD_THRESHOLD) && (!inOMP) ){   \\\n-      TH_TENSOR_APPLY2_OMP(r_Size, r_Contig, tContig, real, r_, real, t, *r__data = CFUNC(*t_data););        \\\n-    }                                                                                                        \\\n-    else {                                                                                                   \\\n-      TH_TENSOR_APPLY2(real, r_, real, t, *r__data = CFUNC(*t_data););                                       \\\n-    }                                                                                                        \\\n+    if (r_Contig && tContig) {                                \\\n+      TH_TENSOR_APPLY2_CONTIG(real, r_, real, t, THVector_(NAME)(r__data, t_data, r__len););                   \\\n+    } else {                                                                                                   \\\n+      int inOMP = omp_in_parallel();                            \\\n+      if( (r_Size > TH_OMP_OVERHEAD_THRESHOLD) && (!inOMP) ){   \\\n+        TH_TENSOR_APPLY2_OMP(r_Size, r_Contig, tContig, real, r_, real, t, *r__data = CFUNC(*t_data););        \\", "path": "aten/src/TH/generic/THTensorMath.c", "position": 17, "original_position": 16, "commit_id": "4b09649650748a8cb42e86009d8fd0c2f34450d5", "original_commit_id": "9325de7e95e2636a28c72ad657ecd1af4f72b390", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "I am concerned about modifying this macro for all the non-AVX functions just so that sigmoid gets remapped. Is it possible to write this so _just_ the functions we want (for now, just sigmoid) check and dispatch to their vector equivalent?  @gchanan do you know why TH_TENSOR_APPLY2_OMP no longer uses TH_TENSOR_APPLY2_CONTIG by default?", "created_at": "2018-02-06T05:50:30Z", "updated_at": "2018-11-23T15:39:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/5010#discussion_r166192714", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5010", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166192714"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5010#discussion_r166192714"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5010"}}, "body_html": "<p>I am concerned about modifying this macro for all the non-AVX functions just so that sigmoid gets remapped. Is it possible to write this so <em>just</em> the functions we want (for now, just sigmoid) check and dispatch to their vector equivalent?  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> do you know why TH_TENSOR_APPLY2_OMP no longer uses TH_TENSOR_APPLY2_CONTIG by default?</p>", "body_text": "I am concerned about modifying this macro for all the non-AVX functions just so that sigmoid gets remapped. Is it possible to write this so just the functions we want (for now, just sigmoid) check and dispatch to their vector equivalent?  @gchanan do you know why TH_TENSOR_APPLY2_OMP no longer uses TH_TENSOR_APPLY2_CONTIG by default?"}