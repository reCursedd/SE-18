{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/364639724", "html_url": "https://github.com/pytorch/pytorch/pull/5010#issuecomment-364639724", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5010", "id": 364639724, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDYzOTcyNA==", "user": {"login": "vedanuj", "id": 13946458, "node_id": "MDQ6VXNlcjEzOTQ2NDU4", "avatar_url": "https://avatars2.githubusercontent.com/u/13946458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vedanuj", "html_url": "https://github.com/vedanuj", "followers_url": "https://api.github.com/users/vedanuj/followers", "following_url": "https://api.github.com/users/vedanuj/following{/other_user}", "gists_url": "https://api.github.com/users/vedanuj/gists{/gist_id}", "starred_url": "https://api.github.com/users/vedanuj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vedanuj/subscriptions", "organizations_url": "https://api.github.com/users/vedanuj/orgs", "repos_url": "https://api.github.com/users/vedanuj/repos", "events_url": "https://api.github.com/users/vedanuj/events{/privacy}", "received_events_url": "https://api.github.com/users/vedanuj/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-10T09:48:54Z", "updated_at": "2018-02-10T09:49:23Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Changes in new commit :</h3>\n<ul>\n<li>\n<p>Added a new macro <code>LAB_IMPLEMENT_VECTORIZED_FUNCTION</code> for the vectorized basic functions. Currently only <code>sigmoid</code> uses this macro which redirects to the vectorized implementation.</p>\n</li>\n<li>\n<p>Although there is no significant improvement in performance(due to exponent being the computationally dominant operation),  replaced <code>_mm256_mul_ps(minus_one, YMM0)</code> with <code>_mm256_sub_ps(zero, YMM0)</code> which should be less expensive.</p>\n</li>\n</ul>\n<p>(Please re-review the code <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a>  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a>)</p>", "body_text": "Changes in new commit :\n\n\nAdded a new macro LAB_IMPLEMENT_VECTORIZED_FUNCTION for the vectorized basic functions. Currently only sigmoid uses this macro which redirects to the vectorized implementation.\n\n\nAlthough there is no significant improvement in performance(due to exponent being the computationally dominant operation),  replaced _mm256_mul_ps(minus_one, YMM0) with _mm256_sub_ps(zero, YMM0) which should be less expensive.\n\n\n(Please re-review the code @zdevito @soumith  @fmassa)", "body": "### Changes in new commit : \r\n\r\n- Added a new macro `LAB_IMPLEMENT_VECTORIZED_FUNCTION` for the vectorized basic functions. Currently only `sigmoid` uses this macro which redirects to the vectorized implementation.\r\n\r\n- Although there is no significant improvement in performance(due to exponent being the computationally dominant operation),  replaced `_mm256_mul_ps(minus_one, YMM0)` with `_mm256_sub_ps(zero, YMM0)` which should be less expensive.\r\n\r\n(Please re-review the code @zdevito @soumith  @fmassa)"}