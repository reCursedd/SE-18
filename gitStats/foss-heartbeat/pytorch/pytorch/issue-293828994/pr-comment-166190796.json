{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166190796", "pull_request_review_id": 94229418, "id": 166190796, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjE5MDc5Ng==", "diff_hunk": "@@ -105,18 +105,25 @@ void THFloatVector_normal_fill_AVX2(float *data,\n   }\n }\n \n-void THFloatVector_sigmoid_AVX2(float *y, const float *x, const ptrdiff_t n){\n+void THFloatVector_sigmoid_AVX2(float *y, const float *x, const ptrdiff_t n) {\n   ptrdiff_t i;\n   const __m256 one = _mm256_set1_ps(1.0f);\n-  __m256 YMM0, YMM1, YMM2;\n-  for (i=0; i<=((n)-8); i+=8) {\n-    YMM0 = _mm256_loadu_ps(x+i);\n-    YMM1 = _mm256_add_ps(one, exp256_ps(YMM0));\n-    YMM2 = _mm256_div_ps(one, YMM1);\n-    _mm256_storeu_ps(y+i, YMM2);\n+  const __m256 minus_one = _mm256_set1_ps(-1.0f);\n+  __m256 YMM0, YMM1, YMM2, YMM3;\n+  for (i = 0; i <= ((n)-16); i += 16) {\n+    YMM0 = _mm256_loadu_ps(x + i);\n+    YMM1 = _mm256_loadu_ps(x + i + 8);\n+    YMM0 = _mm256_mul_ps(minus_one, YMM0);", "path": "aten/src/TH/vector/AVX2.cpp", "position": null, "original_position": 19, "commit_id": "4b09649650748a8cb42e86009d8fd0c2f34450d5", "original_commit_id": "9325de7e95e2636a28c72ad657ecd1af4f72b390", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "Is `_mm256_sub_ps(zero, YMM0)` or an xor of the floating point sign bit cheaper than a multiply here? Though it is probably not that important since exp256 dominates.", "created_at": "2018-02-06T05:32:51Z", "updated_at": "2018-11-23T15:39:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/5010#discussion_r166190796", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5010", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166190796"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5010#discussion_r166190796"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5010"}}, "body_html": "<p>Is <code>_mm256_sub_ps(zero, YMM0)</code> or an xor of the floating point sign bit cheaper than a multiply here? Though it is probably not that important since exp256 dominates.</p>", "body_text": "Is _mm256_sub_ps(zero, YMM0) or an xor of the floating point sign bit cheaper than a multiply here? Though it is probably not that important since exp256 dominates."}