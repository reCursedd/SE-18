{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12875", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12875/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12875/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12875/events", "html_url": "https://github.com/pytorch/pytorch/issues/12875", "id": 372006326, "node_id": "MDU6SXNzdWUzNzIwMDYzMjY=", "number": 12875, "title": "torch.jit.OrderedParameterDict object has no attribute 'copy', when call nn.DataParallel.replicate ", "user": {"login": "unlimblue", "id": 16875768, "node_id": "MDQ6VXNlcjE2ODc1NzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/16875768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/unlimblue", "html_url": "https://github.com/unlimblue", "followers_url": "https://api.github.com/users/unlimblue/followers", "following_url": "https://api.github.com/users/unlimblue/following{/other_user}", "gists_url": "https://api.github.com/users/unlimblue/gists{/gist_id}", "starred_url": "https://api.github.com/users/unlimblue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/unlimblue/subscriptions", "organizations_url": "https://api.github.com/users/unlimblue/orgs", "repos_url": "https://api.github.com/users/unlimblue/repos", "events_url": "https://api.github.com/users/unlimblue/events{/privacy}", "received_events_url": "https://api.github.com/users/unlimblue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-19T15:25:57Z", "updated_at": "2018-10-19T16:52:07Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>prepare a ScriptModule instance</li>\n<li>use nn.Dataparallel with it on multi-gpus env</li>\n<li>get AttributeError: 'OrderedParameterDict' object has no attribute 'copy'</li>\n</ol>\n<ul>\n<li>PyTorch Version (e.g., 1.0): 1.0</li>\n<li>OS (e.g., Linux): Ubuntu 18</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): pip</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version: 9.0</li>\n</ul>\n<h2>Additional context</h2>\n<pre><code># nn/parallel/replicate.py line 21\n    modules = list(network.modules())\n    module_copies = [[] for device in devices]\n    module_indices = {}\n\n    for i, module in enumerate(modules):\n        module_indices[module] = i\n        for j in range(num_replicas):\n            replica = module.__new__(type(module))\n            replica.__dict__ = module.__dict__.copy()\n            **replica._parameters = replica._parameters.copy()**\n            replica._buffers = replica._buffers.copy()\n            replica._modules = replica._modules.copy()\n            module_copies[j].append(replica)\n</code></pre>", "body_text": "\ud83d\udc1b Bug\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nprepare a ScriptModule instance\nuse nn.Dataparallel with it on multi-gpus env\nget AttributeError: 'OrderedParameterDict' object has no attribute 'copy'\n\n\nPyTorch Version (e.g., 1.0): 1.0\nOS (e.g., Linux): Ubuntu 18\nHow you installed PyTorch (conda, pip, source): pip\nPython version: 3.6\nCUDA/cuDNN version: 9.0\n\nAdditional context\n# nn/parallel/replicate.py line 21\n    modules = list(network.modules())\n    module_copies = [[] for device in devices]\n    module_indices = {}\n\n    for i, module in enumerate(modules):\n        module_indices[module] = i\n        for j in range(num_replicas):\n            replica = module.__new__(type(module))\n            replica.__dict__ = module.__dict__.copy()\n            **replica._parameters = replica._parameters.copy()**\n            replica._buffers = replica._buffers.copy()\n            replica._modules = replica._modules.copy()\n            module_copies[j].append(replica)", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. prepare a ScriptModule instance\r\n2. use nn.Dataparallel with it on multi-gpus env\r\n3. get AttributeError: 'OrderedParameterDict' object has no attribute 'copy'\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): Ubuntu 18\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: 9.0\r\n\r\n## Additional context\r\n\r\n```\r\n# nn/parallel/replicate.py line 21\r\n    modules = list(network.modules())\r\n    module_copies = [[] for device in devices]\r\n    module_indices = {}\r\n\r\n    for i, module in enumerate(modules):\r\n        module_indices[module] = i\r\n        for j in range(num_replicas):\r\n            replica = module.__new__(type(module))\r\n            replica.__dict__ = module.__dict__.copy()\r\n            **replica._parameters = replica._parameters.copy()**\r\n            replica._buffers = replica._buffers.copy()\r\n            replica._modules = replica._modules.copy()\r\n            module_copies[j].append(replica)\r\n```"}