{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/423424905", "html_url": "https://github.com/pytorch/pytorch/issues/9062#issuecomment-423424905", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9062", "id": 423424905, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzQyNDkwNQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-21T06:13:07Z", "updated_at": "2018-09-21T06:51:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>So what happens is that you are sampling without replacement and you want more samples than you have categories with positive probability.<br>\nThe strategy of sampling is to zero out the \"taken\" probabilities after each sample.<br>\nWhen this hits the case of having all zeros left, it explodes.</p>\n<p>The CPU version just returns zeros after that happens, which has been met with objections, too, in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"261678734\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2896\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2896/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2896\">#2896</a> .</p>\n<p>Unfortunately, It is not possible to raise an error from the CUDA kernel (without synchronisation, which isn't an option). As mentioned there, I don't think returning invalid values (e.g. -1) is a good option if people use that to index into things.</p>\n<p>I think we have three options:</p>\n<ul>\n<li>keep the CUDA version as is and make the CPU version raise a descriptive error message,</li>\n<li>make the CUDA version return 0 when the probabilities are exhausted to match the CPU version,</li>\n<li>change both the CUDA and CPU version to return the zero probability categories without repetition.</li>\n</ul>", "body_text": "So what happens is that you are sampling without replacement and you want more samples than you have categories with positive probability.\nThe strategy of sampling is to zero out the \"taken\" probabilities after each sample.\nWhen this hits the case of having all zeros left, it explodes.\nThe CPU version just returns zeros after that happens, which has been met with objections, too, in #2896 .\nUnfortunately, It is not possible to raise an error from the CUDA kernel (without synchronisation, which isn't an option). As mentioned there, I don't think returning invalid values (e.g. -1) is a good option if people use that to index into things.\nI think we have three options:\n\nkeep the CUDA version as is and make the CPU version raise a descriptive error message,\nmake the CUDA version return 0 when the probabilities are exhausted to match the CPU version,\nchange both the CUDA and CPU version to return the zero probability categories without repetition.", "body": "So what happens is that you are sampling without replacement and you want more samples than you have categories with positive probability.\r\nThe strategy of sampling is to zero out the \"taken\" probabilities after each sample.\r\nWhen this hits the case of having all zeros left, it explodes.\r\n\r\nThe CPU version just returns zeros after that happens, which has been met with objections, too, in #2896 .\r\n\r\nUnfortunately, It is not possible to raise an error from the CUDA kernel (without synchronisation, which isn't an option). As mentioned there, I don't think returning invalid values (e.g. -1) is a good option if people use that to index into things.\r\n\r\nI think we have three options:\r\n- keep the CUDA version as is and make the CPU version raise a descriptive error message,\r\n- make the CUDA version return 0 when the probabilities are exhausted to match the CPU version,\r\n- change both the CUDA and CPU version to return the zero probability categories without repetition.\r\n"}