{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2010", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2010/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2010/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2010/events", "html_url": "https://github.com/pytorch/pytorch/issues/2010", "id": 241358736, "node_id": "MDU6SXNzdWUyNDEzNTg3MzY=", "number": 2010, "title": "gpu version of pytorch not working on docker image", "user": {"login": "tharindu-mathew", "id": 1774049, "node_id": "MDQ6VXNlcjE3NzQwNDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1774049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tharindu-mathew", "html_url": "https://github.com/tharindu-mathew", "followers_url": "https://api.github.com/users/tharindu-mathew/followers", "following_url": "https://api.github.com/users/tharindu-mathew/following{/other_user}", "gists_url": "https://api.github.com/users/tharindu-mathew/gists{/gist_id}", "starred_url": "https://api.github.com/users/tharindu-mathew/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tharindu-mathew/subscriptions", "organizations_url": "https://api.github.com/users/tharindu-mathew/orgs", "repos_url": "https://api.github.com/users/tharindu-mathew/repos", "events_url": "https://api.github.com/users/tharindu-mathew/events{/privacy}", "received_events_url": "https://api.github.com/users/tharindu-mathew/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 553773019, "node_id": "MDU6TGFiZWw1NTM3NzMwMTk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs-reproduction", "name": "needs-reproduction", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-07-07T19:31:13Z", "updated_at": "2017-07-13T06:11:49Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>The docker image was created by running the command on the README file. My nvidia drivers work fine, and the cpu version of this works fine. But, running the classifier on the gpu as mentioned in <a href=\"url\">http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html</a> gives the following error:</p>\n<pre><code>(pytorch-py35) root@eba92d25c1cd:~# nvidia-smi\nFri Jul  7 19:24:32 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:04:00.0      On |                  N/A |\n| 23%   26C    P8    16W / 250W |   1331MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A |\n| 23%   29C    P8    15W / 250W |      4MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n(pytorch-py35) root@eba92d25c1cd:~# nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Tue_Jan_10_13:22:03_CST_2017\nCuda compilation tools, release 8.0, V8.0.61\n(pytorch-py35) root@eba92d25c1cd:~# python classifier.py\nFiles already downloaded and verified\nFiles already downloaded and verified\nTraceback (most recent call last):\n  File \"classifier.py\", line 45, in &lt;module&gt;\n    net.cuda()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in cuda\n    return self._apply(lambda t: t.cuda(device_id))\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 118, in _apply\n    module._apply(fn)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 124, in _apply\n    param.data = fn(param.data)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in &lt;lambda&gt;\n    return self._apply(lambda t: t.cuda(device_id))\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 65, in _cuda\n    return new_type(self.size()).copy_(self, async)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 272, in __new__\n    _lazy_init()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 84, in _lazy_init\n    _check_driver()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 51, in _check_driver\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled\n\n</code></pre>", "body_text": "The docker image was created by running the command on the README file. My nvidia drivers work fine, and the cpu version of this works fine. But, running the classifier on the gpu as mentioned in http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html gives the following error:\n(pytorch-py35) root@eba92d25c1cd:~# nvidia-smi\nFri Jul  7 19:24:32 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:04:00.0      On |                  N/A |\n| 23%   26C    P8    16W / 250W |   1331MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A |\n| 23%   29C    P8    15W / 250W |      4MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n(pytorch-py35) root@eba92d25c1cd:~# nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Tue_Jan_10_13:22:03_CST_2017\nCuda compilation tools, release 8.0, V8.0.61\n(pytorch-py35) root@eba92d25c1cd:~# python classifier.py\nFiles already downloaded and verified\nFiles already downloaded and verified\nTraceback (most recent call last):\n  File \"classifier.py\", line 45, in <module>\n    net.cuda()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in cuda\n    return self._apply(lambda t: t.cuda(device_id))\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 118, in _apply\n    module._apply(fn)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 124, in _apply\n    param.data = fn(param.data)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in <lambda>\n    return self._apply(lambda t: t.cuda(device_id))\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 65, in _cuda\n    return new_type(self.size()).copy_(self, async)\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 272, in __new__\n    _lazy_init()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 84, in _lazy_init\n    _check_driver()\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 51, in _check_driver\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled", "body": "The docker image was created by running the command on the README file. My nvidia drivers work fine, and the cpu version of this works fine. But, running the classifier on the gpu as mentioned in [http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html](url) gives the following error:\r\n\r\n```\r\n(pytorch-py35) root@eba92d25c1cd:~# nvidia-smi\r\nFri Jul  7 19:24:32 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 0000:04:00.0      On |                  N/A |\r\n| 23%   26C    P8    16W / 250W |   1331MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A |\r\n| 23%   29C    P8    15W / 250W |      4MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n(pytorch-py35) root@eba92d25c1cd:~# nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Tue_Jan_10_13:22:03_CST_2017\r\nCuda compilation tools, release 8.0, V8.0.61\r\n(pytorch-py35) root@eba92d25c1cd:~# python classifier.py\r\nFiles already downloaded and verified\r\nFiles already downloaded and verified\r\nTraceback (most recent call last):\r\n  File \"classifier.py\", line 45, in <module>\r\n    net.cuda()\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in cuda\r\n    return self._apply(lambda t: t.cuda(device_id))\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 118, in _apply\r\n    module._apply(fn)\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 124, in _apply\r\n    param.data = fn(param.data)\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 147, in <lambda>\r\n    return self._apply(lambda t: t.cuda(device_id))\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 65, in _cuda\r\n    return new_type(self.size()).copy_(self, async)\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 272, in __new__\r\n    _lazy_init()\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 84, in _lazy_init\r\n    _check_driver()\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 51, in _check_driver\r\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\r\nAssertionError: Torch not compiled with CUDA enabled\r\n\r\n```"}