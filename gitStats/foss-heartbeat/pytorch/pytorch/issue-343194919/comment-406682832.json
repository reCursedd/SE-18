{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/406682832", "html_url": "https://github.com/pytorch/pytorch/pull/9640#issuecomment-406682832", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9640", "id": 406682832, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjY4MjgzMg==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-20T18:08:27Z", "updated_at": "2018-07-20T18:08:59Z", "author_association": "MEMBER", "body_html": "<p>I think we also want to apply a similar patch to <code>THCUNN</code>, and also handle it somewhere where CUDNN is dispatched, as the error message is not great there.</p>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">1</span>]: <span class=\"pl-k\">import</span> torch\n\nIn [<span class=\"pl-c1\">2</span>]: conv <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>).cuda()\n\nIn [<span class=\"pl-c1\">3</span>]: tensor <span class=\"pl-k\">=</span> torch.empty(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>).cuda()\n\nIn [<span class=\"pl-c1\">4</span>]: conv(tensor).shape\n<span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">4</span><span class=\"pl-k\">-</span>c6df65b7b5a7<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span> conv(tensor).shape\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>github<span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>module.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">475</span>             result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._slow_forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">476</span>         <span class=\"pl-k\">else</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">477</span>             result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">478</span>         <span class=\"pl-k\">for</span> hook <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>._forward_hooks.values():\n    <span class=\"pl-c1\">479</span>             hook_result <span class=\"pl-k\">=</span> hook(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, result)\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>github<span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>)\n    <span class=\"pl-c1\">299</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>):\n    <span class=\"pl-c1\">300</span>         <span class=\"pl-k\">return</span> F.conv2d(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight, <span class=\"pl-c1\">self</span>.bias, <span class=\"pl-c1\">self</span>.stride,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">301</span>                         <span class=\"pl-c1\">self</span>.padding, <span class=\"pl-c1\">self</span>.dilation, <span class=\"pl-c1\">self</span>.groups)\n    <span class=\"pl-c1\">302</span>\n    <span class=\"pl-c1\">303</span>\n\n<span class=\"pl-c1\">RuntimeError</span>: CuDNN error: <span class=\"pl-c1\">CUDNN_STATUS_BAD_PARAM</span>\n\nIn [<span class=\"pl-c1\">5</span>]: torch.backends.cudnn.enabled <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\n\nIn [<span class=\"pl-c1\">6</span>]: conv(tensor).shape\nOut[<span class=\"pl-c1\">6</span>]: torch.Size([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>])</pre></div>", "body_text": "I think we also want to apply a similar patch to THCUNN, and also handle it somewhere where CUDNN is dispatched, as the error message is not great there.\nIn [1]: import torch\n\nIn [2]: conv = torch.nn.Conv2d(1, 1, kernel_size=3, dilation=2, stride=2).cuda()\n\nIn [3]: tensor = torch.empty(1, 1, 4, 4).cuda()\n\nIn [4]: conv(tensor).shape\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-4-c6df65b7b5a7> in <module>()\n----> 1 conv(tensor).shape\n\n~/github/pytorch/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    475             result = self._slow_forward(*input, **kwargs)\n    476         else:\n--> 477             result = self.forward(*input, **kwargs)\n    478         for hook in self._forward_hooks.values():\n    479             hook_result = hook(self, input, result)\n\n~/github/pytorch/torch/nn/modules/conv.py in forward(self, input)\n    299     def forward(self, input):\n    300         return F.conv2d(input, self.weight, self.bias, self.stride,\n--> 301                         self.padding, self.dilation, self.groups)\n    302\n    303\n\nRuntimeError: CuDNN error: CUDNN_STATUS_BAD_PARAM\n\nIn [5]: torch.backends.cudnn.enabled = False\n\nIn [6]: conv(tensor).shape\nOut[6]: torch.Size([1, 1, 1, 1])", "body": "I think we also want to apply a similar patch to `THCUNN`, and also handle it somewhere where CUDNN is dispatched, as the error message is not great there.\r\n```python\r\nIn [1]: import torch\r\n\r\nIn [2]: conv = torch.nn.Conv2d(1, 1, kernel_size=3, dilation=2, stride=2).cuda()\r\n\r\nIn [3]: tensor = torch.empty(1, 1, 4, 4).cuda()\r\n\r\nIn [4]: conv(tensor).shape\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-c6df65b7b5a7> in <module>()\r\n----> 1 conv(tensor).shape\r\n\r\n~/github/pytorch/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n--> 477             result = self.forward(*input, **kwargs)\r\n    478         for hook in self._forward_hooks.values():\r\n    479             hook_result = hook(self, input, result)\r\n\r\n~/github/pytorch/torch/nn/modules/conv.py in forward(self, input)\r\n    299     def forward(self, input):\r\n    300         return F.conv2d(input, self.weight, self.bias, self.stride,\r\n--> 301                         self.padding, self.dilation, self.groups)\r\n    302\r\n    303\r\n\r\nRuntimeError: CuDNN error: CUDNN_STATUS_BAD_PARAM\r\n\r\nIn [5]: torch.backends.cudnn.enabled = False\r\n\r\nIn [6]: conv(tensor).shape\r\nOut[6]: torch.Size([1, 1, 1, 1])\r\n```"}