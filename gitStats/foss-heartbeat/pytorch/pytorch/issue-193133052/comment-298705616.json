{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/298705616", "html_url": "https://github.com/pytorch/pytorch/issues/289#issuecomment-298705616", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/289", "id": 298705616, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODcwNTYxNg==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-02T17:33:58Z", "updated_at": "2017-05-02T17:33:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've been working on broadcasting, and it probably makes sense to introduce broadcasting and squeeze dimension together (i.e. \"Broadcasting itself can be added sooner as it doesn't need any thought on backward-compatibility\" isn't quite true).</p>\n<p>For example, consider test_nn.test_InstanceNorm1d:</p>\n<pre><code>        output = IN(input_var)\n        \n        input_reshaped = input_var.transpose(1, 0).contiguous().view(c, -1)\n        mean = input_reshaped.mean(1)\n\n        # do some calculation based on mean.data - IN.running_mean\n</code></pre>\n<p>Here, mean.data is (4,1) (because the dimension is not squeezed) and In.running_mean is (4).  The broadcast causes the result of the calculation to be (4,4) instead of (4,1), which changes the calculation (e.g. imagine a sum).  If mean is changed to squeeze the dimension, this calculation \"just works\" as written.  Clearly there are cases where this won't hold, but it seems like introducing them together may cause less disruption.</p>", "body_text": "I've been working on broadcasting, and it probably makes sense to introduce broadcasting and squeeze dimension together (i.e. \"Broadcasting itself can be added sooner as it doesn't need any thought on backward-compatibility\" isn't quite true).\nFor example, consider test_nn.test_InstanceNorm1d:\n        output = IN(input_var)\n        \n        input_reshaped = input_var.transpose(1, 0).contiguous().view(c, -1)\n        mean = input_reshaped.mean(1)\n\n        # do some calculation based on mean.data - IN.running_mean\n\nHere, mean.data is (4,1) (because the dimension is not squeezed) and In.running_mean is (4).  The broadcast causes the result of the calculation to be (4,4) instead of (4,1), which changes the calculation (e.g. imagine a sum).  If mean is changed to squeeze the dimension, this calculation \"just works\" as written.  Clearly there are cases where this won't hold, but it seems like introducing them together may cause less disruption.", "body": "I've been working on broadcasting, and it probably makes sense to introduce broadcasting and squeeze dimension together (i.e. \"Broadcasting itself can be added sooner as it doesn't need any thought on backward-compatibility\" isn't quite true).\r\n\r\nFor example, consider test_nn.test_InstanceNorm1d:\r\n```\r\n        output = IN(input_var)\r\n        \r\n        input_reshaped = input_var.transpose(1, 0).contiguous().view(c, -1)\r\n        mean = input_reshaped.mean(1)\r\n\r\n        # do some calculation based on mean.data - IN.running_mean\r\n```\r\n\r\nHere, mean.data is (4,1) (because the dimension is not squeezed) and In.running_mean is (4).  The broadcast causes the result of the calculation to be (4,4) instead of (4,1), which changes the calculation (e.g. imagine a sum).  If mean is changed to squeeze the dimension, this calculation \"just works\" as written.  Clearly there are cases where this won't hold, but it seems like introducing them together may cause less disruption."}