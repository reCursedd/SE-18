{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/286480946", "html_url": "https://github.com/pytorch/pytorch/issues/289#issuecomment-286480946", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/289", "id": 286480946, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjQ4MDk0Ng==", "user": {"login": "jph00", "id": 346999, "node_id": "MDQ6VXNlcjM0Njk5OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/346999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jph00", "html_url": "https://github.com/jph00", "followers_url": "https://api.github.com/users/jph00/followers", "following_url": "https://api.github.com/users/jph00/following{/other_user}", "gists_url": "https://api.github.com/users/jph00/gists{/gist_id}", "starred_url": "https://api.github.com/users/jph00/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jph00/subscriptions", "organizations_url": "https://api.github.com/users/jph00/orgs", "repos_url": "https://api.github.com/users/jph00/repos", "events_url": "https://api.github.com/users/jph00/events{/privacy}", "received_events_url": "https://api.github.com/users/jph00/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-14T16:37:40Z", "updated_at": "2017-03-14T16:37:40Z", "author_association": "NONE", "body_html": "<p>FWIW I'd love to see an auto-squeeze, with an optional keepdims param; as you say, with broadcasting, this becomes much more convenient.</p>\n<p>My $0.02: the design principle of minimizing surprise for lua users should be a distant second to minimizing surprise for numpy users (and, more generally, for creating a concise and expressive API!) The more popular pytorch gets, the more the number of folks using it that come from a numpy background will dwarf the number from a lua background, based on the relative size of the populations of lua-using data scientists vs python-using data scientists.</p>", "body_text": "FWIW I'd love to see an auto-squeeze, with an optional keepdims param; as you say, with broadcasting, this becomes much more convenient.\nMy $0.02: the design principle of minimizing surprise for lua users should be a distant second to minimizing surprise for numpy users (and, more generally, for creating a concise and expressive API!) The more popular pytorch gets, the more the number of folks using it that come from a numpy background will dwarf the number from a lua background, based on the relative size of the populations of lua-using data scientists vs python-using data scientists.", "body": "FWIW I'd love to see an auto-squeeze, with an optional keepdims param; as you say, with broadcasting, this becomes much more convenient.\r\n\r\nMy $0.02: the design principle of minimizing surprise for lua users should be a distant second to minimizing surprise for numpy users (and, more generally, for creating a concise and expressive API!) The more popular pytorch gets, the more the number of folks using it that come from a numpy background will dwarf the number from a lua background, based on the relative size of the populations of lua-using data scientists vs python-using data scientists."}