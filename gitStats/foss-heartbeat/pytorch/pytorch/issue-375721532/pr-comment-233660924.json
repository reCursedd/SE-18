{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233660924", "pull_request_review_id": 175129096, "id": 233660924, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMzY2MDkyNA==", "diff_hunk": "@@ -0,0 +1,245 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/Context.h\"\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/NativeFunctions.h\"\n+#include \"ATen/cuda/CUDAApplyUtils.cuh\"\n+#include \"ATen/cuda/CUDAContext.h\"\n+#include \"ATen/cuda/CUDAEvent.h\"\n+#include \"ATen/cuda/CUDAStream.h\"\n+#include \"ATen/native/Copy.h\"\n+\n+namespace {\n+\n+using namespace at;\n+using namespace at::cuda;\n+\n+// Copy operator for the pointwise apply kernel\n+template <typename dst_T, typename src_T>\n+struct CopyOp {\n+  static void apply(Tensor& dst, const Tensor& src) {\n+    CUDA_tensor_apply2<dst_T, src_T>(\n+        dst, src, [] __device__(dst_T & dst_val, const src_T& src_val) {\n+#if __CUDA_ARCH__ >= 350\n+          dst_val = static_cast<dst_T>(\n+              static_cast<native::inter_copy_type_t<dst_T>>(__ldg(&src_val)));\n+#else\n+          dst_val = static_cast<dst_T>(static_cast<native::inter_copy_type_t<dst_T>>(src_val));\n+#endif\n+        });\n+  }\n+};\n+\n+// device-to-device copy, does type conversion\n+template <typename dst_T, typename src_T>\n+void copy_device_to_device(Tensor& dst, const Tensor& src) {\n+  auto numel = dst.numel();\n+  if (dst.is_same(src) || numel == 0) {\n+    return;\n+  }\n+\n+  // We can memcpy the memory if:\n+  // -both tensors are contiguous; or,\n+  // -there is only one element to copy; or,\n+  // -FIXME: if both tensors have matching size and stride arrays, and no\n+  // holes within (in other words, there is some permutation that can be applied\n+  // to the size/strides such that the resulting tensor is\n+  // contiguous).\n+  // -AND: both tensors have the same type.\n+  bool same_type = std::is_same<dst_T, src_T>::value;\n+  bool memcpy_eligible =\n+      ((src.is_contiguous() && dst.is_contiguous()) || (numel == 1)) &&\n+      same_type;\n+\n+  Device src_device = src.device();\n+  Device dst_device = dst.device();\n+\n+  // Try to enable p2p access. This also handles the case src_device ==\n+  // dst_device.\n+  bool p2pEnabled = THCState_getPeerToPeerAccess(\n+      globalContext().getTHCState(), src_device.index(), dst_device.index());\n+\n+  // We always perform the copy on the source device, using the\n+  // current stream on the source device.\n+  // If the copy is on the default stream, then we fully synchronize\n+  // both src and dst's default streams for completion of the\n+  // copy. We have to explicitly do this for non-contig copies.\n+  // This mimics the behavior of cross-device cudaMemcpyAsync on\n+  // the default stream.\n+  // If the copy is not on the default stream, then it is up to the\n+  // user to add needed synchronization on the dst device, since the\n+  // stream on the dst device that wishes to synchronize may not be\n+  // the same index as the one on the src device.\n+  CUDAStream copy_stream = getCurrentCUDAStream(src_device.index());\n+  if (src_device != dst_device && copy_stream == NULL) {\n+    // This is a cross-device copy on the default stream. We perform a\n+    // two-way barrier between both devices' default streams before\n+    // the copy. This ensures that any write-after-write and\n+    // write-after-read dependencies on the destination side are\n+    // handled, so that no one is operating on the dst memory when\n+    // we perform the copy.\n+    // src waits on dst barrier (src already waits on src)\n+    CUDAEvent dst_ready;\n+    DeviceGuard device_guard_dst{dst_device};\n+    dst_ready.record(getDefaultCUDAStream(dst_device.index()));\n+\n+    DeviceGuard device_guard_src{src_device};\n+    dst_ready.block(copy_stream);\n+  }\n+\n+  DeviceGuard device_guard{src_device};", "path": "aten/src/ATen/native/cuda/Copy.cu", "position": null, "original_position": 89, "commit_id": "4052372d4f8f595ce69417cfd7db9dde6279397c", "original_commit_id": "768d164162b2b688f17f84ac4db6e9998ba00414", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "If you do want the set device to \"splash\" over, probably the best strategy is to define a CUDAGuard at the top level, and then just call `set_device` on it.", "created_at": "2018-11-14T23:27:08Z", "updated_at": "2018-11-23T15:54:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/13348#discussion_r233660924", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13348", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233660924"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13348#discussion_r233660924"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13348"}}, "body_html": "<p>If you do want the set device to \"splash\" over, probably the best strategy is to define a CUDAGuard at the top level, and then just call <code>set_device</code> on it.</p>", "body_text": "If you do want the set device to \"splash\" over, probably the best strategy is to define a CUDAGuard at the top level, and then just call set_device on it."}