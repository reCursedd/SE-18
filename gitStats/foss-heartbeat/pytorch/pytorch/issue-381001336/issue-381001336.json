{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14013", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14013/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14013/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14013/events", "html_url": "https://github.com/pytorch/pytorch/issues/14013", "id": 381001336, "node_id": "MDU6SXNzdWUzODEwMDEzMzY=", "number": 14013, "title": "UserWarning: ONNX export failed on ATen operator _argmax because torch.onnx.symbolic._argmax does not exist", "user": {"login": "mathmanu", "id": 2990503, "node_id": "MDQ6VXNlcjI5OTA1MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2990503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mathmanu", "html_url": "https://github.com/mathmanu", "followers_url": "https://api.github.com/users/mathmanu/followers", "following_url": "https://api.github.com/users/mathmanu/following{/other_user}", "gists_url": "https://api.github.com/users/mathmanu/gists{/gist_id}", "starred_url": "https://api.github.com/users/mathmanu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mathmanu/subscriptions", "organizations_url": "https://api.github.com/users/mathmanu/orgs", "repos_url": "https://api.github.com/users/mathmanu/repos", "events_url": "https://api.github.com/users/mathmanu/events{/privacy}", "received_events_url": "https://api.github.com/users/mathmanu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-15T05:02:26Z", "updated_at": "2018-11-19T18:49:34Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<p>A model containing argmax cannot be converted to ONNX.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:<br>\nTo reproduce the error, place the following in a python code and execute it:</p>\n\n<p>import torch<br>\nimport torch.nn<br>\nclass ArgMaxModule(torch.nn.Module):<br>\ndef forward(self, x):<br>\npred = torch.argmax(x, dim=1, keepdim=True)<br>\nreturn pred</p>\n<p>model = ArgMaxModule()<br>\ninput_rand = torch.rand((1, 3, 512, 1024))<br>\ntorch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)</p>\n<h2>Expected behavior</h2>\n\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<ul>\n<li>PyTorch Version (e.g., 1.0): 1.0</li>\n<li>OS (e.g., Linux): Ubuntu</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): conda</li>\n<li>Build command you used (if compiling from source):</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version: CUDA 9.0</li>\n<li>GPU models and configuration: GTX1080Ti</li>\n<li>Any other relevant information:</li>\n</ul>\n<h2>Additional context</h2>\n\n<p>The error reported is:</p>\n<p>/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator _argmax because torch.onnx.symbolic._argmax does not exist<br>\n.format(op_name, op_name))<br>\ngraph(%x : Float(1, 3, 512, 1024)) {<br>\n%1 : Long() = onnx::Constant<a href=\"\">value={1}</a>, scope: ArgMaxModule<br>\n%2 : Long() = onnx::Constant<a href=\"\">value={1}</a>, scope: ArgMaxModule<br>\n%3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule<br>\nreturn (%3);<br>\n}</p>\n<p>Traceback (most recent call last):<br>\nFile \"./scripts/test_onnx.py\", line 14, in <br>\ntorch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)<br>\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/<strong>init</strong>.py\", line 27, in export<br>\nreturn utils.export(*args, **kwargs)<br>\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export<br>\noperator_export_type=operator_export_type)<br>\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 287, in _export<br>\nproto, export_map = graph.export(params, _onnx_opset_version, defer_weight_export, operator_export_type)<br>\nRuntimeError: ONNX export failed: Couldn't export operator aten::_argmax</p>\n<p>Defined at:<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/functional.py(533): argmax<br>\n./scripts/test_onnx.py(7): forward<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(467): _slow_forward<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(477): <strong>call</strong><br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/<strong>init</strong>.py(225): forward<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(479): <strong>call</strong><br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/<strong>init</strong>.py(172): get_trace_graph<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(192): _trace_and_get_graph_from_model<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(224): _model_to_graph<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(281): _export<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(104): export<br>\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/<strong>init</strong>.py(27): export<br>\n./scripts/test_onnx.py(14): </p>\n<p>Graph we tried to export:<br>\ngraph(%x : Float(1, 3, 512, 1024)) {<br>\n%1 : Long() = onnx::Constant<a href=\"\">value={1}</a>, scope: ArgMaxModule<br>\n%2 : Long() = onnx::Constant<a href=\"\">value={1}</a>, scope: ArgMaxModule<br>\n%3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule<br>\nreturn (%3);<br>\n}</p>", "body_text": "\ud83d\udc1b Bug\n\nA model containing argmax cannot be converted to ONNX.\nTo Reproduce\nSteps to reproduce the behavior:\nTo reproduce the error, place the following in a python code and execute it:\n\nimport torch\nimport torch.nn\nclass ArgMaxModule(torch.nn.Module):\ndef forward(self, x):\npred = torch.argmax(x, dim=1, keepdim=True)\nreturn pred\nmodel = ArgMaxModule()\ninput_rand = torch.rand((1, 3, 512, 1024))\ntorch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)\nExpected behavior\n\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\n\nPyTorch Version (e.g., 1.0): 1.0\nOS (e.g., Linux): Ubuntu\nHow you installed PyTorch (conda, pip, source): conda\nBuild command you used (if compiling from source):\nPython version: 3.6\nCUDA/cuDNN version: CUDA 9.0\nGPU models and configuration: GTX1080Ti\nAny other relevant information:\n\nAdditional context\n\nThe error reported is:\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator _argmax because torch.onnx.symbolic._argmax does not exist\n.format(op_name, op_name))\ngraph(%x : Float(1, 3, 512, 1024)) {\n%1 : Long() = onnx::Constantvalue={1}, scope: ArgMaxModule\n%2 : Long() = onnx::Constantvalue={1}, scope: ArgMaxModule\n%3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule\nreturn (%3);\n}\nTraceback (most recent call last):\nFile \"./scripts/test_onnx.py\", line 14, in \ntorch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/init.py\", line 27, in export\nreturn utils.export(*args, **kwargs)\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\noperator_export_type=operator_export_type)\nFile \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 287, in _export\nproto, export_map = graph.export(params, _onnx_opset_version, defer_weight_export, operator_export_type)\nRuntimeError: ONNX export failed: Couldn't export operator aten::_argmax\nDefined at:\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/functional.py(533): argmax\n./scripts/test_onnx.py(7): forward\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(467): _slow_forward\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(477): call\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/init.py(225): forward\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(479): call\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/init.py(172): get_trace_graph\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(192): _trace_and_get_graph_from_model\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(224): _model_to_graph\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(281): _export\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(104): export\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/init.py(27): export\n./scripts/test_onnx.py(14): \nGraph we tried to export:\ngraph(%x : Float(1, 3, 512, 1024)) {\n%1 : Long() = onnx::Constantvalue={1}, scope: ArgMaxModule\n%2 : Long() = onnx::Constantvalue={1}, scope: ArgMaxModule\n%3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule\nreturn (%3);\n}", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nA model containing argmax cannot be converted to ONNX. \r\n \r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\nTo reproduce the error, place the following in a python code and execute it:\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\nimport torch\r\nimport torch.nn\r\nclass ArgMaxModule(torch.nn.Module):\r\n    def forward(self, x):\r\n        pred = torch.argmax(x, dim=1, keepdim=True)\r\n        return pred\r\n\r\nmodel = ArgMaxModule()\r\ninput_rand = torch.rand((1, 3, 512, 1024))\r\ntorch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): Ubuntu\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: CUDA 9.0\r\n - GPU models and configuration: GTX1080Ti\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\nThe error reported is:\r\n\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator _argmax because torch.onnx.symbolic._argmax does not exist\r\n  .format(op_name, op_name))\r\ngraph(%x : Float(1, 3, 512, 1024)) {\r\n  %1 : Long() = onnx::Constant[value={1}](), scope: ArgMaxModule\r\n  %2 : Long() = onnx::Constant[value={1}](), scope: ArgMaxModule\r\n  %3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule\r\n  return (%3);\r\n}\r\n\r\nTraceback (most recent call last):\r\n  File \"./scripts/test_onnx.py\", line 14, in <module>\r\n    torch.onnx.export(model, input_rand, 'argmax_model.onnx', verbose=True)\r\n  File \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 287, in _export\r\n    proto, export_map = graph.export(params, _onnx_opset_version, defer_weight_export, operator_export_type)\r\nRuntimeError: ONNX export failed: Couldn't export operator aten::_argmax\r\n\r\nDefined at:\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/functional.py(533): argmax\r\n./scripts/test_onnx.py(7): forward\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(467): _slow_forward\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(477): __call__\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py(225): forward\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py(479): __call__\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/jit/__init__.py(172): get_trace_graph\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(192): _trace_and_get_graph_from_model\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(224): _model_to_graph\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(281): _export\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py(104): export\r\n/user/files/apps/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py(27): export\r\n./scripts/test_onnx.py(14): <module>\r\n\r\n\r\nGraph we tried to export:\r\ngraph(%x : Float(1, 3, 512, 1024)) {\r\n  %1 : Long() = onnx::Constant[value={1}](), scope: ArgMaxModule\r\n  %2 : Long() = onnx::Constant[value={1}](), scope: ArgMaxModule\r\n  %3 : Long(1, 1, 512, 1024) = aten::_argmax(%x, %1, %2), scope: ArgMaxModule\r\n  return (%3);\r\n}\r\n"}