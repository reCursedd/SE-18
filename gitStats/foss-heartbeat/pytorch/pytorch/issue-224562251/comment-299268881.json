{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/299268881", "html_url": "https://github.com/pytorch/pytorch/issues/1362#issuecomment-299268881", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1362", "id": 299268881, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTI2ODg4MQ==", "user": {"login": "jekbradbury", "id": 11729078, "node_id": "MDQ6VXNlcjExNzI5MDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11729078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jekbradbury", "html_url": "https://github.com/jekbradbury", "followers_url": "https://api.github.com/users/jekbradbury/followers", "following_url": "https://api.github.com/users/jekbradbury/following{/other_user}", "gists_url": "https://api.github.com/users/jekbradbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/jekbradbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jekbradbury/subscriptions", "organizations_url": "https://api.github.com/users/jekbradbury/orgs", "repos_url": "https://api.github.com/users/jekbradbury/repos", "events_url": "https://api.github.com/users/jekbradbury/events{/privacy}", "received_events_url": "https://api.github.com/users/jekbradbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-04T18:23:39Z", "updated_at": "2017-05-04T18:23:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The <code>_Loss</code> subclass is currently tailored to the set of loss functions that wrap existing C fwd+bwd implementations from the Lua Torch backend library. Since you're most likely implementing in pure PyTorch (unless there are performance issues there that you can't get around), it's probably simpler to just subclass <code>Module</code>, whose ordinary behavior is to use the PyTorch implementation you provide in <code>forward</code> and rely on autograd for the backward pass.<br>\n(I think what you're bringing up is effectively the difference between structural and nominative subtyping, and Python seems to lean towards structural).</p>", "body_text": "The _Loss subclass is currently tailored to the set of loss functions that wrap existing C fwd+bwd implementations from the Lua Torch backend library. Since you're most likely implementing in pure PyTorch (unless there are performance issues there that you can't get around), it's probably simpler to just subclass Module, whose ordinary behavior is to use the PyTorch implementation you provide in forward and rely on autograd for the backward pass.\n(I think what you're bringing up is effectively the difference between structural and nominative subtyping, and Python seems to lean towards structural).", "body": "The `_Loss` subclass is currently tailored to the set of loss functions that wrap existing C fwd+bwd implementations from the Lua Torch backend library. Since you're most likely implementing in pure PyTorch (unless there are performance issues there that you can't get around), it's probably simpler to just subclass `Module`, whose ordinary behavior is to use the PyTorch implementation you provide in `forward` and rely on autograd for the backward pass.\r\n(I think what you're bringing up is effectively the difference between structural and nominative subtyping, and Python seems to lean towards structural)."}