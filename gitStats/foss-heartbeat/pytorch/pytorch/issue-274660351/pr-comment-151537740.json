{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/151537740", "pull_request_review_id": 77260011, "id": 151537740, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MTUzNzc0MA==", "diff_hunk": "@@ -33,6 +35,84 @@ static PyObject * THPVariable_detach_(PyObject* self, PyObject* args)\n   END_HANDLE_TH_ERRORS\n }\n \n+static IntList dispatch_size(const Tensor& self) {\n+  // avoid releasing GIL/changing device, should be quick\n+  // yes, this is called sizes in ATen.\n+  return self.sizes();\n+}\n+\n+static int64_t dispatch_size(const Tensor& self, int64_t dim) {\n+  // avoid releasing GIL/changing device, should be quick\n+  return self.size(dim);\n+}\n+\n+static PyObject * THPVariable_size(PyObject* self, PyObject* args, PyObject* kwargs)\n+{\n+  HANDLE_TH_ERRORS\n+  static PythonArgParser parser({\n+    \"size(int64_t dim)\",\n+    \"size()\",\n+  });\n+  auto& self_ = reinterpret_cast<THPVariable*>(self)->cdata;\n+  PyObject* parsed_args[3];\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+  if (r.idx == 0) {\n+    return wrap(dispatch_size(self_, r.toInt64(0)));\n+  } else if (r.idx == 1) {\n+    // we can't do the normal wrapping here because IntList maps to both\n+    // torch.Size and tuple in python\n+    IntList sizes = dispatch_size(self_);\n+    return THPSize_New(sizes.size(), (int64_t *)sizes.data());\n+  }\n+  Py_RETURN_NONE;\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static IntList dispatch_stride(const Tensor& self) {\n+  // avoid releasing GIL/changing device, should be quick\n+  // yes, this is called strides in ATen.\n+  return self.strides();\n+}\n+\n+static int64_t dispatch_stride(const Tensor& self, int64_t dim) {\n+  // avoid releasing GIL/changing device, should be quick\n+  return self.stride(dim);\n+}\n+\n+static PyObject * THPVariable_stride(PyObject* self, PyObject* args, PyObject* kwargs)\n+{\n+  HANDLE_TH_ERRORS\n+  static PythonArgParser parser({\n+    \"stride(int64_t dim)\",\n+    \"stride()\",\n+  });\n+  auto& self_ = reinterpret_cast<THPVariable*>(self)->cdata;\n+  PyObject* parsed_args[3];\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+  if (r.idx == 0) {\n+    return wrap(dispatch_stride(self_, r.toInt64(0)));\n+  } else if (r.idx == 1) {\n+    // we can't do the normal wrapping here because IntList maps to both\n+    // torch.Size and tuple in python\n+    IntList strides = dispatch_stride(self_);\n+    THPObjectPtr py_stride(PyTuple_New(strides.size()));\n+    for (size_t i = 0; i != strides.size(); ++i) {\n+      PyTuple_SET_ITEM(py_stride.get(), i, PyLong_FromLong(strides[i]));", "path": "tools/autograd/templates/python_variable_methods.cpp", "position": null, "original_position": 77, "commit_id": "4a28a59ab3b089e11ba3ca12de9ed5a2ca8a992b", "original_commit_id": "dd5f7325eecbbb8f0bc3eef7993387b1bfd3cfea", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Can you move this logic to it's own function? We do this in a bunch of places and we keep getting it wrong:\r\n\r\n1. PyLong_FromLong returns null on error. We should check that.\r\n2. We should prefer `THPUtils_packInt64` since `int` types are nicer on Python 2 when the values fit in an int.\r\n\r\nYou can make `THPSize_New` use this function too.", "created_at": "2017-11-16T21:10:52Z", "updated_at": "2018-11-23T15:36:36Z", "html_url": "https://github.com/pytorch/pytorch/pull/3744#discussion_r151537740", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3744", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/151537740"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3744#discussion_r151537740"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3744"}}, "body_html": "<p>Can you move this logic to it's own function? We do this in a bunch of places and we keep getting it wrong:</p>\n<ol>\n<li>PyLong_FromLong returns null on error. We should check that.</li>\n<li>We should prefer <code>THPUtils_packInt64</code> since <code>int</code> types are nicer on Python 2 when the values fit in an int.</li>\n</ol>\n<p>You can make <code>THPSize_New</code> use this function too.</p>", "body_text": "Can you move this logic to it's own function? We do this in a bunch of places and we keep getting it wrong:\n\nPyLong_FromLong returns null on error. We should check that.\nWe should prefer THPUtils_packInt64 since int types are nicer on Python 2 when the values fit in an int.\n\nYou can make THPSize_New use this function too."}