{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10252", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10252/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10252/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10252/events", "html_url": "https://github.com/pytorch/pytorch/issues/10252", "id": 347780621, "node_id": "MDU6SXNzdWUzNDc3ODA2MjE=", "number": 10252, "title": "[feature request] Support ATen:expand() operator for ONNX export", "user": {"login": "tensorbuffer", "id": 42130693, "node_id": "MDQ6VXNlcjQyMTMwNjkz", "avatar_url": "https://avatars3.githubusercontent.com/u/42130693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorbuffer", "html_url": "https://github.com/tensorbuffer", "followers_url": "https://api.github.com/users/tensorbuffer/followers", "following_url": "https://api.github.com/users/tensorbuffer/following{/other_user}", "gists_url": "https://api.github.com/users/tensorbuffer/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorbuffer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorbuffer/subscriptions", "organizations_url": "https://api.github.com/users/tensorbuffer/orgs", "repos_url": "https://api.github.com/users/tensorbuffer/repos", "events_url": "https://api.github.com/users/tensorbuffer/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorbuffer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-08-06T05:11:43Z", "updated_at": "2018-08-06T17:20:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>If you have a question or would like help and support, please ask at our<br>\n<a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">forums</a>.</p>\n<p>If you are submitting a feature request, please preface the title with [feature request].<br>\nIf you are submitting a bug report, please fill in the following details.</p>\n<h2>Issue description</h2>\n<p>Exporting pytorch to onnx model that contains aten::expand() operator fails</p>\n<p>Provide a short description.<br>\nPls refer to below code example to repro the issue.</p>\n<ul>\n<li>With pytorch 0.4.0 (git checkout v0.4.0):<br>\ngraph(%0 : Float(1, 128, 20, 30)) {<br>\n%1 : Float(1, 1, 20, 30) = onnx::ReduceMean<a href=\"%0\">axes=[1], keepdims=1</a>, scope: Model<br>\n%2 : Float(1, 128, 1, 1) = onnx::AveragePool<a href=\"%0\">kernel_shape=[20, 30], pads=[0, 0, 0, 0], strides=[20, 30]</a>, scope: Model<br>\n%3 : Float(1!, 128!, 20, 30) = aten::expand<a href=\"%1\">size=[1, 128, 20, 30]</a>, scope: Model<br>\n%4 : Float(1, 128, 20, 30) = onnx::Mul[broadcast=1, axis=0](%3, %2), scope: Model<br>\nreturn (%4);<br>\n}</li>\n</ul>\n<p>Traceback (most recent call last):<br>\nFile \"onnx_export_sample_model.py\", line 24, in <br>\ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)<br>\nFile \"/root/programs/pytorch/torch/onnx/<strong>init</strong>.py\", line 25, in export<br>\nreturn utils.export(*args, **kwargs)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 84, in export<br>\n_export(model, args, f, export_params, verbose, training, input_names, output_names)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 154, in _export<br>\n_onnx_opset_version, defer_weight_export)<br>\nRuntimeError: ONNX export failed: Couldn't export operator aten::expand</p>\n<ul>\n<li>With top of tree pytorch (8/5/2018):<br>\nTraceback (most recent call last):<br>\nFile \"onnx_export_sample_model.py\", line 24, in <br>\ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)<br>\nFile \"/root/programs/pytorch/torch/onnx/<strong>init</strong>.py\", line 26, in export<br>\nreturn utils.export(*args, **kwargs)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 94, in export<br>\noperator_export_type=operator_export_type)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 247, in _export<br>\nexample_outputs, propagate)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 201, in _model_to_graph<br>\ngraph = _optimize_graph(graph, operator_export_type)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 129, in _optimize_graph<br>\ngraph = torch._C._jit_pass_onnx(graph, operator_export_type)<br>\nFile \"/root/programs/pytorch/torch/onnx/<strong>init</strong>.py\", line 51, in _run_symbolic_function<br>\nreturn utils._run_symbolic_function(*args, **kwargs)<br>\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 470, in _run_symbolic_function<br>\nreturn fn(g, *inputs, **attrs)<br>\nFile \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 83, in wrapper<br>\nargs = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]<br>\nFile \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 40, in _parse_arg<br>\nraise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")<br>\nRuntimeError: ONNX symbolic expected a constant value in the trace</li>\n</ul>\n<h2>Code example</h2>\n<p>import torch<br>\nimport torch.onnx<br>\nimport torch.nn as nn<br>\nimport torch.nn.functional as F<br>\nfrom torch.autograd import Variable</p>\n<p>class Model(nn.Module):<br>\ndef <strong>init</strong>(self):<br>\nsuper(Model, self).<strong>init</strong>()</p>\n<pre><code>def forward(self, x):\n    x_mean = x.mean(1, keepdim = True)\n    x_pool = F.avg_pool2d(x, x.size()[2:])\n    x = x_mean * x_pool\n    return x\n</code></pre>\n<p>model = Model()<br>\nmodel.cpu()<br>\nmodel.train(False)</p>\n<p>input_shape = (128, 20, 30)<br>\ndummy_input = Variable(torch.randn(1, *input_shape))<br>\ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)</p>\n<p>Please try to provide a minimal example to repro the bug.<br>\nError messages and stack traces are also helpful.</p>\n<h2>System Info</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<ul>\n<li>\n<p>PyTorch or Caffe2: PyTorch</p>\n</li>\n<li>\n<p>How you installed PyTorch (conda, pip, source): source</p>\n</li>\n<li>\n<p>Build command you used (if compiling from source):<br>\ndocker file commands:<br>\nRUN cd /root/programs/pytorch; pip install -r \"caffe2/requirements.txt\"; <br>\nCMAKE_ARGS=\"-DCAFFE2_LINK_LOCAL_PROTOBUF=OFF -DBUILD_CUSTOM_PROTOBUF=OFF -DUSE_CUDA=OFF\" python setup_caffe2.py develop<br>\nRUN cd /root/programs/pytorch; pip install -r \"requirements.txt\"; <br>\nNO_CUDA=1 python setup.py build develop</p>\n</li>\n<li>\n<p>OS: ubuntu16.04</p>\n</li>\n<li>\n<p>PyTorch version: tried both: '0.4.0a0+3749c58', '0.5.0a0+f57e4ce'</p>\n</li>\n<li>\n<p>Python version: 2.7</p>\n</li>\n<li>\n<p>CUDA/cuDNN version: NA</p>\n</li>\n<li>\n<p>GPU models and configuration:</p>\n</li>\n<li>\n<p>GCC version (if compiling from source):</p>\n</li>\n<li>\n<p>CMake version:</p>\n</li>\n<li>\n<p>Versions of any other relevant libraries:</p>\n</li>\n</ul>", "body_text": "If you have a question or would like help and support, please ask at our\nforums.\nIf you are submitting a feature request, please preface the title with [feature request].\nIf you are submitting a bug report, please fill in the following details.\nIssue description\nExporting pytorch to onnx model that contains aten::expand() operator fails\nProvide a short description.\nPls refer to below code example to repro the issue.\n\nWith pytorch 0.4.0 (git checkout v0.4.0):\ngraph(%0 : Float(1, 128, 20, 30)) {\n%1 : Float(1, 1, 20, 30) = onnx::ReduceMeanaxes=[1], keepdims=1, scope: Model\n%2 : Float(1, 128, 1, 1) = onnx::AveragePoolkernel_shape=[20, 30], pads=[0, 0, 0, 0], strides=[20, 30], scope: Model\n%3 : Float(1!, 128!, 20, 30) = aten::expandsize=[1, 128, 20, 30], scope: Model\n%4 : Float(1, 128, 20, 30) = onnx::Mul[broadcast=1, axis=0](%3, %2), scope: Model\nreturn (%4);\n}\n\nTraceback (most recent call last):\nFile \"onnx_export_sample_model.py\", line 24, in \ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\nFile \"/root/programs/pytorch/torch/onnx/init.py\", line 25, in export\nreturn utils.export(*args, **kwargs)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 84, in export\n_export(model, args, f, export_params, verbose, training, input_names, output_names)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 154, in _export\n_onnx_opset_version, defer_weight_export)\nRuntimeError: ONNX export failed: Couldn't export operator aten::expand\n\nWith top of tree pytorch (8/5/2018):\nTraceback (most recent call last):\nFile \"onnx_export_sample_model.py\", line 24, in \ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\nFile \"/root/programs/pytorch/torch/onnx/init.py\", line 26, in export\nreturn utils.export(*args, **kwargs)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 94, in export\noperator_export_type=operator_export_type)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 247, in _export\nexample_outputs, propagate)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 201, in _model_to_graph\ngraph = _optimize_graph(graph, operator_export_type)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 129, in _optimize_graph\ngraph = torch._C._jit_pass_onnx(graph, operator_export_type)\nFile \"/root/programs/pytorch/torch/onnx/init.py\", line 51, in _run_symbolic_function\nreturn utils._run_symbolic_function(*args, **kwargs)\nFile \"/root/programs/pytorch/torch/onnx/utils.py\", line 470, in _run_symbolic_function\nreturn fn(g, *inputs, **attrs)\nFile \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 83, in wrapper\nargs = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\nFile \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 40, in _parse_arg\nraise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")\nRuntimeError: ONNX symbolic expected a constant value in the trace\n\nCode example\nimport torch\nimport torch.onnx\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nclass Model(nn.Module):\ndef init(self):\nsuper(Model, self).init()\ndef forward(self, x):\n    x_mean = x.mean(1, keepdim = True)\n    x_pool = F.avg_pool2d(x, x.size()[2:])\n    x = x_mean * x_pool\n    return x\n\nmodel = Model()\nmodel.cpu()\nmodel.train(False)\ninput_shape = (128, 20, 30)\ndummy_input = Variable(torch.randn(1, *input_shape))\ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\nPlease try to provide a minimal example to repro the bug.\nError messages and stack traces are also helpful.\nSystem Info\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\n\n\nPyTorch or Caffe2: PyTorch\n\n\nHow you installed PyTorch (conda, pip, source): source\n\n\nBuild command you used (if compiling from source):\ndocker file commands:\nRUN cd /root/programs/pytorch; pip install -r \"caffe2/requirements.txt\"; \nCMAKE_ARGS=\"-DCAFFE2_LINK_LOCAL_PROTOBUF=OFF -DBUILD_CUSTOM_PROTOBUF=OFF -DUSE_CUDA=OFF\" python setup_caffe2.py develop\nRUN cd /root/programs/pytorch; pip install -r \"requirements.txt\"; \nNO_CUDA=1 python setup.py build develop\n\n\nOS: ubuntu16.04\n\n\nPyTorch version: tried both: '0.4.0a0+3749c58', '0.5.0a0+f57e4ce'\n\n\nPython version: 2.7\n\n\nCUDA/cuDNN version: NA\n\n\nGPU models and configuration:\n\n\nGCC version (if compiling from source):\n\n\nCMake version:\n\n\nVersions of any other relevant libraries:", "body": "If you have a question or would like help and support, please ask at our\r\n[forums](https://discuss.pytorch.org/).\r\n\r\nIf you are submitting a feature request, please preface the title with [feature request].\r\nIf you are submitting a bug report, please fill in the following details.\r\n\r\n## Issue description\r\nExporting pytorch to onnx model that contains aten::expand() operator fails\r\n\r\nProvide a short description.\r\nPls refer to below code example to repro the issue.\r\n- With pytorch 0.4.0 (git checkout v0.4.0):\r\ngraph(%0 : Float(1, 128, 20, 30)) {\r\n  %1 : Float(1, 1, 20, 30) = onnx::ReduceMean[axes=[1], keepdims=1](%0), scope: Model\r\n  %2 : Float(1, 128, 1, 1) = onnx::AveragePool[kernel_shape=[20, 30], pads=[0, 0, 0, 0], strides=[20, 30]](%0), scope: Model\r\n  %3 : Float(1!, 128!, 20, 30) = aten::expand[size=[1, 128, 20, 30]](%1), scope: Model\r\n  %4 : Float(1, 128, 20, 30) = onnx::Mul[broadcast=1, axis=0](%3, %2), scope: Model\r\n  return (%4);\r\n}\r\n\r\nTraceback (most recent call last):\r\n  File \"onnx_export_sample_model.py\", line 24, in <module>\r\n    torch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\r\n  File \"/root/programs/pytorch/torch/onnx/__init__.py\", line 25, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 84, in export\r\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 154, in _export\r\n    _onnx_opset_version, defer_weight_export)\r\nRuntimeError: ONNX export failed: Couldn't export operator aten::expand\r\n\r\n- With top of tree pytorch (8/5/2018):\r\nTraceback (most recent call last):\r\n  File \"onnx_export_sample_model.py\", line 24, in <module>\r\n    torch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\r\n  File \"/root/programs/pytorch/torch/onnx/__init__.py\", line 26, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 94, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 247, in _export\r\n    example_outputs, propagate)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 201, in _model_to_graph\r\n    graph = _optimize_graph(graph, operator_export_type)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 129, in _optimize_graph\r\n    graph = torch._C._jit_pass_onnx(graph, operator_export_type)\r\n  File \"/root/programs/pytorch/torch/onnx/__init__.py\", line 51, in _run_symbolic_function\r\n    return utils._run_symbolic_function(*args, **kwargs)\r\n  File \"/root/programs/pytorch/torch/onnx/utils.py\", line 470, in _run_symbolic_function\r\n    return fn(g, *inputs, **attrs)\r\n  File \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 83, in wrapper\r\n    args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\r\n  File \"/root/programs/pytorch/torch/onnx/symbolic.py\", line 40, in _parse_arg\r\n    raise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")\r\nRuntimeError: ONNX symbolic expected a constant value in the trace\r\n\r\n## Code example\r\nimport torch\r\nimport torch.onnx\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\n\r\nclass Model(nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n\r\n    def forward(self, x):\r\n        x_mean = x.mean(1, keepdim = True)\r\n        x_pool = F.avg_pool2d(x, x.size()[2:])\r\n        x = x_mean * x_pool\r\n        return x\r\n\r\nmodel = Model()\r\nmodel.cpu()\r\nmodel.train(False)\r\n\r\ninput_shape = (128, 20, 30)\r\ndummy_input = Variable(torch.randn(1, *input_shape))\r\ntorch.onnx.export(model, dummy_input, \"sampe_model.onnx\", verbose=True, export_params=True)\r\n\r\nPlease try to provide a minimal example to repro the bug.\r\nError messages and stack traces are also helpful.\r\n\r\n## System Info\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Build command you used (if compiling from source):\r\ndocker file commands:\r\nRUN cd /root/programs/pytorch; pip install -r \"caffe2/requirements.txt\"; \\\r\n    CMAKE_ARGS=\"-DCAFFE2_LINK_LOCAL_PROTOBUF=OFF -DBUILD_CUSTOM_PROTOBUF=OFF -DUSE_CUDA=OFF\" python setup_caffe2.py develop\r\nRUN cd /root/programs/pytorch; pip install -r \"requirements.txt\"; \\\r\n    NO_CUDA=1 python setup.py build develop\r\n\r\n- OS: ubuntu16.04\r\n- PyTorch version: tried both: '0.4.0a0+3749c58', '0.5.0a0+f57e4ce'\r\n- Python version: 2.7\r\n- CUDA/cuDNN version: NA\r\n- GPU models and configuration:\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Versions of any other relevant libraries:\r\n"}