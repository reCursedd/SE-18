{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/356420924", "html_url": "https://github.com/pytorch/pytorch/issues/4509#issuecomment-356420924", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4509", "id": 356420924, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjQyMDkyNA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-09T21:32:36Z", "updated_at": "2018-01-09T21:32:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=991891\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Kaixhin\">@Kaixhin</a> agree on not needing running stats on layer norm/instance norm, however, for both of them you still need trainable scale and shift, right? Don't the dimensions of those depend on the input dimensions?<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=836839\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/netheril96\">@netheril96</a>, right now pytorch in most cases uses cudnn implementation of batch norm, rather than THCUNN. IIRC, cudnn does not have to calculate running statistics (i.e. it will work if one passes null pointers for running_var and running_mean), but pytorch bindings will have to be changed to make use of that. Generalizing dimensions to normalize over is a different story, to a degree it can be worked around by having views on tensor, but it does not cover all possible cases.</p>", "body_text": "@Kaixhin agree on not needing running stats on layer norm/instance norm, however, for both of them you still need trainable scale and shift, right? Don't the dimensions of those depend on the input dimensions?\n@netheril96, right now pytorch in most cases uses cudnn implementation of batch norm, rather than THCUNN. IIRC, cudnn does not have to calculate running statistics (i.e. it will work if one passes null pointers for running_var and running_mean), but pytorch bindings will have to be changed to make use of that. Generalizing dimensions to normalize over is a different story, to a degree it can be worked around by having views on tensor, but it does not cover all possible cases.", "body": "@Kaixhin agree on not needing running stats on layer norm/instance norm, however, for both of them you still need trainable scale and shift, right? Don't the dimensions of those depend on the input dimensions?\r\n@netheril96, right now pytorch in most cases uses cudnn implementation of batch norm, rather than THCUNN. IIRC, cudnn does not have to calculate running statistics (i.e. it will work if one passes null pointers for running_var and running_mean), but pytorch bindings will have to be changed to make use of that. Generalizing dimensions to normalize over is a different story, to a degree it can be worked around by having views on tensor, but it does not cover all possible cases. "}