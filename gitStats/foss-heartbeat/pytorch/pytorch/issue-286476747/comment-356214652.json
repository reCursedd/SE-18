{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/356214652", "html_url": "https://github.com/pytorch/pytorch/issues/4509#issuecomment-356214652", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4509", "id": 356214652, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjIxNDY1Mg==", "user": {"login": "netheril96", "id": 836839, "node_id": "MDQ6VXNlcjgzNjgzOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/836839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/netheril96", "html_url": "https://github.com/netheril96", "followers_url": "https://api.github.com/users/netheril96/followers", "following_url": "https://api.github.com/users/netheril96/following{/other_user}", "gists_url": "https://api.github.com/users/netheril96/gists{/gist_id}", "starred_url": "https://api.github.com/users/netheril96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/netheril96/subscriptions", "organizations_url": "https://api.github.com/users/netheril96/orgs", "repos_url": "https://api.github.com/users/netheril96/repos", "events_url": "https://api.github.com/users/netheril96/events{/privacy}", "received_events_url": "https://api.github.com/users/netheril96/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-09T08:32:11Z", "updated_at": "2018-01-09T08:32:11Z", "author_association": "NONE", "body_html": "<p>I am not familiar with the C sources of PyTorch, so I have a naive question: could the fused kernel of batch norm be more generalized? Not just by making running mean and variance optional, but also by generalizing the dimensions to normalize over. Instance norm and layer norm can then be treated as first class citizens, just like batch norm.</p>", "body_text": "I am not familiar with the C sources of PyTorch, so I have a naive question: could the fused kernel of batch norm be more generalized? Not just by making running mean and variance optional, but also by generalizing the dimensions to normalize over. Instance norm and layer norm can then be treated as first class citizens, just like batch norm.", "body": "I am not familiar with the C sources of PyTorch, so I have a naive question: could the fused kernel of batch norm be more generalized? Not just by making running mean and variance optional, but also by generalizing the dimensions to normalize over. Instance norm and layer norm can then be treated as first class citizens, just like batch norm."}