{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5374", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5374/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5374/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5374/events", "html_url": "https://github.com/pytorch/pytorch/issues/5374", "id": 299773279, "node_id": "MDU6SXNzdWUyOTk3NzMyNzk=", "number": 5374, "title": "Batchnorm1d with affine=False slower than affine=True", "user": {"login": "samuelbroscheit", "id": 22645035, "node_id": "MDQ6VXNlcjIyNjQ1MDM1", "avatar_url": "https://avatars3.githubusercontent.com/u/22645035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelbroscheit", "html_url": "https://github.com/samuelbroscheit", "followers_url": "https://api.github.com/users/samuelbroscheit/followers", "following_url": "https://api.github.com/users/samuelbroscheit/following{/other_user}", "gists_url": "https://api.github.com/users/samuelbroscheit/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelbroscheit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelbroscheit/subscriptions", "organizations_url": "https://api.github.com/users/samuelbroscheit/orgs", "repos_url": "https://api.github.com/users/samuelbroscheit/repos", "events_url": "https://api.github.com/users/samuelbroscheit/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelbroscheit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-23T16:39:06Z", "updated_at": "2018-10-02T16:31:37Z", "closed_at": "2018-02-23T18:33:45Z", "author_association": "NONE", "body_html": "<ul>\n<li>OS: Linux 3.16.0-4-amd64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux</li>\n<li>PyTorch version: 3.0</li>\n<li>How you installed PyTorch (conda, pip, source): pip</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version: '8.0.61'</li>\n<li>GPU models and configuration: GeForce GTX 1080Ti</li>\n<li>GCC version (if compiling from source): -</li>\n</ul>\n<pre><code>import torch\n\nhid_size = 4096\nbatch_size = 100\nepochs = 1000\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(hid_size,hid_size),\n    torch.nn.BatchNorm1d(affine=False, num_features=hid_size),\n    torch.nn.Linear(hid_size,2),\n)\nnet.cuda()\n\nx = torch.autograd.Variable(torch.randn(batch_size,hid_size))\ny = torch.autograd.Variable(torch.LongTensor([1, 0] * 5))\n\nx = x.cuda()\ny = y.cuda()\n\nloss = torch.nn.CrossEntropyLoss()\noptim = torch.optim.SGD(net.parameters(), lr=0.1)\n\ndef train():\n    for i in range(epochs):\n        optim.zero_grad()\n        p = net(x)\n        loss(p, y).backward()\n        optim.step()\n</code></pre>\n<p>%timeit train()</p>\n<p>GPU affine=False 1.98 s \u00b1 860 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)<br>\nGPU affine=True 1.93 s \u00b1 1.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)</p>\n<p>I was expecting a speedup, but in my model \"affine=False\" even led to a 15% decrease in throughput. Is this expected?</p>", "body_text": "OS: Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux\nPyTorch version: 3.0\nHow you installed PyTorch (conda, pip, source): pip\nPython version: 3.6\nCUDA/cuDNN version: '8.0.61'\nGPU models and configuration: GeForce GTX 1080Ti\nGCC version (if compiling from source): -\n\nimport torch\n\nhid_size = 4096\nbatch_size = 100\nepochs = 1000\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(hid_size,hid_size),\n    torch.nn.BatchNorm1d(affine=False, num_features=hid_size),\n    torch.nn.Linear(hid_size,2),\n)\nnet.cuda()\n\nx = torch.autograd.Variable(torch.randn(batch_size,hid_size))\ny = torch.autograd.Variable(torch.LongTensor([1, 0] * 5))\n\nx = x.cuda()\ny = y.cuda()\n\nloss = torch.nn.CrossEntropyLoss()\noptim = torch.optim.SGD(net.parameters(), lr=0.1)\n\ndef train():\n    for i in range(epochs):\n        optim.zero_grad()\n        p = net(x)\n        loss(p, y).backward()\n        optim.step()\n\n%timeit train()\nGPU affine=False 1.98 s \u00b1 860 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nGPU affine=True 1.93 s \u00b1 1.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\nI was expecting a speedup, but in my model \"affine=False\" even led to a 15% decrease in throughput. Is this expected?", "body": "- OS: Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux\r\n- PyTorch version: 3.0\r\n- How you installed PyTorch (conda, pip, source): pip \r\n- Python version: 3.6\r\n- CUDA/cuDNN version: '8.0.61'\r\n- GPU models and configuration: GeForce GTX 1080Ti\r\n- GCC version (if compiling from source): -\r\n\r\n```\r\nimport torch\r\n\r\nhid_size = 4096\r\nbatch_size = 100\r\nepochs = 1000\r\n\r\nnet = torch.nn.Sequential(\r\n    torch.nn.Linear(hid_size,hid_size),\r\n    torch.nn.BatchNorm1d(affine=False, num_features=hid_size),\r\n    torch.nn.Linear(hid_size,2),\r\n)\r\nnet.cuda()\r\n\r\nx = torch.autograd.Variable(torch.randn(batch_size,hid_size))\r\ny = torch.autograd.Variable(torch.LongTensor([1, 0] * 5))\r\n\r\nx = x.cuda()\r\ny = y.cuda()\r\n\r\nloss = torch.nn.CrossEntropyLoss()\r\noptim = torch.optim.SGD(net.parameters(), lr=0.1)\r\n\r\ndef train():\r\n    for i in range(epochs):\r\n        optim.zero_grad()\r\n        p = net(x)\r\n        loss(p, y).backward()\r\n        optim.step()\r\n```\r\n%timeit train()\r\n\r\nGPU affine=False 1.98 s \u00b1 860 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\nGPU affine=True 1.93 s \u00b1 1.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n\r\nI was expecting a speedup, but in my model \"affine=False\" even led to a 15% decrease in throughput. Is this expected? \r\n\r\n"}