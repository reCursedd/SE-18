{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12659", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12659/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12659/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12659/events", "html_url": "https://github.com/pytorch/pytorch/issues/12659", "id": 370241669, "node_id": "MDU6SXNzdWUzNzAyNDE2Njk=", "number": 12659, "title": "Differentiation through Module parameters updates", "user": {"login": "alexis-jacq", "id": 9195965, "node_id": "MDQ6VXNlcjkxOTU5NjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9195965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexis-jacq", "html_url": "https://github.com/alexis-jacq", "followers_url": "https://api.github.com/users/alexis-jacq/followers", "following_url": "https://api.github.com/users/alexis-jacq/following{/other_user}", "gists_url": "https://api.github.com/users/alexis-jacq/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexis-jacq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexis-jacq/subscriptions", "organizations_url": "https://api.github.com/users/alexis-jacq/orgs", "repos_url": "https://api.github.com/users/alexis-jacq/repos", "events_url": "https://api.github.com/users/alexis-jacq/events{/privacy}", "received_events_url": "https://api.github.com/users/alexis-jacq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-15T16:23:37Z", "updated_at": "2018-10-23T09:44:47Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"rocket\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f680.png\">\ud83d\ude80</g-emoji> Feature</h2>\n\n<p>So far, it is possible to get a second order gradient by extracting the first-order gradient as a differentiable tensor:<br>\nobjective = loss(module, target)<br>\ngradients = torch.autograd.grad(objective, module.parameters, create_graph=True)</p>\n<p>However, as far as I understand, it is not possible to differentiate through module updates (using optimizers). For example, let say that Z is an independent parameter I want to optimize, and I have a module M with parameter P (P is not Z). I update P as follow:<br>\ncost1 = loss( f(P,Z), target1)<br>\ncost1.backward()<br>\nM_optimizer.step() # P(Z) = P + g1(Z)<br>\ncost2 = loss( f(P,Z), target2)<br>\ncost2.backward()<br>\nM_optimizer.step() # P(Z) = P + g1(Z) + g2(Z)</p>\n<p>And now, I want to update Z in order to maximize a meta-objective meta_loss( P(Z), meta-target ).</p>\n<h2>Motivation</h2>\n\n<p>This king of meta-update is common in meta-learning approaches, such as MAML (<a href=\"https://arxiv.org/abs/1703.03400\" rel=\"nofollow\">https://arxiv.org/abs/1703.03400</a>). As mentioned in this post (<a href=\"https://discuss.pytorch.org/t/pytorch-implementation-of-maml-that-works-with-module-style-networks/26278\" rel=\"nofollow\">https://discuss.pytorch.org/t/pytorch-implementation-of-maml-that-works-with-module-style-networks/26278</a>) MAML implementations are limited to functional-based structure and gradient descent are done by hand. For more complex models (CNN + LSTM) a user would have to re-implement everything by hands.</p>\n<h2>Pitch</h2>\n\n<p>An optimizer that would change a module's parameters with a differentiable operation, e.g. that would first extract the gradient as a differentiable tensor, and sum the parameter with this differentiable gradient.</p>\n<h2>Alternatives</h2>\n\n<p>At least (if the solution above is not possible), the possibility to sum a module's parameter with a differentiable tensor (and then the gradient descent can be easily implemented by hands).</p>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\ude80 Feature\n\nSo far, it is possible to get a second order gradient by extracting the first-order gradient as a differentiable tensor:\nobjective = loss(module, target)\ngradients = torch.autograd.grad(objective, module.parameters, create_graph=True)\nHowever, as far as I understand, it is not possible to differentiate through module updates (using optimizers). For example, let say that Z is an independent parameter I want to optimize, and I have a module M with parameter P (P is not Z). I update P as follow:\ncost1 = loss( f(P,Z), target1)\ncost1.backward()\nM_optimizer.step() # P(Z) = P + g1(Z)\ncost2 = loss( f(P,Z), target2)\ncost2.backward()\nM_optimizer.step() # P(Z) = P + g1(Z) + g2(Z)\nAnd now, I want to update Z in order to maximize a meta-objective meta_loss( P(Z), meta-target ).\nMotivation\n\nThis king of meta-update is common in meta-learning approaches, such as MAML (https://arxiv.org/abs/1703.03400). As mentioned in this post (https://discuss.pytorch.org/t/pytorch-implementation-of-maml-that-works-with-module-style-networks/26278) MAML implementations are limited to functional-based structure and gradient descent are done by hand. For more complex models (CNN + LSTM) a user would have to re-implement everything by hands.\nPitch\n\nAn optimizer that would change a module's parameters with a differentiable operation, e.g. that would first extract the gradient as a differentiable tensor, and sum the parameter with this differentiable gradient.\nAlternatives\n\nAt least (if the solution above is not possible), the possibility to sum a module's parameter with a differentiable tensor (and then the gradient descent can be easily implemented by hands).\nAdditional context", "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nSo far, it is possible to get a second order gradient by extracting the first-order gradient as a differentiable tensor:\r\nobjective = loss(module, target)\r\ngradients = torch.autograd.grad(objective, module.parameters, create_graph=True)\r\n\r\nHowever, as far as I understand, it is not possible to differentiate through module updates (using optimizers). For example, let say that Z is an independent parameter I want to optimize, and I have a module M with parameter P (P is not Z). I update P as follow:\r\ncost1 = loss( f(P,Z), target1)\r\ncost1.backward()\r\nM_optimizer.step() # P(Z) = P + g1(Z)\r\ncost2 = loss( f(P,Z), target2)\r\ncost2.backward()\r\nM_optimizer.step() # P(Z) = P + g1(Z) + g2(Z)\r\n\r\nAnd now, I want to update Z in order to maximize a meta-objective meta_loss( P(Z), meta-target ). \r\n\r\n## Motivation\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\nThis king of meta-update is common in meta-learning approaches, such as MAML (https://arxiv.org/abs/1703.03400). As mentioned in this post (https://discuss.pytorch.org/t/pytorch-implementation-of-maml-that-works-with-module-style-networks/26278) MAML implementations are limited to functional-based structure and gradient descent are done by hand. For more complex models (CNN + LSTM) a user would have to re-implement everything by hands.\r\n\r\n## Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\nAn optimizer that would change a module's parameters with a differentiable operation, e.g. that would first extract the gradient as a differentiable tensor, and sum the parameter with this differentiable gradient.\r\n\r\n## Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\nAt least (if the solution above is not possible), the possibility to sum a module's parameter with a differentiable tensor (and then the gradient descent can be easily implemented by hands).\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n"}