{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/320126807", "html_url": "https://github.com/pytorch/pytorch/issues/496#issuecomment-320126807", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/496", "id": 320126807, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDEyNjgwNw==", "user": {"login": "ruotianluo", "id": 16023153, "node_id": "MDQ6VXNlcjE2MDIzMTUz", "avatar_url": "https://avatars2.githubusercontent.com/u/16023153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruotianluo", "html_url": "https://github.com/ruotianluo", "followers_url": "https://api.github.com/users/ruotianluo/followers", "following_url": "https://api.github.com/users/ruotianluo/following{/other_user}", "gists_url": "https://api.github.com/users/ruotianluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruotianluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruotianluo/subscriptions", "organizations_url": "https://api.github.com/users/ruotianluo/orgs", "repos_url": "https://api.github.com/users/ruotianluo/repos", "events_url": "https://api.github.com/users/ruotianluo/events{/privacy}", "received_events_url": "https://api.github.com/users/ruotianluo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-04T00:46:03Z", "updated_at": "2017-08-04T00:46:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I guess it's related to discussion above:<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L27\">https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L27</a><br>\nand<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L45\">https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L45</a><br>\nare doing contiguous on the same tensor twice. Wouldn't it be a waste of memory?</p>", "body_text": "I guess it's related to discussion above:\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L27\nand\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L45\nare doing contiguous on the same tensor twice. Wouldn't it be a waste of memory?", "body": "I guess it's related to discussion above:\r\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L27\r\nand\r\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/vision.py#L45\r\nare doing contiguous on the same tensor twice. Wouldn't it be a waste of memory?"}