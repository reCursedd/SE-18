{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/304539186", "html_url": "https://github.com/pytorch/pytorch/issues/496#issuecomment-304539186", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/496", "id": 304539186, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNDUzOTE4Ng==", "user": {"login": "jcjohnson", "id": 2718714, "node_id": "MDQ6VXNlcjI3MTg3MTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2718714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcjohnson", "html_url": "https://github.com/jcjohnson", "followers_url": "https://api.github.com/users/jcjohnson/followers", "following_url": "https://api.github.com/users/jcjohnson/following{/other_user}", "gists_url": "https://api.github.com/users/jcjohnson/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcjohnson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcjohnson/subscriptions", "organizations_url": "https://api.github.com/users/jcjohnson/orgs", "repos_url": "https://api.github.com/users/jcjohnson/repos", "events_url": "https://api.github.com/users/jcjohnson/events{/privacy}", "received_events_url": "https://api.github.com/users/jcjohnson/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-28T20:46:42Z", "updated_at": "2017-05-28T20:46:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'd also like to see this in main PyTorch. Bilinear sampling in particular is used in recent methods for object detection such as <a href=\"https://arxiv.org/abs/1703.06870\" rel=\"nofollow\">Mask R-CNN</a>, <a href=\"https://arxiv.org/abs/1512.04412\" rel=\"nofollow\">Instance-Aware Semantic Segmentation</a>, and <a href=\"https://arxiv.org/abs/1511.07571\" rel=\"nofollow\">DenseCap</a>.</p>\n<p>Also it seems that cuDNN has implemented forward / backward for bilinear sampling; it would be nice if that could be accessible for PyTorch.</p>\n<p>I wrote an implementation of bilinear sampling using autograd: <a href=\"https://gist.github.com/jcjohnson/876ca05163ad23ab06c2f98cf3bcd6bb\">https://gist.github.com/jcjohnson/876ca05163ad23ab06c2f98cf3bcd6bb</a> but it uses way too much memory to be much use with large numbers of channels (e.g. 1024 channels for Mask R-CNN with ResNet-50) or large minibatches.</p>", "body_text": "I'd also like to see this in main PyTorch. Bilinear sampling in particular is used in recent methods for object detection such as Mask R-CNN, Instance-Aware Semantic Segmentation, and DenseCap.\nAlso it seems that cuDNN has implemented forward / backward for bilinear sampling; it would be nice if that could be accessible for PyTorch.\nI wrote an implementation of bilinear sampling using autograd: https://gist.github.com/jcjohnson/876ca05163ad23ab06c2f98cf3bcd6bb but it uses way too much memory to be much use with large numbers of channels (e.g. 1024 channels for Mask R-CNN with ResNet-50) or large minibatches.", "body": "I'd also like to see this in main PyTorch. Bilinear sampling in particular is used in recent methods for object detection such as [Mask R-CNN](https://arxiv.org/abs/1703.06870), [Instance-Aware Semantic Segmentation](https://arxiv.org/abs/1512.04412), and [DenseCap](https://arxiv.org/abs/1511.07571).\r\n\r\nAlso it seems that cuDNN has implemented forward / backward for bilinear sampling; it would be nice if that could be accessible for PyTorch.\r\n\r\nI wrote an implementation of bilinear sampling using autograd: https://gist.github.com/jcjohnson/876ca05163ad23ab06c2f98cf3bcd6bb but it uses way too much memory to be much use with large numbers of channels (e.g. 1024 channels for Mask R-CNN with ResNet-50) or large minibatches."}