{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3740", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3740/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3740/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3740/events", "html_url": "https://github.com/pytorch/pytorch/pull/3740", "id": 274627565, "node_id": "MDExOlB1bGxSZXF1ZXN0MTUzMTIzNDky", "number": 3740, "title": "Fixing Weight Decay Regularization in Adam ", "user": {"login": "jingweiz", "id": 9096283, "node_id": "MDQ6VXNlcjkwOTYyODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/9096283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jingweiz", "html_url": "https://github.com/jingweiz", "followers_url": "https://api.github.com/users/jingweiz/followers", "following_url": "https://api.github.com/users/jingweiz/following{/other_user}", "gists_url": "https://api.github.com/users/jingweiz/gists{/gist_id}", "starred_url": "https://api.github.com/users/jingweiz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jingweiz/subscriptions", "organizations_url": "https://api.github.com/users/jingweiz/orgs", "repos_url": "https://api.github.com/users/jingweiz/repos", "events_url": "https://api.github.com/users/jingweiz/events{/privacy}", "received_events_url": "https://api.github.com/users/jingweiz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 545367190, "node_id": "MDU6TGFiZWw1NDUzNjcxOTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-11-16T19:02:03Z", "updated_at": "2018-11-23T15:48:30Z", "closed_at": null, "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3740", "html_url": "https://github.com/pytorch/pytorch/pull/3740", "diff_url": "https://github.com/pytorch/pytorch/pull/3740.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3740.patch"}, "body_html": "<p>Hey,<br>\nWe added <code>SGDW</code> and <code>AdamW</code> in <code>optim</code>, accoridng to the new ICLR submission from Loshchilov and Hutter: <a href=\"https://arxiv.org/abs/1711.05101\" rel=\"nofollow\">Fixing Weight Decay Regularization in Adam</a>.<br>\nWe also found some inconsistency of the current implementation of <code>Adam</code> with the original Adam paper and we asked about it here: <a href=\"https://discuss.pytorch.org/t/adam-implementation/10031\" rel=\"nofollow\">https://discuss.pytorch.org/t/adam-implementation/10031</a>. We tried to make it consistent in the commit: <code>f195087a3666f85a417ee7561bec439bb68f81c3</code>, but then it failed during testing which might due to some inconsistency with the <code>legacy.optim.adam</code> so we changed it back in the last commit. But it would great if you guys can check it to see if this is actually an inconsistency then we can add it back.<br>\nThanks in advance!</p>", "body_text": "Hey,\nWe added SGDW and AdamW in optim, accoridng to the new ICLR submission from Loshchilov and Hutter: Fixing Weight Decay Regularization in Adam.\nWe also found some inconsistency of the current implementation of Adam with the original Adam paper and we asked about it here: https://discuss.pytorch.org/t/adam-implementation/10031. We tried to make it consistent in the commit: f195087a3666f85a417ee7561bec439bb68f81c3, but then it failed during testing which might due to some inconsistency with the legacy.optim.adam so we changed it back in the last commit. But it would great if you guys can check it to see if this is actually an inconsistency then we can add it back.\nThanks in advance!", "body": "Hey,\r\nWe added `SGDW` and `AdamW` in `optim`, accoridng to the new ICLR submission from Loshchilov and Hutter: [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101).\r\nWe also found some inconsistency of the current implementation of `Adam` with the original Adam paper and we asked about it here: [https://discuss.pytorch.org/t/adam-implementation/10031](https://discuss.pytorch.org/t/adam-implementation/10031). We tried to make it consistent in the commit: `f195087a3666f85a417ee7561bec439bb68f81c3`, but then it failed during testing which might due to some inconsistency with the `legacy.optim.adam` so we changed it back in the last commit. But it would great if you guys can check it to see if this is actually an inconsistency then we can add it back.\r\nThanks in advance!"}