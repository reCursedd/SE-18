{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/209281128", "pull_request_review_id": 145268697, "id": 209281128, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwOTI4MTEyOA==", "diff_hunk": "@@ -55,13 +56,29 @@ void Tensor::backward(\n   pImpl->backward(std::move(gradient), keep_graph, create_graph);\n }\n \n-TensorImpl::TensorImpl(Backend backend, ScalarType scalar_type) {\n-  backend_ = backend;\n-  scalar_type_ = scalar_type;\n+TensorImpl::TensorImpl(Backend backend, ScalarType scalar_type, bool is_variable) {\n   auto type = &globalContext().getType(backend, scalar_type);\n   Storage* storage = type->storage(true).release();\n   StorageImpl* storage_impl = storage->pImpl();\n   tensor = new THTensor(storage_impl);\n+  tensor->backend_ = backend;\n+  tensor->scalar_type_ = scalar_type;\n+  tensor->is_variable_ = is_variable;", "path": "aten/src/ATen/TensorImpl.cpp", "position": 26, "original_position": 26, "commit_id": "ede78c4458cc77af76de57acdba7b67e84c88d91", "original_commit_id": "ede78c4458cc77af76de57acdba7b67e84c88d91", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "it's a good question.  One possibility is just to handle these three cases separately:\r\n1) dense (easy)\r\n2) sparse (just store it in SparseTensorImpl)\r\n3) undefined (are these ever variables?  we could just infer this is tensor is null (and assert it in the constructor)).\r\n\r\nThe only real downside over the design as it currently is IMO is that I think type() would have to be virtual (to deal with sparse vs non-sparse).", "created_at": "2018-08-10T14:37:45Z", "updated_at": "2018-11-23T15:49:05Z", "html_url": "https://github.com/pytorch/pytorch/pull/10335#discussion_r209281128", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10335", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/209281128"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10335#discussion_r209281128"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10335"}}, "body_html": "<p>it's a good question.  One possibility is just to handle these three cases separately:</p>\n<ol>\n<li>dense (easy)</li>\n<li>sparse (just store it in SparseTensorImpl)</li>\n<li>undefined (are these ever variables?  we could just infer this is tensor is null (and assert it in the constructor)).</li>\n</ol>\n<p>The only real downside over the design as it currently is IMO is that I think type() would have to be virtual (to deal with sparse vs non-sparse).</p>", "body_text": "it's a good question.  One possibility is just to handle these three cases separately:\n\ndense (easy)\nsparse (just store it in SparseTensorImpl)\nundefined (are these ever variables?  we could just infer this is tensor is null (and assert it in the constructor)).\n\nThe only real downside over the design as it currently is IMO is that I think type() would have to be virtual (to deal with sparse vs non-sparse).", "in_reply_to_id": 209275788}