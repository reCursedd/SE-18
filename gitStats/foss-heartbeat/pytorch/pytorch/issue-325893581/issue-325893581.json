{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7799", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7799/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7799/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7799/events", "html_url": "https://github.com/pytorch/pytorch/pull/7799", "id": 325893581, "node_id": "MDExOlB1bGxSZXF1ZXN0MTkwMTIwNjg5", "number": 7799, "title": "[script] Add support for torch.zeros, torch.ones, etc.", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-23T22:17:07Z", "updated_at": "2018-11-23T15:44:51Z", "closed_at": "2018-06-01T21:24:19Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/7799", "html_url": "https://github.com/pytorch/pytorch/pull/7799", "diff_url": "https://github.com/pytorch/pytorch/pull/7799.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/7799.patch"}, "body_html": "<ul>\n<li>modifies gen_jit_dispatch to creating bindings for functions that do<br>\nnot take tensor arguments, but do have an initial type argument</li>\n<li>adds tensor attributes to these functions for device, layout, and<br>\ndtype specification</li>\n<li>extends the list of valid compiler constants to include device, layout,<br>\nand dtype.</li>\n<li>allows functions with Generators, but only using the default generator</li>\n</ul>\n<p>Known limitations:</p>\n<ul>\n<li>when using <code>torch.float</code>, we convert it to a scalar tensor and make<br>\nno checks that it is actually used only in a dtype specification.<br>\nThis is similar to how we handle Python numbers, creating some situations<br>\nwhere the script is more permissive. Fixing this requires much more<br>\nsignificant changes to the IR, so is lower priority for now.</li>\n<li>devices specified using string literals e.g. 'cuda:1' do not work,<br>\nsince we do not support string literals in general.</li>\n</ul>", "body_text": "modifies gen_jit_dispatch to creating bindings for functions that do\nnot take tensor arguments, but do have an initial type argument\nadds tensor attributes to these functions for device, layout, and\ndtype specification\nextends the list of valid compiler constants to include device, layout,\nand dtype.\nallows functions with Generators, but only using the default generator\n\nKnown limitations:\n\nwhen using torch.float, we convert it to a scalar tensor and make\nno checks that it is actually used only in a dtype specification.\nThis is similar to how we handle Python numbers, creating some situations\nwhere the script is more permissive. Fixing this requires much more\nsignificant changes to the IR, so is lower priority for now.\ndevices specified using string literals e.g. 'cuda:1' do not work,\nsince we do not support string literals in general.", "body": "* modifies gen_jit_dispatch to creating bindings for functions that do\r\n  not take tensor arguments, but do have an initial type argument\r\n* adds tensor attributes to these functions for device, layout, and\r\n  dtype specification\r\n* extends the list of valid compiler constants to include device, layout,\r\n  and dtype.\r\n* allows functions with Generators, but only using the default generator\r\n\r\nKnown limitations:\r\n* when using `torch.float`, we convert it to a scalar tensor and make\r\n  no checks that it is actually used only in a dtype specification.\r\n  This is similar to how we handle Python numbers, creating some situations\r\n  where the script is more permissive. Fixing this requires much more\r\n  significant changes to the IR, so is lower priority for now.\r\n* devices specified using string literals e.g. 'cuda:1' do not work,\r\n  since we do not support string literals in general.\r\n\r\n"}