{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1812", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1812/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1812/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1812/events", "html_url": "https://github.com/pytorch/pytorch/issues/1812", "id": 236187458, "node_id": "MDU6SXNzdWUyMzYxODc0NTg=", "number": 1812, "title": "padding_idx doesn't work.", "user": {"login": "TropComplique", "id": 19353433, "node_id": "MDQ6VXNlcjE5MzUzNDMz", "avatar_url": "https://avatars0.githubusercontent.com/u/19353433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TropComplique", "html_url": "https://github.com/TropComplique", "followers_url": "https://api.github.com/users/TropComplique/followers", "following_url": "https://api.github.com/users/TropComplique/following{/other_user}", "gists_url": "https://api.github.com/users/TropComplique/gists{/gist_id}", "starred_url": "https://api.github.com/users/TropComplique/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TropComplique/subscriptions", "organizations_url": "https://api.github.com/users/TropComplique/orgs", "repos_url": "https://api.github.com/users/TropComplique/repos", "events_url": "https://api.github.com/users/TropComplique/events{/privacy}", "received_events_url": "https://api.github.com/users/TropComplique/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-06-15T13:11:48Z", "updated_at": "2017-06-17T12:39:14Z", "closed_at": "2017-06-17T12:39:14Z", "author_association": "NONE", "body_html": "<p>Hi. There is no zero padding:</p>\n<pre><code>import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\n\ne = nn.Embedding(3, 2, padding_idx=0)\ne.weight = nn.Parameter(torch.rand(3, 2))\nprint(e.weight)\n</code></pre>\n<p><strong>Output:</strong><br>\nParameter containing:<br>\n0.5051  0.5076<br>\n0.9464  0.2811<br>\n0.4968  0.2109<br>\n[torch.FloatTensor of size 3x2]</p>\n<pre><code>indices = Variable(torch.LongTensor([0, 1, 2]))\ne(indices)\n</code></pre>\n<p><strong>Output:</strong><br>\nVariable containing:<br>\n0.5051  0.5076<br>\n0.9464  0.2811<br>\n0.4968  0.2109<br>\n[torch.FloatTensor of size 3x2]</p>\n<p><strong>pytorch version</strong>: 0.1.12</p>", "body_text": "Hi. There is no zero padding:\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\n\ne = nn.Embedding(3, 2, padding_idx=0)\ne.weight = nn.Parameter(torch.rand(3, 2))\nprint(e.weight)\n\nOutput:\nParameter containing:\n0.5051  0.5076\n0.9464  0.2811\n0.4968  0.2109\n[torch.FloatTensor of size 3x2]\nindices = Variable(torch.LongTensor([0, 1, 2]))\ne(indices)\n\nOutput:\nVariable containing:\n0.5051  0.5076\n0.9464  0.2811\n0.4968  0.2109\n[torch.FloatTensor of size 3x2]\npytorch version: 0.1.12", "body": "Hi. There is no zero padding:\r\n```\r\nimport torch\r\nfrom torch.autograd import Variable\r\nimport torch.nn as nn\r\n\r\ne = nn.Embedding(3, 2, padding_idx=0)\r\ne.weight = nn.Parameter(torch.rand(3, 2))\r\nprint(e.weight)\r\n```\r\n**Output:**\r\nParameter containing:\r\n 0.5051  0.5076\r\n 0.9464  0.2811\r\n 0.4968  0.2109\r\n[torch.FloatTensor of size 3x2]\r\n```\r\nindices = Variable(torch.LongTensor([0, 1, 2]))\r\ne(indices)\r\n```\r\n**Output:**\r\nVariable containing:\r\n 0.5051  0.5076\r\n 0.9464  0.2811\r\n 0.4968  0.2109\r\n[torch.FloatTensor of size 3x2]\r\n\r\n**pytorch version**: 0.1.12"}