{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218309448", "pull_request_review_id": 156216155, "id": 218309448, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxODMwOTQ0OA==", "diff_hunk": "@@ -47,7 +47,9 @@ def __init__(self, probs=None, logits=None, validate_args=None):\n         if probs is not None:\n             if probs.dim() < 1:\n                 raise ValueError(\"`probs` parameter must be at least one-dimensional.\")\n-            self.probs = probs / probs.sum(-1, keepdim=True)\n+            sum_probs = probs.detach().cpu().numpy().sum(-1, keepdims=True)", "path": "torch/distributions/categorical.py", "position": 5, "original_position": 5, "commit_id": "af2a1b8fbc273d5095dffcf7ba886bdb46851b6c", "original_commit_id": "af2a1b8fbc273d5095dffcf7ba886bdb46851b6c", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "body": "I did benchmark the operation: sum along the last dim and divide (tensor of size 100 x 1000 x 1000), and it seems to be slower on NumPy actually.\r\nWith PyTorch (cpu):\r\n`33.2 ms \u00b1 1.53 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)`\r\nWith PyTorch (gpu, 1080Ti):\r\n`3.74 ms \u00b1 28.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)`\r\nWith NumPy:\r\n`189 ms \u00b1 8.33 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)`\r\n\r\nAnd the `detach` is breaking autograd tests.", "created_at": "2018-09-18T06:18:06Z", "updated_at": "2018-11-23T15:51:33Z", "html_url": "https://github.com/pytorch/pytorch/pull/11749#discussion_r218309448", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11749", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218309448"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11749#discussion_r218309448"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11749"}}, "body_html": "<p>I did benchmark the operation: sum along the last dim and divide (tensor of size 100 x 1000 x 1000), and it seems to be slower on NumPy actually.<br>\nWith PyTorch (cpu):<br>\n<code>33.2 ms \u00b1 1.53 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)</code><br>\nWith PyTorch (gpu, 1080Ti):<br>\n<code>3.74 ms \u00b1 28.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)</code><br>\nWith NumPy:<br>\n<code>189 ms \u00b1 8.33 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)</code></p>\n<p>And the <code>detach</code> is breaking autograd tests.</p>", "body_text": "I did benchmark the operation: sum along the last dim and divide (tensor of size 100 x 1000 x 1000), and it seems to be slower on NumPy actually.\nWith PyTorch (cpu):\n33.2 ms \u00b1 1.53 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\nWith PyTorch (gpu, 1080Ti):\n3.74 ms \u00b1 28.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\nWith NumPy:\n189 ms \u00b1 8.33 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\nAnd the detach is breaking autograd tests.", "in_reply_to_id": 218055627}