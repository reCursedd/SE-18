{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176449270", "pull_request_review_id": 106153006, "id": 176449270, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NjQ0OTI3MA==", "diff_hunk": "@@ -542,6 +542,36 @@ def test_multidim(x, dim):\n     def test_dim_reduction(self):\n         self._test_dim_reduction(self, lambda t: t)\n \n+    @unittest.skipIf(not TEST_NUMPY, \"Numpy not found\")\n+    def test_cpu_parallel(self):\n+        # To use parallel branches we'll need to compare on tensors\n+        # that are relatively large. Even if this is run on a single\n+        # core machine these tests will still give you signal on\n+        # the correctness\n+\n+        def _run_test(size):\n+            for dim in range(len(size) + 1):\n+                nv = np.round(np.random.rand(*size))  # 0s and 1s\n+                tv = torch.from_numpy(nv)\n+                # Parallelisim is only used if numel is\n+                # larger than grainsize defined in Parallel.h\n+                self.assertTrue(tv.numel() > 32768)\n+                if dim == len(size):\n+                    nvs = nv.sum()\n+                    tvs = tv.sum()\n+                else:\n+                    nvs = nv.sum(dim)\n+                    tvs = tv.sum(dim)\n+                diff = np.abs(nvs - tvs.numpy()).sum()\n+                self.assertEqual(diff, 0)\n+\n+        sizes = []\n+        sizes += [[2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 3]]\n+        sizes += [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]\n+        sizes += [[1, 32 * 8 * 32 * 8]]\n+        sizes += [[1, 32770]]\n+        map(_run_test, sizes)", "path": "test/test_torch.py", "position": 32, "original_position": 32, "commit_id": "bd676a9dd8cd0ca66f79e65fd21e0e670ecd656d", "original_commit_id": "bd676a9dd8cd0ca66f79e65fd21e0e670ecd656d", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "body": "PR is [here](https://github.com/pytorch/pytorch/pull/5940)", "created_at": "2018-03-22T14:52:08Z", "updated_at": "2018-11-23T15:41:01Z", "html_url": "https://github.com/pytorch/pytorch/pull/5926#discussion_r176449270", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5926", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176449270"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5926#discussion_r176449270"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5926"}}, "body_html": "<p>PR is <a href=\"https://github.com/pytorch/pytorch/pull/5940\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/5940/hovercard\">here</a></p>", "body_text": "PR is here", "in_reply_to_id": 176354339}