{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8154", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8154/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8154/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8154/events", "html_url": "https://github.com/pytorch/pytorch/issues/8154", "id": 329325263, "node_id": "MDU6SXNzdWUzMjkzMjUyNjM=", "number": 8154, "title": "Performance drop on small models trained on CPU between 0.3.1 and 0.4", "user": {"login": "jhmenke", "id": 25080218, "node_id": "MDQ6VXNlcjI1MDgwMjE4", "avatar_url": "https://avatars0.githubusercontent.com/u/25080218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhmenke", "html_url": "https://github.com/jhmenke", "followers_url": "https://api.github.com/users/jhmenke/followers", "following_url": "https://api.github.com/users/jhmenke/following{/other_user}", "gists_url": "https://api.github.com/users/jhmenke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhmenke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhmenke/subscriptions", "organizations_url": "https://api.github.com/users/jhmenke/orgs", "repos_url": "https://api.github.com/users/jhmenke/repos", "events_url": "https://api.github.com/users/jhmenke/events{/privacy}", "received_events_url": "https://api.github.com/users/jhmenke/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-06-05T07:00:34Z", "updated_at": "2018-07-11T06:55:52Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Updating from Pytorch 0.3.1 to 0.4 yields a significant performance drop on small feedforward networks, trained <strong>on CPU</strong>. This effect happens on Linux (in a virtual machine) and on Windows.</p>\n<p>The attached code was executed on a Windows 10 machine with an Intel i7-7700HQ.<br>\nThe Linux test was done in a virtual machine. The computer is equipped with an Intel i7-4702MQ.</p>\n<p>The average runtime over 10 repetitions on Linux is 26.141655 s for Pytorch 0.3.1 and 32.092158 s on 0.4  (~23 % increase)<br>\nThe average runtime over 10 repetitions on Windows is 12.577887 s for Pytorch 0.3.1 and 17.759720 s on 0.4  (~41 % increase)</p>\n<p>Observations:</p>\n<ul>\n<li>The time difference between 0.3.1 and 0.4 seems to be more or less constant on both Windows and Linux.</li>\n<li>Also profiling suggests the DataLoader <strong>next</strong> takes 8 s instead of 4 s previously, a major part of the increased time</li>\n<li>Weirdly, in different calls of the script, the early stopping if-clause activates sometimes despire setting the pytorch seed as to avoid effects due to randomness</li>\n</ul>\n<h2>Code example</h2>\n<p>See my results and the data/script used here:<br>\n<a href=\"https://github.com/pytorch/pytorch/files/2071136/PytorchSpeedTest.zip\">PytorchSpeedTest.zip</a></p>\n<h2>System Info</h2>\n<p>(the collect_env is not yet adapted to Windows, therefore information is missing. I am using pip 10.x and the latest conda)</p>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.1</p>\n<p>OS: Microsoft Windows 10 Home<br>\nGCC version: Could not collect<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.1.85<br>\nGPU models and configuration: Could not collect<br>\nNvidia driver version: Could not collect<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] Could not collect</p>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): all conda (Windows 0.3.1. via conda install -c peterjc123 pytorch-cpu)</li>\n<li>OS: Windows 10 / Ubuntu 16.04</li>\n<li>PyTorch version: 0.3.1 to 0.4</li>\n<li>Python version: 3.6</li>\n</ul>\n<h2>Bottleneck Profiling</h2>\n<p>0.4</p>\n<pre><code>--------------------------------------------------------------------------------\n  cProfile output\n--------------------------------------------------------------------------------\n         12550526 function calls (12252338 primitive calls) in 21.593 seconds\n\n   Ordered by: internal time\n   List reduced from 334 to 15 due to restriction &lt;15&gt;\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    31780    4.498    0.000    4.498    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\n    84840    2.774    0.000    2.774    0.000 {built-in method stack}\n  3049200    2.219    0.000    2.219    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:40(&lt;genexpr&gt;)\n    31780    1.347    0.000    3.899    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\optim\\adam.py:48(step)\n   127260    1.217    0.000    1.217    0.000 {built-in method addmm}\n  1016400    0.866    0.000    3.085    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:39(__getitem__)\n   190680    0.593    0.000    0.593    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n296940/84840    0.566    0.000    3.832    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:485(__call__)\n   381360    0.557    0.000    0.557    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n    84840    0.553    0.000    0.553    0.000 {built-in method torch._C._nn.threshold}\n    42560    0.532    0.000    8.012    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:261(__next__)\n        1    0.511    0.511   21.593   21.593 .\\pytorch.0.4.py:1(&lt;module&gt;)\n   381360    0.470    0.000    0.470    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n    42560    0.438    0.000    0.603    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:136(__iter__)\n   190680    0.421    0.000    0.421    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n\n\n--------------------------------------------------------------------------------\n  autograd profiler output (CPU mode)\n--------------------------------------------------------------------------------\n        top 15 events sorted by cpu_time_total\n\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\nName                           CPU time        CUDA time            Calls        CPU total       CUDA total\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\nstack                         475.169us          0.000us                1        475.169us          0.000us\nstack                         415.362us          0.000us                1        415.362us          0.000us\nstack                         388.741us          0.000us                1        388.741us          0.000us\nstack                         381.812us          0.000us                1        381.812us          0.000us\nstack                         378.531us          0.000us                1        378.531us          0.000us\nstack                         371.966us          0.000us                1        371.966us          0.000us\nThresholdBackward0            370.507us          0.000us                1        370.507us          0.000us\nthreshold_backward            369.049us          0.000us                1        369.049us          0.000us\nAddmmBackward                 358.473us          0.000us                1        358.473us          0.000us\nstack                         350.815us          0.000us                1        350.815us          0.000us\nmm                            347.169us          0.000us                1        347.169us          0.000us\nselect                        343.887us          0.000us                1        343.887us          0.000us\nadd_                          340.239us          0.000us                1        340.239us          0.000us\nunsqueeze                     339.511us          0.000us                1        339.511us          0.000us\naddmm                         335.864us          0.000us                1        335.864us          0.000us\n</code></pre>\n<h3>cProfile</h3>\n<p>0.3.1</p>\n<pre><code>12819090 function calls (12546756 primitive calls) in 14.661 seconds\n\n  Ordered by: internal time\n\n  ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n   28602    3.038    0.000    3.038    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\n 1829520    1.041    0.000    1.041    0.000 {method 'unsqueeze' of 'torch._C.FloatTensorBase' objects}\n   28602    0.855    0.000    2.765    0.000 adam.py:31(step)\n  114534    0.854    0.000    0.854    0.000 {built-in method torch._C.addmm}\n  914760    0.616    0.000    0.616    0.000 dataset.py:42(__getitem__)\n  171612    0.504    0.000    0.504    0.000 {method 'sqrt' of 'torch._C.FloatTensorBase' objects}\n  171612    0.468    0.000    0.468    0.000 {method 'addcdiv_' of 'torch._C.FloatTensorBase' objects}\n   38304    0.466    0.000    0.917    0.000 sampler.py:117(__iter__)\n       1    0.454    0.454   14.661   14.661 pytorch.0.3.1.py:1(&lt;module&gt;)\n267246/76356    0.438    0.000    3.045    0.000 module.py:351(__call__)\n  343224    0.437    0.000    0.437    0.000 {method 'mul_' of 'torch._C.FloatTensorBase' objects}\n   76356    0.431    0.000    0.431    0.000 {built-in method torch._C._nn.threshold}\n114534/38178    0.421    0.000    2.340    0.000 dataloader.py:99(default_collate)\n   38304    0.272    0.000    4.413    0.000 dataloader.py:256(__next__)\n   76356    0.270    0.000    0.270    0.000 {built-in method torch._C.cat}\n</code></pre>", "body_text": "Issue description\nUpdating from Pytorch 0.3.1 to 0.4 yields a significant performance drop on small feedforward networks, trained on CPU. This effect happens on Linux (in a virtual machine) and on Windows.\nThe attached code was executed on a Windows 10 machine with an Intel i7-7700HQ.\nThe Linux test was done in a virtual machine. The computer is equipped with an Intel i7-4702MQ.\nThe average runtime over 10 repetitions on Linux is 26.141655 s for Pytorch 0.3.1 and 32.092158 s on 0.4  (~23 % increase)\nThe average runtime over 10 repetitions on Windows is 12.577887 s for Pytorch 0.3.1 and 17.759720 s on 0.4  (~41 % increase)\nObservations:\n\nThe time difference between 0.3.1 and 0.4 seems to be more or less constant on both Windows and Linux.\nAlso profiling suggests the DataLoader next takes 8 s instead of 4 s previously, a major part of the increased time\nWeirdly, in different calls of the script, the early stopping if-clause activates sometimes despire setting the pytorch seed as to avoid effects due to randomness\n\nCode example\nSee my results and the data/script used here:\nPytorchSpeedTest.zip\nSystem Info\n(the collect_env is not yet adapted to Windows, therefore information is missing. I am using pip 10.x and the latest conda)\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 9.1\nOS: Microsoft Windows 10 Home\nGCC version: Could not collect\nCMake version: Could not collect\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.1.85\nGPU models and configuration: Could not collect\nNvidia driver version: Could not collect\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): all conda (Windows 0.3.1. via conda install -c peterjc123 pytorch-cpu)\nOS: Windows 10 / Ubuntu 16.04\nPyTorch version: 0.3.1 to 0.4\nPython version: 3.6\n\nBottleneck Profiling\n0.4\n--------------------------------------------------------------------------------\n  cProfile output\n--------------------------------------------------------------------------------\n         12550526 function calls (12252338 primitive calls) in 21.593 seconds\n\n   Ordered by: internal time\n   List reduced from 334 to 15 due to restriction <15>\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    31780    4.498    0.000    4.498    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\n    84840    2.774    0.000    2.774    0.000 {built-in method stack}\n  3049200    2.219    0.000    2.219    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:40(<genexpr>)\n    31780    1.347    0.000    3.899    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\optim\\adam.py:48(step)\n   127260    1.217    0.000    1.217    0.000 {built-in method addmm}\n  1016400    0.866    0.000    3.085    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:39(__getitem__)\n   190680    0.593    0.000    0.593    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n296940/84840    0.566    0.000    3.832    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:485(__call__)\n   381360    0.557    0.000    0.557    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n    84840    0.553    0.000    0.553    0.000 {built-in method torch._C._nn.threshold}\n    42560    0.532    0.000    8.012    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:261(__next__)\n        1    0.511    0.511   21.593   21.593 .\\pytorch.0.4.py:1(<module>)\n   381360    0.470    0.000    0.470    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n    42560    0.438    0.000    0.603    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:136(__iter__)\n   190680    0.421    0.000    0.421    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n\n\n--------------------------------------------------------------------------------\n  autograd profiler output (CPU mode)\n--------------------------------------------------------------------------------\n        top 15 events sorted by cpu_time_total\n\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\nName                           CPU time        CUDA time            Calls        CPU total       CUDA total\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\nstack                         475.169us          0.000us                1        475.169us          0.000us\nstack                         415.362us          0.000us                1        415.362us          0.000us\nstack                         388.741us          0.000us                1        388.741us          0.000us\nstack                         381.812us          0.000us                1        381.812us          0.000us\nstack                         378.531us          0.000us                1        378.531us          0.000us\nstack                         371.966us          0.000us                1        371.966us          0.000us\nThresholdBackward0            370.507us          0.000us                1        370.507us          0.000us\nthreshold_backward            369.049us          0.000us                1        369.049us          0.000us\nAddmmBackward                 358.473us          0.000us                1        358.473us          0.000us\nstack                         350.815us          0.000us                1        350.815us          0.000us\nmm                            347.169us          0.000us                1        347.169us          0.000us\nselect                        343.887us          0.000us                1        343.887us          0.000us\nadd_                          340.239us          0.000us                1        340.239us          0.000us\nunsqueeze                     339.511us          0.000us                1        339.511us          0.000us\naddmm                         335.864us          0.000us                1        335.864us          0.000us\n\ncProfile\n0.3.1\n12819090 function calls (12546756 primitive calls) in 14.661 seconds\n\n  Ordered by: internal time\n\n  ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n   28602    3.038    0.000    3.038    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\n 1829520    1.041    0.000    1.041    0.000 {method 'unsqueeze' of 'torch._C.FloatTensorBase' objects}\n   28602    0.855    0.000    2.765    0.000 adam.py:31(step)\n  114534    0.854    0.000    0.854    0.000 {built-in method torch._C.addmm}\n  914760    0.616    0.000    0.616    0.000 dataset.py:42(__getitem__)\n  171612    0.504    0.000    0.504    0.000 {method 'sqrt' of 'torch._C.FloatTensorBase' objects}\n  171612    0.468    0.000    0.468    0.000 {method 'addcdiv_' of 'torch._C.FloatTensorBase' objects}\n   38304    0.466    0.000    0.917    0.000 sampler.py:117(__iter__)\n       1    0.454    0.454   14.661   14.661 pytorch.0.3.1.py:1(<module>)\n267246/76356    0.438    0.000    3.045    0.000 module.py:351(__call__)\n  343224    0.437    0.000    0.437    0.000 {method 'mul_' of 'torch._C.FloatTensorBase' objects}\n   76356    0.431    0.000    0.431    0.000 {built-in method torch._C._nn.threshold}\n114534/38178    0.421    0.000    2.340    0.000 dataloader.py:99(default_collate)\n   38304    0.272    0.000    4.413    0.000 dataloader.py:256(__next__)\n   76356    0.270    0.000    0.270    0.000 {built-in method torch._C.cat}", "body": "## Issue description\r\n\r\nUpdating from Pytorch 0.3.1 to 0.4 yields a significant performance drop on small feedforward networks, trained **on CPU**. This effect happens on Linux (in a virtual machine) and on Windows.\r\n\r\nThe attached code was executed on a Windows 10 machine with an Intel i7-7700HQ.\r\nThe Linux test was done in a virtual machine. The computer is equipped with an Intel i7-4702MQ.\r\n\r\nThe average runtime over 10 repetitions on Linux is 26.141655 s for Pytorch 0.3.1 and 32.092158 s on 0.4  (~23 % increase)\r\nThe average runtime over 10 repetitions on Windows is 12.577887 s for Pytorch 0.3.1 and 17.759720 s on 0.4  (~41 % increase)\r\n\r\nObservations: \r\n- The time difference between 0.3.1 and 0.4 seems to be more or less constant on both Windows and Linux. \r\n- Also profiling suggests the DataLoader __next__ takes 8 s instead of 4 s previously, a major part of the increased time\r\n- Weirdly, in different calls of the script, the early stopping if-clause activates sometimes despire setting the pytorch seed as to avoid effects due to randomness\r\n\r\n## Code example\r\n\r\nSee my results and the data/script used here:\r\n[PytorchSpeedTest.zip](https://github.com/pytorch/pytorch/files/2071136/PytorchSpeedTest.zip)\r\n\r\n## System Info\r\n\r\n(the collect_env is not yet adapted to Windows, therefore information is missing. I am using pip 10.x and the latest conda)\r\n\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.1\r\n\r\nOS: Microsoft Windows 10 Home\r\nGCC version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.1.85\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): all conda (Windows 0.3.1. via conda install -c peterjc123 pytorch-cpu)\r\n- OS: Windows 10 / Ubuntu 16.04 \r\n- PyTorch version: 0.3.1 to 0.4\r\n- Python version: 3.6\r\n\r\n## Bottleneck Profiling\r\n0.4\r\n```\r\n--------------------------------------------------------------------------------\r\n  cProfile output\r\n--------------------------------------------------------------------------------\r\n         12550526 function calls (12252338 primitive calls) in 21.593 seconds\r\n\r\n   Ordered by: internal time\r\n   List reduced from 334 to 15 due to restriction <15>\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n    31780    4.498    0.000    4.498    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\r\n    84840    2.774    0.000    2.774    0.000 {built-in method stack}\r\n  3049200    2.219    0.000    2.219    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:40(<genexpr>)\r\n    31780    1.347    0.000    3.899    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\optim\\adam.py:48(step)\r\n   127260    1.217    0.000    1.217    0.000 {built-in method addmm}\r\n  1016400    0.866    0.000    3.085    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:39(__getitem__)\r\n   190680    0.593    0.000    0.593    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\r\n296940/84840    0.566    0.000    3.832    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:485(__call__)\r\n   381360    0.557    0.000    0.557    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\r\n    84840    0.553    0.000    0.553    0.000 {built-in method torch._C._nn.threshold}\r\n    42560    0.532    0.000    8.012    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:261(__next__)\r\n        1    0.511    0.511   21.593   21.593 .\\pytorch.0.4.py:1(<module>)\r\n   381360    0.470    0.000    0.470    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\r\n    42560    0.438    0.000    0.603    0.000 C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:136(__iter__)\r\n   190680    0.421    0.000    0.421    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\r\n\r\n\r\n--------------------------------------------------------------------------------\r\n  autograd profiler output (CPU mode)\r\n--------------------------------------------------------------------------------\r\n        top 15 events sorted by cpu_time_total\r\n\r\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\r\nName                           CPU time        CUDA time            Calls        CPU total       CUDA total\r\n----------------------  ---------------  ---------------  ---------------  ---------------  ---------------\r\nstack                         475.169us          0.000us                1        475.169us          0.000us\r\nstack                         415.362us          0.000us                1        415.362us          0.000us\r\nstack                         388.741us          0.000us                1        388.741us          0.000us\r\nstack                         381.812us          0.000us                1        381.812us          0.000us\r\nstack                         378.531us          0.000us                1        378.531us          0.000us\r\nstack                         371.966us          0.000us                1        371.966us          0.000us\r\nThresholdBackward0            370.507us          0.000us                1        370.507us          0.000us\r\nthreshold_backward            369.049us          0.000us                1        369.049us          0.000us\r\nAddmmBackward                 358.473us          0.000us                1        358.473us          0.000us\r\nstack                         350.815us          0.000us                1        350.815us          0.000us\r\nmm                            347.169us          0.000us                1        347.169us          0.000us\r\nselect                        343.887us          0.000us                1        343.887us          0.000us\r\nadd_                          340.239us          0.000us                1        340.239us          0.000us\r\nunsqueeze                     339.511us          0.000us                1        339.511us          0.000us\r\naddmm                         335.864us          0.000us                1        335.864us          0.000us\r\n```\r\n\r\n### cProfile\r\n0.3.1\r\n\r\n ``` \r\n 12819090 function calls (12546756 primitive calls) in 14.661 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n    28602    3.038    0.000    3.038    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\r\n  1829520    1.041    0.000    1.041    0.000 {method 'unsqueeze' of 'torch._C.FloatTensorBase' objects}\r\n    28602    0.855    0.000    2.765    0.000 adam.py:31(step)\r\n   114534    0.854    0.000    0.854    0.000 {built-in method torch._C.addmm}\r\n   914760    0.616    0.000    0.616    0.000 dataset.py:42(__getitem__)\r\n   171612    0.504    0.000    0.504    0.000 {method 'sqrt' of 'torch._C.FloatTensorBase' objects}\r\n   171612    0.468    0.000    0.468    0.000 {method 'addcdiv_' of 'torch._C.FloatTensorBase' objects}\r\n    38304    0.466    0.000    0.917    0.000 sampler.py:117(__iter__)\r\n        1    0.454    0.454   14.661   14.661 pytorch.0.3.1.py:1(<module>)\r\n267246/76356    0.438    0.000    3.045    0.000 module.py:351(__call__)\r\n   343224    0.437    0.000    0.437    0.000 {method 'mul_' of 'torch._C.FloatTensorBase' objects}\r\n    76356    0.431    0.000    0.431    0.000 {built-in method torch._C._nn.threshold}\r\n114534/38178    0.421    0.000    2.340    0.000 dataloader.py:99(default_collate)\r\n    38304    0.272    0.000    4.413    0.000 dataloader.py:256(__next__)\r\n    76356    0.270    0.000    0.270    0.000 {built-in method torch._C.cat}\r\n```"}