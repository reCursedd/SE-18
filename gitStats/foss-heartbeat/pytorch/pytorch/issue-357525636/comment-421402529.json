{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/421402529", "html_url": "https://github.com/pytorch/pytorch/issues/11327#issuecomment-421402529", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11327", "id": 421402529, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTQwMjUyOQ==", "user": {"login": "mcarilli", "id": 7799218, "node_id": "MDQ6VXNlcjc3OTkyMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7799218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarilli", "html_url": "https://github.com/mcarilli", "followers_url": "https://api.github.com/users/mcarilli/followers", "following_url": "https://api.github.com/users/mcarilli/following{/other_user}", "gists_url": "https://api.github.com/users/mcarilli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarilli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarilli/subscriptions", "organizations_url": "https://api.github.com/users/mcarilli/orgs", "repos_url": "https://api.github.com/users/mcarilli/repos", "events_url": "https://api.github.com/users/mcarilli/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarilli/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-14T15:53:16Z", "updated_at": "2018-09-14T15:53:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>docker pull pytorch/pytorch</code> pulls the official Pytorch container, created by Facebook people, which contains (as far as I know) Pytorch 0.4.1.</p>\n<p>The 18.0* containers are Nvidia-created containers, available through Nvidia NGC.  They contain snapshots of Pytorch master that are updated on a rolling basis, but the snapshots in publicly available NGC containers tend to lag behind top of tree master by 1-2 months.  For example, the 18.09 container I just used to train successfully is not yet publicly available.</p>\n<p>Because of this lag, IMO the best thing to try in your case is to pull the latest Pytorch master from Github and rebuild from source.  If you don't have NCCL or CuDNN installed on bare metal, pull <code>pytorch/pytorch:0.4.1-cuda9-cudnn7-devel</code>, which should contain the NCCL and CUDNN shared object libraries.   Within that container, you can uninstall the existing Pytorch (0.4.1) and recompile top of tree:</p>\n<pre><code>pip uninstall torch\ngit clone https://github.com/pytorch/pytorch.git\ncd pytorch\npython setup.py install\n</code></pre>\n<p>It'll take about 20 minutes to compile, but using a more recent Pytorch did help me, so maybe this will enable your use case.</p>", "body_text": "docker pull pytorch/pytorch pulls the official Pytorch container, created by Facebook people, which contains (as far as I know) Pytorch 0.4.1.\nThe 18.0* containers are Nvidia-created containers, available through Nvidia NGC.  They contain snapshots of Pytorch master that are updated on a rolling basis, but the snapshots in publicly available NGC containers tend to lag behind top of tree master by 1-2 months.  For example, the 18.09 container I just used to train successfully is not yet publicly available.\nBecause of this lag, IMO the best thing to try in your case is to pull the latest Pytorch master from Github and rebuild from source.  If you don't have NCCL or CuDNN installed on bare metal, pull pytorch/pytorch:0.4.1-cuda9-cudnn7-devel, which should contain the NCCL and CUDNN shared object libraries.   Within that container, you can uninstall the existing Pytorch (0.4.1) and recompile top of tree:\npip uninstall torch\ngit clone https://github.com/pytorch/pytorch.git\ncd pytorch\npython setup.py install\n\nIt'll take about 20 minutes to compile, but using a more recent Pytorch did help me, so maybe this will enable your use case.", "body": "`docker pull pytorch/pytorch` pulls the official Pytorch container, created by Facebook people, which contains (as far as I know) Pytorch 0.4.1.\r\n\r\nThe 18.0* containers are Nvidia-created containers, available through Nvidia NGC.  They contain snapshots of Pytorch master that are updated on a rolling basis, but the snapshots in publicly available NGC containers tend to lag behind top of tree master by 1-2 months.  For example, the 18.09 container I just used to train successfully is not yet publicly available.\r\n\r\nBecause of this lag, IMO the best thing to try in your case is to pull the latest Pytorch master from Github and rebuild from source.  If you don't have NCCL or CuDNN installed on bare metal, pull `pytorch/pytorch:0.4.1-cuda9-cudnn7-devel`, which should contain the NCCL and CUDNN shared object libraries.   Within that container, you can uninstall the existing Pytorch (0.4.1) and recompile top of tree:\r\n```\r\npip uninstall torch\r\ngit clone https://github.com/pytorch/pytorch.git\r\ncd pytorch\r\npython setup.py install\r\n```\r\nIt'll take about 20 minutes to compile, but using a more recent Pytorch did help me, so maybe this will enable your use case.\r\n"}