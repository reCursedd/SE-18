{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/419333150", "html_url": "https://github.com/pytorch/pytorch/issues/11327#issuecomment-419333150", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11327", "id": 419333150, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTMzMzE1MA==", "user": {"login": "yingjianling", "id": 19993503, "node_id": "MDQ6VXNlcjE5OTkzNTAz", "avatar_url": "https://avatars3.githubusercontent.com/u/19993503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yingjianling", "html_url": "https://github.com/yingjianling", "followers_url": "https://api.github.com/users/yingjianling/followers", "following_url": "https://api.github.com/users/yingjianling/following{/other_user}", "gists_url": "https://api.github.com/users/yingjianling/gists{/gist_id}", "starred_url": "https://api.github.com/users/yingjianling/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yingjianling/subscriptions", "organizations_url": "https://api.github.com/users/yingjianling/orgs", "repos_url": "https://api.github.com/users/yingjianling/repos", "events_url": "https://api.github.com/users/yingjianling/events{/privacy}", "received_events_url": "https://api.github.com/users/yingjianling/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T06:07:58Z", "updated_at": "2018-09-07T07:15:43Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8120856\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/teng-li\">@teng-li</a> Is there any difference between <code>multiprocessing.set_start_method('forkserver')</code> and <code>torch.multiprocessing.set_start_method('forkserver')</code>? I have tried the former and the dataloader still shut down after one epoch.<br>\nHere is the modified code:</p>\n<pre><code>import argparse,os,time\nimport torch.multiprocessing as mp\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.distributed as dist\nimport torch.utils.data.distributed\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport models\nfrom utils import *\ndef train(epoch):\n    for batch_idx, (data, label) in enumerate(train_loader, 0):\n        optimizer.zero_grad()\n        data, label = data.cuda(), label.cuda()\n\n        output, grid = model(data)\n        nll_loss = F.nll_loss(output, label)\n        de_loss = deformation_constraint_loss(grid, opt.grid_s)\n        loss =  nll_loss + de_loss\n        loss.backward()\n        optimizer.step()\n\nif __name__ == '__main__':\n    mp.set_start_method('forkserver')\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\n    parser.add_argument('--resume', type=str, default='', help='resume')\n    parser.add_argument(\"--display_interval\", type=int, default=50)\n    parser.add_argument(\"--local_rank\", type=int)\n    opt = parser.parse_args()\n    torch.cuda.set_device(opt.local_rank)\n    \n    dist.init_process_group(backend='nccl', init_method='env://', world_size=8)\n\n    train_dir = os.path.join(opt.data, 'train')\n    train_dataset = datasets.ImageFolder(\n        train_dir,\n        transforms.Compose([transforms.ToTensor()])\n    )\n    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=opt.batch_s,\n            num_workers=opt.workers,\n            drop_last=True,\n            pin_memory=False,\n            shuffle=False,\n            sampler=train_sampler\n        )\n\n    input_size = (opt.batch_s, 3, 128, 128)\n    num_classes = 9092\n    #num_classes = 34\n    model = models.se_resnet34_v3(input_size, opt.grid_s, num_classes)\n    if opt.resume:\n        if os.path.isfile(opt.resume):\n            print(\"=&gt; loading checkpoint '{}'\".format(opt.resume))\n            checkpoint = torch.load(opt.resume)\n            model.load_state_dict(checkpoint['state_dict'])\n            print(\"=&gt; loaded checkpoint '{}' (epoch {})\"\n                .format(opt.resume, checkpoint['epoch']))\n    model.cuda()\n    model = torch.nn.parallel.DistributedDataParallel(model,\\\n        device_ids=[opt.local_rank], output_device=opt.local_rank)\n\n    optimizer = optim.SGD([\n            {'params': get_parameters(model, bias=False)},\n            {'params': get_parameters(model, bias=True), 'lr':opt.lr * 2, 'weight_decay': 0},\n            {'params': get_parameters(model, bn=True), 'lr':opt.lr * 1.00001001358, 'weight_decay':0}\n        ], lr=opt.lr, momentum=opt.momentum, weight_decay=opt.weight_decay)\n\n    if opt.resume:\n        if os.path.isfile(opt.resume):\n            checkpoint = torch.load(opt.resume)\n            optimizer.load_state_dict(checkpoint['optimizer'])\n\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \\\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\n\n    for epoch in range(opt.start_epoch, opt.epoch + 1):\n        train_sampler.set_epoch(epoch)\n        scheduler.step() \n        model.train()\n        train(epoch)\n</code></pre>\n<p>I also tried some other solutions:</p>\n<ol>\n<li>turn off pin_memory</li>\n<li>the pull request from <a href=\"https://github.com/pytorch/pytorch/pull/9655\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9655/hovercard\">here</a></li>\n<li>mp.set_start_method('spwan')<br>\nNone of them worked. Setting <code>num_workers=0</code> work for me, but it is not fast enough.</li>\n</ol>", "body_text": "@teng-li Is there any difference between multiprocessing.set_start_method('forkserver') and torch.multiprocessing.set_start_method('forkserver')? I have tried the former and the dataloader still shut down after one epoch.\nHere is the modified code:\nimport argparse,os,time\nimport torch.multiprocessing as mp\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.distributed as dist\nimport torch.utils.data.distributed\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport models\nfrom utils import *\ndef train(epoch):\n    for batch_idx, (data, label) in enumerate(train_loader, 0):\n        optimizer.zero_grad()\n        data, label = data.cuda(), label.cuda()\n\n        output, grid = model(data)\n        nll_loss = F.nll_loss(output, label)\n        de_loss = deformation_constraint_loss(grid, opt.grid_s)\n        loss =  nll_loss + de_loss\n        loss.backward()\n        optimizer.step()\n\nif __name__ == '__main__':\n    mp.set_start_method('forkserver')\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\n    parser.add_argument('--resume', type=str, default='', help='resume')\n    parser.add_argument(\"--display_interval\", type=int, default=50)\n    parser.add_argument(\"--local_rank\", type=int)\n    opt = parser.parse_args()\n    torch.cuda.set_device(opt.local_rank)\n    \n    dist.init_process_group(backend='nccl', init_method='env://', world_size=8)\n\n    train_dir = os.path.join(opt.data, 'train')\n    train_dataset = datasets.ImageFolder(\n        train_dir,\n        transforms.Compose([transforms.ToTensor()])\n    )\n    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=opt.batch_s,\n            num_workers=opt.workers,\n            drop_last=True,\n            pin_memory=False,\n            shuffle=False,\n            sampler=train_sampler\n        )\n\n    input_size = (opt.batch_s, 3, 128, 128)\n    num_classes = 9092\n    #num_classes = 34\n    model = models.se_resnet34_v3(input_size, opt.grid_s, num_classes)\n    if opt.resume:\n        if os.path.isfile(opt.resume):\n            print(\"=> loading checkpoint '{}'\".format(opt.resume))\n            checkpoint = torch.load(opt.resume)\n            model.load_state_dict(checkpoint['state_dict'])\n            print(\"=> loaded checkpoint '{}' (epoch {})\"\n                .format(opt.resume, checkpoint['epoch']))\n    model.cuda()\n    model = torch.nn.parallel.DistributedDataParallel(model,\\\n        device_ids=[opt.local_rank], output_device=opt.local_rank)\n\n    optimizer = optim.SGD([\n            {'params': get_parameters(model, bias=False)},\n            {'params': get_parameters(model, bias=True), 'lr':opt.lr * 2, 'weight_decay': 0},\n            {'params': get_parameters(model, bn=True), 'lr':opt.lr * 1.00001001358, 'weight_decay':0}\n        ], lr=opt.lr, momentum=opt.momentum, weight_decay=opt.weight_decay)\n\n    if opt.resume:\n        if os.path.isfile(opt.resume):\n            checkpoint = torch.load(opt.resume)\n            optimizer.load_state_dict(checkpoint['optimizer'])\n\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \\\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\n\n    for epoch in range(opt.start_epoch, opt.epoch + 1):\n        train_sampler.set_epoch(epoch)\n        scheduler.step() \n        model.train()\n        train(epoch)\n\nI also tried some other solutions:\n\nturn off pin_memory\nthe pull request from here\nmp.set_start_method('spwan')\nNone of them worked. Setting num_workers=0 work for me, but it is not fast enough.", "body": "@teng-li Is there any difference between `multiprocessing.set_start_method('forkserver')` and `torch.multiprocessing.set_start_method('forkserver')`? I have tried the former and the dataloader still shut down after one epoch. \r\nHere is the modified code:\r\n```\r\nimport argparse,os,time\r\nimport torch.multiprocessing as mp\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nimport torch.distributed as dist\r\nimport torch.utils.data.distributed\r\nimport torchvision\r\nfrom torchvision import datasets, transforms\r\nimport numpy as np\r\nimport models\r\nfrom utils import *\r\ndef train(epoch):\r\n    for batch_idx, (data, label) in enumerate(train_loader, 0):\r\n        optimizer.zero_grad()\r\n        data, label = data.cuda(), label.cuda()\r\n\r\n        output, grid = model(data)\r\n        nll_loss = F.nll_loss(output, label)\r\n        de_loss = deformation_constraint_loss(grid, opt.grid_s)\r\n        loss =  nll_loss + de_loss\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\nif __name__ == '__main__':\r\n    mp.set_start_method('forkserver')\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\r\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\r\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\r\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\r\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\r\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\r\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\r\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\r\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\r\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\r\n    parser.add_argument('--resume', type=str, default='', help='resume')\r\n    parser.add_argument(\"--display_interval\", type=int, default=50)\r\n    parser.add_argument(\"--local_rank\", type=int)\r\n    opt = parser.parse_args()\r\n    torch.cuda.set_device(opt.local_rank)\r\n    \r\n    dist.init_process_group(backend='nccl', init_method='env://', world_size=8)\r\n\r\n    train_dir = os.path.join(opt.data, 'train')\r\n    train_dataset = datasets.ImageFolder(\r\n        train_dir,\r\n        transforms.Compose([transforms.ToTensor()])\r\n    )\r\n    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\r\n    train_loader = torch.utils.data.DataLoader(\r\n            train_dataset,\r\n            batch_size=opt.batch_s,\r\n            num_workers=opt.workers,\r\n            drop_last=True,\r\n            pin_memory=False,\r\n            shuffle=False,\r\n            sampler=train_sampler\r\n        )\r\n\r\n    input_size = (opt.batch_s, 3, 128, 128)\r\n    num_classes = 9092\r\n    #num_classes = 34\r\n    model = models.se_resnet34_v3(input_size, opt.grid_s, num_classes)\r\n    if opt.resume:\r\n        if os.path.isfile(opt.resume):\r\n            print(\"=> loading checkpoint '{}'\".format(opt.resume))\r\n            checkpoint = torch.load(opt.resume)\r\n            model.load_state_dict(checkpoint['state_dict'])\r\n            print(\"=> loaded checkpoint '{}' (epoch {})\"\r\n                .format(opt.resume, checkpoint['epoch']))\r\n    model.cuda()\r\n    model = torch.nn.parallel.DistributedDataParallel(model,\\\r\n        device_ids=[opt.local_rank], output_device=opt.local_rank)\r\n\r\n    optimizer = optim.SGD([\r\n            {'params': get_parameters(model, bias=False)},\r\n            {'params': get_parameters(model, bias=True), 'lr':opt.lr * 2, 'weight_decay': 0},\r\n            {'params': get_parameters(model, bn=True), 'lr':opt.lr * 1.00001001358, 'weight_decay':0}\r\n        ], lr=opt.lr, momentum=opt.momentum, weight_decay=opt.weight_decay)\r\n\r\n    if opt.resume:\r\n        if os.path.isfile(opt.resume):\r\n            checkpoint = torch.load(opt.resume)\r\n            optimizer.load_state_dict(checkpoint['optimizer'])\r\n\r\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \\\r\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\r\n\r\n    for epoch in range(opt.start_epoch, opt.epoch + 1):\r\n        train_sampler.set_epoch(epoch)\r\n        scheduler.step() \r\n        model.train()\r\n        train(epoch)\r\n```\r\nI also tried some other solutions:\r\n1. turn off pin_memory\r\n2. the pull request from [here](https://github.com/pytorch/pytorch/pull/9655)\r\n3. mp.set_start_method('spwan')\r\nNone of them worked. Setting `num_workers=0` work for me, but it is not fast enough."}