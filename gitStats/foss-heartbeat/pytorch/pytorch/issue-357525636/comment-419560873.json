{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/419560873", "html_url": "https://github.com/pytorch/pytorch/issues/11327#issuecomment-419560873", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11327", "id": 419560873, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTU2MDg3Mw==", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T20:45:37Z", "updated_at": "2018-09-07T21:02:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I created the following snippet (below) to try and simplify and reproduce the issue, but it's working OK for me with 8 workers, 20 epochs, and a batch size of 100 . Is it possible that you're setting the higher number of classes incorrectly?</p>\n<p>Edit: sorry, forgot to mention have only 2 gpus right now, working on grabbing an 8 gpu machine. Does using fewer GPUs matter or do you hit this regardless of the # of GPUs you're using?</p>\n<p>Update: 8 gpu machine also seems to be running OK with --workers=8, at least for 30 epochs.</p>\n<pre><code>import argparse,os,time\nimport torch.multiprocessing as mp\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.distributed as dist\nimport torch.utils.data.distributed\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\n\nclass MLPNet(nn.Module):\n    def __init__(self):\n        super(MLPNet, self).__init__()\n        self.fc1 = nn.Linear(28*28, 500)\n        self.fc2 = nn.Linear(500, 256)\n        self.fc3 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def name(self):\n        return \"MLP\"\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\n    parser.add_argument('--resume', type=str, default='', help='resume')\n    parser.add_argument(\"--display_interval\", type=int, default=50)\n    parser.add_argument(\"--local_rank\", type=int)\n    opt = parser.parse_args()\n\n    torch.cuda.set_device(opt.local_rank)\n    \n    dist.init_process_group(backend='nccl', init_method='env://')\n\n    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n    mnist = torchvision.datasets.MNIST(root=\"~/Documents/workspace/datasets/mnist\", train=True, transform=trans, download=True)\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(mnist)\n    train_loader = torch.utils.data.DataLoader(\n            mnist,\n            batch_size=opt.batch_s,\n            num_workers=opt.workers,\n            drop_last=True,\n            pin_memory=False,\n            shuffle=False,\n            sampler=train_sampler\n        )\n\n    model = MLPNet().cuda()\n    criterion = nn.CrossEntropyLoss()\n    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.local_rank], output_device=opt.local_rank)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\n    \n    for epoch in range(opt.start_epoch, opt.epoch + 1):\n        print(epoch)\n        train_sampler.set_epoch(epoch)\n        scheduler.step()\n        for batch_idx, (x, target) in enumerate(train_loader):\n          optimizer.zero_grad()\n          x, target = x.cuda(), target.cuda()\n          out = model(x)\n          loss = criterion(out, target)\n          loss.backward()\n          optimizer.step()\n</code></pre>", "body_text": "I created the following snippet (below) to try and simplify and reproduce the issue, but it's working OK for me with 8 workers, 20 epochs, and a batch size of 100 . Is it possible that you're setting the higher number of classes incorrectly?\nEdit: sorry, forgot to mention have only 2 gpus right now, working on grabbing an 8 gpu machine. Does using fewer GPUs matter or do you hit this regardless of the # of GPUs you're using?\nUpdate: 8 gpu machine also seems to be running OK with --workers=8, at least for 30 epochs.\nimport argparse,os,time\nimport torch.multiprocessing as mp\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.distributed as dist\nimport torch.utils.data.distributed\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\n\nclass MLPNet(nn.Module):\n    def __init__(self):\n        super(MLPNet, self).__init__()\n        self.fc1 = nn.Linear(28*28, 500)\n        self.fc2 = nn.Linear(500, 256)\n        self.fc3 = nn.Linear(256, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n    def name(self):\n        return \"MLP\"\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\n    parser.add_argument('--resume', type=str, default='', help='resume')\n    parser.add_argument(\"--display_interval\", type=int, default=50)\n    parser.add_argument(\"--local_rank\", type=int)\n    opt = parser.parse_args()\n\n    torch.cuda.set_device(opt.local_rank)\n    \n    dist.init_process_group(backend='nccl', init_method='env://')\n\n    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n    mnist = torchvision.datasets.MNIST(root=\"~/Documents/workspace/datasets/mnist\", train=True, transform=trans, download=True)\n\n    train_sampler = torch.utils.data.distributed.DistributedSampler(mnist)\n    train_loader = torch.utils.data.DataLoader(\n            mnist,\n            batch_size=opt.batch_s,\n            num_workers=opt.workers,\n            drop_last=True,\n            pin_memory=False,\n            shuffle=False,\n            sampler=train_sampler\n        )\n\n    model = MLPNet().cuda()\n    criterion = nn.CrossEntropyLoss()\n    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.local_rank], output_device=opt.local_rank)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\n    \n    for epoch in range(opt.start_epoch, opt.epoch + 1):\n        print(epoch)\n        train_sampler.set_epoch(epoch)\n        scheduler.step()\n        for batch_idx, (x, target) in enumerate(train_loader):\n          optimizer.zero_grad()\n          x, target = x.cuda(), target.cuda()\n          out = model(x)\n          loss = criterion(out, target)\n          loss.backward()\n          optimizer.step()", "body": "I created the following snippet (below) to try and simplify and reproduce the issue, but it's working OK for me with 8 workers, 20 epochs, and a batch size of 100 . Is it possible that you're setting the higher number of classes incorrectly?\r\n\r\nEdit: sorry, forgot to mention have only 2 gpus right now, working on grabbing an 8 gpu machine. Does using fewer GPUs matter or do you hit this regardless of the # of GPUs you're using? \r\n\r\nUpdate: 8 gpu machine also seems to be running OK with --workers=8, at least for 30 epochs. \r\n\r\n```\r\nimport argparse,os,time\r\nimport torch.multiprocessing as mp\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nimport torch.distributed as dist\r\nimport torch.utils.data.distributed\r\nimport torchvision\r\nfrom torchvision import datasets, transforms\r\nimport numpy as np\r\n\r\nclass MLPNet(nn.Module):\r\n    def __init__(self):\r\n        super(MLPNet, self).__init__()\r\n        self.fc1 = nn.Linear(28*28, 500)\r\n        self.fc2 = nn.Linear(500, 256)\r\n        self.fc3 = nn.Linear(256, 10)\r\n\r\n    def forward(self, x):\r\n        x = x.view(-1, 28*28)\r\n        x = F.relu(self.fc1(x))\r\n        x = F.relu(self.fc2(x))\r\n        x = self.fc3(x)\r\n        return x\r\n    \r\n    def name(self):\r\n        return \"MLP\"\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--start_epoch', type=int, default=1, help='start epoch number')\r\n    parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')\r\n    parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.1')\r\n    parser.add_argument('--momentum', type=float, default=0.9, help='momentum, default=0.9')\r\n    parser.add_argument('--weight_decay', type=float, default=0.0002, help='weight_decay, default=0.0002')\r\n    parser.add_argument('--batch_s', type=int, default=64, help='input batch size')\r\n    parser.add_argument('--grid_s', type=int, default=8, help='grid size')\r\n    parser.add_argument('--data', type=str, default='../vgg2data', help='data directory')\r\n    parser.add_argument('--workers', type=int, default=1, help='number of data loading workers')\r\n    parser.add_argument('--output_dir', type=str, default='./output/', help='model_saving directory')\r\n    parser.add_argument('--resume', type=str, default='', help='resume')\r\n    parser.add_argument(\"--display_interval\", type=int, default=50)\r\n    parser.add_argument(\"--local_rank\", type=int)\r\n    opt = parser.parse_args()\r\n\r\n    torch.cuda.set_device(opt.local_rank)\r\n    \r\n    dist.init_process_group(backend='nccl', init_method='env://')\r\n\r\n    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\r\n    mnist = torchvision.datasets.MNIST(root=\"~/Documents/workspace/datasets/mnist\", train=True, transform=trans, download=True)\r\n\r\n    train_sampler = torch.utils.data.distributed.DistributedSampler(mnist)\r\n    train_loader = torch.utils.data.DataLoader(\r\n            mnist,\r\n            batch_size=opt.batch_s,\r\n            num_workers=opt.workers,\r\n            drop_last=True,\r\n            pin_memory=False,\r\n            shuffle=False,\r\n            sampler=train_sampler\r\n        )\r\n\r\n    model = MLPNet().cuda()\r\n    criterion = nn.CrossEntropyLoss()\r\n    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.local_rank], output_device=opt.local_rank)\r\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\r\n\r\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\r\n        milestones=[8,10,12,14,15,16,17,18,19,20,21,22,23,24], gamma=0.5)\r\n    \r\n    for epoch in range(opt.start_epoch, opt.epoch + 1):\r\n        print(epoch)\r\n        train_sampler.set_epoch(epoch)\r\n        scheduler.step()\r\n        for batch_idx, (x, target) in enumerate(train_loader):\r\n          optimizer.zero_grad()\r\n          x, target = x.cuda(), target.cuda()\r\n          out = model(x)\r\n          loss = criterion(out, target)\r\n          loss.backward()\r\n          optimizer.step()\r\n```\r\n  "}