{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150859121", "pull_request_review_id": 76471432, "id": 150859121, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDg1OTEyMQ==", "diff_hunk": "@@ -0,0 +1,210 @@\n+#include \"ATen/native/NativeFunctions.h\"\n+#include <cfloat>\n+\n+namespace at {\n+namespace native {\n+\n+__host__ __device__ __forceinline__ float fmin(float a, float b) {\n+  return a > b ? b : a;\n+}\n+\n+__host__ __device__ __forceinline__ float fmax(float a, float b) {\n+  return a > b ? a : b;\n+}\n+\n+template <typename T>\n+__global__ void RoiPooling2d_forward_kernel(\n+  const int outputElements,\n+  const T *input,\n+  const T *rois,\n+  const T spatialScale,\n+  const int inputChannels,\n+  const int inputHeight,\n+  const int inputWidth,\n+  const int pooledHeight,\n+  const int pooledWidth,\n+  T *output,\n+  int *argmaxes)\n+{\n+  for (int linearIndex = blockIdx.x * blockDim.x + threadIdx.x;\n+       linearIndex < outputElements;\n+       linearIndex += blockDim.x * gridDim.x)\n+  {\n+    // Calculate position in output Tensor, i.e. a specific combination\n+    // of proposal, channel, pool height and pool width\n+    // TODO: write to improve performance by minimize computation\n+    int pw = linearIndex % pooledWidth;\n+    int ph = (linearIndex / pooledWidth) % pooledHeight;\n+    int ch = (linearIndex / pooledWidth / pooledHeight) % inputChannels;\n+    int proposal = linearIndex / pooledWidth / pooledHeight / inputChannels;\n+\n+    // Get particular proposal data\n+    const T *roisOffset = rois + (proposal * 5);\n+    int n = roisOffset[0];\n+    int startWidth = llrintf(roisOffset[1] * spatialScale);\n+    int startHeight = llrintf(roisOffset[2] * spatialScale);\n+    int endWidth = llrintf(roisOffset[3] * spatialScale);\n+    int endHeight = llrintf(roisOffset[4] * spatialScale);\n+\n+    // TODO: fix malformed RoIs to be 1x1\n+\n+    int roiHeight = endHeight - startHeight;\n+    int roiWidth = endWidth - startWidth;\n+\n+    // Calculate size of tile based on the size of this particular RoI and the\n+    // output size\n+    T tileHeight = static_cast<T>(roiHeight) / static_cast<T>(pooledHeight);\n+    T tileWidth = static_cast<T>(roiWidth) / static_cast<T>(pooledWidth);\n+\n+    // Calculate offset into the pooled region\n+    int tileHStart = static_cast<int>(floorf(static_cast<T>(ph) * tileHeight));\n+    int tileWStart = static_cast<int>(floorf(static_cast<T>(pw) * tileWidth));\n+    int tileHEnd = static_cast<int>(ceilf(static_cast<T>(ph + 1) * tileHeight));\n+    int tileWEnd = static_cast<int>(ceilf(static_cast<T>(pw + 1) * tileWidth));\n+\n+    // Calculate offset into the image itself, based on RoI + pooled offsets,\n+    // and ensure it falls within image boundaries\n+    tileHStart = fmin(fmax(tileHStart + startHeight, 0), inputHeight);\n+    tileWStart = fmin(fmax(tileWStart + startWidth, 0), inputWidth);\n+    tileHEnd = fmin(fmax(tileHEnd + startHeight, 0), inputHeight);\n+    tileWEnd = fmin(fmax(tileWEnd + startWidth, 0), inputWidth);\n+\n+    // If our pooling region is empty, we set the output to 0, otherwise to\n+    // the min float so we can calculate the max properly\n+    bool isEmpty = (tileHStart >= tileHEnd) || (tileWStart >= tileWEnd);\n+    T max = isEmpty ? 0 : FLT_MIN;\n+    // If nothing is pooled, argmax = -1 causes nothing to be backprop'd\n+    int maxIdx = -1;\n+\n+    const T *inputOffset = input + ((n * inputChannels + ch) * inputHeight * inputWidth);\n+    for (int th = tileHStart; th < tileHEnd; ++th) {\n+      for (int tw = tileWStart; tw < tileWEnd; ++tw) {\n+        int index = (th * inputWidth) + tw;\n+\tif (inputOffset[index] > max) {\n+          max = inputOffset[index];\n+\t  maxIdx = index;\n+\t}\n+      }\n+    }\n+    output[linearIndex] = max;\n+\n+    // TODO optional argmax\n+    argmaxes[linearIndex] = maxIdx;\n+  }\n+}\n+\n+std::tuple<Tensor, Tensor> RoiPooling2d_forward_cuda(\n+  const Tensor& input,\n+  const Tensor& rois,\n+  int64_t pooledHeight,\n+  int64_t pooledWidth,\n+  double spatialScale)\n+{\n+\n+  // Input is the output of the last convolutional layer in the Backbone network, so\n+  // it should be in the format of NCHW\n+  AT_ASSERT(input.ndimension() == 4, \"Input to RoI Pooling should be a NCHW Tensor\");", "path": "aten/src/ATen/native/cuda/NativeFunctionsCuda.cu", "position": 106, "original_position": 106, "commit_id": "63ed778c9072b62a38365a69636e3b78e29e031f", "original_commit_id": "9511912ef618c337bd4c129a722dcd83a3ddb306", "user": {"login": "killeent", "id": 4529377, "node_id": "MDQ6VXNlcjQ1MjkzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4529377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/killeent", "html_url": "https://github.com/killeent", "followers_url": "https://api.github.com/users/killeent/followers", "following_url": "https://api.github.com/users/killeent/following{/other_user}", "gists_url": "https://api.github.com/users/killeent/gists{/gist_id}", "starred_url": "https://api.github.com/users/killeent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/killeent/subscriptions", "organizations_url": "https://api.github.com/users/killeent/orgs", "repos_url": "https://api.github.com/users/killeent/repos", "events_url": "https://api.github.com/users/killeent/events{/privacy}", "received_events_url": "https://api.github.com/users/killeent/received_events", "type": "User", "site_admin": false}, "body": "Yep. These kernels aren't really optimized or clean in anyway, mainly just copied from Caffe2. They will be improved upon later I just need something that works.", "created_at": "2017-11-14T15:07:49Z", "updated_at": "2018-11-23T15:36:29Z", "html_url": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150859121", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3672", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150859121"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150859121"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3672"}}, "body_html": "<p>Yep. These kernels aren't really optimized or clean in anyway, mainly just copied from Caffe2. They will be improved upon later I just need something that works.</p>", "body_text": "Yep. These kernels aren't really optimized or clean in anyway, mainly just copied from Caffe2. They will be improved upon later I just need something that works.", "in_reply_to_id": 150741187}