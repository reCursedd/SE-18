{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150738451", "pull_request_review_id": 76331676, "id": 150738451, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDczODQ1MQ==", "diff_hunk": "@@ -66,5 +66,10 @@ bool Context::hasCUDA() const {\n #endif\n }\n \n+#ifdef AT_CUDA_ENABLED\n+cudaStream_t Context::getCurrentCUDAStream() const {", "path": "aten/src/ATen/Context.cpp", "position": 5, "original_position": 5, "commit_id": "63ed778c9072b62a38365a69636e3b78e29e031f", "original_commit_id": "9511912ef618c337bd4c129a722dcd83a3ddb306", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "Bleh, this one might be tricky because the method is on Context. I'd be careful about perf problems that result from trying to init cuda in this method, because it requires taking a lock to initialize CUDA. Other pathways avoid it because, for instance, you cannot get a CUDA backend type without initializing cuda and so all tensor/type operators are guaranteed that cuda is initialized.\r\n\r\nHence, for any native function that is working on CUDA tensors, CUDA is guaranteed initialized and this is safe to call, but for public uses of the API this may fail.", "created_at": "2017-11-14T05:04:56Z", "updated_at": "2018-11-23T15:36:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150738451", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3672", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150738451"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150738451"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3672"}}, "body_html": "<p>Bleh, this one might be tricky because the method is on Context. I'd be careful about perf problems that result from trying to init cuda in this method, because it requires taking a lock to initialize CUDA. Other pathways avoid it because, for instance, you cannot get a CUDA backend type without initializing cuda and so all tensor/type operators are guaranteed that cuda is initialized.</p>\n<p>Hence, for any native function that is working on CUDA tensors, CUDA is guaranteed initialized and this is safe to call, but for public uses of the API this may fail.</p>", "body_text": "Bleh, this one might be tricky because the method is on Context. I'd be careful about perf problems that result from trying to init cuda in this method, because it requires taking a lock to initialize CUDA. Other pathways avoid it because, for instance, you cannot get a CUDA backend type without initializing cuda and so all tensor/type operators are guaranteed that cuda is initialized.\nHence, for any native function that is working on CUDA tensors, CUDA is guaranteed initialized and this is safe to call, but for public uses of the API this may fail.", "in_reply_to_id": 150704855}