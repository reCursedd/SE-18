{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150704772", "pull_request_review_id": 76294501, "id": 150704772, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDcwNDc3Mg==", "diff_hunk": "@@ -0,0 +1,126 @@\n+#pragma once\n+\n+#include \"ATen/ATen.h\"\n+#include <vector>\n+\n+/**\n+ * ATen native functions are ways to write ATen methods which make only\n+ * make use of other ATen operations (e.g., it is not necessary to\n+ * bind into TH/THC code or drop into CUDA kernels.)  These functions\n+ * are written as both functions as well as cwrap fragments, which are\n+ * then folded into the ATen code generation process; define a function\n+ * here, and it will show up as a method on at::Tensor.\n+ *\n+ * At the moment, only type_method_definition_level: base is supported.\n+ */\n+\n+namespace at {\n+namespace native {\n+\n+// [NativeFunction]\n+Tensor type_as(const Tensor& self, const Tensor& other);\n+\n+// [NativeFunction]\n+Tensor expand_as(const Tensor& self, const Tensor& other);\n+\n+// [NativeFunction]\n+std::vector<Tensor> split(const Tensor& self, int64_t split_size, int64_t dim=0);\n+\n+// [NativeFunction]\n+std::vector<Tensor> chunk(const Tensor& self, int64_t chunks, int64_t dim=0);\n+\n+// [NativeFunction]\n+int64_t size(const Tensor& self, int64_t dim);\n+\n+\n+// [NativeFunction]\n+int64_t stride(const Tensor& self, int64_t dim);\n+\n+\n+// [NativeFunction]\n+bool is_same_size(const Tensor& self, const Tensor& other);\n+\n+// [NativeFunction]\n+Tensor permute(const Tensor& self, IntList dims);\n+\n+\n+// [NativeFunction]\n+Tensor expand(const Tensor& self, IntList size);\n+\n+// [NativeFunction]\n+Tensor squeeze(const Tensor& self);\n+\n+// [NativeFunction]\n+Tensor squeeze(const Tensor& self, int64_t dim);\n+\n+// [NativeFunction]\n+Tensor & squeeze_(Tensor& self);\n+\n+\n+// [NativeFunction]\n+Tensor & squeeze_(Tensor& self, int64_t dim);\n+\n+// [NativeFunction]\n+Tensor unsqueeze(const Tensor& self, int64_t dim);\n+\n+// [NativeFunction]\n+Tensor & unsqueeze_(Tensor& self, int64_t dim);\n+\n+/*\n+[NativeFunction]\n+variants: function\n+*/\n+Tensor stack(TensorList tensors, int64_t dim=0);\n+\n+/*\n+[NativeFunction]\n+name: RoiPooling2d_forward\n+variants: function\n+type_method_definition_dispatch: {\n+  - CPU: at::native::RoiPooling2d_forward_cpu\n+  - CUDA: at::native::RoiPooling2d_forward_cuda\n+}\n+*/\n+std::tuple<Tensor, Tensor> RoiPooling2d_forward_cpu(\n+  const Tensor& input,\n+  const Tensor& rois,\n+  int64_t pooledHeight,\n+  int64_t pooledWidth,\n+  double spatialScale);\n+\n+std::tuple<Tensor, Tensor> RoiPooling2d_forward_cuda(\n+  const Tensor& input,\n+  const Tensor& rois,\n+  int64_t pooledHeight,\n+  int64_t pooledWidth,\n+  double spatialScale);\n+\n+/*\n+[NativeFunction]\n+name: RoiPooling2d_backward\n+variants: function\n+type_method_definition_dispatch: {\n+  - CPU: at::native::RoiPooling2d_backward_cpu\n+  - CUDA: at::native::RoiPooling2d_backward_cuda\n+}\n+*/\n+Tensor RoiPooling2d_backward_cpu(", "path": "aten/src/ATen/native/NativeFunctions.h", "position": null, "original_position": 107, "commit_id": "63ed778c9072b62a38365a69636e3b78e29e031f", "original_commit_id": "9511912ef618c337bd4c129a722dcd83a3ddb306", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Something that I have wondered about while working on CuDNN port to ATen is how native functions should handle the foo_out convention, e.g., there is already a result tensor preallocated and the backward should writre into it. I see in this case you have simply opted to not support this at all. Are we ever planning to support this mode of use, or not? (No code changes necessary.)", "created_at": "2017-11-14T00:15:01Z", "updated_at": "2018-11-23T15:36:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150704772", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3672", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150704772"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3672#discussion_r150704772"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3672"}}, "body_html": "<p>Something that I have wondered about while working on CuDNN port to ATen is how native functions should handle the foo_out convention, e.g., there is already a result tensor preallocated and the backward should writre into it. I see in this case you have simply opted to not support this at all. Are we ever planning to support this mode of use, or not? (No code changes necessary.)</p>", "body_text": "Something that I have wondered about while working on CuDNN port to ATen is how native functions should handle the foo_out convention, e.g., there is already a result tensor preallocated and the backward should writre into it. I see in this case you have simply opted to not support this at all. Are we ever planning to support this mode of use, or not? (No code changes necessary.)"}