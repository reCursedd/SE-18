{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1893", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1893/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1893/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1893/events", "html_url": "https://github.com/pytorch/pytorch/issues/1893", "id": 238255055, "node_id": "MDU6SXNzdWUyMzgyNTUwNTU=", "number": 1893, "title": "GPU usage extremely in-balance for segmentation task", "user": {"login": "zhanghang1989", "id": 8041160, "node_id": "MDQ6VXNlcjgwNDExNjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/8041160?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhanghang1989", "html_url": "https://github.com/zhanghang1989", "followers_url": "https://api.github.com/users/zhanghang1989/followers", "following_url": "https://api.github.com/users/zhanghang1989/following{/other_user}", "gists_url": "https://api.github.com/users/zhanghang1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhanghang1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhanghang1989/subscriptions", "organizations_url": "https://api.github.com/users/zhanghang1989/orgs", "repos_url": "https://api.github.com/users/zhanghang1989/repos", "events_url": "https://api.github.com/users/zhanghang1989/events{/privacy}", "received_events_url": "https://api.github.com/users/zhanghang1989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2017-06-23T21:13:05Z", "updated_at": "2018-05-01T01:08:52Z", "closed_at": "2017-06-25T18:05:55Z", "author_association": "NONE", "body_html": "<p>The usage of the first GPU is much larger than the others. I think it is because by default, the DataParallel model use the first GPU to store all the outputs, but the outputs are pretty big for segmentation tasks. Is this the temporary solution?<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/data_parallel.py#L47\">https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/data_parallel.py#L47</a></p>", "body_text": "The usage of the first GPU is much larger than the others. I think it is because by default, the DataParallel model use the first GPU to store all the outputs, but the outputs are pretty big for segmentation tasks. Is this the temporary solution?\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/data_parallel.py#L47", "body": "The usage of the first GPU is much larger than the others. I think it is because by default, the DataParallel model use the first GPU to store all the outputs, but the outputs are pretty big for segmentation tasks. Is this the temporary solution?\r\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/data_parallel.py#L47"}