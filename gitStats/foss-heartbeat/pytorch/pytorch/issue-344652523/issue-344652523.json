{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9851", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9851/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9851/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9851/events", "html_url": "https://github.com/pytorch/pytorch/pull/9851", "id": 344652523, "node_id": "MDExOlB1bGxSZXF1ZXN0MjAzOTk4NDc1", "number": 9851, "title": "Future-proofing Embedding.cu against heuristic changes", "user": {"login": "mcarilli", "id": 7799218, "node_id": "MDQ6VXNlcjc3OTkyMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7799218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarilli", "html_url": "https://github.com/mcarilli", "followers_url": "https://api.github.com/users/mcarilli/followers", "following_url": "https://api.github.com/users/mcarilli/following{/other_user}", "gists_url": "https://api.github.com/users/mcarilli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarilli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarilli/subscriptions", "organizations_url": "https://api.github.com/users/mcarilli/orgs", "repos_url": "https://api.github.com/users/mcarilli/repos", "events_url": "https://api.github.com/users/mcarilli/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarilli/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-26T00:29:10Z", "updated_at": "2018-08-28T18:39:14Z", "closed_at": "2018-08-28T17:38:56Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9851", "html_url": "https://github.com/pytorch/pytorch/pull/9851", "diff_url": "https://github.com/pytorch/pytorch/pull/9851.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9851.patch"}, "body_html": "<p>Currently, the heuristic in aten/native/cuda/Embedding.cu only chooses my embedding_backward_feature_kernel if ntokens &lt;= 768.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17164548\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/FDecaYed\">@FDecaYed</a> pointed out that my bounds checking logic fails if the kernel is launched with ntokens &gt; 1024.  Currently, this never occurs, but this PR applies his fix so that the kernel does support ntokens &gt; 1024, allowing the \"768\" heuristic to be adjusted in the future without breaking anything.</p>\n<p>THCUNN/LookupTable.cu uses the same kernel, with the same heuristic.  I didn't apply the fix here because I strongly suspect this is dead code (at least, I was unable to find a Python-side exposure for it).  Do you mind if we attempt stripping this file out, as a separate PR?</p>", "body_text": "Currently, the heuristic in aten/native/cuda/Embedding.cu only chooses my embedding_backward_feature_kernel if ntokens <= 768.\n@FDecaYed pointed out that my bounds checking logic fails if the kernel is launched with ntokens > 1024.  Currently, this never occurs, but this PR applies his fix so that the kernel does support ntokens > 1024, allowing the \"768\" heuristic to be adjusted in the future without breaking anything.\nTHCUNN/LookupTable.cu uses the same kernel, with the same heuristic.  I didn't apply the fix here because I strongly suspect this is dead code (at least, I was unable to find a Python-side exposure for it).  Do you mind if we attempt stripping this file out, as a separate PR?", "body": "Currently, the heuristic in aten/native/cuda/Embedding.cu only chooses my embedding_backward_feature_kernel if ntokens <= 768.  \r\n\r\n@FDecaYed pointed out that my bounds checking logic fails if the kernel is launched with ntokens > 1024.  Currently, this never occurs, but this PR applies his fix so that the kernel does support ntokens > 1024, allowing the \"768\" heuristic to be adjusted in the future without breaking anything.  \r\n\r\nTHCUNN/LookupTable.cu uses the same kernel, with the same heuristic.  I didn't apply the fix here because I strongly suspect this is dead code (at least, I was unable to find a Python-side exposure for it).  Do you mind if we attempt stripping this file out, as a separate PR?"}