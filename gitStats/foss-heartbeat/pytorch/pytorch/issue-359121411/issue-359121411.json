{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11521", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11521/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11521/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11521/events", "html_url": "https://github.com/pytorch/pytorch/issues/11521", "id": 359121411, "node_id": "MDU6SXNzdWUzNTkxMjE0MTE=", "number": 11521, "title": "onnx convert issue", "user": {"login": "ShuangLiu1992", "id": 11735658, "node_id": "MDQ6VXNlcjExNzM1NjU4", "avatar_url": "https://avatars3.githubusercontent.com/u/11735658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShuangLiu1992", "html_url": "https://github.com/ShuangLiu1992", "followers_url": "https://api.github.com/users/ShuangLiu1992/followers", "following_url": "https://api.github.com/users/ShuangLiu1992/following{/other_user}", "gists_url": "https://api.github.com/users/ShuangLiu1992/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShuangLiu1992/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShuangLiu1992/subscriptions", "organizations_url": "https://api.github.com/users/ShuangLiu1992/orgs", "repos_url": "https://api.github.com/users/ShuangLiu1992/repos", "events_url": "https://api.github.com/users/ShuangLiu1992/events{/privacy}", "received_events_url": "https://api.github.com/users/ShuangLiu1992/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-11T16:19:46Z", "updated_at": "2018-09-17T18:05:01Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>when converting model to onnx format, .view function with dynamic shape (-1) will be turned into the following. some inference library cannot handle reshape like this and expect the shape to be specified by the reshape layer instead of using a dynamic input.<br>\n%15 : Dynamic = onnx::Constant<a href=\"\">value=  -1  320 [ CPULongTensor{2} ]</a>, scope: Net<br>\n%16 : Float(64, 320) = onnx::Reshape(%14, %15), scope: Net</p>\n<p>code example:</p>\n<pre><code>class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)\n\nx = Variable(torch.randn(x.shape, requires_grad=True))\n\n# Export the model\ntorch_out = torch.onnx.export(model,\n                              x.to(device), \n                              \"../data/mnist.bin\",\n                              export_params=True,\n                              input_names=[\"input\"], \n                              output_names=[\"output\"],\n                              verbose = True)\n</code></pre>", "body_text": "when converting model to onnx format, .view function with dynamic shape (-1) will be turned into the following. some inference library cannot handle reshape like this and expect the shape to be specified by the reshape layer instead of using a dynamic input.\n%15 : Dynamic = onnx::Constantvalue=  -1  320 [ CPULongTensor{2} ], scope: Net\n%16 : Float(64, 320) = onnx::Reshape(%14, %15), scope: Net\ncode example:\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)\n\nx = Variable(torch.randn(x.shape, requires_grad=True))\n\n# Export the model\ntorch_out = torch.onnx.export(model,\n                              x.to(device), \n                              \"../data/mnist.bin\",\n                              export_params=True,\n                              input_names=[\"input\"], \n                              output_names=[\"output\"],\n                              verbose = True)", "body": "when converting model to onnx format, .view function with dynamic shape (-1) will be turned into the following. some inference library cannot handle reshape like this and expect the shape to be specified by the reshape layer instead of using a dynamic input.\r\n%15 : Dynamic = onnx::Constant[value=  -1  320 [ CPULongTensor{2} ]](), scope: Net\r\n%16 : Float(64, 320) = onnx::Reshape(%14, %15), scope: Net\r\n\r\n\r\ncode example:\r\n\r\n```\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n        self.conv2_drop = nn.Dropout2d()\r\n        self.fc1 = nn.Linear(320, 50)\r\n        self.fc2 = nn.Linear(50, 10)\r\n\r\n    def forward(self, x):\r\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\r\n        x = x.view(-1, 320)\r\n        x = F.relu(self.fc1(x))\r\n        x = F.dropout(x, training=self.training)\r\n        x = self.fc2(x)\r\n        return F.softmax(x, dim=1)\r\n\r\nx = Variable(torch.randn(x.shape, requires_grad=True))\r\n\r\n# Export the model\r\ntorch_out = torch.onnx.export(model,\r\n                              x.to(device), \r\n                              \"../data/mnist.bin\",\r\n                              export_params=True,\r\n                              input_names=[\"input\"], \r\n                              output_names=[\"output\"],\r\n                              verbose = True)\r\n```"}