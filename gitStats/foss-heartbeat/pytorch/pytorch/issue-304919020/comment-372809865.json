{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/372809865", "html_url": "https://github.com/pytorch/pytorch/pull/5747#issuecomment-372809865", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5747", "id": 372809865, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjgwOTg2NQ==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-13T20:37:11Z", "updated_at": "2018-03-13T20:37:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>MeanBackward1 struct:</p>\n<pre><code>struct MeanBackward1 : public TraceableFunction {\n  using TraceableFunction::TraceableFunction;\n  variable_list apply(const variable_list&amp; grads) override;\n  std::string name() override { return \"MeanBackward1\"; }\n  void release_variables() override {\n\n  }\n\n  std::vector&lt;int64_t&gt; self_sizes;\n  int64_t self_numel;\n\n};\n</code></pre>\n<p>forward:</p>\n<pre><code>Tensor VariableType::mean(const Tensor &amp; self) const {\n  profiler::RecordFunction profiler(\"mean\");\n  auto&amp; self_ = unpack(self, \"self\", 0);\n  std::shared_ptr&lt;MeanBackward1&gt; grad_fn;\n  if (compute_requires_grad( self )) {\n    grad_fn = std::make_shared&lt;MeanBackward1&gt;();\n    grad_fn-&gt;set_next_edges(collect_next_edges( self ));\n    grad_fn-&gt;self_sizes = self.sizes();\n    grad_fn-&gt;self_numel = self.numel();\n  }\n  jit::tracer::PreTraceInfo trace_info;\n  if (jit::tracer::isTracing( self )) {\n    trace_info = jit::tracer::preRecordTrace( \"mean\", { self } );\n\n  }\n  auto result = as_variable(baseType-&gt;mean(self_));\n  set_history(result, grad_fn);\n  if (trace_info.state != nullptr) {\n    jit::tracer::postRecordTrace( trace_info,  { result } );\n  }\n  return result;\n}\n</code></pre>\n<p>backward:</p>\n<pre><code> variable_list MeanBackward1::apply(const variable_list&amp; grads) {\n   IndexRangeGenerator gen;\n   auto self_ix = gen.range(1);\n   variable_list grad_inputs(gen.size());\n   auto&amp; grad = grads[0];\n   if (should_compute_output({ self_ix })) {\n     auto grad_result = grad.expand(self_sizes) / self_numel;\n     copy_range(grad_inputs, self_ix, grad_result);\n   }\n   return grad_inputs;\n }\n</code></pre>", "body_text": "MeanBackward1 struct:\nstruct MeanBackward1 : public TraceableFunction {\n  using TraceableFunction::TraceableFunction;\n  variable_list apply(const variable_list& grads) override;\n  std::string name() override { return \"MeanBackward1\"; }\n  void release_variables() override {\n\n  }\n\n  std::vector<int64_t> self_sizes;\n  int64_t self_numel;\n\n};\n\nforward:\nTensor VariableType::mean(const Tensor & self) const {\n  profiler::RecordFunction profiler(\"mean\");\n  auto& self_ = unpack(self, \"self\", 0);\n  std::shared_ptr<MeanBackward1> grad_fn;\n  if (compute_requires_grad( self )) {\n    grad_fn = std::make_shared<MeanBackward1>();\n    grad_fn->set_next_edges(collect_next_edges( self ));\n    grad_fn->self_sizes = self.sizes();\n    grad_fn->self_numel = self.numel();\n  }\n  jit::tracer::PreTraceInfo trace_info;\n  if (jit::tracer::isTracing( self )) {\n    trace_info = jit::tracer::preRecordTrace( \"mean\", { self } );\n\n  }\n  auto result = as_variable(baseType->mean(self_));\n  set_history(result, grad_fn);\n  if (trace_info.state != nullptr) {\n    jit::tracer::postRecordTrace( trace_info,  { result } );\n  }\n  return result;\n}\n\nbackward:\n variable_list MeanBackward1::apply(const variable_list& grads) {\n   IndexRangeGenerator gen;\n   auto self_ix = gen.range(1);\n   variable_list grad_inputs(gen.size());\n   auto& grad = grads[0];\n   if (should_compute_output({ self_ix })) {\n     auto grad_result = grad.expand(self_sizes) / self_numel;\n     copy_range(grad_inputs, self_ix, grad_result);\n   }\n   return grad_inputs;\n }", "body": "MeanBackward1 struct:\r\n```\r\nstruct MeanBackward1 : public TraceableFunction {\r\n  using TraceableFunction::TraceableFunction;\r\n  variable_list apply(const variable_list& grads) override;\r\n  std::string name() override { return \"MeanBackward1\"; }\r\n  void release_variables() override {\r\n\r\n  }\r\n\r\n  std::vector<int64_t> self_sizes;\r\n  int64_t self_numel;\r\n\r\n};\r\n```\r\n\r\nforward:\r\n```\r\nTensor VariableType::mean(const Tensor & self) const {\r\n  profiler::RecordFunction profiler(\"mean\");\r\n  auto& self_ = unpack(self, \"self\", 0);\r\n  std::shared_ptr<MeanBackward1> grad_fn;\r\n  if (compute_requires_grad( self )) {\r\n    grad_fn = std::make_shared<MeanBackward1>();\r\n    grad_fn->set_next_edges(collect_next_edges( self ));\r\n    grad_fn->self_sizes = self.sizes();\r\n    grad_fn->self_numel = self.numel();\r\n  }\r\n  jit::tracer::PreTraceInfo trace_info;\r\n  if (jit::tracer::isTracing( self )) {\r\n    trace_info = jit::tracer::preRecordTrace( \"mean\", { self } );\r\n\r\n  }\r\n  auto result = as_variable(baseType->mean(self_));\r\n  set_history(result, grad_fn);\r\n  if (trace_info.state != nullptr) {\r\n    jit::tracer::postRecordTrace( trace_info,  { result } );\r\n  }\r\n  return result;\r\n}\r\n```\r\n\r\nbackward:\r\n```\r\n variable_list MeanBackward1::apply(const variable_list& grads) {\r\n   IndexRangeGenerator gen;\r\n   auto self_ix = gen.range(1);\r\n   variable_list grad_inputs(gen.size());\r\n   auto& grad = grads[0];\r\n   if (should_compute_output({ self_ix })) {\r\n     auto grad_result = grad.expand(self_sizes) / self_numel;\r\n     copy_range(grad_inputs, self_ix, grad_result);\r\n   }\r\n   return grad_inputs;\r\n }\r\n```"}