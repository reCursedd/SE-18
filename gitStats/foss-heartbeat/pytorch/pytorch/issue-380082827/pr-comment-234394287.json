{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234394287", "pull_request_review_id": 176038343, "id": 234394287, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDM5NDI4Nw==", "diff_hunk": "@@ -469,6 +503,187 @@ void testInterp() {\n   ASSERT_TRUE(exactlyEqual(outputs[1], cx));\n }\n \n+void testTHNNConv() {\n+  std::vector<int64_t> input_size = {4, 3, 15, 17}; // B x C x H x W\n+  std::vector<int64_t> kernel_size = {3, 5};\n+  std::vector<int64_t> stride = {1, 2};\n+  std::vector<int64_t> padding = {2, 1};\n+  constexpr int out_channels = 5;\n+\n+  // make inputs\n+  at::Tensor input = torch::randn(input_size);\n+  at::Tensor weight = torch::randn({out_channels, input_size[1], kernel_size[0], kernel_size[1]});\n+  at::Tensor bias = torch::randn({out_channels});\n+\n+  // run forward eagerly\n+  at::Tensor output, finput, fgradinput;\n+  std::tie(output, finput, fgradinput) = at::thnn_conv2d_forward(input, weight, kernel_size,\n+\t\t\t\t\t\t\t\t bias, stride, padding);\n+\n+  // make grad_outputs\n+  at::Tensor grad_output = torch::randn_like(output);\n+  at::Tensor grad_finput = torch::zeros_like(finput);\n+  at::Tensor grad_fgradinput = torch::zeros_like(fgradinput);\n+\n+  // run backward eagerly\n+  at::Tensor grad_input, grad_weight, grad_bias;\n+  std::tie(grad_input, grad_weight, grad_bias) = at::thnn_conv2d_backward(grad_output, input, weight,\n+\t\t\t\t\t\t\t\t\t  kernel_size, stride, padding,\n+\t\t\t\t\t\t\t\t\t  finput, fgradinput, {true, true, true});\n+\n+  // make JIT graph\n+  auto graph = std::make_shared<Graph>();\n+  auto ksz_val = graph->insertConstant(IValue(kernel_size));\n+  auto kst_val = graph->insertConstant(IValue(stride));\n+  auto pad_val = graph->insertConstant(IValue(padding));\n+\n+  auto inputg = graph->addInput(\"self\");\n+  auto weightg = graph->addInput(\"weight\");\n+  auto biasg = graph->addInput(\"bias\");\n+\n+  Value* conv = graph->insert(aten::thnn_conv2d_forward, {inputg, weightg, ksz_val, biasg, kst_val, pad_val});\n+  auto outputs = conv->node()->outputs();\n+  for (auto output : outputs) {\n+    graph->registerOutput(output);\n+  }\n+  LowerAllTuples(graph);\n+  graph->lint();\n+\n+  // differentiate JIT graph\n+  EliminateDeadCode(graph); // Tracing of some ops depends on the DCE trick\n+  ConstantPropagation(graph);\n+  auto grad_spec = differentiate(graph);\n+  LowerGradOf(*grad_spec.df);\n+\n+  // prepare JIT inputs / gradients\n+  tensor_list tensors_in;\n+  tensors_in.push_back(input);\n+  tensors_in.push_back(weight);\n+  tensors_in.push_back(bias);\n+\n+  tensor_list tensor_grads_in;\n+  tensor_grads_in.push_back(grad_output);\n+  tensor_grads_in.push_back(grad_finput);\n+  tensor_grads_in.push_back(grad_fgradinput);\n+\n+  // Get outputs from the interpreter\n+  tensor_list tensors_out, tensor_grads_out;\n+  std::tie(tensors_out, tensor_grads_out) =\n+    runGradient(grad_spec, tensors_in, tensor_grads_in);\n+\n+  // prepare expected structs\n+  tensor_list expected_tensors_out, expected_tensor_grads_out;\n+  expected_tensors_out.push_back(output);\n+  expected_tensors_out.push_back(finput);\n+  expected_tensors_out.push_back(fgradinput);\n+  expected_tensor_grads_out.push_back(grad_input);\n+  expected_tensor_grads_out.push_back(grad_weight);\n+  expected_tensor_grads_out.push_back(grad_bias);\n+\n+  // Compare results\n+  assertAllClose(tensors_out, expected_tensors_out);\n+  assertAllClose(tensor_grads_out, expected_tensor_grads_out);\n+}\n+\n+void testATenNativeBatchNorm() {", "path": "test/cpp/jit/tests.h", "position": 134, "original_position": 134, "commit_id": "f49acbcea527bb8d4b51258715ac243f6f6d7d72", "original_commit_id": "1b2147d4c9bc6e87a844693d460bd371306ac823", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "These are kinda verbose but I don't see a better way to do until we have the ability to parse IR directly for these kinds of tests.", "created_at": "2018-11-17T03:13:35Z", "updated_at": "2018-11-23T15:55:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/13888#discussion_r234394287", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13888", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234394287"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13888#discussion_r234394287"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13888"}}, "body_html": "<p>These are kinda verbose but I don't see a better way to do until we have the ability to parse IR directly for these kinds of tests.</p>", "body_text": "These are kinda verbose but I don't see a better way to do until we have the ability to parse IR directly for these kinds of tests."}