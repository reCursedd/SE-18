{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1810", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1810/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1810/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1810/events", "html_url": "https://github.com/pytorch/pytorch/issues/1810", "id": 236153898, "node_id": "MDU6SXNzdWUyMzYxNTM4OTg=", "number": 1810, "title": "\"nan\" behaves differently in CPU and GPU", "user": {"login": "ShigekiKarita", "id": 6745326, "node_id": "MDQ6VXNlcjY3NDUzMjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/6745326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShigekiKarita", "html_url": "https://github.com/ShigekiKarita", "followers_url": "https://api.github.com/users/ShigekiKarita/followers", "following_url": "https://api.github.com/users/ShigekiKarita/following{/other_user}", "gists_url": "https://api.github.com/users/ShigekiKarita/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShigekiKarita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShigekiKarita/subscriptions", "organizations_url": "https://api.github.com/users/ShigekiKarita/orgs", "repos_url": "https://api.github.com/users/ShigekiKarita/repos", "events_url": "https://api.github.com/users/ShigekiKarita/events{/privacy}", "received_events_url": "https://api.github.com/users/ShigekiKarita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-06-15T11:06:09Z", "updated_at": "2017-10-25T08:19:48Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Should I report this to torch repository?</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.topk(torch.FloatTensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>),<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>]), <span class=\"pl-c1\">1</span>)\n(\n  <span class=\"pl-c1\">2</span>\n [torch.FloatTensor of size <span class=\"pl-c1\">1</span>], \n  <span class=\"pl-c1\">2</span>\n [torch.LongTensor of size <span class=\"pl-c1\">1</span>])\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.topk(torch.cuda.FloatTensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>),<span class=\"pl-c1\">2</span>]), <span class=\"pl-c1\">1</span>)\n(\n nan\n [torch.cuda.FloatTensor of size <span class=\"pl-c1\">1</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)], \n  <span class=\"pl-c1\">9.2054e+18</span>\n [torch.cuda.LongTensor of size <span class=\"pl-c1\">1</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)])</pre></div>\n<p>In CPU, <code>topk</code> seems to ignore \"nan\" and its indices from result.<br>\nIn GPU, <code>topk</code> with \"nan\" is kind of undefined behavior?</p>\n<p>and other examples</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.max(torch.cuda.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\n<span class=\"pl-c1\">1.0</span>\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.max(torch.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\nnan\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.min(torch.cuda.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\n<span class=\"pl-c1\">1.0</span>\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.min(torch.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\nnan</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.sort(torch.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\n(\n nan\n   <span class=\"pl-c1\">1</span>\n [torch.FloatTensor of size <span class=\"pl-c1\">2</span>], \n  <span class=\"pl-c1\">0</span>\n  <span class=\"pl-c1\">1</span>\n [torch.LongTensor of size <span class=\"pl-c1\">2</span>])\n\n<span class=\"pl-k\">&gt;&gt;</span> torch.sort(torch.cuda.FloatTensor([<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nan<span class=\"pl-pds\">\"</span></span>), <span class=\"pl-c1\">1</span>]))\n(\n   <span class=\"pl-c1\">1</span>\n nan\n [torch.cuda.FloatTensor of size <span class=\"pl-c1\">2</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)], \n  <span class=\"pl-c1\">1</span>\n  <span class=\"pl-c1\">0</span>\n [torch.cuda.LongTensor of size <span class=\"pl-c1\">2</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)])</pre></div>", "body_text": "Should I report this to torch repository?\n>>> torch.topk(torch.FloatTensor([-1,float(\"nan\"),2, 1]), 1)\n(\n  2\n [torch.FloatTensor of size 1], \n  2\n [torch.LongTensor of size 1])\n\n>>> torch.topk(torch.cuda.FloatTensor([-1,float(\"nan\"),2]), 1)\n(\n nan\n [torch.cuda.FloatTensor of size 1 (GPU 0)], \n  9.2054e+18\n [torch.cuda.LongTensor of size 1 (GPU 0)])\nIn CPU, topk seems to ignore \"nan\" and its indices from result.\nIn GPU, topk with \"nan\" is kind of undefined behavior?\nand other examples\n>>> torch.max(torch.cuda.FloatTensor([float(\"nan\"), 1]))\n1.0\n\n>>> torch.max(torch.FloatTensor([float(\"nan\"), 1]))\nnan\n\n>>> torch.min(torch.cuda.FloatTensor([float(\"nan\"), 1]))\n1.0\n\n>>> torch.min(torch.FloatTensor([float(\"nan\"), 1]))\nnan\n>>> torch.sort(torch.FloatTensor([float(\"nan\"), 1]))\n(\n nan\n   1\n [torch.FloatTensor of size 2], \n  0\n  1\n [torch.LongTensor of size 2])\n\n>> torch.sort(torch.cuda.FloatTensor([float(\"nan\"), 1]))\n(\n   1\n nan\n [torch.cuda.FloatTensor of size 2 (GPU 0)], \n  1\n  0\n [torch.cuda.LongTensor of size 2 (GPU 0)])", "body": "Should I report this to torch repository?\r\n\r\n``` python\r\n>>> torch.topk(torch.FloatTensor([-1,float(\"nan\"),2, 1]), 1)\r\n(\r\n  2\r\n [torch.FloatTensor of size 1], \r\n  2\r\n [torch.LongTensor of size 1])\r\n\r\n>>> torch.topk(torch.cuda.FloatTensor([-1,float(\"nan\"),2]), 1)\r\n(\r\n nan\r\n [torch.cuda.FloatTensor of size 1 (GPU 0)], \r\n  9.2054e+18\r\n [torch.cuda.LongTensor of size 1 (GPU 0)])\r\n```\r\n\r\nIn CPU, `topk` seems to ignore \"nan\" and its indices from result.\r\nIn GPU, `topk` with \"nan\" is kind of undefined behavior?\r\n\r\nand other examples \r\n\r\n``` python\r\n>>> torch.max(torch.cuda.FloatTensor([float(\"nan\"), 1]))\r\n1.0\r\n\r\n>>> torch.max(torch.FloatTensor([float(\"nan\"), 1]))\r\nnan\r\n\r\n>>> torch.min(torch.cuda.FloatTensor([float(\"nan\"), 1]))\r\n1.0\r\n\r\n>>> torch.min(torch.FloatTensor([float(\"nan\"), 1]))\r\nnan\r\n```\r\n\r\n``` python\r\n>>> torch.sort(torch.FloatTensor([float(\"nan\"), 1]))\r\n(\r\n nan\r\n   1\r\n [torch.FloatTensor of size 2], \r\n  0\r\n  1\r\n [torch.LongTensor of size 2])\r\n\r\n>> torch.sort(torch.cuda.FloatTensor([float(\"nan\"), 1]))\r\n(\r\n   1\r\n nan\r\n [torch.cuda.FloatTensor of size 2 (GPU 0)], \r\n  1\r\n  0\r\n [torch.cuda.LongTensor of size 2 (GPU 0)])\r\n```\r\n"}