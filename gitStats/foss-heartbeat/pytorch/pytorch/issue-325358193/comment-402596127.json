{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/402596127", "html_url": "https://github.com/pytorch/pytorch/issues/7760#issuecomment-402596127", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7760", "id": 402596127, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjU5NjEyNw==", "user": {"login": "Stonesjtu", "id": 4556044, "node_id": "MDQ6VXNlcjQ1NTYwNDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4556044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stonesjtu", "html_url": "https://github.com/Stonesjtu", "followers_url": "https://api.github.com/users/Stonesjtu/followers", "following_url": "https://api.github.com/users/Stonesjtu/following{/other_user}", "gists_url": "https://api.github.com/users/Stonesjtu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stonesjtu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stonesjtu/subscriptions", "organizations_url": "https://api.github.com/users/Stonesjtu/orgs", "repos_url": "https://api.github.com/users/Stonesjtu/repos", "events_url": "https://api.github.com/users/Stonesjtu/events{/privacy}", "received_events_url": "https://api.github.com/users/Stonesjtu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-05T03:21:49Z", "updated_at": "2018-07-05T03:23:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'd like to add a comment in case someone is faced with the same problem as me. (It's already fixed in master, but exists in 0.4.0 pip version)</p>\n<p>I once run with</p>\n<pre><code>big_tensor = torch.Tensor(10000, 300).cuda()\ngrad_clip_norm_(big_tensor)\n</code></pre>\n<p>Besides unnormal gradient clipping,  this slows down my code drastically because the <code>for</code> loop iterates the CUDA tensor over and over again, along with many <strong>DeviceToHost</strong> transferring.</p>", "body_text": "I'd like to add a comment in case someone is faced with the same problem as me. (It's already fixed in master, but exists in 0.4.0 pip version)\nI once run with\nbig_tensor = torch.Tensor(10000, 300).cuda()\ngrad_clip_norm_(big_tensor)\n\nBesides unnormal gradient clipping,  this slows down my code drastically because the for loop iterates the CUDA tensor over and over again, along with many DeviceToHost transferring.", "body": "I'd like to add a comment in case someone is faced with the same problem as me. (It's already fixed in master, but exists in 0.4.0 pip version)\r\n\r\nI once run with\r\n```\r\nbig_tensor = torch.Tensor(10000, 300).cuda()\r\ngrad_clip_norm_(big_tensor)\r\n```\r\nBesides unnormal gradient clipping,  this slows down my code drastically because the `for` loop iterates the CUDA tensor over and over again, along with many **DeviceToHost** transferring."}