{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10500", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10500/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10500/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10500/events", "html_url": "https://github.com/pytorch/pytorch/pull/10500", "id": 350261149, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA4MTU0NTQ2", "number": 10500, "title": "[jit][script] mutable list support", "user": {"login": "suo", "id": 1617424, "node_id": "MDQ6VXNlcjE2MTc0MjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/1617424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suo", "html_url": "https://github.com/suo", "followers_url": "https://api.github.com/users/suo/followers", "following_url": "https://api.github.com/users/suo/following{/other_user}", "gists_url": "https://api.github.com/users/suo/gists{/gist_id}", "starred_url": "https://api.github.com/users/suo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suo/subscriptions", "organizations_url": "https://api.github.com/users/suo/orgs", "repos_url": "https://api.github.com/users/suo/repos", "events_url": "https://api.github.com/users/suo/events{/privacy}", "received_events_url": "https://api.github.com/users/suo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-08-14T02:43:12Z", "updated_at": "2018-11-23T15:49:21Z", "closed_at": "2018-08-16T19:17:25Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10500", "html_url": "https://github.com/pytorch/pytorch/pull/10500", "diff_url": "https://github.com/pytorch/pytorch/pull/10500.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10500.patch"}, "body_html": "<p>Basic support for token-based modeling of effects. The comments are pretty self explanatory, but the tldr is that there's a pass that annotates the IR to make effectful ops explicit. I also added an <code>append()</code> builtin to demonstrate how it might be used.</p>\n<p>Some notes:</p>\n<ol>\n<li>Instead of transforming a mutating op directly to do the return/bind, there's a primitive <code>MemoryFence</code> that wraps the op. This is to preserve the original function schema of the op (otherwise, optimizations have to know how to emit world tokens).</li>\n<li>Right now, world token handling spills into the interpreter. It's not a very significant cost, but I plan to write a pass to erase all the annotation so that there's no runtime overhead to all the token passing.</li>\n</ol>", "body_text": "Basic support for token-based modeling of effects. The comments are pretty self explanatory, but the tldr is that there's a pass that annotates the IR to make effectful ops explicit. I also added an append() builtin to demonstrate how it might be used.\nSome notes:\n\nInstead of transforming a mutating op directly to do the return/bind, there's a primitive MemoryFence that wraps the op. This is to preserve the original function schema of the op (otherwise, optimizations have to know how to emit world tokens).\nRight now, world token handling spills into the interpreter. It's not a very significant cost, but I plan to write a pass to erase all the annotation so that there's no runtime overhead to all the token passing.", "body": "Basic support for token-based modeling of effects. The comments are pretty self explanatory, but the tldr is that there's a pass that annotates the IR to make effectful ops explicit. I also added an `append()` builtin to demonstrate how it might be used.\r\n\r\nSome notes:\r\n1. Instead of transforming a mutating op directly to do the return/bind, there's a primitive `MemoryFence` that wraps the op. This is to preserve the original function schema of the op (otherwise, optimizations have to know how to emit world tokens).\r\n2. Right now, world token handling spills into the interpreter. It's not a very significant cost, but I plan to write a pass to erase all the annotation so that there's no runtime overhead to all the token passing.\r\n"}