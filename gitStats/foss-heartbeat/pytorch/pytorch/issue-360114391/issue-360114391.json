{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11678", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11678/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11678/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11678/events", "html_url": "https://github.com/pytorch/pytorch/issues/11678", "id": 360114391, "node_id": "MDU6SXNzdWUzNjAxMTQzOTE=", "number": 11678, "title": "[caffe2] adam_op implementation is incorrect.", "user": {"login": "yubo-zhang", "id": 14241216, "node_id": "MDQ6VXNlcjE0MjQxMjE2", "avatar_url": "https://avatars2.githubusercontent.com/u/14241216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yubo-zhang", "html_url": "https://github.com/yubo-zhang", "followers_url": "https://api.github.com/users/yubo-zhang/followers", "following_url": "https://api.github.com/users/yubo-zhang/following{/other_user}", "gists_url": "https://api.github.com/users/yubo-zhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yubo-zhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yubo-zhang/subscriptions", "organizations_url": "https://api.github.com/users/yubo-zhang/orgs", "repos_url": "https://api.github.com/users/yubo-zhang/repos", "events_url": "https://api.github.com/users/yubo-zhang/events{/privacy}", "received_events_url": "https://api.github.com/users/yubo-zhang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-14T00:32:47Z", "updated_at": "2018-09-14T00:32:48Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>The formula  currently implemented in adam_op.h and adam_op is:</p>\n<pre><code>t = iters + 1\ncorrected_local_rate = lr * sqrt(1 - power(beta2, t)) /(1 - power(beta1, t))\nm1_o = (beta1 * m1) + (1 - beta1) * grad\nm2_o = (beta2 * m2) + (1 - beta2) * np.square(grad)\ngrad_o = corrected_local_rate * m1_o /(sqrt(m2_o) + epsilon)\nparam_o = param + grad_o\n</code></pre>\n<p>which is different from the original paper, and will lead to explosion during training. The update of param_o is supposed to be param_o = param - grad_o. I already validated the result through experiments. Thanks!</p>", "body_text": "The formula  currently implemented in adam_op.h and adam_op is:\nt = iters + 1\ncorrected_local_rate = lr * sqrt(1 - power(beta2, t)) /(1 - power(beta1, t))\nm1_o = (beta1 * m1) + (1 - beta1) * grad\nm2_o = (beta2 * m2) + (1 - beta2) * np.square(grad)\ngrad_o = corrected_local_rate * m1_o /(sqrt(m2_o) + epsilon)\nparam_o = param + grad_o\n\nwhich is different from the original paper, and will lead to explosion during training. The update of param_o is supposed to be param_o = param - grad_o. I already validated the result through experiments. Thanks!", "body": "The formula  currently implemented in adam_op.h and adam_op is:\r\n\r\n    t = iters + 1\r\n    corrected_local_rate = lr * sqrt(1 - power(beta2, t)) /(1 - power(beta1, t))\r\n    m1_o = (beta1 * m1) + (1 - beta1) * grad\r\n    m2_o = (beta2 * m2) + (1 - beta2) * np.square(grad)\r\n    grad_o = corrected_local_rate * m1_o /(sqrt(m2_o) + epsilon)\r\n    param_o = param + grad_o\r\n\r\nwhich is different from the original paper, and will lead to explosion during training. The update of param_o is supposed to be param_o = param - grad_o. I already validated the result through experiments. Thanks!"}