{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2914", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2914/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2914/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2914/events", "html_url": "https://github.com/pytorch/pytorch/issues/2914", "id": 261854558, "node_id": "MDU6SXNzdWUyNjE4NTQ1NTg=", "number": 2914, "title": "Bug when \u201cnumpy.str_\u201d occur in dataloader using default_collate", "user": {"login": "JindongJiang", "id": 16209724, "node_id": "MDQ6VXNlcjE2MjA5NzI0", "avatar_url": "https://avatars3.githubusercontent.com/u/16209724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JindongJiang", "html_url": "https://github.com/JindongJiang", "followers_url": "https://api.github.com/users/JindongJiang/followers", "following_url": "https://api.github.com/users/JindongJiang/following{/other_user}", "gists_url": "https://api.github.com/users/JindongJiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/JindongJiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JindongJiang/subscriptions", "organizations_url": "https://api.github.com/users/JindongJiang/orgs", "repos_url": "https://api.github.com/users/JindongJiang/repos", "events_url": "https://api.github.com/users/JindongJiang/events{/privacy}", "received_events_url": "https://api.github.com/users/JindongJiang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-30T16:27:42Z", "updated_at": "2017-11-08T15:02:09Z", "closed_at": "2017-11-08T15:02:09Z", "author_association": "NONE", "body_html": "<p>If, for some reason, my <code>sample</code> contains data of type <code>numpy.str_</code> instead of <code>str</code>, e.g., <code>type(sample['filepath']) == type(numpy.str_)</code> then when it passed to <code>DataLoader</code>, a <code>KeyError</code> would occur. I checked and figure that maybe I found a bug. Consider function <code>default_collate</code> below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">default_collate</span>(<span class=\"pl-smi\">batch</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Puts each data field into a tensor with outer dimension batch size<span class=\"pl-pds\">\"</span></span>\n    <span class=\"pl-k\">if</span> torch.is_tensor(batch[<span class=\"pl-c1\">0</span>]):\n        out <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        <span class=\"pl-k\">if</span> _use_shared_memory:\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> If we're in a background process, concatenate directly into a</span>\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> shared memory tensor to avoid an extra copy</span>\n            numel <span class=\"pl-k\">=</span> <span class=\"pl-c1\">sum</span>([x.numel() <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> batch])\n            storage <span class=\"pl-k\">=</span> batch[<span class=\"pl-c1\">0</span>].storage()._new_shared(numel)\n            out <span class=\"pl-k\">=</span> batch[<span class=\"pl-c1\">0</span>].new(storage)\n        <span class=\"pl-k\">return</span> torch.stack(batch, <span class=\"pl-c1\">0</span>, <span class=\"pl-v\">out</span><span class=\"pl-k\">=</span>out)\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">type</span>(batch[<span class=\"pl-c1\">0</span>]).<span class=\"pl-c1\">__module__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>numpy<span class=\"pl-pds\">'</span></span>:\n        elem <span class=\"pl-k\">=</span> batch[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">type</span>(elem).<span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ndarray<span class=\"pl-pds\">'</span></span>:\n            <span class=\"pl-k\">return</span> torch.stack([torch.from_numpy(b) <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> batch], <span class=\"pl-c1\">0</span>)\n        <span class=\"pl-k\">if</span> elem.shape <span class=\"pl-k\">==</span> ():  <span class=\"pl-c\"><span class=\"pl-c\">#</span> scalars</span>\n            py_type <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span> <span class=\"pl-k\">if</span> elem.dtype.name.startswith(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">else</span> <span class=\"pl-c1\">int</span>\n            <span class=\"pl-k\">return</span> numpy_type_map[elem.dtype.name](<span class=\"pl-c1\">list</span>(<span class=\"pl-c1\">map</span>(py_type, batch)))\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(batch[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">int</span>):\n        <span class=\"pl-k\">return</span> torch.LongTensor(batch)\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(batch[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">float</span>):\n        <span class=\"pl-k\">return</span> torch.DoubleTensor(batch)\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(batch[<span class=\"pl-c1\">0</span>], string_classes):\n        <span class=\"pl-k\">return</span> batch\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(batch[<span class=\"pl-c1\">0</span>], collections.Mapping):\n        <span class=\"pl-k\">return</span> {key: default_collate([d[key] <span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> batch]) <span class=\"pl-k\">for</span> key <span class=\"pl-k\">in</span> batch[<span class=\"pl-c1\">0</span>]}\n    <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(batch[<span class=\"pl-c1\">0</span>], collections.Sequence):\n        transposed <span class=\"pl-k\">=</span> <span class=\"pl-c1\">zip</span>(<span class=\"pl-k\">*</span>batch)\n        <span class=\"pl-k\">return</span> [default_collate(samples) <span class=\"pl-k\">for</span> samples <span class=\"pl-k\">in</span> transposed]\n\n    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">TypeError</span>((<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>batch must contain tensors, numbers, dicts or lists; found <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>\n                     .format(<span class=\"pl-c1\">type</span>(batch[<span class=\"pl-c1\">0</span>]))))</pre></div>\n<p>When the data is a <code>numpy.str_</code>, it would pass <code>elif type(batch[0]).__module__ == 'numpy':</code> and then treated like either a 'ndarray' or a 'float' scale. What I should do is set my <code>sample['filepath'] = str(sample['filepath'])</code>, but it would be nice if the function could at least giving more information about the error.</p>", "body_text": "If, for some reason, my sample contains data of type numpy.str_ instead of str, e.g., type(sample['filepath']) == type(numpy.str_) then when it passed to DataLoader, a KeyError would occur. I checked and figure that maybe I found a bug. Consider function default_collate below:\ndef default_collate(batch):\n    \"Puts each data field into a tensor with outer dimension batch size\"\n    if torch.is_tensor(batch[0]):\n        out = None\n        if _use_shared_memory:\n            # If we're in a background process, concatenate directly into a\n            # shared memory tensor to avoid an extra copy\n            numel = sum([x.numel() for x in batch])\n            storage = batch[0].storage()._new_shared(numel)\n            out = batch[0].new(storage)\n        return torch.stack(batch, 0, out=out)\n    elif type(batch[0]).__module__ == 'numpy':\n        elem = batch[0]\n        if type(elem).__name__ == 'ndarray':\n            return torch.stack([torch.from_numpy(b) for b in batch], 0)\n        if elem.shape == ():  # scalars\n            py_type = float if elem.dtype.name.startswith('float') else int\n            return numpy_type_map[elem.dtype.name](list(map(py_type, batch)))\n    elif isinstance(batch[0], int):\n        return torch.LongTensor(batch)\n    elif isinstance(batch[0], float):\n        return torch.DoubleTensor(batch)\n    elif isinstance(batch[0], string_classes):\n        return batch\n    elif isinstance(batch[0], collections.Mapping):\n        return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n    elif isinstance(batch[0], collections.Sequence):\n        transposed = zip(*batch)\n        return [default_collate(samples) for samples in transposed]\n\n    raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\n                     .format(type(batch[0]))))\nWhen the data is a numpy.str_, it would pass elif type(batch[0]).__module__ == 'numpy': and then treated like either a 'ndarray' or a 'float' scale. What I should do is set my sample['filepath'] = str(sample['filepath']), but it would be nice if the function could at least giving more information about the error.", "body": "If, for some reason, my `sample` contains data of type `numpy.str_` instead of `str`, e.g., `type(sample['filepath']) == type(numpy.str_)` then when it passed to `DataLoader`, a `KeyError` would occur. I checked and figure that maybe I found a bug. Consider function `default_collate` below:\r\n```python\r\ndef default_collate(batch):\r\n    \"Puts each data field into a tensor with outer dimension batch size\"\r\n    if torch.is_tensor(batch[0]):\r\n        out = None\r\n        if _use_shared_memory:\r\n            # If we're in a background process, concatenate directly into a\r\n            # shared memory tensor to avoid an extra copy\r\n            numel = sum([x.numel() for x in batch])\r\n            storage = batch[0].storage()._new_shared(numel)\r\n            out = batch[0].new(storage)\r\n        return torch.stack(batch, 0, out=out)\r\n    elif type(batch[0]).__module__ == 'numpy':\r\n        elem = batch[0]\r\n        if type(elem).__name__ == 'ndarray':\r\n            return torch.stack([torch.from_numpy(b) for b in batch], 0)\r\n        if elem.shape == ():  # scalars\r\n            py_type = float if elem.dtype.name.startswith('float') else int\r\n            return numpy_type_map[elem.dtype.name](list(map(py_type, batch)))\r\n    elif isinstance(batch[0], int):\r\n        return torch.LongTensor(batch)\r\n    elif isinstance(batch[0], float):\r\n        return torch.DoubleTensor(batch)\r\n    elif isinstance(batch[0], string_classes):\r\n        return batch\r\n    elif isinstance(batch[0], collections.Mapping):\r\n        return {key: default_collate([d[key] for d in batch]) for key in batch[0]}\r\n    elif isinstance(batch[0], collections.Sequence):\r\n        transposed = zip(*batch)\r\n        return [default_collate(samples) for samples in transposed]\r\n\r\n    raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\r\n                     .format(type(batch[0]))))\r\n```\r\nWhen the data is a `numpy.str_`, it would pass `elif type(batch[0]).__module__ == 'numpy':` and then treated like either a 'ndarray' or a 'float' scale. What I should do is set my `sample['filepath'] = str(sample['filepath'])`, but it would be nice if the function could at least giving more information about the error.\r\n"}