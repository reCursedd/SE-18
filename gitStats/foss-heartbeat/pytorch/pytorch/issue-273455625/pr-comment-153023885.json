{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153023885", "pull_request_review_id": 78980400, "id": 153023885, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MzAyMzg4NQ==", "diff_hunk": "@@ -0,0 +1,24 @@\n+#pragma once\n+\n+#include <ATen/ATen.h>\n+#include \"THC/THC.h\"\n+#include \"cudnn-wrapper.h\"\n+#include \"Handles.h\"\n+\n+namespace at { namespace cudnn {\n+\n+inline void cudnnSetStreamToCurrent() {\n+  // TODO: Should we call lazyInitCUDA() or access thc_state directly?\n+  // TODO: Should getCurrentStream be a method on Context?\n+  cudnnSetStream(getCudnnHandle(), THCState_getCurrentStream(globalContext().lazyInitCUDA()));\n+}\n+\n+// TODO: Move this out to ATen proper?\n+inline Tensor contiguousIfZeroInStrides(const Tensor& t) {\n+  for (auto s : t.strides()) {\n+    if (s == 0) return t.contiguous();", "path": "aten/src/ATen/cudnn/Utils.h", "position": null, "original_position": 19, "commit_id": "6c637bca42913c8377068a1bee874b2160c7f6c1", "original_commit_id": "12677cc3784b39142c6f955b995ddcda2135b586", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "body": "I think what's going on is cudnn has a buggy check for tensor being contiguous (that is, it does not ignore stride for dimension that is equal to 1). And this function does not determine if tensor is contiguous, it makes a tensor that has a zero stride contiguous (hopefully setting strides for size=1 to cudnn't liking). If that's indeed the case, it should be commented better. ", "created_at": "2017-11-24T20:19:50Z", "updated_at": "2018-11-23T15:36:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/3666#discussion_r153023885", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3666", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153023885"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3666#discussion_r153023885"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3666"}}, "body_html": "<p>I think what's going on is cudnn has a buggy check for tensor being contiguous (that is, it does not ignore stride for dimension that is equal to 1). And this function does not determine if tensor is contiguous, it makes a tensor that has a zero stride contiguous (hopefully setting strides for size=1 to cudnn't liking). If that's indeed the case, it should be commented better.</p>", "body_text": "I think what's going on is cudnn has a buggy check for tensor being contiguous (that is, it does not ignore stride for dimension that is equal to 1). And this function does not determine if tensor is contiguous, it makes a tensor that has a zero stride contiguous (hopefully setting strides for size=1 to cudnn't liking). If that's indeed the case, it should be commented better.", "in_reply_to_id": 152955138}