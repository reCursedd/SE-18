{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/348023443", "html_url": "https://github.com/pytorch/pytorch/pull/3666#issuecomment-348023443", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3666", "id": 348023443, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODAyMzQ0Mw==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T22:50:51Z", "updated_at": "2017-11-29T22:50:51Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>There seems to be a lot of unintentional or at least surprising vector allocations in the checking code. Functions that call 5 checking functions might do 20 malloc/free pairs and 20 retain/releases just for checking. It might help to distinguish between TensorGeometries that are long term and need copies and TensorGeometries that are just a view of existing stuff and can use ArrayLists.</p>\n</blockquote>\n<p>I wrote this code assuming that small vector allocation was cheap. I suppose it's not, so I better clean it up...</p>\n<blockquote>\n<p>What remains to eliminate cudnn cpp functions and just go through aten directly for cudnn operators?</p>\n</blockquote>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Teach ATen to link with NNPack</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Port CppFunction bodies to ATen and put them through derivatives</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Port cudnn double backwards in Python to ATen</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Propagate cudnn-enabled to ATen context (patch constructed)</li>\n</ul>\n<blockquote>\n<p>Do you have any idea of the launch performance before/after this pathway to catch potential performance regressions?</p>\n</blockquote>\n<p>No, I guess I better go test this.</p>", "body_text": "There seems to be a lot of unintentional or at least surprising vector allocations in the checking code. Functions that call 5 checking functions might do 20 malloc/free pairs and 20 retain/releases just for checking. It might help to distinguish between TensorGeometries that are long term and need copies and TensorGeometries that are just a view of existing stuff and can use ArrayLists.\n\nI wrote this code assuming that small vector allocation was cheap. I suppose it's not, so I better clean it up...\n\nWhat remains to eliminate cudnn cpp functions and just go through aten directly for cudnn operators?\n\n\n Teach ATen to link with NNPack\n Port CppFunction bodies to ATen and put them through derivatives\n Port cudnn double backwards in Python to ATen\n Propagate cudnn-enabled to ATen context (patch constructed)\n\n\nDo you have any idea of the launch performance before/after this pathway to catch potential performance regressions?\n\nNo, I guess I better go test this.", "body": "> There seems to be a lot of unintentional or at least surprising vector allocations in the checking code. Functions that call 5 checking functions might do 20 malloc/free pairs and 20 retain/releases just for checking. It might help to distinguish between TensorGeometries that are long term and need copies and TensorGeometries that are just a view of existing stuff and can use ArrayLists.\r\n\r\nI wrote this code assuming that small vector allocation was cheap. I suppose it's not, so I better clean it up...\r\n\r\n> What remains to eliminate cudnn cpp functions and just go through aten directly for cudnn operators?\r\n\r\n- [ ] Teach ATen to link with NNPack\r\n- [ ] Port CppFunction bodies to ATen and put them through derivatives\r\n- [ ] Port cudnn double backwards in Python to ATen\r\n- [ ] Propagate cudnn-enabled to ATen context (patch constructed)\r\n\r\n> Do you have any idea of the launch performance before/after this pathway to catch potential performance regressions?\r\n\r\nNo, I guess I better go test this."}