{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347033250", "html_url": "https://github.com/pytorch/pytorch/pull/3666#issuecomment-347033250", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3666", "id": 347033250, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzAzMzI1MA==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-26T19:47:41Z", "updated_at": "2017-11-26T19:47:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>OMG build is finally green.</p>\n<p>Latest changelog:</p>\n<ul>\n<li>\n<p>I expanded the native yaml parser <em>just</em> enough to make it possible for me to explicitly specify the names of multiple return outputs. This allows me to use the NN autogenerated wrapper codepath, which assumes these names are coherent.</p>\n</li>\n<li>\n<p>BatchNorm input checking is now greatly expanded; I basically went through definedness, GPU, type, contiguity, size, and made sure I had checking in all of these cases. I should also expand this checking to other functions but I haven't gotten around to it yet.</p>\n</li>\n<li>\n<p>As suggested by the reviews, descriptors have lost the data pointer, and there is a new ConvolutionArgs struct which contains everything we need to do benchmarking. BTW, I noticed we don't seem to actually exercise the benchmark code in our test suite.</p>\n</li>\n<li>\n<p>I messed up the no CUDA build from deleting some necessary preprocessor ifdefs. These have been added back.</p>\n</li>\n<li>\n<p>I added a few misc warning squishes.</p>\n</li>\n<li>\n<p>I removed the \"propagate cudnn enabled to ATen\" patch, as it was failing CI in a hard to understand way. I'll PR it separately.</p>\n</li>\n</ul>\n<p>I'll squash the patchset before merge.</p>", "body_text": "OMG build is finally green.\nLatest changelog:\n\n\nI expanded the native yaml parser just enough to make it possible for me to explicitly specify the names of multiple return outputs. This allows me to use the NN autogenerated wrapper codepath, which assumes these names are coherent.\n\n\nBatchNorm input checking is now greatly expanded; I basically went through definedness, GPU, type, contiguity, size, and made sure I had checking in all of these cases. I should also expand this checking to other functions but I haven't gotten around to it yet.\n\n\nAs suggested by the reviews, descriptors have lost the data pointer, and there is a new ConvolutionArgs struct which contains everything we need to do benchmarking. BTW, I noticed we don't seem to actually exercise the benchmark code in our test suite.\n\n\nI messed up the no CUDA build from deleting some necessary preprocessor ifdefs. These have been added back.\n\n\nI added a few misc warning squishes.\n\n\nI removed the \"propagate cudnn enabled to ATen\" patch, as it was failing CI in a hard to understand way. I'll PR it separately.\n\n\nI'll squash the patchset before merge.", "body": "OMG build is finally green.\r\n\r\nLatest changelog:\r\n\r\n- I expanded the native yaml parser *just* enough to make it possible for me to explicitly specify the names of multiple return outputs. This allows me to use the NN autogenerated wrapper codepath, which assumes these names are coherent.\r\n\r\n- BatchNorm input checking is now greatly expanded; I basically went through definedness, GPU, type, contiguity, size, and made sure I had checking in all of these cases. I should also expand this checking to other functions but I haven't gotten around to it yet.\r\n\r\n- As suggested by the reviews, descriptors have lost the data pointer, and there is a new ConvolutionArgs struct which contains everything we need to do benchmarking. BTW, I noticed we don't seem to actually exercise the benchmark code in our test suite.\r\n\r\n- I messed up the no CUDA build from deleting some necessary preprocessor ifdefs. These have been added back.\r\n\r\n- I added a few misc warning squishes.\r\n\r\n- I removed the \"propagate cudnn enabled to ATen\" patch, as it was failing CI in a hard to understand way. I'll PR it separately.\r\n\r\nI'll squash the patchset before merge."}