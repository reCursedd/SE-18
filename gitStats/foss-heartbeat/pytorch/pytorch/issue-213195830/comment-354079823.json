{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/354079823", "html_url": "https://github.com/pytorch/pytorch/issues/967#issuecomment-354079823", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/967", "id": 354079823, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDA3OTgyMw==", "user": {"login": "lizhengwei1992", "id": 22869562, "node_id": "MDQ6VXNlcjIyODY5NTYy", "avatar_url": "https://avatars1.githubusercontent.com/u/22869562?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lizhengwei1992", "html_url": "https://github.com/lizhengwei1992", "followers_url": "https://api.github.com/users/lizhengwei1992/followers", "following_url": "https://api.github.com/users/lizhengwei1992/following{/other_user}", "gists_url": "https://api.github.com/users/lizhengwei1992/gists{/gist_id}", "starred_url": "https://api.github.com/users/lizhengwei1992/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lizhengwei1992/subscriptions", "organizations_url": "https://api.github.com/users/lizhengwei1992/orgs", "repos_url": "https://api.github.com/users/lizhengwei1992/repos", "events_url": "https://api.github.com/users/lizhengwei1992/events{/privacy}", "received_events_url": "https://api.github.com/users/lizhengwei1992/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-27T09:02:59Z", "updated_at": "2017-12-27T09:12:01Z", "author_association": "NONE", "body_html": "<p>I find the dilated convolution (dilation=2 ) slower much than convolution (dilation=1). my pytorch version is 0.3.0.post4, I test the dilated convolution like this:</p>\n<h3>batch_size 1:</h3>\n<pre><code>for dilation in reversed([1]):\n    m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\n    input = torch.randn(batch_size, 128, 360, 640).cuda()\n    start = time.time()\n    for j in range(num_runs):\n        output = m(Variable(input, requires_grad=True))\n        output.backward(output.data)\n        torch.cuda.synchronize()\n    mean_time = (time.time() - start) / float(num_runs)\n    print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\n\nfor dilation in reversed([2]):\n    m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\n    input = torch.randn(batch_size, 128, 360, 640).cuda()\n    start = time.time()\n    for j in range(num_runs):\n        output = m(Variable(input, requires_grad=True))\n        output.backward(output.data)\n        torch.cuda.synchronize()\n    mean_time = (time.time() - start) / float(num_runs)\n    print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\n</code></pre>\n<p>get that:<br>\nCUDNN  VERSION 7003<br>\nbatch_size: 1   dilation: 1  time 0.198399<br>\nbatch_size: 1   dilation: 2  time 0.359258<br>\nwhat should I do to accelerate the dilated convolution ?</p>", "body_text": "I find the dilated convolution (dilation=2 ) slower much than convolution (dilation=1). my pytorch version is 0.3.0.post4, I test the dilated convolution like this:\nbatch_size 1:\nfor dilation in reversed([1]):\n    m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\n    input = torch.randn(batch_size, 128, 360, 640).cuda()\n    start = time.time()\n    for j in range(num_runs):\n        output = m(Variable(input, requires_grad=True))\n        output.backward(output.data)\n        torch.cuda.synchronize()\n    mean_time = (time.time() - start) / float(num_runs)\n    print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\n\nfor dilation in reversed([2]):\n    m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\n                      Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\n    input = torch.randn(batch_size, 128, 360, 640).cuda()\n    start = time.time()\n    for j in range(num_runs):\n        output = m(Variable(input, requires_grad=True))\n        output.backward(output.data)\n        torch.cuda.synchronize()\n    mean_time = (time.time() - start) / float(num_runs)\n    print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\n\nget that:\nCUDNN  VERSION 7003\nbatch_size: 1   dilation: 1  time 0.198399\nbatch_size: 1   dilation: 2  time 0.359258\nwhat should I do to accelerate the dilated convolution ?", "body": "I find the dilated convolution (dilation=2 ) slower much than convolution (dilation=1). my pytorch version is 0.3.0.post4, I test the dilated convolution like this:\r\n###  batch_size 1:\r\n    for dilation in reversed([1]):\r\n        m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\r\n        input = torch.randn(batch_size, 128, 360, 640).cuda()\r\n        start = time.time()\r\n        for j in range(num_runs):\r\n            output = m(Variable(input, requires_grad=True))\r\n            output.backward(output.data)\r\n            torch.cuda.synchronize()\r\n        mean_time = (time.time() - start) / float(num_runs)\r\n        print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\r\n\r\n    for dilation in reversed([2]):\r\n        m = nn.Sequential(Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation),\r\n                          Conv2d(128, 128, kernel_size=3, padding=1, dilation=dilation)).cuda()\r\n        input = torch.randn(batch_size, 128, 360, 640).cuda()\r\n        start = time.time()\r\n        for j in range(num_runs):\r\n            output = m(Variable(input, requires_grad=True))\r\n            output.backward(output.data)\r\n            torch.cuda.synchronize()\r\n        mean_time = (time.time() - start) / float(num_runs)\r\n        print('batch_size: %i\\tdilation: %i  time %f' %(batch_size, dilation, mean_time))\r\n\r\nget that:\r\nCUDNN  VERSION 7003\r\nbatch_size: 1   dilation: 1  time 0.198399\r\nbatch_size: 1   dilation: 2  time 0.359258\r\nwhat should I do to accelerate the dilated convolution ? \r\n\r\n\r\n"}