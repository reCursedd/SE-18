{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/285724590", "html_url": "https://github.com/pytorch/pytorch/issues/967#issuecomment-285724590", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/967", "id": 285724590, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTcyNDU5MA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-10T17:01:54Z", "updated_at": "2017-03-10T17:01:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here's output and nvprof output from your snippet on GTX 1080 (I've sent 2d convolutions to the GPU, because they were not on the GPU, and changed ranges to range(2,10) to run dilated cases only. Cudnn is used for dilated convs as shown in the profiler output, and no errors are raised. Have you recompiled pytorch after updating to cudnn v6? I believe it is necessary.</p>\n<pre lang=\"root@e989a22080c1:/workspace/ALL/playground#\" data-meta=\"nvprof python  conv1d_dilated.py\"><code>==400== NVPROF is profiling process 400, command: python conv1d_dilated.py\nTrue\nCUDNN  VERSION 6005\ndilation OK     2\ndilation OK     3\ndilation OK     4\ndilation OK     5\ndilation OK     6\ndilation OK     7\ndilation OK     8\ndilation OK     9\ndilation OK     2\ndilation OK     3\ndilation OK     4\ndilation OK     5\ndilation OK     6\ndilation OK     7\ndilation OK     8\ndilation OK     9\n==400== Profiling application: python conv1d_dilated.py\n==400== Profiling result:\nTime(%)      Time     Calls       Avg       Min       Max  Name\n 46.24%  5.0703ms         7  724.33us  498.86us  1.0062ms  void cudnn::detail::implicit_convolve_sgemm&lt;float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0&gt;(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm&lt;float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0&gt;*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\n 39.50%  4.3313ms        52  83.295us     640ns  537.52us  [CUDA memcpy HtoD]\n  8.87%  973.05us        10  97.305us  12.161us  846.01us  void cudnn::detail::implicit_convolve_sgemm&lt;float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0&gt;(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm&lt;float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0&gt;*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\n  5.19%  568.81us         8  71.101us  46.945us  98.082us  void add_tensor_kernel_v3&lt;int=2, float, float, int=128, int=1, int=1, int=4, int=2&gt;(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)\n  0.21%  22.657us         9  2.5170us  2.1120us  3.1370us  void add_tensor_kernel_v3&lt;int=2, float, float, int=32, int=1, int=4, int=2, int=2&gt;(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)\n</code></pre>", "body_text": "Here's output and nvprof output from your snippet on GTX 1080 (I've sent 2d convolutions to the GPU, because they were not on the GPU, and changed ranges to range(2,10) to run dilated cases only. Cudnn is used for dilated convs as shown in the profiler output, and no errors are raised. Have you recompiled pytorch after updating to cudnn v6? I believe it is necessary.\n==400== NVPROF is profiling process 400, command: python conv1d_dilated.py\nTrue\nCUDNN  VERSION 6005\ndilation OK     2\ndilation OK     3\ndilation OK     4\ndilation OK     5\ndilation OK     6\ndilation OK     7\ndilation OK     8\ndilation OK     9\ndilation OK     2\ndilation OK     3\ndilation OK     4\ndilation OK     5\ndilation OK     6\ndilation OK     7\ndilation OK     8\ndilation OK     9\n==400== Profiling application: python conv1d_dilated.py\n==400== Profiling result:\nTime(%)      Time     Calls       Avg       Min       Max  Name\n 46.24%  5.0703ms         7  724.33us  498.86us  1.0062ms  void cudnn::detail::implicit_convolve_sgemm<float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm<float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\n 39.50%  4.3313ms        52  83.295us     640ns  537.52us  [CUDA memcpy HtoD]\n  8.87%  973.05us        10  97.305us  12.161us  846.01us  void cudnn::detail::implicit_convolve_sgemm<float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm<float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\n  5.19%  568.81us         8  71.101us  46.945us  98.082us  void add_tensor_kernel_v3<int=2, float, float, int=128, int=1, int=1, int=4, int=2>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)\n  0.21%  22.657us         9  2.5170us  2.1120us  3.1370us  void add_tensor_kernel_v3<int=2, float, float, int=32, int=1, int=4, int=2, int=2>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)", "body": "Here's output and nvprof output from your snippet on GTX 1080 (I've sent 2d convolutions to the GPU, because they were not on the GPU, and changed ranges to range(2,10) to run dilated cases only. Cudnn is used for dilated convs as shown in the profiler output, and no errors are raised. Have you recompiled pytorch after updating to cudnn v6? I believe it is necessary.\r\n``` root@e989a22080c1:/workspace/ALL/playground# nvprof python  conv1d_dilated.py \r\n==400== NVPROF is profiling process 400, command: python conv1d_dilated.py\r\nTrue\r\nCUDNN  VERSION 6005\r\ndilation OK     2\r\ndilation OK     3\r\ndilation OK     4\r\ndilation OK     5\r\ndilation OK     6\r\ndilation OK     7\r\ndilation OK     8\r\ndilation OK     9\r\ndilation OK     2\r\ndilation OK     3\r\ndilation OK     4\r\ndilation OK     5\r\ndilation OK     6\r\ndilation OK     7\r\ndilation OK     8\r\ndilation OK     9\r\n==400== Profiling application: python conv1d_dilated.py\r\n==400== Profiling result:\r\nTime(%)      Time     Calls       Avg       Min       Max  Name\r\n 46.24%  5.0703ms         7  724.33us  498.86us  1.0062ms  void cudnn::detail::implicit_convolve_sgemm<float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm<float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\r\n 39.50%  4.3313ms        52  83.295us     640ns  537.52us  [CUDA memcpy HtoD]\r\n  8.87%  973.05us        10  97.305us  12.161us  846.01us  void cudnn::detail::implicit_convolve_sgemm<float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>(int, int, int, float const *, int, cudnn::detail::implicit_convolve_sgemm<float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=0>*, float const *, kernel_conv_params, int, float, float, int, float const *, float const *, int, int)\r\n  5.19%  568.81us         8  71.101us  46.945us  98.082us  void add_tensor_kernel_v3<int=2, float, float, int=128, int=1, int=1, int=4, int=2>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)\r\n  0.21%  22.657us         9  2.5170us  2.1120us  3.1370us  void add_tensor_kernel_v3<int=2, float, float, int=32, int=1, int=4, int=2, int=2>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, float, float)\r\n```\r\n\r\n"}