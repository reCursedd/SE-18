{"url": "https://api.github.com/repos/pytorch/pytorch/issues/967", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/967/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/967/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/967/events", "html_url": "https://github.com/pytorch/pytorch/issues/967", "id": 213195830, "node_id": "MDU6SXNzdWUyMTMxOTU4MzA=", "number": 967, "title": "Conv1d fails with CUDNN 6005 and dilation > 1", "user": {"login": "skaae", "id": 2623134, "node_id": "MDQ6VXNlcjI2MjMxMzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2623134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skaae", "html_url": "https://github.com/skaae", "followers_url": "https://api.github.com/users/skaae/followers", "following_url": "https://api.github.com/users/skaae/following{/other_user}", "gists_url": "https://api.github.com/users/skaae/gists{/gist_id}", "starred_url": "https://api.github.com/users/skaae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skaae/subscriptions", "organizations_url": "https://api.github.com/users/skaae/orgs", "repos_url": "https://api.github.com/users/skaae/repos", "events_url": "https://api.github.com/users/skaae/events{/privacy}", "received_events_url": "https://api.github.com/users/skaae/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 553773019, "node_id": "MDU6TGFiZWw1NTM3NzMwMTk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs-reproduction", "name": "needs-reproduction", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 25, "created_at": "2017-03-09T23:14:39Z", "updated_at": "2017-12-27T09:12:01Z", "closed_at": "2017-04-02T18:43:15Z", "author_association": "NONE", "body_html": "<p>Conv1d with dilation&gt;1 fails after upgrading from cudnn 5105 to  cudnn 6005.<br>\nConv2d works fine.</p>\n<pre><code>Traceback (most recent call last):\n  File \"conv_test.py\", line 29, in &lt;module&gt;\n    output = m(input)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 143, in forward\n    self.padding, self.dilation, self.groups)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\", line 61, in conv1d\n    return f(input, weight, bias) if bias is not None else f(input, weight)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 35, in forward\n    output = self._update_output(input, weight, bias)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 93, in _update_output\n    self.groups, cudnn.benchmark)\nRuntimeError: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n\n</code></pre>\n<pre><code>from torch.autograd import Variable\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nprint(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\ncudnn_version = torch.backends.cudnn.version()\nprint('CUDNN  VERSION', torch.backends.cudnn.version())\nfor i in range(1,10):\n    try:\n        m = nn.Conv1d(16, 33, 3, dilation=i).cuda()\n        input = Variable(torch.randn(20, 16, 50).cuda())\n        output = m(input)\n        print('dilation OK    ', i)\n    except:\n        print('dilation FAILED', i )\n\nfor i in range(1,10):\n    try:\n        m = nn.Conv2d(16, 33, (3, 5), dilation=i)\n        input = Variable(torch.randn(20, 16, 50, 100))\n        output = m(input)\n        print('dilation OK    ', i)\n    except:\n        print('dilation FAILED', i )\n\n# error\nm = nn.Conv1d(16, 33, 3, dilation=i).cuda()\ninput = Variable(torch.randn(20, 16, 50).cuda())\noutput = m(input)\n</code></pre>", "body_text": "Conv1d with dilation>1 fails after upgrading from cudnn 5105 to  cudnn 6005.\nConv2d works fine.\nTraceback (most recent call last):\n  File \"conv_test.py\", line 29, in <module>\n    output = m(input)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 143, in forward\n    self.padding, self.dilation, self.groups)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\", line 61, in conv1d\n    return f(input, weight, bias) if bias is not None else f(input, weight)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 35, in forward\n    output = self._update_output(input, weight, bias)\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 93, in _update_output\n    self.groups, cudnn.benchmark)\nRuntimeError: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n\n\nfrom torch.autograd import Variable\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nprint(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\ncudnn_version = torch.backends.cudnn.version()\nprint('CUDNN  VERSION', torch.backends.cudnn.version())\nfor i in range(1,10):\n    try:\n        m = nn.Conv1d(16, 33, 3, dilation=i).cuda()\n        input = Variable(torch.randn(20, 16, 50).cuda())\n        output = m(input)\n        print('dilation OK    ', i)\n    except:\n        print('dilation FAILED', i )\n\nfor i in range(1,10):\n    try:\n        m = nn.Conv2d(16, 33, (3, 5), dilation=i)\n        input = Variable(torch.randn(20, 16, 50, 100))\n        output = m(input)\n        print('dilation OK    ', i)\n    except:\n        print('dilation FAILED', i )\n\n# error\nm = nn.Conv1d(16, 33, 3, dilation=i).cuda()\ninput = Variable(torch.randn(20, 16, 50).cuda())\noutput = m(input)", "body": "Conv1d with dilation>1 fails after upgrading from cudnn 5105 to  cudnn 6005.\r\nConv2d works fine. \r\n```\r\nTraceback (most recent call last):\r\n  File \"conv_test.py\", line 29, in <module>\r\n    output = m(input)\r\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 143, in forward\r\n    self.padding, self.dilation, self.groups)\r\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/functional.py\", line 61, in conv1d\r\n    return f(input, weight, bias) if bias is not None else f(input, weight)\r\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 35, in forward\r\n    output = self._update_output(input, weight, bias)\r\n  File \"/home/sorson/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 93, in _update_output\r\n    self.groups, cudnn.benchmark)\r\nRuntimeError: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\r\n\r\n```\r\n\r\n```\r\nfrom torch.autograd import Variable\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.backends.cudnn as cudnn\r\nprint(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\r\ncudnn_version = torch.backends.cudnn.version()\r\nprint('CUDNN  VERSION', torch.backends.cudnn.version())\r\nfor i in range(1,10):\r\n    try:\r\n        m = nn.Conv1d(16, 33, 3, dilation=i).cuda()\r\n        input = Variable(torch.randn(20, 16, 50).cuda())\r\n        output = m(input)\r\n        print('dilation OK    ', i)\r\n    except:\r\n        print('dilation FAILED', i )\r\n\r\nfor i in range(1,10):\r\n    try:\r\n        m = nn.Conv2d(16, 33, (3, 5), dilation=i)\r\n        input = Variable(torch.randn(20, 16, 50, 100))\r\n        output = m(input)\r\n        print('dilation OK    ', i)\r\n    except:\r\n        print('dilation FAILED', i )\r\n\r\n# error\r\nm = nn.Conv1d(16, 33, 3, dilation=i).cuda()\r\ninput = Variable(torch.randn(20, 16, 50).cuda())\r\noutput = m(input)\r\n```"}