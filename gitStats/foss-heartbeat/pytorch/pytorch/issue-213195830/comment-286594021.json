{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/286594021", "html_url": "https://github.com/pytorch/pytorch/issues/967#issuecomment-286594021", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/967", "id": 286594021, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjU5NDAyMQ==", "user": {"login": "skaae", "id": 2623134, "node_id": "MDQ6VXNlcjI2MjMxMzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2623134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skaae", "html_url": "https://github.com/skaae", "followers_url": "https://api.github.com/users/skaae/followers", "following_url": "https://api.github.com/users/skaae/following{/other_user}", "gists_url": "https://api.github.com/users/skaae/gists{/gist_id}", "starred_url": "https://api.github.com/users/skaae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skaae/subscriptions", "organizations_url": "https://api.github.com/users/skaae/orgs", "repos_url": "https://api.github.com/users/skaae/repos", "events_url": "https://api.github.com/users/skaae/events{/privacy}", "received_events_url": "https://api.github.com/users/skaae/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-14T23:28:06Z", "updated_at": "2017-03-14T23:55:59Z", "author_association": "NONE", "body_html": "<p>ok. I reran 6.0 with</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">import</span> torch.backends.cudnn <span class=\"pl-k\">as</span> cudnn\ncudnn.benchmark <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n\n<span class=\"pl-c1\">print</span>(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(<span class=\"pl-c1\">1</span>)))\ncudnn_version <span class=\"pl-k\">=</span> torch.backends.cudnn.version()\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>CUDNN  VERSION<span class=\"pl-pds\">'</span></span>, torch.backends.cudnn.version())\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">from</span> torch.nn <span class=\"pl-k\">import</span> Conv1d <span class=\"pl-k\">as</span> Conv1d\n\nnum_runs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\ns <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">22050</span>\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Float<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">for</span> seqlen <span class=\"pl-k\">in</span> [s]:\n    <span class=\"pl-k\">for</span> batch_size <span class=\"pl-k\">in</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">32</span>]:\n        <span class=\"pl-k\">for</span> dilation <span class=\"pl-k\">in</span> <span class=\"pl-c1\">reversed</span>([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">256</span>]):\n            m <span class=\"pl-k\">=</span> nn.Sequential(Conv1d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span>dilation),\n                              Conv1d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span>dilation),\n                              Conv1d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span>dilation),\n                              Conv1d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span>dilation),\n                              Conv1d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span>dilation)).cuda()\n            <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> torch.randn(batch_size, <span class=\"pl-c1\">32</span>, seqlen).float().cuda()\n\n            start <span class=\"pl-k\">=</span> time.time()\n            <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_runs):\n                output <span class=\"pl-k\">=</span> m(Variable(<span class=\"pl-c1\">input</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))\n                output.backward(output.data)\n                torch.cuda.synchronize()\n            mean_time <span class=\"pl-k\">=</span> (time.time() <span class=\"pl-k\">-</span> start) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">float</span>(num_runs)\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>batch_size: <span class=\"pl-c1\">%i</span><span class=\"pl-cce\">\\t</span>dilation: <span class=\"pl-c1\">%i</span><span class=\"pl-cce\">\\t</span>seqlen: <span class=\"pl-c1\">%i</span><span class=\"pl-cce\">\\t</span> time <span class=\"pl-c1\">%f</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span>(batch_size, dilation, seqlen, mean_time))</pre></div>\n<p>The timings are</p>\n<pre><code>CUDNN  VERSION 6005\nFloat\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.162419\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112473\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095722\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.086950\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082691\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080577\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079552\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078340\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028517\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.174036\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.910496\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775035\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704090\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.669370\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.652515\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.643711\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.634073\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.073242\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.434438\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.855506\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.158535\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.816616\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.678162\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.607917\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.575705\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.534676\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.284090\n\nTrue\nCUDNN  VERSION 5110\nFloat\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.163287\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112604\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095797\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.087052\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082770\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080682\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079580\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078428\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028247\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.176725\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.911258\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775866\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704611\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.670090\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.653415\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.662601\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.668462\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.074284\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.444631\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.922886\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.241525\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.856260\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.681688\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.609969\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.577274\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.537217\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.285574\n</code></pre>", "body_text": "ok. I reran 6.0 with\nfrom torch.autograd import Variable\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\ncudnn.benchmark = True\n\n\nprint(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\ncudnn_version = torch.backends.cudnn.version()\nprint('CUDNN  VERSION', torch.backends.cudnn.version())\nimport time\nfrom torch.nn import Conv1d as Conv1d\n\nnum_runs = 10\ns = 5*22050\n\nprint('Float')\nfor seqlen in [s]:\n    for batch_size in [1, 8, 32]:\n        for dilation in reversed([1, 2, 4, 8, 16, 32, 64, 128, 256]):\n            m = nn.Sequential(Conv1d(32, 32, kernel_size=2, dilation=dilation),\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation)).cuda()\n            input = torch.randn(batch_size, 32, seqlen).float().cuda()\n\n            start = time.time()\n            for j in range(num_runs):\n                output = m(Variable(input, requires_grad=True))\n                output.backward(output.data)\n                torch.cuda.synchronize()\n            mean_time = (time.time() - start) / float(num_runs)\n            print('batch_size: %i\\tdilation: %i\\tseqlen: %i\\t time %f' %(batch_size, dilation, seqlen, mean_time))\nThe timings are\nCUDNN  VERSION 6005\nFloat\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.162419\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112473\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095722\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.086950\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082691\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080577\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079552\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078340\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028517\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.174036\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.910496\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775035\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704090\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.669370\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.652515\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.643711\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.634073\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.073242\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.434438\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.855506\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.158535\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.816616\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.678162\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.607917\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.575705\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.534676\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.284090\n\nTrue\nCUDNN  VERSION 5110\nFloat\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.163287\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112604\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095797\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.087052\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082770\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080682\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079580\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078428\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028247\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.176725\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.911258\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775866\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704611\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.670090\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.653415\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.662601\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.668462\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.074284\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.444631\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.922886\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.241525\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.856260\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.681688\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.609969\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.577274\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.537217\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.285574", "body": "ok. I reran 6.0 with \r\n\r\n```Python\r\nfrom torch.autograd import Variable\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.backends.cudnn as cudnn\r\ncudnn.benchmark = True\r\n\r\n\r\nprint(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\r\ncudnn_version = torch.backends.cudnn.version()\r\nprint('CUDNN  VERSION', torch.backends.cudnn.version())\r\nimport time\r\nfrom torch.nn import Conv1d as Conv1d\r\n\r\nnum_runs = 10\r\ns = 5*22050\r\n\r\nprint('Float')\r\nfor seqlen in [s]:\r\n    for batch_size in [1, 8, 32]:\r\n        for dilation in reversed([1, 2, 4, 8, 16, 32, 64, 128, 256]):\r\n            m = nn.Sequential(Conv1d(32, 32, kernel_size=2, dilation=dilation),\r\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\r\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\r\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation),\r\n                              Conv1d(32, 32, kernel_size=2, dilation=dilation)).cuda()\r\n            input = torch.randn(batch_size, 32, seqlen).float().cuda()\r\n\r\n            start = time.time()\r\n            for j in range(num_runs):\r\n                output = m(Variable(input, requires_grad=True))\r\n                output.backward(output.data)\r\n                torch.cuda.synchronize()\r\n            mean_time = (time.time() - start) / float(num_runs)\r\n            print('batch_size: %i\\tdilation: %i\\tseqlen: %i\\t time %f' %(batch_size, dilation, seqlen, mean_time))\r\n```\r\nThe timings are\r\n```\r\nCUDNN  VERSION 6005\r\nFloat\r\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.162419\r\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112473\r\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095722\r\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.086950\r\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082691\r\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080577\r\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079552\r\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078340\r\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028517\r\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.174036\r\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.910496\r\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775035\r\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704090\r\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.669370\r\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.652515\r\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.643711\r\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.634073\r\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.073242\r\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.434438\r\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.855506\r\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.158535\r\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.816616\r\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.678162\r\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.607917\r\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.575705\r\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.534676\r\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.284090\r\n\r\nTrue\r\nCUDNN  VERSION 5110\r\nFloat\r\nbatch_size: 1\tdilation: 256\tseqlen: 110250\t time 0.163287\r\nbatch_size: 1\tdilation: 128\tseqlen: 110250\t time 0.112604\r\nbatch_size: 1\tdilation: 64\tseqlen: 110250\t time 0.095797\r\nbatch_size: 1\tdilation: 32\tseqlen: 110250\t time 0.087052\r\nbatch_size: 1\tdilation: 16\tseqlen: 110250\t time 0.082770\r\nbatch_size: 1\tdilation: 8\tseqlen: 110250\t time 0.080682\r\nbatch_size: 1\tdilation: 4\tseqlen: 110250\t time 0.079580\r\nbatch_size: 1\tdilation: 2\tseqlen: 110250\t time 0.078428\r\nbatch_size: 1\tdilation: 1\tseqlen: 110250\t time 0.028247\r\nbatch_size: 8\tdilation: 256\tseqlen: 110250\t time 1.176725\r\nbatch_size: 8\tdilation: 128\tseqlen: 110250\t time 0.911258\r\nbatch_size: 8\tdilation: 64\tseqlen: 110250\t time 0.775866\r\nbatch_size: 8\tdilation: 32\tseqlen: 110250\t time 0.704611\r\nbatch_size: 8\tdilation: 16\tseqlen: 110250\t time 0.670090\r\nbatch_size: 8\tdilation: 8\tseqlen: 110250\t time 0.653415\r\nbatch_size: 8\tdilation: 4\tseqlen: 110250\t time 0.662601\r\nbatch_size: 8\tdilation: 2\tseqlen: 110250\t time 0.668462\r\nbatch_size: 8\tdilation: 1\tseqlen: 110250\t time 0.074284\r\nbatch_size: 32\tdilation: 256\tseqlen: 110250\t time 5.444631\r\nbatch_size: 32\tdilation: 128\tseqlen: 110250\t time 3.922886\r\nbatch_size: 32\tdilation: 64\tseqlen: 110250\t time 3.241525\r\nbatch_size: 32\tdilation: 32\tseqlen: 110250\t time 2.856260\r\nbatch_size: 32\tdilation: 16\tseqlen: 110250\t time 2.681688\r\nbatch_size: 32\tdilation: 8\tseqlen: 110250\t time 2.609969\r\nbatch_size: 32\tdilation: 4\tseqlen: 110250\t time 2.577274\r\nbatch_size: 32\tdilation: 2\tseqlen: 110250\t time 2.537217\r\nbatch_size: 32\tdilation: 1\tseqlen: 110250\t time 0.285574\r\n```\r\n\r\n"}