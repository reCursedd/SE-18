{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3658", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3658/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3658/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3658/events", "html_url": "https://github.com/pytorch/pytorch/pull/3658", "id": 273233052, "node_id": "MDExOlB1bGxSZXF1ZXN0MTUyMTA1NjYz", "number": 3658, "title": "Cast tensors when loading optimizer state dicts", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-11-12T14:07:07Z", "updated_at": "2017-12-02T21:27:53Z", "closed_at": "2017-11-28T14:56:40Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3658", "html_url": "https://github.com/pytorch/pytorch/pull/3658", "diff_url": "https://github.com/pytorch/pytorch/pull/3658.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3658.patch"}, "body_html": "<p>Right now optimizers can load state dicts of other optimizers only if all parameters are matching in type and device (in contrast to <code>nn.Modules</code>). This is too strict for many use cases, and is addresses in this patch.</p>\n<p>The only problem is that optimizer state isn't typed in any way, so code from this PR tries to make reasonable guesses - only state that's bound to certain parameters is casted (with parameter being the template), and we assume that floating point tensors in the state should match the type of parameter (I can't think of better way to handle load_state_dict across sets of parameters with different fp types). All other types are only moved to a different device.</p>\n<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #2830.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"259816386\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2830\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2830/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2830\">#2830</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"225795077\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1442\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1442/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1442\">#1442</a>.</p>", "body_text": "Right now optimizers can load state dicts of other optimizers only if all parameters are matching in type and device (in contrast to nn.Modules). This is too strict for many use cases, and is addresses in this patch.\nThe only problem is that optimizer state isn't typed in any way, so code from this PR tries to make reasonable guesses - only state that's bound to certain parameters is casted (with parameter being the template), and we assume that floating point tensors in the state should match the type of parameter (I can't think of better way to handle load_state_dict across sets of parameters with different fp types). All other types are only moved to a different device.\nFixes #2830, #1442.", "body": "Right now optimizers can load state dicts of other optimizers only if all parameters are matching in type and device (in contrast to `nn.Modules`). This is too strict for many use cases, and is addresses in this patch.\r\n\r\nThe only problem is that optimizer state isn't typed in any way, so code from this PR tries to make reasonable guesses - only state that's bound to certain parameters is casted (with parameter being the template), and we assume that floating point tensors in the state should match the type of parameter (I can't think of better way to handle load_state_dict across sets of parameters with different fp types). All other types are only moved to a different device.\r\n\r\nFixes #2830, #1442."}