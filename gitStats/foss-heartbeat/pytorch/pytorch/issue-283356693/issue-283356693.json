{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4256", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4256/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4256/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4256/events", "html_url": "https://github.com/pytorch/pytorch/pull/4256", "id": 283356693, "node_id": "MDExOlB1bGxSZXF1ZXN0MTU5MjYyMDY5", "number": 4256, "title": "Implement .numpy_dtype() method for Tensor, Variable", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-12-19T20:18:27Z", "updated_at": "2018-01-09T15:32:14Z", "closed_at": "2017-12-20T05:52:44Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4256", "html_url": "https://github.com/pytorch/pytorch/pull/4256", "diff_url": "https://github.com/pytorch/pytorch/pull/4256.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4256.patch"}, "body_html": "<p>This implements <code>Tensor.numpy_dtype()</code> method equivalent to <code>Tensor.numpy().dtype</code> but without creating the intermediate numpy array.</p>\n<h2>Why?</h2>\n<p>I'm trying to avoid NANs in division by adding tiny numbers to tensors. Tiny numbers depend on datatype: float32 vs float64 etc. In Numpy I can add do this with</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> np.zeros(<span class=\"pl-c1\">1</span>)\nx <span class=\"pl-k\">+=</span> np.finfo(x.dtype).tiny</pre></div>\n<p>PyTorch currently has no way to map PyTorch dataypes to Numpy datatypes. This PR adds a <code>.numpy_dtype()</code> method to support the desired behavior via</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>)\nx <span class=\"pl-k\">+=</span> np.finfo(x.numpy_dtype()).tiny</pre></div>\n<p>See <a href=\"https://discuss.pytorch.org/t/min-positive-value-for-each-tensor-type/11215\" rel=\"nofollow\">https://discuss.pytorch.org/t/min-positive-value-for-each-tensor-type/11215</a></p>", "body_text": "This implements Tensor.numpy_dtype() method equivalent to Tensor.numpy().dtype but without creating the intermediate numpy array.\nWhy?\nI'm trying to avoid NANs in division by adding tiny numbers to tensors. Tiny numbers depend on datatype: float32 vs float64 etc. In Numpy I can add do this with\nx = np.zeros(1)\nx += np.finfo(x.dtype).tiny\nPyTorch currently has no way to map PyTorch dataypes to Numpy datatypes. This PR adds a .numpy_dtype() method to support the desired behavior via\nx = torch.zeros(1)\nx += np.finfo(x.numpy_dtype()).tiny\nSee https://discuss.pytorch.org/t/min-positive-value-for-each-tensor-type/11215", "body": "This implements `Tensor.numpy_dtype()` method equivalent to `Tensor.numpy().dtype` but without creating the intermediate numpy array.\r\n\r\n## Why?\r\n\r\nI'm trying to avoid NANs in division by adding tiny numbers to tensors. Tiny numbers depend on datatype: float32 vs float64 etc. In Numpy I can add do this with\r\n```py\r\nx = np.zeros(1)\r\nx += np.finfo(x.dtype).tiny\r\n```\r\nPyTorch currently has no way to map PyTorch dataypes to Numpy datatypes. This PR adds a `.numpy_dtype()` method to support the desired behavior via\r\n```py\r\nx = torch.zeros(1)\r\nx += np.finfo(x.numpy_dtype()).tiny\r\n```\r\nSee https://discuss.pytorch.org/t/min-positive-value-for-each-tensor-type/11215"}