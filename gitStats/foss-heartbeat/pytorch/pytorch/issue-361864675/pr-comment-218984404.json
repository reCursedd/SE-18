{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218984404", "pull_request_review_id": 157043511, "id": 218984404, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxODk4NDQwNA==", "diff_hunk": "@@ -539,3 +541,112 @@ def _call(self, x):\n     def _inverse(self, y):\n         flat_y = y.contiguous().view((-1,) + y.shape[-2:])\n         return torch.stack([self._inverse_on_event(z) for z in flat_y]).view(y.shape)\n+\n+\n+class CatTransform(Transform):\n+    \"\"\"\n+    Transform functor that applies a sequence of transforms `tseq`\n+    component-wise to each submatrix at `dim` in a way compatible\n+    with `torch.cat`.\n+    \"\"\"\n+    def __init__(self, tseq, dim=0):\n+        assert all(isinstance(t, Transform) for t in tseq)\n+        super(CatTransform, self).__init__()\n+        self.transforms = list(tseq)\n+        self.dim = dim\n+    \n+    def _call(self, x):\n+        assert -x.dim() <= self.dim < x.dim()\n+        assert x.size(self.dim) == len(self.transforms)", "path": "torch/distributions/transforms.py", "position": null, "original_position": 35, "commit_id": "a8745e666ea64dcec8487005e48f55dd90ac42da", "original_commit_id": "e4d4309b77c68d605df24d65fe7b14e957d0fbaf", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "body": "This assumes the `.size(self.dim)` of each input is tensor is 1. I think to handle a more general case you could add a `lengths` arg, maybe like\r\n```py\r\ndef __init__(self, tseq, dim=0, lengths=None):\r\n    if lengths is None:\r\n        lengths = [1] * len(t_seq)\r\n    assert len(lengths) == len(tseq)\r\n    self.lengths = lengths\r\n    ...\r\n\r\n@lazy_property\r\ndef length(self):\r\n    return sum(self.lengths)\r\n\r\ndef _call(self, x):\r\n    ...\r\n    assert x.size(self.dim) == self.length\r\n    yslices = []\r\n    start = 0\r\n    for trans, length in zip(self.transforms, self.lengths):\r\n        xslice = x.narrow(self.dim, start, size)\r\n        yslices.append(trans(xslice))\r\n        start = start + length  # take care to avoid += for jit compatibility\r\n    ...\r\n```", "created_at": "2018-09-19T22:28:05Z", "updated_at": "2018-11-23T15:51:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/11868#discussion_r218984404", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11868", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218984404"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11868#discussion_r218984404"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11868"}}, "body_html": "<p>This assumes the <code>.size(self.dim)</code> of each input is tensor is 1. I think to handle a more general case you could add a <code>lengths</code> arg, maybe like</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">tseq</span>, <span class=\"pl-smi\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-smi\">lengths</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-k\">if</span> lengths <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        lengths <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> <span class=\"pl-c1\">len</span>(t_seq)\n    <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(lengths) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">len</span>(tseq)\n    <span class=\"pl-c1\">self</span>.lengths <span class=\"pl-k\">=</span> lengths\n    <span class=\"pl-c1\">...</span>\n\n<span class=\"pl-en\">@lazy_property</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">length</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">sum</span>(<span class=\"pl-c1\">self</span>.lengths)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_call</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n    <span class=\"pl-c1\">...</span>\n    <span class=\"pl-k\">assert</span> x.size(<span class=\"pl-c1\">self</span>.dim) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">self</span>.length\n    yslices <span class=\"pl-k\">=</span> []\n    start <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    <span class=\"pl-k\">for</span> trans, length <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(<span class=\"pl-c1\">self</span>.transforms, <span class=\"pl-c1\">self</span>.lengths):\n        xslice <span class=\"pl-k\">=</span> x.narrow(<span class=\"pl-c1\">self</span>.dim, start, size)\n        yslices.append(trans(xslice))\n        start <span class=\"pl-k\">=</span> start <span class=\"pl-k\">+</span> length  <span class=\"pl-c\"><span class=\"pl-c\">#</span> take care to avoid += for jit compatibility</span>\n    <span class=\"pl-c1\">...</span></pre></div>", "body_text": "This assumes the .size(self.dim) of each input is tensor is 1. I think to handle a more general case you could add a lengths arg, maybe like\ndef __init__(self, tseq, dim=0, lengths=None):\n    if lengths is None:\n        lengths = [1] * len(t_seq)\n    assert len(lengths) == len(tseq)\n    self.lengths = lengths\n    ...\n\n@lazy_property\ndef length(self):\n    return sum(self.lengths)\n\ndef _call(self, x):\n    ...\n    assert x.size(self.dim) == self.length\n    yslices = []\n    start = 0\n    for trans, length in zip(self.transforms, self.lengths):\n        xslice = x.narrow(self.dim, start, size)\n        yslices.append(trans(xslice))\n        start = start + length  # take care to avoid += for jit compatibility\n    ..."}