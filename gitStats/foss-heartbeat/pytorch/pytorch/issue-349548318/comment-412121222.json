{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/412121222", "html_url": "https://github.com/pytorch/pytorch/issues/10402#issuecomment-412121222", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10402", "id": 412121222, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjEyMTIyMg==", "user": {"login": "ptrblck", "id": 11662379, "node_id": "MDQ6VXNlcjExNjYyMzc5", "avatar_url": "https://avatars3.githubusercontent.com/u/11662379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptrblck", "html_url": "https://github.com/ptrblck", "followers_url": "https://api.github.com/users/ptrblck/followers", "following_url": "https://api.github.com/users/ptrblck/following{/other_user}", "gists_url": "https://api.github.com/users/ptrblck/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptrblck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptrblck/subscriptions", "organizations_url": "https://api.github.com/users/ptrblck/orgs", "repos_url": "https://api.github.com/users/ptrblck/repos", "events_url": "https://api.github.com/users/ptrblck/events{/privacy}", "received_events_url": "https://api.github.com/users/ptrblck/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-10T15:38:54Z", "updated_at": "2018-08-10T15:38:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Would you prefer calling <code>reshape(-1)</code> for every <code>self[i]</code> for <code>start</code> and <code>end</code> or rather once <code>contiguous()</code> on <code>self</code>?</p>\n<p>I've timed it with a quick script and the latter seems to be a bit faster:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> reshape</span>\nx <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">2000</span>, <span class=\"pl-c1\">40</span>, <span class=\"pl-c1\">20</span>)\nx.is_contiguous()\ny <span class=\"pl-k\">=</span> x.permute(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>)\ny.is_contiguous()\n\nt0 <span class=\"pl-k\">=</span> time.perf_counter()\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(y.size(<span class=\"pl-c1\">0</span>)):\n    y[i].reshape(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\nt1 <span class=\"pl-k\">=</span> time.perf_counter()\n<span class=\"pl-c1\">print</span>(t1 <span class=\"pl-k\">-</span> t0)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> contiguous</span>\nx <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">2000</span>, <span class=\"pl-c1\">40</span>, <span class=\"pl-c1\">20</span>)\nx.is_contiguous()\ny <span class=\"pl-k\">=</span> x.permute(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>)\ny.is_contiguous()\n\nt0 <span class=\"pl-k\">=</span> time.perf_counter()\ny <span class=\"pl-k\">=</span> y.contiguous()\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(y.size(<span class=\"pl-c1\">0</span>)):\n    y[i].view(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\nt1 <span class=\"pl-k\">=</span> time.perf_counter()\n<span class=\"pl-c1\">print</span>(t1 <span class=\"pl-k\">-</span> t0)</pre></div>", "body_text": "Would you prefer calling reshape(-1) for every self[i] for start and end or rather once contiguous() on self?\nI've timed it with a quick script and the latter seems to be a bit faster:\n# reshape\nx = torch.randn(2000, 40, 20)\nx.is_contiguous()\ny = x.permute(0, 2, 1)\ny.is_contiguous()\n\nt0 = time.perf_counter()\nfor i in range(y.size(0)):\n    y[i].reshape(-1)\nt1 = time.perf_counter()\nprint(t1 - t0)\n\n# contiguous\nx = torch.randn(2000, 40, 20)\nx.is_contiguous()\ny = x.permute(0, 2, 1)\ny.is_contiguous()\n\nt0 = time.perf_counter()\ny = y.contiguous()\nfor i in range(y.size(0)):\n    y[i].view(-1)\nt1 = time.perf_counter()\nprint(t1 - t0)", "body": "Would you prefer calling `reshape(-1)` for every `self[i]` for `start` and `end` or rather once `contiguous()` on `self`?\r\n\r\nI've timed it with a quick script and the latter seems to be a bit faster:\r\n```python\r\n# reshape\r\nx = torch.randn(2000, 40, 20)\r\nx.is_contiguous()\r\ny = x.permute(0, 2, 1)\r\ny.is_contiguous()\r\n\r\nt0 = time.perf_counter()\r\nfor i in range(y.size(0)):\r\n    y[i].reshape(-1)\r\nt1 = time.perf_counter()\r\nprint(t1 - t0)\r\n\r\n# contiguous\r\nx = torch.randn(2000, 40, 20)\r\nx.is_contiguous()\r\ny = x.permute(0, 2, 1)\r\ny.is_contiguous()\r\n\r\nt0 = time.perf_counter()\r\ny = y.contiguous()\r\nfor i in range(y.size(0)):\r\n    y[i].view(-1)\r\nt1 = time.perf_counter()\r\nprint(t1 - t0)\r\n```"}