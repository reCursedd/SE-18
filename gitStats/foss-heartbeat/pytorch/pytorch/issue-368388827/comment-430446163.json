{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430446163", "html_url": "https://github.com/pytorch/pytorch/issues/12498#issuecomment-430446163", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12498", "id": 430446163, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDQ0NjE2Mw==", "user": {"login": "nkolot", "id": 31786013, "node_id": "MDQ6VXNlcjMxNzg2MDEz", "avatar_url": "https://avatars3.githubusercontent.com/u/31786013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nkolot", "html_url": "https://github.com/nkolot", "followers_url": "https://api.github.com/users/nkolot/followers", "following_url": "https://api.github.com/users/nkolot/following{/other_user}", "gists_url": "https://api.github.com/users/nkolot/gists{/gist_id}", "starred_url": "https://api.github.com/users/nkolot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nkolot/subscriptions", "organizations_url": "https://api.github.com/users/nkolot/orgs", "repos_url": "https://api.github.com/users/nkolot/repos", "events_url": "https://api.github.com/users/nkolot/events{/privacy}", "received_events_url": "https://api.github.com/users/nkolot/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T00:21:07Z", "updated_at": "2018-10-17T00:21:07Z", "author_association": "NONE", "body_html": "<p>I think I am a little bit confused though. Why it works if I don't do <code>x.transpose(0,1)</code> or if I do <code>x.transpose(0,1).clone()</code>?</p>\n<p>I use it in some custom Graph Convolution layers. Right now I am using a workaround where I define a custom spmm autograd.Function and it works fine.</p>", "body_text": "I think I am a little bit confused though. Why it works if I don't do x.transpose(0,1) or if I do x.transpose(0,1).clone()?\nI use it in some custom Graph Convolution layers. Right now I am using a workaround where I define a custom spmm autograd.Function and it works fine.", "body": "I think I am a little bit confused though. Why it works if I don't do `x.transpose(0,1)` or if I do `x.transpose(0,1).clone()`?\r\n\r\nI use it in some custom Graph Convolution layers. Right now I am using a workaround where I define a custom spmm autograd.Function and it works fine."}