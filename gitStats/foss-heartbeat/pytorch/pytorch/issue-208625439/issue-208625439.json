{"url": "https://api.github.com/repos/pytorch/pytorch/issues/776", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/776/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/776/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/776/events", "html_url": "https://github.com/pytorch/pytorch/issues/776", "id": 208625439, "node_id": "MDU6SXNzdWUyMDg2MjU0Mzk=", "number": 776, "title": "Failed when RNN run with cudnn with `requires_grad` set to `False`", "user": {"login": "meijieru", "id": 9511136, "node_id": "MDQ6VXNlcjk1MTExMzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9511136?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meijieru", "html_url": "https://github.com/meijieru", "followers_url": "https://api.github.com/users/meijieru/followers", "following_url": "https://api.github.com/users/meijieru/following{/other_user}", "gists_url": "https://api.github.com/users/meijieru/gists{/gist_id}", "starred_url": "https://api.github.com/users/meijieru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meijieru/subscriptions", "organizations_url": "https://api.github.com/users/meijieru/orgs", "repos_url": "https://api.github.com/users/meijieru/repos", "events_url": "https://api.github.com/users/meijieru/events{/privacy}", "received_events_url": "https://api.github.com/users/meijieru/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2017-02-18T08:42:42Z", "updated_at": "2017-02-21T07:29:29Z", "closed_at": "2017-02-21T07:29:29Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\nlstm <span class=\"pl-k\">=</span> nn.LSTM(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-v\">bidirectional</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nlstm.cuda()\n<span class=\"pl-k\">for</span> param <span class=\"pl-k\">in</span> lstm.parameters():\n    param.requires_grad <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>: Failed when 'False' but succeed when 'True'</span>\n\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">2</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> [T, b, i]</span>\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.cuda()\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> Variable(<span class=\"pl-c1\">input</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\noutput, _ <span class=\"pl-k\">=</span> lstm(<span class=\"pl-c1\">input</span>)\noutput.backward(torch.ones(output.size()).cuda())</pre></div>\n<p>When run on cpu or <code>requires_grad</code> set to <code>True</code>, it does succeed.<br>\nOtherwise, it fails with error message:</p>\n<div class=\"highlight highlight-source-shell\"><pre>Traceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test_lstm.py<span class=\"pl-pds\">\"</span></span>, line 17, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    <span class=\"pl-en\">output.backward(torch.ones(output.size()).cuda</span>())\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/jrmei/.local/lib/python2.7/site-packages/torch/autograd/variable.py<span class=\"pl-pds\">\"</span></span>, line 158, <span class=\"pl-k\">in</span> backward\n    self._execution_engine.run_backward<span class=\"pl-s\"><span class=\"pl-pds\">((</span>self<span class=\"pl-k\">,</span>)<span class=\"pl-k\">,</span> (gradient<span class=\"pl-k\">,</span>)<span class=\"pl-k\">,</span> retain_variables)</span>\n<span class=\"pl-s\">RuntimeError: CudnnRNN returned an invalid number of gradient tensors (expected <span class=\"pl-c1\">11</span>, but got <span class=\"pl-c1\">4</span>)</span></pre></div>\n<p>It seems like the check done by the framework has a bug.</p>", "body_text": "import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nlstm = nn.LSTM(2, 3, 1, bidirectional=True)\nlstm.cuda()\nfor param in lstm.parameters():\n    param.requires_grad = False  # NOTE: Failed when 'False' but succeed when 'True'\n\ninput = torch.ones(4, 5, 2)  # [T, b, i]\ninput = input.cuda()\ninput = Variable(input, requires_grad=True)\noutput, _ = lstm(input)\noutput.backward(torch.ones(output.size()).cuda())\nWhen run on cpu or requires_grad set to True, it does succeed.\nOtherwise, it fails with error message:\nTraceback (most recent call last):\n  File \"test_lstm.py\", line 17, in <module>\n    output.backward(torch.ones(output.size()).cuda())\n  File \"/home/jrmei/.local/lib/python2.7/site-packages/torch/autograd/variable.py\", line 158, in backward\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\nRuntimeError: CudnnRNN returned an invalid number of gradient tensors (expected 11, but got 4)\nIt seems like the check done by the framework has a bug.", "body": "```python\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nlstm = nn.LSTM(2, 3, 1, bidirectional=True)\r\nlstm.cuda()\r\nfor param in lstm.parameters():\r\n    param.requires_grad = False  # NOTE: Failed when 'False' but succeed when 'True'\r\n\r\ninput = torch.ones(4, 5, 2)  # [T, b, i]\r\ninput = input.cuda()\r\ninput = Variable(input, requires_grad=True)\r\noutput, _ = lstm(input)\r\noutput.backward(torch.ones(output.size()).cuda())\r\n```\r\nWhen run on cpu or `requires_grad` set to `True`, it does succeed.\r\nOtherwise, it fails with error message:\r\n```sh\r\nTraceback (most recent call last):\r\n  File \"test_lstm.py\", line 17, in <module>\r\n    output.backward(torch.ones(output.size()).cuda())\r\n  File \"/home/jrmei/.local/lib/python2.7/site-packages/torch/autograd/variable.py\", line 158, in backward\r\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\r\nRuntimeError: CudnnRNN returned an invalid number of gradient tensors (expected 11, but got 4)\r\n```\r\nIt seems like the check done by the framework has a bug."}