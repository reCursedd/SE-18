{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5402", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5402/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5402/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5402/events", "html_url": "https://github.com/pytorch/pytorch/issues/5402", "id": 299996856, "node_id": "MDU6SXNzdWUyOTk5OTY4NTY=", "number": 5402, "title": "torch.cat behaves differently on Tensor vs Variable (also a backward compatibility issue)", "user": {"login": "B1azingB1ade", "id": 19158581, "node_id": "MDQ6VXNlcjE5MTU4NTgx", "avatar_url": "https://avatars0.githubusercontent.com/u/19158581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/B1azingB1ade", "html_url": "https://github.com/B1azingB1ade", "followers_url": "https://api.github.com/users/B1azingB1ade/followers", "following_url": "https://api.github.com/users/B1azingB1ade/following{/other_user}", "gists_url": "https://api.github.com/users/B1azingB1ade/gists{/gist_id}", "starred_url": "https://api.github.com/users/B1azingB1ade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/B1azingB1ade/subscriptions", "organizations_url": "https://api.github.com/users/B1azingB1ade/orgs", "repos_url": "https://api.github.com/users/B1azingB1ade/repos", "events_url": "https://api.github.com/users/B1azingB1ade/events{/privacy}", "received_events_url": "https://api.github.com/users/B1azingB1ade/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-25T04:22:47Z", "updated_at": "2018-03-02T05:35:23Z", "closed_at": "2018-03-02T05:35:23Z", "author_association": "NONE", "body_html": "<ul>\n<li>OS: Ubuntu 16.04.3 LTS</li>\n<li>PyTorch version: 0.3.1</li>\n<li>How you installed PyTorch (conda, pip, source): pip</li>\n<li>Python version: 2.7</li>\n<li>CUDA/cuDNN version: 9.1</li>\n</ul>\n<p>I wanted to concatenate a single variable along a given dimension. I was able to do it for PyTorch 0.2, but 0.3 would give me the error:</p>\n<blockquote>\n<p>RuntimeError: cat(): argument 'tensors' (position 1) must be tuple of Variables, not Variable</p>\n</blockquote>\n<p>However, I'd like to be able to concatenate a Variable along a dimension instead of creating a tuple of Variables. When the input is a Tensor instead of a Variable, torch.cat() still yields the desired output. A script to reproduce the error is as follows:</p>\n<pre><code>import torch\nimport numpy as np\nfrom torch.autograd import Variable\nx = torch.Tensor(np.array(range(24)).reshape(2, 3, 4))\n\nprint torch.cat(x, dim=1)\n# No issue here. Gives me the desired concatenation.\n\nprint torch.cat(Variable(x), dim=1)\n# Error message complains about input being a single Variable.\n</code></pre>\n<p>In short, torch.cat() can concatenate a single Variable along a given dimension in 0.2 but not in 0.3, while torch.cat() can concatenate a single Tensor along a given dimension in both versions.</p>", "body_text": "OS: Ubuntu 16.04.3 LTS\nPyTorch version: 0.3.1\nHow you installed PyTorch (conda, pip, source): pip\nPython version: 2.7\nCUDA/cuDNN version: 9.1\n\nI wanted to concatenate a single variable along a given dimension. I was able to do it for PyTorch 0.2, but 0.3 would give me the error:\n\nRuntimeError: cat(): argument 'tensors' (position 1) must be tuple of Variables, not Variable\n\nHowever, I'd like to be able to concatenate a Variable along a dimension instead of creating a tuple of Variables. When the input is a Tensor instead of a Variable, torch.cat() still yields the desired output. A script to reproduce the error is as follows:\nimport torch\nimport numpy as np\nfrom torch.autograd import Variable\nx = torch.Tensor(np.array(range(24)).reshape(2, 3, 4))\n\nprint torch.cat(x, dim=1)\n# No issue here. Gives me the desired concatenation.\n\nprint torch.cat(Variable(x), dim=1)\n# Error message complains about input being a single Variable.\n\nIn short, torch.cat() can concatenate a single Variable along a given dimension in 0.2 but not in 0.3, while torch.cat() can concatenate a single Tensor along a given dimension in both versions.", "body": "- OS: Ubuntu 16.04.3 LTS\r\n- PyTorch version: 0.3.1\r\n- How you installed PyTorch (conda, pip, source): pip\r\n- Python version: 2.7\r\n- CUDA/cuDNN version: 9.1\r\n\r\nI wanted to concatenate a single variable along a given dimension. I was able to do it for PyTorch 0.2, but 0.3 would give me the error:\r\n\r\n> RuntimeError: cat(): argument 'tensors' (position 1) must be tuple of Variables, not Variable\r\n\r\nHowever, I'd like to be able to concatenate a Variable along a dimension instead of creating a tuple of Variables. When the input is a Tensor instead of a Variable, torch.cat() still yields the desired output. A script to reproduce the error is as follows:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\nfrom torch.autograd import Variable\r\nx = torch.Tensor(np.array(range(24)).reshape(2, 3, 4))\r\n\r\nprint torch.cat(x, dim=1)\r\n# No issue here. Gives me the desired concatenation.\r\n\r\nprint torch.cat(Variable(x), dim=1)\r\n# Error message complains about input being a single Variable.\r\n```\r\nIn short, torch.cat() can concatenate a single Variable along a given dimension in 0.2 but not in 0.3, while torch.cat() can concatenate a single Tensor along a given dimension in both versions.\r\n\r\n"}