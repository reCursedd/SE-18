{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4050", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4050/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4050/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4050/events", "html_url": "https://github.com/pytorch/pytorch/issues/4050", "id": 279629322, "node_id": "MDU6SXNzdWUyNzk2MjkzMjI=", "number": 4050, "title": "Test without backward the model will run out of memory", "user": {"login": "ruiann", "id": 5110107, "node_id": "MDQ6VXNlcjUxMTAxMDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/5110107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruiann", "html_url": "https://github.com/ruiann", "followers_url": "https://api.github.com/users/ruiann/followers", "following_url": "https://api.github.com/users/ruiann/following{/other_user}", "gists_url": "https://api.github.com/users/ruiann/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruiann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruiann/subscriptions", "organizations_url": "https://api.github.com/users/ruiann/orgs", "repos_url": "https://api.github.com/users/ruiann/repos", "events_url": "https://api.github.com/users/ruiann/events{/privacy}", "received_events_url": "https://api.github.com/users/ruiann/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-12-06T05:11:37Z", "updated_at": "2018-05-05T10:55:46Z", "closed_at": "2017-12-06T08:01:30Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre>model <span class=\"pl-k\">=</span> P3D199(<span class=\"pl-v\">num_classes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">101</span>)\nmodel <span class=\"pl-k\">=</span> model.cuda()\ncriterion <span class=\"pl-k\">=</span> torch.nn.CrossEntropyLoss()\noptimizer <span class=\"pl-k\">=</span> torch.optim.Adam(model.parameters(), <span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>)\n\ni <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n<span class=\"pl-k\">while</span> i <span class=\"pl-k\">&lt;</span> step:\n    <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> <span class=\"pl-c1\">100</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        test_data, test_label <span class=\"pl-k\">=</span> read_batch(test_files, test_labels)\n        out <span class=\"pl-k\">=</span> model(torch.autograd.Variable(test_data.float()).cuda())\n        _, predict_label <span class=\"pl-k\">=</span> torch.max(out, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n        eq <span class=\"pl-k\">=</span> torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\n        <span class=\"pl-c1\">print</span>(eq)\n    <span class=\"pl-k\">else</span>:\n        data, data_label <span class=\"pl-k\">=</span> read_batch(files, labels)\n        out <span class=\"pl-k\">=</span> model(torch.autograd.Variable(data.float()).cuda())\n        loss <span class=\"pl-k\">=</span> criterion(out, torch.autograd.Variable(data_label, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>).cuda())\n        <span class=\"pl-c1\">print</span>(i, loss.data[<span class=\"pl-c1\">0</span>])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    i <span class=\"pl-k\">=</span> i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span></pre></div>\n<p>Above code will run out of memory when do a accuracy test every 100 steps.<br>\nAfter accuracy test, the next time <em>model(torch.autograd.Variable(data.float()).cuda())</em> is called, out of memory error has killed the python process.</p>\n<p>log as below:</p>\n<pre><code>96 4.78785133362\n97 4.69954013824\n98 4.39196395874\n99 4.31639766693\nVariable containing:\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n[torch.cuda.ByteTensor of size 10 (GPU 0)]\n\nTHCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory\n*** Error in `python': free(): invalid pointer: 0x00007f4353d1b5a0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f43776967e5]\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f437769f37a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f43776a353c]\n/usr/local/lib/python2.7/dist-packages/torch/_thnn/_THCUNN.so(+0xca1f2)[0x7f43733d61f2]\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce5d0]\n/usr/local/lib/python2.7/dist-packages/torch/_C.so(_Z17THPFunction_applyP7_objectS0_+0x271)[0x7f435279bbd1]\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython(PyEval_EvalFrameEx+0x6099)[0x4ca099]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de8b8]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x4f492e]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x553187]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de8b8]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x4f492e]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x553187]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython(PyEval_EvalCode+0x19)[0x4c2509]\npython[0x4f1def]\npython(PyRun_FileExFlags+0x82)[0x4ec652]\npython(PyRun_SimpleFileExFlags+0x191)[0x4eae31]\npython(Py_Main+0x68a)[0x49e14a]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f437763f830]\npython(_start+0x29)[0x49d9d9]\n======= Memory map: ========\n00400000-006ea000 r-xp 00000000 103:02 11142662                          /usr/bin/python2.7\n008e9000-008eb000 r--p 002e9000 103:02 11142662                          /usr/bin/python2.7\n008eb000-00962000 rw-p 002eb000 103:02 11142662                          /usr/bin/python2.7\n00962000-00985000 rw-p 00000000 00:00 0 \n00d92000-6b918000 rw-p 00000000 00:00 0                                  [heap]\n200000000-200200000 rw-s 36b76a000 00:06 429                             /dev/nvidiactl\n200200000-200400000 ---p 00000000 00:00 0 \n200400000-200404000 rw-s 5e290a000 00:06 429                             /dev/nvidiactl\n200404000-200600000 ---p 00000000 00:00 0 \n200600000-200a00000 rw-s 5e290f000 00:06 429                             /dev/nvidiactl\n200a00000-201600000 ---p 00000000 00:00 0 \n201600000-201604000 rw-s 543306000 00:06 429                             /dev/nvidiactl\n</code></pre>\n<p>you can see when train 100 steps and test the accuracy, it fails to free the memory.</p>\n<p>But if I backward the model with zero_grad when test accuracy, the code can run well</p>\n<div class=\"highlight highlight-source-python\"><pre>model <span class=\"pl-k\">=</span> P3D199(<span class=\"pl-v\">num_classes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">101</span>)\nmodel <span class=\"pl-k\">=</span> model.cuda()\ncriterion <span class=\"pl-k\">=</span> torch.nn.CrossEntropyLoss()\noptimizer <span class=\"pl-k\">=</span> torch.optim.Adam(model.parameters(), <span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-4</span>)\n\ni <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n<span class=\"pl-k\">while</span> i <span class=\"pl-k\">&lt;</span> step:\n    <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> <span class=\"pl-c1\">100</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        test_data, test_label <span class=\"pl-k\">=</span> read_batch(test_files, test_labels)\n        out <span class=\"pl-k\">=</span> model(torch.autograd.Variable(test_data.float()).cuda())\n        _, predict_label <span class=\"pl-k\">=</span> torch.max(out, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n        eq <span class=\"pl-k\">=</span> torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\n        <span class=\"pl-c1\">print</span>(eq)\n        loss <span class=\"pl-k\">=</span> criterion(out, torch.autograd.Variable(test_label, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>).cuda())\n        loss.backward()\n        optimizer.zero_grad()\n        optimizer.step()\n    <span class=\"pl-k\">else</span>:\n        data, data_label <span class=\"pl-k\">=</span> read_batch(files, labels)\n        out <span class=\"pl-k\">=</span> model(torch.autograd.Variable(data.float()).cuda())\n        loss <span class=\"pl-k\">=</span> criterion(out, torch.autograd.Variable(data_label, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>).cuda())\n        <span class=\"pl-c1\">print</span>(i, loss.data[<span class=\"pl-c1\">0</span>])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    i <span class=\"pl-k\">=</span> i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span></pre></div>", "body_text": "model = P3D199(num_classes=101)\nmodel = model.cuda()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\ni = 1\nwhile i < step:\n    if i % 100 == 0:\n        test_data, test_label = read_batch(test_files, test_labels)\n        out = model(torch.autograd.Variable(test_data.float()).cuda())\n        _, predict_label = torch.max(out, dim=1)\n        eq = torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\n        print(eq)\n    else:\n        data, data_label = read_batch(files, labels)\n        out = model(torch.autograd.Variable(data.float()).cuda())\n        loss = criterion(out, torch.autograd.Variable(data_label, requires_grad=False).cuda())\n        print(i, loss.data[0])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    i = i + 1\nAbove code will run out of memory when do a accuracy test every 100 steps.\nAfter accuracy test, the next time model(torch.autograd.Variable(data.float()).cuda()) is called, out of memory error has killed the python process.\nlog as below:\n96 4.78785133362\n97 4.69954013824\n98 4.39196395874\n99 4.31639766693\nVariable containing:\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n[torch.cuda.ByteTensor of size 10 (GPU 0)]\n\nTHCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory\n*** Error in `python': free(): invalid pointer: 0x00007f4353d1b5a0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f43776967e5]\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f437769f37a]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f43776a353c]\n/usr/local/lib/python2.7/dist-packages/torch/_thnn/_THCUNN.so(+0xca1f2)[0x7f43733d61f2]\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce5d0]\n/usr/local/lib/python2.7/dist-packages/torch/_C.so(_Z17THPFunction_applyP7_objectS0_+0x271)[0x7f435279bbd1]\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython(PyEval_EvalFrameEx+0x6099)[0x4ca099]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de8b8]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x4f492e]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x553187]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de8b8]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython[0x4de6fe]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x4f492e]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython[0x553187]\npython(PyObject_Call+0x43)[0x4b0cb3]\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\npython(PyEval_EvalCode+0x19)[0x4c2509]\npython[0x4f1def]\npython(PyRun_FileExFlags+0x82)[0x4ec652]\npython(PyRun_SimpleFileExFlags+0x191)[0x4eae31]\npython(Py_Main+0x68a)[0x49e14a]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f437763f830]\npython(_start+0x29)[0x49d9d9]\n======= Memory map: ========\n00400000-006ea000 r-xp 00000000 103:02 11142662                          /usr/bin/python2.7\n008e9000-008eb000 r--p 002e9000 103:02 11142662                          /usr/bin/python2.7\n008eb000-00962000 rw-p 002eb000 103:02 11142662                          /usr/bin/python2.7\n00962000-00985000 rw-p 00000000 00:00 0 \n00d92000-6b918000 rw-p 00000000 00:00 0                                  [heap]\n200000000-200200000 rw-s 36b76a000 00:06 429                             /dev/nvidiactl\n200200000-200400000 ---p 00000000 00:00 0 \n200400000-200404000 rw-s 5e290a000 00:06 429                             /dev/nvidiactl\n200404000-200600000 ---p 00000000 00:00 0 \n200600000-200a00000 rw-s 5e290f000 00:06 429                             /dev/nvidiactl\n200a00000-201600000 ---p 00000000 00:00 0 \n201600000-201604000 rw-s 543306000 00:06 429                             /dev/nvidiactl\n\nyou can see when train 100 steps and test the accuracy, it fails to free the memory.\nBut if I backward the model with zero_grad when test accuracy, the code can run well\nmodel = P3D199(num_classes=101)\nmodel = model.cuda()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\ni = 1\nwhile i < step:\n    if i % 100 == 0:\n        test_data, test_label = read_batch(test_files, test_labels)\n        out = model(torch.autograd.Variable(test_data.float()).cuda())\n        _, predict_label = torch.max(out, dim=1)\n        eq = torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\n        print(eq)\n        loss = criterion(out, torch.autograd.Variable(test_label, requires_grad=False).cuda())\n        loss.backward()\n        optimizer.zero_grad()\n        optimizer.step()\n    else:\n        data, data_label = read_batch(files, labels)\n        out = model(torch.autograd.Variable(data.float()).cuda())\n        loss = criterion(out, torch.autograd.Variable(data_label, requires_grad=False).cuda())\n        print(i, loss.data[0])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    i = i + 1", "body": "```python\r\nmodel = P3D199(num_classes=101)\r\nmodel = model.cuda()\r\ncriterion = torch.nn.CrossEntropyLoss()\r\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n\r\ni = 1\r\nwhile i < step:\r\n    if i % 100 == 0:\r\n        test_data, test_label = read_batch(test_files, test_labels)\r\n        out = model(torch.autograd.Variable(test_data.float()).cuda())\r\n        _, predict_label = torch.max(out, dim=1)\r\n        eq = torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\r\n        print(eq)\r\n    else:\r\n        data, data_label = read_batch(files, labels)\r\n        out = model(torch.autograd.Variable(data.float()).cuda())\r\n        loss = criterion(out, torch.autograd.Variable(data_label, requires_grad=False).cuda())\r\n        print(i, loss.data[0])\r\n        optimizer.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n    i = i + 1\r\n```\r\n\r\nAbove code will run out of memory when do a accuracy test every 100 steps.\r\nAfter accuracy test, the next time *model(torch.autograd.Variable(data.float()).cuda())* is called, out of memory error has killed the python process.\r\n\r\nlog as below:\r\n```\r\n96 4.78785133362\r\n97 4.69954013824\r\n98 4.39196395874\r\n99 4.31639766693\r\nVariable containing:\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n 0\r\n[torch.cuda.ByteTensor of size 10 (GPU 0)]\r\n\r\nTHCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory\r\n*** Error in `python': free(): invalid pointer: 0x00007f4353d1b5a0 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f43776967e5]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f437769f37a]\r\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f43776a353c]\r\n/usr/local/lib/python2.7/dist-packages/torch/_thnn/_THCUNN.so(+0xca1f2)[0x7f43733d61f2]\r\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython[0x4de6fe]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce5d0]\r\n/usr/local/lib/python2.7/dist-packages/torch/_C.so(_Z17THPFunction_applyP7_objectS0_+0x271)[0x7f435279bbd1]\r\npython(PyEval_EvalFrameEx+0x68a)[0x4c468a]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython(PyEval_EvalFrameEx+0x6099)[0x4ca099]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython[0x4de8b8]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython[0x4de6fe]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython[0x4f492e]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython[0x553187]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython[0x4de8b8]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython(PyEval_EvalFrameEx+0x2ad1)[0x4c6ad1]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython[0x4de6fe]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython[0x4f492e]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython[0x553187]\r\npython(PyObject_Call+0x43)[0x4b0cb3]\r\npython(PyEval_EvalFrameEx+0x5faf)[0x4c9faf]\r\npython(PyEval_EvalCodeEx+0x255)[0x4c2765]\r\npython(PyEval_EvalCode+0x19)[0x4c2509]\r\npython[0x4f1def]\r\npython(PyRun_FileExFlags+0x82)[0x4ec652]\r\npython(PyRun_SimpleFileExFlags+0x191)[0x4eae31]\r\npython(Py_Main+0x68a)[0x49e14a]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f437763f830]\r\npython(_start+0x29)[0x49d9d9]\r\n======= Memory map: ========\r\n00400000-006ea000 r-xp 00000000 103:02 11142662                          /usr/bin/python2.7\r\n008e9000-008eb000 r--p 002e9000 103:02 11142662                          /usr/bin/python2.7\r\n008eb000-00962000 rw-p 002eb000 103:02 11142662                          /usr/bin/python2.7\r\n00962000-00985000 rw-p 00000000 00:00 0 \r\n00d92000-6b918000 rw-p 00000000 00:00 0                                  [heap]\r\n200000000-200200000 rw-s 36b76a000 00:06 429                             /dev/nvidiactl\r\n200200000-200400000 ---p 00000000 00:00 0 \r\n200400000-200404000 rw-s 5e290a000 00:06 429                             /dev/nvidiactl\r\n200404000-200600000 ---p 00000000 00:00 0 \r\n200600000-200a00000 rw-s 5e290f000 00:06 429                             /dev/nvidiactl\r\n200a00000-201600000 ---p 00000000 00:00 0 \r\n201600000-201604000 rw-s 543306000 00:06 429                             /dev/nvidiactl\r\n```\r\n\r\nyou can see when train 100 steps and test the accuracy, it fails to free the memory.\r\n\r\nBut if I backward the model with zero_grad when test accuracy, the code can run well\r\n\r\n```python\r\nmodel = P3D199(num_classes=101)\r\nmodel = model.cuda()\r\ncriterion = torch.nn.CrossEntropyLoss()\r\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n\r\ni = 1\r\nwhile i < step:\r\n    if i % 100 == 0:\r\n        test_data, test_label = read_batch(test_files, test_labels)\r\n        out = model(torch.autograd.Variable(test_data.float()).cuda())\r\n        _, predict_label = torch.max(out, dim=1)\r\n        eq = torch.eq(predict_label, torch.autograd.Variable(test_label).cuda())\r\n        print(eq)\r\n        loss = criterion(out, torch.autograd.Variable(test_label, requires_grad=False).cuda())\r\n        loss.backward()\r\n        optimizer.zero_grad()\r\n        optimizer.step()\r\n    else:\r\n        data, data_label = read_batch(files, labels)\r\n        out = model(torch.autograd.Variable(data.float()).cuda())\r\n        loss = criterion(out, torch.autograd.Variable(data_label, requires_grad=False).cuda())\r\n        print(i, loss.data[0])\r\n        optimizer.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n    i = i + 1\r\n```"}