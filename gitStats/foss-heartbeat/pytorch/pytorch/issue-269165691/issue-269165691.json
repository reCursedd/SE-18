{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3325", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3325/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3325/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3325/events", "html_url": "https://github.com/pytorch/pytorch/pull/3325", "id": 269165691, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ5MjMzNzU4", "number": 3325, "title": "Big batch of JIT and ONNX fixes", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}, {"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-27T16:33:30Z", "updated_at": "2018-11-23T15:35:46Z", "closed_at": "2017-10-30T03:50:35Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3325", "html_url": "https://github.com/pytorch/pytorch/pull/3325", "diff_url": "https://github.com/pytorch/pytorch/pull/3325.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3325.patch"}, "body_html": "<p>The pieces:</p>\n<ul>\n<li>\n<p>I improved the lint / asserts to catch some bugs which I<br>\ncommitted while working on my export.  There are two new<br>\nproperties which the linter checks now:</p>\n<p>(1) \"Anticipated uses\".  If a node says that is used by<br>\nM, M better appear later in the topsort.  Previously,<br>\nwe only checked if it was in all_nodes.</p>\n<p>(2) If you are a select node, you better be a multi-type node;<br>\nif you're not a select node, you better not be!  And you<br>\nshould never have an input that is multi-type.</p>\n</li>\n<li>\n<p>There is a new peephole optimization pass, for simple, local<br>\ntransformations to graphs.  Right now, it implements a simple<br>\noptimization: remove 'expand' invocations that are no-ops<br>\n(the size before matches the size after), but we can add other<br>\nthings to it later.  I needed this for ONNX because no-op expands<br>\nshow up in the left-hand argument, which we don't support.</p>\n</li>\n<li>\n<p>There is now a broadcast fuser, which fuses ATen expand ops<br>\ninto broadcastable ONNX ops (Add, Div, Mul, Pow, Sub, Gemm.)<br>\nIt only fuses when the original size is a suffix of the new<br>\nsize, as per the ONNX spec.</p>\n</li>\n</ul>\n<p>Then, in the next commit:</p>\n<ul>\n<li>\n<p>Deleted Addmm/Concat Function class, as this is now native ATen operator</p>\n</li>\n<li>\n<p>Resurrected ONNX operator for Concat (now called 'cat')</p>\n</li>\n<li>\n<p>Add a \"fake\" Expand ONNX operator, which we now do the optimization on;<br>\nthis helps prevent us from emitting a warning that 'expand' is not supported.<br>\nWe still fail if any of these Expand operators make it to the final model,<br>\nuntil we actually formalize Expand in ONNX.  This also simplifies the<br>\nfuseBroadcast code, because single-return ONNX nodes don't get select nodes.</p>\n</li>\n<li>\n<p>New error reporting strategy.  If we fail to export an operator because of<br>\nsomething, we emit a warning, but otherwise keep going.  At the very end,<br>\nin export.cpp, we now check if there are any ATen operators left over.  If<br>\nthere are, we bug out.  This assumes that ATen is lower case and ONNX is upper<br>\ncase.  You're now supposed to 'return _unimplemented(msg)' in these cases.</p>\n</li>\n<li>\n<p>New toString() method on Graph, for getting the string graph (useful for<br>\nslapping it into error messages.)</p>\n</li>\n<li>\n<p>Some of the legacy symbolics (still in Python symbolic method of Function<br>\nsubclass) have been cleaned up for clarity.)</p>\n</li>\n</ul>\n<p>CC <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17890620\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dzhulgakov\">@dzhulgakov</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4685384\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jamesr66a\">@jamesr66a</a></p>", "body_text": "The pieces:\n\n\nI improved the lint / asserts to catch some bugs which I\ncommitted while working on my export.  There are two new\nproperties which the linter checks now:\n(1) \"Anticipated uses\".  If a node says that is used by\nM, M better appear later in the topsort.  Previously,\nwe only checked if it was in all_nodes.\n(2) If you are a select node, you better be a multi-type node;\nif you're not a select node, you better not be!  And you\nshould never have an input that is multi-type.\n\n\nThere is a new peephole optimization pass, for simple, local\ntransformations to graphs.  Right now, it implements a simple\noptimization: remove 'expand' invocations that are no-ops\n(the size before matches the size after), but we can add other\nthings to it later.  I needed this for ONNX because no-op expands\nshow up in the left-hand argument, which we don't support.\n\n\nThere is now a broadcast fuser, which fuses ATen expand ops\ninto broadcastable ONNX ops (Add, Div, Mul, Pow, Sub, Gemm.)\nIt only fuses when the original size is a suffix of the new\nsize, as per the ONNX spec.\n\n\nThen, in the next commit:\n\n\nDeleted Addmm/Concat Function class, as this is now native ATen operator\n\n\nResurrected ONNX operator for Concat (now called 'cat')\n\n\nAdd a \"fake\" Expand ONNX operator, which we now do the optimization on;\nthis helps prevent us from emitting a warning that 'expand' is not supported.\nWe still fail if any of these Expand operators make it to the final model,\nuntil we actually formalize Expand in ONNX.  This also simplifies the\nfuseBroadcast code, because single-return ONNX nodes don't get select nodes.\n\n\nNew error reporting strategy.  If we fail to export an operator because of\nsomething, we emit a warning, but otherwise keep going.  At the very end,\nin export.cpp, we now check if there are any ATen operators left over.  If\nthere are, we bug out.  This assumes that ATen is lower case and ONNX is upper\ncase.  You're now supposed to 'return _unimplemented(msg)' in these cases.\n\n\nNew toString() method on Graph, for getting the string graph (useful for\nslapping it into error messages.)\n\n\nSome of the legacy symbolics (still in Python symbolic method of Function\nsubclass) have been cleaned up for clarity.)\n\n\nCC @dzhulgakov @jamesr66a", "body": "The pieces:\r\n\r\n- I improved the lint / asserts to catch some bugs which I\r\n  committed while working on my export.  There are two new\r\n  properties which the linter checks now:\r\n\r\n    (1) \"Anticipated uses\".  If a node says that is used by\r\n    M, M better appear later in the topsort.  Previously,\r\n    we only checked if it was in all_nodes.\r\n\r\n    (2) If you are a select node, you better be a multi-type node;\r\n    if you're not a select node, you better not be!  And you\r\n    should never have an input that is multi-type.\r\n\r\n- There is a new peephole optimization pass, for simple, local\r\n  transformations to graphs.  Right now, it implements a simple\r\n  optimization: remove 'expand' invocations that are no-ops\r\n  (the size before matches the size after), but we can add other\r\n  things to it later.  I needed this for ONNX because no-op expands\r\n  show up in the left-hand argument, which we don't support.\r\n\r\n- There is now a broadcast fuser, which fuses ATen expand ops\r\n  into broadcastable ONNX ops (Add, Div, Mul, Pow, Sub, Gemm.)\r\n  It only fuses when the original size is a suffix of the new\r\n  size, as per the ONNX spec.\r\n\r\nThen, in the next commit:\r\n\r\n- Deleted Addmm/Concat Function class, as this is now native ATen operator\r\n\r\n- Resurrected ONNX operator for Concat (now called 'cat')\r\n\r\n- Add a \"fake\" Expand ONNX operator, which we now do the optimization on;\r\n  this helps prevent us from emitting a warning that 'expand' is not supported.\r\n  We still fail if any of these Expand operators make it to the final model,\r\n  until we actually formalize Expand in ONNX.  This also simplifies the\r\n  fuseBroadcast code, because single-return ONNX nodes don't get select nodes.\r\n\r\n- New error reporting strategy.  If we fail to export an operator because of\r\n  something, we emit a warning, but otherwise keep going.  At the very end,\r\n  in export.cpp, we now check if there are any ATen operators left over.  If\r\n  there are, we bug out.  This assumes that ATen is lower case and ONNX is upper\r\n  case.  You're now supposed to 'return _unimplemented(msg)' in these cases.\r\n\r\n- New toString() method on Graph, for getting the string graph (useful for\r\n  slapping it into error messages.)\r\n\r\n- Some of the legacy symbolics (still in Python symbolic method of Function\r\n  subclass) have been cleaned up for clarity.)\r\n\r\nCC @dzhulgakov @jamesr66a "}