{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/147563046", "pull_request_review_id": 72680030, "id": 147563046, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NzU2MzA0Ng==", "diff_hunk": "@@ -220,19 +220,123 @@ void encodeModel(onnx::ModelProto* p_m, const std::shared_ptr<Graph>& g,\n   encodeGraph(p_g, g, initializers);\n }\n \n+// Broadcasting operators have the following property:\n+// They support a 'broadcast' flag, which enables broadcasting\n+// on the last argument.  ATM this is not full-Numpy broadcasting,\n+// only left-size extension (no size 1 to size n broadcast)\n+std::unordered_set<NodeKind> broadcasting = {\n+  kAdd,\n+  kDiv,\n+  kMul,\n+  kPow,\n+  kSub,\n+  kGemm,\n+};\n+\n+bool isBroadcasting(Node *node) {\n+  return broadcasting.count(node->kind());\n+}\n+\n+// When iterating over the dimension sizes, starting at the trailing dimension,\n+// the dimension sizes must either be equal, or one of them does not exist.\n+//\n+//  equivalently:\n+//\n+// Test that 'from' is a suffix of 'to'.\n+bool fusibleExpandTo(at::IntList from, at::IntList to) {\n+  auto f = from.rbegin();\n+  auto t = to.rbegin();\n+  for (; f != from.rend() && t != to.rend(); f++, t++) {\n+    // TODO: if 1->n expansion is supported, adjust this conditional.\n+    if (*f != *t) return false;\n+  }\n+  return f == from.rend();\n+}\n+\n+// This optimization fuses expand calls into ONNX operators, because it is\n+// easier for non-strided backends to more efficiently do broadcasts if this is\n+// local information.  This optimization is not useful for PyTorch as 'expand'\n+// is free.\n+void fuseBroadcast(const std::shared_ptr<Graph>& graph) {\n+  for (auto it = graph->nodes().begin(); it != graph->nodes().end(); ++it) {\n+    auto* n = *it;\n+\n+    // Can't fuse into nodes that don't support broadcasting\n+    if (!isBroadcasting(n)) continue;\n+\n+    // If the node already broadcasts, can't \"rebroadcast\"\n+    // TODO: Actually, maybe you can, if there is a broadcast for some\n+    // dims, and then another broadcast for the rest.  But this will\n+    // never happen in practice so I didn't implement it.\n+    if (n->hasAttribute(kbroadcast) && n->i(kbroadcast)) continue;\n+    JIT_ASSERT(!n->hasAttribute(kaxis));\n+\n+    // TODO: switch ATen tracing to not insert selects for single output.\n+    auto* rhs = n->inputs().at(n->inputs().size() - 1);\n+\n+    // The rhs input isn't actually an expand, so no fusion available\n+    if (rhs->kind() != kExpand) continue;\n+\n+    auto* new_rhs = rhs->input();\n+\n+    // We need to know what the type pre-expand is.  We should basically\n+    // always have this information (because expands are only ever traced,\n+    // not generated from symbolic), but if for some reason we don't\n+    // have it, we need to skip.\n+    if (!new_rhs->hasType()) continue;\n+\n+    // Not all broadcasts are supported by ONNX broadcast.\n+    if (!fusibleExpandTo(new_rhs->type()->expect<TensorType>()->sizes(),    // from\n+                         rhs->type()->expect<TensorType>()->sizes()) // to\n+       ) continue;\n+\n+    auto *new_n = graph->createClone(n, [&](Node* n) { return n == rhs ? new_rhs : n; });\n+    new_n->i_(kbroadcast, 1);\n+    new_n->insertAfter(n);\n+    n->replaceAllUsesWith(new_n);\n+    it.destroyCurrent();\n+    if (rhs->uses().size() == 0) {\n+      if (*it == rhs) {\n+        it.destroyCurrent();\n+      } else {\n+        rhs->destroy();\n+      }\n+    }\n+  }\n+}\n+\n+\n void standardizeGraph(const std::shared_ptr<Graph>& graph) {", "path": "torch/csrc/jit/export.cpp", "position": 90, "original_position": 90, "commit_id": "dcb4a12576ffc1c85f540057c6b755d5d486f49b", "original_commit_id": "dcb4a12576ffc1c85f540057c6b755d5d486f49b", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "I am not sure when export grew this function, but it really should be a separate pass. You can imagine us wanting to export ONNX-style protobufs without standardization, but they are tightly coupled now. This is a separate thing, so no need to fix here, but the changes here showed me that export is growing functionality that really should be separate.", "created_at": "2017-10-28T19:59:25Z", "updated_at": "2018-11-23T15:35:45Z", "html_url": "https://github.com/pytorch/pytorch/pull/3325#discussion_r147563046", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3325", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/147563046"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3325#discussion_r147563046"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3325"}}, "body_html": "<p>I am not sure when export grew this function, but it really should be a separate pass. You can imagine us wanting to export ONNX-style protobufs without standardization, but they are tightly coupled now. This is a separate thing, so no need to fix here, but the changes here showed me that export is growing functionality that really should be separate.</p>", "body_text": "I am not sure when export grew this function, but it really should be a separate pass. You can imagine us wanting to export ONNX-style protobufs without standardization, but they are tightly coupled now. This is a separate thing, so no need to fix here, but the changes here showed me that export is growing functionality that really should be separate."}