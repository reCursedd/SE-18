{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/198673985", "pull_request_review_id": 132647587, "id": 198673985, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5ODY3Mzk4NQ==", "diff_hunk": "@@ -21,6 +21,21 @@ def last_producer(ops, blob):\n     raise ValueError(\"Failed to find last producer of blob, %s\", blob)\n \n \n+def fix_BoxWithNMSLimit(net):\n+    outputs = set()\n+    for op in net.op:\n+        if op.type == 'BoxWithNMSLimit':", "path": "caffe2/python/mkl/rewrite_graph.py", "position": 7, "original_position": 7, "commit_id": "a5792d67f2099488db1bc31d4f916e289cf152d8", "original_commit_id": "7b4c600e90794ec5a7cecc9ed98652c46ce60e7c", "user": {"login": "yinghai", "id": 1100089, "node_id": "MDQ6VXNlcjExMDAwODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1100089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinghai", "html_url": "https://github.com/yinghai", "followers_url": "https://api.github.com/users/yinghai/followers", "following_url": "https://api.github.com/users/yinghai/following{/other_user}", "gists_url": "https://api.github.com/users/yinghai/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinghai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinghai/subscriptions", "organizations_url": "https://api.github.com/users/yinghai/orgs", "repos_url": "https://api.github.com/users/yinghai/repos", "events_url": "https://api.github.com/users/yinghai/events{/privacy}", "received_events_url": "https://api.github.com/users/yinghai/received_events", "type": "User", "site_admin": false}, "body": "This part is really hard coded to work around the 0-dim tensor issue in MKL-DNN:\r\nhttps://github.com/pytorch/pytorch/blob/edb88b5f3af03718b443d015f195faa1832ce95b/caffe2/ideep/operators/operator_fallback_ideep.cc#L101-L103\r\n\r\nIdeally we want all the output to be IDEEP tensor so that they stay in the same context during computation. We only avoid that if for those outputs that can be 0 dim, in this case input 0-2 but not 3. ", "created_at": "2018-06-27T23:51:09Z", "updated_at": "2018-11-23T15:46:30Z", "html_url": "https://github.com/pytorch/pytorch/pull/8959#discussion_r198673985", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8959", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/198673985"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8959#discussion_r198673985"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8959"}}, "body_html": "<p>This part is really hard coded to work around the 0-dim tensor issue in MKL-DNN:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/edb88b5f3af03718b443d015f195faa1832ce95b/caffe2/ideep/operators/operator_fallback_ideep.cc#L101-L103\">pytorch/caffe2/ideep/operators/operator_fallback_ideep.cc</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 101 to 103\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/edb88b5f3af03718b443d015f195faa1832ce95b\">edb88b5</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L101\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"101\"></td>\n          <td id=\"LC101\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-en\">REGISTER_IDEEP_OPERATOR</span>( </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L102\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"102\"></td>\n          <td id=\"LC102\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     BoxWithNMSLimit, </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L103\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"103\"></td>\n          <td id=\"LC103\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     IDEEPFallbackOp&lt;BoxWithNMSLimitOp&lt;CPUContext&gt;, SkipIndices&lt;<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>&gt;&gt;); </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>Ideally we want all the output to be IDEEP tensor so that they stay in the same context during computation. We only avoid that if for those outputs that can be 0 dim, in this case input 0-2 but not 3.</p>", "body_text": "This part is really hard coded to work around the 0-dim tensor issue in MKL-DNN:\n\n  \n    \n      pytorch/caffe2/ideep/operators/operator_fallback_ideep.cc\n    \n    \n        Lines 101 to 103\n      in\n      edb88b5\n    \n    \n    \n    \n\n        \n          \n           REGISTER_IDEEP_OPERATOR( \n        \n\n        \n          \n               BoxWithNMSLimit, \n        \n\n        \n          \n               IDEEPFallbackOp<BoxWithNMSLimitOp<CPUContext>, SkipIndices<0,1,2>>); \n        \n    \n  \n\n\nIdeally we want all the output to be IDEEP tensor so that they stay in the same context during computation. We only avoid that if for those outputs that can be 0 dim, in this case input 0-2 but not 3.", "in_reply_to_id": 198646119}