{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5825", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5825/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5825/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5825/events", "html_url": "https://github.com/pytorch/pytorch/issues/5825", "id": 305752086, "node_id": "MDU6SXNzdWUzMDU3NTIwODY=", "number": 5825, "title": "Support F.normalize on 1-dim tensors without explicit dim", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-03-15T23:19:47Z", "updated_at": "2018-03-19T22:51:13Z", "closed_at": "2018-03-19T19:35:26Z", "author_association": "NONE", "body_html": "<p>Should we reconsider <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"269764273\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3385\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3385/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/3385\">#3385</a>, now that tensors and variables are unified, and functional ops can be used not only in NN minibatch context (also, consistency)?</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\ntorch.nn.functional.normalize(torch.rand(<span class=\"pl-c1\">10</span>))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>Traceback (most recent call last):</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>  File \".../lib/python2.7/site-packages/torch/nn/functional.py\", line 2103, in normalize</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>    return input / input.norm(p, dim, True).clamp(min=eps).expand_as(input)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)</span>\n\ntorch.nn.functional.softmax(torch.rand(<span class=\"pl-c1\">10</span>))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1199</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.0673</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1099</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1007</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1251</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1126</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.0849</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.0697</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.0813</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.1287</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>[torch.FloatTensor of size (10,)]</span></pre></div>\n<p>on <code>0.4.0a0+7f864bb</code>.</p>", "body_text": "Should we reconsider #3385, now that tensors and variables are unified, and functional ops can be used not only in NN minibatch context (also, consistency)?\nimport torch\n\ntorch.nn.functional.normalize(torch.rand(10))\n#Traceback (most recent call last):\n#  File \"<stdin>\", line 1, in <module>\n#  File \".../lib/python2.7/site-packages/torch/nn/functional.py\", line 2103, in normalize\n#    return input / input.norm(p, dim, True).clamp(min=eps).expand_as(input)\n#RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)\n\ntorch.nn.functional.softmax(torch.rand(10))\n# 0.1199\n# 0.0673\n# 0.1099\n# 0.1007\n# 0.1251\n# 0.1126\n# 0.0849\n# 0.0697\n# 0.0813\n# 0.1287\n#[torch.FloatTensor of size (10,)]\non 0.4.0a0+7f864bb.", "body": "Should we reconsider https://github.com/pytorch/pytorch/issues/3385, now that tensors and variables are unified, and functional ops can be used not only in NN minibatch context (also, consistency)?\r\n\r\n```python\r\nimport torch\r\n\r\ntorch.nn.functional.normalize(torch.rand(10))\r\n#Traceback (most recent call last):\r\n#  File \"<stdin>\", line 1, in <module>\r\n#  File \".../lib/python2.7/site-packages/torch/nn/functional.py\", line 2103, in normalize\r\n#    return input / input.norm(p, dim, True).clamp(min=eps).expand_as(input)\r\n#RuntimeError: dimension out of range (expected to be in range of [-1, 0], but got 1)\r\n\r\ntorch.nn.functional.softmax(torch.rand(10))\r\n# 0.1199\r\n# 0.0673\r\n# 0.1099\r\n# 0.1007\r\n# 0.1251\r\n# 0.1126\r\n# 0.0849\r\n# 0.0697\r\n# 0.0813\r\n# 0.1287\r\n#[torch.FloatTensor of size (10,)]\r\n```\r\non `0.4.0a0+7f864bb`."}