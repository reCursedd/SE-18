{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199354280", "pull_request_review_id": 133458676, "id": 199354280, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5OTM1NDI4MA==", "diff_hunk": "@@ -5,179 +5,107 @@\n #include \"../common.h\"\n \n static inline void THNN_(VolumetricUpSamplingNearest_shapeCheck)\n-                        (THCState *state,THCTensor *input, THCTensor *gradOutput,\n-                         int scale_factor) {\n-  THArgCheck(input != NULL, 2, \"4D input tensor expected but got NULL\");\n-  THArgCheck(scale_factor > 1, 4,\n-             \"scale_factor must be greater than 1, but got: %d\", scale_factor);\n-  THCUNN_argCheck(state, !input->is_empty() && (input->dim() == 4 || input->dim() == 5), 2, input,\n-                  \"non-empty 4D or 5D input tensor expected but got: %s\");\n-  if (input->dim() == 4) {\n-    int nChannels    = THCTensor_(size)(state, input, 0);\n-    int inputDepth   = THCTensor_(size)(state, input, 1);\n-    int inputHeight  = THCTensor_(size)(state, input, 2);\n-    int inputWidth   = THCTensor_(size)(state, input, 3);\n-    int outputDepth  = inputDepth * scale_factor;\n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THCUNN_check_dim_size(state, gradOutput, 4, 0, nChannels);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 1, outputDepth);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 2, outputHeight);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 3, outputWidth);\n-    }\n-  } else {\n-    int nBatch       = THCTensor_(size)(state, input, 0);\n-    int nChannels    = THCTensor_(size)(state, input, 1);\n-    int inputDepth   = THCTensor_(size)(state, input, 2);\n-    int inputHeight  = THCTensor_(size)(state, input, 3);\n-    int inputWidth   = THCTensor_(size)(state, input, 4);\n-    int outputDepth  = inputDepth  * scale_factor;\n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THCUNN_check_dim_size(state, gradOutput, 5, 0, nBatch);\n-      THCUNN_check_dim_size(state, gradOutput, 5, 1, nChannels);\n-      THCUNN_check_dim_size(state, gradOutput, 5, 2, outputDepth);\n-      THCUNN_check_dim_size(state, gradOutput, 5, 3, outputHeight);\n-      THCUNN_check_dim_size(state, gradOutput, 5, 4, outputWidth);\n-    }\n+                        (THCState *state,\n+                         THCTensor *input, THCTensor *gradOutput,\n+                         int nBatch, int nChannels,\n+                         int inputDepth, int inputHeight, int inputWidth,\n+                         int outputDepth, int outputHeight, int outputWidth) {\n+  THArgCheck(inputDepth > 0 && inputHeight > 0 && inputWidth > 0\n+             && outputDepth && outputHeight > 0 && outputWidth > 0, 2,\n+             \"input and output sizes should be greater than 0,\"\n+             \" but got input (D: %d, H: %d, W: %d) output (D: %d, H: %d, W: %d)\",\n+             inputDepth, inputHeight, inputWidth, outputDepth, outputHeight, outputWidth);\n+  if (input != NULL) {\n+     THCUNN_argCheck(state, input->_dim() == 5, 2, input,\n+                     \"5D input tensor expected but got: %s\");\n+  }\n+\n+  if (gradOutput != NULL) {\n+    THCUNN_check_dim_size(state, gradOutput, 5, 0, nBatch);\n+    THCUNN_check_dim_size(state, gradOutput, 5, 1, nChannels);\n+    THCUNN_check_dim_size(state, gradOutput, 5, 2, outputDepth);\n+    THCUNN_check_dim_size(state, gradOutput, 5, 3, outputHeight);\n+    THCUNN_check_dim_size(state, gradOutput, 5, 4, outputWidth);\n   }\n }\n \n+\n void THNN_(VolumetricUpSamplingNearest_updateOutput)(\n            THCState *state,\n            THCTensor *input,\n            THCTensor *output,\n-           int scale_factor)\n+\t   int outputDepth,\n+\t   int outputHeight,\n+           int outputWidth)\n {\n-  THCTensor_(zero)(state, output);\n-\n   THCUNN_assertSameGPU(state, 2, input, output);\n-  THNN_(VolumetricUpSamplingNearest_shapeCheck)(state, input, NULL, scale_factor);\n-  int inputDepth = THCTensor_(size)(state, input, input->dim()-3);\n-  int inputHeight = THCTensor_(size)(state, input, input->dim()-2);\n-  int inputWidth  = THCTensor_(size)(state, input,  input->dim()-1);\n-  int outputDepth = inputDepth * scale_factor;\n-  int outputHeight = inputHeight * scale_factor;\n-  int outputWidth = inputWidth * scale_factor;\n-\n-   if (input->dim() == 4) {\n-     THCTensor_(resize4d)(state, output,\n-                          THCTensor_(size)(state, input, 0),\n-                          outputDepth, outputHeight, outputWidth);\n-   } else {\n-     THCTensor_(resize5d)(state, output,\n-                          THCTensor_(size)(state, input, 0),\n-                          THCTensor_(size)(state, input, 1),\n-                          outputDepth, outputHeight, outputWidth);\n-  }\n+  int nbatch = THCTensor_(size)(state, input, 0);\n+  int channels = THCTensor_(size)(state, input, 1);\n+  int inputDepth = THCTensor_(size)(state, input, 2);\n+  int inputHeight = THCTensor_(size)(state, input, 3);\n+  int inputWidth  = THCTensor_(size)(state, input, 4);\n+\n+  THNN_(VolumetricUpSamplingNearest_shapeCheck)(state, input, NULL, nbatch, channels,\n+\t\t  inputDepth, inputHeight, inputWidth,\n+\t\t  outputDepth, outputHeight, outputWidth);\n+  THAssert(inputDepth > 0 && inputHeight > 0 && inputWidth > 0 &&\n+\t\t  outputDepth > 0 && outputHeight > 0 && outputWidth > 0);\n+\n+  THCTensor_(resize5d)(state, output,\n+                       THCTensor_(size)(state, input, 0),\n+                       THCTensor_(size)(state, input, 1),\n+\t\t       outputDepth,\n+\t\t       outputHeight,\n+                       outputWidth);\n+  THCTensor_(zero)(state, output);\n \n   input = THCTensor_(newContiguous)(state, input);\n-  // This is for allocating output Tensor\n-  int64_t no_elements = 1;\n-  for(int i = 0; i < input->dim(); i++){\n-    no_elements *= input->size[i];\n-  }\n-  no_elements *= scale_factor * scale_factor * scale_factor;\n-\n-  int d1;\n-  int d2;\n-  int d3;\n-  int d4;\n-\n-  if (input->dim() == 4) {\n-    d1 = output->size[0];\n-    d2 = output->size[1];\n-    d3 = output->size[2];\n-    d4 = output->size[3];\n-  } else {\n-    d1 = output->size[1];\n-    d2 = output->size[2];\n-    d3 = output->size[3];\n-    d4 = output->size[4];\n-  }\n+  THCDeviceTensor<real, 5> idata = toDeviceTensor<real, 5>(state, input);\n+  THCDeviceTensor<real, 5> odata = toDeviceTensor<real, 5>(state, output);\n \n-  real *input_data = THCTensor_(data)(state, input);\n-  real *output_data = THCTensor_(data)(state, output);\n-\n-  // cuda blocks & threads:\n-  int64_t nthreads = 256;\n-  // Max number of blocks: http://en.wikipedia.org/wiki/CUDA\n-  // 65535 for SM 2.x, 2^32 -1 for >= 3.0\n-  // TODO: When we move to SM 3.5 we should update this\n-  int64_t n_xblocks = min(max((int)ceil((float)no_elements / nthreads), 1), 65535);\n-  int64_t n_yblocks = (int64_t)ceil((float)no_elements / (float)(n_xblocks * nthreads));\n-  if (n_yblocks > 65535) {\n-    THError(\"Input size is too large!  aborting\");\n-  }\n-  dim3 blocks(n_xblocks, n_yblocks);\n-  dim3 threads(nthreads);\n+  const int num_kernels = outputDepth * outputHeight * outputWidth;\n+  const int num_threads = THCState_getCurrentDeviceProperties(state)->maxThreadsPerBlock;\n+  cudaStream_t stream = THCState_getCurrentStream(state);\n+  nearest_neighbor_5d_kernel<real, accreal> <<<THCCeilDiv(num_kernels, num_threads), num_threads,\n+\t 0, stream>>>(num_kernels, idata, odata);\n \n-  // kernel:\n-  vupscale<<<blocks, threads, 0, THCState_getCurrentStream(state)>>> (input_data, output_data, no_elements, scale_factor, d1, d2, d3, d4);\n   THCudaCheck(cudaGetLastError());\n-\n-  // final cut:\n   THCTensor_(free)(state, input);\n }\n \n+\n+\n void THNN_(VolumetricUpSamplingNearest_updateGradInput)(\n            THCState *state,\n-           THCTensor *input,\n            THCTensor *gradOutput,\n            THCTensor *gradInput,\n-           int scale_factor)\n+           int nbatch,\n+\t   int nchannels,", "path": "aten/src/THCUNN/generic/VolumetricUpSamplingNearest.cu", "position": null, "original_position": 181, "commit_id": "f99c543ab514043a5a842d80d166f4ef7e36d93b", "original_commit_id": "03cfb5387bfea8f995540b427c7e8a2855140963", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "tabs :-)", "created_at": "2018-07-01T16:23:56Z", "updated_at": "2018-11-23T15:46:38Z", "html_url": "https://github.com/pytorch/pytorch/pull/8591#discussion_r199354280", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8591", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199354280"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8591#discussion_r199354280"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8591"}}, "body_html": "<p>tabs :-)</p>", "body_text": "tabs :-)"}