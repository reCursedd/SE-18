{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196503721", "pull_request_review_id": 130068877, "id": 196503721, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjUwMzcyMQ==", "diff_hunk": "@@ -2,198 +2,153 @@\n #define TH_GENERIC_FILE \"generic/SpatialUpSamplingNearest.c\"\n #else\n \n+#include \"linear_upsampling.h\"\n+#include <stdio.h>\n \n static inline void THNN_(SpatialUpSamplingNearest_shapeCheck)\n      (THTensor *input, THTensor *gradOutput,\n-      int scale_factor) {\n-  THArgCheck(input != NULL, 2, \"4D input tensor expected but got NULL\");\n-  THArgCheck(scale_factor > 1, 4,\n-\t     \"scale_factor must be greater than 1, but got: %d\", scale_factor);\n-  THNN_ARGCHECK(input->_dim() == 3 || input->_dim() == 4, 2, input,\n-\t\t\"3D or 4D input tensor expected but got: %s\");\n-  if (input->_dim() == 3) {\n-    int nChannels    = THTensor_(size)(input, 0);\n-    int inputHeight  = THTensor_(size)(input, 1);\n-    int inputWidth   = THTensor_(size)(input, 2);\n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THNN_CHECK_DIM_SIZE(gradOutput, 3, 0, nChannels);\n-      THNN_CHECK_DIM_SIZE(gradOutput, 3, 1, outputHeight);\n-      THNN_CHECK_DIM_SIZE(gradOutput, 3, 2, outputWidth);\n-    }\n-  } else {\n-    int nBatch       = THTensor_(size)(input, 0);\n-    int nChannels    = THTensor_(size)(input, 1);\n-    int inputHeight  = THTensor_(size)(input, 2);\n-    int inputWidth   = THTensor_(size)(input, 3);  \n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THNN_CHECK_DIM_SIZE(gradOutput, 4, 0, nBatch);\n-      THNN_CHECK_DIM_SIZE(gradOutput, 4, 1, nChannels);\n-      THNN_CHECK_DIM_SIZE(gradOutput, 4, 2, outputHeight);\n-      THNN_CHECK_DIM_SIZE(gradOutput, 4, 3, outputWidth);\n-    }\n+      int nBatch, int nChannels,\n+      int inputHeight, int inputWidth,\n+      int outputHeight, int outputWidth) {\n+  THArgCheck(inputHeight > 0 && inputWidth > 0\n+       && outputHeight > 0 && outputWidth > 0, 2,\n+       \"input and output sizes should be greater than 0,\"\n+       \" but got input (H: %d, W: %d) output (H: %d, W: %d)\",\n+       inputHeight, inputWidth, outputHeight, outputWidth);\n+  if (input != NULL) {\n+    THNN_ARGCHECK(input->_dim() == 4, 2, input,", "path": "aten/src/THNN/generic/SpatialUpSamplingNearest.c", "position": 47, "original_position": 48, "commit_id": "f99c543ab514043a5a842d80d166f4ef7e36d93b", "original_commit_id": "1958eb421c916bd3864353ffed4e36f574774c4e", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "body": "Yes and no ;) My 2cents : I removed it here bc it was actually never triggered due to a dimension guard in python end. https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1789 And it was never in our python end documentation. \r\nIf we want to support it, we could easily expand the 3D to 4D on python end and pass it along, that way we could avoid complicating our C code by checking sizes. \r\nWhat do you think?", "created_at": "2018-06-19T16:58:09Z", "updated_at": "2018-11-23T15:45:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/8591#discussion_r196503721", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8591", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196503721"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8591#discussion_r196503721"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8591"}}, "body_html": "<p>Yes and no ;) My 2cents : I removed it here bc it was actually never triggered due to a dimension guard in python end. <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1789\">https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1789</a> And it was never in our python end documentation.<br>\nIf we want to support it, we could easily expand the 3D to 4D on python end and pass it along, that way we could avoid complicating our C code by checking sizes.<br>\nWhat do you think?</p>", "body_text": "Yes and no ;) My 2cents : I removed it here bc it was actually never triggered due to a dimension guard in python end. https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1789 And it was never in our python end documentation.\nIf we want to support it, we could easily expand the 3D to 4D on python end and pass it along, that way we could avoid complicating our C code by checking sizes.\nWhat do you think?", "in_reply_to_id": 196468265}