{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199354096", "pull_request_review_id": 133458676, "id": 199354096, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5OTM1NDA5Ng==", "diff_hunk": "@@ -5,165 +5,99 @@\n #include \"../common.h\"\n \n static inline void THNN_(SpatialUpSamplingNearest_shapeCheck)\n-                        (THCState *state,THCTensor *input, THCTensor *gradOutput,\n-                         int scale_factor) {\n-  THArgCheck(input != NULL, 2, \"4D input tensor expected but got NULL\");\n-  THArgCheck(scale_factor > 1, 4,\n-             \"scale_factor must be greater than 1, but got: %d\", scale_factor);\n-  THCUNN_argCheck(state, !input->is_empty() && (input->dim() == 3 || input->dim() == 4), 2, input,\n-                  \"non-empty 3D or 4D input tensor expected but got: %s\");\n-  if (input->dim() == 3) {\n-    int nChannels    = THCTensor_(size)(state, input, 0);\n-    int inputHeight  = THCTensor_(size)(state, input, 1);\n-    int inputWidth   = THCTensor_(size)(state, input, 2);\n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THCUNN_check_dim_size(state, gradOutput, 3, 0, nChannels);\n-      THCUNN_check_dim_size(state, gradOutput, 3, 1, outputHeight);\n-      THCUNN_check_dim_size(state, gradOutput, 3, 2, outputWidth);\n-    }\n-  } else {\n-    int nBatch       = THCTensor_(size)(state, input, 0);\n-    int nChannels    = THCTensor_(size)(state, input, 1);\n-    int inputHeight  = THCTensor_(size)(state, input, 2);\n-    int inputWidth   = THCTensor_(size)(state, input, 3);\n-    int outputHeight = inputHeight * scale_factor;\n-    int outputWidth  = inputWidth  * scale_factor;\n-    if (gradOutput != NULL) {\n-      THCUNN_check_dim_size(state, gradOutput, 4, 0, nBatch);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 1, nChannels);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 2, outputHeight);\n-      THCUNN_check_dim_size(state, gradOutput, 4, 3, outputWidth);\n-    }\n+                        (THCState *state,\n+                         THCTensor *input, THCTensor *gradOutput,\n+                         int nBatch, int nChannels,\n+                         int inputHeight, int inputWidth,\n+                         int outputHeight, int outputWidth) {\n+  THArgCheck(inputHeight > 0 && inputWidth > 0\n+             && outputHeight > 0 && outputWidth > 0, 2,\n+             \"input and output sizes should be greater than 0,\"\n+             \" but got input (H: %d, W: %d) output (H: %d, W: %d)\",\n+             inputHeight, inputWidth, outputHeight, outputWidth);\n+  if (input != NULL) {\n+     THCUNN_argCheck(state, input->_dim() == 4, 2, input,\n+                     \"4D input tensor expected but got: %s\");\n+  }\n+\n+  if (gradOutput != NULL) {\n+    THCUNN_check_dim_size(state, gradOutput, 4, 0, nBatch);\n+    THCUNN_check_dim_size(state, gradOutput, 4, 1, nChannels);\n+    THCUNN_check_dim_size(state, gradOutput, 4, 2, outputHeight);\n+    THCUNN_check_dim_size(state, gradOutput, 4, 3, outputWidth);\n   }\n }\n \n+\n void THNN_(SpatialUpSamplingNearest_updateOutput)(\n            THCState *state,\n            THCTensor *input,\n            THCTensor *output,\n-           int scale_factor)\n+\t   int outputHeight,\n+           int outputWidth)\n {\n-  THCTensor_(zero)(state, output);\n-\n   THCUNN_assertSameGPU(state, 2, input, output);\n-  THNN_(SpatialUpSamplingNearest_shapeCheck)(state, input, NULL, scale_factor);\n-  int inputHeight = THCTensor_(size)(state, input, input->dim()-2);\n-  int inputWidth  = THCTensor_(size)(state, input,  input->dim()-1);\n-  int outputHeight = inputHeight * scale_factor;\n-  int outputWidth = inputWidth * scale_factor;\n-\n-   if (input->dim() == 3) {\n-     THCTensor_(resize3d)(state, output,\n-                          THCTensor_(size)(state, input, 0),\n-                          outputHeight, outputWidth);\n-   } else {\n-     THCTensor_(resize4d)(state, output,\n-                          THCTensor_(size)(state, input, 0),\n-                          THCTensor_(size)(state, input, 1),\n-                          outputHeight, outputWidth);\n-  }\n+  int nbatch = THCTensor_(size)(state, input, 0);\n+  int channels = THCTensor_(size)(state, input, 1);\n+  int inputHeight = THCTensor_(size)(state, input, 2);\n+  int inputWidth  = THCTensor_(size)(state, input, 3);\n+\n+  THNN_(SpatialUpSamplingNearest_shapeCheck)(state, input, NULL, nbatch, channels,\n+\t\t  inputHeight, inputWidth,\n+\t\t  outputHeight, outputWidth);\n+  THAssert(inputHeight > 0 && inputWidth > 0 && outputHeight > 0 && outputWidth > 0);\n+\n+  THCTensor_(resize4d)(state, output,\n+                       THCTensor_(size)(state, input, 0),\n+                       THCTensor_(size)(state, input, 1),\n+\t\t       outputHeight,\n+                       outputWidth);\n+  THCTensor_(zero)(state, output);\n \n   input = THCTensor_(newContiguous)(state, input);", "path": "aten/src/THCUNN/generic/SpatialUpSamplingNearest.cu", "position": null, "original_position": 103, "commit_id": "f99c543ab514043a5a842d80d166f4ef7e36d93b", "original_commit_id": "03cfb5387bfea8f995540b427c7e8a2855140963", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "question: do we still have the restriction that the input should be contiguous?", "created_at": "2018-07-01T16:15:43Z", "updated_at": "2018-11-23T15:46:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/8591#discussion_r199354096", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8591", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199354096"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8591#discussion_r199354096"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8591"}}, "body_html": "<p>question: do we still have the restriction that the input should be contiguous?</p>", "body_text": "question: do we still have the restriction that the input should be contiguous?"}