{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6398", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6398/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6398/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6398/events", "html_url": "https://github.com/pytorch/pytorch/issues/6398", "id": 312276701, "node_id": "MDU6SXNzdWUzMTIyNzY3MDE=", "number": 6398, "title": "torch.get_num_threads returns 1 on Windows", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-04-08T06:18:05Z", "updated_at": "2018-04-12T03:10:29Z", "closed_at": "2018-04-12T03:10:29Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>PyTorch GitHub Issues Guidelines</h2>\n<p>We like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: <a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">https://discuss.pytorch.org/</a></p>\n<p>If you are submitting a feature request, please preface the title with [feature request].</p>\n<p>When submitting a bug report, please include the following information (where relevant):</p>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>OS: Windows 10</li>\n<li>PyTorch version: master (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/67bbf585cda43fc63a8450421aaef24e2f7b3501/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/67bbf585cda43fc63a8450421aaef24e2f7b3501\"><tt>67bbf58</tt></a>)</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU models and configuration: Intel 7700HQ with 8 threads</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Build command you used (if compiling from source):</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>\n<p>In addition, including the following information will also be very helpful for us to diagnose the problem:</p>\n<ul>\n<li>A script to reproduce the bug. Please try to provide as minimal of a test case as possible.</li>\n<li>Error messages and/or stack traces of the bug</li>\n<li>Context around what you are trying to do</li>\n</ul>\n<p>It cannot auto detect the cores on the machine. And it ignores the environmental variables like <code>OMP_NUM_THREADS</code> and <code>MKL_NUM_THREADS</code>. But the MKL side seems to working. I guess there is sth wrong with OpenMP there.</p>\n<div class=\"highlight highlight-text-python-console\"><pre>Python 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 16:13:55) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; <span class=\"pl-k\">import</span> torch\n&gt;&gt;&gt; torch.get_num_threads()\n1\n&gt;&gt;&gt; <span class=\"pl-k\">import</span> mkl\n&gt;&gt;&gt; mkl.get_max_threads()\n4</pre></div>", "body_text": "PyTorch GitHub Issues Guidelines\nWe like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: https://discuss.pytorch.org/\nIf you are submitting a feature request, please preface the title with [feature request].\nWhen submitting a bug report, please include the following information (where relevant):\n\nPyTorch or Caffe2: PyTorch\nOS: Windows 10\nPyTorch version: master (67bbf58)\nHow you installed PyTorch (conda, pip, source): source\nPython version: 3.6\nCUDA/cuDNN version:\nGPU models and configuration: Intel 7700HQ with 8 threads\nGCC version (if compiling from source):\nCMake version:\nBuild command you used (if compiling from source):\nVersions of any other relevant libraries:\n\nIn addition, including the following information will also be very helpful for us to diagnose the problem:\n\nA script to reproduce the bug. Please try to provide as minimal of a test case as possible.\nError messages and/or stack traces of the bug\nContext around what you are trying to do\n\nIt cannot auto detect the cores on the machine. And it ignores the environmental variables like OMP_NUM_THREADS and MKL_NUM_THREADS. But the MKL side seems to working. I guess there is sth wrong with OpenMP there.\nPython 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 16:13:55) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import torch\n>>> torch.get_num_threads()\n1\n>>> import mkl\n>>> mkl.get_max_threads()\n4", "body": "PyTorch GitHub Issues Guidelines\r\n--------------------------------\r\n\r\nWe like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: https://discuss.pytorch.org/\r\n\r\nIf you are submitting a feature request, please preface the title with [feature request].\r\n\r\nWhen submitting a bug report, please include the following information (where relevant):\r\n- PyTorch or Caffe2: PyTorch\r\n- OS: Windows 10\r\n- PyTorch version: master (67bbf585cda43fc63a8450421aaef24e2f7b3501)\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: 3.6\r\n- CUDA/cuDNN version:\r\n- GPU models and configuration: Intel 7700HQ with 8 threads\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Build command you used (if compiling from source):\r\n- Versions of any other relevant libraries:\r\n\r\nIn addition, including the following information will also be very helpful for us to diagnose the problem:\r\n- A script to reproduce the bug. Please try to provide as minimal of a test case as possible.\r\n- Error messages and/or stack traces of the bug\r\n- Context around what you are trying to do\r\n\r\nIt cannot auto detect the cores on the machine. And it ignores the environmental variables like `OMP_NUM_THREADS` and `MKL_NUM_THREADS`. But the MKL side seems to working. I guess there is sth wrong with OpenMP there.\r\n```pycon\r\nPython 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 16:13:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> torch.get_num_threads()\r\n1\r\n>>> import mkl\r\n>>> mkl.get_max_threads()\r\n4\r\n```"}