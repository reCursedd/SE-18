{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160802320", "pull_request_review_id": 87971091, "id": 160802320, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDgwMjMyMA==", "diff_hunk": "@@ -159,90 +260,183 @@ def emit_dispatch(i, function):\n             elif dispatch_type == 'Tensor &':\n                 dispatch_type = 'Tensor'\n             formal_args.append('{} {}'.format(dispatch_type, name))\n+\n+        unpack = any(arg.get('python_default_init') for arg in inputs)\n+        for arg in inputs:\n+            if has_self and arg['name'] == 'self':\n+                formal_args.append('Tensor & self')\n+                actuals.append('self_')\n+                continue\n+            parse_arg(arg, unpack)\n             arg_idx += 1\n \n-        env['i'] = i\n+        if len(outputs) == 1:\n+            parse_arg(outputs[0])\n+        elif len(outputs) > 1:\n+            N = len(outputs)\n+            body.append('auto results = r.tensorlist_n<{}>({});'.format(N, arg_idx))\n+            for i, arg in enumerate(outputs):\n+                formal_args.append('Tensor & {}'.format(arg['name']))\n+                actuals.append('results[{}]'.format(i))\n+\n         env['unpack_args'] = []\n         env['formal_args'] = formal_args\n-        if unpack_args:\n-            unpack_statements_no_default = []\n-            unpack_statements_with_default = []\n-            actual_names = []\n-            for arg, formal_arg, actual in zip(function['arguments'], formal_args, actuals):\n-                name = arg['name']\n-                actual_names.append(name)\n-                unpack_expr = UNPACK_ARG.substitute(formal_arg=formal_arg, actual=actual)\n-                if arg.get('python_default_init'):\n-                    unpack_statements_with_default.append(unpack_expr)\n-                else:\n-                    unpack_statements_no_default.append(unpack_expr)\n-            env['unpack_args'] = unpack_statements_no_default + unpack_statements_with_default\n-            env['actuals'] = actual_names\n-            code_template = PY_VARIABLE_CASE_WITH_UNPACK\n+        env['actuals'] = actuals\n+        if 'call_args' in declaration:\n+            env['dispatch_args'] = declaration['call_args']\n         else:\n-            env['actuals'] = actuals\n-            code_template = PY_VARIABLE_CASE\n-        if 'call_args' in function:\n-            env['dispatch_args'] = function['call_args']\n-        else:\n-            env['dispatch_args'] = [arg['name'] for arg in function['arguments']]\n-        if 'Tensor' in function['method_of']:\n+            env['dispatch_args'] = [arg['name'] for arg in declaration['arguments']]\n+        if 'Tensor' in declaration['method_of']:\n             env['dispatch_args'] = [arg for arg in env['dispatch_args'] if arg != 'self']\n-            env['dispatch_call'] = 'self.{}'.format(function['name'])\n+            env['dispatch_call'] = 'self.{}'.format(declaration['name'])\n         else:\n-            env['dispatch_call'] = 'at::{}'.format(function['name'])\n+            env['dispatch_call'] = 'at::{}'.format(declaration['name'])\n         env['AutoNoGIL'] = 'AutoNoGIL no_gil;'\n-        env['AutoGPU'] = auto_gpu(function)\n-        env['cond'] = 'if' if i == 0 else '} else if'\n-        env = nested_dict(env, function)\n+        env['AutoGPU'] = auto_gpu(declaration)\n+        env = nested_dict(env, nested_dict(base_env, declaration))\n+        body.append(PY_VARIABLE_CALL_DISPATCH.substitute(env))\n         py_method_dispatch.append(PY_VARIABLE_DISPATCH.substitute(env))\n-        return code_template.substitute(env)\n+        return body\n \n-    def process_function(name, functions):\n+    def emit_dispatch(i, declarations, base_env):\n+        if len(declarations) == 1:\n+            body = emit_single_dispatch(declarations[0], base_env)\n+        else:\n+            assert len(declarations) == 2", "path": "tools/autograd/gen_python_functions.py", "position": null, "original_position": 297, "commit_id": "c7b63bd434ccce40348954794518030282ff0ddc", "original_commit_id": "2ff436294709b07373c384c6624382cf7dc9fe19", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "nit: the magic length requirements / ordering seems a little hacky to me; can we just use a namedtuple or something to represent this?", "created_at": "2018-01-10T21:24:47Z", "updated_at": "2018-11-23T15:38:01Z", "html_url": "https://github.com/pytorch/pytorch/pull/4565#discussion_r160802320", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4565", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160802320"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4565#discussion_r160802320"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4565"}}, "body_html": "<p>nit: the magic length requirements / ordering seems a little hacky to me; can we just use a namedtuple or something to represent this?</p>", "body_text": "nit: the magic length requirements / ordering seems a little hacky to me; can we just use a namedtuple or something to represent this?"}