{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160801175", "pull_request_review_id": 87971091, "id": 160801175, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDgwMTE3NQ==", "diff_hunk": "@@ -159,90 +260,183 @@ def emit_dispatch(i, function):\n             elif dispatch_type == 'Tensor &':\n                 dispatch_type = 'Tensor'\n             formal_args.append('{} {}'.format(dispatch_type, name))\n+\n+        unpack = any(arg.get('python_default_init') for arg in inputs)\n+        for arg in inputs:\n+            if has_self and arg['name'] == 'self':\n+                formal_args.append('Tensor & self')\n+                actuals.append('self_')\n+                continue\n+            parse_arg(arg, unpack)\n             arg_idx += 1\n \n-        env['i'] = i\n+        if len(outputs) == 1:\n+            parse_arg(outputs[0])\n+        elif len(outputs) > 1:\n+            N = len(outputs)\n+            body.append('auto results = r.tensorlist_n<{}>({});'.format(N, arg_idx))\n+            for i, arg in enumerate(outputs):\n+                formal_args.append('Tensor & {}'.format(arg['name']))\n+                actuals.append('results[{}]'.format(i))\n+\n         env['unpack_args'] = []\n         env['formal_args'] = formal_args\n-        if unpack_args:\n-            unpack_statements_no_default = []\n-            unpack_statements_with_default = []\n-            actual_names = []\n-            for arg, formal_arg, actual in zip(function['arguments'], formal_args, actuals):\n-                name = arg['name']\n-                actual_names.append(name)\n-                unpack_expr = UNPACK_ARG.substitute(formal_arg=formal_arg, actual=actual)\n-                if arg.get('python_default_init'):\n-                    unpack_statements_with_default.append(unpack_expr)\n-                else:\n-                    unpack_statements_no_default.append(unpack_expr)\n-            env['unpack_args'] = unpack_statements_no_default + unpack_statements_with_default\n-            env['actuals'] = actual_names\n-            code_template = PY_VARIABLE_CASE_WITH_UNPACK\n+        env['actuals'] = actuals\n+        if 'call_args' in declaration:\n+            env['dispatch_args'] = declaration['call_args']\n         else:\n-            env['actuals'] = actuals\n-            code_template = PY_VARIABLE_CASE\n-        if 'call_args' in function:\n-            env['dispatch_args'] = function['call_args']\n-        else:\n-            env['dispatch_args'] = [arg['name'] for arg in function['arguments']]\n-        if 'Tensor' in function['method_of']:\n+            env['dispatch_args'] = [arg['name'] for arg in declaration['arguments']]\n+        if 'Tensor' in declaration['method_of']:\n             env['dispatch_args'] = [arg for arg in env['dispatch_args'] if arg != 'self']\n-            env['dispatch_call'] = 'self.{}'.format(function['name'])\n+            env['dispatch_call'] = 'self.{}'.format(declaration['name'])\n         else:\n-            env['dispatch_call'] = 'at::{}'.format(function['name'])\n+            env['dispatch_call'] = 'at::{}'.format(declaration['name'])\n         env['AutoNoGIL'] = 'AutoNoGIL no_gil;'\n-        env['AutoGPU'] = auto_gpu(function)\n-        env['cond'] = 'if' if i == 0 else '} else if'\n-        env = nested_dict(env, function)\n+        env['AutoGPU'] = auto_gpu(declaration)\n+        env = nested_dict(env, nested_dict(base_env, declaration))\n+        body.append(PY_VARIABLE_CALL_DISPATCH.substitute(env))\n         py_method_dispatch.append(PY_VARIABLE_DISPATCH.substitute(env))\n-        return code_template.substitute(env)\n+        return body\n \n-    def process_function(name, functions):\n+    def emit_dispatch(i, declarations, base_env):\n+        if len(declarations) == 1:\n+            body = emit_single_dispatch(declarations[0], base_env)\n+        else:\n+            assert len(declarations) == 2\n+            env = {\n+                'call_dispatch_out': emit_single_dispatch(declarations[0], base_env),\n+                'call_dispatch': emit_single_dispatch(declarations[1], base_env),\n+            }\n+            out_idx = len([arg for arg in declarations[0]['arguments']\n+                           if not arg.get('output', False)])\n+            body = PY_VARIABLE_OUT.substitute(env, out_idx=out_idx).split('\\n')\n+        cond = 'if' if i == 0 else '} else if'\n+        return PY_VARIABLE_CASE.substitute(i=i, cond=cond, call_dispatch=body)\n+\n+    def process_function(name, declarations):\n         env = {\n             'name': name,\n             'dispatch_name': 'dispatch_{}'.format(name),\n             'pycname': 'THPVariable_{}'.format(name),\n             'prototypes': [],\n-            'max_args': max(len(o['arguments']) for o in functions),\n+            'max_args': max(len(o['arguments']) for o in declarations),\n             'unpack_self': [],\n             'dispatch': [],\n         }\n \n-        is_method = 'Tensor' in functions[0]['method_of']\n-        if is_method:\n+        if has_self:\n             env['unpack_self'] = [UNPACK_SELF]\n \n-        for o in functions:\n-            prototype = o['prototype']\n-            if is_method:\n+        grouped = group_declarations(declarations)\n+        for prototype, decls in grouped:\n+            if has_self:\n                 prototype = prototype.replace('Tensor self, ', '')\n                 prototype = prototype.replace('Tensor self', '')\n-            if not is_class:\n+            if not has_self:\n                 # Use 'input' instead of 'self' for NN functions\n                 prototype = prototype.replace('Tensor self', 'Tensor input')\n             prototype = prototype.replace('SparseTensor', 'Tensor')\n-            if 'deprecated' in o:\n+            if all('deprecated' in o for o in decls):\n                 prototype += '|deprecated'\n             env['prototypes'].append('\"{}\",'.format(prototype))\n \n-        for i, option in enumerate(functions):\n-            env['dispatch'].append(emit_dispatch(i, nested_dict(env, option)))\n+        for i, (_, decls) in enumerate(grouped):\n+            env['dispatch'].append(emit_dispatch(i, decls, env))\n         env['dispatch'].append('}')\n \n-        if len(functions) == 1 and len(functions[0]['args']) == 1 and is_method:\n+        if len(declarations) == 1 and len(declarations[0]['args']) == 1 and has_self:\n             tmpl = PY_VARIABLE_METHOD_NOARGS\n             env['actuals'] = ['self_']\n             env['flags'] = 'METH_NOARGS'\n         else:\n             tmpl = PY_VARIABLE_METHOD_VARARGS\n             env['flags'] = 'METH_VARARGS | METH_KEYWORDS'\n \n-        if is_class and not is_method:\n+        if not is_module and not has_self:\n             env['flags'] += ' | METH_STATIC'\n \n         py_methods.append(tmpl.substitute(env))\n         py_method_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))\n \n     for name in sorted(python_functions.keys()):\n         process_function(name, python_functions[name])\n+\n+    return {\n+        'py_methods': py_methods,\n+        'py_method_defs': py_method_defs,\n+        'py_method_dispatch': py_method_dispatch,\n+    }\n+\n+\n+def group_declarations(declarations):\n+    grouped = defaultdict(list)\n+\n+    # first group by prototype ignoring out arguments", "path": "tools/autograd/gen_python_functions.py", "position": null, "original_position": 378, "commit_id": "c7b63bd434ccce40348954794518030282ff0ddc", "original_commit_id": "2ff436294709b07373c384c6624382cf7dc9fe19", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "I think these are really function signatures.", "created_at": "2018-01-10T21:19:46Z", "updated_at": "2018-11-23T15:38:01Z", "html_url": "https://github.com/pytorch/pytorch/pull/4565#discussion_r160801175", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4565", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160801175"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4565#discussion_r160801175"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4565"}}, "body_html": "<p>I think these are really function signatures.</p>", "body_text": "I think these are really function signatures."}