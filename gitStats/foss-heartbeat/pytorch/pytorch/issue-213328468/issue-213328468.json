{"url": "https://api.github.com/repos/pytorch/pytorch/issues/971", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/971/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/971/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/971/events", "html_url": "https://github.com/pytorch/pytorch/issues/971", "id": 213328468, "node_id": "MDU6SXNzdWUyMTMzMjg0Njg=", "number": 971, "title": "backward() in Autograd Index Function is broken when masking with ByteTensor", "user": {"login": "bermanmaxim", "id": 5989894, "node_id": "MDQ6VXNlcjU5ODk4OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/5989894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bermanmaxim", "html_url": "https://github.com/bermanmaxim", "followers_url": "https://api.github.com/users/bermanmaxim/followers", "following_url": "https://api.github.com/users/bermanmaxim/following{/other_user}", "gists_url": "https://api.github.com/users/bermanmaxim/gists{/gist_id}", "starred_url": "https://api.github.com/users/bermanmaxim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bermanmaxim/subscriptions", "organizations_url": "https://api.github.com/users/bermanmaxim/orgs", "repos_url": "https://api.github.com/users/bermanmaxim/repos", "events_url": "https://api.github.com/users/bermanmaxim/events{/privacy}", "received_events_url": "https://api.github.com/users/bermanmaxim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-10T12:28:02Z", "updated_at": "2017-03-10T14:44:49Z", "closed_at": "2017-03-10T14:44:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello, I hit this possible bug, similar to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"209580426\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/828\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/828/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/828\">#828</a>: the gradients do not seem to back-propagate through a masked array, e.g.:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> Variable(torch.range(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nvalid <span class=\"pl-k\">=</span> torch.ByteTensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>])\nb <span class=\"pl-k\">=</span> a[valid]\nc <span class=\"pl-k\">=</span> b.sum()\nc.backward()\na.grad</pre></div>\n<p>returns a <code>[0, 0, 0]</code> tensor.<br>\n(I have this result with PyTorch compiled from commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/5e7f5db3328a07d54e9fdd91fc20254331f0f1e4/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/5e7f5db3328a07d54e9fdd91fc20254331f0f1e4\"><tt>5e7f5db</tt></a>.</p>", "body_text": "Hello, I hit this possible bug, similar to #828: the gradients do not seem to back-propagate through a masked array, e.g.:\na = Variable(torch.range(1, 3), requires_grad=True)\nvalid = torch.ByteTensor([1, 0, 1])\nb = a[valid]\nc = b.sum()\nc.backward()\na.grad\nreturns a [0, 0, 0] tensor.\n(I have this result with PyTorch compiled from commit 5e7f5db.", "body": "Hello, I hit this possible bug, similar to #828: the gradients do not seem to back-propagate through a masked array, e.g.:\r\n\r\n```python\r\na = Variable(torch.range(1, 3), requires_grad=True)\r\nvalid = torch.ByteTensor([1, 0, 1])\r\nb = a[valid]\r\nc = b.sum()\r\nc.backward()\r\na.grad\r\n```\r\nreturns a `[0, 0, 0]` tensor.\r\n(I have this result with PyTorch compiled from commit 5e7f5db3328a07d54e9fdd91fc20254331f0f1e4."}