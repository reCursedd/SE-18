{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/431627417", "html_url": "https://github.com/pytorch/pytorch/issues/10043#issuecomment-431627417", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10043", "id": 431627417, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTYyNzQxNw==", "user": {"login": "Balandat", "id": 1605878, "node_id": "MDQ6VXNlcjE2MDU4Nzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1605878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Balandat", "html_url": "https://github.com/Balandat", "followers_url": "https://api.github.com/users/Balandat/followers", "following_url": "https://api.github.com/users/Balandat/following{/other_user}", "gists_url": "https://api.github.com/users/Balandat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Balandat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Balandat/subscriptions", "organizations_url": "https://api.github.com/users/Balandat/orgs", "repos_url": "https://api.github.com/users/Balandat/repos", "events_url": "https://api.github.com/users/Balandat/events{/privacy}", "received_events_url": "https://api.github.com/users/Balandat/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-21T00:01:53Z", "updated_at": "2018-10-21T00:01:53Z", "author_association": "NONE", "body_html": "<p>My use case are optimizers for constrained problems, for which the constraint matrices are often very sparse. Consider linear inequality constraints of the form <code>Gx &lt;= h</code>. If <code>x</code> is of size <code>n</code>, a simple unit cube constraint <code>||x||_1 &lt;= 1</code> in that form requires a <code>G</code> matrix of size <code>2n x n</code>,  but with only <code>2n</code> non-zero entries, so memory efficiency is <code>1/n</code>. Thus sing sparse tensors here comes with huge memory savings and, if implemented sanely, also with significant speedups for the MVM and MMs involved. Under the hood, these solvers always involve solving some kind of linear system repeatedly, so sparse linear solvers would be a great addition, too. Finally, I'd like to be able to use this in batch mode as well :)</p>", "body_text": "My use case are optimizers for constrained problems, for which the constraint matrices are often very sparse. Consider linear inequality constraints of the form Gx <= h. If x is of size n, a simple unit cube constraint ||x||_1 <= 1 in that form requires a G matrix of size 2n x n,  but with only 2n non-zero entries, so memory efficiency is 1/n. Thus sing sparse tensors here comes with huge memory savings and, if implemented sanely, also with significant speedups for the MVM and MMs involved. Under the hood, these solvers always involve solving some kind of linear system repeatedly, so sparse linear solvers would be a great addition, too. Finally, I'd like to be able to use this in batch mode as well :)", "body": "My use case are optimizers for constrained problems, for which the constraint matrices are often very sparse. Consider linear inequality constraints of the form `Gx <= h`. If `x` is of size `n`, a simple unit cube constraint `||x||_1 <= 1` in that form requires a `G` matrix of size `2n x n`,  but with only `2n` non-zero entries, so memory efficiency is `1/n`. Thus sing sparse tensors here comes with huge memory savings and, if implemented sanely, also with significant speedups for the MVM and MMs involved. Under the hood, these solvers always involve solving some kind of linear system repeatedly, so sparse linear solvers would be a great addition, too. Finally, I'd like to be able to use this in batch mode as well :)"}