{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/387919411", "html_url": "https://github.com/pytorch/pytorch/issues/5014#issuecomment-387919411", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5014", "id": 387919411, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NzkxOTQxMQ==", "user": {"login": "asford", "id": 282792, "node_id": "MDQ6VXNlcjI4Mjc5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/282792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asford", "html_url": "https://github.com/asford", "followers_url": "https://api.github.com/users/asford/followers", "following_url": "https://api.github.com/users/asford/following{/other_user}", "gists_url": "https://api.github.com/users/asford/gists{/gist_id}", "starred_url": "https://api.github.com/users/asford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asford/subscriptions", "organizations_url": "https://api.github.com/users/asford/orgs", "repos_url": "https://api.github.com/users/asford/repos", "events_url": "https://api.github.com/users/asford/events{/privacy}", "received_events_url": "https://api.github.com/users/asford/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-10T01:03:38Z", "updated_at": "2018-05-10T01:03:38Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Just to support the point above, this becomes quite useful when using reshape &amp; broadcast to perform broadcast operations over variable-sized collections. As a, somewhat contrived, example imagine a function calculating of inter-coordinate distances, given by <code>(a-b).norm()</code>, in batch for a set of points. Intuitively, the following code would be expected to work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">torch_inter_coord_distance</span>(<span class=\"pl-smi\">a</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[n,3]<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">b</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[m, 3]<span class=\"pl-pds\">\"</span></span>) -&gt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[n, m]<span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-k\">return</span> (a.unsqueeze(<span class=\"pl-c1\">1</span>) <span class=\"pl-k\">-</span> b.unsqueeze(<span class=\"pl-c1\">0</span>)).norm(<span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)</pre></div>\n<p>However, this is impossible to express for \"empty\" batches without broadcasting along 0-sized dimensions.</p>\n<p>A full repo, starting with the equivalent numpy implementation:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">numpy_inter_coord_distance</span>(<span class=\"pl-smi\">a</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ndarray[n,3]<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">b</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ndarray[m, 3]<span class=\"pl-pds\">\"</span></span>) -&gt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ndarray[n, m]<span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-k\">return</span> numpy.linalg.norm((numpy.expand_dims(a, <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">-</span> numpy.expand_dims(b, <span class=\"pl-c1\">0</span>)), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n\ncoords <span class=\"pl-k\">=</span> numpy.arange(<span class=\"pl-c1\">12</span>).reshape(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>numpy:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>4x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords, coords))\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords, coords).shape)\n<span class=\"pl-c1\">print</span>()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">2</span>], coords))\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">2</span>], coords).shape)\n<span class=\"pl-c1\">print</span>()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>0x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">0</span>], coords))\n<span class=\"pl-c1\">print</span>(numpy_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">0</span>], coords).shape)\n<span class=\"pl-c1\">print</span>()\n\n<span class=\"pl-k\">import</span> torch\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">torch_inter_coord_distance</span>(<span class=\"pl-smi\">a</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[n,3]<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">b</span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[m, 3]<span class=\"pl-pds\">\"</span></span>) -&gt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Tensor[n, m]<span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-k\">return</span> (a.unsqueeze(<span class=\"pl-c1\">1</span>) <span class=\"pl-k\">-</span> b.unsqueeze(<span class=\"pl-c1\">0</span>)).norm(<span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n\ncoords <span class=\"pl-k\">=</span> torch.arange(<span class=\"pl-c1\">12</span>).reshape(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">3</span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>4x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords, coords))\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords, coords).shape)\n<span class=\"pl-c1\">print</span>()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>2x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">2</span>], coords))\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">2</span>], coords).shape)\n<span class=\"pl-c1\">print</span>()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>0x4:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">0</span>], coords))\n<span class=\"pl-c1\">print</span>(torch_inter_coord_distance(coords[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">0</span>], coords).shape)\n<span class=\"pl-c1\">print</span>()</pre></div>\n<p>Output:</p>\n<pre><code>numpy:\n4x4:\n[[ 0.          5.19615242 10.39230485 15.58845727]\n [ 5.19615242  0.          5.19615242 10.39230485]\n [10.39230485  5.19615242  0.          5.19615242]\n [15.58845727 10.39230485  5.19615242  0.        ]]\n(4, 4)\n\n2x4:\n[[ 0.          5.19615242 10.39230485 15.58845727]\n [ 5.19615242  0.          5.19615242 10.39230485]]\n(2, 4)\n\n0x4:\n[]\n(0, 4)\n\ntorch:\n4x4:\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\n        [  5.1962,   0.0000,   5.1962,  10.3923],\n        [ 10.3923,   5.1962,   0.0000,   5.1962],\n        [ 15.5885,  10.3923,   5.1962,   0.0000]])\ntorch.Size([4, 4])\n\n2x4:\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\n        [  5.1962,   0.0000,   5.1962,  10.3923]])\ntorch.Size([2, 4])\n\n0x4:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-6-3326f96b342b&gt; in &lt;module&gt;()\n     40 \n     41 print(\"0x4:\")\n---&gt; 42 print(torch_inter_coord_distance(coords[0:0], coords))\n     43 print(torch_inter_coord_distance(coords[0:0], coords).shape)\n     44 print()\n\n&lt;ipython-input-6-3326f96b342b&gt; in torch_inter_coord_distance(a, b)\n     24 \n     25 def torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -&gt; \"Tensor[n, m]\":\n---&gt; 26     return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\n     27 \n     28 coords = torch.arange(12).reshape(4, 3)\n\nRuntimeError: cannot unsqueeze empty tensor\n</code></pre>", "body_text": "Just to support the point above, this becomes quite useful when using reshape & broadcast to perform broadcast operations over variable-sized collections. As a, somewhat contrived, example imagine a function calculating of inter-coordinate distances, given by (a-b).norm(), in batch for a set of points. Intuitively, the following code would be expected to work:\ndef torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\n    return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\nHowever, this is impossible to express for \"empty\" batches without broadcasting along 0-sized dimensions.\nA full repo, starting with the equivalent numpy implementation:\nimport numpy\n\ndef numpy_inter_coord_distance(a: \"ndarray[n,3]\", b: \"ndarray[m, 3]\") -> \"ndarray[n, m]\":\n    return numpy.linalg.norm((numpy.expand_dims(a, 1) - numpy.expand_dims(b, 0)), axis=-1)\n\ncoords = numpy.arange(12).reshape(4, 3)\nprint(\"numpy:\")\nprint(\"4x4:\")\nprint(numpy_inter_coord_distance(coords, coords))\nprint(numpy_inter_coord_distance(coords, coords).shape)\nprint()\n\nprint(\"2x4:\")\nprint(numpy_inter_coord_distance(coords[0:2], coords))\nprint(numpy_inter_coord_distance(coords[0:2], coords).shape)\nprint()\n\nprint(\"0x4:\")\nprint(numpy_inter_coord_distance(coords[0:0], coords))\nprint(numpy_inter_coord_distance(coords[0:0], coords).shape)\nprint()\n\nimport torch\n\ndef torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\n    return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\n\ncoords = torch.arange(12).reshape(4, 3)\n\nprint(\"torch:\")\nprint(\"4x4:\")\nprint(torch_inter_coord_distance(coords, coords))\nprint(torch_inter_coord_distance(coords, coords).shape)\nprint()\n\nprint(\"2x4:\")\nprint(torch_inter_coord_distance(coords[0:2], coords))\nprint(torch_inter_coord_distance(coords[0:2], coords).shape)\nprint()\n\nprint(\"0x4:\")\nprint(torch_inter_coord_distance(coords[0:0], coords))\nprint(torch_inter_coord_distance(coords[0:0], coords).shape)\nprint()\nOutput:\nnumpy:\n4x4:\n[[ 0.          5.19615242 10.39230485 15.58845727]\n [ 5.19615242  0.          5.19615242 10.39230485]\n [10.39230485  5.19615242  0.          5.19615242]\n [15.58845727 10.39230485  5.19615242  0.        ]]\n(4, 4)\n\n2x4:\n[[ 0.          5.19615242 10.39230485 15.58845727]\n [ 5.19615242  0.          5.19615242 10.39230485]]\n(2, 4)\n\n0x4:\n[]\n(0, 4)\n\ntorch:\n4x4:\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\n        [  5.1962,   0.0000,   5.1962,  10.3923],\n        [ 10.3923,   5.1962,   0.0000,   5.1962],\n        [ 15.5885,  10.3923,   5.1962,   0.0000]])\ntorch.Size([4, 4])\n\n2x4:\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\n        [  5.1962,   0.0000,   5.1962,  10.3923]])\ntorch.Size([2, 4])\n\n0x4:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-6-3326f96b342b> in <module>()\n     40 \n     41 print(\"0x4:\")\n---> 42 print(torch_inter_coord_distance(coords[0:0], coords))\n     43 print(torch_inter_coord_distance(coords[0:0], coords).shape)\n     44 print()\n\n<ipython-input-6-3326f96b342b> in torch_inter_coord_distance(a, b)\n     24 \n     25 def torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\n---> 26     return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\n     27 \n     28 coords = torch.arange(12).reshape(4, 3)\n\nRuntimeError: cannot unsqueeze empty tensor", "body": "Just to support the point above, this becomes quite useful when using reshape & broadcast to perform broadcast operations over variable-sized collections. As a, somewhat contrived, example imagine a function calculating of inter-coordinate distances, given by `(a-b).norm()`, in batch for a set of points. Intuitively, the following code would be expected to work:\r\n\r\n```python\r\ndef torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\r\n    return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\r\n```\r\n\r\nHowever, this is impossible to express for \"empty\" batches without broadcasting along 0-sized dimensions. \r\n\r\nA full repo, starting with the equivalent numpy implementation:\r\n```python\r\nimport numpy\r\n\r\ndef numpy_inter_coord_distance(a: \"ndarray[n,3]\", b: \"ndarray[m, 3]\") -> \"ndarray[n, m]\":\r\n    return numpy.linalg.norm((numpy.expand_dims(a, 1) - numpy.expand_dims(b, 0)), axis=-1)\r\n\r\ncoords = numpy.arange(12).reshape(4, 3)\r\nprint(\"numpy:\")\r\nprint(\"4x4:\")\r\nprint(numpy_inter_coord_distance(coords, coords))\r\nprint(numpy_inter_coord_distance(coords, coords).shape)\r\nprint()\r\n\r\nprint(\"2x4:\")\r\nprint(numpy_inter_coord_distance(coords[0:2], coords))\r\nprint(numpy_inter_coord_distance(coords[0:2], coords).shape)\r\nprint()\r\n\r\nprint(\"0x4:\")\r\nprint(numpy_inter_coord_distance(coords[0:0], coords))\r\nprint(numpy_inter_coord_distance(coords[0:0], coords).shape)\r\nprint()\r\n\r\nimport torch\r\n\r\ndef torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\r\n    return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\r\n\r\ncoords = torch.arange(12).reshape(4, 3)\r\n\r\nprint(\"torch:\")\r\nprint(\"4x4:\")\r\nprint(torch_inter_coord_distance(coords, coords))\r\nprint(torch_inter_coord_distance(coords, coords).shape)\r\nprint()\r\n\r\nprint(\"2x4:\")\r\nprint(torch_inter_coord_distance(coords[0:2], coords))\r\nprint(torch_inter_coord_distance(coords[0:2], coords).shape)\r\nprint()\r\n\r\nprint(\"0x4:\")\r\nprint(torch_inter_coord_distance(coords[0:0], coords))\r\nprint(torch_inter_coord_distance(coords[0:0], coords).shape)\r\nprint()\r\n```\r\nOutput:\r\n```\r\nnumpy:\r\n4x4:\r\n[[ 0.          5.19615242 10.39230485 15.58845727]\r\n [ 5.19615242  0.          5.19615242 10.39230485]\r\n [10.39230485  5.19615242  0.          5.19615242]\r\n [15.58845727 10.39230485  5.19615242  0.        ]]\r\n(4, 4)\r\n\r\n2x4:\r\n[[ 0.          5.19615242 10.39230485 15.58845727]\r\n [ 5.19615242  0.          5.19615242 10.39230485]]\r\n(2, 4)\r\n\r\n0x4:\r\n[]\r\n(0, 4)\r\n\r\ntorch:\r\n4x4:\r\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\r\n        [  5.1962,   0.0000,   5.1962,  10.3923],\r\n        [ 10.3923,   5.1962,   0.0000,   5.1962],\r\n        [ 15.5885,  10.3923,   5.1962,   0.0000]])\r\ntorch.Size([4, 4])\r\n\r\n2x4:\r\ntensor([[  0.0000,   5.1962,  10.3923,  15.5885],\r\n        [  5.1962,   0.0000,   5.1962,  10.3923]])\r\ntorch.Size([2, 4])\r\n\r\n0x4:\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-6-3326f96b342b> in <module>()\r\n     40 \r\n     41 print(\"0x4:\")\r\n---> 42 print(torch_inter_coord_distance(coords[0:0], coords))\r\n     43 print(torch_inter_coord_distance(coords[0:0], coords).shape)\r\n     44 print()\r\n\r\n<ipython-input-6-3326f96b342b> in torch_inter_coord_distance(a, b)\r\n     24 \r\n     25 def torch_inter_coord_distance(a: \"Tensor[n,3]\", b: \"Tensor[m, 3]\") -> \"Tensor[n, m]\":\r\n---> 26     return (a.unsqueeze(1) - b.unsqueeze(0)).norm(dim=-1)\r\n     27 \r\n     28 coords = torch.arange(12).reshape(4, 3)\r\n\r\nRuntimeError: cannot unsqueeze empty tensor\r\n```"}