{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197664001", "pull_request_review_id": 131447739, "id": 197664001, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzY2NDAwMQ==", "diff_hunk": "@@ -309,40 +309,6 @@ static PyObject * THPVariable_invert(PyObject* self, PyObject* args) {\n   END_HANDLE_TH_ERRORS\n }\n \n-static PyObject * THPVariable_cpu(PyObject* self, PyObject* args)\n-{\n-   HANDLE_TH_ERRORS\n-   auto& self_ = reinterpret_cast<THPVariable*>(self)->cdata;\n-   auto backend = self_.is_sparse() ? Backend::SparseCPU : Backend::CPU;\n-   auto& type = self_.type().toBackend(backend);\n-   return wrap(torch::utils::dispatch_type_conversion(self_, type));\n-   END_HANDLE_TH_ERRORS\n-}\n-\n-static PyObject * THPVariable_cuda(PyObject* self, PyObject* args, PyObject* kwargs)\n-{\n-  HANDLE_TH_ERRORS\n-  static PythonArgParser parser({\n-    \"cuda(Device? device=None, bool non_blocking=False)\",\n-    \"cuda(Device? device=None, bool async=False)|deprecated\"\n-  });\n-  auto& self_ = reinterpret_cast<THPVariable*>(self)->cdata;\n-  ParsedArgs<2> parsed_args;\n-  auto r = parser.parse(args, kwargs, parsed_args);\n-  auto backend = self_.is_sparse() ? at::kSparseCUDA : at::kCUDA;\n-  auto& type = self_.type().toBackend(backend);\n-  auto device_obj = r.device(0);\n-  if (!r.isNone(0) && device_obj.is_cpu()) {\n-    throw std::runtime_error(\"Invalid device, must be cuda device\");\n-  }\n-  int32_t device_index = -1;", "path": "tools/autograd/templates/python_variable_methods.cpp", "position": 30, "original_position": 30, "commit_id": "66b18b5471390a0c888cd3e271a411268c4f01e6", "original_commit_id": "66b18b5471390a0c888cd3e271a411268c4f01e6", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "Yeah so if you follow the logic flow here, the semantics of this method are (cf https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_conversion_dispatch.cpp#L24):\r\n1. If the device passed to `cuda(...)` supplies an index, the tensor will be allocated on that device,\r\n2. Else, allocate on the device index of `self_`.\r\n\r\nYou are changing the semantics to:\r\n1. If the device passed to `cuda(...)` supplies an index, the tensor will be allocated on that device,\r\n2. Else, allocate on the current device.\r\n\r\nThose two are not equivalent. A quick workaround would be to change the native function to (conceptually): \r\n```\r\nreturn self.to({at::kCUDA, device_index == -1 ? (self.is_cuda() ? self.get_device() : -1) : device_index}, non_blocking);\r\n```\r\nbut now what if the user actually did pass `Device(at::kCUDA, -1)`, and thus wanted the new tensor to be allocated on the default device? Then with the above scheme we'd be breaking it. That's why `dispatch_type_conversion` used an `at::optional<int32_t>` and then did funny logic around it.", "created_at": "2018-06-25T01:58:28Z", "updated_at": "2018-11-23T15:46:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/8835#discussion_r197664001", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8835", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197664001"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8835#discussion_r197664001"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8835"}}, "body_html": "<p>Yeah so if you follow the logic flow here, the semantics of this method are (cf <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_conversion_dispatch.cpp#L24\">https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_conversion_dispatch.cpp#L24</a>):</p>\n<ol>\n<li>If the device passed to <code>cuda(...)</code> supplies an index, the tensor will be allocated on that device,</li>\n<li>Else, allocate on the device index of <code>self_</code>.</li>\n</ol>\n<p>You are changing the semantics to:</p>\n<ol>\n<li>If the device passed to <code>cuda(...)</code> supplies an index, the tensor will be allocated on that device,</li>\n<li>Else, allocate on the current device.</li>\n</ol>\n<p>Those two are not equivalent. A quick workaround would be to change the native function to (conceptually):</p>\n<pre><code>return self.to({at::kCUDA, device_index == -1 ? (self.is_cuda() ? self.get_device() : -1) : device_index}, non_blocking);\n</code></pre>\n<p>but now what if the user actually did pass <code>Device(at::kCUDA, -1)</code>, and thus wanted the new tensor to be allocated on the default device? Then with the above scheme we'd be breaking it. That's why <code>dispatch_type_conversion</code> used an <code>at::optional&lt;int32_t&gt;</code> and then did funny logic around it.</p>", "body_text": "Yeah so if you follow the logic flow here, the semantics of this method are (cf https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_conversion_dispatch.cpp#L24):\n\nIf the device passed to cuda(...) supplies an index, the tensor will be allocated on that device,\nElse, allocate on the device index of self_.\n\nYou are changing the semantics to:\n\nIf the device passed to cuda(...) supplies an index, the tensor will be allocated on that device,\nElse, allocate on the current device.\n\nThose two are not equivalent. A quick workaround would be to change the native function to (conceptually):\nreturn self.to({at::kCUDA, device_index == -1 ? (self.is_cuda() ? self.get_device() : -1) : device_index}, non_blocking);\n\nbut now what if the user actually did pass Device(at::kCUDA, -1), and thus wanted the new tensor to be allocated on the default device? Then with the above scheme we'd be breaking it. That's why dispatch_type_conversion used an at::optional<int32_t> and then did funny logic around it.", "in_reply_to_id": 197662943}