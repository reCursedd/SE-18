{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7038", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7038/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7038/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7038/events", "html_url": "https://github.com/pytorch/pytorch/issues/7038", "id": 318414669, "node_id": "MDU6SXNzdWUzMTg0MTQ2Njk=", "number": 7038, "title": "torch.stft output size is not right.", "user": {"login": "erogol", "id": 1402048, "node_id": "MDQ6VXNlcjE0MDIwNDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1402048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erogol", "html_url": "https://github.com/erogol", "followers_url": "https://api.github.com/users/erogol/followers", "following_url": "https://api.github.com/users/erogol/following{/other_user}", "gists_url": "https://api.github.com/users/erogol/gists{/gist_id}", "starred_url": "https://api.github.com/users/erogol/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erogol/subscriptions", "organizations_url": "https://api.github.com/users/erogol/orgs", "repos_url": "https://api.github.com/users/erogol/repos", "events_url": "https://api.github.com/users/erogol/events{/privacy}", "received_events_url": "https://api.github.com/users/erogol/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-04-27T13:43:09Z", "updated_at": "2018-07-17T18:39:47Z", "closed_at": "2018-05-29T22:39:48Z", "author_association": "NONE", "body_html": "<p>I try replace librosa functions with pytorch here <a href=\"https://github.com/mozilla/TTS\">https://github.com/mozilla/TTS</a></p>\n<p>What I realized is, output sequence lengths are different for these two functions.</p>\n<p>Below functions are used for testing. The point is given a audio signal in size 224960, pytorch's output is in size [815, 1025, 2] and librosa's [819, 1025].</p>\n<p>Given the parameters <code>n_fft, hop_length, win_length = [2048, 275, 1102]</code> 819 seems right.</p>\n<div class=\"highlight highlight-source-python\"><pre>win <span class=\"pl-k\">=</span> torch.hann_window(win_length).cuda()\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">spectrogram_torch</span>(<span class=\"pl-smi\">y</span>):\n    n_fft, hop_length, win_length <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">2048</span>, <span class=\"pl-c1\">275</span>, <span class=\"pl-c1\">1102</span>]\n    y[<span class=\"pl-c1\">1</span>:] <span class=\"pl-k\">=</span> y[<span class=\"pl-c1\">1</span>:] <span class=\"pl-k\">-</span> <span class=\"pl-c1\">0.097</span> <span class=\"pl-k\">*</span> y[:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n    <span class=\"pl-c1\">print</span>(y.shape)\n    start <span class=\"pl-k\">=</span> time.time()\n    D <span class=\"pl-k\">=</span> torch.stft(y, <span class=\"pl-v\">frame_length</span><span class=\"pl-k\">=</span>win_length, <span class=\"pl-v\">hop</span><span class=\"pl-k\">=</span>hop_length, <span class=\"pl-v\">fft_size</span><span class=\"pl-k\">=</span>n_fft,\n                   <span class=\"pl-v\">onesided</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">window</span><span class=\"pl-k\">=</span>win)[:, :, <span class=\"pl-c1\">1</span>]\n    <span class=\"pl-c1\">print</span>(time.time()<span class=\"pl-k\">-</span>start)\n    D <span class=\"pl-k\">=</span> torch.abs(D)\n    D[D<span class=\"pl-k\">==</span><span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1e-5</span>\n    D <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span> <span class=\"pl-k\">*</span> torch.log10(D)\n    D <span class=\"pl-k\">-=</span> ap.ref_level_db\n    D <span class=\"pl-k\">=</span> torch.clamp((D <span class=\"pl-k\">-</span> ap.min_level_db) <span class=\"pl-k\">/</span> <span class=\"pl-k\">-</span>ap.min_level_db, <span class=\"pl-c1\">1e-8</span>, <span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">return</span> D\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">spectrogram</span>(<span class=\"pl-smi\">y</span>):\n    start <span class=\"pl-k\">=</span> time.time()\n    D <span class=\"pl-k\">=</span> ap.apply_preemphasis(y)\n    n_fft, hop_length, win_length <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">2048</span>, <span class=\"pl-c1\">275</span>, <span class=\"pl-c1\">1102</span>]\n    D <span class=\"pl-k\">=</span> librosa.stft(<span class=\"pl-v\">y</span><span class=\"pl-k\">=</span>D, <span class=\"pl-v\">n_fft</span><span class=\"pl-k\">=</span>n_fft, <span class=\"pl-v\">hop_length</span><span class=\"pl-k\">=</span>hop_length, <span class=\"pl-v\">win_length</span><span class=\"pl-k\">=</span>win_length)\n    <span class=\"pl-c1\">print</span>(time.time()<span class=\"pl-k\">-</span>start)\n    S <span class=\"pl-k\">=</span> ap._amp_to_db(np.abs(D)) <span class=\"pl-k\">-</span> ap.ref_level_db\n    S <span class=\"pl-k\">=</span> ap._normalize(S)\n    S <span class=\"pl-k\">=</span> S.astype(np.float32)\n    <span class=\"pl-k\">return</span> S</pre></div>", "body_text": "I try replace librosa functions with pytorch here https://github.com/mozilla/TTS\nWhat I realized is, output sequence lengths are different for these two functions.\nBelow functions are used for testing. The point is given a audio signal in size 224960, pytorch's output is in size [815, 1025, 2] and librosa's [819, 1025].\nGiven the parameters n_fft, hop_length, win_length = [2048, 275, 1102] 819 seems right.\nwin = torch.hann_window(win_length).cuda()\ndef spectrogram_torch(y):\n    n_fft, hop_length, win_length = [2048, 275, 1102]\n    y[1:] = y[1:] - 0.097 * y[:-1]\n    print(y.shape)\n    start = time.time()\n    D = torch.stft(y, frame_length=win_length, hop=hop_length, fft_size=n_fft,\n                   onesided=True, window=win)[:, :, 1]\n    print(time.time()-start)\n    D = torch.abs(D)\n    D[D==0] = 1e-5\n    D = 20 * torch.log10(D)\n    D -= ap.ref_level_db\n    D = torch.clamp((D - ap.min_level_db) / -ap.min_level_db, 1e-8, 1)\n    return D\n\n\ndef spectrogram(y):\n    start = time.time()\n    D = ap.apply_preemphasis(y)\n    n_fft, hop_length, win_length = [2048, 275, 1102]\n    D = librosa.stft(y=D, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n    print(time.time()-start)\n    S = ap._amp_to_db(np.abs(D)) - ap.ref_level_db\n    S = ap._normalize(S)\n    S = S.astype(np.float32)\n    return S", "body": "I try replace librosa functions with pytorch here https://github.com/mozilla/TTS\r\n\r\nWhat I realized is, output sequence lengths are different for these two functions.\r\n\r\nBelow functions are used for testing. The point is given a audio signal in size 224960, pytorch's output is in size [815, 1025, 2] and librosa's [819, 1025].\r\n\r\nGiven the parameters ```n_fft, hop_length, win_length = [2048, 275, 1102]``` 819 seems right. \r\n\r\n```python\r\nwin = torch.hann_window(win_length).cuda()\r\ndef spectrogram_torch(y):\r\n    n_fft, hop_length, win_length = [2048, 275, 1102]\r\n    y[1:] = y[1:] - 0.097 * y[:-1]\r\n    print(y.shape)\r\n    start = time.time()\r\n    D = torch.stft(y, frame_length=win_length, hop=hop_length, fft_size=n_fft,\r\n                   onesided=True, window=win)[:, :, 1]\r\n    print(time.time()-start)\r\n    D = torch.abs(D)\r\n    D[D==0] = 1e-5\r\n    D = 20 * torch.log10(D)\r\n    D -= ap.ref_level_db\r\n    D = torch.clamp((D - ap.min_level_db) / -ap.min_level_db, 1e-8, 1)\r\n    return D\r\n\r\n\r\ndef spectrogram(y):\r\n    start = time.time()\r\n    D = ap.apply_preemphasis(y)\r\n    n_fft, hop_length, win_length = [2048, 275, 1102]\r\n    D = librosa.stft(y=D, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\r\n    print(time.time()-start)\r\n    S = ap._amp_to_db(np.abs(D)) - ap.ref_level_db\r\n    S = ap._normalize(S)\r\n    S = S.astype(np.float32)\r\n    return S\r\n```"}