{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8012", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8012/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8012/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8012/events", "html_url": "https://github.com/pytorch/pytorch/issues/8012", "id": 328336675, "node_id": "MDU6SXNzdWUzMjgzMzY2NzU=", "number": 8012, "title": "[Caffe2] VideoInput/LMDB Reader to Standalone Predictor Question", "user": {"login": "mkummer225", "id": 7843299, "node_id": "MDQ6VXNlcjc4NDMyOTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7843299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mkummer225", "html_url": "https://github.com/mkummer225", "followers_url": "https://api.github.com/users/mkummer225/followers", "following_url": "https://api.github.com/users/mkummer225/following{/other_user}", "gists_url": "https://api.github.com/users/mkummer225/gists{/gist_id}", "starred_url": "https://api.github.com/users/mkummer225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mkummer225/subscriptions", "organizations_url": "https://api.github.com/users/mkummer225/orgs", "repos_url": "https://api.github.com/users/mkummer225/repos", "events_url": "https://api.github.com/users/mkummer225/events{/privacy}", "received_events_url": "https://api.github.com/users/mkummer225/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-06-01T00:01:35Z", "updated_at": "2018-06-27T03:03:10Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hey Caffe2/PyTorch team,</p>\n<p>I had a question about going from a trained model (.mdl format) to a standalone predictor model. I've been able to load the .mdl file as follows:</p>\n<pre><code>meta_net_def = pred_exp.load_from_db('trained_model.mdl', 'minidb')\ninit_net = core.Net(\n    pred_utils.GetNet(meta_net_def, predictor_constants.GLOBAL_INIT_NET_TYPE)\n)\npredict_net = core.Net(\n    pred_utils.GetNet(meta_net_def, predictor_constants.PREDICT_NET_TYPE)\n)\n</code></pre>\n<p>However, the model, once loaded, is expecting to be executed on a GPU and initiated via an LMDB reader:<br>\n<strong>init_net proto:</strong></p>\n<pre><code>input: \"!!PREDICTOR_DBREADER\"\noutput: \"gpu_0/conv1_middle_w\"\noutput: \"gpu_0/conv1_middle_spatbn_relu_s\"\noutput: \"gpu_0/conv1_middle_spatbn_relu_b\"\noutput: \"gpu_0/conv1_w\"\noutput: \"gpu_0/conv1_spatbn_relu_s\"\noutput: \"gpu_0/conv1_spatbn_relu_b\"\noutput: \"gpu_0/comp_0_conv_1_middle_w\"\noutput: \"gpu_0/comp_0_spatbn_1_middle_s\"\n...\nname: \"\"\ntype: \"Load\"\n</code></pre>\n<p><strong>first two layers in predict_net proto:</strong></p>\n<pre><code>input: \"trained_init/CreateDB\"\noutput: \"gpu_0/data\"\noutput: \"gpu_0/label\"\nname: \"data\"\ntype: \"VideoInput\"\narg {\n... bunch of VideoInput args ...\n}\ndevice_option {\n  device_type: 1\n  cuda_gpu_id: 0\n}\n\ninput: \"gpu_0/data\"\noutput: \"gpu_0/data\"\nname: \"\"\ntype: \"StopGradient\"\ndevice_option {\n  device_type: 1\n  cuda_gpu_id: 0\n}\n\n{convolutional layers, etc...}\n</code></pre>\n<p>My questions are:<br>\na) how would I go about removing/modifying the top layer(s) of the init and predict nets to allow for individual predictions (without requiring the creation of an LMDB, etc)? (I'd like to be able to point predict.py to a folder or to a single video, load the data into np arrays or otherwise, then feed those into the Caffe2 model for predictions)</p>\n<p>b) how would I go about switching from GPU to CPU execution?</p>\n<p>c) is there anything else I might be missing when going from a training 'checkpoint' .mdl file to a prediction model?</p>\n<p>Thanks so much!</p>", "body_text": "Hey Caffe2/PyTorch team,\nI had a question about going from a trained model (.mdl format) to a standalone predictor model. I've been able to load the .mdl file as follows:\nmeta_net_def = pred_exp.load_from_db('trained_model.mdl', 'minidb')\ninit_net = core.Net(\n    pred_utils.GetNet(meta_net_def, predictor_constants.GLOBAL_INIT_NET_TYPE)\n)\npredict_net = core.Net(\n    pred_utils.GetNet(meta_net_def, predictor_constants.PREDICT_NET_TYPE)\n)\n\nHowever, the model, once loaded, is expecting to be executed on a GPU and initiated via an LMDB reader:\ninit_net proto:\ninput: \"!!PREDICTOR_DBREADER\"\noutput: \"gpu_0/conv1_middle_w\"\noutput: \"gpu_0/conv1_middle_spatbn_relu_s\"\noutput: \"gpu_0/conv1_middle_spatbn_relu_b\"\noutput: \"gpu_0/conv1_w\"\noutput: \"gpu_0/conv1_spatbn_relu_s\"\noutput: \"gpu_0/conv1_spatbn_relu_b\"\noutput: \"gpu_0/comp_0_conv_1_middle_w\"\noutput: \"gpu_0/comp_0_spatbn_1_middle_s\"\n...\nname: \"\"\ntype: \"Load\"\n\nfirst two layers in predict_net proto:\ninput: \"trained_init/CreateDB\"\noutput: \"gpu_0/data\"\noutput: \"gpu_0/label\"\nname: \"data\"\ntype: \"VideoInput\"\narg {\n... bunch of VideoInput args ...\n}\ndevice_option {\n  device_type: 1\n  cuda_gpu_id: 0\n}\n\ninput: \"gpu_0/data\"\noutput: \"gpu_0/data\"\nname: \"\"\ntype: \"StopGradient\"\ndevice_option {\n  device_type: 1\n  cuda_gpu_id: 0\n}\n\n{convolutional layers, etc...}\n\nMy questions are:\na) how would I go about removing/modifying the top layer(s) of the init and predict nets to allow for individual predictions (without requiring the creation of an LMDB, etc)? (I'd like to be able to point predict.py to a folder or to a single video, load the data into np arrays or otherwise, then feed those into the Caffe2 model for predictions)\nb) how would I go about switching from GPU to CPU execution?\nc) is there anything else I might be missing when going from a training 'checkpoint' .mdl file to a prediction model?\nThanks so much!", "body": "Hey Caffe2/PyTorch team,\r\n\r\nI had a question about going from a trained model (.mdl format) to a standalone predictor model. I've been able to load the .mdl file as follows:\r\n```\r\nmeta_net_def = pred_exp.load_from_db('trained_model.mdl', 'minidb')\r\ninit_net = core.Net(\r\n    pred_utils.GetNet(meta_net_def, predictor_constants.GLOBAL_INIT_NET_TYPE)\r\n)\r\npredict_net = core.Net(\r\n    pred_utils.GetNet(meta_net_def, predictor_constants.PREDICT_NET_TYPE)\r\n)\r\n```\r\n\r\nHowever, the model, once loaded, is expecting to be executed on a GPU and initiated via an LMDB reader:\r\n**init_net proto:**\r\n```\r\ninput: \"!!PREDICTOR_DBREADER\"\r\noutput: \"gpu_0/conv1_middle_w\"\r\noutput: \"gpu_0/conv1_middle_spatbn_relu_s\"\r\noutput: \"gpu_0/conv1_middle_spatbn_relu_b\"\r\noutput: \"gpu_0/conv1_w\"\r\noutput: \"gpu_0/conv1_spatbn_relu_s\"\r\noutput: \"gpu_0/conv1_spatbn_relu_b\"\r\noutput: \"gpu_0/comp_0_conv_1_middle_w\"\r\noutput: \"gpu_0/comp_0_spatbn_1_middle_s\"\r\n...\r\nname: \"\"\r\ntype: \"Load\"\r\n```\r\n\r\n**first two layers in predict_net proto:**\r\n```\r\ninput: \"trained_init/CreateDB\"\r\noutput: \"gpu_0/data\"\r\noutput: \"gpu_0/label\"\r\nname: \"data\"\r\ntype: \"VideoInput\"\r\narg {\r\n... bunch of VideoInput args ...\r\n}\r\ndevice_option {\r\n  device_type: 1\r\n  cuda_gpu_id: 0\r\n}\r\n\r\ninput: \"gpu_0/data\"\r\noutput: \"gpu_0/data\"\r\nname: \"\"\r\ntype: \"StopGradient\"\r\ndevice_option {\r\n  device_type: 1\r\n  cuda_gpu_id: 0\r\n}\r\n\r\n{convolutional layers, etc...}\r\n```\r\n\r\nMy questions are:\r\na) how would I go about removing/modifying the top layer(s) of the init and predict nets to allow for individual predictions (without requiring the creation of an LMDB, etc)? (I'd like to be able to point predict.py to a folder or to a single video, load the data into np arrays or otherwise, then feed those into the Caffe2 model for predictions)\r\n\r\nb) how would I go about switching from GPU to CPU execution?\r\n\r\nc) is there anything else I might be missing when going from a training 'checkpoint' .mdl file to a prediction model?\r\n\r\nThanks so much!"}