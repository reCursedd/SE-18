{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188129950", "pull_request_review_id": 119637311, "id": 188129950, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4ODEyOTk1MA==", "diff_hunk": "@@ -0,0 +1,139 @@\n+#pragma once\n+#include \"vec256.h\"\n+\n+namespace at { namespace vec256 {\n+\n+// TODO: Make this more efficient\n+template <typename scalar_t, typename Op>\n+inline scalar_t vec_reduce_all(\n+    const Op& vec_fun,\n+    vec256::Vec256<scalar_t> acc_vec,\n+    int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  scalar_t acc_arr[Vec::size];\n+  acc_vec.store(acc_arr);\n+  for (int64_t i = 1; i < size; i++) {\n+    scalar_t acc_arr_next[Vec::size];\n+    acc_arr_next[0] = acc_arr[i];\n+    Vec acc_vec_next = Vec::loadu(acc_arr_next);\n+    acc_vec = vec_fun(acc_vec, acc_vec_next);\n+  }\n+  acc_vec.store(acc_arr);\n+  return acc_arr[0];\n+}\n+\n+template <typename scalar_t, typename Op>\n+inline scalar_t reduce_all(const Op& vec_fun, scalar_t* data, int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  if (size < Vec::size)\n+    return vec_reduce_all(vec_fun, Vec::loadu(data, size), size);\n+  int64_t d = Vec::size;\n+  Vec acc_vec = Vec::loadu(data);\n+  for (; d < size - (size % Vec::size); d += Vec::size) {\n+    Vec data_vec = Vec::loadu(data + d);\n+    acc_vec = vec_fun(acc_vec, data_vec);\n+  }\n+  if (size - d > 0) {\n+    Vec data_vec = Vec::loadu(data + d, size - d);\n+    acc_vec = Vec::set(acc_vec, vec_fun(acc_vec, data_vec), size - d);\n+  }\n+  return vec_reduce_all(vec_fun, acc_vec, Vec::size);\n+}\n+\n+template <typename scalar_t, typename MapOp, typename ReduceOp>\n+inline scalar_t map_reduce_all(\n+    const MapOp& map_fun,\n+    const ReduceOp& red_fun,\n+    scalar_t* data,\n+    int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  if (size < Vec::size)\n+    return vec_reduce_all(red_fun, map_fun(Vec::loadu(data, size)), size);\n+  int64_t d = Vec::size;\n+  Vec acc_vec = map_fun(Vec::loadu(data));\n+  for (; d < size - (size % Vec::size); d += Vec::size) {\n+    Vec data_vec = Vec::loadu(data + d);\n+    data_vec = map_fun(data_vec);\n+    acc_vec = red_fun(acc_vec, data_vec);\n+  }\n+  if (size - d > 0) {\n+    Vec data_vec = Vec::loadu(data + d, size - d);\n+    data_vec = map_fun(data_vec);\n+    acc_vec = Vec::set(acc_vec, red_fun(acc_vec, data_vec), size - d);\n+  }\n+  return vec_reduce_all(red_fun, acc_vec, Vec::size);\n+}\n+\n+template <typename scalar_t, typename MapOp, typename ReduceOp>\n+inline scalar_t map2_reduce_all(\n+    const MapOp& map_fun,\n+    const ReduceOp& red_fun,\n+    scalar_t* data,\n+    scalar_t* data2,\n+    int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  if (size < Vec::size) {\n+    Vec data_vec = Vec::loadu(data, size);\n+    Vec data2_vec = Vec::loadu(data2, size);\n+    data_vec = map_fun(data_vec, data2_vec);\n+    return vec_reduce_all(red_fun, data_vec, size);\n+  }\n+  int64_t d = Vec::size;\n+  Vec acc_vec = map_fun(Vec::loadu(data), Vec::loadu(data2));\n+  for (; d < size - (size % Vec::size); d += Vec::size) {\n+    Vec data_vec = Vec::loadu(data + d);\n+    Vec data2_vec = Vec::loadu(data2 + d);\n+    data_vec = map_fun(data_vec, data2_vec);\n+    acc_vec = red_fun(acc_vec, data_vec);\n+  }\n+  if (size - d > 0) {\n+    Vec data_vec = Vec::loadu(data + d, size - d);\n+    Vec data2_vec = Vec::loadu(data2 + d, size - d);\n+    data_vec = map_fun(data_vec, data2_vec);\n+    acc_vec = Vec::set(acc_vec, red_fun(acc_vec, data_vec), size - d);\n+  }\n+  return vec_reduce_all(red_fun, acc_vec, Vec::size);\n+}\n+\n+template <typename scalar_t, typename Op>\n+inline void map(\n+    const Op& vec_fun,\n+    scalar_t* output_data,\n+    scalar_t* input_data,\n+    int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  int64_t d = 0;\n+  for (; d < size - (size % Vec::size); d += Vec::size) {\n+    Vec output_vec = vec_fun(Vec::loadu(input_data + d));\n+    output_vec.store(output_data + d);\n+  }\n+  if (size - d > 0) {\n+    Vec output_vec = vec_fun(Vec::loadu(input_data + d, size - d));\n+    output_vec.store(output_data + d, size - d);\n+  }\n+}\n+\n+template <typename scalar_t, typename Op>\n+inline void map2(\n+    const Op& vec_fun,\n+    scalar_t* output_data,\n+    scalar_t* input_data,\n+    scalar_t* input_data2,\n+    int64_t size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  int64_t d = 0;\n+  for (; d < size - (size % Vec::size); d += Vec::size) {\n+    Vec data_vec = Vec::loadu(input_data + d);\n+    Vec data_vec2 = Vec::loadu(input_data2 + d);\n+    Vec output_vec = vec_fun(data_vec, data_vec2);\n+    output_vec.store(output_data + d);\n+  }\n+  if (size - d > 0) {\n+    Vec data_vec = Vec::loadu(input_data + d, size - d);\n+    Vec data_vec2 = Vec::loadu(input_data2 + d, size - d);\n+    Vec output_vec = vec_fun(data_vec, data_vec2);\n+    output_vec.store(output_data + d, size - d);\n+  }\n+}", "path": "aten/src/ATen/cpu/vec256/functional.h", "position": 137, "original_position": 137, "commit_id": "b269b30289cf014a9bc3ce4924567ecb035a5fe1", "original_commit_id": "5daf54c358014219cfd16436f4db8f6fd8f45099", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Would be nice if we could just have generic templates for those (for any number of inputs), but this is fine", "created_at": "2018-05-14T23:40:35Z", "updated_at": "2018-11-23T15:44:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/7375#discussion_r188129950", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7375", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188129950"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7375#discussion_r188129950"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7375"}}, "body_html": "<p>Would be nice if we could just have generic templates for those (for any number of inputs), but this is fine</p>", "body_text": "Would be nice if we could just have generic templates for those (for any number of inputs), but this is fine"}