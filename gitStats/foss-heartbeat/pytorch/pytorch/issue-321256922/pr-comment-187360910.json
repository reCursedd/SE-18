{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187360910", "pull_request_review_id": 119125733, "id": 187360910, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NzM2MDkxMA==", "diff_hunk": "@@ -0,0 +1,484 @@\n+#include \"ATen/native/cpu/ActivationKernel.h\"\n+\n+#include <algorithm>\n+#include <iterator>\n+#include <limits>\n+#include <numeric>\n+\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/Parallel.h\"\n+#include \"ATen/cpu/vec256/vec256.h\"\n+#include \"ATen/optional.h\"\n+\n+// NOTE: In general we avoid calls into cmath for code compiled with AVX/AVX2\n+// This is because of SSE-AVX transitions and a bug in Glibc2.23\n+// See https://bugs.launchpad.net/ubuntu/+source/glibc/+bug/1663280\n+\n+namespace at { namespace native {\n+namespace {\n+\n+static tbb::affinity_partitioner ap;\n+\n+template <int64_t size>\n+inline int64_t _leftover(int64_t x, int64_t y) {\n+  if (x + size > y)\n+    return y - x;\n+  return size;\n+}\n+\n+template <typename scalar_t>\n+inline scalar_t _vec_sum(int64_t dim_size, scalar_t* input_data) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  for (int ii = 0; ii < dim_size; ii++) {\n+  }\n+  int64_t d = 0;\n+  Vec sum_vec(0);\n+  scalar_t sum = 0;\n+  Vec value(0);\n+  for (; d < dim_size; d += Vec::size) {\n+    if (d + Vec::size > dim_size) {\n+      // TODO: For some reason, when using partial loads, value isn't set to 0\n+      // on each iteration\n+      for (int64_t i = d; i < dim_size; i++) {\n+        sum += input_data[i];\n+      }\n+    } else {\n+      value.load(input_data + d);\n+      sum_vec = sum_vec + value;\n+    }\n+  }\n+  scalar_t sum_arr[Vec::size];\n+  sum_vec.store(sum_arr);\n+  for (int64_t i = 0; i < Vec::size; i++) {\n+    sum += sum_arr[i];\n+  }\n+  return sum;\n+}\n+\n+template <typename scalar_t>\n+inline scalar_t\n+_vec_sum_mul(int64_t dim_size, scalar_t* input_data, scalar_t* input_data2) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  int64_t d = 0;\n+  Vec sum_vec(0);\n+  scalar_t sum = 0;\n+  for (; d < dim_size; d += Vec::size) {\n+    if (d + Vec::size > dim_size) {\n+      for (int i = d; i < dim_size; i++) {\n+        sum += input_data[i] * input_data2[i];\n+      }\n+    } else {\n+      Vec value(0);\n+      Vec value2(0);\n+      value.load(input_data + d);\n+      value2.load(input_data2 + d);\n+      value = value * value2;\n+      sum_vec = sum_vec + value;\n+    }\n+  }\n+  scalar_t sum_arr[Vec::size];\n+  sum_vec.store(sum_arr);\n+  for (int64_t i = 0; i < Vec::size; i++) {\n+    sum += sum_arr[i];\n+  }\n+  return sum;\n+}\n+\n+template <typename scalar_t>\n+inline scalar_t _vec_max(int64_t dim_size, scalar_t* input_data) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  Vec max_val_vec(std::numeric_limits<scalar_t>::lowest());\n+  scalar_t max_val = std::numeric_limits<scalar_t>::lowest();\n+  for (int64_t d = 0; d < dim_size; d += Vec::size) {\n+    int64_t leftover = _leftover<Vec::size>(d, dim_size);\n+    Vec value;\n+    value.load(input_data + d, leftover);\n+    if (leftover < Vec::size) {\n+      for (int i = 0; i < leftover; i++) {\n+        if (input_data[d + i] > max_val) {\n+          max_val = input_data[d + i];\n+        }\n+      }\n+    } else {\n+      max_val_vec = vec256::max(value, max_val_vec);\n+    }\n+  }\n+  scalar_t max_val_arr[Vec::size];\n+  max_val_vec.store(max_val_arr);\n+  for (int64_t i = 0; i < Vec::size; i++) {\n+    if (max_val_arr[i] > max_val) {\n+      max_val = max_val_arr[i];\n+    }\n+  }\n+  return max_val;\n+}\n+\n+template <typename scalar_t>\n+inline void _vec_mul_scalarsub_write(\n+    scalar_t* grad_input_data,\n+    scalar_t* grad_data,\n+    scalar_t* output_data,\n+    int64_t dim_size,\n+    scalar_t sum) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  Vec sum_vec(sum);\n+  int64_t d = 0;\n+  for (; d < dim_size; d += Vec::size) {\n+    Vec output(0);\n+    Vec grad(0);\n+    int64_t leftover = _leftover<Vec::size>(d, dim_size);\n+    output.load(output_data + d, leftover);\n+    grad.load(grad_data + d, leftover);\n+    grad = grad - sum_vec;\n+    grad = grad * output;\n+\n+    grad.store(grad_input_data + d, leftover);\n+  }\n+}\n+\n+template <typename scalar_t>\n+inline void _vec_sub_exp_scalarmul_write(\n+    scalar_t* grad_input_data,\n+    scalar_t* grad_data,\n+    scalar_t* output_data,\n+    int64_t dim_size,\n+    scalar_t sum) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  Vec sum_vec(sum);\n+  int64_t d = 0;\n+  for (; d < dim_size; d += Vec::size) {\n+    Vec output(0);\n+    Vec grad(0);\n+    int64_t leftover = _leftover<Vec::size>(d, dim_size);\n+    output.load(output_data + d, leftover);\n+    grad.load(grad_data + d, leftover);\n+    output = output.exp();\n+    output = output * sum_vec;\n+    grad = grad - output;\n+\n+    grad.store(grad_input_data + d, leftover);\n+  }\n+}\n+\n+template <typename scalar_t>\n+inline scalar_t _vec_norm_exp_sum_write(\n+    scalar_t* output_data,\n+    int64_t dim_size,\n+    scalar_t* input_data,\n+    scalar_t max_input) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+\n+  int64_t d = 0;\n+  Vec tmpsum(0);\n+  Vec max_input_vec(max_input);\n+  scalar_t tmp_sum_arr[Vec::size];\n+  scalar_t tmp_sum_scalar = 0;\n+  for (; d < dim_size; d += Vec::size) {\n+    int64_t leftover = _leftover<Vec::size>(d, dim_size);\n+    Vec value(0);\n+    value.load(input_data + d, leftover);\n+    value = value - max_input_vec;\n+    value = value.exp();\n+    // Need to do a partial add\n+    if (d + Vec::size > dim_size) {\n+      scalar_t value_arr[Vec::size];\n+      value.store(value_arr);\n+      for (int64_t i = 0; i < dim_size - d; i++) {\n+        tmp_sum_scalar += value_arr[i];\n+      }\n+      value.store(output_data + d, leftover);\n+    } else {\n+      tmpsum = tmpsum + value;\n+      value.store(output_data + d);\n+    }\n+  }\n+  tmpsum.store(tmp_sum_arr);\n+  for (int64_t i = 0; i < Vec::size; i++) {\n+    tmp_sum_scalar += tmp_sum_arr[i];\n+  }\n+  return tmp_sum_scalar;\n+}\n+\n+template <typename scalar_t>\n+inline void _vec_log_softmax_lastdim(\n+    scalar_t* input_data_base,\n+    scalar_t* output_data_base,\n+    int64_t outer_size,\n+    int64_t dim_size) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  static constexpr int64_t CHUNK_SIZE = (128 / sizeof(scalar_t)) * Vec::size;", "path": "aten/src/ATen/native/cpu/ActivationKernel.cpp", "position": null, "original_position": 209, "commit_id": "b269b30289cf014a9bc3ce4924567ecb035a5fe1", "original_commit_id": "86cd5d1daee4eb5a2258769a99725d967b289dd1", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "body": "Size of a cacheline. 1024bits.", "created_at": "2018-05-10T15:12:19Z", "updated_at": "2018-11-23T15:43:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/7375#discussion_r187360910", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7375", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187360910"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7375#discussion_r187360910"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7375"}}, "body_html": "<p>Size of a cacheline. 1024bits.</p>", "body_text": "Size of a cacheline. 1024bits.", "in_reply_to_id": 187354590}