{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187360088", "pull_request_review_id": 119124681, "id": 187360088, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NzM2MDA4OA==", "diff_hunk": "@@ -0,0 +1,484 @@\n+#include \"ATen/native/cpu/ActivationKernel.h\"\n+\n+#include <algorithm>\n+#include <iterator>\n+#include <limits>\n+#include <numeric>\n+\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/Parallel.h\"\n+#include \"ATen/cpu/vec256/vec256.h\"\n+#include \"ATen/optional.h\"\n+\n+// NOTE: In general we avoid calls into cmath for code compiled with AVX/AVX2\n+// This is because of SSE-AVX transitions and a bug in Glibc2.23\n+// See https://bugs.launchpad.net/ubuntu/+source/glibc/+bug/1663280\n+\n+namespace at { namespace native {\n+namespace {\n+\n+static tbb::affinity_partitioner ap;\n+\n+template <int64_t size>\n+inline int64_t _leftover(int64_t x, int64_t y) {\n+  if (x + size > y)\n+    return y - x;\n+  return size;\n+}\n+\n+template <typename scalar_t>\n+inline scalar_t _vec_sum(int64_t dim_size, scalar_t* input_data) {\n+  using Vec = vec256::Vec256<scalar_t>;\n+  for (int ii = 0; ii < dim_size; ii++) {\n+  }\n+  int64_t d = 0;\n+  Vec sum_vec(0);\n+  scalar_t sum = 0;\n+  Vec value(0);\n+  for (; d < dim_size; d += Vec::size) {\n+    if (d + Vec::size > dim_size) {\n+      // TODO: For some reason, when using partial loads, value isn't set to 0\n+      // on each iteration\n+      for (int64_t i = d; i < dim_size; i++) {\n+        sum += input_data[i];\n+      }\n+    } else {\n+      value.load(input_data + d);\n+      sum_vec = sum_vec + value;\n+    }\n+  }\n+  scalar_t sum_arr[Vec::size];\n+  sum_vec.store(sum_arr);\n+  for (int64_t i = 0; i < Vec::size; i++) {\n+    sum += sum_arr[i];\n+  }", "path": "aten/src/ATen/native/cpu/ActivationKernel.cpp", "position": null, "original_position": 54, "commit_id": "b269b30289cf014a9bc3ce4924567ecb035a5fe1", "original_commit_id": "86cd5d1daee4eb5a2258769a99725d967b289dd1", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "body": "Could be part of the reduce helpers.", "created_at": "2018-05-10T15:09:29Z", "updated_at": "2018-11-23T15:43:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/7375#discussion_r187360088", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7375", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187360088"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7375#discussion_r187360088"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7375"}}, "body_html": "<p>Could be part of the reduce helpers.</p>", "body_text": "Could be part of the reduce helpers.", "in_reply_to_id": 187352712}