{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10587", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10587/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10587/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10587/events", "html_url": "https://github.com/pytorch/pytorch/issues/10587", "id": 351308196, "node_id": "MDU6SXNzdWUzNTEzMDgxOTY=", "number": 10587, "title": "[ppc64le/pytorch] test_c10d.ProcessGroupNCCLTest.test_allgather_ops illegal memory access", "user": {"login": "avmgithub", "id": 9083746, "node_id": "MDQ6VXNlcjkwODM3NDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9083746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avmgithub", "html_url": "https://github.com/avmgithub", "followers_url": "https://api.github.com/users/avmgithub/followers", "following_url": "https://api.github.com/users/avmgithub/following{/other_user}", "gists_url": "https://api.github.com/users/avmgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/avmgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avmgithub/subscriptions", "organizations_url": "https://api.github.com/users/avmgithub/orgs", "repos_url": "https://api.github.com/users/avmgithub/repos", "events_url": "https://api.github.com/users/avmgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/avmgithub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-08-16T17:57:26Z", "updated_at": "2018-08-29T11:37:58Z", "closed_at": "2018-08-29T11:37:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>PyTorch version:  torch (0.5.0a0+00f2731)<br>\nLinked with NCCL2 from nvidia<br>\nCUDA 9.2  CuDNN 7.14<br>\nRH 7.5   ppc64le   Power9 ( but I saw it also happen on a Power8)<br>\n4 x Volta GPUs</p>\n<p>I have following set when I build:<br>\nexport USE_SYSTEM_NCCL=TRUE<br>\nexport NCCL_ROOT_DIR=/usr/local/cuda/<br>\nexport NCCL_LIB_DIR=/usr/local/cuda/lib64<br>\nexport NCCL_INCLUDE_DIR=/usr/local/cuda/include</p>\n<p>here is the error:<br>\n$ python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops<br>\nTHCudaCheck FAIL file=/home/freddie/pytorch/aten/src/THC/THCTensorCopy.cu line=87 error=77 : an illegal memory access was encountered<br>\nterminate called after throwing an instance of 'std::runtime_error'<br>\nwhat():  Error at: /home/freddie/pytorch/torch/lib/c10d/CUDAUtils.cpp:22: an illegal memory access was encountered</p>\n<p>All tests in the ProcessGroupNCCLTest seem to be oK  except for test_allgather_ops</p>\n<p>here is a gdb bt:</p>\n<p>(gdb) bt<br>\n#0  0x00007ffff785faf0 in raise () from /lib64/libc.so.6<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a>  0x00007ffff7861e6c in abort () from /lib64/libc.so.6<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a>  0x00007fffce8eca60 in __gnu_cxx::__verbose_terminate_handler ()<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/vterminate.cc:95<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171485123\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/3\">#3</a>  0x00007fffce8e9e04 in __cxxabiv1::__terminate (handler=)<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_terminate.cc:47<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171522963\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4\">#4</a>  0x00007fffce8e8900 in __cxa_call_terminate (ue_header=0xf35c9ff0)<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_call.cc:54<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"173498149\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/5/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/5\">#5</a>  0x00007fffce8e9694 in __cxxabiv1::__gxx_personality_v0 (version=, actions=,<br>\nexception_class=, ue_header=0xf35c9ff0, context=0x7fffffff8020)<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_personality.cc:676<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174289461\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6\">#6</a>  0x00007fffef2a9d1c in _Unwind_RaiseException_Phase2 (exc=0xf35c9ff0, context=0x7fffffff8020)<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:62<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174818921\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/7/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/7\">#7</a>  0x00007fffef2aa190 in _Unwind_RaiseException (exc=0xf35c9ff0)<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:131<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174871471\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/8\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/8/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/8\">#8</a>  0x00007fffce8ea2a4 in __cxxabiv1::__cxa_throw (obj=, tinfo=0x7fffce9d7d18 ,<br>\ndest=0x7fffce8fa68c std::runtime_error::~runtime_error())<br>\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_throw.cc:88<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175537036\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9\">#9</a>  0x00007fffe42f7174 in c10d::CUDAEvent::~CUDAEvent() ()<br>\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175552272\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10\">#10</a> 0x00007fffe42e880c in c10d::ProcessGroupNCCL::WorkNCCL::~WorkNCCL() ()<br>\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175559413\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/11\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/11/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/11\">#11</a> 0x00007fffe42f30fc in std::_Sp_counted_ptr_inplace&lt;c10d::ProcessGroupNCCL::WorkNCCL, std::allocatorc10d::ProcessGroupNCCL::WorkNCCL---Type  to continue, or q  to quit---<br>\n, (__gnu_cxx::_Lock_policy)2&gt;::_M_dispose() ()<br>\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175559558\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12\">#12</a> 0x00007fffe3bd2b7c in std::_Sp_counted_base&lt;(__gnu_cxx::_Lock_policy)2&gt;::_M_release (this=0xf1dd5cb0)<br>\nat /usr/include/c++/4.8.2/bits/shared_ptr_base.h:144<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175567843\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/13\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/13/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/13\">#13</a> 0x00007fffe42f24c4 in c10d::ProcessGroupNCCL::allgather(std::vector&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;, std::allocator&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt; &gt; &gt;&amp;, std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;&amp;) ()<br>\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175574237\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/14\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/14/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/14\">#14</a> 0x00007fffe408b034 in operator() (args#1=..., args#0=..., c=, __closure=)<br>\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:73<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175627398\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/15\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/15/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/15\">#15</a> call_impl&lt;std::shared_ptrc10d::ProcessGroup::Work, pybind11::cpp_function::cpp_function(Return (Class::<em>)(Arg ...), const Extra&amp; ...) [with Return = std::shared_ptrc10d::ProcessGroup::Work; Class = c10d::ProcessGroup; Arg = {std::vector&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;, std::allocator&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt; &gt; &gt;&amp;, std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;&amp;}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guardpybind11::gil_scoped_release}]::__lambda14&amp;, 0ul, 1ul, 2ul, pybind11::gil_scoped_release&gt; (f=..., this=0x7fffffff9430)<br>\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1866<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175834985\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/16\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/16/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/16\">#16</a> call&lt;std::shared_ptrc10d::ProcessGroup::Work, pybind11::gil_scoped_release, pybind11::cpp_function::cpp_function(Return (Class::</em>)(Arg ...), const Extra&amp; ...) [with Return = std::shared_ptrc10d::ProcessGroup::Work; Class = c10d::ProcessGroup; Arg = {std::vector&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;, std::allocator&lt;std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt; &gt; &gt;&amp;, std::vector&lt;at::Tensor, std::allocatorat::Tensor &gt;&amp;}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guardpybind11::gil_scoped_release}]::__lambda14&amp;&gt; (f=..., this=0x7fffffff9430)<br>\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1843<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175835445\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/17\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/17/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/17\">#17</a> operator() (call=..., __closure=0x0) at /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:155</p>\n<p>When making only 2 CUDA devices available , the test succeeds:</p>\n<p>$ CUDA_VISIBLE_DEVICES=0,1  python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops</p>\n<p>Ran 1 test in 4.096s</p>\n<p>OK</p>", "body_text": "PyTorch version:  torch (0.5.0a0+00f2731)\nLinked with NCCL2 from nvidia\nCUDA 9.2  CuDNN 7.14\nRH 7.5   ppc64le   Power9 ( but I saw it also happen on a Power8)\n4 x Volta GPUs\nI have following set when I build:\nexport USE_SYSTEM_NCCL=TRUE\nexport NCCL_ROOT_DIR=/usr/local/cuda/\nexport NCCL_LIB_DIR=/usr/local/cuda/lib64\nexport NCCL_INCLUDE_DIR=/usr/local/cuda/include\nhere is the error:\n$ python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops\nTHCudaCheck FAIL file=/home/freddie/pytorch/aten/src/THC/THCTensorCopy.cu line=87 error=77 : an illegal memory access was encountered\nterminate called after throwing an instance of 'std::runtime_error'\nwhat():  Error at: /home/freddie/pytorch/torch/lib/c10d/CUDAUtils.cpp:22: an illegal memory access was encountered\nAll tests in the ProcessGroupNCCLTest seem to be oK  except for test_allgather_ops\nhere is a gdb bt:\n(gdb) bt\n#0  0x00007ffff785faf0 in raise () from /lib64/libc.so.6\n#1  0x00007ffff7861e6c in abort () from /lib64/libc.so.6\n#2  0x00007fffce8eca60 in __gnu_cxx::__verbose_terminate_handler ()\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/vterminate.cc:95\n#3  0x00007fffce8e9e04 in __cxxabiv1::__terminate (handler=)\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_terminate.cc:47\n#4  0x00007fffce8e8900 in __cxa_call_terminate (ue_header=0xf35c9ff0)\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_call.cc:54\n#5  0x00007fffce8e9694 in __cxxabiv1::__gxx_personality_v0 (version=, actions=,\nexception_class=, ue_header=0xf35c9ff0, context=0x7fffffff8020)\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_personality.cc:676\n#6  0x00007fffef2a9d1c in _Unwind_RaiseException_Phase2 (exc=0xf35c9ff0, context=0x7fffffff8020)\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:62\n#7  0x00007fffef2aa190 in _Unwind_RaiseException (exc=0xf35c9ff0)\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:131\n#8  0x00007fffce8ea2a4 in __cxxabiv1::__cxa_throw (obj=, tinfo=0x7fffce9d7d18 ,\ndest=0x7fffce8fa68c std::runtime_error::~runtime_error())\nat /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_throw.cc:88\n#9  0x00007fffe42f7174 in c10d::CUDAEvent::~CUDAEvent() ()\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\n#10 0x00007fffe42e880c in c10d::ProcessGroupNCCL::WorkNCCL::~WorkNCCL() ()\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\n#11 0x00007fffe42f30fc in std::_Sp_counted_ptr_inplace<c10d::ProcessGroupNCCL::WorkNCCL, std::allocatorc10d::ProcessGroupNCCL::WorkNCCL---Type  to continue, or q  to quit---\n, (__gnu_cxx::_Lock_policy)2>::_M_dispose() ()\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\n#12 0x00007fffe3bd2b7c in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0xf1dd5cb0)\nat /usr/include/c++/4.8.2/bits/shared_ptr_base.h:144\n#13 0x00007fffe42f24c4 in c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocatorat::Tensor >, std::allocator<std::vector<at::Tensor, std::allocatorat::Tensor > > >&, std::vector<at::Tensor, std::allocatorat::Tensor >&) ()\nfrom /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\n#14 0x00007fffe408b034 in operator() (args#1=..., args#0=..., c=, __closure=)\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:73\n#15 call_impl<std::shared_ptrc10d::ProcessGroup::Work, pybind11::cpp_function::cpp_function(Return (Class::)(Arg ...), const Extra& ...) [with Return = std::shared_ptrc10d::ProcessGroup::Work; Class = c10d::ProcessGroup; Arg = {std::vector<std::vector<at::Tensor, std::allocatorat::Tensor >, std::allocator<std::vector<at::Tensor, std::allocatorat::Tensor > > >&, std::vector<at::Tensor, std::allocatorat::Tensor >&}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guardpybind11::gil_scoped_release}]::__lambda14&, 0ul, 1ul, 2ul, pybind11::gil_scoped_release> (f=..., this=0x7fffffff9430)\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1866\n#16 call<std::shared_ptrc10d::ProcessGroup::Work, pybind11::gil_scoped_release, pybind11::cpp_function::cpp_function(Return (Class::)(Arg ...), const Extra& ...) [with Return = std::shared_ptrc10d::ProcessGroup::Work; Class = c10d::ProcessGroup; Arg = {std::vector<std::vector<at::Tensor, std::allocatorat::Tensor >, std::allocator<std::vector<at::Tensor, std::allocatorat::Tensor > > >&, std::vector<at::Tensor, std::allocatorat::Tensor >&}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guardpybind11::gil_scoped_release}]::__lambda14&> (f=..., this=0x7fffffff9430)\nat /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1843\n#17 operator() (call=..., __closure=0x0) at /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:155\nWhen making only 2 CUDA devices available , the test succeeds:\n$ CUDA_VISIBLE_DEVICES=0,1  python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops\nRan 1 test in 4.096s\nOK", "body": "PyTorch version:  torch (0.5.0a0+00f2731)\r\nLinked with NCCL2 from nvidia\r\nCUDA 9.2  CuDNN 7.14\r\nRH 7.5   ppc64le   Power9 ( but I saw it also happen on a Power8)\r\n4 x Volta GPUs\r\n\r\nI have following set when I build:\r\nexport USE_SYSTEM_NCCL=TRUE\r\nexport NCCL_ROOT_DIR=/usr/local/cuda/\r\nexport NCCL_LIB_DIR=/usr/local/cuda/lib64\r\nexport NCCL_INCLUDE_DIR=/usr/local/cuda/include\r\n\r\n\r\nhere is the error:\r\n$ python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops\r\nTHCudaCheck FAIL file=/home/freddie/pytorch/aten/src/THC/THCTensorCopy.cu line=87 error=77 : an illegal memory access was encountered\r\nterminate called after throwing an instance of 'std::runtime_error'\r\n  what():  Error at: /home/freddie/pytorch/torch/lib/c10d/CUDAUtils.cpp:22: an illegal memory access was encountered\r\n\r\nAll tests in the ProcessGroupNCCLTest seem to be oK  except for test_allgather_ops\r\n\r\nhere is a gdb bt:\r\n\r\n(gdb) bt\r\n#0  0x00007ffff785faf0 in raise () from /lib64/libc.so.6\r\n#1  0x00007ffff7861e6c in abort () from /lib64/libc.so.6\r\n#2  0x00007fffce8eca60 in __gnu_cxx::__verbose_terminate_handler ()\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/vterminate.cc:95\r\n#3  0x00007fffce8e9e04 in __cxxabiv1::__terminate (handler=<optimized out>)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_terminate.cc:47\r\n#4  0x00007fffce8e8900 in __cxa_call_terminate (ue_header=0xf35c9ff0)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_call.cc:54\r\n#5  0x00007fffce8e9694 in __cxxabiv1::__gxx_personality_v0 (version=<optimized out>, actions=<optimized out>,\r\n    exception_class=<optimized out>, ue_header=0xf35c9ff0, context=0x7fffffff8020)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_personality.cc:676\r\n#6  0x00007fffef2a9d1c in _Unwind_RaiseException_Phase2 (exc=0xf35c9ff0, context=0x7fffffff8020)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:62\r\n#7  0x00007fffef2aa190 in _Unwind_RaiseException (exc=0xf35c9ff0)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libgcc/unwind.inc:131\r\n#8  0x00007fffce8ea2a4 in __cxxabiv1::__cxa_throw (obj=<optimized out>, tinfo=0x7fffce9d7d18 <typeinfo for std::runtime_error>,\r\n    dest=0x7fffce8fa68c <std::runtime_error::~runtime_error()>)\r\n    at /opt/conda/conda-bld/compilers_linux-ppc64le_1511862875460/work/.build/src/gcc-7.2.0/libstdc++-v3/libsupc++/eh_throw.cc:88\r\n#9  0x00007fffe42f7174 in c10d::CUDAEvent::~CUDAEvent() ()\r\n   from /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\r\n#10 0x00007fffe42e880c in c10d::ProcessGroupNCCL::WorkNCCL::~WorkNCCL() ()\r\n   from /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\r\n#11 0x00007fffe42f30fc in std::_Sp_counted_ptr_inplace<c10d::ProcessGroupNCCL::WorkNCCL, std::allocator<c10d::ProcessGroupNCCL::WorkNCCL>---Type <return> to continue, or q <return> to quit---\r\n, (__gnu_cxx::_Lock_policy)2>::_M_dispose() ()\r\n   from /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\r\n#12 0x00007fffe3bd2b7c in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0xf1dd5cb0)\r\n    at /usr/include/c++/4.8.2/bits/shared_ptr_base.h:144\r\n#13 0x00007fffe42f24c4 in c10d::ProcessGroupNCCL::allgather(std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&) ()\r\n   from /home/freddie/miniconda/lib/python3.6/site-packages/torch/_C.cpython-36m-powerpc64le-linux-gnu.so\r\n#14 0x00007fffe408b034 in operator() (args#1=..., args#0=..., c=<optimized out>, __closure=<optimized out>)\r\n    at /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:73\r\n#15 call_impl<std::shared_ptr<c10d::ProcessGroup::Work>, pybind11::cpp_function::cpp_function(Return (Class::*)(Arg ...), const Extra& ...) [with Return = std::shared_ptr<c10d::ProcessGroup::Work>; Class = c10d::ProcessGroup; Arg = {std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guard<pybind11::gil_scoped_release>}]::__lambda14&, 0ul, 1ul, 2ul, pybind11::gil_scoped_release> (f=..., this=0x7fffffff9430)\r\n    at /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1866\r\n#16 call<std::shared_ptr<c10d::ProcessGroup::Work>, pybind11::gil_scoped_release, pybind11::cpp_function::cpp_function(Return (Class::*)(Arg ...), const Extra& ...) [with Return = std::shared_ptr<c10d::ProcessGroup::Work>; Class = c10d::ProcessGroup; Arg = {std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >&, std::vector<at::Tensor, std::allocator<at::Tensor> >&}; Extra = {pybind11::name, pybind11::is_method, pybind11::sibling, pybind11::call_guard<pybind11::gil_scoped_release>}]::__lambda14&> (f=..., this=0x7fffffff9430)\r\n    at /home/freddie/pytorch/third_party/pybind11/include/pybind11/cast.h:1843\r\n#17 operator() (call=..., __closure=0x0) at /home/freddie/pytorch/third_party/pybind11/include/pybind11/pybind11.h:155\r\n\r\nWhen making only 2 CUDA devices available , the test succeeds:\r\n\r\n$ CUDA_VISIBLE_DEVICES=0,1  python -m unittest -q  test_c10d.ProcessGroupNCCLTest.test_allgather_ops\r\n\r\nRan 1 test in 4.096s\r\n\r\nOK\r\n\r\n\r\n"}