{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/429573396", "html_url": "https://github.com/pytorch/pytorch/issues/12506#issuecomment-429573396", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12506", "id": 429573396, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTU3MzM5Ng==", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-13T20:37:12Z", "updated_at": "2018-10-13T20:37:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1892175\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zeryx\">@zeryx</a>! This should be pretty smooth with our API. You already did a pretty good job with the loading part. This is how I would write it:</p>\n<div class=\"highlight highlight-source-c++\"><pre>at::Tensor tensor_image = torch::from_blob(image.data, {<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, image.<span class=\"pl-smi\">rows</span>, image.<span class=\"pl-smi\">cols</span>}, at::<span class=\"pl-c1\">kByte</span>);\ntensor_image = tensor_image.to(at::<span class=\"pl-c1\">kFloat</span>);</pre></div>\n<p>Here, I assume that <code>image.data</code> is 8-bit byte values. The <code>to(at::kFloat)</code> will convert the 8-bit values into 32-bit floating points just as if you wrote <code>static_cast&lt;float&gt;(b)</code> where <code>b</code> is a byte -- just in case that wasn't clear. If <code>image.data</code> is already floats, you can just write <code>at::kFloat</code> in place of <code>at::kByte</code> and skip the conversion of course. What's <strong>super important</strong> to know is that <code>from_blob</code> does not take ownership of the data! It only interprets the data as a tensor, but doesn't store the data itself. It's easy to fix this if you want to, by calling <code>.clone()</code> on the tensor, since that will incur a copy of the data such that the resulting tensor will indeed own its data (which means the original <code>cv::Mat</code> can be destroyed and the cloned tensor will live on).</p>\n<p>On the other side, it's actually easier. You can use <code>tensor.data&lt;T&gt;()</code> to access a tensor's underlying data through a <code>T*</code>. For example, <code>tensor_image.data&lt;float&gt;()</code> would give you a <code>float*</code>. If you want a more raw <code>void*</code> because you're dumping the raw data somewhere else, there's also a <code>data_ptr()</code> method that gives you a raw byte pointer.</p>\n<p>Let me know if this helps.</p>", "body_text": "Hi @zeryx! This should be pretty smooth with our API. You already did a pretty good job with the loading part. This is how I would write it:\nat::Tensor tensor_image = torch::from_blob(image.data, {1, 3, image.rows, image.cols}, at::kByte);\ntensor_image = tensor_image.to(at::kFloat);\nHere, I assume that image.data is 8-bit byte values. The to(at::kFloat) will convert the 8-bit values into 32-bit floating points just as if you wrote static_cast<float>(b) where b is a byte -- just in case that wasn't clear. If image.data is already floats, you can just write at::kFloat in place of at::kByte and skip the conversion of course. What's super important to know is that from_blob does not take ownership of the data! It only interprets the data as a tensor, but doesn't store the data itself. It's easy to fix this if you want to, by calling .clone() on the tensor, since that will incur a copy of the data such that the resulting tensor will indeed own its data (which means the original cv::Mat can be destroyed and the cloned tensor will live on).\nOn the other side, it's actually easier. You can use tensor.data<T>() to access a tensor's underlying data through a T*. For example, tensor_image.data<float>() would give you a float*. If you want a more raw void* because you're dumping the raw data somewhere else, there's also a data_ptr() method that gives you a raw byte pointer.\nLet me know if this helps.", "body": "Hi @zeryx! This should be pretty smooth with our API. You already did a pretty good job with the loading part. This is how I would write it:\r\n\r\n```cpp\r\nat::Tensor tensor_image = torch::from_blob(image.data, {1, 3, image.rows, image.cols}, at::kByte);\r\ntensor_image = tensor_image.to(at::kFloat);\r\n```\r\n\r\nHere, I assume that `image.data` is 8-bit byte values. The `to(at::kFloat)` will convert the 8-bit values into 32-bit floating points just as if you wrote `static_cast<float>(b)` where `b` is a byte -- just in case that wasn't clear. If `image.data` is already floats, you can just write `at::kFloat` in place of `at::kByte` and skip the conversion of course. What's __super important__ to know is that `from_blob` does not take ownership of the data! It only interprets the data as a tensor, but doesn't store the data itself. It's easy to fix this if you want to, by calling `.clone()` on the tensor, since that will incur a copy of the data such that the resulting tensor will indeed own its data (which means the original `cv::Mat` can be destroyed and the cloned tensor will live on).\r\n\r\nOn the other side, it's actually easier. You can use `tensor.data<T>()` to access a tensor's underlying data through a `T*`. For example, `tensor_image.data<float>()` would give you a `float*`. If you want a more raw `void*` because you're dumping the raw data somewhere else, there's also a `data_ptr()` method that gives you a raw byte pointer.\r\n\r\nLet me know if this helps."}