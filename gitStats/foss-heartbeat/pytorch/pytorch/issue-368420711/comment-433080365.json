{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/433080365", "html_url": "https://github.com/pytorch/pytorch/issues/12506#issuecomment-433080365", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12506", "id": 433080365, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzA4MDM2NQ==", "user": {"login": "nicolone", "id": 8898094, "node_id": "MDQ6VXNlcjg4OTgwOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/8898094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicolone", "html_url": "https://github.com/nicolone", "followers_url": "https://api.github.com/users/nicolone/followers", "following_url": "https://api.github.com/users/nicolone/following{/other_user}", "gists_url": "https://api.github.com/users/nicolone/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicolone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicolone/subscriptions", "organizations_url": "https://api.github.com/users/nicolone/orgs", "repos_url": "https://api.github.com/users/nicolone/repos", "events_url": "https://api.github.com/users/nicolone/events{/privacy}", "received_events_url": "https://api.github.com/users/nicolone/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-25T14:47:01Z", "updated_at": "2018-10-25T14:47:50Z", "author_association": "NONE", "body_html": "<p>You have to split the interleaved bgr channels inside the <code>cv::Mat</code> to match the dimensions expected by the tensor:</p>\n<pre><code>    cv::Mat image = cv::imread(\"example.jpg\", cv::IMREAD_COLOR);\n    // std::cout &lt;&lt; image &lt;&lt; std::endl;\n\n    //we have to split the interleaved channels\n    cv::Mat bgr[3]; // destination array\n    cv::split(image, bgr);\n    cv::Mat channelsConcatenated;\n    vconcat(bgr[0], bgr[1], channelsConcatenated);\n    vconcat(channelsConcatenated, bgr[2], channelsConcatenated);\n   \n    cv::Mat channelsConcatenatedFloat;\n    channelsConcatenated.convertTo(channelsConcatenatedFloat, CV_32FC3);\n\n    std::vector&lt;int64_t&gt; dims{1, static_cast&lt;int64_t&gt;(image.channels()),\n                              static_cast&lt;int64_t&gt;(image.rows),\n                              static_cast&lt;int64_t&gt;(image.cols)};\n\n    at::TensorOptions options(at::kFloat);\n    at::Tensor tensor_image =\n        torch::from_blob(channelsConcatenated.data, at::IntList(dims), options);\n    // std::cout &lt;&lt; tensor_image &lt;&lt; std::endl;\n\n    // Execute the model and turn its output into a tensor.\n    auto output = module-&gt;forward({tensor_image}).toTensor();\n</code></pre>", "body_text": "You have to split the interleaved bgr channels inside the cv::Mat to match the dimensions expected by the tensor:\n    cv::Mat image = cv::imread(\"example.jpg\", cv::IMREAD_COLOR);\n    // std::cout << image << std::endl;\n\n    //we have to split the interleaved channels\n    cv::Mat bgr[3]; // destination array\n    cv::split(image, bgr);\n    cv::Mat channelsConcatenated;\n    vconcat(bgr[0], bgr[1], channelsConcatenated);\n    vconcat(channelsConcatenated, bgr[2], channelsConcatenated);\n   \n    cv::Mat channelsConcatenatedFloat;\n    channelsConcatenated.convertTo(channelsConcatenatedFloat, CV_32FC3);\n\n    std::vector<int64_t> dims{1, static_cast<int64_t>(image.channels()),\n                              static_cast<int64_t>(image.rows),\n                              static_cast<int64_t>(image.cols)};\n\n    at::TensorOptions options(at::kFloat);\n    at::Tensor tensor_image =\n        torch::from_blob(channelsConcatenated.data, at::IntList(dims), options);\n    // std::cout << tensor_image << std::endl;\n\n    // Execute the model and turn its output into a tensor.\n    auto output = module->forward({tensor_image}).toTensor();", "body": "You have to split the interleaved bgr channels inside the `cv::Mat` to match the dimensions expected by the tensor:\r\n```\r\n    cv::Mat image = cv::imread(\"example.jpg\", cv::IMREAD_COLOR);\r\n    // std::cout << image << std::endl;\r\n\r\n    //we have to split the interleaved channels\r\n    cv::Mat bgr[3]; // destination array\r\n    cv::split(image, bgr);\r\n    cv::Mat channelsConcatenated;\r\n    vconcat(bgr[0], bgr[1], channelsConcatenated);\r\n    vconcat(channelsConcatenated, bgr[2], channelsConcatenated);\r\n   \r\n    cv::Mat channelsConcatenatedFloat;\r\n    channelsConcatenated.convertTo(channelsConcatenatedFloat, CV_32FC3);\r\n\r\n    std::vector<int64_t> dims{1, static_cast<int64_t>(image.channels()),\r\n                              static_cast<int64_t>(image.rows),\r\n                              static_cast<int64_t>(image.cols)};\r\n\r\n    at::TensorOptions options(at::kFloat);\r\n    at::Tensor tensor_image =\r\n        torch::from_blob(channelsConcatenated.data, at::IntList(dims), options);\r\n    // std::cout << tensor_image << std::endl;\r\n\r\n    // Execute the model and turn its output into a tensor.\r\n    auto output = module->forward({tensor_image}).toTensor();\r\n```"}