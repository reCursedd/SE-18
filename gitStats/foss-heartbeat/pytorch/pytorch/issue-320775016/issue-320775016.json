{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7334", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7334/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7334/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7334/events", "html_url": "https://github.com/pytorch/pytorch/issues/7334", "id": 320775016, "node_id": "MDU6SXNzdWUzMjA3NzUwMTY=", "number": 7334, "title": "Segmentation fault (core dumped) While running the fast_neural_style repo!", "user": {"login": "pradeephike", "id": 29882389, "node_id": "MDQ6VXNlcjI5ODgyMzg5", "avatar_url": "https://avatars2.githubusercontent.com/u/29882389?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pradeephike", "html_url": "https://github.com/pradeephike", "followers_url": "https://api.github.com/users/pradeephike/followers", "following_url": "https://api.github.com/users/pradeephike/following{/other_user}", "gists_url": "https://api.github.com/users/pradeephike/gists{/gist_id}", "starred_url": "https://api.github.com/users/pradeephike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pradeephike/subscriptions", "organizations_url": "https://api.github.com/users/pradeephike/orgs", "repos_url": "https://api.github.com/users/pradeephike/repos", "events_url": "https://api.github.com/users/pradeephike/events{/privacy}", "received_events_url": "https://api.github.com/users/pradeephike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-07T11:50:28Z", "updated_at": "2018-06-06T10:16:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>def stylize(args):<br>\ndevice = torch.device(\"cuda\" if args.cuda else \"cpu\")</p>\n<pre><code>content_image = utils.load_image(args.content_image, scale=args.content_scale)\ncontent_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.mul(255))\n])\ncontent_image = content_transform(content_image)\ncontent_image = content_image.unsqueeze(0).to(device)\n\nif args.model.endswith(\".onnx\"):\n    output = stylize_onnx_caffe2(content_image, args)\nelse:\n    with torch.no_grad():\n        style_model = TransformerNet()\n        state_dict = torch.load(args.model)\n        # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n        for k in list(state_dict.keys()):\n            if re.search(r'in\\d+\\.running_(mean|var)$', k):\n                del state_dict[k]\n        style_model.load_state_dict(state_dict)\n        style_model.to(device)\n        if args.export_onnx:\n            assert args.export_onnx.endswith(\".onnx\"), \"Export model file should end with .onnx\"\n            output = torch.onnx._export(style_model, content_image, args.export_onnx)\n        else:\n            output = style_model(content_image).cpu()\nutils.save_image(args.output_image, output[0])\n</code></pre>\n<p>def stylize_onnx_caffe2(content_image, args):<br>\n\"\"\"<br>\nRead ONNX model and run it using Caffe2<br>\n\"\"\"</p>\n<pre><code>assert not args.export_onnx\n\nimport onnx\nimport onnx_caffe2.backend\n\nmodel = onnx.load(args.model)\n\nprepared_backend = onnx_caffe2.backend.prepare(model, device='CUDA' if args.cuda else 'CPU')\ninp = {model.graph.input[0].name: content_image.numpy()}\nc2_out = prepared_backend.run(inp)[0]\n\nreturn torch.from_numpy(c2_out)\n</code></pre>\n<p>This is the part of code I am trying to run.<br>\nThe pytorch model is successfully converted into onnx but when I try to infer using the onnx model, I am encountering segmentation fault.</p>\n<p>Any insights?</p>", "body_text": "def stylize(args):\ndevice = torch.device(\"cuda\" if args.cuda else \"cpu\")\ncontent_image = utils.load_image(args.content_image, scale=args.content_scale)\ncontent_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.mul(255))\n])\ncontent_image = content_transform(content_image)\ncontent_image = content_image.unsqueeze(0).to(device)\n\nif args.model.endswith(\".onnx\"):\n    output = stylize_onnx_caffe2(content_image, args)\nelse:\n    with torch.no_grad():\n        style_model = TransformerNet()\n        state_dict = torch.load(args.model)\n        # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n        for k in list(state_dict.keys()):\n            if re.search(r'in\\d+\\.running_(mean|var)$', k):\n                del state_dict[k]\n        style_model.load_state_dict(state_dict)\n        style_model.to(device)\n        if args.export_onnx:\n            assert args.export_onnx.endswith(\".onnx\"), \"Export model file should end with .onnx\"\n            output = torch.onnx._export(style_model, content_image, args.export_onnx)\n        else:\n            output = style_model(content_image).cpu()\nutils.save_image(args.output_image, output[0])\n\ndef stylize_onnx_caffe2(content_image, args):\n\"\"\"\nRead ONNX model and run it using Caffe2\n\"\"\"\nassert not args.export_onnx\n\nimport onnx\nimport onnx_caffe2.backend\n\nmodel = onnx.load(args.model)\n\nprepared_backend = onnx_caffe2.backend.prepare(model, device='CUDA' if args.cuda else 'CPU')\ninp = {model.graph.input[0].name: content_image.numpy()}\nc2_out = prepared_backend.run(inp)[0]\n\nreturn torch.from_numpy(c2_out)\n\nThis is the part of code I am trying to run.\nThe pytorch model is successfully converted into onnx but when I try to infer using the onnx model, I am encountering segmentation fault.\nAny insights?", "body": "def stylize(args):\r\n    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\r\n\r\n    content_image = utils.load_image(args.content_image, scale=args.content_scale)\r\n    content_transform = transforms.Compose([\r\n        transforms.ToTensor(),\r\n        transforms.Lambda(lambda x: x.mul(255))\r\n    ])\r\n    content_image = content_transform(content_image)\r\n    content_image = content_image.unsqueeze(0).to(device)\r\n\r\n    if args.model.endswith(\".onnx\"):\r\n        output = stylize_onnx_caffe2(content_image, args)\r\n    else:\r\n        with torch.no_grad():\r\n            style_model = TransformerNet()\r\n            state_dict = torch.load(args.model)\r\n            # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\r\n            for k in list(state_dict.keys()):\r\n                if re.search(r'in\\d+\\.running_(mean|var)$', k):\r\n                    del state_dict[k]\r\n            style_model.load_state_dict(state_dict)\r\n            style_model.to(device)\r\n            if args.export_onnx:\r\n                assert args.export_onnx.endswith(\".onnx\"), \"Export model file should end with .onnx\"\r\n                output = torch.onnx._export(style_model, content_image, args.export_onnx)\r\n            else:\r\n                output = style_model(content_image).cpu()\r\n    utils.save_image(args.output_image, output[0])\r\n\r\n\r\ndef stylize_onnx_caffe2(content_image, args):\r\n    \"\"\"\r\n    Read ONNX model and run it using Caffe2\r\n    \"\"\"\r\n\r\n    assert not args.export_onnx\r\n\r\n    import onnx\r\n    import onnx_caffe2.backend\r\n\r\n    model = onnx.load(args.model)\r\n\r\n    prepared_backend = onnx_caffe2.backend.prepare(model, device='CUDA' if args.cuda else 'CPU')\r\n    inp = {model.graph.input[0].name: content_image.numpy()}\r\n    c2_out = prepared_backend.run(inp)[0]\r\n\r\n    return torch.from_numpy(c2_out)\r\n\r\nThis is the part of code I am trying to run.\r\nThe pytorch model is successfully converted into onnx but when I try to infer using the onnx model, I am encountering segmentation fault. \r\n\r\nAny insights?"}