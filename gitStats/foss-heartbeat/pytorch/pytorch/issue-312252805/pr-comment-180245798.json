{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180245798", "pull_request_review_id": 110634652, "id": 180245798, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MDI0NTc5OA==", "diff_hunk": "@@ -0,0 +1,462 @@\n+#include \"import.h\"\n+#include \"torch/csrc/onnx/onnx.pb.h\"\n+#include \"torch/csrc/jit/ir.h\"\n+\n+#include <ATen/ATen.h>\n+\n+#include <unordered_map>\n+#include <vector>\n+#include <string>\n+\n+#include \"third_party/nanopb/pb_decode.h\"\n+\n+namespace torch { namespace jit {\n+\n+namespace {\n+\n+struct GraphWrapper {\n+  std::shared_ptr<Graph> graph;\n+  std::vector<at::Tensor>* initializers;\n+  std::unordered_map<std::string, Value*> value_map;\n+  std::unordered_map<std::string, std::vector<Node*>> node_input_map;\n+};\n+\n+bool read_string_from_stream(pb_istream_t *stream, std::string& str) {\n+\n+  std::vector<uint8_t> res(stream->bytes_left);\n+\n+  if (!pb_read(stream, res.data(), stream->bytes_left)) {\n+    return false;\n+  }\n+\n+  str.assign(res.begin(), res.end());\n+\n+  return true;\n+}\n+\n+bool read_string(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::string& str = *(std::string*)(*arg);\n+\n+  if (!read_string_from_stream(stream, str)) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+bool read_strings(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::vector<std::string>& res = *(std::vector<std::string>*)(*arg);\n+  std::string str;\n+\n+  if (!read_string_from_stream(stream, str)) {\n+    return false;\n+  }\n+\n+  res.push_back(str);\n+\n+  return true;\n+}\n+\n+bool read_floats(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::vector<double>& res = *(std::vector<double>*)(*arg);\n+  double val;\n+\n+  if (!pb_decode_fixed32(stream, &val)) {\n+    return false;\n+  }\n+\n+  res.push_back(val);\n+\n+  return true;\n+}\n+\n+bool read_ints(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::vector<int64_t>& res = *(std::vector<int64_t>*)(*arg);\n+  uint64_t val;\n+\n+  if (!pb_decode_varint(stream, &val)) {\n+    return false;\n+  }\n+\n+  res.push_back(val);\n+\n+  return true;\n+}\n+\n+bool read_packed_bytes(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::vector<uint8_t>& res = *(std::vector<uint8_t>*)(*arg);\n+\n+  res.resize(stream->bytes_left);\n+\n+  if (!pb_read(stream, res.data(), stream->bytes_left)) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+bool read_tensor(pb_istream_t *stream, at::Tensor& tensor) {\n+\n+  onnx_TensorProto proto = onnx_TensorProto_init_default;\n+\n+  std::vector<int64_t> dims;\n+  proto.dims.funcs.decode = &read_ints;\n+  proto.dims.arg = &dims;\n+\n+  std::vector<uint8_t> raw_data;\n+  proto.raw_data.funcs.decode = &read_packed_bytes;\n+  proto.raw_data.arg = &raw_data;\n+\n+  if (!pb_decode(stream, onnx_TensorProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+\tswitch(proto.data_type) {\n+    case onnx_TensorProto_DataType_UINT8:\n+      tensor = at::CPU(at::kByte).tensor();\n+      break;\n+    case onnx_TensorProto_DataType_INT8:\n+      tensor = at::CPU(at::kChar).tensor();\n+      break;\n+    case onnx_TensorProto_DataType_INT16:\n+      tensor = at::CPU(at::kShort).tensor();\n+      break;\n+    case onnx_TensorProto_DataType_INT32:\n+      tensor = at::CPU(at::kInt).tensor();\n+      break;\n+    case onnx_TensorProto_DataType_INT64:\n+      tensor = at::CPU(at::kLong).tensor();\n+      break;\n+    case onnx_TensorProto_DataType_FLOAT16:\n+      tensor = at::CPU(at::kHalf).tensor();\n+\t\t\tbreak;\n+    case onnx_TensorProto_DataType_FLOAT:\n+      tensor = at::CPU(at::kFloat).tensor();\n+\t\t\tbreak;\n+    case onnx_TensorProto_DataType_DOUBLE:\n+      tensor = at::CPU(at::kDouble).tensor();\n+\t\t\tbreak;\n+    default:\n+      throw std::runtime_error(\"Unsupported data type\");\n+  }\n+\n+  tensor.resize_(dims);\n+\n+  JIT_ASSERT(tensor.storage()->size() * tensor.storage()->elementSize() == raw_data.size());\n+\n+  std::memcpy(tensor.data_ptr(), &raw_data[0], raw_data.size());\n+\n+\treturn true;\n+}\n+\n+bool decode_tensor(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  at::Tensor& tensor = *(at::Tensor*)(*arg);\n+\n+\tif (!read_tensor(stream, tensor)) {\n+\t\treturn false;\n+  }\n+\n+\treturn true;\n+}\n+\n+bool decode_tensors(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  std::vector<at::Tensor>& res = *(std::vector<at::Tensor>*)(*arg);\n+\n+\tat::Tensor tensor;\n+\n+\tif (!read_tensor(stream, tensor)) {\n+\t\treturn false;\n+  }\n+\n+\tres.push_back(tensor);\n+\n+\treturn true;\n+}\n+\n+bool decode_attribute(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  onnx_AttributeProto proto = onnx_AttributeProto_init_default;\n+\n+  std::vector<AttributeValue*>& attrs = *(std::vector<AttributeValue*>*)(*arg);\n+\n+  std::string name;\n+  proto.name.funcs.decode = &read_string;\n+  proto.name.arg = &name;\n+\n+  std::string str;\n+  proto.s.funcs.decode = &read_string;\n+  proto.s.arg = &str;\n+\n+\tat::Tensor tensor;\n+\tproto.t.funcs.decode = &decode_tensor;\n+  proto.t.arg = &tensor;\n+\n+  std::vector<double> floats;\n+  proto.floats.funcs.decode = &read_floats;\n+  proto.floats.arg = &floats;\n+\n+  std::vector<int64_t> ints;\n+  proto.ints.funcs.decode = &read_ints;\n+  proto.ints.arg = &ints;\n+\n+  std::vector<std::string> strings;\n+  proto.strings.funcs.decode = &read_strings;\n+  proto.strings.arg = &strings;\n+\n+\tstd::vector<at::Tensor> tensors;\n+\tproto.tensors.funcs.decode = &decode_tensors;\n+  proto.tensors.arg = &tensors;\n+\n+  if (!pb_decode(stream, onnx_AttributeProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+  onnx_AttributeProto_AttributeType type = proto.type;\n+\n+\tAttributeValue* attr = nullptr;\n+\n+\tswitch(type) {\n+    case onnx_AttributeProto_AttributeType_UNDEFINED:\n+\t\t\tthrow std::runtime_error(\"UNDEFINED attribute unsupported\");\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_FLOAT:\n+      attr = new FloatAttr(Symbol::attr(name), proto.f);\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_INT:\n+      attr = new IntAttr(Symbol::attr(name), proto.i);\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_STRING:\n+      attr = new StringAttr(Symbol::attr(name), str);\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_TENSOR:\n+      attr = new TensorAttr(Symbol::attr(name), std::move(tensor));\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_GRAPH:\n+      // TODO\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_FLOATS:\n+      attr = new FloatsAttr(Symbol::attr(name), std::move(floats));\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_INTS:\n+      attr = new IntsAttr(Symbol::attr(name), std::move(ints));\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_STRINGS:\n+      attr = new StringsAttr(Symbol::attr(name), std::move(strings));\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_TENSORS:\n+      attr = new TensorsAttr(Symbol::attr(name), std::move(tensors));\n+\t\t\tbreak;\n+    case onnx_AttributeProto_AttributeType_GRAPHS:\n+      // TODO\n+\t\t\tbreak;\n+\t}\n+\n+\tif (attr) {\n+\t\tattrs.push_back(attr);\n+\t}\n+\n+  return true;\n+}\n+\n+bool decode_node(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  onnx_NodeProto proto = onnx_NodeProto_init_default;\n+\n+  auto graph_wrapper = (GraphWrapper*)(*arg);\n+  auto graph = graph_wrapper->graph;\n+\n+  std::vector<std::string> inputs;\n+  proto.input.funcs.decode = &read_strings;\n+  proto.input.arg = &inputs;\n+\n+  std::vector<std::string> outputs;\n+  proto.output.funcs.decode = &read_strings;\n+  proto.output.arg = &outputs;\n+\n+  std::string op_type;\n+  proto.op_type.funcs.decode = &read_string;\n+  proto.op_type.arg = &op_type;\n+\n+  std::vector<AttributeValue*> attrs;\n+  proto.attribute.funcs.decode = &decode_attribute;\n+  proto.attribute.arg = &attrs;\n+\n+  if (!pb_decode(stream, onnx_NodeProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+\tassert(op_type != \"CppOp\");\n+\tassert(op_type != \"PythonOp\");\n+\n+  Node* n = graph->create(Symbol::aten(op_type), outputs.size());\n+\n+  for (int i=0; i<inputs.size(); i++) {\n+    if (graph_wrapper->value_map.find(inputs[i]) != graph_wrapper->value_map.end()) {\n+      Value* v = graph_wrapper->value_map.at(inputs[i]);\n+      n->addInput(v);\n+    }\n+    else {\n+      graph_wrapper->node_input_map[inputs[i]].push_back(n);\n+    }\n+  }\n+  for (int i=0; i<outputs.size(); i++) {\n+    graph_wrapper->value_map[outputs[i]] = n->outputs()[i];\n+  }\n+\n+  for (int i=0; i<attrs.size(); i++) {\n+\t\tauto attr = attrs[i];\n+  \tswitch(attr->kind()) {\n+      case AttributeKind::f:\n+\t\t\t\tn->f_(attr->name, reinterpret_cast<FloatAttr*>(attr)->value());\n+  \t\t\tbreak;\n+      case AttributeKind::i:\n+\t\t\t\tn->i_(attr->name, reinterpret_cast<IntAttr*>(attr)->value());\n+  \t\t\tbreak;\n+      case AttributeKind::s:\n+\t\t\t\tn->s_(attr->name, reinterpret_cast<StringAttr*>(attr)->value());\n+\t\t\t\tbreak;\n+      case AttributeKind::t:\n+\t\t\t\tn->t_(attr->name, reinterpret_cast<TensorAttr*>(attr)->value());\n+\t\t\t\tbreak;\n+      // case AttributeKind::g:\n+  \t\t//\t break;\n+      case AttributeKind::fs:\n+\t\t\t\tn->fs_(attr->name, std::move(reinterpret_cast<FloatsAttr*>(attr)->value()));\n+  \t\t\tbreak;\n+      case AttributeKind::is:\n+\t\t\t\tn->is_(attr->name, std::move(reinterpret_cast<IntsAttr*>(attr)->value()));\n+  \t\t\tbreak;\n+      case AttributeKind::ss:\n+\t\t\t\tn->ss_(attr->name, std::move(reinterpret_cast<StringsAttr*>(attr)->value()));\n+  \t\t\tbreak;\n+      case AttributeKind::ts:\n+\t\t\t\tn->ts_(attr->name, std::move(reinterpret_cast<TensorsAttr*>(attr)->value()));\n+  \t\t\tbreak;\n+      // case AttributeKind::gs:\n+  \t\t//\t break;\n+  \t}\n+\t\tdelete attr;\n+\t\tattrs[i] = nullptr;\n+  }\n+\n+  graph->appendNode(n);\n+\n+  return true;\n+}\n+\n+bool decode_input(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  onnx_ValueInfoProto proto = onnx_ValueInfoProto_init_default;\n+\n+  auto graph_wrapper = (GraphWrapper*)(*arg);\n+  auto graph = graph_wrapper->graph;\n+\n+  std::string name;\n+  proto.name.funcs.decode = &read_string;\n+  proto.name.arg = &name;\n+\n+  if (!pb_decode(stream, onnx_ValueInfoProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+  Value* v = graph->addInput();\n+  graph_wrapper->value_map[name] = v;\n+  auto nodes = graph_wrapper->node_input_map[name];\n+\n+  for (int i=0; i<nodes.size(); i++) {\n+    nodes[i]->addInput(v);\n+  }\n+\n+  return true;\n+}\n+\n+bool decode_output(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  onnx_ValueInfoProto proto = onnx_ValueInfoProto_init_default;\n+\n+  auto graph_wrapper = (GraphWrapper*)(*arg);\n+  auto graph = graph_wrapper->graph;\n+\n+  std::string name;\n+  proto.name.funcs.decode = &read_string;\n+  proto.name.arg = &name;\n+\n+  if (!pb_decode(stream, onnx_ValueInfoProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+  if (graph_wrapper->value_map.find(name) != graph_wrapper->value_map.end()) {\n+    Value* v = graph_wrapper->value_map.at(name);\n+    graph->block()->registerOutput(v);\n+  }\n+\n+  return true;\n+}\n+\n+bool decode_graph(pb_istream_t *stream, const pb_field_t *field, void **arg) {\n+\n+  onnx_GraphProto proto = onnx_GraphProto_init_default;\n+\n+  auto graph_wrapper = (GraphWrapper*)(*arg);\n+  auto graph = graph_wrapper->graph;\n+  auto initializers = graph_wrapper->initializers;\n+\n+  proto.input.funcs.decode = &decode_input;\n+  proto.input.arg = graph_wrapper;\n+\n+  proto.output.funcs.decode = &decode_output;\n+  proto.output.arg = graph_wrapper;\n+\n+  proto.node.funcs.decode = &decode_node;\n+  proto.node.arg = graph_wrapper;\n+\n+  proto.initializer.funcs.decode = &decode_tensors;\n+  proto.initializer.arg = initializers;\n+\n+  if (!pb_decode(stream, onnx_GraphProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+bool decode_model(pb_istream_t *stream, GraphWrapper* graph_wrapper) {\n+\n+  onnx_ModelProto proto = onnx_ModelProto_init_default;\n+\n+  proto.graph.funcs.decode = &decode_graph;\n+  proto.graph.arg = graph_wrapper;\n+\n+  if (!pb_decode(stream, onnx_ModelProto_fields, &proto)) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+}\n+\n+void ImportGraph(std::string& serialized_graph,\n+                 std::shared_ptr<Graph>& graph,\n+                 std::vector<at::Tensor>& initializers) {\n+\n+  pb_istream_t istream = pb_istream_from_buffer(reinterpret_cast<pb_byte_t *>(&serialized_graph[0]), serialized_graph.size());", "path": "tools/cpp_build/src/import.cpp", "position": null, "original_position": 450, "commit_id": "a907ce98f4875f10b0c45be77ec3556236be5ee3", "original_commit_id": "55ec8eae93d33d6501738e53e49ae98fedf61f2f", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "body": "Done", "created_at": "2018-04-09T22:09:03Z", "updated_at": "2018-11-23T15:42:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/6392#discussion_r180245798", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6392", "author_association": "COLLABORATOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180245798"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6392#discussion_r180245798"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6392"}}, "body_html": "<p>Done</p>", "body_text": "Done", "in_reply_to_id": 180232461}