{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/384814816", "html_url": "https://github.com/pytorch/pytorch/pull/6392#issuecomment-384814816", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6392", "id": 384814816, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NDgxNDgxNg==", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-26T23:03:09Z", "updated_at": "2018-04-26T23:03:09Z", "author_association": "COLLABORATOR", "body_html": "<p>Thanks for the awesome reviews. I'm almost done with this round of fixes.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> here's the export for this model</p>\n<pre><code>class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(3,2)\n\n    def forward(self, x):\n        y = F.tanh(self.linear(x))\n        return y\n</code></pre>\n<p>Graph</p>\n<pre><code>graph(%0 : Float(3)\n      %1 : Float(2, 3)\n      %2 : Float(2)) {\n  %3 : Float(3!, 2!) = aten::t(%1), scope: Net/Linear[linear]\n  %4 : Float(2) = aten::matmul(%0, %3), scope: Net/Linear[linear]\n  %5 : Float(2) = aten::add[alpha={1}](%4, %2), scope: Net/Linear[linear]\n  %6 : Float(2) = aten::tanh(%5), scope: Net\n  return (%6);\n}\n</code></pre>\n<p>Protobuf</p>\n<pre><code>1: 3\n2: \"pytorch\"\n3: \"0.3\"\n7 {\n  1 {\n    1: \"1\"\n    2: \"3\"\n    4: \"aten::t\"\n    6: &lt;redacted source location&gt;\n  }\n  1 {\n    1: \"0\"\n    1: \"3\"\n    2: \"4\"\n    4: \"aten::matmul\"\n    6: &lt;redacted source location&gt;\n  }\n  1 {\n    1: \"4\"\n    1: \"2\"\n    2: \"5\"\n    4 {\n      12: 0x6464613a3a6e6574\n    }\n    5 {\n      1: \"alpha\"\n      5 {\n        2: 11\n        9: \"\\000\\000\\000\\000\\000\\000\\360?\"\n      }\n      20: 4\n    }\n    6: &lt;redacted source location&gt;\n  }\n  1 {\n    1: \"5\"\n    2: \"6\"\n    4: \"aten::tanh\"\n    6: &lt;redacted source location&gt;\n  }\n  2: \"torch-jit-export\"\n  5 {\n    1: 2\n    1: 3\n    2: 1\n    8: \"1\"\n    9: \"\\220\\\\V\\276tw\\305&gt;\\246#\\\\\\276\\026y\\203&gt;\\020-&amp;\\275\\244s\\340&gt;\"\n  }\n  5 {\n    1: 2\n    2: 1\n    8: \"2\"\n    9: \"8~\\362\\275\\034\\306\\225\\276\"\n  }\n  11 {\n    1: \"0\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 3\n          }\n        }\n      }\n    }\n  }\n  11 {\n    1: \"1\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n          1 {\n            1: 3\n          }\n        }\n      }\n    }\n  }\n  11 {\n    1: \"2\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n        }\n      }\n    }\n  }\n  12 {\n    1: \"6\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n        }\n      }\n    }\n  }\n}\n8 {\n  2: 6\n}\n</code></pre>", "body_text": "Thanks for the awesome reviews. I'm almost done with this round of fixes.\n@ezyang here's the export for this model\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(3,2)\n\n    def forward(self, x):\n        y = F.tanh(self.linear(x))\n        return y\n\nGraph\ngraph(%0 : Float(3)\n      %1 : Float(2, 3)\n      %2 : Float(2)) {\n  %3 : Float(3!, 2!) = aten::t(%1), scope: Net/Linear[linear]\n  %4 : Float(2) = aten::matmul(%0, %3), scope: Net/Linear[linear]\n  %5 : Float(2) = aten::add[alpha={1}](%4, %2), scope: Net/Linear[linear]\n  %6 : Float(2) = aten::tanh(%5), scope: Net\n  return (%6);\n}\n\nProtobuf\n1: 3\n2: \"pytorch\"\n3: \"0.3\"\n7 {\n  1 {\n    1: \"1\"\n    2: \"3\"\n    4: \"aten::t\"\n    6: <redacted source location>\n  }\n  1 {\n    1: \"0\"\n    1: \"3\"\n    2: \"4\"\n    4: \"aten::matmul\"\n    6: <redacted source location>\n  }\n  1 {\n    1: \"4\"\n    1: \"2\"\n    2: \"5\"\n    4 {\n      12: 0x6464613a3a6e6574\n    }\n    5 {\n      1: \"alpha\"\n      5 {\n        2: 11\n        9: \"\\000\\000\\000\\000\\000\\000\\360?\"\n      }\n      20: 4\n    }\n    6: <redacted source location>\n  }\n  1 {\n    1: \"5\"\n    2: \"6\"\n    4: \"aten::tanh\"\n    6: <redacted source location>\n  }\n  2: \"torch-jit-export\"\n  5 {\n    1: 2\n    1: 3\n    2: 1\n    8: \"1\"\n    9: \"\\220\\\\V\\276tw\\305>\\246#\\\\\\276\\026y\\203>\\020-&\\275\\244s\\340>\"\n  }\n  5 {\n    1: 2\n    2: 1\n    8: \"2\"\n    9: \"8~\\362\\275\\034\\306\\225\\276\"\n  }\n  11 {\n    1: \"0\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 3\n          }\n        }\n      }\n    }\n  }\n  11 {\n    1: \"1\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n          1 {\n            1: 3\n          }\n        }\n      }\n    }\n  }\n  11 {\n    1: \"2\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n        }\n      }\n    }\n  }\n  12 {\n    1: \"6\"\n    2 {\n      1 {\n        1: 1\n        2 {\n          1 {\n            1: 2\n          }\n        }\n      }\n    }\n  }\n}\n8 {\n  2: 6\n}", "body": "Thanks for the awesome reviews. I'm almost done with this round of fixes.\r\n\r\n@ezyang here's the export for this model\r\n```\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.linear = nn.Linear(3,2)\r\n\r\n    def forward(self, x):\r\n        y = F.tanh(self.linear(x))\r\n        return y\r\n```\r\nGraph\r\n```\r\ngraph(%0 : Float(3)\r\n      %1 : Float(2, 3)\r\n      %2 : Float(2)) {\r\n  %3 : Float(3!, 2!) = aten::t(%1), scope: Net/Linear[linear]\r\n  %4 : Float(2) = aten::matmul(%0, %3), scope: Net/Linear[linear]\r\n  %5 : Float(2) = aten::add[alpha={1}](%4, %2), scope: Net/Linear[linear]\r\n  %6 : Float(2) = aten::tanh(%5), scope: Net\r\n  return (%6);\r\n}\r\n```\r\nProtobuf\r\n```\r\n1: 3\r\n2: \"pytorch\"\r\n3: \"0.3\"\r\n7 {\r\n  1 {\r\n    1: \"1\"\r\n    2: \"3\"\r\n    4: \"aten::t\"\r\n    6: <redacted source location>\r\n  }\r\n  1 {\r\n    1: \"0\"\r\n    1: \"3\"\r\n    2: \"4\"\r\n    4: \"aten::matmul\"\r\n    6: <redacted source location>\r\n  }\r\n  1 {\r\n    1: \"4\"\r\n    1: \"2\"\r\n    2: \"5\"\r\n    4 {\r\n      12: 0x6464613a3a6e6574\r\n    }\r\n    5 {\r\n      1: \"alpha\"\r\n      5 {\r\n        2: 11\r\n        9: \"\\000\\000\\000\\000\\000\\000\\360?\"\r\n      }\r\n      20: 4\r\n    }\r\n    6: <redacted source location>\r\n  }\r\n  1 {\r\n    1: \"5\"\r\n    2: \"6\"\r\n    4: \"aten::tanh\"\r\n    6: <redacted source location>\r\n  }\r\n  2: \"torch-jit-export\"\r\n  5 {\r\n    1: 2\r\n    1: 3\r\n    2: 1\r\n    8: \"1\"\r\n    9: \"\\220\\\\V\\276tw\\305>\\246#\\\\\\276\\026y\\203>\\020-&\\275\\244s\\340>\"\r\n  }\r\n  5 {\r\n    1: 2\r\n    2: 1\r\n    8: \"2\"\r\n    9: \"8~\\362\\275\\034\\306\\225\\276\"\r\n  }\r\n  11 {\r\n    1: \"0\"\r\n    2 {\r\n      1 {\r\n        1: 1\r\n        2 {\r\n          1 {\r\n            1: 3\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  11 {\r\n    1: \"1\"\r\n    2 {\r\n      1 {\r\n        1: 1\r\n        2 {\r\n          1 {\r\n            1: 2\r\n          }\r\n          1 {\r\n            1: 3\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  11 {\r\n    1: \"2\"\r\n    2 {\r\n      1 {\r\n        1: 1\r\n        2 {\r\n          1 {\r\n            1: 2\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  12 {\r\n    1: \"6\"\r\n    2 {\r\n      1 {\r\n        1: 1\r\n        2 {\r\n          1 {\r\n            1: 2\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n8 {\r\n  2: 6\r\n}\r\n```"}