{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160038074", "pull_request_review_id": 87087701, "id": 160038074, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDAzODA3NA==", "diff_hunk": "@@ -425,6 +425,79 @@ def tmp(self):\n \n \n class TestCuda(TestCase):\n+\n+    def test_memory_allocated_stats(self):\n+        torch.cuda.empty_cache()\n+        m0 = last_m = torch.cuda.memory_allocated()\n+        max_m = torch.cuda.max_memory_allocated()\n+\n+        def assert_change(comp=1):\n+            # comp > 0: increased\n+            # comp = 0: equal\n+            # comp < 0: decreased\n+            nonlocal last_m, max_m\n+            new_m = torch.cuda.memory_allocated()\n+            new_max_m = torch.cuda.max_memory_allocated()\n+            if comp > 0:\n+                self.assertGreater(new_m, last_m)\n+            elif comp < 0:\n+                self.assertLess(new_m, last_m)\n+            else:\n+                self.assertEqual(new_m, last_m)\n+            self.assertLessEqual(new_m, new_max_m)\n+            self.assertGreaterEqual(new_max_m, max_m)\n+            last_m = new_m\n+            max_m = new_max_m\n+\n+        tensors1 = [torch.randn(1).cuda(), torch.randn(10, 20).cuda(), torch.randn(200, 300, 2000).cuda()]\n+        m1 = torch.cuda.memory_allocated()\n+        assert_change(1)\n+\n+        tensors2 = []\n+        N = 30\n+\n+        for i in range(1, int(N / 2) + 1):\n+            # small ones\n+            tensors2.append(torch.randn(i, i * 3).cuda())\n+        assert_change(1)\n+\n+        for i in range(1, N - len(tensors2) + 1):\n+            # large ones\n+            tensors2.append(torch.randn(i * 7, i * 9, i * 11).cuda())\n+        assert_change(1)\n+\n+        tensors2.append(torch.randn(0, 0, 0).cuda())\n+        assert_change(0)\n+\n+        permute = []\n+        for i in torch.randperm(len(tensors2)):\n+            permute.append(tensors2[i])\n+            assert_change(0)\n+\n+        del tensors2\n+        assert_change(0)\n+        tensors2 = permute\n+        assert_change(0)\n+        del permute\n+        assert_change(0)\n+\n+        for i in range(int(N / 2)):\n+            x = tensors2[i].numel()\n+            del tensors2[i]\n+            assert_change(-x)", "path": "test/test_cuda.py", "position": null, "original_position": 63, "commit_id": "0e87fbde69b3efa2925109ac1ba224daf338f7b7", "original_commit_id": "ccf104f537c7f386111bfaf0c9eda2c7156ca464", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "This is used to deal with the empty tensor added at line 469 :) If the selected tensor is empty, it asserts that the memory usage stays the same.", "created_at": "2018-01-07T00:31:42Z", "updated_at": "2018-11-23T15:37:54Z", "html_url": "https://github.com/pytorch/pytorch/pull/4511#discussion_r160038074", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4511", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160038074"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4511#discussion_r160038074"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4511"}}, "body_html": "<p>This is used to deal with the empty tensor added at line 469 :) If the selected tensor is empty, it asserts that the memory usage stays the same.</p>", "body_text": "This is used to deal with the empty tensor added at line 469 :) If the selected tensor is empty, it asserts that the memory usage stays the same.", "in_reply_to_id": 160037863}