{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160037863", "pull_request_review_id": 87087419, "id": 160037863, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MDAzNzg2Mw==", "diff_hunk": "@@ -425,6 +425,79 @@ def tmp(self):\n \n \n class TestCuda(TestCase):\n+\n+    def test_memory_allocated_stats(self):\n+        torch.cuda.empty_cache()\n+        m0 = last_m = torch.cuda.memory_allocated()\n+        max_m = torch.cuda.max_memory_allocated()\n+\n+        def assert_change(comp=1):\n+            # comp > 0: increased\n+            # comp = 0: equal\n+            # comp < 0: decreased\n+            nonlocal last_m, max_m\n+            new_m = torch.cuda.memory_allocated()\n+            new_max_m = torch.cuda.max_memory_allocated()\n+            if comp > 0:\n+                self.assertGreater(new_m, last_m)\n+            elif comp < 0:\n+                self.assertLess(new_m, last_m)\n+            else:\n+                self.assertEqual(new_m, last_m)\n+            self.assertLessEqual(new_m, new_max_m)\n+            self.assertGreaterEqual(new_max_m, max_m)\n+            last_m = new_m\n+            max_m = new_max_m\n+\n+        tensors1 = [torch.randn(1).cuda(), torch.randn(10, 20).cuda(), torch.randn(200, 300, 2000).cuda()]\n+        m1 = torch.cuda.memory_allocated()\n+        assert_change(1)\n+\n+        tensors2 = []\n+        N = 30\n+\n+        for i in range(1, int(N / 2) + 1):\n+            # small ones\n+            tensors2.append(torch.randn(i, i * 3).cuda())\n+        assert_change(1)\n+\n+        for i in range(1, N - len(tensors2) + 1):\n+            # large ones\n+            tensors2.append(torch.randn(i * 7, i * 9, i * 11).cuda())\n+        assert_change(1)\n+\n+        tensors2.append(torch.randn(0, 0, 0).cuda())\n+        assert_change(0)\n+\n+        permute = []\n+        for i in torch.randperm(len(tensors2)):\n+            permute.append(tensors2[i])\n+            assert_change(0)\n+\n+        del tensors2\n+        assert_change(0)\n+        tensors2 = permute\n+        assert_change(0)\n+        del permute\n+        assert_change(0)\n+\n+        for i in range(int(N / 2)):\n+            x = tensors2[i].numel()\n+            del tensors2[i]\n+            assert_change(-x)", "path": "test/test_cuda.py", "position": null, "original_position": 63, "commit_id": "0e87fbde69b3efa2925109ac1ba224daf338f7b7", "original_commit_id": "ccf104f537c7f386111bfaf0c9eda2c7156ca464", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "should this just be `-1`? `-x` looks as if you were trying to assert that it dropped exactly by `x` (which isn't true - you're missing a factor of `element_size`)", "created_at": "2018-01-07T00:13:11Z", "updated_at": "2018-11-23T15:37:54Z", "html_url": "https://github.com/pytorch/pytorch/pull/4511#discussion_r160037863", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4511", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/160037863"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4511#discussion_r160037863"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4511"}}, "body_html": "<p>should this just be <code>-1</code>? <code>-x</code> looks as if you were trying to assert that it dropped exactly by <code>x</code> (which isn't true - you're missing a factor of <code>element_size</code>)</p>", "body_text": "should this just be -1? -x looks as if you were trying to assert that it dropped exactly by x (which isn't true - you're missing a factor of element_size)"}