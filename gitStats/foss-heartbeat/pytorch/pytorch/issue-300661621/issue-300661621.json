{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5433", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5433/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5433/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5433/events", "html_url": "https://github.com/pytorch/pytorch/pull/5433", "id": 300661621, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcxNjg1NDc3", "number": 5433, "title": "speed up CPU EmbeddingBag (indexSelectAdd op)", "user": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-02-27T14:53:35Z", "updated_at": "2018-11-23T15:40:43Z", "closed_at": "2018-03-15T19:46:54Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5433", "html_url": "https://github.com/pytorch/pytorch/pull/5433", "diff_url": "https://github.com/pytorch/pytorch/pull/5433.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5433.patch"}, "body_html": "<p>As discussed with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a>, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new <code>index_select_add_</code> operation (which fuses <code>index_select</code> and <code>index_add_</code>).<br>\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.</p>\n<p>Benchmark results on one CPU, for the forward pass only:</p>\n<ul>\n<li>Original code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.349s          1.048s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.371s          1.269s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.385s          1.074s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.947s          1.254s\n</code></pre>\n<ul>\n<li>New code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.921s          1.037s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   9.256s          1.288s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.929s          1.073s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.210s          1.440s\n</code></pre>\n<p>The benchmark code is the same as in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"291686012\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4856\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4856/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4856\">#4856</a> except that I removed the backward pass and the dense tests.</p>\n<p>I also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.</p>\n<ul>\n<li>Original code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.875s          2.946s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.310s          3.715s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.180s          3.122s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.451s          3.562s\n</code></pre>\n<ul>\n<li>New code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.846s          3.003s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.330s          3.671s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.129s          3.065s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.457s          3.548s\n</code></pre>\n<p>Off-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead</p>", "body_text": "As discussed with @cpuhrsch, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new index_select_add_ operation (which fuses index_select and index_add_).\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.\nBenchmark results on one CPU, for the forward pass only:\n\nOriginal code\n\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.349s          1.048s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.371s          1.269s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.385s          1.074s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.947s          1.254s\n\n\nNew code\n\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.921s          1.037s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   9.256s          1.288s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.929s          1.073s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.210s          1.440s\n\nThe benchmark code is the same as in #4856 except that I removed the backward pass and the dense tests.\nI also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.\n\nOriginal code\n\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.875s          2.946s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.310s          3.715s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.180s          3.122s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.451s          3.562s\n\n\nNew code\n\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.846s          3.003s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.330s          3.671s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.129s          3.065s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.457s          3.548s\n\nOff-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead", "body": "As discussed with @cpuhrsch, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new `index_select_add_` operation (which fuses `index_select` and `index_add_`).\r\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.\r\n\r\nBenchmark results on one CPU, for the forward pass only:\r\n\r\n* Original code\r\n```\r\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   5.349s          1.048s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  14.371s          1.269s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   5.385s          1.074s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.947s          1.254s\r\n```\r\n\r\n* New code\r\n```\r\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   4.921s          1.037s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   9.256s          1.288s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   4.929s          1.073s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  14.210s          1.440s\r\n```\r\n\r\nThe benchmark code is the same as in https://github.com/pytorch/pytorch/pull/4856 except that I removed the backward pass and the dense tests.\r\n\r\nI also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.\r\n\r\n* Original code\r\n```\r\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   7.875s          2.946s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.310s          3.715s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   8.180s          3.122s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  21.451s          3.562s\r\n```\r\n\r\n* New code\r\n```\r\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   7.846s          3.003s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.330s          3.671s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   8.129s          3.065s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  21.457s          3.548s\r\n```\r\n\r\nOff-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead"}