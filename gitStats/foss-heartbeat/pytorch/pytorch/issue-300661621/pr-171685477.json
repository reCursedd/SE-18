{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5433", "id": 171685477, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcxNjg1NDc3", "html_url": "https://github.com/pytorch/pytorch/pull/5433", "diff_url": "https://github.com/pytorch/pytorch/pull/5433.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5433.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5433", "number": 5433, "state": "closed", "locked": false, "title": "speed up CPU EmbeddingBag (indexSelectAdd op)", "user": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "body": "As discussed with @cpuhrsch, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new `index_select_add_` operation (which fuses `index_select` and `index_add_`).\r\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.\r\n\r\nBenchmark results on one CPU, for the forward pass only:\r\n\r\n* Original code\r\n```\r\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   5.349s          1.048s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  14.371s          1.269s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   5.385s          1.074s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.947s          1.254s\r\n```\r\n\r\n* New code\r\n```\r\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   4.921s          1.037s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   9.256s          1.288s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   4.929s          1.073s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  14.210s          1.440s\r\n```\r\n\r\nThe benchmark code is the same as in https://github.com/pytorch/pytorch/pull/4856 except that I removed the backward pass and the dense tests.\r\n\r\nI also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.\r\n\r\n* Original code\r\n```\r\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   7.875s          2.946s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.310s          3.715s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   8.180s          3.122s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  21.451s          3.562s\r\n```\r\n\r\n* New code\r\n```\r\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\r\n\r\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\r\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\r\n\r\n====================================================================================================\r\ndimension:      10000   x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   7.846s          3.003s\r\n\r\n====================================================================================================\r\ndimension:      10000   x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  18.330s          3.671s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       100\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n   8.129s          3.065s\r\n\r\n====================================================================================================\r\ndimension:      100000  x       1000\r\n----------------------------------------------------------------------------------------------------\r\ncpu sparse      cuda sparse\r\n  21.457s          3.548s\r\n```\r\n\r\nOff-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead", "created_at": "2018-02-27T14:53:35Z", "updated_at": "2018-11-23T15:40:43Z", "closed_at": "2018-03-15T19:46:54Z", "merged_at": "2018-03-15T19:46:54Z", "merge_commit_sha": "c40b99f9ae3450a0ea47cce6f2082556bc6163e8", "assignee": null, "assignees": [], "requested_reviewers": [], "requested_teams": [], "labels": [], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5433/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5433/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5433/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/daa1c07d381679bbc238af2350c94e3971df88f4", "head": {"label": "martinraison:master", "ref": "master", "sha": "daa1c07d381679bbc238af2350c94e3971df88f4", "user": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "repo": {"id": 81817819, "node_id": "MDEwOlJlcG9zaXRvcnk4MTgxNzgxOQ==", "name": "pytorch", "full_name": "martinraison/pytorch", "private": false, "owner": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/martinraison/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/martinraison/pytorch", "forks_url": "https://api.github.com/repos/martinraison/pytorch/forks", "keys_url": "https://api.github.com/repos/martinraison/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/martinraison/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/martinraison/pytorch/teams", "hooks_url": "https://api.github.com/repos/martinraison/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/martinraison/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/martinraison/pytorch/events", "assignees_url": "https://api.github.com/repos/martinraison/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/martinraison/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/martinraison/pytorch/tags", "blobs_url": "https://api.github.com/repos/martinraison/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/martinraison/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/martinraison/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/martinraison/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/martinraison/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/martinraison/pytorch/languages", "stargazers_url": "https://api.github.com/repos/martinraison/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/martinraison/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/martinraison/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/martinraison/pytorch/subscription", "commits_url": "https://api.github.com/repos/martinraison/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/martinraison/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/martinraison/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/martinraison/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/martinraison/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/martinraison/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/martinraison/pytorch/merges", "archive_url": "https://api.github.com/repos/martinraison/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/martinraison/pytorch/downloads", "issues_url": "https://api.github.com/repos/martinraison/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/martinraison/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/martinraison/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/martinraison/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/martinraison/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/martinraison/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/martinraison/pytorch/deployments", "created_at": "2017-02-13T11:27:34Z", "updated_at": "2018-03-14T15:49:22Z", "pushed_at": "2018-03-14T15:49:21Z", "git_url": "git://github.com/martinraison/pytorch.git", "ssh_url": "git@github.com:martinraison/pytorch.git", "clone_url": "https://github.com/martinraison/pytorch.git", "svn_url": "https://github.com/martinraison/pytorch", "homepage": "http://pytorch.org", "size": 29604, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 0, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "e9fffb5579e570d31a256fde7e387d3d8d40b845", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T12:35:43Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21589, "watchers_count": 21589, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5153, "mirror_url": null, "archived": false, "open_issues_count": 2197, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5153, "open_issues": 2197, "watchers": 21589, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5433"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5433"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/5433"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/5433/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5433/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5433/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/daa1c07d381679bbc238af2350c94e3971df88f4"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>As discussed with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a>, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new <code>index_select_add_</code> operation (which fuses <code>index_select</code> and <code>index_add_</code>).<br>\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.</p>\n<p>Benchmark results on one CPU, for the forward pass only:</p>\n<ul>\n<li>Original code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.349s          1.048s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.371s          1.269s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.385s          1.074s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.947s          1.254s\n</code></pre>\n<ul>\n<li>New code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.921s          1.037s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   9.256s          1.288s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.929s          1.073s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.210s          1.440s\n</code></pre>\n<p>The benchmark code is the same as in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"291686012\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4856\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4856/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4856\">#4856</a> except that I removed the backward pass and the dense tests.</p>\n<p>I also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.</p>\n<ul>\n<li>Original code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.875s          2.946s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.310s          3.715s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.180s          3.122s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.451s          3.562s\n</code></pre>\n<ul>\n<li>New code</li>\n</ul>\n<pre><code>$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.846s          3.003s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.330s          3.671s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.129s          3.065s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.457s          3.548s\n</code></pre>\n<p>Off-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead</p>", "body_text": "As discussed with @cpuhrsch, this should speed up the CPU version of EmbeddingBag in a few cases. The main idea is to avoid creating a large intermediary tensor during the forward pass, using the new index_select_add_ operation (which fuses index_select and index_add_).\nI also slightly optimized the backward to replace a bunch of divisions by a few divisions and a bunch of multiplications.\nBenchmark results on one CPU, for the forward pass only:\n\nOriginal code\n\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.349s          1.048s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.371s          1.269s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   5.385s          1.074s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.947s          1.254s\n\n\nNew code\n\n$ NUMEXPR_NUM_THREADS=1 MKL_NUM_THREADS=1 OMP_NUM_THREADS=1 taskset -c 0 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.921s          1.037s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   9.256s          1.288s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   4.929s          1.073s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  14.210s          1.440s\n\nThe benchmark code is the same as in #4856 except that I removed the backward pass and the dense tests.\nI also tried including the backward pass and multiple CPUs. Perhaps surprisingly, I didn't see any significant change in that scenario, although in my original \"real life\" scenario, the new code makes overall training about 30% faster. I haven't yet found what's different in the benchmark setup.\n\nOriginal code\n\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.875s          2.946s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.310s          3.715s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.180s          3.122s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.451s          3.562s\n\n\nNew code\n\n$ NUMEXPR_NUM_THREADS=8 MKL_NUM_THREADS=8 OMP_NUM_THREADS=8 taskset -c 0-7 python benchmark.py\n\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nruns: 10000     number of indices: 2000 maximum number of bags: 200     maximum bag size: 30\n\n====================================================================================================\ndimension:      10000   x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   7.846s          3.003s\n\n====================================================================================================\ndimension:      10000   x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  18.330s          3.671s\n\n====================================================================================================\ndimension:      100000  x       100\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n   8.129s          3.065s\n\n====================================================================================================\ndimension:      100000  x       1000\n----------------------------------------------------------------------------------------------------\ncpu sparse      cuda sparse\n  21.457s          3.548s\n\nOff-topic: we may want to add support for empty bags at some points, if we can do it without significant overhead", "merged": true, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "comments": 7, "review_comments": 5, "maintainer_can_modify": false, "commits": 5, "additions": 71, "deletions": 13, "changed_files": 3}