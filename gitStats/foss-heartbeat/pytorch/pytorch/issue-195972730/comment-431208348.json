{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/431208348", "html_url": "https://github.com/pytorch/pytorch/issues/315#issuecomment-431208348", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/315", "id": 431208348, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTIwODM0OA==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-19T00:39:42Z", "updated_at": "2018-10-19T00:39:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> I see, I forget to set <code>keep_vars=True</code>:</p>\n<pre><code>&gt;&gt;&gt; import copy\n&gt;&gt;&gt; l = nn.Linear(10,1)\n&gt;&gt;&gt; s = l.state_dict(keep_vars=True)\n&gt;&gt;&gt; s2 = copy.deepcopy(s)\n&gt;&gt;&gt; print s\nOrderedDict([('weight', Parameter containing:\ntensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', Parameter containing:\ntensor([0.0133], requires_grad=True))]) \n\n&gt;&gt;&gt; print s2\nOrderedDict([('weight', tensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', tensor([0.0133], requires_grad=True))])\n</code></pre>\n<p>So yes, s2 is no longer in type <code>Parameter</code> after deepcopy()</p>", "body_text": "@ezyang I see, I forget to set keep_vars=True:\n>>> import copy\n>>> l = nn.Linear(10,1)\n>>> s = l.state_dict(keep_vars=True)\n>>> s2 = copy.deepcopy(s)\n>>> print s\nOrderedDict([('weight', Parameter containing:\ntensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', Parameter containing:\ntensor([0.0133], requires_grad=True))]) \n\n>>> print s2\nOrderedDict([('weight', tensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', tensor([0.0133], requires_grad=True))])\n\nSo yes, s2 is no longer in type Parameter after deepcopy()", "body": "@ezyang I see, I forget to set `keep_vars=True`:\r\n```\r\n>>> import copy\r\n>>> l = nn.Linear(10,1)\r\n>>> s = l.state_dict(keep_vars=True)\r\n>>> s2 = copy.deepcopy(s)\r\n>>> print s\r\nOrderedDict([('weight', Parameter containing:\r\ntensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', Parameter containing:\r\ntensor([0.0133], requires_grad=True))]) \r\n\r\n>>> print s2\r\nOrderedDict([('weight', tensor([[-0.1936, -0.0724, -0.2729, -0.1525,  0.1280,  0.2333,  0.3120, -0.0423, -0.3101, -0.1078]], requires_grad=True)), ('bias', tensor([0.0133], requires_grad=True))])\r\n```\r\nSo yes, s2 is no longer in type `Parameter` after deepcopy()"}