{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5040", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5040/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5040/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5040/events", "html_url": "https://github.com/pytorch/pytorch/issues/5040", "id": 294274594, "node_id": "MDU6SXNzdWUyOTQyNzQ1OTQ=", "number": 5040, "title": "RuntimeError: DataLoader worker (pid 13) is killed by signal: Bus error.", "user": {"login": "miraclewkf", "id": 25998325, "node_id": "MDQ6VXNlcjI1OTk4MzI1", "avatar_url": "https://avatars3.githubusercontent.com/u/25998325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miraclewkf", "html_url": "https://github.com/miraclewkf", "followers_url": "https://api.github.com/users/miraclewkf/followers", "following_url": "https://api.github.com/users/miraclewkf/following{/other_user}", "gists_url": "https://api.github.com/users/miraclewkf/gists{/gist_id}", "starred_url": "https://api.github.com/users/miraclewkf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miraclewkf/subscriptions", "organizations_url": "https://api.github.com/users/miraclewkf/orgs", "repos_url": "https://api.github.com/users/miraclewkf/repos", "events_url": "https://api.github.com/users/miraclewkf/events{/privacy}", "received_events_url": "https://api.github.com/users/miraclewkf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-02-05T05:03:36Z", "updated_at": "2018-11-23T16:29:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>When I set <code>num_workers=1</code> or other value greater than 0 in <code>torch.utils.data.DataLoader</code>, I get this error.<br>\nThe detail of the error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/opt/project/train.py\", line 150, in &lt;module&gt;\n    dataset_sizes=dataset_sizes)\n  File \"/opt/project/train.py\", line 51, in train_model\n    outputs = model(inputs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 64, in forward\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 75, in scatter\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\n    inputs = scatter(inputs, target_gpus, dim) if inputs else []\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\n    return scatter_map(inputs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\n    return list(zip(*map(scatter_map, obj)))\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\n    return Scatter.apply(target_gpus, None, dim, obj)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 68, in forward\n    outputs = comm.scatter(input, ctx.target_gpus, ctx.chunk_sizes, ctx.dim, streams)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/cuda/comm.py\", line 189, in scatter\n    outputs.append(chunk.cuda(device, async=True))\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\n    return new_type(self.size()).copy_(self, async)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 172, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 13) is killed by signal: Bus error.\n</code></pre>", "body_text": "When I set num_workers=1 or other value greater than 0 in torch.utils.data.DataLoader, I get this error.\nThe detail of the error:\nTraceback (most recent call last):\n  File \"/opt/project/train.py\", line 150, in <module>\n    dataset_sizes=dataset_sizes)\n  File \"/opt/project/train.py\", line 51, in train_model\n    outputs = model(inputs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 64, in forward\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 75, in scatter\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\n    inputs = scatter(inputs, target_gpus, dim) if inputs else []\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\n    return scatter_map(inputs)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\n    return list(zip(*map(scatter_map, obj)))\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\n    return Scatter.apply(target_gpus, None, dim, obj)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 68, in forward\n    outputs = comm.scatter(input, ctx.target_gpus, ctx.chunk_sizes, ctx.dim, streams)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/cuda/comm.py\", line 189, in scatter\n    outputs.append(chunk.cuda(device, async=True))\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\n    return new_type(self.size()).copy_(self, async)\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 172, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 13) is killed by signal: Bus error.", "body": "When I set `num_workers=1` or other value greater than 0 in `torch.utils.data.DataLoader`, I get this error.\r\nThe detail of the error:\r\n``` \r\nTraceback (most recent call last):\r\n  File \"/opt/project/train.py\", line 150, in <module>\r\n    dataset_sizes=dataset_sizes)\r\n  File \"/opt/project/train.py\", line 51, in train_model\r\n    outputs = model(inputs)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 357, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 64, in forward\r\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 75, in scatter\r\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\r\n    inputs = scatter(inputs, target_gpus, dim) if inputs else []\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\r\n    return scatter_map(inputs)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\r\n    return list(zip(*map(scatter_map, obj)))\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\r\n    return Scatter.apply(target_gpus, None, dim, obj)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 68, in forward\r\n    outputs = comm.scatter(input, ctx.target_gpus, ctx.chunk_sizes, ctx.dim, streams)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/cuda/comm.py\", line 189, in scatter\r\n    outputs.append(chunk.cuda(device, async=True))\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\r\n    return new_type(self.size()).copy_(self, async)\r\n  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 172, in handler\r\n    _error_if_any_worker_fails()\r\nRuntimeError: DataLoader worker (pid 13) is killed by signal: Bus error.\r\n```"}