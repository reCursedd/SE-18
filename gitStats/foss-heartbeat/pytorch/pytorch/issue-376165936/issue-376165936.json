{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13420", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13420/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13420/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13420/events", "html_url": "https://github.com/pytorch/pytorch/pull/13420", "id": 376165936, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI3NDQ2NTM5", "number": 13420, "title": "Speed-up \"advanced\" indexing operations", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-31T21:23:38Z", "updated_at": "2018-11-16T00:07:41Z", "closed_at": null, "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/13420", "html_url": "https://github.com/pytorch/pytorch/pull/13420", "diff_url": "https://github.com/pytorch/pytorch/pull/13420.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/13420.patch"}, "body_html": "<p>This speeds-up \"advanced\" indexing (indexing a tensor by a tensor)<br>\non CPU and GPU. There's still a bunch of work to do, including<br>\nspeeding up indexing by a byte (boolean) mask and speeding up the derivative<br>\ncalculation for advanced indexing.</p>\n<p>Here's some speed comparisons to indexing on master using a little <a href=\"https://gist.github.com/colesbury/c369db72aad594e5e032c8fda557d909\">benchmark script</a> with 16 OpenMP threads and on a P100. The test cases are listed as (input shape -&gt; output shape).</p>\n<table>\n<thead>\n<tr>\n<th>Test case</th>\n<th>CPU (old vs. new)</th>\n<th>CUDA (old vs. new)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1024x1024 -&gt; 512x1024</td>\n<td>225 us vs. <strong>57 us</strong></td>\n<td>297 us vs. <strong>47 us</strong></td>\n</tr>\n<tr>\n<td>1024x1024 -&gt; 1024x512</td>\n<td>208 us vs. <strong>153 us</strong></td>\n<td>335 us vs. <strong>54 us</strong></td>\n</tr>\n<tr>\n<td>50x50 -&gt; 20000x50</td>\n<td>617 us vs. <strong>77 us</strong></td>\n<td>239 us vs. <strong>54 us</strong></td>\n</tr>\n<tr>\n<td>50x50 -&gt; 50x20000</td>\n<td>575 us vs. <strong>236 us</strong></td>\n<td>262 us vs. <strong>58 us</strong></td>\n</tr>\n<tr>\n<td>2x5x10 -&gt; 10</td>\n<td>65 us  vs. <strong>18 us</strong></td>\n<td>612 us vs. <strong>93 us</strong></td>\n</tr>\n</tbody>\n</table>\n<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"359979938\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/11647\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/11647/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/11647\">#11647</a></p>", "body_text": "This speeds-up \"advanced\" indexing (indexing a tensor by a tensor)\non CPU and GPU. There's still a bunch of work to do, including\nspeeding up indexing by a byte (boolean) mask and speeding up the derivative\ncalculation for advanced indexing.\nHere's some speed comparisons to indexing on master using a little benchmark script with 16 OpenMP threads and on a P100. The test cases are listed as (input shape -> output shape).\n\n\n\nTest case\nCPU (old vs. new)\nCUDA (old vs. new)\n\n\n\n\n1024x1024 -> 512x1024\n225 us vs. 57 us\n297 us vs. 47 us\n\n\n1024x1024 -> 1024x512\n208 us vs. 153 us\n335 us vs. 54 us\n\n\n50x50 -> 20000x50\n617 us vs. 77 us\n239 us vs. 54 us\n\n\n50x50 -> 50x20000\n575 us vs. 236 us\n262 us vs. 58 us\n\n\n2x5x10 -> 10\n65 us  vs. 18 us\n612 us vs. 93 us\n\n\n\nSee #11647", "body": "This speeds-up \"advanced\" indexing (indexing a tensor by a tensor)\r\non CPU and GPU. There's still a bunch of work to do, including\r\nspeeding up indexing by a byte (boolean) mask and speeding up the derivative\r\ncalculation for advanced indexing.\r\n\r\nHere's some speed comparisons to indexing on master using a little [benchmark script](https://gist.github.com/colesbury/c369db72aad594e5e032c8fda557d909) with 16 OpenMP threads and on a P100. The test cases are listed as (input shape -> output shape).\r\n\r\n| Test case             | CPU (old vs. new)   | CUDA (old vs. new)     |\r\n|-----------------------|---------------------|------------------------|\r\n| 1024x1024 -> 512x1024 | 225 us vs. **57 us**  | 297 us vs. **47 us** |\r\n| 1024x1024 -> 1024x512 | 208 us vs. **153 us** | 335 us vs. **54 us** |\r\n| 50x50 -> 20000x50     | 617 us vs. **77 us**  | 239 us vs. **54 us** |\r\n| 50x50 -> 50x20000     | 575 us vs. **236 us** | 262 us vs. **58 us** |\r\n| 2x5x10 -> 10          | 65 us  vs. **18 us**  | 612 us vs. **93 us** |\r\n\r\nSee #11647"}