{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5833", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5833/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5833/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5833/events", "html_url": "https://github.com/pytorch/pytorch/issues/5833", "id": 305919780, "node_id": "MDU6SXNzdWUzMDU5MTk3ODA=", "number": 5833, "title": "[Doc Bug] where is classmethod torch.nn.Embedding.from_pretrained?", "user": {"login": "cdluminate", "id": 5723047, "node_id": "MDQ6VXNlcjU3MjMwNDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5723047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cdluminate", "html_url": "https://github.com/cdluminate", "followers_url": "https://api.github.com/users/cdluminate/followers", "following_url": "https://api.github.com/users/cdluminate/following{/other_user}", "gists_url": "https://api.github.com/users/cdluminate/gists{/gist_id}", "starred_url": "https://api.github.com/users/cdluminate/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cdluminate/subscriptions", "organizations_url": "https://api.github.com/users/cdluminate/orgs", "repos_url": "https://api.github.com/users/cdluminate/repos", "events_url": "https://api.github.com/users/cdluminate/events{/privacy}", "received_events_url": "https://api.github.com/users/cdluminate/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-03-16T13:03:21Z", "updated_at": "2018-03-16T13:19:43Z", "closed_at": "2018-03-16T13:19:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>There is a method to initialize Embedding from pretrained data (torch.Tensor).</p>\n<p><a href=\"http://pytorch.org/docs/master/nn.html\" rel=\"nofollow\">http://pytorch.org/docs/master/nn.html</a></p>\n<p>However that method does not exist in pytorch 0.3.1 .</p>\n<p>If it was deprecated, what should I do to load pretrained word vectors such as torchtext.vocab.GloVe?</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch <span class=\"pl-k\">as</span> th\nemb <span class=\"pl-k\">=</span> th.nn.Embedding(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">20</span>)\nemb.weight[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> ERROR</span>\nemb.weight.requires_grad <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\nemb.weight[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> still ERROR</span></pre></div>\n<p>error message:</p>\n<pre><code>RuntimeError: in-place operations can be only used on variables that don't share storage with any other variables, but detected that there are 2 objects sharing it\n</code></pre>", "body_text": "There is a method to initialize Embedding from pretrained data (torch.Tensor).\nhttp://pytorch.org/docs/master/nn.html\nHowever that method does not exist in pytorch 0.3.1 .\nIf it was deprecated, what should I do to load pretrained word vectors such as torchtext.vocab.GloVe?\nimport torch as th\nemb = th.nn.Embedding(10, 20)\nemb.weight[1] = 0 # ERROR\nemb.weight.requires_grad = False\nemb.weight[1] = 0 # still ERROR\nerror message:\nRuntimeError: in-place operations can be only used on variables that don't share storage with any other variables, but detected that there are 2 objects sharing it", "body": "There is a method to initialize Embedding from pretrained data (torch.Tensor).\r\n\r\nhttp://pytorch.org/docs/master/nn.html\r\n\r\nHowever that method does not exist in pytorch 0.3.1 .\r\n\r\nIf it was deprecated, what should I do to load pretrained word vectors such as torchtext.vocab.GloVe?\r\n\r\n```python\r\nimport torch as th\r\nemb = th.nn.Embedding(10, 20)\r\nemb.weight[1] = 0 # ERROR\r\nemb.weight.requires_grad = False\r\nemb.weight[1] = 0 # still ERROR\r\n```\r\n\r\nerror message:\r\n```\r\nRuntimeError: in-place operations can be only used on variables that don't share storage with any other variables, but detected that there are 2 objects sharing it\r\n```"}