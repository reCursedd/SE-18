{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3947", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3947/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3947/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3947/events", "html_url": "https://github.com/pytorch/pytorch/issues/3947", "id": 277996422, "node_id": "MDU6SXNzdWUyNzc5OTY0MjI=", "number": 3947, "title": "CrossEntropyLoss input dimension ERROR", "user": {"login": "ogugugugugua", "id": 17522733, "node_id": "MDQ6VXNlcjE3NTIyNzMz", "avatar_url": "https://avatars3.githubusercontent.com/u/17522733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ogugugugugua", "html_url": "https://github.com/ogugugugugua", "followers_url": "https://api.github.com/users/ogugugugugua/followers", "following_url": "https://api.github.com/users/ogugugugugua/following{/other_user}", "gists_url": "https://api.github.com/users/ogugugugugua/gists{/gist_id}", "starred_url": "https://api.github.com/users/ogugugugugua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ogugugugugua/subscriptions", "organizations_url": "https://api.github.com/users/ogugugugugua/orgs", "repos_url": "https://api.github.com/users/ogugugugugua/repos", "events_url": "https://api.github.com/users/ogugugugugua/events{/privacy}", "received_events_url": "https://api.github.com/users/ogugugugugua/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-30T04:40:35Z", "updated_at": "2018-09-03T10:24:01Z", "closed_at": "2017-11-30T07:06:02Z", "author_association": "NONE", "body_html": "<p>From the doc of pytorch we know the use of crossentropy loss should be like this :</p>\n<blockquote>\n<p>The <code>input</code> is expected to contain scores for each class.<br>\n<code>input</code> has to be a 2D <code>Tensor</code> of size <code>(minibatch, C)</code>.<br>\nThis criterion expects a class index (0 to C-1) as the<br>\n<code>target</code> for each value of a 1D tensor of size <code>minibatch</code><br>\nAnd<br>\nShape:<br>\n- Input: :math:<code>(N, C)</code> where <code>C = number of classes</code><br>\n- Target: :math:<code>(N)</code> where each value is <code>0 &lt;= targets[i] &lt;= C-1</code></p>\n</blockquote>\n<p>And the example from the doc is :</p>\n<pre><code> loss = nn.CrossEntropyLoss()\n input = autograd.Variable(torch.randn(3, 5), requires_grad=True)\n target = autograd.Variable(torch.LongTensor(3).random_(5))\n output = loss(input, target)\n output.backward()\n</code></pre>\n<p>As a beginner of pytorch, I am confused of the dimension of the input &amp; target.</p>\n<ol>\n<li>If we like to compare how the input is similar to the target, and the classes of the input is C, why the dimension of target is N but not C, since target should have a score for each of its classes, then the comparation between them can happen. Can someone tell me what the dimension of the input and especially the target mean, why we should have a dimension of \"minibatch\" here for the target? Or maybe I misunderstood it?</li>\n<li>In my classifier project I am trying to compare the loss between target and the output of model using crossentropy. Both of them are NOT one-hot. The sizes of them are: Target(5518), Output(1,5518). I'm trying to indicate that there're 5518 classes, my model gives all the classes a score which is storaged in Output tensor, and the 1-D Target tensor, of course storage the right classification answer. All I wanna do is to compare the similarity between them, but how can I do that...?</li>\n</ol>\n<p>Appreciate a lot if someone can do me a favor! Thanks in advance!! <g-emoji class=\"g-emoji\" alias=\"1st_place_medal\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f947.png\">\ud83e\udd47</g-emoji></p>", "body_text": "From the doc of pytorch we know the use of crossentropy loss should be like this :\n\nThe input is expected to contain scores for each class.\ninput has to be a 2D Tensor of size (minibatch, C).\nThis criterion expects a class index (0 to C-1) as the\ntarget for each value of a 1D tensor of size minibatch\nAnd\nShape:\n- Input: :math:(N, C) where C = number of classes\n- Target: :math:(N) where each value is 0 <= targets[i] <= C-1\n\nAnd the example from the doc is :\n loss = nn.CrossEntropyLoss()\n input = autograd.Variable(torch.randn(3, 5), requires_grad=True)\n target = autograd.Variable(torch.LongTensor(3).random_(5))\n output = loss(input, target)\n output.backward()\n\nAs a beginner of pytorch, I am confused of the dimension of the input & target.\n\nIf we like to compare how the input is similar to the target, and the classes of the input is C, why the dimension of target is N but not C, since target should have a score for each of its classes, then the comparation between them can happen. Can someone tell me what the dimension of the input and especially the target mean, why we should have a dimension of \"minibatch\" here for the target? Or maybe I misunderstood it?\nIn my classifier project I am trying to compare the loss between target and the output of model using crossentropy. Both of them are NOT one-hot. The sizes of them are: Target(5518), Output(1,5518). I'm trying to indicate that there're 5518 classes, my model gives all the classes a score which is storaged in Output tensor, and the 1-D Target tensor, of course storage the right classification answer. All I wanna do is to compare the similarity between them, but how can I do that...?\n\nAppreciate a lot if someone can do me a favor! Thanks in advance!! \ud83e\udd47", "body": "From the doc of pytorch we know the use of crossentropy loss should be like this :\r\n\r\n> The `input` is expected to contain scores for each class.\r\n>     `input` has to be a 2D `Tensor` of size `(minibatch, C)`. \r\n> This criterion expects a class index (0 to C-1) as the\r\n>     `target` for each value of a 1D tensor of size `minibatch`\r\n> And \r\n> Shape:\r\n>         - Input: :math:`(N, C)` where `C = number of classes`\r\n>         - Target: :math:`(N)` where each value is `0 <= targets[i] <= C-1`\r\n\r\nAnd the example from the doc is : \r\n```\r\n loss = nn.CrossEntropyLoss()\r\n input = autograd.Variable(torch.randn(3, 5), requires_grad=True)\r\n target = autograd.Variable(torch.LongTensor(3).random_(5))\r\n output = loss(input, target)\r\n output.backward()\r\n```\r\nAs a beginner of pytorch, I am confused of the dimension of the input & target.\r\n1. If we like to compare how the input is similar to the target, and the classes of the input is C, why the dimension of target is N but not C, since target should have a score for each of its classes, then the comparation between them can happen. Can someone tell me what the dimension of the input and especially the target mean, why we should have a dimension of \"minibatch\" here for the target? Or maybe I misunderstood it?\r\n2. In my classifier project I am trying to compare the loss between target and the output of model using crossentropy. Both of them are NOT one-hot. The sizes of them are: Target(5518), Output(1,5518). I'm trying to indicate that there're 5518 classes, my model gives all the classes a score which is storaged in Output tensor, and the 1-D Target tensor, of course storage the right classification answer. All I wanna do is to compare the similarity between them, but how can I do that...?\r\n\r\nAppreciate a lot if someone can do me a favor! Thanks in advance!! \ud83e\udd47 "}