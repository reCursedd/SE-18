{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1629", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1629/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1629/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1629/events", "html_url": "https://github.com/pytorch/pytorch/issues/1629", "id": 230781327, "node_id": "MDU6SXNzdWUyMzA3ODEzMjc=", "number": 1629, "title": "spurious tensor broadcasting, and inconsistent behavior with numpy", "user": {"login": "zym1010", "id": 4273204, "node_id": "MDQ6VXNlcjQyNzMyMDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4273204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zym1010", "html_url": "https://github.com/zym1010", "followers_url": "https://api.github.com/users/zym1010/followers", "following_url": "https://api.github.com/users/zym1010/following{/other_user}", "gists_url": "https://api.github.com/users/zym1010/gists{/gist_id}", "starred_url": "https://api.github.com/users/zym1010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zym1010/subscriptions", "organizations_url": "https://api.github.com/users/zym1010/orgs", "repos_url": "https://api.github.com/users/zym1010/repos", "events_url": "https://api.github.com/users/zym1010/events{/privacy}", "received_events_url": "https://api.github.com/users/zym1010/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-05-23T17:10:32Z", "updated_at": "2017-05-23T18:18:32Z", "closed_at": "2017-05-23T18:18:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>although officially PyTorch doesn't support broadcasting, seems that still it can compare arrays of different shapes, and it gave different behaviors as numpy. Is this expected?</p>\n<pre><code>In [23]: a = np.arange(5).astype(np.float32)\n\nIn [24]: b= a.copy().reshape(5,1)\n\nIn [25]: a_torch=torch.Tensor(a)\n\nIn [26]: b_torch=torch.Tensor(b)\n\nIn [27]: a==b\nOut[27]:\narray([[ True, False, False, False, False],\n       [False,  True, False, False, False],\n       [False, False,  True, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False,  True]], dtype=bool)\n\nIn [28]: a_torch==b_torch\nOut[28]:\n\n 1\n 1\n 1\n 1\n 1\n[torch.ByteTensor of size 5]\n</code></pre>\n<p>more weird problems.</p>\n<pre><code>In [45]: a_torch==b_torch.t()\nOut[45]:\n\n 1\n 1\n 1\n 1\n 1\n[torch.ByteTensor of size 5]\n\nIn [46]: b_torch.t()==a_torch\nOut[46]:\n\n 1  1  1  1  1\n[torch.ByteTensor of size 1x5]\n</code></pre>", "body_text": "although officially PyTorch doesn't support broadcasting, seems that still it can compare arrays of different shapes, and it gave different behaviors as numpy. Is this expected?\nIn [23]: a = np.arange(5).astype(np.float32)\n\nIn [24]: b= a.copy().reshape(5,1)\n\nIn [25]: a_torch=torch.Tensor(a)\n\nIn [26]: b_torch=torch.Tensor(b)\n\nIn [27]: a==b\nOut[27]:\narray([[ True, False, False, False, False],\n       [False,  True, False, False, False],\n       [False, False,  True, False, False],\n       [False, False, False,  True, False],\n       [False, False, False, False,  True]], dtype=bool)\n\nIn [28]: a_torch==b_torch\nOut[28]:\n\n 1\n 1\n 1\n 1\n 1\n[torch.ByteTensor of size 5]\n\nmore weird problems.\nIn [45]: a_torch==b_torch.t()\nOut[45]:\n\n 1\n 1\n 1\n 1\n 1\n[torch.ByteTensor of size 5]\n\nIn [46]: b_torch.t()==a_torch\nOut[46]:\n\n 1  1  1  1  1\n[torch.ByteTensor of size 1x5]", "body": "although officially PyTorch doesn't support broadcasting, seems that still it can compare arrays of different shapes, and it gave different behaviors as numpy. Is this expected?\r\n\r\n~~~\r\nIn [23]: a = np.arange(5).astype(np.float32)\r\n\r\nIn [24]: b= a.copy().reshape(5,1)\r\n\r\nIn [25]: a_torch=torch.Tensor(a)\r\n\r\nIn [26]: b_torch=torch.Tensor(b)\r\n\r\nIn [27]: a==b\r\nOut[27]:\r\narray([[ True, False, False, False, False],\r\n       [False,  True, False, False, False],\r\n       [False, False,  True, False, False],\r\n       [False, False, False,  True, False],\r\n       [False, False, False, False,  True]], dtype=bool)\r\n\r\nIn [28]: a_torch==b_torch\r\nOut[28]:\r\n\r\n 1\r\n 1\r\n 1\r\n 1\r\n 1\r\n[torch.ByteTensor of size 5]\r\n~~~\r\n\r\nmore weird problems.\r\n~~~\r\nIn [45]: a_torch==b_torch.t()\r\nOut[45]:\r\n\r\n 1\r\n 1\r\n 1\r\n 1\r\n 1\r\n[torch.ByteTensor of size 5]\r\n\r\nIn [46]: b_torch.t()==a_torch\r\nOut[46]:\r\n\r\n 1  1  1  1  1\r\n[torch.ByteTensor of size 1x5]\r\n~~~"}