{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4529", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4529/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4529/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4529/events", "html_url": "https://github.com/pytorch/pytorch/pull/4529", "id": 286679018, "node_id": "MDExOlB1bGxSZXF1ZXN0MTYxNTgxMjg2", "number": 4529, "title": "Fix return type for Bernoulli enumerate_support", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-08T08:46:43Z", "updated_at": "2018-11-23T15:37:56Z", "closed_at": "2018-01-08T22:17:44Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4529", "html_url": "https://github.com/pytorch/pytorch/pull/4529", "diff_url": "https://github.com/pytorch/pytorch/pull/4529.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4529.patch"}, "body_html": "<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #68.\">Fixes</span> <a href=\"https://github.com/probtorch/pytorch/issues/68\" data-hovercard-type=\"issue\" data-hovercard-url=\"/probtorch/pytorch/issues/68/hovercard\">probtorch/pytorch#68</a>. Only the return type for Bernoulli's <code>enumerate_support</code> needed change.</p>\n<ul>\n<li>We use <code>FloatTensor</code> as the default return type of distribution's samples, , as most tensor operations support <code>FloatTensor</code> without needing any casting.</li>\n<li>If the underlying torch sampler has a different tensor return type, that may be used instead. e.g. in the case of Categorical, we use <code>torch.multinomial</code> that returns a <code>LongTensor</code>. The return type of <code>Categorical</code> is therefore a <code>LongTensor</code>. This also helps in cases where the generated sample is used to index into tensors or numpy arrays. However, for the <code>OneHotCategorical</code>, we default to <code>FloatTensor</code> since the samples are more generally used as masks.</li>\n</ul>", "body_text": "Fixes probtorch/pytorch#68. Only the return type for Bernoulli's enumerate_support needed change.\n\nWe use FloatTensor as the default return type of distribution's samples, , as most tensor operations support FloatTensor without needing any casting.\nIf the underlying torch sampler has a different tensor return type, that may be used instead. e.g. in the case of Categorical, we use torch.multinomial that returns a LongTensor. The return type of Categorical is therefore a LongTensor. This also helps in cases where the generated sample is used to index into tensors or numpy arrays. However, for the OneHotCategorical, we default to FloatTensor since the samples are more generally used as masks.", "body": "Fixes [probtorch/pytorch#68](https://github.com/probtorch/pytorch/issues/68). Only the return type for Bernoulli's `enumerate_support` needed change. \r\n - We use `FloatTensor` as the default return type of distribution's samples, , as most tensor operations support `FloatTensor` without needing any casting. \r\n - If the underlying torch sampler has a different tensor return type, that may be used instead. e.g. in the case of Categorical, we use `torch.multinomial` that returns a `LongTensor`. The return type of `Categorical` is therefore a `LongTensor`. This also helps in cases where the generated sample is used to index into tensors or numpy arrays. However, for the `OneHotCategorical`, we default to `FloatTensor` since the samples are more generally used as masks."}