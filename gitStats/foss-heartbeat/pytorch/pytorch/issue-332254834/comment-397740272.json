{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/397740272", "html_url": "https://github.com/pytorch/pytorch/pull/8475#issuecomment-397740272", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8475", "id": 397740272, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Nzc0MDI3Mg==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-15T20:57:17Z", "updated_at": "2018-06-15T21:01:53Z", "author_association": "MEMBER", "body_html": "<p>This deserves some tests. Currently, if you call an unsupported method you'll get a linker error which isn't ideal. In my local testing, <code>at::native::tensor({1, 2, 3, 4})</code> also did not work.</p>\n<p>Here are some use cases that I think should work:</p>\n<pre><code>std::vector&lt;int32_t&gt; data(...);\nat::tensor(data);\n\nat::tensor({1, 2, 3, 4})\nat::tensor({1.0, 2.5, 3.5})\n</code></pre>\n<p>I would suggest the following to avoid the ambiguous overloads:</p>\n<pre><code>tensor(ArrayRef&lt;int64_t&gt; values)\ntensor(ArrayRef&lt;int32_t&gt; values)\ntensor(ArrayRef&lt;int16_t&gt; values)\ntensor(ArrayRef&lt;int8_t&gt; values)\ntensor(ArrayRef&lt;uint8_t&gt; values)\ntensor(ArrayRef&lt;float&gt; values)\ntensor(ArrayRef&lt;double&gt; values)\ntensor(ArrayRef&lt;Half&gt; values)\n\ntensor(initializer_list&lt;int&gt; values)\ntensor(initializer_list&lt;float&gt; values)\ntensor(initializer_list&lt;double&gt; values)\n</code></pre>\n<p>I would suggest that the <code>ArrayRef&lt;T&gt;</code> overloads preserve the type T of their values if no dtype is given. For example, the int32_t overload should create an int tensor, not a long tensor.</p>\n<p>I would suggest that the initializer_list overloads default to kLong for <code>&lt;int&gt;</code> and the default tensor type for float and double. Since the default tensor type isn't in ATen yet, you could just assume kFloat for now.</p>", "body_text": "This deserves some tests. Currently, if you call an unsupported method you'll get a linker error which isn't ideal. In my local testing, at::native::tensor({1, 2, 3, 4}) also did not work.\nHere are some use cases that I think should work:\nstd::vector<int32_t> data(...);\nat::tensor(data);\n\nat::tensor({1, 2, 3, 4})\nat::tensor({1.0, 2.5, 3.5})\n\nI would suggest the following to avoid the ambiguous overloads:\ntensor(ArrayRef<int64_t> values)\ntensor(ArrayRef<int32_t> values)\ntensor(ArrayRef<int16_t> values)\ntensor(ArrayRef<int8_t> values)\ntensor(ArrayRef<uint8_t> values)\ntensor(ArrayRef<float> values)\ntensor(ArrayRef<double> values)\ntensor(ArrayRef<Half> values)\n\ntensor(initializer_list<int> values)\ntensor(initializer_list<float> values)\ntensor(initializer_list<double> values)\n\nI would suggest that the ArrayRef<T> overloads preserve the type T of their values if no dtype is given. For example, the int32_t overload should create an int tensor, not a long tensor.\nI would suggest that the initializer_list overloads default to kLong for <int> and the default tensor type for float and double. Since the default tensor type isn't in ATen yet, you could just assume kFloat for now.", "body": "This deserves some tests. Currently, if you call an unsupported method you'll get a linker error which isn't ideal. In my local testing, `at::native::tensor({1, 2, 3, 4})` also did not work.\r\n\r\nHere are some use cases that I think should work:\r\n\r\n```\r\nstd::vector<int32_t> data(...);\r\nat::tensor(data);\r\n\r\nat::tensor({1, 2, 3, 4})\r\nat::tensor({1.0, 2.5, 3.5})\r\n```\r\n\r\nI would suggest the following to avoid the ambiguous overloads:\r\n\r\n```\r\ntensor(ArrayRef<int64_t> values)\r\ntensor(ArrayRef<int32_t> values)\r\ntensor(ArrayRef<int16_t> values)\r\ntensor(ArrayRef<int8_t> values)\r\ntensor(ArrayRef<uint8_t> values)\r\ntensor(ArrayRef<float> values)\r\ntensor(ArrayRef<double> values)\r\ntensor(ArrayRef<Half> values)\r\n\r\ntensor(initializer_list<int> values)\r\ntensor(initializer_list<float> values)\r\ntensor(initializer_list<double> values)\r\n```\r\n\r\nI would suggest that the `ArrayRef<T>` overloads preserve the type T of their values if no dtype is given. For example, the int32_t overload should create an int tensor, not a long tensor.\r\n\r\nI would suggest that the initializer_list overloads default to kLong for `<int>` and the default tensor type for float and double. Since the default tensor type isn't in ATen yet, you could just assume kFloat for now."}