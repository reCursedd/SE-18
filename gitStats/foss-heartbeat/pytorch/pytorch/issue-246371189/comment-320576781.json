{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/320576781", "html_url": "https://github.com/pytorch/pytorch/issues/2230#issuecomment-320576781", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2230", "id": 320576781, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDU3Njc4MQ==", "user": {"login": "lanpa", "id": 2005323, "node_id": "MDQ6VXNlcjIwMDUzMjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2005323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lanpa", "html_url": "https://github.com/lanpa", "followers_url": "https://api.github.com/users/lanpa/followers", "following_url": "https://api.github.com/users/lanpa/following{/other_user}", "gists_url": "https://api.github.com/users/lanpa/gists{/gist_id}", "starred_url": "https://api.github.com/users/lanpa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lanpa/subscriptions", "organizations_url": "https://api.github.com/users/lanpa/orgs", "repos_url": "https://api.github.com/users/lanpa/repos", "events_url": "https://api.github.com/users/lanpa/events{/privacy}", "received_events_url": "https://api.github.com/users/lanpa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-07T06:07:32Z", "updated_at": "2017-08-07T06:07:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>oops, it moves to another GPU after TF initialize!<br>\n<a href=\"https://gist.github.com/anonymous/411931230de42bcecd8a9dd535c64e6b\">https://gist.github.com/anonymous/411931230de42bcecd8a9dd535c64e6b</a></p>\n<pre><code>before import tf:\n0 2\nafter import tf:\n0 2\n2017-08-07 14:00:54.239520: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239548: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239557: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239564: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239571: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.341517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-07 14:00:54.341880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 5.60GiB\n2017-08-07 14:00:54.446014: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x2d66880 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2017-08-07 14:00:54.446348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-07 14:00:54.446694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:02:00.0\nTotal memory: 7.92GiB\nFree memory: 5.60GiB\n2017-08-07 14:00:54.447293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 \n2017-08-07 14:00:54.447318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y \n2017-08-07 14:00:54.447325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y \n2017-08-07 14:00:54.447342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n2017-08-07 14:00:54.447355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\nafter init:\n1 2\nafter init (outside session):\n1 2\nTraceback (most recent call last):\n  File \"bug.py\", line 24, in &lt;module&gt;\n    x = model(data)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 65, in replicate\n    return replicate(module, device_ids)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\n    param_copies = Broadcast(devices)(*params)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 18, in forward\n    outputs = comm.broadcast_coalesced(inputs, self.target_gpus)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/cuda/comm.py\", line 52, in broadcast_coalesced\n    raise RuntimeError('all tensors must be on devices[0]')\nRuntimeError: all tensors must be on devices[0]\n</code></pre>", "body_text": "oops, it moves to another GPU after TF initialize!\nhttps://gist.github.com/anonymous/411931230de42bcecd8a9dd535c64e6b\nbefore import tf:\n0 2\nafter import tf:\n0 2\n2017-08-07 14:00:54.239520: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239548: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239557: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239564: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.239571: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-08-07 14:00:54.341517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-07 14:00:54.341880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 5.60GiB\n2017-08-07 14:00:54.446014: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x2d66880 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\n2017-08-07 14:00:54.446348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-07 14:00:54.446694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\npciBusID 0000:02:00.0\nTotal memory: 7.92GiB\nFree memory: 5.60GiB\n2017-08-07 14:00:54.447293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 \n2017-08-07 14:00:54.447318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y \n2017-08-07 14:00:54.447325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y \n2017-08-07 14:00:54.447342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n2017-08-07 14:00:54.447355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\nafter init:\n1 2\nafter init (outside session):\n1 2\nTraceback (most recent call last):\n  File \"bug.py\", line 24, in <module>\n    x = model(data)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 65, in replicate\n    return replicate(module, device_ids)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\n    param_copies = Broadcast(devices)(*params)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 18, in forward\n    outputs = comm.broadcast_coalesced(inputs, self.target_gpus)\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/cuda/comm.py\", line 52, in broadcast_coalesced\n    raise RuntimeError('all tensors must be on devices[0]')\nRuntimeError: all tensors must be on devices[0]", "body": "oops, it moves to another GPU after TF initialize!\r\nhttps://gist.github.com/anonymous/411931230de42bcecd8a9dd535c64e6b\r\n```\r\nbefore import tf:\r\n0 2\r\nafter import tf:\r\n0 2\r\n2017-08-07 14:00:54.239520: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-07 14:00:54.239548: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-07 14:00:54.239557: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-07 14:00:54.239564: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-07 14:00:54.239571: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-07 14:00:54.341517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-08-07 14:00:54.341880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 5.60GiB\r\n2017-08-07 14:00:54.446014: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x2d66880 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2017-08-07 14:00:54.446348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-08-07 14:00:54.446694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:02:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 5.60GiB\r\n2017-08-07 14:00:54.447293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 \r\n2017-08-07 14:00:54.447318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y \r\n2017-08-07 14:00:54.447325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y \r\n2017-08-07 14:00:54.447342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\r\n2017-08-07 14:00:54.447355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\r\nafter init:\r\n1 2\r\nafter init (outside session):\r\n1 2\r\nTraceback (most recent call last):\r\n  File \"bug.py\", line 24, in <module>\r\n    x = model(data)\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\r\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 65, in replicate\r\n    return replicate(module, device_ids)\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\r\n    param_copies = Broadcast(devices)(*params)\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 18, in forward\r\n    outputs = comm.broadcast_coalesced(inputs, self.target_gpus)\r\n  File \"/home/dexter/anaconda3/lib/python3.6/site-packages/torch/cuda/comm.py\", line 52, in broadcast_coalesced\r\n    raise RuntimeError('all tensors must be on devices[0]')\r\nRuntimeError: all tensors must be on devices[0]\r\n```"}