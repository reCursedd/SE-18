{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12337", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12337/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12337/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12337/events", "html_url": "https://github.com/pytorch/pytorch/pull/12337", "id": 366946051, "node_id": "MDExOlB1bGxSZXF1ZXN0MjIwNDk4NDkx", "number": 12337, "title": "[ROCm] topk and sort fixes", "user": {"login": "iotamudelta", "id": 12565466, "node_id": "MDQ6VXNlcjEyNTY1NDY2", "avatar_url": "https://avatars2.githubusercontent.com/u/12565466?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iotamudelta", "html_url": "https://github.com/iotamudelta", "followers_url": "https://api.github.com/users/iotamudelta/followers", "following_url": "https://api.github.com/users/iotamudelta/following{/other_user}", "gists_url": "https://api.github.com/users/iotamudelta/gists{/gist_id}", "starred_url": "https://api.github.com/users/iotamudelta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iotamudelta/subscriptions", "organizations_url": "https://api.github.com/users/iotamudelta/orgs", "repos_url": "https://api.github.com/users/iotamudelta/repos", "events_url": "https://api.github.com/users/iotamudelta/events{/privacy}", "received_events_url": "https://api.github.com/users/iotamudelta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1078897659, "node_id": "MDU6TGFiZWwxMDc4ODk3NjU5", "url": "https://api.github.com/repos/pytorch/pytorch/labels/rocm", "name": "rocm", "color": "499cd1", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-04T19:56:22Z", "updated_at": "2018-11-23T15:52:41Z", "closed_at": "2018-10-09T19:10:16Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/12337", "html_url": "https://github.com/pytorch/pytorch/pull/12337", "diff_url": "https://github.com/pytorch/pytorch/pull/12337.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/12337.patch"}, "body_html": "<ul>\n<li>Topk part 1: fix intrinsincs for 64 wave front (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"189873319\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/224\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/224/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/224\">#224</a>)<br>\n64 in a wave front - intrinsics change.</li>\n<li>Disable in-place sorting on ROCm. (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"190417430\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/237\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/237/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/237\">#237</a>)<br>\nIt is known to hang - use the Thrust fallback<br>\nSkip one test - fails with the fallback.</li>\n<li>Topk fixes (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"190523314\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/239\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/239/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/239\">#239</a>)</li>\n<li>Spec (<a href=\"https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf\" rel=\"nofollow\">https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf</a>) Sec 9.7.1.19 (bfe) and 9.7.1.20 (bfi) requires pos and len to be limited to 0...255</li>\n<li>Spec (<a href=\"https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf\" rel=\"nofollow\">https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf</a>) Sec 9.7.1.19 requires extracted bits to be in LSBs</li>\n<li>Correct logic for getLaneMaskLe. Previous logic would return 0x0 instead of 0xffffffffffffffff for lane 63</li>\n<li>Round up blockDim.x to prevent negative index for smem</li>\n</ul>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9300575\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bddppq\">@bddppq</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a></p>\n<p>Note the one additional skipped test resulting from using the thrust sort fallback for all sizes. We are working on getting bitonic to work properly (and always). Until then, this needs to be skipped on ROCm.</p>", "body_text": "Topk part 1: fix intrinsincs for 64 wave front (#224)\n64 in a wave front - intrinsics change.\nDisable in-place sorting on ROCm. (#237)\nIt is known to hang - use the Thrust fallback\nSkip one test - fails with the fallback.\nTopk fixes (#239)\nSpec (https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf) Sec 9.7.1.19 (bfe) and 9.7.1.20 (bfi) requires pos and len to be limited to 0...255\nSpec (https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf) Sec 9.7.1.19 requires extracted bits to be in LSBs\nCorrect logic for getLaneMaskLe. Previous logic would return 0x0 instead of 0xffffffffffffffff for lane 63\nRound up blockDim.x to prevent negative index for smem\n\n@bddppq @ezyang\nNote the one additional skipped test resulting from using the thrust sort fallback for all sizes. We are working on getting bitonic to work properly (and always). Until then, this needs to be skipped on ROCm.", "body": "* Topk part 1: fix intrinsincs for 64 wave front (#224)\r\n64 in a wave front - intrinsics change.\r\n* Disable in-place sorting on ROCm. (#237)\r\nIt is known to hang - use the Thrust fallback\r\nSkip one test - fails with the fallback.\r\n* Topk fixes (#239)\r\n* Spec (https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf) Sec 9.7.1.19 (bfe) and 9.7.1.20 (bfi) requires pos and len to be limited to 0...255\r\n* Spec (https://docs.nvidia.com/cuda/pdf/ptx_isa_6.3.pdf) Sec 9.7.1.19 requires extracted bits to be in LSBs\r\n* Correct logic for getLaneMaskLe. Previous logic would return 0x0 instead of 0xffffffffffffffff for lane 63\r\n* Round up blockDim.x to prevent negative index for smem\r\n\r\n@bddppq @ezyang \r\n\r\nNote the one additional skipped test resulting from using the thrust sort fallback for all sizes. We are working on getting bitonic to work properly (and always). Until then, this needs to be skipped on ROCm."}