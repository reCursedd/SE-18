{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2573", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2573/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2573/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2573/events", "html_url": "https://github.com/pytorch/pytorch/issues/2573", "id": 253905785, "node_id": "MDU6SXNzdWUyNTM5MDU3ODU=", "number": 2573, "title": "Cannot backpropagate through DataParallel", "user": {"login": "dalegebit", "id": 9109634, "node_id": "MDQ6VXNlcjkxMDk2MzQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/9109634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dalegebit", "html_url": "https://github.com/dalegebit", "followers_url": "https://api.github.com/users/dalegebit/followers", "following_url": "https://api.github.com/users/dalegebit/following{/other_user}", "gists_url": "https://api.github.com/users/dalegebit/gists{/gist_id}", "starred_url": "https://api.github.com/users/dalegebit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dalegebit/subscriptions", "organizations_url": "https://api.github.com/users/dalegebit/orgs", "repos_url": "https://api.github.com/users/dalegebit/repos", "events_url": "https://api.github.com/users/dalegebit/events{/privacy}", "received_events_url": "https://api.github.com/users/dalegebit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-08-30T07:38:16Z", "updated_at": "2017-09-05T21:30:30Z", "closed_at": "2017-09-05T21:30:30Z", "author_association": "NONE", "body_html": "<p>When I run this code:</p>\n<pre><code>l = nn.Linear(5,5).cuda()\npl = nn.DataParallel(l)\na = Variable(torch.rand(5,5), requires_grad=True).cuda()\npl(a).sum().backward()\nprint a.grad\n</code></pre>\n<p>I sometimes get <code>None</code>, while if I let <code>a</code> directly pass through <code>l</code> everything is normal.<br>\nI test this code with Python 2.7.6 and pytorch version 0.2.0.</p>", "body_text": "When I run this code:\nl = nn.Linear(5,5).cuda()\npl = nn.DataParallel(l)\na = Variable(torch.rand(5,5), requires_grad=True).cuda()\npl(a).sum().backward()\nprint a.grad\n\nI sometimes get None, while if I let a directly pass through l everything is normal.\nI test this code with Python 2.7.6 and pytorch version 0.2.0.", "body": "When I run this code:\r\n```\r\nl = nn.Linear(5,5).cuda()\r\npl = nn.DataParallel(l)\r\na = Variable(torch.rand(5,5), requires_grad=True).cuda()\r\npl(a).sum().backward()\r\nprint a.grad\r\n```\r\nI sometimes get `None`, while if I let `a` directly pass through `l` everything is normal. \r\nI test this code with Python 2.7.6 and pytorch version 0.2.0."}