{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7728", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7728/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7728/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7728/events", "html_url": "https://github.com/pytorch/pytorch/issues/7728", "id": 324811659, "node_id": "MDU6SXNzdWUzMjQ4MTE2NTk=", "number": 7728, "title": "Debug compile does not generate `caffe2_pybind11_state_gpu.so`.", "user": {"login": "samson-wang", "id": 5474454, "node_id": "MDQ6VXNlcjU0NzQ0NTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5474454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samson-wang", "html_url": "https://github.com/samson-wang", "followers_url": "https://api.github.com/users/samson-wang/followers", "following_url": "https://api.github.com/users/samson-wang/following{/other_user}", "gists_url": "https://api.github.com/users/samson-wang/gists{/gist_id}", "starred_url": "https://api.github.com/users/samson-wang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samson-wang/subscriptions", "organizations_url": "https://api.github.com/users/samson-wang/orgs", "repos_url": "https://api.github.com/users/samson-wang/repos", "events_url": "https://api.github.com/users/samson-wang/events{/privacy}", "received_events_url": "https://api.github.com/users/samson-wang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 778855555, "node_id": "MDU6TGFiZWw3Nzg4NTU1NTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/build", "name": "build", "color": "bfdadc", "default": false}, {"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": {"login": "pjh5", "id": 6456020, "node_id": "MDQ6VXNlcjY0NTYwMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6456020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pjh5", "html_url": "https://github.com/pjh5", "followers_url": "https://api.github.com/users/pjh5/followers", "following_url": "https://api.github.com/users/pjh5/following{/other_user}", "gists_url": "https://api.github.com/users/pjh5/gists{/gist_id}", "starred_url": "https://api.github.com/users/pjh5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pjh5/subscriptions", "organizations_url": "https://api.github.com/users/pjh5/orgs", "repos_url": "https://api.github.com/users/pjh5/repos", "events_url": "https://api.github.com/users/pjh5/events{/privacy}", "received_events_url": "https://api.github.com/users/pjh5/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pjh5", "id": 6456020, "node_id": "MDQ6VXNlcjY0NTYwMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6456020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pjh5", "html_url": "https://github.com/pjh5", "followers_url": "https://api.github.com/users/pjh5/followers", "following_url": "https://api.github.com/users/pjh5/following{/other_user}", "gists_url": "https://api.github.com/users/pjh5/gists{/gist_id}", "starred_url": "https://api.github.com/users/pjh5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pjh5/subscriptions", "organizations_url": "https://api.github.com/users/pjh5/orgs", "repos_url": "https://api.github.com/users/pjh5/repos", "events_url": "https://api.github.com/users/pjh5/events{/privacy}", "received_events_url": "https://api.github.com/users/pjh5/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-05-21T07:13:43Z", "updated_at": "2018-05-21T17:05:42Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Compile with <code>-DCMAKE_BUILD_TYPE=Debug</code> leads to a <code>no mudle named caffe2_pybind11_state_gpu</code> error.</p>\n<p>Actually, compile in <code>debug</code> mode, a <code>caffe2_pybind11_state_gpud.so</code> was generated instead of <code>caffe2_pybind11_state_gpu.so</code>.</p>\n<pre><code>find . -name caffe2_pybind11_state_gpu*\n./caffe2/CMakeFiles/caffe2_pybind11_state_gpu.dir\n./caffe2/python/caffe2_pybind11_state_gpud.so\n</code></pre>\n<p>However, when compile in default mode, got a <code>core dump</code> using <code>onnx backend</code>.</p>\n<pre><code>import onnx\n\n# Load the ONNX model\nmodel = onnx.load(\"alexnet.proto\")\n\n# Check that the IR is well formed\nonnx.checker.check_model(model)\n\n# Print a human readable representation of the graph\nprint onnx.helper.printable_graph(model.graph)\n\n\nimport caffe2.python.onnx.backend as backend\nimport numpy as np\n\nrep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\nprint \"Loaded rep\"\n# For the Caffe2 backend:\n#     rep.predict_net is the Caffe2 protobuf for the network\n#     rep.workspace is the Caffe2 workspace for the network\n#       (see the class caffe2.python.onnx.backend.Workspace)\noutputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32))\n# To run networks with more than one input, pass a tuple\n# rather than a single numpy ndarray.\nprint(outputs[0])\n</code></pre>\n<p>And the output as following.</p>\n<pre><code>graph torch-jit-export (\n  %actual_input_1[FLOAT, 10x3x224x224]\n) initializers (\n  %learned_0[FLOAT, 64x3x11x11]\n  %learned_1[FLOAT, 64]\n  %learned_2[FLOAT, 192x64x5x5]\n  %learned_3[FLOAT, 192]\n  %learned_4[FLOAT, 384x192x3x3]\n  %learned_5[FLOAT, 384]\n  %learned_6[FLOAT, 256x384x3x3]\n  %learned_7[FLOAT, 256]\n  %learned_8[FLOAT, 256x256x3x3]\n  %learned_9[FLOAT, 256]\n  %learned_10[FLOAT, 4096x9216]\n  %learned_11[FLOAT, 4096]\n  %learned_12[FLOAT, 4096x4096]\n  %learned_13[FLOAT, 4096]\n  %learned_14[FLOAT, 1000x4096]\n  %learned_15[FLOAT, 1000]\n) {\n  %17 = Conv[dilations = [1, 1], group = 1, kernel_shape = [11, 11], pads = [2, 2, 2, 2], strides = [4, 4]](%actual_input_1, %learned_0, %learned_1)\n  %18 = Relu(%17)\n  %19 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%18)\n  %20 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%19, %learned_2, %learned_3)\n  %21 = Relu(%20)\n  %22 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%21)\n  %23 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%22, %learned_4, %learned_5)\n  %24 = Relu(%23)\n  %25 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%24, %learned_6, %learned_7)\n  %26 = Relu(%25)\n  %27 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%26, %learned_8, %learned_9)\n  %28 = Relu(%27)\n  %29 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%28)\n  %30 = Flatten[axis = 1](%29)\n  %31, %32 = Dropout[is_test = 1, ratio = 0.5](%30)\n  %33 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%31, %learned_10, %learned_11)\n  %34 = Relu(%33)\n  %35, %36 = Dropout[is_test = 1, ratio = 0.5](%34)\n  %37 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%35, %learned_12, %learned_13)\n  %38 = Relu(%37)\n  %output1 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%38, %learned_14, %learned_15)\n  return %output1\n}\nSegmentation fault (core dumped)\n</code></pre>", "body_text": "Compile with -DCMAKE_BUILD_TYPE=Debug leads to a no mudle named caffe2_pybind11_state_gpu error.\nActually, compile in debug mode, a caffe2_pybind11_state_gpud.so was generated instead of caffe2_pybind11_state_gpu.so.\nfind . -name caffe2_pybind11_state_gpu*\n./caffe2/CMakeFiles/caffe2_pybind11_state_gpu.dir\n./caffe2/python/caffe2_pybind11_state_gpud.so\n\nHowever, when compile in default mode, got a core dump using onnx backend.\nimport onnx\n\n# Load the ONNX model\nmodel = onnx.load(\"alexnet.proto\")\n\n# Check that the IR is well formed\nonnx.checker.check_model(model)\n\n# Print a human readable representation of the graph\nprint onnx.helper.printable_graph(model.graph)\n\n\nimport caffe2.python.onnx.backend as backend\nimport numpy as np\n\nrep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\nprint \"Loaded rep\"\n# For the Caffe2 backend:\n#     rep.predict_net is the Caffe2 protobuf for the network\n#     rep.workspace is the Caffe2 workspace for the network\n#       (see the class caffe2.python.onnx.backend.Workspace)\noutputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32))\n# To run networks with more than one input, pass a tuple\n# rather than a single numpy ndarray.\nprint(outputs[0])\n\nAnd the output as following.\ngraph torch-jit-export (\n  %actual_input_1[FLOAT, 10x3x224x224]\n) initializers (\n  %learned_0[FLOAT, 64x3x11x11]\n  %learned_1[FLOAT, 64]\n  %learned_2[FLOAT, 192x64x5x5]\n  %learned_3[FLOAT, 192]\n  %learned_4[FLOAT, 384x192x3x3]\n  %learned_5[FLOAT, 384]\n  %learned_6[FLOAT, 256x384x3x3]\n  %learned_7[FLOAT, 256]\n  %learned_8[FLOAT, 256x256x3x3]\n  %learned_9[FLOAT, 256]\n  %learned_10[FLOAT, 4096x9216]\n  %learned_11[FLOAT, 4096]\n  %learned_12[FLOAT, 4096x4096]\n  %learned_13[FLOAT, 4096]\n  %learned_14[FLOAT, 1000x4096]\n  %learned_15[FLOAT, 1000]\n) {\n  %17 = Conv[dilations = [1, 1], group = 1, kernel_shape = [11, 11], pads = [2, 2, 2, 2], strides = [4, 4]](%actual_input_1, %learned_0, %learned_1)\n  %18 = Relu(%17)\n  %19 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%18)\n  %20 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%19, %learned_2, %learned_3)\n  %21 = Relu(%20)\n  %22 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%21)\n  %23 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%22, %learned_4, %learned_5)\n  %24 = Relu(%23)\n  %25 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%24, %learned_6, %learned_7)\n  %26 = Relu(%25)\n  %27 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%26, %learned_8, %learned_9)\n  %28 = Relu(%27)\n  %29 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%28)\n  %30 = Flatten[axis = 1](%29)\n  %31, %32 = Dropout[is_test = 1, ratio = 0.5](%30)\n  %33 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%31, %learned_10, %learned_11)\n  %34 = Relu(%33)\n  %35, %36 = Dropout[is_test = 1, ratio = 0.5](%34)\n  %37 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%35, %learned_12, %learned_13)\n  %38 = Relu(%37)\n  %output1 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%38, %learned_14, %learned_15)\n  return %output1\n}\nSegmentation fault (core dumped)", "body": "\r\n\r\nCompile with `-DCMAKE_BUILD_TYPE=Debug` leads to a `no mudle named caffe2_pybind11_state_gpu` error.\r\n\r\nActually, compile in `debug` mode, a `caffe2_pybind11_state_gpud.so` was generated instead of `caffe2_pybind11_state_gpu.so`.  \r\n\r\n```\r\nfind . -name caffe2_pybind11_state_gpu*\r\n./caffe2/CMakeFiles/caffe2_pybind11_state_gpu.dir\r\n./caffe2/python/caffe2_pybind11_state_gpud.so\r\n```\r\nHowever, when compile in default mode, got a `core dump` using `onnx backend`.\r\n\r\n```\r\nimport onnx\r\n\r\n# Load the ONNX model\r\nmodel = onnx.load(\"alexnet.proto\")\r\n\r\n# Check that the IR is well formed\r\nonnx.checker.check_model(model)\r\n\r\n# Print a human readable representation of the graph\r\nprint onnx.helper.printable_graph(model.graph)\r\n\r\n\r\nimport caffe2.python.onnx.backend as backend\r\nimport numpy as np\r\n\r\nrep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\r\nprint \"Loaded rep\"\r\n# For the Caffe2 backend:\r\n#     rep.predict_net is the Caffe2 protobuf for the network\r\n#     rep.workspace is the Caffe2 workspace for the network\r\n#       (see the class caffe2.python.onnx.backend.Workspace)\r\noutputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32))\r\n# To run networks with more than one input, pass a tuple\r\n# rather than a single numpy ndarray.\r\nprint(outputs[0])\r\n```\r\n\r\nAnd the output as following.\r\n```\r\ngraph torch-jit-export (\r\n  %actual_input_1[FLOAT, 10x3x224x224]\r\n) initializers (\r\n  %learned_0[FLOAT, 64x3x11x11]\r\n  %learned_1[FLOAT, 64]\r\n  %learned_2[FLOAT, 192x64x5x5]\r\n  %learned_3[FLOAT, 192]\r\n  %learned_4[FLOAT, 384x192x3x3]\r\n  %learned_5[FLOAT, 384]\r\n  %learned_6[FLOAT, 256x384x3x3]\r\n  %learned_7[FLOAT, 256]\r\n  %learned_8[FLOAT, 256x256x3x3]\r\n  %learned_9[FLOAT, 256]\r\n  %learned_10[FLOAT, 4096x9216]\r\n  %learned_11[FLOAT, 4096]\r\n  %learned_12[FLOAT, 4096x4096]\r\n  %learned_13[FLOAT, 4096]\r\n  %learned_14[FLOAT, 1000x4096]\r\n  %learned_15[FLOAT, 1000]\r\n) {\r\n  %17 = Conv[dilations = [1, 1], group = 1, kernel_shape = [11, 11], pads = [2, 2, 2, 2], strides = [4, 4]](%actual_input_1, %learned_0, %learned_1)\r\n  %18 = Relu(%17)\r\n  %19 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%18)\r\n  %20 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%19, %learned_2, %learned_3)\r\n  %21 = Relu(%20)\r\n  %22 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%21)\r\n  %23 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%22, %learned_4, %learned_5)\r\n  %24 = Relu(%23)\r\n  %25 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%24, %learned_6, %learned_7)\r\n  %26 = Relu(%25)\r\n  %27 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%26, %learned_8, %learned_9)\r\n  %28 = Relu(%27)\r\n  %29 = MaxPool[kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%28)\r\n  %30 = Flatten[axis = 1](%29)\r\n  %31, %32 = Dropout[is_test = 1, ratio = 0.5](%30)\r\n  %33 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%31, %learned_10, %learned_11)\r\n  %34 = Relu(%33)\r\n  %35, %36 = Dropout[is_test = 1, ratio = 0.5](%34)\r\n  %37 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%35, %learned_12, %learned_13)\r\n  %38 = Relu(%37)\r\n  %output1 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%38, %learned_14, %learned_15)\r\n  return %output1\r\n}\r\nSegmentation fault (core dumped)\r\n```"}