{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/373733597", "html_url": "https://github.com/pytorch/pytorch/issues/5812#issuecomment-373733597", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5812", "id": 373733597, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzczMzU5Nw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-16T14:39:41Z", "updated_at": "2018-03-16T14:39:41Z", "author_association": "MEMBER", "body_html": "<p>Also the value you're seeing in <code>nvidia-smi</code> is not the amount of memory <em>used</em> by PyTorch tensors at any given moment. PyTorch almost never frees the GPU memory because it's expensive and you can often reuse older allocations. As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> you can use <code>empty_cache()</code> to get rid of the excessive use after every epoch if this is important for some reason.</p>", "body_text": "Also the value you're seeing in nvidia-smi is not the amount of memory used by PyTorch tensors at any given moment. PyTorch almost never frees the GPU memory because it's expensive and you can often reuse older allocations. As @fmassa you can use empty_cache() to get rid of the excessive use after every epoch if this is important for some reason.", "body": "Also the value you're seeing in `nvidia-smi` is not the amount of memory *used* by PyTorch tensors at any given moment. PyTorch almost never frees the GPU memory because it's expensive and you can often reuse older allocations. As @fmassa you can use `empty_cache()` to get rid of the excessive use after every epoch if this is important for some reason."}