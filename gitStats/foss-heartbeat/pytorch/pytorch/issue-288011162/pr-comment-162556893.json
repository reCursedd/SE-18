{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162556893", "pull_request_review_id": 90033227, "id": 162556893, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MjU1Njg5Mw==", "diff_hunk": "@@ -1178,6 +1178,47 @@ def local_response_norm(input, size, alpha=1e-4, beta=0.75, k=1):\n     return input / div\n \n \n+def instance_norm_wrapper(input, weight, bias, saved_running_mean, saved_running_var,\n+                          training=False, momentum=0.1, eps=1e-5, affine=False):\n+    \"\"\"This wrapper is for ONNX exporting.\n+    In PyTorch, InstanceNorm is implemented using BatchNorm. However it is not a good idea to export\n+    InstanceNorm as a combination of Reshapes and BatchNorm to ONNX, since Reshapes may not be cheap\n+    in other frameworks, plus we don't want to lose high-level information during exporting. So here\n+    we apply the same trick/hack as we did for RNN. This trick requires that the symbolic function\n+    and the real implementation must have exactly the same signatures.\n+    \"\"\"\n+    import torch\n+    func = instance_norm\n+    if torch._C._jit_is_tracing(input):", "path": "torch/nn/functional.py", "position": null, "original_position": 15, "commit_id": "6f870f5c329e3e94c9f6b743a0ef40ed56e61b02", "original_commit_id": "579be4111110225e2196b843237ead8937e68f01", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "in general symblic_override does invoke inside of it a check on _jit_is_tracing. I think the only problem is that it checks all args and Adam was complaining that flattening is not perf-cheap.\r\n\r\nMaybe modify symbolic_override to look only at the first argument (if it's a tensor), or have symbolic_override_based_on_first? Then this whole function can be a simple decorator on `instance_norm` function and would look much nicer", "created_at": "2018-01-19T08:04:49Z", "updated_at": "2018-11-23T15:38:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/4626#discussion_r162556893", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4626", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162556893"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4626#discussion_r162556893"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4626"}}, "body_html": "<p>in general symblic_override does invoke inside of it a check on _jit_is_tracing. I think the only problem is that it checks all args and Adam was complaining that flattening is not perf-cheap.</p>\n<p>Maybe modify symbolic_override to look only at the first argument (if it's a tensor), or have symbolic_override_based_on_first? Then this whole function can be a simple decorator on <code>instance_norm</code> function and would look much nicer</p>", "body_text": "in general symblic_override does invoke inside of it a check on _jit_is_tracing. I think the only problem is that it checks all args and Adam was complaining that flattening is not perf-cheap.\nMaybe modify symbolic_override to look only at the first argument (if it's a tensor), or have symbolic_override_based_on_first? Then this whole function can be a simple decorator on instance_norm function and would look much nicer"}