{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2996", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2996/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2996/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2996/events", "html_url": "https://github.com/pytorch/pytorch/issues/2996", "id": 263288444, "node_id": "MDU6SXNzdWUyNjMyODg0NDQ=", "number": 2996, "title": "Conv3d and AvgPool3d interactions yield errors in CUDA mode only", "user": {"login": "samthrasher", "id": 13754673, "node_id": "MDQ6VXNlcjEzNzU0Njcz", "avatar_url": "https://avatars0.githubusercontent.com/u/13754673?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samthrasher", "html_url": "https://github.com/samthrasher", "followers_url": "https://api.github.com/users/samthrasher/followers", "following_url": "https://api.github.com/users/samthrasher/following{/other_user}", "gists_url": "https://api.github.com/users/samthrasher/gists{/gist_id}", "starred_url": "https://api.github.com/users/samthrasher/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samthrasher/subscriptions", "organizations_url": "https://api.github.com/users/samthrasher/orgs", "repos_url": "https://api.github.com/users/samthrasher/repos", "events_url": "https://api.github.com/users/samthrasher/events{/privacy}", "received_events_url": "https://api.github.com/users/samthrasher/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-05T22:39:59Z", "updated_at": "2017-10-07T04:40:51Z", "closed_at": "2017-10-07T04:40:51Z", "author_association": "NONE", "body_html": "<p>The network below runs successfully on CPU, but throws a <code>RuntimeError: Can only downcast contiguous tensors</code> when backpropagating through the <code>AvgPool3d</code> layer on CUDA. If either the initial or final <code>Conv3d</code> layers are removed, the network runs successfully.</p>\n<p>I am using pytorch 0.2.0 on python 3.5 with CUDA 8.0 from the pip binary, on ubuntu 16.04.</p>\n<p>(ref: <a href=\"https://discuss.pytorch.org/t/conv3d-and-avgpool3d-interactions-yield-errors-in-cuda-mode-only/8348\" rel=\"nofollow\">https://discuss.pytorch.org/t/conv3d-and-avgpool3d-interactions-yield-errors-in-cuda-mode-only/8348</a>)</p>\n<pre><code>import torch\nfrom torch import nn\nfrom torch.autograd import Variable\n\nclass ConvBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.net = nn.Conv3d(in_channels=in_channels, out_channels=out_channels,\n                             kernel_size=(3, 5, 5), stride=(3, 3, 3),\n                             padding=(1, 0, 0), bias=False)\n\n    def forward(self, x):\n        return self.net(x)\n\nclass DepthConcatBlock(nn.Module):\n\n    def __init__(self, channels):\n        super(DepthConcatBlock, self).__init__()\n        self.branch1 = nn.Conv3d(in_channels=channels, out_channels=channels,\n                                kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=0)\n\n        self.branch2 = nn.AvgPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2))\n\n    def forward(self, x):\n        return torch.cat([self.branch1(x), self.branch2(x)], dim=1)\n\n\nnet = nn.Sequential(\n    ConvBlock(3, 3),\n    DepthConcatBlock(3),\n    ConvBlock(6, 6)\n    )\n\nnet = net.cuda()\nx = Variable(torch.randn([1, 3, 75, 288, 360])).cuda()\ny = net(x)\nl = torch.sum(y)\nl.backward()\n</code></pre>\n<pre><code>Traceback (most recent call last):\n  File \"debug.py\", line 39, in &lt;module&gt;\n    l.backward()\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\", line 156, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\", line 98, in backward\n    variables, grad_variables, retain_graph)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\", line 91, in apply\n    return self._forward_cls.backward(self, *args)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 419, in backward\n    grad_input = AvgPool3dBackward.apply(input, grad_output, ctx.kernel_size, ctx.stride)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 435, in forward\n    ctx.stride[0], ctx.stride[2], ctx.stride[1])\nRuntimeError: Can only downcast contiguous tensors at /pytorch/torch/lib/tmp_install/include/THC/THCDeviceTensor-inl.cuh:295\n</code></pre>", "body_text": "The network below runs successfully on CPU, but throws a RuntimeError: Can only downcast contiguous tensors when backpropagating through the AvgPool3d layer on CUDA. If either the initial or final Conv3d layers are removed, the network runs successfully.\nI am using pytorch 0.2.0 on python 3.5 with CUDA 8.0 from the pip binary, on ubuntu 16.04.\n(ref: https://discuss.pytorch.org/t/conv3d-and-avgpool3d-interactions-yield-errors-in-cuda-mode-only/8348)\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\n\nclass ConvBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.net = nn.Conv3d(in_channels=in_channels, out_channels=out_channels,\n                             kernel_size=(3, 5, 5), stride=(3, 3, 3),\n                             padding=(1, 0, 0), bias=False)\n\n    def forward(self, x):\n        return self.net(x)\n\nclass DepthConcatBlock(nn.Module):\n\n    def __init__(self, channels):\n        super(DepthConcatBlock, self).__init__()\n        self.branch1 = nn.Conv3d(in_channels=channels, out_channels=channels,\n                                kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=0)\n\n        self.branch2 = nn.AvgPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2))\n\n    def forward(self, x):\n        return torch.cat([self.branch1(x), self.branch2(x)], dim=1)\n\n\nnet = nn.Sequential(\n    ConvBlock(3, 3),\n    DepthConcatBlock(3),\n    ConvBlock(6, 6)\n    )\n\nnet = net.cuda()\nx = Variable(torch.randn([1, 3, 75, 288, 360])).cuda()\ny = net(x)\nl = torch.sum(y)\nl.backward()\n\nTraceback (most recent call last):\n  File \"debug.py\", line 39, in <module>\n    l.backward()\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\", line 156, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\", line 98, in backward\n    variables, grad_variables, retain_graph)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\", line 91, in apply\n    return self._forward_cls.backward(self, *args)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 419, in backward\n    grad_input = AvgPool3dBackward.apply(input, grad_output, ctx.kernel_size, ctx.stride)\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 435, in forward\n    ctx.stride[0], ctx.stride[2], ctx.stride[1])\nRuntimeError: Can only downcast contiguous tensors at /pytorch/torch/lib/tmp_install/include/THC/THCDeviceTensor-inl.cuh:295", "body": "The network below runs successfully on CPU, but throws a `RuntimeError: Can only downcast contiguous tensors` when backpropagating through the `AvgPool3d` layer on CUDA. If either the initial or final `Conv3d` layers are removed, the network runs successfully. \r\n\r\nI am using pytorch 0.2.0 on python 3.5 with CUDA 8.0 from the pip binary, on ubuntu 16.04. \r\n\r\n(ref: https://discuss.pytorch.org/t/conv3d-and-avgpool3d-interactions-yield-errors-in-cuda-mode-only/8348)\r\n```\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.autograd import Variable\r\n\r\nclass ConvBlock(nn.Module):\r\n\r\n    def __init__(self, in_channels, out_channels):\r\n        super(ConvBlock, self).__init__()\r\n        self.net = nn.Conv3d(in_channels=in_channels, out_channels=out_channels,\r\n                             kernel_size=(3, 5, 5), stride=(3, 3, 3),\r\n                             padding=(1, 0, 0), bias=False)\r\n\r\n    def forward(self, x):\r\n        return self.net(x)\r\n\r\nclass DepthConcatBlock(nn.Module):\r\n\r\n    def __init__(self, channels):\r\n        super(DepthConcatBlock, self).__init__()\r\n        self.branch1 = nn.Conv3d(in_channels=channels, out_channels=channels,\r\n                                kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=0)\r\n\r\n        self.branch2 = nn.AvgPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2))\r\n\r\n    def forward(self, x):\r\n        return torch.cat([self.branch1(x), self.branch2(x)], dim=1)\r\n\r\n\r\nnet = nn.Sequential(\r\n    ConvBlock(3, 3),\r\n    DepthConcatBlock(3),\r\n    ConvBlock(6, 6)\r\n    )\r\n\r\nnet = net.cuda()\r\nx = Variable(torch.randn([1, 3, 75, 288, 360])).cuda()\r\ny = net(x)\r\nl = torch.sum(y)\r\nl.backward()\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"debug.py\", line 39, in <module>\r\n    l.backward()\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\", line 156, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\", line 98, in backward\r\n    variables, grad_variables, retain_graph)\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\", line 91, in apply\r\n    return self._forward_cls.backward(self, *args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 419, in backward\r\n    grad_input = AvgPool3dBackward.apply(input, grad_output, ctx.kernel_size, ctx.stride)\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/pooling.py\", line 435, in forward\r\n    ctx.stride[0], ctx.stride[2], ctx.stride[1])\r\nRuntimeError: Can only downcast contiguous tensors at /pytorch/torch/lib/tmp_install/include/THC/THCDeviceTensor-inl.cuh:295\r\n```"}