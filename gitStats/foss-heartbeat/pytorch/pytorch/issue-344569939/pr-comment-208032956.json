{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208032956", "pull_request_review_id": 143764837, "id": 208032956, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwODAzMjk1Ng==", "diff_hunk": "@@ -61,7 +61,7 @@ fi\n WERROR=1 python setup.py install\n \n # Add the test binaries so that they won't be git clean'ed away\n-git add -f build/bin\n+git add -f build/bin build/lib", "path": ".jenkins/pytorch/build.sh", "position": 5, "original_position": 5, "commit_id": "3e8b76d1dd11c1d6eb4746862aef677be22e8540", "original_commit_id": "3e8b76d1dd11c1d6eb4746862aef677be22e8540", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "> It maintains the behavior from before this diff that the tests are run out of their build directory\r\n\r\nBut no one actually cares about that. The actual functional requirements are:\r\n\r\n1. The tests in CI need to find the libraries, somehow. (E.g., you could just use `LD_LIBRARY_PATH` to fix the path situation)\r\n2. When I, a random developer, run tests from the build directory, they ought to work (without me having to `LD_LIBRARY_PATH` explicitly)\r\n3. We should not be shipping multiple copies of the same libraries and binaries in the Docker image when we push from CPU to GPU. (But if you want to show that this doesn't actually make a difference, e.g., in time to push, then we can drop this requirement.)", "created_at": "2018-08-06T21:19:59Z", "updated_at": "2018-11-23T15:48:50Z", "html_url": "https://github.com/pytorch/pytorch/pull/9836#discussion_r208032956", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9836", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208032956"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9836#discussion_r208032956"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9836"}}, "body_html": "<blockquote>\n<p>It maintains the behavior from before this diff that the tests are run out of their build directory</p>\n</blockquote>\n<p>But no one actually cares about that. The actual functional requirements are:</p>\n<ol>\n<li>The tests in CI need to find the libraries, somehow. (E.g., you could just use <code>LD_LIBRARY_PATH</code> to fix the path situation)</li>\n<li>When I, a random developer, run tests from the build directory, they ought to work (without me having to <code>LD_LIBRARY_PATH</code> explicitly)</li>\n<li>We should not be shipping multiple copies of the same libraries and binaries in the Docker image when we push from CPU to GPU. (But if you want to show that this doesn't actually make a difference, e.g., in time to push, then we can drop this requirement.)</li>\n</ol>", "body_text": "It maintains the behavior from before this diff that the tests are run out of their build directory\n\nBut no one actually cares about that. The actual functional requirements are:\n\nThe tests in CI need to find the libraries, somehow. (E.g., you could just use LD_LIBRARY_PATH to fix the path situation)\nWhen I, a random developer, run tests from the build directory, they ought to work (without me having to LD_LIBRARY_PATH explicitly)\nWe should not be shipping multiple copies of the same libraries and binaries in the Docker image when we push from CPU to GPU. (But if you want to show that this doesn't actually make a difference, e.g., in time to push, then we can drop this requirement.)", "in_reply_to_id": 207371914}