{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/158877275", "pull_request_review_id": 85741245, "id": 158877275, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1ODg3NzI3NQ==", "diff_hunk": "@@ -0,0 +1,174 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/Check.h\"\n+#include \"ATen/NativeFunctions.h\"\n+\n+#include <cstring>\n+#include <memory>\n+#include <sstream>\n+#include <vector>\n+\n+#ifdef _OPENMP\n+#include <omp.h>\n+#endif\n+\n+\n+namespace at { namespace native {\n+\n+Tensor embedding(const Tensor & weight, const Tensor & indices,\n+                 int64_t padding_idx, bool scale_grad_by_freq, bool sparse) {\n+  auto indices_arg = TensorArg(indices, \"indices\", 1);\n+  checkScalarType(\"embedding\", indices_arg, kLong);\n+  checkContiguous(\"embedding\", indices_arg);\n+\n+  // TODO: use tensor.index() after improving perf\n+  if (indices.dim() == 1) {\n+    return weight.index_select(0, indices);\n+  }\n+\n+  auto size = std::vector<int64_t>(indices.sizes());\n+  for (auto d : weight.sizes().slice(1)) {\n+    size.push_back(d);\n+  }\n+  return weight.index_select(0, indices.view(-1)).view(size);\n+}\n+\n+Tensor embedding_backward(\n+    const Tensor & grad, const Tensor & indices, int64_t num_weights,\n+    int64_t padding_idx, bool scale_grad_by_freq, bool sparse) {\n+\n+  if (sparse) {\n+    return at::embedding_sparse_backward(\n+        grad, indices, num_weights, padding_idx, scale_grad_by_freq);\n+  } else {\n+    return at::embedding_dense_backward(\n+        grad, indices, num_weights, padding_idx, scale_grad_by_freq);\n+  }\n+}\n+\n+Tensor embedding_sparse_backward(\n+    const Tensor & grad_, const Tensor & indices_, int64_t num_weights,\n+    int64_t padding_idx, bool scale_grad_by_freq) {\n+\n+  auto indices_arg = TensorArg(indices_, \"indices\", 2);\n+  checkScalarType(\"embedding_backward\", indices_arg, kLong);\n+  checkContiguous(\"embedding_backward\", indices_arg);\n+\n+  // TODO: implement scale_grad_by_freq\n+  if (scale_grad_by_freq) {\n+    runtime_error(\"embedding_backward: scale_grad_by_freq not supported with sparse gradients\");\n+  }\n+\n+  Tensor indices = indices_;\n+  Tensor grad = grad_;\n+  if (padding_idx != -1) {\n+    auto c = indices != padding_idx;\n+    indices = indices.index(c);\n+    grad = grad.index(c);\n+  }\n+\n+  auto index = indices.view({1, -1});\n+  auto values = grad.contiguous().view({-1, grad.size(1)});\n+\n+  auto& sparse_type = grad.type().toBackend(grad.is_cuda() ? kSparseCUDA : kSparseCPU);\n+  return sparse_type.sparse_coo_tensor(index, values);\n+}\n+\n+Tensor embedding_backward_cpu(\n+    const Tensor & grad_, const Tensor & indices, int64_t num_weights,\n+    int64_t padding_idx, bool scale_grad_by_freq) {\n+\n+  auto indices_arg = TensorArg(indices, \"indices\", 2);\n+  checkScalarType(\"embedding_backward\", indices_arg, kLong);\n+  checkContiguous(\"embedding_backward\", indices_arg);\n+\n+  auto indices_data = indices.data<int64_t>();\n+  int64_t numel = indices.numel();\n+", "path": "aten/src/ATen/native/Embedding.cpp", "position": 86, "original_position": 86, "commit_id": "8dab6c62f8e579ea93f407aeeafc57bedfb0ca37", "original_commit_id": "68e748279abc32d650a527282223faf2b703e3f5", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "do you want to check that indices are in the valid range?  We currently do on CPU at least.", "created_at": "2017-12-27T22:50:06Z", "updated_at": "2018-11-23T15:37:40Z", "html_url": "https://github.com/pytorch/pytorch/pull/4322#discussion_r158877275", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4322", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/158877275"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4322#discussion_r158877275"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4322"}}, "body_html": "<p>do you want to check that indices are in the valid range?  We currently do on CPU at least.</p>", "body_text": "do you want to check that indices are in the valid range?  We currently do on CPU at least."}