{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159342362", "pull_request_review_id": 86275404, "id": 159342362, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTM0MjM2Mg==", "diff_hunk": "@@ -0,0 +1,348 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/Check.h\"\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/NativeFunctions.h\"\n+\n+#include \"ATen/cuda/AccumulateType.h\"\n+\n+#include <THC/THCDeviceUtils.cuh>\n+#include <THC/THCNumerics.cuh>\n+#include <THC/THCTensorMathReduce.cuh>\n+#include <THC/THCTensorSort.cuh>\n+#include <THC/THCThrustAllocator.cuh>\n+#include <THCUNN/THCHalfAutoNumerics.cuh>\n+\n+#include <thrust/execution_policy.h>\n+#include <thrust/unique.h>\n+\n+\n+namespace at { namespace native {\n+\n+namespace {\n+\n+static const int WARP_SIZE = 32;\n+\n+__device__ __forceinline__ bool warp_has_collision(int val) {\n+  // Compare our value to the values stored in the next 16 lanes,\n+  // wrapping around at 32. If any pair of values is the same than\n+  // there is a collision in the warp.\n+  bool dup = 0;\n+  const int laneId = threadIdx.x % 32;\n+  #pragma unroll\n+  for (int i = 1; i <= 16; i++) {\n+    dup |= (WARP_SHFL(val, (laneId + i) % 32) == val);\n+  }\n+  return __any(dup) != 0;\n+}\n+\n+// parallelizes over features\n+template <typename scalar_t>\n+__global__ void embedding_backward_feature_kernel(\n+  int64_t* indices, scalar_t* grad, scalar_t* grad_weight,\n+  int64_t num_indices, int64_t stride, int padding_idx) {\n+\n+  const int feature_dim = blockIdx.x * 4 + threadIdx.x / 32;\n+  if (feature_dim >= stride) {\n+    return;\n+  }\n+\n+  // The strategy here is that each warp handles a single feature\n+  // dimension.\n+  // Within that feature dimension, points in the [batch][element]\n+  // dimension can overlap, and we need to determine if threads want\n+  // to add to the gradient in a colliding manner.\n+  // Typically one would use floating-point atomicAdd() to resolve\n+  // these collisions, but that is non-deterministic if there are\n+  // collisions. Non-determinism for this code is really bad,\n+  // especially in RNNs, and is prone to snowballing error.\n+  // In order to get a deterministic order of execution, we handle\n+  // non-colliding updates separately from colliding ones. Colliding\n+  // updates are serialized in their order of execution by using the\n+  // warp-wide collision detector `warp_has_collision`.\n+  const int laneId = threadIdx.x % 32;\n+  for (int64_t i = laneId; i < num_indices; i += WARP_SIZE) {\n+    const int weight_index = (int)indices[i];\n+    if (weight_index == padding_idx) {\n+      continue;\n+    }\n+\n+    auto value = grad[i * stride + feature_dim];\n+\n+    // FIXME: should we accumulate as accreal?\n+    // Check for collision\n+    if (warp_has_collision(weight_index)) {\n+      // Run all lanes sequentially; warp divergence\n+      for (int i = 0; i < WARP_SIZE; ++i) {\n+        if (laneId == i) {\n+          grad_weight[weight_index * stride + feature_dim] += value;\n+        }\n+      }\n+    } else {\n+      // No collision; warp coherence\n+      grad_weight[weight_index * stride + feature_dim] += value;\n+    }\n+  }\n+}\n+\n+\n+template <typename scalar_t>\n+__global__ void embedding_backward_kernel(\n+  int64_t* input, int64_t* indices, scalar_t* grad_output, scalar_t* grad_weight,\n+  int64_t* count, int64_t numel, int64_t stride, int padding_idx) {\n+\n+  using accscalar_t = cuda::acc_type<scalar_t>;\n+  int idx = blockIdx.x * 4 + threadIdx.y;\n+\n+  // Each warp is responsible for an input into the LookupTable.\n+  // If the preceding input has the same as this input, then the warp\n+  // exits immediately. The warp also processes subsequent inputs with the\n+  // same value.\n+  //\n+  // Input Warp\n+  // 1     <warp 1>\n+  // 1     <warp 1> (<warp 2> exits without doing any work)\n+  // 5     <warp 3>\n+  // 8     <warp 4>\n+\n+  // Number of values proceessed by each thread (grain size)\n+  const int SZ = 4;\n+\n+  if (idx < numel\n+      && (idx == 0 || input[idx] != input[idx - 1])\n+      && input[idx] != padding_idx) {\n+    do {\n+      const int start_feature = threadIdx.x + blockIdx.y * blockDim.x * SZ;\n+      const int weight_row = ((int) input[idx]) * stride;\n+      const int grad_row = ((int) indices[idx]) * stride;\n+      const accscalar_t scale = count ? (accscalar_t)1.0 / count[idx] : 1.0;\n+\n+      accscalar_t gradient[SZ];\n+      accscalar_t weight[SZ];\n+\n+      #pragma unroll\n+      for (int ii = 0; ii < SZ; ii++) {\n+        int feature_dim = start_feature + ii * WARP_SIZE;\n+        if (feature_dim < stride) {\n+          gradient[ii] = scalar_cast<accscalar_t>(grad_output[grad_row + feature_dim]);\n+          weight[ii] = scalar_cast<accscalar_t>(grad_weight[weight_row + feature_dim]);\n+        }\n+      }\n+\n+      #pragma unroll\n+      for (int ii = 0; ii < SZ; ii++) {\n+        weight[ii] += gradient[ii] * scale;\n+      }\n+\n+      #pragma unroll\n+      for (int ii = 0; ii < SZ; ii++) {\n+        int feature_dim = start_feature + ii * WARP_SIZE;\n+        if (feature_dim < stride) {\n+            grad_weight[weight_row + feature_dim] = scalar_cast<scalar_t>(weight[ii]);\n+        }\n+      }\n+\n+      idx++;\n+    } while (idx < numel && input[idx] == input[idx - 1]);\n+  }\n+}\n+\n+/* Calculate norms of the rows of weight_ptr given by idx_ptr and capture them in norms */\n+template <typename scalar_t, typename accscalar_t>\n+__global__ void renorm_kernel(\n+    scalar_t* weights, int64_t* indices, accscalar_t max_norm,\n+    accscalar_t norm_type, int dim) {\n+\n+  // Some casting hacks since dynamic shared memory and templates don't work together:\n+  extern __shared__ unsigned char smem[];\n+  auto sdata = reinterpret_cast<accscalar_t*>(smem);\n+\n+  int tid = threadIdx.x;\n+  int base_index = indices[blockIdx.x] * dim;\n+\n+  accscalar_t v = 0;\n+  for (int i = tid; i < dim; i += blockDim.x) {\n+    auto x = scalar_cast<accscalar_t>(weights[base_index + i]);\n+    if (norm_type == 1) {\n+      v += std::abs(x);\n+    } else if (norm_type == 2) {\n+      v += x * x;\n+    } else {\n+      v += std::pow(x, norm_type);\n+    }\n+  }\n+\n+  using Op = ReduceAdd<accscalar_t, accscalar_t>;\n+  v = reduceBlock<accscalar_t>(sdata, blockDim.x, v, Op(), 0);\n+\n+  if (tid == 0) {\n+    sdata[0] = std::pow(v, 1.0 / scalar_cast<accscalar_t>(norm_type));", "path": "aten/src/ATen/native/cuda/Embedding.cu", "position": 178, "original_position": 178, "commit_id": "8dab6c62f8e579ea93f407aeeafc57bedfb0ca37", "original_commit_id": "8dab6c62f8e579ea93f407aeeafc57bedfb0ca37", "user": {"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}, "body": "MSVC seems to complain about the following:\r\n```\r\nerror: calling a __host__ function(\"pow<float, double, void> \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel<float, float> \") is not allowed\r\nerror: identifier \"pow<float, double, void> \" is undefined in device code\r\nerror: calling a __host__ function(\"pow<float, double, void> \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel< ::__half, float> \") is not allowed\r\nerror: identifier \"pow<float, double, void> \" is undefined in device code\r\n```\r\n\r\nEDITED: \r\nfigured out what the issue is: for the second arg in `std::pow` we should use `scalar_cast<accscalar_t>(1.0 / norm_type)` instead\r\n  ", "created_at": "2018-01-03T00:01:39Z", "updated_at": "2018-11-23T15:37:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/4322#discussion_r159342362", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4322", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159342362"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4322#discussion_r159342362"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4322"}}, "body_html": "<p>MSVC seems to complain about the following:</p>\n<pre><code>error: calling a __host__ function(\"pow&lt;float, double, void&gt; \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel&lt;float, float&gt; \") is not allowed\nerror: identifier \"pow&lt;float, double, void&gt; \" is undefined in device code\nerror: calling a __host__ function(\"pow&lt;float, double, void&gt; \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel&lt; ::__half, float&gt; \") is not allowed\nerror: identifier \"pow&lt;float, double, void&gt; \" is undefined in device code\n</code></pre>\n<p>EDITED:<br>\nfigured out what the issue is: for the second arg in <code>std::pow</code> we should use <code>scalar_cast&lt;accscalar_t&gt;(1.0 / norm_type)</code> instead</p>", "body_text": "MSVC seems to complain about the following:\nerror: calling a __host__ function(\"pow<float, double, void> \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel<float, float> \") is not allowed\nerror: identifier \"pow<float, double, void> \" is undefined in device code\nerror: calling a __host__ function(\"pow<float, double, void> \") from a __global__ function(\"at::native::_NV_ANON_NAMESPACE::renorm_kernel< ::__half, float> \") is not allowed\nerror: identifier \"pow<float, double, void> \" is undefined in device code\n\nEDITED:\nfigured out what the issue is: for the second arg in std::pow we should use scalar_cast<accscalar_t>(1.0 / norm_type) instead"}