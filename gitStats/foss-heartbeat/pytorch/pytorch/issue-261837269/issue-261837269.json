{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2912", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2912/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2912/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2912/events", "html_url": "https://github.com/pytorch/pytorch/issues/2912", "id": 261837269, "node_id": "MDU6SXNzdWUyNjE4MzcyNjk=", "number": 2912, "title": "torch.mm has CUDA memory leaks for sparse matrices", "user": {"login": "antspy", "id": 625297, "node_id": "MDQ6VXNlcjYyNTI5Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/625297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/antspy", "html_url": "https://github.com/antspy", "followers_url": "https://api.github.com/users/antspy/followers", "following_url": "https://api.github.com/users/antspy/following{/other_user}", "gists_url": "https://api.github.com/users/antspy/gists{/gist_id}", "starred_url": "https://api.github.com/users/antspy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/antspy/subscriptions", "organizations_url": "https://api.github.com/users/antspy/orgs", "repos_url": "https://api.github.com/users/antspy/repos", "events_url": "https://api.github.com/users/antspy/events{/privacy}", "received_events_url": "https://api.github.com/users/antspy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-09-30T11:10:00Z", "updated_at": "2017-11-07T16:56:27Z", "closed_at": "2017-11-07T16:56:26Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I am using pytorch 0.1.12. I think I have found a bug in torch.mm that creates memory leaks, see discussion here: <a href=\"https://discuss.pytorch.org/t/cuda-memory-leaks/8142\" rel=\"nofollow\">https://discuss.pytorch.org/t/cuda-memory-leaks/8142</a></p>\n<p>In short, I was creating a big sparse matrix, and then multiplying it by a vector. So I did something like</p>\n<pre><code>big_sparse = big_sparse.cuda()\nreturn torch.mm(big_sparse, dense_vector.view(-1,1))\n</code></pre>\n<p>Running this code several times increased the CUDA usage enormously (from 700Mb to more than 12 GB). After some debugging, it appeared that torch.mm was responsible for the huge CUDA leaks. Therefore I tried to use make that operation run on CPU, with</p>\n<p><code>    return torch.mm(big_sparse, dense_vector.view(-1,1).cpu()).cuda()</code></p>\n<p>With this change the memory leaks are not there anymore. I don't know if torch.mm is creating leaks into RAM now, but with a quick check it did not appear to be the case.</p>\n<p>Is this issue fixed in version 0.2?</p>", "body_text": "Hi,\nI am using pytorch 0.1.12. I think I have found a bug in torch.mm that creates memory leaks, see discussion here: https://discuss.pytorch.org/t/cuda-memory-leaks/8142\nIn short, I was creating a big sparse matrix, and then multiplying it by a vector. So I did something like\nbig_sparse = big_sparse.cuda()\nreturn torch.mm(big_sparse, dense_vector.view(-1,1))\n\nRunning this code several times increased the CUDA usage enormously (from 700Mb to more than 12 GB). After some debugging, it appeared that torch.mm was responsible for the huge CUDA leaks. Therefore I tried to use make that operation run on CPU, with\n    return torch.mm(big_sparse, dense_vector.view(-1,1).cpu()).cuda()\nWith this change the memory leaks are not there anymore. I don't know if torch.mm is creating leaks into RAM now, but with a quick check it did not appear to be the case.\nIs this issue fixed in version 0.2?", "body": "Hi, \r\n\r\nI am using pytorch 0.1.12. I think I have found a bug in torch.mm that creates memory leaks, see discussion here: https://discuss.pytorch.org/t/cuda-memory-leaks/8142\r\n\r\nIn short, I was creating a big sparse matrix, and then multiplying it by a vector. So I did something like\r\n\r\n    big_sparse = big_sparse.cuda()\r\n    return torch.mm(big_sparse, dense_vector.view(-1,1))\r\n\r\nRunning this code several times increased the CUDA usage enormously (from 700Mb to more than 12 GB). After some debugging, it appeared that torch.mm was responsible for the huge CUDA leaks. Therefore I tried to use make that operation run on CPU, with \r\n\r\n`    return torch.mm(big_sparse, dense_vector.view(-1,1).cpu()).cuda()`\r\n\r\nWith this change the memory leaks are not there anymore. I don't know if torch.mm is creating leaks into RAM now, but with a quick check it did not appear to be the case. \r\n\r\nIs this issue fixed in version 0.2?"}