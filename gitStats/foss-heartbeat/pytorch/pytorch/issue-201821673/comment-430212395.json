{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430212395", "html_url": "https://github.com/pytorch/pytorch/issues/499#issuecomment-430212395", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/499", "id": 430212395, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDIxMjM5NQ==", "user": {"login": "shir994", "id": 8977719, "node_id": "MDQ6VXNlcjg5Nzc3MTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8977719?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shir994", "html_url": "https://github.com/shir994", "followers_url": "https://api.github.com/users/shir994/followers", "following_url": "https://api.github.com/users/shir994/following{/other_user}", "gists_url": "https://api.github.com/users/shir994/gists{/gist_id}", "starred_url": "https://api.github.com/users/shir994/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shir994/subscriptions", "organizations_url": "https://api.github.com/users/shir994/orgs", "repos_url": "https://api.github.com/users/shir994/repos", "events_url": "https://api.github.com/users/shir994/events{/privacy}", "received_events_url": "https://api.github.com/users/shir994/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-16T12:08:47Z", "updated_at": "2018-10-16T12:10:19Z", "author_association": "NONE", "body_html": "<p>I was playing around with PyTorch unfold operation. If I understand correctly, LocalConv2d could be done, if we first use torch.nn.Unfold, and then apply element-wise multiplication of kernel with different weights to each of the last dimension and then sum over first unfolded dimension. I think, it could be implemented as follows, as very ad-hoc approach:</p>\n<pre><code>class LocallyConnected2d(nn.Module):\n    def calculate_spatial_output_shape(self, input_shape, kernel_size, dilation, padding, stride):\n        return [np.floor((input_shape[index] + 2 * padding[index] - dilation[index] * (kernel_size[index] - 1) - 1) /\n                stride[index] + 1).astype(int) for index in range(len(input_shape))]\n    \n    def __init__(self, input_shape, in_channels, out_channels, kernel_size, dilation=(1,1), padding=(0,0), stride=(1,1)):\n        super().__init__()\n        self.kernel_size = kernel_size\n        self.out_channels = out_channels\n        self.dilation = dilation\n        self.padding = padding\n        self.stride = stride\n        \n        self.output_height, self.output_width = self.calculate_spatial_output_shape(input_shape, kernel_size,\n                                                                               dilation, padding, stride)\n        self.weight_tensor_depth = in_channels * kernel_size[0] * kernel_size[1]\n        self.spatial_blocks_size = self.output_height * self.output_width\n        self.weights = nn.Parameter(torch.empty((1, self.weight_tensor_depth, self.spatial_blocks_size, out_channels),\n                                   requires_grad=True, dtype=torch.float))\n        self.bias = nn.Parameter(torch.empty((1, out_channels, self.output_height, self.output_width),\n                                requires_grad=True, dtype=torch.float))\n        \n        torch.nn.init.xavier_uniform_(self.weights)\n        torch.nn.init.xavier_uniform_(self.bias)\n        \n    def forward(self, input):\n        input_unf = torch.nn.functional.unfold(input, self.kernel_size, dilation=self.dilation,\n                                               padding=self.padding, stride=self.stride)\n        local_conv_unf = (input_unf.view((*input_unf.shape, 1)) * self.weights)\n        return local_conv_unf.sum(dim=1).transpose(2, 1).reshape(\n                                        (-1, self.out_channels, self.output_height, self.output_width)) + self.bias\n</code></pre>\n<p>Although, I am very suspicious about speed performance of such implementation, since I do no use any of raw PyTorch backend methods.</p>", "body_text": "I was playing around with PyTorch unfold operation. If I understand correctly, LocalConv2d could be done, if we first use torch.nn.Unfold, and then apply element-wise multiplication of kernel with different weights to each of the last dimension and then sum over first unfolded dimension. I think, it could be implemented as follows, as very ad-hoc approach:\nclass LocallyConnected2d(nn.Module):\n    def calculate_spatial_output_shape(self, input_shape, kernel_size, dilation, padding, stride):\n        return [np.floor((input_shape[index] + 2 * padding[index] - dilation[index] * (kernel_size[index] - 1) - 1) /\n                stride[index] + 1).astype(int) for index in range(len(input_shape))]\n    \n    def __init__(self, input_shape, in_channels, out_channels, kernel_size, dilation=(1,1), padding=(0,0), stride=(1,1)):\n        super().__init__()\n        self.kernel_size = kernel_size\n        self.out_channels = out_channels\n        self.dilation = dilation\n        self.padding = padding\n        self.stride = stride\n        \n        self.output_height, self.output_width = self.calculate_spatial_output_shape(input_shape, kernel_size,\n                                                                               dilation, padding, stride)\n        self.weight_tensor_depth = in_channels * kernel_size[0] * kernel_size[1]\n        self.spatial_blocks_size = self.output_height * self.output_width\n        self.weights = nn.Parameter(torch.empty((1, self.weight_tensor_depth, self.spatial_blocks_size, out_channels),\n                                   requires_grad=True, dtype=torch.float))\n        self.bias = nn.Parameter(torch.empty((1, out_channels, self.output_height, self.output_width),\n                                requires_grad=True, dtype=torch.float))\n        \n        torch.nn.init.xavier_uniform_(self.weights)\n        torch.nn.init.xavier_uniform_(self.bias)\n        \n    def forward(self, input):\n        input_unf = torch.nn.functional.unfold(input, self.kernel_size, dilation=self.dilation,\n                                               padding=self.padding, stride=self.stride)\n        local_conv_unf = (input_unf.view((*input_unf.shape, 1)) * self.weights)\n        return local_conv_unf.sum(dim=1).transpose(2, 1).reshape(\n                                        (-1, self.out_channels, self.output_height, self.output_width)) + self.bias\n\nAlthough, I am very suspicious about speed performance of such implementation, since I do no use any of raw PyTorch backend methods.", "body": "I was playing around with PyTorch unfold operation. If I understand correctly, LocalConv2d could be done, if we first use torch.nn.Unfold, and then apply element-wise multiplication of kernel with different weights to each of the last dimension and then sum over first unfolded dimension. I think, it could be implemented as follows, as very ad-hoc approach:\r\n\r\n```\r\nclass LocallyConnected2d(nn.Module):\r\n    def calculate_spatial_output_shape(self, input_shape, kernel_size, dilation, padding, stride):\r\n        return [np.floor((input_shape[index] + 2 * padding[index] - dilation[index] * (kernel_size[index] - 1) - 1) /\r\n                stride[index] + 1).astype(int) for index in range(len(input_shape))]\r\n    \r\n    def __init__(self, input_shape, in_channels, out_channels, kernel_size, dilation=(1,1), padding=(0,0), stride=(1,1)):\r\n        super().__init__()\r\n        self.kernel_size = kernel_size\r\n        self.out_channels = out_channels\r\n        self.dilation = dilation\r\n        self.padding = padding\r\n        self.stride = stride\r\n        \r\n        self.output_height, self.output_width = self.calculate_spatial_output_shape(input_shape, kernel_size,\r\n                                                                               dilation, padding, stride)\r\n        self.weight_tensor_depth = in_channels * kernel_size[0] * kernel_size[1]\r\n        self.spatial_blocks_size = self.output_height * self.output_width\r\n        self.weights = nn.Parameter(torch.empty((1, self.weight_tensor_depth, self.spatial_blocks_size, out_channels),\r\n                                   requires_grad=True, dtype=torch.float))\r\n        self.bias = nn.Parameter(torch.empty((1, out_channels, self.output_height, self.output_width),\r\n                                requires_grad=True, dtype=torch.float))\r\n        \r\n        torch.nn.init.xavier_uniform_(self.weights)\r\n        torch.nn.init.xavier_uniform_(self.bias)\r\n        \r\n    def forward(self, input):\r\n        input_unf = torch.nn.functional.unfold(input, self.kernel_size, dilation=self.dilation,\r\n                                               padding=self.padding, stride=self.stride)\r\n        local_conv_unf = (input_unf.view((*input_unf.shape, 1)) * self.weights)\r\n        return local_conv_unf.sum(dim=1).transpose(2, 1).reshape(\r\n                                        (-1, self.out_channels, self.output_height, self.output_width)) + self.bias\r\n```\r\nAlthough, I am very suspicious about speed performance of such implementation, since I do no use any of raw PyTorch backend methods."}