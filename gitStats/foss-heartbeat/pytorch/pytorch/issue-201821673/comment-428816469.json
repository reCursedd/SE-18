{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428816469", "html_url": "https://github.com/pytorch/pytorch/issues/499#issuecomment-428816469", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/499", "id": 428816469, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODgxNjQ2OQ==", "user": {"login": "sorenchiron", "id": 11555547, "node_id": "MDQ6VXNlcjExNTU1NTQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/11555547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sorenchiron", "html_url": "https://github.com/sorenchiron", "followers_url": "https://api.github.com/users/sorenchiron/followers", "following_url": "https://api.github.com/users/sorenchiron/following{/other_user}", "gists_url": "https://api.github.com/users/sorenchiron/gists{/gist_id}", "starred_url": "https://api.github.com/users/sorenchiron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sorenchiron/subscriptions", "organizations_url": "https://api.github.com/users/sorenchiron/orgs", "repos_url": "https://api.github.com/users/sorenchiron/repos", "events_url": "https://api.github.com/users/sorenchiron/events{/privacy}", "received_events_url": "https://api.github.com/users/sorenchiron/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-11T04:26:11Z", "updated_at": "2018-10-11T04:39:43Z", "author_association": "NONE", "body_html": "<p>Saddly, neither of  <code>torch.nn.backends.thnn.backend.SpatialConvolutionLocal</code> nor <code>torch.nn._functions.thnn.SpatialConvolutionLocal</code> works for pyTorch 0.4.0.</p>\n<p>directly calling <code>local(x,w,b)</code> yields:</p>\n<pre><code>lib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\n    173                 args += (None,)\n    174             else:\n--&gt; 175                 raise ValueError(\"missing required argument '%s'\" % param.name)\n    176\n    177         args += tuple(additional_args)\n\nValueError: missing required argument 'bias'\n</code></pre>\n<p>That's because, as mentioned in <a href=\"https://pytorch.org/docs/stable/notes/extending.html?highlight=ctx\" rel=\"nofollow\">This doc</a>, invoking <code>local.forward(ctx,inputs, *params)</code> requires a <strong>ctx</strong> (SpatialConvolutionLocalBackward object here) , which by the documentation is sth not supposed to be handled by users creating extensions.</p>\n<p>On the other hand, the correct way of invoking forward is explained in <a href=\"https://pytorch.org/docs/stable/autograd.html?highlight=ctx#torch.autograd.detect_anomaly\" rel=\"nofollow\">Doc: Anomaly detection example</a>, which is by <code>local.apply(x,w,b)</code></p>\n<p>Saddly again, the outcomes of calling <code>local.apply(x,w,b)</code> is :</p>\n<pre><code>\\lib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\n    193             del ctx.buffers\n    194\n--&gt; 195         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\n    196         return output\n    197\n\nTypeError: FloatSpatialConvolutionLocal_updateOutput received an invalid combination of arguments - got (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, torch.FloatTensor bias, torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH, int inputWidth, int inputHeight, int outputWidth, int outputHeight)\n</code></pre>\n<p>By hacking around <code>auto.py</code>, I found that it is not the problem of the input <code>(x,w,b)</code> or args <code>kW,dW,dH...</code> which are of the exact required type <code>torch.FloatTensor</code>. The problem lays in some hidden builtin functions that were designed to generate  (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor) params.</p>\n<p>Hope that there will be a more general <code>ConvBase</code> class that provides ways to define <strong>cuda accelerated spatial iterations</strong>. Providing this <code>ConvBase</code> might satisfy most of the Conv-related feature-requirement issues.  Since end users know math well. Rather than asking busy developers to implement well-known <code>LocalConv</code>, maybe users only want <strong>simple</strong> access to <strong>performance</strong>, which is what they cannot achieve by themselves except by experting cuda nvcc.</p>\n<p>Most obviously, given <code>ConvBase</code>, I myself can contribute almost all kinds of special Conv layers.<br>\nPerhaps, users may feel good if pyTorch ask them to do the math, providing high-performance friendly API.<br>\nBut it's possible that users may feel bad if pyTorch is slow, and they have to wait until the all-known math is implemented by overworked/tired developers using the parallel APIs that the user actually need.</p>", "body_text": "Saddly, neither of  torch.nn.backends.thnn.backend.SpatialConvolutionLocal nor torch.nn._functions.thnn.SpatialConvolutionLocal works for pyTorch 0.4.0.\ndirectly calling local(x,w,b) yields:\nlib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\n    173                 args += (None,)\n    174             else:\n--> 175                 raise ValueError(\"missing required argument '%s'\" % param.name)\n    176\n    177         args += tuple(additional_args)\n\nValueError: missing required argument 'bias'\n\nThat's because, as mentioned in This doc, invoking local.forward(ctx,inputs, *params) requires a ctx (SpatialConvolutionLocalBackward object here) , which by the documentation is sth not supposed to be handled by users creating extensions.\nOn the other hand, the correct way of invoking forward is explained in Doc: Anomaly detection example, which is by local.apply(x,w,b)\nSaddly again, the outcomes of calling local.apply(x,w,b) is :\n\\lib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\n    193             del ctx.buffers\n    194\n--> 195         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\n    196         return output\n    197\n\nTypeError: FloatSpatialConvolutionLocal_updateOutput received an invalid combination of arguments - got (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, torch.FloatTensor bias, torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH, int inputWidth, int inputHeight, int outputWidth, int outputHeight)\n\nBy hacking around auto.py, I found that it is not the problem of the input (x,w,b) or args kW,dW,dH... which are of the exact required type torch.FloatTensor. The problem lays in some hidden builtin functions that were designed to generate  (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor) params.\nHope that there will be a more general ConvBase class that provides ways to define cuda accelerated spatial iterations. Providing this ConvBase might satisfy most of the Conv-related feature-requirement issues.  Since end users know math well. Rather than asking busy developers to implement well-known LocalConv, maybe users only want simple access to performance, which is what they cannot achieve by themselves except by experting cuda nvcc.\nMost obviously, given ConvBase, I myself can contribute almost all kinds of special Conv layers.\nPerhaps, users may feel good if pyTorch ask them to do the math, providing high-performance friendly API.\nBut it's possible that users may feel bad if pyTorch is slow, and they have to wait until the all-known math is implemented by overworked/tired developers using the parallel APIs that the user actually need.", "body": "Saddly, neither of  `torch.nn.backends.thnn.backend.SpatialConvolutionLocal` nor `torch.nn._functions.thnn.SpatialConvolutionLocal` works for pyTorch 0.4.0.  \r\n\r\ndirectly calling `local(x,w,b)` yields:\r\n\r\n```\r\nlib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\r\n    173                 args += (None,)\r\n    174             else:\r\n--> 175                 raise ValueError(\"missing required argument '%s'\" % param.name)\r\n    176\r\n    177         args += tuple(additional_args)\r\n\r\nValueError: missing required argument 'bias'\r\n```\r\nThat's because, as mentioned in [This doc](https://pytorch.org/docs/stable/notes/extending.html?highlight=ctx), invoking `local.forward(ctx,inputs, *params)` requires a __ctx__ (SpatialConvolutionLocalBackward object here) , which by the documentation is sth not supposed to be handled by users creating extensions.\r\n\r\nOn the other hand, the correct way of invoking forward is explained in [Doc: Anomaly detection example](https://pytorch.org/docs/stable/autograd.html?highlight=ctx#torch.autograd.detect_anomaly), which is by `local.apply(x,w,b)`\r\n\r\nSaddly again, the outcomes of calling `local.apply(x,w,b)` is :   \r\n\r\n```\r\n\\lib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py in forward(ctx, input, *params)\r\n    193             del ctx.buffers\r\n    194\r\n--> 195         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\r\n    196         return output\r\n    197\r\n\r\nTypeError: FloatSpatialConvolutionLocal_updateOutput received an invalid combination of arguments - got (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, torch.FloatTensor bias, torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH, int inputWidth, int inputHeight, int outputWidth, int outputHeight)\r\n```\r\n\r\nBy hacking around `auto.py`, I found that it is not the problem of the input `(x,w,b)` or args `kW,dW,dH...` which are of the exact required type `torch.FloatTensor`. The problem lays in some hidden builtin functions that were designed to generate  (int, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor) params.\r\n\r\nHope that there will be a more general `ConvBase` class that provides ways to define __cuda accelerated spatial iterations__. Providing this `ConvBase` might satisfy most of the Conv-related feature-requirement issues.  Since end users know math well. Rather than asking busy developers to implement well-known `LocalConv`, maybe users only want __simple__ access to __performance__, which is what they cannot achieve by themselves except by experting cuda nvcc. \r\n\r\nMost obviously, given `ConvBase`, I myself can contribute almost all kinds of special Conv layers. \r\nPerhaps, users may feel good if pyTorch ask them to do the math, providing high-performance friendly API. \r\nBut it's possible that users may feel bad if pyTorch is slow, and they have to wait until the all-known math is implemented by overworked/tired developers using the parallel APIs that the user actually need.\r\n"}