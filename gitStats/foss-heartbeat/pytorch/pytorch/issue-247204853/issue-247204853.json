{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2267", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2267/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2267/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2267/events", "html_url": "https://github.com/pytorch/pytorch/issues/2267", "id": 247204853, "node_id": "MDU6SXNzdWUyNDcyMDQ4NTM=", "number": 2267, "title": "CUDNN_STATUS_BAD_PARAM and LSTM/RNN or any recurrent structure", "user": {"login": "rasoolfa", "id": 11698385, "node_id": "MDQ6VXNlcjExNjk4Mzg1", "avatar_url": "https://avatars2.githubusercontent.com/u/11698385?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rasoolfa", "html_url": "https://github.com/rasoolfa", "followers_url": "https://api.github.com/users/rasoolfa/followers", "following_url": "https://api.github.com/users/rasoolfa/following{/other_user}", "gists_url": "https://api.github.com/users/rasoolfa/gists{/gist_id}", "starred_url": "https://api.github.com/users/rasoolfa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rasoolfa/subscriptions", "organizations_url": "https://api.github.com/users/rasoolfa/orgs", "repos_url": "https://api.github.com/users/rasoolfa/repos", "events_url": "https://api.github.com/users/rasoolfa/events{/privacy}", "received_events_url": "https://api.github.com/users/rasoolfa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-01T21:19:11Z", "updated_at": "2017-08-04T16:53:19Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I am getting a very strange error when using bidirectional lstm in which it deals with a very long sequence:</p>\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport torch.autograd as autograd\n\ndef Variable(data, *args, **kwargs):\n    if torch.cuda.is_available():\n        return autograd.Variable(data.cuda(), *args, **kwargs)\n    else:\n        return autograd.Variable(data, *args, **kwargs)\n\nclass LSTM_MEM_LEAK(nn.Module):\n    \n    def __init__(self):\n      \n        super(LSTM_MEM_LEAK, self).__init__()\n        self.h_size = 600\n        self.e_size = 900\n        self.l1 = nn.Linear(256, self.e_size)\n        self.lstm =nn.LSTM(self.e_size, self.h_size, batch_first = True, num_layers = 2, bidirectional = 1)\n        self.l2 = nn.Linear(self.h_size*2, 300)\n            \n    def forward(self, input):\n        \n        hidden = (Variable(torch.zeros(2*2, 16, self.h_size)),\n                Variable(torch.zeros(2*2, 16, self.h_size))) \n        l1 = F.relu(self.l1(input.view(-1, 256)))\n        lstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\n        l2  = F.relu(self.l2(lstm_out.contiguous().view(-1, self.h_size*2)))\n        \n        return l2    \n    \nnet = LSTM_MEM_LEAK()\nnet.cuda()\ninput = Variable(torch.rand(16, 6000, 256))\nprint(input.requires_grad)\nout = net(input)\n</code></pre>\n<p>and here is the error:</p>\n<pre><code>Traceback (most recent call last):\nFile \"test.py\", line 38, in \nout = net(input)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\nresult = self.forward(*input, **kwargs)\nFile \"test.py\", line 29, in forward\nlstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\nresult = self.forward(*input, **kwargs)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 162, in forward\noutput, hidden = func(input, self.all_weights, hx)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 351, in forward\nreturn func(input, *fargs, **fkwargs)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 284, in doforward\nflat_output = super(NestedIOFunction, self).doforward(*flat_input)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 306, in forward\nresult = self.forward_extended(*nested_tensors)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 293, in forward_extended\ncudnn.rnn.forward(self, input, hx, weight, output, hy)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py\", line 305, in forward\nctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py\", line 255, in check_error\nraise CuDNNError(status)\ntorch.backends.cudnn.CuDNNError: 3: b'CUDNN_STATUS_BAD_PARAM'\n\n</code></pre>\n<p>This error happens when h_size &gt;=600 and using bi-LSTM.<br>\nI guess there is a bug somewhere.<br>\nIn addition, I believe this is related to the following issue:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"245315814\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2198\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2198/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2198\">#2198</a><br>\nand I asked in the forum as well:<br>\n<a href=\"https://discuss.pytorch.org/t/cudnn-status-bad-param-and-lstm/5604\" rel=\"nofollow\">https://discuss.pytorch.org/t/cudnn-status-bad-param-and-lstm/5604</a><br>\nAny idea what is the problem?</p>", "body_text": "I am getting a very strange error when using bidirectional lstm in which it deals with a very long sequence:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport torch.autograd as autograd\n\ndef Variable(data, *args, **kwargs):\n    if torch.cuda.is_available():\n        return autograd.Variable(data.cuda(), *args, **kwargs)\n    else:\n        return autograd.Variable(data, *args, **kwargs)\n\nclass LSTM_MEM_LEAK(nn.Module):\n    \n    def __init__(self):\n      \n        super(LSTM_MEM_LEAK, self).__init__()\n        self.h_size = 600\n        self.e_size = 900\n        self.l1 = nn.Linear(256, self.e_size)\n        self.lstm =nn.LSTM(self.e_size, self.h_size, batch_first = True, num_layers = 2, bidirectional = 1)\n        self.l2 = nn.Linear(self.h_size*2, 300)\n            \n    def forward(self, input):\n        \n        hidden = (Variable(torch.zeros(2*2, 16, self.h_size)),\n                Variable(torch.zeros(2*2, 16, self.h_size))) \n        l1 = F.relu(self.l1(input.view(-1, 256)))\n        lstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\n        l2  = F.relu(self.l2(lstm_out.contiguous().view(-1, self.h_size*2)))\n        \n        return l2    \n    \nnet = LSTM_MEM_LEAK()\nnet.cuda()\ninput = Variable(torch.rand(16, 6000, 256))\nprint(input.requires_grad)\nout = net(input)\n\nand here is the error:\nTraceback (most recent call last):\nFile \"test.py\", line 38, in \nout = net(input)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\nresult = self.forward(*input, **kwargs)\nFile \"test.py\", line 29, in forward\nlstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\nresult = self.forward(*input, **kwargs)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 162, in forward\noutput, hidden = func(input, self.all_weights, hx)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 351, in forward\nreturn func(input, *fargs, **fkwargs)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 284, in doforward\nflat_output = super(NestedIOFunction, self).doforward(*flat_input)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 306, in forward\nresult = self.forward_extended(*nested_tensors)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 293, in forward_extended\ncudnn.rnn.forward(self, input, hx, weight, output, hy)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py\", line 305, in forward\nctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py\", line 255, in check_error\nraise CuDNNError(status)\ntorch.backends.cudnn.CuDNNError: 3: b'CUDNN_STATUS_BAD_PARAM'\n\n\nThis error happens when h_size >=600 and using bi-LSTM.\nI guess there is a bug somewhere.\nIn addition, I believe this is related to the following issue:\n#2198\nand I asked in the forum as well:\nhttps://discuss.pytorch.org/t/cudnn-status-bad-param-and-lstm/5604\nAny idea what is the problem?", "body": "I am getting a very strange error when using bidirectional lstm in which it deals with a very long sequence:\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport numpy as np\r\nimport torch.autograd as autograd\r\n\r\ndef Variable(data, *args, **kwargs):\r\n    if torch.cuda.is_available():\r\n        return autograd.Variable(data.cuda(), *args, **kwargs)\r\n    else:\r\n        return autograd.Variable(data, *args, **kwargs)\r\n\r\nclass LSTM_MEM_LEAK(nn.Module):\r\n    \r\n    def __init__(self):\r\n      \r\n        super(LSTM_MEM_LEAK, self).__init__()\r\n        self.h_size = 600\r\n        self.e_size = 900\r\n        self.l1 = nn.Linear(256, self.e_size)\r\n        self.lstm =nn.LSTM(self.e_size, self.h_size, batch_first = True, num_layers = 2, bidirectional = 1)\r\n        self.l2 = nn.Linear(self.h_size*2, 300)\r\n            \r\n    def forward(self, input):\r\n        \r\n        hidden = (Variable(torch.zeros(2*2, 16, self.h_size)),\r\n                Variable(torch.zeros(2*2, 16, self.h_size))) \r\n        l1 = F.relu(self.l1(input.view(-1, 256)))\r\n        lstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\r\n        l2  = F.relu(self.l2(lstm_out.contiguous().view(-1, self.h_size*2)))\r\n        \r\n        return l2    \r\n    \r\nnet = LSTM_MEM_LEAK()\r\nnet.cuda()\r\ninput = Variable(torch.rand(16, 6000, 256))\r\nprint(input.requires_grad)\r\nout = net(input)\r\n```\r\nand here is the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\nFile \"test.py\", line 38, in \r\nout = net(input)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\r\nresult = self.forward(*input, **kwargs)\r\nFile \"test.py\", line 29, in forward\r\nlstm_out, h = self.lstm(l1.view(16, -1, self.e_size), hidden)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 224, in call\r\nresult = self.forward(*input, **kwargs)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 162, in forward\r\noutput, hidden = func(input, self.all_weights, hx)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 351, in forward\r\nreturn func(input, *fargs, **fkwargs)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 284, in doforward\r\nflat_output = super(NestedIOFunction, self).doforward(*flat_input)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/autograd/function.py\", line 306, in forward\r\nresult = self.forward_extended(*nested_tensors)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 293, in forward_extended\r\ncudnn.rnn.forward(self, input, hx, weight, output, hy)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py\", line 305, in forward\r\nctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\r\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py\", line 255, in check_error\r\nraise CuDNNError(status)\r\ntorch.backends.cudnn.CuDNNError: 3: b'CUDNN_STATUS_BAD_PARAM'\r\n\r\n```\r\nThis error happens when h_size >=600 and using bi-LSTM.\r\nI guess there is a bug somewhere. \r\nIn addition, I believe this is related to the following issue:\r\nhttps://github.com/pytorch/pytorch/issues/2198\r\nand I asked in the forum as well:\r\nhttps://discuss.pytorch.org/t/cudnn-status-bad-param-and-lstm/5604\r\nAny idea what is the problem?\r\n"}