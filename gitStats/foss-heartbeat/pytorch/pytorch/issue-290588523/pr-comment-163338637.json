{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163338637", "pull_request_review_id": 90918001, "id": 163338637, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzMzODYzNw==", "diff_hunk": "@@ -1618,20 +1611,22 @@ def test_reentrant(self):\n \n         class Reenter(Function):\n             @staticmethod\n-            def forward(ctx, x_data):\n-                ctx.x = Variable(x_data, requires_grad=True)\n-                ctx.y = Variable(y_data, requires_grad=True)\n-                ctx.output_var = ctx.x * ctx.y\n-                return ctx.output_var.data\n+            def forward(ctx, x):\n+                with torch.enable_grad():\n+                    ctx.x = Variable(x.data, requires_grad=True)\n+                    ctx.y = Variable(y_data, requires_grad=True)\n+                    ctx.output_var = ctx.x * ctx.y\n+                return ctx.output_var[:]\n \n             @staticmethod\n             def backward(ctx, grad_output):\n-                ctx.output_var.sum().backward()\n+                with torch.enable_grad():", "path": "test/test_autograd.py", "position": 166, "original_position": 113, "commit_id": "a52a6a4055e7bc0053fbc4c65f217b3cb39f0b29", "original_commit_id": "296394a9359ec2a3504b3bc155077d6a90bbf7e5", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "`backward()` runs with no-grad if `create_graph` is False because you don't care about higher order derivatives. We could run with `create_graph=True` here (the previous behavior), but that saves more history then necessary. It's a little more clean to just use `enable_grad()` so that the `sum()` calls is differentiable, but not he multiplication on the line below.", "created_at": "2018-01-23T18:44:32Z", "updated_at": "2018-11-23T15:38:27Z", "html_url": "https://github.com/pytorch/pytorch/pull/4786#discussion_r163338637", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4786", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163338637"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4786#discussion_r163338637"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4786"}}, "body_html": "<p><code>backward()</code> runs with no-grad if <code>create_graph</code> is False because you don't care about higher order derivatives. We could run with <code>create_graph=True</code> here (the previous behavior), but that saves more history then necessary. It's a little more clean to just use <code>enable_grad()</code> so that the <code>sum()</code> calls is differentiable, but not he multiplication on the line below.</p>", "body_text": "backward() runs with no-grad if create_graph is False because you don't care about higher order derivatives. We could run with create_graph=True here (the previous behavior), but that saves more history then necessary. It's a little more clean to just use enable_grad() so that the sum() calls is differentiable, but not he multiplication on the line below.", "in_reply_to_id": 163322457}