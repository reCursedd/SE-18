{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14260", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14260/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14260/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14260/events", "html_url": "https://github.com/pytorch/pytorch/issues/14260", "id": 382912414, "node_id": "MDU6SXNzdWUzODI5MTI0MTQ=", "number": 14260, "title": "RNN have CuDNN error: CUDNN_STATUS_SUCCESS with Tesla T4", "user": {"login": "fuzihaofzh", "id": 1419566, "node_id": "MDQ6VXNlcjE0MTk1NjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1419566?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fuzihaofzh", "html_url": "https://github.com/fuzihaofzh", "followers_url": "https://api.github.com/users/fuzihaofzh/followers", "following_url": "https://api.github.com/users/fuzihaofzh/following{/other_user}", "gists_url": "https://api.github.com/users/fuzihaofzh/gists{/gist_id}", "starred_url": "https://api.github.com/users/fuzihaofzh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fuzihaofzh/subscriptions", "organizations_url": "https://api.github.com/users/fuzihaofzh/orgs", "repos_url": "https://api.github.com/users/fuzihaofzh/repos", "events_url": "https://api.github.com/users/fuzihaofzh/events{/privacy}", "received_events_url": "https://api.github.com/users/fuzihaofzh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T01:05:23Z", "updated_at": "2018-11-21T01:05:23Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>rnn cannot work on Tesla T4.</p>\n<h2>To Reproduce</h2>\n<p>System: Ubuntu 18.04.1 LTS<br>\nCUDA Version: 10.0.130<br>\nGPU: Tesla T4</p>\n<p>Steps to reproduce the behavior:</p>\n<p>run the code:</p>\n<pre><code>import torch\nimport torch.nn as nn\na = torch.randn(5, 3, 10) # This can be sent into GPU correctly!\nrnn = nn.RNN(10, 20, 2)\nrnn.cuda()\n</code></pre>\n<p>The error is:</p>\n<pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-4-951688d61d0c&gt; in &lt;module&gt;\n----&gt; 1 rnn.cuda()\n\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in cuda(s\nelf, device)\n    256             Module: self\n    257         \"\"\"\n--&gt; 258         return self._apply(lambda t: t.cuda(device))\n    259\n    260     def cpu(self):\n\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in _apply(se\nlf, fn)\n    110     def _apply(self, fn):\n    111         ret = super(RNNBase, self)._apply(fn)\n--&gt; 112         self.flatten_parameters()\n    113         return ret\n    114\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in flatten_p\narameters(self)\n    103                     weight_arr, weight_stride0,\n    104                     self.input_size, rnn.get_cudnn_mode(self.mode), self.hidden_si\nze, self.num_layers,\n--&gt; 105                     self.batch_first, bool(self.bidirectional))\n    106\n    107             self._param_buf_size = weight_buf.size(0)\n\nRuntimeError: CuDNN error: CUDNN_STATUS_SUCCESS\n</code></pre>\n\n<h2>Expected behavior</h2>\n\n<p>Expect rnn is sent to GPU</p>\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<ul>\n<li>PyTorch Version (e.g., 1.0): 0.4.1.post2</li>\n<li>OS (e.g., Linux): Linux</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): pip</li>\n<li>Build command you used (if compiling from source):</li>\n<li>Python version:  3.7</li>\n<li>CUDA/cuDNN version: 10.0.130</li>\n<li>GPU models and configuration:<br>\nGPU 0: Tesla T4</li>\n<li>Any other relevant information:</li>\n</ul>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\nrnn cannot work on Tesla T4.\nTo Reproduce\nSystem: Ubuntu 18.04.1 LTS\nCUDA Version: 10.0.130\nGPU: Tesla T4\nSteps to reproduce the behavior:\nrun the code:\nimport torch\nimport torch.nn as nn\na = torch.randn(5, 3, 10) # This can be sent into GPU correctly!\nrnn = nn.RNN(10, 20, 2)\nrnn.cuda()\n\nThe error is:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-4-951688d61d0c> in <module>\n----> 1 rnn.cuda()\n\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in cuda(s\nelf, device)\n    256             Module: self\n    257         \"\"\"\n--> 258         return self._apply(lambda t: t.cuda(device))\n    259\n    260     def cpu(self):\n\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in _apply(se\nlf, fn)\n    110     def _apply(self, fn):\n    111         ret = super(RNNBase, self)._apply(fn)\n--> 112         self.flatten_parameters()\n    113         return ret\n    114\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in flatten_p\narameters(self)\n    103                     weight_arr, weight_stride0,\n    104                     self.input_size, rnn.get_cudnn_mode(self.mode), self.hidden_si\nze, self.num_layers,\n--> 105                     self.batch_first, bool(self.bidirectional))\n    106\n    107             self._param_buf_size = weight_buf.size(0)\n\nRuntimeError: CuDNN error: CUDNN_STATUS_SUCCESS\n\n\nExpected behavior\n\nExpect rnn is sent to GPU\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\n\nPyTorch Version (e.g., 1.0): 0.4.1.post2\nOS (e.g., Linux): Linux\nHow you installed PyTorch (conda, pip, source): pip\nBuild command you used (if compiling from source):\nPython version:  3.7\nCUDA/cuDNN version: 10.0.130\nGPU models and configuration:\nGPU 0: Tesla T4\nAny other relevant information:\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\n\r\nrnn cannot work on Tesla T4.\r\n\r\n## To Reproduce\r\nSystem: Ubuntu 18.04.1 LTS\r\nCUDA Version: 10.0.130\r\nGPU: Tesla T4\r\n\r\nSteps to reproduce the behavior:\r\n\r\nrun the code:\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\na = torch.randn(5, 3, 10) # This can be sent into GPU correctly!\r\nrnn = nn.RNN(10, 20, 2)\r\nrnn.cuda()\r\n```\r\nThe error is:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-951688d61d0c> in <module>\r\n----> 1 rnn.cuda()\r\n\r\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in cuda(s\r\nelf, device)\r\n    256             Module: self\r\n    257         \"\"\"\r\n--> 258         return self._apply(lambda t: t.cuda(device))\r\n    259\r\n    260     def cpu(self):\r\n\r\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in _apply(se\r\nlf, fn)\r\n    110     def _apply(self, fn):\r\n    111         ret = super(RNNBase, self)._apply(fn)\r\n--> 112         self.flatten_parameters()\r\n    113         return ret\r\n    114\r\n~/ProgramFiles/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py in flatten_p\r\narameters(self)\r\n    103                     weight_arr, weight_stride0,\r\n    104                     self.input_size, rnn.get_cudnn_mode(self.mode), self.hidden_si\r\nze, self.num_layers,\r\n--> 105                     self.batch_first, bool(self.bidirectional))\r\n    106\r\n    107             self._param_buf_size = weight_buf.size(0)\r\n\r\nRuntimeError: CuDNN error: CUDNN_STATUS_SUCCESS\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nExpect rnn is sent to GPU\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 0.4.1.post2\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source):\r\n - Python version:  3.7\r\n - CUDA/cuDNN version: 10.0.130\r\n - GPU models and configuration:\r\nGPU 0: Tesla T4\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}