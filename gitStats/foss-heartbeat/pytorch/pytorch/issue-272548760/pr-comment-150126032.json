{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150126032", "pull_request_review_id": 75632108, "id": 150126032, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDEyNjAzMg==", "diff_hunk": "@@ -0,0 +1,219 @@\n+#include \"python_compiled_function.h\"\n+\n+#include \"torch/csrc/jit/pybind.h\"\n+#include \"torch/csrc/autograd/variable.h\"\n+#include \"torch/csrc/autograd/functions/jit_closure.h\"\n+#include \"torch/csrc/jit/tracer.h\"\n+#include \"torch/csrc/jit/passes/dead_code_elimination.h\"\n+#include \"torch/csrc/jit/passes/peephole.h\"\n+#include \"torch/csrc/jit/passes/graph_fuser.h\"\n+#include \"torch/csrc/jit/passes/inplace_check.h\"\n+#include \"torch/csrc/jit/python_arg_flatten.h\"\n+\n+#include <algorithm>\n+#include <functional>\n+#include <atomic>\n+\n+namespace torch { namespace jit { namespace python {\n+\n+using namespace torch::autograd;\n+using namespace torch::jit::tracer;\n+\n+namespace {\n+\n+// pybind casts are really verobse...\n+py::object steal(py::handle x) {\n+  return py::reinterpret_steal<py::object>(x);\n+}\n+\n+py::object borrow(py::handle x) {\n+  return py::reinterpret_borrow<py::object>(x);\n+}\n+\n+} // anonymous namespace\n+\n+// Lifecycle of a CompiledFunction:\n+//\n+// - It is given an underlying function, which knows how to actually\n+//   execute the code that we want to compile.\n+// - When we encounter an input configuration for which we don't\n+//   have an optimized trace, we run the underlying function, tracing its\n+//   result.  The trace is not done yet, so we save it into our set of pending\n+//   traces for that configuration.\n+// - When we encounter an input configuration whose trace is \"ready\"\n+//   (that is, we've seen all of the passes, so the trace contains\n+//   forwards/backwards/etc), we compile it, and then register this\n+//   as the compiled trace.\n+// - When we encounter an input configuration whose trace is compiled,\n+//   we just directly run the compiled trace.\n+struct CompiledFunction {\n+\n+  struct TraceForKey {\n+    TraceForKey(CompiledFunction& fn, bool is_volatile)\n+      : fn_(fn)\n+      , is_volatile_(is_volatile) {}\n+\n+    bool ready() {\n+      if (closure_) return true;\n+\n+      // Remove expired traces\n+      traces_.erase(std::remove_if(traces_.begin(),\n+                                   traces_.end(),\n+                                   [](const std::shared_ptr<TracingState>& state) {\n+                                     return state->is_expired();\n+                                   }),\n+                    traces_.end());\n+\n+      // Check if any trace is complete\n+      auto complete_it = std::find_if(traces_.begin(),\n+                                   traces_.end(),\n+                                   [](const std::shared_ptr<TracingState>& state) {\n+                                     return state->is_complete();\n+                                   });\n+      if (complete_it == traces_.end())\n+        return false;\n+\n+      auto complete_trace = *complete_it; // NOTE: copy, because we clear right after\n+      traces_.clear();\n+\n+      // Now, we have a complete trace. Compile it.\n+      EliminateDeadCode(complete_trace->graph);", "path": "torch/csrc/jit/python_compiled_function.cpp", "position": 80, "original_position": 80, "commit_id": "f98292f85b7bceddb52a7e160cb94a9aef261cd2", "original_commit_id": "66aa44d2b1851587309961284cf2e5feaa37fed5", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Not for this patch, but now that the optimizations live in C++, it would be really good to have a gcc/clang style way of toggling specific optimizations on/off from Python.", "created_at": "2017-11-10T00:21:04Z", "updated_at": "2018-11-23T15:36:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/3597#discussion_r150126032", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3597", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150126032"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3597#discussion_r150126032"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3597"}}, "body_html": "<p>Not for this patch, but now that the optimizations live in C++, it would be really good to have a gcc/clang style way of toggling specific optimizations on/off from Python.</p>", "body_text": "Not for this patch, but now that the optimizations live in C++, it would be really good to have a gcc/clang style way of toggling specific optimizations on/off from Python."}