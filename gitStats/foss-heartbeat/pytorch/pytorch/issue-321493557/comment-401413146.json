{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/401413146", "html_url": "https://github.com/pytorch/pytorch/issues/7415#issuecomment-401413146", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7415", "id": 401413146, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTQxMzE0Ng==", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-29T16:55:46Z", "updated_at": "2018-06-29T16:55:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31921471\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/travel-go\">@travel-go</a> , if you are referring your checkpoint as a state_dict, then load_state_dict() is doing a for loop to load them one by one.<br>\nIf you are loading your checkpoint from a file, the tensor reconstruction happens in <strong>reduce</strong> behavior of Tensor &amp; storageBase object, and triggered by pickle. Please note that loading from file is done through <code>torch.load()</code> and it has nothing to do with a model yet. Thus it's true that if you load something from a file, it will load the whole to either cpu/gpu and then you can load one by one to your model. In most cases we think it's okay to use more CPU memory rather than GPU memory. Could you elaborate more of your use case( is cpu/gpu memory constrained?) so that we could help resolve it?</p>", "body_text": "Hi @travel-go , if you are referring your checkpoint as a state_dict, then load_state_dict() is doing a for loop to load them one by one.\nIf you are loading your checkpoint from a file, the tensor reconstruction happens in reduce behavior of Tensor & storageBase object, and triggered by pickle. Please note that loading from file is done through torch.load() and it has nothing to do with a model yet. Thus it's true that if you load something from a file, it will load the whole to either cpu/gpu and then you can load one by one to your model. In most cases we think it's okay to use more CPU memory rather than GPU memory. Could you elaborate more of your use case( is cpu/gpu memory constrained?) so that we could help resolve it?", "body": "Hi @travel-go , if you are referring your checkpoint as a state_dict, then load_state_dict() is doing a for loop to load them one by one. \r\nIf you are loading your checkpoint from a file, the tensor reconstruction happens in __reduce__ behavior of Tensor & storageBase object, and triggered by pickle. Please note that loading from file is done through `torch.load()` and it has nothing to do with a model yet. Thus it's true that if you load something from a file, it will load the whole to either cpu/gpu and then you can load one by one to your model. In most cases we think it's okay to use more CPU memory rather than GPU memory. Could you elaborate more of your use case( is cpu/gpu memory constrained?) so that we could help resolve it?"}