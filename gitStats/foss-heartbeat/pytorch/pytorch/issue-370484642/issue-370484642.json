{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12702", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12702/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12702/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12702/events", "html_url": "https://github.com/pytorch/pytorch/issues/12702", "id": 370484642, "node_id": "MDU6SXNzdWUzNzA0ODQ2NDI=", "number": 12702, "title": "How to run a pytorch-onnx-caffe2 model on GPU?", "user": {"login": "perrywu1989", "id": 29011669, "node_id": "MDQ6VXNlcjI5MDExNjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/29011669?v=4", "gravatar_id": "", "url": "https://api.github.com/users/perrywu1989", "html_url": "https://github.com/perrywu1989", "followers_url": "https://api.github.com/users/perrywu1989/followers", "following_url": "https://api.github.com/users/perrywu1989/following{/other_user}", "gists_url": "https://api.github.com/users/perrywu1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/perrywu1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/perrywu1989/subscriptions", "organizations_url": "https://api.github.com/users/perrywu1989/orgs", "repos_url": "https://api.github.com/users/perrywu1989/repos", "events_url": "https://api.github.com/users/perrywu1989/events{/privacy}", "received_events_url": "https://api.github.com/users/perrywu1989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-16T07:58:19Z", "updated_at": "2018-11-18T14:03:24Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>envs:<br>\nPytorch of latest version(torch 1.0.0a0+058c12) from source.<br>\n|--- install build-in convert-onnx-to-caffe2 tool ---|<br>\nOnnx (onnx   1.3.0) from pip<br>\nconda python 3.5</p>\n<p>First:<br>\nI use codes below to convert pytorch to onnx. Works!</p>\n<pre><code>model = Resnet18()\nif torch.cuda.is_available():\n    state_dict = torch.load(model_file)\n    model.load_state_dict(state_dict)\n    model.cuda()\n    x = torch.randn(1, 3, 128, 128, requires_grad=True).cuda()\nelse:\n    state_dict = torch.load(model_file, map_location='cpu')\n    model.load_state_dict(state_dict)\n    x = torch.randn(1, 3, 128, 128, requires_grad=True)\nmodel.train(False)\ntorch_out = torch.onnx._export(model,  \n                               x,  \n                               \"ocr_api.onnx\",  \n                               export_params=True)\n</code></pre>\n<p>After I got ONNX, I convert it to caffe2.Works!</p>\n<pre><code>Bash Command: onvert-onnx-to-caffe2 ocr_api.onnx --output predict_net.pb --init-net-output init_net.pb\n</code></pre>\n<p><strong>After I got two .pb files, I run them on Caffe2. Works but in CPU model!</strong></p>\n<pre><code>with open(\"init_net.pb\",'rb') as f:\n    init_net = f.read()\nwith open(\"predict_net.pb\",'rb') as f:\n    predict_net = f.read()\np = workspace.Predictor(init_net, predict_net)\nimg = np.random.randn(1, 3, 128, 128).astype(np.float32)\nout = p.run([img])\n</code></pre>\n<p><strong>Unfortunately, I try many ways to make them run on GPU, but not any works.</strong><br>\nFor examplse:</p>\n<pre><code>import numpy as np\nimport os, time\nfrom caffe2.python import core, workspace, model_helper\nfrom caffe2.proto import caffe2_pb2, caffe2_legacy_pb2\n\nworkspace.ResetWorkspace()\ndevice_opts = core.DeviceOption(caffe2_pb2.CUDA, 0)\n\nnet_def = caffe2_pb2.NetDef()\nwith open('predict_net.pb', 'rb') as f:\n    net_def.ParseFromString(f.read())\n    net_def.device_option.CopyFrom(device_opts)\n    workspace.CreateNet(net_def)\n    # workspace.CreateNet(net_def.SerializeToString())\n\ninit_def = caffe2_pb2.NetDef()\nwith open('init_net.pb', 'rb') as f:\n    init_def.ParseFromString(f.read())\n    init_def.device_option.CopyFrom(device_opts)\n    workspace.RunNetOnce(init_def)\n    # workspace.RunNetOnce(init_def.SerializeToString())\n\nname = net_def.name\noutput_name = net_def.external_output[-1]\ninput_name = net_def.external_input[0]\n\n\ninput_data = np.random.rand(1, 3, 32, 128).astype(np.float32) # NCHW\n\nworkspace.FeedBlob(input_name, input_data, device_opts) # workspace.FeedBlob('data', input_data, device_opts)\n\nworkspace.RunNet(name, 1)\nresults = workspace.FetchBlob(output_name)\n</code></pre>\n<p>it said:</p>\n<pre><code>Traceback (most recent call last):\n  File \"run_caffe2.py\", line 78, in &lt;module&gt;\n    workspace.CreateNet(net_def)\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 154, in CreateNet\n    StringifyProto(net), overwrite,\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: [enforce fail at operator.cc:46] blob != nullptr. op Conv: Encountered a non-existing input blob: 0\n</code></pre>\n<p>Even I use the codes in comment lines, the error messages are the same.</p>\n<p>Is there anyone who knows how to solve this problem? Or how to make a pytorch-onnx-caffe2 model<br>\nrun on GPU?<br>\nThanks very much!</p>", "body_text": "envs:\nPytorch of latest version(torch 1.0.0a0+058c12) from source.\n|--- install build-in convert-onnx-to-caffe2 tool ---|\nOnnx (onnx   1.3.0) from pip\nconda python 3.5\nFirst:\nI use codes below to convert pytorch to onnx. Works!\nmodel = Resnet18()\nif torch.cuda.is_available():\n    state_dict = torch.load(model_file)\n    model.load_state_dict(state_dict)\n    model.cuda()\n    x = torch.randn(1, 3, 128, 128, requires_grad=True).cuda()\nelse:\n    state_dict = torch.load(model_file, map_location='cpu')\n    model.load_state_dict(state_dict)\n    x = torch.randn(1, 3, 128, 128, requires_grad=True)\nmodel.train(False)\ntorch_out = torch.onnx._export(model,  \n                               x,  \n                               \"ocr_api.onnx\",  \n                               export_params=True)\n\nAfter I got ONNX, I convert it to caffe2.Works!\nBash Command: onvert-onnx-to-caffe2 ocr_api.onnx --output predict_net.pb --init-net-output init_net.pb\n\nAfter I got two .pb files, I run them on Caffe2. Works but in CPU model!\nwith open(\"init_net.pb\",'rb') as f:\n    init_net = f.read()\nwith open(\"predict_net.pb\",'rb') as f:\n    predict_net = f.read()\np = workspace.Predictor(init_net, predict_net)\nimg = np.random.randn(1, 3, 128, 128).astype(np.float32)\nout = p.run([img])\n\nUnfortunately, I try many ways to make them run on GPU, but not any works.\nFor examplse:\nimport numpy as np\nimport os, time\nfrom caffe2.python import core, workspace, model_helper\nfrom caffe2.proto import caffe2_pb2, caffe2_legacy_pb2\n\nworkspace.ResetWorkspace()\ndevice_opts = core.DeviceOption(caffe2_pb2.CUDA, 0)\n\nnet_def = caffe2_pb2.NetDef()\nwith open('predict_net.pb', 'rb') as f:\n    net_def.ParseFromString(f.read())\n    net_def.device_option.CopyFrom(device_opts)\n    workspace.CreateNet(net_def)\n    # workspace.CreateNet(net_def.SerializeToString())\n\ninit_def = caffe2_pb2.NetDef()\nwith open('init_net.pb', 'rb') as f:\n    init_def.ParseFromString(f.read())\n    init_def.device_option.CopyFrom(device_opts)\n    workspace.RunNetOnce(init_def)\n    # workspace.RunNetOnce(init_def.SerializeToString())\n\nname = net_def.name\noutput_name = net_def.external_output[-1]\ninput_name = net_def.external_input[0]\n\n\ninput_data = np.random.rand(1, 3, 32, 128).astype(np.float32) # NCHW\n\nworkspace.FeedBlob(input_name, input_data, device_opts) # workspace.FeedBlob('data', input_data, device_opts)\n\nworkspace.RunNet(name, 1)\nresults = workspace.FetchBlob(output_name)\n\nit said:\nTraceback (most recent call last):\n  File \"run_caffe2.py\", line 78, in <module>\n    workspace.CreateNet(net_def)\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 154, in CreateNet\n    StringifyProto(net), overwrite,\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: [enforce fail at operator.cc:46] blob != nullptr. op Conv: Encountered a non-existing input blob: 0\n\nEven I use the codes in comment lines, the error messages are the same.\nIs there anyone who knows how to solve this problem? Or how to make a pytorch-onnx-caffe2 model\nrun on GPU?\nThanks very much!", "body": "envs:\r\nPytorch of latest version(torch 1.0.0a0+058c12) from source.\r\n            |--- install build-in convert-onnx-to-caffe2 tool ---|\r\nOnnx (onnx   1.3.0) from pip\r\nconda python 3.5\r\n\r\nFirst:\r\nI use codes below to convert pytorch to onnx. Works!\r\n```\r\nmodel = Resnet18()\r\nif torch.cuda.is_available():\r\n    state_dict = torch.load(model_file)\r\n    model.load_state_dict(state_dict)\r\n    model.cuda()\r\n    x = torch.randn(1, 3, 128, 128, requires_grad=True).cuda()\r\nelse:\r\n    state_dict = torch.load(model_file, map_location='cpu')\r\n    model.load_state_dict(state_dict)\r\n    x = torch.randn(1, 3, 128, 128, requires_grad=True)\r\nmodel.train(False)\r\ntorch_out = torch.onnx._export(model,  \r\n                               x,  \r\n                               \"ocr_api.onnx\",  \r\n                               export_params=True)\r\n```\r\nAfter I got ONNX, I convert it to caffe2.Works!\r\n```\r\nBash Command: onvert-onnx-to-caffe2 ocr_api.onnx --output predict_net.pb --init-net-output init_net.pb\r\n```\r\n**After I got two .pb files, I run them on Caffe2. Works but in CPU model!**\r\n```\r\nwith open(\"init_net.pb\",'rb') as f:\r\n    init_net = f.read()\r\nwith open(\"predict_net.pb\",'rb') as f:\r\n    predict_net = f.read()\r\np = workspace.Predictor(init_net, predict_net)\r\nimg = np.random.randn(1, 3, 128, 128).astype(np.float32)\r\nout = p.run([img])\r\n```\r\n**Unfortunately, I try many ways to make them run on GPU, but not any works.**\r\nFor examplse:\r\n```\r\nimport numpy as np\r\nimport os, time\r\nfrom caffe2.python import core, workspace, model_helper\r\nfrom caffe2.proto import caffe2_pb2, caffe2_legacy_pb2\r\n\r\nworkspace.ResetWorkspace()\r\ndevice_opts = core.DeviceOption(caffe2_pb2.CUDA, 0)\r\n\r\nnet_def = caffe2_pb2.NetDef()\r\nwith open('predict_net.pb', 'rb') as f:\r\n    net_def.ParseFromString(f.read())\r\n    net_def.device_option.CopyFrom(device_opts)\r\n    workspace.CreateNet(net_def)\r\n    # workspace.CreateNet(net_def.SerializeToString())\r\n\r\ninit_def = caffe2_pb2.NetDef()\r\nwith open('init_net.pb', 'rb') as f:\r\n    init_def.ParseFromString(f.read())\r\n    init_def.device_option.CopyFrom(device_opts)\r\n    workspace.RunNetOnce(init_def)\r\n    # workspace.RunNetOnce(init_def.SerializeToString())\r\n\r\nname = net_def.name\r\noutput_name = net_def.external_output[-1]\r\ninput_name = net_def.external_input[0]\r\n\r\n\r\ninput_data = np.random.rand(1, 3, 32, 128).astype(np.float32) # NCHW\r\n\r\nworkspace.FeedBlob(input_name, input_data, device_opts) # workspace.FeedBlob('data', input_data, device_opts)\r\n\r\nworkspace.RunNet(name, 1)\r\nresults = workspace.FetchBlob(output_name)\r\n```\r\nit said:\r\n```\r\nTraceback (most recent call last):\r\n  File \"run_caffe2.py\", line 78, in <module>\r\n    workspace.CreateNet(net_def)\r\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 154, in CreateNet\r\n    StringifyProto(net), overwrite,\r\n  File \"/home/wfy/anaconda3/envs/caffe2/lib/python3.5/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\r\n    return func(*args, **kwargs)\r\nRuntimeError: [enforce fail at operator.cc:46] blob != nullptr. op Conv: Encountered a non-existing input blob: 0\r\n```\r\nEven I use the codes in comment lines, the error messages are the same.\r\n\r\nIs there anyone who knows how to solve this problem? Or how to make a pytorch-onnx-caffe2 model \r\nrun on GPU?\r\nThanks very much!\r\n\r\n"}