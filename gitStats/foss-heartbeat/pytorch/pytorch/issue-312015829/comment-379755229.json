{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/379755229", "html_url": "https://github.com/pytorch/pytorch/issues/6351#issuecomment-379755229", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6351", "id": 379755229, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTc1NTIyOQ==", "user": {"login": "lvdmaaten", "id": 1168046, "node_id": "MDQ6VXNlcjExNjgwNDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1168046?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lvdmaaten", "html_url": "https://github.com/lvdmaaten", "followers_url": "https://api.github.com/users/lvdmaaten/followers", "following_url": "https://api.github.com/users/lvdmaaten/following{/other_user}", "gists_url": "https://api.github.com/users/lvdmaaten/gists{/gist_id}", "starred_url": "https://api.github.com/users/lvdmaaten/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lvdmaaten/subscriptions", "organizations_url": "https://api.github.com/users/lvdmaaten/orgs", "repos_url": "https://api.github.com/users/lvdmaaten/repos", "events_url": "https://api.github.com/users/lvdmaaten/events{/privacy}", "received_events_url": "https://api.github.com/users/lvdmaaten/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-09T13:39:21Z", "updated_at": "2018-04-09T13:39:21Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> Yeah, those are good points. The context for this issue was I was writing some CI tests for my project, checking the output of a small training pipeline. I couldn't get the tests to pass even though <code>cudnn.deterministic=True</code> because there was <code>cudnn.benchmark=True</code> lurking somewhere in the code. I think a reasonable guarantee would be for <code>cudnn.deterministic=True</code> to always produce the same results on the same GPU hardware and the same CUDA / cudnn / cublas software stack -- as this is a minimal requirement for automated tests, and as you say, it seems unlikely we can give any stronger guarantees.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> Sounds good!</p>", "body_text": "@ngimel Yeah, those are good points. The context for this issue was I was writing some CI tests for my project, checking the output of a small training pipeline. I couldn't get the tests to pass even though cudnn.deterministic=True because there was cudnn.benchmark=True lurking somewhere in the code. I think a reasonable guarantee would be for cudnn.deterministic=True to always produce the same results on the same GPU hardware and the same CUDA / cudnn / cublas software stack -- as this is a minimal requirement for automated tests, and as you say, it seems unlikely we can give any stronger guarantees.\n@apaszke Sounds good!", "body": "@ngimel Yeah, those are good points. The context for this issue was I was writing some CI tests for my project, checking the output of a small training pipeline. I couldn't get the tests to pass even though `cudnn.deterministic=True` because there was `cudnn.benchmark=True` lurking somewhere in the code. I think a reasonable guarantee would be for `cudnn.deterministic=True` to always produce the same results on the same GPU hardware and the same CUDA / cudnn / cublas software stack -- as this is a minimal requirement for automated tests, and as you say, it seems unlikely we can give any stronger guarantees.\r\n\r\n@apaszke Sounds good!"}