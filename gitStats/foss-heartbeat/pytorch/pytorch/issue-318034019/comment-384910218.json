{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/384910218", "html_url": "https://github.com/pytorch/pytorch/issues/6988#issuecomment-384910218", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6988", "id": 384910218, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NDkxMDIxOA==", "user": {"login": "zuoxingdong", "id": 18168681, "node_id": "MDQ6VXNlcjE4MTY4Njgx", "avatar_url": "https://avatars0.githubusercontent.com/u/18168681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zuoxingdong", "html_url": "https://github.com/zuoxingdong", "followers_url": "https://api.github.com/users/zuoxingdong/followers", "following_url": "https://api.github.com/users/zuoxingdong/following{/other_user}", "gists_url": "https://api.github.com/users/zuoxingdong/gists{/gist_id}", "starred_url": "https://api.github.com/users/zuoxingdong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zuoxingdong/subscriptions", "organizations_url": "https://api.github.com/users/zuoxingdong/orgs", "repos_url": "https://api.github.com/users/zuoxingdong/repos", "events_url": "https://api.github.com/users/zuoxingdong/events{/privacy}", "received_events_url": "https://api.github.com/users/zuoxingdong/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-27T08:58:58Z", "updated_at": "2018-04-27T08:58:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> Thanks a lot for the explanation. Just to make sure I don't take it wrong. By setting <code>size_average=True</code> by default to average over all elements rather than firstly summing up losses for each training example and then to average. This does not alter the gradient direction but indeed a smaller scale of the gradient. Will it have potential effects to slow down the training ? Because averaging over all elements gets smaller loss, leading to smaller gradient norm.</p>", "body_text": "@zou3519 Thanks a lot for the explanation. Just to make sure I don't take it wrong. By setting size_average=True by default to average over all elements rather than firstly summing up losses for each training example and then to average. This does not alter the gradient direction but indeed a smaller scale of the gradient. Will it have potential effects to slow down the training ? Because averaging over all elements gets smaller loss, leading to smaller gradient norm.", "body": "@zou3519 Thanks a lot for the explanation. Just to make sure I don't take it wrong. By setting `size_average=True` by default to average over all elements rather than firstly summing up losses for each training example and then to average. This does not alter the gradient direction but indeed a smaller scale of the gradient. Will it have potential effects to slow down the training ? Because averaging over all elements gets smaller loss, leading to smaller gradient norm. "}