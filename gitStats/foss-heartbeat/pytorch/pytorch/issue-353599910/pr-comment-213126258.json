{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213126258", "pull_request_review_id": 149893404, "id": 213126258, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMzEyNjI1OA==", "diff_hunk": "@@ -252,6 +254,139 @@ def _verify_equal(xs, ys):\n             raise RuntimeError(\"JIT and real computation mismatch\")\n \n \n+def indent(s):\n+    return '\\n'.join(['\\t' + line for line in s.splitlines()])\n+\n+\n+class TracingCheckError(Exception):\n+    def __init__(self, graph_diff_error, tensor_compare_error, nondeterm_warning, extra_msg=None):\n+        self.message = 'Tracing failed sanity checks!\\n'\n+        if extra_msg is not None:\n+            self.message += extra_msg + '\\n'\n+        if graph_diff_error is not None:\n+            self.message += 'ERROR: Graphs differed across invocations!\\n'\n+            self.message += indent(graph_diff_error) + '\\n'\n+        if nondeterm_warning is not None:\n+            self.message += 'WARNING: '\n+            self.message += nondeterm_warning + '\\n'\n+        if tensor_compare_error is not None:\n+            self.message += 'ERROR: Tensor-valued Constant nodes differed in value ' \\\n+                            'across invocations. This often indicates that the tracer has' \\\n+                            ' encountered untraceable code.\\n'\n+            self.message += indent(tensor_compare_error) + '\\n'\n+        super(TracingCheckError, self).__init__(self.message)\n+\n+\n+# Check the traced module against a set of user-provided validation inputs\n+def check_trace(check_inputs, func, executor_options, module, check_tolerance):\n+    for inputs in check_inputs:\n+        check_mod = TopLevelTracedModule(func, **executor_options)\n+        check_mod._create_method_from_trace('forward', func, _clone_inputs(inputs))\n+\n+        def graph_diagnostic_info():\n+            mod_canonicalized = torch._C._jit_pass_canonicalize(module.graph)\n+            torch._C._jit_pass_decay_types(mod_canonicalized)\n+            check_canonicalized = torch._C._jit_pass_canonicalize(check_mod.graph)\n+            torch._C._jit_pass_decay_types(check_canonicalized)\n+\n+            graph_diff_errors = None\n+            if (str(mod_canonicalized) != str(check_canonicalized)):\n+                import difflib\n+                graph_diff = difflib.ndiff(str(mod_canonicalized).splitlines(1),\n+                                           str(check_canonicalized).splitlines(1))\n+                graph_diff_errors = 'Graph diff:\\n' + indent(''.join(graph_diff)) + '\\n'\n+\n+                num_errors = 0\n+                MAX_ERROR_PRINTOUT = 20  # arbitrary\n+\n+                for n_mod, n_check in zip(mod_canonicalized.nodes(), check_canonicalized.nodes()):\n+                    if num_errors > MAX_ERROR_PRINTOUT:\n+                        graph_diff_errors += '<reached max number of differing nodes to print>'\n+                        break\n+                    if str(n_mod) != str(n_check):\n+                        node_diff = difflib.ndiff(str(n_mod).splitlines(1),\n+                                                  str(n_check).splitlines(1))\n+                        source_printout = 'Node diff:\\n' + indent(''.join(node_diff)) + '\\n'\n+                        source_printout += 'Trace source location:\\n' + indent(n_mod.sourceLocation()) + '\\n'\n+                        source_printout += 'Check source location:\\n' + indent(n_check.sourceLocation()) + '\\n'\n+                        graph_diff_errors += source_printout\n+                        num_errors += 1\n+\n+            tensor_compare_errors = None\n+            # Check Tensor-valued constant nodes\n+            for n_mod, n_check in zip(mod_canonicalized.nodes(), check_canonicalized.nodes()):\n+                if n_mod.kind() == n_check.kind() and n_mod.kind() == 'prim::Constant':\n+                    try:\n+                        mod_tensor_val = n_mod.t('value')\n+                        check_tensor_val = n_check.t('value')\n+                    except RuntimeError:", "path": "torch/jit/__init__.py", "position": null, "original_position": 78, "commit_id": "dc008cc6bf20f723ea9b9f4e419e039aec3224d7", "original_commit_id": "dd7bd71c4f7272b568d007a717477da7c86f5b0a", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "You can also check the output type of constant node. If it is a tensor type then it will have an attribute t.", "created_at": "2018-08-27T21:46:01Z", "updated_at": "2018-11-23T15:50:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/10841#discussion_r213126258", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10841", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213126258"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10841#discussion_r213126258"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10841"}}, "body_html": "<p>You can also check the output type of constant node. If it is a tensor type then it will have an attribute t.</p>", "body_text": "You can also check the output type of constant node. If it is a tensor type then it will have an attribute t.", "in_reply_to_id": 213094301}