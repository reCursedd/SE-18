{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10841", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10841/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10841/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10841/events", "html_url": "https://github.com/pytorch/pytorch/pull/10841", "id": 353599910, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEwNjA5MTk5", "number": 10841, "title": "[JIT][tracer] Sanity checks for tracing", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-24T00:21:02Z", "updated_at": "2018-11-23T15:50:13Z", "closed_at": "2018-08-29T03:26:28Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10841", "html_url": "https://github.com/pytorch/pytorch/pull/10841", "diff_url": "https://github.com/pytorch/pytorch/pull/10841.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10841.patch"}, "body_html": "<p>TODO: integrate into torch.onnx.export -- separate PR</p>\n<p><em>Problem:</em> We have a facility to trace PyTorch operations on Python code, but there are several failure modes where the trace is not representative of the actual underlying computation:</p>\n<ul>\n<li>The tracer encountered dynamic control flow</li>\n<li>Some computation escaped the tracer, and appeared as a Constant tensor node in the graph</li>\n<li>Some stateful function was traced, e.g. someone did an optimization in Python by memoizing function outputs</li>\n</ul>\n<p><em>Objective</em>: In an ideal world, this whole process would be automated and the user can trust that the system will magically capture the intended semantics from the program. Realistically speaking, we will likely have to settle with a human-in-the-loop error reporting system, allowing for the user to identify problems and modify the source code to allow for tracing.</p>\n<p><em>Stage 1</em> (this PR): Output-level checking &amp; graph diff. torch.jit.trace gains a kwarg 'check_inputs', which is a list of tuples of input arguments. We will iterate through the list and trace the function again for each set of check inputs. We'll also interpret the original trace with these inputs and compare output values and graphs, printing a diff of the graph if there is a difference.</p>\n<p>Examples:</p>\n<pre><code>@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 5),)])\ndef foo(x):\n    y = torch.arange(0, x.shape[0]).float()\n    return x + y.unsqueeze(1)\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t-   %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\t\t?                                                              ^\n\t\t+   %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\n\t\t?                                                +++              ^\n\t\t    %2 : int = prim::Constant[value=0]()\n\t\t    %3 : Dynamic = aten::_cast_Float(%1, %2)\n\t\t    %4 : int = prim::Constant[value=1]()\n\t\t    %5 : Dynamic = aten::unsqueeze(%3, %4)\n\t\t    %6 : int = prim::Constant[value=1]()\n\t\t    %7 : Dynamic = aten::add(%0, %5, %6)\n\t\t    return (%7);\n\t\t  }\n\tNode diff:\n\t\t- %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\t\t?                                                            ^\n\t\t+ %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\n\t\t?                                              +++              ^\n\tTrace source location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): &lt;module&gt;\n\tCheck source location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\n\t\tdank.py(3): &lt;module&gt;\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\tSource Location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): &lt;module&gt;\n\tComparison exception:\n\t\tNot equal to tolerance rtol=1e-07, atol=0\n\n\t\t(shapes (3,), (4,) mismatch)\n\t\t x: array([0, 1, 2])\n\t\t y: array([0, 1, 2, 3])\n\n</code></pre>\n<p>==</p>\n<pre><code>@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\ndef foo(x):\n    y = x.data\n    return x + y\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%1 : Dynamic = prim::Constant[value=&lt;Tensor&gt;]()\n\tSource Location:\n\t\tdank.py(6): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): &lt;module&gt;\n\tComparison exception:\n\t\tNot equal to tolerance rtol=1e-07, atol=0\n\n\t\t(mismatch 100.0%)\n\t\t x: array([0.397137, 0.956105, 0.169478, 0.560292, 0.392568, 0.108441,\n\t\t       0.97645 , 0.34412 , 0.951246, 0.793061, 0.557595, 0.770245],\n\t\t      dtype=float32)\n\t\t y: array([0.243178, 0.315964, 0.972041, 0.0215  , 0.927751, 0.457512,\n\t\t       0.951092, 0.97883 , 0.048688, 0.118066, 0.779345, 0.271272],\n\t\t      dtype=float32)\n</code></pre>\n<p>==</p>\n<pre><code>import torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 4),)])\ndef foo(x):\n    for _ in range(x.size(0)):\n        x = torch.neg(x)\n    return x\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t    %1 : Dynamic = aten::neg(%0)\n\t\t    %2 : Dynamic = aten::neg(%1)\n\t\t    %3 : Dynamic = aten::neg(%2)\n\t\t+   %4 : Dynamic = aten::neg(%3)\n\t\t-   return (%3);\n\t\t?            ^\n\t\t+   return (%4);\n\t\t?            ^\n\t\t  }\n</code></pre>\n<p>==</p>\n<pre><code>import torch\n\ndef foo(x):\n    if not hasattr(foo, 'cache'):\n        foo.cache = torch.neg(x)\n    return x + foo.cache\n\ntraced = torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])(foo)\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t-   %1 : Dynamic = aten::neg(%0)\n\t\t+   %1 : Dynamic = prim::Constant[value=&lt;Tensor&gt;]()\n\t\t    %2 : int = prim::Constant[value=1]()\n\t\t    %3 : Dynamic = aten::add(%0, %1, %2)\n\t\t    return (%3);\n\t\t  }\n\tNode diff:\n\t\t- %1 : Dynamic = aten::neg(%0)\n\t\t+ %1 : Dynamic = prim::Constant[value=&lt;Tensor&gt;]()\n\tTrace source location:\n\t\ttest.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\ttest.py(8): &lt;module&gt;\n\tCheck source location:\n\t\ttest.py(6): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\n\t\ttest.py(8): &lt;module&gt;\n</code></pre>\n<p>The following two examples show instances where program semantics are lost in the Python -&gt; trace transformation, and repeated invocation does not give us useful debug information. Further design in underway for catching these scenarios.</p>\n<pre><code>import torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\ndef foo(x):\n    for i in range(3):\n        x[i, :] = torch.zeros(4)\n    return x\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nException:\nNot equal to tolerance rtol=1e-07, atol=0\n\n(mismatch 100.0%)\n x: array([0.830221, 0.915481, 0.940281, 0.555241], dtype=float32)\n y: array([0., 0., 0., 0.], dtype=float32)\n</code></pre>\n<p>==</p>\n<pre><code>import torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(5, 6),)])\ndef foo(x):\n    x.view(-1).add_(-x.view(-1))\n    return x\n</code></pre>\n<pre><code>torch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nException:\nNot equal to tolerance rtol=1e-07, atol=0\n\n(mismatch 100.0%)\n x: array([0.734441, 0.445327, 0.640592, 0.30076 , 0.891674, 0.124771],\n      dtype=float32)\n y: array([0., 0., 0., 0., 0., 0.], dtype=float32)\n</code></pre>", "body_text": "TODO: integrate into torch.onnx.export -- separate PR\nProblem: We have a facility to trace PyTorch operations on Python code, but there are several failure modes where the trace is not representative of the actual underlying computation:\n\nThe tracer encountered dynamic control flow\nSome computation escaped the tracer, and appeared as a Constant tensor node in the graph\nSome stateful function was traced, e.g. someone did an optimization in Python by memoizing function outputs\n\nObjective: In an ideal world, this whole process would be automated and the user can trust that the system will magically capture the intended semantics from the program. Realistically speaking, we will likely have to settle with a human-in-the-loop error reporting system, allowing for the user to identify problems and modify the source code to allow for tracing.\nStage 1 (this PR): Output-level checking & graph diff. torch.jit.trace gains a kwarg 'check_inputs', which is a list of tuples of input arguments. We will iterate through the list and trace the function again for each set of check inputs. We'll also interpret the original trace with these inputs and compare output values and graphs, printing a diff of the graph if there is a difference.\nExamples:\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 5),)])\ndef foo(x):\n    y = torch.arange(0, x.shape[0]).float()\n    return x + y.unsqueeze(1)\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t-   %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\t\t?                                                              ^\n\t\t+   %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\n\t\t?                                                +++              ^\n\t\t    %2 : int = prim::Constant[value=0]()\n\t\t    %3 : Dynamic = aten::_cast_Float(%1, %2)\n\t\t    %4 : int = prim::Constant[value=1]()\n\t\t    %5 : Dynamic = aten::unsqueeze(%3, %4)\n\t\t    %6 : int = prim::Constant[value=1]()\n\t\t    %7 : Dynamic = aten::add(%0, %5, %6)\n\t\t    return (%7);\n\t\t  }\n\tNode diff:\n\t\t- %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\t\t?                                                            ^\n\t\t+ %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\n\t\t?                                              +++              ^\n\tTrace source location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): <module>\n\tCheck source location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\n\t\tdank.py(3): <module>\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\n\tSource Location:\n\t\tdank.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): <module>\n\tComparison exception:\n\t\tNot equal to tolerance rtol=1e-07, atol=0\n\n\t\t(shapes (3,), (4,) mismatch)\n\t\t x: array([0, 1, 2])\n\t\t y: array([0, 1, 2, 3])\n\n\n==\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\ndef foo(x):\n    y = x.data\n    return x + y\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%1 : Dynamic = prim::Constant[value=<Tensor>]()\n\tSource Location:\n\t\tdank.py(6): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\tdank.py(3): <module>\n\tComparison exception:\n\t\tNot equal to tolerance rtol=1e-07, atol=0\n\n\t\t(mismatch 100.0%)\n\t\t x: array([0.397137, 0.956105, 0.169478, 0.560292, 0.392568, 0.108441,\n\t\t       0.97645 , 0.34412 , 0.951246, 0.793061, 0.557595, 0.770245],\n\t\t      dtype=float32)\n\t\t y: array([0.243178, 0.315964, 0.972041, 0.0215  , 0.927751, 0.457512,\n\t\t       0.951092, 0.97883 , 0.048688, 0.118066, 0.779345, 0.271272],\n\t\t      dtype=float32)\n\n==\nimport torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 4),)])\ndef foo(x):\n    for _ in range(x.size(0)):\n        x = torch.neg(x)\n    return x\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t    %1 : Dynamic = aten::neg(%0)\n\t\t    %2 : Dynamic = aten::neg(%1)\n\t\t    %3 : Dynamic = aten::neg(%2)\n\t\t+   %4 : Dynamic = aten::neg(%3)\n\t\t-   return (%3);\n\t\t?            ^\n\t\t+   return (%4);\n\t\t?            ^\n\t\t  }\n\n==\nimport torch\n\ndef foo(x):\n    if not hasattr(foo, 'cache'):\n        foo.cache = torch.neg(x)\n    return x + foo.cache\n\ntraced = torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])(foo)\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%0 : Dynamic) {\n\t\t-   %1 : Dynamic = aten::neg(%0)\n\t\t+   %1 : Dynamic = prim::Constant[value=<Tensor>]()\n\t\t    %2 : int = prim::Constant[value=1]()\n\t\t    %3 : Dynamic = aten::add(%0, %1, %2)\n\t\t    return (%3);\n\t\t  }\n\tNode diff:\n\t\t- %1 : Dynamic = aten::neg(%0)\n\t\t+ %1 : Dynamic = prim::Constant[value=<Tensor>]()\n\tTrace source location:\n\t\ttest.py(5): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\n\t\ttest.py(8): <module>\n\tCheck source location:\n\t\ttest.py(6): foo\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\n\t\ttest.py(8): <module>\n\nThe following two examples show instances where program semantics are lost in the Python -> trace transformation, and repeated invocation does not give us useful debug information. Further design in underway for catching these scenarios.\nimport torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\ndef foo(x):\n    for i in range(3):\n        x[i, :] = torch.zeros(4)\n    return x\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nException:\nNot equal to tolerance rtol=1e-07, atol=0\n\n(mismatch 100.0%)\n x: array([0.830221, 0.915481, 0.940281, 0.555241], dtype=float32)\n y: array([0., 0., 0., 0.], dtype=float32)\n\n==\nimport torch\n\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(5, 6),)])\ndef foo(x):\n    x.view(-1).add_(-x.view(-1))\n    return x\n\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\nERROR: Traced function outputs do not match the Python function outputs.\nException:\nNot equal to tolerance rtol=1e-07, atol=0\n\n(mismatch 100.0%)\n x: array([0.734441, 0.445327, 0.640592, 0.30076 , 0.891674, 0.124771],\n      dtype=float32)\n y: array([0., 0., 0., 0., 0., 0.], dtype=float32)", "body": "TODO: integrate into torch.onnx.export -- separate PR\r\n\r\n*Problem:* We have a facility to trace PyTorch operations on Python code, but there are several failure modes where the trace is not representative of the actual underlying computation:\r\n\r\n* The tracer encountered dynamic control flow\r\n* Some computation escaped the tracer, and appeared as a Constant tensor node in the graph\r\n* Some stateful function was traced, e.g. someone did an optimization in Python by memoizing function outputs\r\n\r\n*Objective*: In an ideal world, this whole process would be automated and the user can trust that the system will magically capture the intended semantics from the program. Realistically speaking, we will likely have to settle with a human-in-the-loop error reporting system, allowing for the user to identify problems and modify the source code to allow for tracing.\r\n\r\n*Stage 1* (this PR): Output-level checking & graph diff. torch.jit.trace gains a kwarg 'check_inputs', which is a list of tuples of input arguments. We will iterate through the list and trace the function again for each set of check inputs. We'll also interpret the original trace with these inputs and compare output values and graphs, printing a diff of the graph if there is a difference.\r\n\r\n\r\nExamples:\r\n\r\n```\r\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 5),)])\r\ndef foo(x):\r\n    y = torch.arange(0, x.shape[0]).float()\r\n    return x + y.unsqueeze(1)\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Graphs differed across invocations!\r\n\tGraph diff:\r\n\t\t  graph(%0 : Dynamic) {\r\n\t\t-   %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\r\n\t\t?                                                              ^\r\n\t\t+   %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\r\n\t\t?                                                +++              ^\r\n\t\t    %2 : int = prim::Constant[value=0]()\r\n\t\t    %3 : Dynamic = aten::_cast_Float(%1, %2)\r\n\t\t    %4 : int = prim::Constant[value=1]()\r\n\t\t    %5 : Dynamic = aten::unsqueeze(%3, %4)\r\n\t\t    %6 : int = prim::Constant[value=1]()\r\n\t\t    %7 : Dynamic = aten::add(%0, %5, %6)\r\n\t\t    return (%7);\r\n\t\t  }\r\n\tNode diff:\r\n\t\t- %1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\r\n\t\t?                                                            ^\r\n\t\t+ %1 : Dynamic = prim::Constant[value= 0  1  2  3 [ CPULongType{4} ]]()\r\n\t\t?                                              +++              ^\r\n\tTrace source location:\r\n\t\tdank.py(5): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\r\n\t\tdank.py(3): <module>\r\n\tCheck source location:\r\n\t\tdank.py(5): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\r\n\t\tdank.py(3): <module>\r\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\r\n\tNode:\r\n\t\t%1 : Dynamic = prim::Constant[value= 0  1  2 [ CPULongType{3} ]]()\r\n\tSource Location:\r\n\t\tdank.py(5): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\r\n\t\tdank.py(3): <module>\r\n\tComparison exception:\r\n\t\tNot equal to tolerance rtol=1e-07, atol=0\r\n\r\n\t\t(shapes (3,), (4,) mismatch)\r\n\t\t x: array([0, 1, 2])\r\n\t\t y: array([0, 1, 2, 3])\r\n\r\n```\r\n==\r\n\r\n```\r\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\r\ndef foo(x):\r\n    y = x.data\r\n    return x + y\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Traced function outputs do not match the Python function outputs.\r\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\r\n\tNode:\r\n\t\t%1 : Dynamic = prim::Constant[value=<Tensor>]()\r\n\tSource Location:\r\n\t\tdank.py(6): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\r\n\t\tdank.py(3): <module>\r\n\tComparison exception:\r\n\t\tNot equal to tolerance rtol=1e-07, atol=0\r\n\r\n\t\t(mismatch 100.0%)\r\n\t\t x: array([0.397137, 0.956105, 0.169478, 0.560292, 0.392568, 0.108441,\r\n\t\t       0.97645 , 0.34412 , 0.951246, 0.793061, 0.557595, 0.770245],\r\n\t\t      dtype=float32)\r\n\t\t y: array([0.243178, 0.315964, 0.972041, 0.0215  , 0.927751, 0.457512,\r\n\t\t       0.951092, 0.97883 , 0.048688, 0.118066, 0.779345, 0.271272],\r\n\t\t      dtype=float32)\r\n```\r\n\r\n==\r\n\r\n```\r\nimport torch\r\n\r\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(4, 4),)])\r\ndef foo(x):\r\n    for _ in range(x.size(0)):\r\n        x = torch.neg(x)\r\n    return x\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Traced function outputs do not match the Python function outputs.\r\nERROR: Graphs differed across invocations!\r\n\tGraph diff:\r\n\t\t  graph(%0 : Dynamic) {\r\n\t\t    %1 : Dynamic = aten::neg(%0)\r\n\t\t    %2 : Dynamic = aten::neg(%1)\r\n\t\t    %3 : Dynamic = aten::neg(%2)\r\n\t\t+   %4 : Dynamic = aten::neg(%3)\r\n\t\t-   return (%3);\r\n\t\t?            ^\r\n\t\t+   return (%4);\r\n\t\t?            ^\r\n\t\t  }\r\n```\r\n\r\n==\r\n\r\n```\r\nimport torch\r\n\r\ndef foo(x):\r\n    if not hasattr(foo, 'cache'):\r\n        foo.cache = torch.neg(x)\r\n    return x + foo.cache\r\n\r\ntraced = torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])(foo)\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Traced function outputs do not match the Python function outputs.\r\nERROR: Graphs differed across invocations!\r\n\tGraph diff:\r\n\t\t  graph(%0 : Dynamic) {\r\n\t\t-   %1 : Dynamic = aten::neg(%0)\r\n\t\t+   %1 : Dynamic = prim::Constant[value=<Tensor>]()\r\n\t\t    %2 : int = prim::Constant[value=1]()\r\n\t\t    %3 : Dynamic = aten::add(%0, %1, %2)\r\n\t\t    return (%3);\r\n\t\t  }\r\n\tNode diff:\r\n\t\t- %1 : Dynamic = aten::neg(%0)\r\n\t\t+ %1 : Dynamic = prim::Constant[value=<Tensor>]()\r\n\tTrace source location:\r\n\t\ttest.py(5): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(402): wrapper\r\n\t\ttest.py(8): <module>\r\n\tCheck source location:\r\n\t\ttest.py(6): foo\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(281): check_trace\r\n\t\t/Users/jamesreed/onnx-fairseq/pytorch/torch/jit/__init__.py(408): wrapper\r\n\t\ttest.py(8): <module>\r\n```\r\n\r\nThe following two examples show instances where program semantics are lost in the Python -> trace transformation, and repeated invocation does not give us useful debug information. Further design in underway for catching these scenarios.\r\n\r\n```\r\nimport torch\r\n\r\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(3, 4),)])\r\ndef foo(x):\r\n    for i in range(3):\r\n        x[i, :] = torch.zeros(4)\r\n    return x\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Traced function outputs do not match the Python function outputs.\r\nException:\r\nNot equal to tolerance rtol=1e-07, atol=0\r\n\r\n(mismatch 100.0%)\r\n x: array([0.830221, 0.915481, 0.940281, 0.555241], dtype=float32)\r\n y: array([0., 0., 0., 0.], dtype=float32)\r\n```\r\n\r\n==\r\n\r\n```\r\nimport torch\r\n\r\n@torch.jit.trace(torch.rand(3, 4), check_inputs=[(torch.rand(5, 6),)])\r\ndef foo(x):\r\n    x.view(-1).add_(-x.view(-1))\r\n    return x\r\n```\r\n\r\n```\r\ntorch.jit.TracingCheckError: Tracing failed sanity checks!\r\nERROR: Traced function outputs do not match the Python function outputs.\r\nException:\r\nNot equal to tolerance rtol=1e-07, atol=0\r\n\r\n(mismatch 100.0%)\r\n x: array([0.734441, 0.445327, 0.640592, 0.30076 , 0.891674, 0.124771],\r\n      dtype=float32)\r\n y: array([0., 0., 0., 0., 0., 0.], dtype=float32)\r\n```\r\n"}