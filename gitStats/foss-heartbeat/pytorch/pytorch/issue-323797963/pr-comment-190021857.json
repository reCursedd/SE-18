{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/190021857", "pull_request_review_id": 122314613, "id": 190021857, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MDAyMTg1Nw==", "diff_hunk": "@@ -0,0 +1,224 @@\n+#pragma once\n+\n+#include <condition_variable>\n+#include <deque>\n+#include <mutex>\n+#include <thread>\n+#include <unordered_map>\n+#include <vector>\n+\n+#include <gloo/algorithm.h>\n+#include <gloo/common/error.h>\n+#include <gloo/context.h>\n+#include <gloo/rendezvous/store.h>\n+#include <gloo/transport/device.h>\n+\n+#include \"ProcessGroup.hpp\"\n+#include \"Store.hpp\"\n+#include \"Types.hpp\"\n+#include \"Utils.hpp\"\n+\n+namespace c10d {\n+\n+// AlgorithmKey is a const identifier for a Gloo algorithm.\n+//\n+// It captures the set of participating devices, the source device,\n+// destination device, source rank, destination rank, reduction type\n+// (if applicable), etcetera. This key is used to cache instances of a\n+// Gloo algorithm for reuse. The number of cached instances can vary\n+// over time and is agreed upon between all processes in the group.\n+//\n+// When we're dealing with multiple entries per key, it is also used\n+// to broadcast the number of entries such that all processes agree.\n+//\n+struct AlgorithmKey {\n+  bool operator==(const AlgorithmKey& other) const {\n+    return (collectiveType == other.collectiveType) && (type == other.type) &&\n+        (devices == other.devices) && (srcSizes == other.srcSizes) &&\n+        (dstSizes == other.dstSizes) && (srcRank == other.srcRank) &&\n+        (dstRank == other.dstRank) && (srcTensor == other.srcTensor) &&\n+        (dstTensor == other.dstTensor) && (reduceOp == other.reduceOp);\n+  }\n+\n+  CollectiveType collectiveType = CollectiveType::UNUSED;\n+  at::Type* type = nullptr;\n+  std::vector<int> devices;\n+  std::vector<std::vector<int64_t>> srcSizes;\n+  std::vector<std::vector<int64_t>> dstSizes;\n+  int srcRank = -1;\n+  int dstRank = -1;\n+  int srcTensor = -1;\n+  int dstTensor = -1;\n+  ReduceOp reduceOp = ReduceOp::UNUSED;\n+};\n+\n+// AlgorithmEntry is the state associated with a single algorithm instance.\n+//\n+// Keeping Gloo algorithms around for reuse is a win, since most of\n+// them end up allocating some memory, constructing them takes some\n+// time, and they may do some I/O (to setup communication buffers\n+// between processes). Also, until it supports executing on arbitrary\n+// memory, we need to hold on to memory that we instantiated the\n+// algorithm with. The lifecycle of memory in ATen is arbitrary, so to\n+// do caching, this entry holds on to memory that we copy to/from.\n+//\n+// Every unique call (in terms of number of tensors, tensor types,\n+// tensor sizes, etc.) gets its own entry. In the future we may extend\n+// this to allow multiple entries per unique call, to better exploit\n+// parallelism for calls with the same signature.\n+//\n+struct AlgorithmEntry {\n+  AlgorithmKey key;\n+  std::unique_ptr<::gloo::Algorithm> algorithm;\n+  std::vector<at::Tensor> src;\n+  std::vector<at::Tensor> dst;\n+  std::function<void(std::unique_ptr<AlgorithmEntry>&)> run;\n+\n+  AlgorithmEntry() {}\n+\n+  // Must not be copyable\n+  AlgorithmEntry& operator=(const AlgorithmEntry&) = delete;\n+  AlgorithmEntry(const AlgorithmEntry&) = delete;\n+};\n+\n+} // namespace c10d\n+\n+MAKE_HASHABLE(\n+    ::c10d::AlgorithmKey,\n+    t.collectiveType,\n+    t.type,\n+    t.devices,\n+    t.srcSizes,\n+    t.dstSizes,\n+    t.srcRank,\n+    t.dstRank,\n+    t.srcTensor,\n+    t.dstTensor,\n+    t.reduceOp);\n+\n+namespace c10d {\n+\n+// ProcessGroupGloo implements Gloo bindings for c10d.\n+//\n+// All functions on this class are expected to be called in the same\n+// order across processes in the group. This is the only way that we\n+// can guarantee to match up the same calls across processes. For\n+// multi-threaded usage of process groups, you can use consider using\n+// multiple process group instances.\n+//\n+// The Gloo algorithms that this class calls into are cached by their\n+// signature (see description of AlgorithmKey above). This cache works\n+// as follows: every function call instantiates an AlgorithmKey and\n+// looks in the cache for existing entries. If there is one, it is\n+// removed from the cache and returned to the caller. If there are\n+// none, a new entry is created and returned. If an entry was created\n+// before, but is still in use, the call will block and wait until the\n+// entry is returned to the cache.\n+//\n+// In the future, we hope to extend this to allow multiple entries per\n+// key, to enable parallelism for a single key. The number of entries\n+// per key must always be identical for all processes. This maximum\n+// number can be automatically tuned, but only if we let a single\n+// process take charge, and have it broadcast the limits.\n+//\n+class ProcessGroupGloo : public ProcessGroup {\n+ public:\n+  class WorkGloo : public ProcessGroup::Work {\n+   public:\n+    explicit WorkGloo();\n+    virtual ~WorkGloo();\n+\n+    // Checks if request has completed. Non-blocking operation.\n+    bool isCompleted() const override;\n+\n+    // Waits until request completes. Blocking operation.\n+    // Returns false if the work completed with an exception.\n+    bool wait() override;\n+\n+    // Returns exception if wait() returned false.\n+    const std::exception& exception() const override;\n+\n+   protected:\n+    void finish();\n+    void finishWithException(const ::gloo::Exception& ex);\n+\n+    std::mutex m_;\n+    std::condition_variable cv_;\n+    std::atomic<bool> completed_;\n+\n+    // Use pointer to ::gloo::Exception because it doesn't have a\n+    // default constructor and constructing an empty std::unique_ptr\n+    // is probably cheaper (this is highly speculative).\n+    std::unique_ptr<::gloo::Exception> ex_;\n+\n+    friend class ProcessGroupGloo;\n+  };\n+\n+  struct Options {\n+    explicit Options();\n+\n+    std::vector<std::shared_ptr<::gloo::transport::Device>> devices;\n+    std::chrono::milliseconds timeout;\n+    int threads;\n+  };\n+\n+  explicit ProcessGroupGloo(\n+      const std::shared_ptr<Store>& store,\n+      int rank,\n+      int size);\n+\n+  virtual ~ProcessGroupGloo();\n+\n+  void initialize();\n+\n+  void initialize(Options& options);", "path": "torch/lib/c10d/ProcessGroupGloo.hpp", "position": null, "original_position": 174, "commit_id": "f81bd359f6b3550c6c311ff39b58bf62535e43cc", "original_commit_id": "9eae42435952a9e0c723aff63234ca783460d467", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "body": "Alright, I'm changing to init on construct and destroy on destruct.\r\n\r\nCan change again when we get bitten by it. For now it might be fine. Having control over destruction is good since then you decide when it happens, as opposed to some random object being destroying implying the process group goes away.", "created_at": "2018-05-22T19:18:27Z", "updated_at": "2018-11-23T15:44:31Z", "html_url": "https://github.com/pytorch/pytorch/pull/7628#discussion_r190021857", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7628", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/190021857"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7628#discussion_r190021857"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7628"}}, "body_html": "<p>Alright, I'm changing to init on construct and destroy on destruct.</p>\n<p>Can change again when we get bitten by it. For now it might be fine. Having control over destruction is good since then you decide when it happens, as opposed to some random object being destroying implying the process group goes away.</p>", "body_text": "Alright, I'm changing to init on construct and destroy on destruct.\nCan change again when we get bitten by it. For now it might be fine. Having control over destruction is good since then you decide when it happens, as opposed to some random object being destroying implying the process group goes away.", "in_reply_to_id": 189441263}