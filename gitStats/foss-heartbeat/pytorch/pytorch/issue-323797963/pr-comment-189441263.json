{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189441263", "pull_request_review_id": 121625607, "id": 189441263, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTQ0MTI2Mw==", "diff_hunk": "@@ -0,0 +1,224 @@\n+#pragma once\n+\n+#include <condition_variable>\n+#include <deque>\n+#include <mutex>\n+#include <thread>\n+#include <unordered_map>\n+#include <vector>\n+\n+#include <gloo/algorithm.h>\n+#include <gloo/common/error.h>\n+#include <gloo/context.h>\n+#include <gloo/rendezvous/store.h>\n+#include <gloo/transport/device.h>\n+\n+#include \"ProcessGroup.hpp\"\n+#include \"Store.hpp\"\n+#include \"Types.hpp\"\n+#include \"Utils.hpp\"\n+\n+namespace c10d {\n+\n+// AlgorithmKey is a const identifier for a Gloo algorithm.\n+//\n+// It captures the set of participating devices, the source device,\n+// destination device, source rank, destination rank, reduction type\n+// (if applicable), etcetera. This key is used to cache instances of a\n+// Gloo algorithm for reuse. The number of cached instances can vary\n+// over time and is agreed upon between all processes in the group.\n+//\n+// When we're dealing with multiple entries per key, it is also used\n+// to broadcast the number of entries such that all processes agree.\n+//\n+struct AlgorithmKey {\n+  bool operator==(const AlgorithmKey& other) const {\n+    return (collectiveType == other.collectiveType) && (type == other.type) &&\n+        (devices == other.devices) && (srcSizes == other.srcSizes) &&\n+        (dstSizes == other.dstSizes) && (srcRank == other.srcRank) &&\n+        (dstRank == other.dstRank) && (srcTensor == other.srcTensor) &&\n+        (dstTensor == other.dstTensor) && (reduceOp == other.reduceOp);\n+  }\n+\n+  CollectiveType collectiveType = CollectiveType::UNUSED;\n+  at::Type* type = nullptr;\n+  std::vector<int> devices;\n+  std::vector<std::vector<int64_t>> srcSizes;\n+  std::vector<std::vector<int64_t>> dstSizes;\n+  int srcRank = -1;\n+  int dstRank = -1;\n+  int srcTensor = -1;\n+  int dstTensor = -1;\n+  ReduceOp reduceOp = ReduceOp::UNUSED;\n+};\n+\n+// AlgorithmEntry is the state associated with a single algorithm instance.\n+//\n+// Keeping Gloo algorithms around for reuse is a win, since most of\n+// them end up allocating some memory, constructing them takes some\n+// time, and they may do some I/O (to setup communication buffers\n+// between processes). Also, until it supports executing on arbitrary\n+// memory, we need to hold on to memory that we instantiated the\n+// algorithm with. The lifecycle of memory in ATen is arbitrary, so to\n+// do caching, this entry holds on to memory that we copy to/from.\n+//\n+// Every unique call (in terms of number of tensors, tensor types,\n+// tensor sizes, etc.) gets its own entry. In the future we may extend\n+// this to allow multiple entries per unique call, to better exploit\n+// parallelism for calls with the same signature.\n+//\n+struct AlgorithmEntry {\n+  AlgorithmKey key;\n+  std::unique_ptr<::gloo::Algorithm> algorithm;\n+  std::vector<at::Tensor> src;\n+  std::vector<at::Tensor> dst;\n+  std::function<void(std::unique_ptr<AlgorithmEntry>&)> run;\n+\n+  AlgorithmEntry() {}\n+\n+  // Must not be copyable\n+  AlgorithmEntry& operator=(const AlgorithmEntry&) = delete;\n+  AlgorithmEntry(const AlgorithmEntry&) = delete;\n+};\n+\n+} // namespace c10d\n+\n+MAKE_HASHABLE(\n+    ::c10d::AlgorithmKey,\n+    t.collectiveType,\n+    t.type,\n+    t.devices,\n+    t.srcSizes,\n+    t.dstSizes,\n+    t.srcRank,\n+    t.dstRank,\n+    t.srcTensor,\n+    t.dstTensor,\n+    t.reduceOp);\n+\n+namespace c10d {\n+\n+// ProcessGroupGloo implements Gloo bindings for c10d.\n+//\n+// All functions on this class are expected to be called in the same\n+// order across processes in the group. This is the only way that we\n+// can guarantee to match up the same calls across processes. For\n+// multi-threaded usage of process groups, you can use consider using\n+// multiple process group instances.\n+//\n+// The Gloo algorithms that this class calls into are cached by their\n+// signature (see description of AlgorithmKey above). This cache works\n+// as follows: every function call instantiates an AlgorithmKey and\n+// looks in the cache for existing entries. If there is one, it is\n+// removed from the cache and returned to the caller. If there are\n+// none, a new entry is created and returned. If an entry was created\n+// before, but is still in use, the call will block and wait until the\n+// entry is returned to the cache.\n+//\n+// In the future, we hope to extend this to allow multiple entries per\n+// key, to enable parallelism for a single key. The number of entries\n+// per key must always be identical for all processes. This maximum\n+// number can be automatically tuned, but only if we let a single\n+// process take charge, and have it broadcast the limits.\n+//\n+class ProcessGroupGloo : public ProcessGroup {\n+ public:\n+  class WorkGloo : public ProcessGroup::Work {\n+   public:\n+    explicit WorkGloo();\n+    virtual ~WorkGloo();\n+\n+    // Checks if request has completed. Non-blocking operation.\n+    bool isCompleted() const override;\n+\n+    // Waits until request completes. Blocking operation.\n+    // Returns false if the work completed with an exception.\n+    bool wait() override;\n+\n+    // Returns exception if wait() returned false.\n+    const std::exception& exception() const override;\n+\n+   protected:\n+    void finish();\n+    void finishWithException(const ::gloo::Exception& ex);\n+\n+    std::mutex m_;\n+    std::condition_variable cv_;\n+    std::atomic<bool> completed_;\n+\n+    // Use pointer to ::gloo::Exception because it doesn't have a\n+    // default constructor and constructing an empty std::unique_ptr\n+    // is probably cheaper (this is highly speculative).\n+    std::unique_ptr<::gloo::Exception> ex_;\n+\n+    friend class ProcessGroupGloo;\n+  };\n+\n+  struct Options {\n+    explicit Options();\n+\n+    std::vector<std::shared_ptr<::gloo::transport::Device>> devices;\n+    std::chrono::milliseconds timeout;\n+    int threads;\n+  };\n+\n+  explicit ProcessGroupGloo(\n+      const std::shared_ptr<Store>& store,\n+      int rank,\n+      int size);\n+\n+  virtual ~ProcessGroupGloo();\n+\n+  void initialize();\n+\n+  void initialize(Options& options);", "path": "torch/lib/c10d/ProcessGroupGloo.hpp", "position": null, "original_position": 174, "commit_id": "f81bd359f6b3550c6c311ff39b58bf62535e43cc", "original_commit_id": "9eae42435952a9e0c723aff63234ca783460d467", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "What's the reason to separate initialization from construction?", "created_at": "2018-05-19T18:18:45Z", "updated_at": "2018-11-23T15:44:20Z", "html_url": "https://github.com/pytorch/pytorch/pull/7628#discussion_r189441263", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7628", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189441263"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7628#discussion_r189441263"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7628"}}, "body_html": "<p>What's the reason to separate initialization from construction?</p>", "body_text": "What's the reason to separate initialization from construction?"}