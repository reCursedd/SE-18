{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189014628", "pull_request_review_id": 121110814, "id": 189014628, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTAxNDYyOA==", "diff_hunk": "@@ -0,0 +1,184 @@\n+#pragma once\n+\n+#include <condition_variable>\n+#include <deque>\n+#include <mutex>\n+#include <thread>\n+#include <unordered_map>\n+#include <vector>\n+\n+#include <gloo/algorithm.h>\n+#include <gloo/common/error.h>\n+#include <gloo/context.h>\n+#include <gloo/rendezvous/store.h>\n+#include <gloo/transport/device.h>\n+\n+#include \"ProcessGroup.hpp\"\n+#include \"Store.hpp\"\n+#include \"Types.hpp\"\n+#include \"Utils.hpp\"\n+\n+namespace c10d {\n+\n+// AlgorithmKey is a const identifier for a Gloo algorithm.\n+//\n+// It captures the set of participating devices, the source device,\n+// destination device, source rank, destination rank, reduction type\n+// (if applicable), etcetera. This key is used to cache instances of a\n+// Gloo algorithm for reuse. The number of cached instances can vary\n+// over time and is agreed upon between all processes in the group. It\n+// is also used in identifying the algorithm type for which to change\n+// the maximum alotted number of instances.\n+//\n+struct AlgorithmKey {\n+  bool operator==(const AlgorithmKey &other) const {\n+    return\n+      (collectiveType == other.collectiveType) &&\n+      (type == other.type) &&\n+      (devices == other.devices) &&\n+      (srcSizes == other.srcSizes) &&\n+      (dstSizes == other.dstSizes) &&\n+      (srcDevice == other.srcDevice) &&\n+      (dstDevice == other.dstDevice) &&\n+      (srcRank == other.srcRank) &&\n+      (dstRank == other.dstRank) &&\n+      (reduceOp == other.reduceOp);\n+  }\n+\n+  CollectiveType collectiveType = CollectiveType::UNUSED;\n+  at::Type* type = nullptr;\n+  std::vector<int> devices;\n+  std::vector<std::vector<int64_t>> srcSizes;\n+  std::vector<std::vector<int64_t>> dstSizes;\n+  int srcDevice = -1;\n+  int dstDevice = -1;\n+  int srcRank = -1;\n+  int dstRank = -1;\n+  ReduceOp reduceOp = ReduceOp::UNUSED;\n+};\n+\n+struct AlgorithmEntry {\n+  AlgorithmKey key;\n+  std::unique_ptr<::gloo::Algorithm> algorithm;\n+  std::vector<at::Tensor> src;\n+  std::vector<at::Tensor> dst;\n+  std::function<void(std::unique_ptr<AlgorithmEntry>&)> run;\n+\n+  explicit AlgorithmEntry() {\n+  }\n+\n+  // Must not be copied\n+  AlgorithmEntry & operator=(const AlgorithmEntry&) = delete;\n+  AlgorithmEntry(const AlgorithmEntry&) = delete;\n+\n+  // May be moved\n+  AlgorithmEntry(AlgorithmEntry&& other) {\n+    key = std::move(other.key);\n+    algorithm = std::move(other.algorithm);\n+    src = std::move(other.src);\n+    dst = std::move(other.dst);\n+  }\n+};\n+\n+} // namespace c10d\n+\n+MAKE_HASHABLE(\n+    ::c10d::AlgorithmKey,\n+    t.collectiveType,\n+    t.type,\n+    t.devices,\n+    t.srcSizes,\n+    t.dstSizes,\n+    t.srcDevice,\n+    t.dstDevice,\n+    t.srcRank,\n+    t.dstRank,\n+    t.reduceOp);\n+\n+namespace c10d {\n+\n+class ProcessGroupGloo : public ProcessGroup {\n+ public:\n+  class WorkGloo : public Work {\n+   public:\n+    explicit WorkGloo();\n+    virtual ~WorkGloo();\n+\n+    // Checks if request has completed. Non-blocking operation.\n+    bool isCompleted() override;\n+\n+    // Waits until request completes. Blocking operation.\n+    // Returns false if the work completed with an exception.\n+    bool wait() override;\n+\n+    // Returns exception if wait() returned false.\n+    const std::exception& exception() const override;\n+\n+   protected:\n+    void finish();\n+    void finishWithException(const ::gloo::Exception& ex);\n+\n+    std::mutex m_;\n+    std::condition_variable cv_;\n+    bool completed_;\n+\n+    // Use pointer to ::gloo::Exception because it doesn't have a\n+    // default constructor and constructing an empty std::unique_ptr\n+    // is probably cheaper (this is highly speculative).\n+    std::unique_ptr<::gloo::Exception> ex_;\n+\n+    friend class ProcessGroupGloo;\n+  };\n+\n+  explicit ProcessGroupGloo(", "path": "torch/lib/c10d/ProcessGroupGloo.hpp", "position": null, "original_position": 133, "commit_id": "f81bd359f6b3550c6c311ff39b58bf62535e43cc", "original_commit_id": "eed8b1e7d7febb5d1c6cc9eef757290ff957bd7f", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "body": "Good point. We can initialize if nothing is specified for ex, then folks can still override.", "created_at": "2018-05-17T16:04:32Z", "updated_at": "2018-11-23T15:44:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/7628#discussion_r189014628", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7628", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189014628"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7628#discussion_r189014628"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7628"}}, "body_html": "<p>Good point. We can initialize if nothing is specified for ex, then folks can still override.</p>", "body_text": "Good point. We can initialize if nothing is specified for ex, then folks can still override.", "in_reply_to_id": 188812615}