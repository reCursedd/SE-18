{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/311822214", "html_url": "https://github.com/pytorch/pytorch/pull/1935#issuecomment-311822214", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1935", "id": 311822214, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTgyMjIxNA==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-28T23:43:15Z", "updated_at": "2017-06-28T23:43:15Z", "author_association": "MEMBER", "body_html": "<p>Some micro-benchmark performance here:<br>\n<a href=\"https://gist.github.com/colesbury/fcfed34f6ddfde391adee71c67ec24a8\">https://gist.github.com/colesbury/fcfed34f6ddfde391adee71c67ec24a8</a></p>\n<p>There's not a significant difference in perf with this PR for the sizes I tried.</p>\n<p>One weird thing is that passing in a 3D input can sometimes be faster than the equivalent 2D input (and likely slower for some other cases). The difference is in the <code>bias.grad</code> computation. It's because:</p>\n<ul>\n<li><a href=\"https://github.com/pytorch/pytorch/blob/8a4eb50ed1ae875bcca6458b232fff289942911e/torch/autograd/_functions/utils.py#L17\">maybe_unexpand</a> is implemented using repeated calls to <code>sum(0)</code> for each dimension</li>\n<li>Strangely, this is actually sometimes faster, probably because sum(dim) is not implemented very efficiently. (Too much work in each thread, not enough parallelism)</li>\n</ul>", "body_text": "Some micro-benchmark performance here:\nhttps://gist.github.com/colesbury/fcfed34f6ddfde391adee71c67ec24a8\nThere's not a significant difference in perf with this PR for the sizes I tried.\nOne weird thing is that passing in a 3D input can sometimes be faster than the equivalent 2D input (and likely slower for some other cases). The difference is in the bias.grad computation. It's because:\n\nmaybe_unexpand is implemented using repeated calls to sum(0) for each dimension\nStrangely, this is actually sometimes faster, probably because sum(dim) is not implemented very efficiently. (Too much work in each thread, not enough parallelism)", "body": "Some micro-benchmark performance here:\r\nhttps://gist.github.com/colesbury/fcfed34f6ddfde391adee71c67ec24a8\r\n\r\nThere's not a significant difference in perf with this PR for the sizes I tried. \r\n\r\nOne weird thing is that passing in a 3D input can sometimes be faster than the equivalent 2D input (and likely slower for some other cases). The difference is in the `bias.grad` computation. It's because:\r\n* [maybe_unexpand](https://github.com/pytorch/pytorch/blob/8a4eb50ed1ae875bcca6458b232fff289942911e/torch/autograd/_functions/utils.py#L17) is implemented using repeated calls to `sum(0)` for each dimension\r\n* Strangely, this is actually sometimes faster, probably because sum(dim) is not implemented very efficiently. (Too much work in each thread, not enough parallelism)\r\n"}