{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/312709863", "html_url": "https://github.com/pytorch/pytorch/pull/1935#issuecomment-312709863", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1935", "id": 312709863, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjcwOTg2Mw==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-03T18:29:37Z", "updated_at": "2017-07-03T18:29:37Z", "author_association": "MEMBER", "body_html": "<p>I'll send a PR to remove the extra copies in the backwards.</p>\n<p>The forward didn't previously trigger a memcopy because the bias addition was separate.</p>\n<p>Previously it was:</p>\n<ol>\n<li>gemm</li>\n<li>add bias</li>\n</ol>\n<p>Now it is:</p>\n<ol>\n<li>copy bias to output</li>\n<li>gemm</li>\n</ol>\n<p>So there's an extra copy, but one fewer addition. I'm surprised this is slower. We can get old behavior by removing these <a href=\"https://github.com/pytorch/pytorch/blob/35ed224d04ba3eb604dd6b8029ae346ecbaad572/torch/nn/functional.py#L536-L538\">three lines</a> in nn/functional.py:</p>", "body_text": "I'll send a PR to remove the extra copies in the backwards.\nThe forward didn't previously trigger a memcopy because the bias addition was separate.\nPreviously it was:\n\ngemm\nadd bias\n\nNow it is:\n\ncopy bias to output\ngemm\n\nSo there's an extra copy, but one fewer addition. I'm surprised this is slower. We can get old behavior by removing these three lines in nn/functional.py:", "body": "I'll send a PR to remove the extra copies in the backwards.\r\n\r\nThe forward didn't previously trigger a memcopy because the bias addition was separate.  \r\n\r\nPreviously it was:\r\n1) gemm\r\n2) add bias\r\n\r\nNow it is:\r\n1) copy bias to output\r\n2) gemm\r\n\r\nSo there's an extra copy, but one fewer addition. I'm surprised this is slower. We can get old behavior by removing these [three lines](https://github.com/pytorch/pytorch/blob/35ed224d04ba3eb604dd6b8029ae346ecbaad572/torch/nn/functional.py#L536-L538) in nn/functional.py:\r\n\r\n"}