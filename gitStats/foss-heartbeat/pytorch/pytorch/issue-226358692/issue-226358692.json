{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1473", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1473/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1473/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1473/events", "html_url": "https://github.com/pytorch/pytorch/issues/1473", "id": 226358692, "node_id": "MDU6SXNzdWUyMjYzNTg2OTI=", "number": 1473, "title": "Suspected memory leak in torch.addmm with sparse matrices", "user": {"login": "germank", "id": 1215174, "node_id": "MDQ6VXNlcjEyMTUxNzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1215174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/germank", "html_url": "https://github.com/germank", "followers_url": "https://api.github.com/users/germank/followers", "following_url": "https://api.github.com/users/germank/following{/other_user}", "gists_url": "https://api.github.com/users/germank/gists{/gist_id}", "starred_url": "https://api.github.com/users/germank/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/germank/subscriptions", "organizations_url": "https://api.github.com/users/germank/orgs", "repos_url": "https://api.github.com/users/germank/repos", "events_url": "https://api.github.com/users/germank/events{/privacy}", "received_events_url": "https://api.github.com/users/germank/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-04T17:49:05Z", "updated_at": "2017-05-05T15:56:11Z", "closed_at": "2017-05-05T15:56:11Z", "author_association": "NONE", "body_html": "<p>If I repeatedly run the following operation where \"sparse\" is a cuda sparse matrix and x is some 1-d Tensor (not a Variable!), I observe an unbounded grow in the gpu's memory usage:<br>\n<code>y = torch.addmm(x, sparse, x)</code></p>\n<p>Furthermore, it goes on until it fails to allocate any more memory:<br>\n<code>THCudaCheck FAIL file=/py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory Traceback (most recent call last): File \"debug.py\", line 21, in &lt;module&gt; x = torch.addmm(x, sparse, x) RuntimeError: cuda runtime error (2) : out of memory at /py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu:66 </code></p>\n<p>This is some minimal code to reproduce the issue:</p>\n<pre><code>import torch\nimport random\n\nN=50000\nS=500\ncuda=True\nsparse = torch.sparse.FloatTensor(\n    #randomly populate the matrix, but make sure it has desired dimensionality\n    torch.LongTensor([\n        [random.randint(0,S) for i in range(S-1)]+[N-1],\n        [random.randint(0,S) for i in range(S-1)]+[N-1]]),\n    torch.FloatTensor([random.random() for i in range(S-1)]+[1])\n)\ndense = torch.arange(0,N*N).view(N, N)\nx = torch.Tensor([[0]]*N)\nif cuda:\n    x=x.cuda()\n    sparse=sparse.cuda()\n    dense=dense.cuda()\nwhile True:\n    y = torch.addmm(x, sparse, x)\n</code></pre>\n<p>The amount of leaked memory per iteration seems to correlate with the number of items in the sparse matrix (<code>S</code> above) but it's independent of the matrix dimensionality (<code>N</code>).</p>\n<p>Also note that if we replace <code>y = torch.addmm(x, sparse, x)</code> with <code>y = torch.addmm(x, dense, x)</code> no leak is observed.</p>\n<pre><code>torch.__version__ == '0.1.12_2'\ntorch.backends.cudnn.version() == 6021\n</code></pre>\n<p>EDIT: removed the unnecessary recurrence in the minimal example. Just doing y = Ax+b where A is a  sparse matrix leaks memory.</p>", "body_text": "If I repeatedly run the following operation where \"sparse\" is a cuda sparse matrix and x is some 1-d Tensor (not a Variable!), I observe an unbounded grow in the gpu's memory usage:\ny = torch.addmm(x, sparse, x)\nFurthermore, it goes on until it fails to allocate any more memory:\nTHCudaCheck FAIL file=/py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory Traceback (most recent call last): File \"debug.py\", line 21, in <module> x = torch.addmm(x, sparse, x) RuntimeError: cuda runtime error (2) : out of memory at /py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu:66 \nThis is some minimal code to reproduce the issue:\nimport torch\nimport random\n\nN=50000\nS=500\ncuda=True\nsparse = torch.sparse.FloatTensor(\n    #randomly populate the matrix, but make sure it has desired dimensionality\n    torch.LongTensor([\n        [random.randint(0,S) for i in range(S-1)]+[N-1],\n        [random.randint(0,S) for i in range(S-1)]+[N-1]]),\n    torch.FloatTensor([random.random() for i in range(S-1)]+[1])\n)\ndense = torch.arange(0,N*N).view(N, N)\nx = torch.Tensor([[0]]*N)\nif cuda:\n    x=x.cuda()\n    sparse=sparse.cuda()\n    dense=dense.cuda()\nwhile True:\n    y = torch.addmm(x, sparse, x)\n\nThe amount of leaked memory per iteration seems to correlate with the number of items in the sparse matrix (S above) but it's independent of the matrix dimensionality (N).\nAlso note that if we replace y = torch.addmm(x, sparse, x) with y = torch.addmm(x, dense, x) no leak is observed.\ntorch.__version__ == '0.1.12_2'\ntorch.backends.cudnn.version() == 6021\n\nEDIT: removed the unnecessary recurrence in the minimal example. Just doing y = Ax+b where A is a  sparse matrix leaks memory.", "body": "If I repeatedly run the following operation where \"sparse\" is a cuda sparse matrix and x is some 1-d Tensor (not a Variable!), I observe an unbounded grow in the gpu's memory usage:\r\n`y = torch.addmm(x, sparse, x)`\r\n\r\nFurthermore, it goes on until it fails to allocate any more memory:\r\n`THCudaCheck FAIL file=/py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\r\nTraceback (most recent call last):\r\n  File \"debug.py\", line 21, in <module>\r\n    x = torch.addmm(x, sparse, x)\r\nRuntimeError: cuda runtime error (2) : out of memory at /py/conda-bld/pytorch_1493676237139/work/torch/lib/THC/generic/THCStorage.cu:66\r\n`\r\n\r\nThis is some minimal code to reproduce the issue:\r\n\r\n```\r\nimport torch\r\nimport random\r\n\r\nN=50000\r\nS=500\r\ncuda=True\r\nsparse = torch.sparse.FloatTensor(\r\n    #randomly populate the matrix, but make sure it has desired dimensionality\r\n    torch.LongTensor([\r\n        [random.randint(0,S) for i in range(S-1)]+[N-1],\r\n        [random.randint(0,S) for i in range(S-1)]+[N-1]]),\r\n    torch.FloatTensor([random.random() for i in range(S-1)]+[1])\r\n)\r\ndense = torch.arange(0,N*N).view(N, N)\r\nx = torch.Tensor([[0]]*N)\r\nif cuda:\r\n    x=x.cuda()\r\n    sparse=sparse.cuda()\r\n    dense=dense.cuda()\r\nwhile True:\r\n    y = torch.addmm(x, sparse, x)\r\n```\r\n\r\nThe amount of leaked memory per iteration seems to correlate with the number of items in the sparse matrix (`S` above) but it's independent of the matrix dimensionality (`N`). \r\n\r\nAlso note that if we replace `y = torch.addmm(x, sparse, x)` with `y = torch.addmm(x, dense, x)` no leak is observed.\r\n\r\n```\r\ntorch.__version__ == '0.1.12_2'\r\ntorch.backends.cudnn.version() == 6021\r\n```\r\n\r\nEDIT: removed the unnecessary recurrence in the minimal example. Just doing y = Ax+b where A is a  sparse matrix leaks memory."}