{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12013", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12013/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12013/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12013/events", "html_url": "https://github.com/pytorch/pytorch/issues/12013", "id": 363203090, "node_id": "MDU6SXNzdWUzNjMyMDMwOTA=", "number": 12013, "title": "[Feature Request] Make nn layers accept empty batch size", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-09-24T15:39:11Z", "updated_at": "2018-10-03T23:32:27Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>Now that we have support for tensors with zero in its size, I believe it would be very handy to have support for accepting batches of size 0 in <code>nn.functional</code> functions.</p>\n<p>A (non-exhaustive) list of functions that would be good supporting:</p>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <code>conv{1-2-3}d</code></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <code>conv_transpose{1-2-3}d</code></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <code>batch_norm</code></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <code>interpolate</code></li>\n</ul>\n<p>Handling the losses is a bit trickier, because it generally involves computing a <code>.mean()</code>, which results in <code>NaN</code> due to 0 / 0 division. I'd expect having a 0 loss for empty batches to make sense, but that's debatable so might be worth postponing this decision.</p>", "body_text": "Now that we have support for tensors with zero in its size, I believe it would be very handy to have support for accepting batches of size 0 in nn.functional functions.\nA (non-exhaustive) list of functions that would be good supporting:\n\n conv{1-2-3}d\n conv_transpose{1-2-3}d\n batch_norm\n interpolate\n\nHandling the losses is a bit trickier, because it generally involves computing a .mean(), which results in NaN due to 0 / 0 division. I'd expect having a 0 loss for empty batches to make sense, but that's debatable so might be worth postponing this decision.", "body": "Now that we have support for tensors with zero in its size, I believe it would be very handy to have support for accepting batches of size 0 in `nn.functional` functions.\r\n\r\nA (non-exhaustive) list of functions that would be good supporting:\r\n- [ ] `conv{1-2-3}d`\r\n- [ ] `conv_transpose{1-2-3}d`\r\n- [ ] `batch_norm`\r\n- [ ] `interpolate`\r\n\r\nHandling the losses is a bit trickier, because it generally involves computing a `.mean()`, which results in `NaN` due to 0 / 0 division. I'd expect having a 0 loss for empty batches to make sense, but that's debatable so might be worth postponing this decision."}