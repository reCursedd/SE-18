{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189442623", "pull_request_review_id": 121627132, "id": 189442623, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTQ0MjYyMw==", "diff_hunk": "@@ -2,84 +2,164 @@\n \n #include <cmath>\n #include <iostream>\n+#include \"ATen/CPUApplyUtils.h\"\n #include \"ATen/Dispatch.h\"\n #include \"ATen/Parallel.h\"\n-#include \"ATen/cpu/vec256/vec256.h\"\n #include \"ATen/cpu/vec256/functional.h\"\n+#include \"ATen/cpu/vec256/vec256.h\"\n #include \"ATen/native/cpu/CapabilityDispatch.h\"\n \n namespace at { namespace native {\n namespace {\n \n using namespace vec256;\n \n-template <class scalar_t, class F>\n-static void parallel_apply(Tensor& result, const Tensor& self, F f) {\n-  internal::init_tbb_num_threads();\n-\n-  static tbb::affinity_partitioner ap;\n-\n-  auto arr_out = result.data<scalar_t>();\n-  auto arr_in = self.data<scalar_t>();\n-  int64_t size = self.numel();\n-  if (size < internal::TBB_GRAIN_SIZE) {\n-    map(f, arr_out, arr_in, size);\n-  } else {\n-    tbb::parallel_for(\n-        tbb::blocked_range<int64_t>(0, size, internal::TBB_GRAIN_SIZE),\n-        [&](const tbb::blocked_range<int64_t>& r) {\n-          map(f, arr_out + r.begin(), arr_in + r.begin(), r.end() - r.begin());\n-        },\n-        ap);\n-  }\n-}\n-\n static void abs_kernel(Tensor& result, const Tensor& self) {\n   AT_DISPATCH_ALL_TYPES(self.type(), \"abs\", [&] {\n-    parallel_apply<scalar_t>(\n+    CPU_tensor_parallel_kernel_apply2<scalar_t, scalar_t>(", "path": "aten/src/ATen/native/cpu/UnaryOpsKernel.cpp", "position": null, "original_position": 41, "commit_id": "7d71bee290679800bae475a261ac70f97ad1b472", "original_commit_id": "17685fff7430239ff7014dc3d81d94095ff8bea2", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Ok, we should really do something about those names, because they are really long and not very meaningful. I'd start with getting rid of the `_tensor` part, because we don't apply over anything else (and can just overload in any other case). Why not just `CPU_kernel_apply2`? Can you remind me why do we even keep the non-parallel `apply` functions?", "created_at": "2018-05-19T19:18:29Z", "updated_at": "2018-11-23T15:44:21Z", "html_url": "https://github.com/pytorch/pytorch/pull/7655#discussion_r189442623", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7655", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189442623"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7655#discussion_r189442623"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7655"}}, "body_html": "<p>Ok, we should really do something about those names, because they are really long and not very meaningful. I'd start with getting rid of the <code>_tensor</code> part, because we don't apply over anything else (and can just overload in any other case). Why not just <code>CPU_kernel_apply2</code>? Can you remind me why do we even keep the non-parallel <code>apply</code> functions?</p>", "body_text": "Ok, we should really do something about those names, because they are really long and not very meaningful. I'd start with getting rid of the _tensor part, because we don't apply over anything else (and can just overload in any other case). Why not just CPU_kernel_apply2? Can you remind me why do we even keep the non-parallel apply functions?"}