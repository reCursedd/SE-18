{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/390052053", "html_url": "https://github.com/pytorch/pytorch/pull/7655#issuecomment-390052053", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7655", "id": 390052053, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MDA1MjA1Mw==", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-18T00:06:55Z", "updated_at": "2018-05-18T00:46:52Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This brach is on the left side. Usually this helps a lot for the non-contiguous cases. The main reason is that each kernel can first write the memory into a temporary buffer and thus apply the vectorized instructions. For kernels that are compute bound that helps a lot. There is a lot more tuning that can be done here, but it might be futile and quickly overfitting on my development machine. Further, since the apply utilities collapse dimension, this can find inner regions that are contiguous and then apply the vectorized instructions.</p>\n<pre><code>branch vs master\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2082   0.2059\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2056   0.2044\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4923   2.3861\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4965   2.3993\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3500   0.3783\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3499   0.3783\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6922   3.2073\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6829   3.2006\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7691   0.7660\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7676   0.7658\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3875   1.3803\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3872   1.3797\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5724   5.8824\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5513   5.8788\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4586   1.7213\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4245   0.4199\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.2512   2.3957\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.3329   2.3646\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.6516   4.3856\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.5458   0.5777\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.7560   4.7663\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.5085   4.7192\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.0878   5.0152\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.9873   0.9812\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.1609   5.3641\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.8665   5.2935\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.6905   7.1322\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.5827   1.5985\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.9814   7.3642\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.4726   7.3120\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3272   1.5769\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3309   1.5762\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4644   2.3653\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4647   2.3646\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7573   1.5888\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7562   1.5905\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5571   1.3571\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5572   1.3591\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4617   4.2395\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4380   4.2425\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5988   1.7152\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2036   1.8047\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9984   1.6968\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.0249   4.3960\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.1890   4.5766\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2684   4.3577\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3478   5.0633\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.6705   5.2051\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5939   4.9866\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.0848   7.1309\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5459   1.3638\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   4.0267   7.2036\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.3033   7.0419\n</code></pre>\n<p>EDIT:  Regression examples</p>\n<pre><code>log_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\n</code></pre>\n<p>EDIT2:</p>\n<p>Tests pass, except for a valgrind example on each build instance.</p>\n<pre><code>00:15:20 + valgrind --suppressions=aten/tools/valgrind.sup --error-exitcode=1 aten/build/src/ATen/test/basic '[cpu]'\n00:15:20 ==2976== Memcheck, a memory error detector\n00:15:20 ==2976== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.\n00:15:20 ==2976== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info\n00:15:20 ==2976== Command: aten/build/src/ATen/test/basic [cpu]\n00:15:20 ==2976== \n00:15:23    497 ms\n00:15:26    3643 ms\n00:15:26 ==2976== Conditional jump or move depends on uninitialised value(s)\n00:15:26 ==2976==    at 0x591584C: tbb::interface9::internal::start_for&lt;tbb::blocked_range&lt;unsigned long&gt;, void at::CPU_tensor_parallel_kernel_apply2&lt;float, float, at::native::(anonymous namespace)::abs_kernel(at::Tensor&amp;, at::Tensor const&amp;)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1}&gt;(at::Tensor, at::Tensor, at::native::(anonymous namespace)::abs_kernel(at::Tensor&amp;, at::Tensor const&amp;)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1})::{lambda(tbb::blocked_range&lt;unsigned long&gt;)#1}, tbb::auto_partitioner const&gt;::execute() (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x59C19C9: tbb::internal::custom_scheduler&lt;tbb::internal::IntelSchedulerTraits&gt;::local_wait_for_all(tbb::task&amp;, tbb::task*) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x59BF77F: tbb::internal::generic_scheduler::local_spawn_root_and_wait(tbb::task*, tbb::task*&amp;) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x58CFB66: at::native::(anonymous namespace)::abs_kernel(at::Tensor&amp;, at::Tensor const&amp;) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x507982D: at::native::_abs_out_cpu(at::Tensor&amp;, at::Tensor const&amp;) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x50748CC: at::native::abs(at::Tensor const&amp;) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x51AD40B: at::Type::abs(at::Tensor const&amp;) const (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x44FA44: test(at::Type&amp;) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x456855: ____C_A_T_C_H____T_E_S_T____25() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x43C2A1: Catch::RunContext::invokeActiveTestCase() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x4632C7: Catch::(anonymous namespace)::runTests(std::shared_ptr&lt;Catch::Config&gt; const&amp;) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x469AD5: Catch::Session::runInternal() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976== \n</code></pre>\n<p>EDIT3: This valgrind error was fixed by initializing all member variables of the fixed sized tensor struct within CPUApplyUtils.h. They're not necessary, but valgrind can't infer that. It has no visible effect on these timings, so I'm not updating them.</p>", "body_text": "This brach is on the left side. Usually this helps a lot for the non-contiguous cases. The main reason is that each kernel can first write the memory into a temporary buffer and thus apply the vectorized instructions. For kernels that are compute bound that helps a lot. There is a lot more tuning that can be done here, but it might be futile and quickly overfitting on my development machine. Further, since the apply utilities collapse dimension, this can find inner regions that are contiguous and then apply the vectorized instructions.\nbranch vs master\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2082   0.2059\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2056   0.2044\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4923   2.3861\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4965   2.3993\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3500   0.3783\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3499   0.3783\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6922   3.2073\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6829   3.2006\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7691   0.7660\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7676   0.7658\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3875   1.3803\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3872   1.3797\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5724   5.8824\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5513   5.8788\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4586   1.7213\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4245   0.4199\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.2512   2.3957\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.3329   2.3646\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.6516   4.3856\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.5458   0.5777\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.7560   4.7663\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.5085   4.7192\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.0878   5.0152\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.9873   0.9812\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.1609   5.3641\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.8665   5.2935\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.6905   7.1322\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.5827   1.5985\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.9814   7.3642\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.4726   7.3120\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3272   1.5769\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3309   1.5762\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4644   2.3653\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4647   2.3646\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7573   1.5888\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7562   1.5905\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5571   1.3571\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5572   1.3591\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4617   4.2395\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4380   4.2425\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5988   1.7152\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2036   1.8047\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9984   1.6968\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.0249   4.3960\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.1890   4.5766\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2684   4.3577\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3478   5.0633\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.6705   5.2051\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5939   4.9866\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.0848   7.1309\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5459   1.3638\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   4.0267   7.2036\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.3033   7.0419\n\nEDIT:  Regression examples\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\n\nEDIT2:\nTests pass, except for a valgrind example on each build instance.\n00:15:20 + valgrind --suppressions=aten/tools/valgrind.sup --error-exitcode=1 aten/build/src/ATen/test/basic '[cpu]'\n00:15:20 ==2976== Memcheck, a memory error detector\n00:15:20 ==2976== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.\n00:15:20 ==2976== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info\n00:15:20 ==2976== Command: aten/build/src/ATen/test/basic [cpu]\n00:15:20 ==2976== \n00:15:23    497 ms\n00:15:26    3643 ms\n00:15:26 ==2976== Conditional jump or move depends on uninitialised value(s)\n00:15:26 ==2976==    at 0x591584C: tbb::interface9::internal::start_for<tbb::blocked_range<unsigned long>, void at::CPU_tensor_parallel_kernel_apply2<float, float, at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1}>(at::Tensor, at::Tensor, at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1})::{lambda(tbb::blocked_range<unsigned long>)#1}, tbb::auto_partitioner const>::execute() (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x59C19C9: tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all(tbb::task&, tbb::task*) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x59BF77F: tbb::internal::generic_scheduler::local_spawn_root_and_wait(tbb::task*, tbb::task*&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x58CFB66: at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x507982D: at::native::_abs_out_cpu(at::Tensor&, at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x50748CC: at::native::abs(at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x51AD40B: at::Type::abs(at::Tensor const&) const (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\n00:15:26 ==2976==    by 0x44FA44: test(at::Type&) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x456855: ____C_A_T_C_H____T_E_S_T____25() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x43C2A1: Catch::RunContext::invokeActiveTestCase() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x4632C7: Catch::(anonymous namespace)::runTests(std::shared_ptr<Catch::Config> const&) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976==    by 0x469AD5: Catch::Session::runInternal() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\n00:15:26 ==2976== \n\nEDIT3: This valgrind error was fixed by initializing all member variables of the fixed sized tensor struct within CPUApplyUtils.h. They're not necessary, but valgrind can't infer that. It has no visible effect on these timings, so I'm not updating them.", "body": "This brach is on the left side. Usually this helps a lot for the non-contiguous cases. The main reason is that each kernel can first write the memory into a temporary buffer and thus apply the vectorized instructions. For kernels that are compute bound that helps a lot. There is a lot more tuning that can be done here, but it might be futile and quickly overfitting on my development machine. Further, since the apply utilities collapse dimension, this can find inner regions that are contiguous and then apply the vectorized instructions.\r\n\r\n```\r\nbranch vs master\r\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2082   0.2059\r\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.2056   0.2044\r\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4923   2.3861\r\nsqrt_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.4965   2.3993\r\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3500   0.3783\r\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.3499   0.3783\r\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6922   3.2073\r\nexp_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.6829   3.2006\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7691   0.7660\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.7676   0.7658\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\r\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3875   1.3803\r\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.3872   1.3797\r\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5724   5.8824\r\ntanh_           memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.5513   5.8788\r\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4586   1.7213\r\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.4245   0.4199\r\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.2512   2.3957\r\nsqrt            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.3329   2.3646\r\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.6516   4.3856\r\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.5458   0.5777\r\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.7560   4.7663\r\nexp             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.5085   4.7192\r\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.0878   5.0152\r\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   0.9873   0.9812\r\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.1609   5.3641\r\nlog             memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.8665   5.2935\r\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['    215', '  46225', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.6905   7.1322\r\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['  46225', '    215', '      1']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   1.5827   1.5985\r\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.9814   7.3642\r\ntanh            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   3.4726   7.3120\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3272   1.5769\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3309   1.5762\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4644   2.3653\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.4647   2.3646\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7573   1.5888\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.7562   1.5905\r\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5571   1.3571\r\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5572   1.3591\r\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4617   4.2395\r\ntanh_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.4380   4.2425\r\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5988   1.7152\r\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\r\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2036   1.8047\r\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9984   1.6968\r\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.0249   4.3960\r\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\r\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.1890   4.5766\r\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.2684   4.3577\r\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.3478   5.0633\r\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\r\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.6705   5.2051\r\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5939   4.9866\r\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.0848   7.1309\r\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   1.5459   1.3638\r\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['    828', '  38088', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   4.0267   7.2036\r\ntanh            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['  38088', '    828', '     18']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   2.3033   7.0419\r\n```\r\n\r\nEDIT:  Regression examples\r\n\r\n```\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: ['   3870', ' 832050', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9603   2.5461\r\nlog_            memory: O(10^4)KB  count: 25     size: [215, 215, 215]      stride: [' 832050', '   3870', '     18']                            numel: 9938375   type: torch.float32      dim: 3     elapsed:   2.9685   2.5473\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4177   0.2043\r\nsqrt_           memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4167   0.2047\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5328   0.3546\r\nexp_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5322   0.3563\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['     46', '   2116', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9795   0.7519\r\nlog_            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9784   0.7521\r\nsqrt            memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.4209   0.2077\r\nexp             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.5422   0.3523\r\nlog             memory: O(10^2)KB  count: 2500   size: [46, 46, 46]         stride: ['   2116', '     46', '      1']                            numel: 97336     type: torch.float32      dim: 3     elapsed:   0.9769   0.7496\r\n```\r\n\r\nEDIT2:\r\n\r\nTests pass, except for a valgrind example on each build instance. \r\n```\r\n00:15:20 + valgrind --suppressions=aten/tools/valgrind.sup --error-exitcode=1 aten/build/src/ATen/test/basic '[cpu]'\r\n00:15:20 ==2976== Memcheck, a memory error detector\r\n00:15:20 ==2976== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.\r\n00:15:20 ==2976== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info\r\n00:15:20 ==2976== Command: aten/build/src/ATen/test/basic [cpu]\r\n00:15:20 ==2976== \r\n00:15:23    497 ms\r\n00:15:26    3643 ms\r\n00:15:26 ==2976== Conditional jump or move depends on uninitialised value(s)\r\n00:15:26 ==2976==    at 0x591584C: tbb::interface9::internal::start_for<tbb::blocked_range<unsigned long>, void at::CPU_tensor_parallel_kernel_apply2<float, float, at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1}>(at::Tensor, at::Tensor, at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, float*, {lambda()#4}, long, long)#1})::{lambda(tbb::blocked_range<unsigned long>)#1}, tbb::auto_partitioner const>::execute() (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x59C19C9: tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::local_wait_for_all(tbb::task&, tbb::task*) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x59BF77F: tbb::internal::generic_scheduler::local_spawn_root_and_wait(tbb::task*, tbb::task*&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x58CFB66: at::native::(anonymous namespace)::abs_kernel(at::Tensor&, at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x507982D: at::native::_abs_out_cpu(at::Tensor&, at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x50748CC: at::native::abs(at::Tensor const&) (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x51AD40B: at::Type::abs(at::Tensor const&) const (in /opt/python/2.7.15/lib/python2.7/site-packages/torch/lib/libATen_cpu.so)\r\n00:15:26 ==2976==    by 0x44FA44: test(at::Type&) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\r\n00:15:26 ==2976==    by 0x456855: ____C_A_T_C_H____T_E_S_T____25() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\r\n00:15:26 ==2976==    by 0x43C2A1: Catch::RunContext::invokeActiveTestCase() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\r\n00:15:26 ==2976==    by 0x4632C7: Catch::(anonymous namespace)::runTests(std::shared_ptr<Catch::Config> const&) (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\r\n00:15:26 ==2976==    by 0x469AD5: Catch::Session::runInternal() (in /var/lib/jenkins/workspace/aten/build/src/ATen/test/basic)\r\n00:15:26 ==2976== \r\n```\r\n\r\nEDIT3: This valgrind error was fixed by initializing all member variables of the fixed sized tensor struct within CPUApplyUtils.h. They're not necessary, but valgrind can't infer that. It has no visible effect on these timings, so I'm not updating them."}