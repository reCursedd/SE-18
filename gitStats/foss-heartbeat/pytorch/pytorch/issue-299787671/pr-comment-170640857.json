{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/170640857", "pull_request_review_id": 99355766, "id": 170640857, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MDY0MDg1Nw==", "diff_hunk": "@@ -1,10 +1,41 @@\n import torch\n+import warnings\n from ..modules import Module\n from .scatter_gather import scatter_kwargs, gather\n from .replicate import replicate\n from .parallel_apply import parallel_apply\n \n \n+def _check_balance(device_ids):\n+    imbalance_warn = \"\"\"\n+    There is an imbalance between your GPUs. You may want to exclude GPU {} which\n+    has >25% less memory or cores than GPU {}. You can do so by setting the\n+    CUDA_VISIBLE_DEVICES environment variable.\"\"\"\n+\n+    mem_min = cores_min = float('inf')\n+    mem_max = cores_max = -float('inf')\n+    for i in device_ids:\n+        prop = torch.cuda.get_device_properties(i)\n+        if prop.total_memory < mem_min:\n+            mem_min = prop.total_memory\n+            mem_min_i = i\n+        if prop.total_memory > mem_max:\n+            mem_max = prop.total_memory\n+            mem_max_i = i\n+        if prop.multi_processor_count < cores_min:\n+            cores_min = prop.multi_processor_count\n+            cores_min_i = i\n+        if prop.multi_processor_count > cores_max:\n+            cores_max = prop.multi_processor_count\n+            cores_max_i = i", "path": "torch/nn/parallel/data_parallel.py", "position": null, "original_position": 30, "commit_id": "5d70e344ac0ea7eb543b08f9d56885a92f5ebc92", "original_commit_id": "77ca81caa12ce998229a20d86233f9af638f56c6", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "a shorter way:\r\n```python\r\ndef warn_imbalance(device_ids, dev_props, get_prop):\r\n    values = [get_prop(props) for props in dev_props]\r\n    min_pos, min_val = min(enumerate(values), key=operator.itemgetter(1))\r\n    max_pos, max_val = max(enumerate(values), key=operator.itemgetter(1))\r\n    if min_val / max_val < 0.75:\r\n        warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\r\n        return True\r\n    return False\r\n\r\nif warn_imbalance(lambda props: props.total_memory):\r\n    return\r\nif warn_imbalance(lambda props: props.multi_processor_count):\r\n    return\r\n```", "created_at": "2018-02-26T16:02:10Z", "updated_at": "2018-11-23T15:40:00Z", "html_url": "https://github.com/pytorch/pytorch/pull/5376#discussion_r170640857", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5376", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/170640857"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5376#discussion_r170640857"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5376"}}, "body_html": "<p>a shorter way:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">warn_imbalance</span>(<span class=\"pl-smi\">device_ids</span>, <span class=\"pl-smi\">dev_props</span>, <span class=\"pl-smi\">get_prop</span>):\n    values <span class=\"pl-k\">=</span> [get_prop(props) <span class=\"pl-k\">for</span> props <span class=\"pl-k\">in</span> dev_props]\n    min_pos, min_val <span class=\"pl-k\">=</span> <span class=\"pl-c1\">min</span>(<span class=\"pl-c1\">enumerate</span>(values), <span class=\"pl-v\">key</span><span class=\"pl-k\">=</span>operator.itemgetter(<span class=\"pl-c1\">1</span>))\n    max_pos, max_val <span class=\"pl-k\">=</span> <span class=\"pl-c1\">max</span>(<span class=\"pl-c1\">enumerate</span>(values), <span class=\"pl-v\">key</span><span class=\"pl-k\">=</span>operator.itemgetter(<span class=\"pl-c1\">1</span>))\n    <span class=\"pl-k\">if</span> min_val <span class=\"pl-k\">/</span> max_val <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">0.75</span>:\n        warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">True</span>\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">False</span>\n\n<span class=\"pl-k\">if</span> warn_imbalance(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">props</span>: props.total_memory):\n    <span class=\"pl-k\">return</span>\n<span class=\"pl-k\">if</span> warn_imbalance(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">props</span>: props.multi_processor_count):\n    <span class=\"pl-k\">return</span></pre></div>", "body_text": "a shorter way:\ndef warn_imbalance(device_ids, dev_props, get_prop):\n    values = [get_prop(props) for props in dev_props]\n    min_pos, min_val = min(enumerate(values), key=operator.itemgetter(1))\n    max_pos, max_val = max(enumerate(values), key=operator.itemgetter(1))\n    if min_val / max_val < 0.75:\n        warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n        return True\n    return False\n\nif warn_imbalance(lambda props: props.total_memory):\n    return\nif warn_imbalance(lambda props: props.multi_processor_count):\n    return"}