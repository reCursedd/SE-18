{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368562990", "html_url": "https://github.com/pytorch/pytorch/pull/5376#issuecomment-368562990", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5376", "id": 368562990, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODU2Mjk5MA==", "user": {"login": "lemairecarl", "id": 13444373, "node_id": "MDQ6VXNlcjEzNDQ0Mzcz", "avatar_url": "https://avatars3.githubusercontent.com/u/13444373?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lemairecarl", "html_url": "https://github.com/lemairecarl", "followers_url": "https://api.github.com/users/lemairecarl/followers", "following_url": "https://api.github.com/users/lemairecarl/following{/other_user}", "gists_url": "https://api.github.com/users/lemairecarl/gists{/gist_id}", "starred_url": "https://api.github.com/users/lemairecarl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lemairecarl/subscriptions", "organizations_url": "https://api.github.com/users/lemairecarl/orgs", "repos_url": "https://api.github.com/users/lemairecarl/repos", "events_url": "https://api.github.com/users/lemairecarl/events{/privacy}", "received_events_url": "https://api.github.com/users/lemairecarl/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-26T16:34:48Z", "updated_at": "2018-02-26T16:40:00Z", "author_association": "CONTRIBUTOR", "body_html": "<pre><code>In [1]: from torch.nn.parallel import DataParallel\n\nIn [2]: from torch.nn.modules import Conv2d\n\nIn [3]: m = Conv2d(2, 2, 2)\n\nIn [4]: d = DataParallel(m)\n\nIn [5]: d = d.cuda()\n/home/local/USHERBROOKE/lemc2220/source/pytorch/torch/nn/parallel/data_parallel.py:37: UserWarning: \n    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n    has &gt;25% less memory or cores than GPU 0. You can do so by setting the\n    device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n    environment variable.\n  warnings.warn(imbalance_warn.format(weak_i, good_i))\n\nIn [6]: import torch.cuda as cu\n\nIn [7]: cu.get_device_properties(0)\nOut[7]: GeForce GTX TITAN X | CUDA 5.2 | Memory: 12800 MB | Processors: 24\n\nIn [8]: cu.get_device_properties(1)\nOut[8]: GeForce GT 710 | CUDA 3.5 | Memory: 1027 MB | Processors: 1\n</code></pre>\n<p>One thing to note is that <code>torch.cuda.get_device_properties()</code> does not exist before CUDA is initialized. Maybe we should move the <code>py::class_</code> definition somewhere else. I imitated <a href=\"https://github.com/pytorch/pytorch/blob/f38b6f611e0e841496c7d9ad901e07296a253a0d/torch/csrc/autograd/init.cpp\">csrc/autograd/init.cpp</a>.</p>", "body_text": "In [1]: from torch.nn.parallel import DataParallel\n\nIn [2]: from torch.nn.modules import Conv2d\n\nIn [3]: m = Conv2d(2, 2, 2)\n\nIn [4]: d = DataParallel(m)\n\nIn [5]: d = d.cuda()\n/home/local/USHERBROOKE/lemc2220/source/pytorch/torch/nn/parallel/data_parallel.py:37: UserWarning: \n    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n    has >25% less memory or cores than GPU 0. You can do so by setting the\n    device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n    environment variable.\n  warnings.warn(imbalance_warn.format(weak_i, good_i))\n\nIn [6]: import torch.cuda as cu\n\nIn [7]: cu.get_device_properties(0)\nOut[7]: GeForce GTX TITAN X | CUDA 5.2 | Memory: 12800 MB | Processors: 24\n\nIn [8]: cu.get_device_properties(1)\nOut[8]: GeForce GT 710 | CUDA 3.5 | Memory: 1027 MB | Processors: 1\n\nOne thing to note is that torch.cuda.get_device_properties() does not exist before CUDA is initialized. Maybe we should move the py::class_ definition somewhere else. I imitated csrc/autograd/init.cpp.", "body": "```\r\nIn [1]: from torch.nn.parallel import DataParallel\r\n\r\nIn [2]: from torch.nn.modules import Conv2d\r\n\r\nIn [3]: m = Conv2d(2, 2, 2)\r\n\r\nIn [4]: d = DataParallel(m)\r\n\r\nIn [5]: d = d.cuda()\r\n/home/local/USHERBROOKE/lemc2220/source/pytorch/torch/nn/parallel/data_parallel.py:37: UserWarning: \r\n    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\r\n    has >25% less memory or cores than GPU 0. You can do so by setting the\r\n    device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\r\n    environment variable.\r\n  warnings.warn(imbalance_warn.format(weak_i, good_i))\r\n\r\nIn [6]: import torch.cuda as cu\r\n\r\nIn [7]: cu.get_device_properties(0)\r\nOut[7]: GeForce GTX TITAN X | CUDA 5.2 | Memory: 12800 MB | Processors: 24\r\n\r\nIn [8]: cu.get_device_properties(1)\r\nOut[8]: GeForce GT 710 | CUDA 3.5 | Memory: 1027 MB | Processors: 1\r\n```\r\n\r\nOne thing to note is that `torch.cuda.get_device_properties()` does not exist before CUDA is initialized. Maybe we should move the `py::class_` definition somewhere else. I imitated [csrc/autograd/init.cpp](https://github.com/pytorch/pytorch/blob/f38b6f611e0e841496c7d9ad901e07296a253a0d/torch/csrc/autograd/init.cpp)."}