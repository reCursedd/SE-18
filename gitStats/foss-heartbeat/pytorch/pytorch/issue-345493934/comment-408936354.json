{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/408936354", "html_url": "https://github.com/pytorch/pytorch/pull/9979#issuecomment-408936354", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9979", "id": 408936354, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODkzNjM1NA==", "user": {"login": "zasdfgbnm", "id": 1032377, "node_id": "MDQ6VXNlcjEwMzIzNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1032377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zasdfgbnm", "html_url": "https://github.com/zasdfgbnm", "followers_url": "https://api.github.com/users/zasdfgbnm/followers", "following_url": "https://api.github.com/users/zasdfgbnm/following{/other_user}", "gists_url": "https://api.github.com/users/zasdfgbnm/gists{/gist_id}", "starred_url": "https://api.github.com/users/zasdfgbnm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zasdfgbnm/subscriptions", "organizations_url": "https://api.github.com/users/zasdfgbnm/orgs", "repos_url": "https://api.github.com/users/zasdfgbnm/repos", "events_url": "https://api.github.com/users/zasdfgbnm/events{/privacy}", "received_events_url": "https://api.github.com/users/zasdfgbnm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-30T17:01:36Z", "updated_at": "2018-07-30T17:01:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> Yes, you are right. All layers except the first are assumed to to take a single input.</p>\n<p>There are some ambiguities for hidden layer. For example, if the first layer returns <code>(a, b)</code>, it is not clear to <code>nn.Sequential</code> whether we should call the second layer by <code>layer2(a, b)</code> or <code>layer2((a,b))</code>. In this case, we are manually enforcing the second way.</p>\n<p>For the first layer, allowing multiple inputs is just a simple trick to make it a bit more convenient for user codes.</p>", "body_text": "@fmassa Yes, you are right. All layers except the first are assumed to to take a single input.\nThere are some ambiguities for hidden layer. For example, if the first layer returns (a, b), it is not clear to nn.Sequential whether we should call the second layer by layer2(a, b) or layer2((a,b)). In this case, we are manually enforcing the second way.\nFor the first layer, allowing multiple inputs is just a simple trick to make it a bit more convenient for user codes.", "body": "@fmassa Yes, you are right. All layers except the first are assumed to to take a single input.\r\n\r\nThere are some ambiguities for hidden layer. For example, if the first layer returns `(a, b)`, it is not clear to `nn.Sequential` whether we should call the second layer by `layer2(a, b)` or `layer2((a,b))`. In this case, we are manually enforcing the second way.\r\n\r\nFor the first layer, allowing multiple inputs is just a simple trick to make it a bit more convenient for user codes."}