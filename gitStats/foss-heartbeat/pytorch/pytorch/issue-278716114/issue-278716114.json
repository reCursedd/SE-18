{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3983", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3983/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3983/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3983/events", "html_url": "https://github.com/pytorch/pytorch/issues/3983", "id": 278716114, "node_id": "MDU6SXNzdWUyNzg3MTYxMTQ=", "number": 3983, "title": "Out of memory with higher-order gradients involving batchnorm2d", "user": {"login": "andreasrobinson", "id": 9981968, "node_id": "MDQ6VXNlcjk5ODE5Njg=", "avatar_url": "https://avatars1.githubusercontent.com/u/9981968?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andreasrobinson", "html_url": "https://github.com/andreasrobinson", "followers_url": "https://api.github.com/users/andreasrobinson/followers", "following_url": "https://api.github.com/users/andreasrobinson/following{/other_user}", "gists_url": "https://api.github.com/users/andreasrobinson/gists{/gist_id}", "starred_url": "https://api.github.com/users/andreasrobinson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andreasrobinson/subscriptions", "organizations_url": "https://api.github.com/users/andreasrobinson/orgs", "repos_url": "https://api.github.com/users/andreasrobinson/repos", "events_url": "https://api.github.com/users/andreasrobinson/events{/privacy}", "received_events_url": "https://api.github.com/users/andreasrobinson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-02T20:46:08Z", "updated_at": "2017-12-03T17:07:41Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>There seems to be a memory leak when using higher-order gradients with batchnorm, closely related to previous bugs which have already been fixed.  I'm using the release version 0.2.0 (though I also reproduced the bug with source revision <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/99141e62a682ad0d1e10974eccad12e0cbdc5e51/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/99141e62a682ad0d1e10974eccad12e0cbdc5e51\"><tt>99141e6</tt></a>... from master).</p>\n<p>I'm using the same test code from this (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"247848035\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2287\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2287/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2287\">#2287</a>) bug report, which is marked as fixed and merged into 0.2.0.</p>\n<p>Here is the error (after a couple of iterations on a gtx1070):</p>\n<p>0<br>\n1<br>\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory<br>\nTraceback (most recent call last):<br>\nFile \"batch_norm_test.py\", line 42, in <br>\nloss.backward()<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 156, in backward<br>\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, retain_$ariables)<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/auto$rad/<strong>init</strong>.py\", line 98, in backward<br>\nvariables, grad_variables, retain_graph)<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/nn/_functions/thnn/batchnorm_double_backwards.py\", line 97, in batchnorm_double_backwards_fn<br>\ngG = ggI * first_back_grad_input(gO, 1)<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 829, in <strong>mul</strong><br>\nreturn self.mul(other)<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 339, in mul<br>\nreturn Mul.apply(self, other)<br>\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/_functions/basic_ops.py\", line 48, in forward<br>\nreturn a.mul(b)<br>\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu:66</p>\n<p>Here is the code to reproduce the issue, copied from the ticket referenced above:</p>\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass BatchNormTest(nn.Module):\n    def __init__(self, c, num_classes=2):\n        super(BatchNormTest, self).__init__()\n        self.bn = nn.BatchNorm2d(c)\n\n    def forward(self, x):\n        out = x\n        out = self.bn(out)\n        out = F.relu(out)\n        return out\n\nc = 100\nnet = BatchNormTest(c)\nuse_cuda = True\ninputs = Variable(torch.rand(100,c,100,100), requires_grad=True)\nif use_cuda:\n    net.cuda()\n    inputs = inputs.cuda()\n\nT = 100\nfor i in range(T):\n    output = net(inputs)\n    loss1 = torch.sum(output)\n    grad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\n\n    grad = grad_params[0]\n    loss = torch.sum(grad)\n\n    loss.backward()\n    print(i)\n</code></pre>", "body_text": "There seems to be a memory leak when using higher-order gradients with batchnorm, closely related to previous bugs which have already been fixed.  I'm using the release version 0.2.0 (though I also reproduced the bug with source revision 99141e6... from master).\nI'm using the same test code from this (#2287) bug report, which is marked as fixed and merged into 0.2.0.\nHere is the error (after a couple of iterations on a gtx1070):\n0\n1\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\nTraceback (most recent call last):\nFile \"batch_norm_test.py\", line 42, in \nloss.backward()\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 156, in backward\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, retain_$ariables)\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/auto$rad/init.py\", line 98, in backward\nvariables, grad_variables, retain_graph)\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/nn/_functions/thnn/batchnorm_double_backwards.py\", line 97, in batchnorm_double_backwards_fn\ngG = ggI * first_back_grad_input(gO, 1)\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 829, in mul\nreturn self.mul(other)\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 339, in mul\nreturn Mul.apply(self, other)\nFile \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/_functions/basic_ops.py\", line 48, in forward\nreturn a.mul(b)\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu:66\nHere is the code to reproduce the issue, copied from the ticket referenced above:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass BatchNormTest(nn.Module):\n    def __init__(self, c, num_classes=2):\n        super(BatchNormTest, self).__init__()\n        self.bn = nn.BatchNorm2d(c)\n\n    def forward(self, x):\n        out = x\n        out = self.bn(out)\n        out = F.relu(out)\n        return out\n\nc = 100\nnet = BatchNormTest(c)\nuse_cuda = True\ninputs = Variable(torch.rand(100,c,100,100), requires_grad=True)\nif use_cuda:\n    net.cuda()\n    inputs = inputs.cuda()\n\nT = 100\nfor i in range(T):\n    output = net(inputs)\n    loss1 = torch.sum(output)\n    grad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\n\n    grad = grad_params[0]\n    loss = torch.sum(grad)\n\n    loss.backward()\n    print(i)", "body": "There seems to be a memory leak when using higher-order gradients with batchnorm, closely related to previous bugs which have already been fixed.  I'm using the release version 0.2.0 (though I also reproduced the bug with source revision 99141e62... from master).  \r\n\r\nI'm using the same test code from this (https://github.com/pytorch/pytorch/issues/2287) bug report, which is marked as fixed and merged into 0.2.0.  \r\n\r\nHere is the error (after a couple of iterations on a gtx1070):\r\n\r\n0\r\n1\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\r\nTraceback (most recent call last):\r\n  File \"batch_norm_test.py\", line 42, in <module>\r\n    loss.backward()\r\n File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 156, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_$ariables)\r\n  File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/auto$rad/__init__.py\", line 98, in backward\r\n    variables, grad_variables, retain_graph)\r\n  File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/nn/_functions/thnn/batchnorm_double_backwards.py\", line 97, in batchnorm_double_backwards_fn\r\n    gG = ggI * first_back_grad_input(gO, 1)\r\n  File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 829, in __mul__\r\n    return self.mul(other)\r\n  File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/variable.py\", line 339, in mul\r\n    return Mul.apply(self, other)\r\n  File \"/home/andreas/anaconda2/envs/env/lib/python2.7/site-packages/torch/autograd/_functions/basic_ops.py\", line 48, in forward\r\n    return a.mul(b)\r\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1502006348621/work/torch/lib/THC/generic/THCStorage.cu:66\r\n\r\nHere is the code to reproduce the issue, copied from the ticket referenced above:\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\n\r\nclass BatchNormTest(nn.Module):\r\n    def __init__(self, c, num_classes=2):\r\n        super(BatchNormTest, self).__init__()\r\n        self.bn = nn.BatchNorm2d(c)\r\n\r\n    def forward(self, x):\r\n        out = x\r\n        out = self.bn(out)\r\n        out = F.relu(out)\r\n        return out\r\n\r\nc = 100\r\nnet = BatchNormTest(c)\r\nuse_cuda = True\r\ninputs = Variable(torch.rand(100,c,100,100), requires_grad=True)\r\nif use_cuda:\r\n    net.cuda()\r\n    inputs = inputs.cuda()\r\n\r\nT = 100\r\nfor i in range(T):\r\n    output = net(inputs)\r\n    loss1 = torch.sum(output)\r\n    grad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\r\n\r\n    grad = grad_params[0]\r\n    loss = torch.sum(grad)\r\n\r\n    loss.backward()\r\n    print(i)\r\n```"}