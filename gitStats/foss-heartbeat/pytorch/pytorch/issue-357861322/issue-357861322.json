{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11350", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11350/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11350/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11350/events", "html_url": "https://github.com/pytorch/pytorch/pull/11350", "id": 357861322, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEzNzc0OTk0", "number": 11350, "title": "[c2][serialized_tests] Refactor tests part 1", "user": {"login": "ajyu", "id": 1071670, "node_id": "MDQ6VXNlcjEwNzE2NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1071670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajyu", "html_url": "https://github.com/ajyu", "followers_url": "https://api.github.com/users/ajyu/followers", "following_url": "https://api.github.com/users/ajyu/following{/other_user}", "gists_url": "https://api.github.com/users/ajyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajyu/subscriptions", "organizations_url": "https://api.github.com/users/ajyu/orgs", "repos_url": "https://api.github.com/users/ajyu/repos", "events_url": "https://api.github.com/users/ajyu/events{/privacy}", "received_events_url": "https://api.github.com/users/ajyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-06T23:10:02Z", "updated_at": "2018-11-23T15:51:35Z", "closed_at": "2018-09-18T17:43:25Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11350", "html_url": "https://github.com/pytorch/pytorch/pull/11350", "diff_url": "https://github.com/pytorch/pytorch/pull/11350.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11350.patch"}, "body_html": "<p>Followup to <a href=\"https://github.com/pytorch/pytorch/pull/10594\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/10594/hovercard\">the serialized test framework</a></p>\n<p>Round 1 for refactoring tests, starting alphabetically. I added some functionality, so I wanted to send out some of these initial changes sooner.</p>\n<p>I'm skipping all tests that don't explicitly call assertReferenceChecks. Some tests directly call np.allclose, and others are simply TestCase (rather than HypothesisTestCase).</p>\n<ol>\n<li>Start alphabetically producing serialized outputs for test functions, annotating those we want to include with <code>@serialized_test_util.given</code>. So far I've only added one test per operator, but this already does seem to add quite a few tests.</li>\n<li>Add functionality to allow us to generate outputs using pytest by adding pytest argument options. This allows us to skip adding a <code>__main__</code> function to quite a few tests.</li>\n<li>Catch any exceptions generating the gradient operator and skip serializing/reading it, since certain operators don't have gradients.</li>\n<li>Add functionality to better handle jagged array inputs, which numpy doesn't handle very well. We simply explicitly do the conversion to dtype=object.</li>\n<li>Make only one file per test function, rather than 4, to reduce the number of files in the github repo.</li>\n</ol>\n<p>I also noticed that there is some hypothesis handling that makes <code>@serialized_test_util.given</code> not compatible with adding more hypothesis decorators on top. For example, there are tests that do</p>\n<pre><code>@settings(...)\n@given(...)\ndef test_my_stuff(...)\n</code></pre>\n<p>But there is a hypothesis handler that explicitly checks that <code>@given</code> is called below <code>@settings</code>, so we cannot refactor this to <code>@serialized_test_util.given</code>. I've just avoided decorating these kinds of tests for now, I hope that's alright.</p>", "body_text": "Followup to the serialized test framework\nRound 1 for refactoring tests, starting alphabetically. I added some functionality, so I wanted to send out some of these initial changes sooner.\nI'm skipping all tests that don't explicitly call assertReferenceChecks. Some tests directly call np.allclose, and others are simply TestCase (rather than HypothesisTestCase).\n\nStart alphabetically producing serialized outputs for test functions, annotating those we want to include with @serialized_test_util.given. So far I've only added one test per operator, but this already does seem to add quite a few tests.\nAdd functionality to allow us to generate outputs using pytest by adding pytest argument options. This allows us to skip adding a __main__ function to quite a few tests.\nCatch any exceptions generating the gradient operator and skip serializing/reading it, since certain operators don't have gradients.\nAdd functionality to better handle jagged array inputs, which numpy doesn't handle very well. We simply explicitly do the conversion to dtype=object.\nMake only one file per test function, rather than 4, to reduce the number of files in the github repo.\n\nI also noticed that there is some hypothesis handling that makes @serialized_test_util.given not compatible with adding more hypothesis decorators on top. For example, there are tests that do\n@settings(...)\n@given(...)\ndef test_my_stuff(...)\n\nBut there is a hypothesis handler that explicitly checks that @given is called below @settings, so we cannot refactor this to @serialized_test_util.given. I've just avoided decorating these kinds of tests for now, I hope that's alright.", "body": "Followup to [the serialized test framework](https://github.com/pytorch/pytorch/pull/10594)\r\n\r\nRound 1 for refactoring tests, starting alphabetically. I added some functionality, so I wanted to send out some of these initial changes sooner.\r\n\r\nI'm skipping all tests that don't explicitly call assertReferenceChecks. Some tests directly call np.allclose, and others are simply TestCase (rather than HypothesisTestCase).\r\n\r\n1. Start alphabetically producing serialized outputs for test functions, annotating those we want to include with `@serialized_test_util.given`. So far I've only added one test per operator, but this already does seem to add quite a few tests.\r\n2. Add functionality to allow us to generate outputs using pytest by adding pytest argument options. This allows us to skip adding a `__main__` function to quite a few tests.\r\n3. Catch any exceptions generating the gradient operator and skip serializing/reading it, since certain operators don't have gradients.\r\n4. Add functionality to better handle jagged array inputs, which numpy doesn't handle very well. We simply explicitly do the conversion to dtype=object.\r\n5. Make only one file per test function, rather than 4, to reduce the number of files in the github repo.\r\n\r\nI also noticed that there is some hypothesis handling that makes `@serialized_test_util.given` not compatible with adding more hypothesis decorators on top. For example, there are tests that do \r\n```\r\n@settings(...)\r\n@given(...)\r\ndef test_my_stuff(...)\r\n```\r\nBut there is a hypothesis handler that explicitly checks that `@given` is called below `@settings`, so we cannot refactor this to `@serialized_test_util.given`. I've just avoided decorating these kinds of tests for now, I hope that's alright."}