{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162755510", "pull_request_review_id": 90271330, "id": 162755510, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Mjc1NTUxMA==", "diff_hunk": "@@ -0,0 +1,26 @@\n+#include \"torch/csrc/jit/autodiff.h\"\n+\n+#include \"torch/csrc/jit/symbolic_variable.h\"\n+#include \"torch/csrc/utils/functional.h\"\n+\n+namespace torch { namespace jit {\n+\n+std::vector<Value*> gradientForNode(Node* node, ArrayRef<Value*> grad_values) {\n+  const auto build_sym_grad = [node](const std::vector<SymbolicVariable>& grads) -> std::vector<SymbolicVariable> {\n+    switch(node->kind()) {\n+      case kadd:\n+        return {grads[0], grads[0]};\n+      case ksub:\n+        return {grads[0], -grads[0]};\n+      case kmul:\n+        auto inputs = node->inputs();", "path": "torch/csrc/jit/autodiff.cpp", "position": null, "original_position": 16, "commit_id": "6166c723a72fea116fa2c515dbba327099e706d2", "original_commit_id": "ab6bea0d82767c85cc62be6128b5592ea98b593d", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "nit: if we add this line before the switch, then any op that needs the inputs won't have to repeat this line, we could do the same for outputs as well. That way, we can keep many ops 1 liners.", "created_at": "2018-01-19T23:19:01Z", "updated_at": "2018-11-23T15:38:20Z", "html_url": "https://github.com/pytorch/pytorch/pull/4743#discussion_r162755510", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4743", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162755510"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4743#discussion_r162755510"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4743"}}, "body_html": "<p>nit: if we add this line before the switch, then any op that needs the inputs won't have to repeat this line, we could do the same for outputs as well. That way, we can keep many ops 1 liners.</p>", "body_text": "nit: if we add this line before the switch, then any op that needs the inputs won't have to repeat this line, we could do the same for outputs as well. That way, we can keep many ops 1 liners."}