{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/95070130", "pull_request_review_id": 15616123, "id": 95070130, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk1MDcwMTMw", "diff_hunk": "@@ -0,0 +1,69 @@\n+import torch\n+from torch.autograd.function import Function\n+from torch._thnn import type2backend\n+import torch.backends.cudnn as cudnn\n+\n+\n+class BatchNorm(Function):\n+    def __init__(self, running_mean, running_var, training, momentum, eps):\n+        super(BatchNorm, self).__init__()\n+        self.running_mean = running_mean\n+        self.running_var = running_var\n+        self.training = training\n+        self.momentum = momentum\n+        self.eps = eps\n+\n+    def forward(self, input, weight=None, bias=None):\n+        self.save_for_backward(input, weight, bias)\n+\n+        self.use_cudnn = (cudnn.is_acceptable(input)\n+                          and weight is not None and bias is not None)\n+        self.use_cudnn = False\n+\n+        # temporary buffers used in forward and backward\n+        num_features = input.size(1)\n+        self._save_mean = input.new(num_features)", "path": "torch/nn/_functions/batchnorm.py", "position": 25, "original_position": 25, "commit_id": "b488866fdc921e7b090adbe74e3082f4aa8c3db5", "original_commit_id": "b488866fdc921e7b090adbe74e3082f4aa8c3db5", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "body": "save_mean, save_std, running_mean, running_var, weight, grad_weight, bias, grad_bias should be float for half inputs. ", "created_at": "2017-01-08T02:20:49Z", "updated_at": "2018-11-23T15:32:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/421#discussion_r95070130", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/421", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/95070130"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/421#discussion_r95070130"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/421"}}, "body_html": "<p>save_mean, save_std, running_mean, running_var, weight, grad_weight, bias, grad_bias should be float for half inputs.</p>", "body_text": "save_mean, save_std, running_mean, running_var, weight, grad_weight, bias, grad_bias should be float for half inputs."}