{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7996", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7996/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7996/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7996/events", "html_url": "https://github.com/pytorch/pytorch/issues/7996", "id": 328235404, "node_id": "MDU6SXNzdWUzMjgyMzU0MDQ=", "number": 7996, "title": "[JIT]torch._C._infer_size throws an exception when traced", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-31T17:47:55Z", "updated_at": "2018-08-02T21:23:17Z", "closed_at": "2018-08-02T21:23:17Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>I was experimenting with the <code>torch.jit</code> module in PyTorch master to test time savings on static Pyro models. I found that the call to <code>torch._C._infer_size</code> function in <code>torch.distributions.utils._broadcast_shape</code> fails when the function is traced. All distributions call this function to ensure that the parameters are correctly broadcasted and stored as attributes with the correct shape (even if broadcasting is not required in all instances).</p>\n<p>A minimal example that throws error is pasted below. I am not sure what the status of JIT is currently (and whether distributions are expected to work currently), so please feel free to close this if it is a known issue.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">@</span>torch.jit.trace(torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>))\n<span class=\"pl-c1\">...</span> <span class=\"pl-k\">def</span> <span class=\"pl-en\">fn_to_jit</span>(<span class=\"pl-smi\">a</span>, <span class=\"pl-smi\">b</span>):\n<span class=\"pl-c1\">...</span>     shape <span class=\"pl-k\">=</span> torch._C._infer_size(a.size(), b.size())\n<span class=\"pl-c1\">...</span>     <span class=\"pl-k\">return</span> torch.ones(shape).sum()\n<span class=\"pl-c1\">...</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> fn_to_jit(torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>))</pre></div>\n<p>Error Trace:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\n    pydev_imports.execfile(file, globals, locals)  # execute the script\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 20, in &lt;module&gt;\n    @torch.jit.trace(torch.randn(3, 3), torch.randn(3, 3))\n  File \"/Users/npradhan/miniconda2/envs/pytorch-build/lib/python2.7/site-packages/torch/jit/__init__.py\", line 308, in wrapper\n    return torch._C.GraphExecutor(func, args, **executor_options)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 22, in fn_to_jit\n    shape = torch._C._infer_size(a.size(), b.size())\nRuntimeError: expected int at position 0, but got: Tensor\nfn_to_jit(torch.randn(3, 3), torch.randn(3, 3))\n\n</code></pre>", "body_text": "Issue description\nI was experimenting with the torch.jit module in PyTorch master to test time savings on static Pyro models. I found that the call to torch._C._infer_size function in torch.distributions.utils._broadcast_shape fails when the function is traced. All distributions call this function to ensure that the parameters are correctly broadcasted and stored as attributes with the correct shape (even if broadcasting is not required in all instances).\nA minimal example that throws error is pasted below. I am not sure what the status of JIT is currently (and whether distributions are expected to work currently), so please feel free to close this if it is a known issue.\nCode example\n>>> @torch.jit.trace(torch.randn(3, 3), torch.randn(3, 3))\n... def fn_to_jit(a, b):\n...     shape = torch._C._infer_size(a.size(), b.size())\n...     return torch.ones(shape).sum()\n...\n>>> fn_to_jit(torch.randn(3, 3), torch.randn(3, 3))\nError Trace:\nTraceback (most recent call last):\n  File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\n    pydev_imports.execfile(file, globals, locals)  # execute the script\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 20, in <module>\n    @torch.jit.trace(torch.randn(3, 3), torch.randn(3, 3))\n  File \"/Users/npradhan/miniconda2/envs/pytorch-build/lib/python2.7/site-packages/torch/jit/__init__.py\", line 308, in wrapper\n    return torch._C.GraphExecutor(func, args, **executor_options)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 22, in fn_to_jit\n    shape = torch._C._infer_size(a.size(), b.size())\nRuntimeError: expected int at position 0, but got: Tensor\nfn_to_jit(torch.randn(3, 3), torch.randn(3, 3))", "body": "## Issue description\r\n\r\nI was experimenting with the `torch.jit` module in PyTorch master to test time savings on static Pyro models. I found that the call to `torch._C._infer_size` function in `torch.distributions.utils._broadcast_shape` fails when the function is traced. All distributions call this function to ensure that the parameters are correctly broadcasted and stored as attributes with the correct shape (even if broadcasting is not required in all instances). \r\n\r\nA minimal example that throws error is pasted below. I am not sure what the status of JIT is currently (and whether distributions are expected to work currently), so please feel free to close this if it is a known issue.\r\n\r\n## Code example\r\n\r\n```python\r\n>>> @torch.jit.trace(torch.randn(3, 3), torch.randn(3, 3))\r\n... def fn_to_jit(a, b):\r\n...     shape = torch._C._infer_size(a.size(), b.size())\r\n...     return torch.ones(shape).sum()\r\n...\r\n>>> fn_to_jit(torch.randn(3, 3), torch.randn(3, 3))\r\n```\r\n\r\nError Trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydev_run_in_console.py\", line 53, in run_file\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 20, in <module>\r\n    @torch.jit.trace(torch.randn(3, 3), torch.randn(3, 3))\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-build/lib/python2.7/site-packages/torch/jit/__init__.py\", line 308, in wrapper\r\n    return torch._C.GraphExecutor(func, args, **executor_options)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/examples/jit.py\", line 22, in fn_to_jit\r\n    shape = torch._C._infer_size(a.size(), b.size())\r\nRuntimeError: expected int at position 0, but got: Tensor\r\nfn_to_jit(torch.randn(3, 3), torch.randn(3, 3))\r\n\r\n```\r\n"}