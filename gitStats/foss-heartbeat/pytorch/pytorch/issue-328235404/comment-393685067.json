{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/393685067", "html_url": "https://github.com/pytorch/pytorch/issues/7996#issuecomment-393685067", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7996", "id": 393685067, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MzY4NTA2Nw==", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-31T21:23:28Z", "updated_at": "2018-05-31T21:23:28Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>If we just want to get this working quickly, and don't care about preserving the semantics of _infer_size in traces (meaning they will be bound to a particular input size), then we can just patch the function to accept tensors as well (we have functions for that).</p>\n</blockquote>\n<p>Got it! I think this should work fine for most of our use cases, since this is only called when distribution instances are being constructed, after which the parameters are frozen and should have a fixed shape. One possible downside might be that we will need to pass tensors with the correct shape in the <code>torch.trace</code> annotation, and that can get tricky if it depends on the minibatch size. So eventually, it will be nice to have a more generic support for JIT. cc. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2032320\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/eb8680\">@eb8680</a>.</p>", "body_text": "If we just want to get this working quickly, and don't care about preserving the semantics of _infer_size in traces (meaning they will be bound to a particular input size), then we can just patch the function to accept tensors as well (we have functions for that).\n\nGot it! I think this should work fine for most of our use cases, since this is only called when distribution instances are being constructed, after which the parameters are frozen and should have a fixed shape. One possible downside might be that we will need to pass tensors with the correct shape in the torch.trace annotation, and that can get tricky if it depends on the minibatch size. So eventually, it will be nice to have a more generic support for JIT. cc. @fritzo, @eb8680.", "body": "> If we just want to get this working quickly, and don't care about preserving the semantics of _infer_size in traces (meaning they will be bound to a particular input size), then we can just patch the function to accept tensors as well (we have functions for that).\r\n\r\nGot it! I think this should work fine for most of our use cases, since this is only called when distribution instances are being constructed, after which the parameters are frozen and should have a fixed shape. One possible downside might be that we will need to pass tensors with the correct shape in the `torch.trace` annotation, and that can get tricky if it depends on the minibatch size. So eventually, it will be nice to have a more generic support for JIT. cc. @fritzo, @eb8680. "}