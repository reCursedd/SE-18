{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4631", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4631/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4631/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4631/events", "html_url": "https://github.com/pytorch/pytorch/issues/4631", "id": 288045846, "node_id": "MDU6SXNzdWUyODgwNDU4NDY=", "number": 4631, "title": "Only nn.Parameters defined directly within nn.Module are listed in module.parameters()", "user": {"login": "SahilC", "id": 1071837, "node_id": "MDQ6VXNlcjEwNzE4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1071837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SahilC", "html_url": "https://github.com/SahilC", "followers_url": "https://api.github.com/users/SahilC/followers", "following_url": "https://api.github.com/users/SahilC/following{/other_user}", "gists_url": "https://api.github.com/users/SahilC/gists{/gist_id}", "starred_url": "https://api.github.com/users/SahilC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SahilC/subscriptions", "organizations_url": "https://api.github.com/users/SahilC/orgs", "repos_url": "https://api.github.com/users/SahilC/repos", "events_url": "https://api.github.com/users/SahilC/events{/privacy}", "received_events_url": "https://api.github.com/users/SahilC/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-12T08:46:01Z", "updated_at": "2018-01-12T10:58:53Z", "closed_at": "2018-01-12T10:58:53Z", "author_association": "NONE", "body_html": "<p>I was trying to implement a custom neural network module when I encountered this bug. Only parameters which are defined as attributes of module directly are listed in module.parameters().</p>\n<p>Code to reproduce bug:</p>\n<pre><code>class Module1(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Module1, self).__init__()\n\n        self.w_i = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\n\n\nclass Module2(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Module2, self).__init__()\n\n        self.weights = {}\n        self.weights['w_i'] = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\n\nm = Module1(512, 512)\nprint('m parameters:')\n\nfor i in m.parameters():\n     print(i)\n\nm2 = Module2(512, 512)\nprint('m2 parameters:')\n\nfor i in m2.parameters():\n    print(i)\n</code></pre>\n<p>Pytorch version: 0.3.0</p>\n<p>It makes sense to have parameters which are nested within lists or dictionaries, so shouldn't module.parameters() list all parameters defined within a module?</p>", "body_text": "I was trying to implement a custom neural network module when I encountered this bug. Only parameters which are defined as attributes of module directly are listed in module.parameters().\nCode to reproduce bug:\nclass Module1(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Module1, self).__init__()\n\n        self.w_i = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\n\n\nclass Module2(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Module2, self).__init__()\n\n        self.weights = {}\n        self.weights['w_i'] = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\n\nm = Module1(512, 512)\nprint('m parameters:')\n\nfor i in m.parameters():\n     print(i)\n\nm2 = Module2(512, 512)\nprint('m2 parameters:')\n\nfor i in m2.parameters():\n    print(i)\n\nPytorch version: 0.3.0\nIt makes sense to have parameters which are nested within lists or dictionaries, so shouldn't module.parameters() list all parameters defined within a module?", "body": "I was trying to implement a custom neural network module when I encountered this bug. Only parameters which are defined as attributes of module directly are listed in module.parameters(). \r\n\r\nCode to reproduce bug:\r\n\r\n    class Module1(nn.Module):\r\n        def __init__(self, input_size, hidden_size):\r\n            super(Module1, self).__init__()\r\n\r\n            self.w_i = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\r\n\r\n\r\n    class Module2(nn.Module):\r\n        def __init__(self, input_size, hidden_size):\r\n            super(Module2, self).__init__()\r\n\r\n            self.weights = {}\r\n            self.weights['w_i'] = nn.Parameter(torch.FloatTensor(input_size, hidden_size))\r\n\r\n    m = Module1(512, 512)\r\n    print('m parameters:')\r\n\r\n    for i in m.parameters():\r\n         print(i)\r\n\r\n    m2 = Module2(512, 512)\r\n    print('m2 parameters:')\r\n\r\n    for i in m2.parameters():\r\n        print(i)\r\n\r\nPytorch version: 0.3.0 \r\n\r\nIt makes sense to have parameters which are nested within lists or dictionaries, so shouldn't module.parameters() list all parameters defined within a module?  "}