{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/103997401", "pull_request_review_id": 24545390, "id": 103997401, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwMzk5NzQwMQ==", "diff_hunk": "@@ -19,6 +19,9 @@ auto GradBuffer::addGrad(size_t pos, std::shared_ptr<Variable>&& var) -> void {\n   if (!item.first) {\n     buffer[pos] = std::make_pair<>(std::move(tensor), true);\n   } else {\n+    if (item.first->isSparse() && !tensor->isSparse()) {", "path": "torch/csrc/autograd/grad_buffer.cpp", "position": null, "original_position": 4, "commit_id": "d5a99574d20676583112f982ab429a1ea1ae1a5b", "original_commit_id": "27e053e0c70da19a221e7b9829edde4be2aa6a45", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "So it is ok to mix grad types, as long as the first result is dense? That seems a bit unfortunate, because we don't guarantee any particular order of evaluation of backward, so changes in the engine can suddenly break models.", "created_at": "2017-03-02T18:39:54Z", "updated_at": "2018-11-23T15:32:41Z", "html_url": "https://github.com/pytorch/pytorch/pull/735#discussion_r103997401", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/735", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/103997401"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/735#discussion_r103997401"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/735"}}, "body_html": "<p>So it is ok to mix grad types, as long as the first result is dense? That seems a bit unfortunate, because we don't guarantee any particular order of evaluation of backward, so changes in the engine can suddenly break models.</p>", "body_text": "So it is ok to mix grad types, as long as the first result is dense? That seems a bit unfortunate, because we don't guarantee any particular order of evaluation of backward, so changes in the engine can suddenly break models."}