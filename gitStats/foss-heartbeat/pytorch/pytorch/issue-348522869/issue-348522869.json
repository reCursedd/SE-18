{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10336", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10336/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10336/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10336/events", "html_url": "https://github.com/pytorch/pytorch/pull/10336", "id": 348522869, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA2ODU0NDk4", "number": 10336, "title": "speed up kl div loss", "user": {"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 559719279, "node_id": "MDU6TGFiZWw1NTk3MTkyNzk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/ready%20for%20review", "name": "ready for review", "color": "b60205", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-08-07T23:33:18Z", "updated_at": "2018-11-23T15:50:01Z", "closed_at": "2018-08-27T23:12:03Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10336", "html_url": "https://github.com/pytorch/pytorch/pull/10336", "diff_url": "https://github.com/pytorch/pytorch/pull/10336.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10336.patch"}, "body_html": "<p>Moved kl div loss to aten.</p>\n<p>benchmarks for 5000 iterations on input size (1000,100)</p>\n<p>New</p>\n<pre><code>cuda:\nforward [0.9736350309103727, 0.9922929517924786, 0.9694818360731006]\ninput requires_grad=True:\nbackward [0.5595634011551738, 0.558339926879853, 0.5546616851352155]\ndouble backward [1.2445648494176567, 1.2245905152522027, 1.2349751549772918]\ntarget requires_grad=True:\nbackward (new C++) [0.9489959231577814, 0.9553070571273565, 0.9556351029314101]\ndouble backward (new C++) [1.8184774098917842, 1.8164670099504292, 1.845708406995982]\n\ncpu:\nforward (new C++) [7.892430987209082, 8.3068826389499, 7.985283812973648]\ninput requires_grad=True:\nbackward (new C++) [4.328460982069373, 4.45323242014274, 4.27946363389492]\ndouble backward (new C++) [5.153504415880889, 4.629372010007501, 4.712803596165031]\ntarget requires_grad=True:\nbackward (new C++) [3.4181493939831853, 3.3771288259886205, 3.7086612950079143]\ndouble backward (new C++) [0.21922698011621833, 0.1858532396145165, 0.19477044604718685]\n</code></pre>\n<p>Old</p>\n<pre><code>cuda:\nforward [3.101281268056482, 3.068499860819429, 3.0527669726870954]\ninput requires_grad=True:\nbackward [0.5650290949270129, 0.5730433077551425, 0.5588279226794839]\ndouble backward [1.1287697306834161, 1.13834543293342, 1.1298578432761133]\ntarget requires_grad=True:\nbackward [0.9470391101203859, 0.9560198178514838, 0.9750375030562282]\ndouble backward [1.85760727385059, 1.7989214668050408, 1.788982989732176]\n\ncpu:\nforward (new C++) [12.474591840058565, 12.511441555805504, 12.666544185951352]\ninput requires_grad=True:\nbackward (new C++) [7.660991386976093, 7.449987292289734, 7.513917901087552]\ndouble backward (new C++) [4.073225498665124, 4.264980792999268, 4.429787891916931]\ntarget requires_grad=True:\nbackward (new C++) [3.448499082121998, 3.9072313378565013, 3.2433970272541046]\ndouble backward (new C++) [2.126378359273076, 1.9045450473204255, 1.7932004742324352]\n</code></pre>", "body_text": "Moved kl div loss to aten.\nbenchmarks for 5000 iterations on input size (1000,100)\nNew\ncuda:\nforward [0.9736350309103727, 0.9922929517924786, 0.9694818360731006]\ninput requires_grad=True:\nbackward [0.5595634011551738, 0.558339926879853, 0.5546616851352155]\ndouble backward [1.2445648494176567, 1.2245905152522027, 1.2349751549772918]\ntarget requires_grad=True:\nbackward (new C++) [0.9489959231577814, 0.9553070571273565, 0.9556351029314101]\ndouble backward (new C++) [1.8184774098917842, 1.8164670099504292, 1.845708406995982]\n\ncpu:\nforward (new C++) [7.892430987209082, 8.3068826389499, 7.985283812973648]\ninput requires_grad=True:\nbackward (new C++) [4.328460982069373, 4.45323242014274, 4.27946363389492]\ndouble backward (new C++) [5.153504415880889, 4.629372010007501, 4.712803596165031]\ntarget requires_grad=True:\nbackward (new C++) [3.4181493939831853, 3.3771288259886205, 3.7086612950079143]\ndouble backward (new C++) [0.21922698011621833, 0.1858532396145165, 0.19477044604718685]\n\nOld\ncuda:\nforward [3.101281268056482, 3.068499860819429, 3.0527669726870954]\ninput requires_grad=True:\nbackward [0.5650290949270129, 0.5730433077551425, 0.5588279226794839]\ndouble backward [1.1287697306834161, 1.13834543293342, 1.1298578432761133]\ntarget requires_grad=True:\nbackward [0.9470391101203859, 0.9560198178514838, 0.9750375030562282]\ndouble backward [1.85760727385059, 1.7989214668050408, 1.788982989732176]\n\ncpu:\nforward (new C++) [12.474591840058565, 12.511441555805504, 12.666544185951352]\ninput requires_grad=True:\nbackward (new C++) [7.660991386976093, 7.449987292289734, 7.513917901087552]\ndouble backward (new C++) [4.073225498665124, 4.264980792999268, 4.429787891916931]\ntarget requires_grad=True:\nbackward (new C++) [3.448499082121998, 3.9072313378565013, 3.2433970272541046]\ndouble backward (new C++) [2.126378359273076, 1.9045450473204255, 1.7932004742324352]", "body": "Moved kl div loss to aten.\r\n\r\nbenchmarks for 5000 iterations on input size (1000,100)\r\n\r\nNew\r\n```\r\ncuda:\r\nforward [0.9736350309103727, 0.9922929517924786, 0.9694818360731006]\r\ninput requires_grad=True:\r\nbackward [0.5595634011551738, 0.558339926879853, 0.5546616851352155]\r\ndouble backward [1.2445648494176567, 1.2245905152522027, 1.2349751549772918]\r\ntarget requires_grad=True:\r\nbackward (new C++) [0.9489959231577814, 0.9553070571273565, 0.9556351029314101]\r\ndouble backward (new C++) [1.8184774098917842, 1.8164670099504292, 1.845708406995982]\r\n\r\ncpu:\r\nforward (new C++) [7.892430987209082, 8.3068826389499, 7.985283812973648]\r\ninput requires_grad=True:\r\nbackward (new C++) [4.328460982069373, 4.45323242014274, 4.27946363389492]\r\ndouble backward (new C++) [5.153504415880889, 4.629372010007501, 4.712803596165031]\r\ntarget requires_grad=True:\r\nbackward (new C++) [3.4181493939831853, 3.3771288259886205, 3.7086612950079143]\r\ndouble backward (new C++) [0.21922698011621833, 0.1858532396145165, 0.19477044604718685]\r\n```\r\n\r\nOld\r\n```\r\ncuda:\r\nforward [3.101281268056482, 3.068499860819429, 3.0527669726870954]\r\ninput requires_grad=True:\r\nbackward [0.5650290949270129, 0.5730433077551425, 0.5588279226794839]\r\ndouble backward [1.1287697306834161, 1.13834543293342, 1.1298578432761133]\r\ntarget requires_grad=True:\r\nbackward [0.9470391101203859, 0.9560198178514838, 0.9750375030562282]\r\ndouble backward [1.85760727385059, 1.7989214668050408, 1.788982989732176]\r\n\r\ncpu:\r\nforward (new C++) [12.474591840058565, 12.511441555805504, 12.666544185951352]\r\ninput requires_grad=True:\r\nbackward (new C++) [7.660991386976093, 7.449987292289734, 7.513917901087552]\r\ndouble backward (new C++) [4.073225498665124, 4.264980792999268, 4.429787891916931]\r\ntarget requires_grad=True:\r\nbackward (new C++) [3.448499082121998, 3.9072313378565013, 3.2433970272541046]\r\ndouble backward (new C++) [2.126378359273076, 1.9045450473204255, 1.7932004742324352]\r\n```"}