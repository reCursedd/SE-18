{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10539", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10539/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10539/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10539/events", "html_url": "https://github.com/pytorch/pytorch/issues/10539", "id": 350839707, "node_id": "MDU6SXNzdWUzNTA4Mzk3MDc=", "number": 10539, "title": "pytorch grads are different from TF?", "user": {"login": "xfwu", "id": 4200282, "node_id": "MDQ6VXNlcjQyMDAyODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4200282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xfwu", "html_url": "https://github.com/xfwu", "followers_url": "https://api.github.com/users/xfwu/followers", "following_url": "https://api.github.com/users/xfwu/following{/other_user}", "gists_url": "https://api.github.com/users/xfwu/gists{/gist_id}", "starred_url": "https://api.github.com/users/xfwu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xfwu/subscriptions", "organizations_url": "https://api.github.com/users/xfwu/orgs", "repos_url": "https://api.github.com/users/xfwu/repos", "events_url": "https://api.github.com/users/xfwu/events{/privacy}", "received_events_url": "https://api.github.com/users/xfwu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-08-15T14:51:45Z", "updated_at": "2018-08-15T16:40:32Z", "closed_at": "2018-08-15T16:40:32Z", "author_association": "NONE", "body_html": "<p>problem descriptions:<br>\nI used exactly the same setting ( two simple networks, use both the first network and second networks\u2019s output create two norm distributions and use the KL of the two pdfs as loss\u2026 the first networks output goes directly in to the second network)</p>\n<p>The strange thing is that with the above exact settings, the TF\u2019s grads are different with PTY\u2019s grads. and I did a manual check that the TF\u2019s results are identical with mine</p>\n<p>Can you please help me to understand this?</p>\n<pre><code>import torch\nfrom torch import nn\nfrom torch.autograd import Variable, grad\nimport tensorflow as tf\n\n#define network weights and input\nA_LOC_W = [2.]\nA_SCALE_W = [3.]\nB_LOC_W = [2.]\nB_SCALE_W = [3.]\nINPUT_NUM = 1.\n\n#PyTorch A network\nclass PT_A(nn.Module):\n    def __init__(self):\n        super(PT_A, self).__init__()\n        self.loc_w = Variable(torch.FloatTensor(A_LOC_W), requires_grad=True)\n        self.scale_w = Variable(torch.FloatTensor(A_SCALE_W), requires_grad=True)\n\n    def forward(self, z):\n        loc = self.loc_w * z\n        scale = self.scale_w * z\n        z = z * scale + loc\n        return z, loc, scale\n\n#Tensorflow A network\nclass TF_A:\n    def __init__(self):\n        super(TF_A, self).__init__()\n        self.loc_w = tf.Variable(A_LOC_W)\n        self.scale_w = tf.Variable(A_SCALE_W)\n\n    def forward(self, z):\n        loc = tf.multiply(self.loc_w, z)\n        scale = tf.multiply(self.scale_w, z)\n        z = tf.multiply(z, scale) + loc\n        return z, loc, scale\n\n#PyTorch B network  \nclass PT_B(nn.Module):\n    def __init__(self):\n        super(PT_B, self).__init__()\n        self.loc_w = Variable(torch.FloatTensor(B_LOC_W), requires_grad=True)\n        self.scale_w = Variable(torch.FloatTensor(B_SCALE_W), requires_grad=True)\n\n    def forward(self, x):\n        loc = self.loc_w * x\n        scale = self.scale_w * x\n        return loc, scale\n\n#Tensorflow B network\nclass TF_B:\n    def __init__(self):\n        super(TF_B, self).__init__()\n        self.loc_w = tf.Variable(B_LOC_W)\n        self.scale_w = tf.Variable(B_SCALE_W)\n\n    def forward(self, x):\n        loc = tf.multiply(self.loc_w , x)\n        scale = tf.multiply(self.scale_w , x)\n        return loc, scale\n\n\n#PyTorch Code        \na_net = PT_A()\nb_net = PT_B()\n\n#input -&gt; A\ninput = Variable(torch.FloatTensor([INPUT_NUM]))\na_pred, a_loc, a_scale = a_net(input)\n#output of A -&gt; B\nb_loc, b_scale = b_net(a_pred)\n\n#compute KL loss\na_dis = torch.distributions.normal.Normal(loc=a_loc, scale=a_scale)\nb_dis = torch.distributions.normal.Normal(loc=b_loc, scale=b_scale)\n#kl_loss = torch.distributions.kl._kl_normal_normal(a_dis, b_dis)\nkl_loss = torch.log(b_scale/a_scale) + (a_scale**2 + (a_loc - b_loc)**2) / (2 * b_scale**2) - 0.5\n\n\n#compute grads\ngrads = grad(kl_loss, [kl_loss, a_loc, a_scale, b_loc, b_scale, a_pred])\nkl_loss_loss,a_loc_grad, a_scale_grad, b_loc_grad, b_scale_grad, a_pred_grad = grads[0].item(), \\\n                                                                 grads[1].item(), \\\n                                                                 grads[2].item(), \\\n                                                                 grads[3].item(), \\\n                                                                 grads[4].item(), \\\n                                                                 grads[5].item()\n\n#print\nprint (\"PyTorch a_loc value:{}, grad:{}\".format(a_loc.item(), a_loc_grad))\nprint (\"PyTorch a_scale value:{}, grad:{}\".format(a_scale.item(), a_scale_grad))\nprint (\"PyTorch b_loc value:{}, grad:{}\".format(b_loc.item(), b_loc_grad))\nprint (\"PyTorch b_scale value:{}, grad:{}\".format(b_scale.item(), b_scale_grad))\nprint (\"PyTorch a_pred value:{}, grad:{} \".format(a_pred.item(), a_pred_grad))\nprint (\"PyTorch kl_loss {}, grad:{}\".format(kl_loss.item(),kl_loss_loss))\n\n########Tensorflow Code\n_net = TF_A()\nb_net = TF_B()\n\n#input -&gt; A\ninput = tf.placeholder(tf.float32, [1,])\na_pred, a_loc, a_scale = a_net.forward(input)\n#output of A -&gt; B\nb_loc, b_scale = b_net.forward(a_pred)\n\n#compute KL loss\na_dis = tf.distributions.Normal(loc=a_loc, scale=a_scale)\nb_dis = tf.distributions.Normal(loc=b_loc, scale=b_scale)\nkl_loss = a_dis.kl_divergence(b_dis)\n\n#compute grads\na_loc_grad = tf.gradients(kl_loss, [a_net.loc_w])[0]\na_scale_grad = tf.gradients(kl_loss, [a_net.scale_w])[0]\nb_loc_grad = tf.gradients(kl_loss, [b_net.loc_w])[0]\nb_scale_grad = tf.gradients(kl_loss, [b_net.scale_w])[0]\na_pred_grad = tf.gradients(kl_loss, [a_pred])[0]\n\n\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\nvals = sess.run([a_loc, a_loc_grad, \\\n                 a_scale, a_scale_grad, \\\n                 b_loc, b_loc_grad, \\\n                 b_scale, b_scale_grad, \\\n                 a_pred, a_pred_grad, \\\n                 kl_loss], {input:[INPUT_NUM]})\n#print\nprint (\"Tensorflow a_loc value:{}, grad:{}\".format(vals[0][0], vals[1][0]))\nprint (\"Tensorflow a_scale value:{}, grad:{}\".format(vals[2][0], vals[3][0]))\nprint (\"Tensorflow b_loc value:{}, grad:{}\".format(vals[4][0], vals[5][0]))\nprint (\"Tensorflow b_scale value:{}, grad:{}\".format(vals[6][0], vals[7][0]))\nprint (\"Tensorflow a_pred value:{}, grad:{} \".format(vals[8][0], vals[9][0]))\nprint (\"Tensorflow kl_loss value:{} \".format(vals[10][0]))\n</code></pre>\n<p>the output is</p>\n<pre><code>PyTorch a_loc value:2.0, grad:0.1706666797399521\nPyTorch a_scale value:3.0, grad:-0.11377778649330139\nPyTorch b_loc value:10.0, grad:0.035555556416511536\nPyTorch b_scale value:15.0, grad:0.04503703862428665\nPyTorch a_pred value:5.0, grad:0.20622223615646362 \nPyTorch kl_loss 1.2716602087020874, grad:1.0\n\nTensorflow a_loc value:2.0, grad:0.1706666797399521\nTensorflow a_scale value:3.0, grad:-0.113777756690979\nTensorflow b_loc value:10.0, grad:0.17777778208255768\nTensorflow b_scale value:15.0, grad:0.22518518567085266\nTensorflow a_pred value:5.0, grad:0.20622223615646362 \nTensorflow kl_loss value:1.2716600894927979 \n</code></pre>\n<p>my manual calculations:<br>\nin the<br>\n<a href=\"https://discuss.pytorch.org/t/tf-and-pyt-gradient-are-not-identical/22217\" rel=\"nofollow\">https://discuss.pytorch.org/t/tf-and-pyt-gradient-are-not-identical/22217</a></p>", "body_text": "problem descriptions:\nI used exactly the same setting ( two simple networks, use both the first network and second networks\u2019s output create two norm distributions and use the KL of the two pdfs as loss\u2026 the first networks output goes directly in to the second network)\nThe strange thing is that with the above exact settings, the TF\u2019s grads are different with PTY\u2019s grads. and I did a manual check that the TF\u2019s results are identical with mine\nCan you please help me to understand this?\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable, grad\nimport tensorflow as tf\n\n#define network weights and input\nA_LOC_W = [2.]\nA_SCALE_W = [3.]\nB_LOC_W = [2.]\nB_SCALE_W = [3.]\nINPUT_NUM = 1.\n\n#PyTorch A network\nclass PT_A(nn.Module):\n    def __init__(self):\n        super(PT_A, self).__init__()\n        self.loc_w = Variable(torch.FloatTensor(A_LOC_W), requires_grad=True)\n        self.scale_w = Variable(torch.FloatTensor(A_SCALE_W), requires_grad=True)\n\n    def forward(self, z):\n        loc = self.loc_w * z\n        scale = self.scale_w * z\n        z = z * scale + loc\n        return z, loc, scale\n\n#Tensorflow A network\nclass TF_A:\n    def __init__(self):\n        super(TF_A, self).__init__()\n        self.loc_w = tf.Variable(A_LOC_W)\n        self.scale_w = tf.Variable(A_SCALE_W)\n\n    def forward(self, z):\n        loc = tf.multiply(self.loc_w, z)\n        scale = tf.multiply(self.scale_w, z)\n        z = tf.multiply(z, scale) + loc\n        return z, loc, scale\n\n#PyTorch B network  \nclass PT_B(nn.Module):\n    def __init__(self):\n        super(PT_B, self).__init__()\n        self.loc_w = Variable(torch.FloatTensor(B_LOC_W), requires_grad=True)\n        self.scale_w = Variable(torch.FloatTensor(B_SCALE_W), requires_grad=True)\n\n    def forward(self, x):\n        loc = self.loc_w * x\n        scale = self.scale_w * x\n        return loc, scale\n\n#Tensorflow B network\nclass TF_B:\n    def __init__(self):\n        super(TF_B, self).__init__()\n        self.loc_w = tf.Variable(B_LOC_W)\n        self.scale_w = tf.Variable(B_SCALE_W)\n\n    def forward(self, x):\n        loc = tf.multiply(self.loc_w , x)\n        scale = tf.multiply(self.scale_w , x)\n        return loc, scale\n\n\n#PyTorch Code        \na_net = PT_A()\nb_net = PT_B()\n\n#input -> A\ninput = Variable(torch.FloatTensor([INPUT_NUM]))\na_pred, a_loc, a_scale = a_net(input)\n#output of A -> B\nb_loc, b_scale = b_net(a_pred)\n\n#compute KL loss\na_dis = torch.distributions.normal.Normal(loc=a_loc, scale=a_scale)\nb_dis = torch.distributions.normal.Normal(loc=b_loc, scale=b_scale)\n#kl_loss = torch.distributions.kl._kl_normal_normal(a_dis, b_dis)\nkl_loss = torch.log(b_scale/a_scale) + (a_scale**2 + (a_loc - b_loc)**2) / (2 * b_scale**2) - 0.5\n\n\n#compute grads\ngrads = grad(kl_loss, [kl_loss, a_loc, a_scale, b_loc, b_scale, a_pred])\nkl_loss_loss,a_loc_grad, a_scale_grad, b_loc_grad, b_scale_grad, a_pred_grad = grads[0].item(), \\\n                                                                 grads[1].item(), \\\n                                                                 grads[2].item(), \\\n                                                                 grads[3].item(), \\\n                                                                 grads[4].item(), \\\n                                                                 grads[5].item()\n\n#print\nprint (\"PyTorch a_loc value:{}, grad:{}\".format(a_loc.item(), a_loc_grad))\nprint (\"PyTorch a_scale value:{}, grad:{}\".format(a_scale.item(), a_scale_grad))\nprint (\"PyTorch b_loc value:{}, grad:{}\".format(b_loc.item(), b_loc_grad))\nprint (\"PyTorch b_scale value:{}, grad:{}\".format(b_scale.item(), b_scale_grad))\nprint (\"PyTorch a_pred value:{}, grad:{} \".format(a_pred.item(), a_pred_grad))\nprint (\"PyTorch kl_loss {}, grad:{}\".format(kl_loss.item(),kl_loss_loss))\n\n########Tensorflow Code\n_net = TF_A()\nb_net = TF_B()\n\n#input -> A\ninput = tf.placeholder(tf.float32, [1,])\na_pred, a_loc, a_scale = a_net.forward(input)\n#output of A -> B\nb_loc, b_scale = b_net.forward(a_pred)\n\n#compute KL loss\na_dis = tf.distributions.Normal(loc=a_loc, scale=a_scale)\nb_dis = tf.distributions.Normal(loc=b_loc, scale=b_scale)\nkl_loss = a_dis.kl_divergence(b_dis)\n\n#compute grads\na_loc_grad = tf.gradients(kl_loss, [a_net.loc_w])[0]\na_scale_grad = tf.gradients(kl_loss, [a_net.scale_w])[0]\nb_loc_grad = tf.gradients(kl_loss, [b_net.loc_w])[0]\nb_scale_grad = tf.gradients(kl_loss, [b_net.scale_w])[0]\na_pred_grad = tf.gradients(kl_loss, [a_pred])[0]\n\n\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\nvals = sess.run([a_loc, a_loc_grad, \\\n                 a_scale, a_scale_grad, \\\n                 b_loc, b_loc_grad, \\\n                 b_scale, b_scale_grad, \\\n                 a_pred, a_pred_grad, \\\n                 kl_loss], {input:[INPUT_NUM]})\n#print\nprint (\"Tensorflow a_loc value:{}, grad:{}\".format(vals[0][0], vals[1][0]))\nprint (\"Tensorflow a_scale value:{}, grad:{}\".format(vals[2][0], vals[3][0]))\nprint (\"Tensorflow b_loc value:{}, grad:{}\".format(vals[4][0], vals[5][0]))\nprint (\"Tensorflow b_scale value:{}, grad:{}\".format(vals[6][0], vals[7][0]))\nprint (\"Tensorflow a_pred value:{}, grad:{} \".format(vals[8][0], vals[9][0]))\nprint (\"Tensorflow kl_loss value:{} \".format(vals[10][0]))\n\nthe output is\nPyTorch a_loc value:2.0, grad:0.1706666797399521\nPyTorch a_scale value:3.0, grad:-0.11377778649330139\nPyTorch b_loc value:10.0, grad:0.035555556416511536\nPyTorch b_scale value:15.0, grad:0.04503703862428665\nPyTorch a_pred value:5.0, grad:0.20622223615646362 \nPyTorch kl_loss 1.2716602087020874, grad:1.0\n\nTensorflow a_loc value:2.0, grad:0.1706666797399521\nTensorflow a_scale value:3.0, grad:-0.113777756690979\nTensorflow b_loc value:10.0, grad:0.17777778208255768\nTensorflow b_scale value:15.0, grad:0.22518518567085266\nTensorflow a_pred value:5.0, grad:0.20622223615646362 \nTensorflow kl_loss value:1.2716600894927979 \n\nmy manual calculations:\nin the\nhttps://discuss.pytorch.org/t/tf-and-pyt-gradient-are-not-identical/22217", "body": "problem descriptions:\r\nI used exactly the same setting ( two simple networks, use both the first network and second networks\u2019s output create two norm distributions and use the KL of the two pdfs as loss\u2026 the first networks output goes directly in to the second network)\r\n\r\nThe strange thing is that with the above exact settings, the TF\u2019s grads are different with PTY\u2019s grads. and I did a manual check that the TF\u2019s results are identical with mine\r\n\r\nCan you please help me to understand this?\r\n```\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.autograd import Variable, grad\r\nimport tensorflow as tf\r\n\r\n#define network weights and input\r\nA_LOC_W = [2.]\r\nA_SCALE_W = [3.]\r\nB_LOC_W = [2.]\r\nB_SCALE_W = [3.]\r\nINPUT_NUM = 1.\r\n\r\n#PyTorch A network\r\nclass PT_A(nn.Module):\r\n    def __init__(self):\r\n        super(PT_A, self).__init__()\r\n        self.loc_w = Variable(torch.FloatTensor(A_LOC_W), requires_grad=True)\r\n        self.scale_w = Variable(torch.FloatTensor(A_SCALE_W), requires_grad=True)\r\n\r\n    def forward(self, z):\r\n        loc = self.loc_w * z\r\n        scale = self.scale_w * z\r\n        z = z * scale + loc\r\n        return z, loc, scale\r\n\r\n#Tensorflow A network\r\nclass TF_A:\r\n    def __init__(self):\r\n        super(TF_A, self).__init__()\r\n        self.loc_w = tf.Variable(A_LOC_W)\r\n        self.scale_w = tf.Variable(A_SCALE_W)\r\n\r\n    def forward(self, z):\r\n        loc = tf.multiply(self.loc_w, z)\r\n        scale = tf.multiply(self.scale_w, z)\r\n        z = tf.multiply(z, scale) + loc\r\n        return z, loc, scale\r\n\r\n#PyTorch B network  \r\nclass PT_B(nn.Module):\r\n    def __init__(self):\r\n        super(PT_B, self).__init__()\r\n        self.loc_w = Variable(torch.FloatTensor(B_LOC_W), requires_grad=True)\r\n        self.scale_w = Variable(torch.FloatTensor(B_SCALE_W), requires_grad=True)\r\n\r\n    def forward(self, x):\r\n        loc = self.loc_w * x\r\n        scale = self.scale_w * x\r\n        return loc, scale\r\n\r\n#Tensorflow B network\r\nclass TF_B:\r\n    def __init__(self):\r\n        super(TF_B, self).__init__()\r\n        self.loc_w = tf.Variable(B_LOC_W)\r\n        self.scale_w = tf.Variable(B_SCALE_W)\r\n\r\n    def forward(self, x):\r\n        loc = tf.multiply(self.loc_w , x)\r\n        scale = tf.multiply(self.scale_w , x)\r\n        return loc, scale\r\n\r\n\r\n#PyTorch Code        \r\na_net = PT_A()\r\nb_net = PT_B()\r\n\r\n#input -> A\r\ninput = Variable(torch.FloatTensor([INPUT_NUM]))\r\na_pred, a_loc, a_scale = a_net(input)\r\n#output of A -> B\r\nb_loc, b_scale = b_net(a_pred)\r\n\r\n#compute KL loss\r\na_dis = torch.distributions.normal.Normal(loc=a_loc, scale=a_scale)\r\nb_dis = torch.distributions.normal.Normal(loc=b_loc, scale=b_scale)\r\n#kl_loss = torch.distributions.kl._kl_normal_normal(a_dis, b_dis)\r\nkl_loss = torch.log(b_scale/a_scale) + (a_scale**2 + (a_loc - b_loc)**2) / (2 * b_scale**2) - 0.5\r\n\r\n\r\n#compute grads\r\ngrads = grad(kl_loss, [kl_loss, a_loc, a_scale, b_loc, b_scale, a_pred])\r\nkl_loss_loss,a_loc_grad, a_scale_grad, b_loc_grad, b_scale_grad, a_pred_grad = grads[0].item(), \\\r\n                                                                 grads[1].item(), \\\r\n                                                                 grads[2].item(), \\\r\n                                                                 grads[3].item(), \\\r\n                                                                 grads[4].item(), \\\r\n                                                                 grads[5].item()\r\n\r\n#print\r\nprint (\"PyTorch a_loc value:{}, grad:{}\".format(a_loc.item(), a_loc_grad))\r\nprint (\"PyTorch a_scale value:{}, grad:{}\".format(a_scale.item(), a_scale_grad))\r\nprint (\"PyTorch b_loc value:{}, grad:{}\".format(b_loc.item(), b_loc_grad))\r\nprint (\"PyTorch b_scale value:{}, grad:{}\".format(b_scale.item(), b_scale_grad))\r\nprint (\"PyTorch a_pred value:{}, grad:{} \".format(a_pred.item(), a_pred_grad))\r\nprint (\"PyTorch kl_loss {}, grad:{}\".format(kl_loss.item(),kl_loss_loss))\r\n\r\n########Tensorflow Code\r\n_net = TF_A()\r\nb_net = TF_B()\r\n\r\n#input -> A\r\ninput = tf.placeholder(tf.float32, [1,])\r\na_pred, a_loc, a_scale = a_net.forward(input)\r\n#output of A -> B\r\nb_loc, b_scale = b_net.forward(a_pred)\r\n\r\n#compute KL loss\r\na_dis = tf.distributions.Normal(loc=a_loc, scale=a_scale)\r\nb_dis = tf.distributions.Normal(loc=b_loc, scale=b_scale)\r\nkl_loss = a_dis.kl_divergence(b_dis)\r\n\r\n#compute grads\r\na_loc_grad = tf.gradients(kl_loss, [a_net.loc_w])[0]\r\na_scale_grad = tf.gradients(kl_loss, [a_net.scale_w])[0]\r\nb_loc_grad = tf.gradients(kl_loss, [b_net.loc_w])[0]\r\nb_scale_grad = tf.gradients(kl_loss, [b_net.scale_w])[0]\r\na_pred_grad = tf.gradients(kl_loss, [a_pred])[0]\r\n\r\n\r\nsess = tf.Session()\r\nsess.run(tf.initialize_all_variables())\r\nvals = sess.run([a_loc, a_loc_grad, \\\r\n                 a_scale, a_scale_grad, \\\r\n                 b_loc, b_loc_grad, \\\r\n                 b_scale, b_scale_grad, \\\r\n                 a_pred, a_pred_grad, \\\r\n                 kl_loss], {input:[INPUT_NUM]})\r\n#print\r\nprint (\"Tensorflow a_loc value:{}, grad:{}\".format(vals[0][0], vals[1][0]))\r\nprint (\"Tensorflow a_scale value:{}, grad:{}\".format(vals[2][0], vals[3][0]))\r\nprint (\"Tensorflow b_loc value:{}, grad:{}\".format(vals[4][0], vals[5][0]))\r\nprint (\"Tensorflow b_scale value:{}, grad:{}\".format(vals[6][0], vals[7][0]))\r\nprint (\"Tensorflow a_pred value:{}, grad:{} \".format(vals[8][0], vals[9][0]))\r\nprint (\"Tensorflow kl_loss value:{} \".format(vals[10][0]))\r\n```\r\nthe output is \r\n```\r\nPyTorch a_loc value:2.0, grad:0.1706666797399521\r\nPyTorch a_scale value:3.0, grad:-0.11377778649330139\r\nPyTorch b_loc value:10.0, grad:0.035555556416511536\r\nPyTorch b_scale value:15.0, grad:0.04503703862428665\r\nPyTorch a_pred value:5.0, grad:0.20622223615646362 \r\nPyTorch kl_loss 1.2716602087020874, grad:1.0\r\n\r\nTensorflow a_loc value:2.0, grad:0.1706666797399521\r\nTensorflow a_scale value:3.0, grad:-0.113777756690979\r\nTensorflow b_loc value:10.0, grad:0.17777778208255768\r\nTensorflow b_scale value:15.0, grad:0.22518518567085266\r\nTensorflow a_pred value:5.0, grad:0.20622223615646362 \r\nTensorflow kl_loss value:1.2716600894927979 \r\n```\r\nmy manual calculations: \r\nin the \r\nhttps://discuss.pytorch.org/t/tf-and-pyt-gradient-are-not-identical/22217"}