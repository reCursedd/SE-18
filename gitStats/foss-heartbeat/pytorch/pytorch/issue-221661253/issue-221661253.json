{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1254", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1254/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1254/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1254/events", "html_url": "https://github.com/pytorch/pytorch/issues/1254", "id": 221661253, "node_id": "MDU6SXNzdWUyMjE2NjEyNTM=", "number": 1254, "title": "[proposed feature] np.corrcoef and scipy.stats.pearsonr equivalents", "user": {"login": "ncullen93", "id": 13004360, "node_id": "MDQ6VXNlcjEzMDA0MzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/13004360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ncullen93", "html_url": "https://github.com/ncullen93", "followers_url": "https://api.github.com/users/ncullen93/followers", "following_url": "https://api.github.com/users/ncullen93/following{/other_user}", "gists_url": "https://api.github.com/users/ncullen93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ncullen93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ncullen93/subscriptions", "organizations_url": "https://api.github.com/users/ncullen93/orgs", "repos_url": "https://api.github.com/users/ncullen93/repos", "events_url": "https://api.github.com/users/ncullen93/events{/privacy}", "received_events_url": "https://api.github.com/users/ncullen93/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-13T19:37:22Z", "updated_at": "2017-04-16T20:54:05Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>Hey all,</p>\n<p>I implemented bare bones versions of <code>np.corrcoef</code> and <code>scipy.stats.pearsonr</code>. These are two functions I use all the time, so I often have to convert back and forth to numpy for this. It'd be nice to have these incorporated, although I only see the need for the forward pass.</p>\n<p>Clearly, they need to be in a more suitable format (inheriting from Function?) and need some tests, so any advice &amp; code review there is appreciated. The functions are found below and in this <a href=\"https://gist.github.com/ncullen93/58e71c4303b89e420bd8e0b0aa54bf48\">gist</a></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">pearsonr</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Mimics `scipy.stats.pearsonr`</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Arguments</span>\n<span class=\"pl-s\">    ---------</span>\n<span class=\"pl-s\">    x : 1D torch.Tensor</span>\n<span class=\"pl-s\">    y : 1D torch.Tensor</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Returns</span>\n<span class=\"pl-s\">    -------</span>\n<span class=\"pl-s\">    r_val : float</span>\n<span class=\"pl-s\">        pearsonr correlation coefficient between x and y</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Scipy docs ref:</span>\n<span class=\"pl-s\">        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Scipy code ref:</span>\n<span class=\"pl-s\">        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033</span>\n<span class=\"pl-s\">    Example:</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>x = np.random.randn(100)</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>y = np.random.randn(100)</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>sp_corr = scipy.stats.pearsonr(x, y)[0]</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>np.allclose(sp_corr, th_corr)</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    mean_x <span class=\"pl-k\">=</span> torch.mean(x)\n    mean_y <span class=\"pl-k\">=</span> torch.mean(y)\n    xm <span class=\"pl-k\">=</span> x.sub(mean_x)\n    ym <span class=\"pl-k\">=</span> y.sub(mean_y)\n    r_num <span class=\"pl-k\">=</span> xm.dot(ym)\n    r_den <span class=\"pl-k\">=</span> torch.norm(xm, <span class=\"pl-c1\">2</span>) <span class=\"pl-k\">*</span> torch.norm(ym, <span class=\"pl-c1\">2</span>)\n    r_val <span class=\"pl-k\">=</span> r_num <span class=\"pl-k\">/</span> r_den\n    <span class=\"pl-k\">return</span> r_val\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">corrcoef</span>(<span class=\"pl-smi\">x</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">    Mimics `np.corrcoef`</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Arguments</span>\n<span class=\"pl-s\">    ---------</span>\n<span class=\"pl-s\">    x : 2D torch.Tensor</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Returns</span>\n<span class=\"pl-s\">    -------</span>\n<span class=\"pl-s\">    c : torch.Tensor</span>\n<span class=\"pl-s\">        if x.size() = (5, 100), then return val will be of size (5,5)</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Numpy docs ref:</span>\n<span class=\"pl-s\">        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html</span>\n<span class=\"pl-s\">    Numpy code ref: </span>\n<span class=\"pl-s\">        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Example:</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>x = np.random.randn(5,120)</span>\n<span class=\"pl-s\">        # result is a (5,5) matrix of correlations between rows</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>np_corr = np.corrcoef(x)</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>th_corr = corrcoef(torch.from_numpy(x))</span>\n<span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>np.allclose(np_corr, th_corr.numpy())</span>\n<span class=\"pl-s\">        # [out]: True</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> calculate covariance matrix of rows</span>\n    mean_x <span class=\"pl-k\">=</span> torch.mean(x, <span class=\"pl-c1\">1</span>)\n    xm <span class=\"pl-k\">=</span> x.sub(mean_x.expand_as(x))\n    c <span class=\"pl-k\">=</span> xm.mm(xm.t())\n    c <span class=\"pl-k\">=</span> c <span class=\"pl-k\">/</span> (x.size(<span class=\"pl-c1\">1</span>) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> normalize covariance matrix</span>\n    d <span class=\"pl-k\">=</span> torch.diag(c)\n    stddev <span class=\"pl-k\">=</span> torch.pow(d, <span class=\"pl-c1\">0.5</span>)\n    c <span class=\"pl-k\">=</span> c.div(stddev.expand_as(c))\n    c <span class=\"pl-k\">=</span> c.div(stddev.expand_as(c).t())\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> clamp between -1 and 1</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> probably not necessary but numpy does it</span>\n    c <span class=\"pl-k\">=</span> torch.clamp(c, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>)\n\n    <span class=\"pl-k\">return</span> c</pre></div>", "body_text": "Hey all,\nI implemented bare bones versions of np.corrcoef and scipy.stats.pearsonr. These are two functions I use all the time, so I often have to convert back and forth to numpy for this. It'd be nice to have these incorporated, although I only see the need for the forward pass.\nClearly, they need to be in a more suitable format (inheriting from Function?) and need some tests, so any advice & code review there is appreciated. The functions are found below and in this gist\ndef pearsonr(x, y):\n    \"\"\"\n    Mimics `scipy.stats.pearsonr`\n\n    Arguments\n    ---------\n    x : 1D torch.Tensor\n    y : 1D torch.Tensor\n\n    Returns\n    -------\n    r_val : float\n        pearsonr correlation coefficient between x and y\n    \n    Scipy docs ref:\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n    \n    Scipy code ref:\n        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n    Example:\n        >>> x = np.random.randn(100)\n        >>> y = np.random.randn(100)\n        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n        >>> np.allclose(sp_corr, th_corr)\n    \"\"\"\n    mean_x = torch.mean(x)\n    mean_y = torch.mean(y)\n    xm = x.sub(mean_x)\n    ym = y.sub(mean_y)\n    r_num = xm.dot(ym)\n    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n    r_val = r_num / r_den\n    return r_val\n\ndef corrcoef(x):\n    \"\"\"\n    Mimics `np.corrcoef`\n\n    Arguments\n    ---------\n    x : 2D torch.Tensor\n    \n    Returns\n    -------\n    c : torch.Tensor\n        if x.size() = (5, 100), then return val will be of size (5,5)\n\n    Numpy docs ref:\n        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n    Numpy code ref: \n        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\n\n    Example:\n        >>> x = np.random.randn(5,120)\n        # result is a (5,5) matrix of correlations between rows\n        >>> np_corr = np.corrcoef(x)\n        >>> th_corr = corrcoef(torch.from_numpy(x))\n        >>> np.allclose(np_corr, th_corr.numpy())\n        # [out]: True\n    \"\"\"\n    # calculate covariance matrix of rows\n    mean_x = torch.mean(x, 1)\n    xm = x.sub(mean_x.expand_as(x))\n    c = xm.mm(xm.t())\n    c = c / (x.size(1) - 1)\n\n    # normalize covariance matrix\n    d = torch.diag(c)\n    stddev = torch.pow(d, 0.5)\n    c = c.div(stddev.expand_as(c))\n    c = c.div(stddev.expand_as(c).t())\n\n    # clamp between -1 and 1\n    # probably not necessary but numpy does it\n    c = torch.clamp(c, -1.0, 1.0)\n\n    return c", "body": "Hey all,\r\n\r\nI implemented bare bones versions of `np.corrcoef` and `scipy.stats.pearsonr`. These are two functions I use all the time, so I often have to convert back and forth to numpy for this. It'd be nice to have these incorporated, although I only see the need for the forward pass.\r\n\r\nClearly, they need to be in a more suitable format (inheriting from Function?) and need some tests, so any advice & code review there is appreciated. The functions are found below and in this [gist](https://gist.github.com/ncullen93/58e71c4303b89e420bd8e0b0aa54bf48)\r\n\r\n```python\r\ndef pearsonr(x, y):\r\n    \"\"\"\r\n    Mimics `scipy.stats.pearsonr`\r\n\r\n    Arguments\r\n    ---------\r\n    x : 1D torch.Tensor\r\n    y : 1D torch.Tensor\r\n\r\n    Returns\r\n    -------\r\n    r_val : float\r\n        pearsonr correlation coefficient between x and y\r\n    \r\n    Scipy docs ref:\r\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\r\n    \r\n    Scipy code ref:\r\n        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\r\n    Example:\r\n        >>> x = np.random.randn(100)\r\n        >>> y = np.random.randn(100)\r\n        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\r\n        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\r\n        >>> np.allclose(sp_corr, th_corr)\r\n    \"\"\"\r\n    mean_x = torch.mean(x)\r\n    mean_y = torch.mean(y)\r\n    xm = x.sub(mean_x)\r\n    ym = y.sub(mean_y)\r\n    r_num = xm.dot(ym)\r\n    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\r\n    r_val = r_num / r_den\r\n    return r_val\r\n\r\ndef corrcoef(x):\r\n    \"\"\"\r\n    Mimics `np.corrcoef`\r\n\r\n    Arguments\r\n    ---------\r\n    x : 2D torch.Tensor\r\n    \r\n    Returns\r\n    -------\r\n    c : torch.Tensor\r\n        if x.size() = (5, 100), then return val will be of size (5,5)\r\n\r\n    Numpy docs ref:\r\n        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\r\n    Numpy code ref: \r\n        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\r\n\r\n    Example:\r\n        >>> x = np.random.randn(5,120)\r\n        # result is a (5,5) matrix of correlations between rows\r\n        >>> np_corr = np.corrcoef(x)\r\n        >>> th_corr = corrcoef(torch.from_numpy(x))\r\n        >>> np.allclose(np_corr, th_corr.numpy())\r\n        # [out]: True\r\n    \"\"\"\r\n    # calculate covariance matrix of rows\r\n    mean_x = torch.mean(x, 1)\r\n    xm = x.sub(mean_x.expand_as(x))\r\n    c = xm.mm(xm.t())\r\n    c = c / (x.size(1) - 1)\r\n\r\n    # normalize covariance matrix\r\n    d = torch.diag(c)\r\n    stddev = torch.pow(d, 0.5)\r\n    c = c.div(stddev.expand_as(c))\r\n    c = c.div(stddev.expand_as(c).t())\r\n\r\n    # clamp between -1 and 1\r\n    # probably not necessary but numpy does it\r\n    c = torch.clamp(c, -1.0, 1.0)\r\n\r\n    return c\r\n```"}