{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8108", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8108/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8108/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8108/events", "html_url": "https://github.com/pytorch/pytorch/issues/8108", "id": 328964189, "node_id": "MDU6SXNzdWUzMjg5NjQxODk=", "number": 8108, "title": "Gradients through MultivariateNormal distribution log_prob behaving strangely", "user": {"login": "fleeb24", "id": 29988633, "node_id": "MDQ6VXNlcjI5OTg4NjMz", "avatar_url": "https://avatars1.githubusercontent.com/u/29988633?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fleeb24", "html_url": "https://github.com/fleeb24", "followers_url": "https://api.github.com/users/fleeb24/followers", "following_url": "https://api.github.com/users/fleeb24/following{/other_user}", "gists_url": "https://api.github.com/users/fleeb24/gists{/gist_id}", "starred_url": "https://api.github.com/users/fleeb24/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fleeb24/subscriptions", "organizations_url": "https://api.github.com/users/fleeb24/orgs", "repos_url": "https://api.github.com/users/fleeb24/repos", "events_url": "https://api.github.com/users/fleeb24/events{/privacy}", "received_events_url": "https://api.github.com/users/fleeb24/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-06-04T08:53:23Z", "updated_at": "2018-06-05T14:34:31Z", "closed_at": "2018-06-05T14:34:31Z", "author_association": "NONE", "body_html": "<p>I would like to use MultivariateNormal distributions to compute the log probs of some samples and then differentiate wrt to the distribution mean and covariance matrix. During testing, I encountered a strange inconsistency when trying to compute the gradients wrt the covariance matrix.</p>\n<p>Here's a little test script to test how log_prob behaves, please let me know if you get different results than me</p>\n<pre><code>import torch\nfrom torch.autograd import grad\nimport torch.distributions as distrib\ndef get_n():\n    mu = torch.Tensor([1,2])#torch.randn(2)\n    mu.requires_grad = True\n    sigma = torch.Tensor([2,3])#torch.rand(2) * 10 + 1\n    sigma.requires_grad = True\n\n    n = distrib.MultivariateNormal(loc=mu, covariance_matrix=torch.diag(sigma))\n    return n\ndef check(fn):\n    try:\n        fn()\n    except Exception as e:\n        return 'failed - {}'.format(e)\n    return 'passed'\ndef test1():\n    n = get_n()\n    s = torch.ones(2)\n    grad(n.log_prob(s).sum(), n.covariance_matrix)#, retain_graph=True))\ndef test2():\n    n = get_n()\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix)\ndef test3():\n    n = get_n()\n    s = torch.ones(2)\n    grad(n.log_prob(s).sum(), n.covariance_matrix, retain_graph=True)\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\ndef test4():\n    n = get_n()\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\nprint(check(test1)) # this test passes for me\nprint(check(test2)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\nprint(check(test3)) # this test passes\nprint(check(test4)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\n\n</code></pre>\n<h2>System Info</h2>\n<p>Ubuntu 14.04 - Anaconda 5.x - Python 3.6 (I don't think this is system dependent)</p>\n<p>Thanks for the help!</p>", "body_text": "I would like to use MultivariateNormal distributions to compute the log probs of some samples and then differentiate wrt to the distribution mean and covariance matrix. During testing, I encountered a strange inconsistency when trying to compute the gradients wrt the covariance matrix.\nHere's a little test script to test how log_prob behaves, please let me know if you get different results than me\nimport torch\nfrom torch.autograd import grad\nimport torch.distributions as distrib\ndef get_n():\n    mu = torch.Tensor([1,2])#torch.randn(2)\n    mu.requires_grad = True\n    sigma = torch.Tensor([2,3])#torch.rand(2) * 10 + 1\n    sigma.requires_grad = True\n\n    n = distrib.MultivariateNormal(loc=mu, covariance_matrix=torch.diag(sigma))\n    return n\ndef check(fn):\n    try:\n        fn()\n    except Exception as e:\n        return 'failed - {}'.format(e)\n    return 'passed'\ndef test1():\n    n = get_n()\n    s = torch.ones(2)\n    grad(n.log_prob(s).sum(), n.covariance_matrix)#, retain_graph=True))\ndef test2():\n    n = get_n()\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix)\ndef test3():\n    n = get_n()\n    s = torch.ones(2)\n    grad(n.log_prob(s).sum(), n.covariance_matrix, retain_graph=True)\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\ndef test4():\n    n = get_n()\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\nprint(check(test1)) # this test passes for me\nprint(check(test2)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\nprint(check(test3)) # this test passes\nprint(check(test4)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\n\n\nSystem Info\nUbuntu 14.04 - Anaconda 5.x - Python 3.6 (I don't think this is system dependent)\nThanks for the help!", "body": "I would like to use MultivariateNormal distributions to compute the log probs of some samples and then differentiate wrt to the distribution mean and covariance matrix. During testing, I encountered a strange inconsistency when trying to compute the gradients wrt the covariance matrix.\r\n\r\nHere's a little test script to test how log_prob behaves, please let me know if you get different results than me\r\n\r\n```\r\nimport torch\r\nfrom torch.autograd import grad\r\nimport torch.distributions as distrib\r\ndef get_n():\r\n    mu = torch.Tensor([1,2])#torch.randn(2)\r\n    mu.requires_grad = True\r\n    sigma = torch.Tensor([2,3])#torch.rand(2) * 10 + 1\r\n    sigma.requires_grad = True\r\n\r\n    n = distrib.MultivariateNormal(loc=mu, covariance_matrix=torch.diag(sigma))\r\n    return n\r\ndef check(fn):\r\n    try:\r\n        fn()\r\n    except Exception as e:\r\n        return 'failed - {}'.format(e)\r\n    return 'passed'\r\ndef test1():\r\n    n = get_n()\r\n    s = torch.ones(2)\r\n    grad(n.log_prob(s).sum(), n.covariance_matrix)#, retain_graph=True))\r\ndef test2():\r\n    n = get_n()\r\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix)\r\ndef test3():\r\n    n = get_n()\r\n    s = torch.ones(2)\r\n    grad(n.log_prob(s).sum(), n.covariance_matrix, retain_graph=True)\r\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\r\ndef test4():\r\n    n = get_n()\r\n    grad(n.log_prob(n.sample()).sum(), n.covariance_matrix, retain_graph=True)\r\nprint(check(test1)) # this test passes for me\r\nprint(check(test2)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\r\nprint(check(test3)) # this test passes\r\nprint(check(test4)) # this test fails (One of the differentiated Tensors appears to not have been used in the graph)\r\n\r\n```\r\n## System Info\r\nUbuntu 14.04 - Anaconda 5.x - Python 3.6 (I don't think this is system dependent)\r\n\r\nThanks for the help!"}