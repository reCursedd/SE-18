{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6286", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6286/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6286/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6286/events", "html_url": "https://github.com/pytorch/pytorch/issues/6286", "id": 311417474, "node_id": "MDU6SXNzdWUzMTE0MTc0NzQ=", "number": 6286, "title": "Doing an operation on tensors of a different device", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 912691507, "node_id": "MDU6TGFiZWw5MTI2OTE1MDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/c10", "name": "c10", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-04T22:50:42Z", "updated_at": "2018-06-16T07:40:36Z", "closed_at": "2018-06-16T07:40:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In ATen, doing operation on tensors of a different device seems unspecified.</p>\n<div class=\"highlight highlight-source-c++\"><pre>at::Tensor x, y;\n{\n  AutoGPU <span class=\"pl-smi\">autogpu</span>(<span class=\"pl-c1\">0</span>);\n  x = <span class=\"pl-c1\">at::CUDA</span>(at::<span class=\"pl-c1\">kFloat</span>).<span class=\"pl-c1\">randn</span>({<span class=\"pl-c1\">100</span>});\n  y = <span class=\"pl-c1\">at::CUDA</span>(at::<span class=\"pl-c1\">kFloat</span>).<span class=\"pl-c1\">randn</span>({<span class=\"pl-c1\">100</span>});\n}\n{\n  AutoGPU <span class=\"pl-smi\">autogpu</span>(<span class=\"pl-c1\">1</span>);\n  <span class=\"pl-k\">auto</span> z = x * y; <span class=\"pl-c\"><span class=\"pl-c\">//</span> What happens here? Error | Copy z to GPU 1 | keep z on GPU 0</span>\n}</pre></div>\n<p>Currently, according to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> there's an error. However, writing models, I think it's preferred it be one of the latter options, since my model will work but maybe just a bit slower. I think <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> just suggested that keeping z on GPU 0 is the way PyTorch goes, and maybe ATen should also do this</p>", "body_text": "In ATen, doing operation on tensors of a different device seems unspecified.\nat::Tensor x, y;\n{\n  AutoGPU autogpu(0);\n  x = at::CUDA(at::kFloat).randn({100});\n  y = at::CUDA(at::kFloat).randn({100});\n}\n{\n  AutoGPU autogpu(1);\n  auto z = x * y; // What happens here? Error | Copy z to GPU 1 | keep z on GPU 0\n}\nCurrently, according to @ezyang there's an error. However, writing models, I think it's preferred it be one of the latter options, since my model will work but maybe just a bit slower. I think @gchanan just suggested that keeping z on GPU 0 is the way PyTorch goes, and maybe ATen should also do this", "body": "In ATen, doing operation on tensors of a different device seems unspecified. \r\n\r\n```c++\r\nat::Tensor x, y;\r\n{\r\n  AutoGPU autogpu(0);\r\n  x = at::CUDA(at::kFloat).randn({100});\r\n  y = at::CUDA(at::kFloat).randn({100});\r\n}\r\n{\r\n  AutoGPU autogpu(1);\r\n  auto z = x * y; // What happens here? Error | Copy z to GPU 1 | keep z on GPU 0\r\n}\r\n```\r\n\r\nCurrently, according to @ezyang there's an error. However, writing models, I think it's preferred it be one of the latter options, since my model will work but maybe just a bit slower. I think @gchanan just suggested that keeping z on GPU 0 is the way PyTorch goes, and maybe ATen should also do this\r\n"}