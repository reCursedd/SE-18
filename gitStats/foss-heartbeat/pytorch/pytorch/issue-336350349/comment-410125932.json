{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/410125932", "html_url": "https://github.com/pytorch/pytorch/pull/8958#issuecomment-410125932", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8958", "id": 410125932, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDEyNTkzMg==", "user": {"login": "alsrgv", "id": 16640218, "node_id": "MDQ6VXNlcjE2NjQwMjE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16640218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsrgv", "html_url": "https://github.com/alsrgv", "followers_url": "https://api.github.com/users/alsrgv/followers", "following_url": "https://api.github.com/users/alsrgv/following{/other_user}", "gists_url": "https://api.github.com/users/alsrgv/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsrgv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsrgv/subscriptions", "organizations_url": "https://api.github.com/users/alsrgv/orgs", "repos_url": "https://api.github.com/users/alsrgv/repos", "events_url": "https://api.github.com/users/alsrgv/events{/privacy}", "received_events_url": "https://api.github.com/users/alsrgv/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-03T02:32:16Z", "updated_at": "2018-08-03T02:32:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This change makes <code>DistributedSampler</code> very slow.  To repro, take <a href=\"https://github.com/pytorch/examples/blob/master/mnist/main.py\">MNIST example</a> and add <code>DistributedSampler</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>    train_dataset <span class=\"pl-k\">=</span> \\\n        datasets.MNIST(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">download</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                       <span class=\"pl-v\">transform</span><span class=\"pl-k\">=</span>transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((<span class=\"pl-c1\">0.1307</span>,), (<span class=\"pl-c1\">0.3081</span>,))\n                       ]))\n    train_loader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(train_dataset,\n        <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>args.batch_size, <span class=\"pl-v\">sampler</span><span class=\"pl-k\">=</span>torch.utils.data.distributed.DistributedSampler(train_dataset, <span class=\"pl-v\">num_replicas</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">rank</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>), <span class=\"pl-k\">**</span>kwargs)</pre></div>\n<p>The reason seems to be that it creates a lot of tensors for each index element.  I was able to make it fast again by adding the cast to int.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2872615\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dmitriy-serdyuk\">@dmitriy-serdyuk</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>", "body_text": "This change makes DistributedSampler very slow.  To repro, take MNIST example and add DistributedSampler:\n    train_dataset = \\\n        datasets.MNIST('../data', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ]))\n    train_loader = torch.utils.data.DataLoader(train_dataset,\n        batch_size=args.batch_size, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=1, rank=0), **kwargs)\nThe reason seems to be that it creates a lot of tensors for each index element.  I was able to make it fast again by adding the cast to int.\ncc @dmitriy-serdyuk, @apaszke", "body": "This change makes `DistributedSampler` very slow.  To repro, take [MNIST example](https://github.com/pytorch/examples/blob/master/mnist/main.py) and add `DistributedSampler`:\r\n\r\n```python\r\n    train_dataset = \\\r\n        datasets.MNIST('../data', train=True, download=True,\r\n                       transform=transforms.Compose([\r\n                           transforms.ToTensor(),\r\n                           transforms.Normalize((0.1307,), (0.3081,))\r\n                       ]))\r\n    train_loader = torch.utils.data.DataLoader(train_dataset,\r\n        batch_size=args.batch_size, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=1, rank=0), **kwargs)\r\n```\r\n\r\nThe reason seems to be that it creates a lot of tensors for each index element.  I was able to make it fast again by adding the cast to int.\r\n\r\ncc @dmitriy-serdyuk, @apaszke "}