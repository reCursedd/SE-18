{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6959", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6959/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6959/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6959/events", "html_url": "https://github.com/pytorch/pytorch/issues/6959", "id": 317739655, "node_id": "MDU6SXNzdWUzMTc3Mzk2NTU=", "number": 6959, "title": "RecursionError when using torch.utils.checkpoint", "user": {"login": "shubhtuls", "id": 2220731, "node_id": "MDQ6VXNlcjIyMjA3MzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/2220731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shubhtuls", "html_url": "https://github.com/shubhtuls", "followers_url": "https://api.github.com/users/shubhtuls/followers", "following_url": "https://api.github.com/users/shubhtuls/following{/other_user}", "gists_url": "https://api.github.com/users/shubhtuls/gists{/gist_id}", "starred_url": "https://api.github.com/users/shubhtuls/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shubhtuls/subscriptions", "organizations_url": "https://api.github.com/users/shubhtuls/orgs", "repos_url": "https://api.github.com/users/shubhtuls/repos", "events_url": "https://api.github.com/users/shubhtuls/events{/privacy}", "received_events_url": "https://api.github.com/users/shubhtuls/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 914008058, "node_id": "MDU6TGFiZWw5MTQwMDgwNTg=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/checkpoint", "name": "checkpoint", "color": "f7ec1d", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-25T18:17:51Z", "updated_at": "2018-06-05T01:31:20Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi,<br>\nThanks for adding the checkpoint feature in the new release.</p>\n<p>I was trying to use it in a setting where there are many 'inputs', which we want to first independently process using 'module' (but not store intermediate states) and then jointly reason over. Below is a code sample for this that results in 'RecursionError: maximum recursion depth exceeded'. If the code does not use checkpoint, everything runs fine.</p>\n<p>I was wondering if there is a way to handle this.</p>\n<p>Thanks!</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n<span class=\"pl-k\">from</span> torch.utils.checkpoint <span class=\"pl-k\">import</span> checkpoint\n\nnum_inp <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5000</span>\n\nnz_inp <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\nnz_out <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\nnz_bottleneck <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> small proxy network for some complex reasoning we want to do per input</span>\nmodule <span class=\"pl-k\">=</span> nn.Sequential(\n    nn.Linear(nz_inp, nz_bottleneck),\n    nn.ReLU(),\n    nn.Linear(nz_bottleneck, nz_inp)\n)\n\nfeat_combined <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> r <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_inp):\n    data_r <span class=\"pl-k\">=</span> torch.Tensor(<span class=\"pl-c1\">1</span>, nz_inp)\n    data_r.uniform_()\n    data_r.requires_grad<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> feat_r = module(data_r) # using this instead of checkpoint line below works fine</span>\n    feat_r <span class=\"pl-k\">=</span> checkpoint(module, data_r)\n\n    feat_combined.append(feat_r)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compute mean as a proxy for some joint reasoning</span>\nmean_combined <span class=\"pl-k\">=</span> torch.stack(feat_combined).mean()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> the backward pass makes the code crash</span>\nmean_combined.backward()</pre></div>", "body_text": "Hi,\nThanks for adding the checkpoint feature in the new release.\nI was trying to use it in a setting where there are many 'inputs', which we want to first independently process using 'module' (but not store intermediate states) and then jointly reason over. Below is a code sample for this that results in 'RecursionError: maximum recursion depth exceeded'. If the code does not use checkpoint, everything runs fine.\nI was wondering if there is a way to handle this.\nThanks!\nimport torch\nfrom torch import nn\nfrom torch.utils.checkpoint import checkpoint\n\nnum_inp = 5000\n\nnz_inp = 10\nnz_out = 10\nnz_bottleneck = 1000\n\n# small proxy network for some complex reasoning we want to do per input\nmodule = nn.Sequential(\n    nn.Linear(nz_inp, nz_bottleneck),\n    nn.ReLU(),\n    nn.Linear(nz_bottleneck, nz_inp)\n)\n\nfeat_combined = []\nfor r in range(num_inp):\n    data_r = torch.Tensor(1, nz_inp)\n    data_r.uniform_()\n    data_r.requires_grad=True\n    # feat_r = module(data_r) # using this instead of checkpoint line below works fine\n    feat_r = checkpoint(module, data_r)\n\n    feat_combined.append(feat_r)\n\n# compute mean as a proxy for some joint reasoning\nmean_combined = torch.stack(feat_combined).mean()\n\n# the backward pass makes the code crash\nmean_combined.backward()", "body": "Hi,\r\nThanks for adding the checkpoint feature in the new release.\r\n\r\nI was trying to use it in a setting where there are many 'inputs', which we want to first independently process using 'module' (but not store intermediate states) and then jointly reason over. Below is a code sample for this that results in 'RecursionError: maximum recursion depth exceeded'. If the code does not use checkpoint, everything runs fine.\r\n\r\nI was wondering if there is a way to handle this.\r\n\r\nThanks!\r\n\r\n```python\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.utils.checkpoint import checkpoint\r\n\r\nnum_inp = 5000\r\n\r\nnz_inp = 10\r\nnz_out = 10\r\nnz_bottleneck = 1000\r\n\r\n# small proxy network for some complex reasoning we want to do per input\r\nmodule = nn.Sequential(\r\n    nn.Linear(nz_inp, nz_bottleneck),\r\n    nn.ReLU(),\r\n    nn.Linear(nz_bottleneck, nz_inp)\r\n)\r\n\r\nfeat_combined = []\r\nfor r in range(num_inp):\r\n    data_r = torch.Tensor(1, nz_inp)\r\n    data_r.uniform_()\r\n    data_r.requires_grad=True\r\n    # feat_r = module(data_r) # using this instead of checkpoint line below works fine\r\n    feat_r = checkpoint(module, data_r)\r\n\r\n    feat_combined.append(feat_r)\r\n\r\n# compute mean as a proxy for some joint reasoning\r\nmean_combined = torch.stack(feat_combined).mean()\r\n\r\n# the backward pass makes the code crash\r\nmean_combined.backward()\r\n```\r\n\r\n\r\n"}