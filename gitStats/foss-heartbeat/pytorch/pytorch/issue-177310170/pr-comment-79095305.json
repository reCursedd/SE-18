{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/79095305", "pull_request_review_id": 284347, "id": 79095305, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc5MDk1MzA1", "diff_hunk": "@@ -0,0 +1,290 @@\n+import ctypes\n+import torch.cuda\n+\n+lib = None\n+\n+def _loadlib():\n+    global lib\n+    lib = ctypes.cdll.LoadLibrary('libcudnn.so.5.0.5')\n+    lib.cudnnGetErrorString.restype = ctypes.c_char_p\n+\n+\n+_handles = {}\n+\n+benchmark = False\n+verbose = False\n+workspace_limit = None\n+\n+CUDNN_DATA_FLOAT = 0\n+CUDNN_DATA_DOUBLE = 1\n+CUDNN_DATA_HALF = 2\n+\n+CUDNN_CONVOLUTION = 0\n+CUDNN_CROSS_CORRELATION = 1\n+\n+CUDNN_CONVOLUTION_FWD_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_FWD_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_CONVOLUTION_BWD_FILTER_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_TENSOR_NCHW = 0\n+CUDNN_TENSOR_NHWC = 1\n+\n+\n+class CuDNNHandle:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreate(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroy(self))\n+\n+class CuDNNError(RuntimeError):\n+    def __init__(self, status):\n+        self.status = status\n+        msg = '{}: {}'.format(status, get_error_string(status))\n+        super(CuDNNError, self).__init__(msg)\n+\n+class TensorDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateTensorDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyTensorDescriptor(self))\n+\n+    def set(self, tensor):\n+        self._type = tensor.type()\n+        self._size = tensor.size()\n+        self._stride = tensor.stride()\n+        check_error(lib.cudnnSetTensorNdDescriptor(\n+            self, _typemap[tensor.type()], tensor.dim(),\n+            int_array(tensor.size()), int_array(tensor.stride())))\n+\n+    def as_tuple(self):\n+        return (self._type, tuple(self._size), tuple(self._stride))\n+\n+class ConvolutionDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateConvolutionDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyConvolutionDescriptor(self))\n+\n+    def set(self, typename, pad, stride):\n+        self._pad = pad\n+        self._stride = stride\n+        upscale = int_array([1, 1])\n+        check_error(lib.cudnnSetConvolutionNdDescriptor(\n+            self, 2, int_array(pad), int_array(stride), upscale,\n+            CUDNN_CROSS_CORRELATION, _typemap[typename]))\n+\n+    def as_tuple(self):\n+        return (self._pad, self._stride)\n+\n+class FilterDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateFilterDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyFilterDescriptor(self))\n+\n+    def set(self, weight):\n+        self._size = weight.size()\n+        datatype = _typemap[weight.type()]\n+        check_error(lib.cudnnSetFilterNdDescriptor(\n+            self, datatype, CUDNN_TENSOR_NCHW, 4, int_array(weight.size())))\n+\n+    def as_tuple(self):\n+        return tuple(self._size)\n+\n+class ConvolutionAlgoPerf(ctypes.Structure):\n+    _fields_ = [\n+        (\"algo\", ctypes.c_int),\n+        (\"status\", ctypes.c_int),\n+        (\"time\", ctypes.c_float),\n+        (\"memory\", ctypes.c_size_t),\n+    ]\n+\n+def check_error(status):\n+    if status is not 0:\n+        raise CuDNNError(status)\n+\n+def get_error_string(status):\n+    return lib.cudnnGetErrorString(status)\n+\n+def get_handle():\n+    if lib is None:\n+        _loadlib()\n+    current_device = torch.cuda.current_device()\n+    handle = _handles.get(current_device, None)\n+    if handle is None:\n+        handle = CuDNNHandle()\n+        _handles[current_device] = handle\n+    return handle\n+\n+_typemap = {\n+    'torch.cuda.HalfTensor': CUDNN_DATA_HALF,\n+    'torch.cuda.FloatTensor': CUDNN_DATA_FLOAT,\n+    'torch.cuda.DoubleTensor': CUDNN_DATA_DOUBLE,\n+}\n+\n+def c_type(tensor):\n+    if isinstance(tensor, torch.cuda.HalfTensor):\n+        return ctypes.c_float", "path": "torch/cuda/cudnn.py", "position": null, "original_position": 147, "commit_id": "e2c52918dd85a87f5ac4033b2f1e6a57e01c40a5", "original_commit_id": "ab82860687eb0fd9e89ee69daded7c2bd37fbeed", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Yes, the corresponding CPU-type for scalars for GPU half-type is float. See https://github.com/soumith/cudnn.torch/blob/master/init.lua#L55\n", "created_at": "2016-09-16T01:40:40Z", "updated_at": "2018-11-23T15:31:29Z", "html_url": "https://github.com/pytorch/pytorch/pull/36#discussion_r79095305", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/36", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/79095305"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/36#discussion_r79095305"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/36"}}, "body_html": "<p>Yes, the corresponding CPU-type for scalars for GPU half-type is float. See <a href=\"https://github.com/soumith/cudnn.torch/blob/master/init.lua#L55\">https://github.com/soumith/cudnn.torch/blob/master/init.lua#L55</a></p>", "body_text": "Yes, the corresponding CPU-type for scalars for GPU half-type is float. See https://github.com/soumith/cudnn.torch/blob/master/init.lua#L55", "in_reply_to_id": 79094378}