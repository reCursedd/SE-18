{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/79094733", "pull_request_review_id": 283488, "id": 79094733, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc5MDk0NzMz", "diff_hunk": "@@ -0,0 +1,290 @@\n+import ctypes\n+import torch.cuda\n+\n+lib = None\n+\n+def _loadlib():\n+    global lib\n+    lib = ctypes.cdll.LoadLibrary('libcudnn.so.5.0.5')\n+    lib.cudnnGetErrorString.restype = ctypes.c_char_p\n+\n+\n+_handles = {}\n+\n+benchmark = False\n+verbose = False\n+workspace_limit = None\n+\n+CUDNN_DATA_FLOAT = 0\n+CUDNN_DATA_DOUBLE = 1\n+CUDNN_DATA_HALF = 2\n+\n+CUDNN_CONVOLUTION = 0\n+CUDNN_CROSS_CORRELATION = 1\n+\n+CUDNN_CONVOLUTION_FWD_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_FWD_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_CONVOLUTION_BWD_FILTER_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE = 0\n+CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST = 1\n+CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT = 2\n+\n+CUDNN_TENSOR_NCHW = 0\n+CUDNN_TENSOR_NHWC = 1\n+\n+\n+class CuDNNHandle:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreate(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroy(self))\n+\n+class CuDNNError(RuntimeError):\n+    def __init__(self, status):\n+        self.status = status\n+        msg = '{}: {}'.format(status, get_error_string(status))\n+        super(CuDNNError, self).__init__(msg)\n+\n+class TensorDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateTensorDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyTensorDescriptor(self))\n+\n+    def set(self, tensor):\n+        self._type = tensor.type()\n+        self._size = tensor.size()\n+        self._stride = tensor.stride()\n+        check_error(lib.cudnnSetTensorNdDescriptor(\n+            self, _typemap[tensor.type()], tensor.dim(),\n+            int_array(tensor.size()), int_array(tensor.stride())))\n+\n+    def as_tuple(self):\n+        return (self._type, tuple(self._size), tuple(self._stride))\n+\n+class ConvolutionDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateConvolutionDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyConvolutionDescriptor(self))\n+\n+    def set(self, typename, pad, stride):\n+        self._pad = pad\n+        self._stride = stride\n+        upscale = int_array([1, 1])\n+        check_error(lib.cudnnSetConvolutionNdDescriptor(\n+            self, 2, int_array(pad), int_array(stride), upscale,\n+            CUDNN_CROSS_CORRELATION, _typemap[typename]))\n+\n+    def as_tuple(self):\n+        return (self._pad, self._stride)\n+\n+class FilterDescriptor:\n+    def __init__(self):\n+        ptr = ctypes.c_void_p()\n+        check_error(lib.cudnnCreateFilterDescriptor(ctypes.byref(ptr)))\n+        self._as_parameter_ = ptr\n+\n+    def __del__(self):\n+        check_error(lib.cudnnDestroyFilterDescriptor(self))\n+\n+    def set(self, weight):\n+        self._size = weight.size()\n+        datatype = _typemap[weight.type()]\n+        check_error(lib.cudnnSetFilterNdDescriptor(\n+            self, datatype, CUDNN_TENSOR_NCHW, 4, int_array(weight.size())))\n+\n+    def as_tuple(self):\n+        return tuple(self._size)\n+\n+class ConvolutionAlgoPerf(ctypes.Structure):\n+    _fields_ = [\n+        (\"algo\", ctypes.c_int),\n+        (\"status\", ctypes.c_int),\n+        (\"time\", ctypes.c_float),\n+        (\"memory\", ctypes.c_size_t),\n+    ]\n+\n+def check_error(status):\n+    if status is not 0:\n+        raise CuDNNError(status)\n+\n+def get_error_string(status):\n+    return lib.cudnnGetErrorString(status)\n+\n+def get_handle():\n+    if lib is None:\n+        _loadlib()\n+    current_device = torch.cuda.current_device()\n+    handle = _handles.get(current_device, None)\n+    if handle is None:\n+        handle = CuDNNHandle()\n+        _handles[current_device] = handle\n+    return handle\n+\n+_typemap = {\n+    'torch.cuda.HalfTensor': CUDNN_DATA_HALF,\n+    'torch.cuda.FloatTensor': CUDNN_DATA_FLOAT,\n+    'torch.cuda.DoubleTensor': CUDNN_DATA_DOUBLE,\n+}\n+\n+def c_type(tensor):\n+    if isinstance(tensor, torch.cuda.HalfTensor):\n+        return ctypes.c_float\n+    elif isinstance(tensor, torch.cuda.FloatTensor):\n+        return ctypes.c_float\n+    elif isinstance(tensor, torch.cuda.DoubleTensor):\n+        return ctypes.c_double\n+    else:\n+        raise ValueError(\"unknown type '{}'\".format(type(tensor)))\n+\n+def int_array(itr):\n+    array_type = ctypes.c_int * len(itr)\n+    return array_type(*itr)\n+\n+def descriptor(tensor):\n+    descriptor = TensorDescriptor()\n+    if tensor.dim() == 2:\n+        tensor = tensor.view(tensor.size(0), tensor.size(1), 1, 1)\n+    elif tensor.dim() == 3:\n+        tensor = tensor.view(tensor.size(0), tensor.size(1), tensor.size(2), 1)\n+    descriptor.set(tensor)\n+    return descriptor\n+\n+_autotuner_forward = {}\n+_autotuner_backward_data = {}\n+_autotuner_backward_filter = {}\n+\n+def convolution_autotuner_key(idesc, weight_desc, conv_desc):\n+    return (idesc.as_tuple(), weight_desc.as_tuple(), conv_desc.as_tuple())\n+\n+def convolution_forward_algorithm(idesc, weight_desc, conv_desc, odesc):\n+    k = convolution_autotuner_key(idesc, weight_desc, conv_desc)\n+    if k in _autotuner_forward:\n+        return _autotuner_forward[k]\n+\n+    if benchmark:\n+        perf_results = ConvolutionAlgoPerf()\n+        algo_count = ctypes.c_int()\n+        check_error(lib.cudnnFindConvolutionForwardAlgorithm(\n+            get_handle(), idesc, weight_desc, conv_desc, odesc, 1,\n+            ctypes.byref(algo_count), ctypes.byref(perf_results)))\n+        _autotuner_forward[k] = perf_results.algo\n+        return perf_results.algo\n+\n+    search_mode = CUDNN_CONVOLUTION_FWD_PREFER_FASTEST\n+    wlimit = 0\n+    if workspace_limit is not None:\n+        wlimit = workspace_limit\n+        search_mode = CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT\n+\n+    fwd_alg = ctypes.c_int()\n+    check_error(lib.cudnnGetConvolutionForwardAlgorithm(\n+        get_handle(), idesc, weight_desc, conv_desc, odesc, search_mode,\n+        wlimit, ctypes.byref(fwd_alg)))\n+    return fwd_alg\n+\n+def convolution_forward_workspace_size(*args):\n+    check_error(lib.cudnnGetConvolutionForwardWorkspaceSize(*args))\n+\n+def convolution_forward(*args):\n+    check_error(lib.cudnnConvolutionForward(*args))\n+\n+def convolution_backward_data(*args):\n+    return check_error(lib.cudnnConvolutionBackwardData(*args))\n+\n+def convolution_backward_data_algorithm(weight_desc, odesc, conv_desc, idesc):\n+    k = convolution_autotuner_key(idesc, weight_desc, conv_desc)\n+    if k in _autotuner_backward_data:\n+        return _autotuner_backward_data[k]\n+\n+    if benchmark:\n+        perf_results = ConvolutionAlgoPerf()\n+        algo_count = ctypes.c_int()\n+        check_error(lib.cudnnFindConvolutionBackwardDataAlgorithm(\n+            get_handle(), weight_desc, odesc, conv_desc, idesc, 1,\n+            ctypes.byref(algo_count), ctypes.byref(perf_results)))\n+        _autotuner_backward_data[k] = perf_results.algo\n+        return perf_results.algo\n+\n+    search_mode = CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST\n+    wlimit = 0\n+    if workspace_limit is not None:\n+        wlimit = workspace_limit\n+        search_mode = CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT\n+\n+    bwd_data_alg = ctypes.c_int()\n+    check_error(lib.cudnnGetConvolutionBackwardDataAlgorithm(\n+        get_handle(), weight_desc, odesc, conv_desc, idesc, search_mode,\n+        wlimit, ctypes.byref(bwd_data_alg)))\n+    return bwd_data_alg\n+\n+def convolution_backward_data_workspace_size(*args):\n+    return check_error(lib.cudnnGetConvolutionBackwardDataWorkspaceSize(*args))\n+\n+def convolution_backward_filter(*args):\n+    return check_error(lib.cudnnConvolutionBackwardFilter(*args))\n+\n+def convolution_backward_filter_algorithm(idesc, odesc, conv_desc, weight_desc):\n+    k = convolution_autotuner_key(idesc, weight_desc, conv_desc)\n+    if k in _autotuner_backward_filter:\n+        return _autotuner_backward_filter[k]\n+\n+    if benchmark:\n+        perf_results = ConvolutionAlgoPerf()\n+        algo_count = ctypes.c_int()\n+        check_error(lib.cudnnFindConvolutionBackwardFilterAlgorithm(\n+            get_handle(), idesc, odesc, conv_desc, weight_desc, 1,\n+            ctypes.byref(algo_count), ctypes.byref(perf_results)))\n+        _autotuner_backward_filter[k] = perf_results.algo\n+        return perf_results.algo\n+\n+    search_mode = CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST\n+    wlimit = 0\n+    if workspace_limit is not None:\n+        wlimit = workspace_limit\n+        search_mode = CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT\n+\n+    bwd_filter_alg = ctypes.c_int()\n+    check_error(lib.cudnnGetConvolutionBackwardFilterAlgorithm(\n+        get_handle(), idesc, odesc, conv_desc, weight_desc, search_mode,\n+        wlimit, ctypes.byref(bwd_filter_alg)))\n+    return bwd_filter_alg\n+\n+def convolution_backward_filter_workspace_size(*args):\n+    return check_error(lib.cudnnGetConvolutionBackwardFilterWorkspaceSize(*args))\n+\n+def convolution_backward_bias(*args):\n+    check_error(lib.cudnnConvolutionBackwardBias(*args))\n+\n+def add_tensor(*args):\n+    check_error(lib.cudnnAddTensor(*args))\n+\n+def is_acceptable(tensor):\n+    return (isinstance(tensor, torch.cuda.HalfTensor) or\n+            isinstance(tensor, torch.cuda.FloatTensor) or\n+            isinstance(tensor, torch.cuda.DoubleTensor))\n+\n+def element_size(tensor):", "path": "torch/cuda/cudnn.py", "position": null, "original_position": 282, "commit_id": "e2c52918dd85a87f5ac4033b2f1e6a57e01c40a5", "original_commit_id": "ab82860687eb0fd9e89ee69daded7c2bd37fbeed", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Could you please implement `element_size` as tensor method?\n", "created_at": "2016-09-16T01:31:40Z", "updated_at": "2018-11-23T15:31:29Z", "html_url": "https://github.com/pytorch/pytorch/pull/36#discussion_r79094733", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/36", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/79094733"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/36#discussion_r79094733"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/36"}}, "body_html": "<p>Could you please implement <code>element_size</code> as tensor method?</p>", "body_text": "Could you please implement element_size as tensor method?"}