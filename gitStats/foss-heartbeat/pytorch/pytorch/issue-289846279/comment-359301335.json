{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/359301335", "html_url": "https://github.com/pytorch/pytorch/issues/4738#issuecomment-359301335", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4738", "id": 359301335, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTMwMTMzNQ==", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-22T01:28:41Z", "updated_at": "2018-01-22T08:14:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I think <a href=\"https://github.com/intel/pytorch/blob/dev-omp/aten/src/TH/THTensorApply.h#L375\">ivdep</a> and <a href=\"https://github.com/intel/pytorch/blob/dev-omp/aten/src/TH/THTensorApply.h#L383\">simd</a> pragma directive will hint the compiler to vectorize many math operations like <code>exp</code> and <code>log</code> when the operands are contiguous.<br>\nI have enabled Intel compiler on PyTorch and benchmarked some <a href=\"https://github.com/MlWoo/PyTorch-benchmark\">data</a>.  ICC version on intel PyTorch could gains <strong>8.43X</strong>, while GCC could gains <strong>6.59X</strong>.</p>", "body_text": "@apaszke I think ivdep and simd pragma directive will hint the compiler to vectorize many math operations like exp and log when the operands are contiguous.\nI have enabled Intel compiler on PyTorch and benchmarked some data.  ICC version on intel PyTorch could gains 8.43X, while GCC could gains 6.59X.", "body": "@apaszke I think [ivdep](https://github.com/intel/pytorch/blob/dev-omp/aten/src/TH/THTensorApply.h#L375) and [simd](https://github.com/intel/pytorch/blob/dev-omp/aten/src/TH/THTensorApply.h#L383) pragma directive will hint the compiler to vectorize many math operations like `exp` and `log` when the operands are contiguous. \r\nI have enabled Intel compiler on PyTorch and benchmarked some [data](https://github.com/MlWoo/PyTorch-benchmark).  ICC version on intel PyTorch could gains __8.43X__, while GCC could gains __6.59X__. "}