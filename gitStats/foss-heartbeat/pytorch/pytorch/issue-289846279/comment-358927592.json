{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/358927592", "html_url": "https://github.com/pytorch/pytorch/issues/4738#issuecomment-358927592", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4738", "id": 358927592, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODkyNzU5Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T10:31:16Z", "updated_at": "2018-01-19T10:31:16Z", "author_association": "MEMBER", "body_html": "<p>It is ok, but I don't think it's particularily useful. Once someone has 3D data it's likely that the individual tensors are large and it would be much faster to process them on the GPU. I think it would be better to focus on optimization of ops that are more commonly used on the CPU. For example, our reduction functions (<code>sum</code>, <code>prod</code>) aren't vectorized at all. Additionally, ops like <code>exp</code> or <code>log</code> could be changed to use vectorized versions that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a> has added recently (right now they can't be vectorized because they use <code>libm</code> implementations). Next, ops like <code>Softmax</code> and <code>LogSoftmax</code> are heavily bottlenecked on <code>exp</code> and <code>log</code> and this also prevents them from being vectorized. In general I think there are many low hanging fruits that would be much more useful to the whole community.</p>", "body_text": "It is ok, but I don't think it's particularily useful. Once someone has 3D data it's likely that the individual tensors are large and it would be much faster to process them on the GPU. I think it would be better to focus on optimization of ops that are more commonly used on the CPU. For example, our reduction functions (sum, prod) aren't vectorized at all. Additionally, ops like exp or log could be changed to use vectorized versions that @goldsborough has added recently (right now they can't be vectorized because they use libm implementations). Next, ops like Softmax and LogSoftmax are heavily bottlenecked on exp and log and this also prevents them from being vectorized. In general I think there are many low hanging fruits that would be much more useful to the whole community.", "body": "It is ok, but I don't think it's particularily useful. Once someone has 3D data it's likely that the individual tensors are large and it would be much faster to process them on the GPU. I think it would be better to focus on optimization of ops that are more commonly used on the CPU. For example, our reduction functions (`sum`, `prod`) aren't vectorized at all. Additionally, ops like `exp` or `log` could be changed to use vectorized versions that @goldsborough has added recently (right now they can't be vectorized because they use `libm` implementations). Next, ops like `Softmax` and `LogSoftmax` are heavily bottlenecked on `exp` and `log` and this also prevents them from being vectorized. In general I think there are many low hanging fruits that would be much more useful to the whole community."}