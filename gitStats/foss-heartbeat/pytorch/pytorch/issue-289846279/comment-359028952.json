{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/359028952", "html_url": "https://github.com/pytorch/pytorch/issues/4738#issuecomment-359028952", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4738", "id": 359028952, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTAyODk1Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T17:07:06Z", "updated_at": "2018-01-19T17:07:06Z", "author_association": "MEMBER", "body_html": "<p>Just out of curiosity how does <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"258349266\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2764\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2764/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2764\">#2764</a> allow us to use SIMD for <code>exp</code> or <code>log</code>? As far as I understood, it only improves some thread-level paralellism, not vectorization. For example the inner loop of <code>sum</code> in that PR still can't be vectorized because we compile without <code>-ffast-math</code>, so the fact that we're using a single accumulator prevents this optimization. Remember that the results you're getting with <code>icc</code> (which has this flag on by default IIRC) might not be representable of the assembly that <code>gcc</code> and <code>clang</code> produce, but these are the compilers that 99.99% of our users use (since they're free). In fact, we're only using <code>gcc</code> to build our binaries.</p>", "body_text": "Just out of curiosity how does #2764 allow us to use SIMD for exp or log? As far as I understood, it only improves some thread-level paralellism, not vectorization. For example the inner loop of sum in that PR still can't be vectorized because we compile without -ffast-math, so the fact that we're using a single accumulator prevents this optimization. Remember that the results you're getting with icc (which has this flag on by default IIRC) might not be representable of the assembly that gcc and clang produce, but these are the compilers that 99.99% of our users use (since they're free). In fact, we're only using gcc to build our binaries.", "body": "Just out of curiosity how does #2764 allow us to use SIMD for `exp` or `log`? As far as I understood, it only improves some thread-level paralellism, not vectorization. For example the inner loop of `sum` in that PR still can't be vectorized because we compile without `-ffast-math`, so the fact that we're using a single accumulator prevents this optimization. Remember that the results you're getting with `icc` (which has this flag on by default IIRC) might not be representable of the assembly that `gcc` and `clang` produce, but these are the compilers that 99.99% of our users use (since they're free). In fact, we're only using `gcc` to build our binaries."}