{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2934", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2934/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2934/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2934/events", "html_url": "https://github.com/pytorch/pytorch/issues/2934", "id": 262214957, "node_id": "MDU6SXNzdWUyNjIyMTQ5NTc=", "number": 2934, "title": "__setitem__ with numpy arrays and sequences", "user": {"login": "kohr-h", "id": 5030250, "node_id": "MDQ6VXNlcjUwMzAyNTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/5030250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kohr-h", "html_url": "https://github.com/kohr-h", "followers_url": "https://api.github.com/users/kohr-h/followers", "following_url": "https://api.github.com/users/kohr-h/following{/other_user}", "gists_url": "https://api.github.com/users/kohr-h/gists{/gist_id}", "starred_url": "https://api.github.com/users/kohr-h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kohr-h/subscriptions", "organizations_url": "https://api.github.com/users/kohr-h/orgs", "repos_url": "https://api.github.com/users/kohr-h/repos", "events_url": "https://api.github.com/users/kohr-h/events{/privacy}", "received_events_url": "https://api.github.com/users/kohr-h/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-10-02T20:23:19Z", "updated_at": "2017-10-02T20:23:19Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>Hi, I wonder if there are plans to add support for assignment with Numpy arrays or sequence types.</p>\n<p>A working but rather lame implementation for Numpy arrays would be</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">__setitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">indices</span>, <span class=\"pl-smi\">values</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(values, np.ndarray):\n        values <span class=\"pl-k\">=</span> torch.from_numpy(values)\n    <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">self</span>), <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__setitem__</span>(indices, values)</pre></div>\n<p>For list or sequences, one could do something equally lame:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">__setitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">indices</span>, <span class=\"pl-smi\">values</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(values, torch._TensorBase) <span class=\"pl-k\">and</span> <span class=\"pl-k\">not</span> np.isscalar(values):\n        values <span class=\"pl-k\">=</span> <span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">self</span>)(values)\n    <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">self</span>), <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__setitem__</span>(indices, values)</pre></div>\n<p>This won't support broadcasting, but it may be better than nothing. A fix for broadcasting in whole-tensor assignment situations could be</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">__setitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">indices</span>, <span class=\"pl-smi\">values</span>):\n    <span class=\"pl-c1\">...</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">iterable</span>(<span class=\"pl-smi\">obj</span>):\n        <span class=\"pl-k\">try</span>:\n            <span class=\"pl-c1\">iter</span>(obj)\n        <span class=\"pl-k\">except</span> <span class=\"pl-c1\">TypeError</span>:\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">False</span>\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">True</span>\n\n    <span class=\"pl-k\">if</span> (<span class=\"pl-c1\">isinstance</span>(values, torch._TensorBase) <span class=\"pl-k\">and</span>\n            (indices <span class=\"pl-k\">in</span> (<span class=\"pl-c1\">slice</span>(<span class=\"pl-c1\">None</span>), <span class=\"pl-c1\">Ellipsis</span>)) <span class=\"pl-k\">or</span>\n            (iterable(indices) <span class=\"pl-k\">and</span> <span class=\"pl-c1\">all</span>(i <span class=\"pl-k\">in</span> (<span class=\"pl-c1\">slice</span>(<span class=\"pl-c1\">None</span>), <span class=\"pl-c1\">Ellipsis</span>)\n                                       <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> indices))):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Covers `x[:] = values`, `x[:, :] = values` etc, and `x[...] = values`</span>\n        <span class=\"pl-c1\">self</span>.copy_(values)</pre></div>", "body_text": "Hi, I wonder if there are plans to add support for assignment with Numpy arrays or sequence types.\nA working but rather lame implementation for Numpy arrays would be\ndef __setitem__(self, indices, values):\n    if isinstance(values, np.ndarray):\n        values = torch.from_numpy(values)\n    super(type(self), self).__setitem__(indices, values)\nFor list or sequences, one could do something equally lame:\ndef __setitem__(self, indices, values):\n    if not isinstance(values, torch._TensorBase) and not np.isscalar(values):\n        values = type(self)(values)\n    super(type(self), self).__setitem__(indices, values)\nThis won't support broadcasting, but it may be better than nothing. A fix for broadcasting in whole-tensor assignment situations could be\ndef __setitem__(self, indices, values):\n    ...\n    def iterable(obj):\n        try:\n            iter(obj)\n        except TypeError:\n            return False\n        else:\n            return True\n\n    if (isinstance(values, torch._TensorBase) and\n            (indices in (slice(None), Ellipsis)) or\n            (iterable(indices) and all(i in (slice(None), Ellipsis)\n                                       for i in indices))):\n        # Covers `x[:] = values`, `x[:, :] = values` etc, and `x[...] = values`\n        self.copy_(values)", "body": "Hi, I wonder if there are plans to add support for assignment with Numpy arrays or sequence types.\r\n\r\nA working but rather lame implementation for Numpy arrays would be\r\n```python\r\ndef __setitem__(self, indices, values):\r\n    if isinstance(values, np.ndarray):\r\n        values = torch.from_numpy(values)\r\n    super(type(self), self).__setitem__(indices, values)\r\n```\r\nFor list or sequences, one could do something equally lame:\r\n```python\r\ndef __setitem__(self, indices, values):\r\n    if not isinstance(values, torch._TensorBase) and not np.isscalar(values):\r\n        values = type(self)(values)\r\n    super(type(self), self).__setitem__(indices, values)\r\n```\r\nThis won't support broadcasting, but it may be better than nothing. A fix for broadcasting in whole-tensor assignment situations could be\r\n```python\r\ndef __setitem__(self, indices, values):\r\n    ...\r\n    def iterable(obj):\r\n        try:\r\n            iter(obj)\r\n        except TypeError:\r\n            return False\r\n        else:\r\n            return True\r\n\r\n    if (isinstance(values, torch._TensorBase) and\r\n            (indices in (slice(None), Ellipsis)) or\r\n            (iterable(indices) and all(i in (slice(None), Ellipsis)\r\n                                       for i in indices))):\r\n        # Covers `x[:] = values`, `x[:, :] = values` etc, and `x[...] = values`\r\n        self.copy_(values)\r\n```"}