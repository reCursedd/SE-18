{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109316970", "pull_request_review_id": 30411608, "id": 109316970, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwOTMxNjk3MA==", "diff_hunk": "@@ -16,12 +20,18 @@ def parallel_apply(modules, inputs, kwargs_tup=None):\n     lock = threading.Lock()\n     results = {}\n \n+    def _get_device(obj):\n+        if isinstance(obj, Variable):\n+            return torch.cuda.device_of(obj)\n+        if isinstance(obj, collections.Iterable):\n+            vals = obj.values() if isinstance(obj, collections.Mapping) else obj\n+            return next(dev for dev in map(_get_device, vals) if dev is not None)", "path": "torch/nn/parallel/parallel_apply.py", "position": 25, "original_position": 25, "commit_id": "2150be2acf3f2720956eef3f427cf585fa303b09", "original_commit_id": "2150be2acf3f2720956eef3f427cf585fa303b09", "user": {"login": "nhynes", "id": 2353785, "node_id": "MDQ6VXNlcjIzNTM3ODU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2353785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nhynes", "html_url": "https://github.com/nhynes", "followers_url": "https://api.github.com/users/nhynes/followers", "following_url": "https://api.github.com/users/nhynes/following{/other_user}", "gists_url": "https://api.github.com/users/nhynes/gists{/gist_id}", "starred_url": "https://api.github.com/users/nhynes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nhynes/subscriptions", "organizations_url": "https://api.github.com/users/nhynes/orgs", "repos_url": "https://api.github.com/users/nhynes/repos", "events_url": "https://api.github.com/users/nhynes/events{/privacy}", "received_events_url": "https://api.github.com/users/nhynes/received_events", "type": "User", "site_admin": false}, "body": "All sorts of other errors occur before here if there are no inputs :) These are all easily fixed, but if there are no inputs do zero or all devices run?\r\nI think the latter makes sense since it allows generating the input for each replica directly on the device (useful for noise inputs). It also helps with failing fast since, instead of silently ignoring a bad null input, eventually the replicated module will complain.", "created_at": "2017-04-02T19:07:53Z", "updated_at": "2018-11-23T15:32:57Z", "html_url": "https://github.com/pytorch/pytorch/pull/1169#discussion_r109316970", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1169", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109316970"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1169#discussion_r109316970"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1169"}}, "body_html": "<p>All sorts of other errors occur before here if there are no inputs :) These are all easily fixed, but if there are no inputs do zero or all devices run?<br>\nI think the latter makes sense since it allows generating the input for each replica directly on the device (useful for noise inputs). It also helps with failing fast since, instead of silently ignoring a bad null input, eventually the replicated module will complain.</p>", "body_text": "All sorts of other errors occur before here if there are no inputs :) These are all easily fixed, but if there are no inputs do zero or all devices run?\nI think the latter makes sense since it allows generating the input for each replica directly on the device (useful for noise inputs). It also helps with failing fast since, instead of silently ignoring a bad null input, eventually the replicated module will complain.", "in_reply_to_id": 109314839}