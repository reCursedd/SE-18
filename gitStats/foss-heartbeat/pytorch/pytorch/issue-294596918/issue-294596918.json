{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5067", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5067/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5067/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5067/events", "html_url": "https://github.com/pytorch/pytorch/issues/5067", "id": 294596918, "node_id": "MDU6SXNzdWUyOTQ1OTY5MTg=", "number": 5067, "title": ".backward bug with .squeeze()", "user": {"login": "jpchen", "id": 1869641, "node_id": "MDQ6VXNlcjE4Njk2NDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1869641?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpchen", "html_url": "https://github.com/jpchen", "followers_url": "https://api.github.com/users/jpchen/followers", "following_url": "https://api.github.com/users/jpchen/following{/other_user}", "gists_url": "https://api.github.com/users/jpchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpchen/subscriptions", "organizations_url": "https://api.github.com/users/jpchen/orgs", "repos_url": "https://api.github.com/users/jpchen/repos", "events_url": "https://api.github.com/users/jpchen/events{/privacy}", "received_events_url": "https://api.github.com/users/jpchen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-02-06T01:03:34Z", "updated_at": "2018-02-06T02:26:20Z", "closed_at": "2018-02-06T02:24:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>for python 3 and any version of pytorch, when using <code>.squeeze()</code>, autograd will append a dimension on the backward pass, even if that dimension has been collapsed out. simple example below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">model</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n      <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n          <span class=\"pl-c1\">super</span>(model, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n          <span class=\"pl-c1\">self</span>.linear <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>)\n \n      <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n          <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.linear(x).squeeze()\n\nm <span class=\"pl-k\">=</span> model()\nd <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">1</span>))\nout <span class=\"pl-k\">=</span> m(d)\nout.backward() <span class=\"pl-c\"><span class=\"pl-c\">#</span> RuntimeError: matrices expected, got [1 x 1 x 1], [1 x 1] at /Users/jpchen/pytorch/aten/src/TH/generic/THTensorMath.c:1428</span></pre></div>", "body_text": "for python 3 and any version of pytorch, when using .squeeze(), autograd will append a dimension on the backward pass, even if that dimension has been collapsed out. simple example below:\nclass model(nn.Module):\n      def __init__(self):\n          super(model, self).__init__()\n          self.linear = nn.Linear(1, 1)\n \n      def forward(self, x):\n          return self.linear(x).squeeze()\n\nm = model()\nd = Variable(torch.randn(1))\nout = m(d)\nout.backward() # RuntimeError: matrices expected, got [1 x 1 x 1], [1 x 1] at /Users/jpchen/pytorch/aten/src/TH/generic/THTensorMath.c:1428", "body": "for python 3 and any version of pytorch, when using `.squeeze()`, autograd will append a dimension on the backward pass, even if that dimension has been collapsed out. simple example below:\r\n```python\r\nclass model(nn.Module):\r\n      def __init__(self):\r\n          super(model, self).__init__()\r\n          self.linear = nn.Linear(1, 1)\r\n \r\n      def forward(self, x):\r\n          return self.linear(x).squeeze()\r\n\r\nm = model()\r\nd = Variable(torch.randn(1))\r\nout = m(d)\r\nout.backward() # RuntimeError: matrices expected, got [1 x 1 x 1], [1 x 1] at /Users/jpchen/pytorch/aten/src/TH/generic/THTensorMath.c:1428\r\n```"}