{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1389", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1389/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1389/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1389/events", "html_url": "https://github.com/pytorch/pytorch/issues/1389", "id": 224972443, "node_id": "MDU6SXNzdWUyMjQ5NzI0NDM=", "number": 1389, "title": "Inconsistent behavior between ByteTensor and Variable(ByteTensor): bug or feature?", "user": {"login": "WarBean", "id": 5501392, "node_id": "MDQ6VXNlcjU1MDEzOTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5501392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WarBean", "html_url": "https://github.com/WarBean", "followers_url": "https://api.github.com/users/WarBean/followers", "following_url": "https://api.github.com/users/WarBean/following{/other_user}", "gists_url": "https://api.github.com/users/WarBean/gists{/gist_id}", "starred_url": "https://api.github.com/users/WarBean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WarBean/subscriptions", "organizations_url": "https://api.github.com/users/WarBean/orgs", "repos_url": "https://api.github.com/users/WarBean/repos", "events_url": "https://api.github.com/users/WarBean/events{/privacy}", "received_events_url": "https://api.github.com/users/WarBean/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}, {"id": 526654084, "node_id": "MDU6TGFiZWw1MjY2NTQwODQ=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/on%20hold", "name": "on hold", "color": "cccccc", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-04-28T03:46:05Z", "updated_at": "2018-04-24T20:35:33Z", "closed_at": "2018-04-24T20:35:33Z", "author_association": "NONE", "body_html": "<p>Test script:</p>\n<pre><code>import torch\nfrom torch.autograd import Variable\n\nbyte_tensor = torch.ByteTensor(256)\nbyte_tensor[:] = 1\nbyte_variable = Variable(byte_tensor)\n# The results should be the same, but actually not\nprint('byte_tensor.sum():')\nprint(byte_tensor.sum())\nprint('byte_variable.sum():')\nprint(byte_variable.sum())\n</code></pre>\n<p>Results:</p>\n<pre><code>byte_tensor.sum():\n256\nbyte_variable.sum():\nVariable containing:\n 0\n[torch.ByteTensor of size 1]\n</code></pre>\n<p>Looks like <code>ByteTensor</code> <strong>does handle overflow</strong> but <code>Variable(ByteTensor)</code> <strong>doesn't</strong>. Such inconsistency has caused some troubles when I'm calculating my model's accuracy.</p>", "body_text": "Test script:\nimport torch\nfrom torch.autograd import Variable\n\nbyte_tensor = torch.ByteTensor(256)\nbyte_tensor[:] = 1\nbyte_variable = Variable(byte_tensor)\n# The results should be the same, but actually not\nprint('byte_tensor.sum():')\nprint(byte_tensor.sum())\nprint('byte_variable.sum():')\nprint(byte_variable.sum())\n\nResults:\nbyte_tensor.sum():\n256\nbyte_variable.sum():\nVariable containing:\n 0\n[torch.ByteTensor of size 1]\n\nLooks like ByteTensor does handle overflow but Variable(ByteTensor) doesn't. Such inconsistency has caused some troubles when I'm calculating my model's accuracy.", "body": "Test script:\r\n\r\n```\r\nimport torch\r\nfrom torch.autograd import Variable\r\n\r\nbyte_tensor = torch.ByteTensor(256)\r\nbyte_tensor[:] = 1\r\nbyte_variable = Variable(byte_tensor)\r\n# The results should be the same, but actually not\r\nprint('byte_tensor.sum():')\r\nprint(byte_tensor.sum())\r\nprint('byte_variable.sum():')\r\nprint(byte_variable.sum())\r\n```\r\n\r\nResults:\r\n\r\n```\r\nbyte_tensor.sum():\r\n256\r\nbyte_variable.sum():\r\nVariable containing:\r\n 0\r\n[torch.ByteTensor of size 1]\r\n```\r\n\r\nLooks like `ByteTensor` **does handle overflow** but `Variable(ByteTensor)` **doesn't**. Such inconsistency has caused some troubles when I'm calculating my model's accuracy."}