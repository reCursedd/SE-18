{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6002", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6002/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6002/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6002/events", "html_url": "https://github.com/pytorch/pytorch/issues/6002", "id": 308530707, "node_id": "MDU6SXNzdWUzMDg1MzA3MDc=", "number": 6002, "title": "Error loading gzipped weights", "user": {"login": "Atnas1010", "id": 11504118, "node_id": "MDQ6VXNlcjExNTA0MTE4", "avatar_url": "https://avatars1.githubusercontent.com/u/11504118?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Atnas1010", "html_url": "https://github.com/Atnas1010", "followers_url": "https://api.github.com/users/Atnas1010/followers", "following_url": "https://api.github.com/users/Atnas1010/following{/other_user}", "gists_url": "https://api.github.com/users/Atnas1010/gists{/gist_id}", "starred_url": "https://api.github.com/users/Atnas1010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Atnas1010/subscriptions", "organizations_url": "https://api.github.com/users/Atnas1010/orgs", "repos_url": "https://api.github.com/users/Atnas1010/repos", "events_url": "https://api.github.com/users/Atnas1010/events{/privacy}", "received_events_url": "https://api.github.com/users/Atnas1010/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-03-26T11:18:45Z", "updated_at": "2018-05-31T19:06:39Z", "closed_at": "2018-05-31T19:06:39Z", "author_association": "NONE", "body_html": "<p>I'm trying to compress the weights of a network using gzip. Here is a MWE:</p>\n<pre><code>import torch, shutil, gzip\nimport torchvision.models as models\nresnet18 = models.resnet18()\ntorch.save(resnet18.state_dict(), 'test.pt')\nwith open('test.pt', 'rb') as f_in, gzip.open('test.pt.gz', 'wb') as f_out:\n    shutil.copyfileobj(f_in, f_out)\n    #f_out.write(f_in.read())\n    \nwith gzip.open('test.pt.gz', 'rb') as f:\n    state_dict = torch.load(f)\n</code></pre>\n<p>When loading the compressed file I get the error:</p>\n<pre><code>  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 267, in load\n    return _load(f, map_location, pickle_module)\n  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 428, in _load\n    deserialized_objects[key]._set_from_file(f, offset)\nRuntimeError: storage has wrong size: expected -772918636240159923 got 64\n</code></pre>\n<p>Even if I create the file using <code>f_out.write(f_in.read())</code> I still get the same error. The <code>test.pt</code> is identical to <code>test.pt.gz</code> when I compare them using <code>f.read()</code>. It works if I open the uncompressed file:</p>\n<pre><code>with open('test.pt', 'rb') as f:\n    state_dict = torch.load(f)\n</code></pre>\n<p>The expected size is sometimes negative, which leads me to believe it could be some sort of underflow, but it also changes each time it's run, so it must also be related to the randomly generated weights.</p>\n<p>I'm using:</p>\n<ul>\n<li>OS: ubuntu 16.04</li>\n<li>PyTorch version: 0.3.1</li>\n<li>Installed via: conda</li>\n<li>Python version: 3.5.2</li>\n</ul>", "body_text": "I'm trying to compress the weights of a network using gzip. Here is a MWE:\nimport torch, shutil, gzip\nimport torchvision.models as models\nresnet18 = models.resnet18()\ntorch.save(resnet18.state_dict(), 'test.pt')\nwith open('test.pt', 'rb') as f_in, gzip.open('test.pt.gz', 'wb') as f_out:\n    shutil.copyfileobj(f_in, f_out)\n    #f_out.write(f_in.read())\n    \nwith gzip.open('test.pt.gz', 'rb') as f:\n    state_dict = torch.load(f)\n\nWhen loading the compressed file I get the error:\n  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 267, in load\n    return _load(f, map_location, pickle_module)\n  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 428, in _load\n    deserialized_objects[key]._set_from_file(f, offset)\nRuntimeError: storage has wrong size: expected -772918636240159923 got 64\n\nEven if I create the file using f_out.write(f_in.read()) I still get the same error. The test.pt is identical to test.pt.gz when I compare them using f.read(). It works if I open the uncompressed file:\nwith open('test.pt', 'rb') as f:\n    state_dict = torch.load(f)\n\nThe expected size is sometimes negative, which leads me to believe it could be some sort of underflow, but it also changes each time it's run, so it must also be related to the randomly generated weights.\nI'm using:\n\nOS: ubuntu 16.04\nPyTorch version: 0.3.1\nInstalled via: conda\nPython version: 3.5.2", "body": "I'm trying to compress the weights of a network using gzip. Here is a MWE:\r\n```\r\nimport torch, shutil, gzip\r\nimport torchvision.models as models\r\nresnet18 = models.resnet18()\r\ntorch.save(resnet18.state_dict(), 'test.pt')\r\nwith open('test.pt', 'rb') as f_in, gzip.open('test.pt.gz', 'wb') as f_out:\r\n    shutil.copyfileobj(f_in, f_out)\r\n    #f_out.write(f_in.read())\r\n    \r\nwith gzip.open('test.pt.gz', 'rb') as f:\r\n    state_dict = torch.load(f)\r\n```\r\nWhen loading the compressed file I get the error:\r\n```\r\n  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 267, in load\r\n    return _load(f, map_location, pickle_module)\r\n  File \"/home/user/.virtualenvs/py3/lib/python3.5/site-packages/torch/serialization.py\", line 428, in _load\r\n    deserialized_objects[key]._set_from_file(f, offset)\r\nRuntimeError: storage has wrong size: expected -772918636240159923 got 64\r\n```\r\nEven if I create the file using `f_out.write(f_in.read())` I still get the same error. The `test.pt` is identical to `test.pt.gz` when I compare them using `f.read()`. It works if I open the uncompressed file:\r\n```\r\nwith open('test.pt', 'rb') as f:\r\n    state_dict = torch.load(f)\r\n```\r\nThe expected size is sometimes negative, which leads me to believe it could be some sort of underflow, but it also changes each time it's run, so it must also be related to the randomly generated weights.\r\n\r\nI'm using:\r\n- OS: ubuntu 16.04\r\n- PyTorch version: 0.3.1\r\n- Installed via: conda\r\n- Python version: 3.5.2\r\n\r\n\r\n"}