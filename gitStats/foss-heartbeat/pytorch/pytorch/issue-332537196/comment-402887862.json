{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/402887862", "html_url": "https://github.com/pytorch/pytorch/issues/8502#issuecomment-402887862", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8502", "id": 402887862, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjg4Nzg2Mg==", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-06T00:16:49Z", "updated_at": "2018-07-06T00:16:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Discussed with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9443650\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wanchaol\">@wanchaol</a> in person. These steps are needed to fix clamp. It is currently special-cased on Python:</p>\n<ol>\n<li>Change THTensor_(clamp) to check for nan in min or max, and call cminValue or cmaxValue instead.</li>\n<li>Change THCTensor_(clamp) to do the same</li>\n<li>Fix derivatives.yaml to check for NaN and call the right gradient variant</li>\n<li>Remove special handling of clamp in python_torch_functions.h</li>\n<li>The rest of the task.</li>\n</ol>", "body_text": "Discussed with @wanchaol in person. These steps are needed to fix clamp. It is currently special-cased on Python:\n\nChange THTensor_(clamp) to check for nan in min or max, and call cminValue or cmaxValue instead.\nChange THCTensor_(clamp) to do the same\nFix derivatives.yaml to check for NaN and call the right gradient variant\nRemove special handling of clamp in python_torch_functions.h\nThe rest of the task.", "body": "Discussed with @wanchaol in person. These steps are needed to fix clamp. It is currently special-cased on Python:\r\n\r\n1. Change THTensor_(clamp) to check for nan in min or max, and call cminValue or cmaxValue instead.\r\n2. Change THCTensor_(clamp) to do the same\r\n3. Fix derivatives.yaml to check for NaN and call the right gradient variant\r\n4. Remove special handling of clamp in python_torch_functions.h\r\n5. The rest of the task."}