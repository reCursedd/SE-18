{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/359116989", "html_url": "https://github.com/pytorch/pytorch/pull/4746#issuecomment-359116989", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4746", "id": 359116989, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTExNjk4OQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T23:20:22Z", "updated_at": "2018-01-19T23:20:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>FWIW, here are the <code>short-perf-test-*</code> outputs from <code>pytorch-linux-xenial-cuda8-cudnn6-py3</code> CI:</p>\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>z-value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>test_cpu_speed_mini_sequence_labeler</td>\n<td>-0.2878277307471087</td>\n</tr>\n<tr>\n<td>test_cpu_speed_mnist</td>\n<td>-1.2850299502022648</td>\n</tr>\n<tr>\n<td>test_gpu_speed_mnist</td>\n<td>-4.470857984650843</td>\n</tr>\n<tr>\n<td>test_gpu_speed_word_language_model</td>\n<td>-0.721292663063553</td>\n</tr>\n<tr>\n<td>test_gpu_speed_cudnn_lstm</td>\n<td>-0.454405894995399</td>\n</tr>\n<tr>\n<td>test_gpu_speed_lstm</td>\n<td>0.38482758620688173</td>\n</tr>\n<tr>\n<td>test_gpu_speed_mlstm</td>\n<td>-1.5262515262515481</td>\n</tr>\n</tbody>\n</table>", "body_text": "FWIW, here are the short-perf-test-* outputs from pytorch-linux-xenial-cuda8-cudnn6-py3 CI:\n\n\n\nTask\nz-value\n\n\n\n\ntest_cpu_speed_mini_sequence_labeler\n-0.2878277307471087\n\n\ntest_cpu_speed_mnist\n-1.2850299502022648\n\n\ntest_gpu_speed_mnist\n-4.470857984650843\n\n\ntest_gpu_speed_word_language_model\n-0.721292663063553\n\n\ntest_gpu_speed_cudnn_lstm\n-0.454405894995399\n\n\ntest_gpu_speed_lstm\n0.38482758620688173\n\n\ntest_gpu_speed_mlstm\n-1.5262515262515481", "body": "FWIW, here are the `short-perf-test-*` outputs from `pytorch-linux-xenial-cuda8-cudnn6-py3` CI:\r\n\r\n| Task  | z-value |\r\n| ------------- | ------------- |\r\n| test_cpu_speed_mini_sequence_labeler | -0.2878277307471087  |\r\n| test_cpu_speed_mnist  | -1.2850299502022648 |\r\n| test_gpu_speed_mnist | -4.470857984650843 |\r\n| test_gpu_speed_word_language_model | -0.721292663063553 |\r\n| test_gpu_speed_cudnn_lstm | -0.454405894995399 |\r\n| test_gpu_speed_lstm | 0.38482758620688173 |\r\n| test_gpu_speed_mlstm | -1.5262515262515481 |\r\n\r\n\r\n"}