{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182077972", "pull_request_review_id": 112816509, "id": 182077972, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MjA3Nzk3Mg==", "diff_hunk": "@@ -1,9 +1,202 @@\n #include \"ATen/ATen.h\"\n #include \"ATen/NativeFunctions.h\"\n+#include \"ATen/WrapDimUtilsMulti.h\"\n \n \n namespace at { namespace native {\n \n+Tensor sumproduct_pair(const Tensor& left_, const Tensor& right_, IntList sum_dims_, bool keepdim) {\n+  // assumes that tensors have been pre-unsqueezed\n+  AT_ASSERT(left_.dim()==right_.dim(), \"number of dimensions must match\");\n+  if (sum_dims_.size() == 0)\n+    return at::mul(left_, right_);\n+  int64_t dim = left_.dim();\n+  auto sum_dims = dim_list_to_vector(sum_dims_, dim);\n+  std::vector<int64_t> lro, lo, ro;\n+  int64_t lro_size = 1, lo_size = 1, ro_size = 1, sum_size = 1;\n+  Tensor left = left_;\n+  Tensor right = right_;\n+  for (int64_t i = 0; i < dim; i++) {\n+    auto sl = left.size(i)>1;\n+    auto sr = right.size(i)>1;\n+    if (sum_dims[i]) {\n+      if (sl && sr) {\n+\tAT_ASSERT(left.size(i)==right.size(i), \"sum indexes must match\");\n+\tsum_size *= left.size(i);\n+      } else if (sl) {\n+\tleft = left.sum(i, true);\n+      } else if (sr) {\n+\tright = right.sum(i, true);\n+      }\n+    } else if (sl && sr) {\n+      AT_ASSERT(left.size(i)==right.size(i), \"non-broadcast dimensions must match\");\n+      lro.push_back(i);\n+      lro_size *= left.size(i);\n+    } else if (sl) {\n+      lo.push_back(i);\n+      lo_size *= left.size(i);\n+    } else {\n+      ro.push_back(i);\n+      ro_size *= right.size(i);\n+    }\n+  }\n+  std::vector<int64_t> out_size;\n+  for (auto& d : lro) out_size.push_back(left.size(d));\n+  for (auto& d : lo) out_size.push_back(left.size(d));\n+  for (auto& d : sum_dims_) { out_size.push_back(1); (void)(d); }; // avoid warining about not using d\n+  for (auto& d : ro) out_size.push_back(right.size(d));\n+\n+  std::vector<int64_t> lpermutation(lro);\n+  lpermutation.insert(lpermutation.end(), lo.begin(), lo.end());\n+  lpermutation.insert(lpermutation.end(), sum_dims_.begin(), sum_dims_.end());\n+  lpermutation.insert(lpermutation.end(), ro.begin(), ro.end());\n+\n+  std::vector<int64_t> rpermutation(lro);\n+  rpermutation.insert(rpermutation.end(), sum_dims_.begin(), sum_dims_.end());\n+  rpermutation.insert(rpermutation.end(), ro.begin(), ro.end());\n+  rpermutation.insert(rpermutation.end(), lo.begin(), lo.end());\n+\n+  std::vector<int64_t> opermutation(lro.size()+lo.size()+sum_dims_.size()+ro.size(), -1);\n+  {\n+  int64_t i = 0;\n+\n+  for (auto it = lro.begin(); it != lro.end(); i++, it++) {\n+    opermutation[*it] = i;\n+  }\n+  for (auto it = lo.begin(); it != lo.end(); i++, it++) {\n+    opermutation[*it] = i;\n+  }\n+  for (auto it = sum_dims_.begin(); it != sum_dims_.end(); i++, it++) {\n+    opermutation[*it] = i;\n+  }\n+  for (auto it = ro.begin(); it != ro.end(); i++, it++) {\n+    opermutation[*it] = i;\n+  }\n+  }\n+\n+  left = left.permute(lpermutation).reshape({lro_size, lo_size, sum_size});\n+  right = right.permute(rpermutation).reshape({lro_size, sum_size, ro_size});\n+  Tensor result = at::bmm(left, right);\n+  result = result.view(out_size).permute(opermutation);\n+  if (! keepdim) {\n+    for (int i = dim-1; i>=0; i--)\n+      if (sum_dims[i])\n+\tresult.squeeze_(i);\n+  }\n+  return result;\n+}\n+\n+\n+Tensor einsum(String eqn, TensorList tensors) {\n+  std::string in_eqn;\n+  size_t pos;\n+  std::vector<std::int64_t> number_of_occurences(26, 0);\n+  std::vector<std::int64_t> last_occurence(26, -1);\n+  std::vector<std::int64_t> sorted_position(26, -1);", "path": "aten/src/ATen/native/Linear.cpp", "position": null, "original_position": 95, "commit_id": "daf3c25ee5e9a1a8fe038ddc416761646410b199", "original_commit_id": "d7c7ebe6d0a6513ea95fb356abe751ca4893b8ac", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "It is the letters in the alphabet, I changed 26 to a constexpr to be reduce confusing magic.", "created_at": "2018-04-17T13:46:45Z", "updated_at": "2018-11-23T15:42:35Z", "html_url": "https://github.com/pytorch/pytorch/pull/6307#discussion_r182077972", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6307", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182077972"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6307#discussion_r182077972"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6307"}}, "body_html": "<p>It is the letters in the alphabet, I changed 26 to a constexpr to be reduce confusing magic.</p>", "body_text": "It is the letters in the alphabet, I changed 26 to a constexpr to be reduce confusing magic.", "in_reply_to_id": 181875622}