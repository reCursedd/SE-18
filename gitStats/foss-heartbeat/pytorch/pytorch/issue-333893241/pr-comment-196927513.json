{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196927513", "pull_request_review_id": 130570766, "id": 196927513, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjkyNzUxMw==", "diff_hunk": "@@ -416,27 +419,65 @@ def f(x, y):\n \n         ge = self.checkTrace(f, (x, y))\n \n+    @staticmethod\n+    def fn_test_relu(x, y):\n+        return F.relu(x + .5 * y)\n+\n     @unittest.skipIf(IS_WINDOWS, \"NYI: fuser support for Windows\")\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\n     def test_relu(self):\n-        def f(x, y):\n-            return F.relu(x + .5 * y)\n-\n         x = torch.randn(4, 4, dtype=torch.float, device='cuda')\n         y = torch.randn(4, 4, dtype=torch.float, device='cuda')\n \n-        ge = self.checkTrace(f, (x, y))\n+        ge = self.checkTrace(self.fn_test_relu, (x, y))\n+\n+    @staticmethod\n+    def fn_test_exp(x, y):\n+        return (x + .5 * y).exp()\n \n     @unittest.skipIf(IS_WINDOWS, \"NYI: fuser support for Windows\")\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\n     def test_exp(self):\n-        def f(x, y):\n-            return (x + .5 * y).exp()\n-\n         x = torch.randn(4, 4, dtype=torch.float, device='cuda')\n         y = torch.randn(4, 4, dtype=torch.float, device='cuda')\n \n-        ge = self.checkTrace(f, (x, y))\n+        ge = self.checkTrace(self.fn_test_exp, (x, y))\n+\n+    @unittest.skipIf(IS_WINDOWS, \"NYI: fuser support for Windows\")\n+    @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\n+    @unittest.skipIf(not RUN_CUDA_HALF, \"no half support\")\n+    def test_cuda_half(self):\n+        x = torch.randn(4, 4, dtype=torch.half, device='cuda')\n+        y = torch.randn(4, 4, dtype=torch.half, device='cuda')\n+\n+        funcs = [\n+            self.fn_test_comparison_gt_lt,\n+            self.fn_test_relu,\n+            self.fn_test_exp\n+        ]\n+\n+        # Note: Non fused inputs must be float to prevent loss of precision\n+        inputs = (x.float(), y.float())\n+        fusion_inputs = (x, y)\n+        for fn in funcs:\n+            local_inputs = [t.clone().requires_grad_() for t in inputs]\n+            local_fusion_inputs = [t.clone().requires_grad_() for t in fusion_inputs]\n+\n+            # Verifies outputs\n+            fusion = torch.jit.trace(*local_fusion_inputs, optimize=True)(fn)\n+            outputs = fn(*local_inputs)\n+            fusion_outputs = fusion(*local_fusion_inputs)\n+            outputs_half = [t.half() for t in outputs]\n+            self.assertEqual(outputs_half, fusion_outputs)", "path": "test/test_jit.py", "position": 115, "original_position": 115, "commit_id": "e854f3b794be068c2f1eaba6980641e9c5b9308b", "original_commit_id": "fa1bd53a4a635dfd10a13bac1844bd46c95fb872", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "body": "I believe you are missing the dtype=torch.half when x and y are created.\r\n\r\nThe fusion_inputs tuple is composed of half tensors and they create the local_fusion_inputs which are put through the torch.jit.trace call. The inputs tuple is float tensors that are exactly representable in half. \r\n\r\nAs I mention above, it would be risky to run halfs through an unfused network because there could be loss of precision within and across operations. That's why I'm doing the work here to compare floats representable as halfs through an unfused network vs the equivalent halfs through the fused network.", "created_at": "2018-06-20T20:15:17Z", "updated_at": "2018-11-23T15:45:56Z", "html_url": "https://github.com/pytorch/pytorch/pull/8679#discussion_r196927513", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8679", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196927513"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8679#discussion_r196927513"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8679"}}, "body_html": "<p>I believe you are missing the dtype=torch.half when x and y are created.</p>\n<p>The fusion_inputs tuple is composed of half tensors and they create the local_fusion_inputs which are put through the torch.jit.trace call. The inputs tuple is float tensors that are exactly representable in half.</p>\n<p>As I mention above, it would be risky to run halfs through an unfused network because there could be loss of precision within and across operations. That's why I'm doing the work here to compare floats representable as halfs through an unfused network vs the equivalent halfs through the fused network.</p>", "body_text": "I believe you are missing the dtype=torch.half when x and y are created.\nThe fusion_inputs tuple is composed of half tensors and they create the local_fusion_inputs which are put through the torch.jit.trace call. The inputs tuple is float tensors that are exactly representable in half.\nAs I mention above, it would be risky to run halfs through an unfused network because there could be loss of precision within and across operations. That's why I'm doing the work here to compare floats representable as halfs through an unfused network vs the equivalent halfs through the fused network.", "in_reply_to_id": 196926025}