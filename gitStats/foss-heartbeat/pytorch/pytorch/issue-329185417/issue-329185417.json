{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8126", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8126/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8126/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8126/events", "html_url": "https://github.com/pytorch/pytorch/issues/8126", "id": 329185417, "node_id": "MDU6SXNzdWUzMjkxODU0MTc=", "number": 8126, "title": "PyTorch multiprocessing using single CPU core", "user": {"login": "xdever", "id": 2706617, "node_id": "MDQ6VXNlcjI3MDY2MTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/2706617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xdever", "html_url": "https://github.com/xdever", "followers_url": "https://api.github.com/users/xdever/followers", "following_url": "https://api.github.com/users/xdever/following{/other_user}", "gists_url": "https://api.github.com/users/xdever/gists{/gist_id}", "starred_url": "https://api.github.com/users/xdever/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xdever/subscriptions", "organizations_url": "https://api.github.com/users/xdever/orgs", "repos_url": "https://api.github.com/users/xdever/repos", "events_url": "https://api.github.com/users/xdever/events{/privacy}", "received_events_url": "https://api.github.com/users/xdever/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-06-04T19:27:05Z", "updated_at": "2018-09-13T14:34:04Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I was trying to load data with DataLoader with multiple workers, and I noticed that although it creates the processes they all run on the same CPU core, thus the data loading is very slow.</p>\n<p>I succeeded in creating a minimal example (below). If I run the script below, it uses 4 CPU cores. If I uncomment the \"import torch\" line, only single core is used. If I also uncomment the taskset command, it will use 4 cores again.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python3</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>import torch</span>\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">loop</span>():\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        <span class=\"pl-k\">pass</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>os.system(\"taskset -p 0xff %d\" % os.getpid())</span>\n<span class=\"pl-k\">from</span> multiprocessing <span class=\"pl-k\">import</span> Process\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">4</span>):\n    Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>loop).start()</pre></div>\n<h2>System Info</h2>\n<p>Although the collect_env.py prints gcc 8.1.0, it was overridden to 7.3.1 during build. Also cudnn detection failed, its version is 7.1.3.</p>\n<p>Built from source (commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/f24d715e235eb7d188cb610d7b29386b9eaf0ab9/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/f24d715e235eb7d188cb610d7b29386b9eaf0ab9\"><tt>f24d715</tt></a>), command: \"CC=gcc-7 CXX=g++-7 python setup.py bdist_wheel\", package installed with pip install --user.</p>\n<p>PyTorch version: 0.5.0a0+f24d715<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.88</p>\n<p>OS: Antergos Linux<br>\nGCC version: (GCC) 8.1.0<br>\nCMake version: version 3.11.2</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.88<br>\nGPU models and configuration:<br>\nGPU 0: TITAN X (Pascal)<br>\nGPU 1: GeForce GTX 1070</p>\n<p>Nvidia driver version: 396.24<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.13.1)<br>\n[pip3] torch (0.5.0a0+f24d715)<br>\n[pip3] torchfile (0.1.0)<br>\n[pip3] torchvision (0.1.8)<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nI was trying to load data with DataLoader with multiple workers, and I noticed that although it creates the processes they all run on the same CPU core, thus the data loading is very slow.\nI succeeded in creating a minimal example (below). If I run the script below, it uses 4 CPU cores. If I uncomment the \"import torch\" line, only single core is used. If I also uncomment the taskset command, it will use 4 cores again.\nCode example\n#!/usr/bin/env python3\n\n#import torch\nimport os\ndef loop():\n    while True:\n        pass\n\n#os.system(\"taskset -p 0xff %d\" % os.getpid())\nfrom multiprocessing import Process\nfor i in range(4):\n    Process(target=loop).start()\nSystem Info\nAlthough the collect_env.py prints gcc 8.1.0, it was overridden to 7.3.1 during build. Also cudnn detection failed, its version is 7.1.3.\nBuilt from source (commit f24d715), command: \"CC=gcc-7 CXX=g++-7 python setup.py bdist_wheel\", package installed with pip install --user.\nPyTorch version: 0.5.0a0+f24d715\nIs debug build: No\nCUDA used to build PyTorch: 9.2.88\nOS: Antergos Linux\nGCC version: (GCC) 8.1.0\nCMake version: version 3.11.2\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.88\nGPU models and configuration:\nGPU 0: TITAN X (Pascal)\nGPU 1: GeForce GTX 1070\nNvidia driver version: 396.24\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip3] numpy (1.13.1)\n[pip3] torch (0.5.0a0+f24d715)\n[pip3] torchfile (0.1.0)\n[pip3] torchvision (0.1.8)\n[conda] Could not collect", "body": "## Issue description\r\n\r\nI was trying to load data with DataLoader with multiple workers, and I noticed that although it creates the processes they all run on the same CPU core, thus the data loading is very slow.\r\n\r\nI succeeded in creating a minimal example (below). If I run the script below, it uses 4 CPU cores. If I uncomment the \"import torch\" line, only single core is used. If I also uncomment the taskset command, it will use 4 cores again.\r\n\r\n## Code example\r\n\r\n```python\r\n#!/usr/bin/env python3\r\n\r\n#import torch\r\nimport os\r\ndef loop():\r\n    while True:\r\n        pass\r\n\r\n#os.system(\"taskset -p 0xff %d\" % os.getpid())\r\nfrom multiprocessing import Process\r\nfor i in range(4):\r\n    Process(target=loop).start()\r\n```\r\n\r\n## System Info\r\nAlthough the collect_env.py prints gcc 8.1.0, it was overridden to 7.3.1 during build. Also cudnn detection failed, its version is 7.1.3.\r\n\r\nBuilt from source (commit f24d715e235eb7d188cb610d7b29386b9eaf0ab9), command: \"CC=gcc-7 CXX=g++-7 python setup.py bdist_wheel\", package installed with pip install --user.\r\n\r\nPyTorch version: 0.5.0a0+f24d715\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.88\r\n\r\nOS: Antergos Linux\r\nGCC version: (GCC) 8.1.0\r\nCMake version: version 3.11.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.88\r\nGPU models and configuration: \r\nGPU 0: TITAN X (Pascal)\r\nGPU 1: GeForce GTX 1070\r\n\r\nNvidia driver version: 396.24\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.13.1)\r\n[pip3] torch (0.5.0a0+f24d715)\r\n[pip3] torchfile (0.1.0)\r\n[pip3] torchvision (0.1.8)\r\n[conda] Could not collect\r\n"}