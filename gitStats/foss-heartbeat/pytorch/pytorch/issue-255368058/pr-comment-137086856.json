{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/137086856", "pull_request_review_id": 60709061, "id": 137086856, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzNzA4Njg1Ng==", "diff_hunk": "@@ -74,22 +74,24 @@ def reduce_add(inputs, destination=None):\n     \"\"\"\n     # TODO: try to find an input on another gpu, copy it,\n     # and accumulate into the copy\n+    if destination is None:\n+        destination = torch.cuda.current_device()\n     input_size = inputs[0].size()\n     for i, inp in enumerate(inputs):\n         assert inp.is_cuda, \"reduce_add expects all inputs to be on GPUs\"\n+        if inp.get_device() == destination:\n+            nccl_root = i", "path": "torch/cuda/comm.py", "position": null, "original_position": 10, "commit_id": "1bd22cbb3e6141e6057bfc8025dd612b4fe572dd", "original_commit_id": "1c803edb4e4b0533f27075ab0515d552472f816f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "The problem with this is that it's ambiguous if there are two tensors on destination device. Can you add `assert nccl_root is None` + `assert nccl_root is not None` to check that we really found the root after the loop?", "created_at": "2017-09-05T19:09:10Z", "updated_at": "2018-11-23T15:34:32Z", "html_url": "https://github.com/pytorch/pytorch/pull/2632#discussion_r137086856", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2632", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/137086856"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2632#discussion_r137086856"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2632"}}, "body_html": "<p>The problem with this is that it's ambiguous if there are two tensors on destination device. Can you add <code>assert nccl_root is None</code> + <code>assert nccl_root is not None</code> to check that we really found the root after the loop?</p>", "body_text": "The problem with this is that it's ambiguous if there are two tensors on destination device. Can you add assert nccl_root is None + assert nccl_root is not None to check that we really found the root after the loop?"}