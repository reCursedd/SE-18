{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4765", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4765/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4765/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4765/events", "html_url": "https://github.com/pytorch/pytorch/pull/4765", "id": 290255986, "node_id": "MDExOlB1bGxSZXF1ZXN0MTY0MTY1MDc2", "number": 4765, "title": "Removing NCCL clear_group_cache workaround with one more check in new_group", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-21T08:25:13Z", "updated_at": "2018-01-21T08:29:39Z", "closed_at": "2018-01-21T08:29:31Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4765", "html_url": "https://github.com/pytorch/pytorch/pull/4765", "diff_url": "https://github.com/pytorch/pytorch/pull/4765.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4765.patch"}, "body_html": "<p>Removed hack clear_group_cache workaround in DDP module for NCCL backend after root-causing the NCCL deadlock problem, which is caused by the weirdness of multiprocessing fork (we have already had GitHub issues tracking this). Tested with both fork server and spawn method and they both work well without any deadlock or issues.</p>\n<p>The NCCL backend with DDP module has been tested well enough (with good accuracy for ResNet50 and reliability on Infiniband) to be added as one of the supported backend for DDP.</p>\n<p>The fork warning has also been added to DDP warnings</p>\n<p>Added an unsupported new_group check since NCCL backend currently doesn't support subgroup creation. Tested the code path as well:</p>\n<pre><code>/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\nTraceback (most recent call last):\n  File \"nccl2_test/test_nccl2.py\", line 20, in &lt;module&gt;\n    c= dist.new_group([0])\n  File \"/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 558, in new_group\n    raise RuntimeError(\"Currently NCCL backend only supports full group \"\nRuntimeError: Currently NCCL backend only supports full group creation. In other words, every rank in the process group needs to be a member of the new group to be created and sub-group creation is currently not supported\n</code></pre>", "body_text": "Removed hack clear_group_cache workaround in DDP module for NCCL backend after root-causing the NCCL deadlock problem, which is caused by the weirdness of multiprocessing fork (we have already had GitHub issues tracking this). Tested with both fork server and spawn method and they both work well without any deadlock or issues.\nThe NCCL backend with DDP module has been tested well enough (with good accuracy for ResNet50 and reliability on Infiniband) to be added as one of the supported backend for DDP.\nThe fork warning has also been added to DDP warnings\nAdded an unsupported new_group check since NCCL backend currently doesn't support subgroup creation. Tested the code path as well:\n/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\nTraceback (most recent call last):\n  File \"nccl2_test/test_nccl2.py\", line 20, in <module>\n    c= dist.new_group([0])\n  File \"/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 558, in new_group\n    raise RuntimeError(\"Currently NCCL backend only supports full group \"\nRuntimeError: Currently NCCL backend only supports full group creation. In other words, every rank in the process group needs to be a member of the new group to be created and sub-group creation is currently not supported", "body": "Removed hack clear_group_cache workaround in DDP module for NCCL backend after root-causing the NCCL deadlock problem, which is caused by the weirdness of multiprocessing fork (we have already had GitHub issues tracking this). Tested with both fork server and spawn method and they both work well without any deadlock or issues.\r\n\r\nThe NCCL backend with DDP module has been tested well enough (with good accuracy for ResNet50 and reliability on Infiniband) to be added as one of the supported backend for DDP.\r\n\r\nThe fork warning has also been added to DDP warnings\r\n\r\nAdded an unsupported new_group check since NCCL backend currently doesn't support subgroup creation. Tested the code path as well:\r\n\r\n```\r\n/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\r\n        ================================================================================\r\n                                            WARNING\r\n        ================================================================================\r\n        NCCL backend is still experimental. The APIs will change without\r\n        notice and we're can't guarantee full correctness and expected performance yet.\r\n        We'll announce it once it's ready.\r\n\r\n  \"\"\")\r\nTraceback (most recent call last):\r\n  File \"nccl2_test/test_nccl2.py\", line 20, in <module>\r\n    c= dist.new_group([0])\r\n  File \"/private/home/tengli/miniconda3/envs/cuda9/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 558, in new_group\r\n    raise RuntimeError(\"Currently NCCL backend only supports full group \"\r\nRuntimeError: Currently NCCL backend only supports full group creation. In other words, every rank in the process group needs to be a member of the new group to be created and sub-group creation is currently not supported\r\n```\r\n\r\n\r\n\r\n\r\n"}