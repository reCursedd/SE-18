{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/346381562", "html_url": "https://github.com/pytorch/pytorch/issues/3749#issuecomment-346381562", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3749", "id": 346381562, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NjM4MTU2Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-22T15:20:27Z", "updated_at": "2017-11-22T15:20:27Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4969797\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zhuwenxi\">@zhuwenxi</a> thanks for the explanation. By the way, autograd profiler works with all kinds of functions, including the ones implemented in Python, and it should be very easy to extend it to register ranges for <code>nn</code> modules.</p>\n<p>While I see your point, I don't think we will be including this in the core, but of course feel free to develop this as a community package (we're very happy to have you working on this!). My argument is that because it doesn't give you a full breakdown of the time, you don't really know what the bottleneck is. <code>torch.nn</code> is designed to naturally integrate with autograd, and removing overhead that comes from non-linearities and other operations that aren't modules simply gives the user a skewed picture. Consider a case where your model takes 200ms / batch, but the nn profiler sees only 40ms / batch overhead. In this case it's clear that there are a lot of things you should look into before you start optimizing the <code>nn</code> part.</p>\n<p>The python-level output of autograd profiler is actually very similar to that of your tool, so it should be usable by regular users as well:</p>\n<pre><code>        -------------------------------------  ---------------  ---------------\n        Name                                          CPU time        CUDA time\n        -------------------------------------  ---------------  ---------------\n        PowConstant                                  142.036us          0.000us\n        N5torch8autograd9GraphRootE                   63.524us          0.000us\n        PowConstantBackward                          184.228us          0.000us\n        MulConstant                                   50.288us          0.000us\n        PowConstant                                   28.439us          0.000us\n        Mul                                           20.154us          0.000us\n        N5torch8autograd14AccumulateGradE             13.790us          0.000us\n        N5torch8autograd5CloneE                        4.088us          0.000us\n</code></pre>\n<p>Also, this dump is from before the ATen refactor. Most of the names that show up in the profiler now are exactly the names of methods triggering them (e.g. <code>PowConstant</code> -&gt; <code>pow</code>, <code>MulConstant</code> -&gt; <code>mul</code>).</p>\n<hr>\n<p>Nevertheless, I'd be ok with adding a profiler mode that would also record ranges for nn modules.</p>", "body_text": "@zhuwenxi thanks for the explanation. By the way, autograd profiler works with all kinds of functions, including the ones implemented in Python, and it should be very easy to extend it to register ranges for nn modules.\nWhile I see your point, I don't think we will be including this in the core, but of course feel free to develop this as a community package (we're very happy to have you working on this!). My argument is that because it doesn't give you a full breakdown of the time, you don't really know what the bottleneck is. torch.nn is designed to naturally integrate with autograd, and removing overhead that comes from non-linearities and other operations that aren't modules simply gives the user a skewed picture. Consider a case where your model takes 200ms / batch, but the nn profiler sees only 40ms / batch overhead. In this case it's clear that there are a lot of things you should look into before you start optimizing the nn part.\nThe python-level output of autograd profiler is actually very similar to that of your tool, so it should be usable by regular users as well:\n        -------------------------------------  ---------------  ---------------\n        Name                                          CPU time        CUDA time\n        -------------------------------------  ---------------  ---------------\n        PowConstant                                  142.036us          0.000us\n        N5torch8autograd9GraphRootE                   63.524us          0.000us\n        PowConstantBackward                          184.228us          0.000us\n        MulConstant                                   50.288us          0.000us\n        PowConstant                                   28.439us          0.000us\n        Mul                                           20.154us          0.000us\n        N5torch8autograd14AccumulateGradE             13.790us          0.000us\n        N5torch8autograd5CloneE                        4.088us          0.000us\n\nAlso, this dump is from before the ATen refactor. Most of the names that show up in the profiler now are exactly the names of methods triggering them (e.g. PowConstant -> pow, MulConstant -> mul).\n\nNevertheless, I'd be ok with adding a profiler mode that would also record ranges for nn modules.", "body": "@zhuwenxi thanks for the explanation. By the way, autograd profiler works with all kinds of functions, including the ones implemented in Python, and it should be very easy to extend it to register ranges for `nn` modules.\r\n\r\nWhile I see your point, I don't think we will be including this in the core, but of course feel free to develop this as a community package (we're very happy to have you working on this!). My argument is that because it doesn't give you a full breakdown of the time, you don't really know what the bottleneck is. `torch.nn` is designed to naturally integrate with autograd, and removing overhead that comes from non-linearities and other operations that aren't modules simply gives the user a skewed picture. Consider a case where your model takes 200ms / batch, but the nn profiler sees only 40ms / batch overhead. In this case it's clear that there are a lot of things you should look into before you start optimizing the `nn` part.\r\n\r\nThe python-level output of autograd profiler is actually very similar to that of your tool, so it should be usable by regular users as well:\r\n```\r\n        -------------------------------------  ---------------  ---------------\r\n        Name                                          CPU time        CUDA time\r\n        -------------------------------------  ---------------  ---------------\r\n        PowConstant                                  142.036us          0.000us\r\n        N5torch8autograd9GraphRootE                   63.524us          0.000us\r\n        PowConstantBackward                          184.228us          0.000us\r\n        MulConstant                                   50.288us          0.000us\r\n        PowConstant                                   28.439us          0.000us\r\n        Mul                                           20.154us          0.000us\r\n        N5torch8autograd14AccumulateGradE             13.790us          0.000us\r\n        N5torch8autograd5CloneE                        4.088us          0.000us\r\n```\r\n\r\nAlso, this dump is from before the ATen refactor. Most of the names that show up in the profiler now are exactly the names of methods triggering them (e.g. `PowConstant` -> `pow`, `MulConstant` -> `mul`).\r\n\r\n---\r\n\r\nNevertheless, I'd be ok with adding a profiler mode that would also record ranges for nn modules."}