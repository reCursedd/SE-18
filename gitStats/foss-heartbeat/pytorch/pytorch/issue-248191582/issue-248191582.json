{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2300", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2300/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2300/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2300/events", "html_url": "https://github.com/pytorch/pytorch/issues/2300", "id": 248191582, "node_id": "MDU6SXNzdWUyNDgxOTE1ODI=", "number": 2300, "title": "cuda runtime error on jupyter", "user": {"login": "lucidfrontier45", "id": 655305, "node_id": "MDQ6VXNlcjY1NTMwNQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/655305?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucidfrontier45", "html_url": "https://github.com/lucidfrontier45", "followers_url": "https://api.github.com/users/lucidfrontier45/followers", "following_url": "https://api.github.com/users/lucidfrontier45/following{/other_user}", "gists_url": "https://api.github.com/users/lucidfrontier45/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucidfrontier45/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucidfrontier45/subscriptions", "organizations_url": "https://api.github.com/users/lucidfrontier45/orgs", "repos_url": "https://api.github.com/users/lucidfrontier45/repos", "events_url": "https://api.github.com/users/lucidfrontier45/events{/privacy}", "received_events_url": "https://api.github.com/users/lucidfrontier45/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-08-05T15:36:38Z", "updated_at": "2018-01-31T22:48:50Z", "closed_at": "2017-08-06T03:03:18Z", "author_association": "NONE", "body_html": "<p>Hi, I have a problem that on jupyter notebook, if an error occurs for a Variable or Layer which exists in GPU, the entire notebook session is corrupt.</p>\n<p>For example</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\nv <span class=\"pl-k\">=</span> Variable(torch.LongTensor([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">20</span>])).cuda()\nemb <span class=\"pl-k\">=</span> nn.Embedding(<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">1</span>).cuda()\nemb(v)</pre></div>\n<p>will raise error at the line of <code>emb(v)</code> like</p>\n<pre><code>cuda runtime error (59) : device-side assert triggered at /py/conda-bld/pytorch_1493681908901/work/torch/lib/THC/generic/THCTensorCopy.c:65\n</code></pre>\n<p>It's OK, the Embedding dict size is too small.<br>\nThe problem is after this error occurs, any valid statement will fail with cuda runtime error as well.<br>\nFor instance, running the following code in the different cell fails.</p>\n<div class=\"highlight highlight-source-python\"><pre>v2 <span class=\"pl-k\">=</span> Variable(torch.LongTensor([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])).cuda()\n\n<span class=\"pl-c1\">RuntimeError</span>: cuda runtime error (<span class=\"pl-c1\">59</span>) : device<span class=\"pl-k\">-</span>side <span class=\"pl-k\">assert</span> triggered at <span class=\"pl-k\">/</span>py<span class=\"pl-k\">/</span>conda<span class=\"pl-k\">-</span>bld<span class=\"pl-k\">/</span>pytorch_1493681908901<span class=\"pl-k\">/</span>work<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span><span class=\"pl-c1\">THC</span><span class=\"pl-k\">/</span>generic<span class=\"pl-k\">/</span>THCTensorCopy.c:<span class=\"pl-c1\">18</span></pre></div>\n<p>The only way to reset this situation I found was to restart this notebook's kernel but it will seriously slow iteration of trial and error and very frustrating.<br>\nIs there any workaround?</p>", "body_text": "Hi, I have a problem that on jupyter notebook, if an error occurs for a Variable or Layer which exists in GPU, the entire notebook session is corrupt.\nFor example\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\n\nv = Variable(torch.LongTensor([0, 1, 20])).cuda()\nemb = nn.Embedding(10,1).cuda()\nemb(v)\nwill raise error at the line of emb(v) like\ncuda runtime error (59) : device-side assert triggered at /py/conda-bld/pytorch_1493681908901/work/torch/lib/THC/generic/THCTensorCopy.c:65\n\nIt's OK, the Embedding dict size is too small.\nThe problem is after this error occurs, any valid statement will fail with cuda runtime error as well.\nFor instance, running the following code in the different cell fails.\nv2 = Variable(torch.LongTensor([0, 1, 2])).cuda()\n\nRuntimeError: cuda runtime error (59) : device-side assert triggered at /py/conda-bld/pytorch_1493681908901/work/torch/lib/THC/generic/THCTensorCopy.c:18\nThe only way to reset this situation I found was to restart this notebook's kernel but it will seriously slow iteration of trial and error and very frustrating.\nIs there any workaround?", "body": "Hi, I have a problem that on jupyter notebook, if an error occurs for a Variable or Layer which exists in GPU, the entire notebook session is corrupt.\r\n\r\nFor example\r\n\r\n```python\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.autograd import Variable\r\n\r\nv = Variable(torch.LongTensor([0, 1, 20])).cuda()\r\nemb = nn.Embedding(10,1).cuda()\r\nemb(v)\r\n```\r\n\r\nwill raise error at the line of `emb(v)` like\r\n```\r\ncuda runtime error (59) : device-side assert triggered at /py/conda-bld/pytorch_1493681908901/work/torch/lib/THC/generic/THCTensorCopy.c:65\r\n```\r\nIt's OK, the Embedding dict size is too small.\r\nThe problem is after this error occurs, any valid statement will fail with cuda runtime error as well.\r\nFor instance, running the following code in the different cell fails.\r\n\r\n```python\r\nv2 = Variable(torch.LongTensor([0, 1, 2])).cuda()\r\n\r\nRuntimeError: cuda runtime error (59) : device-side assert triggered at /py/conda-bld/pytorch_1493681908901/work/torch/lib/THC/generic/THCTensorCopy.c:18\r\n```\r\n\r\nThe only way to reset this situation I found was to restart this notebook's kernel but it will seriously slow iteration of trial and error and very frustrating.\r\nIs there any workaround?"}