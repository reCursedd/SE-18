{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7178", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7178/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7178/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7178/events", "html_url": "https://github.com/pytorch/pytorch/issues/7178", "id": 319557410, "node_id": "MDU6SXNzdWUzMTk1NTc0MTA=", "number": 7178, "title": "Should torch.load and torch.save take a device (since PyTorch 0.4)", "user": {"login": "daniel-j-h", "id": 527241, "node_id": "MDQ6VXNlcjUyNzI0MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/527241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daniel-j-h", "html_url": "https://github.com/daniel-j-h", "followers_url": "https://api.github.com/users/daniel-j-h/followers", "following_url": "https://api.github.com/users/daniel-j-h/following{/other_user}", "gists_url": "https://api.github.com/users/daniel-j-h/gists{/gist_id}", "starred_url": "https://api.github.com/users/daniel-j-h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daniel-j-h/subscriptions", "organizations_url": "https://api.github.com/users/daniel-j-h/orgs", "repos_url": "https://api.github.com/users/daniel-j-h/repos", "events_url": "https://api.github.com/users/daniel-j-h/events{/privacy}", "received_events_url": "https://api.github.com/users/daniel-j-h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-02T13:42:09Z", "updated_at": "2018-05-31T13:44:51Z", "closed_at": "2018-05-31T13:44:51Z", "author_association": "NONE", "body_html": "<p>Reading the <a href=\"https://pytorch.org/2018/04/22/0_4_0-migration-guide.html\" rel=\"nofollow\">PyTorch 0.4.0 migration guide</a> I came across the <a href=\"https://pytorch.org/docs/stable/tensor_attributes.html\" rel=\"nofollow\"><code>torch.device</code></a> abstraction.</p>\n<p>It is great for creating a device once and then passing it around and using the <code>.to</code> functions, e.g. as in:</p>\n<div class=\"highlight highlight-source-python\"><pre>device <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> torch.cuda.is_available() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>)\ninputs <span class=\"pl-k\">=</span> data.to(device)</pre></div>\n<p>The <a href=\"https://github.com/pytorch/pytorch/blob/d564ecb4a515e34184c976617f57b2eb01665660/torch/serialization.py#L241\"><code>torch.load</code></a> function does not take a device, though. Instead it takes a <code>map_location</code> argument which can either be a lambda, a mapping, or since <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"282569409\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4203\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4203/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4203\">#4203</a> it can be a string like <code>'cpu'</code>.</p>\n<p>Now the question is why are there these two different concepts and can they be unified into one device abstraction? Otherwise we can pass the device around <em>except</em> for serialization where we need to transform the device abstraction into a <code>map_location</code> parameter.</p>\n<p>Can we unify these concepts behind an API like the following?</p>\n<div class=\"highlight highlight-source-python\"><pre>device <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> torch.cuda.is_available() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>)\nrestored <span class=\"pl-k\">=</span> torch.load(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.pth<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>device)</pre></div>\n<p>Related: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"314748064\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6630\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6630/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6630\">#6630</a> - <code>torch.save</code> should also take a device</p>", "body_text": "Reading the PyTorch 0.4.0 migration guide I came across the torch.device abstraction.\nIt is great for creating a device once and then passing it around and using the .to functions, e.g. as in:\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninputs = data.to(device)\nThe torch.load function does not take a device, though. Instead it takes a map_location argument which can either be a lambda, a mapping, or since #4203 it can be a string like 'cpu'.\nNow the question is why are there these two different concepts and can they be unified into one device abstraction? Otherwise we can pass the device around except for serialization where we need to transform the device abstraction into a map_location parameter.\nCan we unify these concepts behind an API like the following?\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nrestored = torch.load('model.pth', device=device)\nRelated: #6630 - torch.save should also take a device", "body": "Reading the [PyTorch 0.4.0 migration guide](https://pytorch.org/2018/04/22/0_4_0-migration-guide.html) I came across the [`torch.device`](https://pytorch.org/docs/stable/tensor_attributes.html) abstraction.\r\n\r\nIt is great for creating a device once and then passing it around and using the `.to` functions, e.g. as in:\r\n\r\n```python\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\ninputs = data.to(device)\r\n```\r\n\r\nThe [`torch.load`](https://github.com/pytorch/pytorch/blob/d564ecb4a515e34184c976617f57b2eb01665660/torch/serialization.py#L241) function does not take a device, though. Instead it takes a `map_location` argument which can either be a lambda, a mapping, or since https://github.com/pytorch/pytorch/pull/4203 it can be a string like `'cpu'`.\r\n\r\nNow the question is why are there these two different concepts and can they be unified into one device abstraction? Otherwise we can pass the device around _except_ for serialization where we need to transform the device abstraction into a `map_location` parameter.\r\n\r\nCan we unify these concepts behind an API like the following?\r\n\r\n```python\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\nrestored = torch.load('model.pth', device=device)\r\n```\r\n\r\nRelated: https://github.com/pytorch/pytorch/issues/6630 - `torch.save` should also take a device"}