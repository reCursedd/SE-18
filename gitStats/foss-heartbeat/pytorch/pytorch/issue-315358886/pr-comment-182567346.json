{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182567346", "pull_request_review_id": 113381082, "id": 182567346, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MjU2NzM0Ng==", "diff_hunk": "@@ -467,102 +435,47 @@ void TensorRTTransformer::Transform(\n       SsaRewriteAndMapIO(ws, pred_net, input_shape_hints);\n   auto shape_hints = InferShapes(ws, pred_net, &shape_hints_ordered);\n \n-  std::unordered_set<std::string> weights;\n-  const std::vector<string>& ws_blobs = ws->Blobs();\n-  for (const auto& s : ws_blobs) {\n-    weights.emplace(s);\n-  }\n-\n   CAFFE_ENFORCE(pred_net, \"Predict net cannot be nullptr\");\n-  ::ONNX_NAMESPACE::ModelProto onnx_model;\n-  FillModelInfo(&onnx_model);\n-\n-  std::vector<OperatorDef> new_ops;\n-  bool trt_group = false;\n-  auto importer = tensorrt::TrtObject(onnx2trt::createImporter(nullptr));\n-  int op_idx = 0;\n-  int start = 0;\n-  int end = 0;\n   onnx::OnnxExporter exporter(nullptr, true);\n-  for (const OperatorDef& op : pred_net->op()) {\n-    bool support_trt = true;\n-    const OpSchema* schema = OpSchemaRegistry::Schema(op.type());\n-    caffe2::onnx::ConvertedResult results;\n-    if (!schema || schema->onnx_schema().empty()) {\n-      LOG(INFO) << \"Cannot export c2 op \" << op.type() << \" to onnx\";\n-      support_trt = false;\n-    } else {\n-      // One c2 op can be converted into multiple onnx nodes. For simplicity, we\n-      // enforce all or nothing here\n-      results = exporter.Caffe2OpToOnnxNodes(op, shape_hints);\n-      for (const auto& n : results.first) {\n-        if (!importer->supports(n)) {\n-          LOG(INFO) << \"TRT does not support ONNX node \" << n.op_type();\n-          support_trt = false;\n-          break;\n-        }\n-      }\n-    }\n+  auto importer = tensorrt::TrtObject(onnx2trt::createImporter(nullptr));\n \n-    if (support_trt) {\n-      const auto& node_protos = results.first;\n-      if (!trt_group) {\n-        trt_group = true;\n-        start = op_idx;\n-      }\n-      for (const auto& n : node_protos) {\n-        onnx_model.mutable_graph()->add_node()->CopyFrom(n);\n-      }\n+  // function to tell whether TensorRT supports a given C2 op or not\n+  auto supports =\n+      [&exporter, &shape_hints, importer](const caffe2::OperatorDef& op) {\n+        const OpSchema* schema = OpSchemaRegistry::Schema(op.type());\n+        if (!schema || schema->onnx_schema().empty()) {\n+          LOG(INFO) << \"Cannot export c2 op \" << op.type() << \" to onnx\";\n+          return false;\n+        }\n \n-      for (const auto& t : results.second) {\n-        VLOG(2) << \"Adding extra init tensor: \" << t.name();\n-        TensorShape shape;\n-        shape.mutable_dims()->CopyFrom(t.dims());\n-        shape_hints.emplace(t.name(), std::move(shape));\n-        ::ONNX_NAMESPACE::TensorProto tf;\n-        tf.set_name(t.name());\n-        tf.mutable_dims()->CopyFrom(t.dims());\n-        tf.set_data_type(::ONNX_NAMESPACE::TensorProto::FLOAT);\n-        std::vector<int64_t> v;\n-        v.resize(t.raw_data().size() / sizeof(int64_t));\n-        memcpy(v.data(), t.raw_data().data(), t.raw_data().size());\n-        std::vector<float> vf;\n-        for (auto i : v) {\n-          vf.push_back(static_cast<float>(i));\n+        auto results = exporter.Caffe2OpToOnnxNodes(op, shape_hints);\n+        for (const auto& n : results.first) {\n+          if (!importer->supports(n)) {\n+            LOG(INFO) << \"TRT does not support ONNX node \" << n.op_type();\n+            return false;\n+          }\n         }\n-        tf.mutable_raw_data()->assign(\n-            reinterpret_cast<const char*>(vf.data()),\n-            sizeof(float) * vf.size());\n \n-        onnx_model.mutable_graph()->add_initializer()->CopyFrom(tf);\n-      }\n-    } else {\n-      end = op_idx;\n-      ClusterToTrtOp(\n-          ws,\n-          *pred_net,\n-          start,\n-          end,\n-          weights,\n-          shape_hints,\n-          &onnx_model,\n-          &new_ops);\n-      trt_group = false;\n-      new_ops.emplace_back(op);\n-    }\n-    ++op_idx;\n-  }\n-  if (trt_group) {\n-    end = op_idx;\n-    ClusterToTrtOp(\n-        ws, *pred_net, start, end, weights, shape_hints, &onnx_model, &new_ops);\n-    trt_group = false;\n-  }\n+        return true;\n+      };\n+\n+  // function to convert runnbale subgraph into a trt op. Note that to keep the\n+  // interface clean, we do the double conversion from C2 op to Onnx ops here\n+  // but it should be OK as the cost is really small. We also need to keep the\n+  // same exporter throughout the process to avoid duplicated dummy name\n+  // generation\n+  onnx::OnnxExporter exporter2(nullptr, true);\n+  auto trt_converter =\n+      [this, ws, &shape_hints, &exporter2](const caffe2::NetDef& net) mutable {\n+        return SubnetToTrtOp(net, ws, &exporter2, &shape_hints);\n+      };\n+\n+  NetDef net_opt = opt::OptimizeForBackend(*pred_net, supports, trt_converter);\n+\n+  // Need to figure out a proper place to handle device option\n+  net_opt.mutable_device_option()->CopyFrom(pred_net->device_option());", "path": "caffe2/contrib/tensorrt/tensorrt_tranformer.cc", "position": 431, "original_position": 421, "commit_id": "f5557d66938f4b650f59ef0df73276bbb4401fb1", "original_commit_id": "1befdbf81796cfb902b8be63d2a848ba4bed5e65", "user": {"login": "bwasti", "id": 4842908, "node_id": "MDQ6VXNlcjQ4NDI5MDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/4842908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bwasti", "html_url": "https://github.com/bwasti", "followers_url": "https://api.github.com/users/bwasti/followers", "following_url": "https://api.github.com/users/bwasti/following{/other_user}", "gists_url": "https://api.github.com/users/bwasti/gists{/gist_id}", "starred_url": "https://api.github.com/users/bwasti/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bwasti/subscriptions", "organizations_url": "https://api.github.com/users/bwasti/orgs", "repos_url": "https://api.github.com/users/bwasti/repos", "events_url": "https://api.github.com/users/bwasti/events{/privacy}", "received_events_url": "https://api.github.com/users/bwasti/received_events", "type": "User", "site_admin": false}, "body": "we may want to include a `Caffe2Annotation : nom::repr::Annotation` class to handle a lot of the caffe2 specific things in the future", "created_at": "2018-04-18T20:58:28Z", "updated_at": "2018-11-23T15:42:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/6696#discussion_r182567346", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6696", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182567346"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6696#discussion_r182567346"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6696"}}, "body_html": "<p>we may want to include a <code>Caffe2Annotation : nom::repr::Annotation</code> class to handle a lot of the caffe2 specific things in the future</p>", "body_text": "we may want to include a Caffe2Annotation : nom::repr::Annotation class to handle a lot of the caffe2 specific things in the future"}