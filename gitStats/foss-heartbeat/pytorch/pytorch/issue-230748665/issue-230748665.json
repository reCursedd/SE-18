{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1624", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1624/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1624/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1624/events", "html_url": "https://github.com/pytorch/pytorch/issues/1624", "id": 230748665, "node_id": "MDU6SXNzdWUyMzA3NDg2NjU=", "number": 1624, "title": "Fatal Python error: Python memory allocator called without holding the GIL (with debug build of python)", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/pytorch/pytorch/milestones/2", "html_url": "https://github.com/pytorch/pytorch/milestone/2", "labels_url": "https://api.github.com/repos/pytorch/pytorch/milestones/2/labels", "id": 2536200, "node_id": "MDk6TWlsZXN0b25lMjUzNjIwMA==", "number": 2, "title": "v0.2", "description": "", "creator": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 34, "state": "closed", "created_at": "2017-05-22T18:19:28Z", "updated_at": "2018-08-06T21:16:06Z", "due_on": "2017-06-04T07:00:00Z", "closed_at": "2018-08-06T21:16:06Z"}, "comments": 3, "created_at": "2017-05-23T15:25:25Z", "updated_at": "2017-05-24T19:45:36Z", "closed_at": "2017-05-24T19:45:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I built a debug version of python 3.6.1 (via \"./configure --with-pydebug\") and ran TestAutograd and the following error came up:</p>\n<pre><code>[~/local/pytorch6] python3 test/test_autograd.py TestAutograd.test_grad\nFatal Python error: Python memory allocator called without holding the GIL\n\nThread 0x00007fc8f4f8f700 (most recent call first):\n\nThread 0x00007fc8f5790700 (most recent call first):\n\nCurrent thread 0x00007fc8f5f91700 (most recent call first):\n\nThread 0x00007fc92d4ae740 (most recent call first):\n  File \"/data/users/gchanan/pytorch6/torch/autograd/__init__.py\", line 153 in grad\n  File \"test/test_autograd.py\", line 184 in test_grad\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 601 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 649 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/runner.py\", line 176 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 255 in runTests\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 94 in __init__\n  File \"/data/users/gchanan/pytorch6/test/common.py\", line 30 in run_tests\n  File \"test/test_autograd.py\", line 1717 in &lt;module&gt;\nAborted (core dumped)\n</code></pre>\n<p>Running this through gdb I get the following backtrace:</p>\n<pre><code>(gdb) bt\n#0  0x00007ffff712c1d7 in raise () at /lib64/libc.so.6\n#1  0x00007ffff712d8c8 in abort () at /lib64/libc.so.6\n#2  0x0000000000420e2f in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1457\n#3  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\n#4  0x000000000041daa2 in _PyMem_DebugFree (ctx=0x880fd0 &lt;_PyMem_Debug+48&gt;, ptr=0x936420) at Objects/obmalloc.c:1994\n#5  0x000000000041e78d in PyMem_Free (ptr=&lt;optimized out&gt;) at Objects/obmalloc.c:442\n#6  0x000000000043a9b4 in _PyFaulthandler_Fini () at ./Modules/faulthandler.c:1369\n#7  0x0000000000420e19 in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1431\n#8  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\n#9  0x000000000041d5ec in _PyMem_DebugMalloc (ctx=0x881000 &lt;_PyMem_Debug+96&gt;, nbytes=104) at Objects/obmalloc.c:1980\n#10 0x000000000041e83b in PyObject_Malloc (size=size@entry=104) at Objects/obmalloc.c:479\n#11 0x0000000000436e4d in _PyObject_GC_Alloc (use_calloc=use_calloc@entry=0, basicsize=basicsize@entry=80) at Modules/gcmodule.c:1714\n#12 0x0000000000437382 in _PyObject_GC_Malloc (basicsize=basicsize@entry=80) at Modules/gcmodule.c:1736\n#13 0x00000000004a8443 in PyType_GenericAlloc (type=0x1145908, nitems=0) at Objects/typeobject.c:936\n#14 0x00007fffef4c7e92 in THPVariable_NewWithVar(PyTypeObject*, std::shared_ptr&lt;torch::autograd::Variable&gt;) (type=&lt;optimized out&gt;, var=...) at torch/csrc/autograd/python_variable.cpp:23\n#15 0x00007fffef4c8f7b in THPVariable_Wrap(std::shared_ptr&lt;torch::autograd::Variable&gt; const&amp;) (var=...) at torch/csrc/autograd/python_variable.cpp:38\n#16 0x00007fffef4cab2a in __lambda1::operator() (grads=..., _unused=&lt;optimized out&gt;, __closure=0x1312900) at torch/csrc/autograd/python_engine.cpp:187\n#17 0x00007fffef4cab2a in std::_Function_handler&lt;bool(torch::autograd::Function*, std::vector&lt;std::shared_ptr&lt;torch::autograd::Variable&gt;, std::allocator&lt;std::shared_ptr&lt;torch::autograd::Variable&gt; &gt; &gt;&amp;), THPEngine_run_backward(THPEngine*, PyObject*, PyObject*)::__lambda1&gt;::_M_invoke(const std::_Any_data &amp;, torch::autograd::Function *, std::vector&lt;std::shared_ptr&lt;torch::autograd::Variable&gt;, std::allocator&lt;std::shared_ptr&lt;torch::autograd::Variable&gt; &gt; &gt; &amp;) (__functor=..., __args#0=&lt;optimized out&gt;, __args#1=...) at /usr/include/c++/4.8.2/functional:2057\n#18 0x00007fffef4b5706 in std::function&lt;bool (torch::autograd::Function*, std::vector&lt;std::shared_ptr&lt;torch::autograd::Variable&gt;, std::allocator&lt;std::shared_ptr&lt;torch::autograd::Variable&gt; &gt; &gt;&amp;)&gt;::operator()(torch::autograd::Function*, std::vector&lt;std::shared_ptr&lt;torch::autograd::Variable&gt;, std::allocator&lt;std::shared_ptr&lt;torch::autograd::Variable&gt; &gt; &gt;&amp;) const (this=&lt;optimized out&gt;, __args#0=__args#0@entry=0x12fe868, __args#1=...) at /usr/include/c++/4.8.2/functional:2471\n#19 0x00007fffef4b1f83 in torch::autograd::call_function(torch::autograd::FunctionTask&amp;) (task=...) at torch/csrc/autograd/engine.cpp:152\n#20 0x00007fffef4b3345 in torch::autograd::Engine::evaluate_function(torch::autograd::FunctionTask&amp;) (this=this@entry=0x7ffff01671a0 &lt;engine&gt;, task=...) at torch/csrc/autograd/engine.cpp:160\n#21 0x00007fffef4b41e3 in torch::autograd::Engine::thread_main(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;) (this=this@entry=0x7ffff01671a0 &lt;engine&gt;, queue=...) at torch/csrc/autograd/engine.cpp:110\n#22 0x00007fffef4cd7f7 in PythonEngine::thread_main(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;) (this=0x7ffff01671a0 &lt;engine&gt;, queue=...) at torch/csrc/autograd/python_engine.cpp:23\n#23 0x00007fffef4b57ca in std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt;::operator()&lt;std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;, void&gt; (__object=&lt;optimized out&gt;, this=&lt;optimized out&gt;) at /usr/include/c++/4.8.2/functional:601\n#24 0x00007fffef4b57ca in std::_Bind_simple&lt;std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt;(torch::autograd::Engine*, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt;::_M_invoke&lt;0ul, 1ul&gt; (this=&lt;optimized out&gt;) at /usr/include/c++/4.8.2/functional:1732\n#25 0x00007fffef4b57ca in std::_Bind_simple&lt;std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt; (torch::autograd::Engine*, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt;::operator()() (this=&lt;optimized out&gt;) at /usr/include/c++/4.8.2/functional:1720\n#26 0x00007fffef4b57ca in std::thread::_Impl&lt;std::_Bind_simple&lt;std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt; (torch::autograd::Engine*, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt; &gt;::_M_run() (this=&lt;optimized out&gt;) at /usr/include/c++/4.8.2/thread:115\n#27 0x00007fffd3a58230 in  () at /lib64/libstdc++.so.6\n#28 0x00007ffff7bc8dc5 in start_thread () at /lib64/libpthread.so.0\n#29 0x00007ffff71ee73d in clone () at /lib64/libc.so.6\n</code></pre>\n<p>The following commit seems to fix the issue: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/gchanan/pytorch/commit/eef93b7dcbc50e38c03bbc319ee8acc20b756fa5/hovercard\" href=\"https://github.com/gchanan/pytorch/commit/eef93b7dcbc50e38c03bbc319ee8acc20b756fa5\">gchanan@<tt>eef93b7</tt></a> although I don't know enough about the autograd engine at this point to say if that's the correct fix or not.</p>\n<p>Even with the above change I can't get through the test suite with a debug build of python3.6.1; I'll file more issues as I find them (perhaps we should have a jenkins job running this?)</p>", "body_text": "I built a debug version of python 3.6.1 (via \"./configure --with-pydebug\") and ran TestAutograd and the following error came up:\n[~/local/pytorch6] python3 test/test_autograd.py TestAutograd.test_grad\nFatal Python error: Python memory allocator called without holding the GIL\n\nThread 0x00007fc8f4f8f700 (most recent call first):\n\nThread 0x00007fc8f5790700 (most recent call first):\n\nCurrent thread 0x00007fc8f5f91700 (most recent call first):\n\nThread 0x00007fc92d4ae740 (most recent call first):\n  File \"/data/users/gchanan/pytorch6/torch/autograd/__init__.py\", line 153 in grad\n  File \"test/test_autograd.py\", line 184 in test_grad\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 601 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 649 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/runner.py\", line 176 in run\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 255 in runTests\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 94 in __init__\n  File \"/data/users/gchanan/pytorch6/test/common.py\", line 30 in run_tests\n  File \"test/test_autograd.py\", line 1717 in <module>\nAborted (core dumped)\n\nRunning this through gdb I get the following backtrace:\n(gdb) bt\n#0  0x00007ffff712c1d7 in raise () at /lib64/libc.so.6\n#1  0x00007ffff712d8c8 in abort () at /lib64/libc.so.6\n#2  0x0000000000420e2f in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1457\n#3  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\n#4  0x000000000041daa2 in _PyMem_DebugFree (ctx=0x880fd0 <_PyMem_Debug+48>, ptr=0x936420) at Objects/obmalloc.c:1994\n#5  0x000000000041e78d in PyMem_Free (ptr=<optimized out>) at Objects/obmalloc.c:442\n#6  0x000000000043a9b4 in _PyFaulthandler_Fini () at ./Modules/faulthandler.c:1369\n#7  0x0000000000420e19 in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1431\n#8  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\n#9  0x000000000041d5ec in _PyMem_DebugMalloc (ctx=0x881000 <_PyMem_Debug+96>, nbytes=104) at Objects/obmalloc.c:1980\n#10 0x000000000041e83b in PyObject_Malloc (size=size@entry=104) at Objects/obmalloc.c:479\n#11 0x0000000000436e4d in _PyObject_GC_Alloc (use_calloc=use_calloc@entry=0, basicsize=basicsize@entry=80) at Modules/gcmodule.c:1714\n#12 0x0000000000437382 in _PyObject_GC_Malloc (basicsize=basicsize@entry=80) at Modules/gcmodule.c:1736\n#13 0x00000000004a8443 in PyType_GenericAlloc (type=0x1145908, nitems=0) at Objects/typeobject.c:936\n#14 0x00007fffef4c7e92 in THPVariable_NewWithVar(PyTypeObject*, std::shared_ptr<torch::autograd::Variable>) (type=<optimized out>, var=...) at torch/csrc/autograd/python_variable.cpp:23\n#15 0x00007fffef4c8f7b in THPVariable_Wrap(std::shared_ptr<torch::autograd::Variable> const&) (var=...) at torch/csrc/autograd/python_variable.cpp:38\n#16 0x00007fffef4cab2a in __lambda1::operator() (grads=..., _unused=<optimized out>, __closure=0x1312900) at torch/csrc/autograd/python_engine.cpp:187\n#17 0x00007fffef4cab2a in std::_Function_handler<bool(torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&), THPEngine_run_backward(THPEngine*, PyObject*, PyObject*)::__lambda1>::_M_invoke(const std::_Any_data &, torch::autograd::Function *, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > > &) (__functor=..., __args#0=<optimized out>, __args#1=...) at /usr/include/c++/4.8.2/functional:2057\n#18 0x00007fffef4b5706 in std::function<bool (torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&)>::operator()(torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&) const (this=<optimized out>, __args#0=__args#0@entry=0x12fe868, __args#1=...) at /usr/include/c++/4.8.2/functional:2471\n#19 0x00007fffef4b1f83 in torch::autograd::call_function(torch::autograd::FunctionTask&) (task=...) at torch/csrc/autograd/engine.cpp:152\n#20 0x00007fffef4b3345 in torch::autograd::Engine::evaluate_function(torch::autograd::FunctionTask&) (this=this@entry=0x7ffff01671a0 <engine>, task=...) at torch/csrc/autograd/engine.cpp:160\n#21 0x00007fffef4b41e3 in torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::ReadyQueue>) (this=this@entry=0x7ffff01671a0 <engine>, queue=...) at torch/csrc/autograd/engine.cpp:110\n#22 0x00007fffef4cd7f7 in PythonEngine::thread_main(std::shared_ptr<torch::autograd::ReadyQueue>) (this=0x7ffff01671a0 <engine>, queue=...) at torch/csrc/autograd/python_engine.cpp:23\n#23 0x00007fffef4b57ca in std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()<std::shared_ptr<torch::autograd::ReadyQueue>, void> (__object=<optimized out>, this=<optimized out>) at /usr/include/c++/4.8.2/functional:601\n#24 0x00007fffef4b57ca in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)>(torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)>::_M_invoke<0ul, 1ul> (this=<optimized out>) at /usr/include/c++/4.8.2/functional:1732\n#25 0x00007fffef4b57ca in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()() (this=<optimized out>) at /usr/include/c++/4.8.2/functional:1720\n#26 0x00007fffef4b57ca in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=<optimized out>) at /usr/include/c++/4.8.2/thread:115\n#27 0x00007fffd3a58230 in  () at /lib64/libstdc++.so.6\n#28 0x00007ffff7bc8dc5 in start_thread () at /lib64/libpthread.so.0\n#29 0x00007ffff71ee73d in clone () at /lib64/libc.so.6\n\nThe following commit seems to fix the issue: gchanan@eef93b7 although I don't know enough about the autograd engine at this point to say if that's the correct fix or not.\nEven with the above change I can't get through the test suite with a debug build of python3.6.1; I'll file more issues as I find them (perhaps we should have a jenkins job running this?)", "body": "I built a debug version of python 3.6.1 (via \"./configure --with-pydebug\") and ran TestAutograd and the following error came up:\r\n\r\n```\r\n[~/local/pytorch6] python3 test/test_autograd.py TestAutograd.test_grad\r\nFatal Python error: Python memory allocator called without holding the GIL\r\n\r\nThread 0x00007fc8f4f8f700 (most recent call first):\r\n\r\nThread 0x00007fc8f5790700 (most recent call first):\r\n\r\nCurrent thread 0x00007fc8f5f91700 (most recent call first):\r\n\r\nThread 0x00007fc92d4ae740 (most recent call first):\r\n  File \"/data/users/gchanan/pytorch6/torch/autograd/__init__.py\", line 153 in grad\r\n  File \"test/test_autograd.py\", line 184 in test_grad\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 601 in run\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/case.py\", line 649 in __call__\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 122 in run\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/suite.py\", line 84 in __call__\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/runner.py\", line 176 in run\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 255 in runTests\r\n  File \"/data/users/gchanan/python3/lib/python3.6/unittest/main.py\", line 94 in __init__\r\n  File \"/data/users/gchanan/pytorch6/test/common.py\", line 30 in run_tests\r\n  File \"test/test_autograd.py\", line 1717 in <module>\r\nAborted (core dumped)\r\n```\r\n\r\nRunning this through gdb I get the following backtrace:\r\n```\r\n(gdb) bt\r\n#0  0x00007ffff712c1d7 in raise () at /lib64/libc.so.6\r\n#1  0x00007ffff712d8c8 in abort () at /lib64/libc.so.6\r\n#2  0x0000000000420e2f in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1457\r\n#3  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\r\n#4  0x000000000041daa2 in _PyMem_DebugFree (ctx=0x880fd0 <_PyMem_Debug+48>, ptr=0x936420) at Objects/obmalloc.c:1994\r\n#5  0x000000000041e78d in PyMem_Free (ptr=<optimized out>) at Objects/obmalloc.c:442\r\n#6  0x000000000043a9b4 in _PyFaulthandler_Fini () at ./Modules/faulthandler.c:1369\r\n#7  0x0000000000420e19 in Py_FatalError (msg=msg@entry=0x5c0b70 \"Python memory allocator called without holding the GIL\") at Python/pylifecycle.c:1431\r\n#8  0x000000000041d5b1 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:1972\r\n#9  0x000000000041d5ec in _PyMem_DebugMalloc (ctx=0x881000 <_PyMem_Debug+96>, nbytes=104) at Objects/obmalloc.c:1980\r\n#10 0x000000000041e83b in PyObject_Malloc (size=size@entry=104) at Objects/obmalloc.c:479\r\n#11 0x0000000000436e4d in _PyObject_GC_Alloc (use_calloc=use_calloc@entry=0, basicsize=basicsize@entry=80) at Modules/gcmodule.c:1714\r\n#12 0x0000000000437382 in _PyObject_GC_Malloc (basicsize=basicsize@entry=80) at Modules/gcmodule.c:1736\r\n#13 0x00000000004a8443 in PyType_GenericAlloc (type=0x1145908, nitems=0) at Objects/typeobject.c:936\r\n#14 0x00007fffef4c7e92 in THPVariable_NewWithVar(PyTypeObject*, std::shared_ptr<torch::autograd::Variable>) (type=<optimized out>, var=...) at torch/csrc/autograd/python_variable.cpp:23\r\n#15 0x00007fffef4c8f7b in THPVariable_Wrap(std::shared_ptr<torch::autograd::Variable> const&) (var=...) at torch/csrc/autograd/python_variable.cpp:38\r\n#16 0x00007fffef4cab2a in __lambda1::operator() (grads=..., _unused=<optimized out>, __closure=0x1312900) at torch/csrc/autograd/python_engine.cpp:187\r\n#17 0x00007fffef4cab2a in std::_Function_handler<bool(torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&), THPEngine_run_backward(THPEngine*, PyObject*, PyObject*)::__lambda1>::_M_invoke(const std::_Any_data &, torch::autograd::Function *, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > > &) (__functor=..., __args#0=<optimized out>, __args#1=...) at /usr/include/c++/4.8.2/functional:2057\r\n#18 0x00007fffef4b5706 in std::function<bool (torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&)>::operator()(torch::autograd::Function*, std::vector<std::shared_ptr<torch::autograd::Variable>, std::allocator<std::shared_ptr<torch::autograd::Variable> > >&) const (this=<optimized out>, __args#0=__args#0@entry=0x12fe868, __args#1=...) at /usr/include/c++/4.8.2/functional:2471\r\n#19 0x00007fffef4b1f83 in torch::autograd::call_function(torch::autograd::FunctionTask&) (task=...) at torch/csrc/autograd/engine.cpp:152\r\n#20 0x00007fffef4b3345 in torch::autograd::Engine::evaluate_function(torch::autograd::FunctionTask&) (this=this@entry=0x7ffff01671a0 <engine>, task=...) at torch/csrc/autograd/engine.cpp:160\r\n#21 0x00007fffef4b41e3 in torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::ReadyQueue>) (this=this@entry=0x7ffff01671a0 <engine>, queue=...) at torch/csrc/autograd/engine.cpp:110\r\n#22 0x00007fffef4cd7f7 in PythonEngine::thread_main(std::shared_ptr<torch::autograd::ReadyQueue>) (this=0x7ffff01671a0 <engine>, queue=...) at torch/csrc/autograd/python_engine.cpp:23\r\n#23 0x00007fffef4b57ca in std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()<std::shared_ptr<torch::autograd::ReadyQueue>, void> (__object=<optimized out>, this=<optimized out>) at /usr/include/c++/4.8.2/functional:601\r\n#24 0x00007fffef4b57ca in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)>(torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)>::_M_invoke<0ul, 1ul> (this=<optimized out>) at /usr/include/c++/4.8.2/functional:1732\r\n#25 0x00007fffef4b57ca in std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)>::operator()() (this=<optimized out>) at /usr/include/c++/4.8.2/functional:1720\r\n#26 0x00007fffef4b57ca in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=<optimized out>) at /usr/include/c++/4.8.2/thread:115\r\n#27 0x00007fffd3a58230 in  () at /lib64/libstdc++.so.6\r\n#28 0x00007ffff7bc8dc5 in start_thread () at /lib64/libpthread.so.0\r\n#29 0x00007ffff71ee73d in clone () at /lib64/libc.so.6\r\n```\r\n\r\nThe following commit seems to fix the issue: https://github.com/gchanan/pytorch/commit/eef93b7dcbc50e38c03bbc319ee8acc20b756fa5 although I don't know enough about the autograd engine at this point to say if that's the correct fix or not.\r\n\r\nEven with the above change I can't get through the test suite with a debug build of python3.6.1; I'll file more issues as I find them (perhaps we should have a jenkins job running this?)"}