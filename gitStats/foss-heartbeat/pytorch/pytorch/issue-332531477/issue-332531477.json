{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8499", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8499/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8499/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8499/events", "html_url": "https://github.com/pytorch/pytorch/issues/8499", "id": 332531477, "node_id": "MDU6SXNzdWUzMzI1MzE0Nzc=", "number": 8499, "title": "[JIT] Accumulation operator shape propagation broadcast failures", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-06-14T19:21:00Z", "updated_at": "2018-06-18T19:41:42Z", "closed_at": "2018-06-18T19:41:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>These operator-level tests fail at shape propagation, ostensibly because they are accumulation ops where the accumulation input is passed in as a scalar whereas the other operands are tensors. Shape propagation seems to not be handling this broadcasting case:</p>\n<p>Example failure</p>\n<pre><code>\n======================================================================\nERROR: test_addbmm_broadcast_lhs_coef (__main__.TestAutogradGenerated)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test/test_autograd.py\", line 3665, in do_test\n    check(name)\n  File \"test/test_autograd.py\", line 3592, in check\n    fn, (self_variable,) + args_variable)\n  File \"test/test_autograd.py\", line 3498, in check_against_reference\n    outputs_test = func(*nograd_inputs)\n  File \"test/test_autograd.py\", line 3474, in script_fn\n    return output_process_fn(CU.the_method(*tensors))\nRuntimeError: \ninvalid argument 2: size '[1]' is invalid for input with 125 elements at ../aten/src/TH/THStorage.cpp:59:\noperation failed shape propagation:\n\ndef the_method(i0, i1, i2):\n    return i0.addbmm(0.2, 0.6, i1, i2)\n           ~~~~~~~~~ &lt;--- HERE\n</code></pre>\n<p>Failing tests:</p>\n<ul>\n<li><code>test_addbmm_broadcast_lhs_coef</code></li>\n<li><code>test_addbmm_coef</code></li>\n<li><code>test_addbmm_scalar_broadcast_lhs_coef</code></li>\n<li><code>test_addcdiv_scalar_scale_broadcast_lhs</code></li>\n<li><code>test_addcdiv_scale</code></li>\n<li><code>test_addcdiv_scale_broadcast_all</code></li>\n<li><code>test_addcdiv_scale_broadcast_rhs</code></li>\n<li><code>test_addcmul_scalar_scale_broadcast_lhs</code></li>\n<li><code>test_addcmul_scale</code></li>\n<li><code>test_addcmul_scale_broadcast_all</code></li>\n<li><code>test_addcmul_scale_broadcast_rhs</code></li>\n<li><code>test_addmv_broadcast_lhs_coef</code></li>\n<li><code>test_addmv_coef</code></li>\n<li><code>test_addmv_scalar_broadcast_lhs_coef</code></li>\n<li><code>test_addr_broadcast_lhs_coef</code></li>\n<li><code>test_addr_coef</code></li>\n<li><code>test_baddbmm_broadcast_lhs_coef</code></li>\n<li><code>test_baddbmm_coef</code></li>\n<li><code>test_baddbmm_scalar_broadcast_lhs_coef</code></li>\n<li><code>test_addmm_broadcast_lhs_coef</code></li>\n<li><code>test_addmm_coef</code></li>\n<li><code>test_addmm_scalar_broadcast_lhs_coef</code></li>\n</ul>", "body_text": "These operator-level tests fail at shape propagation, ostensibly because they are accumulation ops where the accumulation input is passed in as a scalar whereas the other operands are tensors. Shape propagation seems to not be handling this broadcasting case:\nExample failure\n\n======================================================================\nERROR: test_addbmm_broadcast_lhs_coef (__main__.TestAutogradGenerated)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test/test_autograd.py\", line 3665, in do_test\n    check(name)\n  File \"test/test_autograd.py\", line 3592, in check\n    fn, (self_variable,) + args_variable)\n  File \"test/test_autograd.py\", line 3498, in check_against_reference\n    outputs_test = func(*nograd_inputs)\n  File \"test/test_autograd.py\", line 3474, in script_fn\n    return output_process_fn(CU.the_method(*tensors))\nRuntimeError: \ninvalid argument 2: size '[1]' is invalid for input with 125 elements at ../aten/src/TH/THStorage.cpp:59:\noperation failed shape propagation:\n\ndef the_method(i0, i1, i2):\n    return i0.addbmm(0.2, 0.6, i1, i2)\n           ~~~~~~~~~ <--- HERE\n\nFailing tests:\n\ntest_addbmm_broadcast_lhs_coef\ntest_addbmm_coef\ntest_addbmm_scalar_broadcast_lhs_coef\ntest_addcdiv_scalar_scale_broadcast_lhs\ntest_addcdiv_scale\ntest_addcdiv_scale_broadcast_all\ntest_addcdiv_scale_broadcast_rhs\ntest_addcmul_scalar_scale_broadcast_lhs\ntest_addcmul_scale\ntest_addcmul_scale_broadcast_all\ntest_addcmul_scale_broadcast_rhs\ntest_addmv_broadcast_lhs_coef\ntest_addmv_coef\ntest_addmv_scalar_broadcast_lhs_coef\ntest_addr_broadcast_lhs_coef\ntest_addr_coef\ntest_baddbmm_broadcast_lhs_coef\ntest_baddbmm_coef\ntest_baddbmm_scalar_broadcast_lhs_coef\ntest_addmm_broadcast_lhs_coef\ntest_addmm_coef\ntest_addmm_scalar_broadcast_lhs_coef", "body": "These operator-level tests fail at shape propagation, ostensibly because they are accumulation ops where the accumulation input is passed in as a scalar whereas the other operands are tensors. Shape propagation seems to not be handling this broadcasting case:\r\n\r\nExample failure\r\n```\r\n\r\n======================================================================\r\nERROR: test_addbmm_broadcast_lhs_coef (__main__.TestAutogradGenerated)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test/test_autograd.py\", line 3665, in do_test\r\n    check(name)\r\n  File \"test/test_autograd.py\", line 3592, in check\r\n    fn, (self_variable,) + args_variable)\r\n  File \"test/test_autograd.py\", line 3498, in check_against_reference\r\n    outputs_test = func(*nograd_inputs)\r\n  File \"test/test_autograd.py\", line 3474, in script_fn\r\n    return output_process_fn(CU.the_method(*tensors))\r\nRuntimeError: \r\ninvalid argument 2: size '[1]' is invalid for input with 125 elements at ../aten/src/TH/THStorage.cpp:59:\r\noperation failed shape propagation:\r\n\r\ndef the_method(i0, i1, i2):\r\n    return i0.addbmm(0.2, 0.6, i1, i2)\r\n           ~~~~~~~~~ <--- HERE\r\n```\r\n\r\nFailing tests:\r\n- `test_addbmm_broadcast_lhs_coef`\r\n- `test_addbmm_coef`\r\n- `test_addbmm_scalar_broadcast_lhs_coef`\r\n- `test_addcdiv_scalar_scale_broadcast_lhs`\r\n- `test_addcdiv_scale`\r\n- `test_addcdiv_scale_broadcast_all`\r\n- `test_addcdiv_scale_broadcast_rhs`\r\n- `test_addcmul_scalar_scale_broadcast_lhs`\r\n- `test_addcmul_scale`\r\n- `test_addcmul_scale_broadcast_all`\r\n- `test_addcmul_scale_broadcast_rhs`\r\n- `test_addmv_broadcast_lhs_coef`\r\n- `test_addmv_coef`\r\n- `test_addmv_scalar_broadcast_lhs_coef`\r\n- `test_addr_broadcast_lhs_coef`\r\n- `test_addr_coef`\r\n- `test_baddbmm_broadcast_lhs_coef`\r\n- `test_baddbmm_coef`\r\n- `test_baddbmm_scalar_broadcast_lhs_coef`\r\n- `test_addmm_broadcast_lhs_coef`\r\n- `test_addmm_coef`\r\n- `test_addmm_scalar_broadcast_lhs_coef`\r\n"}