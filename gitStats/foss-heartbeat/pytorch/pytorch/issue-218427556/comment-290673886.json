{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/290673886", "html_url": "https://github.com/pytorch/pytorch/issues/1150#issuecomment-290673886", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1150", "id": 290673886, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDY3Mzg4Ng==", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-31T10:10:16Z", "updated_at": "2017-03-31T10:10:16Z", "author_association": "COLLABORATOR", "body_html": "<p>A simple solution for this would be to set the current device to the first element so that everything is created on the right device with <code>torch.cuda.set_device(gpus[0])</code>.<br>\nThat being said I agree that the behaviour of this function may be changed to:</p>\n<ul>\n<li>If the tensor is cpu, just send it to all specified gpus</li>\n<li>If the tensor is on one of the specified gpus, send it to the others</li>\n<li>If the tensor is on gpu but none of the specified one, send it to all specified gpus.<br>\nI am not sure how to do that for an list of gpus that is an Iterable though.</li>\n</ul>\n<p>We should check with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> but if he agrees with this change, a PR would be welcomed :)</p>", "body_text": "A simple solution for this would be to set the current device to the first element so that everything is created on the right device with torch.cuda.set_device(gpus[0]).\nThat being said I agree that the behaviour of this function may be changed to:\n\nIf the tensor is cpu, just send it to all specified gpus\nIf the tensor is on one of the specified gpus, send it to the others\nIf the tensor is on gpu but none of the specified one, send it to all specified gpus.\nI am not sure how to do that for an list of gpus that is an Iterable though.\n\nWe should check with @apaszke but if he agrees with this change, a PR would be welcomed :)", "body": "A simple solution for this would be to set the current device to the first element so that everything is created on the right device with `torch.cuda.set_device(gpus[0])`.\r\nThat being said I agree that the behaviour of this function may be changed to:\r\n* If the tensor is cpu, just send it to all specified gpus\r\n* If the tensor is on one of the specified gpus, send it to the others\r\n* If the tensor is on gpu but none of the specified one, send it to all specified gpus.\r\nI am not sure how to do that for an list of gpus that is an Iterable though.\r\n\r\nWe should check with @apaszke but if he agrees with this change, a PR would be welcomed :)"}