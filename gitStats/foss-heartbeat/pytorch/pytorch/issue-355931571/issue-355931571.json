{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11139", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11139/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11139/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11139/events", "html_url": "https://github.com/pytorch/pytorch/issues/11139", "id": 355931571, "node_id": "MDU6SXNzdWUzNTU5MzE1NzE=", "number": 11139, "title": "Custom torch.utils.data.Dataset causes DataLoader crash on Windows Machine", "user": {"login": "liona24", "id": 25030208, "node_id": "MDQ6VXNlcjI1MDMwMjA4", "avatar_url": "https://avatars0.githubusercontent.com/u/25030208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liona24", "html_url": "https://github.com/liona24", "followers_url": "https://api.github.com/users/liona24/followers", "following_url": "https://api.github.com/users/liona24/following{/other_user}", "gists_url": "https://api.github.com/users/liona24/gists{/gist_id}", "starred_url": "https://api.github.com/users/liona24/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liona24/subscriptions", "organizations_url": "https://api.github.com/users/liona24/orgs", "repos_url": "https://api.github.com/users/liona24/repos", "events_url": "https://api.github.com/users/liona24/events{/privacy}", "received_events_url": "https://api.github.com/users/liona24/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 790080431, "node_id": "MDU6TGFiZWw3OTAwODA0MzE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/windows", "name": "windows", "color": "fcff6b", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-31T10:45:20Z", "updated_at": "2018-08-31T14:06:45Z", "closed_at": "2018-08-31T11:33:05Z", "author_association": "NONE", "body_html": "<p>When I try to use a custom dataset in conjunction with a dataloader and multiple workers an error occurs.</p>\n<p>It only happens on my Windows 10 64 bit machine.</p>\n<p>Minimal working example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.utils.data <span class=\"pl-k\">as</span> data\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">CDataset</span>(<span class=\"pl-e\">data</span>.<span class=\"pl-e\">Dataset</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        data.Dataset.<span class=\"pl-c1\">__init__</span>(<span class=\"pl-c1\">self</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__len__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">4</span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">i</span>):\n        <span class=\"pl-k\">return</span> torch.randn(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)\n\ndataset <span class=\"pl-k\">=</span> CDataset()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> num_workers &gt; 1</span>\nloader <span class=\"pl-k\">=</span> data.DataLoader(dataset, <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\n<span class=\"pl-c1\">next</span>(<span class=\"pl-c1\">iter</span>(loader))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> &lt;-- error here</span></pre></div>\n<p>It produces a rather lengthy error message, depending on the number of workers specified it repeats itself:</p>\n<pre><code>Traceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\n    exitcode = _main(fd)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 114, in _main\n    prepare(preparation_data)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 225, in prepare\n    _fixup_main_from_path(data['init_main_from_path'])\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\n    run_name=\"__mp_main__\")\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lion\\test.py\", line 17, in &lt;module&gt;\n    next(iter(loader))\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 501, in __iter__\n    return _DataLoaderIter(self)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 289, in __init__\n    w.start()\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n    return Popen(process_obj)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 33, in __init__\n    prep_data = spawn.get_preparation_data(process_obj._name)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\n    _check_not_importing_main()\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\n    is not going to be frozen to produce an executable.''')\nRuntimeError:\n        An attempt has been made to start a new process before the\n        current process has finished its bootstrapping phase.\n\n        This probably means that you are not using fork to start your\n        child processes and you have forgotten to use the proper idiom\n        in the main module:\n\n            if __name__ == '__main__':\n                freeze_support()\n                ...\n\n        The \"freeze_support()\" line can be omitted if the program\n        is not going to be frozen to produce an executable.\n</code></pre>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Microsoft Windows 10 Education<br>\nGCC version: (MinGW.org GCC-6.3.0-1) 6.3.0<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.6<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.13.3)<br>\n[pip] numpydoc (0.7.0)<br>\n[pip] torch (0.4.1)<br>\n[conda] pytorch                   0.3.0                py36_0.3.0    peterjc123<br>\n[conda] pytorch-cpu               0.4.1           py36_cpuhe774522_1    pytorch</p>", "body_text": "When I try to use a custom dataset in conjunction with a dataloader and multiple workers an error occurs.\nIt only happens on my Windows 10 64 bit machine.\nMinimal working example:\nimport torch\nimport torch.utils.data as data\n\nclass CDataset(data.Dataset):\n    def __init__(self):\n        data.Dataset.__init__(self)\n\n    def __len__(self):\n        return 4\n\n    def __getitem__(self, i):\n        return torch.randn(2, 3)\n\ndataset = CDataset()\n\n# num_workers > 1\nloader = data.DataLoader(dataset, num_workers=2)\n\nnext(iter(loader))  # <-- error here\nIt produces a rather lengthy error message, depending on the number of workers specified it repeats itself:\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\n    exitcode = _main(fd)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 114, in _main\n    prepare(preparation_data)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 225, in prepare\n    _fixup_main_from_path(data['init_main_from_path'])\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\n    run_name=\"__mp_main__\")\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lion\\test.py\", line 17, in <module>\n    next(iter(loader))\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 501, in __iter__\n    return _DataLoaderIter(self)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 289, in __init__\n    w.start()\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n    return Popen(process_obj)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 33, in __init__\n    prep_data = spawn.get_preparation_data(process_obj._name)\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\n    _check_not_importing_main()\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\n    is not going to be frozen to produce an executable.''')\nRuntimeError:\n        An attempt has been made to start a new process before the\n        current process has finished its bootstrapping phase.\n\n        This probably means that you are not using fork to start your\n        child processes and you have forgotten to use the proper idiom\n        in the main module:\n\n            if __name__ == '__main__':\n                freeze_support()\n                ...\n\n        The \"freeze_support()\" line can be omitted if the program\n        is not going to be frozen to produce an executable.\n\nSystem Info\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Microsoft Windows 10 Education\nGCC version: (MinGW.org GCC-6.3.0-1) 6.3.0\nCMake version: Could not collect\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip] numpy (1.13.3)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.4.1)\n[conda] pytorch                   0.3.0                py36_0.3.0    peterjc123\n[conda] pytorch-cpu               0.4.1           py36_cpuhe774522_1    pytorch", "body": "When I try to use a custom dataset in conjunction with a dataloader and multiple workers an error occurs.\r\n\r\nIt only happens on my Windows 10 64 bit machine. \r\n\r\nMinimal working example:\r\n\r\n```python\r\nimport torch\r\nimport torch.utils.data as data\r\n\r\nclass CDataset(data.Dataset):\r\n    def __init__(self):\r\n        data.Dataset.__init__(self)\r\n\r\n    def __len__(self):\r\n        return 4\r\n\r\n    def __getitem__(self, i):\r\n        return torch.randn(2, 3)\r\n\r\ndataset = CDataset()\r\n\r\n# num_workers > 1\r\nloader = data.DataLoader(dataset, num_workers=2)\r\n\r\nnext(iter(loader))  # <-- error here\r\n```\r\n\r\nIt produces a rather lengthy error message, depending on the number of workers specified it repeats itself:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 114, in _main\r\n    prepare(preparation_data)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 225, in prepare\r\n    _fixup_main_from_path(data['init_main_from_path'])\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 277, in _fixup_main_from_path\r\n    run_name=\"__mp_main__\")\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Lion\\test.py\", line 17, in <module>\r\n    next(iter(loader))\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 501, in __iter__\r\n    return _DataLoaderIter(self)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 289, in __init__\r\n    w.start()\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 33, in __init__\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 143, in get_preparation_data\r\n    _check_not_importing_main()\r\n  File \"E:\\Users\\Lion\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 136, in _check_not_importing_main\r\n    is not going to be frozen to produce an executable.''')\r\nRuntimeError:\r\n        An attempt has been made to start a new process before the\r\n        current process has finished its bootstrapping phase.\r\n\r\n        This probably means that you are not using fork to start your\r\n        child processes and you have forgotten to use the proper idiom\r\n        in the main module:\r\n\r\n            if __name__ == '__main__':\r\n                freeze_support()\r\n                ...\r\n\r\n        The \"freeze_support()\" line can be omitted if the program\r\n        is not going to be frozen to produce an executable.\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Microsoft Windows 10 Education\r\nGCC version: (MinGW.org GCC-6.3.0-1) 6.3.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.13.3)\r\n[pip] numpydoc (0.7.0)\r\n[pip] torch (0.4.1)\r\n[conda] pytorch                   0.3.0                py36_0.3.0    peterjc123\r\n[conda] pytorch-cpu               0.4.1           py36_cpuhe774522_1    pytorch"}