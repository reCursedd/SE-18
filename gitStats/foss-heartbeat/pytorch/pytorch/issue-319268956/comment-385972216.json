{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/385972216", "html_url": "https://github.com/pytorch/pytorch/issues/7142#issuecomment-385972216", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7142", "id": 385972216, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTk3MjIxNg==", "user": {"login": "PetrochukM", "id": 7424737, "node_id": "MDQ6VXNlcjc0MjQ3Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7424737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PetrochukM", "html_url": "https://github.com/PetrochukM", "followers_url": "https://api.github.com/users/PetrochukM/followers", "following_url": "https://api.github.com/users/PetrochukM/following{/other_user}", "gists_url": "https://api.github.com/users/PetrochukM/gists{/gist_id}", "starred_url": "https://api.github.com/users/PetrochukM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PetrochukM/subscriptions", "organizations_url": "https://api.github.com/users/PetrochukM/orgs", "repos_url": "https://api.github.com/users/PetrochukM/repos", "events_url": "https://api.github.com/users/PetrochukM/events{/privacy}", "received_events_url": "https://api.github.com/users/PetrochukM/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-02T13:10:20Z", "updated_at": "2018-05-02T13:10:56Z", "author_association": "NONE", "body_html": "<p>Thanks for getting in touch with me! Sorry if this issue is naive!</p>\n<p>I'm faithfully replicating a paper from Google dealing with audio. It's common for a 10-second clip of audio to be represented by a sequence of 800 vectors. They are able to run their model without running out of memory on 10-second clips with a batch size of 64. They do not use truncated backprop, I checked</p>\n<p>I was expecting I would be able to do the same in PyTorch!</p>\n<p>The demonstration above is that with a super simple Attention model PyTorch is running out of memory in 1600 steps. The real attention used is a bit more complicated in the paper. I run out of memory in 500 steps instead with it.</p>\n<p>tl;dr I am hoping to replicate a paper from Google faithfully, that I expect was built in tensorflow but it seems that PyTorch is less memory efficient based on the evidence above. Noting that I have not worked much with tensorflow.</p>", "body_text": "Thanks for getting in touch with me! Sorry if this issue is naive!\nI'm faithfully replicating a paper from Google dealing with audio. It's common for a 10-second clip of audio to be represented by a sequence of 800 vectors. They are able to run their model without running out of memory on 10-second clips with a batch size of 64. They do not use truncated backprop, I checked\nI was expecting I would be able to do the same in PyTorch!\nThe demonstration above is that with a super simple Attention model PyTorch is running out of memory in 1600 steps. The real attention used is a bit more complicated in the paper. I run out of memory in 500 steps instead with it.\ntl;dr I am hoping to replicate a paper from Google faithfully, that I expect was built in tensorflow but it seems that PyTorch is less memory efficient based on the evidence above. Noting that I have not worked much with tensorflow.", "body": "Thanks for getting in touch with me! Sorry if this issue is naive!\r\n\r\nI'm faithfully replicating a paper from Google dealing with audio. It's common for a 10-second clip of audio to be represented by a sequence of 800 vectors. They are able to run their model without running out of memory on 10-second clips with a batch size of 64. They do not use truncated backprop, I checked\r\n\r\nI was expecting I would be able to do the same in PyTorch!\r\n\r\nThe demonstration above is that with a super simple Attention model PyTorch is running out of memory in 1600 steps. The real attention used is a bit more complicated in the paper. I run out of memory in 500 steps instead with it.\r\n\r\ntl;dr I am hoping to replicate a paper from Google faithfully, that I expect was built in tensorflow but it seems that PyTorch is less memory efficient based on the evidence above. Noting that I have not worked much with tensorflow."}