{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/385988794", "html_url": "https://github.com/pytorch/pytorch/issues/7142#issuecomment-385988794", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7142", "id": 385988794, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTk4ODc5NA==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-02T14:04:13Z", "updated_at": "2018-05-02T14:04:13Z", "author_association": "MEMBER", "body_html": "<p>The fact that your code doesn't match the (probably heavily tuned) TF code from Google doesn't necessarily mean that PyTorch is less memory efficient. There are many tricks like gradient checkpointing, or simply using multiple CUDA devices (with either data or model paralellism), that will let you fairly easily scale the example to longer sequences and larger batches. I'd be surprised if Google used a single GPU for that experiment, so that's likely where the difference lies. I can't see any immediate problems in your issue, so I'll close it, but if you'll manage to create simple PyTorch and TF snippets, where PyTorch is much less efficient than TF, then we'll be happy to investigate that. Currently we don't have anything to compare to. Hope you understand.</p>", "body_text": "The fact that your code doesn't match the (probably heavily tuned) TF code from Google doesn't necessarily mean that PyTorch is less memory efficient. There are many tricks like gradient checkpointing, or simply using multiple CUDA devices (with either data or model paralellism), that will let you fairly easily scale the example to longer sequences and larger batches. I'd be surprised if Google used a single GPU for that experiment, so that's likely where the difference lies. I can't see any immediate problems in your issue, so I'll close it, but if you'll manage to create simple PyTorch and TF snippets, where PyTorch is much less efficient than TF, then we'll be happy to investigate that. Currently we don't have anything to compare to. Hope you understand.", "body": "The fact that your code doesn't match the (probably heavily tuned) TF code from Google doesn't necessarily mean that PyTorch is less memory efficient. There are many tricks like gradient checkpointing, or simply using multiple CUDA devices (with either data or model paralellism), that will let you fairly easily scale the example to longer sequences and larger batches. I'd be surprised if Google used a single GPU for that experiment, so that's likely where the difference lies. I can't see any immediate problems in your issue, so I'll close it, but if you'll manage to create simple PyTorch and TF snippets, where PyTorch is much less efficient than TF, then we'll be happy to investigate that. Currently we don't have anything to compare to. Hope you understand."}