{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83602586", "pull_request_review_id": 4426897, "id": 83602586, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgzNjAyNTg2", "diff_hunk": "@@ -0,0 +1,233 @@\n+from torch.autograd import Function, NestedIOFunction, Variable\n+from torch._thnn import type2backend\n+import torch.backends.cudnn as cudnn\n+try:\n+    import torch.backends.cudnn.rnn\n+except ImportError:\n+    print \"Couldn't import cudnn.rnn\"\n+    pass\n+import torch.backends.cudnn.rnn\n+\n+\n+def _getCudnnMode(mode):\n+    if mode == 'RNN_RELU':\n+        return cudnn.CUDNN_RNN_RELU\n+    elif mode == 'RNN_TANH':\n+        return cudnn.CUDNN_RNN_TANH\n+    elif mode == 'LSTM':\n+        return cudnn.CUDNN_LSTM\n+    elif mode == 'GRU':\n+        return cudnn.CUDNN_GRU\n+    else:\n+        raise Exception(\"Unknown mode: {}\".format(mode))\n+\n+\n+\n+# FIXME: write a proper function library!\n+import thnn\n+import linear as _linear\n+import activation\n+\n+def _wrap(fn, *args):\n+    def inner(*inner_args):\n+        return fn(*args)(*inner_args)\n+    return inner\n+tanh = _wrap(thnn.Tanh)\n+sigmoid = _wrap(thnn.Sigmoid)\n+ReLU = _wrap(thnn.Threshold, 0, 0, False)\n+\n+# get around autograd's lack of None-handling\n+def linear(input, w, b):\n+    if b is not None:\n+        return _linear.Linear()(input, w, b)\n+    else:\n+        return _linear.Linear()(input, w)\n+\n+\n+def RNNReLUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n+        hy = ReLU(linear(input, w_ih, b_ih) + linear(hidden, w_hh, b_hh))\n+        return hy\n+\n+def RNNTanhCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n+        hy = tanh(linear(input, w_ih, b_ih) + linear(hidden, w_hh, b_hh))\n+        return hy\n+\n+def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n+        hx, cx = hidden\n+        hsz = hx.size(1)\n+        gates = linear(input, w_ih, b_ih) + linear(hx, w_hh, b_hh)\n+        # FIXME: chunk\n+        ingate     = sigmoid(gates[:,0*hsz:1*hsz])\n+        forgetgate = sigmoid(gates[:,1*hsz:2*hsz])\n+        cellgate   = tanh(   gates[:,2*hsz:3*hsz])\n+        outgate    = sigmoid(gates[:,3*hsz:4*hsz])\n+        cy = (forgetgate * cx) + (ingate * cellgate)\n+        hy = outgate * tanh(cy)\n+\n+        return hy, cy\n+\n+def GRUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n+        hsz = hidden.size(1)\n+        gi = linear(input, w_ih, b_ih)\n+        gh = linear(hidden, w_hh, b_hh)\n+        # FIXME: chunk\n+\n+        resetgate = sigmoid(gi[:,0*hsz:1*hsz] + gh[:,0*hsz:1*hsz])\n+        inputgate = sigmoid(gi[:,1*hsz:2*hsz] + gh[:,1*hsz:2*hsz])\n+        newgate   = tanh(gi[:,2*hsz:3*hsz] + resetgate * gh[:,2*hsz:3*hsz])\n+        hy     = newgate + inputgate * (hidden - newgate)\n+\n+        return hy\n+\n+def StackedRNN(cell, num_layers, lstm=False):\n+    def forward(input, hidden, weight):\n+        assert(len(weight) == num_layers)\n+        next_hidden = []\n+\n+        if lstm:\n+            hidden = zip(*hidden)\n+\n+        for i in range(num_layers):\n+            hy = cell(input, hidden[i], *weight[i])\n+            next_hidden.append(hy)\n+            input = hy[0] if lstm else hy\n+\n+        if lstm:\n+            next_h, next_c = zip(*next_hidden)\n+            next_hidden = (\n+                input.cat(next_h, 0).view(num_layers, *next_h[0].size()),\n+                input.cat(next_c, 0).view(num_layers, *next_c[0].size())\n+            )\n+        else:\n+            next_hidden = input.cat(next_hidden, 0).view(\n+                num_layers, *next_hidden[0].size()) # FIXME: why input.cat???", "path": "torch/nn/functions/rnn.py", "position": null, "original_position": 103, "commit_id": "b5d13296c65e4b3cd5aa9715cf58df0fc043454e", "original_commit_id": "ccb1f401ff482f1fb25251272656149899758d4a", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "??\n", "created_at": "2016-10-17T09:05:51Z", "updated_at": "2018-11-23T15:31:41Z", "html_url": "https://github.com/pytorch/pytorch/pull/129#discussion_r83602586", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/129", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83602586"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/129#discussion_r83602586"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/129"}}, "body_html": "<p>??</p>", "body_text": "??"}