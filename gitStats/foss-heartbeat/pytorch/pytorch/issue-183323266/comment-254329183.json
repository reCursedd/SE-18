{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/254329183", "html_url": "https://github.com/pytorch/pytorch/pull/129#issuecomment-254329183", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/129", "id": 254329183, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NDMyOTE4Mw==", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-17T20:48:08Z", "updated_at": "2016-10-17T20:48:08Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>So what's exactly the deal with RNN vs cells? RNN is a huge container that accepts all timesteps at once and returns all outputs at once, while all cells are like a regular layer that you can use in a loop?</p>\n</blockquote>\n<p>That's correct. nn.rnn.RNN(...) implements the whole CUDNN RNN API, which does all timesteps, multiple layers, optional dropout, bidirectional, etc.</p>\n<p>nn.rnn.cell.* are just RNN, LSTM, and GRU cells that you can use to make your own RNNs (although they will be much slower than CuDNN). We could also hadd nn.rnn.container that contain the StackedRNN and Recurrent containers, but I'm inclined to let people write that themselves, since it's pretty easy in pytorch.</p>", "body_text": "So what's exactly the deal with RNN vs cells? RNN is a huge container that accepts all timesteps at once and returns all outputs at once, while all cells are like a regular layer that you can use in a loop?\n\nThat's correct. nn.rnn.RNN(...) implements the whole CUDNN RNN API, which does all timesteps, multiple layers, optional dropout, bidirectional, etc.\nnn.rnn.cell.* are just RNN, LSTM, and GRU cells that you can use to make your own RNNs (although they will be much slower than CuDNN). We could also hadd nn.rnn.container that contain the StackedRNN and Recurrent containers, but I'm inclined to let people write that themselves, since it's pretty easy in pytorch.", "body": "> So what's exactly the deal with RNN vs cells? RNN is a huge container that accepts all timesteps at once and returns all outputs at once, while all cells are like a regular layer that you can use in a loop?\n\nThat's correct. nn.rnn.RNN(...) implements the whole CUDNN RNN API, which does all timesteps, multiple layers, optional dropout, bidirectional, etc.\n\nnn.rnn.cell.\\* are just RNN, LSTM, and GRU cells that you can use to make your own RNNs (although they will be much slower than CuDNN). We could also hadd nn.rnn.container that contain the StackedRNN and Recurrent containers, but I'm inclined to let people write that themselves, since it's pretty easy in pytorch.\n"}