{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83594165", "pull_request_review_id": 4426897, "id": 83594165, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgzNTk0MTY1", "diff_hunk": "@@ -596,6 +605,115 @@ def test_MaxUnpool2d_output_size(self):\n                             mu(output_small, indices_small, (h, w)))\n \n \n+    def test_RNN_cell(self):\n+        # this is just a smoke test; these modules are implemented through\n+        # autograd so no Jacobian test is needed\n+        for module in (nn.rnn.cell.RNN, nn.rnn.cell.RNNReLU, nn.rnn.cell.GRU):\n+            for bias in (True, False):\n+                input = Variable(torch.randn(3, 10))\n+                hx = Variable(torch.randn(3, 20))\n+                cell = module(10, 20, bias=bias)\n+                for i in range(6):\n+                    hx = cell(input, hx)\n+\n+                hx.sum().backward()\n+\n+    def test_LSTM_cell(self):\n+        # this is just a smoke test; these modules are implemented through\n+        # autograd so no Jacobian test is needed\n+        for bias in (True, False):\n+            input = Variable(torch.randn(3, 10))\n+            hx = Variable(torch.randn(3, 20))\n+            cx = Variable(torch.randn(3, 20))\n+            lstm = nn.rnn.cell.LSTM(10, 20, bias=bias)\n+            for i in range(6):\n+                hx, cx = lstm(input, (hx, cx))\n+\n+            (hx+cx).sum().backward()\n+\n+    @unittest.skipIf(not TEST_CUDNN, \"needs cudnn\")\n+    def test_RNN_cpu_vs_cudnn(self):\n+\n+        def forward_backward(cuda, module, bias, input_val, hx_val, weights_val):\n+            rnn = module(input_size, hidden_size, num_layers, bias=bias)\n+            is_lstm = module == nn.rnn.LSTM\n+\n+            for x_layer, y_layer in zip(rnn.all_weights, weights_val):\n+                for x, y in zip(x_layer, y_layer):\n+                    x.data.copy_(y.data)\n+\n+            input = Variable(input_val.clone(), requires_grad=True)\n+            if is_lstm:\n+                hx = (Variable(hx_val.clone(), requires_grad=True),\n+                      Variable(hx_val.add(1), requires_grad=True))\n+            else:\n+                hx = Variable(hx_val.clone(), requires_grad=True)\n+\n+            if cuda:\n+                rnn.cuda()\n+                input.data = input.data.cuda()\n+                if is_lstm:\n+                    hx[0].data = hx[0].data.cuda()\n+                    hx[1].data = hx[1].data.cuda()\n+                else:\n+                    hx.data = hx.data.cuda()\n+\n+            output, hy = rnn(input, hx)\n+            # FIXME this is because of a pytorch bug\n+            if is_lstm:\n+                fake_loss = 0*(hy[0] + hy[1]).sum()\n+            else:\n+                fake_loss = 0*hy.sum()\n+\n+            loss = output.sum() + fake_loss\n+            loss.backward()\n+\n+            return {'output': output.data,\n+                    'hy': hy[0].data if is_lstm else hy.data,\n+                    'weights': rnn.all_weights,\n+                    'grad_input': input.grad,\n+                    'grad_hx': hx[0].grad if is_lstm else hx.grad,\n+                    'cy': hy[1].data if is_lstm else None,\n+                    'grad_cx': hx[1].grad if is_lstm else None}\n+\n+        def diff(t_cpu, t_gpu, name):", "path": "test/test_nn.py", "position": null, "original_position": 102, "commit_id": "b5d13296c65e4b3cd5aa9715cf58df0fc043454e", "original_commit_id": "ccb1f401ff482f1fb25251272656149899758d4a", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Use `self.assertEqual`. It accepts different tensor types and checks equality with some precision margin.\n", "created_at": "2016-10-17T08:15:28Z", "updated_at": "2018-11-23T15:31:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/129#discussion_r83594165", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/129", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83594165"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/129#discussion_r83594165"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/129"}}, "body_html": "<p>Use <code>self.assertEqual</code>. It accepts different tensor types and checks equality with some precision margin.</p>", "body_text": "Use self.assertEqual. It accepts different tensor types and checks equality with some precision margin."}