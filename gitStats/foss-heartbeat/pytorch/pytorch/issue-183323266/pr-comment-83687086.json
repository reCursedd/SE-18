{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83687086", "pull_request_review_id": 4514422, "id": 83687086, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgzNjg3MDg2", "diff_hunk": "@@ -0,0 +1,408 @@\n+import torch.cuda\n+import torch.backends.cudnn as cudnn\n+from torch.backends.cudnn import check_error\n+import ctypes\n+\n+\n+def initDropoutDescriptor(fn, handle):\n+    dropout_desc = cudnn.DropoutDescriptor()\n+\n+    dropout_states_size = ctypes.c_long()\n+    check_error(cudnn.lib.cudnnDropoutGetStatesSize(\n+        handle,\n+        ctypes.byref(dropout_states_size)))\n+\n+    dropout_states = torch.cuda.ByteTensor(dropout_states_size.value)\n+    dropout_desc.set(\n+        handle,\n+        fn.dropout,\n+        dropout_states,\n+        fn.seed\n+    )\n+    return dropout_desc\n+\n+\n+def initRNNDescriptor(fn):\n+    rnn_desc = cudnn.RNNDescriptor()\n+\n+    rnn_desc.set(\n+        fn.hidden_size,\n+        fn.num_layers,\n+        fn.dropout_desc,\n+        fn.input_mode,\n+        fn.bidirectional,\n+        fn.mode,\n+        fn.datatype\n+    )\n+    return rnn_desc\n+\n+\n+def initWeightDescriptor(fn, weight):\n+    w_desc = cudnn.FilterDescriptor()\n+    w_view = weight.view(-1, 1, 1)  # seems that filters require >=3 dimensions\n+    w_desc.set(w_view)\n+    return w_desc\n+\n+\n+def _inputSize(fn):\n+    return (fn.seq_length, fn.mini_batch, fn.input_size)\n+\n+\n+def _hiddenSize(fn):\n+    return (fn.num_layers * fn.num_directions, fn.mini_batch, fn.hidden_size)\n+\n+\n+def _outputSize(fn):\n+    return (fn.seq_length, fn.mini_batch, fn.hidden_size * fn.num_directions)\n+\n+\n+def getNumWeights(handle, rnn_desc, x_desc, datatype):\n+    weight_size = ctypes.c_long()\n+    check_error(cudnn.lib.cudnnGetRNNParamsSize(\n+        handle,\n+        rnn_desc,\n+        x_desc,\n+        ctypes.byref(weight_size),\n+        datatype\n+    ))\n+    elem_size = cudnn._sizeofmap[datatype]\n+    assert(weight_size.value % elem_size == 0)\n+    return weight_size.value // elem_size\n+\n+\n+def getParameters(fn, handle, weight_buf):\n+\n+    cudnn_methods = [\n+        cudnn.lib.cudnnGetRNNLinLayerMatrixParams,\n+        cudnn.lib.cudnnGetRNNLinLayerBiasParams\n+    ]\n+\n+    # if fn.mode == cudnn.CUDNN_RNN_RELU or fn.mode == cudnn.CUDNN_RNN_TANH:\n+    #     linear_name = [\"ih\", \"hh\"]\n+    # elif fn.mode == cudnn.CUDNN_LSTM:\n+    #     linear_name = [\"ii\", \"if\", \"ic\", \"io\", \"hi\", \"hf\", \"hc\", \"ho\"]\n+    # elif fn.mode == cudnn.CUDNN_GRU:\n+    #     linear_name = [\"ir\", \"iu\", \"ic\", \"hr\", \"hu\", \"hc\"]\n+    # else:\n+    #     raise Exception(\"Unknown mode: {}\".format(fn.mode))\n+\n+    params = []\n+    num_linear_layers = _numLinearLayers(fn)\n+    num_layers = fn.num_directions * fn.num_layers\n+    for layer in range(num_layers):\n+        layer_params = []\n+        for cudnn_method in cudnn_methods:\n+            for linear_id in range(num_linear_layers):\n+                lin_layer_mat_desc = cudnn.FilterDescriptor()\n+                matrix_pointer = ctypes.c_void_p()\n+                check_error(cudnn_method(\n+                    handle,\n+                    fn.rnn_desc,\n+                    layer,\n+                    fn.x_descs[0],\n+                    fn.w_desc,\n+                    ctypes.c_void_p(weight_buf.data_ptr()),\n+                    linear_id,\n+                    lin_layer_mat_desc,\n+                    ctypes.byref(matrix_pointer)))\n+\n+                data_type = ctypes.c_int()\n+                format = ctypes.c_int()\n+                nb_dims = ctypes.c_int()\n+                min_dim = 3\n+                filter_dim_a = torch.IntTensor(min_dim)\n+                check_error(cudnn.lib.cudnnGetFilterNdDescriptor(\n+                    lin_layer_mat_desc,\n+                    min_dim,\n+                    ctypes.byref(data_type),\n+                    ctypes.byref(format),\n+                    ctypes.byref(nb_dims),\n+                    ctypes.c_void_p(filter_dim_a.data_ptr())))\n+\n+                filter_dim_a.resize_(nb_dims.value)\n+                elem_size = cudnn._sizeofmap[fn.datatype]\n+                offset_bytes = (matrix_pointer.value - weight_buf.data_ptr())\n+                assert(offset_bytes % elem_size == 0)\n+                offset = offset_bytes // elem_size\n+\n+                # for all the RNN types provided by CUDNN, all the ih weights\n+                # are the same size and are allocated in a contiguous chunk\n+                # (same for the hh weights, and the ih and hh biases).\n+                # Since we're storing all the weights in a single tensor anyway,\n+                # might as well merge the CUDNN ones into a single tensor as well\n+                if linear_id == 0 or linear_id == num_linear_layers / 2:\n+                    assert(filter_dim_a.prod() == filter_dim_a[0])\n+                    param = fn.weight_buf.new().set_(\n+                        weight_buf.storage(), offset,\n+                        filter_dim_a[0] * num_linear_layers / 2, filter_dim_a[2])\n+                    layer_params.append(param)\n+                else:\n+                    assert(cur_offset == offset)\n+\n+                cur_offset = offset + filter_dim_a[0]\n+\n+\n+        params.append(layer_params)\n+\n+    return params\n+\n+\n+def _copyParams(params_from, params_to):\n+    for layer_params_from, layer_params_to in zip(params_from, params_to):\n+        for param_from, param_to in zip(layer_params_from, layer_params_to):\n+            assert(param_from.type() == param_to.type())\n+            param_to.copy_(param_from)\n+\n+\n+def forward(fn, input, hx, weight, output, hy):\n+    with torch.cuda.device_of(input):\n+        lib = cudnn.lib\n+        handle = cudnn.get_handle()\n+        fn.datatype = cudnn._typemap[input.type()]\n+\n+        if fn.mode == cudnn.CUDNN_LSTM:\n+            hx, cx = hx\n+            hy, cy = hy\n+        else:\n+            cx, cy = None, None\n+\n+        if fn.batch_first:\n+            input = input.transpose(0, 1)\n+\n+        if input.dim() != 3:\n+            raise Exception(\n+                'input must have 3 dimensions: seq_length, mini_batch, input_size')\n+        if fn.input_size != input.size(2):\n+            raise Exception('input.size(2) must be equal to input_size provided')\n+        if fn.dropout != 0 and cudnn.lib.version < 5103:\n+            raise Exception('dropout supported only in cudnn v5.1 and above')\n+\n+        fn.seq_length, fn.mini_batch, fn.input_size = input.size()\n+        hidden_size = _hiddenSize(fn)\n+        output_size = _outputSize(fn)\n+        x = input.contiguous()\n+        output.resize_(*output_size)\n+        hy.resize_(*hidden_size).zero_()\n+        if cy:\n+            cy.resize_(*hidden_size).zero_()\n+        y = output\n+\n+        # init descriptors\n+        fn.dropout_desc = initDropoutDescriptor(fn, handle)\n+        fn.rnn_desc     = initRNNDescriptor(fn)\n+        fn.x_descs      = cudnn.descriptor(x[0], fn.seq_length)\n+        fn.y_descs      = cudnn.descriptor(y[0], fn.seq_length)\n+        fn.hx_desc      = cudnn.descriptor(hx)\n+        fn.hy_desc      = cudnn.descriptor(hx)\n+        fn.cx_desc      = cudnn.descriptor(cx) if cx else None\n+        fn.cy_desc      = cudnn.descriptor(cx) if cx else None\n+\n+        # create the weight buffer and copy the weights into it\n+        num_weights = getNumWeights(\n+            handle, fn.rnn_desc, fn.x_descs[0], fn.datatype)\n+        fn.weight_buf = input.new(num_weights)\n+        fn.w_desc       = initWeightDescriptor(fn, fn.weight_buf)\n+        w = fn.weight_buf\n+        # this zero might not seem necessary, but it is in the case\n+        # where biases are disabled; then they won't be copied and must be zero'd.\n+        # Alternatively, _copyParams could be written more carefully.\n+        w.zero_()\n+        params = getParameters(fn, handle, w)\n+        _copyParams(weight, params)\n+\n+        if tuple(hx.size()) != hidden_size:\n+            raise Exception('Expected hx size {}, got {}'.format(", "path": "torch/backends/cudnn/rnn.py", "position": null, "original_position": 214, "commit_id": "b5d13296c65e4b3cd5aa9715cf58df0fc043454e", "original_commit_id": "ccb1f401ff482f1fb25251272656149899758d4a", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "body": "What went wrong is that you provided a hidden state of the wrong size, e.g.\n\n```\nrnn = RNN(input_size=5, hidden_size=10)\ninput_size = Tensor(1,5)\nhidden_size = Tensor(1,9) # oops\nrnn.forward(input_size, hidden_size)\n```\n\nI changed `hx` to `hidden`; I think it's clear enough.\n", "created_at": "2016-10-17T16:57:05Z", "updated_at": "2018-11-23T15:31:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/129#discussion_r83687086", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/129", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/83687086"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/129#discussion_r83687086"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/129"}}, "body_html": "<p>What went wrong is that you provided a hidden state of the wrong size, e.g.</p>\n<pre><code>rnn = RNN(input_size=5, hidden_size=10)\ninput_size = Tensor(1,5)\nhidden_size = Tensor(1,9) # oops\nrnn.forward(input_size, hidden_size)\n</code></pre>\n<p>I changed <code>hx</code> to <code>hidden</code>; I think it's clear enough.</p>", "body_text": "What went wrong is that you provided a hidden state of the wrong size, e.g.\nrnn = RNN(input_size=5, hidden_size=10)\ninput_size = Tensor(1,5)\nhidden_size = Tensor(1,9) # oops\nrnn.forward(input_size, hidden_size)\n\nI changed hx to hidden; I think it's clear enough.", "in_reply_to_id": 83599825}