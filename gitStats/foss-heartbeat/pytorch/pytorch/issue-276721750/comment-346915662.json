{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/346915662", "html_url": "https://github.com/pytorch/pytorch/pull/3866#issuecomment-346915662", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3866", "id": 346915662, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NjkxNTY2Mg==", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-25T03:19:21Z", "updated_at": "2017-11-25T03:19:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> this currently is failing in test_backward_closure, becuase I think this uncovered something the InterpreterAutogradFunction that appears to be due to Edge pruning semantics. Not sure what is wrong but I figured I'd put the code up here so you might know what is wrong.</p>\n<pre><code>======================================================================\nERROR: test_backward_closure (__main__.TestJit)\nCheck that autograd closures handle multiple stages correctly.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test/test_jit.py\", line 506, in test_backward_closure\n    grad_x.backward()\n  File \"/data/users/zdevito/pytorch/torch/autograd/variable.py\", line 128, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/data/users/zdevito/pytorch/torch/autograd/__init__.py\", line 98, in backward\n    variables, grad_variables, retain_graph)\nRuntimeError: Function 'N5torch3jit27InterpreterAutogradFunctionE' returned an invalid number of outputs - expected 0, but got 1\n</code></pre>\n<hr>", "body_text": "@apaszke this currently is failing in test_backward_closure, becuase I think this uncovered something the InterpreterAutogradFunction that appears to be due to Edge pruning semantics. Not sure what is wrong but I figured I'd put the code up here so you might know what is wrong.\n======================================================================\nERROR: test_backward_closure (__main__.TestJit)\nCheck that autograd closures handle multiple stages correctly.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test/test_jit.py\", line 506, in test_backward_closure\n    grad_x.backward()\n  File \"/data/users/zdevito/pytorch/torch/autograd/variable.py\", line 128, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/data/users/zdevito/pytorch/torch/autograd/__init__.py\", line 98, in backward\n    variables, grad_variables, retain_graph)\nRuntimeError: Function 'N5torch3jit27InterpreterAutogradFunctionE' returned an invalid number of outputs - expected 0, but got 1", "body": "@apaszke this currently is failing in test_backward_closure, becuase I think this uncovered something the InterpreterAutogradFunction that appears to be due to Edge pruning semantics. Not sure what is wrong but I figured I'd put the code up here so you might know what is wrong.\r\n\r\n```\r\n======================================================================\r\nERROR: test_backward_closure (__main__.TestJit)\r\nCheck that autograd closures handle multiple stages correctly.\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test/test_jit.py\", line 506, in test_backward_closure\r\n    grad_x.backward()\r\n  File \"/data/users/zdevito/pytorch/torch/autograd/variable.py\", line 128, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n  File \"/data/users/zdevito/pytorch/torch/autograd/__init__.py\", line 98, in backward\r\n    variables, grad_variables, retain_graph)\r\nRuntimeError: Function 'N5torch3jit27InterpreterAutogradFunctionE' returned an invalid number of outputs - expected 0, but got 1\r\n```\r\n\r\n----------------------------------------------------------------------"}