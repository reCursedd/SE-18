{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153693325", "pull_request_review_id": 79736320, "id": 153693325, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MzY5MzMyNQ==", "diff_hunk": "@@ -20,19 +20,75 @@ using operator_constructor = std::function<TensorOp(jit::Node*)>;\n \n namespace {\n \n-void pack_list(std::vector<Tensor> & outputs, Tensor v) { outputs.push_back(v); }\n-void pack_list(std::vector<Tensor> & outputs, Scalar v) { outputs.push_back(v.toTensor()); }\n-void pack_list(std::vector<Tensor> & outputs, const std::vector<Tensor> & t) {\n-  outputs.insert(outputs.end(), t.begin(), t.end());\n+// a temporary Tensor that does not alter the refcount of impl on\n+// acquisition or release, avoids any refcounting in dispatch functions\n+struct TensorTemporary {\n+  explicit TensorTemporary(at::Retainable * impl)\n+  : temp(static_cast<at::TensorImpl*>(impl), false /* do not retain*/) {}\n+  const at::Tensor & value() {\n+    return temp;\n+  }\n+  ~TensorTemporary() {\n+    // don't reduce the refcount on deletion\n+    temp.detach();\n+  }\n+private:\n+  at::Tensor temp;\n+};\n+\n+// same list of Tensors that does not alter the refcount on acquisition or\n+// release of the refcount temporaries, only used rarely (e.g. for cat)\n+struct TensorTemporaryList {\n+  explicit TensorTemporaryList(const list_of_retainable & ts) {\n+    tensors.reserve(ts.size());\n+    for(auto & t : ts) {\n+      tensors.push_back(at::Tensor(static_cast<at::TensorImpl*>(t), false /*do not retain*/));\n+    }\n+  }\n+  // TensorTemporaryList only exposes a TensorList,\n+  // not its underlying std::vector<at::Tensor>.\n+  // This ArrayRef has the desired semantics: if you get out an at::Tensor from it,\n+  // the refcount is bumped;\n+  // if you take a reference, it is only guaranteed to stay live as long as the ArrayRef is live,\n+  operator TensorList() const {\n+    return tensors;\n+  }\n+  ~TensorTemporaryList() {\n+    // we didnt retain the tensors when we created the list\n+    // so make sure we don't release them when we free it\n+    for(auto & t : tensors) {\n+      t.detach();\n+    }\n+  }\n+private:\n+  std::vector<at::Tensor> tensors;\n+};\n+\n+using list_of_retainable = std::vector<at::Retainable*>;\n+\n+// pack list takes the return values of aten functions and puts them into a\n+// refcounted list. Each pack_list variant takes a Tensor by value, ensuring\n+// it has a owning reference and then that reference is stolen ad added to the\n+// list_of_retainable output list.\n+// pack_list never operates on tensor temporaries.\n+void pack_list(list_of_retainable & outputs, Tensor v) { outputs.push_back(toRetainableSteal(std::move(v))); }", "path": "tools/jit/templates/aten_dispatch.cpp", "position": 59, "original_position": 59, "commit_id": "9ed71c792b2ea33bbc30a18bd9b0bc7cc7ea5c84", "original_commit_id": "0354127c52b21be07d61d7441a8babcc1c35d529", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "I tried using std::vectors of unique_ptrs for the register list and for outputs. It doesn't really work: for outputs, you add a whole useless loop during the destruction of the list to check for destructors that will never run. for the register list, it can't be a trivial vector<unique_ptr> list because it has to support a copy constructor. It can be a new container that uses a unique_ptr underneath, but that container is almost as long as the implementation of the current container anyway with little added benefit. Working around this stuff just doesn't seem worth the effort.", "created_at": "2017-11-29T04:50:12Z", "updated_at": "2018-11-23T15:36:56Z", "html_url": "https://github.com/pytorch/pytorch/pull/3866#discussion_r153693325", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3866", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153693325"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3866#discussion_r153693325"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3866"}}, "body_html": "<p>I tried using std::vectors of unique_ptrs for the register list and for outputs. It doesn't really work: for outputs, you add a whole useless loop during the destruction of the list to check for destructors that will never run. for the register list, it can't be a trivial vector&lt;unique_ptr&gt; list because it has to support a copy constructor. It can be a new container that uses a unique_ptr underneath, but that container is almost as long as the implementation of the current container anyway with little added benefit. Working around this stuff just doesn't seem worth the effort.</p>", "body_text": "I tried using std::vectors of unique_ptrs for the register list and for outputs. It doesn't really work: for outputs, you add a whole useless loop during the destruction of the list to check for destructors that will never run. for the register list, it can't be a trivial vector<unique_ptr> list because it has to support a copy constructor. It can be a new container that uses a unique_ptr underneath, but that container is almost as long as the implementation of the current container anyway with little added benefit. Working around this stuff just doesn't seem worth the effort.", "in_reply_to_id": 153648585}