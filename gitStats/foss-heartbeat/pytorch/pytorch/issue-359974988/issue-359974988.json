{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11645", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11645/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11645/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11645/events", "html_url": "https://github.com/pytorch/pytorch/issues/11645", "id": 359974988, "node_id": "MDU6SXNzdWUzNTk5NzQ5ODg=", "number": 11645, "title": "One GPU is more memory efficient than Multiple GPUs", "user": {"login": "PetrochukM", "id": 7424737, "node_id": "MDQ6VXNlcjc0MjQ3Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7424737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PetrochukM", "html_url": "https://github.com/PetrochukM", "followers_url": "https://api.github.com/users/PetrochukM/followers", "following_url": "https://api.github.com/users/PetrochukM/following{/other_user}", "gists_url": "https://api.github.com/users/PetrochukM/gists{/gist_id}", "starred_url": "https://api.github.com/users/PetrochukM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PetrochukM/subscriptions", "organizations_url": "https://api.github.com/users/PetrochukM/orgs", "repos_url": "https://api.github.com/users/PetrochukM/repos", "events_url": "https://api.github.com/users/PetrochukM/events{/privacy}", "received_events_url": "https://api.github.com/users/PetrochukM/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-13T16:38:37Z", "updated_at": "2018-09-14T01:25:58Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Multiple GPUs runs out of memory with <code>DataParallel</code> while one GPU handles the load.</p>\n<pre><code>Hidden Size: 7150\nInput Size: 1024\nSequence Length: 1024\nBatch Size: 64\n====================================================================================================\nOne GPU...\n====================================================================================================\nMultiple GPUs...\nabc.py:16: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n  output, hidden_state = self.rnn(input_[i].unsqueeze(0))\nTraceback (most recent call last):\n  File \"abc.py\", line 50, in &lt;module&gt;\n    module=model, inputs=input_, dim=1, output_device=device.index)[-1]\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in data_parallel\n    outputs = parallel_apply(replicas, inputs, module_kwargs, used_device_ids)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\n    raise output\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"abc.py\", line 16, in forward\n    output, hidden_state = self.rnn(input_[i].unsqueeze(0))\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 192, in forward\n    output, hidden = func(input, self.all_weights, hx, batch_sizes)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 324, in forward\n    return func(input, *fargs, **fkwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 288, in forward\n    dropout_ts)\nRuntimeError: CUDA error: out of memory\n</code></pre>\n<h2>Code example</h2>\n<p>This is a minimal code example of my actual model. I am unable to use multiple GPUs due to this issue.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">args</span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.rnn <span class=\"pl-k\">=</span> nn.LSTM(<span class=\"pl-k\">*</span>args)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_</span>):\n        hidden_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n        outputs <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(input_.shape[<span class=\"pl-c1\">0</span>]):\n            output, hidden_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.rnn(input_[i].unsqueeze(<span class=\"pl-c1\">0</span>))\n            outputs.append(output)\n        <span class=\"pl-k\">return</span> outputs\n\n\nhidden_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">7150</span>\ninput_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span>\nsequence_length <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\nmodel <span class=\"pl-k\">=</span> Model(input_size, hidden_size)\ninput_ <span class=\"pl-k\">=</span> torch.FloatTensor(sequence_length, batch_size, input_size).uniform_(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>)\n\ndevice <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\nmodel <span class=\"pl-k\">=</span> model.to(device)\ninput_ <span class=\"pl-k\">=</span> input_.to(device)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Hidden Size:<span class=\"pl-pds\">'</span></span>, hidden_size)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Input Size:<span class=\"pl-pds\">'</span></span>, input_size)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sequence Length:<span class=\"pl-pds\">'</span></span>, sequence_length)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Batch Size:<span class=\"pl-pds\">'</span></span>, batch_size)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>=<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">100</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> One GPU</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>One GPU...<span class=\"pl-pds\">'</span></span>)\noutput <span class=\"pl-k\">=</span> model(input_)[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\nmodel.zero_grad()\noutput.sum().backward()\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>=<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">100</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Multiple GPUs</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Multiple GPUs...<span class=\"pl-pds\">'</span></span>)\noutput <span class=\"pl-k\">=</span> torch.nn.parallel.data_parallel(\n    <span class=\"pl-v\">module</span><span class=\"pl-k\">=</span>model, <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>input_, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">output_device</span><span class=\"pl-k\">=</span>device.index)[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\nmodel.zero_grad()\noutput.sum().backward()</pre></div>\n<h2>System Info</h2>\n<pre><code>Collecting environment information...\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: Tesla P100-PCIE-16GB\nGPU 1: Tesla P100-PCIE-16GB\nGPU 2: Tesla P100-PCIE-16GB\nGPU 3: Tesla P100-PCIE-16GB\n\nNvidia driver version: 390.30\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] pytorch-nlp (0.3.5)\n[pip3] torch (0.4.0)\n[conda] Could not collect\n</code></pre>", "body_text": "Issue description\nMultiple GPUs runs out of memory with DataParallel while one GPU handles the load.\nHidden Size: 7150\nInput Size: 1024\nSequence Length: 1024\nBatch Size: 64\n====================================================================================================\nOne GPU...\n====================================================================================================\nMultiple GPUs...\nabc.py:16: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n  output, hidden_state = self.rnn(input_[i].unsqueeze(0))\nTraceback (most recent call last):\n  File \"abc.py\", line 50, in <module>\n    module=model, inputs=input_, dim=1, output_device=device.index)[-1]\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in data_parallel\n    outputs = parallel_apply(replicas, inputs, module_kwargs, used_device_ids)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\n    raise output\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"abc.py\", line 16, in forward\n    output, hidden_state = self.rnn(input_[i].unsqueeze(0))\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 192, in forward\n    output, hidden = func(input, self.all_weights, hx, batch_sizes)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 324, in forward\n    return func(input, *fargs, **fkwargs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 288, in forward\n    dropout_ts)\nRuntimeError: CUDA error: out of memory\n\nCode example\nThis is a minimal code example of my actual model. I am unable to use multiple GPUs due to this issue.\nimport torch\n\nfrom torch import nn\n\n\nclass Model(nn.Module):\n\n    def __init__(self, *args):\n        super().__init__()\n        self.rnn = nn.LSTM(*args)\n\n    def forward(self, input_):\n        hidden_state = None\n        outputs = []\n        for i in range(input_.shape[0]):\n            output, hidden_state = self.rnn(input_[i].unsqueeze(0))\n            outputs.append(output)\n        return outputs\n\n\nhidden_size = 7150\ninput_size = 1024\nsequence_length = 1024\nbatch_size = 64\nmodel = Model(input_size, hidden_size)\ninput_ = torch.FloatTensor(sequence_length, batch_size, input_size).uniform_(0, 1)\n\ndevice = torch.device('cuda')\nmodel = model.to(device)\ninput_ = input_.to(device)\n\nprint('Hidden Size:', hidden_size)\nprint('Input Size:', input_size)\nprint('Sequence Length:', sequence_length)\nprint('Batch Size:', batch_size)\n\nprint('=' * 100)\n\n# One GPU\nprint('One GPU...')\noutput = model(input_)[-1]\nmodel.zero_grad()\noutput.sum().backward()\n\nprint('=' * 100)\n\n# Multiple GPUs\nprint('Multiple GPUs...')\noutput = torch.nn.parallel.data_parallel(\n    module=model, inputs=input_, dim=1, output_device=device.index)[-1]\nmodel.zero_grad()\noutput.sum().backward()\nSystem Info\nCollecting environment information...\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: Tesla P100-PCIE-16GB\nGPU 1: Tesla P100-PCIE-16GB\nGPU 2: Tesla P100-PCIE-16GB\nGPU 3: Tesla P100-PCIE-16GB\n\nNvidia driver version: 390.30\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] pytorch-nlp (0.3.5)\n[pip3] torch (0.4.0)\n[conda] Could not collect", "body": "## Issue description\r\n\r\nMultiple GPUs runs out of memory with ``DataParallel`` while one GPU handles the load. \r\n\r\n```\r\nHidden Size: 7150\r\nInput Size: 1024\r\nSequence Length: 1024\r\nBatch Size: 64\r\n====================================================================================================\r\nOne GPU...\r\n====================================================================================================\r\nMultiple GPUs...\r\nabc.py:16: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\r\n  output, hidden_state = self.rnn(input_[i].unsqueeze(0))\r\nTraceback (most recent call last):\r\n  File \"abc.py\", line 50, in <module>\r\n    module=model, inputs=input_, dim=1, output_device=device.index)[-1]\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in data_parallel\r\n    outputs = parallel_apply(replicas, inputs, module_kwargs, used_device_ids)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\r\n    raise output\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\r\n    output = module(*input, **kwargs)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"abc.py\", line 16, in forward\r\n    output, hidden_state = self.rnn(input_[i].unsqueeze(0))\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py\", line 192, in forward\r\n    output, hidden = func(input, self.all_weights, hx, batch_sizes)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 324, in forward\r\n    return func(input, *fargs, **fkwargs)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\", line 288, in forward\r\n    dropout_ts)\r\nRuntimeError: CUDA error: out of memory\r\n```\r\n\r\n## Code example\r\n\r\nThis is a minimal code example of my actual model. I am unable to use multiple GPUs due to this issue.\r\n\r\n```python\r\nimport torch\r\n\r\nfrom torch import nn\r\n\r\n\r\nclass Model(nn.Module):\r\n\r\n    def __init__(self, *args):\r\n        super().__init__()\r\n        self.rnn = nn.LSTM(*args)\r\n\r\n    def forward(self, input_):\r\n        hidden_state = None\r\n        outputs = []\r\n        for i in range(input_.shape[0]):\r\n            output, hidden_state = self.rnn(input_[i].unsqueeze(0))\r\n            outputs.append(output)\r\n        return outputs\r\n\r\n\r\nhidden_size = 7150\r\ninput_size = 1024\r\nsequence_length = 1024\r\nbatch_size = 64\r\nmodel = Model(input_size, hidden_size)\r\ninput_ = torch.FloatTensor(sequence_length, batch_size, input_size).uniform_(0, 1)\r\n\r\ndevice = torch.device('cuda')\r\nmodel = model.to(device)\r\ninput_ = input_.to(device)\r\n\r\nprint('Hidden Size:', hidden_size)\r\nprint('Input Size:', input_size)\r\nprint('Sequence Length:', sequence_length)\r\nprint('Batch Size:', batch_size)\r\n\r\nprint('=' * 100)\r\n\r\n# One GPU\r\nprint('One GPU...')\r\noutput = model(input_)[-1]\r\nmodel.zero_grad()\r\noutput.sum().backward()\r\n\r\nprint('=' * 100)\r\n\r\n# Multiple GPUs\r\nprint('Multiple GPUs...')\r\noutput = torch.nn.parallel.data_parallel(\r\n    module=model, inputs=input_, dim=1, output_device=device.index)[-1]\r\nmodel.zero_grad()\r\noutput.sum().backward()\r\n```\r\n\r\n## System Info\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration:\r\nGPU 0: Tesla P100-PCIE-16GB\r\nGPU 1: Tesla P100-PCIE-16GB\r\nGPU 2: Tesla P100-PCIE-16GB\r\nGPU 3: Tesla P100-PCIE-16GB\r\n\r\nNvidia driver version: 390.30\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.3)\r\n[pip3] pytorch-nlp (0.3.5)\r\n[pip3] torch (0.4.0)\r\n[conda] Could not collect\r\n```"}