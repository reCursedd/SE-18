{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/107628413", "pull_request_review_id": 28610697, "id": 107628413, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNzYyODQxMw==", "diff_hunk": "@@ -738,6 +738,50 @@ def test_caching_pinned_memory_multi_gpu(self):\n         self.assertEqual(gpu_tensor1[0], 1)\n         self.assertEqual(gpu_tensor0[0], 2)\n \n+    def test_btrifact(self):\n+        a = torch.Tensor((((1.3722, -0.9020),\n+                           (1.8849, 1.9169)),\n+                          ((0.7187, -1.1695),\n+                           (-0.0139, 1.3572)),\n+                          ((-1.6181, 0.7148),\n+                           (1.3728, 0.1319)))).cuda()\n+        LU_data, pivots, info = a.btrifact()\n+        self.assertEqual(info.abs().sum(), 0)\n+        I_U = torch.triu(torch.ones(2, 2)).unsqueeze(0).expand(3, 2, 2).type_as(a).byte()\n+        I_L = 1 - I_U\n+        a_L = torch.zeros(a.size()).type_as(a)\n+        a_U = a_L.clone()\n+        a_L[torch.eye(2).unsqueeze(0).expand(3, 2, 2).type_as(a).byte()] = 1.0\n+        a_L[I_L] = LU_data[I_L]\n+        a_U[I_U] = LU_data[I_U]\n+\n+        P = torch.eye(2).unsqueeze(0).expand(3, 2, 2).type_as(a)\n+        for i in range(3):\n+            for j in range(2):\n+                k = pivots[i, j] - 1\n+                t = P[i, j, :].clone()\n+                P[i, j, :] = P[i, k, :]\n+                P[i, k, :] = t\n+\n+        a_ = torch.bmm(P, torch.bmm(a_L, a_U))\n+        self.assertEqual(a_, a)\n+\n+    def test_btrisolve(self):\n+        a = torch.Tensor((((1.3722, -0.9020),\n+                           (1.8849, 1.9169)),\n+                          ((0.7187, -1.1695),\n+                           (-0.0139, 1.3572)),\n+                          ((-1.6181, 0.7148),\n+                           (1.3728, 0.1319)))).cuda()\n+        b = torch.Tensor(((4.02, 6.19),\n+                          (-1.56, 4.00),\n+                          (9.81, -4.09))).cuda()\n+        LU_data, pivots, info = a.btrifact()\n+        self.assertEqual(info.abs().sum(), 0)", "path": "test/test_cuda.py", "position": null, "original_position": 43, "commit_id": "73dcc642f27c87cfd1e908b9bf2a7309c06bcf1b", "original_commit_id": "8bf70088b3ef04be06ca52a36e4bbda6a9d56cc2", "user": {"login": "bamos", "id": 707462, "node_id": "MDQ6VXNlcjcwNzQ2Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/707462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bamos", "html_url": "https://github.com/bamos", "followers_url": "https://api.github.com/users/bamos/followers", "following_url": "https://api.github.com/users/bamos/following{/other_user}", "gists_url": "https://api.github.com/users/bamos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bamos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bamos/subscriptions", "organizations_url": "https://api.github.com/users/bamos/orgs", "repos_url": "https://api.github.com/users/bamos/repos", "events_url": "https://api.github.com/users/bamos/events{/privacy}", "received_events_url": "https://api.github.com/users/bamos/received_events", "type": "User", "site_admin": false}, "body": "Yes, I think `btrifact` is slightly different than other Torch functions. The factorization can fail for some (but not necessarily all) of the examples in the minibatch. In our use of `btrifact` in `qpth`, we hit instability in some of the minibatch examples that causes them to not be LU-factorizable and returning `info` here provides a nice way of disabling them without failing the factorization for the entire minibatch.\r\n\r\nI do agree that it's non-standard in Torch to return an `info` like this and require users to manually check the values. What do you think about making it an optional parameter? If it's provided, it can be written to as it is now, and otherwise `btrifact` can throw an error. If you prefer this, is an optional parameter easy to handle in `cwrap` or should I privatize the C call and add a quick Python wrapper for this?", "created_at": "2017-03-23T10:04:39Z", "updated_at": "2018-11-23T15:32:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/903#discussion_r107628413", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/903", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/107628413"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/903#discussion_r107628413"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/903"}}, "body_html": "<p>Yes, I think <code>btrifact</code> is slightly different than other Torch functions. The factorization can fail for some (but not necessarily all) of the examples in the minibatch. In our use of <code>btrifact</code> in <code>qpth</code>, we hit instability in some of the minibatch examples that causes them to not be LU-factorizable and returning <code>info</code> here provides a nice way of disabling them without failing the factorization for the entire minibatch.</p>\n<p>I do agree that it's non-standard in Torch to return an <code>info</code> like this and require users to manually check the values. What do you think about making it an optional parameter? If it's provided, it can be written to as it is now, and otherwise <code>btrifact</code> can throw an error. If you prefer this, is an optional parameter easy to handle in <code>cwrap</code> or should I privatize the C call and add a quick Python wrapper for this?</p>", "body_text": "Yes, I think btrifact is slightly different than other Torch functions. The factorization can fail for some (but not necessarily all) of the examples in the minibatch. In our use of btrifact in qpth, we hit instability in some of the minibatch examples that causes them to not be LU-factorizable and returning info here provides a nice way of disabling them without failing the factorization for the entire minibatch.\nI do agree that it's non-standard in Torch to return an info like this and require users to manually check the values. What do you think about making it an optional parameter? If it's provided, it can be written to as it is now, and otherwise btrifact can throw an error. If you prefer this, is an optional parameter easy to handle in cwrap or should I privatize the C call and add a quick Python wrapper for this?", "in_reply_to_id": 107530948}