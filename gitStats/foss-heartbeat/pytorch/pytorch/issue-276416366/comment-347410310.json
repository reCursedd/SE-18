{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347410310", "html_url": "https://github.com/pytorch/pytorch/issues/3851#issuecomment-347410310", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3851", "id": 347410310, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzQxMDMxMA==", "user": {"login": "oneTaken", "id": 18045872, "node_id": "MDQ6VXNlcjE4MDQ1ODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/18045872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oneTaken", "html_url": "https://github.com/oneTaken", "followers_url": "https://api.github.com/users/oneTaken/followers", "following_url": "https://api.github.com/users/oneTaken/following{/other_user}", "gists_url": "https://api.github.com/users/oneTaken/gists{/gist_id}", "starred_url": "https://api.github.com/users/oneTaken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oneTaken/subscriptions", "organizations_url": "https://api.github.com/users/oneTaken/orgs", "repos_url": "https://api.github.com/users/oneTaken/repos", "events_url": "https://api.github.com/users/oneTaken/events{/privacy}", "received_events_url": "https://api.github.com/users/oneTaken/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-28T04:29:47Z", "updated_at": "2017-11-28T04:29:47Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a><br>\nTo better reproduce the error, I use the official code example of <a href=\"http://pytorch.org/docs/master/nn.html?highlight=rnn#recurrent-layers\" rel=\"nofollow\">torch.nn.RNN</a><br>\nThe origin runs well:</p>\n<pre><code>rnn = nn.RNN(10, 20, 2, batch_first=False)\ninput = Variable(torch.randn(5, 3, 10))\nh0 = Variable(torch.randn(2, 3, 20))\noutput, hn = rnn(input, h0)\noutput.size(), hn.size()\n</code></pre>\n<p>Due to use <code>embedding</code>, I have to make batch first.<br>\nAnd then , it raises error.</p>\n<pre><code>rnn = nn.RNN(10, 20, 2, batch_first=True)\ninput = Variable(torch.randn(5, 3, 10).transpose(0, 1))\nh0 = Variable(torch.randn(2, 3, 20).transpose(0, 1))\noutput, hn = rnn(input, h0)\noutput.size(), hn.size()\n</code></pre>\n<pre><code>RuntimeError: inconsistent tensor size, expected r_ [3 x 20], t [3 x 20] and src [2 x 20] to\n have the same number of elements, but got 60, 60 and 40 elements respectively at \n/opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:887\n</code></pre>", "body_text": "@zou3519\nTo better reproduce the error, I use the official code example of torch.nn.RNN\nThe origin runs well:\nrnn = nn.RNN(10, 20, 2, batch_first=False)\ninput = Variable(torch.randn(5, 3, 10))\nh0 = Variable(torch.randn(2, 3, 20))\noutput, hn = rnn(input, h0)\noutput.size(), hn.size()\n\nDue to use embedding, I have to make batch first.\nAnd then , it raises error.\nrnn = nn.RNN(10, 20, 2, batch_first=True)\ninput = Variable(torch.randn(5, 3, 10).transpose(0, 1))\nh0 = Variable(torch.randn(2, 3, 20).transpose(0, 1))\noutput, hn = rnn(input, h0)\noutput.size(), hn.size()\n\nRuntimeError: inconsistent tensor size, expected r_ [3 x 20], t [3 x 20] and src [2 x 20] to\n have the same number of elements, but got 60, 60 and 40 elements respectively at \n/opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:887", "body": "@zou3519 \r\nTo better reproduce the error, I use the official code example of [torch.nn.RNN](http://pytorch.org/docs/master/nn.html?highlight=rnn#recurrent-layers)\r\nThe origin runs well:\r\n```\r\nrnn = nn.RNN(10, 20, 2, batch_first=False)\r\ninput = Variable(torch.randn(5, 3, 10))\r\nh0 = Variable(torch.randn(2, 3, 20))\r\noutput, hn = rnn(input, h0)\r\noutput.size(), hn.size()\r\n```\r\nDue to use `embedding`, I have to make batch first.\r\nAnd then , it raises error.\r\n```\r\nrnn = nn.RNN(10, 20, 2, batch_first=True)\r\ninput = Variable(torch.randn(5, 3, 10).transpose(0, 1))\r\nh0 = Variable(torch.randn(2, 3, 20).transpose(0, 1))\r\noutput, hn = rnn(input, h0)\r\noutput.size(), hn.size()\r\n```\r\n\r\n```\r\nRuntimeError: inconsistent tensor size, expected r_ [3 x 20], t [3 x 20] and src [2 x 20] to\r\n have the same number of elements, but got 60, 60 and 40 elements respectively at \r\n/opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:887\r\n```"}