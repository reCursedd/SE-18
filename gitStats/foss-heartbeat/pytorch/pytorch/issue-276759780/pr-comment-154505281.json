{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/154505281", "pull_request_review_id": 80683412, "id": 154505281, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NDUwNTI4MQ==", "diff_hunk": "@@ -123,3 +124,126 @@ def pad_packed_sequence(sequence, batch_first=False, padding_value=0.0):\n     if batch_first:\n         output = output.transpose(0, 1)\n     return output, lengths\n+\n+\n+def pad_sequence(sequences, lengths, batch_first=False):\n+    r\"\"\"Pad a list of variable length Variables with zero\n+\n+    The ``pad_sequence`` pads the list of Variables on zeroth dimension and\n+    stack all the sequences on zeroth dimension. For example, if the input is\n+    list of sequences with size `` Lx*`` and if batch_first is False, the\n+    output will be of size `` TxBx* `` and if batch_first is True,\n+    output will be of size ``BxTx* ``. The ``pad_sequence`` accepts list of\n+    sequences and its lengths which should be sorted in decreasing order\n+\n+    B is batch size - Number of elements in ``sequences``\n+    T is length longest sequence\n+    L is length of the sequence\n+    * is any number of trailing dimensions, including none\n+\n+    >>> from torch.nn.utils.rnn import pad_sequence\n+    >>> a = Variable(torch.ones(25, 300))\n+    >>> b = Variable(torch.ones(22, 300))\n+    >>> c = Variable(torch.ones(15, 300))\n+    >>> pad_sequence([a, b, c], [25, 22, 15]).size()\n+    torch.Size([25, 3, 300])\n+\n+    Note:\n+        This function returns a Variable of size TxBx* or BxTx* where T is the\n+            length of longest sequence (lengths[0])\n+        Function assumes trailing dimensions and type of all the Variables\n+            in sequences are same\n+\n+    Arguments:\n+        sequences (list[Variable]): list of variable length sequences.\n+        lengths (list[int]): list of sequences lengths of each batch element.\n+        batch_first (bool, optional): if True, the input is expected in Bx*x*\n+            format.\n+\n+    Returns:\n+        Variable of size ``T x B x * `` if batch_first = False\n+        Variable of size ``B x T x * `` otherwise\n+    \"\"\"\n+\n+    if len(lengths) != len(sequences):\n+        raise ValueError(\"number of elements in lengths and sequences didn't match\")\n+\n+    # assuming trailing dimensions and type of all the Variables\n+    # in sequences are same and fetching those from sequences[0]\n+    max_len = lengths[0]\n+    trailing_dims = list(sequences[0].size())[1:]\n+    prev_l = max_len\n+    if batch_first:\n+        out_dims = [len(sequences), max_len] + trailing_dims\n+        out_variable = Variable(sequences[0].data.new(*out_dims).zero_())\n+        for i, variable, length in zip(range(len(lengths)), sequences, lengths):\n+            # temperory sort check, can be removed when we handle sorting internally\n+            if prev_l < length:\n+                    raise ValueError(\"lengths array has to be sorted in decreasing order\")\n+            prev_l = length\n+            if length < max_len:\n+                prev_l = length\n+                padding_dims = [lengths[0] - length] + trailing_dims\n+                filler = Variable(variable.data.new(*padding_dims).zero_())\n+                out_variable[i] = torch.cat((variable, filler))\n+            else:\n+                out_variable[i] = variable\n+    else:\n+        # repeating the same logic but with T as first dimension", "path": "torch/nn/utils/rnn.py", "position": null, "original_position": 75, "commit_id": "7bdd58e4ab2ef58e72c2d1b5fa62f3dc0f511cf6", "original_commit_id": "91291f56d4006c7dcdc9de4c57ac9ac643ec2fdb", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "`select` does not perform a copy, but returns an object that shares the same storage. But maybe using `select` might become cumbersome.\r\nIf it is easier, you could instead index with tuples (which was used internally in an old version of `select`).\r\nSomething like\r\n```python\r\na = Variable(torch.rand(2, 3))\r\nindex = (i, ) if batch_first else (slice(None), i)\r\na[index] = ...\r\n```", "created_at": "2017-12-02T20:00:45Z", "updated_at": "2018-11-23T15:37:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/3875#discussion_r154505281", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3875", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/154505281"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3875#discussion_r154505281"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3875"}}, "body_html": "<p><code>select</code> does not perform a copy, but returns an object that shares the same storage. But maybe using <code>select</code> might become cumbersome.<br>\nIf it is easier, you could instead index with tuples (which was used internally in an old version of <code>select</code>).<br>\nSomething like</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> Variable(torch.rand(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>))\nindex <span class=\"pl-k\">=</span> (i, ) <span class=\"pl-k\">if</span> batch_first <span class=\"pl-k\">else</span> (<span class=\"pl-c1\">slice</span>(<span class=\"pl-c1\">None</span>), i)\na[index] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">...</span></pre></div>", "body_text": "select does not perform a copy, but returns an object that shares the same storage. But maybe using select might become cumbersome.\nIf it is easier, you could instead index with tuples (which was used internally in an old version of select).\nSomething like\na = Variable(torch.rand(2, 3))\nindex = (i, ) if batch_first else (slice(None), i)\na[index] = ...", "in_reply_to_id": 154501241}