{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/417927601", "html_url": "https://github.com/pytorch/pytorch/issues/11184#issuecomment-417927601", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11184", "id": 417927601, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzkyNzYwMQ==", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-02T12:32:08Z", "updated_at": "2018-09-02T12:32:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Seems like it, because it works with NumPy's <code>float32</code>.</p>\n<pre><code>&gt;&gt;&gt; np.float32(1.001e10)\n10010000000.0\n</code></pre>\n<p>I discovered weirder behavior:</p>\n<pre><code>&gt;&gt;&gt; torch.tensor(10000000000.)\ntensor(10000000000.)\n&gt;&gt;&gt; torch.tensor(10000000001.)\ntensor(10000000000.)\n&gt;&gt;&gt; torch.tensor(10000000010.)\ntensor(10000000000.)\n&gt;&gt;&gt; torch.tensor(10000000003.) - 100\ntensor(10000000000.)\n</code></pre>", "body_text": "Seems like it, because it works with NumPy's float32.\n>>> np.float32(1.001e10)\n10010000000.0\n\nI discovered weirder behavior:\n>>> torch.tensor(10000000000.)\ntensor(10000000000.)\n>>> torch.tensor(10000000001.)\ntensor(10000000000.)\n>>> torch.tensor(10000000010.)\ntensor(10000000000.)\n>>> torch.tensor(10000000003.) - 100\ntensor(10000000000.)", "body": "Seems like it, because it works with NumPy's `float32`.\r\n```\r\n>>> np.float32(1.001e10)\r\n10010000000.0\r\n```\r\n\r\nI discovered weirder behavior:\r\n```\r\n>>> torch.tensor(10000000000.)\r\ntensor(10000000000.)\r\n>>> torch.tensor(10000000001.)\r\ntensor(10000000000.)\r\n>>> torch.tensor(10000000010.)\r\ntensor(10000000000.)\r\n>>> torch.tensor(10000000003.) - 100\r\ntensor(10000000000.)\r\n```"}