{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/174654546", "pull_request_review_id": 104048714, "id": 174654546, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NDY1NDU0Ng==", "diff_hunk": "@@ -0,0 +1,41 @@\n+from torch.distributions import constraints\n+from torch.distributions.transforms import InvertableBoltzmannTransform\n+from torch.distributions.normal import Normal\n+from torch.distributions.transformed_distribution import TransformedDistribution\n+\n+\n+class LogitNormal(TransformedDistribution):\n+    r\"\"\"\n+    Creates a logit-normal distribution parameterized by\n+    `mean` and `std` where::\n+\n+        X ~ LogitNormal(loc, scale)\n+        Y = log(X / (1 - X)) ~ Normal(loc, scale)\n+\n+    Example::\n+\n+        >>> m = LogitNormal(torch.Tensor([0.0]), torch.Tensor([1.0]))\n+        >>> m.sample()  # logit-normal distributed with mean=0 and stddev=1\n+         0.4655\n+         0.5345\n+        [torch.FloatTensor of size (2,)]\n+\n+    Args:\n+        loc (float or Tensor): mean\n+        scale (float or Tensor): standard deviation\n+    \"\"\"\n+    params = {'loc': constraints.real, 'scale': constraints.positive}\n+    support = constraints.positive\n+    has_rsample = True\n+\n+    def __init__(self, loc, scale):\n+        super(LogitNormal, self).__init__(\n+            Normal(loc, scale), InvertableBoltzmannTransform())\n+\n+    @property\n+    def loc(self):\n+        return self.base_dist.loc\n+\n+    @property\n+    def scale(self):\n+        return self.base_dist.scale", "path": "torch/distributions/logit_normal.py", "position": null, "original_position": 41, "commit_id": "10377b822c64e8fc42893656f98451efaccc6559", "original_commit_id": "1ba3b1f9be364fd10c95cf6cedd689910a215cc8", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "body": "I'm happy either way, but I guess I don't see much value over the one-line version:\r\n```py\r\nTransformedDistribution(Normal(loc, scale), SigmoidTransform())\r\n```\r\n@alshedivat do you have specific need for the extra constraints and attributes provided by subclassing? Note that `kl_divergence(-,-)` should already come for free.", "created_at": "2018-03-15T01:14:00Z", "updated_at": "2018-11-23T15:40:45Z", "html_url": "https://github.com/pytorch/pytorch/pull/5547#discussion_r174654546", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5547", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/174654546"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5547#discussion_r174654546"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5547"}}, "body_html": "<p>I'm happy either way, but I guess I don't see much value over the one-line version:</p>\n<div class=\"highlight highlight-source-python\"><pre>TransformedDistribution(Normal(loc, scale), SigmoidTransform())</pre></div>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2126561\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alshedivat\">@alshedivat</a> do you have specific need for the extra constraints and attributes provided by subclassing? Note that <code>kl_divergence(-,-)</code> should already come for free.</p>", "body_text": "I'm happy either way, but I guess I don't see much value over the one-line version:\nTransformedDistribution(Normal(loc, scale), SigmoidTransform())\n@alshedivat do you have specific need for the extra constraints and attributes provided by subclassing? Note that kl_divergence(-,-) should already come for free.", "in_reply_to_id": 172062171}