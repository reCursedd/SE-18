{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/235982624", "pull_request_review_id": 177979060, "id": 235982624, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNTk4MjYyNA==", "diff_hunk": "@@ -0,0 +1,366 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/NativeFunctions.h\"\n+#include \"ATen/WrapDimUtilsMulti.h\"\n+\n+#ifdef USE_FBGEMM\n+#include \"fbgemm/Fbgemm.h\"\n+#endif // USE_FBGEMM\n+\n+#include <array>\n+#include <cctype>\n+#include <cmath>\n+#include <cstddef>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+namespace at { namespace native {\n+\n+#ifdef USE_FBGEMM\n+namespace {\n+\n+void FindMinMax(const float *a, float* min, float* max, int len) {\n+  if (len <= 0) {\n+    *min = 0.0f;\n+    *max = 0.0f;\n+    return;\n+  }\n+\n+  float temp_min = *a, temp_max = *a;\n+  int i = 0;\n+\n+#ifdef __AVX__\n+  __m256 min_v = _mm256_set1_ps(*a), max_v = _mm256_set1_ps(*a);\n+  constexpr int VLEN = 8;\n+  if (len >= VLEN) {\n+    for ( ; i < len / VLEN * VLEN; i += VLEN) {\n+      min_v = _mm256_min_ps(min_v, _mm256_loadu_ps(a + i));\n+      max_v = _mm256_max_ps(max_v, _mm256_loadu_ps(a + i));\n+    }\n+\n+    float min_buf[VLEN], max_buf[VLEN];\n+    _mm256_storeu_ps(min_buf, min_v);\n+    _mm256_storeu_ps(max_buf, max_v);\n+    for (int j = 0; j < VLEN; ++j) {\n+      temp_min = std::min(temp_min, min_buf[j]);\n+      temp_max = std::max(temp_max, max_buf[j]);\n+    }\n+  }\n+#endif\n+\n+  for ( ; i < len; i++) {\n+    temp_min = std::min(temp_min, a[i]);\n+    temp_max = std::max(temp_max, a[i]);\n+  }\n+  *min = temp_min;\n+  *max = temp_max;\n+}\n+\n+struct TensorQuantizationParams {\n+  float scale;\n+  std::int32_t zero_point;\n+  int precision;\n+  float Min() const;\n+  float Max() const;\n+};\n+\n+TensorQuantizationParams ChooseQuantizationParams(", "path": "aten/src/ATen/native/QuantizedLinear.cpp", "position": 67, "original_position": 67, "commit_id": "b284c1280e5dbfad8b3f221aa72bf482c4cf0f99", "original_commit_id": "b284c1280e5dbfad8b3f221aa72bf482c4cf0f99", "user": {"login": "harouwu", "id": 5057263, "node_id": "MDQ6VXNlcjUwNTcyNjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5057263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harouwu", "html_url": "https://github.com/harouwu", "followers_url": "https://api.github.com/users/harouwu/followers", "following_url": "https://api.github.com/users/harouwu/following{/other_user}", "gists_url": "https://api.github.com/users/harouwu/gists{/gist_id}", "starred_url": "https://api.github.com/users/harouwu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harouwu/subscriptions", "organizations_url": "https://api.github.com/users/harouwu/orgs", "repos_url": "https://api.github.com/users/harouwu/repos", "events_url": "https://api.github.com/users/harouwu/events{/privacy}", "received_events_url": "https://api.github.com/users/harouwu/received_events", "type": "User", "site_admin": false}, "body": "Same for ChooseQuantizationParams. QNNPACK follows a different name. We might need to wrap a quant param choosing function with ifdef macro", "created_at": "2018-11-23T16:09:36Z", "updated_at": "2018-11-23T16:24:36Z", "html_url": "https://github.com/pytorch/pytorch/pull/13777#discussion_r235982624", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13777", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/235982624"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13777#discussion_r235982624"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13777"}}, "body_html": "<p>Same for ChooseQuantizationParams. QNNPACK follows a different name. We might need to wrap a quant param choosing function with ifdef macro</p>", "body_text": "Same for ChooseQuantizationParams. QNNPACK follows a different name. We might need to wrap a quant param choosing function with ifdef macro"}