{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232336779", "pull_request_review_id": 173518740, "id": 232336779, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMjMzNjc3OQ==", "diff_hunk": "@@ -23,6 +25,127 @@ Tensor linear(const Tensor& input, const Tensor& weight, const Tensor& bias) {\n   return output;\n }\n \n+namespace {\n+\n+void FindMinMax(const float *a, float* min, float* max, int len) {\n+  if (len <= 0) {\n+    *min = 0.0f;\n+    *max = 0.0f;\n+    return;\n+  }\n+\n+  float temp_min = *a, temp_max = *a;\n+  int i = 0;\n+\n+#ifdef __AVX__\n+  __m256 min_v = _mm256_set1_ps(*a), max_v = _mm256_set1_ps(*a);\n+  constexpr int VLEN = 8;\n+  if (len >= VLEN) {\n+    for ( ; i < len / VLEN * VLEN; i += VLEN) {\n+      min_v = _mm256_min_ps(min_v, _mm256_loadu_ps(a + i));\n+      max_v = _mm256_max_ps(max_v, _mm256_loadu_ps(a + i));\n+    }\n+\n+    float min_buf[VLEN], max_buf[VLEN];\n+    _mm256_storeu_ps(min_buf, min_v);\n+    _mm256_storeu_ps(max_buf, max_v);\n+    for (int j = 0; j < VLEN; ++j) {\n+      temp_min = std::min(temp_min, min_buf[j]);\n+      temp_max = std::max(temp_max, max_buf[j]);\n+    }\n+  }\n+#endif\n+\n+  for ( ; i < len; i++) {\n+    temp_min = std::min(temp_min, a[i]);\n+    temp_max = std::max(temp_max, a[i]);\n+  }\n+  *min = temp_min;\n+  *max = temp_max;\n+}\n+\n+}  // namespace\n+\n+Tensor linear_int8_weight(const Tensor& input, const Tensor& weight, const Tensor& bias) {\n+  auto *input_ptr = input.data<float>();\n+  auto *weight_ptr = (int8_t*)weight.data<uint8_t>();\n+\n+  AT_ASSERT(input.dim() == 2);\n+  AT_ASSERT(weight.dim() == 2);\n+  auto M = input.size(0), K = input.size(1);\n+  AT_ASSERT(K == weight.size(1));\n+  auto N = weight.size(0);\n+  AT_ASSERT(bias.dim() == 1);\n+  AT_ASSERT(bias.size(0) == N);\n+\n+  float x_min, x_max;\n+  FindMinMax(input_ptr, &x_min, &x_max, input.numel());\n+\n+  // TODO\n+  int32_t Aint8_zero_point = 43;\n+  float Aint8_scale = 1.0f;\n+  int32_t Bint8_zero_point = 42;\n+  float Bint8_scale = 1.0f;\n+  float C_multiplier = 0.1234;\n+  int32_t C_zero_pt = 5;\n+\n+  using namespace fbgemm2;\n+\n+  std::vector<int32_t> row_offsets_, column_offsets_;\n+  column_offsets_.resize(M * N);\n+  row_offsets_.resize(\n+      PackAWithQuantRowOffset<uint8_t>::rowOffsetBufferSize());\n+  std::vector<uint8_t> X_pack_buf_;\n+  X_pack_buf_.resize(\n+      PackAWithQuantRowOffset<uint8_t>::packedBufferSize());\n+  PackAWithQuantRowOffset<uint8_t> packA(\n+      matrix_op_t::NoTranspose,\n+      M,\n+      K,\n+      input_ptr,\n+      K,\n+      X_pack_buf_.data(), // buffer for packed matrix\n+      Aint8_scale,\n+      Aint8_zero_point,\n+      1, // groups\n+      row_offsets_.data());\n+\n+  DoNothing<float, float> doNothingObj{};\n+  ReQuantizeForFloat<false /* FUSE_RELU*/> outputProcObj(\n+      doNothingObj,\n+      Aint8_scale,\n+      Bint8_scale,\n+      Aint8_zero_point,\n+      Bint8_zero_point,\n+      packA.getRowOffsetBuffer(),\n+      column_offsets_.data(),\n+      bias.data<float>()); // bias\n+\n+  fbgemm2::PackBMatrix<int8_t> packB(\n+    fbgemm2::matrix_op_t::Transpose,\n+    N,\n+    K,", "path": "aten/src/ATen/native/Linear.cpp", "position": null, "original_position": 112, "commit_id": "b284c1280e5dbfad8b3f221aa72bf482c4cf0f99", "original_commit_id": "fac73ad9bcb0128b6e7d00f143093b2cd5f4fd39", "user": {"login": "jspark1105", "id": 5545022, "node_id": "MDQ6VXNlcjU1NDUwMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5545022?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jspark1105", "html_url": "https://github.com/jspark1105", "followers_url": "https://api.github.com/users/jspark1105/followers", "following_url": "https://api.github.com/users/jspark1105/following{/other_user}", "gists_url": "https://api.github.com/users/jspark1105/gists{/gist_id}", "starred_url": "https://api.github.com/users/jspark1105/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jspark1105/subscriptions", "organizations_url": "https://api.github.com/users/jspark1105/orgs", "repos_url": "https://api.github.com/users/jspark1105/repos", "events_url": "https://api.github.com/users/jspark1105/events{/privacy}", "received_events_url": "https://api.github.com/users/jspark1105/received_events", "type": "User", "site_admin": false}, "body": "I think this should be K, N,", "created_at": "2018-11-09T17:45:15Z", "updated_at": "2018-11-23T15:54:35Z", "html_url": "https://github.com/pytorch/pytorch/pull/13777#discussion_r232336779", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13777", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232336779"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13777#discussion_r232336779"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13777"}}, "body_html": "<p>I think this should be K, N,</p>", "body_text": "I think this should be K, N,"}