{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11461", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11461/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11461/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11461/events", "html_url": "https://github.com/pytorch/pytorch/pull/11461", "id": 358722130, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE0Mzg5MzUz", "number": 11461, "title": "Split Type into TypeInternalInterface and Type.", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-10T17:35:01Z", "updated_at": "2018-11-23T15:51:02Z", "closed_at": "2018-09-11T17:34:23Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11461", "html_url": "https://github.com/pytorch/pytorch/pull/11461", "diff_url": "https://github.com/pytorch/pytorch/pull/11461.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11461.patch"}, "body_html": "<p>Previously, we had Type which was a catch all interface for all<br>\nfunctions and methods we could possibly want to do dynamic dispatch<br>\non.  However, we want to check in a non-autogenerated Tensor class<br>\nto ATen/core, and to do this, we must also check in a non-autogenerated<br>\nType class which we can do dispatch on.  In principle, we could<br>\nput the <em>full</em> Type interface in ATen/core, but this would be<br>\na bad developer experience, since any time you add a new free<br>\nfunction, you'd have to regenerate the checked in Type header.</p>\n<p>For a better dev experience, we split Type into a two parts,<br>\nType, which will be checked in (though not in this diff), and<br>\nTypeInternalInterface, which will NOT be checked in.  Type contains<br>\njust enough methods to let Tensor be defined, and leaves the<br>\nrest to TypeInternalInterface.</p>\n<p>Some complications:</p>\n<ul>\n<li>\n<p>We (very unfortunately) have overloaded virtual methods.  Because<br>\nof C++'s rules, we cannot move one overload without doing some<br>\nextra work to make sure that overload in a superclass and an<br>\noverload in a subclass resolve together.  I've chosen to resolve<br>\nthis problem simply by moving ALL overloads of a method which<br>\noccurs in Tensor to Type.</p>\n</li>\n<li>\n<p>There are some places where we take a type() object and call<br>\na method on it, which is not a Tensor base method.  I've eliminated<br>\nsome where possible, but in other cases calling the method on type<br>\nis the ONLY way to invoke it; in that case, I've just inserted<br>\na cast.  Further refactoring is necessary.</p>\n</li>\n</ul>\n<p>Signed-off-by: Edward Z. Yang <a href=\"mailto:ezyang@fb.com\">ezyang@fb.com</a></p>", "body_text": "Previously, we had Type which was a catch all interface for all\nfunctions and methods we could possibly want to do dynamic dispatch\non.  However, we want to check in a non-autogenerated Tensor class\nto ATen/core, and to do this, we must also check in a non-autogenerated\nType class which we can do dispatch on.  In principle, we could\nput the full Type interface in ATen/core, but this would be\na bad developer experience, since any time you add a new free\nfunction, you'd have to regenerate the checked in Type header.\nFor a better dev experience, we split Type into a two parts,\nType, which will be checked in (though not in this diff), and\nTypeInternalInterface, which will NOT be checked in.  Type contains\njust enough methods to let Tensor be defined, and leaves the\nrest to TypeInternalInterface.\nSome complications:\n\n\nWe (very unfortunately) have overloaded virtual methods.  Because\nof C++'s rules, we cannot move one overload without doing some\nextra work to make sure that overload in a superclass and an\noverload in a subclass resolve together.  I've chosen to resolve\nthis problem simply by moving ALL overloads of a method which\noccurs in Tensor to Type.\n\n\nThere are some places where we take a type() object and call\na method on it, which is not a Tensor base method.  I've eliminated\nsome where possible, but in other cases calling the method on type\nis the ONLY way to invoke it; in that case, I've just inserted\na cast.  Further refactoring is necessary.\n\n\nSigned-off-by: Edward Z. Yang ezyang@fb.com", "body": "Previously, we had Type which was a catch all interface for all\r\nfunctions and methods we could possibly want to do dynamic dispatch\r\non.  However, we want to check in a non-autogenerated Tensor class\r\nto ATen/core, and to do this, we must also check in a non-autogenerated\r\nType class which we can do dispatch on.  In principle, we could\r\nput the *full* Type interface in ATen/core, but this would be\r\na bad developer experience, since any time you add a new free\r\nfunction, you'd have to regenerate the checked in Type header.\r\n\r\nFor a better dev experience, we split Type into a two parts,\r\nType, which will be checked in (though not in this diff), and\r\nTypeInternalInterface, which will NOT be checked in.  Type contains\r\njust enough methods to let Tensor be defined, and leaves the\r\nrest to TypeInternalInterface.\r\n\r\nSome complications:\r\n\r\n- We (very unfortunately) have overloaded virtual methods.  Because\r\n  of C++'s rules, we cannot move one overload without doing some\r\n  extra work to make sure that overload in a superclass and an\r\n  overload in a subclass resolve together.  I've chosen to resolve\r\n  this problem simply by moving ALL overloads of a method which\r\n  occurs in Tensor to Type.\r\n\r\n- There are some places where we take a type() object and call\r\n  a method on it, which is not a Tensor base method.  I've eliminated\r\n  some where possible, but in other cases calling the method on type\r\n  is the ONLY way to invoke it; in that case, I've just inserted\r\n  a cast.  Further refactoring is necessary.\r\n\r\nSigned-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\n"}