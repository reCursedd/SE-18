{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/300637848", "html_url": "https://github.com/pytorch/pytorch/issues/1532#issuecomment-300637848", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1532", "id": 300637848, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDYzNzg0OA==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-10T23:10:12Z", "updated_at": "2017-05-10T23:11:22Z", "author_association": "MEMBER", "body_html": "<p>Here's a hotfix patch if you want to apply it:</p>\n<div class=\"highlight highlight-source-diff\"><pre>From 00721e4e212d0e1ac8e8f789d7f2fd317ec94edd Mon Sep 17 00:00:00 2001               \nFrom: Adam Paszke &lt;adam.paszke@gmail.com&gt;                                            \nDate: Wed, 10 May 2017 16:08:57 -0700                                                \nSubject: [PATCH] tmp                                                                 \n                                                                                     \n<span class=\"pl-md\">---                                                                                  </span>\n torch/nn/_functions/rnn.py | 4 ++--                                                 \n 1 file changed, 2 insertions(+), 2 deletions(-)                                     \n                                                                                     \n<span class=\"pl-c1\">diff --git a/torch/nn/_functions/rnn.py b/torch/nn/_functions/rnn.py                 </span>\nindex 6881a2d..3389a8e 100644                                                        \n<span class=\"pl-md\">--- a/torch/nn/_functions/rnn.py                                                     </span>\n<span class=\"pl-mi1\">+++ b/torch/nn/_functions/rnn.py                                                     </span>\n<span class=\"pl-mdr\">@@ -20,7 +20,7 @@</span> def RNNTanhCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):  \n                                                                                     \n                                                                                     \n def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                      \n<span class=\"pl-md\"><span class=\"pl-md\">-</span>    if input.is_cuda:                                                               </span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    if False and input.is_cuda:                                                     </span>\n         igates = F.linear(input, w_ih)                                              \n         hgates = F.linear(hidden[0], w_hh)                                          \n         state = fusedBackend.LSTMFused()                                            \n<span class=\"pl-mdr\">@@ -44,7 +44,7 @@</span> def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):     \n                                                                                     \n def GRUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                       \n                                                                                     \n<span class=\"pl-md\"><span class=\"pl-md\">-</span>    if input.is_cuda:                                                               </span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    if False and input.is_cuda:                                                     </span>\n         gi = F.linear(input, w_ih)                                                  \n         gh = F.linear(hidden, w_hh)                                                 \n         state = fusedBackend.GRUFused()                                             \n<span class=\"pl-md\"><span class=\"pl-md\">-</span>-                                                                                   </span>\n2.9.3                                                                                </pre></div>\n<p>I'll work out a better solution tomorrow.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22205833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/csarofeen\">@csarofeen</a> I think I'm going to add <code>clone()</code> calls for now, but it seems less efficient than filling the tensors directly in the kernel. Could you fix that please?</p>", "body_text": "Here's a hotfix patch if you want to apply it:\nFrom 00721e4e212d0e1ac8e8f789d7f2fd317ec94edd Mon Sep 17 00:00:00 2001               \nFrom: Adam Paszke <adam.paszke@gmail.com>                                            \nDate: Wed, 10 May 2017 16:08:57 -0700                                                \nSubject: [PATCH] tmp                                                                 \n                                                                                     \n---                                                                                  \n torch/nn/_functions/rnn.py | 4 ++--                                                 \n 1 file changed, 2 insertions(+), 2 deletions(-)                                     \n                                                                                     \ndiff --git a/torch/nn/_functions/rnn.py b/torch/nn/_functions/rnn.py                 \nindex 6881a2d..3389a8e 100644                                                        \n--- a/torch/nn/_functions/rnn.py                                                     \n+++ b/torch/nn/_functions/rnn.py                                                     \n@@ -20,7 +20,7 @@ def RNNTanhCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):  \n                                                                                     \n                                                                                     \n def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                      \n-    if input.is_cuda:                                                               \n+    if False and input.is_cuda:                                                     \n         igates = F.linear(input, w_ih)                                              \n         hgates = F.linear(hidden[0], w_hh)                                          \n         state = fusedBackend.LSTMFused()                                            \n@@ -44,7 +44,7 @@ def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):     \n                                                                                     \n def GRUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                       \n                                                                                     \n-    if input.is_cuda:                                                               \n+    if False and input.is_cuda:                                                     \n         gi = F.linear(input, w_ih)                                                  \n         gh = F.linear(hidden, w_hh)                                                 \n         state = fusedBackend.GRUFused()                                             \n--                                                                                   \n2.9.3                                                                                \nI'll work out a better solution tomorrow.\n@csarofeen I think I'm going to add clone() calls for now, but it seems less efficient than filling the tensors directly in the kernel. Could you fix that please?", "body": "Here's a hotfix patch if you want to apply it:\r\n```patch\r\nFrom 00721e4e212d0e1ac8e8f789d7f2fd317ec94edd Mon Sep 17 00:00:00 2001               \r\nFrom: Adam Paszke <adam.paszke@gmail.com>                                            \r\nDate: Wed, 10 May 2017 16:08:57 -0700                                                \r\nSubject: [PATCH] tmp                                                                 \r\n                                                                                     \r\n---                                                                                  \r\n torch/nn/_functions/rnn.py | 4 ++--                                                 \r\n 1 file changed, 2 insertions(+), 2 deletions(-)                                     \r\n                                                                                     \r\ndiff --git a/torch/nn/_functions/rnn.py b/torch/nn/_functions/rnn.py                 \r\nindex 6881a2d..3389a8e 100644                                                        \r\n--- a/torch/nn/_functions/rnn.py                                                     \r\n+++ b/torch/nn/_functions/rnn.py                                                     \r\n@@ -20,7 +20,7 @@ def RNNTanhCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):  \r\n                                                                                     \r\n                                                                                     \r\n def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                      \r\n-    if input.is_cuda:                                                               \r\n+    if False and input.is_cuda:                                                     \r\n         igates = F.linear(input, w_ih)                                              \r\n         hgates = F.linear(hidden[0], w_hh)                                          \r\n         state = fusedBackend.LSTMFused()                                            \r\n@@ -44,7 +44,7 @@ def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):     \r\n                                                                                     \r\n def GRUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):                       \r\n                                                                                     \r\n-    if input.is_cuda:                                                               \r\n+    if False and input.is_cuda:                                                     \r\n         gi = F.linear(input, w_ih)                                                  \r\n         gh = F.linear(hidden, w_hh)                                                 \r\n         state = fusedBackend.GRUFused()                                             \r\n--                                                                                   \r\n2.9.3                                                                                \r\n```\r\n\r\nI'll work out a better solution tomorrow.\r\n\r\n@csarofeen I think I'm going to add `clone()` calls for now, but it seems less efficient than filling the tensors directly in the kernel. Could you fix that please?"}