{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1791", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1791/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1791/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1791/events", "html_url": "https://github.com/pytorch/pytorch/issues/1791", "id": 235611598, "node_id": "MDU6SXNzdWUyMzU2MTE1OTg=", "number": 1791, "title": "Improve the performance of btriunpack", "user": {"login": "bamos", "id": 707462, "node_id": "MDQ6VXNlcjcwNzQ2Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/707462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bamos", "html_url": "https://github.com/bamos", "followers_url": "https://api.github.com/users/bamos/followers", "following_url": "https://api.github.com/users/bamos/following{/other_user}", "gists_url": "https://api.github.com/users/bamos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bamos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bamos/subscriptions", "organizations_url": "https://api.github.com/users/bamos/orgs", "repos_url": "https://api.github.com/users/bamos/repos", "events_url": "https://api.github.com/users/bamos/events{/privacy}", "received_events_url": "https://api.github.com/users/bamos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": {"login": "bamos", "id": 707462, "node_id": "MDQ6VXNlcjcwNzQ2Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/707462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bamos", "html_url": "https://github.com/bamos", "followers_url": "https://api.github.com/users/bamos/followers", "following_url": "https://api.github.com/users/bamos/following{/other_user}", "gists_url": "https://api.github.com/users/bamos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bamos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bamos/subscriptions", "organizations_url": "https://api.github.com/users/bamos/orgs", "repos_url": "https://api.github.com/users/bamos/repos", "events_url": "https://api.github.com/users/bamos/events{/privacy}", "received_events_url": "https://api.github.com/users/bamos/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bamos", "id": 707462, "node_id": "MDQ6VXNlcjcwNzQ2Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/707462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bamos", "html_url": "https://github.com/bamos", "followers_url": "https://api.github.com/users/bamos/followers", "following_url": "https://api.github.com/users/bamos/following{/other_user}", "gists_url": "https://api.github.com/users/bamos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bamos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bamos/subscriptions", "organizations_url": "https://api.github.com/users/bamos/orgs", "repos_url": "https://api.github.com/users/bamos/repos", "events_url": "https://api.github.com/users/bamos/events{/privacy}", "received_events_url": "https://api.github.com/users/bamos/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-06-13T16:22:59Z", "updated_at": "2017-10-09T21:47:41Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>The part of <code>btriunpack</code> that extract pivots has been causing some unexpected performance bottlenecks in qpth. Here's a newer version I've tried that uses gather/scatter operations across a batched vector instead of row interchanges on a batched matrix. I think it's a step towards a better method but the current form is just as slow. I want to do what the LAPACK LASWP function provides but with a batch so maybe we could use some knowledge from those implementations, like <a href=\"https://github.com/xianyi/OpenBLAS/blob/develop/lapack/laswp/generic/laswp_k_1.c\">this one in OpenBLAS</a>.</p>\n<h2>Slightly improved pivot matrix extraction but still slow version using gather/scatter</h2>\n<div class=\"highlight highlight-source-python\"><pre>Pidx <span class=\"pl-k\">=</span> <span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">LU_data</span>)(<span class=\"pl-c1\">range</span>(sz)).repeat(nBatch, <span class=\"pl-c1\">1</span>).long()\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(sz):\n    k <span class=\"pl-k\">=</span> <span class=\"pl-c1\">LU_pivots</span>[:, i] <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\n    t <span class=\"pl-k\">=</span> Pidx[:, i].clone()\n    Pidx[:, i] <span class=\"pl-k\">=</span> torch.gather(Pidx, <span class=\"pl-c1\">1</span>, k.unsqueeze(<span class=\"pl-c1\">1</span>).long())\n    Pidx.scatter_(<span class=\"pl-c1\">1</span>, k.unsqueeze(<span class=\"pl-c1\">1</span>).long(), t.unsqueeze(<span class=\"pl-c1\">1</span>))\n\nP <span class=\"pl-k\">=</span> <span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">LU_data</span>)(nBatch, sz, sz).zero_()\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(nBatch):\n    P[i].scatter_(<span class=\"pl-c1\">0</span>, Pidx[i].unsqueeze(<span class=\"pl-c1\">0</span>), <span class=\"pl-c1\">1.0</span>)</pre></div>", "body_text": "The part of btriunpack that extract pivots has been causing some unexpected performance bottlenecks in qpth. Here's a newer version I've tried that uses gather/scatter operations across a batched vector instead of row interchanges on a batched matrix. I think it's a step towards a better method but the current form is just as slow. I want to do what the LAPACK LASWP function provides but with a batch so maybe we could use some knowledge from those implementations, like this one in OpenBLAS.\nSlightly improved pivot matrix extraction but still slow version using gather/scatter\nPidx = type(LU_data)(range(sz)).repeat(nBatch, 1).long()\n\nfor i in range(sz):\n    k = LU_pivots[:, i] - 1\n    t = Pidx[:, i].clone()\n    Pidx[:, i] = torch.gather(Pidx, 1, k.unsqueeze(1).long())\n    Pidx.scatter_(1, k.unsqueeze(1).long(), t.unsqueeze(1))\n\nP = type(LU_data)(nBatch, sz, sz).zero_()\nfor i in range(nBatch):\n    P[i].scatter_(0, Pidx[i].unsqueeze(0), 1.0)", "body": "The part of `btriunpack` that extract pivots has been causing some unexpected performance bottlenecks in qpth. Here's a newer version I've tried that uses gather/scatter operations across a batched vector instead of row interchanges on a batched matrix. I think it's a step towards a better method but the current form is just as slow. I want to do what the LAPACK LASWP function provides but with a batch so maybe we could use some knowledge from those implementations, like [this one in OpenBLAS](https://github.com/xianyi/OpenBLAS/blob/develop/lapack/laswp/generic/laswp_k_1.c).\r\n\r\n## Slightly improved pivot matrix extraction but still slow version using gather/scatter\r\n\r\n```Python\r\nPidx = type(LU_data)(range(sz)).repeat(nBatch, 1).long()\r\n\r\nfor i in range(sz):\r\n    k = LU_pivots[:, i] - 1\r\n    t = Pidx[:, i].clone()\r\n    Pidx[:, i] = torch.gather(Pidx, 1, k.unsqueeze(1).long())\r\n    Pidx.scatter_(1, k.unsqueeze(1).long(), t.unsqueeze(1))\r\n\r\nP = type(LU_data)(nBatch, sz, sz).zero_()\r\nfor i in range(nBatch):\r\n    P[i].scatter_(0, Pidx[i].unsqueeze(0), 1.0)\r\n```"}