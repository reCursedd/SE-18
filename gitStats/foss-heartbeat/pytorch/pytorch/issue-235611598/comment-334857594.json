{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/334857594", "html_url": "https://github.com/pytorch/pytorch/issues/1791#issuecomment-334857594", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1791", "id": 334857594, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDg1NzU5NA==", "user": {"login": "IssamLaradji", "id": 3382128, "node_id": "MDQ6VXNlcjMzODIxMjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/3382128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IssamLaradji", "html_url": "https://github.com/IssamLaradji", "followers_url": "https://api.github.com/users/IssamLaradji/followers", "following_url": "https://api.github.com/users/IssamLaradji/following{/other_user}", "gists_url": "https://api.github.com/users/IssamLaradji/gists{/gist_id}", "starred_url": "https://api.github.com/users/IssamLaradji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IssamLaradji/subscriptions", "organizations_url": "https://api.github.com/users/IssamLaradji/orgs", "repos_url": "https://api.github.com/users/IssamLaradji/repos", "events_url": "https://api.github.com/users/IssamLaradji/events{/privacy}", "received_events_url": "https://api.github.com/users/IssamLaradji/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-06T20:09:17Z", "updated_at": "2017-10-06T20:09:17Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I was hoping to use batch <code>.triu</code>  for a different algorithm. I am implementing Variational Gaussian Processes and one of the requirements is obtaining <code>triu</code> for <code>n</code> matrices. I am currently using the following code where I am applying <code>.triu</code> to  <code>qVar</code> across its first axis (<code>qVar</code> is <code>n x m x m</code>):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">apply</span>(<span class=\"pl-smi\">func</span>, <span class=\"pl-smi\">M</span>):\n    tList <span class=\"pl-k\">=</span> [func(m) <span class=\"pl-k\">for</span> m <span class=\"pl-k\">in</span> torch.unbind(M, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)]\n    res <span class=\"pl-k\">=</span> torch.stack(tList, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    <span class=\"pl-k\">return</span> res \n\napply(torch.triu,  qVar)</pre></div>\n<p>but as <code>n</code> gets larger, this operation becomes a large bottleneck. Are there plans to have a generic batched function mode ?  In bayesian methods it is often necessary to apply batch functions such as <code>Inverse</code>, <code>cholesky</code>, <code>triu</code>, etc. Sorry for posting this here which is not completely relevant to <code>btriunpack</code>, I might have to open a new issue for this. Thanks!</p>", "body_text": "@apaszke I was hoping to use batch .triu  for a different algorithm. I am implementing Variational Gaussian Processes and one of the requirements is obtaining triu for n matrices. I am currently using the following code where I am applying .triu to  qVar across its first axis (qVar is n x m x m):\ndef apply(func, M):\n    tList = [func(m) for m in torch.unbind(M, dim=0)]\n    res = torch.stack(tList, dim=0)\n    return res \n\napply(torch.triu,  qVar)\nbut as n gets larger, this operation becomes a large bottleneck. Are there plans to have a generic batched function mode ?  In bayesian methods it is often necessary to apply batch functions such as Inverse, cholesky, triu, etc. Sorry for posting this here which is not completely relevant to btriunpack, I might have to open a new issue for this. Thanks!", "body": "@apaszke I was hoping to use batch `.triu`  for a different algorithm. I am implementing Variational Gaussian Processes and one of the requirements is obtaining `triu` for `n` matrices. I am currently using the following code where I am applying `.triu` to  `qVar` across its first axis (`qVar` is `n x m x m`):\r\n```python\r\ndef apply(func, M):\r\n    tList = [func(m) for m in torch.unbind(M, dim=0)]\r\n    res = torch.stack(tList, dim=0)\r\n    return res \r\n\r\napply(torch.triu,  qVar)\r\n```\r\nbut as `n` gets larger, this operation becomes a large bottleneck. Are there plans to have a generic batched function mode ?  In bayesian methods it is often necessary to apply batch functions such as `Inverse`, `cholesky`, `triu`, etc. Sorry for posting this here which is not completely relevant to `btriunpack`, I might have to open a new issue for this. Thanks!"}