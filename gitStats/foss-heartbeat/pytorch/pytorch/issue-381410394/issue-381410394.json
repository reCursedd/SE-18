{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14056", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14056/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14056/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14056/events", "html_url": "https://github.com/pytorch/pytorch/pull/14056", "id": 381410394, "node_id": "MDExOlB1bGxSZXF1ZXN0MjMxMzg5ODY0", "number": 14056, "title": "Fix CUDA_tensor_apply1 base case", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-16T01:36:10Z", "updated_at": "2018-11-16T17:46:17Z", "closed_at": "2018-11-16T05:34:38Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/14056", "html_url": "https://github.com/pytorch/pytorch/pull/14056", "diff_url": "https://github.com/pytorch/pytorch/pull/14056.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/14056.patch"}, "body_html": "<p>I got some build errors when modifying the <code>bernoulli_tensor_cuda_kernel</code> in my Generator refactor <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"373654981\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/13070\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/13070/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/13070\">#13070</a>. Turns out the functions signature for <code>CUDA_tensor_apply1</code> was a little wrong. This PR fixes it. Following is the code and error I was getting before this patch:</p>\n<p>Code:</p>\n<pre><code>template&lt;typename scalar_t, typename prob_t&gt;\nvoid bernoulli_tensor_cuda_kernel(\n    at::Tensor&amp; ret, const at::Tensor&amp; p,\n    std::pair&lt;uint64_t, uint64_t&gt; seeds) {\n  // The template argument `4` below indicates that we want to operate on four\n  // element at each time. See NOTE [ CUDA_tensor_applyN helpers ] for details.\n  at::cuda::CUDA_tensor_apply2&lt;scalar_t, prob_t, 4&gt;(\n      ret, p,\n      [seeds] __device__(scalar_t&amp; v1, const prob_t&amp; p1) {\n      at::cuda::Philox4_32_10 engine(\n                                seeds.first,\n                                blockIdx.x * blockDim.x + threadIdx.x,\n                                seeds.second);\n      auto x = at::cuda::standard_uniform_distribution(engine);\n      assert(0 &lt;= p1 &amp;&amp; p1 &lt;= 1);\n      v1 = static_cast&lt;scalar_t&gt;(x &lt;= p1);\n    }\n  );\n}\n</code></pre>\n<p>Error:</p>\n<pre><code>ov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/cuda/CUDAApplyUtils.cuh(236): error: no suitable conversion function from \"const lambda [](uint8_t &amp;)-&gt;void\" to \"int\" exists\nNov 15 23:43:03           detected during:\nNov 15 23:43:03             instantiation of \"void at::cuda::&lt;unnamed&gt;::ApplyOp1&lt;Op, scalar, IndexType, ADims, remaining_steps, Offsets...&gt;::apply(at::cuda::detail::TensorInfo&lt;scalar, IndexType&gt; &amp;, const Op &amp;, int, IndexType, Offsets...) [with Op=lambda [](uint8_t &amp;)-&gt;void, scalar=uint8_t, IndexType=unsigned int, ADims=1, remaining_steps=1, Offsets=&lt;&gt;]\" \nNov 15 23:43:03 (282): here\nNov 15 23:43:03             instantiation of \"void at::cuda::&lt;unnamed&gt;::kernelPointwiseApply1&lt;Op,scalar,IndexType,ADims,step&gt;(at::cuda::detail::TensorInfo&lt;scalar, IndexType&gt;, IndexType, Op) [with Op=lambda [](uint8_t &amp;)-&gt;void, scalar=uint8_t, IndexType=unsigned int, ADims=1, step=1]\" \nNov 15 23:43:03 (735): here\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1&lt;scalar,step,Op&gt;(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, step=1, Op=lambda [](uint8_t &amp;)-&gt;void]\" \nNov 15 23:43:03 (774): here\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1&lt;scalar,Op&gt;(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, Op=lambda [](uint8_t &amp;)-&gt;void]\" \nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(118): here\nNov 15 23:43:03             instantiation of \"void &lt;unnamed&gt;::bernoulli_scalar_cuda_kernel&lt;scalar_t&gt;(at::Tensor &amp;, double, std::pair&lt;uint64_t, uint64_t&gt;) [with scalar_t=uint8_t]\" \nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(227): here\nNov 15 23:43:03 \n</code></pre>", "body_text": "I got some build errors when modifying the bernoulli_tensor_cuda_kernel in my Generator refactor #13070. Turns out the functions signature for CUDA_tensor_apply1 was a little wrong. This PR fixes it. Following is the code and error I was getting before this patch:\nCode:\ntemplate<typename scalar_t, typename prob_t>\nvoid bernoulli_tensor_cuda_kernel(\n    at::Tensor& ret, const at::Tensor& p,\n    std::pair<uint64_t, uint64_t> seeds) {\n  // The template argument `4` below indicates that we want to operate on four\n  // element at each time. See NOTE [ CUDA_tensor_applyN helpers ] for details.\n  at::cuda::CUDA_tensor_apply2<scalar_t, prob_t, 4>(\n      ret, p,\n      [seeds] __device__(scalar_t& v1, const prob_t& p1) {\n      at::cuda::Philox4_32_10 engine(\n                                seeds.first,\n                                blockIdx.x * blockDim.x + threadIdx.x,\n                                seeds.second);\n      auto x = at::cuda::standard_uniform_distribution(engine);\n      assert(0 <= p1 && p1 <= 1);\n      v1 = static_cast<scalar_t>(x <= p1);\n    }\n  );\n}\n\nError:\nov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/cuda/CUDAApplyUtils.cuh(236): error: no suitable conversion function from \"const lambda [](uint8_t &)->void\" to \"int\" exists\nNov 15 23:43:03           detected during:\nNov 15 23:43:03             instantiation of \"void at::cuda::<unnamed>::ApplyOp1<Op, scalar, IndexType, ADims, remaining_steps, Offsets...>::apply(at::cuda::detail::TensorInfo<scalar, IndexType> &, const Op &, int, IndexType, Offsets...) [with Op=lambda [](uint8_t &)->void, scalar=uint8_t, IndexType=unsigned int, ADims=1, remaining_steps=1, Offsets=<>]\" \nNov 15 23:43:03 (282): here\nNov 15 23:43:03             instantiation of \"void at::cuda::<unnamed>::kernelPointwiseApply1<Op,scalar,IndexType,ADims,step>(at::cuda::detail::TensorInfo<scalar, IndexType>, IndexType, Op) [with Op=lambda [](uint8_t &)->void, scalar=uint8_t, IndexType=unsigned int, ADims=1, step=1]\" \nNov 15 23:43:03 (735): here\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1<scalar,step,Op>(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, step=1, Op=lambda [](uint8_t &)->void]\" \nNov 15 23:43:03 (774): here\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1<scalar,Op>(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, Op=lambda [](uint8_t &)->void]\" \nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(118): here\nNov 15 23:43:03             instantiation of \"void <unnamed>::bernoulli_scalar_cuda_kernel<scalar_t>(at::Tensor &, double, std::pair<uint64_t, uint64_t>) [with scalar_t=uint8_t]\" \nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(227): here\nNov 15 23:43:03", "body": "I got some build errors when modifying the `bernoulli_tensor_cuda_kernel` in my Generator refactor https://github.com/pytorch/pytorch/pull/13070. Turns out the functions signature for `CUDA_tensor_apply1` was a little wrong. This PR fixes it. Following is the code and error I was getting before this patch:\r\n\r\nCode:\r\n```\r\ntemplate<typename scalar_t, typename prob_t>\r\nvoid bernoulli_tensor_cuda_kernel(\r\n    at::Tensor& ret, const at::Tensor& p,\r\n    std::pair<uint64_t, uint64_t> seeds) {\r\n  // The template argument `4` below indicates that we want to operate on four\r\n  // element at each time. See NOTE [ CUDA_tensor_applyN helpers ] for details.\r\n  at::cuda::CUDA_tensor_apply2<scalar_t, prob_t, 4>(\r\n      ret, p,\r\n      [seeds] __device__(scalar_t& v1, const prob_t& p1) {\r\n      at::cuda::Philox4_32_10 engine(\r\n                                seeds.first,\r\n                                blockIdx.x * blockDim.x + threadIdx.x,\r\n                                seeds.second);\r\n      auto x = at::cuda::standard_uniform_distribution(engine);\r\n      assert(0 <= p1 && p1 <= 1);\r\n      v1 = static_cast<scalar_t>(x <= p1);\r\n    }\r\n  );\r\n}\r\n```\r\n\r\nError:\r\n```\r\nov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/cuda/CUDAApplyUtils.cuh(236): error: no suitable conversion function from \"const lambda [](uint8_t &)->void\" to \"int\" exists\r\nNov 15 23:43:03           detected during:\r\nNov 15 23:43:03             instantiation of \"void at::cuda::<unnamed>::ApplyOp1<Op, scalar, IndexType, ADims, remaining_steps, Offsets...>::apply(at::cuda::detail::TensorInfo<scalar, IndexType> &, const Op &, int, IndexType, Offsets...) [with Op=lambda [](uint8_t &)->void, scalar=uint8_t, IndexType=unsigned int, ADims=1, remaining_steps=1, Offsets=<>]\" \r\nNov 15 23:43:03 (282): here\r\nNov 15 23:43:03             instantiation of \"void at::cuda::<unnamed>::kernelPointwiseApply1<Op,scalar,IndexType,ADims,step>(at::cuda::detail::TensorInfo<scalar, IndexType>, IndexType, Op) [with Op=lambda [](uint8_t &)->void, scalar=uint8_t, IndexType=unsigned int, ADims=1, step=1]\" \r\nNov 15 23:43:03 (735): here\r\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1<scalar,step,Op>(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, step=1, Op=lambda [](uint8_t &)->void]\" \r\nNov 15 23:43:03 (774): here\r\nNov 15 23:43:03             instantiation of \"__nv_bool at::cuda::CUDA_tensor_apply1<scalar,Op>(at::Tensor, Op, at::cuda::TensorArgType) [with scalar=uint8_t, Op=lambda [](uint8_t &)->void]\" \r\nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(118): here\r\nNov 15 23:43:03             instantiation of \"void <unnamed>::bernoulli_scalar_cuda_kernel<scalar_t>(at::Tensor &, double, std::pair<uint64_t, uint64_t>) [with scalar_t=uint8_t]\" \r\nNov 15 23:43:03 /var/lib/jenkins/workspace/aten/src/ATen/native/cuda/Distributions.cu(227): here\r\nNov 15 23:43:03 \r\n```"}