{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153316079", "pull_request_review_id": 79303879, "id": 153316079, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MzMxNjA3OQ==", "diff_hunk": "@@ -397,16 +403,23 @@ def __missing__(self, key):\n def parse_cpu_trace(thread_records):\n     next_id = 0\n     start_record = None\n+    cuda_records = {}\n     functions = []\n     record_stack = []\n     string_table = StringTable()\n     # '__start_profile' is not guarenteed to be first, so we must find it here\n     for record in itertools.chain(*thread_records):\n         if record.name() == '__start_profile':\n             start_record = record\n-            break\n+        elif record.name() == '__cuda_start':\n+            cuda_records[record.device()] = record\n     assert start_record is not None\n \n+    # we don't know the correlation between CUDA/CPU time,\n+    # instead, we just make sure the corresponding cuda kernels are shifted\n+    # in time so they happen _after_ their CPU time, which is not\n+    # alway show they get recorded.\n+    max_shift = 0", "path": "torch/autograd/profiler.py", "position": null, "original_position": 97, "commit_id": "84c2e653ce154ea5b01797bed9dc4612266a6672", "original_commit_id": "ebf3f9336465b145e167dbf8419e5abe00583e64", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "The problem with `cuptiDeviceGetTimeStamp` is that there is no way I know of to turn a cudaEvent_t back into a (absolute) device timestamp. Knowing the correlation between cpu time and cuda device time doesn't help since I don't know the correlation between an event record and the GPU timestamp. Even the cuptiAPI doesn't seem to report the record time for an event, it only seems to record kernel start/stop times.", "created_at": "2017-11-27T20:39:08Z", "updated_at": "2018-11-23T15:36:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/3754#discussion_r153316079", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3754", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153316079"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3754#discussion_r153316079"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3754"}}, "body_html": "<p>The problem with <code>cuptiDeviceGetTimeStamp</code> is that there is no way I know of to turn a cudaEvent_t back into a (absolute) device timestamp. Knowing the correlation between cpu time and cuda device time doesn't help since I don't know the correlation between an event record and the GPU timestamp. Even the cuptiAPI doesn't seem to report the record time for an event, it only seems to record kernel start/stop times.</p>", "body_text": "The problem with cuptiDeviceGetTimeStamp is that there is no way I know of to turn a cudaEvent_t back into a (absolute) device timestamp. Knowing the correlation between cpu time and cuda device time doesn't help since I don't know the correlation between an event record and the GPU timestamp. Even the cuptiAPI doesn't seem to report the record time for an event, it only seems to record kernel start/stop times.", "in_reply_to_id": 151659740}