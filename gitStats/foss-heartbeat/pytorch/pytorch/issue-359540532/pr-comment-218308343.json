{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218308343", "pull_request_review_id": 156214750, "id": 218308343, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxODMwODM0Mw==", "diff_hunk": "@@ -106,6 +107,19 @@ static std::vector<Value*> gradientForNode(Node* node, ArrayRef<Value*> grad_val\n     } else if (node->matches(\"aten::relu(Tensor self) -> Tensor\")) {\n       return {grads.at(0) * (outputs.at(0) > at::Scalar(0)).type_as(outputs.at(0))};\n \n+    } else if (node->matches(\"aten::clamp(Tensor self, Scalar min, Scalar max) -> Tensor\")) {\n+      // we do two type_as as it's free (hopefully) and the \"*\" only works with float\n+      // the \"! (val > min)\" is chosen such that the gradient is 0 on the\n+      // boundary and the factor is 1 when the boundary is NaN\n+      // the ! is expressed as \"1-\" for lack of a \"not\" function and\n+      // the the fuser insisting on float\n+      // it would be prettier to return NaN as gradient for NaN,\n+      // but that is hard to reliably code here, so we have 0 as gradient\n+      // when the input is NaN (unless grads is NaN or infinite)\n+      return {grads.at(0)\n+\t      * (1-(inputs.at(0).isnan()).type_as(inputs.at(0)))", "path": "torch/csrc/jit/autodiff.cpp", "position": null, "original_position": 22, "commit_id": "30be1e7983687052b37e4261489878d50e223a3b", "original_commit_id": "be5b5e64f27227b11abaee3839c099869f656fc6", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "Personally, I think that proper NaN handling is a good feature and was about to fix it, but I'll take it out if the policy is not to treat NaN. (I do seem to recall from the forum that it caused quite bit of confusion that ReLU forward used to swallow NaN.)", "created_at": "2018-09-18T06:10:35Z", "updated_at": "2018-11-23T15:51:33Z", "html_url": "https://github.com/pytorch/pytorch/pull/11574#discussion_r218308343", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11574", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218308343"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11574#discussion_r218308343"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11574"}}, "body_html": "<p>Personally, I think that proper NaN handling is a good feature and was about to fix it, but I'll take it out if the policy is not to treat NaN. (I do seem to recall from the forum that it caused quite bit of confusion that ReLU forward used to swallow NaN.)</p>", "body_text": "Personally, I think that proper NaN handling is a good feature and was about to fix it, but I'll take it out if the policy is not to treat NaN. (I do seem to recall from the forum that it caused quite bit of confusion that ReLU forward used to swallow NaN.)", "in_reply_to_id": 218104538}