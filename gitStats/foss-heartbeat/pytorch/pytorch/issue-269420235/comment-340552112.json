{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/340552112", "html_url": "https://github.com/pytorch/pytorch/issues/3356#issuecomment-340552112", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3356", "id": 340552112, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDU1MjExMg==", "user": {"login": "ozancaglayan", "id": 330946, "node_id": "MDQ6VXNlcjMzMDk0Ng==", "avatar_url": "https://avatars0.githubusercontent.com/u/330946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ozancaglayan", "html_url": "https://github.com/ozancaglayan", "followers_url": "https://api.github.com/users/ozancaglayan/followers", "following_url": "https://api.github.com/users/ozancaglayan/following{/other_user}", "gists_url": "https://api.github.com/users/ozancaglayan/gists{/gist_id}", "starred_url": "https://api.github.com/users/ozancaglayan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ozancaglayan/subscriptions", "organizations_url": "https://api.github.com/users/ozancaglayan/orgs", "repos_url": "https://api.github.com/users/ozancaglayan/repos", "events_url": "https://api.github.com/users/ozancaglayan/events{/privacy}", "received_events_url": "https://api.github.com/users/ozancaglayan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-30T19:08:01Z", "updated_at": "2017-10-30T19:08:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think if the samplers were producing batch indices at once instead of sequentially, it would be much easier to implement some advanced iteration mechanisms. I would like to implement sorted batches w.r.t target sequence lengths for example and right now none of the provided building blocks suit me.</p>\n<p>The fact that the samplers are returning each index sequentially is also time-consuming when you slice a big numpy tensor and then merge it using the default or custom collate_fn although a numpy tensor is already sliceable with a set of indices directly.</p>", "body_text": "I think if the samplers were producing batch indices at once instead of sequentially, it would be much easier to implement some advanced iteration mechanisms. I would like to implement sorted batches w.r.t target sequence lengths for example and right now none of the provided building blocks suit me.\nThe fact that the samplers are returning each index sequentially is also time-consuming when you slice a big numpy tensor and then merge it using the default or custom collate_fn although a numpy tensor is already sliceable with a set of indices directly.", "body": "I think if the samplers were producing batch indices at once instead of sequentially, it would be much easier to implement some advanced iteration mechanisms. I would like to implement sorted batches w.r.t target sequence lengths for example and right now none of the provided building blocks suit me.\r\n\r\nThe fact that the samplers are returning each index sequentially is also time-consuming when you slice a big numpy tensor and then merge it using the default or custom collate_fn although a numpy tensor is already sliceable with a set of indices directly."}