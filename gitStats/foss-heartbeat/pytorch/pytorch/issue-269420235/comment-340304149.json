{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/340304149", "html_url": "https://github.com/pytorch/pytorch/issues/3356#issuecomment-340304149", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3356", "id": 340304149, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDMwNDE0OQ==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-29T21:55:12Z", "updated_at": "2017-10-29T21:55:12Z", "author_association": "MEMBER", "body_html": "<p>Ad 1. Dynamic sampling is well supported and there's no reason to have to re-assign the <code>.sampler</code> attribute. Creating <code>DataLoader</code>s is very cheap (only instantiating their iterators is more expensive). Your sampler can return itself as an iterator, and you can make it a mutable object. Consider this example:</p>\n<div class=\"highlight highlight-source-python\"><pre>my_sampler <span class=\"pl-k\">=</span> DynamicSampler()\nloader <span class=\"pl-k\">=</span> DataLoader(dataset, <span class=\"pl-v\">sampler</span><span class=\"pl-k\">=</span>my_sampler)\n<span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> loader:\n    result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">...</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> do sth with the batch</span>\n    my_sampler.update_distribution(result)\n    <span class=\"pl-k\">if</span> result.should_stop:\n        my_sampler.finish_sequence() <span class=\"pl-c\"><span class=\"pl-c\">#</span> calling `next(my_sampler)` will raise `StopIteration` and terminate the loop</span></pre></div>\n<p>Regarding 2., it would be really helpful for us if you could provide us a small repro for the memory leak.</p>\n<p>I don't think that adding worker threads to datasets is a good idea. It will make it considerably harder for people to write them, and it makes the semantics of sharing datasets with worker processes dangerous (forking with threads is a bad idea in general). Datasets are just lazy lists, and they should remain like this. If you need multithreaded data loading, this should be a different abstraction, but as far as I see everything you mentioned seems possible to implement with <code>DataLoader</code>.</p>", "body_text": "Ad 1. Dynamic sampling is well supported and there's no reason to have to re-assign the .sampler attribute. Creating DataLoaders is very cheap (only instantiating their iterators is more expensive). Your sampler can return itself as an iterator, and you can make it a mutable object. Consider this example:\nmy_sampler = DynamicSampler()\nloader = DataLoader(dataset, sampler=my_sampler)\nfor batch in loader:\n    result = ... # do sth with the batch\n    my_sampler.update_distribution(result)\n    if result.should_stop:\n        my_sampler.finish_sequence() # calling `next(my_sampler)` will raise `StopIteration` and terminate the loop\nRegarding 2., it would be really helpful for us if you could provide us a small repro for the memory leak.\nI don't think that adding worker threads to datasets is a good idea. It will make it considerably harder for people to write them, and it makes the semantics of sharing datasets with worker processes dangerous (forking with threads is a bad idea in general). Datasets are just lazy lists, and they should remain like this. If you need multithreaded data loading, this should be a different abstraction, but as far as I see everything you mentioned seems possible to implement with DataLoader.", "body": "Ad 1. Dynamic sampling is well supported and there's no reason to have to re-assign the `.sampler` attribute. Creating `DataLoader`s is very cheap (only instantiating their iterators is more expensive). Your sampler can return itself as an iterator, and you can make it a mutable object. Consider this example:\r\n\r\n```python\r\nmy_sampler = DynamicSampler()\r\nloader = DataLoader(dataset, sampler=my_sampler)\r\nfor batch in loader:\r\n    result = ... # do sth with the batch\r\n    my_sampler.update_distribution(result)\r\n    if result.should_stop:\r\n        my_sampler.finish_sequence() # calling `next(my_sampler)` will raise `StopIteration` and terminate the loop\r\n```\r\n\r\nRegarding 2., it would be really helpful for us if you could provide us a small repro for the memory leak.\r\n\r\nI don't think that adding worker threads to datasets is a good idea. It will make it considerably harder for people to write them, and it makes the semantics of sharing datasets with worker processes dangerous (forking with threads is a bad idea in general). Datasets are just lazy lists, and they should remain like this. If you need multithreaded data loading, this should be a different abstraction, but as far as I see everything you mentioned seems possible to implement with `DataLoader`."}