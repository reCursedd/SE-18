{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422921227", "html_url": "https://github.com/pytorch/pytorch/pull/11872#issuecomment-422921227", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11872", "id": 422921227, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjkyMTIyNw==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T19:02:15Z", "updated_at": "2018-09-19T19:06:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Needless to say, I'd be happy to split the PR into two parts if you think they're too unrelated.<br>\nThere aren't any other functions affected, but there is this comment that would now be obsolete:</p>\n<pre><code># NB: We MUST call the input self, otherwise codegen will attempt to\n# dispatch on ggI... which might be undefined.\n- func: _convolution_double_backward(Tensor? ggI, Tensor? ggW, Tensor? ggb, Tensor gO, Tensor weight, Tensor self, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups, bool benchmark, bool deterministic, bool cudnn_enabled, std::array&lt;bool,3&gt; output_mask) -&gt; (Tensor, Tensor, Tensor)\n</code></pre>", "body_text": "Needless to say, I'd be happy to split the PR into two parts if you think they're too unrelated.\nThere aren't any other functions affected, but there is this comment that would now be obsolete:\n# NB: We MUST call the input self, otherwise codegen will attempt to\n# dispatch on ggI... which might be undefined.\n- func: _convolution_double_backward(Tensor? ggI, Tensor? ggW, Tensor? ggb, Tensor gO, Tensor weight, Tensor self, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups, bool benchmark, bool deterministic, bool cudnn_enabled, std::array<bool,3> output_mask) -> (Tensor, Tensor, Tensor)", "body": "Needless to say, I'd be happy to split the PR into two parts if you think they're too unrelated.\r\nThere aren't any other functions affected, but there is this comment that would now be obsolete:\r\n```\r\n# NB: We MUST call the input self, otherwise codegen will attempt to\r\n# dispatch on ggI... which might be undefined.\r\n- func: _convolution_double_backward(Tensor? ggI, Tensor? ggW, Tensor? ggb, Tensor gO, Tensor weight, Tensor self, IntList stride, IntList padding, IntList dilation, bool transposed, IntList output_padding, int64_t groups, bool benchmark, bool deterministic, bool cudnn_enabled, std::array<bool,3> output_mask) -> (Tensor, Tensor, Tensor)\r\n```\r\n"}