{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347479772", "html_url": "https://github.com/pytorch/pytorch/issues/3917#issuecomment-347479772", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3917", "id": 347479772, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzQ3OTc3Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-28T10:27:57Z", "updated_at": "2017-11-28T10:27:57Z", "author_association": "MEMBER", "body_html": "<p>My guess would be that you\u2019re using a small batch size (64, so 16 per GPU) so they are not effectively used at 100%, but you have to pay the communication costs that make it slower. Check how the run times change if you increase the batch size (you still have plenty of free memory)</p>", "body_text": "My guess would be that you\u2019re using a small batch size (64, so 16 per GPU) so they are not effectively used at 100%, but you have to pay the communication costs that make it slower. Check how the run times change if you increase the batch size (you still have plenty of free memory)", "body": "My guess would be that you\u2019re using a small batch size (64, so 16 per GPU) so they are not effectively used at 100%, but you have to pay the communication costs that make it slower. Check how the run times change if you increase the batch size (you still have plenty of free memory)"}