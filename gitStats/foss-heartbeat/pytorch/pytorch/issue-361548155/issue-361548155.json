{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11850", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11850/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11850/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11850/events", "html_url": "https://github.com/pytorch/pytorch/issues/11850", "id": 361548155, "node_id": "MDU6SXNzdWUzNjE1NDgxNTU=", "number": 11850, "title": "[Caffe2/Bug] Cannot enable MKL-DNN", "user": {"login": "jiecaoyu", "id": 10011346, "node_id": "MDQ6VXNlcjEwMDExMzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/10011346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiecaoyu", "html_url": "https://github.com/jiecaoyu", "followers_url": "https://api.github.com/users/jiecaoyu/followers", "following_url": "https://api.github.com/users/jiecaoyu/following{/other_user}", "gists_url": "https://api.github.com/users/jiecaoyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiecaoyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiecaoyu/subscriptions", "organizations_url": "https://api.github.com/users/jiecaoyu/orgs", "repos_url": "https://api.github.com/users/jiecaoyu/repos", "events_url": "https://api.github.com/users/jiecaoyu/events{/privacy}", "received_events_url": "https://api.github.com/users/jiecaoyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-19T02:00:52Z", "updated_at": "2018-09-27T20:21:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Solution</h2>\n<p>A solution is found for the problem, but maybe a bug in Caffe2</p>\n<p>MKL-DNN can be enabled by first compiling the PyTorch. Then turn on MKL by</p>\n<div class=\"highlight highlight-source-shell\"><pre>diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 827121b1f..235d00bd6 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\n option(USE_TENSORRT <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Using Nvidia TensorRT library<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_ZMQ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use ZMQ<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_ZSTD <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use ZSTD<span class=\"pl-pds\">\"</span></span> OFF)\n+option(USE_MKL <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKL<span class=\"pl-pds\">\"</span></span> ON)\n option(USE_MKLDNN <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKLDNN<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_IDEEP <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use IDEEP interface in MKL BLAS<span class=\"pl-pds\">\"</span></span> ON)\n option(USE_MKLML <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKLML interface in MKL BLAS<span class=\"pl-pds\">\"</span></span> ON)</pre></div>\n<p>and recompile PyTorch. Then MKL-DNN is enabled.</p>\n<h2>Issue description</h2>\n<p>Trying to accelerate caffe2 inference with MKL-DNN.</p>\n<p>The MKL-DNN lib can be detected:</p>\n<pre><code>-- Found MKLDNN: /home/jiecaoyu/.local/include  \n-- Found MKLDNN      (include: /home/jiecaoyu/.local/include, library: /home/jiecaoyu/.local/lib/libmkldnn.so)\n</code></pre>\n<p>But mkl operators are not compiled</p>\n<pre><code>-- Excluding mkl operators as we are not using mkl\n</code></pre>\n<p>And MKL-DNN cannot be found after installation since</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> caffe2.python <span class=\"pl-k\">import</span> workspace\nworkspace.C.has_mkldnn</pre></div>\n<p>returns False.</p>\n<p>Also, I try to enable MKL by changing the CMakeLists.txt:</p>\n<div class=\"highlight highlight-source-shell\"><pre>diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 827121b1f..235d00bd6 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\n option(USE_TENSORRT <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Using Nvidia TensorRT library<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_ZMQ <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use ZMQ<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_ZSTD <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use ZSTD<span class=\"pl-pds\">\"</span></span> OFF)\n+option(USE_MKL <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKL<span class=\"pl-pds\">\"</span></span> ON)\n option(USE_MKLDNN <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKLDNN<span class=\"pl-pds\">\"</span></span> OFF)\n option(USE_IDEEP <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use IDEEP interface in MKL BLAS<span class=\"pl-pds\">\"</span></span> ON)\n option(USE_MKLML <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Use MKLML interface in MKL BLAS<span class=\"pl-pds\">\"</span></span> ON)</pre></div>\n<p>It acutally cause an error:</p>\n<pre><code>...\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:397:1: error: prototype for \u2018THMapAllocator::THMapAllocator(WithFd, const char*, int, int)\u2019 does not match any in class \u2018THMapAllocator\u2019\n THMapAllocator::THMapAllocator(WithFd, const char *filename, int fd, int flags) {\n ^~~~~~~~~~~~~~\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:41:3: error: candidates are: THMapAllocator::THMapAllocator(THMapAllocator&amp;&amp;)\n   THMapAllocator(THMapAllocator&amp;&amp;) = delete;\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:39:3: error:                 THMapAllocator::THMapAllocator(const THMapAllocator&amp;)\n   THMapAllocator(const THMapAllocator&amp;) = delete;\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:38:3: error:                 THMapAllocator::THMapAllocator(WithFd, const char*, int, int, size_t)\n   THMapAllocator(WithFd, const char *filename, int fd, int flags, size_t size);\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:393:1: error:                 THMapAllocator::THMapAllocator(const char*, int, size_t)\n THMapAllocator::THMapAllocator(const char *filename, int flags, size_t size) {\n ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:52: error: destructors may not have parameters\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\n                                                    ^\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:1: error: redefinition of \u2018THMapAllocator::~THMapAllocator()\u2019\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\n ^~~~~~~~~~~~~~\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\n...\n</code></pre>\n<h2>System Info</h2>\n<p>PyTorch version: 1.0.0a0+98aebed<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0<br>\nCMake version: version 3.10.2</p>\n<p>Python version: 2.7<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.15.1)<br>\n[pip] torch (1.0.0a0+98aebed)<br>\n[conda] Could not collect</p>", "body_text": "Solution\nA solution is found for the problem, but maybe a bug in Caffe2\nMKL-DNN can be enabled by first compiling the PyTorch. Then turn on MKL by\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 827121b1f..235d00bd6 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\n option(USE_TENSORRT \"Using Nvidia TensorRT library\" OFF)\n option(USE_ZMQ \"Use ZMQ\" OFF)\n option(USE_ZSTD \"Use ZSTD\" OFF)\n+option(USE_MKL \"Use MKL\" ON)\n option(USE_MKLDNN \"Use MKLDNN\" OFF)\n option(USE_IDEEP \"Use IDEEP interface in MKL BLAS\" ON)\n option(USE_MKLML \"Use MKLML interface in MKL BLAS\" ON)\nand recompile PyTorch. Then MKL-DNN is enabled.\nIssue description\nTrying to accelerate caffe2 inference with MKL-DNN.\nThe MKL-DNN lib can be detected:\n-- Found MKLDNN: /home/jiecaoyu/.local/include  \n-- Found MKLDNN      (include: /home/jiecaoyu/.local/include, library: /home/jiecaoyu/.local/lib/libmkldnn.so)\n\nBut mkl operators are not compiled\n-- Excluding mkl operators as we are not using mkl\n\nAnd MKL-DNN cannot be found after installation since\nfrom caffe2.python import workspace\nworkspace.C.has_mkldnn\nreturns False.\nAlso, I try to enable MKL by changing the CMakeLists.txt:\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 827121b1f..235d00bd6 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\n option(USE_TENSORRT \"Using Nvidia TensorRT library\" OFF)\n option(USE_ZMQ \"Use ZMQ\" OFF)\n option(USE_ZSTD \"Use ZSTD\" OFF)\n+option(USE_MKL \"Use MKL\" ON)\n option(USE_MKLDNN \"Use MKLDNN\" OFF)\n option(USE_IDEEP \"Use IDEEP interface in MKL BLAS\" ON)\n option(USE_MKLML \"Use MKLML interface in MKL BLAS\" ON)\nIt acutally cause an error:\n...\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:397:1: error: prototype for \u2018THMapAllocator::THMapAllocator(WithFd, const char*, int, int)\u2019 does not match any in class \u2018THMapAllocator\u2019\n THMapAllocator::THMapAllocator(WithFd, const char *filename, int fd, int flags) {\n ^~~~~~~~~~~~~~\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:41:3: error: candidates are: THMapAllocator::THMapAllocator(THMapAllocator&&)\n   THMapAllocator(THMapAllocator&&) = delete;\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:39:3: error:                 THMapAllocator::THMapAllocator(const THMapAllocator&)\n   THMapAllocator(const THMapAllocator&) = delete;\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:38:3: error:                 THMapAllocator::THMapAllocator(WithFd, const char*, int, int, size_t)\n   THMapAllocator(WithFd, const char *filename, int fd, int flags, size_t size);\n   ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:393:1: error:                 THMapAllocator::THMapAllocator(const char*, int, size_t)\n THMapAllocator::THMapAllocator(const char *filename, int flags, size_t size) {\n ^~~~~~~~~~~~~~\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:52: error: destructors may not have parameters\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\n                                                    ^\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:1: error: redefinition of \u2018THMapAllocator::~THMapAllocator()\u2019\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\n ^~~~~~~~~~~~~~\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\n...\n\nSystem Info\nPyTorch version: 1.0.0a0+98aebed\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\nCMake version: version 3.10.2\nPython version: 2.7\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip] numpy (1.15.1)\n[pip] torch (1.0.0a0+98aebed)\n[conda] Could not collect", "body": "## Solution\r\nA solution is found for the problem, but maybe a bug in Caffe2\r\n\r\nMKL-DNN can be enabled by first compiling the PyTorch. Then turn on MKL by\r\n```bash\r\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\r\nindex 827121b1f..235d00bd6 100644\r\n--- a/CMakeLists.txt\r\n+++ b/CMakeLists.txt\r\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\r\n option(USE_TENSORRT \"Using Nvidia TensorRT library\" OFF)\r\n option(USE_ZMQ \"Use ZMQ\" OFF)\r\n option(USE_ZSTD \"Use ZSTD\" OFF)\r\n+option(USE_MKL \"Use MKL\" ON)\r\n option(USE_MKLDNN \"Use MKLDNN\" OFF)\r\n option(USE_IDEEP \"Use IDEEP interface in MKL BLAS\" ON)\r\n option(USE_MKLML \"Use MKLML interface in MKL BLAS\" ON)\r\n```\r\nand recompile PyTorch. Then MKL-DNN is enabled.\r\n\r\n## Issue description\r\n\r\nTrying to accelerate caffe2 inference with MKL-DNN.\r\n\r\nThe MKL-DNN lib can be detected:\r\n```\r\n-- Found MKLDNN: /home/jiecaoyu/.local/include  \r\n-- Found MKLDNN      (include: /home/jiecaoyu/.local/include, library: /home/jiecaoyu/.local/lib/libmkldnn.so)\r\n```\r\nBut mkl operators are not compiled\r\n```\r\n-- Excluding mkl operators as we are not using mkl\r\n```\r\nAnd MKL-DNN cannot be found after installation since\r\n```python\r\nfrom caffe2.python import workspace\r\nworkspace.C.has_mkldnn\r\n```\r\nreturns False.\r\n\r\nAlso, I try to enable MKL by changing the CMakeLists.txt:\r\n```bash\r\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\r\nindex 827121b1f..235d00bd6 100644\r\n--- a/CMakeLists.txt\r\n+++ b/CMakeLists.txt\r\n@@ -111,6 +111,7 @@ option(USE_SYSTEM_EIGEN_INSTALL\r\n option(USE_TENSORRT \"Using Nvidia TensorRT library\" OFF)\r\n option(USE_ZMQ \"Use ZMQ\" OFF)\r\n option(USE_ZSTD \"Use ZSTD\" OFF)\r\n+option(USE_MKL \"Use MKL\" ON)\r\n option(USE_MKLDNN \"Use MKLDNN\" OFF)\r\n option(USE_IDEEP \"Use IDEEP interface in MKL BLAS\" ON)\r\n option(USE_MKLML \"Use MKLML interface in MKL BLAS\" ON)\r\n```\r\nIt acutally cause an error:\r\n```\r\n...\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:397:1: error: prototype for \u2018THMapAllocator::THMapAllocator(WithFd, const char*, int, int)\u2019 does not match any in class \u2018THMapAllocator\u2019\r\n THMapAllocator::THMapAllocator(WithFd, const char *filename, int fd, int flags) {\r\n ^~~~~~~~~~~~~~\r\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:41:3: error: candidates are: THMapAllocator::THMapAllocator(THMapAllocator&&)\r\n   THMapAllocator(THMapAllocator&&) = delete;\r\n   ^~~~~~~~~~~~~~\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:39:3: error:                 THMapAllocator::THMapAllocator(const THMapAllocator&)\r\n   THMapAllocator(const THMapAllocator&) = delete;\r\n   ^~~~~~~~~~~~~~\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.h:38:3: error:                 THMapAllocator::THMapAllocator(WithFd, const char*, int, int, size_t)\r\n   THMapAllocator(WithFd, const char *filename, int fd, int flags, size_t size);\r\n   ^~~~~~~~~~~~~~\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:393:1: error:                 THMapAllocator::THMapAllocator(const char*, int, size_t)\r\n THMapAllocator::THMapAllocator(const char *filename, int flags, size_t size) {\r\n ^~~~~~~~~~~~~~\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:52: error: destructors may not have parameters\r\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\r\n                                                    ^\r\n/home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:401:1: error: redefinition of \u2018THMapAllocator::~THMapAllocator()\u2019\r\n THMapAllocator::~THMapAllocator(THMapAllocator* ctx) {}\r\n ^~~~~~~~~~~~~~\r\nIn file included from /home/jiecaoyu/LIBS/pytorch/aten/src/TH/THAllocator.cpp:1:0:\r\n...\r\n```\r\n\r\n## System Info\r\nPyTorch version: 1.0.0a0+98aebed\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 2.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.1)\r\n[pip] torch (1.0.0a0+98aebed)\r\n[conda] Could not collect\r\n\r\n"}