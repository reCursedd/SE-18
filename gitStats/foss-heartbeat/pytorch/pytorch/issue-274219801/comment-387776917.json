{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/387776917", "html_url": "https://github.com/pytorch/pytorch/issues/3716#issuecomment-387776917", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3716", "id": 387776917, "node_id": "MDEyOklzc3VlQ29tbWVudDM4Nzc3NjkxNw==", "user": {"login": "hartb", "id": 18429659, "node_id": "MDQ6VXNlcjE4NDI5NjU5", "avatar_url": "https://avatars1.githubusercontent.com/u/18429659?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hartb", "html_url": "https://github.com/hartb", "followers_url": "https://api.github.com/users/hartb/followers", "following_url": "https://api.github.com/users/hartb/following{/other_user}", "gists_url": "https://api.github.com/users/hartb/gists{/gist_id}", "starred_url": "https://api.github.com/users/hartb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hartb/subscriptions", "organizations_url": "https://api.github.com/users/hartb/orgs", "repos_url": "https://api.github.com/users/hartb/repos", "events_url": "https://api.github.com/users/hartb/events{/privacy}", "received_events_url": "https://api.github.com/users/hartb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-09T15:24:00Z", "updated_at": "2018-05-09T15:24:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We're using a PowerAI build of OpenBLAS 0.2.20 (a bit newer than yours and not published yet <code>libopenblas-0.2.20-2593.b59753e.ppc64le</code>).</p>\n<p>Some particulars in case this rings any bells with anyone...</p>\n<p>We can force the failure with a simple test, based on the failing test_qr testcase:</p>\n<pre><code>#!/usr/bin/env python\n\nimport torch\n\nfor sz in [ 127, 128, 129, 130, 500 ]:\n        print(\"Size = {}\".format(sz))\n        for i in range(10):\n                a = torch.randn(sz, sz)\n                q, r = torch.qr(a)\n                a_qr = torch.mm(q, r)\n                m = float(max(max(x) for x in a - a_qr))\n                print(\"max diff = {0:.6f}{1}\".format(m, \" FAIL!\" if m &gt; 0.001 else \"\"))\n</code></pre>\n<p>The failure doesn't seem to occur with matrix sizes of 128x128 or smaller, but will occur with increasing frequency as the matrix size grows. With 129x129, it fails maybe 1 in 10; 500x500 around 9 in 10.</p>\n<p>Not clear whether the problem is coming from torch.qr() or torch.mm() (or both). But presumably one of them is getting into some code that chooses a different algorithm at the 128x128 size cutoff (maybe based on particulars of the build or runtime environment).</p>\n<p>Doesn't fail for us on our Power8 machines but does on Power9, with same OpenBLAS and PyTorch binaries.</p>", "body_text": "We're using a PowerAI build of OpenBLAS 0.2.20 (a bit newer than yours and not published yet libopenblas-0.2.20-2593.b59753e.ppc64le).\nSome particulars in case this rings any bells with anyone...\nWe can force the failure with a simple test, based on the failing test_qr testcase:\n#!/usr/bin/env python\n\nimport torch\n\nfor sz in [ 127, 128, 129, 130, 500 ]:\n        print(\"Size = {}\".format(sz))\n        for i in range(10):\n                a = torch.randn(sz, sz)\n                q, r = torch.qr(a)\n                a_qr = torch.mm(q, r)\n                m = float(max(max(x) for x in a - a_qr))\n                print(\"max diff = {0:.6f}{1}\".format(m, \" FAIL!\" if m > 0.001 else \"\"))\n\nThe failure doesn't seem to occur with matrix sizes of 128x128 or smaller, but will occur with increasing frequency as the matrix size grows. With 129x129, it fails maybe 1 in 10; 500x500 around 9 in 10.\nNot clear whether the problem is coming from torch.qr() or torch.mm() (or both). But presumably one of them is getting into some code that chooses a different algorithm at the 128x128 size cutoff (maybe based on particulars of the build or runtime environment).\nDoesn't fail for us on our Power8 machines but does on Power9, with same OpenBLAS and PyTorch binaries.", "body": "We're using a PowerAI build of OpenBLAS 0.2.20 (a bit newer than yours and not published yet `libopenblas-0.2.20-2593.b59753e.ppc64le`).\r\n\r\nSome particulars in case this rings any bells with anyone...\r\n\r\nWe can force the failure with a simple test, based on the failing test_qr testcase:\r\n\r\n```\r\n#!/usr/bin/env python\r\n\r\nimport torch\r\n\r\nfor sz in [ 127, 128, 129, 130, 500 ]:\r\n        print(\"Size = {}\".format(sz))\r\n        for i in range(10):\r\n                a = torch.randn(sz, sz)\r\n                q, r = torch.qr(a)\r\n                a_qr = torch.mm(q, r)\r\n                m = float(max(max(x) for x in a - a_qr))\r\n                print(\"max diff = {0:.6f}{1}\".format(m, \" FAIL!\" if m > 0.001 else \"\"))\r\n```\r\n\r\nThe failure doesn't seem to occur with matrix sizes of 128x128 or smaller, but will occur with increasing frequency as the matrix size grows. With 129x129, it fails maybe 1 in 10; 500x500 around 9 in 10.\r\n\r\nNot clear whether the problem is coming from torch.qr() or torch.mm() (or both). But presumably one of them is getting into some code that chooses a different algorithm at the 128x128 size cutoff (maybe based on particulars of the build or runtime environment).\r\n\r\nDoesn't fail for us on our Power8 machines but does on Power9, with same OpenBLAS and PyTorch binaries."}