{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/387276122", "html_url": "https://github.com/pytorch/pytorch/issues/7338#issuecomment-387276122", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7338", "id": 387276122, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NzI3NjEyMg==", "user": {"login": "bingo619", "id": 1096590, "node_id": "MDQ6VXNlcjEwOTY1OTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1096590?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bingo619", "html_url": "https://github.com/bingo619", "followers_url": "https://api.github.com/users/bingo619/followers", "following_url": "https://api.github.com/users/bingo619/following{/other_user}", "gists_url": "https://api.github.com/users/bingo619/gists{/gist_id}", "starred_url": "https://api.github.com/users/bingo619/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bingo619/subscriptions", "organizations_url": "https://api.github.com/users/bingo619/orgs", "repos_url": "https://api.github.com/users/bingo619/repos", "events_url": "https://api.github.com/users/bingo619/events{/privacy}", "received_events_url": "https://api.github.com/users/bingo619/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-08T03:49:50Z", "updated_at": "2018-05-08T03:49:50Z", "author_association": "NONE", "body_html": "<p>I think if the tensor does not require gradients at all, you should not declare it as Parameter.</p>\n<p>If you want to freeze your subgraph, you should do it explicitly as described  on <a href=\"https://pytorch.org/docs/master/notes/autograd.html\" rel=\"nofollow\">https://pytorch.org/docs/master/notes/autograd.html</a></p>", "body_text": "I think if the tensor does not require gradients at all, you should not declare it as Parameter.\nIf you want to freeze your subgraph, you should do it explicitly as described  on https://pytorch.org/docs/master/notes/autograd.html", "body": "I think if the tensor does not require gradients at all, you should not declare it as Parameter.\r\n\r\nIf you want to freeze your subgraph, you should do it explicitly as described  on https://pytorch.org/docs/master/notes/autograd.html"}