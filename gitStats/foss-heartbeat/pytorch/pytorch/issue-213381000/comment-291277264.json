{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/291277264", "html_url": "https://github.com/pytorch/pytorch/issues/973#issuecomment-291277264", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/973", "id": 291277264, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTI3NzI2NA==", "user": {"login": "skaae", "id": 2623134, "node_id": "MDQ6VXNlcjI2MjMxMzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2623134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skaae", "html_url": "https://github.com/skaae", "followers_url": "https://api.github.com/users/skaae/followers", "following_url": "https://api.github.com/users/skaae/following{/other_user}", "gists_url": "https://api.github.com/users/skaae/gists{/gist_id}", "starred_url": "https://api.github.com/users/skaae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skaae/subscriptions", "organizations_url": "https://api.github.com/users/skaae/orgs", "repos_url": "https://api.github.com/users/skaae/repos", "events_url": "https://api.github.com/users/skaae/events{/privacy}", "received_events_url": "https://api.github.com/users/skaae/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T21:19:27Z", "updated_at": "2017-04-03T21:19:27Z", "author_association": "NONE", "body_html": "<p>I have the same problem. I can get rid of the problem by having my collate_fn return numpy arrays instead of Torch tensors. I.e. commenting the <code>from_numpy</code> lines removes the problem. I also get the problem if i create the tensor with <code>torch.FloatTensor(some_np_arr)</code>.</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-en\">@</span><span class=\"pl-c1\">staticmethod</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">collate_fn</span>(<span class=\"pl-smi\">batch</span>):\n        org_audio_len_lst, audio_lst, spec_linear_lst, spec_mel_lst, speaker_class_lst, sample_info_lst <span class=\"pl-k\">=</span> <span class=\"pl-c1\">zip</span>(<span class=\"pl-k\">*</span>batch)\n        audio_arr <span class=\"pl-k\">=</span> np.stack(audio_lst,<span class=\"pl-c1\">0</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n        spec_linear_arr <span class=\"pl-k\">=</span> np.stack(spec_linear_lst, <span class=\"pl-c1\">0</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n        spec_mel_arr <span class=\"pl-k\">=</span> np.stack(spec_mel_lst, <span class=\"pl-c1\">0</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)\n\n        audio_arr <span class=\"pl-k\">=</span> torch.from_numpy(audio_arr)    \n        spec_linear_arr <span class=\"pl-k\">=</span> torch.from_numpy(spec_linear_arr)\n        spec_mel_arr <span class=\"pl-k\">=</span> torch.from_numpy(spec_mel_arr)\n        speaker_class_tensor <span class=\"pl-k\">=</span> torch.LongTensor(speaker_class_lst)\n        <span class=\"pl-k\">return</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>audio<span class=\"pl-pds\">'</span></span>: audio_arr, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>spec_linear<span class=\"pl-pds\">'</span></span>: spec_linear_arr, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>spec_mel<span class=\"pl-pds\">'</span></span>: spec_mel_arr,\n                <span class=\"pl-s\"><span class=\"pl-pds\">'</span>speaker_class<span class=\"pl-pds\">'</span></span>: speaker_class_tensor}\n</pre></div>", "body_text": "I have the same problem. I can get rid of the problem by having my collate_fn return numpy arrays instead of Torch tensors. I.e. commenting the from_numpy lines removes the problem. I also get the problem if i create the tensor with torch.FloatTensor(some_np_arr).\n    @staticmethod\n    def collate_fn(batch):\n        org_audio_len_lst, audio_lst, spec_linear_lst, spec_mel_lst, speaker_class_lst, sample_info_lst = zip(*batch)\n        audio_arr = np.stack(audio_lst,0).astype('float32')\n        spec_linear_arr = np.stack(spec_linear_lst, 0).astype('float32')\n        spec_mel_arr = np.stack(spec_mel_lst, 0).astype('float32')\n\n        audio_arr = torch.from_numpy(audio_arr)    \n        spec_linear_arr = torch.from_numpy(spec_linear_arr)\n        spec_mel_arr = torch.from_numpy(spec_mel_arr)\n        speaker_class_tensor = torch.LongTensor(speaker_class_lst)\n        return {'audio': audio_arr, 'spec_linear': spec_linear_arr, 'spec_mel': spec_mel_arr,\n                'speaker_class': speaker_class_tensor}", "body": "I have the same problem. I can get rid of the problem by having my collate_fn return numpy arrays instead of Torch tensors. I.e. commenting the `from_numpy` lines removes the problem. I also get the problem if i create the tensor with `torch.FloatTensor(some_np_arr)`. \r\n\r\n```Python\r\n    @staticmethod\r\n    def collate_fn(batch):\r\n        org_audio_len_lst, audio_lst, spec_linear_lst, spec_mel_lst, speaker_class_lst, sample_info_lst = zip(*batch)\r\n        audio_arr = np.stack(audio_lst,0).astype('float32')\r\n        spec_linear_arr = np.stack(spec_linear_lst, 0).astype('float32')\r\n        spec_mel_arr = np.stack(spec_mel_lst, 0).astype('float32')\r\n\r\n        audio_arr = torch.from_numpy(audio_arr)    \r\n        spec_linear_arr = torch.from_numpy(spec_linear_arr)\r\n        spec_mel_arr = torch.from_numpy(spec_mel_arr)\r\n        speaker_class_tensor = torch.LongTensor(speaker_class_lst)\r\n        return {'audio': audio_arr, 'spec_linear': spec_linear_arr, 'spec_mel': spec_mel_arr,\r\n                'speaker_class': speaker_class_tensor}\r\n\r\n```"}