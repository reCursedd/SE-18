{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/291289739", "html_url": "https://github.com/pytorch/pytorch/issues/973#issuecomment-291289739", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/973", "id": 291289739, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTI4OTczOQ==", "user": {"login": "skaae", "id": 2623134, "node_id": "MDQ6VXNlcjI2MjMxMzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2623134?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skaae", "html_url": "https://github.com/skaae", "followers_url": "https://api.github.com/users/skaae/followers", "following_url": "https://api.github.com/users/skaae/following{/other_user}", "gists_url": "https://api.github.com/users/skaae/gists{/gist_id}", "starred_url": "https://api.github.com/users/skaae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skaae/subscriptions", "organizations_url": "https://api.github.com/users/skaae/orgs", "repos_url": "https://api.github.com/users/skaae/repos", "events_url": "https://api.github.com/users/skaae/events{/privacy}", "received_events_url": "https://api.github.com/users/skaae/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-03T22:13:57Z", "updated_at": "2017-04-03T22:14:09Z", "author_association": "NONE", "body_html": "<p>Ok.<br>\nIt always happens after the same number of batches have been loaded from disk. like i'm hitting some limit.</p>\n<p>In my setup I load 512 samples to memory at the beginning of training. The samples are stored in list.<br>\nThe 512 samples in memory are periodically replaced randomly with new samples loaded from disk.</p>\n<p>Is that the problem and do you have workaround ? :)</p>", "body_text": "Ok.\nIt always happens after the same number of batches have been loaded from disk. like i'm hitting some limit.\nIn my setup I load 512 samples to memory at the beginning of training. The samples are stored in list.\nThe 512 samples in memory are periodically replaced randomly with new samples loaded from disk.\nIs that the problem and do you have workaround ? :)", "body": "Ok. \r\nIt always happens after the same number of batches have been loaded from disk. like i'm hitting some limit.\r\n\r\nIn my setup I load 512 samples to memory at the beginning of training. The samples are stored in list. \r\nThe 512 samples in memory are periodically replaced randomly with new samples loaded from disk. \r\n\r\nIs that the problem and do you have workaround ? :)"}