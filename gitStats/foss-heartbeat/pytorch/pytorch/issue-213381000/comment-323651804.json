{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/323651804", "html_url": "https://github.com/pytorch/pytorch/issues/973#issuecomment-323651804", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/973", "id": 323651804, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzY1MTgwNA==", "user": {"login": "kamo-naoyuki", "id": 19261024, "node_id": "MDQ6VXNlcjE5MjYxMDI0", "avatar_url": "https://avatars0.githubusercontent.com/u/19261024?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kamo-naoyuki", "html_url": "https://github.com/kamo-naoyuki", "followers_url": "https://api.github.com/users/kamo-naoyuki/followers", "following_url": "https://api.github.com/users/kamo-naoyuki/following{/other_user}", "gists_url": "https://api.github.com/users/kamo-naoyuki/gists{/gist_id}", "starred_url": "https://api.github.com/users/kamo-naoyuki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kamo-naoyuki/subscriptions", "organizations_url": "https://api.github.com/users/kamo-naoyuki/orgs", "repos_url": "https://api.github.com/users/kamo-naoyuki/repos", "events_url": "https://api.github.com/users/kamo-naoyuki/events{/privacy}", "received_events_url": "https://api.github.com/users/kamo-naoyuki/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-21T05:47:29Z", "updated_at": "2017-08-21T06:29:18Z", "author_association": "NONE", "body_html": "<p>Maybe I could reproduce a same error by the following code.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.multiprocessing <span class=\"pl-k\">as</span> multiprocessing\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_worker_loop</span>(<span class=\"pl-smi\">data_queue</span>, ):\n    <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n        t <span class=\"pl-k\">=</span> torch.FloatTensor(<span class=\"pl-c1\">1</span>)\n        data_queue.put(t)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    data_queue <span class=\"pl-k\">=</span> multiprocessing.Queue(<span class=\"pl-v\">maxsize</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    p <span class=\"pl-k\">=</span> multiprocessing.Process(\n        <span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>_worker_loop,\n        <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(data_queue,))\n\n    p.daemon <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n    p.start()\n    lis <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10000</span>):\n        <span class=\"pl-k\">try</span>:\n            lis.append(data_queue.get())\n        <span class=\"pl-k\">except</span>:\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>i = <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(i))\n            <span class=\"pl-k\">raise</span></pre></div>\n<pre><code>i = 1015\nTraceback (most recent call last):\n  File \"a.py\", line 28, in &lt;module&gt;\n    lis.append(data_queue.get())\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n    return _ForkingPickler.loads(res)\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n    fd = df.detach()\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n    return reduction.recv_handle(conn)\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n    return recvfds(s, 1)[0]\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 161, in recvfds\n    len(ancdata))\nRuntimeError: received 0 items of ancdata\n</code></pre>\n<p>The i number always becomes 1015 in the environment.</p>\n<p>In this case this error would be caused by the limitation of the number of file descriptors. In my setting, \"ulimit -n\" gives 1024 and if the limitation is changed to the lower number, the i gets the lower number by that amount.</p>", "body_text": "Maybe I could reproduce a same error by the following code.\nimport torch\nimport torch.multiprocessing as multiprocessing\n\ndef _worker_loop(data_queue, ):\n    while True:\n        t = torch.FloatTensor(1)\n        data_queue.put(t)\n\n\nif __name__ == '__main__':\n    data_queue = multiprocessing.Queue(maxsize=1)\n    p = multiprocessing.Process(\n        target=_worker_loop,\n        args=(data_queue,))\n\n    p.daemon = True\n    p.start()\n    lis = []\n    for i in range(10000):\n        try:\n            lis.append(data_queue.get())\n        except:\n            print('i = {}'.format(i))\n            raise\ni = 1015\nTraceback (most recent call last):\n  File \"a.py\", line 28, in <module>\n    lis.append(data_queue.get())\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n    return _ForkingPickler.loads(res)\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n    fd = df.detach()\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n    return reduction.recv_handle(conn)\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n    return recvfds(s, 1)[0]\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 161, in recvfds\n    len(ancdata))\nRuntimeError: received 0 items of ancdata\n\nThe i number always becomes 1015 in the environment.\nIn this case this error would be caused by the limitation of the number of file descriptors. In my setting, \"ulimit -n\" gives 1024 and if the limitation is changed to the lower number, the i gets the lower number by that amount.", "body": "Maybe I could reproduce a same error by the following code.\r\n\r\n```python\r\nimport torch\r\nimport torch.multiprocessing as multiprocessing\r\n\r\ndef _worker_loop(data_queue, ):\r\n    while True:\r\n        t = torch.FloatTensor(1)\r\n        data_queue.put(t)\r\n\r\n\r\nif __name__ == '__main__':\r\n    data_queue = multiprocessing.Queue(maxsize=1)\r\n    p = multiprocessing.Process(\r\n        target=_worker_loop,\r\n        args=(data_queue,))\r\n\r\n    p.daemon = True\r\n    p.start()\r\n    lis = []\r\n    for i in range(10000):\r\n        try:\r\n            lis.append(data_queue.get())\r\n        except:\r\n            print('i = {}'.format(i))\r\n            raise\r\n```\r\n\r\n```\r\ni = 1015\r\nTraceback (most recent call last):\r\n  File \"a.py\", line 28, in <module>\r\n    lis.append(data_queue.get())\r\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/queues.py\", line 113, in get\r\n    return _ForkingPickler.loads(res)\r\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\r\n    fd = df.detach()\r\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\r\n    return reduction.recv_handle(conn)\r\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\r\n    return recvfds(s, 1)[0]\r\n  File \"/home.local/kamo/.anyenv/envs/pyenv/versions/my3/lib/python3.6/multiprocessing/reduction.py\", line 161, in recvfds\r\n    len(ancdata))\r\nRuntimeError: received 0 items of ancdata\r\n```\r\n\r\nThe i number always becomes 1015 in the environment.\r\n\r\nIn this case this error would be caused by the limitation of the number of file descriptors. In my setting, \"ulimit -n\" gives 1024 and if the limitation is changed to the lower number, the i gets the lower number by that amount."}