{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12261", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12261/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12261/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12261/events", "html_url": "https://github.com/pytorch/pytorch/issues/12261", "id": 365986860, "node_id": "MDU6SXNzdWUzNjU5ODY4NjA=", "number": 12261, "title": "Deprecated gloo-based DDP modules are not pickleable: TypeError: can't pickle thread.lock objects", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953883, "node_id": "MDU6TGFiZWw2Nzk5NTM4ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributed", "name": "distributed", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-02T16:47:56Z", "updated_at": "2018-11-15T23:47:24Z", "closed_at": "2018-11-15T23:47:24Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Apply this patch:</li>\n</ol>\n<pre><code>diff --git a/test/test_thd_distributed.py b/test/test_thd_distributed.py\nindex a104baeb3..032b2dd58 100644\n--- a/test/test_thd_distributed.py\n+++ b/test/test_thd_distributed.py\n@@ -8,6 +8,7 @@ import time\n import unittest\n from contextlib import contextmanager\n from functools import reduce, wraps\n+import tempfile\n \n import torch\n import torch.cuda\n@@ -154,6 +155,22 @@ class Barrier(object):\n             time.sleep(0.1)\n \n \n+# The test network must live at top level so we can test pickling it.\n+class Net(nn.Module):\n+    def __init__(self):\n+        super(Net, self).__init__()\n+        self.fc1 = nn.Linear(2, 10, bias=False)\n+        self.fc2 = nn.Linear(10, 50, bias=False)\n+        self.fc3 = nn.Linear(50, 4, bias=False)\n+        self.relu = nn.ReLU()\n+\n+    def forward(self, x):\n+        x = self.relu(self.fc1(x))\n+        x = self.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return F.softmax(x, dim=1)\n+\n+\n class _DistTestBase(object):\n     def _barrier(self, *args, **kwargs):\n         Barrier.sync(*args, **kwargs)\n@@ -896,20 +913,6 @@ class _DistTestBase(object):\n         self._test_all_gather_multigpu_helper(group, group_id, rank, rank_to_GPU)\n \n     def _create_Net(self):\n-        class Net(nn.Module):\n-            def __init__(self):\n-                super(Net, self).__init__()\n-                self.fc1 = nn.Linear(2, 10, bias=False)\n-                self.fc2 = nn.Linear(10, 50, bias=False)\n-                self.fc3 = nn.Linear(50, 4, bias=False)\n-                self.relu = nn.ReLU()\n-\n-            def forward(self, x):\n-                x = self.relu(self.fc1(x))\n-                x = self.relu(self.fc2(x))\n-                x = self.fc3(x)\n-                return F.softmax(x, dim=1)\n-\n         return Net()\n \n     def _model_step(self, model):\n@@ -962,6 +965,12 @@ class _DistTestBase(object):\n             # Shuffle the input so that DDP input is different\n             input = input[torch.randperm(batch_size)]\n \n+        # Test that saving and loading works\n+        tmp_file = tempfile.TemporaryFile()\n+        torch.save(model_DDP, tmp_file)\n+        tmp_file.seek(0)\n+        saved_model_DDP = torch.load(tmp_file)\n+\n     @unittest.skipIf(\n         BACKEND != \"nccl\" and BACKEND != \"gloo\",\n         \"Only Nccl &amp; Gloo backend support DistributedDataParallel\",\n</code></pre>\n<p>Run the thd_distributed tests for gloo backend. (I actually don't know how to do this locally; I can only do it on CI; see <a href=\"https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-linux-xenial-cuda9-cudnn7-py2-test2/11715/console\" rel=\"nofollow\">https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-linux-xenial-cuda9-cudnn7-py2-test2/11715/console</a> )</p>\n<p>I get:</p>\n<pre><code>17:31:06 test_DistributedDataParallel (__main__.TestDistBackend) ... Process process 0:\n17:31:09 Process process 1:\n17:31:09 Traceback (most recent call last):\n17:31:09 Traceback (most recent call last):\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n17:31:09     self.run()\n17:31:09     self.run()\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n17:31:09     self._target(*self._args, **self._kwargs)\n17:31:09     self._target(*self._args, **self._kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\n17:31:09     getattr(self, self.id().split(\".\")[2])()\n17:31:09     getattr(self, self.id().split(\".\")[2])()\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\n17:31:09     fn(self)\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\n17:31:09     fn(self)\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\n17:31:09     return func(*args, **kwargs)\n17:31:09     global_bs,\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\n17:31:09     torch.save(model_DDP, tmp_file)\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\n17:31:09     global_bs,\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\n17:31:09     torch.save(model_DDP, tmp_file)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\n17:31:09     return body(f)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in &lt;lambda&gt;\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09     pickler.dump(obj)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\n17:31:09 TypeError: can't pickle thread.lock objects\n17:31:09     return body(f)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in &lt;lambda&gt;\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\n17:31:09     pickler.dump(obj)\n17:31:09 TypeError: can't pickle thread.lock objects\n</code></pre>\n<p>I don't intend on fixing this unless someone shouts.</p>", "body_text": "To Reproduce\nSteps to reproduce the behavior:\n\nApply this patch:\n\ndiff --git a/test/test_thd_distributed.py b/test/test_thd_distributed.py\nindex a104baeb3..032b2dd58 100644\n--- a/test/test_thd_distributed.py\n+++ b/test/test_thd_distributed.py\n@@ -8,6 +8,7 @@ import time\n import unittest\n from contextlib import contextmanager\n from functools import reduce, wraps\n+import tempfile\n \n import torch\n import torch.cuda\n@@ -154,6 +155,22 @@ class Barrier(object):\n             time.sleep(0.1)\n \n \n+# The test network must live at top level so we can test pickling it.\n+class Net(nn.Module):\n+    def __init__(self):\n+        super(Net, self).__init__()\n+        self.fc1 = nn.Linear(2, 10, bias=False)\n+        self.fc2 = nn.Linear(10, 50, bias=False)\n+        self.fc3 = nn.Linear(50, 4, bias=False)\n+        self.relu = nn.ReLU()\n+\n+    def forward(self, x):\n+        x = self.relu(self.fc1(x))\n+        x = self.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return F.softmax(x, dim=1)\n+\n+\n class _DistTestBase(object):\n     def _barrier(self, *args, **kwargs):\n         Barrier.sync(*args, **kwargs)\n@@ -896,20 +913,6 @@ class _DistTestBase(object):\n         self._test_all_gather_multigpu_helper(group, group_id, rank, rank_to_GPU)\n \n     def _create_Net(self):\n-        class Net(nn.Module):\n-            def __init__(self):\n-                super(Net, self).__init__()\n-                self.fc1 = nn.Linear(2, 10, bias=False)\n-                self.fc2 = nn.Linear(10, 50, bias=False)\n-                self.fc3 = nn.Linear(50, 4, bias=False)\n-                self.relu = nn.ReLU()\n-\n-            def forward(self, x):\n-                x = self.relu(self.fc1(x))\n-                x = self.relu(self.fc2(x))\n-                x = self.fc3(x)\n-                return F.softmax(x, dim=1)\n-\n         return Net()\n \n     def _model_step(self, model):\n@@ -962,6 +965,12 @@ class _DistTestBase(object):\n             # Shuffle the input so that DDP input is different\n             input = input[torch.randperm(batch_size)]\n \n+        # Test that saving and loading works\n+        tmp_file = tempfile.TemporaryFile()\n+        torch.save(model_DDP, tmp_file)\n+        tmp_file.seek(0)\n+        saved_model_DDP = torch.load(tmp_file)\n+\n     @unittest.skipIf(\n         BACKEND != \"nccl\" and BACKEND != \"gloo\",\n         \"Only Nccl & Gloo backend support DistributedDataParallel\",\n\nRun the thd_distributed tests for gloo backend. (I actually don't know how to do this locally; I can only do it on CI; see https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-linux-xenial-cuda9-cudnn7-py2-test2/11715/console )\nI get:\n17:31:06 test_DistributedDataParallel (__main__.TestDistBackend) ... Process process 0:\n17:31:09 Process process 1:\n17:31:09 Traceback (most recent call last):\n17:31:09 Traceback (most recent call last):\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n17:31:09     self.run()\n17:31:09     self.run()\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\n17:31:09     self._target(*self._args, **self._kwargs)\n17:31:09     self._target(*self._args, **self._kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\n17:31:09     getattr(self, self.id().split(\".\")[2])()\n17:31:09     getattr(self, self.id().split(\".\")[2])()\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\n17:31:09     fn(self)\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\n17:31:09     fn(self)\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\n17:31:09     return func(*args, **kwargs)\n17:31:09     global_bs,\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\n17:31:09     torch.save(model_DDP, tmp_file)\n17:31:09     return func(*args, **kwargs)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\n17:31:09     global_bs,\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\n17:31:09     torch.save(model_DDP, tmp_file)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\n17:31:09     return body(f)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in <lambda>\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09     pickler.dump(obj)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\n17:31:09 TypeError: can't pickle thread.lock objects\n17:31:09     return body(f)\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in <lambda>\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\n17:31:09     pickler.dump(obj)\n17:31:09 TypeError: can't pickle thread.lock objects\n\nI don't intend on fixing this unless someone shouts.", "body": "## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Apply this patch:\r\n\r\n```\r\ndiff --git a/test/test_thd_distributed.py b/test/test_thd_distributed.py\r\nindex a104baeb3..032b2dd58 100644\r\n--- a/test/test_thd_distributed.py\r\n+++ b/test/test_thd_distributed.py\r\n@@ -8,6 +8,7 @@ import time\r\n import unittest\r\n from contextlib import contextmanager\r\n from functools import reduce, wraps\r\n+import tempfile\r\n \r\n import torch\r\n import torch.cuda\r\n@@ -154,6 +155,22 @@ class Barrier(object):\r\n             time.sleep(0.1)\r\n \r\n \r\n+# The test network must live at top level so we can test pickling it.\r\n+class Net(nn.Module):\r\n+    def __init__(self):\r\n+        super(Net, self).__init__()\r\n+        self.fc1 = nn.Linear(2, 10, bias=False)\r\n+        self.fc2 = nn.Linear(10, 50, bias=False)\r\n+        self.fc3 = nn.Linear(50, 4, bias=False)\r\n+        self.relu = nn.ReLU()\r\n+\r\n+    def forward(self, x):\r\n+        x = self.relu(self.fc1(x))\r\n+        x = self.relu(self.fc2(x))\r\n+        x = self.fc3(x)\r\n+        return F.softmax(x, dim=1)\r\n+\r\n+\r\n class _DistTestBase(object):\r\n     def _barrier(self, *args, **kwargs):\r\n         Barrier.sync(*args, **kwargs)\r\n@@ -896,20 +913,6 @@ class _DistTestBase(object):\r\n         self._test_all_gather_multigpu_helper(group, group_id, rank, rank_to_GPU)\r\n \r\n     def _create_Net(self):\r\n-        class Net(nn.Module):\r\n-            def __init__(self):\r\n-                super(Net, self).__init__()\r\n-                self.fc1 = nn.Linear(2, 10, bias=False)\r\n-                self.fc2 = nn.Linear(10, 50, bias=False)\r\n-                self.fc3 = nn.Linear(50, 4, bias=False)\r\n-                self.relu = nn.ReLU()\r\n-\r\n-            def forward(self, x):\r\n-                x = self.relu(self.fc1(x))\r\n-                x = self.relu(self.fc2(x))\r\n-                x = self.fc3(x)\r\n-                return F.softmax(x, dim=1)\r\n-\r\n         return Net()\r\n \r\n     def _model_step(self, model):\r\n@@ -962,6 +965,12 @@ class _DistTestBase(object):\r\n             # Shuffle the input so that DDP input is different\r\n             input = input[torch.randperm(batch_size)]\r\n \r\n+        # Test that saving and loading works\r\n+        tmp_file = tempfile.TemporaryFile()\r\n+        torch.save(model_DDP, tmp_file)\r\n+        tmp_file.seek(0)\r\n+        saved_model_DDP = torch.load(tmp_file)\r\n+\r\n     @unittest.skipIf(\r\n         BACKEND != \"nccl\" and BACKEND != \"gloo\",\r\n         \"Only Nccl & Gloo backend support DistributedDataParallel\",\r\n```\r\n\r\nRun the thd_distributed tests for gloo backend. (I actually don't know how to do this locally; I can only do it on CI; see https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-linux-xenial-cuda9-cudnn7-py2-test2/11715/console )\r\n\r\nI get:\r\n\r\n```\r\n17:31:06 test_DistributedDataParallel (__main__.TestDistBackend) ... Process process 0:\r\n17:31:09 Process process 1:\r\n17:31:09 Traceback (most recent call last):\r\n17:31:09 Traceback (most recent call last):\r\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\r\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\r\n17:31:09     self.run()\r\n17:31:09     self.run()\r\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n17:31:09   File \"/opt/conda/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n17:31:09     self._target(*self._args, **self._kwargs)\r\n17:31:09     self._target(*self._args, **self._kwargs)\r\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\r\n17:31:09   File \"test_thd_distributed.py\", line 1102, in _run\r\n17:31:09     getattr(self, self.id().split(\".\")[2])()\r\n17:31:09     getattr(self, self.id().split(\".\")[2])()\r\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\r\n17:31:09   File \"test_thd_distributed.py\", line 1057, in wrapper\r\n17:31:09     fn(self)\r\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\r\n17:31:09     fn(self)\r\n17:31:09     return func(*args, **kwargs)\r\n17:31:09   File \"test_thd_distributed.py\", line 59, in wrapper\r\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\r\n17:31:09     return func(*args, **kwargs)\r\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\r\n17:31:09     return func(*args, **kwargs)\r\n17:31:09     global_bs,\r\n17:31:09   File \"test_thd_distributed.py\", line 75, in wrapper\r\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\r\n17:31:09     torch.save(model_DDP, tmp_file)\r\n17:31:09     return func(*args, **kwargs)\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\r\n17:31:09   File \"test_thd_distributed.py\", line 1014, in test_DistributedDataParallel\r\n17:31:09     global_bs,\r\n17:31:09   File \"test_thd_distributed.py\", line 970, in _test_DDP_2iter\r\n17:31:09     torch.save(model_DDP, tmp_file)\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in save\r\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\r\n17:31:09     return body(f)\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in <lambda>\r\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\r\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n17:31:09     pickler.dump(obj)\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 134, in _with_file_like\r\n17:31:09 TypeError: can't pickle thread.lock objects\r\n17:31:09     return body(f)\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 209, in <lambda>\r\n17:31:09     return _with_file_like(f, \"wb\", lambda f: _save(obj, f, pickle_module, pickle_protocol))\r\n17:31:09   File \"/opt/conda/lib/python2.7/site-packages/torch/serialization.py\", line 282, in _save\r\n17:31:09     pickler.dump(obj)\r\n17:31:09 TypeError: can't pickle thread.lock objects\r\n```\r\n\r\nI don't intend on fixing this unless someone shouts."}