{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212669248", "pull_request_review_id": 149354306, "id": 212669248, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjY2OTI0OA==", "diff_hunk": "@@ -272,15 +261,7 @@ struct GraphFuser {\n     // allUsersAreThisConsumerOrOccurAfterIt would still be satisfied. However, I don't expect this\n     // to be necessary any time soon, and so we're simply assuming that we don't have to deal with that.\n     if (tensors_node->output()->uses().size() > 1) return false;\n-    auto tensors = tensors_node->inputs();\n-\n-    // Our fusion code assumes that all inputs have the same shapes, so we need to check this too.\n-    auto expected = tensors.at(0)->type()->cast<TensorType>();\n-    if (!expected) return false;\n-    return std::all_of(tensors.begin(), tensors.end(), [&expected](Value *v) {\n-        auto actual = v->type()->cast<TensorType>();\n-        return actual && actual->sizes() == expected->sizes();\n-    });", "path": "torch/csrc/jit/passes/graph_fuser.cpp", "position": 38, "original_position": 38, "commit_id": "acc2435ce6aed9b51258e32ff56124a11eaacd82", "original_commit_id": "5c300b6e70abb13121d37deac2f2bb9563d92a7b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Oh, my point is that testing for complete information doesn't really make sense, because it really shouldn't be available to this pass. Optimizations at the GraphExecutor level will see *only* `TensorType` and almost never `CompleteTensorType` (maybe except for some mostly constant subgraphs). \r\n\r\nYou do have a point, but:\r\n- It's a temporary state. We need to get this out to unblock splitting the fusers, and the deoptimization path can be easily improved in the future.\r\n- The condition you referred to here is about inputs to concat. I'm pretty sure that the real world examples outside of RNNs will cause us much more trouble because of moving the broadcasts earlier in the graph, or simply having different numbers of elements in different parts of the graph. Irregular cats and chunks are not all that common I think.", "created_at": "2018-08-24T15:37:32Z", "updated_at": "2018-11-23T15:49:56Z", "html_url": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212669248", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10844", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212669248"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212669248"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10844"}}, "body_html": "<p>Oh, my point is that testing for complete information doesn't really make sense, because it really shouldn't be available to this pass. Optimizations at the GraphExecutor level will see <em>only</em> <code>TensorType</code> and almost never <code>CompleteTensorType</code> (maybe except for some mostly constant subgraphs).</p>\n<p>You do have a point, but:</p>\n<ul>\n<li>It's a temporary state. We need to get this out to unblock splitting the fusers, and the deoptimization path can be easily improved in the future.</li>\n<li>The condition you referred to here is about inputs to concat. I'm pretty sure that the real world examples outside of RNNs will cause us much more trouble because of moving the broadcasts earlier in the graph, or simply having different numbers of elements in different parts of the graph. Irregular cats and chunks are not all that common I think.</li>\n</ul>", "body_text": "Oh, my point is that testing for complete information doesn't really make sense, because it really shouldn't be available to this pass. Optimizations at the GraphExecutor level will see only TensorType and almost never CompleteTensorType (maybe except for some mostly constant subgraphs).\nYou do have a point, but:\n\nIt's a temporary state. We need to get this out to unblock splitting the fusers, and the deoptimization path can be easily improved in the future.\nThe condition you referred to here is about inputs to concat. I'm pretty sure that the real world examples outside of RNNs will cause us much more trouble because of moving the broadcasts earlier in the graph, or simply having different numbers of elements in different parts of the graph. Irregular cats and chunks are not all that common I think.", "in_reply_to_id": 212663899}