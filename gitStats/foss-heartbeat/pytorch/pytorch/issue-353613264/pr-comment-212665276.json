{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212665276", "pull_request_review_id": 149349519, "id": 212665276, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjY2NTI3Ng==", "diff_hunk": "@@ -272,15 +261,7 @@ struct GraphFuser {\n     // allUsersAreThisConsumerOrOccurAfterIt would still be satisfied. However, I don't expect this\n     // to be necessary any time soon, and so we're simply assuming that we don't have to deal with that.\n     if (tensors_node->output()->uses().size() > 1) return false;\n-    auto tensors = tensors_node->inputs();\n-\n-    // Our fusion code assumes that all inputs have the same shapes, so we need to check this too.\n-    auto expected = tensors.at(0)->type()->cast<TensorType>();\n-    if (!expected) return false;\n-    return std::all_of(tensors.begin(), tensors.end(), [&expected](Value *v) {\n-        auto actual = v->type()->cast<TensorType>();\n-        return actual && actual->sizes() == expected->sizes();\n-    });", "path": "torch/csrc/jit/passes/graph_fuser.cpp", "position": 38, "original_position": 38, "commit_id": "acc2435ce6aed9b51258e32ff56124a11eaacd82", "original_commit_id": "5c300b6e70abb13121d37deac2f2bb9563d92a7b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Not sure why you're saying \"another way to do it\", because that's exactly what we do now - optimistically assume that all the fusion opportunities we have are valid, and hope for the best.\r\n\r\nI think the general direction for the future is to keep slicing as large fused subgraphs as we can, and to only deoptimize the incorrect parts when we detect that they're invalid in the fusion compiler (instead of having a complete fallback). Having said this, this code doesn't cause a single regression in our tests. I verified that the checks always pass.", "created_at": "2018-08-24T15:25:01Z", "updated_at": "2018-11-23T15:49:55Z", "html_url": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212665276", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10844", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212665276"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212665276"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10844"}}, "body_html": "<p>Not sure why you're saying \"another way to do it\", because that's exactly what we do now - optimistically assume that all the fusion opportunities we have are valid, and hope for the best.</p>\n<p>I think the general direction for the future is to keep slicing as large fused subgraphs as we can, and to only deoptimize the incorrect parts when we detect that they're invalid in the fusion compiler (instead of having a complete fallback). Having said this, this code doesn't cause a single regression in our tests. I verified that the checks always pass.</p>", "body_text": "Not sure why you're saying \"another way to do it\", because that's exactly what we do now - optimistically assume that all the fusion opportunities we have are valid, and hope for the best.\nI think the general direction for the future is to keep slicing as large fused subgraphs as we can, and to only deoptimize the incorrect parts when we detect that they're invalid in the fusion compiler (instead of having a complete fallback). Having said this, this code doesn't cause a single regression in our tests. I verified that the checks always pass.", "in_reply_to_id": 212663899}