{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212658504", "pull_request_review_id": 149341112, "id": 212658504, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjY1ODUwNA==", "diff_hunk": "@@ -183,22 +248,22 @@ struct TORCH_API TensorType : public Type {\n   }\n   static TypePtr fromNumberType(TypePtr typ);\n \n+  static CompleteTensorTypePtr sliceSubtypes(const CompleteTensorTypePtr& type) {", "path": "torch/csrc/jit/type.h", "position": null, "original_position": 186, "commit_id": "acc2435ce6aed9b51258e32ff56124a11eaacd82", "original_commit_id": "5c300b6e70abb13121d37deac2f2bb9563d92a7b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I think I'll slightly change this part before we merge it. There's a subtlety in when you do `type_ptr->cast<TensorType>()`, because if it's a `CompleteTensorType`, it will give you a `TensorTypePtr`. Now, if you later do `node->output()->setType(type->expect<TensorType>())`, then your code probably assumes that you don't care about the sizes, but in reality you never sliced the derived object to the `TensorType` superclass, and so `node->output()` will also inherit its shapes and strides, which might not be valid.\r\n\r\nI discovered this because it caused a bug in shape prop. I had a `chunk` with an input with `CompleteTensorType`, it didn't have a case in the complete-shape case, but it did fit into the simplified function, where it simply did\r\n```cpp\r\nstd::vector<TensorTypePtr> tensor_types;\r\n...\r\nfor (Value * output : node->outputs()) {\r\n  output->setType(tensor_types.at(0));\r\n}\r\n```\r\nthus inheriting pre-chunk sizes in the output, which is obviously incorrect.", "created_at": "2018-08-24T15:03:18Z", "updated_at": "2018-11-23T15:49:54Z", "html_url": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212658504", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10844", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212658504"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10844#discussion_r212658504"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10844"}}, "body_html": "<p>I think I'll slightly change this part before we merge it. There's a subtlety in when you do <code>type_ptr-&gt;cast&lt;TensorType&gt;()</code>, because if it's a <code>CompleteTensorType</code>, it will give you a <code>TensorTypePtr</code>. Now, if you later do <code>node-&gt;output()-&gt;setType(type-&gt;expect&lt;TensorType&gt;())</code>, then your code probably assumes that you don't care about the sizes, but in reality you never sliced the derived object to the <code>TensorType</code> superclass, and so <code>node-&gt;output()</code> will also inherit its shapes and strides, which might not be valid.</p>\n<p>I discovered this because it caused a bug in shape prop. I had a <code>chunk</code> with an input with <code>CompleteTensorType</code>, it didn't have a case in the complete-shape case, but it did fit into the simplified function, where it simply did</p>\n<div class=\"highlight highlight-source-c++\"><pre>std::vector&lt;TensorTypePtr&gt; tensor_types;\n...\n<span class=\"pl-k\">for</span> (Value * output : node-&gt;<span class=\"pl-en\">outputs</span>()) {\n  output-&gt;<span class=\"pl-c1\">setType</span>(tensor_types.<span class=\"pl-c1\">at</span>(<span class=\"pl-c1\">0</span>));\n}</pre></div>\n<p>thus inheriting pre-chunk sizes in the output, which is obviously incorrect.</p>", "body_text": "I think I'll slightly change this part before we merge it. There's a subtlety in when you do type_ptr->cast<TensorType>(), because if it's a CompleteTensorType, it will give you a TensorTypePtr. Now, if you later do node->output()->setType(type->expect<TensorType>()), then your code probably assumes that you don't care about the sizes, but in reality you never sliced the derived object to the TensorType superclass, and so node->output() will also inherit its shapes and strides, which might not be valid.\nI discovered this because it caused a bug in shape prop. I had a chunk with an input with CompleteTensorType, it didn't have a case in the complete-shape case, but it did fit into the simplified function, where it simply did\nstd::vector<TensorTypePtr> tensor_types;\n...\nfor (Value * output : node->outputs()) {\n  output->setType(tensor_types.at(0));\n}\nthus inheriting pre-chunk sizes in the output, which is obviously incorrect.", "in_reply_to_id": 212651711}