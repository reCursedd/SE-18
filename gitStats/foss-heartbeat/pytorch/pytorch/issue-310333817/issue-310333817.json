{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6171", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6171/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6171/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6171/events", "html_url": "https://github.com/pytorch/pytorch/issues/6171", "id": 310333817, "node_id": "MDU6SXNzdWUzMTAzMzM4MTc=", "number": 6171, "title": "Compute csr representation on torch.sparse.Tensor.coalesce for faster sparse matrix multiplication ", "user": {"login": "kose-y", "id": 8198142, "node_id": "MDQ6VXNlcjgxOTgxNDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8198142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kose-y", "html_url": "https://github.com/kose-y", "followers_url": "https://api.github.com/users/kose-y/followers", "following_url": "https://api.github.com/users/kose-y/following{/other_user}", "gists_url": "https://api.github.com/users/kose-y/gists{/gist_id}", "starred_url": "https://api.github.com/users/kose-y/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kose-y/subscriptions", "organizations_url": "https://api.github.com/users/kose-y/orgs", "repos_url": "https://api.github.com/users/kose-y/repos", "events_url": "https://api.github.com/users/kose-y/events{/privacy}", "received_events_url": "https://api.github.com/users/kose-y/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679954154, "node_id": "MDU6TGFiZWw2Nzk5NTQxNTQ=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/sparse", "name": "sparse", "color": "bfd4f2", "default": false}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-04-01T15:56:41Z", "updated_at": "2018-09-12T21:24:29Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>On the code on sparse matrix-dense matrix multiplication<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensorMath.c#L305\">https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensorMath.c#L305</a><br>\nand<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensorMath.cu#L58\">https://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensorMath.cu#L58</a> ,<br>\nit first computes csr representation, then perform sparse matrix-dense matrix multiplication based on that representation, then destroy the csr representation.<br>\nIf we repeatedly perform matrix multiplication on the same sparse matrix, computing csr representation is redundant. This could be resolved by computing csr representation only once when coalescing  and save it as a member of <code>THSTensor</code> or <code>THCSTensor</code> ( <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensor.cpp#L428\">https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensor.cpp#L428</a> and<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensor.cu#L38\">https://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensor.cu#L38</a> ). This would enhance speed of sparse matrix-dense matrix multiplication.</p>\n<p>Will this be a good modification? Shall I try to make a pull request on this one?</p>", "body_text": "On the code on sparse matrix-dense matrix multiplication\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensorMath.c#L305\nand\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensorMath.cu#L58 ,\nit first computes csr representation, then perform sparse matrix-dense matrix multiplication based on that representation, then destroy the csr representation.\nIf we repeatedly perform matrix multiplication on the same sparse matrix, computing csr representation is redundant. This could be resolved by computing csr representation only once when coalescing  and save it as a member of THSTensor or THCSTensor ( https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensor.cpp#L428 and\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensor.cu#L38 ). This would enhance speed of sparse matrix-dense matrix multiplication.\nWill this be a good modification? Shall I try to make a pull request on this one?", "body": "On the code on sparse matrix-dense matrix multiplication\r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensorMath.c#L305\r\nand \r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensorMath.cu#L58 , \r\nit first computes csr representation, then perform sparse matrix-dense matrix multiplication based on that representation, then destroy the csr representation. \r\nIf we repeatedly perform matrix multiplication on the same sparse matrix, computing csr representation is redundant. This could be resolved by computing csr representation only once when coalescing  and save it as a member of `THSTensor` or `THCSTensor` ( https://github.com/pytorch/pytorch/blob/master/aten/src/THS/generic/THSTensor.cpp#L428 and\r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/THCS/generic/THCSTensor.cu#L38 ). This would enhance speed of sparse matrix-dense matrix multiplication.\r\n\r\nWill this be a good modification? Shall I try to make a pull request on this one?\r\n\r\n"}