{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428374331", "html_url": "https://github.com/pytorch/pytorch/issues/9996#issuecomment-428374331", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9996", "id": 428374331, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODM3NDMzMQ==", "user": {"login": "known-ai", "id": 8900094, "node_id": "MDQ6VXNlcjg5MDAwOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/8900094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/known-ai", "html_url": "https://github.com/known-ai", "followers_url": "https://api.github.com/users/known-ai/followers", "following_url": "https://api.github.com/users/known-ai/following{/other_user}", "gists_url": "https://api.github.com/users/known-ai/gists{/gist_id}", "starred_url": "https://api.github.com/users/known-ai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/known-ai/subscriptions", "organizations_url": "https://api.github.com/users/known-ai/orgs", "repos_url": "https://api.github.com/users/known-ai/repos", "events_url": "https://api.github.com/users/known-ai/events{/privacy}", "received_events_url": "https://api.github.com/users/known-ai/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-09T22:25:40Z", "updated_at": "2018-10-09T22:25:40Z", "author_association": "NONE", "body_html": "<p>I'm having the same problem:</p>\n<p>Traceback (most recent call last):<br>\nFile \"seq2seq_translation_tutorial.py\", line 829, in <br>\np.start()<br>\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start<br>\nself._popen = self._Popen(self)<br>\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen<br>\nreturn _default_context.get_context().Process._Popen(process_obj)<br>\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen<br>\nreturn Popen(process_obj)<br>\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in <strong>init</strong><br>\nreduction.dump(process_obj, to_child)<br>\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump<br>\nForkingPickler(file, protocol).dump(obj)<br>\nFile \"C:\\Anaconda3\\lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 179, in reduce_storage<br>\nraise RuntimeError(\"Cannot pickle CUDA storage; try pickling a CUDA tensor instead\")<br>\nRuntimeError: Cannot pickle CUDA storage; try pickling a CUDA tensor instead</p>\n<p>I've converted the seq2seq_translation_tutorial.py code to run in hogwild mode.</p>\n<pre><code>encoder1 = EncoderRNN(input_lang.n_words, hidden_size, input_lang).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, output_lang, dropout_p=0.1).to(device)\nencoder1.share_memory()\nattn_decoder1.share_memory()\nlearning_rate = 0.01\nencoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\ndecoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\ncriterion = nn.NLLLoss()\nlogger.info(\"training\")\nprocesses = []\nnum_processes = 10\nfor rank in range(num_processes):\n    p = mp.Process(target=train, args=(encoder1, attn_decoder1, 7500,  encoder_optimizer, decoder_optimizer, criterion, input_lang, output_lang, pairs, 500, 100, learning_rate))\n    p.start()\n    processes.append(p)\nfor p in processes:\n    p.join()\n</code></pre>\n<p>Latest nightly build of pytorch per the above, cuda 9.2, running Anaconda3 on Windows10</p>", "body_text": "I'm having the same problem:\nTraceback (most recent call last):\nFile \"seq2seq_translation_tutorial.py\", line 829, in \np.start()\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\nself._popen = self._Popen(self)\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\nreturn _default_context.get_context().Process._Popen(process_obj)\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\nreturn Popen(process_obj)\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in init\nreduction.dump(process_obj, to_child)\nFile \"C:\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\nForkingPickler(file, protocol).dump(obj)\nFile \"C:\\Anaconda3\\lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 179, in reduce_storage\nraise RuntimeError(\"Cannot pickle CUDA storage; try pickling a CUDA tensor instead\")\nRuntimeError: Cannot pickle CUDA storage; try pickling a CUDA tensor instead\nI've converted the seq2seq_translation_tutorial.py code to run in hogwild mode.\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size, input_lang).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, output_lang, dropout_p=0.1).to(device)\nencoder1.share_memory()\nattn_decoder1.share_memory()\nlearning_rate = 0.01\nencoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\ndecoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\ncriterion = nn.NLLLoss()\nlogger.info(\"training\")\nprocesses = []\nnum_processes = 10\nfor rank in range(num_processes):\n    p = mp.Process(target=train, args=(encoder1, attn_decoder1, 7500,  encoder_optimizer, decoder_optimizer, criterion, input_lang, output_lang, pairs, 500, 100, learning_rate))\n    p.start()\n    processes.append(p)\nfor p in processes:\n    p.join()\n\nLatest nightly build of pytorch per the above, cuda 9.2, running Anaconda3 on Windows10", "body": "I'm having the same problem:\r\n\r\nTraceback (most recent call last):\r\n  File \"seq2seq_translation_tutorial.py\", line 829, in <module>\r\n    p.start()\r\n  File \"C:\\Anaconda3\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"C:\\Anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"C:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n  File \"C:\\Anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 179, in reduce_storage\r\n    raise RuntimeError(\"Cannot pickle CUDA storage; try pickling a CUDA tensor instead\")\r\nRuntimeError: Cannot pickle CUDA storage; try pickling a CUDA tensor instead\r\n\r\nI've converted the seq2seq_translation_tutorial.py code to run in hogwild mode.\r\n\r\n    encoder1 = EncoderRNN(input_lang.n_words, hidden_size, input_lang).to(device)\r\n    attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, output_lang, dropout_p=0.1).to(device)\r\n    encoder1.share_memory()\r\n    attn_decoder1.share_memory()\r\n    learning_rate = 0.01\r\n    encoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\r\n    decoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\r\n    criterion = nn.NLLLoss()\r\n    logger.info(\"training\")\r\n    processes = []\r\n    num_processes = 10\r\n    for rank in range(num_processes):\r\n        p = mp.Process(target=train, args=(encoder1, attn_decoder1, 7500,  encoder_optimizer, decoder_optimizer, criterion, input_lang, output_lang, pairs, 500, 100, learning_rate))\r\n        p.start()\r\n        processes.append(p)\r\n    for p in processes:\r\n        p.join()\r\n\r\nLatest nightly build of pytorch per the above, cuda 9.2, running Anaconda3 on Windows10"}