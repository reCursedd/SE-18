{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171093088", "pull_request_review_id": 99886178, "id": 171093088, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTA5MzA4OA==", "diff_hunk": "@@ -5,10 +5,13 @@\n #include <sstream>\n \n #include \"torch/csrc/assertions.h\"\n+#include \"torch/csrc/Dtype.h\"\n+#include \"torch/csrc/DynamicTypes.h\"\n #include \"torch/csrc/Exceptions.h\"\n #include \"torch/csrc/autograd/variable.h\"\n #include \"torch/csrc/autograd/python_variable.h\"\n #include \"torch/csrc/autograd/generated/VariableType.h\"\n+#include \"torch/csrc/autograd/utils/wrap_outputs.h\"", "path": "torch/csrc/tensor/python_tensor.cpp", "position": 10, "original_position": 10, "commit_id": "a77fd18c5b00db0507dda0498045e43382f3c1a2", "original_commit_id": "2922aa5f21c36746daa3ae22edb00fc807d4f99b", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "To return the dtype we call:\r\n```\r\nreturn torch::autograd::utils::wrap(self->dtype);\r\n```\r\n\r\nwhich just does a Py_INCREF(dtype); it seemed nice to reuse that function but I'm fine changing it.", "created_at": "2018-02-27T22:47:25Z", "updated_at": "2018-11-23T15:40:05Z", "html_url": "https://github.com/pytorch/pytorch/pull/5444#discussion_r171093088", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5444", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171093088"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5444#discussion_r171093088"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5444"}}, "body_html": "<p>To return the dtype we call:</p>\n<pre><code>return torch::autograd::utils::wrap(self-&gt;dtype);\n</code></pre>\n<p>which just does a Py_INCREF(dtype); it seemed nice to reuse that function but I'm fine changing it.</p>", "body_text": "To return the dtype we call:\nreturn torch::autograd::utils::wrap(self->dtype);\n\nwhich just does a Py_INCREF(dtype); it seemed nice to reuse that function but I'm fine changing it.", "in_reply_to_id": 171090799}