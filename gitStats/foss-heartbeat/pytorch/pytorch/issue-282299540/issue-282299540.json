{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4188", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4188/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4188/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4188/events", "html_url": "https://github.com/pytorch/pytorch/issues/4188", "id": 282299540, "node_id": "MDU6SXNzdWUyODIyOTk1NDA=", "number": 4188, "title": "[Proposal] OMP overhead threshold setting", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-15T02:14:50Z", "updated_at": "2018-04-25T08:19:58Z", "closed_at": "2018-04-25T08:19:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Both the PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"258349266\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2764\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2764/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2764\">#2764</a> and the <a href=\"https://github.com/zy97140/omp-benchmark-for-pytorch\">benchmark</a> show:</p>\n<ul>\n<li>The optimal OpenMP threshold is dependent on the operation type and CPU type and tensors' contiguity.</li>\n<li>Setting OMP overhead threshold value to 100K in current version is not appropriate  for most operations in different types of CPU.</li>\n<li>Usually setting OMP overhead threshold value to1K will benefit these transcendental functions like sin, cos and exp from openmp.</li>\n<li>OpenMP threshold of discontiguous tensor is usually lower than that of contiguous tensor if the PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"258349266\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2764\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2764/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2764\">#2764</a> is accepted.</li>\n</ul>\n<p>However, evaluation of optimal overhead is very tricky and trivial because of complex conditions. There are two plans proposed by our team:</p>\n<ol>\n<li>Coarse setting:  Ignore the CPU types and follow the existing design but provide a set of threshold values for different operations and tensors' contiguity.</li>\n<li>Fine setting: Besides 1,  the specific threshold values are according to CPU types. Try to query CPU id and choose the corresponding threshold values when compiling pytorch.</li>\n</ol>", "body_text": "Both the PR #2764 and the benchmark show:\n\nThe optimal OpenMP threshold is dependent on the operation type and CPU type and tensors' contiguity.\nSetting OMP overhead threshold value to 100K in current version is not appropriate  for most operations in different types of CPU.\nUsually setting OMP overhead threshold value to1K will benefit these transcendental functions like sin, cos and exp from openmp.\nOpenMP threshold of discontiguous tensor is usually lower than that of contiguous tensor if the PR #2764 is accepted.\n\nHowever, evaluation of optimal overhead is very tricky and trivial because of complex conditions. There are two plans proposed by our team:\n\nCoarse setting:  Ignore the CPU types and follow the existing design but provide a set of threshold values for different operations and tensors' contiguity.\nFine setting: Besides 1,  the specific threshold values are according to CPU types. Try to query CPU id and choose the corresponding threshold values when compiling pytorch.", "body": "Both the PR #2764 and the [benchmark](https://github.com/zy97140/omp-benchmark-for-pytorch) show:   \r\n- The optimal OpenMP threshold is dependent on the operation type and CPU type and tensors' contiguity.  \r\n- Setting OMP overhead threshold value to 100K in current version is not appropriate  for most operations in different types of CPU.  \r\n- Usually setting OMP overhead threshold value to1K will benefit these transcendental functions like sin, cos and exp from openmp.  \r\n- OpenMP threshold of discontiguous tensor is usually lower than that of contiguous tensor if the PR #2764 is accepted.  \r\n\r\nHowever, evaluation of optimal overhead is very tricky and trivial because of complex conditions. There are two plans proposed by our team:\r\n1. Coarse setting:  Ignore the CPU types and follow the existing design but provide a set of threshold values for different operations and tensors' contiguity.  \r\n2. Fine setting: Besides 1,  the specific threshold values are according to CPU types. Try to query CPU id and choose the corresponding threshold values when compiling pytorch. "}