{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/387483031", "html_url": "https://github.com/pytorch/pytorch/issues/6879#issuecomment-387483031", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6879", "id": 387483031, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NzQ4MzAzMQ==", "user": {"login": "mathisdon", "id": 39098660, "node_id": "MDQ6VXNlcjM5MDk4NjYw", "avatar_url": "https://avatars0.githubusercontent.com/u/39098660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mathisdon", "html_url": "https://github.com/mathisdon", "followers_url": "https://api.github.com/users/mathisdon/followers", "following_url": "https://api.github.com/users/mathisdon/following{/other_user}", "gists_url": "https://api.github.com/users/mathisdon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mathisdon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mathisdon/subscriptions", "organizations_url": "https://api.github.com/users/mathisdon/orgs", "repos_url": "https://api.github.com/users/mathisdon/repos", "events_url": "https://api.github.com/users/mathisdon/events{/privacy}", "received_events_url": "https://api.github.com/users/mathisdon/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-08T17:38:59Z", "updated_at": "2018-05-08T17:38:59Z", "author_association": "NONE", "body_html": "<p>I interpret the Bias spec to be saying that in a single direction LSTM, the Bias tensor should have dimensions</p>\n<pre><code>    [1, 4*hidden_size]\n</code></pre>\n<blockquote>\n<p>B (optional) : T<br>\nThe bias tensor for input gate. Concatenation of <code>[Wb[iofc], Rb[iofc]]</code>, and <code>[WBb[iofc], RBb[iofc]]</code> (if bidirectional) along dimension 0. This tensor has shape <code>[num_directions, 8*hidden_size]</code>. Optional: If not specified - assumed to be 0.</p>\n</blockquote>", "body_text": "I interpret the Bias spec to be saying that in a single direction LSTM, the Bias tensor should have dimensions\n    [1, 4*hidden_size]\n\n\nB (optional) : T\nThe bias tensor for input gate. Concatenation of [Wb[iofc], Rb[iofc]], and [WBb[iofc], RBb[iofc]] (if bidirectional) along dimension 0. This tensor has shape [num_directions, 8*hidden_size]. Optional: If not specified - assumed to be 0.", "body": "I interpret the Bias spec to be saying that in a single direction LSTM, the Bias tensor should have dimensions\r\n\r\n        [1, 4*hidden_size]\r\n\r\n> B (optional) : T\r\n> The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0."}