{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10882", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10882/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10882/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10882/events", "html_url": "https://github.com/pytorch/pytorch/issues/10882", "id": 354072598, "node_id": "MDU6SXNzdWUzNTQwNzI1OTg=", "number": 10882, "title": "[ONNX] torch.ne and torch.expand_as are not symbolically defined.", "user": {"login": "ArmenAg", "id": 4429794, "node_id": "MDQ6VXNlcjQ0Mjk3OTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4429794?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArmenAg", "html_url": "https://github.com/ArmenAg", "followers_url": "https://api.github.com/users/ArmenAg/followers", "following_url": "https://api.github.com/users/ArmenAg/following{/other_user}", "gists_url": "https://api.github.com/users/ArmenAg/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArmenAg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArmenAg/subscriptions", "organizations_url": "https://api.github.com/users/ArmenAg/orgs", "repos_url": "https://api.github.com/users/ArmenAg/repos", "events_url": "https://api.github.com/users/ArmenAg/events{/privacy}", "received_events_url": "https://api.github.com/users/ArmenAg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-08-26T07:13:22Z", "updated_at": "2018-09-10T19:23:23Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>This toy piece of code cannot be exported through onnx:</p>\n<pre><code>import torch\nimport torch.nn as nn\n\nclass NEModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embedding = nn.Embedding(100,10)\n\n    def forward(self, x):\n        emb = self.embedding(x)\n        mask = torch.ne(x, 0)\n        return emb * mask.unsqueeze(2).expand_as(emb).float()\n\n\nx = torch.randint(0,100,(32,10),dtype=torch.long)\nmod = NEModule()\ntorch.onnx.export(mod, x, \"ne.onnx\", verbose=True)\n</code></pre>\n<p>Raising the exception:</p>\n<pre><code>UserWarning: ONNX export failed on ATen operator ne because torch.onnx.symbolic.ne does not exist\n  .format(op_name, op_name))\nUserWarning: ONNX export failed on ATen operator expand_as because torch.onnx.symbolic.expand_as does not exist\n\ngraph(%0 : Long(32, 10)\n      %1 : Float(100, 10)) {\n  %2 : Float(32, 10, 10) = onnx::Gather(%1, %0), scope: NEModule/Embedding[embedding]\n  %3 : Long() = onnx::Constant[value={0}]()\n  %4 : Byte(32, 10) = aten::ne(%0, %3), scope: NEModule\n  %5 : Byte(32, 10, 1) = onnx::Unsqueeze[axes=[2]](%4), scope: NEModule\n  %6 : Byte(32, 10!, 10!) = aten::expand_as(%5, %2), scope: NEModule\n  %7 : Float(32, 10, 10) = onnx::Cast[to=1](%6), scope: NEModule\n  %8 : Float(32, 10, 10) = onnx::Mul(%2, %7), scope: NEModule\n  return (%8);\n}\n</code></pre>\n<p>Implementing torch.ne is trivial through torch.eq and torch.neg in onnx/symbolic (since it seems onnx doesn't have a ne operator). I can work on this if there are no objections.</p>", "body_text": "This toy piece of code cannot be exported through onnx:\nimport torch\nimport torch.nn as nn\n\nclass NEModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embedding = nn.Embedding(100,10)\n\n    def forward(self, x):\n        emb = self.embedding(x)\n        mask = torch.ne(x, 0)\n        return emb * mask.unsqueeze(2).expand_as(emb).float()\n\n\nx = torch.randint(0,100,(32,10),dtype=torch.long)\nmod = NEModule()\ntorch.onnx.export(mod, x, \"ne.onnx\", verbose=True)\n\nRaising the exception:\nUserWarning: ONNX export failed on ATen operator ne because torch.onnx.symbolic.ne does not exist\n  .format(op_name, op_name))\nUserWarning: ONNX export failed on ATen operator expand_as because torch.onnx.symbolic.expand_as does not exist\n\ngraph(%0 : Long(32, 10)\n      %1 : Float(100, 10)) {\n  %2 : Float(32, 10, 10) = onnx::Gather(%1, %0), scope: NEModule/Embedding[embedding]\n  %3 : Long() = onnx::Constant[value={0}]()\n  %4 : Byte(32, 10) = aten::ne(%0, %3), scope: NEModule\n  %5 : Byte(32, 10, 1) = onnx::Unsqueeze[axes=[2]](%4), scope: NEModule\n  %6 : Byte(32, 10!, 10!) = aten::expand_as(%5, %2), scope: NEModule\n  %7 : Float(32, 10, 10) = onnx::Cast[to=1](%6), scope: NEModule\n  %8 : Float(32, 10, 10) = onnx::Mul(%2, %7), scope: NEModule\n  return (%8);\n}\n\nImplementing torch.ne is trivial through torch.eq and torch.neg in onnx/symbolic (since it seems onnx doesn't have a ne operator). I can work on this if there are no objections.", "body": "This toy piece of code cannot be exported through onnx:\r\n\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass NEModule(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.embedding = nn.Embedding(100,10)\r\n\r\n    def forward(self, x):\r\n        emb = self.embedding(x)\r\n        mask = torch.ne(x, 0)\r\n        return emb * mask.unsqueeze(2).expand_as(emb).float()\r\n\r\n\r\nx = torch.randint(0,100,(32,10),dtype=torch.long)\r\nmod = NEModule()\r\ntorch.onnx.export(mod, x, \"ne.onnx\", verbose=True)\r\n```\r\n\r\nRaising the exception: \r\n```\r\nUserWarning: ONNX export failed on ATen operator ne because torch.onnx.symbolic.ne does not exist\r\n  .format(op_name, op_name))\r\nUserWarning: ONNX export failed on ATen operator expand_as because torch.onnx.symbolic.expand_as does not exist\r\n\r\ngraph(%0 : Long(32, 10)\r\n      %1 : Float(100, 10)) {\r\n  %2 : Float(32, 10, 10) = onnx::Gather(%1, %0), scope: NEModule/Embedding[embedding]\r\n  %3 : Long() = onnx::Constant[value={0}]()\r\n  %4 : Byte(32, 10) = aten::ne(%0, %3), scope: NEModule\r\n  %5 : Byte(32, 10, 1) = onnx::Unsqueeze[axes=[2]](%4), scope: NEModule\r\n  %6 : Byte(32, 10!, 10!) = aten::expand_as(%5, %2), scope: NEModule\r\n  %7 : Float(32, 10, 10) = onnx::Cast[to=1](%6), scope: NEModule\r\n  %8 : Float(32, 10, 10) = onnx::Mul(%2, %7), scope: NEModule\r\n  return (%8);\r\n}\r\n```\r\n\r\nImplementing torch.ne is trivial through torch.eq and torch.neg in onnx/symbolic (since it seems onnx doesn't have a ne operator). I can work on this if there are no objections.\r\n"}