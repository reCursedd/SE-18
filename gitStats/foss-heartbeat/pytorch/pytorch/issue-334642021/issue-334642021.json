{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8765", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8765/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8765/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8765/events", "html_url": "https://github.com/pytorch/pytorch/pull/8765", "id": 334642021, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk2NTYzOTc5", "number": 8765, "title": "[c10d] Configurable number of algorithm entries per key", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953883, "node_id": "MDU6TGFiZWw2Nzk5NTM4ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributed", "name": "distributed", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-06-21T20:18:39Z", "updated_at": "2018-11-23T15:46:04Z", "closed_at": "2018-06-21T21:30:56Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8765", "html_url": "https://github.com/pytorch/pytorch/pull/8765", "diff_url": "https://github.com/pytorch/pytorch/pull/8765.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8765.patch"}, "body_html": "<p>This is relevant for benchmarking where you're dealing with the same operation running against identically sized tensors in parallel. Without this change, they will still run sequentially, because they all run the same cached algorithm instance.</p>", "body_text": "This is relevant for benchmarking where you're dealing with the same operation running against identically sized tensors in parallel. Without this change, they will still run sequentially, because they all run the same cached algorithm instance.", "body": "This is relevant for benchmarking where you're dealing with the same operation running against identically sized tensors in parallel. Without this change, they will still run sequentially, because they all run the same cached algorithm instance."}