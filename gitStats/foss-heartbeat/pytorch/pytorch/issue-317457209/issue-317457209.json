{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6925", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6925/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6925/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6925/events", "html_url": "https://github.com/pytorch/pytorch/issues/6925", "id": 317457209, "node_id": "MDU6SXNzdWUzMTc0NTcyMDk=", "number": 6925, "title": "Confusing error message in Criterion output Tensor in v0.4", "user": {"login": "varunagrawal", "id": 975964, "node_id": "MDQ6VXNlcjk3NTk2NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/975964?v=4", "gravatar_id": "", "url": "https://api.github.com/users/varunagrawal", "html_url": "https://github.com/varunagrawal", "followers_url": "https://api.github.com/users/varunagrawal/followers", "following_url": "https://api.github.com/users/varunagrawal/following{/other_user}", "gists_url": "https://api.github.com/users/varunagrawal/gists{/gist_id}", "starred_url": "https://api.github.com/users/varunagrawal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/varunagrawal/subscriptions", "organizations_url": "https://api.github.com/users/varunagrawal/orgs", "repos_url": "https://api.github.com/users/varunagrawal/repos", "events_url": "https://api.github.com/users/varunagrawal/events{/privacy}", "received_events_url": "https://api.github.com/users/varunagrawal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-25T02:20:03Z", "updated_at": "2018-04-25T07:14:09Z", "closed_at": "2018-04-25T03:34:48Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>When computing operations on a Tensor returned from a Criterion on a per epoch basis, program always crashes with the error:</p>\n<p><code>RuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58</code></p>\n<p>if we update the old-style <code>loss.data[0]</code> to just <code>loss</code>. This issue is not seen is we use <code>loss.item()</code>.</p>\n<p>While I agree this issue may not be valid since in PyTorch 0.5 indexing of 0-dim tensors will cause an error, I am not convinced a cuda out-of-memory error should be happening.</p>\n<h2>Code example</h2>\n<p>Using the <code>AverageMeter</code> class from the <a href=\"https://github.com/pytorch/examples/blob/master/imagenet/main.py\">ImageNet example</a>, if we use <code>losses.update(loss, input.size(0))</code> we get the above error message.</p>\n<p>But if we use <code>losses.update(loss.item(), input.size(0))</code>, the error does not show up.</p>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 8.0.61<br>\nGPU models and configuration: GPU 0: TITAN X (Pascal)<br>\nNvidia driver version: 390.48<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7<br>\n/usr/local/MATLAB/R2017b/bin/glnxa64/libcudnn.so.5.1.5<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.5<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.7<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.7.0.1<br>\n/usr/local/cuda-8.0/lib64/libcudnn_static.a<br>\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5<br>\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.14.2)<br>\n[pip3] torch (0.4.0)<br>\n[pip3] torchfile (0.1.0)<br>\n[pip3] torchvision (0.2.1)<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nWhen computing operations on a Tensor returned from a Criterion on a per epoch basis, program always crashes with the error:\nRuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58\nif we update the old-style loss.data[0] to just loss. This issue is not seen is we use loss.item().\nWhile I agree this issue may not be valid since in PyTorch 0.5 indexing of 0-dim tensors will cause an error, I am not convinced a cuda out-of-memory error should be happening.\nCode example\nUsing the AverageMeter class from the ImageNet example, if we use losses.update(loss, input.size(0)) we get the above error message.\nBut if we use losses.update(loss.item(), input.size(0)), the error does not show up.\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: GPU 0: TITAN X (Pascal)\nNvidia driver version: 390.48\ncuDNN version: Probably one of the following:\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7\n/usr/local/MATLAB/R2017b/bin/glnxa64/libcudnn.so.5.1.5\n/usr/local/cuda-8.0/lib64/libcudnn.so\n/usr/local/cuda-8.0/lib64/libcudnn.so.5\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\n/usr/local/cuda-8.0/lib64/libcudnn.so.7\n/usr/local/cuda-8.0/lib64/libcudnn.so.7.0.1\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\nVersions of relevant libraries:\n[pip3] numpy (1.14.2)\n[pip3] torch (0.4.0)\n[pip3] torchfile (0.1.0)\n[pip3] torchvision (0.2.1)\n[conda] Could not collect", "body": "## Issue description\r\n\r\nWhen computing operations on a Tensor returned from a Criterion on a per epoch basis, program always crashes with the error:\r\n\r\n`RuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58`\r\n\r\nif we update the old-style `loss.data[0]` to just `loss`. This issue is not seen is we use `loss.item()`.\r\n\r\nWhile I agree this issue may not be valid since in PyTorch 0.5 indexing of 0-dim tensors will cause an error, I am not convinced a cuda out-of-memory error should be happening.\r\n\r\n## Code example\r\n\r\nUsing the `AverageMeter` class from the [ImageNet example](https://github.com/pytorch/examples/blob/master/imagenet/main.py), if we use `losses.update(loss, input.size(0))` we get the above error message.\r\n\r\nBut if we use `losses.update(loss.item(), input.size(0))`, the error does not show up.\r\n\r\n## System Info\r\n\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: GPU 0: TITAN X (Pascal)\r\nNvidia driver version: 390.48\r\ncuDNN version: Probably one of the following:\r\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7\r\n/usr/local/MATLAB/R2017b/bin/glnxa64/libcudnn.so.5.1.5\r\n/usr/local/cuda-8.0/lib64/libcudnn.so\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.7\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.7.0.1\r\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\r\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.2)\r\n[pip3] torch (0.4.0)\r\n[pip3] torchfile (0.1.0)\r\n[pip3] torchvision (0.2.1)\r\n[conda] Could not collect"}