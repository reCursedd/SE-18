{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/431541531", "html_url": "https://github.com/pytorch/pytorch/issues/12831#issuecomment-431541531", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12831", "id": 431541531, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTU0MTUzMQ==", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-20T02:27:55Z", "updated_at": "2018-10-20T02:40:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>However, I can also reproduce this issue on WSL using PyTorch 0.4.1.<br>\nComplete code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.utils.data <span class=\"pl-k\">as</span> Data\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>Step 2: time it</span>\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    train_dataset <span class=\"pl-k\">=</span> torch.FloatTensor((<span class=\"pl-c1\">100000</span>, <span class=\"pl-c1\">32</span>))\n\n    batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\n\n    train_loader <span class=\"pl-k\">=</span> Data.DataLoader(<span class=\"pl-v\">dataset</span><span class=\"pl-k\">=</span>train_dataset,\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    train_loader2 <span class=\"pl-k\">=</span> Data.DataLoader(<span class=\"pl-v\">dataset</span><span class=\"pl-k\">=</span>train_dataset,\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>batch_size, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>)\n\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">200</span>):\n        <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> train_loader:\n            <span class=\"pl-k\">pass</span>\n    end <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-c1\">print</span>(end <span class=\"pl-k\">-</span> start)\n\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">200</span>):\n        <span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> train_loader2:\n            <span class=\"pl-k\">pass</span>\n    end <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-c1\">print</span>(end <span class=\"pl-k\">-</span> start)</pre></div>\n<p>Output:</p>\n<pre><code>0.005545377731323242\n39.24760317802429\n</code></pre>", "body_text": "However, I can also reproduce this issue on WSL using PyTorch 0.4.1.\nComplete code:\nimport time\nimport torch\nimport torch.utils.data as Data\n\n\n#Step 2: time it\nif __name__ == '__main__':\n    train_dataset = torch.FloatTensor((100000, 32))\n\n    batch_size = 32\n\n    train_loader = Data.DataLoader(dataset=train_dataset,\n    batch_size=batch_size, shuffle=True)\n    train_loader2 = Data.DataLoader(dataset=train_dataset,\n    batch_size=batch_size, shuffle=True, num_workers=8)\n\n    start = time.time()\n    for _ in range(200):\n        for x in train_loader:\n            pass\n    end = time.time()\n    print(end - start)\n\n    start = time.time()\n    for _ in range(200):\n        for x in train_loader2:\n            pass\n    end = time.time()\n    print(end - start)\nOutput:\n0.005545377731323242\n39.24760317802429", "body": "However, I can also reproduce this issue on WSL using PyTorch 0.4.1. \r\nComplete code:\r\n```python\r\nimport time\r\nimport torch\r\nimport torch.utils.data as Data\r\n\r\n\r\n#Step 2: time it\r\nif __name__ == '__main__':\r\n    train_dataset = torch.FloatTensor((100000, 32))\r\n\r\n    batch_size = 32\r\n\r\n    train_loader = Data.DataLoader(dataset=train_dataset,\r\n    batch_size=batch_size, shuffle=True)\r\n    train_loader2 = Data.DataLoader(dataset=train_dataset,\r\n    batch_size=batch_size, shuffle=True, num_workers=8)\r\n\r\n    start = time.time()\r\n    for _ in range(200):\r\n        for x in train_loader:\r\n            pass\r\n    end = time.time()\r\n    print(end - start)\r\n\r\n    start = time.time()\r\n    for _ in range(200):\r\n        for x in train_loader2:\r\n            pass\r\n    end = time.time()\r\n    print(end - start)\r\n```\r\nOutput:\r\n```\r\n0.005545377731323242\r\n39.24760317802429\r\n```"}