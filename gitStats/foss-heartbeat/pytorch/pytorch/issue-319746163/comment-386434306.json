{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386434306", "html_url": "https://github.com/pytorch/pytorch/issues/7209#issuecomment-386434306", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7209", "id": 386434306, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjQzNDMwNg==", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T20:57:21Z", "updated_at": "2018-05-03T21:08:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>More on the first proposed solution to instantiate random seed in the worker, see the <a href=\"https://github.com/pytorch/pytorch/compare/master...vfdev-5:issue_7209?expand=1\">diff</a></p>\n<p>and some results on the shuffling between epochs and batches:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> np.arange(<span class=\"pl-c1\">30</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">transform</span>(<span class=\"pl-smi\">v</span>):\n    <span class=\"pl-k\">return</span> torch.rand(<span class=\"pl-c1\">1</span>).item()\n    \n<span class=\"pl-k\">class</span> <span class=\"pl-en\">TestDataset</span>(<span class=\"pl-e\">Dataset</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__len__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">30</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        <span class=\"pl-k\">return</span> transform(x[index]), x[index]\n    \ndataset <span class=\"pl-k\">=</span> TestDataset()\nseed <span class=\"pl-k\">=</span> <span class=\"pl-c1\">12345</span>\nloader <span class=\"pl-k\">=</span> DataLoader(dataset, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">drop_last</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>):\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>epoch <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>))\n    torch.manual_seed(seed <span class=\"pl-k\">+</span> i)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> loader:\n        iteration <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-c1\">print</span>(iteration, batch)</pre></div>\n<p>gives:</p>\n<pre><code>epoch 1\n1 [tensor([ 0.5298,  0.4755,  0.0034,  0.8210], dtype=torch.float64), tensor([  0,  20,  19,  15])]\n2 [tensor([ 0.3666,  0.3264,  0.9305,  0.1377], dtype=torch.float64), tensor([ 22,  17,  28,  18])]\n3 [tensor([ 0.7048,  0.8053,  0.9652,  0.6854], dtype=torch.float64), tensor([ 21,  26,  11,  16])]\n4 [tensor([ 0.4799,  0.5304,  0.7838,  0.6162], dtype=torch.float64), tensor([ 10,   1,  25,  12])]\n5 [tensor([ 0.3307,  0.2305,  0.0226,  0.1470], dtype=torch.float64), tensor([  5,  14,  29,  23])]\n6 [tensor([ 0.5632,  0.8774,  0.6882,  0.9848], dtype=torch.float64), tensor([ 13,   9,   2,  24])]\n7 [tensor([ 0.8899,  0.1296,  0.2472,  0.8481], dtype=torch.float64), tensor([  3,   8,  27,   4])]\nepoch 2\n8 [tensor([ 0.7797,  0.1144,  0.9237,  0.2798], dtype=torch.float64), tensor([ 13,   5,  10,   7])]\n9 [tensor([ 0.6019,  0.8239,  0.1237,  0.9589], dtype=torch.float64), tensor([ 27,  23,  12,  29])]\n10 [tensor([ 0.7774,  0.8230,  0.7273,  0.8032], dtype=torch.float64), tensor([  2,   6,   8,  16])]\n11 [tensor([ 0.0075,  0.3194,  0.5676,  0.8277], dtype=torch.float64), tensor([ 14,  19,  28,   0])]\n12 [tensor([ 0.7530,  0.5262,  0.6337,  0.8992], dtype=torch.float64), tensor([ 20,   4,  17,  26])]\n13 [tensor([ 0.9373,  0.8393,  0.4855,  0.3121], dtype=torch.float64), tensor([  9,   3,  18,  15])]\n14 [tensor([ 0.5623,  0.6143,  0.1209,  0.1100], dtype=torch.float64), tensor([ 11,  24,  22,   1])]\nepoch 3\n15 [tensor([ 0.9595,  0.1186,  0.3112,  0.2225], dtype=torch.float64), tensor([ 24,  29,  20,   8])]\n16 [tensor([ 0.0555,  0.0452,  0.9801,  0.6574], dtype=torch.float64), tensor([  0,  23,  10,  14])]\n17 [tensor([ 0.4699,  0.7552,  0.4622,  0.6710], dtype=torch.float64), tensor([ 25,  12,   6,  16])]\n18 [tensor([ 0.9679,  0.2385,  0.0775,  0.2921], dtype=torch.float64), tensor([  5,  21,  11,   7])]\n19 [tensor([ 0.1383,  0.0527,  0.5839,  0.9611], dtype=torch.float64), tensor([ 22,   1,  27,   2])]\n20 [tensor([ 0.3035,  0.2059,  0.3913,  0.1332], dtype=torch.float64), tensor([  3,   9,  26,   4])]\n21 [tensor([ 0.8397,  0.1433,  0.0186,  0.3563], dtype=torch.float64), tensor([ 19,  28,  13,  15])]\n</code></pre>", "body_text": "More on the first proposed solution to instantiate random seed in the worker, see the diff\nand some results on the shuffling between epochs and batches:\nx = np.arange(30)\n\ndef transform(v):\n    return torch.rand(1).item()\n    \nclass TestDataset(Dataset):\n    def __len__(self):\n        return 30\n    def __getitem__(self, index):\n        return transform(x[index]), x[index]\n    \ndataset = TestDataset()\nseed = 12345\nloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\n\nfor i in range(3):\n    print(\"epoch {}\".format(i + 1))\n    torch.manual_seed(seed + i)\n    for batch in loader:\n        iteration += 1\n        print(iteration, batch)\ngives:\nepoch 1\n1 [tensor([ 0.5298,  0.4755,  0.0034,  0.8210], dtype=torch.float64), tensor([  0,  20,  19,  15])]\n2 [tensor([ 0.3666,  0.3264,  0.9305,  0.1377], dtype=torch.float64), tensor([ 22,  17,  28,  18])]\n3 [tensor([ 0.7048,  0.8053,  0.9652,  0.6854], dtype=torch.float64), tensor([ 21,  26,  11,  16])]\n4 [tensor([ 0.4799,  0.5304,  0.7838,  0.6162], dtype=torch.float64), tensor([ 10,   1,  25,  12])]\n5 [tensor([ 0.3307,  0.2305,  0.0226,  0.1470], dtype=torch.float64), tensor([  5,  14,  29,  23])]\n6 [tensor([ 0.5632,  0.8774,  0.6882,  0.9848], dtype=torch.float64), tensor([ 13,   9,   2,  24])]\n7 [tensor([ 0.8899,  0.1296,  0.2472,  0.8481], dtype=torch.float64), tensor([  3,   8,  27,   4])]\nepoch 2\n8 [tensor([ 0.7797,  0.1144,  0.9237,  0.2798], dtype=torch.float64), tensor([ 13,   5,  10,   7])]\n9 [tensor([ 0.6019,  0.8239,  0.1237,  0.9589], dtype=torch.float64), tensor([ 27,  23,  12,  29])]\n10 [tensor([ 0.7774,  0.8230,  0.7273,  0.8032], dtype=torch.float64), tensor([  2,   6,   8,  16])]\n11 [tensor([ 0.0075,  0.3194,  0.5676,  0.8277], dtype=torch.float64), tensor([ 14,  19,  28,   0])]\n12 [tensor([ 0.7530,  0.5262,  0.6337,  0.8992], dtype=torch.float64), tensor([ 20,   4,  17,  26])]\n13 [tensor([ 0.9373,  0.8393,  0.4855,  0.3121], dtype=torch.float64), tensor([  9,   3,  18,  15])]\n14 [tensor([ 0.5623,  0.6143,  0.1209,  0.1100], dtype=torch.float64), tensor([ 11,  24,  22,   1])]\nepoch 3\n15 [tensor([ 0.9595,  0.1186,  0.3112,  0.2225], dtype=torch.float64), tensor([ 24,  29,  20,   8])]\n16 [tensor([ 0.0555,  0.0452,  0.9801,  0.6574], dtype=torch.float64), tensor([  0,  23,  10,  14])]\n17 [tensor([ 0.4699,  0.7552,  0.4622,  0.6710], dtype=torch.float64), tensor([ 25,  12,   6,  16])]\n18 [tensor([ 0.9679,  0.2385,  0.0775,  0.2921], dtype=torch.float64), tensor([  5,  21,  11,   7])]\n19 [tensor([ 0.1383,  0.0527,  0.5839,  0.9611], dtype=torch.float64), tensor([ 22,   1,  27,   2])]\n20 [tensor([ 0.3035,  0.2059,  0.3913,  0.1332], dtype=torch.float64), tensor([  3,   9,  26,   4])]\n21 [tensor([ 0.8397,  0.1433,  0.0186,  0.3563], dtype=torch.float64), tensor([ 19,  28,  13,  15])]", "body": "More on the first proposed solution to instantiate random seed in the worker, see the [diff](https://github.com/pytorch/pytorch/compare/master...vfdev-5:issue_7209?expand=1)\r\n\r\nand some results on the shuffling between epochs and batches:\r\n```python\r\nx = np.arange(30)\r\n\r\ndef transform(v):\r\n    return torch.rand(1).item()\r\n    \r\nclass TestDataset(Dataset):\r\n    def __len__(self):\r\n        return 30\r\n    def __getitem__(self, index):\r\n        return transform(x[index]), x[index]\r\n    \r\ndataset = TestDataset()\r\nseed = 12345\r\nloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, drop_last=True)\r\n\r\nfor i in range(3):\r\n    print(\"epoch {}\".format(i + 1))\r\n    torch.manual_seed(seed + i)\r\n    for batch in loader:\r\n        iteration += 1\r\n        print(iteration, batch)\r\n```\r\ngives:\r\n```\r\nepoch 1\r\n1 [tensor([ 0.5298,  0.4755,  0.0034,  0.8210], dtype=torch.float64), tensor([  0,  20,  19,  15])]\r\n2 [tensor([ 0.3666,  0.3264,  0.9305,  0.1377], dtype=torch.float64), tensor([ 22,  17,  28,  18])]\r\n3 [tensor([ 0.7048,  0.8053,  0.9652,  0.6854], dtype=torch.float64), tensor([ 21,  26,  11,  16])]\r\n4 [tensor([ 0.4799,  0.5304,  0.7838,  0.6162], dtype=torch.float64), tensor([ 10,   1,  25,  12])]\r\n5 [tensor([ 0.3307,  0.2305,  0.0226,  0.1470], dtype=torch.float64), tensor([  5,  14,  29,  23])]\r\n6 [tensor([ 0.5632,  0.8774,  0.6882,  0.9848], dtype=torch.float64), tensor([ 13,   9,   2,  24])]\r\n7 [tensor([ 0.8899,  0.1296,  0.2472,  0.8481], dtype=torch.float64), tensor([  3,   8,  27,   4])]\r\nepoch 2\r\n8 [tensor([ 0.7797,  0.1144,  0.9237,  0.2798], dtype=torch.float64), tensor([ 13,   5,  10,   7])]\r\n9 [tensor([ 0.6019,  0.8239,  0.1237,  0.9589], dtype=torch.float64), tensor([ 27,  23,  12,  29])]\r\n10 [tensor([ 0.7774,  0.8230,  0.7273,  0.8032], dtype=torch.float64), tensor([  2,   6,   8,  16])]\r\n11 [tensor([ 0.0075,  0.3194,  0.5676,  0.8277], dtype=torch.float64), tensor([ 14,  19,  28,   0])]\r\n12 [tensor([ 0.7530,  0.5262,  0.6337,  0.8992], dtype=torch.float64), tensor([ 20,   4,  17,  26])]\r\n13 [tensor([ 0.9373,  0.8393,  0.4855,  0.3121], dtype=torch.float64), tensor([  9,   3,  18,  15])]\r\n14 [tensor([ 0.5623,  0.6143,  0.1209,  0.1100], dtype=torch.float64), tensor([ 11,  24,  22,   1])]\r\nepoch 3\r\n15 [tensor([ 0.9595,  0.1186,  0.3112,  0.2225], dtype=torch.float64), tensor([ 24,  29,  20,   8])]\r\n16 [tensor([ 0.0555,  0.0452,  0.9801,  0.6574], dtype=torch.float64), tensor([  0,  23,  10,  14])]\r\n17 [tensor([ 0.4699,  0.7552,  0.4622,  0.6710], dtype=torch.float64), tensor([ 25,  12,   6,  16])]\r\n18 [tensor([ 0.9679,  0.2385,  0.0775,  0.2921], dtype=torch.float64), tensor([  5,  21,  11,   7])]\r\n19 [tensor([ 0.1383,  0.0527,  0.5839,  0.9611], dtype=torch.float64), tensor([ 22,   1,  27,   2])]\r\n20 [tensor([ 0.3035,  0.2059,  0.3913,  0.1332], dtype=torch.float64), tensor([  3,   9,  26,   4])]\r\n21 [tensor([ 0.8397,  0.1433,  0.0186,  0.3563], dtype=torch.float64), tensor([ 19,  28,  13,  15])]\r\n```\r\n\r\n\r\n"}