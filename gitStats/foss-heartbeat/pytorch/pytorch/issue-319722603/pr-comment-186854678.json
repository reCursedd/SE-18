{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/186854678", "pull_request_review_id": 118515914, "id": 186854678, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4Njg1NDY3OA==", "diff_hunk": "@@ -23,10 +23,107 @@ def __init__(self, ptr):\n         self.cdata = ptr\n \n \n-# mapping from handles to StorageRef objects\n+# mapping from handles to StorageRef objects. Doesn't include CUDA handles.\n shared_cache = weakref.WeakValueDictionary()\n \n \n+# CUDA storage caching strategy\n+# -----------------------------\n+#\n+# All CUDA storages are cached into 'cuda_cache'.\n+#\n+# Call a \"CUDA storage that processes wish to share\" a \"real storage\".\n+# \"real storages\" are the storages that other processes want to and\n+# eventually will receive.\n+#\n+# Call a \"CUDA storage that points to the base of an allocation block\" a\n+# \"base storage\". These are obtained by opening CUDA handles to the\n+# base of an allocation block, where multiple \"real storages\" may live.\n+# Those \"real storages\" can be obtained by adding an offset to \"base storage\"\n+#\n+# \"base storages\" are cached into the \"base cache\" and \"real storages\" are\n+# cached into the \"real cache\"\n+#\n+# When a process shares a cuda storage:\n+# - It looks in the \"real cache\" for the storage.\n+# - If the storage is not found, we go into cpp-land to share the storage.\n+# - If the storage is found, we return the \"real storage\"'s metadata\n+#   (device, handle, size, offset, view_size) that was previously obtained\n+#   when cpp-land shared the storage.\n+#\n+# When a process receives a cuda storage:\n+# - It looks in the \"real cache\" for the real storage.\n+# - If it's not there, look in the \"base cache\".\n+# - If it exists in the \"base cache\", recreate the real storage, add it to the\n+#   \"real cache\", and return it.\n+# - If it doesn't exist in the \"base cache\", recreate the real and base storages\n+#   in cpp-land and add them to their respective caches.\n+#\n+# \"base storages\" are uniquely identified by their CUDA handle.\n+# \"real storages\" are uniquely identified by (handle, offset).\n+class CUDASharedCache:\n+    def __init__(self):\n+        # (handle) -> \"base storage\" ref\n+        self.base_cache = weakref.WeakValueDictionary()\n+\n+        # (handle, offset) -> \"real storage\" ref\n+        self.real_cache = weakref.WeakValueDictionary()\n+\n+        # dataptr -> \"real storage\" ref\n+        self.data_cache = weakref.WeakValueDictionary()\n+\n+    @staticmethod\n+    def real_key(handle, offset):\n+        return '{}_{}'.format(handle, offset)\n+\n+    def save_base(self, base_storage, handle):\n+        storageref = base_storage._weak_ref(StorageRef)\n+        self.base_cache[handle] = storageref\n+\n+    def save_real(self, real_storage, metadata):\n+        _, handle, _, offset, _ = metadata\n+\n+        # Saving metadata so this process does not need to re-get\n+        # the IPC handle in cpp-land when re-sharing this storage.\n+        storageref = real_storage._weak_ref(StorageRef)\n+        storageref.__real_metadata = metadata\n+\n+        key = self.real_key(handle, offset)\n+        dataptr = real_storage.data_ptr()\n+\n+        self.real_cache[key] = storageref\n+        self.data_cache[dataptr] = storageref\n+\n+    def get_storage(self, cls, metadata):\n+        _, handle, _, offset, view_size = metadata\n+\n+        # Case 1: \"real storage\" cached\n+        key = self.real_key(handle, offset)\n+        real_ref = self.real_cache.get(key)\n+        if real_ref is not None:\n+            return cls._new_with_weak_ptr(real_ref)\n+\n+        # Case 3: Neither \"real storage\" nor \"base storage\" cached", "path": "torch/multiprocessing/reductions.py", "position": null, "original_position": 85, "commit_id": "bb9d7b36ff4bd90e197fb645de2cd1393ca6654b", "original_commit_id": "96a94dbaa059dfa47dbf664caf5ce0d74c380c38", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Ordering the cases 1, 3, 2 is a little strange.", "created_at": "2018-05-08T20:20:26Z", "updated_at": "2018-11-23T15:43:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/7204#discussion_r186854678", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7204", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/186854678"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7204#discussion_r186854678"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7204"}}, "body_html": "<p>Ordering the cases 1, 3, 2 is a little strange.</p>", "body_text": "Ordering the cases 1, 3, 2 is a little strange."}