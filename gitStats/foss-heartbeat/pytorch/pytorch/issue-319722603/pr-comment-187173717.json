{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187173717", "pull_request_review_id": 118901750, "id": 187173717, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NzE3MzcxNw==", "diff_hunk": "@@ -23,10 +23,108 @@ def __init__(self, ptr):\n         self.cdata = ptr\n \n \n-# mapping from handles to StorageRef objects\n+# mapping from handles to StorageRef objects. Doesn't include CUDA handles.\n shared_cache = weakref.WeakValueDictionary()\n \n \n+# CUDA storage caching strategy\n+# -----------------------------\n+#\n+# All CUDA storages are cached into 'cuda_cache'.\n+#\n+# Call a \"CUDA storage that processes wish to share\" a \"real storage\".\n+# \"real storages\" are the storages that other processes want to and\n+# eventually will receive.\n+#\n+# Call a \"CUDA storage that points to the base of an allocation block\" a\n+# \"base storage\". These are obtained by opening CUDA handles to the\n+# base of an allocation block, where multiple \"real storages\" may live.\n+# Those \"real storages\" can be obtained by adding an offset to \"base storage\"\n+#\n+# \"base storages\" are cached into the \"base cache\" and \"real storages\" are\n+# cached into the \"real cache\"\n+#\n+# When a process shares a cuda storage:\n+# - If the cuda storage is from opening a received handle, find the handle\n+#   in the metadata cache and send the returned metadata.\n+# - If the cuda storage is from allocating storage, get the handle, build\n+#   the metadata, and send it.\n+#\n+# When a process receives a cuda storage:\n+# - Check the caches:\n+#   - Check the \"real cache\" for the real storage.\n+#   - If it's not there, look in the \"base cache\".\n+#   - If the storage exists in the \"base cache\", recreate the real storage by\n+#     add it to the \"base storage\"\n+# - If it's not in the caches, recreate the real and base storages and cache\n+#   both.\n+# - In addition, if this process received a handle that it has opened\n+#   (either now or in the past), we cache the storage's metadata in the\n+#   metadata cache. This is so that the process can access the handle\n+#   to send to other processes.\n+#   A process that didn't open a handle (the process that allocated the storage)\n+#   doesn't cache the metadata.\n+#\n+# \"base storages\" are uniquely identified by their CUDA handle.\n+# \"real storages\" are uniquely identified by (handle, offset).", "path": "torch/multiprocessing/reductions.py", "position": 48, "original_position": 48, "commit_id": "bb9d7b36ff4bd90e197fb645de2cd1393ca6654b", "original_commit_id": "1d96f36b8ceeae37bba31ecf769ace4061213e63", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "Right, we could have `storage1` have `(base, offset, view_size=10)` and `storage2` have `(base, offset, view_size=20)` and then they'd be different", "created_at": "2018-05-09T20:56:06Z", "updated_at": "2018-11-23T15:43:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/7204#discussion_r187173717", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7204", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187173717"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7204#discussion_r187173717"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7204"}}, "body_html": "<p>Right, we could have <code>storage1</code> have <code>(base, offset, view_size=10)</code> and <code>storage2</code> have <code>(base, offset, view_size=20)</code> and then they'd be different</p>", "body_text": "Right, we could have storage1 have (base, offset, view_size=10) and storage2 have (base, offset, view_size=20) and then they'd be different", "in_reply_to_id": 187170319}