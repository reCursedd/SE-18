{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179105791", "pull_request_review_id": 109284699, "id": 179105791, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTEwNTc5MQ==", "diff_hunk": "@@ -22,289 +24,224 @@ namespace at {\n  * B[1][0]\n  * B[1][1]\n  *\n- * We set the offset into the underlying storage as (storageOffset + stride_B * index_B),\n- * i.e. basically we compute the offset into the storage as we would normally for a\n- * Tensor. But because we are guaranteed the subsequent data is contiguous in memory, we\n- * can simply loop for sizeof(A) iterations and perform the operation, without having to\n- * follow the order described by the strides of A.\n+ * We set the offset into the underlying storage as (storageOffset + stride_B *\n+ * index_B), i.e. basically we compute the offset into the storage as we would\n+ * normally for a Tensor. But because we are guaranteed the subsequent data is\n+ * contiguous in memory, we can simply loop for sizeof(A) iterations and perform\n+ * the operation, without having to follow the order described by the strides of\n+ * A.\n  *\n- * 3. As an optimization, we merge dimensions of A that are contiguous in memory. For\n- * example, if A is a 3x3x3x3 tensor narrowed from a 3x3x4x3 tensor, then the first two\n- * dimensions can be merged for the purposes of APPLY, reducing the number of nested\n- * loops.\n+ * 3. As an optimization, we merge dimensions of A that are contiguous in\n+ * memory. For example, if A is a 3x3x3x3 tensor narrowed from a 3x3x4x3 tensor,\n+ * then the first two dimensions can be merged for the purposes of APPLY,\n+ * reducing the number of nested loops.\n  */\n \n-// TODO: turn this macro into a proper template\n-#define __ATH_TENSOR_APPLYX_PREAMBLE(TYPE, ATENSOR, DIM, ALLOW_CONTIGUOUS) \\\n-  TYPE *ATENSOR##_data = NULL; \\\n-  int64_t *ATENSOR##_counter = NULL, *ATENSOR##_sizes = NULL, *ATENSOR##_strides = NULL, *ATENSOR##_dimOffset = NULL; \\\n-  int64_t ATENSOR##_stride = 0, ATENSOR##_size = 0, ATENSOR##_dim = 0, ATENSOR##_i; \\\n-  int ATENSOR##_contiguous = ALLOW_CONTIGUOUS && DIM < 0; \\\n-\\\n-  if(ATENSOR.sizes().equals({0})) \\\n-    TH_TENSOR_APPLY_hasFinished = true; \\\n-  else \\\n-  { \\\n-    ATENSOR##_data = ATENSOR.data<TYPE>(); \\\n-    ATENSOR##_size = 1; \\\n-    ATENSOR##_stride = 1; \\\n-    for(ATENSOR##_i = ATENSOR.dim() - 1; ATENSOR##_i >= 0; ATENSOR##_i--) { \\\n-      if(ATENSOR.sizes()[ATENSOR##_i] != 1) { \\\n-        if(ATENSOR.strides()[ATENSOR##_i] == ATENSOR##_size && ATENSOR##_i != DIM) \\\n-          ATENSOR##_size *= ATENSOR.sizes()[ATENSOR##_i]; \\\n-        else{ \\\n-          ATENSOR##_contiguous = 0; \\\n-          break; \\\n-        } \\\n-      } \\\n-    } \\\n-    if (!ATENSOR##_contiguous) { \\\n-      /* Find the dimension of contiguous sections */ \\\n-      ATENSOR##_dim = 1; \\\n-      for(ATENSOR##_i = ATENSOR.dim() - 2; ATENSOR##_i >= 0; ATENSOR##_i--) \\\n-      { \\\n-        if(ATENSOR.strides()[ATENSOR##_i] != ATENSOR.strides()[ATENSOR##_i+1] * ATENSOR.sizes()[ATENSOR##_i+1] || ATENSOR##_i == DIM || ATENSOR##_i+1 == DIM) \\\n-          ATENSOR##_dim++; \\\n-      } \\\n-      /* Allocate an array of 3*dim elements, where dim is the number of contiguous sections */ \\\n-      ATENSOR##_counter = new int64_t[3*ATENSOR##_dim]; \\\n-      ATENSOR##_sizes = ATENSOR##_counter + ATENSOR##_dim; \\\n-      ATENSOR##_strides = ATENSOR##_counter + 2*ATENSOR##_dim; \\\n-      TH_TENSOR_dim_index = ATENSOR##_dim-1; \\\n-      ATENSOR##_dimOffset = (DIM == ATENSOR.dim()-1) ? &ATENSOR##_i : &ATENSOR##_counter[DIM]; \\\n-      ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR.dim()-1]; \\\n-      ATENSOR##_strides[TH_TENSOR_dim_index] = ATENSOR.strides()[ATENSOR.dim()-1]; \\\n-      /* ATENSOR##_counter tracks where we are in the storage. The offset into the */ \\\n-      /* storage is given by storage_offset + (i * j), where i is the stride */ \\\n-      /* vector and j is tensor_counter vector. This sets the starting position for the loop. */ \\\n-      for(ATENSOR##_i = ATENSOR##_dim-1; ATENSOR##_i >= 0; --ATENSOR##_i) { \\\n-        ATENSOR##_counter[ATENSOR##_i] = 0; \\\n-      } \\\n-      for(ATENSOR##_i = ATENSOR.dim()-2; ATENSOR##_i >= 0; --ATENSOR##_i) { \\\n-        if (ATENSOR.strides()[ATENSOR##_i] == ATENSOR.strides()[ATENSOR##_i+1] * ATENSOR.sizes()[ATENSOR##_i+1] && ATENSOR##_i != DIM && ATENSOR##_i+1 != DIM) { \\\n-          ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR##_i] * ATENSOR##_sizes[TH_TENSOR_dim_index]; \\\n-          if (DIM != ATENSOR.dim()-1 && ATENSOR##_i < DIM) \\\n-            ATENSOR##_dimOffset--; \\\n-        } else { \\\n-          --TH_TENSOR_dim_index; \\\n-          ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR##_i]; \\\n-          ATENSOR##_strides[TH_TENSOR_dim_index] = ATENSOR.strides()[ATENSOR##_i]; \\\n-        } \\\n-      } \\\n-      /* Size of the inner most section */ \\\n-      ATENSOR##_size = ATENSOR##_sizes[ATENSOR##_dim-1]; \\\n-      /* Stride of the inner most section */ \\\n-      ATENSOR##_stride = ATENSOR##_strides[ATENSOR##_dim-1]; \\\n-    } \\\n-  } \\\n-  ATENSOR##_i = 0;\n-\n-// TODO: turn this macro into a proper template\n-#define  __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(ATENSOR, ALWAYS_UPDATE) \\\n-  if(ATENSOR##_i == ATENSOR##_size || ALWAYS_UPDATE) \\\n-  { \\\n-    if(ATENSOR##_contiguous) \\\n-      break; \\\n-\\\n-    if(ATENSOR##_dim == 1) \\\n-       break; \\\n-\\\n-    /* Reset pointer to beginning of loop */ \\\n-    ATENSOR##_data -= ATENSOR##_size*ATENSOR##_stride; \\\n-    for(ATENSOR##_i = ATENSOR##_dim-2; ATENSOR##_i >= 0; ATENSOR##_i--) \\\n-    { \\\n-      ATENSOR##_counter[ATENSOR##_i]++; \\\n-      /* Jump ahread by the stride of this dimension */ \\\n-      ATENSOR##_data += ATENSOR##_strides[ATENSOR##_i]; \\\n-\\\n-      if(ATENSOR##_counter[ATENSOR##_i]  == ATENSOR##_sizes[ATENSOR##_i]) \\\n-      { \\\n-        if(ATENSOR##_i == 0) \\\n-        { \\\n-          TH_TENSOR_APPLY_hasFinished = true; \\\n-          break; \\\n-        } \\\n-          else \\\n-        { \\\n-          /* Reset the pointer to the beginning of the chunk defined by this dimension */ \\\n-          ATENSOR##_data -= ATENSOR##_counter[ATENSOR##_i]*ATENSOR##_strides[ATENSOR##_i]; \\\n-          ATENSOR##_counter[ATENSOR##_i] = 0; \\\n-        } \\\n-      } \\\n-      else \\\n-        break; \\\n-    } \\\n-    ATENSOR##_i = 0; \\\n+// TODO:\n+// Create a larger set of test cases for non-contiguous tensors\n+// Optimize for parallelization and performance\n+\n+template <typename T>\n+struct strided_tensor_iter {\n+ private:\n+  const bool is_contiguous_;\n+  const int64_t dim_;\n+  int64_t offset_;\n+  const int64_t numel_;\n+  std::vector<int64_t> counter_;\n+  std::vector<int64_t> sizes_;\n+  std::vector<int64_t> strides_;\n+  T* data_ = NULL;\n+  bool is_finished_;\n+\n+ public:\n+  strided_tensor_iter(strided_tensor_iter const&) = delete;\n+  void operator=(strided_tensor_iter const& x) = delete;\n+  strided_tensor_iter(strided_tensor_iter&&) = default;\n+  strided_tensor_iter(Tensor& tensor)\n+      : is_contiguous_(tensor.is_contiguous()),\n+        dim_(tensor.ndimension()),\n+        offset_(0),\n+        numel_(tensor.numel()),\n+        data_(tensor.data<T>()),\n+        is_finished_(false) {\n+    if (!is_contiguous_) {", "path": "aten/src/ATen/CPUApplyUtils.h", "position": null, "original_position": 181, "commit_id": "ca55c40ec722ecb64659682bdb81caa0cfb82e36", "original_commit_id": "bc3aeacd207168b90a5727d3ea839f1c82965de4", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "in the previous implementation, we would merge together contiguous dimensions so that we have less indices to iterate on.\r\nFor example, in\r\n```python\r\na = torch.rand(3, 4, 5, 6).permute(1, 0, 2, 3)\r\n```\r\nwe can merge dimensions 2 and 3 together, effectively as if we were dealing with a non-contiguous tensor of shape `(4, 3, 30)`. Is that something that we could do here?\r\n\r\nAlso, if the `op` that we are passing is aware of vector operations, we could even exploit those larger contiguous chunks and perform vector operations there as well.", "created_at": "2018-04-04T11:23:45Z", "updated_at": "2018-11-23T15:41:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/6119#discussion_r179105791", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6119", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179105791"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6119#discussion_r179105791"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6119"}}, "body_html": "<p>in the previous implementation, we would merge together contiguous dimensions so that we have less indices to iterate on.<br>\nFor example, in</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">6</span>).permute(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)</pre></div>\n<p>we can merge dimensions 2 and 3 together, effectively as if we were dealing with a non-contiguous tensor of shape <code>(4, 3, 30)</code>. Is that something that we could do here?</p>\n<p>Also, if the <code>op</code> that we are passing is aware of vector operations, we could even exploit those larger contiguous chunks and perform vector operations there as well.</p>", "body_text": "in the previous implementation, we would merge together contiguous dimensions so that we have less indices to iterate on.\nFor example, in\na = torch.rand(3, 4, 5, 6).permute(1, 0, 2, 3)\nwe can merge dimensions 2 and 3 together, effectively as if we were dealing with a non-contiguous tensor of shape (4, 3, 30). Is that something that we could do here?\nAlso, if the op that we are passing is aware of vector operations, we could even exploit those larger contiguous chunks and perform vector operations there as well."}