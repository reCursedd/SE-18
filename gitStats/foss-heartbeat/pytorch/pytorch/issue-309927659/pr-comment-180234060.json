{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180234060", "pull_request_review_id": 110621036, "id": 180234060, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MDIzNDA2MA==", "diff_hunk": "@@ -39,81 +40,172 @@ namespace at {\n \n // TODO:\n // Create a larger set of test cases for non-contiguous tensors\n+// // Cover large dimensions\n // Optimize for parallelization and performance\n+// - Collapse contiguous dimensions\n+// - Parallelize over outer dimensions until you hit a contiguous part, which is\n+// then parallelized / vectorized as usual.\n+// - Be careful that the offsets across tensors still match\n+// - Vectorize as appropiate\n+// - Preprocess to discover cont. cases such as transposed\n+// - Create templated fixed-sized strided tensor for small dimensions\n+//\n \n template <typename T>\n struct strided_tensor_iter {\n+ public:\n+  virtual T* next() {\n+    return nullptr;\n+  }\n+};\n+\n+template <typename T>\n+struct zero_tensor_iter : virtual strided_tensor_iter<T> {\n+ private:\n+  T* data_ = NULL;\n+\n+ public:\n+  zero_tensor_iter(Tensor& tensor) : data_(tensor.data<T>()) {}\n+  // A 0 dimensional tensor may only ever contain 1 element!\n+  inline T* next() {\n+    return data_;\n+  }\n+};\n+\n+template <typename T>\n+struct cont_tensor_iter : virtual strided_tensor_iter<T> {\n  private:\n-  const bool is_contiguous_;\n-  const int64_t dim_;\n-  int64_t offset_;\n-  const int64_t numel_;\n+  T* data_ = NULL;\n+\n+ public:\n+  cont_tensor_iter(Tensor& tensor) : data_(tensor.data<T>()) {}\n+  inline T* next() {\n+    return data_++;\n+  }\n+};\n+\n+template <typename T>\n+struct variable_strided_tensor_iter : virtual strided_tensor_iter<T> {\n+ private:\n+  int64_t dim_;\n   std::vector<int64_t> counter_;\n-  std::vector<int64_t> sizes_;\n-  std::vector<int64_t> strides_;\n+  std::vector<int64_t> size_;\n+  std::vector<int64_t> stride_;\n   T* data_ = NULL;\n-  bool is_finished_;\n \n  public:\n-  strided_tensor_iter(strided_tensor_iter const&) = delete;\n-  void operator=(strided_tensor_iter const& x) = delete;\n-  strided_tensor_iter(strided_tensor_iter&&) = default;\n-  strided_tensor_iter(Tensor& tensor)\n-      : is_contiguous_(tensor.is_contiguous()),\n-        dim_(tensor.ndimension()),\n-        offset_(0),\n-        numel_(tensor.numel()),\n-        data_(tensor.data<T>()),\n-        is_finished_(false) {\n-    if (!is_contiguous_) {\n-      counter_.resize(dim_, 0);\n-      sizes_.resize(dim_, 1);\n-      strides_.resize(dim_, 1);\n-      for (int64_t i = 0; i < dim_; i++) {\n-        sizes_[i] = tensor.size(i);\n-        strides_[i] = tensor.stride(i);\n+  variable_strided_tensor_iter(variable_strided_tensor_iter const&) = delete;\n+  void operator=(variable_strided_tensor_iter const& x) = delete;\n+  variable_strided_tensor_iter(variable_strided_tensor_iter&&) = default;\n+  variable_strided_tensor_iter(Tensor& tensor) : data_(tensor.data<T>()) {\n+    dim_ = 0;\n+    for (int64_t i = 0; i < tensor.ndimension(); i++) {\n+      int64_t size = tensor.size(i);\n+      int64_t stride = tensor.stride(i);\n+      while (i < tensor.ndimension() - 1 &&\n+             stride == tensor.size(i + 1) * tensor.stride(i + 1)) {\n+        size = size * tensor.size(i + 1) * tensor.stride(i + 1);\n+        stride = tensor.stride(i + 1);\n+        i++;\n       }\n+      size_.push_back(size);\n+      stride_.push_back(stride);\n+      counter_.push_back(0);\n+      dim_++;\n     }\n   }\n-  inline T* data() {\n-    return data_ + offset_;\n+  inline T* next() {\n+    T* ret = data_;\n+    counter_[dim_ - 1]++;\n+    data_ += stride_[dim_ - 1];\n+    if (counter_[dim_ - 1] == size_[dim_ - 1]) {\n+      for (int64_t i = dim_ - 1; i > 0; i--) {\n+        if (counter_[i] == size_[i]) {\n+          counter_[i] = 0;\n+          counter_[i - 1]++;\n+          data_ = data_ - size_[i] * stride_[i] + stride_[i - 1];\n+        }\n+      }\n+    }\n+    return ret;\n   }\n-  inline bool is_finished() {\n-    return is_finished_;\n+};\n+\n+template <typename T, int N>\n+struct fixed_strided_tensor_iter : virtual strided_tensor_iter<T> {\n+ private:\n+  int64_t base_counter_;\n+  int64_t base_stride_;\n+  int64_t base_size_;\n+  int64_t dim_;\n+  __at_align32__ int64_t size_[N];\n+  __at_align32__ int64_t stride_[N];\n+  __at_align32__ int64_t counter_[N];\n+  __at_align32__ int64_t cache_[N];\n+  T* data_ = NULL;\n+\n+ public:\n+  fixed_strided_tensor_iter(fixed_strided_tensor_iter const&) = delete;\n+  void operator=(fixed_strided_tensor_iter const& x) = delete;\n+  fixed_strided_tensor_iter(fixed_strided_tensor_iter&&) = default;\n+  fixed_strided_tensor_iter(Tensor& tensor) : data_(tensor.data<T>()) {\n+    dim_ = 0;\n+    for (int64_t i = 0; i < tensor.ndimension(); i++) {\n+      int64_t size = tensor.size(i);\n+      int64_t stride = tensor.stride(i);\n+      while (i < tensor.ndimension() - 1 &&\n+             stride == tensor.size(i + 1) * tensor.stride(i + 1)) {\n+        size = size * tensor.size(i + 1) * tensor.stride(i + 1);\n+        stride = tensor.stride(i + 1);\n+        i++;\n+      }\n+      size_[dim_] = size;\n+      stride_[dim_] = stride;\n+      counter_[dim_] = 0;\n+      dim_++;\n+    }\n+    base_counter_ = 0;\n+    base_stride_ = stride_[dim_ - 1];\n+    base_size_ = size_[dim_ - 1];\n+    for (int64_t i = dim_ - 1; i > 0; i--)\n+      cache_[i] = -size_[i] * stride_[i] + stride_[i - 1];\n   }\n-  inline void iterate() {\n-    // We don't need to calculate non-trival offsets for contiguous tensors\n-    if (is_contiguous_) {\n-      offset_++;\n-      if (offset_ == numel_)\n-        is_finished_ = true;\n-    } else {\n-      if (dim_ > 0) {\n-        counter_[dim_ - 1]++;\n-        offset_ += strides_[dim_ - 1];\n-        if (counter_[dim_ - 1] == sizes_[dim_ - 1]) {\n-          for (int64_t i = dim_ - 1; i > 0; i--) {\n-            if (counter_[i] == sizes_[i]) {\n-              counter_[i] = (counter_[i]) % sizes_[i];\n-              counter_[i - 1]++;\n-            }\n-          }\n-          offset_ = 0;\n-          for (int64_t i = 0; i < dim_; i++) {\n-            offset_ += counter_[i] * strides_[i];\n-          }\n-          if (counter_[0] == sizes_[0]) {\n-            is_finished_ = true;\n-          }\n+  inline T* next() {\n+    T* ret = data_;\n+    base_counter_++;\n+    data_ += base_stride_;\n+    if (base_counter_ == base_size_) {\n+      base_counter_ = 0;\n+      if (dim_ > 1) {\n+        counter_[dim_ - 2]++;\n+        data_ = data_ + cache_[dim_ - 1];\n+      }\n+      for (int64_t i = dim_ - 2; i > 0; i--) {\n+        if (counter_[i] == size_[i]) {\n+          counter_[i] = 0;\n+          counter_[i - 1]++;\n+          data_ = data_ + cache_[i];\n         }\n-      } else {\n-        // A 0 dimensional tensor may only ever contain 1 element!\n-        is_finished_ = true;\n       }\n     }\n+    return ret;\n   }\n };\n \n+template <typename scalar>\n+std::unique_ptr<strided_tensor_iter<scalar>> make_strided_tensor_iter(\n+    Tensor& tensor) {\n+  if (tensor.ndimension() == 0)\n+    return at::make_unique<zero_tensor_iter<scalar>>(tensor);\n+  if (tensor.is_contiguous())\n+    return at::make_unique<cont_tensor_iter<scalar>>(tensor);\n+  if (tensor.ndimension() < 4)", "path": "aten/src/ATen/CPUApplyUtils.h", "position": null, "original_position": 226, "commit_id": "ca55c40ec722ecb64659682bdb81caa0cfb82e36", "original_commit_id": "aa6c21cfb9f7138eaa747ad6f325ba39ad59e6bf", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "nit: should this be `<= 4`? Same thing below for 8.", "created_at": "2018-04-09T21:19:03Z", "updated_at": "2018-11-23T15:42:06Z", "html_url": "https://github.com/pytorch/pytorch/pull/6119#discussion_r180234060", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6119", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180234060"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6119#discussion_r180234060"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6119"}}, "body_html": "<p>nit: should this be <code>&lt;= 4</code>? Same thing below for 8.</p>", "body_text": "nit: should this be <= 4? Same thing below for 8."}