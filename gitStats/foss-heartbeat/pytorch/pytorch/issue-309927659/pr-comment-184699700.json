{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184699700", "pull_request_review_id": 115952808, "id": 184699700, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDY5OTcwMA==", "diff_hunk": "@@ -3,48 +3,117 @@\n #include \"ATen/ExpandUtils.h\"\n #include \"ATen/NativeFunctions.h\"\n #include \"ATen/WrapDimUtils.h\"\n-#include \"cpu/UnaryOpsKernel.h\"\n+\n+#include \"ATen/CPUApplyUtils.h\"\n+#include \"ATen/Parallel.h\"\n+#include \"ATen/native/cpu/UnaryOpsKernel.h\"\n \n #include <algorithm>\n+#include <cmath>\n #include <functional>\n+#include <iostream>\n #include <numeric>\n #include <vector>\n \n #include <map>\n \n namespace at { namespace native {\n \n-#define IMPLEMENT_UNARY_OP(op)                                                \\\n-Tensor op(const Tensor& self) {                                               \\\n-  Tensor result = self.type().tensor();                                       \\\n-  return at::op ## _out(result, self);                                        \\\n-}                                                                             \\\n-Tensor& op##_(Tensor& self) {                                                 \\\n-  return at::op ## _out(self, self);                                          \\\n-}                                                                             \\\n-Tensor& _ ## op ## _out_cuda(Tensor& result, const Tensor& self) {            \\\n-  return at::_ ## op ## _out(result, self);                                   \\\n-}                                                                             \\\n-Tensor& _ ## op ## _out_cpu(Tensor& result, const Tensor& self) {             \\\n-  if (result.is_contiguous() && self.is_contiguous()) {                       \\\n-    result.resize_(self.sizes());                                             \\\n-    if (result.numel() > 0) {                                                 \\\n-      op ## Impl(result, self);                                               \\\n-    }                                                                         \\\n-    return result;                                                            \\\n-  }                                                                           \\\n-  return at::_ ## op ## _out(result, self);                                   \\\n+static Tensor _sort_strides(Tensor& tensor_) {", "path": "aten/src/ATen/native/UnaryOps.cpp", "position": null, "original_position": 41, "commit_id": "ca55c40ec722ecb64659682bdb81caa0cfb82e36", "original_commit_id": "953f35ee873ca496b1e3c500e3e42e4550eae879", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "body": "For now this still needs to be called here, because otherwise we won't get the contiguous case from sorting a transposed contiguous tensors, since we're still branching instead of processing both cases within the CPUApplyUtils.", "created_at": "2018-04-27T14:13:35Z", "updated_at": "2018-11-23T15:43:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/6119#discussion_r184699700", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6119", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184699700"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6119#discussion_r184699700"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6119"}}, "body_html": "<p>For now this still needs to be called here, because otherwise we won't get the contiguous case from sorting a transposed contiguous tensors, since we're still branching instead of processing both cases within the CPUApplyUtils.</p>", "body_text": "For now this still needs to be called here, because otherwise we won't get the contiguous case from sorting a transposed contiguous tensors, since we're still branching instead of processing both cases within the CPUApplyUtils.", "in_reply_to_id": 184660156}