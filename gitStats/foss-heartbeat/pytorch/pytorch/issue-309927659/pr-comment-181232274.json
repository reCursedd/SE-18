{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181232274", "pull_request_review_id": 111808055, "id": 181232274, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTIzMjI3NA==", "diff_hunk": "@@ -22,289 +26,236 @@ namespace at {\n  * B[1][0]\n  * B[1][1]\n  *\n- * We set the offset into the underlying storage as (storageOffset + stride_B * index_B),\n- * i.e. basically we compute the offset into the storage as we would normally for a\n- * Tensor. But because we are guaranteed the subsequent data is contiguous in memory, we\n- * can simply loop for sizeof(A) iterations and perform the operation, without having to\n- * follow the order described by the strides of A.\n+ * We set the offset into the underlying storage as (storageOffset + stride_B *\n+ * index_B), i.e. basically we compute the offset into the storage as we would\n+ * normally for a Tensor. But because we are guaranteed the subsequent data is\n+ * contiguous in memory, we can simply loop for sizeof(A) iterations and perform\n+ * the operation, without having to follow the order described by the strides of\n+ * A.\n  *\n- * 3. As an optimization, we merge dimensions of A that are contiguous in memory. For\n- * example, if A is a 3x3x3x3 tensor narrowed from a 3x3x4x3 tensor, then the first two\n- * dimensions can be merged for the purposes of APPLY, reducing the number of nested\n- * loops.\n+ * 3. As an optimization, we merge dimensions of A that are contiguous in\n+ * memory. For example, if A is a 3x3x3x3 tensor narrowed from a 3x3x4x3 tensor,\n+ * then the first two dimensions can be merged for the purposes of APPLY,\n+ * reducing the number of nested loops.\n  */\n \n-// TODO: turn this macro into a proper template\n-#define __ATH_TENSOR_APPLYX_PREAMBLE(TYPE, ATENSOR, DIM, ALLOW_CONTIGUOUS) \\\n-  TYPE *ATENSOR##_data = NULL; \\\n-  int64_t *ATENSOR##_counter = NULL, *ATENSOR##_sizes = NULL, *ATENSOR##_strides = NULL, *ATENSOR##_dimOffset = NULL; \\\n-  int64_t ATENSOR##_stride = 0, ATENSOR##_size = 0, ATENSOR##_dim = 0, ATENSOR##_i; \\\n-  int ATENSOR##_contiguous = ALLOW_CONTIGUOUS && DIM < 0; \\\n-\\\n-  if(ATENSOR.sizes().equals({0})) \\\n-    TH_TENSOR_APPLY_hasFinished = true; \\\n-  else \\\n-  { \\\n-    ATENSOR##_data = ATENSOR.data<TYPE>(); \\\n-    ATENSOR##_size = 1; \\\n-    ATENSOR##_stride = 1; \\\n-    for(ATENSOR##_i = ATENSOR.dim() - 1; ATENSOR##_i >= 0; ATENSOR##_i--) { \\\n-      if(ATENSOR.sizes()[ATENSOR##_i] != 1) { \\\n-        if(ATENSOR.strides()[ATENSOR##_i] == ATENSOR##_size && ATENSOR##_i != DIM) \\\n-          ATENSOR##_size *= ATENSOR.sizes()[ATENSOR##_i]; \\\n-        else{ \\\n-          ATENSOR##_contiguous = 0; \\\n-          break; \\\n-        } \\\n-      } \\\n-    } \\\n-    if (!ATENSOR##_contiguous) { \\\n-      /* Find the dimension of contiguous sections */ \\\n-      ATENSOR##_dim = 1; \\\n-      for(ATENSOR##_i = ATENSOR.dim() - 2; ATENSOR##_i >= 0; ATENSOR##_i--) \\\n-      { \\\n-        if(ATENSOR.strides()[ATENSOR##_i] != ATENSOR.strides()[ATENSOR##_i+1] * ATENSOR.sizes()[ATENSOR##_i+1] || ATENSOR##_i == DIM || ATENSOR##_i+1 == DIM) \\\n-          ATENSOR##_dim++; \\\n-      } \\\n-      /* Allocate an array of 3*dim elements, where dim is the number of contiguous sections */ \\\n-      ATENSOR##_counter = new int64_t[3*ATENSOR##_dim]; \\\n-      ATENSOR##_sizes = ATENSOR##_counter + ATENSOR##_dim; \\\n-      ATENSOR##_strides = ATENSOR##_counter + 2*ATENSOR##_dim; \\\n-      TH_TENSOR_dim_index = ATENSOR##_dim-1; \\\n-      ATENSOR##_dimOffset = (DIM == ATENSOR.dim()-1) ? &ATENSOR##_i : &ATENSOR##_counter[DIM]; \\\n-      ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR.dim()-1]; \\\n-      ATENSOR##_strides[TH_TENSOR_dim_index] = ATENSOR.strides()[ATENSOR.dim()-1]; \\\n-      /* ATENSOR##_counter tracks where we are in the storage. The offset into the */ \\\n-      /* storage is given by storage_offset + (i * j), where i is the stride */ \\\n-      /* vector and j is tensor_counter vector. This sets the starting position for the loop. */ \\\n-      for(ATENSOR##_i = ATENSOR##_dim-1; ATENSOR##_i >= 0; --ATENSOR##_i) { \\\n-        ATENSOR##_counter[ATENSOR##_i] = 0; \\\n-      } \\\n-      for(ATENSOR##_i = ATENSOR.dim()-2; ATENSOR##_i >= 0; --ATENSOR##_i) { \\\n-        if (ATENSOR.strides()[ATENSOR##_i] == ATENSOR.strides()[ATENSOR##_i+1] * ATENSOR.sizes()[ATENSOR##_i+1] && ATENSOR##_i != DIM && ATENSOR##_i+1 != DIM) { \\\n-          ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR##_i] * ATENSOR##_sizes[TH_TENSOR_dim_index]; \\\n-          if (DIM != ATENSOR.dim()-1 && ATENSOR##_i < DIM) \\\n-            ATENSOR##_dimOffset--; \\\n-        } else { \\\n-          --TH_TENSOR_dim_index; \\\n-          ATENSOR##_sizes[TH_TENSOR_dim_index] = ATENSOR.sizes()[ATENSOR##_i]; \\\n-          ATENSOR##_strides[TH_TENSOR_dim_index] = ATENSOR.strides()[ATENSOR##_i]; \\\n-        } \\\n-      } \\\n-      /* Size of the inner most section */ \\\n-      ATENSOR##_size = ATENSOR##_sizes[ATENSOR##_dim-1]; \\\n-      /* Stride of the inner most section */ \\\n-      ATENSOR##_stride = ATENSOR##_strides[ATENSOR##_dim-1]; \\\n-    } \\\n-  } \\\n-  ATENSOR##_i = 0;\n+template <typename T, int N>\n+struct strided_tensor_iter_fixed {\n+ public:\n+  T* data_ = NULL;\n+  int64_t dim_;\n \n-// TODO: turn this macro into a proper template\n-#define  __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(ATENSOR, ALWAYS_UPDATE) \\\n-  if(ATENSOR##_i == ATENSOR##_size || ALWAYS_UPDATE) \\\n-  { \\\n-    if(ATENSOR##_contiguous) \\\n-      break; \\\n-\\\n-    if(ATENSOR##_dim == 1) \\\n-       break; \\\n-\\\n-    /* Reset pointer to beginning of loop */ \\\n-    ATENSOR##_data -= ATENSOR##_size*ATENSOR##_stride; \\\n-    for(ATENSOR##_i = ATENSOR##_dim-2; ATENSOR##_i >= 0; ATENSOR##_i--) \\\n-    { \\\n-      ATENSOR##_counter[ATENSOR##_i]++; \\\n-      /* Jump ahread by the stride of this dimension */ \\\n-      ATENSOR##_data += ATENSOR##_strides[ATENSOR##_i]; \\\n-\\\n-      if(ATENSOR##_counter[ATENSOR##_i]  == ATENSOR##_sizes[ATENSOR##_i]) \\\n-      { \\\n-        if(ATENSOR##_i == 0) \\\n-        { \\\n-          TH_TENSOR_APPLY_hasFinished = true; \\\n-          break; \\\n-        } \\\n-          else \\\n-        { \\\n-          /* Reset the pointer to the beginning of the chunk defined by this dimension */ \\\n-          ATENSOR##_data -= ATENSOR##_counter[ATENSOR##_i]*ATENSOR##_strides[ATENSOR##_i]; \\\n-          ATENSOR##_counter[ATENSOR##_i] = 0; \\\n-        } \\\n-      } \\\n-      else \\\n-        break; \\\n-    } \\\n-    ATENSOR##_i = 0; \\\n-  }\n+  int64_t counter_[N];\n+  int64_t sizes_[N];\n+  int64_t strides_[N];\n \n-template <typename scalar1, typename scalar2, typename Op>\n-void CPU_tensor_apply2_dim(Tensor& tensor1, Tensor& tensor2, int64_t dim, Op op) {\n-  checkBackend(\"CPU_tensor_apply2\", {tensor1, tensor2}, Backend::CPU);\n-  bool TH_TENSOR_APPLY_hasFinished = false;\n-  int64_t TH_TENSOR_dim_index = 0;\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar1, tensor1, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar2, tensor2, dim, 1)\n-  auto t1_numel = tensor1.numel();\n-  auto t2_numel = tensor2.numel();\n-  if(t1_numel != t2_numel) {\n-    std::ostringstream oss;\n-    oss << \"inconsistent tensor size, expected \" << tensor1.sizes() << \" and \" << tensor2.sizes()\n-        << \" to have the same number of elements, but got \" << t1_numel << \" and \" << t2_numel << \" elements respectively\";\n-    throw std::runtime_error(oss.str());\n-  }\n-  while(!TH_TENSOR_APPLY_hasFinished)\n-  {\n-    /* Loop through the inner most region of the Tensor */\n-    for(; tensor1_i < tensor1_size && tensor2_i < tensor2_size; tensor1_i++, tensor2_i++, tensor1_data += tensor1_stride, tensor2_data += tensor2_stride)\n-    {\n-      op(*tensor1_data, *tensor2_data);\n+  strided_tensor_iter_fixed(strided_tensor_iter_fixed const&) = delete;\n+  void operator=(strided_tensor_iter_fixed const& x) = delete;\n+  strided_tensor_iter_fixed(strided_tensor_iter_fixed&&) = default;\n+  strided_tensor_iter_fixed(Tensor& tensor) : data_(tensor.data<T>()), dim_(0) {\n+    int64_t max_dim = tensor.ndimension();\n+    dim_ = 0;\n+    for (int64_t i = 0; i < max_dim; i++) {\n+      int64_t size = tensor.size(i);\n+      int64_t stride = tensor.stride(i);\n+      while (i + 1 < max_dim &&\n+             tensor.stride(i) == tensor.size(i + 1) * tensor.stride(i + 1)) {\n+        size = size * tensor.size(i + 1);\n+        stride = tensor.stride(i + 1);\n+        i++;\n+      }\n+      sizes_[dim_] = size;\n+      strides_[dim_] = stride;\n+      counter_[dim_] = 0;\n+      dim_++;\n     }\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor1, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor2, 0)\n   }\n-  if(tensor1_counter != NULL)\n-    delete [] tensor1_counter;\n-  if(tensor2_counter != NULL)\n-    delete [] tensor2_counter;\n-}\n+};\n \n-/*\n-  Apply a pointwise operator to two tensors.\n+template <typename T>\n+struct strided_tensor_iter {\n+ private:\n+ public:\n+  T* data_ = NULL;\n+  const int64_t dim_;\n \n-  The calling convention for op is a function/functor that takes takes two references to\n-  type scalar; at least one of these references should be non-const in order to write the output.\n-  For example, to compute a = b^2, op would be of the form:\n-  [](scalar &a_val, const scalar &b_val) { a_val = b_val * b_val; };\n-*/\n-template<typename scalar1, typename scalar2, typename Op>\n-void CPU_tensor_apply2(Tensor tensor1, Tensor tensor2, Op op) {\n-  CPU_tensor_apply2_dim<scalar1, scalar2, Op>(tensor1, tensor2, -1, op);\n-}\n+  std::vector<int64_t> counter_;\n+  std::vector<int64_t> sizes_;\n+  std::vector<int64_t> strides_;\n \n-template<typename scalar1, typename scalar2, typename scalar3, typename Op>\n-void CPU_tensor_apply3_dim(Tensor &tensor1, Tensor& tensor2, Tensor& tensor3, int64_t dim, Op op) {\n-  checkBackend(\"CPU_tensor_apply3\", {tensor1, tensor2, tensor3}, Backend::CPU);\n-  bool TH_TENSOR_APPLY_hasFinished = false;\n-  int64_t TH_TENSOR_dim_index = 0;\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar1, tensor1, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar2, tensor2, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar3, tensor3, dim, 1)\n+  strided_tensor_iter(strided_tensor_iter const&) = delete;\n+  void operator=(strided_tensor_iter const& x) = delete;\n+  strided_tensor_iter(strided_tensor_iter&&) = default;\n+  strided_tensor_iter(Tensor& tensor)\n+      : data_(tensor.data<T>()),\n+        dim_(tensor.ndimension()),\n+        counter_(dim_, 0),\n+        sizes_(tensor.sizes()),\n+        strides_(tensor.strides()) {}\n+};\n \n-  int elements_equal = 1;\n-  auto t1_numel = tensor1.numel();\n-  auto t2_numel = tensor2.numel();\n-  auto t3_numel = tensor3.numel();\n-  if(t1_numel!= t2_numel) {\n-    elements_equal = 0;\n-  } else if(t1_numel != t3_numel) {\n-    elements_equal = 0;\n+template <typename Arg>\n+inline void iterate(Arg& ut) {\n+  if (ut.counter_[ut.dim_ - 1] == ut.sizes_[ut.dim_ - 1]) {\n+    for (int64_t i = ut.dim_ - 1; i > 0; i--) {\n+      if (ut.counter_[i] == ut.sizes_[i]) {\n+        ut.counter_[i] = 0;\n+        ut.counter_[i - 1]++;\n+        ut.data_ =\n+            ut.data_ - (ut.sizes_[i] * ut.strides_[i]) + ut.strides_[i - 1];\n+      }\n+    }\n   }\n-  if (elements_equal == 0) {\n-    std::ostringstream oss;\n-    oss << \"inconsistent tensor size, expected \" << tensor1.sizes() << \", \" << tensor2.sizes() << \", and \" << tensor3.sizes()\n-        << \" to have the same number of elements, but got \" << t1_numel << \", \" << t2_numel << \", and \" << t3_numel << \" elements respectively\";\n-    throw std::runtime_error(oss.str());\n+}\n+\n+inline bool _all_equal_numel(at::ArrayRef<Tensor> tensors) {\n+  if (tensors.size() == 0)\n+    return true;\n+  int64_t all_numel = tensors[0].numel();\n+  for (size_t i = 1; i < tensors.size(); i++) {\n+    if (tensors[i].numel() != all_numel)\n+      return false;\n   }\n+  return true;\n+}\n \n-  while(!TH_TENSOR_APPLY_hasFinished)\n-  {\n-    /* Loop through the inner most region of the Tensor */\n-    for(; tensor1_i <  tensor1_size && tensor2_i < tensor2_size && tensor3_i < tensor3_size; tensor1_i++, tensor2_i++, tensor3_i++, tensor1_data += tensor1_stride, tensor2_data += tensor2_stride, tensor3_data += tensor3_stride)\n-    {\n-      op(*tensor1_data, *tensor2_data, *tensor3_data);\n-    }\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor1, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor2, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor3, 0)\n+inline std::string _all_equal_numel_error(at::ArrayRef<Tensor> tensors) {\n+  std::ostringstream oss;\n+  oss << \"inconsistent tensor size, expected \";\n+  for (size_t i = 0; i < tensors.size() - 1; i++) {\n+    oss << tensors[i].sizes() << \", \";\n+  }\n+  oss << \"and \" << tensors[tensors.size() - 1]\n+      << \" to have the same number of elements, but got \";\n+  for (size_t i = 0; i < tensors.size() - 1; i++) {\n+    oss << tensors[i].numel() << \", \";\n   }\n-  if(tensor1_counter != NULL)\n-    delete [] tensor1_counter;\n-  if(tensor2_counter != NULL)\n-    delete [] tensor2_counter;\n-  if(tensor3_counter != NULL)\n-    delete [] tensor3_counter;\n+  oss << \"and \" << tensors[tensors.size() - 1].numel()\n+      << \" elements respectively\";\n+  return oss.str();\n }\n \n-/*\n-  Apply a pointwise operator to three tensors.\n+inline bool _apply_preamble(ArrayRef<Tensor> tensors) {\n+  checkBackend(\"CPU_tensor_apply\", tensors, Backend::CPU);\n+  if (!_all_equal_numel(tensors))\n+    throw std::runtime_error(_all_equal_numel_error(tensors));\n+  // An empty tensor has no elements\n+  for (auto& t : tensors)\n+    if (t.sizes().equals({0}))\n+      return false;\n+  return true;\n+}\n \n-  The calling convention for op is a function/functor that takes takes three references to\n-  type scalar; at least one of these references should be non-const in order to write the output.\n-  For example, to compute a = b + c, op would be of the form:\n-  [](scalar &a_val, const scalar &b_val, const scalar &c_val) { a_val = b_val + c_val; };\n-*/\n-template<typename scalar1, typename scalar2, typename scalar3, typename Op>\n-void CPU_tensor_apply3(Tensor tensor1, Tensor tensor2, Tensor tensor3, Op op) {\n-  CPU_tensor_apply3_dim<scalar1, scalar2, scalar3, Op>(tensor1, tensor2, tensor3, -1, op);\n+inline void iterate_all(){};\n+\n+template <typename Arg, typename... Args>\n+inline void iterate_all(Arg& iter, Args&... iter_tail) {\n+  iterate(iter);\n+  iterate_all(iter_tail...);\n }\n \n-template <typename scalar1, typename scalar2, typename scalar3, typename scalar4, typename Op>\n-void CPU_tensor_apply4_dim(Tensor &tensor1, Tensor& tensor2, Tensor& tensor3, Tensor& tensor4, int64_t dim, Op op) {\n-  checkBackend(\"CPU_tensor_apply4\", {tensor1, tensor2, tensor3, tensor4}, Backend::CPU);\n-  bool TH_TENSOR_APPLY_hasFinished = false;\n-  int64_t TH_TENSOR_dim_index = 0;\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar1, tensor1, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar2, tensor2, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar3, tensor3, dim, 1)\n-  __ATH_TENSOR_APPLYX_PREAMBLE(scalar4, tensor4, dim, 1)\n+inline bool continue_loop() {\n+  return true;\n+}\n \n-  int elements_equal = 1;\n-  auto t1_numel = tensor1.numel();\n-  auto t2_numel = tensor2.numel();\n-  auto t3_numel = tensor3.numel();\n-  auto t4_numel = tensor4.numel();\n-  if(t1_numel!= t2_numel) {\n-    elements_equal = 0;\n-  } else if(t1_numel != t3_numel) {\n-    elements_equal = 0;\n-  } else if(t1_numel != t4_numel) {\n-      elements_equal = 0;\n-  }\n-  if (elements_equal == 0) {\n-    std::ostringstream oss;\n-    oss << \"inconsistent tensor size, expected \" << tensor1.sizes() << \", \" << tensor2.sizes() << \", \"\n-        << tensor3.sizes() << \", and \" << tensor4.sizes() << \" to have the same number of elements, but got \"\n-        << t1_numel << \", \" << t2_numel << \", \" << t3_numel << \", and \" << t4_numel << \" elements respectively\";\n-    throw std::runtime_error(oss.str());\n+template <typename Arg, typename... Args>\n+inline bool continue_loop(Arg& iter, Args&... iter_tail) {\n+  bool result = false;\n+  if (iter.dim_ != 0) {\n+    result = (iter.counter_[iter.dim_ - 1] < iter.sizes_[iter.dim_ - 1]);\n   }\n+  return result && continue_loop(iter_tail...);\n+}\n+\n+inline void increase_counters(){};\n \n-  while(!TH_TENSOR_APPLY_hasFinished)\n-  {\n-    /* Loop through the inner most region of the Tensor */\n-    for(; tensor1_i <  tensor1_size && tensor2_i < tensor2_size && tensor3_i < tensor3_size && tensor4_i < tensor4_size\n-        ; tensor1_i++, tensor2_i++, tensor3_i++, tensor4_i++,\n-          tensor1_data += tensor1_stride, tensor2_data += tensor2_stride, tensor3_data += tensor3_stride, tensor4_data += tensor4_stride)\n-    {\n-      op(*tensor1_data, *tensor2_data, *tensor3_data, *tensor4_data);\n+template <typename Arg, typename... Args>\n+inline void increase_counters(Arg& iter, Args&... iter_tail) {\n+  iter.counter_[iter.dim_ - 1]++;\n+  iter.data_ += iter.strides_[iter.dim_ - 1];\n+  increase_counters(iter_tail...);\n+}\n+\n+inline void apply_op(){};\n+\n+template <typename Op, typename... Args>\n+inline void apply_op(int64_t numel, const Op& op, Args... iters) {\n+  // For 0-dim tensors\n+  if (numel == 1 && !continue_loop(iters...)) {\n+    op(*iters.data_...);\n+    return;\n+  }\n+  for (int64_t i = 0; i < numel;) {\n+    for (; continue_loop(iters...); increase_counters(iters...)) {\n+      op(*iters.data_...);\n+      i++;\n     }\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor1, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor2, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor3, 0)\n-    __ATH_TENSOR_APPLYX_UPDATE_COUNTERS(tensor4, 0)\n+    iterate_all(iters...);", "path": "aten/src/ATen/CPUApplyUtils.h", "position": null, "original_position": 431, "commit_id": "ca55c40ec722ecb64659682bdb81caa0cfb82e36", "original_commit_id": "52c3f836fbe1d24eee063a499a6f11fc8816269f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Do I understand correctly that `increase_counters` just blindly increments them, while `iterate` takes care of dim overflows in counters? Why the distinction? It looks like `iterate_all` is always followed by `increase_counters`, so why keep them separate?", "created_at": "2018-04-12T21:49:05Z", "updated_at": "2018-11-23T15:42:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/6119#discussion_r181232274", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6119", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181232274"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6119#discussion_r181232274"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6119"}}, "body_html": "<p>Do I understand correctly that <code>increase_counters</code> just blindly increments them, while <code>iterate</code> takes care of dim overflows in counters? Why the distinction? It looks like <code>iterate_all</code> is always followed by <code>increase_counters</code>, so why keep them separate?</p>", "body_text": "Do I understand correctly that increase_counters just blindly increments them, while iterate takes care of dim overflows in counters? Why the distinction? It looks like iterate_all is always followed by increase_counters, so why keep them separate?"}