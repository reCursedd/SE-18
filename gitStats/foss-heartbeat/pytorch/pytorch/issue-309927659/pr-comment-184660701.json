{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184660701", "pull_request_review_id": 115901671, "id": 184660701, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDY2MDcwMQ==", "diff_hunk": "@@ -3,48 +3,117 @@\n #include \"ATen/ExpandUtils.h\"\n #include \"ATen/NativeFunctions.h\"\n #include \"ATen/WrapDimUtils.h\"\n-#include \"cpu/UnaryOpsKernel.h\"\n+\n+#include \"ATen/CPUApplyUtils.h\"\n+#include \"ATen/Parallel.h\"\n+#include \"ATen/native/cpu/UnaryOpsKernel.h\"\n \n #include <algorithm>\n+#include <cmath>\n #include <functional>\n+#include <iostream>\n #include <numeric>\n #include <vector>\n \n #include <map>\n \n namespace at { namespace native {\n \n-#define IMPLEMENT_UNARY_OP(op)                                                \\\n-Tensor op(const Tensor& self) {                                               \\\n-  Tensor result = self.type().tensor();                                       \\\n-  return at::op ## _out(result, self);                                        \\\n-}                                                                             \\\n-Tensor& op##_(Tensor& self) {                                                 \\\n-  return at::op ## _out(self, self);                                          \\\n-}                                                                             \\\n-Tensor& _ ## op ## _out_cuda(Tensor& result, const Tensor& self) {            \\\n-  return at::_ ## op ## _out(result, self);                                   \\\n-}                                                                             \\\n-Tensor& _ ## op ## _out_cpu(Tensor& result, const Tensor& self) {             \\\n-  if (result.is_contiguous() && self.is_contiguous()) {                       \\\n-    result.resize_(self.sizes());                                             \\\n-    if (result.numel() > 0) {                                                 \\\n-      op ## Impl(result, self);                                               \\\n-    }                                                                         \\\n-    return result;                                                            \\\n-  }                                                                           \\\n-  return at::_ ## op ## _out(result, self);                                   \\\n+static Tensor _sort_strides(Tensor& tensor_) {\n+  std::vector<int64_t> strides = tensor_.strides();\n+  std::vector<int64_t> indices(strides.size());\n+  iota(indices.begin(), indices.end(), 0);\n+  std::sort(indices.begin(), indices.end(), [&strides](int64_t i1, int64_t i2) {\n+    return strides[i1] > strides[i2];\n+  });\n+  Tensor tensor = tensor_.permute(indices);\n+  return tensor;\n }\n \n-IMPLEMENT_UNARY_OP(abs)\n-IMPLEMENT_UNARY_OP(ceil)\n-IMPLEMENT_UNARY_OP(cos)\n-IMPLEMENT_UNARY_OP(exp)\n-IMPLEMENT_UNARY_OP(floor)\n-IMPLEMENT_UNARY_OP(log)\n-IMPLEMENT_UNARY_OP(round)\n-IMPLEMENT_UNARY_OP(sin)\n-IMPLEMENT_UNARY_OP(sqrt)\n-IMPLEMENT_UNARY_OP(trunc)\n-\n-}} // namespace at::native\n+#define IMPLEMENT_UNARY_OP_PREQUEL(op)                           \\\n+  Tensor op(const Tensor& self) {                                \\\n+    Tensor result = self.type().tensor();                        \\\n+    return at::op##_out(result, self);                           \\\n+  }                                                              \\\n+  Tensor& _##op##__cuda(Tensor& self) {                          \\\n+    return at::_##op##_out(self, self);                                    \\\n+  }                                                              \\\n+  Tensor& _##op##_out_cuda(Tensor& result, const Tensor& self) { \\\n+    return at::_##op##_out(result, self);                        \\\n+  }\n+\n+#define IMPLEMENT_UNARY_OP_FLOAT_CMATH(op)                                   \\\n+  Tensor& _##op##__cpu(Tensor& self_) {                                      \\\n+    if (self_.numel() > 0) {                                                 \\\n+      Tensor self = _sort_strides(self_);                                    \\\n+      AT_DISPATCH_FLOATING_TYPES(self.type(), op, [&] {                      \\\n+        CPU_tensor_parallel_apply1<scalar_t>(                                \\\n+            self, [](scalar_t& y) { y = std::op(y); });                      \\\n+      });                                                                    \\\n+    }                                                                        \\\n+    return self_;                                                            \\\n+  }                                                                          \\\n+  Tensor& _##op##_out_cpu(Tensor& result, const Tensor& self) {              \\\n+    result.resize_(self.sizes());                                            \\\n+    if (result.numel() > 0) {                                                \\\n+      AT_DISPATCH_FLOATING_TYPES(self.type(), op, [&] {                      \\\n+        CPU_tensor_parallel_apply2<scalar_t, scalar_t>(                      \\\n+            result, self, [](scalar_t& y, scalar_t& x) { y = std::op(x); }); \\\n+      });                                                                    \\\n+    }                                                                        \\\n+    return result;                                                           \\\n+  }\n+\n+#define IMPLEMENT_UNARY_OP_VEC(op)                                             \\\n+  Tensor& _##op##__cpu(Tensor& self_) {                                        \\\n+    if (self_.numel() > 0) {                                                   \\\n+      Tensor self = _sort_strides(self_);                                      \\\n+      if (self.is_contiguous()) {                                              \\\n+        at::op##_out(self, self);                                              \\", "path": "aten/src/ATen/native/UnaryOps.cpp", "position": null, "original_position": 103, "commit_id": "ca55c40ec722ecb64659682bdb81caa0cfb82e36", "original_commit_id": "953f35ee873ca496b1e3c500e3e42e4550eae879", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Couldn't we call `op##Impl(self, self)` directly?", "created_at": "2018-04-27T11:25:52Z", "updated_at": "2018-11-23T15:43:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/6119#discussion_r184660701", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6119", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184660701"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6119#discussion_r184660701"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6119"}}, "body_html": "<p>Couldn't we call <code>op##Impl(self, self)</code> directly?</p>", "body_text": "Couldn't we call op##Impl(self, self) directly?"}