{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/303772421", "html_url": "https://github.com/pytorch/pytorch/pull/1594#issuecomment-303772421", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1594", "id": 303772421, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzc3MjQyMQ==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-24T16:08:42Z", "updated_at": "2017-05-24T16:08:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You can't cudaMalloc largest_cached_free_block without first emptying cache, right? And in some unfortunate cases subsequent cudaFree'ing can interfere with nccl (though in some unfortunate cases that may happen also when caching allocator can't allocate requested block and starts cleaning up). Grrr, this is so hard to solve cleanly.</p>", "body_text": "You can't cudaMalloc largest_cached_free_block without first emptying cache, right? And in some unfortunate cases subsequent cudaFree'ing can interfere with nccl (though in some unfortunate cases that may happen also when caching allocator can't allocate requested block and starts cleaning up). Grrr, this is so hard to solve cleanly.", "body": "You can't cudaMalloc largest_cached_free_block without first emptying cache, right? And in some unfortunate cases subsequent cudaFree'ing can interfere with nccl (though in some unfortunate cases that may happen also when caching allocator can't allocate requested block and starts cleaning up). Grrr, this is so hard to solve cleanly. "}