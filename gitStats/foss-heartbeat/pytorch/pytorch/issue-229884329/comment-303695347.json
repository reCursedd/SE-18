{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/303695347", "html_url": "https://github.com/pytorch/pytorch/pull/1594#issuecomment-303695347", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1594", "id": 303695347, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzY5NTM0Nw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-24T11:20:33Z", "updated_at": "2017-05-24T11:20:56Z", "author_association": "MEMBER", "body_html": "<p>Yeah sure. Everything is ok as long as the cache is going to be flushed only when benchmarks are run (this should only happen a few times during training).</p>\n<p>Actually I've just started wondering if it wouldn't be simpler to limit the max workspace size to <code>max(largest_cached_free_block, free_device_memory)</code> and use use <code>cudaMalloc</code> (without using THC) to allocate the benchmarks workspace. This shouldn't change the state of cache at all, and wouldn't require the flush.</p>", "body_text": "Yeah sure. Everything is ok as long as the cache is going to be flushed only when benchmarks are run (this should only happen a few times during training).\nActually I've just started wondering if it wouldn't be simpler to limit the max workspace size to max(largest_cached_free_block, free_device_memory) and use use cudaMalloc (without using THC) to allocate the benchmarks workspace. This shouldn't change the state of cache at all, and wouldn't require the flush.", "body": "Yeah sure. Everything is ok as long as the cache is going to be flushed only when benchmarks are run (this should only happen a few times during training). \r\n\r\nActually I've just started wondering if it wouldn't be simpler to limit the max workspace size to `max(largest_cached_free_block, free_device_memory)` and use use `cudaMalloc` (without using THC) to allocate the benchmarks workspace. This shouldn't change the state of cache at all, and wouldn't require the flush."}