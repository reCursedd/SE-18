{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/86693702", "pull_request_review_id": 7338159, "id": 86693702, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDg2NjkzNzAy", "diff_hunk": "@@ -12,39 +17,41 @@ def _fd_id(fd):\n \n \n def _shm_object_handle(handle):\n-    if len(handle) == 3:\n+    if len(handle) == 3 or len(handle) == 5:\n         return handle[1]\n     else:\n         return _fd_id(handle[0])\n \n \n def _shared_serialize(self, use_fd):\n-    handle, weak_storage = self._share(use_fd)\n+    handle, storage_ref = self._share(use_fd, StorageRef)\n     object_handle = _shm_object_handle(handle)\n-    _shared_cache[object_handle] = weak_storage\n-    self._shared_incref()\n+    _shared_cache[object_handle] = storage_ref\n+    if not self.is_cuda:\n+        self._shared_incref()\n     return handle\n \n \n-def _shared_deserialize(cls, args):\n-    object_handle = _shm_object_handle(args)\n+def _shared_deserialize(cls, handle):\n+    object_handle = _shm_object_handle(handle)\n     new_storage = None\n \n-    try:\n-        weak_storage = _shared_cache[object_handle]\n-        # Try to momentarily convert a weak reference into a strong one\n-        weak_storage.retain()\n-        if weak_storage._cdata != 0:\n-            # Success, we managed to retain the storage before it was freed\n-            new_storage = type(weak_storage)(cdata=weak_storage._cdata)\n-    except KeyError:\n-        pass\n+    storage_ref = _shared_cache.get(object_handle)\n+    if storage_ref:\n+        new_storage = cls._new_with_weak_ptr(storage_ref)\n+        if new_storage and len(handle) == 5:\n+            # CUDA handles include an offset and size\n+            offset, size = handle[3:5]\n+            new_storage = new_storage._new_view(offset, size)\n \n     if new_storage is None:\n-        new_storage, weak_storage = cls._new_shared(*args)\n-        _shared_cache[object_handle] = weak_storage\n+        if cls.is_cuda:\n+            torch.cuda._lazy_init()\n+        new_storage, storage_ref = cls._new_shared(handle, StorageRef)\n+        _shared_cache[object_handle] = storage_ref\n \n-    new_storage._shared_decref()\n+    if not new_storage.is_cuda:\n+        new_storage._shared_decref()", "path": "torch/multiprocessing/_storage.py", "position": null, "original_position": 70, "commit_id": "f2c88c328ee29fb70123b30a2c637434382624c9", "original_commit_id": "782b98406e53e23328102307e4f8a0271d9f5231", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Same as with incref\n", "created_at": "2016-11-06T19:14:57Z", "updated_at": "2018-11-23T15:31:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/203#discussion_r86693702", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/203", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/86693702"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/203#discussion_r86693702"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/203"}}, "body_html": "<p>Same as with incref</p>", "body_text": "Same as with incref"}