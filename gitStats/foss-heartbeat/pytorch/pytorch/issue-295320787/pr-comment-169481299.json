{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169481299", "pull_request_review_id": 98014456, "id": 169481299, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2OTQ4MTI5OQ==", "diff_hunk": "@@ -169,17 +225,18 @@ def tmp(t):\n     ('pow', small_3d, lambda t: [number(2., 2, t)], 'pow2', float_types),\n     ('pow', small_3d, lambda t: [number(3., 3, t)], 'pow3', float_types),\n     ('pow', small_3d, lambda t: [number(-1., -1, t)], 'pow-1', float_types),\n-    ('pow', small_3d, lambda t: [number(-2., -2, t)], 'pow-2', float_types),\n-    ('pow', small_3d, lambda t: [small_3d(t).abs_()], 'tensor', float_types),\n+    # HalfTensor gives bad result at pow-2 with data sampled from torch.randn\n+    ('pow', small_3d, lambda t: [number(-2., -2, t)], 'pow-2', float_types_no_half),", "path": "test/test_cuda.py", "position": 146, "original_position": 143, "commit_id": "71c458ece098633106b7f73c744f43c85bb0d318", "original_commit_id": "aedc804ef14049e2ad38dc03a70fdba227399ae5", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "body": "The difference between float cpu and half gpu results is too large. For example, \r\n```\r\n>>> a=torch.cuda.HalfTensor([0.0069])\r\n>>> a\r\n\r\n1.00000e-03 *\r\n  6.9008\r\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\r\n\r\n>>> a.pow(-2)\r\n\r\n 20992\r\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\r\n\r\n>>> b=torch.cuda.FloatTensor([0.0069])\r\n>>> b.pow(-2)\r\n\r\n 21003.9902\r\n[torch.cuda.FloatTensor of size 1 (GPU 0)]\r\n```\r\nwith a power of -2, the difference can easily go above 1 even 10 so I thought it's okay to skip it. \r\n", "created_at": "2018-02-20T22:28:08Z", "updated_at": "2018-11-23T15:39:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/5122#discussion_r169481299", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5122", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169481299"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5122#discussion_r169481299"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5122"}}, "body_html": "<p>The difference between float cpu and half gpu results is too large. For example,</p>\n<pre><code>&gt;&gt;&gt; a=torch.cuda.HalfTensor([0.0069])\n&gt;&gt;&gt; a\n\n1.00000e-03 *\n  6.9008\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\n\n&gt;&gt;&gt; a.pow(-2)\n\n 20992\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\n\n&gt;&gt;&gt; b=torch.cuda.FloatTensor([0.0069])\n&gt;&gt;&gt; b.pow(-2)\n\n 21003.9902\n[torch.cuda.FloatTensor of size 1 (GPU 0)]\n</code></pre>\n<p>with a power of -2, the difference can easily go above 1 even 10 so I thought it's okay to skip it.</p>", "body_text": "The difference between float cpu and half gpu results is too large. For example,\n>>> a=torch.cuda.HalfTensor([0.0069])\n>>> a\n\n1.00000e-03 *\n  6.9008\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\n\n>>> a.pow(-2)\n\n 20992\n[torch.cuda.HalfTensor of size 1 (GPU 0)]\n\n>>> b=torch.cuda.FloatTensor([0.0069])\n>>> b.pow(-2)\n\n 21003.9902\n[torch.cuda.FloatTensor of size 1 (GPU 0)]\n\nwith a power of -2, the difference can easily go above 1 even 10 so I thought it's okay to skip it.", "in_reply_to_id": 168965969}