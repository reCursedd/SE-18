{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/433632322", "html_url": "https://github.com/pytorch/pytorch/issues/13209#issuecomment-433632322", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13209", "id": 433632322, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzYzMjMyMg==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-27T15:55:41Z", "updated_at": "2018-10-27T16:20:49Z", "author_association": "NONE", "body_html": "<p>I chatted with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> and we found a repro:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\na <span class=\"pl-k\">=</span> torch.load(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>xr.pt7<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(a.sum(<span class=\"pl-v\">dim</span> <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]))\n<span class=\"pl-c1\">print</span>(a.sum(<span class=\"pl-v\">dim</span> <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]))\n<span class=\"pl-c1\">print</span>(a)\n<span class=\"pl-c1\">print</span>(a.sum(<span class=\"pl-v\">dim</span> <span class=\"pl-k\">=</span> [<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]))</pre></div>\n<pre><code>tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', grad_fn=&lt;SumBackward2&gt;)\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', grad_fn=&lt;SumBackward2&gt;)\ntensor([[[[7.4156e-01, 6.4194e-01, ..., 7.8143e-01]]]], device='cuda:0', requires_grad=True) # this is print(x)\ntensor([[0.8696, 0.7665, 0.7814, 0.7338, 0.7225, 0.7059, 0.6850, 0.7237, 0.6988,\n         0.6976, 0.6906, 0.7052, 0.7207, 0.7307, 0.7172, 0.6921, 0.6703, 0.6489,\n         0.6426, 0.6478]], device='cuda:0', grad_fn=&lt;SumBackward2&gt;)\n</code></pre>\n<p><a href=\"https://github.com/pytorch/pytorch/files/2521958/log.txt\">log.txt</a><br>\n<a href=\"https://github.com/pytorch/pytorch/files/2521959/xr.zip\">xr.zip</a></p>", "body_text": "I chatted with @colesbury and we found a repro:\nimport torch\n\na = torch.load('xr.pt7')\nprint(a.sum(dim = [-2, -1]))\nprint(a.sum(dim = [-2, -1]))\nprint(a)\nprint(a.sum(dim = [-2, -1]))\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', grad_fn=<SumBackward2>)\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', grad_fn=<SumBackward2>)\ntensor([[[[7.4156e-01, 6.4194e-01, ..., 7.8143e-01]]]], device='cuda:0', requires_grad=True) # this is print(x)\ntensor([[0.8696, 0.7665, 0.7814, 0.7338, 0.7225, 0.7059, 0.6850, 0.7237, 0.6988,\n         0.6976, 0.6906, 0.7052, 0.7207, 0.7307, 0.7172, 0.6921, 0.6703, 0.6489,\n         0.6426, 0.6478]], device='cuda:0', grad_fn=<SumBackward2>)\n\nlog.txt\nxr.zip", "body": "I chatted with @colesbury and we found a repro:\r\n\r\n```python\r\nimport torch\r\n\r\na = torch.load('xr.pt7')\r\nprint(a.sum(dim = [-2, -1]))\r\nprint(a.sum(dim = [-2, -1]))\r\nprint(a)\r\nprint(a.sum(dim = [-2, -1]))\r\n```\r\n\r\n```\r\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\r\n       device='cuda:0', grad_fn=<SumBackward2>)\r\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\r\n       device='cuda:0', grad_fn=<SumBackward2>)\r\ntensor([[[[7.4156e-01, 6.4194e-01, ..., 7.8143e-01]]]], device='cuda:0', requires_grad=True) # this is print(x)\r\ntensor([[0.8696, 0.7665, 0.7814, 0.7338, 0.7225, 0.7059, 0.6850, 0.7237, 0.6988,\r\n         0.6976, 0.6906, 0.7052, 0.7207, 0.7307, 0.7172, 0.6921, 0.6703, 0.6489,\r\n         0.6426, 0.6478]], device='cuda:0', grad_fn=<SumBackward2>)\r\n```\r\n\r\n[log.txt](https://github.com/pytorch/pytorch/files/2521958/log.txt)\r\n[xr.zip](https://github.com/pytorch/pytorch/files/2521959/xr.zip)\r\n"}