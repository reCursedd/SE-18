{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/126567760", "pull_request_review_id": 49064263, "id": 126567760, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyNjU2Nzc2MA==", "diff_hunk": "@@ -102,3 +102,42 @@ def backward(ctx, grad_output, grad_LU=None):\n         grad_b, _ = torch.gesv(grad_output, a.t())\n         grad_a = -torch.mm(grad_b, X.t())\n         return grad_b, grad_a\n+\n+class Symeig(Function):\n+\n+    @staticmethod\n+    def forward(ctx, input, eigenvectors=False, upper=True):\n+        ctx.eigenvectors = eigenvectors\n+        ctx.upper = upper\n+        w, v = torch.symeig(input, eigenvectors=ctx.eigenvectors, upper=ctx.upper)\n+        ctx.save_for_backward(input, w, v)\n+        return w, v\n+\n+    @staticmethod\n+    def backward(ctx, grad_w, grad_v):\n+        x, w, v, = ctx.saved_variables\n+\n+        # gives an error if I don't do this..\n+        x = x.data\n+        w = w.data\n+        v = v.data\n+\n+        N = x.size(0)\n+\n+        if ctx.upper:\n+            tri0 = torch.triu\n+            tri1 = lambda a: torch.tril(a, -1)\n+        else:\n+            tri0 = torch.tril\n+            tri1 = lambda a: torch.triu(a, 1)\n+\n+        def G(n):\n+            return sum([v[:, m] * grad_v.t()[n].matmul(v[:, m]) / (w[n] - w[m])", "path": "torch/autograd/_functions/linalg.py", "position": null, "original_position": 34, "commit_id": "8f44e075bef0d627c0991c784b0763e5ddd78980", "original_commit_id": "41962c86c331674e0059974fb6d0ea97a266eff3", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "Can't we simplify that by using sopething like `baddbmm` or some matrix manipulation? This will be very expensive on the GPU as is", "created_at": "2017-07-11T00:13:19Z", "updated_at": "2018-11-23T15:34:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/2026#discussion_r126567760", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2026", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/126567760"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2026#discussion_r126567760"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2026"}}, "body_html": "<p>Can't we simplify that by using sopething like <code>baddbmm</code> or some matrix manipulation? This will be very expensive on the GPU as is</p>", "body_text": "Can't we simplify that by using sopething like baddbmm or some matrix manipulation? This will be very expensive on the GPU as is"}