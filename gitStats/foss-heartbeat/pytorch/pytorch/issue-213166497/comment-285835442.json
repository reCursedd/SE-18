{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/285835442", "html_url": "https://github.com/pytorch/pytorch/issues/964#issuecomment-285835442", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/964", "id": 285835442, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTgzNTQ0Mg==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-11T02:36:14Z", "updated_at": "2017-03-11T02:36:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It turns out that cudnn breaks only for negative values of output_padding. While I certainly could add checks for that, does that mean that regular padding should be checked for negative values too? Cudnn would break in this case also (regular padding being negative), and no checks are performed currently. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6359743\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/albanD\">@albanD</a>, @abweiss, how common is negative padding in transposed convolutions?</p>", "body_text": "It turns out that cudnn breaks only for negative values of output_padding. While I certainly could add checks for that, does that mean that regular padding should be checked for negative values too? Cudnn would break in this case also (regular padding being negative), and no checks are performed currently. @albanD, @abweiss, how common is negative padding in transposed convolutions?", "body": "It turns out that cudnn breaks only for negative values of output_padding. While I certainly could add checks for that, does that mean that regular padding should be checked for negative values too? Cudnn would break in this case also (regular padding being negative), and no checks are performed currently. @albanD, @abweiss, how common is negative padding in transposed convolutions?"}