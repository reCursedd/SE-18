{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11136", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11136/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11136/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11136/events", "html_url": "https://github.com/pytorch/pytorch/issues/11136", "id": 355886334, "node_id": "MDU6SXNzdWUzNTU4ODYzMzQ=", "number": 11136, "title": "[feature request] Image Histogram Transformation", "user": {"login": "Miladiouss", "id": 20514398, "node_id": "MDQ6VXNlcjIwNTE0Mzk4", "avatar_url": "https://avatars2.githubusercontent.com/u/20514398?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Miladiouss", "html_url": "https://github.com/Miladiouss", "followers_url": "https://api.github.com/users/Miladiouss/followers", "following_url": "https://api.github.com/users/Miladiouss/following{/other_user}", "gists_url": "https://api.github.com/users/Miladiouss/gists{/gist_id}", "starred_url": "https://api.github.com/users/Miladiouss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Miladiouss/subscriptions", "organizations_url": "https://api.github.com/users/Miladiouss/orgs", "repos_url": "https://api.github.com/users/Miladiouss/repos", "events_url": "https://api.github.com/users/Miladiouss/events{/privacy}", "received_events_url": "https://api.github.com/users/Miladiouss/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-31T08:26:26Z", "updated_at": "2018-09-04T16:41:04Z", "closed_at": "2018-09-04T16:41:03Z", "author_association": "NONE", "body_html": "<p>It is often useful (especially in the field of astronomy) to transform the histogram of images. I would like to suggest an image histogram transformation function (under torchvision.transforms) that transforms the histogram of an image to match that of a template image as closely as possible. For instance, consider the following function:</p>\n<pre><code>def match_histogram(source, template):\n\n    source   = np.asanyarray(source)\n    template = np.asanyarray(template)\n    oldshape = source.shape\n    source   = source.ravel()\n    template = template.ravel()\n\n    # get the set of unique pixel values and their corresponding indices and\n    # counts\n    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n                                            return_counts=True)\n    t_values, t_counts = np.unique(template, return_counts=True)\n\n    # take the cumsum of the counts and normalize by the number of pixels to\n    # get the empirical cumulative distribution functions for the source and\n    # template images (maps pixel value --&gt; quantile)\n    s_quantiles  = np.cumsum(s_counts).astype(np.float32)\n    s_quantiles /= s_quantiles[-1]\n    t_quantiles  = np.cumsum(t_counts).astype(np.float32)\n    t_quantiles /= t_quantiles[-1]\n\n    # interpolate linearly to find the pixel values in the template image\n    # that corresponds most closely to the quantiles in the source image\n    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n\n    return interp_t_values[bin_idx].reshape(oldshape)\n</code></pre>\n<p>The function above is not optimal since it has to recalculate template image information. It is not discretized for float type images. It only performs for highly discretized images such as png (0-255 bins). It also performs poorly when the number of diverse pixels is too low which might be fixed by adding small noise.</p>", "body_text": "It is often useful (especially in the field of astronomy) to transform the histogram of images. I would like to suggest an image histogram transformation function (under torchvision.transforms) that transforms the histogram of an image to match that of a template image as closely as possible. For instance, consider the following function:\ndef match_histogram(source, template):\n\n    source   = np.asanyarray(source)\n    template = np.asanyarray(template)\n    oldshape = source.shape\n    source   = source.ravel()\n    template = template.ravel()\n\n    # get the set of unique pixel values and their corresponding indices and\n    # counts\n    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n                                            return_counts=True)\n    t_values, t_counts = np.unique(template, return_counts=True)\n\n    # take the cumsum of the counts and normalize by the number of pixels to\n    # get the empirical cumulative distribution functions for the source and\n    # template images (maps pixel value --> quantile)\n    s_quantiles  = np.cumsum(s_counts).astype(np.float32)\n    s_quantiles /= s_quantiles[-1]\n    t_quantiles  = np.cumsum(t_counts).astype(np.float32)\n    t_quantiles /= t_quantiles[-1]\n\n    # interpolate linearly to find the pixel values in the template image\n    # that corresponds most closely to the quantiles in the source image\n    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n\n    return interp_t_values[bin_idx].reshape(oldshape)\n\nThe function above is not optimal since it has to recalculate template image information. It is not discretized for float type images. It only performs for highly discretized images such as png (0-255 bins). It also performs poorly when the number of diverse pixels is too low which might be fixed by adding small noise.", "body": "It is often useful (especially in the field of astronomy) to transform the histogram of images. I would like to suggest an image histogram transformation function (under torchvision.transforms) that transforms the histogram of an image to match that of a template image as closely as possible. For instance, consider the following function:\r\n\r\n```\r\ndef match_histogram(source, template):\r\n\r\n    source   = np.asanyarray(source)\r\n    template = np.asanyarray(template)\r\n    oldshape = source.shape\r\n    source   = source.ravel()\r\n    template = template.ravel()\r\n\r\n    # get the set of unique pixel values and their corresponding indices and\r\n    # counts\r\n    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\r\n                                            return_counts=True)\r\n    t_values, t_counts = np.unique(template, return_counts=True)\r\n\r\n    # take the cumsum of the counts and normalize by the number of pixels to\r\n    # get the empirical cumulative distribution functions for the source and\r\n    # template images (maps pixel value --> quantile)\r\n    s_quantiles  = np.cumsum(s_counts).astype(np.float32)\r\n    s_quantiles /= s_quantiles[-1]\r\n    t_quantiles  = np.cumsum(t_counts).astype(np.float32)\r\n    t_quantiles /= t_quantiles[-1]\r\n\r\n    # interpolate linearly to find the pixel values in the template image\r\n    # that corresponds most closely to the quantiles in the source image\r\n    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\r\n\r\n    return interp_t_values[bin_idx].reshape(oldshape)\r\n```\r\n\r\nThe function above is not optimal since it has to recalculate template image information. It is not discretized for float type images. It only performs for highly discretized images such as png (0-255 bins). It also performs poorly when the number of diverse pixels is too low which might be fixed by adding small noise.\r\n"}