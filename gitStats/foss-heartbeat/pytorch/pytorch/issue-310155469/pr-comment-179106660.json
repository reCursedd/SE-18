{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179106660", "pull_request_review_id": 109285157, "id": 179106660, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTEwNjY2MA==", "diff_hunk": "@@ -120,5 +122,92 @@ Tensor prod(const Tensor &self, int64_t dim_, bool keepdim) {\n }\n \n // \\DIM REDUCE ################################################################\n+\n+// MULTI DIM REDUCE ###########################################################\n+\n+template <Tensor (reduce_1)(const Tensor &, int64_t, bool)>\n+inline Tensor reduce_multi(const Tensor &self, IntList dims_, bool keepdim) {\n+  if (dims_.size() == 1) {\n+    return reduce_1(self, dims_[0], keepdim);\n+  }\n+  if (dims_.size() == 0) {\n+    return self;\n+  }\n+  size_t ndims = self.dim();\n+  AT_ASSERT(ndims <= (int64_t) dim_bitset_size, \"tensor dimension must be <= %zu for multiple dims\", dim_bitset_size);\n+  std::bitset<dim_bitset_size> seen;\n+  Tensor result = self;\n+  for (size_t i = 0; i < dims_.size(); i++) {\n+    size_t dim = maybe_wrap_dim(dims_[i], ndims);\n+    if (seen[dim])\n+      AT_ERROR(\"repeated dim\");\n+    seen[dim] = true;\n+    result = reduce_1(result, dim, true);\n+  }", "path": "aten/src/ATen/native/ReduceOps.cpp", "position": null, "original_position": 40, "commit_id": "3b631f02f2d88b09e83d700f3c33cc2e3ad01e63", "original_commit_id": "d32ca285576fe1ed0691e270e03cb7bb175d3b9b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "This is duplicated code, and it's better to avoid it. Let's just use the function to create the bitset and validate the arg, and then just iterate over dims again.", "created_at": "2018-04-04T11:27:29Z", "updated_at": "2018-11-23T15:41:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/6152#discussion_r179106660", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6152", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179106660"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6152#discussion_r179106660"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6152"}}, "body_html": "<p>This is duplicated code, and it's better to avoid it. Let's just use the function to create the bitset and validate the arg, and then just iterate over dims again.</p>", "body_text": "This is duplicated code, and it's better to avoid it. Let's just use the function to create the bitset and validate the arg, and then just iterate over dims again."}