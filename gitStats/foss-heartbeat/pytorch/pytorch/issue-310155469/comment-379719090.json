{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/379719090", "html_url": "https://github.com/pytorch/pytorch/pull/6152#issuecomment-379719090", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6152", "id": 379719090, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTcxOTA5MA==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-09T11:22:21Z", "updated_at": "2018-04-09T11:22:21Z", "author_association": "MEMBER", "body_html": "<p>I have one comment about reduction over multiple axis: I think we should follow numpy behavior.</p>\n<p>For many functions where the order of operations doesn't matter (like <code>sum</code> or <code>mean</code>), this is not a problem. But for other operations like <code>median</code>, there is a difference in performing the reduction over the different axes independently or by transpose + reshape + operation.</p>\n<p>It seems that numpy performs the operations differently than what is implemented here:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>)\n\nm1 <span class=\"pl-k\">=</span> np.median(a, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> perform a single median, after putting the</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> reduction dimensions in together</span>\nm2 <span class=\"pl-k\">=</span> np.median(a.transpose((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>)).reshape(<span class=\"pl-c1\">3</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> independently perform the reductions</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> on each different axis</span>\nm3 <span class=\"pl-k\">=</span> np.median(np.median(a, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nm4 <span class=\"pl-k\">=</span> np.median(np.median(a, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\n<span class=\"pl-c1\">print</span> (np.all(m1 <span class=\"pl-k\">==</span> m2))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> True</span>\n<span class=\"pl-c1\">print</span>(np.all(m1 <span class=\"pl-k\">==</span> m3))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> False</span>\n<span class=\"pl-c1\">print</span>(np.all(m1 <span class=\"pl-k\">==</span> m4))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> False</span></pre></div>\n<p>It might be good to benchmark it, but I have the feeling that it might also be faster to perform <code>permute</code> + <code>reshape</code> + <code>op</code>, instead of n times performing <code>op</code>.</p>", "body_text": "I have one comment about reduction over multiple axis: I think we should follow numpy behavior.\nFor many functions where the order of operations doesn't matter (like sum or mean), this is not a problem. But for other operations like median, there is a difference in performing the reduction over the different axes independently or by transpose + reshape + operation.\nIt seems that numpy performs the operations differently than what is implemented here:\na = np.random.rand(3, 3, 3)\n\nm1 = np.median(a, axis=[0, 2])\n\n# perform a single median, after putting the\n# reduction dimensions in together\nm2 = np.median(a.transpose((1, 0, 2)).reshape(3, -1), axis=1)\n\n# independently perform the reductions\n# on each different axis\nm3 = np.median(np.median(a, axis=0), axis=1)\nm4 = np.median(np.median(a, axis=2), axis=0)\n\nprint (np.all(m1 == m2))  # True\nprint(np.all(m1 == m3))  # False\nprint(np.all(m1 == m4))  # False\nIt might be good to benchmark it, but I have the feeling that it might also be faster to perform permute + reshape + op, instead of n times performing op.", "body": "I have one comment about reduction over multiple axis: I think we should follow numpy behavior.\r\n\r\nFor many functions where the order of operations doesn't matter (like `sum` or `mean`), this is not a problem. But for other operations like `median`, there is a difference in performing the reduction over the different axes independently or by transpose + reshape + operation.\r\n\r\nIt seems that numpy performs the operations differently than what is implemented here:\r\n\r\n```python\r\na = np.random.rand(3, 3, 3)\r\n\r\nm1 = np.median(a, axis=[0, 2])\r\n\r\n# perform a single median, after putting the\r\n# reduction dimensions in together\r\nm2 = np.median(a.transpose((1, 0, 2)).reshape(3, -1), axis=1)\r\n\r\n# independently perform the reductions\r\n# on each different axis\r\nm3 = np.median(np.median(a, axis=0), axis=1)\r\nm4 = np.median(np.median(a, axis=2), axis=0)\r\n\r\nprint (np.all(m1 == m2))  # True\r\nprint(np.all(m1 == m3))  # False\r\nprint(np.all(m1 == m4))  # False\r\n```\r\n\r\nIt might be good to benchmark it, but I have the feeling that it might also be faster to perform `permute` + `reshape` + `op`, instead of n times performing `op`."}