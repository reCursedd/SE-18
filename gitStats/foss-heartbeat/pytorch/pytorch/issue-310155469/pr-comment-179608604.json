{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179608604", "pull_request_review_id": 109887039, "id": 179608604, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTYwODYwNA==", "diff_hunk": "@@ -120,5 +122,84 @@ Tensor prod(const Tensor &self, int64_t dim_, bool keepdim) {\n }\n \n // \\DIM REDUCE ################################################################\n+\n+// MULTI DIM REDUCE ###########################################################\n+\n+template <Tensor (reduce_1)(const Tensor &, int64_t, bool)>\n+inline Tensor reduce_multi(const Tensor &self, IntList dims_, bool keepdim) {\n+  if (dims_.size() == 1) {\n+    return reduce_1(self, dims_[0], keepdim);\n+  }\n+  if (dims_.size() == 0) {\n+    return self;\n+  }\n+  size_t ndims = self.dim();\n+  std::bitset<dim_bitset_size> seen = dim_list_to_bitset(dims_, ndims);\n+  Tensor result = self;\n+  for (size_t i = 0; i < dims_.size(); i++) {\n+    size_t dim = maybe_wrap_dim(dims_[i], ndims);\n+    result = reduce_1(result, dim, true);", "path": "aten/src/ATen/native/ReduceOps.cpp", "position": null, "original_position": 35, "commit_id": "3b631f02f2d88b09e83d700f3c33cc2e3ad01e63", "original_commit_id": "fa7f0a940bde207c759d04ccc41f94ea7872aec4", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "Here,`dims_` is in the order the caller has given us, so we would have to keep track of the mapping input dims to reduced dims.\r\nThe crucial question is whether we want to let the user decide the order of reduction axes as the current code does. If we don't, we can reduce in order (as we squeeze now) with `keepdim=False`. If we do, the above seems to be more straightforward to me.", "created_at": "2018-04-05T21:38:32Z", "updated_at": "2018-11-23T15:41:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/6152#discussion_r179608604", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6152", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179608604"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6152#discussion_r179608604"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6152"}}, "body_html": "<p>Here,<code>dims_</code> is in the order the caller has given us, so we would have to keep track of the mapping input dims to reduced dims.<br>\nThe crucial question is whether we want to let the user decide the order of reduction axes as the current code does. If we don't, we can reduce in order (as we squeeze now) with <code>keepdim=False</code>. If we do, the above seems to be more straightforward to me.</p>", "body_text": "Here,dims_ is in the order the caller has given us, so we would have to keep track of the mapping input dims to reduced dims.\nThe crucial question is whether we want to let the user decide the order of reduction axes as the current code does. If we don't, we can reduce in order (as we squeeze now) with keepdim=False. If we do, the above seems to be more straightforward to me.", "in_reply_to_id": 179585485}