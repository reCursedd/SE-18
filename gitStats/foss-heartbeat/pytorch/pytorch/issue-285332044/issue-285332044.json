{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4433", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4433/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4433/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4433/events", "html_url": "https://github.com/pytorch/pytorch/issues/4433", "id": 285332044, "node_id": "MDU6SXNzdWUyODUzMzIwNDQ=", "number": 4433, "title": "Unexpected behaviour when multiplying a np.float64 before Variable", "user": {"login": "lxuechen", "id": 12689993, "node_id": "MDQ6VXNlcjEyNjg5OTkz", "avatar_url": "https://avatars1.githubusercontent.com/u/12689993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lxuechen", "html_url": "https://github.com/lxuechen", "followers_url": "https://api.github.com/users/lxuechen/followers", "following_url": "https://api.github.com/users/lxuechen/following{/other_user}", "gists_url": "https://api.github.com/users/lxuechen/gists{/gist_id}", "starred_url": "https://api.github.com/users/lxuechen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lxuechen/subscriptions", "organizations_url": "https://api.github.com/users/lxuechen/orgs", "repos_url": "https://api.github.com/users/lxuechen/repos", "events_url": "https://api.github.com/users/lxuechen/events{/privacy}", "received_events_url": "https://api.github.com/users/lxuechen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-01T22:01:46Z", "updated_at": "2018-01-01T22:37:36Z", "closed_at": "2018-01-01T22:37:36Z", "author_association": "NONE", "body_html": "<p>It seems that when I multiply a floating number of type np.float64 before a torch.autograd.Variable I get a nested np.ndarray with the \"core\" inside it being the Variable. However, when I reverse the order of multiplication, the problem is gone. Here's one example</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np \n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\ns <span class=\"pl-k\">=</span> np.float64(<span class=\"pl-c1\">0.1</span>)\na <span class=\"pl-k\">=</span> Variable(torch.FloatTensor([<span class=\"pl-c1\">2.3</span>]))\n\n<span class=\"pl-c1\">print</span> (s<span class=\"pl-k\">*</span>a)\n<span class=\"pl-c1\">print</span> (a<span class=\"pl-k\">*</span>s)</pre></div>\n<p>I get the follow result when running with python3.5.2 and torch-0.3.0.post4</p>\n<pre><code>[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\n 0.2300\n[torch.FloatTensor of size 1]\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\nVariable containing:\n 0.2300\n[torch.FloatTensor of size 1]\n</code></pre>\n<p>Is this expected?</p>", "body_text": "It seems that when I multiply a floating number of type np.float64 before a torch.autograd.Variable I get a nested np.ndarray with the \"core\" inside it being the Variable. However, when I reverse the order of multiplication, the problem is gone. Here's one example\nimport numpy as np \nimport torch\nfrom torch.autograd import Variable\n\ns = np.float64(0.1)\na = Variable(torch.FloatTensor([2.3]))\n\nprint (s*a)\nprint (a*s)\nI get the follow result when running with python3.5.2 and torch-0.3.0.post4\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\n 0.2300\n[torch.FloatTensor of size 1]\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\nVariable containing:\n 0.2300\n[torch.FloatTensor of size 1]\n\nIs this expected?", "body": "It seems that when I multiply a floating number of type np.float64 before a torch.autograd.Variable I get a nested np.ndarray with the \"core\" inside it being the Variable. However, when I reverse the order of multiplication, the problem is gone. Here's one example\r\n\r\n```python\r\nimport numpy as np \r\nimport torch\r\nfrom torch.autograd import Variable\r\n\r\ns = np.float64(0.1)\r\na = Variable(torch.FloatTensor([2.3]))\r\n\r\nprint (s*a)\r\nprint (a*s)\r\n```\r\n\r\nI get the follow result when running with python3.5.2 and torch-0.3.0.post4\r\n```\r\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\r\n 0.2300\r\n[torch.FloatTensor of size 1]\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\r\nVariable containing:\r\n 0.2300\r\n[torch.FloatTensor of size 1]\r\n```\r\nIs this expected?"}