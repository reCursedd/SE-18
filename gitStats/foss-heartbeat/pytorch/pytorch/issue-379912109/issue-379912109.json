{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13850", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13850/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13850/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13850/events", "html_url": "https://github.com/pytorch/pytorch/issues/13850", "id": 379912109, "node_id": "MDU6SXNzdWUzNzk5MTIxMDk=", "number": 13850, "title": "num_workers > 0 leading to OOM in non-IPython environment", "user": {"login": "toemm", "id": 15850161, "node_id": "MDQ6VXNlcjE1ODUwMTYx", "avatar_url": "https://avatars3.githubusercontent.com/u/15850161?v=4", "gravatar_id": "", "url": "https://api.github.com/users/toemm", "html_url": "https://github.com/toemm", "followers_url": "https://api.github.com/users/toemm/followers", "following_url": "https://api.github.com/users/toemm/following{/other_user}", "gists_url": "https://api.github.com/users/toemm/gists{/gist_id}", "starred_url": "https://api.github.com/users/toemm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/toemm/subscriptions", "organizations_url": "https://api.github.com/users/toemm/orgs", "repos_url": "https://api.github.com/users/toemm/repos", "events_url": "https://api.github.com/users/toemm/events{/privacy}", "received_events_url": "https://api.github.com/users/toemm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-11-12T19:05:31Z", "updated_at": "2018-11-14T11:15:21Z", "closed_at": "2018-11-14T11:15:21Z", "author_association": "NONE", "body_html": "<p>My code works perfectly in an IPython Jupyter Notebook environment. I'm training a GAN while asynchronous loading data with ImageFolder and DataLoader. <code>Num_workers</code> behaves as expected.</p>\n<p>When I export my code to .py and execute it from VSCode inside my conda environment (where I started the notebook from) my memory quickly goes up until it reaches <code>OOM: RuntimeError: CUDA error: out of memory</code>. (RAM goes to 100% aswell).</p>\n<p>I am using this syntax because I'm on windows:</p>\n<pre><code>import torch\n\ndef main()\n    for i, data in enumerate(dataloader):\n        # do something here\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p>Using <code>num_workers=0</code> and <code>num_workers=1</code> works but then my epoch time increases about 22x. Everything over 1 leads to the aforementioned OOMs.</p>\n<p>Theres shouldn't be any issue because I'm just copying my Ipython code to VSCode and then run the .py file from there, why is this happening?</p>\n<p><strong>System information</strong></p>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2</p>\n<p>OS: Microsoft Windows 10 Home<br>\nGCC version: Could not collect<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.7<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.148<br>\nGPU models and configuration: GPU 0: GeForce RTX 2070<br>\nNvidia driver version: 416.81<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] cuda92                    1.0                           0    pytorch<br>\n[conda] pytorch                   0.4.1           py37_cuda92_cudnn7he774522_1  [cuda92]  pytorch<br>\n[conda] torchvision               0.2.1                     </p>", "body_text": "My code works perfectly in an IPython Jupyter Notebook environment. I'm training a GAN while asynchronous loading data with ImageFolder and DataLoader. Num_workers behaves as expected.\nWhen I export my code to .py and execute it from VSCode inside my conda environment (where I started the notebook from) my memory quickly goes up until it reaches OOM: RuntimeError: CUDA error: out of memory. (RAM goes to 100% aswell).\nI am using this syntax because I'm on windows:\nimport torch\n\ndef main()\n    for i, data in enumerate(dataloader):\n        # do something here\n\nif __name__ == '__main__':\n    main()\n\nUsing num_workers=0 and num_workers=1 works but then my epoch time increases about 22x. Everything over 1 leads to the aforementioned OOMs.\nTheres shouldn't be any issue because I'm just copying my Ipython code to VSCode and then run the .py file from there, why is this happening?\nSystem information\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.2\nOS: Microsoft Windows 10 Home\nGCC version: Could not collect\nCMake version: Could not collect\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: 9.2.148\nGPU models and configuration: GPU 0: GeForce RTX 2070\nNvidia driver version: 416.81\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] cuda92                    1.0                           0    pytorch\n[conda] pytorch                   0.4.1           py37_cuda92_cudnn7he774522_1  [cuda92]  pytorch\n[conda] torchvision               0.2.1", "body": "My code works perfectly in an IPython Jupyter Notebook environment. I'm training a GAN while asynchronous loading data with ImageFolder and DataLoader. `Num_workers` behaves as expected.\r\n\r\nWhen I export my code to .py and execute it from VSCode inside my conda environment (where I started the notebook from) my memory quickly goes up until it reaches `OOM: RuntimeError: CUDA error: out of memory`. (RAM goes to 100% aswell).\r\n\r\nI am using this syntax because I'm on windows: \r\n\r\n```\r\nimport torch\r\n\r\ndef main()\r\n    for i, data in enumerate(dataloader):\r\n        # do something here\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\nUsing `num_workers=0` and `num_workers=1` works but then my epoch time increases about 22x. Everything over 1 leads to the aforementioned OOMs.\r\n\r\nTheres shouldn't be any issue because I'm just copying my Ipython code to VSCode and then run the .py file from there, why is this happening?\r\n\r\n\r\n**System information**\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2\r\n\r\nOS: Microsoft Windows 10 Home\r\nGCC version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: GeForce RTX 2070\r\nNvidia driver version: 416.81\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] cuda92                    1.0                           0    pytorch\r\n[conda] pytorch                   0.4.1           py37_cuda92_cudnn7he774522_1  [cuda92]  pytorch\r\n[conda] torchvision               0.2.1                     <pip>"}