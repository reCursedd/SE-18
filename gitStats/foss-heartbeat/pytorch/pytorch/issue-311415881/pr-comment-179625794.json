{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179625794", "pull_request_review_id": 109907630, "id": 179625794, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTYyNTc5NA==", "diff_hunk": "@@ -0,0 +1,217 @@\n+#include \"Device.h\"\n+\n+#include <cstring>\n+#include <structmember.h>\n+#include <sstream>\n+#include \"torch/csrc/Exceptions.h\"\n+#include \"torch/csrc/utils/object_ptr.h\"\n+#include \"torch/csrc/utils/python_arg_parser.h\"\n+#include \"torch/csrc/utils/python_strings.h\"\n+\n+PyObject *THPDevice_New(torch::DeviceType device_type, int64_t device_index, bool is_default)\n+{\n+  auto type = (PyTypeObject*)&THPDeviceType;\n+  auto self = THPObjectPtr{type->tp_alloc(type, 0)};\n+  if (!self) throw python_error();\n+  auto self_ = reinterpret_cast<THPDevice*>(self.get());\n+  self_->device_type = device_type;\n+  self_->device_index = device_index;\n+  self_->is_default = is_default;\n+  return self.release();\n+}\n+\n+static const char* cuda_str = \"cuda\";\n+static const char* cpu_str = \"cpu\";\n+\n+static inline const char* deviceTypeString(torch::DeviceType device_type) {\n+  switch (device_type) {\n+    case torch::DeviceType::CUDA:\n+      return cuda_str;\n+    case torch::DeviceType::CPU:\n+      return cpu_str;\n+    default:\n+      throw std::runtime_error(\"unexpected device type\");\n+  }\n+}\n+\n+PyObject *THPDevice_repr(THPDevice *self)\n+{\n+  std::ostringstream oss;\n+  oss << \"Device(device_type=\\'\" << deviceTypeString(self->device_type) << \"\\'\";\n+  if (!self->is_default) {\n+    oss << \", device_index=\" << self->device_index;\n+  }\n+  oss << \")\";\n+  return THPUtils_packString(oss.str().c_str());\n+}\n+\n+PyObject *THPDevice_str(THPDevice*self)\n+{\n+  std::ostringstream oss;\n+  if (!self->is_default) {\n+    oss << deviceTypeString(self->device_type) << \":\" << self->device_index;\n+  } else {\n+    oss << deviceTypeString(self->device_type);\n+  }\n+  return THPUtils_packString(oss.str().c_str());\n+}\n+\n+PyObject *THPDevice_pynew(PyTypeObject *type, PyObject *args, PyObject *kwargs)\n+{\n+  HANDLE_TH_ERRORS\n+  static torch::PythonArgParser parser({\n+    \"Device(Device device)\",\n+    \"Device(String device_type, int64_t? device_index=-1)\"\n+  });\n+  torch::ParsedArgs<2> parsed_args;\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+  if (r.idx == 0) {\n+    auto device = r.device(0);\n+    return THPDevice_New(device.device_type, device.device_index, device.is_default);\n+  } else if (r.idx == 1) {\n+    auto as_device = r.device(0);  // this works, because device can take strings\n+    auto device_type = r.string(0);\n+    if (!as_device.is_default) {\n+      throw std::runtime_error(\"device_type must not include index because index is passed explicitly \" + device_type);\n+    }\n+\n+    auto is_default = r.isNone(1);\n+    auto device_index = r.toInt64WithDefault(1, -1);\n+    // make sure this is constructible\n+    auto device = torch::Device(as_device.device_type, device_index, is_default);\n+    return THPDevice_New(device.device_type, device.device_index, device.is_default);\n+  }\n+  Py_RETURN_NONE;\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+PyObject *THPDevice_type(THPDevice *self)\n+{\n+  HANDLE_TH_ERRORS\n+  return THPUtils_packString(deviceTypeString(self->device_type));\n+  Py_RETURN_NONE;\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+PyObject *THPDevice_index(THPDevice *self)\n+{\n+  HANDLE_TH_ERRORS\n+  if (self->is_default) {\n+    Py_RETURN_NONE;\n+  } else {\n+    return THPUtils_packInt64(self->device_index);\n+  }\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+PyObject *THPDevice_cuda_index(THPDevice *self)", "path": "torch/csrc/Device.cpp", "position": null, "original_position": 107, "commit_id": "e591346acf064c4bd31383f1e5f57ba1a086206a", "original_commit_id": "e2fd745e9b7ccd464f4400ab9b1db6c1cfea13b3", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "`torch.utils.backcompat` -- it currently has stuff about settings warnings for broadcasting/keepdim, but this is backcompat related.", "created_at": "2018-04-05T23:15:50Z", "updated_at": "2018-11-23T15:41:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/6283#discussion_r179625794", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6283", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179625794"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6283#discussion_r179625794"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6283"}}, "body_html": "<p><code>torch.utils.backcompat</code> -- it currently has stuff about settings warnings for broadcasting/keepdim, but this is backcompat related.</p>", "body_text": "torch.utils.backcompat -- it currently has stuff about settings warnings for broadcasting/keepdim, but this is backcompat related.", "in_reply_to_id": 179620649}