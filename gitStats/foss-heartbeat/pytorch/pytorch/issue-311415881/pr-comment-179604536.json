{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179604536", "pull_request_review_id": 109882217, "id": 179604536, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTYwNDUzNg==", "diff_hunk": "@@ -1303,6 +1303,73 @@ def test_dtypes(self):\n         cuda_dtypes = [d for d in all_dtypes if d.is_cuda]\n         self._test_dtypes(self, cpu_dtypes, cuda_dtypes, torch.strided)\n \n+    def test_device(self):\n+        self.assertEqual('cpu', torch.tensor(5).device)\n+        self.assertEqual('cpu', torch.ones((2, 3), dtype=torch.float32, device='cpu').device)\n+        self.assertEqual('cpu', torch.ones((2, 3), dtype=torch.float32, device='cpu:0').device)\n+        if torch.cuda.is_available():\n+            self.assertEqual('cuda:0', torch.tensor(5).cuda(0).device)\n+            self.assertEqual('cuda:0', torch.tensor(5).cuda('cuda:0').device)\n+            self.assertRaises(RuntimeError, lambda: torch.tensor(5).cuda('cpu'))\n+            self.assertRaises(RuntimeError, lambda: torch.tensor(5).cuda('cpu:0'))\n+            self.assertEqual('cuda:0', torch.tensor(5, dtype=torch.cuda.int64, device=0).device)\n+            self.assertEqual('cuda:0', torch.tensor(5, dtype=torch.cuda.int64, device='cuda:0').device)\n+            self.assertEqual('cuda:' + str(torch.cuda.current_device()),\n+                             torch.tensor(5, dtype=torch.cuda.int64, device='cuda').device)\n+\n+            if torch.cuda.device_count() > 1:\n+                self.assertEqual('cuda:1', torch.tensor(5).cuda(1).device)\n+                self.assertEqual('cuda:1', torch.tensor(5).cuda('cuda:1').device)\n+                self.assertEqual('cuda:1', torch.tensor(5, dtype=torch.cuda.int64, device=1).device)\n+                self.assertEqual('cuda:1', torch.tensor(5, dtype=torch.cuda.int64, device='cuda:1').device)\n+\n+    def test_devicespec(self):\n+        cpu = torch.DeviceSpec('cpu')\n+        self.assertEqual('cpu', str(cpu))\n+        self.assertEqual('cpu', cpu.device_type)\n+        self.assertEqual(None, cpu.device_index)\n+        self.assertRaises(RuntimeError, lambda: cpu.cuda_device_index)\n+\n+        cpu0 = torch.DeviceSpec('cpu:0')", "path": "test/test_torch.py", "position": null, "original_position": 31, "commit_id": "e591346acf064c4bd31383f1e5f57ba1a086206a", "original_commit_id": "146c33f6860b80f42151007b7210b31995eecf10", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "Putting this together, I propose:\r\n\r\n1) `tensor.device` returns a `torch.device`\r\n2) No `tensor.device_str`, use `str(tensor.device)`\r\n3) Users can create (unrealized) devices by calling `torch.device(...)`\r\n4) In the future, we can add lazy initialization such that `tensor.device` returns an information-initialized `torch.device` (it's guaranteed to be initialized because the tensor's device is) and `torch.device(...)` returns a information-uninitialized `torch.device` that can be initialized by calling `.info` or whatever.", "created_at": "2018-04-05T21:21:13Z", "updated_at": "2018-11-23T15:41:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/6283#discussion_r179604536", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6283", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179604536"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6283#discussion_r179604536"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6283"}}, "body_html": "<p>Putting this together, I propose:</p>\n<ol>\n<li><code>tensor.device</code> returns a <code>torch.device</code></li>\n<li>No <code>tensor.device_str</code>, use <code>str(tensor.device)</code></li>\n<li>Users can create (unrealized) devices by calling <code>torch.device(...)</code></li>\n<li>In the future, we can add lazy initialization such that <code>tensor.device</code> returns an information-initialized <code>torch.device</code> (it's guaranteed to be initialized because the tensor's device is) and <code>torch.device(...)</code> returns a information-uninitialized <code>torch.device</code> that can be initialized by calling <code>.info</code> or whatever.</li>\n</ol>", "body_text": "Putting this together, I propose:\n\ntensor.device returns a torch.device\nNo tensor.device_str, use str(tensor.device)\nUsers can create (unrealized) devices by calling torch.device(...)\nIn the future, we can add lazy initialization such that tensor.device returns an information-initialized torch.device (it's guaranteed to be initialized because the tensor's device is) and torch.device(...) returns a information-uninitialized torch.device that can be initialized by calling .info or whatever.", "in_reply_to_id": 179570026}