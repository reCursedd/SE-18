{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182058863", "pull_request_review_id": 112792660, "id": 182058863, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MjA1ODg2Mw==", "diff_hunk": "@@ -0,0 +1,256 @@\n+Windows Usage\n+==========================\n+\n+Building from source\n+--------------------\n+\n+Include optional components\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+There're two supported components for Windows PyTorch:\n+MKL and MAGMA. Here are the steps to build with them.\n+\n+.. code-block:: bat\n+\n+    REM Make sure you has 7z and curl installed.\n+\n+    REM Download MKL files\n+    curl https://s3.amazonaws.com/ossci-windows/mkl_2018.2.185.7z -k -O\n+    7z x -aoa mkl_2018.2.185.7z -omkl\n+\n+    REM Download MAGMA diles\n+    REM cuda90/cuda91 is also available in the following line.\n+    set CUDA_PREFIX=cuda80 \n+    curl -k https://s3.amazonaws.com/ossci-windows/magma_%CUDA_PREFIX%_release_mkl_2018.2.185.7z -o magma.7z\n+    7z x -aoa magma.7z -omagma\n+    \n+    REM Setting essential environment variables\n+    set \"CMAKE_INCLUDE_PATH=%cd%\\\\mkl\\\\include\"\n+    set \"LIB=%cd%\\\\mkl\\\\lib;%LIB%\"\n+    set \"MAGMA_HOME=%cd%\\\\magma\"\n+\n+Speeding CUDA build for Windows\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Visual Studio doesn't support parallel custom task currently.\n+As an alternative, we can use ``Ninja`` to parallelize CUDA\n+build tasks. It can used by typing only a few lines of code.\n+\n+.. code-block:: bat\n+    \n+    REM Let's install ninja first.\n+    pip install ninja\n+\n+    REM Set it as the cmake generator\n+    set CMAKE_GENERATOR=Ninja\n+\n+\n+One key install script\n+^^^^^^^^^^^^^^^^^^^^^^\n+\n+You can take a look at the script `here\n+<https://github.com/peterjc123/pytorch-scripts>`_. \n+It will lead the way for you.\n+\n+Extension\n+---------\n+\n+CFFI Extension\n+^^^^^^^^^^^^^^\n+\n+The support for CFFI Extension is very experimental. There're \n+generally two steps to enable it under Windows.\n+\n+First, specify additional ``libraries`` in ``Extension``\n+object to make it build on Windows.\n+\n+.. code-block:: python\n+   ffi = create_extension(\n+       '_ext.my_lib',\n+       headers=headers,\n+       sources=sources,\n+       define_macros=defines,\n+       relative_to=__file__,\n+       with_cuda=with_cuda,\n+       extra_compile_args=[\"-std=c99\"],\n+       libraries=['ATen', '_C'] # Append cuda libaries when necessary, like cudart\n+   )\n+\n+Second, here is a workground for \"unresolved external symbol \n+state caused by``extern THCState *state;``\"\n+\n+Change the source code from C to C++. An example is listed below.\n+\n+.. code-block:: cpp\n+    #include <THC/THC.h>\n+    #include <ATen/ATen.h>\n+\n+    THCState *state = at::globalContext().thc_state;\n+\n+    extern \"C\" int my_lib_add_forward_cuda(THCudaTensor *input1, THCudaTensor *input2,\n+                                            THCudaTensor *output)\n+    {\n+        if (!THCudaTensor_isSameSizeAs(state, input1, input2))\n+        return 0;\n+        THCudaTensor_resizeAs(state, output, input1);\n+        THCudaTensor_cadd(state, output, input1, 1.0, input2);\n+        return 1;\n+    }\n+\n+    extern \"C\" int my_lib_add_backward_cuda(THCudaTensor *grad_output, THCudaTensor *grad_input)\n+    {\n+        THCudaTensor_resizeAs(state, grad_input, grad_output);\n+        THCudaTensor_fill(state, grad_input, 1);\n+        return 1;\n+    }\n+\n+Cpp Extension\n+^^^^^^^^^^^^^\n+\n+This type of extension has better support compared with\n+the previous one. However, it still need some manual", "path": "docs/source/notes/windows.rst", "position": null, "original_position": 111, "commit_id": "ec1eeab2d5ba8b535ed62b6589602b6f1de023a2", "original_commit_id": "0d29fcd829187da0601ae080c0a3fff202a2e42d", "user": {"login": "nzw0301", "id": 7121753, "node_id": "MDQ6VXNlcjcxMjE3NTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/7121753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nzw0301", "html_url": "https://github.com/nzw0301", "followers_url": "https://api.github.com/users/nzw0301/followers", "following_url": "https://api.github.com/users/nzw0301/following{/other_user}", "gists_url": "https://api.github.com/users/nzw0301/gists{/gist_id}", "starred_url": "https://api.github.com/users/nzw0301/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nzw0301/subscriptions", "organizations_url": "https://api.github.com/users/nzw0301/orgs", "repos_url": "https://api.github.com/users/nzw0301/repos", "events_url": "https://api.github.com/users/nzw0301/events{/privacy}", "received_events_url": "https://api.github.com/users/nzw0301/received_events", "type": "User", "site_admin": false}, "body": "`need` \u2192 `needs`", "created_at": "2018-04-17T12:47:31Z", "updated_at": "2018-11-23T15:42:35Z", "html_url": "https://github.com/pytorch/pytorch/pull/6653#discussion_r182058863", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6653", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182058863"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6653#discussion_r182058863"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6653"}}, "body_html": "<p><code>need</code> \u2192 <code>needs</code></p>", "body_text": "need \u2192 needs"}