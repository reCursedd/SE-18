{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182625791", "pull_request_review_id": 113457987, "id": 182625791, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MjYyNTc5MQ==", "diff_hunk": "@@ -0,0 +1,258 @@\n+Windows FAQ\n+==========================\n+\n+Building from source\n+--------------------\n+\n+Include optional components\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+There are two supported components for Windows PyTorch:\n+MKL and MAGMA. Here are the steps to build with them.\n+\n+.. code-block:: bat\n+\n+    REM Make sure you have 7z and curl installed.\n+\n+    REM Download MKL files\n+    curl https://s3.amazonaws.com/ossci-windows/mkl_2018.2.185.7z -k -O\n+    7z x -aoa mkl_2018.2.185.7z -omkl\n+\n+    REM Download MAGMA files\n+    REM cuda90/cuda91 is also available in the following line.\n+    set CUDA_PREFIX=cuda80 \n+    curl -k https://s3.amazonaws.com/ossci-windows/magma_%CUDA_PREFIX%_release_mkl_2018.2.185.7z -o magma.7z\n+    7z x -aoa magma.7z -omagma\n+    \n+    REM Setting essential environment variables\n+    set \"CMAKE_INCLUDE_PATH=%cd%\\\\mkl\\\\include\"\n+    set \"LIB=%cd%\\\\mkl\\\\lib;%LIB%\"\n+    set \"MAGMA_HOME=%cd%\\\\magma\"\n+\n+Speeding CUDA build for Windows\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Visual Studio doesn't support parallel custom task currently.\n+As an alternative, we can use ``Ninja`` to parallelize CUDA\n+build tasks. It can be used by typing only a few lines of code.\n+\n+.. code-block:: bat\n+    \n+    REM Let's install ninja first.\n+    pip install ninja\n+\n+    REM Set it as the cmake generator\n+    set CMAKE_GENERATOR=Ninja\n+\n+\n+One key install script\n+^^^^^^^^^^^^^^^^^^^^^^\n+\n+You can take a look at the script `here\n+<https://github.com/peterjc123/pytorch-scripts>`_. \n+It will lead the way for you.\n+\n+Extension\n+---------\n+\n+CFFI Extension\n+^^^^^^^^^^^^^^\n+\n+The support for CFFI Extension is very experimental. There're \n+generally two steps to enable it under Windows.\n+\n+First, specify additional ``libraries`` in ``Extension``\n+object to make it build on Windows.\n+\n+.. code-block:: python\n+   ffi = create_extension(\n+       '_ext.my_lib',\n+       headers=headers,\n+       sources=sources,\n+       define_macros=defines,\n+       relative_to=__file__,\n+       with_cuda=with_cuda,\n+       extra_compile_args=[\"-std=c99\"],\n+       libraries=['ATen', '_C'] # Append cuda libaries when necessary, like cudart\n+   )\n+\n+Second, here is a workground for \"unresolved external symbol \n+state caused by``extern THCState *state;``\"\n+\n+Change the source code from C to C++. An example is listed below.\n+\n+.. code-block:: cpp\n+    #include <THC/THC.h>\n+    #include <ATen/ATen.h>\n+\n+    THCState *state = at::globalContext().thc_state;\n+\n+    extern \"C\" int my_lib_add_forward_cuda(THCudaTensor *input1, THCudaTensor *input2,\n+                                            THCudaTensor *output)\n+    {\n+        if (!THCudaTensor_isSameSizeAs(state, input1, input2))\n+        return 0;\n+        THCudaTensor_resizeAs(state, output, input1);\n+        THCudaTensor_cadd(state, output, input1, 1.0, input2);\n+        return 1;\n+    }\n+\n+    extern \"C\" int my_lib_add_backward_cuda(THCudaTensor *grad_output, THCudaTensor *grad_input)\n+    {\n+        THCudaTensor_resizeAs(state, grad_input, grad_output);\n+        THCudaTensor_fill(state, grad_input, 1);\n+        return 1;\n+    }\n+\n+Cpp Extension\n+^^^^^^^^^^^^^\n+\n+This type of extension has better support compared with\n+the previous one. However, it still needs some manual\n+configuration. First, you should open the\n+**x86_x64 Cross Tools Command Prompt for VS 2017**\n+And then, you can open the Git-Bash in it. It is\n+usually located in ``C:\\Program Files\\Git\\git-bash.exe``.\n+Finally, you can start your compiling process.\n+\n+Installation\n+------------\n+\n+Package not found in win-32 channel.\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+.. code-block:: bat\n+\n+    Solving environment: failed\n+\n+    PackagesNotFoundError: The following packages are not available from current channels:\n+\n+    - pytorch\n+\n+    Current channels:\n+    - https://conda.anaconda.org/pytorch/win-32\n+    - https://conda.anaconda.org/pytorch/noarch\n+    - https://repo.continuum.io/pkgs/main/win-32\n+    - https://repo.continuum.io/pkgs/main/noarch\n+    - https://repo.continuum.io/pkgs/free/win-32\n+    - https://repo.continuum.io/pkgs/free/noarch\n+    - https://repo.continuum.io/pkgs/r/win-32\n+    - https://repo.continuum.io/pkgs/r/noarch\n+    - https://repo.continuum.io/pkgs/pro/win-32\n+    - https://repo.continuum.io/pkgs/pro/noarch\n+    - https://repo.continuum.io/pkgs/msys2/win-32\n+    - https://repo.continuum.io/pkgs/msys2/noarch\n+\n+PyTorch doesn't work on 32-bit system. Please use Windows and\n+Python 64-bit version.\n+\n+Why are there no Python 2 packages for Windows?\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Because it's not stable enough. There're some issues that need to\n+be solved before we officially release it. You can build it by yourself.\n+\n+Import error\n+^^^^^^^^^^^^\n+\n+.. code-block:: py3tb\n+\n+    from torch._C import *\n+\n+    ImportError: DLL load failed: The specified module could not be found.\n+\n+\n+The problem is caused by the missing of the essential files. Actually,\n+we include almost all the essential files that PyTorch need except VC2017\n+redistributable. You can resolve this by typing the following command.\n+\n+.. code-block:: bat\n+\n+    conda install -c peterjc123 vc vs2017_runtime\n+\n+Another possible cause may be you are using GPU version without NVIDIA\n+graphics cards. Please replace your GPU package with the CPU one.\n+\n+Usage (multiprocessing)\n+-------------------------------------------------------\n+\n+Multiprocessing error without if-clause protection\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+.. code-block:: py3tb\n+\n+    RuntimeError:\n+   \tAn attempt has been made to start a new process before the\n+   \tcurrent process has finished its bootstrapping phase.\n+\n+       This probably means that you are not using fork to start your\n+       child processes and you have forgotten to use the proper idiom\n+       in the main module:\n+\n+           if __name__ == '__main__':\n+               freeze_support()\n+               ...\n+\n+       The \"freeze_support()\" line can be omitted if the program\n+       is not going to be frozen to produce an executable.\n+\n+The implementation of ``multiprocessing`` is different on Windows, which\n+uses ``spawn`` instead of ``fork``. So we have to wrap the code with an\n+if-clause to protect the code from executing multiple times. Refactor\n+your code into the following structure.\n+\n+.. code-block:: python\n+\n+    import torch\n+\n+    def main()\n+        for i, (x, y) in dataloader:", "path": "docs/source/notes/windows.rst", "position": null, "original_position": 209, "commit_id": "ec1eeab2d5ba8b535ed62b6589602b6f1de023a2", "original_commit_id": "ccf24cb5995c3cf2238d262e7ac05b4558cda7d2", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "nit: you need `enumerate` to get `i`. Also can we just say `data` instead of `(x, y)`", "created_at": "2018-04-19T03:30:15Z", "updated_at": "2018-11-23T15:42:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/6653#discussion_r182625791", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6653", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/182625791"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6653#discussion_r182625791"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6653"}}, "body_html": "<p>nit: you need <code>enumerate</code> to get <code>i</code>. Also can we just say <code>data</code> instead of <code>(x, y)</code></p>", "body_text": "nit: you need enumerate to get i. Also can we just say data instead of (x, y)"}