{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109739773", "pull_request_review_id": 30671730, "id": 109739773, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwOTczOTc3Mw==", "diff_hunk": "@@ -297,4 +349,113 @@ void THCSTensor_(retain)(THCState *state, THCSTensor *self)\n   THAtomicIncrementRef(&self->refcount);\n }\n \n+void THCSTensor_(contiguous)(THCState *state, THCSTensor *self) {\n+  if (self->contiguous) return;\n+  THCSTensor_(reorder)(state, self);\n+  self->contiguous = 1;\n+}\n+\n+int THCSTensor_(checkGPU)(THCState *state, unsigned int nSparseTensors, unsigned int nTensors, ...)\n+{\n+  /* FIXME: remove this flag after any users stop using it since it is\n+     now superseded by the runtime option */\n+#ifdef DISABLE_CHECK_GPU\n+  return 1;\n+#else\n+  int kernelP2PEnabled =\n+    THCState_getKernelPeerToPeerAccessEnabled(state);\n+\n+  int curDev = -1;\n+  unsigned int nDenseTensors = nTensors - nSparseTensors;\n+  THCudaCheck(cudaGetDevice(&curDev));\n+  va_list(args);\n+  va_start(args, nTensors);\n+  int valid = 1;\n+  int sparse = 1;\n+  for (unsigned int i = 0; i < nSparseTensors + nDenseTensors; i++) {\n+    THCSTensor *sparseTensor;\n+    THCTensor *denseTensor;\n+    if (i < nSparseTensors) {\n+      sparseTensor = va_arg(args, THCSTensor*);\n+      if (sparseTensor == NULL) {\n+        continue;\n+      }\n+    } else {\n+      denseTensor = va_arg(args, THCTensor*);\n+      if (denseTensor == NULL) {\n+        continue;\n+      }\n+    }\n+    int tensorDev = i < nSparseTensors ?\n+      THCSTensor_(getDevice)(state, sparseTensor) :\n+      THCTensor_(getDevice)(state, denseTensor);\n+    if (tensorDev == -1) {\n+      /* This tensor does not have GPU memory (empty) */\n+      continue;\n+    }\n+\n+    if (tensorDev != curDev) {\n+      if (kernelP2PEnabled) {\n+        /* Kernel p2p access is allowed */\n+        /* Can `curDev` access `tensorDev` directly? */\n+        if (!THCState_getPeerToPeerAccess(state, curDev, tensorDev)) {\n+          valid = 0;\n+          break;\n+        }\n+      } else {\n+        /* No kernel p2p access allowed */\n+        valid = 0;\n+        break;\n+      }\n+    }\n+  }\n+\n+  va_end(args);\n+  return valid;\n+#endif // DISABLE_CHECK_GPU\n+}\n+\n+void THCTensor_(sparseMask)(THCState *state, THCSTensor *r_, THCTensor *t, THCSTensor *mask) {\n+  THCAssertSameGPU(THCSTensor_(checkGPU)(state, 2, 3, r_, mask, t));\n+  if(!THCSTensor_(isSameSizeAsDense)(state, mask, t)) {\n+    THError(\"sparseMask operands have incompatible sizes\");\n+  }\n+  THCSTensor_(resizeAs)(state, r_, mask);\n+  if (mask->nnz == 0) {\n+    THCSTensor_(zero)(state, r_);\n+    return;\n+  }\n+  THCIndexTensor *maskIndices = THCSTensor_(indices)(state, mask);\n+  THCTensor *maskValues = THCSTensor_(values)(state, mask);\n+  THCTensor *rValues = THCTensor_(new)(state);\n+  THCTensor_(resizeAs)(state, rValues, maskValues);\n+  THCSTensor_(_move)(state, r_, THCIndexTensor_(newClone)(state, maskIndices), rValues);\n+  r_->contiguous = mask->contiguous;\n+  r_->nnz = mask->nnz;\n+\n+  THCudaLongTensor *indices = THCudaLongTensor_newWithSize1d(state, mask->nnz);\n+  THCudaLongTensor *indicesBuffer = THCudaLongTensor_new(state);\n+\n+  THCudaLongTensor_zero(state, indices);\n+  for (long d = 0; d < mask->nDimensionI; d++) {\n+    THCudaLongTensor_mul(state, indices, indices, mask->size[d]);\n+    THCudaLongTensor_select(state, indicesBuffer, maskIndices, 0, d);\n+    THCudaLongTensor_cadd(state, indices, indices, 1, indicesBuffer);\n+  }\n+  THLongStorage *viewSize = THLongStorage_newWithSize(1 + mask->nDimensionV);\n+  viewSize->data[0] = -1;\n+  for (long d = 0; d < mask->nDimensionV; d++) {\n+    viewSize->data[1 + d] = mask->size[mask->nDimensionI + d];\n+  }\n+  THCTensor *t_view = THCTensor_(newView)(state, t, viewSize);\n+  THCTensor_(indexSelect)(state, rValues, t_view, 0, indices);", "path": "torch/lib/THCS/generic/THCSTensor.c", "position": 402, "original_position": 317, "commit_id": "f4105bcbb3dc4ebc23f20112949a0de79e24d978", "original_commit_id": "179b2dafe865e7cbdd79b18f58143e8ca5d4782d", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "body": "\ud83d\udc4d \r\n\r\n", "created_at": "2017-04-04T18:19:40Z", "updated_at": "2018-11-23T15:33:00Z", "html_url": "https://github.com/pytorch/pytorch/pull/1147#discussion_r109739773", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1147", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109739773"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1147#discussion_r109739773"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1147"}}, "body_html": "<p><g-emoji class=\"g-emoji\" alias=\"+1\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f44d.png\">\ud83d\udc4d</g-emoji></p>", "body_text": "\ud83d\udc4d"}