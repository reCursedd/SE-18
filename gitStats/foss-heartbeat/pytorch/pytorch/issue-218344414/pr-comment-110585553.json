{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/110585553", "pull_request_review_id": 31767655, "id": 110585553, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMDU4NTU1Mw==", "diff_hunk": "@@ -14,68 +30,178 @@ THCTensor *THCSTensor_(toDense)(THCState *state, THCSTensor *self) {\n   other = THCTensor_(newWithSize)(state, storage, NULL);\n   THCTensor_(zero)(state, other);\n \n-  // Some necessary dimensions and sizes\n   const ptrdiff_t nnz = THCSTensor_(nnz)(state, self);\n+  if (nnz == 0) {\n+    THLongStorage_free(storage);\n+    return other;\n+  }\n+\n+  // TODO more benchmarking\n   const dim3 block = getApplyBlock();\n   dim3 grid;\n-  THArgCheck(getApplyGrid(state, nnz, grid), 1, CUTORCH_DIM_WARNING);\n+  if (self->nDimensionV == 0) {\n+    THArgCheck(getApplyGrid(state, nnz, grid), 1, CUTORCH_DIM_WARNING);\n \n-  TensorInfo<real, unsigned long> otherInfo =\n-    getTensorInfo<THCTensor, unsigned long>(state, other);\n-  TensorInfo<long, unsigned long> indicesInfo =\n-    getTensorInfo<THCudaLongTensor, unsigned long>(state, self->indices);\n-  TensorInfo<real, unsigned long> valuesInfo =\n-    getTensorInfo<THCTensor, unsigned long>(state, self->values);\n+    THCSTensor_spcKernelScalar<TensorAddOp<real>, unsigned long, real>\n+      <<<grid, block, 0, THCState_getCurrentStream(state)>>>(\n+          TensorAddOp<real>(),\n+          V_INFO(other), I_INFO(self->indices), V_INFO(self->values),\n+          (unsigned long)(nnz));\n+  } else {\n+    THArgCheck(getApplyGrid(state, nnz * block.x, grid), 1, CUTORCH_DIM_WARNING);\n \n-  THCSTensor_toDenseKernel<unsigned long, real>\n-    <<<grid, block, 0, THCState_getCurrentStream(state)>>>(\n-        otherInfo, indicesInfo, valuesInfo, (unsigned long)(nnz));\n+    THCSTensor_spcKernel<TensorAddOp<real>, unsigned long, real>\n+      <<<grid, block, 0, THCState_getCurrentStream(state)>>>(\n+          TensorAddOp<real>(),\n+          V_INFO(other), I_INFO(self->indices), V_INFO(self->values),\n+          (unsigned long)(nnz));\n+  }\n \n   THCudaCheck(cudaGetLastError());\n   THLongStorage_free(storage);\n   return other;\n-  */\n-  THError(\"WARNING: Sparse Cuda Tensor op toDense is not implemented\");\n-  return NULL;\n }\n \n void THCSTensor_(reorder)(THCState *state, THCSTensor *self) {\n-  THError(\"WARNING: Sparse Cuda Tensor op reorder is not implemented\");\n-}\n+  if (self->nnz < 2) return;\n+#if CUDA_VERSION >= 7000\n+  THCThrustAllocator thrustAlloc(state);\n+#define THRUST_EXEC(fn, ...) fn(thrust::cuda::par(thrustAlloc).on(THCState_getCurrentStream(state)), ##__VA_ARGS__)\n+#else\n+#define THRUST_EXEC(fn, ...) fn(##__VA_ARGS__)\n+#endif\n+\n+  THCIndexTensor *indices = THCSTensor_(indices)(state, self);\n+  THCTensor *values = THCSTensor_(values)(state, self);\n+  THCIndexTensor *indicesSlice = THCIndexTensor_(new)(state);\n+  THCIndexTensor *indicesScalar = THCIndexTensor_(newWithSize1d)(state, self->nnz);\n+  THCIndexTensor *projectIndices = THCIndexTensor_(newWithSize2d)(state, 2, self->nnz);\n+  THCTensor *projectValues = THCTensor_(newWithSize1d)(state, self->nnz);\n+  THCTensor_(fill)(state, projectValues, ScalarConvert<int, real>::to(1));\n+  THCudaLongTensor *mapping = THCudaLongTensor_new(state);\n+  THCudaLongTensor *permutation = THCudaLongTensor_new(state);\n+  THCudaLongTensor_select(state, mapping, projectIndices, 0, 0);\n+  THCudaLongTensor_select(state, permutation, projectIndices, 0, 1);\n+  THCudaLongTensor *unique = THCudaLongTensor_newWithSize1d(state, self->nnz);\n+\n+  thrust::device_ptr<long> permutationIter(THCudaLongTensor_data(state, permutation));\n+  THRUST_EXEC(thrust::sequence, permutationIter, permutationIter + self->nnz);\n+  THCIndexTensor_(zero)(state, indicesScalar);\n+  integer factor = 1;\n+  for (int i = self->nDimensionI - 1; i >= 0; i--) {\n+    THCIndexTensor_(select)(state, indicesSlice, indices, 0, i);\n+    THCIndexTensor_(cadd)(state, indicesScalar, indicesScalar, factor, indicesSlice);\n+    factor *= self->size[i];\n+  }\n+  thrust::device_ptr<integer> indicesIter(THCIndexTensor_(data)(state, indicesScalar));\n+\n+  // HACK *theoretically* we need stable sort, so that indices mapped to the same\n+  // location are sorted in the permutation. This is necessary to ensure that\n+  // the projection matrix is contiguous\n+  // However, it seems to work even with non-stable sort, which is nice because it's faster...\n+  // Revert this if bugs arise, or add a step to sort the projection matrix indices explicitly", "path": "torch/lib/THCS/generic/THCSTensor.cu", "position": null, "original_position": 115, "commit_id": "f4105bcbb3dc4ebc23f20112949a0de79e24d978", "original_commit_id": "8e4660ac5145c4a48e35620f8810fa8863cb7b50", "user": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "body": "Yes I went with the safe option in the end (if you look at the latest code)", "created_at": "2017-04-10T07:05:46Z", "updated_at": "2018-11-23T15:33:05Z", "html_url": "https://github.com/pytorch/pytorch/pull/1147#discussion_r110585553", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1147", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/110585553"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1147#discussion_r110585553"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1147"}}, "body_html": "<p>Yes I went with the safe option in the end (if you look at the latest code)</p>", "body_text": "Yes I went with the safe option in the end (if you look at the latest code)", "in_reply_to_id": 109175304}