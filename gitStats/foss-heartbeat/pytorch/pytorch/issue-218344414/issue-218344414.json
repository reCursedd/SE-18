{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1147", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1147/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1147/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1147/events", "html_url": "https://github.com/pytorch/pytorch/pull/1147", "id": 218344414, "node_id": "MDExOlB1bGxSZXF1ZXN0MTEzNTM3MTA3", "number": 1147, "title": "CUDA sparse operations (+ CPU improvements)", "user": {"login": "martinraison", "id": 2560662, "node_id": "MDQ6VXNlcjI1NjA2NjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2560662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinraison", "html_url": "https://github.com/martinraison", "followers_url": "https://api.github.com/users/martinraison/followers", "following_url": "https://api.github.com/users/martinraison/following{/other_user}", "gists_url": "https://api.github.com/users/martinraison/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinraison/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinraison/subscriptions", "organizations_url": "https://api.github.com/users/martinraison/orgs", "repos_url": "https://api.github.com/users/martinraison/repos", "events_url": "https://api.github.com/users/martinraison/events{/privacy}", "received_events_url": "https://api.github.com/users/martinraison/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-03-30T22:19:03Z", "updated_at": "2018-11-23T15:33:05Z", "closed_at": "2017-04-18T19:47:35Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1147", "html_url": "https://github.com/pytorch/pytorch/pull/1147", "diff_url": "https://github.com/pytorch/pytorch/pull/1147.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1147.patch"}, "body_html": "<p>This is a follow-up to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"207307698\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/735\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/735/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/735\">#735</a> . The goal was to add a similar level of support for CUDA sparse tensors. This includes:</p>\n<ul>\n<li><code>sparse_mask</code></li>\n<li><code>to_dense</code></li>\n<li><code>contiguous</code></li>\n<li><code>transpose</code></li>\n<li><code>spaddmm</code></li>\n<li><code>spcadd</code></li>\n<li><code>mul</code>, <code>div</code></li>\n<li><code>cadd</code>, <code>csub</code>, <code>cmul</code></li>\n<li>(new for CPU as well) <code>hspmm</code> operation that does multiplies a sparse matrix with a dense matrix and returns a matrix in the form of a hybrid tensor (i.e. 1 sparse dimension, 1 dense dimension). This seems to be the most natural output format for this problem, since the output is a collection of non-zero rows</li>\n<li>updated <code>Embedding</code> layer to work with CUDA and use sparse efficient sparse operations</li>\n<li>cuSPARSE handle management (same logic as for cuBLAS)</li>\n</ul>\n<p>Bonus:</p>\n<ul>\n<li>faster <code>contiguous</code> for CPU sparse tensors (the previous implementation was using insertion sort)</li>\n<li>faster <code>cadd</code> for CPU sparse tensors using blas</li>\n<li><code>abs</code> for <code>ShortTensor</code>. For some reason this was missing, and I needed it for the testing code</li>\n<li>more test coverage for spares tensors</li>\n<li>faster tensor comparison in tests. This comes at the cost of slightly more complex logic (which is usually bad in test code), but it is hard to avoid since converting all sparse matrices to dense in order to compare them is very slow</li>\n</ul>\n<p>I hacked this quick thing together just to get a sense of the speed improvement: <a href=\"https://gist.github.com/martinraison/1e7c18c6f6eda87f1cb4995b0e6a22a5\">https://gist.github.com/martinraison/1e7c18c6f6eda87f1cb4995b0e6a22a5</a></p>\n<p>With the default params I get:</p>\n<ul>\n<li>10 sec/batch with dense + CPU</li>\n<li>0.86 sec/batch with dense + CUDA</li>\n<li>0.15 sec/batch with sparse + CPU</li>\n<li>0.13 sec/batch with sparse + CUDA</li>\n</ul>\n<p>This shouldn't be considered as a benchmark though (it measures the time for a complete training iteration, including all the python processing, and the forward/backward passes through tanh/linear/cross-entropy)</p>", "body_text": "This is a follow-up to #735 . The goal was to add a similar level of support for CUDA sparse tensors. This includes:\n\nsparse_mask\nto_dense\ncontiguous\ntranspose\nspaddmm\nspcadd\nmul, div\ncadd, csub, cmul\n(new for CPU as well) hspmm operation that does multiplies a sparse matrix with a dense matrix and returns a matrix in the form of a hybrid tensor (i.e. 1 sparse dimension, 1 dense dimension). This seems to be the most natural output format for this problem, since the output is a collection of non-zero rows\nupdated Embedding layer to work with CUDA and use sparse efficient sparse operations\ncuSPARSE handle management (same logic as for cuBLAS)\n\nBonus:\n\nfaster contiguous for CPU sparse tensors (the previous implementation was using insertion sort)\nfaster cadd for CPU sparse tensors using blas\nabs for ShortTensor. For some reason this was missing, and I needed it for the testing code\nmore test coverage for spares tensors\nfaster tensor comparison in tests. This comes at the cost of slightly more complex logic (which is usually bad in test code), but it is hard to avoid since converting all sparse matrices to dense in order to compare them is very slow\n\nI hacked this quick thing together just to get a sense of the speed improvement: https://gist.github.com/martinraison/1e7c18c6f6eda87f1cb4995b0e6a22a5\nWith the default params I get:\n\n10 sec/batch with dense + CPU\n0.86 sec/batch with dense + CUDA\n0.15 sec/batch with sparse + CPU\n0.13 sec/batch with sparse + CUDA\n\nThis shouldn't be considered as a benchmark though (it measures the time for a complete training iteration, including all the python processing, and the forward/backward passes through tanh/linear/cross-entropy)", "body": "This is a follow-up to #735 . The goal was to add a similar level of support for CUDA sparse tensors. This includes:\r\n\r\n* `sparse_mask`\r\n* `to_dense`\r\n* `contiguous`\r\n* `transpose`\r\n* `spaddmm`\r\n* `spcadd`\r\n* `mul`, `div`\r\n* `cadd`, `csub`, `cmul`\r\n* (new for CPU as well) `hspmm` operation that does multiplies a sparse matrix with a dense matrix and returns a matrix in the form of a hybrid tensor (i.e. 1 sparse dimension, 1 dense dimension). This seems to be the most natural output format for this problem, since the output is a collection of non-zero rows\r\n* updated `Embedding` layer to work with CUDA and use sparse efficient sparse operations\r\n* cuSPARSE handle management (same logic as for cuBLAS)\r\n\r\nBonus:\r\n\r\n* faster `contiguous` for CPU sparse tensors (the previous implementation was using insertion sort)\r\n* faster `cadd` for CPU sparse tensors using blas\r\n* `abs` for `ShortTensor`. For some reason this was missing, and I needed it for the testing code\r\n* more test coverage for spares tensors\r\n* faster tensor comparison in tests. This comes at the cost of slightly more complex logic (which is usually bad in test code), but it is hard to avoid since converting all sparse matrices to dense in order to compare them is very slow\r\n\r\nI hacked this quick thing together just to get a sense of the speed improvement: https://gist.github.com/martinraison/1e7c18c6f6eda87f1cb4995b0e6a22a5\r\n\r\nWith the default params I get:\r\n* 10 sec/batch with dense + CPU\r\n* 0.86 sec/batch with dense + CUDA\r\n* 0.15 sec/batch with sparse + CPU\r\n* 0.13 sec/batch with sparse + CUDA\r\n\r\nThis shouldn't be considered as a benchmark though (it measures the time for a complete training iteration, including all the python processing, and the forward/backward passes through tanh/linear/cross-entropy)\r\n"}