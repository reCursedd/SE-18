{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/110108242", "pull_request_review_id": 31254325, "id": 110108242, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMDEwODI0Mg==", "diff_hunk": "@@ -1385,12 +1385,80 @@ def test_LSTM_cell(self):\n \n             (hx + cx).sum().backward()\n \n+    @unittest.skipIf(not TEST_CUDA, 'CUDA not available')\n+    def test_cuda_rnn_fused(self):\n+        def copy_rnn(rnn1, rnn2):\n+            for x_layer, y_layer in zip(rnn1.all_weights, rnn2.all_weights):\n+                for x, y in zip(x_layer, y_layer):\n+                    x.data.copy_(y.data)\n+\n+        def check_rnn_grads(rnn1, rnn2):\n+            for x_layer, y_layer in zip(rnn1.all_weights, rnn2.all_weights):\n+                for x, y in zip(x_layer, y_layer):\n+                    self.assertEqual(x.grad, y.grad, prec=5e-5)\n+\n+        input_size = 10\n+        hidden_size = 6\n+        num_layers = 2\n+        seq_length = 7\n+        batch = 6\n+        input_val = torch.randn(seq_length, batch, input_size)\n+        grad_output = torch.randn(seq_length, batch, hidden_size)\n+        hx_val = torch.randn(num_layers, batch, hidden_size)\n+        grad_hy = torch.randn(num_layers, batch, hidden_size)\n+        prev = torch.backends.cudnn.enabled\n+        torch.backends.cudnn.enabled = False\n+        for module in (nn.GRU, nn.LSTM):\n+            for bias in (True, False):\n+                rnn = module(input_size, hidden_size, num_layers, bias=bias)\n+                rnn_cuda = module(input_size, hidden_size, num_layers, bias=bias).cuda()\n+                copy_rnn(rnn, rnn_cuda)\n+\n+                is_lstm = type(rnn) == nn.LSTM\n+                if is_lstm:\n+                    hx = (Variable(hx_val.clone(), requires_grad=True),\n+                          Variable(hx_val.clone().add(1), requires_grad=True))\n+                    hx_cuda = (Variable(hx_val.clone().cuda(), requires_grad=True),\n+                               Variable(hx_val.clone().cuda().add(1), requires_grad=True))\n+                else:\n+                    hx = Variable(hx_val.clone(), requires_grad=True)\n+                    hx_cuda = Variable(hx_val.clone().cuda(), requires_grad=True)\n+\n+                inp = Variable(input_val.clone(), requires_grad=True)\n+                inp_cu = Variable(input_val.clone().cuda(), requires_grad=True)\n+                output1, hy1 = rnn(inp, hx)\n+                output2, hy2 = rnn_cuda(inp_cu, hx_cuda)\n+                if is_lstm:\n+                    torch.autograd.backward(\n+                        [output1, hy1[0], hy1[1]], [grad_output, grad_hy, grad_hy + 1]\n+                    )\n+                    torch.autograd.backward(\n+                        [output2, hy2[0], hy2[1]],\n+                        [grad_output.clone().cuda(), grad_hy.clone().cuda(), (grad_hy + 1).cuda()]\n+                    )\n+                else:\n+                    torch.autograd.backward([output1, hy1], [grad_output, grad_hy])\n+                    torch.autograd.backward([output2, hy2], [grad_output.clone().cuda(), grad_hy.clone().cuda()])", "path": "test/test_nn.py", "position": null, "original_position": 57, "commit_id": "4b269de7bd2dc272edfb456696a1552bf575bace", "original_commit_id": "c058a4c0cceccc54a2e0cdf67ecfe47b90bb0d3d", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Same here. The clones should be unnecessary.", "created_at": "2017-04-06T08:47:47Z", "updated_at": "2018-11-23T15:33:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/1119#discussion_r110108242", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1119", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/110108242"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1119#discussion_r110108242"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1119"}}, "body_html": "<p>Same here. The clones should be unnecessary.</p>", "body_text": "Same here. The clones should be unnecessary."}