{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/326186733", "html_url": "https://github.com/pytorch/pytorch/issues/2583#issuecomment-326186733", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2583", "id": 326186733, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjE4NjczMw==", "user": {"login": "godisboy", "id": 14243507, "node_id": "MDQ6VXNlcjE0MjQzNTA3", "avatar_url": "https://avatars0.githubusercontent.com/u/14243507?v=4", "gravatar_id": "", "url": "https://api.github.com/users/godisboy", "html_url": "https://github.com/godisboy", "followers_url": "https://api.github.com/users/godisboy/followers", "following_url": "https://api.github.com/users/godisboy/following{/other_user}", "gists_url": "https://api.github.com/users/godisboy/gists{/gist_id}", "starred_url": "https://api.github.com/users/godisboy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/godisboy/subscriptions", "organizations_url": "https://api.github.com/users/godisboy/orgs", "repos_url": "https://api.github.com/users/godisboy/repos", "events_url": "https://api.github.com/users/godisboy/events{/privacy}", "received_events_url": "https://api.github.com/users/godisboy/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-31T04:31:18Z", "updated_at": "2017-08-31T04:31:18Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15871674\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/allenye0119\">@allenye0119</a>  This is the code for training.</p>\n<pre><code>for epoch in range(0, 25):\n    for i, data in enumerate(dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        D.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n            \n        input.resize_as_(real_cpu).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n        output = D(inputv)\n        errD_real = criterion(output, labelv)\n        errD_real.backward()\n        D_x = output.data.mean()\n\n        # train with fake\n        noise.resize_(ntimestep, batch_size, nz).normal_(0, 1) \n        noisev = Variable(noise)\n        fake, fakeseq, fgimgseq, fgmaskseq = G(noisev) \n        labelv = Variable(label.fill_(fake_label))\n\n        output = D(fake.detach())  \n        errD_fake = criterion(output, labelv)\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        G.zero_grad()\n        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n        output = D(fake)\n        errG = criterion(output, labelv)\n        print(errG)\n        errG.backward()\n        D_G_z2 = output.data.mean()\n        optimizerG.step()\n</code></pre>", "body_text": "@allenye0119  This is the code for training.\nfor epoch in range(0, 25):\n    for i, data in enumerate(dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        D.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n            \n        input.resize_as_(real_cpu).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n        output = D(inputv)\n        errD_real = criterion(output, labelv)\n        errD_real.backward()\n        D_x = output.data.mean()\n\n        # train with fake\n        noise.resize_(ntimestep, batch_size, nz).normal_(0, 1) \n        noisev = Variable(noise)\n        fake, fakeseq, fgimgseq, fgmaskseq = G(noisev) \n        labelv = Variable(label.fill_(fake_label))\n\n        output = D(fake.detach())  \n        errD_fake = criterion(output, labelv)\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        G.zero_grad()\n        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n        output = D(fake)\n        errG = criterion(output, labelv)\n        print(errG)\n        errG.backward()\n        D_G_z2 = output.data.mean()\n        optimizerG.step()", "body": "@allenye0119  This is the code for training.\r\n\r\n```\r\nfor epoch in range(0, 25):\r\n    for i, data in enumerate(dataloader, 0):\r\n        ############################\r\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\r\n        ###########################\r\n        # train with real\r\n        D.zero_grad()\r\n        real_cpu, _ = data\r\n        batch_size = real_cpu.size(0)\r\n            \r\n        input.resize_as_(real_cpu).copy_(real_cpu)\r\n        label.resize_(batch_size).fill_(real_label)\r\n        inputv = Variable(input)\r\n        labelv = Variable(label)\r\n        output = D(inputv)\r\n        errD_real = criterion(output, labelv)\r\n        errD_real.backward()\r\n        D_x = output.data.mean()\r\n\r\n        # train with fake\r\n        noise.resize_(ntimestep, batch_size, nz).normal_(0, 1) \r\n        noisev = Variable(noise)\r\n        fake, fakeseq, fgimgseq, fgmaskseq = G(noisev) \r\n        labelv = Variable(label.fill_(fake_label))\r\n\r\n        output = D(fake.detach())  \r\n        errD_fake = criterion(output, labelv)\r\n        errD_fake.backward()\r\n        D_G_z1 = output.data.mean()\r\n        errD = errD_real + errD_fake\r\n        optimizerD.step()\r\n\r\n        ############################\r\n        # (2) Update G network: maximize log(D(G(z)))\r\n        ###########################\r\n        G.zero_grad()\r\n        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\r\n        output = D(fake)\r\n        errG = criterion(output, labelv)\r\n        print(errG)\r\n        errG.backward()\r\n        D_G_z2 = output.data.mean()\r\n        optimizerG.step()"}