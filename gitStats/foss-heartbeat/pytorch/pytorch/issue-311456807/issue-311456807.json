{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6300", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6300/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6300/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6300/events", "html_url": "https://github.com/pytorch/pytorch/issues/6300", "id": 311456807, "node_id": "MDU6SXNzdWUzMTE0NTY4MDc=", "number": 6300, "title": "ONNX problem with BatchNormalization in FlowNet (pytorch variant)", "user": {"login": "epiception", "id": 13215333, "node_id": "MDQ6VXNlcjEzMjE1MzMz", "avatar_url": "https://avatars3.githubusercontent.com/u/13215333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epiception", "html_url": "https://github.com/epiception", "followers_url": "https://api.github.com/users/epiception/followers", "following_url": "https://api.github.com/users/epiception/following{/other_user}", "gists_url": "https://api.github.com/users/epiception/gists{/gist_id}", "starred_url": "https://api.github.com/users/epiception/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epiception/subscriptions", "organizations_url": "https://api.github.com/users/epiception/orgs", "repos_url": "https://api.github.com/users/epiception/repos", "events_url": "https://api.github.com/users/epiception/events{/privacy}", "received_events_url": "https://api.github.com/users/epiception/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-04-05T02:59:23Z", "updated_at": "2018-11-15T01:45:43Z", "closed_at": "2018-04-06T19:52:29Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI faced this problem when exporting the pytorch model for FlowNetS with BatchNorm, mainly when checking the IR</p>\n<p>The pytorch model is,  <a href=\"https://github.com/ClementPinard/FlowNetPytorch\">https://github.com/ClementPinard/FlowNetPytorch</a></p>\n<p>PyTorch version: 0.4.0a0+2e156f3 (No GPU, CPU only)<br>\nThe repo steps I followed,</p>\n<ol>\n<li>\n<p>Cloned the model: <a href=\"https://github.com/ClementPinard/FlowNetPytorch\">https://github.com/ClementPinard/FlowNetPytorch</a><br>\ngit clone <a href=\"https://github.com/ClementPinard/FlowNetPytorch.git\">https://github.com/ClementPinard/FlowNetPytorch.git</a></p>\n</li>\n<li>\n<p>Downloaded pretrained weights for the BatchNorm variant, and placed it in the main repo folder:<br>\n<a href=\"https://drive.google.com/drive/folders/16eo3p9dO_vmssxRoZCmWkTpNjKRzJzn5\" rel=\"nofollow\">https://drive.google.com/drive/folders/16eo3p9dO_vmssxRoZCmWkTpNjKRzJzn5</a></p>\n</li>\n<li>\n<p>Script to create onnx file (again in the same folder), check IR, recreate error:</p>\n<pre><code> import torch\n from torch.autograd import Variable\n import torch.onnx\n \n import onnx\n from onnx_tf.backend import prepare\n \n import models\n \n model = models.FlowNetS\n \n # Original model trained on GPU, mapped for CPU\n data = torch.load(\"./flownets_bn_EPE2.459.pth.tar\", map_location=lambda storage, loc: storage)\n \n # dummy input\n dummy_input = Variable(torch.randn(10, 6, 224, 224))\n \n state_dict = model.flownets_bn(data = data)\n torch.onnx.export(state_dict, dummy_input, \"flownet.onnx\", verbose=True)\n \n #no error here\n model = onnx.load(\"flownet.onnx\")\n \n # Check that the IR is well formed\n onnx.checker.check_model(model)\n</code></pre>\n</li>\n</ol>\n<p>Traceback message,<br>\nTraceback (most recent call last):<br>\nFile \"onnx_example.py\", line 29, in <br>\nonnx.checker.check_model(model)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/onnx/checker.py\", line 77, in check_model<br>\nC.check_model(model.SerializeToString())<br>\nonnx.onnx_cpp2py_export.checker.ValidationError: Input index 3 must be set to consumed for operator BatchNormalization</p>\n<p>==&gt; Context: Bad node spec: input: \"64\" input: \"2\" input: \"3\" input: \"4\" input: \"5\" output: \"65\" op_type: \"BatchNormalization\" attribute { name: \"epsilon\" f: 1e-05 type: FLOAT } attribute { name: \"is_test\" i: 1 type: INT } attribute { name: \"momentum\" f: 0.9 type: FLOAT } doc_string: \"/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py(1206): batch_norm\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/batchnorm.py(49): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): <strong>call</strong>\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.py(91): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): <strong>call</strong>\\n/media/epiception/Windows/Ganesh/Datasets/Weights/flownet/FlowNetPytorch/models/FlowNetS.py(86): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): <strong>call</strong>\\n/usr/local/lib/python2.7/dist-packages/torch/jit/<strong>init</strong>.py(286): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(371): <strong>call</strong>\\n/usr/local/lib/python2.7/dist-packages/torch/jit/<strong>init</strong>.py(253): get_trace_graph\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(133): _export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(84): export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/<strong>init</strong>.py(21): export\\nonnx_example.py(23): \\n\"</p>\n<p>Thank You!</p>", "body_text": "Hi,\nI faced this problem when exporting the pytorch model for FlowNetS with BatchNorm, mainly when checking the IR\nThe pytorch model is,  https://github.com/ClementPinard/FlowNetPytorch\nPyTorch version: 0.4.0a0+2e156f3 (No GPU, CPU only)\nThe repo steps I followed,\n\n\nCloned the model: https://github.com/ClementPinard/FlowNetPytorch\ngit clone https://github.com/ClementPinard/FlowNetPytorch.git\n\n\nDownloaded pretrained weights for the BatchNorm variant, and placed it in the main repo folder:\nhttps://drive.google.com/drive/folders/16eo3p9dO_vmssxRoZCmWkTpNjKRzJzn5\n\n\nScript to create onnx file (again in the same folder), check IR, recreate error:\n import torch\n from torch.autograd import Variable\n import torch.onnx\n \n import onnx\n from onnx_tf.backend import prepare\n \n import models\n \n model = models.FlowNetS\n \n # Original model trained on GPU, mapped for CPU\n data = torch.load(\"./flownets_bn_EPE2.459.pth.tar\", map_location=lambda storage, loc: storage)\n \n # dummy input\n dummy_input = Variable(torch.randn(10, 6, 224, 224))\n \n state_dict = model.flownets_bn(data = data)\n torch.onnx.export(state_dict, dummy_input, \"flownet.onnx\", verbose=True)\n \n #no error here\n model = onnx.load(\"flownet.onnx\")\n \n # Check that the IR is well formed\n onnx.checker.check_model(model)\n\n\n\nTraceback message,\nTraceback (most recent call last):\nFile \"onnx_example.py\", line 29, in \nonnx.checker.check_model(model)\nFile \"/usr/local/lib/python2.7/dist-packages/onnx/checker.py\", line 77, in check_model\nC.check_model(model.SerializeToString())\nonnx.onnx_cpp2py_export.checker.ValidationError: Input index 3 must be set to consumed for operator BatchNormalization\n==> Context: Bad node spec: input: \"64\" input: \"2\" input: \"3\" input: \"4\" input: \"5\" output: \"65\" op_type: \"BatchNormalization\" attribute { name: \"epsilon\" f: 1e-05 type: FLOAT } attribute { name: \"is_test\" i: 1 type: INT } attribute { name: \"momentum\" f: 0.9 type: FLOAT } doc_string: \"/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py(1206): batch_norm\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/batchnorm.py(49): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): call\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.py(91): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): call\\n/media/epiception/Windows/Ganesh/Datasets/Weights/flownet/FlowNetPytorch/models/FlowNetS.py(86): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): call\\n/usr/local/lib/python2.7/dist-packages/torch/jit/init.py(286): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(371): call\\n/usr/local/lib/python2.7/dist-packages/torch/jit/init.py(253): get_trace_graph\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(133): _export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(84): export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/init.py(21): export\\nonnx_example.py(23): \\n\"\nThank You!", "body": "Hi,\r\nI faced this problem when exporting the pytorch model for FlowNetS with BatchNorm, mainly when checking the IR \r\n\r\nThe pytorch model is,  https://github.com/ClementPinard/FlowNetPytorch\r\n\r\nPyTorch version: 0.4.0a0+2e156f3 (No GPU, CPU only)\r\nThe repo steps I followed,\r\n\r\n1. Cloned the model: https://github.com/ClementPinard/FlowNetPytorch\r\ngit clone https://github.com/ClementPinard/FlowNetPytorch.git\r\n\r\n2. Downloaded pretrained weights for the BatchNorm variant, and placed it in the main repo folder:\r\nhttps://drive.google.com/drive/folders/16eo3p9dO_vmssxRoZCmWkTpNjKRzJzn5\r\n\r\n3. Script to create onnx file (again in the same folder), check IR, recreate error:\r\n\r\n        import torch\r\n        from torch.autograd import Variable\r\n        import torch.onnx\r\n        \r\n        import onnx\r\n        from onnx_tf.backend import prepare\r\n        \r\n        import models\r\n        \r\n        model = models.FlowNetS\r\n        \r\n        # Original model trained on GPU, mapped for CPU\r\n        data = torch.load(\"./flownets_bn_EPE2.459.pth.tar\", map_location=lambda storage, loc: storage)\r\n        \r\n        # dummy input\r\n        dummy_input = Variable(torch.randn(10, 6, 224, 224))\r\n        \r\n        state_dict = model.flownets_bn(data = data)\r\n        torch.onnx.export(state_dict, dummy_input, \"flownet.onnx\", verbose=True)\r\n        \r\n        #no error here\r\n        model = onnx.load(\"flownet.onnx\")\r\n        \r\n        # Check that the IR is well formed\r\n        onnx.checker.check_model(model)\r\n\r\nTraceback message,\r\nTraceback (most recent call last):\r\n  File \"onnx_example.py\", line 29, in <module>\r\n    onnx.checker.check_model(model)\r\n  File \"/usr/local/lib/python2.7/dist-packages/onnx/checker.py\", line 77, in check_model\r\n    C.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Input index 3 must be set to consumed for operator BatchNormalization\r\n\r\n==> Context: Bad node spec: input: \"64\" input: \"2\" input: \"3\" input: \"4\" input: \"5\" output: \"65\" op_type: \"BatchNormalization\" attribute { name: \"epsilon\" f: 1e-05 type: FLOAT } attribute { name: \"is_test\" i: 1 type: INT } attribute { name: \"momentum\" f: 0.9 type: FLOAT } doc_string: \"/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py(1206): batch_norm\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/batchnorm.py(49): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): __call__\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.py(91): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): __call__\\n/media/epiception/Windows/Ganesh/Datasets/Weights/flownet/FlowNetPytorch/models/FlowNetS.py(86): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(359): _slow_forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(369): __call__\\n/usr/local/lib/python2.7/dist-packages/torch/jit/__init__.py(286): forward\\n/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py(371): __call__\\n/usr/local/lib/python2.7/dist-packages/torch/jit/__init__.py(253): get_trace_graph\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(133): _export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/utils.py(84): export\\n/usr/local/lib/python2.7/dist-packages/torch/onnx/__init__.py(21): export\\nonnx_example.py(23): <module>\\n\"\r\n\r\nThank You!\r\n"}