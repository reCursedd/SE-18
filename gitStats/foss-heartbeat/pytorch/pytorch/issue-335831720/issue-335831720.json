{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8899", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8899/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8899/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8899/events", "html_url": "https://github.com/pytorch/pytorch/pull/8899", "id": 335831720, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk3NDMxODU0", "number": 8899, "title": "Unique cuda support ", "user": {"login": "yueyericardo", "id": 9999318, "node_id": "MDQ6VXNlcjk5OTkzMTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/9999318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yueyericardo", "html_url": "https://github.com/yueyericardo", "followers_url": "https://api.github.com/users/yueyericardo/followers", "following_url": "https://api.github.com/users/yueyericardo/following{/other_user}", "gists_url": "https://api.github.com/users/yueyericardo/gists{/gist_id}", "starred_url": "https://api.github.com/users/yueyericardo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yueyericardo/subscriptions", "organizations_url": "https://api.github.com/users/yueyericardo/orgs", "repos_url": "https://api.github.com/users/yueyericardo/repos", "events_url": "https://api.github.com/users/yueyericardo/events{/privacy}", "received_events_url": "https://api.github.com/users/yueyericardo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-06-26T13:55:48Z", "updated_at": "2018-07-09T00:10:33Z", "closed_at": "2018-07-09T00:10:33Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8899", "html_url": "https://github.com/pytorch/pytorch/pull/8899", "diff_url": "https://github.com/pytorch/pytorch/pull/8899.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8899.patch"}, "body_html": "<p>Add cuda support for unique.</p>\n<p>There is a simple test below for a tensor including 1M  data.<br>\nAnd the performance is faster.</p>\n<div class=\"highlight highlight-source-python\"><pre>Performance\ncpu: <span class=\"pl-c1\">0.05040597915649414</span> s\nx: tensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>,  <span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">4</span>])\nx output: tensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">9</span>])\nx inverse: tensor([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>,  <span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">3</span>])\n\ngpu: <span class=\"pl-c1\">0.015192985534667969</span> s\ny: tensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>,  <span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">4</span>], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\ny output: tensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">9</span>], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\ny inverse: tensor([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>,  <span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">3</span>], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)</pre></div>\n<div class=\"highlight highlight-source-python\"><pre>Code\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> time\nx<span class=\"pl-k\">=</span>torch.randint(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">10</span>,(<span class=\"pl-c1\">1000000</span>,),<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.long)\ndevice <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda<span class=\"pl-pds\">\"</span></span>)\ny<span class=\"pl-k\">=</span>x.to(device)\nstart <span class=\"pl-k\">=</span> time.time()<span class=\"pl-bu\">;</span>\noutput,inverse <span class=\"pl-k\">=</span> x.unique(<span class=\"pl-v\">sorted</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,<span class=\"pl-v\">return_inverse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nstop <span class=\"pl-k\">=</span> time.time()<span class=\"pl-bu\">;</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cpu:<span class=\"pl-pds\">'</span></span>,stop<span class=\"pl-k\">-</span>start,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x:<span class=\"pl-pds\">'</span></span>,x)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x output:<span class=\"pl-pds\">'</span></span>,output)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x inverse:<span class=\"pl-pds\">'</span></span>,inverse)\n\nstart <span class=\"pl-k\">=</span> time.time()<span class=\"pl-bu\">;</span>\noutput1,inverse1 <span class=\"pl-k\">=</span> y.unique(<span class=\"pl-v\">sorted</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,<span class=\"pl-v\">return_inverse</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\ntorch.cuda.synchronize()<span class=\"pl-bu\">;</span>\nstop <span class=\"pl-k\">=</span> time.time()<span class=\"pl-bu\">;</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>gpu:<span class=\"pl-pds\">'</span></span>,stop<span class=\"pl-k\">-</span>start,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>s<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>y:<span class=\"pl-pds\">'</span></span>,y)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>y output:<span class=\"pl-pds\">'</span></span>,output1)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>y inverse:<span class=\"pl-pds\">'</span></span>,inverse1)</pre></div>", "body_text": "Add cuda support for unique.\nThere is a simple test below for a tensor including 1M  data.\nAnd the performance is faster.\nPerformance\ncpu: 0.05040597915649414 s\nx: tensor([1, 3, 1,  ..., 4, 9, 4])\nx output: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\nx inverse: tensor([0, 2, 0,  ..., 3, 8, 3])\n\ngpu: 0.015192985534667969 s\ny: tensor([1, 3, 1,  ..., 4, 9, 4], device='cuda:0')\ny output: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\ny inverse: tensor([0, 2, 0,  ..., 3, 8, 3], device='cuda:0')\nCode\nimport torch\nimport time\nx=torch.randint(1,10,(1000000,),dtype=torch.long)\ndevice = torch.device(\"cuda\")\ny=x.to(device)\nstart = time.time();\noutput,inverse = x.unique(sorted=True,return_inverse=True)\nstop = time.time();\nprint('cpu:',stop-start,'s')\nprint('x:',x)\nprint('x output:',output)\nprint('x inverse:',inverse)\n\nstart = time.time();\noutput1,inverse1 = y.unique(sorted=True,return_inverse=True)\ntorch.cuda.synchronize();\nstop = time.time();\nprint('gpu:',stop-start,'s')\nprint('y:',y)\nprint('y output:',output1)\nprint('y inverse:',inverse1)", "body": "Add cuda support for unique.\r\n\r\nThere is a simple test below for a tensor including 1M <int> data.\r\nAnd the performance is faster.\r\n\r\n```python\r\nPerformance\r\ncpu: 0.05040597915649414 s\r\nx: tensor([1, 3, 1,  ..., 4, 9, 4])\r\nx output: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\r\nx inverse: tensor([0, 2, 0,  ..., 3, 8, 3])\r\n\r\ngpu: 0.015192985534667969 s\r\ny: tensor([1, 3, 1,  ..., 4, 9, 4], device='cuda:0')\r\ny output: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\r\ny inverse: tensor([0, 2, 0,  ..., 3, 8, 3], device='cuda:0')\r\n```\r\n\r\n```python\r\nCode\r\nimport torch\r\nimport time\r\nx=torch.randint(1,10,(1000000,),dtype=torch.long)\r\ndevice = torch.device(\"cuda\")\r\ny=x.to(device)\r\nstart = time.time();\r\noutput,inverse = x.unique(sorted=True,return_inverse=True)\r\nstop = time.time();\r\nprint('cpu:',stop-start,'s')\r\nprint('x:',x)\r\nprint('x output:',output)\r\nprint('x inverse:',inverse)\r\n\r\nstart = time.time();\r\noutput1,inverse1 = y.unique(sorted=True,return_inverse=True)\r\ntorch.cuda.synchronize();\r\nstop = time.time();\r\nprint('gpu:',stop-start,'s')\r\nprint('y:',y)\r\nprint('y output:',output1)\r\nprint('y inverse:',inverse1)\r\n```"}