{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/289488731", "html_url": "https://github.com/pytorch/pytorch/issues/1113#issuecomment-289488731", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1113", "id": 289488731, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTQ4ODczMQ==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-27T15:26:18Z", "updated_at": "2017-03-27T15:26:18Z", "author_association": "MEMBER", "body_html": "<p>Python's <code>float</code> number type has Double precision, and there's no float32 in python numbers.<br>\nHence, we are doing exactly what we should without losing precision.</p>\n<p>If we detect that the incoming data is a Tensor, we already retain it's correct type in the section: <code>if torch.is_tensor(batch[0]):</code></p>", "body_text": "Python's float number type has Double precision, and there's no float32 in python numbers.\nHence, we are doing exactly what we should without losing precision.\nIf we detect that the incoming data is a Tensor, we already retain it's correct type in the section: if torch.is_tensor(batch[0]):", "body": "Python's `float` number type has Double precision, and there's no float32 in python numbers.\r\nHence, we are doing exactly what we should without losing precision.\r\n\r\nIf we detect that the incoming data is a Tensor, we already retain it's correct type in the section: `if torch.is_tensor(batch[0]):`"}