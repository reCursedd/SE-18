{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386172283", "html_url": "https://github.com/pytorch/pytorch/issues/7087#issuecomment-386172283", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7087", "id": 386172283, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjE3MjI4Mw==", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T01:54:48Z", "updated_at": "2018-05-03T01:54:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4556044\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Stonesjtu\">@Stonesjtu</a> All the CPU operations that rely on OpenMP has a threshold value <code>OMP_THRESHOLD</code>, below the threshold will launch serial calls otherwise parallel calls.<br>\nSomehow the threshold value is not a generic number, it is related to hardware, operation type (add and exp has diverse threshold value), contiguous memory access or not, etc. So typically it is impossible to make it suitable for every hardware for every operation.</p>\n<p>This is the result on my CPU, the latest Xeon <a href=\"https://ark.intel.com/products/120496/Intel-Xeon-Platinum-8180-Processor-38_5M-Cache-2_50-GHz\" rel=\"nofollow\">skylake-8180</a>, you can access this type of CPU on AWS.<br>\nThe performance pretty much saturates after OMP_NUM_THREADS=16 which probably means memory bandwidth is already peak.</p>\n<pre><code>[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=2 python test1.py\n0.5540544986724854s\n1.1089115142822266s\n1.6616630554199219s\n2.2161214351654053s\n2.7701406478881836s\n3.3247148990631104s\n3.878696918487549s\n4.433142185211182s\n4.986017227172852s\n5.540700435638428s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=4 python test1.py\n0.29080915451049805s\n0.5815765857696533s\n0.8714227676391602s\n1.1636464595794678s\n1.454512596130371s\n1.7470240592956543s\n2.0370874404907227s\n2.329000949859619s\n2.61970591545105s\n2.912081241607666s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=8 python test1.py\n0.16283059120178223s\n0.32903051376342773s\n0.49161839485168457s\n0.6557948589324951s\n0.819077730178833s\n0.9841725826263428s\n1.1471338272094727s\n1.3126704692840576s\n1.4737608432769775s\n1.640467882156372s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=16 python test1.py\n0.13701176643371582s\n0.2756643295288086s\n0.41257262229919434s\n0.5519325733184814s\n0.6888313293457031s\n0.8278582096099854s\n0.9643378257751465s\n1.1032180786132812s\n1.2402722835540771s\n1.379800796508789s\n</code></pre>", "body_text": "@Stonesjtu All the CPU operations that rely on OpenMP has a threshold value OMP_THRESHOLD, below the threshold will launch serial calls otherwise parallel calls.\nSomehow the threshold value is not a generic number, it is related to hardware, operation type (add and exp has diverse threshold value), contiguous memory access or not, etc. So typically it is impossible to make it suitable for every hardware for every operation.\nThis is the result on my CPU, the latest Xeon skylake-8180, you can access this type of CPU on AWS.\nThe performance pretty much saturates after OMP_NUM_THREADS=16 which probably means memory bandwidth is already peak.\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=2 python test1.py\n0.5540544986724854s\n1.1089115142822266s\n1.6616630554199219s\n2.2161214351654053s\n2.7701406478881836s\n3.3247148990631104s\n3.878696918487549s\n4.433142185211182s\n4.986017227172852s\n5.540700435638428s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=4 python test1.py\n0.29080915451049805s\n0.5815765857696533s\n0.8714227676391602s\n1.1636464595794678s\n1.454512596130371s\n1.7470240592956543s\n2.0370874404907227s\n2.329000949859619s\n2.61970591545105s\n2.912081241607666s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=8 python test1.py\n0.16283059120178223s\n0.32903051376342773s\n0.49161839485168457s\n0.6557948589324951s\n0.819077730178833s\n0.9841725826263428s\n1.1471338272094727s\n1.3126704692840576s\n1.4737608432769775s\n1.640467882156372s\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=16 python test1.py\n0.13701176643371582s\n0.2756643295288086s\n0.41257262229919434s\n0.5519325733184814s\n0.6888313293457031s\n0.8278582096099854s\n0.9643378257751465s\n1.1032180786132812s\n1.2402722835540771s\n1.379800796508789s", "body": "@Stonesjtu All the CPU operations that rely on OpenMP has a threshold value `OMP_THRESHOLD`, below the threshold will launch serial calls otherwise parallel calls.\r\nSomehow the threshold value is not a generic number, it is related to hardware, operation type (add and exp has diverse threshold value), contiguous memory access or not, etc. So typically it is impossible to make it suitable for every hardware for every operation.\r\n\r\nThis is the result on my CPU, the latest Xeon [skylake-8180](https://ark.intel.com/products/120496/Intel-Xeon-Platinum-8180-Processor-38_5M-Cache-2_50-GHz), you can access this type of CPU on AWS.\r\nThe performance pretty much saturates after OMP_NUM_THREADS=16 which probably means memory bandwidth is already peak.\r\n```\r\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=2 python test1.py\r\n0.5540544986724854s\r\n1.1089115142822266s\r\n1.6616630554199219s\r\n2.2161214351654053s\r\n2.7701406478881836s\r\n3.3247148990631104s\r\n3.878696918487549s\r\n4.433142185211182s\r\n4.986017227172852s\r\n5.540700435638428s\r\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=4 python test1.py\r\n0.29080915451049805s\r\n0.5815765857696533s\r\n0.8714227676391602s\r\n1.1636464595794678s\r\n1.454512596130371s\r\n1.7470240592956543s\r\n2.0370874404907227s\r\n2.329000949859619s\r\n2.61970591545105s\r\n2.912081241607666s\r\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=8 python test1.py\r\n0.16283059120178223s\r\n0.32903051376342773s\r\n0.49161839485168457s\r\n0.6557948589324951s\r\n0.819077730178833s\r\n0.9841725826263428s\r\n1.1471338272094727s\r\n1.3126704692840576s\r\n1.4737608432769775s\r\n1.640467882156372s\r\n[mingfeim@mlt-skx062 bench]$ OMP_NUM_THREADS=16 python test1.py\r\n0.13701176643371582s\r\n0.2756643295288086s\r\n0.41257262229919434s\r\n0.5519325733184814s\r\n0.6888313293457031s\r\n0.8278582096099854s\r\n0.9643378257751465s\r\n1.1032180786132812s\r\n1.2402722835540771s\r\n1.379800796508789s\r\n```"}