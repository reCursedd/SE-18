{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12827", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12827/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12827/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12827/events", "html_url": "https://github.com/pytorch/pytorch/issues/12827", "id": 371643303, "node_id": "MDU6SXNzdWUzNzE2NDMzMDM=", "number": 12827, "title": "Address performance regression from \"Get rid of most usages of Type.tensor\".", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-18T17:56:38Z", "updated_at": "2018-10-18T17:56:38Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> found that this commit (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/117885128073c9c2b32f4b33c6c79df3895b7071/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/117885128073c9c2b32f4b33c6c79df3895b7071\"><tt>1178851</tt></a>) is a major culprit in the ~6% perf regression we've seen on here: <a href=\"https://apaszke.github.io/pytorch-perf-hud/\" rel=\"nofollow\">https://apaszke.github.io/pytorch-perf-hud/</a>.</p>\n<p>The above commit makes a bunch of changes, most of which are probably not relevant.  In particular the commit message mentions:</p>\n<pre><code>1) Most usages are replaced by at::empty.\n2) native_tensor has its namespace function removed\n3) Type.tensor(sizes, strides) becomes at::empty_strided(sizes, strides).\n</code></pre>\n<ol start=\"2\">\n<li>\n<p>is certainly not relevant.</p>\n</li>\n<li>\n<p>or 3) may be, it's likely that the dispatch is slower for <code>at::empty(...)</code> or <code>at::empty_strided(...)</code> than <code>Type.tensor(...)</code>.  This most of the time shouldn't matter, but it's likely one or more places we changed are along some hot path.  Luckily the changes are pretty much self contained, so it should be possible to find the culprit by just reverting the changes basically file-by-file.</p>\n</li>\n</ol>\n<p>Once the culprit is addressed, we should figure out why the specific function call is slower than Type.tensor.  Is this all TensorOptions overhead?  e.g. before:<br>\n<code>Type.tensor(size)</code> would be dispatched directly, whereas now the pattern is:<br>\n<code>at::empty(size, Type.options())</code> -&gt; native::empty(size, Type.options())<code> -&gt; Type.tensor(size)</code></p>\n<p>Is creating options slow?  Is passing options slow?  Is looking up Type from options slow?</p>\n<p>Note also that this has further changed in master.  In particular:</p>\n<ol>\n<li>TensorOptions is now smaller, so should pass faster (I think this was changed after this commit)</li>\n<li>at::empty now uses backend-specific dispatch instead of dispatching back through Type.</li>\n</ol>", "body_text": "@apaszke found that this commit (1178851) is a major culprit in the ~6% perf regression we've seen on here: https://apaszke.github.io/pytorch-perf-hud/.\nThe above commit makes a bunch of changes, most of which are probably not relevant.  In particular the commit message mentions:\n1) Most usages are replaced by at::empty.\n2) native_tensor has its namespace function removed\n3) Type.tensor(sizes, strides) becomes at::empty_strided(sizes, strides).\n\n\n\nis certainly not relevant.\n\n\nor 3) may be, it's likely that the dispatch is slower for at::empty(...) or at::empty_strided(...) than Type.tensor(...).  This most of the time shouldn't matter, but it's likely one or more places we changed are along some hot path.  Luckily the changes are pretty much self contained, so it should be possible to find the culprit by just reverting the changes basically file-by-file.\n\n\nOnce the culprit is addressed, we should figure out why the specific function call is slower than Type.tensor.  Is this all TensorOptions overhead?  e.g. before:\nType.tensor(size) would be dispatched directly, whereas now the pattern is:\nat::empty(size, Type.options()) -> native::empty(size, Type.options()) -> Type.tensor(size)\nIs creating options slow?  Is passing options slow?  Is looking up Type from options slow?\nNote also that this has further changed in master.  In particular:\n\nTensorOptions is now smaller, so should pass faster (I think this was changed after this commit)\nat::empty now uses backend-specific dispatch instead of dispatching back through Type.", "body": "@apaszke found that this commit (https://github.com/pytorch/pytorch/commit/117885128073c9c2b32f4b33c6c79df3895b7071) is a major culprit in the ~6% perf regression we've seen on here: https://apaszke.github.io/pytorch-perf-hud/.\r\n\r\nThe above commit makes a bunch of changes, most of which are probably not relevant.  In particular the commit message mentions:\r\n```\r\n1) Most usages are replaced by at::empty.\r\n2) native_tensor has its namespace function removed\r\n3) Type.tensor(sizes, strides) becomes at::empty_strided(sizes, strides).\r\n```\r\n\r\n2) is certainly not relevant.\r\n\r\n1) or 3) may be, it's likely that the dispatch is slower for `at::empty(...)` or `at::empty_strided(...)` than `Type.tensor(...)`.  This most of the time shouldn't matter, but it's likely one or more places we changed are along some hot path.  Luckily the changes are pretty much self contained, so it should be possible to find the culprit by just reverting the changes basically file-by-file.\r\n\r\nOnce the culprit is addressed, we should figure out why the specific function call is slower than Type.tensor.  Is this all TensorOptions overhead?  e.g. before:\r\n`Type.tensor(size)` would be dispatched directly, whereas now the pattern is:\r\n`at::empty(size, Type.options())` -> native::empty(size, Type.options())` -> Type.tensor(size)`\r\n\r\nIs creating options slow?  Is passing options slow?  Is looking up Type from options slow?\r\n\r\nNote also that this has further changed in master.  In particular:\r\n1) TensorOptions is now smaller, so should pass faster (I think this was changed after this commit)\r\n2) at::empty now uses backend-specific dispatch instead of dispatching back through Type."}