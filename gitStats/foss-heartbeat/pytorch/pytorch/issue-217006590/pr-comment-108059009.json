{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/108059009", "pull_request_review_id": 29068595, "id": 108059009, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwODA1OTAwOQ==", "diff_hunk": "@@ -59,5 +59,66 @@ def __repr__(self):\n             + str(self.out_features) + ')'\n \n \n-# TODO: Bilinear\n+class BiLinear(Module):\n+    r\"\"\"Applies a bilinear transformation to the incoming data: :math:`\\forall k: y_k = x_1 A_k x_2 + b`\n+\n+    Args:\n+        in_features_1: size of each input sample of the first input\n+        in_features_2: size of each input sample of the second input\n+        out_features: size of each output sample\n+        bias: If set to False, the layer will not learn an additive bias. Default: True\n+\n+    Shape:\n+        - Input: :math:`[(N, in\\_features\\_1), (N, in\\_features\\_2)`\n+        - Output: :math:`(N, out\\_features)`\n+\n+    Attributes:\n+        weight: the learnable weights of the module of shape (out_features x in_features_1 x in_features_2)\n+        bias:   the learnable bias of the module of shape (out_features)\n+\n+    Examples::\n+\n+        >>> m = nn.BiLinear(10, 20, 30)\n+        >>> input_1 = autograd.Variable(torch.randn(128, 20))\n+        >>> input_2 = autograd.Variable(torch.randn(128, 30))\n+        >>> output = m([input_1, input_2])\n+        >>> print(output.size())\n+    \"\"\"\n+\n+    def __init__(self, in_features_1, in_features_2, out_features, bias=True):\n+        super(BiLinear, self).__init__()\n+        self.in_features_1 = in_features_1\n+        self.in_features_2 = in_features_2\n+        self.out_features = out_features\n+        self.weight = Parameter(torch.Tensor(out_features, in_features_1, in_features_2))\n+        if bias:\n+            self.bias = Parameter(torch.Tensor(out_features))\n+        else:\n+            self.register_parameter('bias', None)\n+        self.reset_parameters()\n+\n+    def reset_parameters(self):\n+        stdv = 1. / math.sqrt(self.weight.size(1))", "path": "torch/nn/modules/linear.py", "position": 44, "original_position": 44, "commit_id": "d0e59aa27e32ff7b3f07f8888fbfc32eacad4072", "original_commit_id": "d0e59aa27e32ff7b3f07f8888fbfc32eacad4072", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Not sure if that's the correct initialization. It seems that this is what Lua Torch uses, but I don't think it should ignore `in_features_2`. @soumith any ideas?", "created_at": "2017-03-26T12:15:05Z", "updated_at": "2018-11-23T15:32:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/1104#discussion_r108059009", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1104", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/108059009"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1104#discussion_r108059009"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1104"}}, "body_html": "<p>Not sure if that's the correct initialization. It seems that this is what Lua Torch uses, but I don't think it should ignore <code>in_features_2</code>. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> any ideas?</p>", "body_text": "Not sure if that's the correct initialization. It seems that this is what Lua Torch uses, but I don't think it should ignore in_features_2. @soumith any ideas?"}