{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4740", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4740/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4740/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4740/events", "html_url": "https://github.com/pytorch/pytorch/pull/4740", "id": 289906897, "node_id": "MDExOlB1bGxSZXF1ZXN0MTYzOTE3OTYz", "number": 4740, "title": "add half cauchy distribution", "user": {"login": "jpchen", "id": 1869641, "node_id": "MDQ6VXNlcjE4Njk2NDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1869641?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpchen", "html_url": "https://github.com/jpchen", "followers_url": "https://api.github.com/users/jpchen/followers", "following_url": "https://api.github.com/users/jpchen/following{/other_user}", "gists_url": "https://api.github.com/users/jpchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpchen/subscriptions", "organizations_url": "https://api.github.com/users/jpchen/orgs", "repos_url": "https://api.github.com/users/jpchen/repos", "events_url": "https://api.github.com/users/jpchen/events{/privacy}", "received_events_url": "https://api.github.com/users/jpchen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-19T09:09:35Z", "updated_at": "2018-01-19T09:14:58Z", "closed_at": "2018-01-19T09:10:45Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4740", "html_url": "https://github.com/pytorch/pytorch/pull/4740", "diff_url": "https://github.com/pytorch/pytorch/pull/4740.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4740.patch"}, "body_html": "<p>not finalized. i used some of the previous distribution PRs as a reference</p>\n<p>Implementation:<br>\ni reused the cauchy sampler and enforced positivity.  the <code>abs()</code> is added to the computation graph, since the whole sampler is differentiable, but im not sure if this is correct.  if the transformation happens in place (thereby omitting it from the graph), then the scale gradients will match the signs of the underlying cauchy sample, otherwise the location gradients will.</p>\n<p>Tests:<br>\ntests are reused from <code>Cauchy</code> sans gradient tests</p>", "body_text": "not finalized. i used some of the previous distribution PRs as a reference\nImplementation:\ni reused the cauchy sampler and enforced positivity.  the abs() is added to the computation graph, since the whole sampler is differentiable, but im not sure if this is correct.  if the transformation happens in place (thereby omitting it from the graph), then the scale gradients will match the signs of the underlying cauchy sample, otherwise the location gradients will.\nTests:\ntests are reused from Cauchy sans gradient tests", "body": "not finalized. i used some of the previous distribution PRs as a reference\r\n\r\nImplementation:\r\ni reused the cauchy sampler and enforced positivity.  the `abs()` is added to the computation graph, since the whole sampler is differentiable, but im not sure if this is correct.  if the transformation happens in place (thereby omitting it from the graph), then the scale gradients will match the signs of the underlying cauchy sample, otherwise the location gradients will.\r\n\r\nTests:\r\ntests are reused from `Cauchy` sans gradient tests "}