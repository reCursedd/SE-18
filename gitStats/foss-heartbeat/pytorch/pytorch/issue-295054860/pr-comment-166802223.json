{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166802223", "pull_request_review_id": 94923239, "id": 166802223, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjgwMjIyMw==", "diff_hunk": "@@ -319,43 +319,44 @@\n \n #define TH_TENSOR_APPLY_REDUCTION_OMP(TYPE, TENSOR, OPERATION, CODE) \\\n {\\\n-  TYPE *rp = TENSOR->storage->data+TENSOR->storageOffset;                   \\\n   int TENSOR##Contg = THTensor_(isContiguous)(TENSOR);                      \\\n   ptrdiff_t TENSOR##Size = THTensor_(nElement)(TENSOR);                     \\\n-  ptrdiff_t iter = 0;                                                         \\\n   if(TENSOR##Contg){                                                         \\\n-    TYPE *TENSOR##_data = NULL;         \\\n-    PRAGMA( omp parallel for if (TENSOR##Size > TH_OMP_OVERHEAD_THRESHOLD_OMP) private(TENSOR##_data,  iter) reduction(OPERATION) ) \\\n+    ptrdiff_t iter = 0;                                                         \\\n+    TYPE *rp = TENSOR->storage->data+TENSOR->storageOffset;                   \\\n+    PRAGMA( omp parallel for if (TENSOR##Size > TH_OMP_OVERHEAD_THRESHOLD_OMP) firstprivate(rp) reduction(OPERATION) ) \\\n     for (iter = 0; iter < TENSOR##Size; iter++) { \\\n-      TENSOR##_data = rp+iter;                    \\\n+      TYPE *TENSOR##_data = rp+iter;                    \\\n       CODE                                         \\\n     }                                              \\\n   } else {                                         \\\n-    TH_UNUSED int TH_TENSOR_APPLY_hasFinished = 0;           \\\n+    int TH_TENSOR_APPLY_hasFinished = 0;           \\\n     int64_t TH_TENSOR_dim_index = 0;               \\\n     __TH_TENSOR_APPLYX_PREAMBLE(TYPE, TENSOR, -1, 1);\\\n-    PRAGMA(omp parallel if (TENSOR##Size > TH_OMP_OVERHEAD_THRESHOLD_OMP) firstprivate(TENSOR##_sizes, TENSOR##_strides, TENSOR##_dim, TENSOR##_stride, TENSOR##_size, TENSOR##_i) reduction(OPERATION))\\\n-    {\\\n-      size_t num_threads = omp_get_num_threads();\\\n-      size_t tid = omp_get_thread_num();\\\n-      size_t line_seg_length_avg = TENSOR##Size/num_threads;                                                     \\\n-      ptrdiff_t line_index_start = tid * line_seg_length_avg;                                            \\\n-      ptrdiff_t line_seg_length = (tid == num_threads - 1)? (TENSOR##Size - line_index_start):line_seg_length_avg;  \\\n-      __TH_TENSOR_APPLYX_CAL_MEMORY_OFFSET(TENSOR);\\\n-      TYPE *TENSOR##_data = rp + TENSOR##_memory_offset;\\\n-      ptrdiff_t count = 0;\\\n-      ptrdiff_t TENSOR##_start = TENSOR##_counter_tmp[TENSOR##_dim - 1];\\\n-      while(count < line_seg_length){\\\n-        for(TENSOR##_i=TENSOR##_start; (count < line_seg_length)&&(TENSOR##_i < TENSOR##_size); ++TENSOR##_i, ++count){\\\n-          CODE\\\n-          TENSOR##_data += TENSOR##_stride;\\\n-        }\\\n-        if(count < line_seg_length){\\\n-          __TH_TENSOR_APPLYX_UPDATE_COUNTERS_OMP(TENSOR);\\\n+    if (0 == TH_TENSOR_APPLY_hasFinished) {          \\", "path": "aten/src/TH/THTensorApply.h", "position": 51, "original_position": 51, "commit_id": "c180e2106ad8c12329a5017010cf952a7a18483e", "original_commit_id": "c180e2106ad8c12329a5017010cf952a7a18483e", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "body": "It just follows the [previous usage](https://github.com/intel/pytorch/blob/c180e2106ad8c12329a5017010cf952a7a18483e/aten/src/TH/THTensorApply.h#L208). Actually, it's redundant check of size. If the size is zero,just skip the rest operation. It just follows the existed rules and remove the compilation warnings.\r\nI am sorry to introduce the side effect when I committed the #2764.", "created_at": "2018-02-08T00:38:00Z", "updated_at": "2018-11-23T15:39:21Z", "html_url": "https://github.com/pytorch/pytorch/pull/5104#discussion_r166802223", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5104", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166802223"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5104#discussion_r166802223"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5104"}}, "body_html": "<p>It just follows the <a href=\"https://github.com/intel/pytorch/blob/c180e2106ad8c12329a5017010cf952a7a18483e/aten/src/TH/THTensorApply.h#L208\">previous usage</a>. Actually, it's redundant check of size. If the size is zero,just skip the rest operation. It just follows the existed rules and remove the compilation warnings.<br>\nI am sorry to introduce the side effect when I committed the <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"258349266\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2764\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2764/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2764\">#2764</a>.</p>", "body_text": "It just follows the previous usage. Actually, it's redundant check of size. If the size is zero,just skip the rest operation. It just follows the existed rules and remove the compilation warnings.\nI am sorry to introduce the side effect when I committed the #2764.", "in_reply_to_id": 166718153}