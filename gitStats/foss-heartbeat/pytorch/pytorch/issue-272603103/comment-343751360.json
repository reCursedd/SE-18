{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/343751360", "html_url": "https://github.com/pytorch/pytorch/issues/3600#issuecomment-343751360", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3600", "id": 343751360, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Mzc1MTM2MA==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-12T17:03:47Z", "updated_at": "2017-11-12T17:03:47Z", "author_association": "MEMBER", "body_html": "<p>I'm not sure having a fallback of \"<code>gpu</code> doing nothing\" is a good thing. I think it's better to say that it's unsupported than do things behind your back. Mixing CPU and GPU code makes writing device-agnostic code harder indeed, but that might be the price to pay to have such flexibility.</p>\n<p>Another possibility is to perform automatic device conversion, with a default being specified by the user (so <code>op(cpu_tensor, gpu_tensor)</code> can be either run as moving everything to the cpu or to the gpu). The drawback is that it could become very easy to write non-performant code, as the CPU-GPU copy is expensive.</p>\n<p>But that's just my 2 cents, I'll let the others comment as well. :)</p>", "body_text": "I'm not sure having a fallback of \"gpu doing nothing\" is a good thing. I think it's better to say that it's unsupported than do things behind your back. Mixing CPU and GPU code makes writing device-agnostic code harder indeed, but that might be the price to pay to have such flexibility.\nAnother possibility is to perform automatic device conversion, with a default being specified by the user (so op(cpu_tensor, gpu_tensor) can be either run as moving everything to the cpu or to the gpu). The drawback is that it could become very easy to write non-performant code, as the CPU-GPU copy is expensive.\nBut that's just my 2 cents, I'll let the others comment as well. :)", "body": "I'm not sure having a fallback of \"`gpu` doing nothing\" is a good thing. I think it's better to say that it's unsupported than do things behind your back. Mixing CPU and GPU code makes writing device-agnostic code harder indeed, but that might be the price to pay to have such flexibility.\r\n\r\nAnother possibility is to perform automatic device conversion, with a default being specified by the user (so `op(cpu_tensor, gpu_tensor)` can be either run as moving everything to the cpu or to the gpu). The drawback is that it could become very easy to write non-performant code, as the CPU-GPU copy is expensive.\r\n\r\nBut that's just my 2 cents, I'll let the others comment as well. :)"}