{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/225880386", "pull_request_review_id": 165573977, "id": 225880386, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNTg4MDM4Ng==", "diff_hunk": "@@ -0,0 +1,301 @@\n+#pragma once\n+\n+#include <torch/data/data_loader_options.h>\n+#include <torch/data/detail/data_shuttle.h>\n+#include <torch/data/detail/sequencers.h>\n+#include <torch/data/iterator.h>\n+#include <torch/data/samplers/random.h>\n+#include <torch/data/worker_exception.h>\n+\n+#include <torch/csrc/utils/memory.h>\n+#include <torch/csrc/utils/variadic.h>\n+\n+#include <ATen/Error.h>\n+#include <ATen/optional.h>\n+\n+#include <cstddef>\n+#include <exception>\n+#include <memory>\n+#include <thread>\n+#include <type_traits>\n+#include <utility>\n+#include <vector>\n+\n+namespace torch {\n+namespace data {\n+template <typename Dataset, typename Sampler>\n+class DataLoader {\n+ public:\n+  using Batch = typename Dataset::BatchType;\n+  using IndexBatch = std::vector<size_t>;\n+\n+  /// Constructs a new `DataLoader` from a `dataset` to sample from, `options`\n+  /// to configure the `DataLoader` with, and a `sampler` that specifies the\n+  /// sampling strategy.\n+  DataLoader(Dataset dataset, DataLoaderOptions options, Sampler sampler)\n+      : options_(std::move(options)),\n+        dataset_size_(dataset.size()),\n+        sampler_(std::move(sampler)),\n+        sequencer_(new_sequencer()) {\n+    // clang-format off\n+    AT_CHECK(\n+        options_.batch_size <= dataset.size(),\n+        \"Batch size (was \", options_.batch_size, \") \",\n+        \"must not be larger than the dataset size (was \",\n+        dataset.size(), \")\");\n+    // clang-format on\n+\n+    if (options_.workers > 0) {\n+      for (size_t w = 0; w < options_.workers; ++w) {\n+        // Here we copy the dataset into the worker thread closure. Each worker\n+        // has its own copy of the dataset. This means the dataset must be\n+        // trivially copiable, or else we don't expect more than one worker to\n+        // be in use.\n+        workers_.emplace_back(\n+            [this, dataset] { this->worker_thread(std::move(dataset)); });\n+      }\n+    } else {\n+      main_thread_dataset_ = torch::make_unique<Dataset>(std::move(dataset));\n+    }\n+  }\n+\n+  ~DataLoader() {\n+    join();\n+  }\n+\n+  /// Returns an iterator into the `DataLoader`. The lifetime of the iterator is\n+  /// bound to the `DataLoader`. In C++ standards language, the category of the\n+  /// iterator is `OutputIterator`. See\n+  /// https://en.cppreference.com/w/cpp/named_req/OutputIterator for what this\n+  /// means. In short: you may increment the iterator and dereference it, but\n+  /// cannot go back, or step forward more than one position at a time. When the\n+  /// `DataLoader` is exhausted, it will compare equal with the special\n+  /// \"sentinel\" iterator returned by `DataLoader::end()`. Most of the time, you\n+  /// should only use range-for loops to loop over the `DataLoader`, but\n+  /// standard algorithms like `std::copy(dataloader.begin(), dataloader.end(),\n+  /// output_iterator)`  are supported too.\n+  Iterator<Batch> begin() {\n+    reset();", "path": "torch/csrc/api/include/torch/data/dataloader.h", "position": 82, "original_position": 78, "commit_id": "2fabdad63c0bc48b26af6bf8d2e74513b09c97da", "original_commit_id": "0cf5d795bd8b96ac542039a8f612df1ce84602f2", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "I've added a check. It's true there's still a difference between iterators doing all the work like in Python.", "created_at": "2018-10-17T11:11:55Z", "updated_at": "2018-11-23T15:53:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/11918#discussion_r225880386", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11918", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/225880386"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11918#discussion_r225880386"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11918"}}, "body_html": "<p>I've added a check. It's true there's still a difference between iterators doing all the work like in Python.</p>", "body_text": "I've added a check. It's true there's still a difference between iterators doing all the work like in Python.", "in_reply_to_id": 223740165}