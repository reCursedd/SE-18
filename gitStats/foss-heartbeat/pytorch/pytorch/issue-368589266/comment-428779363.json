{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428779363", "html_url": "https://github.com/pytorch/pytorch/issues/12527#issuecomment-428779363", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12527", "id": 428779363, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODc3OTM2Mw==", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-11T00:44:07Z", "updated_at": "2018-10-11T00:47:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Two notes from your experimental setup:</p>\n<p>(1), if the two machines share the same shared file system, please use <code>file://</code> init method while we will be fixing the <code>tcp://</code> init method.</p>\n<p>(2), if you are using multi-processing distributed training and each GPU is governed by a process (I assume you have more than 1 GPU per node),  you are recommended to use NCCL backend for this purpose, since it is optimized for such multi-process distributed scenario with CUDA IPC and can be a lot faster.</p>", "body_text": "Two notes from your experimental setup:\n(1), if the two machines share the same shared file system, please use file:// init method while we will be fixing the tcp:// init method.\n(2), if you are using multi-processing distributed training and each GPU is governed by a process (I assume you have more than 1 GPU per node),  you are recommended to use NCCL backend for this purpose, since it is optimized for such multi-process distributed scenario with CUDA IPC and can be a lot faster.", "body": "Two notes from your experimental setup:\r\n\r\n(1), if the two machines share the same shared file system, please use `file://` init method while we will be fixing the `tcp://` init method.\r\n\r\n(2), if you are using multi-processing distributed training and each GPU is governed by a process (I assume you have more than 1 GPU per node),  you are recommended to use NCCL backend for this purpose, since it is optimized for such multi-process distributed scenario with CUDA IPC and can be a lot faster."}