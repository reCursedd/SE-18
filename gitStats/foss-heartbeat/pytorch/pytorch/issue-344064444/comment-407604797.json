{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407604797", "html_url": "https://github.com/pytorch/pytorch/issues/9761#issuecomment-407604797", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9761", "id": 407604797, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzYwNDc5Nw==", "user": {"login": "XiongChengxin", "id": 32812590, "node_id": "MDQ6VXNlcjMyODEyNTkw", "avatar_url": "https://avatars0.githubusercontent.com/u/32812590?v=4", "gravatar_id": "", "url": "https://api.github.com/users/XiongChengxin", "html_url": "https://github.com/XiongChengxin", "followers_url": "https://api.github.com/users/XiongChengxin/followers", "following_url": "https://api.github.com/users/XiongChengxin/following{/other_user}", "gists_url": "https://api.github.com/users/XiongChengxin/gists{/gist_id}", "starred_url": "https://api.github.com/users/XiongChengxin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/XiongChengxin/subscriptions", "organizations_url": "https://api.github.com/users/XiongChengxin/orgs", "repos_url": "https://api.github.com/users/XiongChengxin/repos", "events_url": "https://api.github.com/users/XiongChengxin/events{/privacy}", "received_events_url": "https://api.github.com/users/XiongChengxin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-25T01:37:54Z", "updated_at": "2018-07-25T01:37:54Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4958441\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jerryzh168\">@jerryzh168</a> The whole error message are as follows. At the same time, for 3d conv, pads should have 3 elements, one for temporal dimension, two for spatial dimension.</p>\n<p>Ignoring @/caffe2/caffe2/contrib/nccl:nccl_ops as it is not a valid file.<br>\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops as it is not a valid file.<br>\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops_gpu as it is not a valid file.<br>\nE0724 22:27:31.919901 10520 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.<br>\nE0724 22:27:31.920105 10520 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.<br>\nE0724 22:27:31.920117 10520 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.<br>\nINFO:train_net:Namespace(base_learning_rate=0.0001, batch_size=4, clip_length_of=8, clip_length_rgb=32, crop_size=112, cudnn_workspace_limit_mb=64, db_type='pickle', display_iter=10, do_flow_aggregation=0, epoch_size=100000, file_store_path='.', flow_data_type=0, frame_gap_of=2, gamma=0.1, get_video_id=0, gpus='0,1,2', input_type=0, is_checkpoint=0, model_depth=34, model_name='r2plus1d', num_channels=3, num_decode_threads=4, num_epochs=4, num_gpus=1, num_labels=101, pred_layer_name=None, pretrained_model='/home/xiongcx/R2Plus1D-master/models/r2.5d_d34_l32.pkl', profiling=0, sampling_rate_of=2, sampling_rate_rgb=1, scale_h=128, scale_w=171, step_epoch=2, test_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_testing_lmdb', train_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_training_lmdb', use_cudnn=1, use_dropout=0, use_local_file=0, weight_decay=0.005)<br>\nINFO:model_builder:Validated: r2plus1d with 34 layers<br>\nINFO:model_builder:with input 32x112x112<br>\nINFO:train_net:Running on GPUs: [0, 1, 2]<br>\nINFO:train_net:Using epoch size: 99996<br>\nWARNING:root:[====DEPRECATE WARNING====]: you are creating an object from CNNModelHelper class which will be deprecated soon. Please use ModelHelper object with brew module. For more information, please refer to caffe2.ai and python/brew.py, python/brew_test.py for more information.<br>\nINFO:train_net:train set has 9990 examples<br>\nINFO:data_parallel_model:Parallelizing model for devices: [0, 1, 2]<br>\nINFO:data_parallel_model:Create input and model training operators<br>\nINFO:data_parallel_model:Model for GPU : 0<br>\nINFO:model_helper:outputing rgb data<br>\nINFO:model_builder:creating r2plus1d, depth=34...<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 144<br>\nINFO:video_model:Number of middle filters: 230<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 288<br>\nINFO:video_model:Number of middle filters: 460<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 576<br>\nINFO:video_model:Number of middle filters: 921<br>\nINFO:video_model:Number of middle filters: 1152<br>\nINFO:video_model:Number of middle filters: 1152<br>\nINFO:video_model:Number of middle filters: 1152<br>\nINFO:video_model:Number of middle filters: 1152<br>\nINFO:video_model:Number of middle filters: 1152<br>\nTraceback (most recent call last):<br>\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 528, in <br>\nmain()<br>\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 523, in main<br>\nTrain(args)<br>\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 303, in Train<br>\nnet_type=('prof_dag' if args.profiling == 1 else 'dag'),<br>\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 32, in Parallelize_GPU<br>\nParallelize(*args, **kwargs)<br>\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 209, in Parallelize<br>\nlosses = forward_pass_builder_fun(model_helper_obj, loss_scale)<br>\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 240, in create_model_ops<br>\npred_layer_name=args.pred_layer_name,<br>\nFile \"../lib/models/model_builder.py\", line 134, in build_model<br>\nis_test=is_test,<br>\nFile \"../lib/models/r3d_model.py\", line 101, in create_model<br>\nis_decomposed=(model_name == 'r2plus1d'),<br>\nFile \"../lib/models/r3d_model.py\", line 236, in create_r3d<br>\npads=[1,0,0],<br>\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/brew.py\", line 107, in scope_wrapper<br>\nreturn func(*args, **new_kwargs)<br>\nTypeError: conv_transpose() takes at least 6 arguments (9 given)</p>", "body_text": "@jerryzh168 The whole error message are as follows. At the same time, for 3d conv, pads should have 3 elements, one for temporal dimension, two for spatial dimension.\nIgnoring @/caffe2/caffe2/contrib/nccl:nccl_ops as it is not a valid file.\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops as it is not a valid file.\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops_gpu as it is not a valid file.\nE0724 22:27:31.919901 10520 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0724 22:27:31.920105 10520 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0724 22:27:31.920117 10520 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:train_net:Namespace(base_learning_rate=0.0001, batch_size=4, clip_length_of=8, clip_length_rgb=32, crop_size=112, cudnn_workspace_limit_mb=64, db_type='pickle', display_iter=10, do_flow_aggregation=0, epoch_size=100000, file_store_path='.', flow_data_type=0, frame_gap_of=2, gamma=0.1, get_video_id=0, gpus='0,1,2', input_type=0, is_checkpoint=0, model_depth=34, model_name='r2plus1d', num_channels=3, num_decode_threads=4, num_epochs=4, num_gpus=1, num_labels=101, pred_layer_name=None, pretrained_model='/home/xiongcx/R2Plus1D-master/models/r2.5d_d34_l32.pkl', profiling=0, sampling_rate_of=2, sampling_rate_rgb=1, scale_h=128, scale_w=171, step_epoch=2, test_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_testing_lmdb', train_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_training_lmdb', use_cudnn=1, use_dropout=0, use_local_file=0, weight_decay=0.005)\nINFO:model_builder:Validated: r2plus1d with 34 layers\nINFO:model_builder:with input 32x112x112\nINFO:train_net:Running on GPUs: [0, 1, 2]\nINFO:train_net:Using epoch size: 99996\nWARNING:root:[====DEPRECATE WARNING====]: you are creating an object from CNNModelHelper class which will be deprecated soon. Please use ModelHelper object with brew module. For more information, please refer to caffe2.ai and python/brew.py, python/brew_test.py for more information.\nINFO:train_net:train set has 9990 examples\nINFO:data_parallel_model:Parallelizing model for devices: [0, 1, 2]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:model_helper:outputing rgb data\nINFO:model_builder:creating r2plus1d, depth=34...\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 144\nINFO:video_model:Number of middle filters: 230\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 288\nINFO:video_model:Number of middle filters: 460\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 576\nINFO:video_model:Number of middle filters: 921\nINFO:video_model:Number of middle filters: 1152\nINFO:video_model:Number of middle filters: 1152\nINFO:video_model:Number of middle filters: 1152\nINFO:video_model:Number of middle filters: 1152\nINFO:video_model:Number of middle filters: 1152\nTraceback (most recent call last):\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 528, in \nmain()\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 523, in main\nTrain(args)\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 303, in Train\nnet_type=('prof_dag' if args.profiling == 1 else 'dag'),\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 32, in Parallelize_GPU\nParallelize(*args, **kwargs)\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 209, in Parallelize\nlosses = forward_pass_builder_fun(model_helper_obj, loss_scale)\nFile \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 240, in create_model_ops\npred_layer_name=args.pred_layer_name,\nFile \"../lib/models/model_builder.py\", line 134, in build_model\nis_test=is_test,\nFile \"../lib/models/r3d_model.py\", line 101, in create_model\nis_decomposed=(model_name == 'r2plus1d'),\nFile \"../lib/models/r3d_model.py\", line 236, in create_r3d\npads=[1,0,0],\nFile \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/brew.py\", line 107, in scope_wrapper\nreturn func(*args, **new_kwargs)\nTypeError: conv_transpose() takes at least 6 arguments (9 given)", "body": "@jerryzh168 The whole error message are as follows. At the same time, for 3d conv, pads should have 3 elements, one for temporal dimension, two for spatial dimension. \r\n\r\nIgnoring @/caffe2/caffe2/contrib/nccl:nccl_ops as it is not a valid file.\r\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops as it is not a valid file.\r\nIgnoring @/caffe2/caffe2/contrib/gloo:gloo_ops_gpu as it is not a valid file.\r\nE0724 22:27:31.919901 10520 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0724 22:27:31.920105 10520 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0724 22:27:31.920117 10520 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nINFO:train_net:Namespace(base_learning_rate=0.0001, batch_size=4, clip_length_of=8, clip_length_rgb=32, crop_size=112, cudnn_workspace_limit_mb=64, db_type='pickle', display_iter=10, do_flow_aggregation=0, epoch_size=100000, file_store_path='.', flow_data_type=0, frame_gap_of=2, gamma=0.1, get_video_id=0, gpus='0,1,2', input_type=0, is_checkpoint=0, model_depth=34, model_name='r2plus1d', num_channels=3, num_decode_threads=4, num_epochs=4, num_gpus=1, num_labels=101, pred_layer_name=None, pretrained_model='/home/xiongcx/R2Plus1D-master/models/r2.5d_d34_l32.pkl', profiling=0, sampling_rate_of=2, sampling_rate_rgb=1, scale_h=128, scale_w=171, step_epoch=2, test_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_testing_lmdb', train_data='/home/xiongcx/R2Plus1D-master/lmdb/TH14_training_lmdb', use_cudnn=1, use_dropout=0, use_local_file=0, weight_decay=0.005)\r\nINFO:model_builder:Validated: r2plus1d with 34 layers\r\nINFO:model_builder:with input 32x112x112\r\nINFO:train_net:Running on GPUs: [0, 1, 2]\r\nINFO:train_net:Using epoch size: 99996\r\nWARNING:root:[====DEPRECATE WARNING====]: you are creating an object from CNNModelHelper class which will be deprecated soon. Please use ModelHelper object with brew module. For more information, please refer to caffe2.ai and python/brew.py, python/brew_test.py for more information.\r\nINFO:train_net:train set has 9990 examples\r\nINFO:data_parallel_model:Parallelizing model for devices: [0, 1, 2]\r\nINFO:data_parallel_model:Create input and model training operators\r\nINFO:data_parallel_model:Model for GPU : 0\r\nINFO:model_helper:outputing rgb data\r\nINFO:model_builder:creating r2plus1d, depth=34...\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 144\r\nINFO:video_model:Number of middle filters: 230\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 288\r\nINFO:video_model:Number of middle filters: 460\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 576\r\nINFO:video_model:Number of middle filters: 921\r\nINFO:video_model:Number of middle filters: 1152\r\nINFO:video_model:Number of middle filters: 1152\r\nINFO:video_model:Number of middle filters: 1152\r\nINFO:video_model:Number of middle filters: 1152\r\nINFO:video_model:Number of middle filters: 1152\r\nTraceback (most recent call last):\r\n  File \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 528, in <module>\r\n    main()\r\n  File \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 523, in main\r\n    Train(args)\r\n  File \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 303, in Train\r\n    net_type=('prof_dag' if args.profiling == 1 else 'dag'),\r\n  File \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 32, in Parallelize_GPU\r\n    Parallelize(*args, **kwargs)\r\n  File \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/data_parallel_model.py\", line 209, in Parallelize\r\n    losses = forward_pass_builder_fun(model_helper_obj, loss_scale)\r\n  File \"/home/xiongcx/R2Plus1D-master/tools/train_net.py\", line 240, in create_model_ops\r\n    pred_layer_name=args.pred_layer_name,\r\n  File \"../lib/models/model_builder.py\", line 134, in build_model\r\n    is_test=is_test,\r\n  File \"../lib/models/r3d_model.py\", line 101, in create_model\r\n    is_decomposed=(model_name == 'r2plus1d'),\r\n  File \"../lib/models/r3d_model.py\", line 236, in create_r3d\r\n    pads=[1,0,0],\r\n  File \"/home/xiongcx/files/duhaijun/pytorch/build/caffe2/python/brew.py\", line 107, in scope_wrapper\r\n    return func(*args, **new_kwargs)\r\nTypeError: conv_transpose() takes at least 6 arguments (9 given)"}