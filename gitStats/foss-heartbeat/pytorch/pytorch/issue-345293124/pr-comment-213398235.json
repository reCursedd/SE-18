{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213398235", "pull_request_review_id": 150226438, "id": 213398235, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMzM5ODIzNQ==", "diff_hunk": "@@ -1,57 +1,127 @@\n #include \"ATen/cuda/CUDAStream.h\"\n #include \"ATen/cuda/CUDAContext.h\"\n #include \"ATen/cuda/Exceptions.h\"\n+#include \"ATen/DeviceGuard.h\"\n #include \"ATen/Error.h\"\n \n #include <mutex>\n #include <atomic>\n+#include <cstdint>\n+#include <deque>\n+#include <vector>\n \n // Internal implementation is entirely hidden\n+// Note: CUDAStreamInternals doubles for a THCStream\n struct CUDAStreamInternals {\n-  bool is_destructible;\n-  std::atomic<int> refcount;\n-  int64_t device; // Note: cudaGetDevice works with int32_t, not int64_t\n-  cudaStream_t stream;\n+  CUDAStreamInternals() = default;\n+\n+  ~CUDAStreamInternals() {\n+    if (stream) cudaStreamDestroy(stream);\n+  }\n+\n+  int64_t device = -1; \n+  cudaStream_t stream = nullptr;\n };\n \n namespace at {\n namespace cuda {\n \n namespace detail {\n \n-  /*\n-  * Stream state\n-  */\n-  static constexpr cudaStream_t DEFAULT_STREAM = 0;\n-\n-  static std::once_flag init_flag;\n+  // Global stream state and constants\n   static int64_t num_gpus;\n-  static CUDAStreamInternals* default_streams;\n+  static constexpr int STREAMS_PER_POOL = 32;\n+  static constexpr unsigned int DEFAULT_FLAGS = cudaStreamNonBlocking;\n+  static int HIGH_PRIORITY = 0;\n+  static int LOW_PRIORITY = 0;\n+  \n+  // Default streams\n+  static std::once_flag init_flag;\n+  static std::vector<CUDAStreamInternals> default_streams;\n+\n+  // Non-default streams\n+  static std::deque<std::once_flag> device_flags;\n+  static std::deque<std::atomic<int>> low_priority_counters;\n+  static std::deque<std::atomic<int>> high_priority_counters;\n+  static std::vector<std::vector<CUDAStreamInternals>> low_priority_streams;\n+  static std::vector<std::vector<CUDAStreamInternals>> high_priority_streams;\n+\n+  // Thread-local current streams\n   static thread_local CUDAStreamInternals** current_streams = nullptr;\n \n-  // Creates a(n indestructible) default stream for each device\n-  // Note: the default stream on each device is signified by a zero\n-  // value for the pointer, and so is not actually created as usual.\n+  // Populates global values and creates a default stream for each device.\n+  // Note: the default stream on each device is signified by a nullptr, \n+  // and so is not created as usual.\n   // In particular, we don't need to switch devices when creating the\n   // streams.\n-  static void initDefaultCUDAStreams() {\n+  static void initGlobalStreamState() {\n     num_gpus = getNumGPUs();\n-    default_streams = (CUDAStreamInternals*) malloc(num_gpus * sizeof(CUDAStreamInternals));\n+\n+    // Resizes deques and vectors\n+    default_streams.resize(num_gpus);\n+    device_flags.resize(num_gpus);\n+    low_priority_counters.resize(num_gpus);\n+    high_priority_counters.resize(num_gpus);\n+    low_priority_streams.resize(num_gpus);\n+    high_priority_streams.resize(num_gpus);\n+\n+    // Initializes streams and counters\n     for (auto i = decltype(num_gpus){0}; i < num_gpus; ++i) {\n-      default_streams[i].is_destructible = false;\n-      default_streams[i].refcount = 0;\n       default_streams[i].device = i;\n-      default_streams[i].stream = DEFAULT_STREAM;\n+      low_priority_counters[i] = 0;\n+      high_priority_counters[i] = 0;\n+    }\n+\n+    // Populates low and high priority range\n+    #ifndef __HIP_PLATFORM_HCC__\n+      AT_CUDA_CHECK(cudaDeviceGetStreamPriorityRange(&LOW_PRIORITY, &HIGH_PRIORITY));\n+    #endif \n+  }\n+\n+  // Creates the low and high priority stream pools for the specified device\n+  static void initDeviceStreamState(const int64_t device) {\n+    // Switches to the requested device so streams are properly associated\n+    // with it.\n+    at::DeviceGuard device_guard{(int)device};\n+\n+    low_priority_streams[device].resize(STREAMS_PER_POOL);\n+    high_priority_streams[device].resize(STREAMS_PER_POOL);\n+    \n+    for (auto i = decltype(STREAMS_PER_POOL){0}; i < STREAMS_PER_POOL; ++i) {", "path": "aten/src/ATen/cuda/CUDAStream.cpp", "position": null, "original_position": 109, "commit_id": "3c0c30659be4528f10b94829b64f8532c3e61bb1", "original_commit_id": "47920408ab3d205b1817b9be4865fc8d0b2402ba", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "This loop is unrolled unnecessarily. I'm pretty sure you could do sth like\r\n```cpp\r\nfor (auto streams : {low_priority_streams, high_priority_streams})\r\n```", "created_at": "2018-08-28T17:11:28Z", "updated_at": "2018-11-23T15:50:10Z", "html_url": "https://github.com/pytorch/pytorch/pull/9938#discussion_r213398235", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9938", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213398235"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9938#discussion_r213398235"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9938"}}, "body_html": "<p>This loop is unrolled unnecessarily. I'm pretty sure you could do sth like</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-k\">for</span> (<span class=\"pl-k\">auto</span> streams : {low_priority_streams, high_priority_streams})</pre></div>", "body_text": "This loop is unrolled unnecessarily. I'm pretty sure you could do sth like\nfor (auto streams : {low_priority_streams, high_priority_streams})"}