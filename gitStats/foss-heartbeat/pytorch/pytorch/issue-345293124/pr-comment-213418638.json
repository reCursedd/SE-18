{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213418638", "pull_request_review_id": 150250782, "id": 213418638, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMzQxODYzOA==", "diff_hunk": "@@ -1,57 +1,127 @@\n #include \"ATen/cuda/CUDAStream.h\"\n #include \"ATen/cuda/CUDAContext.h\"\n #include \"ATen/cuda/Exceptions.h\"\n+#include \"ATen/DeviceGuard.h\"\n #include \"ATen/Error.h\"\n \n #include <mutex>\n #include <atomic>\n+#include <cstdint>\n+#include <deque>\n+#include <vector>\n \n // Internal implementation is entirely hidden\n+// Note: CUDAStreamInternals doubles for a THCStream\n struct CUDAStreamInternals {\n-  bool is_destructible;\n-  std::atomic<int> refcount;\n-  int64_t device; // Note: cudaGetDevice works with int32_t, not int64_t\n-  cudaStream_t stream;\n+  CUDAStreamInternals() = default;\n+\n+  ~CUDAStreamInternals() {\n+    if (stream) cudaStreamDestroy(stream);\n+  }\n+\n+  int64_t device = -1; \n+  cudaStream_t stream = nullptr;\n };\n \n namespace at {\n namespace cuda {\n \n namespace detail {\n \n-  /*\n-  * Stream state\n-  */\n-  static constexpr cudaStream_t DEFAULT_STREAM = 0;\n-\n-  static std::once_flag init_flag;\n+  // Global stream state and constants\n   static int64_t num_gpus;\n-  static CUDAStreamInternals* default_streams;\n+  static constexpr int STREAMS_PER_POOL = 32;\n+  static constexpr unsigned int DEFAULT_FLAGS = cudaStreamNonBlocking;\n+  static int HIGH_PRIORITY = 0;\n+  static int LOW_PRIORITY = 0;\n+  \n+  // Default streams\n+  static std::once_flag init_flag;\n+  static std::vector<CUDAStreamInternals> default_streams;\n+\n+  // Non-default streams\n+  static std::deque<std::once_flag> device_flags;\n+  static std::deque<std::atomic<int>> low_priority_counters;\n+  static std::deque<std::atomic<int>> high_priority_counters;\n+  static std::vector<std::vector<CUDAStreamInternals>> low_priority_streams;\n+  static std::vector<std::vector<CUDAStreamInternals>> high_priority_streams;\n+\n+  // Thread-local current streams\n   static thread_local CUDAStreamInternals** current_streams = nullptr;\n \n-  // Creates a(n indestructible) default stream for each device\n-  // Note: the default stream on each device is signified by a zero\n-  // value for the pointer, and so is not actually created as usual.\n+  // Populates global values and creates a default stream for each device.\n+  // Note: the default stream on each device is signified by a nullptr, \n+  // and so is not created as usual.\n   // In particular, we don't need to switch devices when creating the\n   // streams.\n-  static void initDefaultCUDAStreams() {\n+  static void initGlobalStreamState() {\n     num_gpus = getNumGPUs();\n-    default_streams = (CUDAStreamInternals*) malloc(num_gpus * sizeof(CUDAStreamInternals));\n+\n+    // Resizes deques and vectors\n+    default_streams.resize(num_gpus);\n+    device_flags.resize(num_gpus);\n+    low_priority_counters.resize(num_gpus);\n+    high_priority_counters.resize(num_gpus);\n+    low_priority_streams.resize(num_gpus);\n+    high_priority_streams.resize(num_gpus);\n+\n+    // Initializes streams and counters\n     for (auto i = decltype(num_gpus){0}; i < num_gpus; ++i) {\n-      default_streams[i].is_destructible = false;\n-      default_streams[i].refcount = 0;\n       default_streams[i].device = i;\n-      default_streams[i].stream = DEFAULT_STREAM;\n+      low_priority_counters[i] = 0;\n+      high_priority_counters[i] = 0;\n+    }\n+\n+    // Populates low and high priority range\n+    #ifndef __HIP_PLATFORM_HCC__\n+      AT_CUDA_CHECK(cudaDeviceGetStreamPriorityRange(&LOW_PRIORITY, &HIGH_PRIORITY));\n+    #endif \n+  }\n+\n+  // Creates the low and high priority stream pools for the specified device\n+  static void initDeviceStreamState(const int64_t device) {\n+    // Switches to the requested device so streams are properly associated\n+    // with it.\n+    at::DeviceGuard device_guard{(int)device};\n+\n+    low_priority_streams[device].resize(STREAMS_PER_POOL);\n+    high_priority_streams[device].resize(STREAMS_PER_POOL);\n+    \n+    for (auto i = decltype(STREAMS_PER_POOL){0}; i < STREAMS_PER_POOL; ++i) {\n+      auto& lowpri_stream = low_priority_streams[device][i];\n+      auto& hipri_stream = high_priority_streams[device][i];\n+      \n+      lowpri_stream.device = device;\n+      hipri_stream.device = device;\n+      \n+      #ifndef __HIP_PLATFORM_HCC__\n+        AT_CUDA_CHECK(cudaStreamCreateWithPriority(\n+          &lowpri_stream.stream\n+        , DEFAULT_FLAGS\n+        , LOW_PRIORITY));\n+        AT_CUDA_CHECK(cudaStreamCreateWithPriority(\n+          &hipri_stream.stream\n+        , DEFAULT_FLAGS\n+        , HIGH_PRIORITY));\n+      #else \n+        AT_CUDA_CHECK(cudaStreamCreateWithFlags(", "path": "aten/src/ATen/cuda/CUDAStream.cpp", "position": null, "original_position": 126, "commit_id": "3c0c30659be4528f10b94829b64f8532c3e61bb1", "original_commit_id": "47920408ab3d205b1817b9be4865fc8d0b2402ba", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Maybe a comment here with something like, \"HIP doesn't support stream priority, so we just create two streams with the same priority.\"", "created_at": "2018-08-28T18:10:46Z", "updated_at": "2018-11-23T15:50:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/9938#discussion_r213418638", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9938", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213418638"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9938#discussion_r213418638"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9938"}}, "body_html": "<p>Maybe a comment here with something like, \"HIP doesn't support stream priority, so we just create two streams with the same priority.\"</p>", "body_text": "Maybe a comment here with something like, \"HIP doesn't support stream priority, so we just create two streams with the same priority.\""}