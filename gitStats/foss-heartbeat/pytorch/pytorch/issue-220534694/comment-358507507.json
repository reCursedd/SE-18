{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/358507507", "html_url": "https://github.com/pytorch/pytorch/issues/1220#issuecomment-358507507", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1220", "id": 358507507, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODUwNzUwNw==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-18T01:30:08Z", "updated_at": "2018-11-12T09:18:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>From the related comments here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"286436765\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/15897\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/15897/hovercard?comment_id=356725027&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/15897#issuecomment-356725027\">tensorflow/tensorflow#15897 (comment)</a>, NCHW is not necessarily more efficient than NHWC in Volta and future architectures.</p>\n<p>Also from <a href=\"https://devblogs.nvidia.com/tensor-core-ai-performance-milestones/\" rel=\"nofollow\">https://devblogs.nvidia.com/tensor-core-ai-performance-milestones/</a>:</p>\n<blockquote>\n<p>The tensors operated on by Tensor Cores should be in a channel-interleaved data layout in memory (Number-Height-Width-Channel, often called NHWC) in order to get the best performance. The layout expected in memory by the training framework is channel-major data layout (Number-Channel-Width-Height, often called NCHW). So the cuDNN library executes tensor transpose operations between NCHW and NHWC</p>\n</blockquote>", "body_text": "From the related comments here: tensorflow/tensorflow#15897 (comment), NCHW is not necessarily more efficient than NHWC in Volta and future architectures.\nAlso from https://devblogs.nvidia.com/tensor-core-ai-performance-milestones/:\n\nThe tensors operated on by Tensor Cores should be in a channel-interleaved data layout in memory (Number-Height-Width-Channel, often called NHWC) in order to get the best performance. The layout expected in memory by the training framework is channel-major data layout (Number-Channel-Width-Height, often called NCHW). So the cuDNN library executes tensor transpose operations between NCHW and NHWC", "body": "From the related comments here: https://github.com/tensorflow/tensorflow/issues/15897#issuecomment-356725027, NCHW is not necessarily more efficient than NHWC in Volta and future architectures.\r\n\r\nAlso from https://devblogs.nvidia.com/tensor-core-ai-performance-milestones/:\r\n\r\n> The tensors operated on by Tensor Cores should be in a channel-interleaved data layout in memory (Number-Height-Width-Channel, often called NHWC) in order to get the best performance. The layout expected in memory by the training framework is channel-major data layout (Number-Channel-Width-Height, often called NCHW). So the cuDNN library executes tensor transpose operations between NCHW and NHWC"}