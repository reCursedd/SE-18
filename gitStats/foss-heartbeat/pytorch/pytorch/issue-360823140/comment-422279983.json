{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422279983", "html_url": "https://github.com/pytorch/pytorch/issues/11752#issuecomment-422279983", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11752", "id": 422279983, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjI3OTk4Mw==", "user": {"login": "fab-jul", "id": 3440923, "node_id": "MDQ6VXNlcjM0NDA5MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/3440923?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fab-jul", "html_url": "https://github.com/fab-jul", "followers_url": "https://api.github.com/users/fab-jul/followers", "following_url": "https://api.github.com/users/fab-jul/following{/other_user}", "gists_url": "https://api.github.com/users/fab-jul/gists{/gist_id}", "starred_url": "https://api.github.com/users/fab-jul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fab-jul/subscriptions", "organizations_url": "https://api.github.com/users/fab-jul/orgs", "repos_url": "https://api.github.com/users/fab-jul/repos", "events_url": "https://api.github.com/users/fab-jul/events{/privacy}", "received_events_url": "https://api.github.com/users/fab-jul/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-18T07:08:46Z", "updated_at": "2018-09-18T07:08:46Z", "author_association": "NONE", "body_html": "<p>Good insight, however, for double I get the same fail for <code>1e8 ** 2 == 1e16</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>y_small <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.double)\ny_big <span class=\"pl-k\">=</span> y_small <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1e16</span>\n<span class=\"pl-c1\">print</span>(torch.nn.functional.log_softmax(y_small, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>))\n<span class=\"pl-c1\">print</span>(torch.nn.functional.log_softmax(y_big, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> output</span>\ntensor([[<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.6931</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.6931</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float64)\ntensor([[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float64)</pre></div>", "body_text": "Good insight, however, for double I get the same fail for 1e8 ** 2 == 1e16:\ny_small = torch.ones(1, 2, dtype=torch.double)\ny_big = y_small * 1e16\nprint(torch.nn.functional.log_softmax(y_small, -1))\nprint(torch.nn.functional.log_softmax(y_big, -1))\n\n# output\ntensor([[-0.6931, -0.6931]], dtype=torch.float64)\ntensor([[0., 0.]], dtype=torch.float64)", "body": "Good insight, however, for double I get the same fail for `1e8 ** 2 == 1e16`:\r\n\r\n```python\r\ny_small = torch.ones(1, 2, dtype=torch.double)\r\ny_big = y_small * 1e16\r\nprint(torch.nn.functional.log_softmax(y_small, -1))\r\nprint(torch.nn.functional.log_softmax(y_big, -1))\r\n\r\n# output\r\ntensor([[-0.6931, -0.6931]], dtype=torch.float64)\r\ntensor([[0., 0.]], dtype=torch.float64)\r\n```"}