{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422883379", "html_url": "https://github.com/pytorch/pytorch/issues/11752#issuecomment-422883379", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11752", "id": 422883379, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjg4MzM3OQ==", "user": {"login": "sytrus-in-github", "id": 12224616, "node_id": "MDQ6VXNlcjEyMjI0NjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/12224616?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sytrus-in-github", "html_url": "https://github.com/sytrus-in-github", "followers_url": "https://api.github.com/users/sytrus-in-github/followers", "following_url": "https://api.github.com/users/sytrus-in-github/following{/other_user}", "gists_url": "https://api.github.com/users/sytrus-in-github/gists{/gist_id}", "starred_url": "https://api.github.com/users/sytrus-in-github/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sytrus-in-github/subscriptions", "organizations_url": "https://api.github.com/users/sytrus-in-github/orgs", "repos_url": "https://api.github.com/users/sytrus-in-github/repos", "events_url": "https://api.github.com/users/sytrus-in-github/events{/privacy}", "received_events_url": "https://api.github.com/users/sytrus-in-github/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T17:10:31Z", "updated_at": "2018-09-19T17:10:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think there is a numerical problem in <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L44-L60\">the CPU code</a> especially at <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L54\">line 54</a>:</p>\n<p>In this case <code>input_data[d * dim_stride] = max_input = 1e8</code> and <code>z = 1</code>. <code>tmpsum = 2</code> before line 54.</p>\n<p>At line 54, we have <code>tmpsum = 1e8 + log(2) = 1e8</code>. Numerically with float precision the <code>log(2)</code> is ignored so at the end we basically have <code> 1e8 - (1e8 + log(2)) = 0</code> instead of <code>-log(2)</code>.</p>\n<p>Changing line 54 to</p>\n<div class=\"highlight highlight-source-python\"><pre>tmpsum <span class=\"pl-k\">=</span> std::log(tmpsum)<span class=\"pl-bu\">;</span></pre></div>\n<p>and line 60 to</p>\n<div class=\"highlight highlight-source-python\"><pre>output_data[d <span class=\"pl-k\">*</span> dim_stride] <span class=\"pl-k\">=</span> input_data[d <span class=\"pl-k\">*</span> dim_stride] <span class=\"pl-k\">-</span> max_input <span class=\"pl-k\">-</span> tmpsum<span class=\"pl-bu\">;</span></pre></div>\n<p>should hopefully solve the problem. (and also the case with double precision)</p>\n<p>I am quite busy right now. But if these are the only lines that need to change. I don't mind do a PR :)</p>", "body_text": "I think there is a numerical problem in the CPU code especially at line 54:\nIn this case input_data[d * dim_stride] = max_input = 1e8 and z = 1. tmpsum = 2 before line 54.\nAt line 54, we have tmpsum = 1e8 + log(2) = 1e8. Numerically with float precision the log(2) is ignored so at the end we basically have  1e8 - (1e8 + log(2)) = 0 instead of -log(2).\nChanging line 54 to\ntmpsum = std::log(tmpsum);\nand line 60 to\noutput_data[d * dim_stride] = input_data[d * dim_stride] - max_input - tmpsum;\nshould hopefully solve the problem. (and also the case with double precision)\nI am quite busy right now. But if these are the only lines that need to change. I don't mind do a PR :)", "body": "I think there is a numerical problem in [the CPU code](https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L44-L60) especially at [line 54](https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L54):\r\n\r\nIn this case `input_data[d * dim_stride] = max_input = 1e8` and `z = 1`. `tmpsum = 2` before line 54.\r\n\r\nAt line 54, we have `tmpsum = 1e8 + log(2) = 1e8`. Numerically with float precision the `log(2)` is ignored so at the end we basically have ` 1e8 - (1e8 + log(2)) = 0` instead of `-log(2)`.\r\n\r\nChanging line 54 to\r\n```python\r\ntmpsum = std::log(tmpsum);\r\n```\r\nand line 60 to\r\n```python\r\noutput_data[d * dim_stride] = input_data[d * dim_stride] - max_input - tmpsum;\r\n```\r\nshould hopefully solve the problem. (and also the case with double precision)\r\n\r\nI am quite busy right now. But if these are the only lines that need to change. I don't mind do a PR :) \r\n"}