{"url": "https://api.github.com/repos/pytorch/pytorch/issues/823", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/823/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/823/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/823/events", "html_url": "https://github.com/pytorch/pytorch/issues/823", "id": 209429275, "node_id": "MDU6SXNzdWUyMDk0MjkyNzU=", "number": 823, "title": "when modifying Variable.data, Variable.grad is not automatically resized", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-02-22T11:40:34Z", "updated_at": "2017-02-22T17:37:42Z", "closed_at": "2017-02-22T17:37:42Z", "author_association": "MEMBER", "body_html": "<p>Failure case which shouldn't fail.</p>\n<pre><code>import torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear\n\na = Variable(torch.randn(10), requires_grad=True)\n\nb = torch.mean(a)\nb.backward()\n\na.data.resize_(20).fill_(1)\nb = torch.mean(a)\nb.backward()\n</code></pre>\n<p>It errors with:</p>\n<pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n/data/users/soumith/fbsource/fbcode/pytorch/a.py in &lt;module&gt;()\n     10 a.data.resize_(20).fill_(1)\n     11 b = torch.mean(a)\n---&gt; 12 b.backward()\n\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in backward(self, gradient, retain_variables)\n    156                     'or with gradient w.r.t. the variable')\n    157             gradient = self.data.new().resize_as_(self.data).fill_(1)\n--&gt; 158         self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n    159\n    160     def register_hook(self, hook):\n\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in _do_backward(self, grad_output, retain_variables)\n    206                 if result is not None:\n    207                     unpacked_grad = result\n--&gt; 208         self.grad.data.add_(unpacked_grad)\n    209         return tuple()\n    210\n\nRuntimeError: inconsistent tensor size at pytorch/pytorch/torch/lib/TH/generic/THTensorMath.c:601\n</code></pre>\n<p>a.grad needs to be resized appropriately if a.data changes shape.</p>", "body_text": "Failure case which shouldn't fail.\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear\n\na = Variable(torch.randn(10), requires_grad=True)\n\nb = torch.mean(a)\nb.backward()\n\na.data.resize_(20).fill_(1)\nb = torch.mean(a)\nb.backward()\n\nIt errors with:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n/data/users/soumith/fbsource/fbcode/pytorch/a.py in <module>()\n     10 a.data.resize_(20).fill_(1)\n     11 b = torch.mean(a)\n---> 12 b.backward()\n\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in backward(self, gradient, retain_variables)\n    156                     'or with gradient w.r.t. the variable')\n    157             gradient = self.data.new().resize_as_(self.data).fill_(1)\n--> 158         self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n    159\n    160     def register_hook(self, hook):\n\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in _do_backward(self, grad_output, retain_variables)\n    206                 if result is not None:\n    207                     unpacked_grad = result\n--> 208         self.grad.data.add_(unpacked_grad)\n    209         return tuple()\n    210\n\nRuntimeError: inconsistent tensor size at pytorch/pytorch/torch/lib/TH/generic/THTensorMath.c:601\n\na.grad needs to be resized appropriately if a.data changes shape.", "body": "Failure case which shouldn't fail.\r\n\r\n```\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom torch.nn import Linear\r\n\r\na = Variable(torch.randn(10), requires_grad=True)\r\n\r\nb = torch.mean(a)\r\nb.backward()\r\n\r\na.data.resize_(20).fill_(1)\r\nb = torch.mean(a)\r\nb.backward()\r\n```\r\n\r\nIt errors with:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n/data/users/soumith/fbsource/fbcode/pytorch/a.py in <module>()\r\n     10 a.data.resize_(20).fill_(1)\r\n     11 b = torch.mean(a)\r\n---> 12 b.backward()\r\n\r\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in backward(self, gradient, retain_variables)\r\n    156                     'or with gradient w.r.t. the variable')\r\n    157             gradient = self.data.new().resize_as_(self.data).fill_(1)\r\n--> 158         self._execution_engine.run_backward((self,), (gradient,), retain_variables)\r\n    159\r\n    160     def register_hook(self, hook):\r\n\r\n/data/users/soumith/fbsource/fbcode/buck-out/dev/gen/pytorch/ifbpy#link-tree/torch/autograd/variable.pyc in _do_backward(self, grad_output, retain_variables)\r\n    206                 if result is not None:\r\n    207                     unpacked_grad = result\r\n--> 208         self.grad.data.add_(unpacked_grad)\r\n    209         return tuple()\r\n    210\r\n\r\nRuntimeError: inconsistent tensor size at pytorch/pytorch/torch/lib/TH/generic/THTensorMath.c:601\r\n```\r\n\r\na.grad needs to be resized appropriately if a.data changes shape."}