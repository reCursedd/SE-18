{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9526", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9526/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9526/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9526/events", "html_url": "https://github.com/pytorch/pytorch/issues/9526", "id": 342251364, "node_id": "MDU6SXNzdWUzNDIyNTEzNjQ=", "number": 9526, "title": "MarginRankingLoss with multiple examples per batch is broken", "user": {"login": "marchbnr", "id": 927273, "node_id": "MDQ6VXNlcjkyNzI3Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/927273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marchbnr", "html_url": "https://github.com/marchbnr", "followers_url": "https://api.github.com/users/marchbnr/followers", "following_url": "https://api.github.com/users/marchbnr/following{/other_user}", "gists_url": "https://api.github.com/users/marchbnr/gists{/gist_id}", "starred_url": "https://api.github.com/users/marchbnr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marchbnr/subscriptions", "organizations_url": "https://api.github.com/users/marchbnr/orgs", "repos_url": "https://api.github.com/users/marchbnr/repos", "events_url": "https://api.github.com/users/marchbnr/events{/privacy}", "received_events_url": "https://api.github.com/users/marchbnr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-18T09:38:38Z", "updated_at": "2018-08-29T16:01:26Z", "closed_at": "2018-07-18T11:03:25Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Using the MarginRankingLoss with multiple examples per batch seems to be broken.</p>\n<p>It seems like this has been implemented here:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"213358688\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/972\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/972/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/972\">#972</a></p>\n<p>but is broken after this change:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"299213558\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5346\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/5346/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/5346\">#5346</a></p>\n<h2>Code example</h2>\n<pre><code>import torch\nimport torch.nn as nn\nx1 = torch.ones(64, 128)\nx2 = torch.ones(64, 128)\ntarget = torch.ones(64)\nloss = nn.MarginRankingLoss(margin=1.0).forward(x1, x2, target)\n</code></pre>\n<p>This results in the following Exception:<br>\nTraceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nFile \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 874, in forward<br>\nself.reduce)<br>\nFile \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/functional.py\", line 1580, in margin_ranking_loss<br>\nreturn torch.margin_ranking_loss(input1, input2, target, margin, size_average, reduce)<br>\nRuntimeError: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1</p>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.6<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.13.1)<br>\n[conda] pytorch-ignite            0.1.0                     <br>\n[conda] pytorch-nlp               0.3.5                     <br>\n[conda] pytorch-quasar            0.0.1a0                   <br>\n[conda] torch                     0.4.0                     <br>\n[conda] torchfile                 0.1.0                     <br>\n[conda] torchtext                 0.2.3                     &lt;pip</p>", "body_text": "Issue description\nUsing the MarginRankingLoss with multiple examples per batch seems to be broken.\nIt seems like this has been implemented here:\n#972\nbut is broken after this change:\n#5346\nCode example\nimport torch\nimport torch.nn as nn\nx1 = torch.ones(64, 128)\nx2 = torch.ones(64, 128)\ntarget = torch.ones(64)\nloss = nn.MarginRankingLoss(margin=1.0).forward(x1, x2, target)\n\nThis results in the following Exception:\nTraceback (most recent call last):\nFile \"\", line 1, in \nFile \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 874, in forward\nself.reduce)\nFile \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/functional.py\", line 1580, in margin_ranking_loss\nreturn torch.margin_ranking_loss(input1, input2, target, margin, size_average, reduce)\nRuntimeError: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1\nSystem Info\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: Could not collect\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip3] numpy (1.13.1)\n[conda] pytorch-ignite            0.1.0                     \n[conda] pytorch-nlp               0.3.5                     \n[conda] pytorch-quasar            0.0.1a0                   \n[conda] torch                     0.4.0                     \n[conda] torchfile                 0.1.0                     \n[conda] torchtext                 0.2.3                     <pip", "body": "## Issue description\r\nUsing the MarginRankingLoss with multiple examples per batch seems to be broken.\r\n\r\nIt seems like this has been implemented here:\r\nhttps://github.com/pytorch/pytorch/issues/972\r\n\r\nbut is broken after this change:\r\nhttps://github.com/pytorch/pytorch/pull/5346\r\n\r\n## Code example\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nx1 = torch.ones(64, 128)\r\nx2 = torch.ones(64, 128)\r\ntarget = torch.ones(64)\r\nloss = nn.MarginRankingLoss(margin=1.0).forward(x1, x2, target)\r\n```\r\n\r\nThis results in the following Exception:\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 874, in forward\r\n    self.reduce)\r\n  File \"/home/marc/Applications/miniconda3/envs/pytorch-env/lib/python3.6/site-packages/torch/nn/functional.py\", line 1580, in margin_ranking_loss\r\n    return torch.margin_ranking_loss(input1, input2, target, margin, size_average, reduce)\r\nRuntimeError: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.13.1)\r\n[conda] pytorch-ignite            0.1.0                     <pip>\r\n[conda] pytorch-nlp               0.3.5                     <pip>\r\n[conda] pytorch-quasar            0.0.1a0                   <pip>\r\n[conda] torch                     0.4.0                     <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchtext                 0.2.3                     <pip\r\n"}