{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422448150", "html_url": "https://github.com/pytorch/pytorch/issues/11797#issuecomment-422448150", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11797", "id": 422448150, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjQ0ODE1MA==", "user": {"login": "matthieuheitz", "id": 2835332, "node_id": "MDQ6VXNlcjI4MzUzMzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2835332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthieuheitz", "html_url": "https://github.com/matthieuheitz", "followers_url": "https://api.github.com/users/matthieuheitz/followers", "following_url": "https://api.github.com/users/matthieuheitz/following{/other_user}", "gists_url": "https://api.github.com/users/matthieuheitz/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthieuheitz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthieuheitz/subscriptions", "organizations_url": "https://api.github.com/users/matthieuheitz/orgs", "repos_url": "https://api.github.com/users/matthieuheitz/repos", "events_url": "https://api.github.com/users/matthieuheitz/events{/privacy}", "received_events_url": "https://api.github.com/users/matthieuheitz/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-18T15:51:00Z", "updated_at": "2018-09-18T15:54:46Z", "author_association": "NONE", "body_html": "<p>After having modified the code in <code>gradcheck.py</code> to ignore sparse matrices, like below, it still works for dense matrices and not for sparse ones, but at least the error message is consistent for all formats of sparse matrices : I get the error \"RuntimeError: all inputs have to be Tensors, but got csr_matrix\", and the last part of the message changes according to the format. Of course my edit is not acceptable, but maybe you could add a condition in those 2 functions, that if the object is neither a Tensor, neither an Iterable, then you treat it just like if it was a non-gradient-requiring tensor ? That way the user would have a clear message saying that they can't put non-tensors as argument.</p>\n<p>Although, it would be great to be able to pass non-Pytorch objects in those arguments, as long as we don't require or return a gradient for them.</p>\n<pre><code>def make_jacobian(input, num_out):\n    if scipy.sparse.isspmatrix(input):  # Added\n        return None                                # Added\n    elif isinstance(input, torch.Tensor): # Replaced if by elif\n        if not input.is_floating_point():\n            return None\n        if not input.requires_grad:\n            return None\n        return torch.zeros(input.nelement(), num_out, dtype=input.dtype)\n    elif isinstance(input, Iterable):\n        jacobians = list(filter(\n            lambda x: x is not None, (make_jacobian(elem, num_out) for elem in input)))\n        if not jacobians:\n            return None\n        return type(input)(jacobians)\n    else:\n        return None\n\nimport scipy.sparse   # Added\n\ndef iter_tensors(x, only_requiring_grad=False):\n    if scipy.sparse.isspmatrix(x):  # Added\n        yield x                                 # Added\n    elif isinstance(x, torch.Tensor):   # Replaced if by elif\n        if x.requires_grad or not only_requiring_grad:\n            yield x\n    elif isinstance(x, Iterable):\n        for elem in x:\n            for result in iter_tensors(elem, only_requiring_grad):\n                yield result\n</code></pre>", "body_text": "After having modified the code in gradcheck.py to ignore sparse matrices, like below, it still works for dense matrices and not for sparse ones, but at least the error message is consistent for all formats of sparse matrices : I get the error \"RuntimeError: all inputs have to be Tensors, but got csr_matrix\", and the last part of the message changes according to the format. Of course my edit is not acceptable, but maybe you could add a condition in those 2 functions, that if the object is neither a Tensor, neither an Iterable, then you treat it just like if it was a non-gradient-requiring tensor ? That way the user would have a clear message saying that they can't put non-tensors as argument.\nAlthough, it would be great to be able to pass non-Pytorch objects in those arguments, as long as we don't require or return a gradient for them.\ndef make_jacobian(input, num_out):\n    if scipy.sparse.isspmatrix(input):  # Added\n        return None                                # Added\n    elif isinstance(input, torch.Tensor): # Replaced if by elif\n        if not input.is_floating_point():\n            return None\n        if not input.requires_grad:\n            return None\n        return torch.zeros(input.nelement(), num_out, dtype=input.dtype)\n    elif isinstance(input, Iterable):\n        jacobians = list(filter(\n            lambda x: x is not None, (make_jacobian(elem, num_out) for elem in input)))\n        if not jacobians:\n            return None\n        return type(input)(jacobians)\n    else:\n        return None\n\nimport scipy.sparse   # Added\n\ndef iter_tensors(x, only_requiring_grad=False):\n    if scipy.sparse.isspmatrix(x):  # Added\n        yield x                                 # Added\n    elif isinstance(x, torch.Tensor):   # Replaced if by elif\n        if x.requires_grad or not only_requiring_grad:\n            yield x\n    elif isinstance(x, Iterable):\n        for elem in x:\n            for result in iter_tensors(elem, only_requiring_grad):\n                yield result", "body": "After having modified the code in `gradcheck.py` to ignore sparse matrices, like below, it still works for dense matrices and not for sparse ones, but at least the error message is consistent for all formats of sparse matrices : I get the error \"RuntimeError: all inputs have to be Tensors, but got csr_matrix\", and the last part of the message changes according to the format. Of course my edit is not acceptable, but maybe you could add a condition in those 2 functions, that if the object is neither a Tensor, neither an Iterable, then you treat it just like if it was a non-gradient-requiring tensor ? That way the user would have a clear message saying that they can't put non-tensors as argument.\r\n\r\nAlthough, it would be great to be able to pass non-Pytorch objects in those arguments, as long as we don't require or return a gradient for them.\r\n\r\n```\r\ndef make_jacobian(input, num_out):\r\n    if scipy.sparse.isspmatrix(input):  # Added\r\n        return None                                # Added\r\n    elif isinstance(input, torch.Tensor): # Replaced if by elif\r\n        if not input.is_floating_point():\r\n            return None\r\n        if not input.requires_grad:\r\n            return None\r\n        return torch.zeros(input.nelement(), num_out, dtype=input.dtype)\r\n    elif isinstance(input, Iterable):\r\n        jacobians = list(filter(\r\n            lambda x: x is not None, (make_jacobian(elem, num_out) for elem in input)))\r\n        if not jacobians:\r\n            return None\r\n        return type(input)(jacobians)\r\n    else:\r\n        return None\r\n\r\nimport scipy.sparse   # Added\r\n\r\ndef iter_tensors(x, only_requiring_grad=False):\r\n    if scipy.sparse.isspmatrix(x):  # Added\r\n        yield x                                 # Added\r\n    elif isinstance(x, torch.Tensor):   # Replaced if by elif\r\n        if x.requires_grad or not only_requiring_grad:\r\n            yield x\r\n    elif isinstance(x, Iterable):\r\n        for elem in x:\r\n            for result in iter_tensors(elem, only_requiring_grad):\r\n                yield result\r\n```\r\n\r\n"}