{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10710", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10710/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10710/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10710/events", "html_url": "https://github.com/pytorch/pytorch/pull/10710", "id": 352315454, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA5NjU4MzI3", "number": 10710, "title": "Support Loading to GPU", "user": {"login": "xsh6528", "id": 7608630, "node_id": "MDQ6VXNlcjc2MDg2MzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/7608630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xsh6528", "html_url": "https://github.com/xsh6528", "followers_url": "https://api.github.com/users/xsh6528/followers", "following_url": "https://api.github.com/users/xsh6528/following{/other_user}", "gists_url": "https://api.github.com/users/xsh6528/gists{/gist_id}", "starred_url": "https://api.github.com/users/xsh6528/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xsh6528/subscriptions", "organizations_url": "https://api.github.com/users/xsh6528/orgs", "repos_url": "https://api.github.com/users/xsh6528/repos", "events_url": "https://api.github.com/users/xsh6528/events{/privacy}", "received_events_url": "https://api.github.com/users/xsh6528/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-08-20T22:13:48Z", "updated_at": "2018-08-21T20:58:44Z", "closed_at": "2018-08-21T20:58:44Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10710", "html_url": "https://github.com/pytorch/pytorch/pull/10710", "diff_url": "https://github.com/pytorch/pytorch/pull/10710.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10710.patch"}, "body_html": "<p>Summary:<br>\nCan't resume from checkpoint for workflows that use GPU.</p>\n<p>The problem is just we didn't leverage the already-provided GPU deserialization of Caffe2.</p>\n<p><code>keep_device</code> arg of LoadOp. See <a href=\"https://fburl.com/y27ltaxw\" rel=\"nofollow\">https://fburl.com/y27ltaxw</a></p>\n<p>How a serialized BlobProto (contraining TensorProto) is loaded into GPU memory?</p>\n<ul>\n<li>Load BlobProto from DB. <a href=\"https://fburl.com/pe1qaeyf\" rel=\"nofollow\">https://fburl.com/pe1qaeyf</a></li>\n<li>Deserialize the BlobProto into a Blob instance. <a href=\"https://fburl.com/5dirjuuh\" rel=\"nofollow\">https://fburl.com/5dirjuuh</a> and <a href=\"https://fburl.com/stoho0x1\" rel=\"nofollow\">https://fburl.com/stoho0x1</a></li>\n<li>Call Blob-&gt;Deserialized. <a href=\"https://fburl.com/bnureu32\" rel=\"nofollow\">https://fburl.com/bnureu32</a></li>\n<li>Deserializer Registration. <a href=\"https://fburl.com/wbu95ry7\" rel=\"nofollow\">https://fburl.com/wbu95ry7</a> <a href=\"https://fburl.com/ycetud8u\" rel=\"nofollow\">https://fburl.com/ycetud8u</a></li>\n<li>Create TensorCUDA Deserializer. <a href=\"https://fburl.com/2lirfuqj\" rel=\"nofollow\">https://fburl.com/2lirfuqj</a></li>\n<li>Create Tensor on GPU and get TensorProto of BlobProto. <a href=\"https://fburl.com/7dre82zg\" rel=\"nofollow\">https://fburl.com/7dre82zg</a></li>\n<li>Copy TensorProto in CPU to Tensor on GPU. <a href=\"https://fburl.com/fr0qk2oe\" rel=\"nofollow\">https://fburl.com/fr0qk2oe</a></li>\n</ul>\n<p>Cloned the GPU workflows for testing in D9125520.</p>\n<p>Differential Revision: D9372950</p>", "body_text": "Summary:\nCan't resume from checkpoint for workflows that use GPU.\nThe problem is just we didn't leverage the already-provided GPU deserialization of Caffe2.\nkeep_device arg of LoadOp. See https://fburl.com/y27ltaxw\nHow a serialized BlobProto (contraining TensorProto) is loaded into GPU memory?\n\nLoad BlobProto from DB. https://fburl.com/pe1qaeyf\nDeserialize the BlobProto into a Blob instance. https://fburl.com/5dirjuuh and https://fburl.com/stoho0x1\nCall Blob->Deserialized. https://fburl.com/bnureu32\nDeserializer Registration. https://fburl.com/wbu95ry7 https://fburl.com/ycetud8u\nCreate TensorCUDA Deserializer. https://fburl.com/2lirfuqj\nCreate Tensor on GPU and get TensorProto of BlobProto. https://fburl.com/7dre82zg\nCopy TensorProto in CPU to Tensor on GPU. https://fburl.com/fr0qk2oe\n\nCloned the GPU workflows for testing in D9125520.\nDifferential Revision: D9372950", "body": "Summary:\nCan't resume from checkpoint for workflows that use GPU.\n\nThe problem is just we didn't leverage the already-provided GPU deserialization of Caffe2.\n\n`keep_device` arg of LoadOp. See https://fburl.com/y27ltaxw\n\nHow a serialized BlobProto (contraining TensorProto) is loaded into GPU memory?\n- Load BlobProto from DB. https://fburl.com/pe1qaeyf\n- Deserialize the BlobProto into a Blob instance. https://fburl.com/5dirjuuh and https://fburl.com/stoho0x1\n- Call Blob->Deserialized. https://fburl.com/bnureu32\n- Deserializer Registration. https://fburl.com/wbu95ry7 https://fburl.com/ycetud8u\n- Create TensorCUDA Deserializer. https://fburl.com/2lirfuqj\n- Create Tensor on GPU and get TensorProto of BlobProto. https://fburl.com/7dre82zg\n- Copy TensorProto in CPU to Tensor on GPU. https://fburl.com/fr0qk2oe\n\nCloned the GPU workflows for testing in D9125520.\n\nDifferential Revision: D9372950\n"}