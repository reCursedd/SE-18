{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3922", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3922/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3922/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3922/events", "html_url": "https://github.com/pytorch/pytorch/issues/3922", "id": 277398841, "node_id": "MDU6SXNzdWUyNzczOTg4NDE=", "number": 3922, "title": "x.index_fill_() on cuda tensors doesn't do bounds checks", "user": {"login": "jh-jeong", "id": 9063308, "node_id": "MDQ6VXNlcjkwNjMzMDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/9063308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jh-jeong", "html_url": "https://github.com/jh-jeong", "followers_url": "https://api.github.com/users/jh-jeong/followers", "following_url": "https://api.github.com/users/jh-jeong/following{/other_user}", "gists_url": "https://api.github.com/users/jh-jeong/gists{/gist_id}", "starred_url": "https://api.github.com/users/jh-jeong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jh-jeong/subscriptions", "organizations_url": "https://api.github.com/users/jh-jeong/orgs", "repos_url": "https://api.github.com/users/jh-jeong/repos", "events_url": "https://api.github.com/users/jh-jeong/events{/privacy}", "received_events_url": "https://api.github.com/users/jh-jeong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-28T14:13:04Z", "updated_at": "2017-11-30T19:42:07Z", "closed_at": "2017-11-30T19:42:07Z", "author_association": "NONE", "body_html": "<p>It seems that <code>x.index_fill_()</code> can change memory outside x, when x is a cuda tensor.</p>\n<p>If x is non-cuda tensor, we get:</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; x = torch.Tensor([1,1,1])\n&gt;&gt;&gt; x.index_fill_(0, torch.LongTensor([100]), -1)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nRuntimeError: invalid argument 2: out of range at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/TH/generic/THTensor.c:861\n</code></pre>\n<p>In contrast, when x is cuda tensor, <code>index_fill_()</code> does not make any error</p>\n<pre><code>&gt;&gt;&gt; a = torch.Tensor([1,1,1]).cuda()\n&gt;&gt;&gt; a.index_fill_(0, torch.LongTensor([100]).cuda(), -1)\n\n 1\n 1\n 1\n[torch.cuda.FloatTensor of size 3 (GPU 0)]\n</code></pre>\n<p>It's hard to share the whole code, but I have noticed that such operation outside a tensor did affect the performance of existing network, so I'm afraid that this op can change arbitrary memory on GPU which can be dangerous. Could you check this out?</p>", "body_text": "It seems that x.index_fill_() can change memory outside x, when x is a cuda tensor.\nIf x is non-cuda tensor, we get:\n>>> import torch\n>>> x = torch.Tensor([1,1,1])\n>>> x.index_fill_(0, torch.LongTensor([100]), -1)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nRuntimeError: invalid argument 2: out of range at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/TH/generic/THTensor.c:861\n\nIn contrast, when x is cuda tensor, index_fill_() does not make any error\n>>> a = torch.Tensor([1,1,1]).cuda()\n>>> a.index_fill_(0, torch.LongTensor([100]).cuda(), -1)\n\n 1\n 1\n 1\n[torch.cuda.FloatTensor of size 3 (GPU 0)]\n\nIt's hard to share the whole code, but I have noticed that such operation outside a tensor did affect the performance of existing network, so I'm afraid that this op can change arbitrary memory on GPU which can be dangerous. Could you check this out?", "body": "It seems that `x.index_fill_()` can change memory outside x, when x is a cuda tensor.\r\n\r\nIf x is non-cuda tensor, we get:\r\n```\r\n>>> import torch\r\n>>> x = torch.Tensor([1,1,1])\r\n>>> x.index_fill_(0, torch.LongTensor([100]), -1)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nRuntimeError: invalid argument 2: out of range at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/TH/generic/THTensor.c:861\r\n```\r\n\r\nIn contrast, when x is cuda tensor, `index_fill_()` does not make any error\r\n```\r\n>>> a = torch.Tensor([1,1,1]).cuda()\r\n>>> a.index_fill_(0, torch.LongTensor([100]).cuda(), -1)\r\n\r\n 1\r\n 1\r\n 1\r\n[torch.cuda.FloatTensor of size 3 (GPU 0)]\r\n```\r\n\r\nIt's hard to share the whole code, but I have noticed that such operation outside a tensor did affect the performance of existing network, so I'm afraid that this op can change arbitrary memory on GPU which can be dangerous. Could you check this out?\r\n\r\n"}