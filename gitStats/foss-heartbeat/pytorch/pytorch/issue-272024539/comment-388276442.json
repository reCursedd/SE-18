{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/388276442", "html_url": "https://github.com/pytorch/pytorch/issues/3556#issuecomment-388276442", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3556", "id": 388276442, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODI3NjQ0Mg==", "user": {"login": "John1231983", "id": 24875971, "node_id": "MDQ6VXNlcjI0ODc1OTcx", "avatar_url": "https://avatars3.githubusercontent.com/u/24875971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/John1231983", "html_url": "https://github.com/John1231983", "followers_url": "https://api.github.com/users/John1231983/followers", "following_url": "https://api.github.com/users/John1231983/following{/other_user}", "gists_url": "https://api.github.com/users/John1231983/gists{/gist_id}", "starred_url": "https://api.github.com/users/John1231983/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/John1231983/subscriptions", "organizations_url": "https://api.github.com/users/John1231983/orgs", "repos_url": "https://api.github.com/users/John1231983/repos", "events_url": "https://api.github.com/users/John1231983/events{/privacy}", "received_events_url": "https://api.github.com/users/John1231983/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-11T06:46:55Z", "updated_at": "2018-05-11T07:15:17Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a>  and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> : Thanks for it, I have same problem. I am implementing 3D Unet loss function.</p>\n<ul>\n<li>The labels size is <code>batch_size x depth x height x width</code></li>\n<li>The logits size is <code>batch_size x number_class x depth x height x width</code></li>\n</ul>\n<p>How can I use CrossEntropyLoss to compute the loss? this is my current way, but not sure the correction</p>\n<pre><code>criterion = nn.CrossEntropyLoss()\nfor epoch in range (num_epoch): \n     loss = 0\n     for deep_slice in range(depth):\n            loss += criterion(logits[:, :, deep_slice], labels[:, deep_slice])\n     loss=loss_seg/depth\n     loss.backward()\n</code></pre>\n<p>Another way may be converted to 2D</p>\n<pre><code>B,C,D,H,W=outputs.size()\nlogits_2d=logits.view(B,C,D, -1)\nlabels_2d = labels.view(B, D,-1)\nloss = criterion(logits_2d, labels_2d)\n</code></pre>\n<p>Thanks!</p>", "body_text": "@soumith  and @zou3519 : Thanks for it, I have same problem. I am implementing 3D Unet loss function.\n\nThe labels size is batch_size x depth x height x width\nThe logits size is batch_size x number_class x depth x height x width\n\nHow can I use CrossEntropyLoss to compute the loss? this is my current way, but not sure the correction\ncriterion = nn.CrossEntropyLoss()\nfor epoch in range (num_epoch): \n     loss = 0\n     for deep_slice in range(depth):\n            loss += criterion(logits[:, :, deep_slice], labels[:, deep_slice])\n     loss=loss_seg/depth\n     loss.backward()\n\nAnother way may be converted to 2D\nB,C,D,H,W=outputs.size()\nlogits_2d=logits.view(B,C,D, -1)\nlabels_2d = labels.view(B, D,-1)\nloss = criterion(logits_2d, labels_2d)\n\nThanks!", "body": "@soumith  and @zou3519 : Thanks for it, I have same problem. I am implementing 3D Unet loss function. \r\n\r\n- The labels size is `batch_size x depth x height x width`\r\n- The logits size is `batch_size x number_class x depth x height x width`\r\n\r\nHow can I use CrossEntropyLoss to compute the loss? this is my current way, but not sure the correction\r\n```\r\ncriterion = nn.CrossEntropyLoss()\r\nfor epoch in range (num_epoch): \r\n     loss = 0\r\n     for deep_slice in range(depth):\r\n            loss += criterion(logits[:, :, deep_slice], labels[:, deep_slice])\r\n     loss=loss_seg/depth\r\n     loss.backward()\r\n```\r\nAnother way may be converted to 2D\r\n```\r\nB,C,D,H,W=outputs.size()\r\nlogits_2d=logits.view(B,C,D, -1)\r\nlabels_2d = labels.view(B, D,-1)\r\nloss = criterion(logits_2d, labels_2d)\r\n```\r\nThanks!"}