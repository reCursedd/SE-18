{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/173257169", "pull_request_review_id": 102417622, "id": 173257169, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MzI1NzE2OQ==", "diff_hunk": "@@ -92,150 +97,201 @@ void PropagateShapeOnNode(Node * node) {\n     return setDynamicType(node);\n   }\n \n+  bool handled = false;", "path": "torch/csrc/jit/passes/shape_analysis.cpp", "position": 23, "original_position": 23, "commit_id": "a42f2c0e6a131b63c10134c6d43fe23afe26324e", "original_commit_id": "a42f2c0e6a131b63c10134c6d43fe23afe26324e", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Yes, but in most cases you'll just use `check_overload` and have it all handled for you, while otherwise you can easily forget a `return` because it's going to be needed at the end of *every if branch* (otherwise you *want to fall through*), and you'll have the auto-inference run anyway. I can change it if you want it, but this it feels less error prone this way", "created_at": "2018-03-08T19:00:44Z", "updated_at": "2018-11-23T15:40:30Z", "html_url": "https://github.com/pytorch/pytorch/pull/5574#discussion_r173257169", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5574", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/173257169"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5574#discussion_r173257169"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5574"}}, "body_html": "<p>Yes, but in most cases you'll just use <code>check_overload</code> and have it all handled for you, while otherwise you can easily forget a <code>return</code> because it's going to be needed at the end of <em>every if branch</em> (otherwise you <em>want to fall through</em>), and you'll have the auto-inference run anyway. I can change it if you want it, but this it feels less error prone this way</p>", "body_text": "Yes, but in most cases you'll just use check_overload and have it all handled for you, while otherwise you can easily forget a return because it's going to be needed at the end of every if branch (otherwise you want to fall through), and you'll have the auto-inference run anyway. I can change it if you want it, but this it feels less error prone this way", "in_reply_to_id": 173239438}