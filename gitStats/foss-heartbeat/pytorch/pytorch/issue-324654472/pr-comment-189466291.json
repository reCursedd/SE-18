{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189466291", "pull_request_review_id": 121650966, "id": 189466291, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTQ2NjI5MQ==", "diff_hunk": "@@ -182,6 +182,7 @@ def __init__(self, wrapped):\n     def __get__(self, instance, obj_type=None):\n         if instance is None:\n             return self\n-        value = self.wrapped(instance)\n+        with torch.enable_grad():", "path": "torch/distributions/utils.py", "position": 5, "original_position": 5, "commit_id": "e860e39f173f673536341d5ce8ce11dd4fe254ff", "original_commit_id": "db3aab10a4f95aedcc4ceec774c88b527b7bdf63", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "If I understand the logic correctly, the logic is to use `__get__` unless there is an attribute of the same name. If you cache `value` in self and make recalculation and the `setattr` conditional on `is_grad_enabled`, you'd get a property that becomes lazy on the first invocation with grads. I'm not sure whether the overhead of calling `__get__` is that large in the grand scheme of things, but if the property is regularly used with `no_grad`, I think the memory saving might be worth the compute.", "created_at": "2018-05-20T18:13:56Z", "updated_at": "2018-11-23T15:44:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/7708#discussion_r189466291", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7708", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189466291"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7708#discussion_r189466291"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7708"}}, "body_html": "<p>If I understand the logic correctly, the logic is to use <code>__get__</code> unless there is an attribute of the same name. If you cache <code>value</code> in self and make recalculation and the <code>setattr</code> conditional on <code>is_grad_enabled</code>, you'd get a property that becomes lazy on the first invocation with grads. I'm not sure whether the overhead of calling <code>__get__</code> is that large in the grand scheme of things, but if the property is regularly used with <code>no_grad</code>, I think the memory saving might be worth the compute.</p>", "body_text": "If I understand the logic correctly, the logic is to use __get__ unless there is an attribute of the same name. If you cache value in self and make recalculation and the setattr conditional on is_grad_enabled, you'd get a property that becomes lazy on the first invocation with grads. I'm not sure whether the overhead of calling __get__ is that large in the grand scheme of things, but if the property is regularly used with no_grad, I think the memory saving might be worth the compute.", "in_reply_to_id": 189443514}