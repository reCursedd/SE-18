{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/340544571", "html_url": "https://github.com/pytorch/pytorch/issues/3354#issuecomment-340544571", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3354", "id": 340544571, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDU0NDU3MQ==", "user": {"login": "gokceneraslan", "id": 1140359, "node_id": "MDQ6VXNlcjExNDAzNTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1140359?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gokceneraslan", "html_url": "https://github.com/gokceneraslan", "followers_url": "https://api.github.com/users/gokceneraslan/followers", "following_url": "https://api.github.com/users/gokceneraslan/following{/other_user}", "gists_url": "https://api.github.com/users/gokceneraslan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gokceneraslan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gokceneraslan/subscriptions", "organizations_url": "https://api.github.com/users/gokceneraslan/orgs", "repos_url": "https://api.github.com/users/gokceneraslan/repos", "events_url": "https://api.github.com/users/gokceneraslan/events{/privacy}", "received_events_url": "https://api.github.com/users/gokceneraslan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-30T18:42:06Z", "updated_at": "2017-10-30T19:04:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Now I feel like there is something weird. I changed my code, so that the training loss is now calculated as the mean of all batch training losses within epoch. Then, I generated another dataset (via negative binomial regression since I'm mostly working with integer count data) and plotted train/val loss with and without shuffling in Torch and Keras. Here is how it looks like:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1140359/32190274-870b7152-bdad-11e7-90db-7fa04b27a208.png\"><img src=\"https://user-images.githubusercontent.com/1140359/32190274-870b7152-bdad-11e7-90db-7fa04b27a208.png\" alt=\"shuffle\" style=\"max-width:100%;\"></a></p>\n<p>Is this fluctuation really normal? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> any comments?</p>\n<p>Code is here: <a href=\"https://gist.github.com/gokceneraslan/397cf160aed741a9ba2296505026c659\">https://gist.github.com/gokceneraslan/397cf160aed741a9ba2296505026c659</a></p>", "body_text": "Now I feel like there is something weird. I changed my code, so that the training loss is now calculated as the mean of all batch training losses within epoch. Then, I generated another dataset (via negative binomial regression since I'm mostly working with integer count data) and plotted train/val loss with and without shuffling in Torch and Keras. Here is how it looks like:\n\nIs this fluctuation really normal? @soumith any comments?\nCode is here: https://gist.github.com/gokceneraslan/397cf160aed741a9ba2296505026c659", "body": "Now I feel like there is something weird. I changed my code, so that the training loss is now calculated as the mean of all batch training losses within epoch. Then, I generated another dataset (via negative binomial regression since I'm mostly working with integer count data) and plotted train/val loss with and without shuffling in Torch and Keras. Here is how it looks like:\r\n\r\n![shuffle](https://user-images.githubusercontent.com/1140359/32190274-870b7152-bdad-11e7-90db-7fa04b27a208.png)\r\n\r\nIs this fluctuation really normal? @soumith any comments?\r\n\r\nCode is here: https://gist.github.com/gokceneraslan/397cf160aed741a9ba2296505026c659\r\n"}