{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/340656634", "html_url": "https://github.com/pytorch/pytorch/issues/2740#issuecomment-340656634", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2740", "id": 340656634, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDY1NjYzNA==", "user": {"login": "Smerity", "id": 32325, "node_id": "MDQ6VXNlcjMyMzI1", "avatar_url": "https://avatars0.githubusercontent.com/u/32325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Smerity", "html_url": "https://github.com/Smerity", "followers_url": "https://api.github.com/users/Smerity/followers", "following_url": "https://api.github.com/users/Smerity/following{/other_user}", "gists_url": "https://api.github.com/users/Smerity/gists{/gist_id}", "starred_url": "https://api.github.com/users/Smerity/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Smerity/subscriptions", "organizations_url": "https://api.github.com/users/Smerity/orgs", "repos_url": "https://api.github.com/users/Smerity/repos", "events_url": "https://api.github.com/users/Smerity/events{/privacy}", "received_events_url": "https://api.github.com/users/Smerity/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-31T04:27:46Z", "updated_at": "2017-10-31T04:53:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>FYI I ran into this bug when I was generating random numbers in the C style using CPU. PyTorch docs promise [0, 1) so I multiplied <code>rand()</code> by N and expected it never to actually produce N. Rarely my program would crash - very rarely - i.e. 1 in a million as seen below ;)</p>\n<pre><code>&gt;&gt;&gt; sum(((torch.rand(1000000) * 10).int() == 10).sum() for _ in range(10))\n1\n</code></pre>\n<p>I understand the issue is horrendously complex thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a>'s fascinating commentary. For now, a hacky fix of multiplying by some arbitrary scalar (<code>0.999</code>) prevents the issue above. Luckily I don't mind a pseudo uniform distribution ;) The same issue occurs when you call <code>uniform_(from=0, to=10)</code> too - I didn't know of <code>from=X, to=Y</code> until checking docs for sanity.</p>\n<p>These issues are likely a worthwhile addition to the PyTorch docs. For those who don't care about the details they won't look into it, but for others who do, it's a very useful heads-up. I have also never been able to sample 0, on either the CPU or GPU, yet can consistently sample 1.</p>", "body_text": "FYI I ran into this bug when I was generating random numbers in the C style using CPU. PyTorch docs promise [0, 1) so I multiplied rand() by N and expected it never to actually produce N. Rarely my program would crash - very rarely - i.e. 1 in a million as seen below ;)\n>>> sum(((torch.rand(1000000) * 10).int() == 10).sum() for _ in range(10))\n1\n\nI understand the issue is horrendously complex thanks to @ngimel's fascinating commentary. For now, a hacky fix of multiplying by some arbitrary scalar (0.999) prevents the issue above. Luckily I don't mind a pseudo uniform distribution ;) The same issue occurs when you call uniform_(from=0, to=10) too - I didn't know of from=X, to=Y until checking docs for sanity.\nThese issues are likely a worthwhile addition to the PyTorch docs. For those who don't care about the details they won't look into it, but for others who do, it's a very useful heads-up. I have also never been able to sample 0, on either the CPU or GPU, yet can consistently sample 1.", "body": "FYI I ran into this bug when I was generating random numbers in the C style using CPU. PyTorch docs promise [0, 1) so I multiplied `rand()` by N and expected it never to actually produce N. Rarely my program would crash - very rarely - i.e. 1 in a million as seen below ;)\r\n\r\n```\r\n>>> sum(((torch.rand(1000000) * 10).int() == 10).sum() for _ in range(10))\r\n1\r\n```\r\n\r\nI understand the issue is horrendously complex thanks to @ngimel's fascinating commentary. For now, a hacky fix of multiplying by some arbitrary scalar (`0.999`) prevents the issue above. Luckily I don't mind a pseudo uniform distribution ;) The same issue occurs when you call `uniform_(from=0, to=10)` too - I didn't know of `from=X, to=Y` until checking docs for sanity.\r\n\r\nThese issues are likely a worthwhile addition to the PyTorch docs. For those who don't care about the details they won't look into it, but for others who do, it's a very useful heads-up. I have also never been able to sample 0, on either the CPU or GPU, yet can consistently sample 1."}