{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/332616944", "html_url": "https://github.com/pytorch/pytorch/issues/2740#issuecomment-332616944", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2740", "id": 332616944, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjYxNjk0NA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-27T18:39:49Z", "updated_at": "2017-09-27T18:39:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here's a small test, reproducing device- and host-side generation, as implemented in TH/THC:</p>\n<pre><code>#include &lt;curand_globals.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n\nint main(){\n   uint x = UINT_MAX;\n   double d = x * CURAND_2POW32_INV_DOUBLE + (CURAND_2POW32_INV_DOUBLE/2.0f);\n   std::cout &lt;&lt; std::setprecision(14) &lt;&lt; \"double max \" &lt;&lt; d &lt;&lt; \"\\n\";\n   float f = x * CURAND_2POW32_INV + (CURAND_2POW32_INV/2.0f);\n   std::cout &lt;&lt; \"float max \" &lt;&lt; f &lt;&lt; \"\\n\";\n//TH backend\n   double dc = UINT_MAX * (1.0/4294967296.0);   \n   std::cout &lt;&lt; std::setprecision(14) &lt;&lt; \"double max cpu \" &lt;&lt; dc &lt;&lt; \"\\n\"; \n   float fc = (float)(UINT_MAX * (1.0/4294967296.0));\n   std::cout &lt;&lt; std::setprecision(14) &lt;&lt; \"float max cpu \" &lt;&lt; fc &lt;&lt; \"\\n\"; \n  \n}\n</code></pre>\n<p>Only cpu-side double generation is doing what is promised: [0, 1). cpu-side for floats of course rounds max to 1, thus generating [0 1]<br>\ngpu-side for floats generates (0,1], as promised by curand manual, but that's not what torch manual specifies.<br>\ngpu-side for doubles has a bug, thus generates (0,1), contrary to what's promised in the manual.<br>\nReplacing x by (1-x) is expected to fail because of the different density of fp numbers near 0 and near 1 (thus, when 1-x is calculated for a small non-zero x, result will be rounded to 1, so (0,1] range will essentially be mapped to [0 1] range).</p>", "body_text": "Here's a small test, reproducing device- and host-side generation, as implemented in TH/THC:\n#include <curand_globals.h>\n#include <limits.h>\n#include <iostream>\n#include <iomanip>\n\nint main(){\n   uint x = UINT_MAX;\n   double d = x * CURAND_2POW32_INV_DOUBLE + (CURAND_2POW32_INV_DOUBLE/2.0f);\n   std::cout << std::setprecision(14) << \"double max \" << d << \"\\n\";\n   float f = x * CURAND_2POW32_INV + (CURAND_2POW32_INV/2.0f);\n   std::cout << \"float max \" << f << \"\\n\";\n//TH backend\n   double dc = UINT_MAX * (1.0/4294967296.0);   \n   std::cout << std::setprecision(14) << \"double max cpu \" << dc << \"\\n\"; \n   float fc = (float)(UINT_MAX * (1.0/4294967296.0));\n   std::cout << std::setprecision(14) << \"float max cpu \" << fc << \"\\n\"; \n  \n}\n\nOnly cpu-side double generation is doing what is promised: [0, 1). cpu-side for floats of course rounds max to 1, thus generating [0 1]\ngpu-side for floats generates (0,1], as promised by curand manual, but that's not what torch manual specifies.\ngpu-side for doubles has a bug, thus generates (0,1), contrary to what's promised in the manual.\nReplacing x by (1-x) is expected to fail because of the different density of fp numbers near 0 and near 1 (thus, when 1-x is calculated for a small non-zero x, result will be rounded to 1, so (0,1] range will essentially be mapped to [0 1] range).", "body": "Here's a small test, reproducing device- and host-side generation, as implemented in TH/THC:\r\n```\r\n#include <curand_globals.h>\r\n#include <limits.h>\r\n#include <iostream>\r\n#include <iomanip>\r\n\r\nint main(){\r\n   uint x = UINT_MAX;\r\n   double d = x * CURAND_2POW32_INV_DOUBLE + (CURAND_2POW32_INV_DOUBLE/2.0f);\r\n   std::cout << std::setprecision(14) << \"double max \" << d << \"\\n\";\r\n   float f = x * CURAND_2POW32_INV + (CURAND_2POW32_INV/2.0f);\r\n   std::cout << \"float max \" << f << \"\\n\";\r\n//TH backend\r\n   double dc = UINT_MAX * (1.0/4294967296.0);   \r\n   std::cout << std::setprecision(14) << \"double max cpu \" << dc << \"\\n\"; \r\n   float fc = (float)(UINT_MAX * (1.0/4294967296.0));\r\n   std::cout << std::setprecision(14) << \"float max cpu \" << fc << \"\\n\"; \r\n  \r\n}\r\n```\r\nOnly cpu-side double generation is doing what is promised: [0, 1). cpu-side for floats of course rounds max to 1, thus generating [0 1]\r\ngpu-side for floats generates (0,1], as promised by curand manual, but that's not what torch manual specifies. \r\ngpu-side for doubles has a bug, thus generates (0,1), contrary to what's promised in the manual. \r\nReplacing x by (1-x) is expected to fail because of the different density of fp numbers near 0 and near 1 (thus, when 1-x is calculated for a small non-zero x, result will be rounded to 1, so (0,1] range will essentially be mapped to [0 1] range). \r\n"}