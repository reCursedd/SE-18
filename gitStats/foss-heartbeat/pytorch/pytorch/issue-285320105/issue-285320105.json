{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4431", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4431/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4431/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4431/events", "html_url": "https://github.com/pytorch/pytorch/issues/4431", "id": 285320105, "node_id": "MDU6SXNzdWUyODUzMjAxMDU=", "number": 4431, "title": "method `cuda` for PackedSequence", "user": {"login": "jusjusjus", "id": 6298900, "node_id": "MDQ6VXNlcjYyOTg5MDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6298900?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jusjusjus", "html_url": "https://github.com/jusjusjus", "followers_url": "https://api.github.com/users/jusjusjus/followers", "following_url": "https://api.github.com/users/jusjusjus/following{/other_user}", "gists_url": "https://api.github.com/users/jusjusjus/gists{/gist_id}", "starred_url": "https://api.github.com/users/jusjusjus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jusjusjus/subscriptions", "organizations_url": "https://api.github.com/users/jusjusjus/orgs", "repos_url": "https://api.github.com/users/jusjusjus/repos", "events_url": "https://api.github.com/users/jusjusjus/events{/privacy}", "received_events_url": "https://api.github.com/users/jusjusjus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-01T17:57:56Z", "updated_at": "2018-01-01T21:34:12Z", "closed_at": "2018-01-01T21:34:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My use-case necessitates sending a <code>PackedSequence</code> to the GPU.  What I currently do is <code>packed_gpu = PackedSequence(packed.data.cuda(), packed.batch_sizes)</code>.  I think this could be included in a convenience method as so:  <code>packed_gpu = packed.cuda()</code>.</p>\n<p>See pull request: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"285320084\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4430\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4430/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4430\">#4430</a></p>", "body_text": "My use-case necessitates sending a PackedSequence to the GPU.  What I currently do is packed_gpu = PackedSequence(packed.data.cuda(), packed.batch_sizes).  I think this could be included in a convenience method as so:  packed_gpu = packed.cuda().\nSee pull request: #4430", "body": "My use-case necessitates sending a `PackedSequence` to the GPU.  What I currently do is `packed_gpu = PackedSequence(packed.data.cuda(), packed.batch_sizes)`.  I think this could be included in a convenience method as so:  `packed_gpu = packed.cuda()`.\r\n\r\nSee pull request: #4430"}