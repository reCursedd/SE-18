{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11030", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11030/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11030/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11030/events", "html_url": "https://github.com/pytorch/pytorch/issues/11030", "id": 355351641, "node_id": "MDU6SXNzdWUzNTUzNTE2NDE=", "number": 11030, "title": "implement dirichlet / beta GPU grad ", "user": {"login": "jramapuram", "id": 8204807, "node_id": "MDQ6VXNlcjgyMDQ4MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/8204807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jramapuram", "html_url": "https://github.com/jramapuram", "followers_url": "https://api.github.com/users/jramapuram/followers", "following_url": "https://api.github.com/users/jramapuram/following{/other_user}", "gists_url": "https://api.github.com/users/jramapuram/gists{/gist_id}", "starred_url": "https://api.github.com/users/jramapuram/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jramapuram/subscriptions", "organizations_url": "https://api.github.com/users/jramapuram/orgs", "repos_url": "https://api.github.com/users/jramapuram/repos", "events_url": "https://api.github.com/users/jramapuram/events{/privacy}", "received_events_url": "https://api.github.com/users/jramapuram/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 819357941, "node_id": "MDU6TGFiZWw4MTkzNTc5NDE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributions", "name": "distributions", "color": "39d651", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-29T22:08:10Z", "updated_at": "2018-11-18T21:17:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p><code>torch.distributions.Beta</code> and <code>torch.distributions.Dirichlet</code> don't allow for backward() calls on the GPU; the CPU versions works fine though.</p>\n<pre lang=\"ipython\"><code>In [1]: import torch\n\nIn [2]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\n   ...: es_grad=True))).rsample()\n\nIn [3]: torch.mean(d).backward()\n\nIn [4]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\n   ...: es_grad=True).cuda())).rsample()\n\n\nIn [5]: \n\nIn [5]: torch.mean(d).backward()\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-5-d517ed89bac2&gt; in &lt;module&gt;()\n----&gt; 1 torch.mean(d).backward()\n\n~/.venv3/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\n     94                 products. Defaults to ``False``.\n     95         \"\"\"\n---&gt; 96         torch.autograd.backward(self, gradient, retain_graph, create_graph)\n     97 \n     98     def register_hook(self, hook):\n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\n     88     Variable._execution_engine.run_backward(\n     89         tensors, grad_tensors, retain_graph, create_graph,\n---&gt; 90         allow_unreachable=True)  # allow_unreachable flag\n     91 \n     92 \n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in apply(self, *args)\n     74 \n     75     def apply(self, *args):\n---&gt; 76         return self._forward_cls.backward(self, *args)\n     77 \n     78 \n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in wrapper(ctx, *args)\n    186     def wrapper(ctx, *args):\n    187         with torch.no_grad():\n--&gt; 188             outputs = fn(ctx, *args)\n    189 \n    190         if not torch.is_grad_enabled():\n\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in backward(ctx, grad_output)\n     33     def backward(ctx, grad_output):\n     34         x, concentration = ctx.saved_tensors\n---&gt; 35         return _Dirichlet_backward(x, concentration, grad_output)\n     36 \n     37 \n\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in _Dirichlet_backward(x, concentration, grad_output)\n     18 def _Dirichlet_backward(x, concentration, grad_output):\n     19     total = concentration.sum(-1, True).expand_as(concentration)\n---&gt; 20     grad = torch._dirichlet_grad(x, concentration, total)\n     21     return grad * (grad_output - (x * grad_output).sum(-1, True))\n     22 \n\nRuntimeError: _dirichlet_grad is not implemented for type torch.cuda.FloatTensor\n\n</code></pre>\n<p>Provide a short description.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\nd <span class=\"pl-k\">=</span> torch.distributions.Dirichlet(torch.sigmoid(torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>))).rsample()\ntorch.mean(d).backward() <span class=\"pl-c\"><span class=\"pl-c\">#</span> works!</span>\nd <span class=\"pl-k\">=</span> torch.distributions.Dirichlet(torch.sigmoid(torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>).cuda())).rsample()\ntorch.mean(d).backward() <span class=\"pl-c\"><span class=\"pl-c\">#</span> throws above exception</span></pre></div>\n<h2>System Info</h2>\n<p>(base) \u279c  /tmp python collect_env.py<br>\nCollecting environment information...<br>\nPyTorch version: 0.5.0a0+ddc37d7<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Manjaro Linux<br>\nGCC version: (GCC) 8.2.0<br>\nCMake version: version 3.11.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.148<br>\nGPU models and configuration: GPU 0: GeForce GTX 1060<br>\nNvidia driver version: 396.54<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] magma-cuda92              2.3.0                         1    pytorch<br>\n[conda] torch                     0.5.0a0+ddc37d7           <br>\n[conda] torchfile                 0.1.0                     <br>\n[conda] torchvision               0.2.1                     </p>\n<ul>\n<li>PyTorch or Caffe2: pytorch</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>OS: arch</li>\n<li>Python version: 3.7</li>\n</ul>", "body_text": "Issue description\ntorch.distributions.Beta and torch.distributions.Dirichlet don't allow for backward() calls on the GPU; the CPU versions works fine though.\nIn [1]: import torch\n\nIn [2]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\n   ...: es_grad=True))).rsample()\n\nIn [3]: torch.mean(d).backward()\n\nIn [4]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\n   ...: es_grad=True).cuda())).rsample()\n\n\nIn [5]: \n\nIn [5]: torch.mean(d).backward()\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-5-d517ed89bac2> in <module>()\n----> 1 torch.mean(d).backward()\n\n~/.venv3/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\n     94                 products. Defaults to ``False``.\n     95         \"\"\"\n---> 96         torch.autograd.backward(self, gradient, retain_graph, create_graph)\n     97 \n     98     def register_hook(self, hook):\n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\n     88     Variable._execution_engine.run_backward(\n     89         tensors, grad_tensors, retain_graph, create_graph,\n---> 90         allow_unreachable=True)  # allow_unreachable flag\n     91 \n     92 \n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in apply(self, *args)\n     74 \n     75     def apply(self, *args):\n---> 76         return self._forward_cls.backward(self, *args)\n     77 \n     78 \n\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in wrapper(ctx, *args)\n    186     def wrapper(ctx, *args):\n    187         with torch.no_grad():\n--> 188             outputs = fn(ctx, *args)\n    189 \n    190         if not torch.is_grad_enabled():\n\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in backward(ctx, grad_output)\n     33     def backward(ctx, grad_output):\n     34         x, concentration = ctx.saved_tensors\n---> 35         return _Dirichlet_backward(x, concentration, grad_output)\n     36 \n     37 \n\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in _Dirichlet_backward(x, concentration, grad_output)\n     18 def _Dirichlet_backward(x, concentration, grad_output):\n     19     total = concentration.sum(-1, True).expand_as(concentration)\n---> 20     grad = torch._dirichlet_grad(x, concentration, total)\n     21     return grad * (grad_output - (x * grad_output).sum(-1, True))\n     22 \n\nRuntimeError: _dirichlet_grad is not implemented for type torch.cuda.FloatTensor\n\n\nProvide a short description.\nCode example\nimport torch\nd = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requires_grad=True))).rsample()\ntorch.mean(d).backward() # works!\nd = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requires_grad=True).cuda())).rsample()\ntorch.mean(d).backward() # throws above exception\nSystem Info\n(base) \u279c  /tmp python collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+ddc37d7\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Manjaro Linux\nGCC version: (GCC) 8.2.0\nCMake version: version 3.11.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.148\nGPU models and configuration: GPU 0: GeForce GTX 1060\nNvidia driver version: 396.54\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] magma-cuda92              2.3.0                         1    pytorch\n[conda] torch                     0.5.0a0+ddc37d7           \n[conda] torchfile                 0.1.0                     \n[conda] torchvision               0.2.1                     \n\nPyTorch or Caffe2: pytorch\nHow you installed PyTorch (conda, pip, source): source\nOS: arch\nPython version: 3.7", "body": "## Issue description\r\n`torch.distributions.Beta` and `torch.distributions.Dirichlet` don't allow for backward() calls on the GPU; the CPU versions works fine though. \r\n\r\n```ipython\r\nIn [1]: import torch\r\n\r\nIn [2]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\r\n   ...: es_grad=True))).rsample()\r\n\r\nIn [3]: torch.mean(d).backward()\r\n\r\nIn [4]: d = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requir\r\n   ...: es_grad=True).cuda())).rsample()\r\n\r\n\r\nIn [5]: \r\n\r\nIn [5]: torch.mean(d).backward()\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-5-d517ed89bac2> in <module>()\r\n----> 1 torch.mean(d).backward()\r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\r\n     94                 products. Defaults to ``False``.\r\n     95         \"\"\"\r\n---> 96         torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n     97 \r\n     98     def register_hook(self, hook):\r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\r\n     88     Variable._execution_engine.run_backward(\r\n     89         tensors, grad_tensors, retain_graph, create_graph,\r\n---> 90         allow_unreachable=True)  # allow_unreachable flag\r\n     91 \r\n     92 \r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in apply(self, *args)\r\n     74 \r\n     75     def apply(self, *args):\r\n---> 76         return self._forward_cls.backward(self, *args)\r\n     77 \r\n     78 \r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/autograd/function.py in wrapper(ctx, *args)\r\n    186     def wrapper(ctx, *args):\r\n    187         with torch.no_grad():\r\n--> 188             outputs = fn(ctx, *args)\r\n    189 \r\n    190         if not torch.is_grad_enabled():\r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in backward(ctx, grad_output)\r\n     33     def backward(ctx, grad_output):\r\n     34         x, concentration = ctx.saved_tensors\r\n---> 35         return _Dirichlet_backward(x, concentration, grad_output)\r\n     36 \r\n     37 \r\n\r\n~/.venv3/lib/python3.6/site-packages/torch/distributions/dirichlet.py in _Dirichlet_backward(x, concentration, grad_output)\r\n     18 def _Dirichlet_backward(x, concentration, grad_output):\r\n     19     total = concentration.sum(-1, True).expand_as(concentration)\r\n---> 20     grad = torch._dirichlet_grad(x, concentration, total)\r\n     21     return grad * (grad_output - (x * grad_output).sum(-1, True))\r\n     22 \r\n\r\nRuntimeError: _dirichlet_grad is not implemented for type torch.cuda.FloatTensor\r\n\r\n```\r\nProvide a short description.\r\n\r\n## Code example\r\n\r\n```python\r\nimport torch\r\nd = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requires_grad=True))).rsample()\r\ntorch.mean(d).backward() # works!\r\nd = torch.distributions.Dirichlet(torch.sigmoid(torch.randn(3, 4, requires_grad=True).cuda())).rsample()\r\ntorch.mean(d).backward() # throws above exception\r\n```\r\n\r\n## System Info\r\n\r\n(base) \u279c  /tmp python collect_env.py \r\nCollecting environment information...\r\nPyTorch version: 0.5.0a0+ddc37d7\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Manjaro Linux\r\nGCC version: (GCC) 8.2.0\r\nCMake version: version 3.11.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: GeForce GTX 1060\r\nNvidia driver version: 396.54\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] magma-cuda92              2.3.0                         1    pytorch\r\n[conda] torch                     0.5.0a0+ddc37d7           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n\r\n- PyTorch or Caffe2: pytorch\r\n- How you installed PyTorch (conda, pip, source): source \r\n- OS: arch\r\n- Python version: 3.7"}