{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11333", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11333/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11333/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11333/events", "html_url": "https://github.com/pytorch/pytorch/issues/11333", "id": 357716758, "node_id": "MDU6SXNzdWUzNTc3MTY3NTg=", "number": 11333, "title": "MultivariateNormal and potrf is slow on gpu and seems to have some memory leak", "user": {"login": "koszpe", "id": 11389587, "node_id": "MDQ6VXNlcjExMzg5NTg3", "avatar_url": "https://avatars1.githubusercontent.com/u/11389587?v=4", "gravatar_id": "", "url": "https://api.github.com/users/koszpe", "html_url": "https://github.com/koszpe", "followers_url": "https://api.github.com/users/koszpe/followers", "following_url": "https://api.github.com/users/koszpe/following{/other_user}", "gists_url": "https://api.github.com/users/koszpe/gists{/gist_id}", "starred_url": "https://api.github.com/users/koszpe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/koszpe/subscriptions", "organizations_url": "https://api.github.com/users/koszpe/orgs", "repos_url": "https://api.github.com/users/koszpe/repos", "events_url": "https://api.github.com/users/koszpe/events{/privacy}", "received_events_url": "https://api.github.com/users/koszpe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1002715609, "node_id": "MDU6TGFiZWwxMDAyNzE1NjA5", "url": "https://api.github.com/repos/pytorch/pytorch/labels/blocker", "name": "blocker", "color": "b60205", "default": false}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "open", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-09-06T15:44:47Z", "updated_at": "2018-09-20T08:32:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>When I initialize a <a href=\"https://github.com/pytorch/pytorch/blob/bb7d1837bc164b06e1d0826a20a8f7e8338a44e3/torch/distributions/multivariate_normal.py#L76\">MultivariateNormal</a> object with a covariance matrix provided with batch dimension too, it is very slow on GPU, and it is always slower on GPU then on CPU.<br>\nIt even seems to leak the memory with or without the batch dimension and both on CPU and GPU, but with different intensity (check n parameter in code example).<br>\nOne more strange thing: It uses more CPU RAM when running on GPU.</p>\n<p>Digging a bit deeper, I experienced the same with the Tensor's potrf function, so probably this is the root cause.</p>\n<h2>Code example</h2>\n<pre><code>import resource\nimport torch\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nimport gc\nimport time\n\ndef gpu(item, use_GPU=True):\n    if use_GPU:\n        return item.cuda()\n    else:\n        return item\n\ndef test_multivariate(loc_mat, cov_mat):\n    standard_normal_dist = MultivariateNormal(loc=loc_mat,\n                                              covariance_matrix=cov_mat)\n\ndef test_potrf(loc_mat, cov_mat):\n    n = cov_mat.size(-1)\n    [m.potrf(upper=False) for m in cov_mat.reshape(-1, n, n)]\n\ndef loop(fn_ref, n=10, size=10000, use_GPU=True, covariance_with_batch_dim=True, print_n=1):\n    cov_mat = gpu(torch.zeros((2, 2)) + torch.eye(2), use_GPU)\n    if covariance_with_batch_dim:\n        cov_mat = cov_mat.unsqueeze(0).repeat(size, 1, 1)\n    loc_mat = gpu(torch.zeros((size, 2)), use_GPU)\n\n    for i in range(n):\n        gc.collect()\n        fn_ref(loc_mat, cov_mat)\n        if i % print_n == 0:\n            print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n\n\nif __name__ == '__main__':\n\n    n = 10\n    fn_ref = test_multivariate\n    use_GPU = True\n    covariance_with_batch_dim = True\n    print_n = n / 10\n\n    print(\"test_fn: \", fn_ref.__name__)\n    print(\"n: \", n)\n    print(\"use_GPU: \", use_GPU)\n    print(\"covariance_with_batch_dim: \", covariance_with_batch_dim, \"\\n\")\n\n    start = time.time()\n\n    loop(fn_ref=fn_ref, use_GPU=use_GPU, covariance_with_batch_dim=covariance_with_batch_dim, n=n, print_n=print_n)\n\n    print(\"\\ntime: \", (time.time() - start) / n)\n</code></pre>\n<h2>Outputs</h2>\n<p>Testing MultivariateNormal</p>\n<pre><code>test_fn:  test_multivariate\nn:  5\nuse_GPU:  False\ncovariance_with_batch_dim:  True \n\n118808\n119200\n119552\n119908\n120268\n\ntime:  0.08764233589172363\n</code></pre>\n<pre><code>test_fn:  test_multivariate\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  True \n\n1477808\n1479680\n1479996\n1480312\n1480684\n\ntime:  27.707138347625733\n</code></pre>\n<pre><code>test_fn:  test_multivariate\nn:  5000\nuse_GPU:  False\ncovariance_with_batch_dim:  False \n\n107904\n107904\n109436\n109436\n109700\n\ntime:  0.008288921689987183\n</code></pre>\n<pre><code>test_fn:  test_multivariate\nn:  50\nuse_GPU:  True\ncovariance_with_batch_dim:  False \n\n1467364\n1468676\n1468676\n1468680\n1468680\n\ntime:  0.037353959083557126\n</code></pre>\n<p>Testing potrf</p>\n<pre><code>test_fn:  test_potrf\nn:  5\nuse_GPU:  False\ncovariance_with_batch_dim:  True \n\n116984\n117300\n117672\n118032\n118380\n\ntime:  0.06480374336242675\n</code></pre>\n<pre><code>test_fn:  test_potrf\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  True \n\n1476688\n1477008\n1477320\n1477916\n1478168\n\ntime:  26.757283926010132\n</code></pre>\n<pre><code>test_fn:  test_potrf\nn:  50000\nuse_GPU:  False\ncovariance_with_batch_dim:  False \n\n108420\n109720\n109984\n110248\n110512\n\ntime:  0.008067794122695923\n</code></pre>\n<pre><code>test_fn:  test_potrf\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  False \n\n1468760\n1469664\n1469680\n1469680\n1469680\n\ntime:  0.2711141109466553\n</code></pre>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.5.0a0+e9ad743<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.88</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0<br>\nCMake version: version 3.12.0</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.148<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti</p>\n<p>Nvidia driver version: 396.54<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1<br>\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] magma-cuda91              2.3.0                         1    pytorch<br>\n[conda] torch                     0.5.0a0+e9ad743           <br>\n[conda] torchfile                 0.1.0                     <br>\n[conda] torchnet                  0.0.4                     <br>\n[conda] torchvision               0.2.1                     </p>\n<p>Pytorch is used in docker container<br>\npip version:<br>\npip 18.0 from /opt/conda/lib/python3.6/site-packages/pip (python 3.6)</p>", "body_text": "Issue description\nWhen I initialize a MultivariateNormal object with a covariance matrix provided with batch dimension too, it is very slow on GPU, and it is always slower on GPU then on CPU.\nIt even seems to leak the memory with or without the batch dimension and both on CPU and GPU, but with different intensity (check n parameter in code example).\nOne more strange thing: It uses more CPU RAM when running on GPU.\nDigging a bit deeper, I experienced the same with the Tensor's potrf function, so probably this is the root cause.\nCode example\nimport resource\nimport torch\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nimport gc\nimport time\n\ndef gpu(item, use_GPU=True):\n    if use_GPU:\n        return item.cuda()\n    else:\n        return item\n\ndef test_multivariate(loc_mat, cov_mat):\n    standard_normal_dist = MultivariateNormal(loc=loc_mat,\n                                              covariance_matrix=cov_mat)\n\ndef test_potrf(loc_mat, cov_mat):\n    n = cov_mat.size(-1)\n    [m.potrf(upper=False) for m in cov_mat.reshape(-1, n, n)]\n\ndef loop(fn_ref, n=10, size=10000, use_GPU=True, covariance_with_batch_dim=True, print_n=1):\n    cov_mat = gpu(torch.zeros((2, 2)) + torch.eye(2), use_GPU)\n    if covariance_with_batch_dim:\n        cov_mat = cov_mat.unsqueeze(0).repeat(size, 1, 1)\n    loc_mat = gpu(torch.zeros((size, 2)), use_GPU)\n\n    for i in range(n):\n        gc.collect()\n        fn_ref(loc_mat, cov_mat)\n        if i % print_n == 0:\n            print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n\n\nif __name__ == '__main__':\n\n    n = 10\n    fn_ref = test_multivariate\n    use_GPU = True\n    covariance_with_batch_dim = True\n    print_n = n / 10\n\n    print(\"test_fn: \", fn_ref.__name__)\n    print(\"n: \", n)\n    print(\"use_GPU: \", use_GPU)\n    print(\"covariance_with_batch_dim: \", covariance_with_batch_dim, \"\\n\")\n\n    start = time.time()\n\n    loop(fn_ref=fn_ref, use_GPU=use_GPU, covariance_with_batch_dim=covariance_with_batch_dim, n=n, print_n=print_n)\n\n    print(\"\\ntime: \", (time.time() - start) / n)\n\nOutputs\nTesting MultivariateNormal\ntest_fn:  test_multivariate\nn:  5\nuse_GPU:  False\ncovariance_with_batch_dim:  True \n\n118808\n119200\n119552\n119908\n120268\n\ntime:  0.08764233589172363\n\ntest_fn:  test_multivariate\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  True \n\n1477808\n1479680\n1479996\n1480312\n1480684\n\ntime:  27.707138347625733\n\ntest_fn:  test_multivariate\nn:  5000\nuse_GPU:  False\ncovariance_with_batch_dim:  False \n\n107904\n107904\n109436\n109436\n109700\n\ntime:  0.008288921689987183\n\ntest_fn:  test_multivariate\nn:  50\nuse_GPU:  True\ncovariance_with_batch_dim:  False \n\n1467364\n1468676\n1468676\n1468680\n1468680\n\ntime:  0.037353959083557126\n\nTesting potrf\ntest_fn:  test_potrf\nn:  5\nuse_GPU:  False\ncovariance_with_batch_dim:  True \n\n116984\n117300\n117672\n118032\n118380\n\ntime:  0.06480374336242675\n\ntest_fn:  test_potrf\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  True \n\n1476688\n1477008\n1477320\n1477916\n1478168\n\ntime:  26.757283926010132\n\ntest_fn:  test_potrf\nn:  50000\nuse_GPU:  False\ncovariance_with_batch_dim:  False \n\n108420\n109720\n109984\n110248\n110512\n\ntime:  0.008067794122695923\n\ntest_fn:  test_potrf\nn:  5\nuse_GPU:  True\ncovariance_with_batch_dim:  False \n\n1468760\n1469664\n1469680\n1469680\n1469680\n\ntime:  0.2711141109466553\n\nSystem Info\nCollecting environment information...\nPyTorch version: 0.5.0a0+e9ad743\nIs debug build: No\nCUDA used to build PyTorch: 9.2.88\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\nCMake version: version 3.12.0\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.148\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nNvidia driver version: 396.54\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] magma-cuda91              2.3.0                         1    pytorch\n[conda] torch                     0.5.0a0+e9ad743           \n[conda] torchfile                 0.1.0                     \n[conda] torchnet                  0.0.4                     \n[conda] torchvision               0.2.1                     \nPytorch is used in docker container\npip version:\npip 18.0 from /opt/conda/lib/python3.6/site-packages/pip (python 3.6)", "body": "## Issue description\r\n\r\nWhen I initialize a [MultivariateNormal](https://github.com/pytorch/pytorch/blob/bb7d1837bc164b06e1d0826a20a8f7e8338a44e3/torch/distributions/multivariate_normal.py#L76) object with a covariance matrix provided with batch dimension too, it is very slow on GPU, and it is always slower on GPU then on CPU. \r\nIt even seems to leak the memory with or without the batch dimension and both on CPU and GPU, but with different intensity (check n parameter in code example).\r\nOne more strange thing: It uses more CPU RAM when running on GPU.\r\n\r\nDigging a bit deeper, I experienced the same with the Tensor's potrf function, so probably this is the root cause.\r\n\r\n## Code example\r\n\r\n```\r\nimport resource\r\nimport torch\r\nfrom torch.distributions.multivariate_normal import MultivariateNormal\r\nimport gc\r\nimport time\r\n\r\ndef gpu(item, use_GPU=True):\r\n    if use_GPU:\r\n        return item.cuda()\r\n    else:\r\n        return item\r\n\r\ndef test_multivariate(loc_mat, cov_mat):\r\n    standard_normal_dist = MultivariateNormal(loc=loc_mat,\r\n                                              covariance_matrix=cov_mat)\r\n\r\ndef test_potrf(loc_mat, cov_mat):\r\n    n = cov_mat.size(-1)\r\n    [m.potrf(upper=False) for m in cov_mat.reshape(-1, n, n)]\r\n\r\ndef loop(fn_ref, n=10, size=10000, use_GPU=True, covariance_with_batch_dim=True, print_n=1):\r\n    cov_mat = gpu(torch.zeros((2, 2)) + torch.eye(2), use_GPU)\r\n    if covariance_with_batch_dim:\r\n        cov_mat = cov_mat.unsqueeze(0).repeat(size, 1, 1)\r\n    loc_mat = gpu(torch.zeros((size, 2)), use_GPU)\r\n\r\n    for i in range(n):\r\n        gc.collect()\r\n        fn_ref(loc_mat, cov_mat)\r\n        if i % print_n == 0:\r\n            print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    n = 10\r\n    fn_ref = test_multivariate\r\n    use_GPU = True\r\n    covariance_with_batch_dim = True\r\n    print_n = n / 10\r\n\r\n    print(\"test_fn: \", fn_ref.__name__)\r\n    print(\"n: \", n)\r\n    print(\"use_GPU: \", use_GPU)\r\n    print(\"covariance_with_batch_dim: \", covariance_with_batch_dim, \"\\n\")\r\n\r\n    start = time.time()\r\n\r\n    loop(fn_ref=fn_ref, use_GPU=use_GPU, covariance_with_batch_dim=covariance_with_batch_dim, n=n, print_n=print_n)\r\n\r\n    print(\"\\ntime: \", (time.time() - start) / n)\r\n```\r\n## Outputs\r\n\r\nTesting MultivariateNormal\r\n\r\n```\r\ntest_fn:  test_multivariate\r\nn:  5\r\nuse_GPU:  False\r\ncovariance_with_batch_dim:  True \r\n\r\n118808\r\n119200\r\n119552\r\n119908\r\n120268\r\n\r\ntime:  0.08764233589172363\r\n```\r\n\r\n```\r\ntest_fn:  test_multivariate\r\nn:  5\r\nuse_GPU:  True\r\ncovariance_with_batch_dim:  True \r\n\r\n1477808\r\n1479680\r\n1479996\r\n1480312\r\n1480684\r\n\r\ntime:  27.707138347625733\r\n```\r\n\r\n```\r\ntest_fn:  test_multivariate\r\nn:  5000\r\nuse_GPU:  False\r\ncovariance_with_batch_dim:  False \r\n\r\n107904\r\n107904\r\n109436\r\n109436\r\n109700\r\n\r\ntime:  0.008288921689987183\r\n```\r\n\r\n```\r\ntest_fn:  test_multivariate\r\nn:  50\r\nuse_GPU:  True\r\ncovariance_with_batch_dim:  False \r\n\r\n1467364\r\n1468676\r\n1468676\r\n1468680\r\n1468680\r\n\r\ntime:  0.037353959083557126\r\n```\r\n\r\nTesting potrf\r\n\r\n```\r\ntest_fn:  test_potrf\r\nn:  5\r\nuse_GPU:  False\r\ncovariance_with_batch_dim:  True \r\n\r\n116984\r\n117300\r\n117672\r\n118032\r\n118380\r\n\r\ntime:  0.06480374336242675\r\n```\r\n\r\n```\r\ntest_fn:  test_potrf\r\nn:  5\r\nuse_GPU:  True\r\ncovariance_with_batch_dim:  True \r\n\r\n1476688\r\n1477008\r\n1477320\r\n1477916\r\n1478168\r\n\r\ntime:  26.757283926010132\r\n```\r\n\r\n```\r\ntest_fn:  test_potrf\r\nn:  50000\r\nuse_GPU:  False\r\ncovariance_with_batch_dim:  False \r\n\r\n108420\r\n109720\r\n109984\r\n110248\r\n110512\r\n\r\ntime:  0.008067794122695923\r\n```\r\n\r\n```\r\ntest_fn:  test_potrf\r\nn:  5\r\nuse_GPU:  True\r\ncovariance_with_batch_dim:  False \r\n\r\n1468760\r\n1469664\r\n1469680\r\n1469680\r\n1469680\r\n\r\ntime:  0.2711141109466553\r\n```\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.5.0a0+e9ad743\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.88\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 396.54\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] magma-cuda91              2.3.0                         1    pytorch\r\n[conda] torch                     0.5.0a0+e9ad743           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchnet                  0.0.4                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n\r\nPytorch is used in docker container\r\npip version:\r\npip 18.0 from /opt/conda/lib/python3.6/site-packages/pip (python 3.6)\r\n"}