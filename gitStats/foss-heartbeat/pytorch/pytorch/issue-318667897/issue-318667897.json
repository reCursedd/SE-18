{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7071", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7071/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7071/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7071/events", "html_url": "https://github.com/pytorch/pytorch/issues/7071", "id": 318667897, "node_id": "MDU6SXNzdWUzMTg2Njc4OTc=", "number": 7071, "title": "DataParallel spills memory to GPU #0", "user": {"login": "deepbrain", "id": 10003025, "node_id": "MDQ6VXNlcjEwMDAzMDI1", "avatar_url": "https://avatars3.githubusercontent.com/u/10003025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepbrain", "html_url": "https://github.com/deepbrain", "followers_url": "https://api.github.com/users/deepbrain/followers", "following_url": "https://api.github.com/users/deepbrain/following{/other_user}", "gists_url": "https://api.github.com/users/deepbrain/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepbrain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepbrain/subscriptions", "organizations_url": "https://api.github.com/users/deepbrain/orgs", "repos_url": "https://api.github.com/users/deepbrain/repos", "events_url": "https://api.github.com/users/deepbrain/events{/privacy}", "received_events_url": "https://api.github.com/users/deepbrain/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-28T20:52:19Z", "updated_at": "2018-11-09T19:30:37Z", "closed_at": "2018-05-16T18:02:36Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>on a multi GPU system, if a GPU != 0 is used, pytorch will still allocate some memory on the GPU 0 - see the nvidia-smi screenshot below.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch.optim <span class=\"pl-k\">as</span> optim<span class=\"pl-c1\">......</span>..\n\ntorch.backends.cudnn.benchmark <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">TestNet</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(TestNet, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.net1 <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">200</span>)\n        <span class=\"pl-c1\">self</span>.net2 <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">200</span>, <span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">self</span>.bn <span class=\"pl-k\">=</span> nn.BatchNorm1d(<span class=\"pl-c1\">200</span>)\n        <span class=\"pl-c1\">self</span>.sigmoid <span class=\"pl-k\">=</span> nn.Sigmoid()\n        <span class=\"pl-c1\">self</span>.ReLU <span class=\"pl-k\">=</span> nn.ReLU(<span class=\"pl-v\">inplace</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n        <span class=\"pl-c1\">self</span>.drop <span class=\"pl-k\">=</span> nn.Dropout(<span class=\"pl-c1\">0.5</span>)\n<span class=\"pl-c1\">...............</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">V</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.sigmoid(<span class=\"pl-c1\">self</span>.net2(<span class=\"pl-c1\">self</span>.drop(<span class=\"pl-c1\">self</span>.ReLU(<span class=\"pl-c1\">self</span>.bn(<span class=\"pl-c1\">self</span>.net1(V)))))).squeeze().\n\n\n<span class=\"pl-c1\">GPU</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\nnet <span class=\"pl-k\">=</span> TestNet()\ncriterion <span class=\"pl-k\">=</span> nn.BCELoss()\nnet.cuda(<span class=\"pl-c1\">GPU</span>)\ncriterion.cuda(<span class=\"pl-c1\">GPU</span>)\nV <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>)).cuda(<span class=\"pl-c1\">GPU</span>)\nlabel <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">100</span>)).cuda(<span class=\"pl-c1\">GPU</span>)\noptim_betas <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">0.9</span>, <span class=\"pl-c1\">0.999</span>)\noptimizer <span class=\"pl-k\">=</span> optim.Adam(<span class=\"pl-c1\">filter</span>(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">p</span>: p.requires_grad, net.parameters()), <span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.01</span>, <span class=\"pl-v\">betas</span><span class=\"pl-k\">=</span>optim_betas)\n\nnet.train()\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1000000</span>):\n    net.zero_grad()\n    r <span class=\"pl-k\">=</span> net(V)\n    err <span class=\"pl-k\">=</span> criterion(r, label)\n    err.backward()<span class=\"pl-c1\">...</span>\n</pre></div>\n<p>tester@NEWTITAN:~$ nvidia-smi<br>\nSat Apr 28 23:45:03 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |<br>\n| 23%   33C    P2    57W / 250W |    401MiB / 12189MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |<br>\n| 29%   33C    P2    58W / 250W |    549MiB / 11172MiB |      6%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |<br>\n| 29%   36C    P8    10W / 250W |     10MiB / 11172MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1262      C   python                                       391MiB |<br>\n|    1      1262      C   python                                       539MiB |<br>\n+-----------------------------------------------------------------------------+</p>", "body_text": "Issue description\non a multi GPU system, if a GPU != 0 is used, pytorch will still allocate some memory on the GPU 0 - see the nvidia-smi screenshot below.\nCode example\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.optim as optim........\n\ntorch.backends.cudnn.benchmark = True\n\nclass TestNet(nn.Module):\n    def __init__(self):\n        super(TestNet, self).__init__()\n        self.net1 = nn.Linear(100, 200)\n        self.net2 = nn.Linear(200, 1)\n        self.bn = nn.BatchNorm1d(200)\n        self.sigmoid = nn.Sigmoid()\n        self.ReLU = nn.ReLU(inplace=False)\n        self.drop = nn.Dropout(0.5)\n...............\n    def forward(self, V):\n        return self.sigmoid(self.net2(self.drop(self.ReLU(self.bn(self.net1(V)))))).squeeze().\n\n\nGPU = 1\nnet = TestNet()\ncriterion = nn.BCELoss()\nnet.cuda(GPU)\ncriterion.cuda(GPU)\nV = Variable(torch.randn(100, 100)).cuda(GPU)\nlabel = Variable(torch.randn(100)).cuda(GPU)\noptim_betas = (0.9, 0.999)\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01, betas=optim_betas)\n\nnet.train()\nfor i in range(0,1000000):\n    net.zero_grad()\n    r = net(V)\n    err = criterion(r, label)\n    err.backward()...\n\ntester@NEWTITAN:~$ nvidia-smi\nSat Apr 28 23:45:03 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\n| 23%   33C    P2    57W / 250W |    401MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n| 29%   33C    P2    58W / 250W |    549MiB / 11172MiB |      6%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n| 29%   36C    P8    10W / 250W |     10MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1262      C   python                                       391MiB |\n|    1      1262      C   python                                       539MiB |\n+-----------------------------------------------------------------------------+", "body": "## Issue description\r\n\r\non a multi GPU system, if a GPU != 0 is used, pytorch will still allocate some memory on the GPU 0 - see the nvidia-smi screenshot below.\r\n\r\n## Code example\r\n\r\n```python \r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport torch.optim as optim........\r\n\r\ntorch.backends.cudnn.benchmark = True\r\n\r\nclass TestNet(nn.Module):\r\n    def __init__(self):\r\n        super(TestNet, self).__init__()\r\n        self.net1 = nn.Linear(100, 200)\r\n        self.net2 = nn.Linear(200, 1)\r\n        self.bn = nn.BatchNorm1d(200)\r\n        self.sigmoid = nn.Sigmoid()\r\n        self.ReLU = nn.ReLU(inplace=False)\r\n        self.drop = nn.Dropout(0.5)\r\n...............\r\n    def forward(self, V):\r\n        return self.sigmoid(self.net2(self.drop(self.ReLU(self.bn(self.net1(V)))))).squeeze().\r\n\r\n\r\nGPU = 1\r\nnet = TestNet()\r\ncriterion = nn.BCELoss()\r\nnet.cuda(GPU)\r\ncriterion.cuda(GPU)\r\nV = Variable(torch.randn(100, 100)).cuda(GPU)\r\nlabel = Variable(torch.randn(100)).cuda(GPU)\r\noptim_betas = (0.9, 0.999)\r\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01, betas=optim_betas)\r\n\r\nnet.train()\r\nfor i in range(0,1000000):\r\n    net.zero_grad()\r\n    r = net(V)\r\n    err = criterion(r, label)\r\n    err.backward()...\r\n\r\n```\r\ntester@NEWTITAN:~$ nvidia-smi\r\nSat Apr 28 23:45:03 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\r\n| 23%   33C    P2    57W / 250W |    401MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\r\n| 29%   33C    P2    58W / 250W |    549MiB / 11172MiB |      6%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n| 29%   36C    P8    10W / 250W |     10MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1262      C   python                                       391MiB |\r\n|    1      1262      C   python                                       539MiB |\r\n+-----------------------------------------------------------------------------+\r\n"}