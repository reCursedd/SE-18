{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1106", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1106/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1106/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1106/events", "html_url": "https://github.com/pytorch/pytorch/issues/1106", "id": 217046872, "node_id": "MDU6SXNzdWUyMTcwNDY4NzI=", "number": 1106, "title": "Validation split with Dataloader/Dataset", "user": {"login": "sudarshan85", "id": 488428, "node_id": "MDQ6VXNlcjQ4ODQyOA==", "avatar_url": "https://avatars1.githubusercontent.com/u/488428?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sudarshan85", "html_url": "https://github.com/sudarshan85", "followers_url": "https://api.github.com/users/sudarshan85/followers", "following_url": "https://api.github.com/users/sudarshan85/following{/other_user}", "gists_url": "https://api.github.com/users/sudarshan85/gists{/gist_id}", "starred_url": "https://api.github.com/users/sudarshan85/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sudarshan85/subscriptions", "organizations_url": "https://api.github.com/users/sudarshan85/orgs", "repos_url": "https://api.github.com/users/sudarshan85/repos", "events_url": "https://api.github.com/users/sudarshan85/events{/privacy}", "received_events_url": "https://api.github.com/users/sudarshan85/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-03-26T11:56:02Z", "updated_at": "2018-07-23T19:06:01Z", "closed_at": "2017-03-26T17:38:48Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I've been searching for a way to do this but didn't come across any solution in the docs/tutorials/forums. I'm not sure whether its a feature and I don't know how to use it or whether its not implemented at all (if not just wanted to throw it out here to be considered). I'm new here and I'm working with the CIFAR10 dataset to start and get familiar with the pytorch framework.</p>\n<p>In the <a href=\"http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\" rel=\"nofollow\">tutorials</a>, the data set is loaded and split into the trainset and test by using the train flag in the arguments. This is nice, but it doesn't give a validation set to work with for hyperparameter tuning.</p>\n<p>Was this intentional or is there anyway to do this with dataloader? In particular, I was wonder whether the sequence of: (1) train mini-batches for n iterations keep track of acc and loss, (2) test on validation set, record acc and loss, (3) sample new hyperparameters; rinse and repeat (similar to what I've done in the cs231n Stanford course).</p>\n<p>Is there a way to do this in the current framework? I can imagine doing this I have manually loaded the data  (maybe using numpy) and have my (X_train, y_train, X_dev, y_dev, X_test, y_test) tuple and proceed in the fashion I've stated above, but I just wanted to check in here first.</p>\n<p>Thanks.</p>", "body_text": "Hi,\nI've been searching for a way to do this but didn't come across any solution in the docs/tutorials/forums. I'm not sure whether its a feature and I don't know how to use it or whether its not implemented at all (if not just wanted to throw it out here to be considered). I'm new here and I'm working with the CIFAR10 dataset to start and get familiar with the pytorch framework.\nIn the tutorials, the data set is loaded and split into the trainset and test by using the train flag in the arguments. This is nice, but it doesn't give a validation set to work with for hyperparameter tuning.\nWas this intentional or is there anyway to do this with dataloader? In particular, I was wonder whether the sequence of: (1) train mini-batches for n iterations keep track of acc and loss, (2) test on validation set, record acc and loss, (3) sample new hyperparameters; rinse and repeat (similar to what I've done in the cs231n Stanford course).\nIs there a way to do this in the current framework? I can imagine doing this I have manually loaded the data  (maybe using numpy) and have my (X_train, y_train, X_dev, y_dev, X_test, y_test) tuple and proceed in the fashion I've stated above, but I just wanted to check in here first.\nThanks.", "body": "Hi,\r\n\r\nI've been searching for a way to do this but didn't come across any solution in the docs/tutorials/forums. I'm not sure whether its a feature and I don't know how to use it or whether its not implemented at all (if not just wanted to throw it out here to be considered). I'm new here and I'm working with the CIFAR10 dataset to start and get familiar with the pytorch framework. \r\n\r\nIn the [tutorials](http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py), the data set is loaded and split into the trainset and test by using the train flag in the arguments. This is nice, but it doesn't give a validation set to work with for hyperparameter tuning.\r\n\r\nWas this intentional or is there anyway to do this with dataloader? In particular, I was wonder whether the sequence of: (1) train mini-batches for n iterations keep track of acc and loss, (2) test on validation set, record acc and loss, (3) sample new hyperparameters; rinse and repeat (similar to what I've done in the cs231n Stanford course). \r\n\r\nIs there a way to do this in the current framework? I can imagine doing this I have manually loaded the data  (maybe using numpy) and have my (X_train, y_train, X_dev, y_dev, X_test, y_test) tuple and proceed in the fashion I've stated above, but I just wanted to check in here first.\r\n\r\nThanks.\r\n "}