{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/224324979", "pull_request_review_id": 163661144, "id": 224324979, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNDMyNDk3OQ==", "diff_hunk": "@@ -0,0 +1,249 @@\n+from __future__ import print_function\n+import os\n+import sys\n+import inspect\n+\n+needed_modules = set()\n+\n+\n+def type_to_python(typename):\n+    typename = {'int64_t': 'int',\n+                'Scalar': 'Union[float, int]',\n+                'ScalarType': 'dtype',\n+                'Device': 'Union[device, str, None]',\n+                'IntList': 'Union[Tuple[int, ...], List[int, ...]]',\n+                'Tensor?': 'Optional[Tensor]',\n+                'Tensor': 'Tensor',\n+                'bool': 'bool',\n+                'double': 'float',\n+                'Generator *': 'Generator',\n+                'Generator*': 'Generator',\n+                'std::vector<Tensor>': 'Union[Tuple[Tensor, ...],List[Tensor, ...]]',\n+                'TensorList': 'Union[Tuple[Tensor, ...],List[Tensor, ...]]',\n+                'Storage': 'Storage',  # inaccurate (FloatStorage...)\n+                'SparseTensorRef': 'Tensor',\n+                'void': 'None',\n+                'Layout': 'layout',\n+                'void*': 'int',  # dataptr\n+                'std::string': 'str',\n+                'real': 'Union[float, int]',\n+                'accreal': 'Union[float, int]',\n+                'IntegerTensor': 'Tensor',\n+                'BoolTensor': 'Tensor',\n+                'IndexTensor': 'Tensor',\n+                }[typename]\n+    # handle IntList[]\n+    return typename\n+\n+\n+def arg_to_type_hint(arg):\n+    name = arg['name']\n+    if name == 'from':  # keyword...\n+        name += '_'\n+    typename = type_to_python(arg['dynamic_type'])\n+    if arg.get('is_nullable'):\n+        typename = 'Optional[' + typename + ']'\n+    if 'default' in arg:\n+        default = '=' + str(arg['default'])\n+    else:\n+        default = ''\n+    return name + ': ' + typename + default\n+\n+\n+def generate_type_hints(fname, decls, is_tensor=False):\n+    type_hints = []\n+    dnames = ([d['name'] for d in decls])\n+    has_out = fname + '_out' in dnames\n+    if has_out:\n+        decls = [d for d in decls if d['name'] != fname + '_out']\n+    for decl in decls:\n+        skip = 'Type' in [a['dynamic_type'] for a in decl['arguments']]\n+        if not skip:\n+            has_tensor_options = 'TensorOptions' in [a['dynamic_type'] for a in decl['arguments']]\n+            python_args = [arg_to_type_hint(a) for a in decl['arguments'] if a['dynamic_type'] != 'TensorOptions']\n+            if is_tensor:\n+                if 'self: Tensor' in python_args:\n+                    python_args.remove('self: Tensor')\n+                    python_args = ['self'] + python_args\n+                else:\n+                    raise Exception(\"method without self is unexpected\")\n+            if has_out:\n+                python_args += ['*', 'out: Optional[Tensor]=None']\n+            if has_tensor_options:\n+                if '*' not in python_args:\n+                    python_args.append('*')\n+                python_args += [\"dtype: dtype=None\",\n+                                \"layout: layout=torch.strided\",\n+                                \"device: Optional[device]=None\",\n+                                \"requires_grad:bool=False\"]\n+            python_args_s = ', '.join(python_args)\n+            python_returns = [type_to_python(r['dynamic_type']) for r in decl['returns']]\n+            if len(python_returns) > 1:\n+                python_returns_s = 'Tuple[' + ', '.join(python_returns) + ']'\n+            else:\n+                python_returns_s = python_returns[0]\n+            type_hint = \"def {}({}) -> {}: ...\".format(fname, python_args_s, python_returns_s)\n+            numargs = len(decl['arguments'])\n+            have_vararg_version = (numargs > 0 and decl['arguments'][0]['dynamic_type'] in {'IntList', 'TensorList'} and\n+                                   (numargs == 1 or python_args[1] == '*'))\n+            if len(decls) > 1 or have_vararg_version:\n+                type_hint = \"@overload\\n\" + type_hint\n+            type_hints.append(type_hint)\n+            if have_vararg_version:\n+                typelist = decl['arguments'][0]['dynamic_type']\n+                if typelist == 'IntList':\n+                    vararg_type = 'int'\n+                else:\n+                    vararg_type = 'Tensor'\n+                # replace first argument and eliminate '*' if present\n+                python_args = ['*' + decl['arguments'][0]['name'] + ': ' + vararg_type] + python_args[2:]\n+                python_args_s = ', '.join(python_args)\n+                type_hint = \"@overload\\ndef {}({}) -> {}: ...\".format(fname, python_args_s, python_returns_s)\n+                type_hints.append(type_hint)\n+    return type_hints\n+\n+\n+def parameters_from_signature(sig):\n+    # adapted from standard library inspect\n+    result = []\n+    render_pos_only_separator = False\n+    render_kw_only_separator = True\n+    for param in sig.parameters.values():\n+        kind = param.kind\n+        formatted = param._name\n+\n+        if param._annotation is not inspect._empty:\n+            formatted = '{}:{}'.format(formatted, inspect.formatannotation(param._annotation))\n+\n+        if param._default is not inspect._empty:\n+            if type(param._default).__name__ == 'module':  # better way?\n+                default_repr = param._default.__name__\n+                needed_modules.add(default_repr)\n+            else:\n+                default_repr = repr(param._default)\n+            formatted = '{}={}'.format(formatted, default_repr)\n+\n+        if kind == inspect._VAR_POSITIONAL:\n+            formatted = '*' + formatted\n+        elif kind == inspect._VAR_KEYWORD:\n+            formatted = '**' + formatted\n+\n+        if kind == inspect._POSITIONAL_ONLY:\n+            render_pos_only_separator = True\n+        elif render_pos_only_separator:\n+            result.append('/')\n+            render_pos_only_separator = False\n+\n+        if kind == inspect._VAR_POSITIONAL:\n+            render_kw_only_separator = False\n+        elif kind == inspect._KEYWORD_ONLY and render_kw_only_separator:\n+            result.append('*')\n+            render_kw_only_separator = False\n+\n+        formatted = formatted.replace('torch.Tensor', 'Tensor')\n+        result.append(formatted)\n+\n+    if render_pos_only_separator:\n+        result.append('/')\n+    return result\n+\n+\n+def type_hint_from_python_fn(fname, fn):\n+    sig = inspect.signature(fn)\n+    python_parameters = parameters_from_signature(sig)\n+\n+    return_annotation = None\n+    if sig.return_annotation is not inspect._empty:\n+        return_annotation = inspect.formatannotation(sig.return_annotation)\n+        return_annotation = return_annotation.replace('torch.Tensor', 'Tensor')\n+\n+    python_parameters = ', '.join(python_parameters)\n+    if return_annotation:\n+        return [\"def {}({}) -> {}: ...\".format(fname, python_parameters, return_annotation)]\n+    else:\n+        return [\"def {}({}): ...\".format(fname, python_parameters, return_annotation)]\n+\n+\n+def do_gen_py(build_lib_path):\n+    while '' in sys.path:", "path": "tools/pyi/gen_pyi.py", "position": 303, "original_position": 168, "commit_id": "4538b13a88cdc2fe41f9efe11b31536ae09b8f37", "original_commit_id": "a327e187b778667a574b2997f950c46d73a2c7b6", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "lol", "created_at": "2018-10-11T06:12:05Z", "updated_at": "2018-11-23T15:52:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/12500#discussion_r224324979", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12500", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/224324979"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12500#discussion_r224324979"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12500"}}, "body_html": "<p>lol</p>", "body_text": "lol"}