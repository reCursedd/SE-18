{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428832637", "html_url": "https://github.com/pytorch/pytorch/pull/12500#issuecomment-428832637", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12500", "id": 428832637, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODgzMjYzNw==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-11T06:10:47Z", "updated_at": "2018-10-11T06:10:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Re testing: So the type hints should ideally have two properties:</p>\n<ul>\n<li>\n<p>Code satisfying the type hints will be \"correct\" in some way. One could try to check this using an approach similar to the one you mention, parsing the error messages. If we are off here, programs/people will have wrong ideas about what can be passed, but it isn't worse than now.</p>\n</li>\n<li>\n<p>Any correct code will satisfy the type hint restrictions.<br>\nI think this may be more important property - people will get upset if their correct code is marked as wrong by checkers. One testing approach I could think of is to put \"known good code\" (our tests? the examples/tutorials?) through a checker (mypy?) and see if it passes. The question is whether the tests are a tad too dynamic to be statically checked and where to get good test code from if they are.</p>\n</li>\n</ul>", "body_text": "Re testing: So the type hints should ideally have two properties:\n\n\nCode satisfying the type hints will be \"correct\" in some way. One could try to check this using an approach similar to the one you mention, parsing the error messages. If we are off here, programs/people will have wrong ideas about what can be passed, but it isn't worse than now.\n\n\nAny correct code will satisfy the type hint restrictions.\nI think this may be more important property - people will get upset if their correct code is marked as wrong by checkers. One testing approach I could think of is to put \"known good code\" (our tests? the examples/tutorials?) through a checker (mypy?) and see if it passes. The question is whether the tests are a tad too dynamic to be statically checked and where to get good test code from if they are.", "body": "Re testing: So the type hints should ideally have two properties:\r\n- Code satisfying the type hints will be \"correct\" in some way. One could try to check this using an approach similar to the one you mention, parsing the error messages. If we are off here, programs/people will have wrong ideas about what can be passed, but it isn't worse than now.\r\n\r\n- Any correct code will satisfy the type hint restrictions. \r\n  I think this may be more important property - people will get upset if their correct code is marked as wrong by checkers. One testing approach I could think of is to put \"known good code\" (our tests? the examples/tutorials?) through a checker (mypy?) and see if it passes. The question is whether the tests are a tad too dynamic to be statically checked and where to get good test code from if they are.\r\n"}