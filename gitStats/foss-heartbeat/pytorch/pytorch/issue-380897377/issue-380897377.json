{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13991", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13991/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13991/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13991/events", "html_url": "https://github.com/pytorch/pytorch/issues/13991", "id": 380897377, "node_id": "MDU6SXNzdWUzODA4OTczNzc=", "number": 13991, "title": "[jit] ScriptModule with Dropout layers can't be set to eval", "user": {"login": "Evpok", "id": 1656541, "node_id": "MDQ6VXNlcjE2NTY1NDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1656541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Evpok", "html_url": "https://github.com/Evpok", "followers_url": "https://api.github.com/users/Evpok/followers", "following_url": "https://api.github.com/users/Evpok/following{/other_user}", "gists_url": "https://api.github.com/users/Evpok/gists{/gist_id}", "starred_url": "https://api.github.com/users/Evpok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Evpok/subscriptions", "organizations_url": "https://api.github.com/users/Evpok/orgs", "repos_url": "https://api.github.com/users/Evpok/repos", "events_url": "https://api.github.com/users/Evpok/events{/privacy}", "received_events_url": "https://api.github.com/users/Evpok/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-11-14T21:37:02Z", "updated_at": "2018-11-21T02:32:54Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Adding a <code>Dropout</code> layer to a <code>jit.ScriptModule</code> makes it impossible to set that module to eval mode.</p>\n<h2>MWE</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.jit\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">jit</span>.<span class=\"pl-e\">ScriptModule</span>):\n\t<span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n\t\t<span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n\t\t<span class=\"pl-c1\">self</span>.linear <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>)\n\t\t<span class=\"pl-c1\">self</span>.dropout <span class=\"pl-k\">=</span> torch.nn.Dropout(<span class=\"pl-c1\">0.1</span>)\n\n\t<span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n\t\tx <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.dropout(x)\n\t\tx <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.linear(x)\n\t\t<span class=\"pl-k\">return</span> x\n\nn <span class=\"pl-k\">=</span> Net()\nn.eval()</pre></div>\n<p>Fails with</p>\n<pre><code>RuntimeError: attempting to re-assign constant 'training'\n</code></pre>\n<h2>Environment</h2>\n<p>PyTorch version: 1.0.0.dev20181109<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: KDE neon Developer Edition<br>\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0<br>\nCMake version: version 3.10.2</p>\n<p>Python version: 3.7<br>\nIs CUDA available: No</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.15.4)<br>\n[pip3] pytorch-ignite (0.1.1)<br>\n[pip3] torch-nightly (1.0.0.dev20181109)<br>\n[pip3] torchtext (0.3.1)</p>", "body_text": "\ud83d\udc1b Bug\nAdding a Dropout layer to a jit.ScriptModule makes it impossible to set that module to eval mode.\nMWE\nimport torch\nimport torch.jit\n\nclass Net(torch.jit.ScriptModule):\n\tdef __init__(self):\n\t\tsuper().__init__()\n\t\tself.linear = torch.nn.Linear(10, 10)\n\t\tself.dropout = torch.nn.Dropout(0.1)\n\n\tdef forward(self, x):\n\t\tx = self.dropout(x)\n\t\tx = self.linear(x)\n\t\treturn x\n\nn = Net()\nn.eval()\nFails with\nRuntimeError: attempting to re-assign constant 'training'\n\nEnvironment\nPyTorch version: 1.0.0.dev20181109\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: KDE neon Developer Edition\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\nCMake version: version 3.10.2\nPython version: 3.7\nIs CUDA available: No\nVersions of relevant libraries:\n[pip3] numpy (1.15.4)\n[pip3] pytorch-ignite (0.1.1)\n[pip3] torch-nightly (1.0.0.dev20181109)\n[pip3] torchtext (0.3.1)", "body": "## \ud83d\udc1b Bug\r\n\r\nAdding a `Dropout` layer to a `jit.ScriptModule` makes it impossible to set that module to eval mode.\r\n\r\n## MWE\r\n\r\n```python\r\nimport torch\r\nimport torch.jit\r\n\r\nclass Net(torch.jit.ScriptModule):\r\n\tdef __init__(self):\r\n\t\tsuper().__init__()\r\n\t\tself.linear = torch.nn.Linear(10, 10)\r\n\t\tself.dropout = torch.nn.Dropout(0.1)\r\n\r\n\tdef forward(self, x):\r\n\t\tx = self.dropout(x)\r\n\t\tx = self.linear(x)\r\n\t\treturn x\r\n\r\nn = Net()\r\nn.eval()\r\n```\r\nFails with\r\n\r\n```\r\nRuntimeError: attempting to re-assign constant 'training'\r\n```\r\n\r\n## Environment\r\nPyTorch version: 1.0.0.dev20181109\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: KDE neon Developer Edition\r\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.15.4)\r\n[pip3] pytorch-ignite (0.1.1)\r\n[pip3] torch-nightly (1.0.0.dev20181109)\r\n[pip3] torchtext (0.3.1)\r\n"}