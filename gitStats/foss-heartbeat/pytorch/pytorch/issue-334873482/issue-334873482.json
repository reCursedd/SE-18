{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8789", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8789/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8789/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8789/events", "html_url": "https://github.com/pytorch/pytorch/issues/8789", "id": 334873482, "node_id": "MDU6SXNzdWUzMzQ4NzM0ODI=", "number": 8789, "title": "nn.AdaptiveMaxPool3d does not support tuple composed by None", "user": {"login": "Rhythmblue", "id": 26090712, "node_id": "MDQ6VXNlcjI2MDkwNzEy", "avatar_url": "https://avatars0.githubusercontent.com/u/26090712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rhythmblue", "html_url": "https://github.com/Rhythmblue", "followers_url": "https://api.github.com/users/Rhythmblue/followers", "following_url": "https://api.github.com/users/Rhythmblue/following{/other_user}", "gists_url": "https://api.github.com/users/Rhythmblue/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rhythmblue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rhythmblue/subscriptions", "organizations_url": "https://api.github.com/users/Rhythmblue/orgs", "repos_url": "https://api.github.com/users/Rhythmblue/repos", "events_url": "https://api.github.com/users/Rhythmblue/events{/privacy}", "received_events_url": "https://api.github.com/users/Rhythmblue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-06-22T13:13:56Z", "updated_at": "2018-06-22T17:29:55Z", "closed_at": "2018-06-22T17:29:54Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Doc of  <a href=\"https://pytorch.org/docs/stable/nn.html#adaptivemaxpool3d\" rel=\"nofollow\">torch.nn.AdaptiveMaxPool3d</a>:<br>\noutput_size \u2013 the target output size of the image of the form D x H x W. Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or None which means the size will be the same as that of the input.</p>\n<p>The option of (7, None, None) cannot work on 0.4.0 now. It can work on 0.3.0.<br>\nI don't know how to fix it. Maybe a simple check statement can solve it.</p>\n<h2>Code</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\nm <span class=\"pl-k\">=</span> nn.AdaptiveMaxPool3d((<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>))\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">8</span>)\noutput <span class=\"pl-k\">=</span> m(<span class=\"pl-c1\">input</span>)</pre></div>\n<h2>Result</h2>\n<pre><code>Traceback (most recent call last):\n  File \"test.py\", line 6, in &lt;module&gt;\n    output = m(input)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/pooling.py\", line 885, in forward\n    return F.adaptive_max_pool3d(input, self.output_size, self.return_indices)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py\", line 506, in adaptive_max_pool3d\n    ret = torch._C._nn.adaptive_max_pool3d(input, output_size)\nTypeError: an integer is required (got type NoneType)\n\n</code></pre>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.3 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti<br>\nGPU 3: GeForce GTX 1080 Ti</p>\n<p>Nvidia driver version: 384.111<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a<br>\n/usr/local/matlab/2018a/bin/glnxa64/libcudnn.so.7.0.3</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.13.3)<br>\n[conda] cuda90                    1.0                  h6433d27_0    <a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\" rel=\"nofollow\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch</a><br>\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  <a href=\"https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\" rel=\"nofollow\">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch</a><br>\n[conda] torchvision               0.2.1                    py36_0    <a href=\"https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge\" rel=\"nofollow\">https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge</a></p>", "body_text": "Issue description\nDoc of  torch.nn.AdaptiveMaxPool3d:\noutput_size \u2013 the target output size of the image of the form D x H x W. Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or None which means the size will be the same as that of the input.\nThe option of (7, None, None) cannot work on 0.4.0 now. It can work on 0.3.0.\nI don't know how to fix it. Maybe a simple check statement can solve it.\nCode\nimport torch\nimport torch.nn as nn\n\nm = nn.AdaptiveMaxPool3d((7, None, None))\ninput = torch.randn(1, 64, 10, 9, 8)\noutput = m(input)\nResult\nTraceback (most recent call last):\n  File \"test.py\", line 6, in <module>\n    output = m(input)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/pooling.py\", line 885, in forward\n    return F.adaptive_max_pool3d(input, self.output_size, self.return_indices)\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py\", line 506, in adaptive_max_pool3d\n    ret = torch._C._nn.adaptive_max_pool3d(input, output_size)\nTypeError: an integer is required (got type NoneType)\n\n\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\nNvidia driver version: 384.111\ncuDNN version: Probably one of the following:\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\n/usr/local/matlab/2018a/bin/glnxa64/libcudnn.so.7.0.3\nVersions of relevant libraries:\n[pip3] numpy (1.13.3)\n[conda] cuda90                    1.0                  h6433d27_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\n[conda] torchvision               0.2.1                    py36_0    https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge", "body": "## Issue description\r\nDoc of  [torch.nn.AdaptiveMaxPool3d](https://pytorch.org/docs/stable/nn.html#adaptivemaxpool3d):\r\noutput_size \u2013 the target output size of the image of the form D x H x W. Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or None which means the size will be the same as that of the input.\r\n\r\nThe option of (7, None, None) cannot work on 0.4.0 now. It can work on 0.3.0.\r\nI don't know how to fix it. Maybe a simple check statement can solve it.\r\n\r\n## Code\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nm = nn.AdaptiveMaxPool3d((7, None, None))\r\ninput = torch.randn(1, 64, 10, 9, 8)\r\noutput = m(input)\r\n```\r\n\r\n## Result\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 6, in <module>\r\n    output = m(input)\r\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/modules/pooling.py\", line 885, in forward\r\n    return F.adaptive_max_pool3d(input, self.output_size, self.return_indices)\r\n  File \"/home/zhouhao/lib_my/miniconda3/envs/pytorch4/lib/python3.6/site-packages/torch/nn/functional.py\", line 506, in adaptive_max_pool3d\r\n    ret = torch._C._nn.adaptive_max_pool3d(input, output_size)\r\nTypeError: an integer is required (got type NoneType)\r\n\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration:\r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 384.111\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\r\n/usr/local/matlab/2018a/bin/glnxa64/libcudnn.so.7.0.3\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.13.3)\r\n[conda] cuda90                    1.0                  h6433d27_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\r\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch\r\n[conda] torchvision               0.2.1                    py36_0    https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge\r\n"}