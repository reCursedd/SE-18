{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10096", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10096/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10096/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10096/events", "html_url": "https://github.com/pytorch/pytorch/issues/10096", "id": 346374545, "node_id": "MDU6SXNzdWUzNDYzNzQ1NDU=", "number": 10096, "title": "[jit] Proposal: fuse add ops that expand tensors", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-07-31T22:01:08Z", "updated_at": "2018-08-17T23:05:14Z", "closed_at": "2018-08-17T23:05:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Let's say we have <code>torch.add(self, other)</code> and <code>self</code> has size <code>(64, 2048)</code>, while other has size <code>(2048)</code>. This isn't fusable into a FusionGroup because the inputs (self, other) have different sizes.</p>\n<p>However, <code>other</code> can be expanded into the size of <code>self</code>. If we insert an <code>expand</code> node, then the operation will be fusable into a FusionGroup. The cost of an expand is around 3 microseconds, which is less than launching a kernel specifically for adding <code>self, other</code> (launch overhead of 6-12 microseconds).</p>\n<p>This matters for LSTM perf: the following graph is the nvprof output for a lstm cell's forward pass.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5652049/43489620-9b9a95b0-94eb-11e8-850f-f4199c9d51d5.png\"><img src=\"https://user-images.githubusercontent.com/5652049/43489620-9b9a95b0-94eb-11e8-850f-f4199c9d51d5.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>The two kernels after the second sgemm are add kernels that \"should\" be fusable into the FusionGroup kernel on the right.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>", "body_text": "Let's say we have torch.add(self, other) and self has size (64, 2048), while other has size (2048). This isn't fusable into a FusionGroup because the inputs (self, other) have different sizes.\nHowever, other can be expanded into the size of self. If we insert an expand node, then the operation will be fusable into a FusionGroup. The cost of an expand is around 3 microseconds, which is less than launching a kernel specifically for adding self, other (launch overhead of 6-12 microseconds).\nThis matters for LSTM perf: the following graph is the nvprof output for a lstm cell's forward pass.\n\nThe two kernels after the second sgemm are add kernels that \"should\" be fusable into the FusionGroup kernel on the right.\ncc @zdevito @apaszke", "body": "Let's say we have `torch.add(self, other)` and `self` has size `(64, 2048)`, while other has size `(2048)`. This isn't fusable into a FusionGroup because the inputs (self, other) have different sizes.\r\n\r\nHowever, `other` can be expanded into the size of `self`. If we insert an `expand` node, then the operation will be fusable into a FusionGroup. The cost of an expand is around 3 microseconds, which is less than launching a kernel specifically for adding `self, other` (launch overhead of 6-12 microseconds).\r\n\r\nThis matters for LSTM perf: the following graph is the nvprof output for a lstm cell's forward pass.\r\n![image](https://user-images.githubusercontent.com/5652049/43489620-9b9a95b0-94eb-11e8-850f-f4199c9d51d5.png)\r\n\r\nThe two kernels after the second sgemm are add kernels that \"should\" be fusable into the FusionGroup kernel on the right.\r\n\r\ncc @zdevito @apaszke "}