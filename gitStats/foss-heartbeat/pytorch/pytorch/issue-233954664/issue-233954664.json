{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1738", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1738/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1738/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1738/events", "html_url": "https://github.com/pytorch/pytorch/issues/1738", "id": 233954664, "node_id": "MDU6SXNzdWUyMzM5NTQ2NjQ=", "number": 1738, "title": "How do make batchnorm to maintain multiple pairs of running_mean and running_var?", "user": {"login": "zhiqiangdon", "id": 25371851, "node_id": "MDQ6VXNlcjI1MzcxODUx", "avatar_url": "https://avatars1.githubusercontent.com/u/25371851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhiqiangdon", "html_url": "https://github.com/zhiqiangdon", "followers_url": "https://api.github.com/users/zhiqiangdon/followers", "following_url": "https://api.github.com/users/zhiqiangdon/following{/other_user}", "gists_url": "https://api.github.com/users/zhiqiangdon/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhiqiangdon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhiqiangdon/subscriptions", "organizations_url": "https://api.github.com/users/zhiqiangdon/orgs", "repos_url": "https://api.github.com/users/zhiqiangdon/repos", "events_url": "https://api.github.com/users/zhiqiangdon/events{/privacy}", "received_events_url": "https://api.github.com/users/zhiqiangdon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-06T16:43:38Z", "updated_at": "2017-06-06T19:46:14Z", "closed_at": "2017-06-06T17:49:21Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>The current batchnorm implementation only has one pair of running_mean and running_var. However, some modules in the neural networks may be used twice or more in one network forward. Based on my experimental experience and also stated in paper <a href=\"https://arxiv.org/pdf/1603.09025.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1603.09025.pdf</a> , different running_mean and running_var should be computed for different iterations(or time steps). I have found in my experiments, for the same testing data, net.eval() performs much worse than net.train() (backward is turned off here). The only difference in this situation is different running_mean and running_var are used. So how to make the batchnorm to keep multiple running_mean and running_var and I can choose to use the first pair in the first iteration, the second pair in the second iteration, and so on?</p>", "body_text": "Hi,\nThe current batchnorm implementation only has one pair of running_mean and running_var. However, some modules in the neural networks may be used twice or more in one network forward. Based on my experimental experience and also stated in paper https://arxiv.org/pdf/1603.09025.pdf , different running_mean and running_var should be computed for different iterations(or time steps). I have found in my experiments, for the same testing data, net.eval() performs much worse than net.train() (backward is turned off here). The only difference in this situation is different running_mean and running_var are used. So how to make the batchnorm to keep multiple running_mean and running_var and I can choose to use the first pair in the first iteration, the second pair in the second iteration, and so on?", "body": "Hi,\r\n\r\nThe current batchnorm implementation only has one pair of running_mean and running_var. However, some modules in the neural networks may be used twice or more in one network forward. Based on my experimental experience and also stated in paper https://arxiv.org/pdf/1603.09025.pdf , different running_mean and running_var should be computed for different iterations(or time steps). I have found in my experiments, for the same testing data, net.eval() performs much worse than net.train() (backward is turned off here). The only difference in this situation is different running_mean and running_var are used. So how to make the batchnorm to keep multiple running_mean and running_var and I can choose to use the first pair in the first iteration, the second pair in the second iteration, and so on?"}