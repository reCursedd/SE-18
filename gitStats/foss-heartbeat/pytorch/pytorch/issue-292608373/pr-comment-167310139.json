{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/167310139", "pull_request_review_id": 95519085, "id": 167310139, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzMxMDEzOQ==", "diff_hunk": "@@ -3,61 +3,62 @@\n \n \n class _InstanceNorm(_BatchNorm):\n-    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=False):\n+    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=False,\n+                 track_running_stats=False):\n         super(_InstanceNorm, self).__init__(\n-            num_features, eps, momentum, affine)\n-        self._use_running_stats = False\n+            num_features, eps, momentum, affine, track_running_stats)\n \n-    def forward(self, input):\n-        b = input.size(0)\n-\n-        weight, bias = None, None\n-        if self.affine:\n-            weight = self.weight.repeat(b)\n-            bias = self.bias.repeat(b)\n-\n-        training = not self._use_running_stats\n-        return F.instance_norm(input, weight=weight, bias=bias,\n-                               saved_running_mean=self.running_mean,\n-                               saved_running_var=self.running_var,\n-                               training=training, momentum=self.momentum,\n-                               eps=self.eps, affine=self.affine)\n+    def _check_input_dim(self, input):\n+        return NotImplemented\n \n-    def use_running_stats(self, mode=True):\n-        r\"\"\"Set using running statistics or instance statistics.\n+    def forward(self, input):\n+        self._check_input_dim(input)\n \n-        Instance normalization usually use instance statistics in both training\n-        and evaluation modes. But users can set this method to use running\n-        statistics in the fashion similar to batch normalization in eval mode.\n-        \"\"\"\n-        self._use_running_stats = mode\n+        return F.instance_norm(\n+            input, self.running_mean, self.running_var, self.weight, self.bias,\n+            self.training or not self.track_running_stats, self.momentum, self.eps)\n \n \n class InstanceNorm1d(_InstanceNorm):\n-    r\"\"\"Applies Instance Normalization over a 3d input that is seen as a mini-batch.\n+    r\"\"\"Applies Instance Normalization over a 3d input (a mini-batch of 2d inputs)\n+    as described in the paper\n+    `Instance Normalization: The Missing Ingredient for Fast Stylization`_ .\n \n     .. math::\n \n         y = \\frac{x - mean[x]}{ \\sqrt{Var[x]} + \\epsilon} * gamma + beta\n \n     The mean and standard-deviation are calculated per-dimension separately\n     for each object in a mini-batch. Gamma and beta are learnable parameter vectors\n-    of size C (where C is the input size).\n+    of size C (where C is the input size) if :attr:`affine` is ``True``.\n+\n+    By default, this layer uses instance statistics computed from input data in\n+    both training and evaluation modes.\n \n-    During training, this layer keeps a running estimate of its computed mean\n-    and variance. The running sum is kept with a default momentum of 0.1.\n+    If :attr:`track_running_stats` is set to ``True``, during training this\n+    layer keeps running estimates of its computed mean and variance, which are\n+    then used for normalization during evaluation. The running estimates are\n+    kept with a default :attr:`momentum` of 0.1.\n \n-    At evaluation time (`.eval()`), the default behaviour of the InstanceNorm module stays the same\n-    i.e. running mean/variance is NOT used for normalization. One can force using stored\n-    mean and variance with `.use_running_stats(mode=True)` method, and switch back to normal\n-    behavior with `.use_running_stats(mode=False)` method.\n+    .. note::\n+        This :attr:`momentum` argument is different from one used in optimizer\n+        classes and the conventional notion of momentum. Mathematically, the\n+        update rule for running statistics here is\n+        :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x}_\\text{new} + \\text{momemtum} \\times x_t`,\n+        where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n+        new observed value.\n \n     Args:\n-        num_features: num_features from an expected input of size `batch_size x num_features x width`\n+        num_features: num_features from an expected input of size\n+            `[batch_size x num_features x width]`", "path": "torch/nn/modules/instancenorm.py", "position": null, "original_position": 84, "commit_id": "b1359c8212165027bb3a1fbf500a1328ef7e0f39", "original_commit_id": "e790c04ac7c97c33a3fc0378b6dc6a8eba1cefe8", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "body": "Should be `length` for consistency.", "created_at": "2018-02-09T18:35:44Z", "updated_at": "2018-11-23T15:39:26Z", "html_url": "https://github.com/pytorch/pytorch/pull/4922#discussion_r167310139", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4922", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/167310139"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4922#discussion_r167310139"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4922"}}, "body_html": "<p>Should be <code>length</code> for consistency.</p>", "body_text": "Should be length for consistency."}