{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/167309518", "pull_request_review_id": 95518372, "id": 167309518, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NzMwOTUxOA==", "diff_hunk": "@@ -8,43 +8,56 @@\n # TODO: use separate backend functions?\n class _BatchNorm(Module):\n \n-    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True):\n+    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n+                 track_running_stats=True):\n         super(_BatchNorm, self).__init__()\n         self.num_features = num_features\n-        self.affine = affine\n         self.eps = eps\n         self.momentum = momentum\n+        self.affine = affine\n+        self.track_running_stats = track_running_stats\n         if self.affine:\n             self.weight = Parameter(torch.Tensor(num_features))\n             self.bias = Parameter(torch.Tensor(num_features))\n         else:\n             self.register_parameter('weight', None)\n             self.register_parameter('bias', None)\n-        self.register_buffer('running_mean', torch.zeros(num_features))\n-        self.register_buffer('running_var', torch.ones(num_features))\n+        if self.track_running_stats:\n+            self.register_buffer('running_mean', torch.zeros(num_features))\n+            self.register_buffer('running_var', torch.ones(num_features))\n+        else:\n+            self.register_parameter('running_mean', None)\n+            self.register_parameter('running_var', None)\n         self.reset_parameters()\n \n     def reset_parameters(self):\n-        self.running_mean.zero_()\n-        self.running_var.fill_(1)\n+        if self.track_running_stats:\n+            self.running_mean.zero_()\n+            self.running_var.fill_(1)\n         if self.affine:\n             self.weight.data.uniform_()\n             self.bias.data.zero_()\n \n+    def _check_input_dim(self, input):\n+        return NotImplemented\n+\n     def forward(self, input):\n+        self._check_input_dim(input)\n+\n         return F.batch_norm(\n             input, self.running_mean, self.running_var, self.weight, self.bias,\n-            self.training, self.momentum, self.eps)\n+            self.training or not self.track_running_stats, self.momentum, self.eps)\n \n     def __repr__(self):\n         return ('{name}({num_features}, eps={eps}, momentum={momentum},'\n-                ' affine={affine})'\n+                ' affine={affine}, track_running_stats={track_running_stats})'\n                 .format(name=self.__class__.__name__, **self.__dict__))\n \n \n class BatchNorm1d(_BatchNorm):\n-    r\"\"\"Applies Batch Normalization over a 2d or 3d input that is seen as a\n-    mini-batch.\n+    r\"\"\"Applies Batch Normalization over a 3d input (a mini-batch of 2d inputs)", "path": "torch/nn/modules/batchnorm.py", "position": null, "original_position": 61, "commit_id": "b1359c8212165027bb3a1fbf500a1328ef7e0f39", "original_commit_id": "e790c04ac7c97c33a3fc0378b6dc6a8eba1cefe8", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "body": "Is this not still 2D and 3D? This was overloaded to do the original batch norm with N x C (e.g. fully-connected layers) and the 1D signal version N x C x L (e.g. 1D conv layers).", "created_at": "2018-02-09T18:33:15Z", "updated_at": "2018-11-23T15:39:26Z", "html_url": "https://github.com/pytorch/pytorch/pull/4922#discussion_r167309518", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4922", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/167309518"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4922#discussion_r167309518"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4922"}}, "body_html": "<p>Is this not still 2D and 3D? This was overloaded to do the original batch norm with N x C (e.g. fully-connected layers) and the 1D signal version N x C x L (e.g. 1D conv layers).</p>", "body_text": "Is this not still 2D and 3D? This was overloaded to do the original batch norm with N x C (e.g. fully-connected layers) and the 1D signal version N x C x L (e.g. 1D conv layers)."}