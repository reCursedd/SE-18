{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6863", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6863/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6863/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6863/events", "html_url": "https://github.com/pytorch/pytorch/issues/6863", "id": 316844760, "node_id": "MDU6SXNzdWUzMTY4NDQ3NjA=", "number": 6863, "title": "[PyTorch] Printing large tensors is slow", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 809246977, "node_id": "MDU6TGFiZWw4MDkyNDY5Nzc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/0.4", "name": "0.4", "color": "ff05fa", "default": false}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-04-23T14:44:40Z", "updated_at": "2018-05-08T09:08:02Z", "closed_at": "2018-04-24T20:05:08Z", "author_association": "MEMBER", "body_html": "<p>Printing large tensors is slow in master.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">1000</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">%</span>timeit <span class=\"pl-c1\">repr</span>(x)\n<span class=\"pl-c1\">1</span> loop, best of <span class=\"pl-c1\">3</span>: <span class=\"pl-c1\">21.8</span> s per loop</pre></div>\n<p>This is important because we often deal with very large tensors.</p>\n<p>Note that printing large tensors is much faster in NumPy (10,000x in this case):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">%</span>timeit <span class=\"pl-c1\">repr</span>(x.numpy())\n<span class=\"pl-c1\">100</span> loops, best of <span class=\"pl-c1\">3</span>: <span class=\"pl-c1\">2.18</span> ms per loop</pre></div>", "body_text": "Printing large tensors is slow in master.\n>>> x = torch.randn(1000, 1000, 1000)\n>>> %timeit repr(x)\n1 loop, best of 3: 21.8 s per loop\nThis is important because we often deal with very large tensors.\nNote that printing large tensors is much faster in NumPy (10,000x in this case):\n>>> %timeit repr(x.numpy())\n100 loops, best of 3: 2.18 ms per loop", "body": "Printing large tensors is slow in master.\r\n\r\n```python\r\n>>> x = torch.randn(1000, 1000, 1000)\r\n>>> %timeit repr(x)\r\n1 loop, best of 3: 21.8 s per loop\r\n```\r\n\r\nThis is important because we often deal with very large tensors.\r\n\r\nNote that printing large tensors is much faster in NumPy (10,000x in this case):\r\n\r\n```python\r\n>>> %timeit repr(x.numpy())\r\n100 loops, best of 3: 2.18 ms per loop\r\n```"}