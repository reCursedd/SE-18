{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9160", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9160/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9160/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9160/events", "html_url": "https://github.com/pytorch/pytorch/issues/9160", "id": 338139303, "node_id": "MDU6SXNzdWUzMzgxMzkzMDM=", "number": 9160, "title": "[feature request] nn.Identity", "user": {"login": "elbaro", "id": 1851290, "node_id": "MDQ6VXNlcjE4NTEyOTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1851290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elbaro", "html_url": "https://github.com/elbaro", "followers_url": "https://api.github.com/users/elbaro/followers", "following_url": "https://api.github.com/users/elbaro/following{/other_user}", "gists_url": "https://api.github.com/users/elbaro/gists{/gist_id}", "starred_url": "https://api.github.com/users/elbaro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elbaro/subscriptions", "organizations_url": "https://api.github.com/users/elbaro/orgs", "repos_url": "https://api.github.com/users/elbaro/repos", "events_url": "https://api.github.com/users/elbaro/events{/privacy}", "received_events_url": "https://api.github.com/users/elbaro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-04T05:57:52Z", "updated_at": "2018-07-04T14:24:52Z", "closed_at": "2018-07-04T14:24:52Z", "author_association": "NONE", "body_html": "<p>nn.Identity (similar to tf.identity or tf.no_op) would be useful as a placeholder.</p>\n<h2>Use cases</h2>\n<p>it is common to parameterize building blocks (e.g. ResBlock depth, Bottleneck width, etc).<br>\nnn.Identity can fill in gaps to provide a consistent architecture.</p>\n<h2>Code example</h2>\n<p>To simulate padding='SAME' in TF, nn.ZeroPad2d((0,1,0,1)) is conditionally inserted.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">SamePadding</span>(<span class=\"pl-smi\">num_inputs</span>, <span class=\"pl-smi\">num_outputs</span>, <span class=\"pl-smi\">kernel_size</span>, <span class=\"pl-smi\">stride</span>):\n    <span class=\"pl-k\">if</span> stride <span class=\"pl-k\">==</span> <span class=\"pl-c1\">2</span>:\n        <span class=\"pl-k\">return</span> nn.Sequential(\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                               <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>),\n            nn.ZeroPad2d((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>)),\n            nn.BatchNorm2d(num_outputs),\n            nn.ReLU()\n        )\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-k\">return</span> nn.Sequential(\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n                               <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>),\n            nn.ZeroPad2d((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>)),\n            nn.BatchNorm2d(num_outputs),\n            nn.ReLU()\n        )</pre></div>\n<p>By inserting <code>ZeroPad2d((0, 0, 0, 0))</code>, <code>nn.Sequential</code> is always of length 4, which makes the debugging and network surgery easier.</p>", "body_text": "nn.Identity (similar to tf.identity or tf.no_op) would be useful as a placeholder.\nUse cases\nit is common to parameterize building blocks (e.g. ResBlock depth, Bottleneck width, etc).\nnn.Identity can fill in gaps to provide a consistent architecture.\nCode example\nTo simulate padding='SAME' in TF, nn.ZeroPad2d((0,1,0,1)) is conditionally inserted.\ndef SamePadding(num_inputs, num_outputs, kernel_size, stride):\n    if stride == 2:\n        return nn.Sequential(\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, bias=False,\n                               padding=1),\n            nn.ZeroPad2d((0, 0, 0, 0)),\n            nn.BatchNorm2d(num_outputs),\n            nn.ReLU()\n        )\n    else:\n        return nn.Sequential(\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, bias=False,\n                               padding=2),\n            nn.ZeroPad2d((0, 1, 0, 1)),\n            nn.BatchNorm2d(num_outputs),\n            nn.ReLU()\n        )\nBy inserting ZeroPad2d((0, 0, 0, 0)), nn.Sequential is always of length 4, which makes the debugging and network surgery easier.", "body": "nn.Identity (similar to tf.identity or tf.no_op) would be useful as a placeholder.\r\n\r\n## Use cases\r\nit is common to parameterize building blocks (e.g. ResBlock depth, Bottleneck width, etc).\r\nnn.Identity can fill in gaps to provide a consistent architecture.\r\n\r\n## Code example\r\nTo simulate padding='SAME' in TF, nn.ZeroPad2d((0,1,0,1)) is conditionally inserted.\r\n\r\n```py\r\ndef SamePadding(num_inputs, num_outputs, kernel_size, stride):\r\n    if stride == 2:\r\n        return nn.Sequential(\r\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, bias=False,\r\n                               padding=1),\r\n            nn.ZeroPad2d((0, 0, 0, 0)),\r\n            nn.BatchNorm2d(num_outputs),\r\n            nn.ReLU()\r\n        )\r\n    else:\r\n        return nn.Sequential(\r\n            nn.ConvTranspose2d(num_inputs, num_outputs, kernel_size, stride, bias=False,\r\n                               padding=2),\r\n            nn.ZeroPad2d((0, 1, 0, 1)),\r\n            nn.BatchNorm2d(num_outputs),\r\n            nn.ReLU()\r\n        )\r\n```\r\nBy inserting `ZeroPad2d((0, 0, 0, 0))`, `nn.Sequential` is always of length 4, which makes the debugging and network surgery easier."}