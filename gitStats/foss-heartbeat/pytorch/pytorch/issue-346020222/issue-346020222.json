{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10050", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10050/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10050/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10050/events", "html_url": "https://github.com/pytorch/pytorch/issues/10050", "id": 346020222, "node_id": "MDU6SXNzdWUzNDYwMjAyMjI=", "number": 10050, "title": "Cannot export ONNX model with ELU operations", "user": {"login": "tengyifei", "id": 2877531, "node_id": "MDQ6VXNlcjI4Nzc1MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2877531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tengyifei", "html_url": "https://github.com/tengyifei", "followers_url": "https://api.github.com/users/tengyifei/followers", "following_url": "https://api.github.com/users/tengyifei/following{/other_user}", "gists_url": "https://api.github.com/users/tengyifei/gists{/gist_id}", "starred_url": "https://api.github.com/users/tengyifei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tengyifei/subscriptions", "organizations_url": "https://api.github.com/users/tengyifei/orgs", "repos_url": "https://api.github.com/users/tengyifei/repos", "events_url": "https://api.github.com/users/tengyifei/events{/privacy}", "received_events_url": "https://api.github.com/users/tengyifei/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-31T03:20:19Z", "updated_at": "2018-11-15T08:03:01Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>When I export a model to ONNX format using the tracer, the following error appears:</p>\n<pre><code>Traceback (most recent call last):\n  File \"export.py\", line 64, in &lt;module&gt;\n    torch.onnx.export(model, data, onnx_model_path)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 25, in export\n    return utils.export(*args, **kwargs)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 84, in export\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 140, in _export\n    trace.set_graph(_optimize_graph(trace.graph(), aten))\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 95, in _optimize_graph\n    graph = torch._C._jit_pass_onnx(graph, aten)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 40, in _run_symbolic_function\n    return utils._run_symbolic_function(*args, **kwargs)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 368, in _run_symbolic_function\n    return fn(g, *inputs, **attrs)\nTypeError: elu() got an unexpected keyword argument 'scale' (occurred when translating elu)\n</code></pre>\n<p>ONNX version is 1.2.2</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> onnx\n<span class=\"pl-k\">import</span> onnx.utils\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">TestModel</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(TestModel, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.linear <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">self</span>.elu <span class=\"pl-k\">=</span> nn.ELU()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inp</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.elu(<span class=\"pl-c1\">self</span>.linear(inp))\n\nmodel <span class=\"pl-k\">=</span> TestModel()\ninp <span class=\"pl-k\">=</span> torch.from_numpy(np.array([<span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">2.0</span>, <span class=\"pl-c1\">3.0</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32))\ntorch.onnx.export(model, inp, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>model.onnx<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>If I examine the offending \"scale\" attribute passed to ELU, its value is 1, which is effectively not there.</p>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Mac OSX 10.13.6<br>\nGCC version: Could not collect<br>\nCMake version: version 3.11.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] torch                     0.4.0                     <br>\n[conda] torchvision               0.2.1                     </p>", "body_text": "Issue description\nWhen I export a model to ONNX format using the tracer, the following error appears:\nTraceback (most recent call last):\n  File \"export.py\", line 64, in <module>\n    torch.onnx.export(model, data, onnx_model_path)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 25, in export\n    return utils.export(*args, **kwargs)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 84, in export\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 140, in _export\n    trace.set_graph(_optimize_graph(trace.graph(), aten))\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 95, in _optimize_graph\n    graph = torch._C._jit_pass_onnx(graph, aten)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 40, in _run_symbolic_function\n    return utils._run_symbolic_function(*args, **kwargs)\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 368, in _run_symbolic_function\n    return fn(g, *inputs, **attrs)\nTypeError: elu() got an unexpected keyword argument 'scale' (occurred when translating elu)\n\nONNX version is 1.2.2\nCode example\nimport torch\nimport onnx\nimport onnx.utils\nfrom torch import nn\nimport numpy as np\n\n\nclass TestModel(nn.Module):\n    def __init__(self):\n        super(TestModel, self).__init__()\n        self.linear = nn.Linear(3, 1)\n        self.elu = nn.ELU()\n\n    def forward(self, inp):\n        return self.elu(self.linear(inp))\n\nmodel = TestModel()\ninp = torch.from_numpy(np.array([1.0, 2.0, 3.0], dtype=np.float32))\ntorch.onnx.export(model, inp, \"model.onnx\")\nIf I examine the offending \"scale\" attribute passed to ELU, its value is 1, which is effectively not there.\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Mac OSX 10.13.6\nGCC version: Could not collect\nCMake version: version 3.11.1\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     0.4.0                     \n[conda] torchvision               0.2.1", "body": "## Issue description\r\n\r\nWhen I export a model to ONNX format using the tracer, the following error appears:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"export.py\", line 64, in <module>\r\n    torch.onnx.export(model, data, onnx_model_path)\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 25, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 84, in export\r\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 140, in _export\r\n    trace.set_graph(_optimize_graph(trace.graph(), aten))\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 95, in _optimize_graph\r\n    graph = torch._C._jit_pass_onnx(graph, aten)\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 40, in _run_symbolic_function\r\n    return utils._run_symbolic_function(*args, **kwargs)\r\n  File \"/anaconda3/envs/py36/lib/python3.6/site-packages/torch/onnx/utils.py\", line 368, in _run_symbolic_function\r\n    return fn(g, *inputs, **attrs)\r\nTypeError: elu() got an unexpected keyword argument 'scale' (occurred when translating elu)\r\n```\r\n\r\nONNX version is 1.2.2\r\n\r\n## Code example\r\n\r\n```python3\r\nimport torch\r\nimport onnx\r\nimport onnx.utils\r\nfrom torch import nn\r\nimport numpy as np\r\n\r\n\r\nclass TestModel(nn.Module):\r\n    def __init__(self):\r\n        super(TestModel, self).__init__()\r\n        self.linear = nn.Linear(3, 1)\r\n        self.elu = nn.ELU()\r\n\r\n    def forward(self, inp):\r\n        return self.elu(self.linear(inp))\r\n\r\nmodel = TestModel()\r\ninp = torch.from_numpy(np.array([1.0, 2.0, 3.0], dtype=np.float32))\r\ntorch.onnx.export(model, inp, \"model.onnx\")\r\n```\r\n\r\nIf I examine the offending \"scale\" attribute passed to ELU, its value is 1, which is effectively not there.\r\n\r\n## System Info\r\n\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.6\r\nGCC version: Could not collect\r\nCMake version: version 3.11.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] torch                     0.4.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>"}