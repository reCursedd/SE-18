{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/122041916", "pull_request_review_id": 44116940, "id": 122041916, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMjA0MTkxNg==", "diff_hunk": "@@ -496,14 +503,363 @@ static bool THPTensor_(_indexOnce)(PyObject *index, int &indexed_dim,\n   return true;\n }\n \n+#ifndef TH_REAL_IS_HALF\n+static bool THPTensor_(_checkAdvancedIndexing)(THPTensor *indexed, PyObject *arg) {\n+  // Currently we only support the integer-array indexing strategy for advanced\n+  // indexing - where we have ndim sequence/LongTensor arguments\n+\n+  long ndim = THTensor_(nDimension)(LIBRARY_STATE indexed->cdata);\n+\n+  // Verify that all of the inputs are either Tensors or Sequences.\n+  if (PySequence_Check(arg) && PySequence_Size(arg) == ndim) {\n+    for (Py_ssize_t i = 0; i < ndim; ++i) {\n+      PyObject *item = PySequence_GetItem(arg, i);\n+      if (!THPIndexTensor_Check(item) && !PySequence_Check(item)) {\n+        Py_DECREF(item);\n+        return false;\n+      }\n+      Py_DECREF(item);\n+    }\n+    return true;\n+  }\n+  return false;\n+\n+  // Full NumPy advanced indexing requirements are coded up below. To fully support\n+  // such indexing will require changes to the actual indexing logic, so we will\n+  // leave this commented out as a reference\n+\n+  /**\n+  // Checks whether the specified selection object should trigger advanced\n+  // indexing\n+\n+  // Case 1: arg is a non-tuple sequence object\n+  if (PySequence_Check(arg) && !PyTuple_Check(arg)) return true;\n+\n+#ifdef WITH_NUMPY\n+  // Case 2: arg is an nd-array with type integer or bool\n+  if (PyArray_Check(arg) && (PyArray_TYPE((PyArrayObject*)arg) == NPY_INT64 || PyArray_TYPE((PyArrayObject*)arg) == NPY_BOOL)) return true;\n+#endif\n+\n+  // Case 3: arg is a tuple containing at least one sequence object, ndarray, or LongTensor\n+  if (PyTuple_Check(arg)) {\n+    for (Py_ssize_t i = 0; i < PyTuple_GET_SIZE(arg); ++i) {\n+      PyObject *item = PyTuple_GET_ITEM(arg, i);\n+      if (PySequence_Check(item)) {\n+        return true;\n+      }\n+#ifdef WITH_NUMPY\n+      if (PyArray_Check(item) && (PyArray_TYPE((PyArrayObject*)item) == NPY_INT64 || PyArray_TYPE((PyArrayObject*)item) == NPY_BOOL)) return true;\n+#endif\n+      if (THPIndexTensor_Check(item)) return true;\n+    }\n+  }\n+\n+  return false;\n+  **/\n+}\n+\n+// Exposed at the interpreter level\n+static PyObject* THPTensor_(checkAdvancedIndexing)(THPTensor *self, PyObject *arg) {\n+  if (THPTensor_(_checkAdvancedIndexing)(self, arg)) {\n+    Py_RETURN_TRUE;\n+  }\n+  Py_RETURN_FALSE;\n+}\n+\n+static bool THPTensor_(_convertToTensorIndexers)(PyObject *index, std::vector<THIndexTensor*>& broadcasted) {\n+  // At the top-level, index must be a sequence. PySequence_Fast returns a new\n+  // reference\n+  PyObject *fast = PySequence_Fast(index, NULL);\n+  Py_ssize_t seqCount = PySequence_Fast_GET_SIZE(fast);\n+  std::vector<THPIndexTensor*> indexers;\n \n+  for (Py_ssize_t i = 0; i < seqCount; ++i) {\n+    THPIndexTensor *indexer = (THPIndexTensor *)PyObject_CallFunctionObjArgs(THPLongTensorClass, PySequence_Fast_GET_ITEM(fast, i), NULL);\n+    if (!indexer) {\n+      PyErr_Format(PyExc_IndexError,\n+          \"When performing advanced indexing the indexing objects must be LongTensors or convertible to such\");\n+      return false;\n+    }\n+    indexers.push_back(indexer);\n+  }\n+  Py_DECREF(fast);\n+\n+  THIndexTensor **maybeBroadcasted = (THIndexTensor **)THAlloc(seqCount * sizeof(THIndexTensor*));\n+  THIndexTensor **candidates = (THIndexTensor **)THAlloc(seqCount * sizeof(THIndexTensor*));\n+\n+  for (Py_ssize_t i = 0; i < seqCount; ++i) {\n+    maybeBroadcasted[i] = THIndexTensor_(new)(LIBRARY_STATE_NOARGS);\n+    candidates[i] = THIndexTensor_(newWithTensor)(LIBRARY_STATE indexers[i]->cdata);\n+  }\n+\n+  // Broadcast/Expand indexing Tensors as necessary\n+  bool broadcastSuccess = true;\n+  try {\n+    THIndexTensor_(expandNd)(LIBRARY_STATE maybeBroadcasted, candidates, seqCount);\n+    // Place Broadcasted Tensors into output vector, implicitly transferring\n+    // ownership\n+    for (Py_ssize_t i = 0; i < seqCount; ++i) {\n+      broadcasted.push_back(maybeBroadcasted[i]);\n+    }\n+  } catch (std::exception& e) {\n+    // Broadcasted failed, cleanup and set error\n+    for (int i = 0; i < seqCount; ++i) {\n+      THIndexTensor_(free)(LIBRARY_STATE maybeBroadcasted[i]);\n+    }\n+    broadcastSuccess = false;\n+    PyErr_Format(PyExc_IndexError, \"The advanced indexing objects could not be broadcast\");\n+  }\n+\n+  // No matter what, need to cleanup the candidates\n+  for (Py_ssize_t i = 0; i < seqCount; ++i) {\n+    THIndexTensor_(free)(LIBRARY_STATE candidates[i]);\n+  }\n+  THFree(candidates);\n+  THFree(maybeBroadcasted);\n+\n+  return broadcastSuccess;\n+}\n+\n+// Caller takes ownership of the returned IndexTensor\n+static THIndexTensor* THPTensor_(_calculateLinearIndices)(\n+    THTensorPtr& indexed, std::vector<THIndexTensor *>& broadcasted) {\n+\n+  // Get the number of indices to generate - this will be equal to the number\n+  // of elements in each broadcasted Tensor\n+  ptrdiff_t indexingElements = THIndexTensor_(nElement)(LIBRARY_STATE broadcasted.at(0));\n+  THIndexTensor *linearIndices = THIndexTensor_(newWithSize1d)(LIBRARY_STATE indexingElements);\n+  THLongStorage *indexerSize = THLongStorage_newWithSize(1);\n+  THLongStorage_set(indexerSize, 0, indexingElements);\n+\n+  for (ptrdiff_t i = 0; i < indexingElements; ++i) {\n+    long linearIdx = THTensor_(storageOffset)(LIBRARY_STATE indexed);\n+    for (int j = broadcasted.size() - 1; j >= 0; --j) {\n+      // Given a series of broadcasted Tensors, we take the jth tensor from the sequence (representing\n+      // the indices at dim j) and grab the ith value (used in generating the ith output value)\n+      THIndexTensor *indexer = THIndexTensor_(newContiguous)(LIBRARY_STATE broadcasted.at(j));\n+\n+      // The indexing tensor might not be one-dimensional, but we are generating a vector of\n+      // indices, so we need to view the indexer as 1D prior to getting the value for the\n+      // particular dimension\n+      THIndexTensor *oned = THIndexTensor_(newView)(LIBRARY_STATE indexer, indexerSize);\n+\n+      // Actually laod the value, and verify it is not out-of-bounds\n+      long indexAtDim = THIndexTensor_(get1d)(LIBRARY_STATE oned, i);", "path": "torch/csrc/generic/Tensor.cpp", "position": null, "original_position": 193, "commit_id": "99ce824c967a7ed87303842db5478d6b7d509b2f", "original_commit_id": "93155cecf3952514ce56ef7254657bd024d80c92", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "Can `oned` be on the GPU? If yes, I'm afraid this part will be very slow, as we would have a lot of `cudaMemCpy`.", "created_at": "2017-06-14T19:25:53Z", "updated_at": "2018-11-23T15:33:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/1588#discussion_r122041916", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1588", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/122041916"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1588#discussion_r122041916"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1588"}}, "body_html": "<p>Can <code>oned</code> be on the GPU? If yes, I'm afraid this part will be very slow, as we would have a lot of <code>cudaMemCpy</code>.</p>", "body_text": "Can oned be on the GPU? If yes, I'm afraid this part will be very slow, as we would have a lot of cudaMemCpy."}