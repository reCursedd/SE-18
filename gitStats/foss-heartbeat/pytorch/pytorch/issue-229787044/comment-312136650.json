{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/312136650", "html_url": "https://github.com/pytorch/pytorch/pull/1588#issuecomment-312136650", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1588", "id": 312136650, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjEzNjY1MA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-29T23:41:46Z", "updated_at": "2017-06-29T23:41:46Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4529377\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/killeent\">@killeent</a>, I have a cuda test failing when I build from master, <code>python test_cuda.py TestCuda.test_advancedindex</code>. It's failing in assert_set_eq when the indexer has dupes, and I've added some printouts there:</p>\n<pre><code>tensor\n  0   1   2   3   4\n  5   6   7   8   9\n 10  11  12  13  14\n 15  16  17  18  19\nindexer [slice(None, None, None), [0, 1, 1, 2, 2]]\nval\n 16  12   0  14  10\n 19  17   2   7   4\n  5   9   6   1  15\n 13  11   3   8  18\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\n\npyt \n 16  12  14   3   4\n 19  17   7   8   9\n  5   9   1  13  14\n 13  11   8  18  19\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\n numt \n 16   0  10   3   4\n 19   2   4   8   9\n  5   6  15  13  14\n 13   3  18  18  19\n</code></pre>\n<p>Apparently, in the correct output (numt) the second of the duped columns should be copied to tensor from val, and in my failing case (pyt) the first one is. Can you point me to where in the backend this is happening? It's passing on most architectures, so that's not an outright bug, but failing on one.</p>", "body_text": "@killeent, I have a cuda test failing when I build from master, python test_cuda.py TestCuda.test_advancedindex. It's failing in assert_set_eq when the indexer has dupes, and I've added some printouts there:\ntensor\n  0   1   2   3   4\n  5   6   7   8   9\n 10  11  12  13  14\n 15  16  17  18  19\nindexer [slice(None, None, None), [0, 1, 1, 2, 2]]\nval\n 16  12   0  14  10\n 19  17   2   7   4\n  5   9   6   1  15\n 13  11   3   8  18\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\n\npyt \n 16  12  14   3   4\n 19  17   7   8   9\n  5   9   1  13  14\n 13  11   8  18  19\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\n numt \n 16   0  10   3   4\n 19   2   4   8   9\n  5   6  15  13  14\n 13   3  18  18  19\n\nApparently, in the correct output (numt) the second of the duped columns should be copied to tensor from val, and in my failing case (pyt) the first one is. Can you point me to where in the backend this is happening? It's passing on most architectures, so that's not an outright bug, but failing on one.", "body": "@killeent, I have a cuda test failing when I build from master, ```python test_cuda.py TestCuda.test_advancedindex```. It's failing in assert_set_eq when the indexer has dupes, and I've added some printouts there:\r\n```\r\ntensor\r\n  0   1   2   3   4\r\n  5   6   7   8   9\r\n 10  11  12  13  14\r\n 15  16  17  18  19\r\nindexer [slice(None, None, None), [0, 1, 1, 2, 2]]\r\nval\r\n 16  12   0  14  10\r\n 19  17   2   7   4\r\n  5   9   6   1  15\r\n 13  11   3   8  18\r\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\r\n\r\npyt \r\n 16  12  14   3   4\r\n 19  17   7   8   9\r\n  5   9   1  13  14\r\n 13  11   8  18  19\r\n[torch.cuda.DoubleTensor of size 4x5 (GPU 0)]\r\n numt \r\n 16   0  10   3   4\r\n 19   2   4   8   9\r\n  5   6  15  13  14\r\n 13   3  18  18  19\r\n```\r\nApparently, in the correct output (numt) the second of the duped columns should be copied to tensor from val, and in my failing case (pyt) the first one is. Can you point me to where in the backend this is happening? It's passing on most architectures, so that's not an outright bug, but failing on one. "}