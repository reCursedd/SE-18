{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196091762", "pull_request_review_id": 129578188, "id": 196091762, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjA5MTc2Mg==", "diff_hunk": "@@ -167,5 +167,105 @@ def allreduce(x, op):\n         self.assertEqual(torch.Tensor([self.size]), x)\n \n \n+class ProcessGroupNCCLTest(TestCase):\n+    MAIN_PROCESS_RANK = 0\n+\n+    def setUp(self):\n+        if not hasattr(c10d, \"ProcessGroupNCCL\"):\n+            raise unittest.SkipTest(\"C10D is not built with NCCL process group,\"\n+                                    \" skipping test\")\n+\n+        self.rank = self.MAIN_PROCESS_RANK\n+        self.size = 1\n+        self.file = tempfile.NamedTemporaryFile()\n+\n+        if not torch.cuda.is_available():\n+            raise unittest.SkipTest(\"torch.cuda not available, skipping test\")\n+\n+        self.num_gpus = torch.cuda.device_count()\n+\n+        if self.num_gpus < 2:\n+            raise unittest.SkipTest(\"Requires at least 2 GPUs, skipping test\")\n+\n+    def tearDown(self):\n+        self.file.close()\n+\n+    def test_broadcast_ops(self):\n+        store = c10d.FileStore(self.file.name)\n+        pg = c10d.ProcessGroupNCCL(store, self.rank, self.size)\n+\n+        def broadcast(xs, rootRank, rootTensor):\n+            opts = c10d.BroadcastOptions()\n+            opts.rootRank = rootRank\n+            opts.rootTensor = rootTensor\n+            work = pg.broadcast(xs, opts)\n+            work.wait()\n+\n+        # for every root tensor\n+        for rt in range(self.num_gpus):\n+            tensors = []\n+            for i in range(self.num_gpus):\n+                tensors.append(torch.Tensor([i]).cuda(i))\n+\n+            broadcast(tensors, self.rank, rt)\n+\n+            for i in range(self.num_gpus):\n+                self.assertEqual(tensors[i], tensors[rt])\n+\n+    def test_allreduce_ops(self):\n+        store = c10d.FileStore(self.file.name)\n+        pg = c10d.ProcessGroupNCCL(store, self.rank, self.size)\n+\n+        def allreduce(tensors, op):\n+            opts = c10d.AllreduceOptions()\n+            opts.reduceOp = op\n+            work = pg.allreduce(tensors, opts)\n+            work.wait()\n+\n+        # Sum\n+        tensors = []\n+        for i in range(self.num_gpus):\n+            tensors.append(torch.Tensor([i + 1]).cuda(i))\n+\n+        allreduce(tensors, c10d.ReduceOp.SUM)\n+\n+        for i in range(self.num_gpus):\n+            self.assertEqual(\n+                torch.Tensor([float(self.num_gpus * (self.num_gpus + 1) / 2)]),\n+                tensors[i])\n+\n+        # Product\n+        tensors = []\n+        for i in range(self.num_gpus):\n+            tensors.append(torch.Tensor([i + 1]).cuda(i))\n+\n+        allreduce(tensors, c10d.ReduceOp.PRODUCT)\n+\n+        for i in range(self.num_gpus):\n+            self.assertEqual(\n+                torch.Tensor([float(math.factorial(self.num_gpus))]),\n+                tensors[i])\n+\n+        # Min\n+        tensors = []\n+        for i in range(self.num_gpus):\n+            tensors.append(torch.Tensor([i + 1]).cuda(i))\n+\n+        allreduce(tensors, c10d.ReduceOp.MIN)\n+\n+        for i in range(self.num_gpus):\n+            self.assertEqual(torch.Tensor([1.0]), tensors[i])\n+\n+        # Max\n+        tensors = []\n+        for i in range(self.num_gpus):\n+            tensors.append(torch.Tensor([i + 1]).cuda(i))\n+\n+        allreduce(tensors, c10d.ReduceOp.MAX)\n+\n+        for i in range(self.num_gpus):\n+            self.assertEqual(torch.Tensor([self.num_gpus]), tensors[i])", "path": "test/test_c10d.py", "position": 101, "original_position": 101, "commit_id": "ac86a8bfe0f243c213b1717abe3e96d5f9682f48", "original_commit_id": "592ce2613a85be21277ad488008e8265a6525462", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "These tests could have been easily deduplicated by providing a list of `(ReduceOp, expected_output)` pairs", "created_at": "2018-06-18T14:10:03Z", "updated_at": "2018-11-23T15:45:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/8357#discussion_r196091762", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8357", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196091762"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8357#discussion_r196091762"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8357"}}, "body_html": "<p>These tests could have been easily deduplicated by providing a list of <code>(ReduceOp, expected_output)</code> pairs</p>", "body_text": "These tests could have been easily deduplicated by providing a list of (ReduceOp, expected_output) pairs"}