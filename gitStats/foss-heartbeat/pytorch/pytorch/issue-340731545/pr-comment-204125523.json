{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204125523", "pull_request_review_id": 139156915, "id": 204125523, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDEyNTUyMw==", "diff_hunk": "@@ -1222,12 +1309,210 @@ def LSTMCell_batch(x, h, c, w_xi, w_xf, w_xo, w_xc, w_hi, w_hf, w_ho, w_hc, b_i,\n         b_o = torch.rand(hidden_size)\n         b_c = torch.rand(hidden_size)\n \n-        ys = [LSTMCell(xs[j].squeeze(0), hx[j], cx[j], w_xi, w_xf, w_xo, w_xc,\n-                       w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c) for j in range(batch_size)]\n-        ybs = LSTMCell_batch(batch, h_batch, c_batch, w_xi, w_xf, w_xo, w_xc,\n-                             w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c)\n+        ys = [LSTM(xs[j], hx[j], cx[j], w_xi, w_xf, w_xo, w_xc,\n+                   w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c) for j in range(batch_size)]\n+        ybs = LSTM_batch(batch, h_batch, c_batch, w_xi, w_xf, w_xo, w_xc,\n+                         w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c)\n         self.assertEqual(ys, ybs.examples())\n \n+    def test_numToTensor(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_numToTensor(a):\n+            a = a + 1\n+            return a\n+\n+        def single_numToTensor(a):\n+            a = a + 1\n+            return a\n+\n+        a, batch = self.rand_batch(4, ())\n+        res_batch = batch_numToTensor(batch)\n+        res = [single_numToTensor(a[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_numToTensor(a):\n+            a = a + 1\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_numToTensor.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_else(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > b:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > b:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > b:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_else_with_scalar(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            else:\n+                a -= b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_noelse(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > b:\n+                a += b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > b:\n+                a += b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > b:\n+                a += b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_noelse_with_scalar(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a += b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_while(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_while(a, b):\n+            while a > b:\n+                a -= b\n+            return a\n+\n+        def single_while(a, b):\n+            while a > b:\n+                a -= b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b = [torch.abs(torch.rand(1)) for i in range(4)]\n+        batch_b = BatchTensor(b, torch.tensor([]).byte())\n+        res_batch = batch_while(batch_a, batch_b)\n+        res = [single_while(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_while(a, b):\n+            while a > b:\n+                a -= b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_while.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_for(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_for(x, y):\n+            for _i in range(10):\n+                x += y\n+            return x\n+\n+        def single_for(x, y):\n+            for _i in range(10):\n+                x += y\n+            return x\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_for(batch_a, batch_b)\n+        res = [single_for(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_for(x, y):\n+            for _i in range(10):", "path": "test/test_jit.py", "position": null, "original_position": 379, "commit_id": "154e4eb8cd13cacd121fe3577831ed0590a1a5d5", "original_commit_id": "1c6a6dd82fcf8a3775b54b94a50096dd531a7248", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "body": "Can't you just use `_` and not `_i`?", "created_at": "2018-07-20T18:04:01Z", "updated_at": "2018-11-23T15:47:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/9392#discussion_r204125523", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9392", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204125523"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9392#discussion_r204125523"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9392"}}, "body_html": "<p>Can't you just use <code>_</code> and not <code>_i</code>?</p>", "body_text": "Can't you just use _ and not _i?"}