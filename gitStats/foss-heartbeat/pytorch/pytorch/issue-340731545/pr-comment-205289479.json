{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/205289479", "pull_request_review_id": 140532318, "id": 205289479, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNTI4OTQ3OQ==", "diff_hunk": "@@ -1220,42 +1248,408 @@ def where(c, a, b):\n         res = [torch.where(xs_cond[j], xs[j], xs2[j]) for j in range(4)]\n         self.assertEqual(res, res_batch.examples())\n \n-    def test_lstm_cell(self):\n-        def LSTMCell(x, h, c, w_xi, w_xf, w_xo, w_xc, w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c):\n-            i_t = torch.matmul(x, w_xi) + torch.matmul(h, w_hi) + b_i\n-            f_t = torch.matmul(x, w_xf) + torch.matmul(h, w_hf) + b_f\n-            o_t = torch.matmul(x, w_xo) + torch.matmul(h, w_ho) + b_o\n-            # activations\n-            i_t = torch.sigmoid(i_t)\n-            f_t = torch.sigmoid(f_t)\n-            o_t = torch.sigmoid(o_t)\n-            # cell computations\n-            c_t = torch.matmul(x, w_xc) + torch.matmul(h, w_hc) + b_c\n-            c_t = torch.tanh(c_t)\n-            c_t = torch.mul(c, f_t) + torch.mul(i_t, c_t)\n-            h_t = torch.mul(o_t, torch.tanh(c_t))\n-            return h_t\n+    def test_batch_argmax(self):\n+        @torch.jit.batch(batch_size=4)\n+        def argmax(a):\n+            return torch.argmax(a, 1)\n+\n+        xs, batch = self.rand_batch(4, (True, 5), (True, 6))\n+        res_batch = argmax(batch)\n+        res = [torch.argmax(xs[j], 1) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.batch(batch_size=4)\n+        def argmax(a):\n+            return torch.argmax(a, 1, False)\n+\n+        res_batch = argmax(batch)\n+        res = [torch.argmax(xs[j], 1, False) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+    def test_batch_topk(self):\n+        @torch.jit.batch(batch_size=4)\n+        def topk(a):\n+            return torch.topk(a, 3, 1)\n+\n+        xs, batch = self.rand_batch(4, (False, 5), (True, 6))\n+\n+        # along static dim\n+        res_batch = topk(batch)\n+        res = [torch.topk(xs[j], 3, 1)[0] for j in range(4)]\n+        res_idx = [torch.topk(xs[j], 3, 1)[1] for j in range(4)]\n+        self.assertEqual(res, res_batch[0].examples())\n+        self.assertEqual(res_idx, res_batch[1].examples())\n+\n+        @torch.jit.batch(batch_size=4)\n+        def topk(a):\n+            return torch.topk(a, 1, 2)\n+\n+        # along dynamic dim\n+        res_batch = topk(batch)\n+        res = [torch.topk(xs[j], 1, 2)[0] for j in range(4)]\n+        res_idx = [torch.topk(xs[j], 1, 2)[1] for j in range(4)]\n+        self.assertEqual(res, res_batch[0].examples())\n+        self.assertEqual(res_idx, res_batch[1].examples())\n+\n+    def test_batch_softmax(self):\n+        @torch.jit.batch(batch_size=4)\n+        def softmax(a):\n+            return torch.softmax(a, 1)\n+\n+        xs, batch = self.rand_batch(4, (False, 5), (True, 6))\n+\n+        # along static dim\n+        res_batch = softmax(batch)\n+        res = [torch.softmax(xs[j], 1) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.batch(batch_size=4)\n+        def softmax(a):\n+            return torch.softmax(a, 2)\n+\n+        # along dynamic dim\n+        res_batch = softmax(batch)\n+        res = [torch.softmax(xs[j], 2) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+    def test_batch_view(self):\n+        @torch.jit.batch(batch_size=4)\n+        def view(a):\n+            return a.view([4, -1, 3])\n+\n+        xs, batch = self.rand_batch(4, (True, 5), (False, 3))\n+        res_batch = view(batch)\n+        res = [xs[j].view([1, -1, 3]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+    def test_batch_cat(self):\n+        @torch.jit.batch(batch_size=4)\n+        def cat2(a, b):\n+            return torch.cat([a, b], 2)\n+\n+        xs, batch = self.rand_batch(4, (True, 5), (False, 3))\n+        xs2, batch2 = xs, batch\n+        res_batch = cat2(batch, batch2)\n+        res = [torch.cat([xs[j], xs2[j]], 2) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+    def test_batch_sum(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_sum(a):\n+            return a.sum()\n+\n+        xs, batch = self.rand_batch(4, (True, 5), (False, 3))\n+        res_batch = batch_sum(batch)\n+        res = [xs[j].sum().unsqueeze(0) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+    def test_if_else(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > b:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > b:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > b:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n \n+    def test_if_else_with_scalar(self):\n         @torch.jit.batch(batch_size=4)\n-        def LSTMCell_batch(x, h, c, w_xi, w_xf, w_xo, w_xc, w_hi, w_hf, w_ho, w_hc, b_i, b_f, b_o, b_c):\n-            i_t = torch.matmul(x, w_xi) + torch.matmul(h, w_hi) + b_i\n-            f_t = torch.matmul(x, w_xf) + torch.matmul(h, w_hf) + b_f\n-            o_t = torch.matmul(x, w_xo) + torch.matmul(h, w_ho) + b_o\n-            # activations\n-            i_t = torch.sigmoid(i_t)\n-            f_t = torch.sigmoid(f_t)\n-            o_t = torch.sigmoid(o_t)\n-            # cell computations\n-            c_t = torch.matmul(x, w_xc) + torch.matmul(h, w_hc) + b_c\n-            c_t = torch.tanh(c_t)\n-            c_t = torch.mul(c, f_t) + torch.mul(i_t, c_t)\n-            h_t = torch.mul(o_t, torch.tanh(c_t))\n-            return h_t\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            else:\n+                a = a - b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_noelse(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > b:\n+                a = a + b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > b:\n+                a = a + b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > b:\n+                a = a + b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_if_noelse_with_scalar(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            return a\n+\n+        def single_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_if(batch_a, batch_b)\n+        res = [single_if(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_if(a, b):\n+            if a > 0.1:\n+                a = a + b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_if.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_while(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_while(a, b):\n+            while a > b:\n+                a = a - b\n+            return a\n+\n+        def single_while(a, b):\n+            while a > b:\n+                a = a - b\n+            return a\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b = [torch.abs(torch.rand(1)) for i in range(4)]\n+        batch_b = BatchTensor(b, torch.tensor([]).byte())\n+        res_batch = batch_while(batch_a, batch_b)\n+        res = [single_while(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_while(a, b):\n+            while a > b:\n+                a = a - b\n+            return a\n+\n+        graph = torch.to_batch_graph(batch_while.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_for(self):\n+        @torch.jit.batch(batch_size=4)\n+        def batch_for(x, y):\n+            for _ in range(10):\n+                x = x + y\n+            return x\n+\n+        def single_for(x, y):\n+            for _ in range(10):\n+                x = x + y\n+            return x\n+\n+        a, batch_a = self.rand_batch(4, ())\n+        b, batch_b = self.rand_batch(4, ())\n+        res_batch = batch_for(batch_a, batch_b)\n+        res = [single_for(a[j], b[j]) for j in range(4)]\n+        self.assertEqual(res, res_batch.examples())\n+\n+        @torch.jit.script\n+        def batch_for(x, y):\n+            for _ in range(10):\n+                x = x + y\n+            return x\n+\n+        graph = torch.to_batch_graph(batch_for.graph)\n+        self.assertExpected(str(graph))\n+\n+    def test_lstm(self):", "path": "test/test_jit.py", "position": null, "original_position": 349, "commit_id": "154e4eb8cd13cacd121fe3577831ed0590a1a5d5", "original_commit_id": "293895b64826f9c29bdf93f29ce2da7c7a2a628f", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "body": "For these tests, instead of repeating the implementation twice, you can simply use the decorator as a function:\r\n\r\n```\r\ndef foo(x):\r\n  return x\r\n\r\nfoo_batched = torch.jit.batch(batch_size=4)(foo)", "created_at": "2018-07-25T23:13:38Z", "updated_at": "2018-11-23T15:48:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/9392#discussion_r205289479", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9392", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/205289479"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9392#discussion_r205289479"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9392"}}, "body_html": "<p>For these tests, instead of repeating the implementation twice, you can simply use the decorator as a function:</p>\n<pre><code>def foo(x):\n  return x\n\nfoo_batched = torch.jit.batch(batch_size=4)(foo)\n</code></pre>", "body_text": "For these tests, instead of repeating the implementation twice, you can simply use the decorator as a function:\ndef foo(x):\n  return x\n\nfoo_batched = torch.jit.batch(batch_size=4)(foo)"}