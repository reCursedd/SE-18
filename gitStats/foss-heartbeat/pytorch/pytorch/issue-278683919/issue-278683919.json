{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3979", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3979/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3979/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3979/events", "html_url": "https://github.com/pytorch/pytorch/issues/3979", "id": 278683919, "node_id": "MDU6SXNzdWUyNzg2ODM5MTk=", "number": 3979, "title": "nvidia-smi shows Unknown Error , and the corresponding 3 gpus can't be used", "user": {"login": "oneTaken", "id": 18045872, "node_id": "MDQ6VXNlcjE4MDQ1ODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/18045872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oneTaken", "html_url": "https://github.com/oneTaken", "followers_url": "https://api.github.com/users/oneTaken/followers", "following_url": "https://api.github.com/users/oneTaken/following{/other_user}", "gists_url": "https://api.github.com/users/oneTaken/gists{/gist_id}", "starred_url": "https://api.github.com/users/oneTaken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oneTaken/subscriptions", "organizations_url": "https://api.github.com/users/oneTaken/orgs", "repos_url": "https://api.github.com/users/oneTaken/repos", "events_url": "https://api.github.com/users/oneTaken/events{/privacy}", "received_events_url": "https://api.github.com/users/oneTaken/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-12-02T13:26:17Z", "updated_at": "2017-12-05T03:08:57Z", "closed_at": "2017-12-04T10:56:35Z", "author_association": "NONE", "body_html": "<p>Due to multi-process dataloader, some process may not be cleared.<br>\nSo, I always <code>kill pid</code> manually.<br>\nAnd then,  I faced this unreasonable error.<br>\n2 process can't be killed. Even Though I use <code>killall -u &lt;usename&gt;</code><br>\nOnce some data put to the broken gpu, the program is no response.<br>\nHere is the <code>nvidia-smi</code> shows:</p>\n<pre><code>Sat Dec  2 21:24:47 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           On   | 0000:04:00.0     Off |                    0 |\n| N/A   41C    P0    58W / 149W |    495MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           On   | 0000:05:00.0     Off |                    0 |\n| N/A   38C    P0   119W / 149W |   8225MiB / 11439MiB |     91%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           On   | 0000:83:00.0     Off |                    0 |\n| N/A   44C    P0    71W / 149W |   8231MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           On   | 0000:84:00.0     Off |                    0 |\n| N/A   32C    P0    92W / 149W |  10919MiB / 11439MiB |     50%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           On   | 0000:89:00.0     Off |                    0 |\n| N/A   18C    P8    28W / 149W |      2MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           On   | 0000:8A:00.0     Off |                    0 |\n| N/A   36C    P0    89W / 149W |  10942MiB / 11439MiB |     30%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           On   | 0000:8D:00.0     Off |                    0 |\n| N/A   30C    P0    75W / 149W |   9564MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           On   | 0000:8E:00.0     Off |                    0 |\n| N/A   56C    P0   150W / 149W |  10915MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     17631    C   Unknown Error                                  281MiB |\n|    1       378    C   python                                        8221MiB |\n|    2     17631    C   Unknown Error                                  380MiB |\n|    3     15657    C   python                                       10915MiB |\n|    5      2479    C   python3                                      10938MiB |\n|    6     17631    C   Unknown Error                                  411MiB |\n|    7     35513    C   python                                       10909MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>", "body_text": "Due to multi-process dataloader, some process may not be cleared.\nSo, I always kill pid manually.\nAnd then,  I faced this unreasonable error.\n2 process can't be killed. Even Though I use killall -u <usename>\nOnce some data put to the broken gpu, the program is no response.\nHere is the nvidia-smi shows:\nSat Dec  2 21:24:47 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           On   | 0000:04:00.0     Off |                    0 |\n| N/A   41C    P0    58W / 149W |    495MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           On   | 0000:05:00.0     Off |                    0 |\n| N/A   38C    P0   119W / 149W |   8225MiB / 11439MiB |     91%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           On   | 0000:83:00.0     Off |                    0 |\n| N/A   44C    P0    71W / 149W |   8231MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           On   | 0000:84:00.0     Off |                    0 |\n| N/A   32C    P0    92W / 149W |  10919MiB / 11439MiB |     50%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           On   | 0000:89:00.0     Off |                    0 |\n| N/A   18C    P8    28W / 149W |      2MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           On   | 0000:8A:00.0     Off |                    0 |\n| N/A   36C    P0    89W / 149W |  10942MiB / 11439MiB |     30%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           On   | 0000:8D:00.0     Off |                    0 |\n| N/A   30C    P0    75W / 149W |   9564MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           On   | 0000:8E:00.0     Off |                    0 |\n| N/A   56C    P0   150W / 149W |  10915MiB / 11439MiB |    100%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     17631    C   Unknown Error                                  281MiB |\n|    1       378    C   python                                        8221MiB |\n|    2     17631    C   Unknown Error                                  380MiB |\n|    3     15657    C   python                                       10915MiB |\n|    5      2479    C   python3                                      10938MiB |\n|    6     17631    C   Unknown Error                                  411MiB |\n|    7     35513    C   python                                       10909MiB |\n+-----------------------------------------------------------------------------+", "body": "Due to multi-process dataloader, some process may not be cleared. \r\nSo, I always `kill pid` manually.\r\nAnd then,  I faced this unreasonable error.\r\n2 process can't be killed. Even Though I use `killall -u <usename>`\r\nOnce some data put to the broken gpu, the program is no response.\r\nHere is the `nvidia-smi` shows:\r\n\r\n```\r\nSat Dec  2 21:24:47 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 0000:04:00.0     Off |                    0 |\r\n| N/A   41C    P0    58W / 149W |    495MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           On   | 0000:05:00.0     Off |                    0 |\r\n| N/A   38C    P0   119W / 149W |   8225MiB / 11439MiB |     91%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           On   | 0000:83:00.0     Off |                    0 |\r\n| N/A   44C    P0    71W / 149W |   8231MiB / 11439MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           On   | 0000:84:00.0     Off |                    0 |\r\n| N/A   32C    P0    92W / 149W |  10919MiB / 11439MiB |     50%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla K80           On   | 0000:89:00.0     Off |                    0 |\r\n| N/A   18C    P8    28W / 149W |      2MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla K80           On   | 0000:8A:00.0     Off |                    0 |\r\n| N/A   36C    P0    89W / 149W |  10942MiB / 11439MiB |     30%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla K80           On   | 0000:8D:00.0     Off |                    0 |\r\n| N/A   30C    P0    75W / 149W |   9564MiB / 11439MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  Tesla K80           On   | 0000:8E:00.0     Off |                    0 |\r\n| N/A   56C    P0   150W / 149W |  10915MiB / 11439MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0     17631    C   Unknown Error                                  281MiB |\r\n|    1       378    C   python                                        8221MiB |\r\n|    2     17631    C   Unknown Error                                  380MiB |\r\n|    3     15657    C   python                                       10915MiB |\r\n|    5      2479    C   python3                                      10938MiB |\r\n|    6     17631    C   Unknown Error                                  411MiB |\r\n|    7     35513    C   python                                       10909MiB |\r\n+-----------------------------------------------------------------------------+\r\n```"}