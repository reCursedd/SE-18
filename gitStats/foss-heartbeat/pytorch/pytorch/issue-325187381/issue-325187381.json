{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7756", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7756/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7756/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7756/events", "html_url": "https://github.com/pytorch/pytorch/issues/7756", "id": 325187381, "node_id": "MDU6SXNzdWUzMjUxODczODE=", "number": 7756, "title": " [Caffe2] Error running imported pytorch-model in caffe2", "user": {"login": "Pipoderoso", "id": 30522200, "node_id": "MDQ6VXNlcjMwNTIyMjAw", "avatar_url": "https://avatars2.githubusercontent.com/u/30522200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pipoderoso", "html_url": "https://github.com/Pipoderoso", "followers_url": "https://api.github.com/users/Pipoderoso/followers", "following_url": "https://api.github.com/users/Pipoderoso/following{/other_user}", "gists_url": "https://api.github.com/users/Pipoderoso/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pipoderoso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pipoderoso/subscriptions", "organizations_url": "https://api.github.com/users/Pipoderoso/orgs", "repos_url": "https://api.github.com/users/Pipoderoso/repos", "events_url": "https://api.github.com/users/Pipoderoso/events{/privacy}", "received_events_url": "https://api.github.com/users/Pipoderoso/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-05-22T08:22:07Z", "updated_at": "2018-05-22T13:56:36Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I am trying to deploy a Pytorch model in C++.  First I am exporting the the model with its weight to ONNX with the function <code>torch.onnx.export()</code>. Then importing it with <code>onnn.load()</code>. Calling <code>onnx.helper.printable_graph</code> produces this output:</p>\n<pre><code>graph torch-jit-export (\n  %0[FLOAT, 1x1x1080x1920]\n) initializers (\n  %1[FLOAT, 16x1x9x9]\n  %2[FLOAT, 16]\n  %3[FLOAT, 1]\n  %4[FLOAT, 32x16x7x7]\n  %5[FLOAT, 32]\n  %6[FLOAT, 1]\n  %7[FLOAT, 16x32x9x9]\n  %8[FLOAT, 16]\n  %9[FLOAT, 1]\n  %10[FLOAT, 32x16x7x7]\n  %11[FLOAT, 32]\n  %12[FLOAT, 1]\n  %13[FLOAT, 16x32x7x7]\n  %14[FLOAT, 16]\n  %15[FLOAT, 1]\n  %16[FLOAT, 8x16x7x7]\n  %17[FLOAT, 8]\n  %18[FLOAT, 1]\n  %19[FLOAT, 4x8x1x1]\n  %20[FLOAT, 4]\n  %21[FLOAT, 1]\n  %22[FLOAT, 512x4096]\n  %23[FLOAT, 512]\n  %24[FLOAT, 1]\n  %25[FLOAT, 256x512]\n  %26[FLOAT, 256]\n  %27[FLOAT, 1]\n  %28[FLOAT, 10x256]\n  %29[FLOAT, 10]\n  %30[FLOAT, 1]\n  %31[FLOAT, 20x32x7x7]\n  %32[FLOAT, 20]\n  %33[FLOAT, 1]\n  %34[FLOAT, 40x20x5x5]\n  %35[FLOAT, 40]\n  %36[FLOAT, 1]\n  %37[FLOAT, 20x40x5x5]\n  %38[FLOAT, 20]\n  %39[FLOAT, 1]\n  %40[FLOAT, 10x20x5x5]\n  %41[FLOAT, 10]\n  %42[FLOAT, 1]\n  %43[FLOAT, 24x18x3x3]\n  %44[FLOAT, 24]\n  %45[FLOAT, 1]\n  %46[FLOAT, 32x24x3x3]\n  %47[FLOAT, 32]\n  %48[FLOAT, 1]\n  %49[FLOAT, 32x16x4x4]\n  %50[FLOAT, 16]\n  %51[FLOAT, 1]\n  %52[FLOAT, 16x8x4x4]\n  %53[FLOAT, 8]\n  %54[FLOAT, 1]\n  %55[FLOAT, 1x8x1x1]\n  %56[FLOAT, 1]\n) {\n  %57 = Constant[value = &lt;Tensor&gt;]()\n  %58 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%57, %1, %2)\n  %59 = PRelu(%58, %3)\n  %60 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%59, %4, %5)\n  %61 = PRelu(%60, %6)\n  %62 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%61, %7, %8)\n  %63 = PRelu(%62, %9)\n  %64 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%63)\n  %65 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%64, %10, %11)\n  %66 = PRelu(%65, %12)\n  %67 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%66)\n  %68 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%67, %13, %14)\n  %69 = PRelu(%68, %15)\n  %70 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%69, %16, %17)\n  %71 = PRelu(%70, %18)\n  %72 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%61, %31, %32)\n  %73 = PRelu(%72, %33)\n  %74 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%73)\n  %75 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%74, %34, %35)\n  %76 = PRelu(%75, %36)\n  %77 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%76)\n  %78 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%77, %37, %38)\n  %79 = PRelu(%78, %39)\n  %80 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%79, %40, %41)\n  %81 = PRelu(%80, %42)\n  %82 = Concat[axis = 1](%71, %81)\n  %83 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%82, %43, %44)\n  %84 = PRelu(%83, %45)\n  %85 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%84, %46, %47)\n  %86 = PRelu(%85, %48)\n  %87 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%86, %49, %50)\n  %88 = PRelu(%87, %51)\n  %89 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%88, %52, %53)\n  %90 = PRelu(%89, %54)\n  %91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%90, %55, %56)\n  %92 = Relu(%91)\n  return %92\n}\n\n</code></pre>\n<p>When I try to use the model with <code>caffe2.python.onnx.backend.run_model(net, [input])</code> I get the following error.</p>\n<pre><code>Original python traceback for operator `3` in network `torch-jit-export_init` in exception above (most recent call last):\nTraceback (most recent call last):\n  File \"onnxTest.py\", line 16, in &lt;module&gt;\n    outputs = backend.run_model(net, [img])\n  File \"/home/garcir/Downloads/otros/onnx/onnx/backend/base.py\", line 76, in run_model\n    return backend.run(inputs)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/backend_rep.py\", line 55, in run\n    self.workspace.RunNet(self.init_net.name)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/workspace.py\", line 63, in f\n    return getattr(workspace, attr)(*args, **kwargs)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 217, in RunNet\n    StringifyNetName(name), num_iter, allow_fail,\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 178, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: [enforce fail at allocator.h:54] posix_memalign(&amp;data, gCaffe2Alignment, nbytes) == 0. 12 vs 0 Error from operator: \ninput: \"59\" input: \"4\" input: \"5\" output: \"60\" name: \"\" type: \"Conv\" arg { name: \"strides\" ints: 1 ints: 1 } arg { name: \"pads\" ints: 3 ints: 3 ints: 3 ints: 3 } arg { name: \"dilations\" ints: 1 ints: 1 } arg { name: \"kernels\" ints: 7 ints: 7 } arg { name: \"group\" i: 1 } device_option { device_type: 0 cuda_gpu_id: 0 }\n\n</code></pre>\n<h2>System Info</h2>\n<ul>\n<li>Built from source, command I used:</li>\n</ul>\n<pre><code>CONDA_INSTALL_LOCALLY=1 ./scripts/build_anaconda.sh --cuda 9.0 --cudnn 7 -DNCCL_ROOT_DIR:PATH=/home/garcir/anaconda3/envs/caffe2/lib -DCUDA_HOST_COMPILER=/home/garcir/anaconda3/envs/caffe2/bin/gcc -DUSE_MPI=OFF  -DUSE_CUDA=0N -DUSE_NCCL=ON ..\n</code></pre>\n<ul>\n<li>Script output:</li>\n</ul>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Debian GNU/Linux 9.4 (stretch)<br>\nGCC version: (GCC) 5.2.0<br>\nCMake version: version 3.9.5</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration: GPU 0: GeForce GTX 1070<br>\nNvidia driver version: 390.48<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.14.3)<br>\n[pip3] torch (0.4.0)<br>\n[pip3] torchvision (0.2.0)<br>\n[pip3] onnx (1.1.1)<br>\n[conda] cuda90                    1.0                  h6433d27_0    pytorch<br>\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  pytorch<br>\n[conda] torchvision               0.2.1                    py36_1    pytorch</p>", "body_text": "Issue description\nI am trying to deploy a Pytorch model in C++.  First I am exporting the the model with its weight to ONNX with the function torch.onnx.export(). Then importing it with onnn.load(). Calling onnx.helper.printable_graph produces this output:\ngraph torch-jit-export (\n  %0[FLOAT, 1x1x1080x1920]\n) initializers (\n  %1[FLOAT, 16x1x9x9]\n  %2[FLOAT, 16]\n  %3[FLOAT, 1]\n  %4[FLOAT, 32x16x7x7]\n  %5[FLOAT, 32]\n  %6[FLOAT, 1]\n  %7[FLOAT, 16x32x9x9]\n  %8[FLOAT, 16]\n  %9[FLOAT, 1]\n  %10[FLOAT, 32x16x7x7]\n  %11[FLOAT, 32]\n  %12[FLOAT, 1]\n  %13[FLOAT, 16x32x7x7]\n  %14[FLOAT, 16]\n  %15[FLOAT, 1]\n  %16[FLOAT, 8x16x7x7]\n  %17[FLOAT, 8]\n  %18[FLOAT, 1]\n  %19[FLOAT, 4x8x1x1]\n  %20[FLOAT, 4]\n  %21[FLOAT, 1]\n  %22[FLOAT, 512x4096]\n  %23[FLOAT, 512]\n  %24[FLOAT, 1]\n  %25[FLOAT, 256x512]\n  %26[FLOAT, 256]\n  %27[FLOAT, 1]\n  %28[FLOAT, 10x256]\n  %29[FLOAT, 10]\n  %30[FLOAT, 1]\n  %31[FLOAT, 20x32x7x7]\n  %32[FLOAT, 20]\n  %33[FLOAT, 1]\n  %34[FLOAT, 40x20x5x5]\n  %35[FLOAT, 40]\n  %36[FLOAT, 1]\n  %37[FLOAT, 20x40x5x5]\n  %38[FLOAT, 20]\n  %39[FLOAT, 1]\n  %40[FLOAT, 10x20x5x5]\n  %41[FLOAT, 10]\n  %42[FLOAT, 1]\n  %43[FLOAT, 24x18x3x3]\n  %44[FLOAT, 24]\n  %45[FLOAT, 1]\n  %46[FLOAT, 32x24x3x3]\n  %47[FLOAT, 32]\n  %48[FLOAT, 1]\n  %49[FLOAT, 32x16x4x4]\n  %50[FLOAT, 16]\n  %51[FLOAT, 1]\n  %52[FLOAT, 16x8x4x4]\n  %53[FLOAT, 8]\n  %54[FLOAT, 1]\n  %55[FLOAT, 1x8x1x1]\n  %56[FLOAT, 1]\n) {\n  %57 = Constant[value = <Tensor>]()\n  %58 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%57, %1, %2)\n  %59 = PRelu(%58, %3)\n  %60 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%59, %4, %5)\n  %61 = PRelu(%60, %6)\n  %62 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%61, %7, %8)\n  %63 = PRelu(%62, %9)\n  %64 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%63)\n  %65 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%64, %10, %11)\n  %66 = PRelu(%65, %12)\n  %67 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%66)\n  %68 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%67, %13, %14)\n  %69 = PRelu(%68, %15)\n  %70 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%69, %16, %17)\n  %71 = PRelu(%70, %18)\n  %72 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%61, %31, %32)\n  %73 = PRelu(%72, %33)\n  %74 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%73)\n  %75 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%74, %34, %35)\n  %76 = PRelu(%75, %36)\n  %77 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%76)\n  %78 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%77, %37, %38)\n  %79 = PRelu(%78, %39)\n  %80 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%79, %40, %41)\n  %81 = PRelu(%80, %42)\n  %82 = Concat[axis = 1](%71, %81)\n  %83 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%82, %43, %44)\n  %84 = PRelu(%83, %45)\n  %85 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%84, %46, %47)\n  %86 = PRelu(%85, %48)\n  %87 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%86, %49, %50)\n  %88 = PRelu(%87, %51)\n  %89 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%88, %52, %53)\n  %90 = PRelu(%89, %54)\n  %91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%90, %55, %56)\n  %92 = Relu(%91)\n  return %92\n}\n\n\nWhen I try to use the model with caffe2.python.onnx.backend.run_model(net, [input]) I get the following error.\nOriginal python traceback for operator `3` in network `torch-jit-export_init` in exception above (most recent call last):\nTraceback (most recent call last):\n  File \"onnxTest.py\", line 16, in <module>\n    outputs = backend.run_model(net, [img])\n  File \"/home/garcir/Downloads/otros/onnx/onnx/backend/base.py\", line 76, in run_model\n    return backend.run(inputs)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/backend_rep.py\", line 55, in run\n    self.workspace.RunNet(self.init_net.name)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/workspace.py\", line 63, in f\n    return getattr(workspace, attr)(*args, **kwargs)\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 217, in RunNet\n    StringifyNetName(name), num_iter, allow_fail,\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 178, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: [enforce fail at allocator.h:54] posix_memalign(&data, gCaffe2Alignment, nbytes) == 0. 12 vs 0 Error from operator: \ninput: \"59\" input: \"4\" input: \"5\" output: \"60\" name: \"\" type: \"Conv\" arg { name: \"strides\" ints: 1 ints: 1 } arg { name: \"pads\" ints: 3 ints: 3 ints: 3 ints: 3 } arg { name: \"dilations\" ints: 1 ints: 1 } arg { name: \"kernels\" ints: 7 ints: 7 } arg { name: \"group\" i: 1 } device_option { device_type: 0 cuda_gpu_id: 0 }\n\n\nSystem Info\n\nBuilt from source, command I used:\n\nCONDA_INSTALL_LOCALLY=1 ./scripts/build_anaconda.sh --cuda 9.0 --cudnn 7 -DNCCL_ROOT_DIR:PATH=/home/garcir/anaconda3/envs/caffe2/lib -DCUDA_HOST_COMPILER=/home/garcir/anaconda3/envs/caffe2/bin/gcc -DUSE_MPI=OFF  -DUSE_CUDA=0N -DUSE_NCCL=ON ..\n\n\nScript output:\n\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Debian GNU/Linux 9.4 (stretch)\nGCC version: (GCC) 5.2.0\nCMake version: version 3.9.5\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration: GPU 0: GeForce GTX 1070\nNvidia driver version: 390.48\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] torch (0.4.0)\n[pip3] torchvision (0.2.0)\n[pip3] onnx (1.1.1)\n[conda] cuda90                    1.0                  h6433d27_0    pytorch\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch", "body": "## Issue description\r\n\r\nI am trying to deploy a Pytorch model in C++.  First I am exporting the the model with its weight to ONNX with the function `torch.onnx.export()`. Then importing it with `onnn.load()`. Calling `onnx.helper.printable_graph` produces this output:\r\n\r\n```\r\ngraph torch-jit-export (\r\n  %0[FLOAT, 1x1x1080x1920]\r\n) initializers (\r\n  %1[FLOAT, 16x1x9x9]\r\n  %2[FLOAT, 16]\r\n  %3[FLOAT, 1]\r\n  %4[FLOAT, 32x16x7x7]\r\n  %5[FLOAT, 32]\r\n  %6[FLOAT, 1]\r\n  %7[FLOAT, 16x32x9x9]\r\n  %8[FLOAT, 16]\r\n  %9[FLOAT, 1]\r\n  %10[FLOAT, 32x16x7x7]\r\n  %11[FLOAT, 32]\r\n  %12[FLOAT, 1]\r\n  %13[FLOAT, 16x32x7x7]\r\n  %14[FLOAT, 16]\r\n  %15[FLOAT, 1]\r\n  %16[FLOAT, 8x16x7x7]\r\n  %17[FLOAT, 8]\r\n  %18[FLOAT, 1]\r\n  %19[FLOAT, 4x8x1x1]\r\n  %20[FLOAT, 4]\r\n  %21[FLOAT, 1]\r\n  %22[FLOAT, 512x4096]\r\n  %23[FLOAT, 512]\r\n  %24[FLOAT, 1]\r\n  %25[FLOAT, 256x512]\r\n  %26[FLOAT, 256]\r\n  %27[FLOAT, 1]\r\n  %28[FLOAT, 10x256]\r\n  %29[FLOAT, 10]\r\n  %30[FLOAT, 1]\r\n  %31[FLOAT, 20x32x7x7]\r\n  %32[FLOAT, 20]\r\n  %33[FLOAT, 1]\r\n  %34[FLOAT, 40x20x5x5]\r\n  %35[FLOAT, 40]\r\n  %36[FLOAT, 1]\r\n  %37[FLOAT, 20x40x5x5]\r\n  %38[FLOAT, 20]\r\n  %39[FLOAT, 1]\r\n  %40[FLOAT, 10x20x5x5]\r\n  %41[FLOAT, 10]\r\n  %42[FLOAT, 1]\r\n  %43[FLOAT, 24x18x3x3]\r\n  %44[FLOAT, 24]\r\n  %45[FLOAT, 1]\r\n  %46[FLOAT, 32x24x3x3]\r\n  %47[FLOAT, 32]\r\n  %48[FLOAT, 1]\r\n  %49[FLOAT, 32x16x4x4]\r\n  %50[FLOAT, 16]\r\n  %51[FLOAT, 1]\r\n  %52[FLOAT, 16x8x4x4]\r\n  %53[FLOAT, 8]\r\n  %54[FLOAT, 1]\r\n  %55[FLOAT, 1x8x1x1]\r\n  %56[FLOAT, 1]\r\n) {\r\n  %57 = Constant[value = <Tensor>]()\r\n  %58 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%57, %1, %2)\r\n  %59 = PRelu(%58, %3)\r\n  %60 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%59, %4, %5)\r\n  %61 = PRelu(%60, %6)\r\n  %62 = Conv[dilations = [1, 1], group = 1, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%61, %7, %8)\r\n  %63 = PRelu(%62, %9)\r\n  %64 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%63)\r\n  %65 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%64, %10, %11)\r\n  %66 = PRelu(%65, %12)\r\n  %67 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%66)\r\n  %68 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%67, %13, %14)\r\n  %69 = PRelu(%68, %15)\r\n  %70 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%69, %16, %17)\r\n  %71 = PRelu(%70, %18)\r\n  %72 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [1, 1]](%61, %31, %32)\r\n  %73 = PRelu(%72, %33)\r\n  %74 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%73)\r\n  %75 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%74, %34, %35)\r\n  %76 = PRelu(%75, %36)\r\n  %77 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%76)\r\n  %78 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%77, %37, %38)\r\n  %79 = PRelu(%78, %39)\r\n  %80 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%79, %40, %41)\r\n  %81 = PRelu(%80, %42)\r\n  %82 = Concat[axis = 1](%71, %81)\r\n  %83 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%82, %43, %44)\r\n  %84 = PRelu(%83, %45)\r\n  %85 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%84, %46, %47)\r\n  %86 = PRelu(%85, %48)\r\n  %87 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%86, %49, %50)\r\n  %88 = PRelu(%87, %51)\r\n  %89 = ConvTranspose[dilations = [1, 1], group = 1, kernel_shape = [4, 4], pads = [1, 1, 1, 1], strides = [2, 2]](%88, %52, %53)\r\n  %90 = PRelu(%89, %54)\r\n  %91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%90, %55, %56)\r\n  %92 = Relu(%91)\r\n  return %92\r\n}\r\n\r\n```\r\n\r\nWhen I try to use the model with `caffe2.python.onnx.backend.run_model(net, [input])` I get the following error.\r\n\r\n```\r\nOriginal python traceback for operator `3` in network `torch-jit-export_init` in exception above (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"onnxTest.py\", line 16, in <module>\r\n    outputs = backend.run_model(net, [img])\r\n  File \"/home/garcir/Downloads/otros/onnx/onnx/backend/base.py\", line 76, in run_model\r\n    return backend.run(inputs)\r\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/backend_rep.py\", line 55, in run\r\n    self.workspace.RunNet(self.init_net.name)\r\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/onnx/workspace.py\", line 63, in f\r\n    return getattr(workspace, attr)(*args, **kwargs)\r\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 217, in RunNet\r\n    StringifyNetName(name), num_iter, allow_fail,\r\n  File \"/home/garcir/anaconda3/envs/caffe2-test/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 178, in CallWithExceptionIntercept\r\n    return func(*args, **kwargs)\r\nRuntimeError: [enforce fail at allocator.h:54] posix_memalign(&data, gCaffe2Alignment, nbytes) == 0. 12 vs 0 Error from operator: \r\ninput: \"59\" input: \"4\" input: \"5\" output: \"60\" name: \"\" type: \"Conv\" arg { name: \"strides\" ints: 1 ints: 1 } arg { name: \"pads\" ints: 3 ints: 3 ints: 3 ints: 3 } arg { name: \"dilations\" ints: 1 ints: 1 } arg { name: \"kernels\" ints: 7 ints: 7 } arg { name: \"group\" i: 1 } device_option { device_type: 0 cuda_gpu_id: 0 }\r\n\r\n```\r\n\r\n## System Info\r\n- Built from source, command I used: \r\n```\r\nCONDA_INSTALL_LOCALLY=1 ./scripts/build_anaconda.sh --cuda 9.0 --cudnn 7 -DNCCL_ROOT_DIR:PATH=/home/garcir/anaconda3/envs/caffe2/lib -DCUDA_HOST_COMPILER=/home/garcir/anaconda3/envs/caffe2/bin/gcc -DUSE_MPI=OFF  -DUSE_CUDA=0N -DUSE_NCCL=ON ..\r\n```\r\n\r\n- Script output:\r\n\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Debian GNU/Linux 9.4 (stretch)\r\nGCC version: (GCC) 5.2.0\r\nCMake version: version 3.9.5\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: GPU 0: GeForce GTX 1070\r\nNvidia driver version: 390.48\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.3)\r\n[pip3] torch (0.4.0)\r\n[pip3] torchvision (0.2.0)\r\n[pip3] onnx (1.1.1)\r\n[conda] cuda90                    1.0                  h6433d27_0    pytorch\r\n[conda] pytorch                   0.4.0           py36_cuda9.0.176_cudnn7.1.2_1  [cuda90]  pytorch\r\n[conda] torchvision               0.2.1                    py36_1    pytorch"}