{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11231", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11231/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11231/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11231/events", "html_url": "https://github.com/pytorch/pytorch/pull/11231", "id": 356917132, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEzMDU4MjM2", "number": 11231, "title": " Optional expand=True kwarg in distribution.enumerate_support", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-04T18:02:56Z", "updated_at": "2018-09-07T04:40:52Z", "closed_at": "2018-09-07T04:40:52Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11231", "html_url": "https://github.com/pytorch/pytorch/pull/11231", "diff_url": "https://github.com/pytorch/pytorch/pull/11231.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11231.patch"}, "body_html": "<p>This adds an optional <code>expand=True</code> kwarg to the <code>distribution.expand_support()</code> method, to get a distribution's support without expanding the values over the distribution's <code>batch_shape</code>.</p>\n<ul>\n<li>The default <code>expand=True</code> preserves the current behavior, whereas <code>expand=False</code> collapses the batch dimensions.</li>\n</ul>\n<p>e.g.</p>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">47</span>]: d <span class=\"pl-k\">=</span> dist.OneHotCategorical(torch.ones(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">0.5</span>)\n\nIn [<span class=\"pl-c1\">48</span>]: d.batch_shape\nOut[<span class=\"pl-c1\">48</span>]: torch.Size([<span class=\"pl-c1\">3</span>])\n\nIn [<span class=\"pl-c1\">49</span>]: d.enumerate_support()\nOut[<span class=\"pl-c1\">49</span>]:\ntensor([[[<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>.],\n         [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>.]]])\n\nIn [<span class=\"pl-c1\">50</span>]: d.enumerate_support().shape\nOut[<span class=\"pl-c1\">50</span>]: torch.Size([<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>])\n\nIn [<span class=\"pl-c1\">51</span>]: d.enumerate_support(<span class=\"pl-v\">expand</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nOut[<span class=\"pl-c1\">51</span>]:\ntensor([[[<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>.]],\n\n        [[<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">1</span>.]]])\n\nIn [<span class=\"pl-c1\">52</span>]: d.enumerate_support(<span class=\"pl-v\">expand</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>).shape\nOut[<span class=\"pl-c1\">52</span>]: torch.Size([<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">5</span>])</pre></div>\n<p><strong>Motivation:</strong></p>\n<ul>\n<li>Currently <code>enumerate_support</code> builds up tensors of size <code>support + batch_shape + event_shape</code>, but the values are <em>repeated</em> over the <code>batch_shape</code> (adding little in the way of information). This can lead to expensive matrix operations over large tensors when <code>batch_shape</code> is large (see, example above), often leading to OOM issues. We use <code>expand=False</code> in Pyro for message passing inference. e.g. when enumerating over the state space in a Hidden Markov Model. This creates sparse tensors that capture the markov dependence, and allows for the possibility of using optimized matrix operations over these sparse tensors. <code>expand=True</code>, on the other hand, will create tensors that scale exponentially in size with the length of the Markov chain.</li>\n<li>We have been using this in our <a href=\"https://github.com/uber/pyro/blob/dev/pyro/distributions/torch.py\">patch</a> of <code>torch.distributions</code> in Pyro. The interface has been stable, and it is already being used in a few Pyro algorithms. We think that this is more broadly applicable and will be of interest to the larger distributions community.</li>\n</ul>\n<p>cc. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1093846\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alicanb\">@alicanb</a></p>", "body_text": "This adds an optional expand=True kwarg to the distribution.expand_support() method, to get a distribution's support without expanding the values over the distribution's batch_shape.\n\nThe default expand=True preserves the current behavior, whereas expand=False collapses the batch dimensions.\n\ne.g.\nIn [47]: d = dist.OneHotCategorical(torch.ones(3, 5) * 0.5)\n\nIn [48]: d.batch_shape\nOut[48]: torch.Size([3])\n\nIn [49]: d.enumerate_support()\nOut[49]:\ntensor([[[1., 0., 0., 0., 0.],\n         [1., 0., 0., 0., 0.],\n         [1., 0., 0., 0., 0.]],\n\n        [[0., 1., 0., 0., 0.],\n         [0., 1., 0., 0., 0.],\n         [0., 1., 0., 0., 0.]],\n\n        [[0., 0., 1., 0., 0.],\n         [0., 0., 1., 0., 0.],\n         [0., 0., 1., 0., 0.]],\n\n        [[0., 0., 0., 1., 0.],\n         [0., 0., 0., 1., 0.],\n         [0., 0., 0., 1., 0.]],\n\n        [[0., 0., 0., 0., 1.],\n         [0., 0., 0., 0., 1.],\n         [0., 0., 0., 0., 1.]]])\n\nIn [50]: d.enumerate_support().shape\nOut[50]: torch.Size([5, 3, 5])\n\nIn [51]: d.enumerate_support(expand=False)\nOut[51]:\ntensor([[[1., 0., 0., 0., 0.]],\n\n        [[0., 1., 0., 0., 0.]],\n\n        [[0., 0., 1., 0., 0.]],\n\n        [[0., 0., 0., 1., 0.]],\n\n        [[0., 0., 0., 0., 1.]]])\n\nIn [52]: d.enumerate_support(expand=False).shape\nOut[52]: torch.Size([5, 1, 5])\nMotivation:\n\nCurrently enumerate_support builds up tensors of size support + batch_shape + event_shape, but the values are repeated over the batch_shape (adding little in the way of information). This can lead to expensive matrix operations over large tensors when batch_shape is large (see, example above), often leading to OOM issues. We use expand=False in Pyro for message passing inference. e.g. when enumerating over the state space in a Hidden Markov Model. This creates sparse tensors that capture the markov dependence, and allows for the possibility of using optimized matrix operations over these sparse tensors. expand=True, on the other hand, will create tensors that scale exponentially in size with the length of the Markov chain.\nWe have been using this in our patch of torch.distributions in Pyro. The interface has been stable, and it is already being used in a few Pyro algorithms. We think that this is more broadly applicable and will be of interest to the larger distributions community.\n\ncc. @apaszke, @fritzo, @alicanb", "body": "This adds an optional `expand=True` kwarg to the `distribution.expand_support()` method, to get a distribution's support without expanding the values over the distribution's `batch_shape`. \r\n - The default `expand=True` preserves the current behavior, whereas `expand=False` collapses the batch dimensions.\r\n\r\ne.g.\r\n```python\r\nIn [47]: d = dist.OneHotCategorical(torch.ones(3, 5) * 0.5)\r\n\r\nIn [48]: d.batch_shape\r\nOut[48]: torch.Size([3])\r\n\r\nIn [49]: d.enumerate_support()\r\nOut[49]:\r\ntensor([[[1., 0., 0., 0., 0.],\r\n         [1., 0., 0., 0., 0.],\r\n         [1., 0., 0., 0., 0.]],\r\n\r\n        [[0., 1., 0., 0., 0.],\r\n         [0., 1., 0., 0., 0.],\r\n         [0., 1., 0., 0., 0.]],\r\n\r\n        [[0., 0., 1., 0., 0.],\r\n         [0., 0., 1., 0., 0.],\r\n         [0., 0., 1., 0., 0.]],\r\n\r\n        [[0., 0., 0., 1., 0.],\r\n         [0., 0., 0., 1., 0.],\r\n         [0., 0., 0., 1., 0.]],\r\n\r\n        [[0., 0., 0., 0., 1.],\r\n         [0., 0., 0., 0., 1.],\r\n         [0., 0., 0., 0., 1.]]])\r\n\r\nIn [50]: d.enumerate_support().shape\r\nOut[50]: torch.Size([5, 3, 5])\r\n\r\nIn [51]: d.enumerate_support(expand=False)\r\nOut[51]:\r\ntensor([[[1., 0., 0., 0., 0.]],\r\n\r\n        [[0., 1., 0., 0., 0.]],\r\n\r\n        [[0., 0., 1., 0., 0.]],\r\n\r\n        [[0., 0., 0., 1., 0.]],\r\n\r\n        [[0., 0., 0., 0., 1.]]])\r\n\r\nIn [52]: d.enumerate_support(expand=False).shape\r\nOut[52]: torch.Size([5, 1, 5])\r\n```\r\n\r\n**Motivation:**\r\n - Currently `enumerate_support` builds up tensors of size `support + batch_shape + event_shape`, but the values are *repeated* over the `batch_shape` (adding little in the way of information). This can lead to expensive matrix operations over large tensors when `batch_shape` is large (see, example above), often leading to OOM issues. We use `expand=False` in Pyro for message passing inference. e.g. when enumerating over the state space in a Hidden Markov Model. This creates sparse tensors that capture the markov dependence, and allows for the possibility of using optimized matrix operations over these sparse tensors. `expand=True`, on the other hand, will create tensors that scale exponentially in size with the length of the Markov chain.\r\n - We have been using this in our [patch](https://github.com/uber/pyro/blob/dev/pyro/distributions/torch.py) of `torch.distributions` in Pyro. The interface has been stable, and it is already being used in a few Pyro algorithms. We think that this is more broadly applicable and will be of interest to the larger distributions community.\r\n\r\ncc. @apaszke, @fritzo, @alicanb \r\n"}