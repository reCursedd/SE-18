{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/415149443", "html_url": "https://github.com/pytorch/pytorch/issues/10723#issuecomment-415149443", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10723", "id": 415149443, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTE0OTQ0Mw==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-22T19:22:36Z", "updated_at": "2018-08-22T19:25:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>backtrace:</p>\n<pre><code>(gdb) bt\n#0  0x00007fffcb14b598 in at::TensorImpl::is_empty (this=0x0) at /home/rzou/pt/master/aten/src/ATen/TensorImpl.h:124\n#1  0x00007fffcb14b5fb in THTensor_nDimensionLegacyAll (tensor=0x0) at /home/rzou/pt/master/aten/src/TH/THTensor.hpp:70\n#2  0x00007fffcd021dd6 in THCTensor_nElement (state=0x55555678eb70, self=0x0) at ../aten/src/THC/THCTensor.cpp:287\n#3  0x00007fffcc83d2ff in THC_pointwiseApply3&lt;float, float, float, at::TensorImpl, at::TensorImpl, at::TensorImpl, PReLUAccGradParametersShared&lt;float&gt; &gt; (\n    state=0x55555678eb70, a=0x0, b=0x555556cf2b10, c=0x7fff740020c0, op=..., aType=ReadWrite, bType=ReadOnly, cType=ReadOnly)\n    at /home/rzou/pt/master/aten/src/THC/THCApply.cuh:523\n#4  0x00007fffcc7f7464 in THNN_CudaPReLU_accGradParameters (state=0x55555678eb70, input=0x555556cf2b10, gradOutput=0x7fff740020c0, gradInput=0x0,\n    weight=0x55557e434bb0, gradWeight=0x7fff74002c00, scale_=1) at /home/rzou/pt/master/aten/src/THCUNN/generic/PReLU.cu:110\n#5  0x00007fffccf22a6f in at::CUDAFloatType::prelu_backward (this=0x55555684fa70, grad_output=..., self=..., weight=..., output_mask=...)\n    at aten/src/ATen/CUDAFloatType.cpp:4159\n#6  0x00007fffc9b16262 in torch::autograd::VariableType::prelu_backward (this=0x55555684f9e0, grad_output=..., self=..., weight=..., output_mask=...)\n    at ../torch/csrc/autograd/generated/VariableType.cpp:12804\n#7  0x00007fffc9a20368 in at::prelu_backward (grad_output=..., self=..., weight=..., output_mask=...) at aten/src/ATen/Functions.h:2329\n#8  0x00007fffc9a5c0d6 in torch::autograd::generated::PreluBackward::apply (this=0x55557e433ab0, grads=...)\n    at ../torch/csrc/autograd/generated/Functions.cpp:5033\n#9  0x00007fffc99f43c9 in torch::autograd::Function::operator() (this=0x55557e433ab0, inputs=...) at ../torch/csrc/autograd/function.h:117\n#10 0x00007fffc99ee637 in torch::autograd::call_function (task=...) at ../torch/csrc/autograd/engine.cpp:368\n#11 0x00007fffc99ee9c4 in torch::autograd::Engine::evaluate_function (this=0x7fffddf79480 &lt;engine&gt;, task=...) at ../torch/csrc/autograd/engine.cpp:398\n#12 0x00007fffc99edd7f in torch::autograd::Engine::thread_main (this=0x7fffddf79480 &lt;engine&gt;, graph_task=0x0) at ../torch/csrc/autograd/engine.cpp:237\n#13 0x00007fffc99edc57 in torch::autograd::Engine::thread_init (this=0x7fffddf79480 &lt;engine&gt;, device=0) at ../torch/csrc/autograd/engine.cpp:211\n#14 0x00007fffdd646ea5 in torch::autograd::python::PythonEngine::thread_init (this=0x7fffddf79480 &lt;engine&gt;, device=0)\n</code></pre>\n<p><del>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> maybe?</del> nvm, the problem looks like we're trying to call numel on a NULL tensor</p>", "body_text": "backtrace:\n(gdb) bt\n#0  0x00007fffcb14b598 in at::TensorImpl::is_empty (this=0x0) at /home/rzou/pt/master/aten/src/ATen/TensorImpl.h:124\n#1  0x00007fffcb14b5fb in THTensor_nDimensionLegacyAll (tensor=0x0) at /home/rzou/pt/master/aten/src/TH/THTensor.hpp:70\n#2  0x00007fffcd021dd6 in THCTensor_nElement (state=0x55555678eb70, self=0x0) at ../aten/src/THC/THCTensor.cpp:287\n#3  0x00007fffcc83d2ff in THC_pointwiseApply3<float, float, float, at::TensorImpl, at::TensorImpl, at::TensorImpl, PReLUAccGradParametersShared<float> > (\n    state=0x55555678eb70, a=0x0, b=0x555556cf2b10, c=0x7fff740020c0, op=..., aType=ReadWrite, bType=ReadOnly, cType=ReadOnly)\n    at /home/rzou/pt/master/aten/src/THC/THCApply.cuh:523\n#4  0x00007fffcc7f7464 in THNN_CudaPReLU_accGradParameters (state=0x55555678eb70, input=0x555556cf2b10, gradOutput=0x7fff740020c0, gradInput=0x0,\n    weight=0x55557e434bb0, gradWeight=0x7fff74002c00, scale_=1) at /home/rzou/pt/master/aten/src/THCUNN/generic/PReLU.cu:110\n#5  0x00007fffccf22a6f in at::CUDAFloatType::prelu_backward (this=0x55555684fa70, grad_output=..., self=..., weight=..., output_mask=...)\n    at aten/src/ATen/CUDAFloatType.cpp:4159\n#6  0x00007fffc9b16262 in torch::autograd::VariableType::prelu_backward (this=0x55555684f9e0, grad_output=..., self=..., weight=..., output_mask=...)\n    at ../torch/csrc/autograd/generated/VariableType.cpp:12804\n#7  0x00007fffc9a20368 in at::prelu_backward (grad_output=..., self=..., weight=..., output_mask=...) at aten/src/ATen/Functions.h:2329\n#8  0x00007fffc9a5c0d6 in torch::autograd::generated::PreluBackward::apply (this=0x55557e433ab0, grads=...)\n    at ../torch/csrc/autograd/generated/Functions.cpp:5033\n#9  0x00007fffc99f43c9 in torch::autograd::Function::operator() (this=0x55557e433ab0, inputs=...) at ../torch/csrc/autograd/function.h:117\n#10 0x00007fffc99ee637 in torch::autograd::call_function (task=...) at ../torch/csrc/autograd/engine.cpp:368\n#11 0x00007fffc99ee9c4 in torch::autograd::Engine::evaluate_function (this=0x7fffddf79480 <engine>, task=...) at ../torch/csrc/autograd/engine.cpp:398\n#12 0x00007fffc99edd7f in torch::autograd::Engine::thread_main (this=0x7fffddf79480 <engine>, graph_task=0x0) at ../torch/csrc/autograd/engine.cpp:237\n#13 0x00007fffc99edc57 in torch::autograd::Engine::thread_init (this=0x7fffddf79480 <engine>, device=0) at ../torch/csrc/autograd/engine.cpp:211\n#14 0x00007fffdd646ea5 in torch::autograd::python::PythonEngine::thread_init (this=0x7fffddf79480 <engine>, device=0)\n\ncc @gchanan maybe? nvm, the problem looks like we're trying to call numel on a NULL tensor", "body": "backtrace:\r\n```\r\n(gdb) bt\r\n#0  0x00007fffcb14b598 in at::TensorImpl::is_empty (this=0x0) at /home/rzou/pt/master/aten/src/ATen/TensorImpl.h:124\r\n#1  0x00007fffcb14b5fb in THTensor_nDimensionLegacyAll (tensor=0x0) at /home/rzou/pt/master/aten/src/TH/THTensor.hpp:70\r\n#2  0x00007fffcd021dd6 in THCTensor_nElement (state=0x55555678eb70, self=0x0) at ../aten/src/THC/THCTensor.cpp:287\r\n#3  0x00007fffcc83d2ff in THC_pointwiseApply3<float, float, float, at::TensorImpl, at::TensorImpl, at::TensorImpl, PReLUAccGradParametersShared<float> > (\r\n    state=0x55555678eb70, a=0x0, b=0x555556cf2b10, c=0x7fff740020c0, op=..., aType=ReadWrite, bType=ReadOnly, cType=ReadOnly)\r\n    at /home/rzou/pt/master/aten/src/THC/THCApply.cuh:523\r\n#4  0x00007fffcc7f7464 in THNN_CudaPReLU_accGradParameters (state=0x55555678eb70, input=0x555556cf2b10, gradOutput=0x7fff740020c0, gradInput=0x0,\r\n    weight=0x55557e434bb0, gradWeight=0x7fff74002c00, scale_=1) at /home/rzou/pt/master/aten/src/THCUNN/generic/PReLU.cu:110\r\n#5  0x00007fffccf22a6f in at::CUDAFloatType::prelu_backward (this=0x55555684fa70, grad_output=..., self=..., weight=..., output_mask=...)\r\n    at aten/src/ATen/CUDAFloatType.cpp:4159\r\n#6  0x00007fffc9b16262 in torch::autograd::VariableType::prelu_backward (this=0x55555684f9e0, grad_output=..., self=..., weight=..., output_mask=...)\r\n    at ../torch/csrc/autograd/generated/VariableType.cpp:12804\r\n#7  0x00007fffc9a20368 in at::prelu_backward (grad_output=..., self=..., weight=..., output_mask=...) at aten/src/ATen/Functions.h:2329\r\n#8  0x00007fffc9a5c0d6 in torch::autograd::generated::PreluBackward::apply (this=0x55557e433ab0, grads=...)\r\n    at ../torch/csrc/autograd/generated/Functions.cpp:5033\r\n#9  0x00007fffc99f43c9 in torch::autograd::Function::operator() (this=0x55557e433ab0, inputs=...) at ../torch/csrc/autograd/function.h:117\r\n#10 0x00007fffc99ee637 in torch::autograd::call_function (task=...) at ../torch/csrc/autograd/engine.cpp:368\r\n#11 0x00007fffc99ee9c4 in torch::autograd::Engine::evaluate_function (this=0x7fffddf79480 <engine>, task=...) at ../torch/csrc/autograd/engine.cpp:398\r\n#12 0x00007fffc99edd7f in torch::autograd::Engine::thread_main (this=0x7fffddf79480 <engine>, graph_task=0x0) at ../torch/csrc/autograd/engine.cpp:237\r\n#13 0x00007fffc99edc57 in torch::autograd::Engine::thread_init (this=0x7fffddf79480 <engine>, device=0) at ../torch/csrc/autograd/engine.cpp:211\r\n#14 0x00007fffdd646ea5 in torch::autograd::python::PythonEngine::thread_init (this=0x7fffddf79480 <engine>, device=0)\r\n```\r\n~~cc @gchanan maybe?~~ nvm, the problem looks like we're trying to call numel on a NULL tensor"}