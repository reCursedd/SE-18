{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/146520365", "pull_request_review_id": 71471789, "id": 146520365, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NjUyMDM2NQ==", "diff_hunk": "@@ -75,18 +75,32 @@ follows::\n       x = x.cuda()\n       net.cuda()\n \n-To avoid the if statement for tensors, an alternative is to have a default\n+When working with multiple GPUs on a system, you can use the\n+`CUDA_VISIBLE_DEVICES` environment flag to manage which GPUs are available to\n+PyTorch. To manually control which GPU a tensor is created on, the best practice\n+is to use the `torch.cuda.device()` context manager::\n+\n+    torch.cuda.set_device(0)\n+    print(\"Outside device is 0\")  # On device 0\n+    with torch.cuda.device(1):\n+        print(\"Inside device is 1\")  # On device 1\n+    print(\"Outside device is still 0\")  # On device 0\n+\n+When creating tensors, an alternative to the if statement is to have a default\n datatype defined, and cast all tensors using that. An example when using a\n dataloader would be as follows::\n \n     dtype = torch.cuda.FloatTensor\n     for i, x in enumerate(train_loader):\n         x = Variable(x.type(dtype))\n \n-If you have a tensor and would like to create a new tensor of the same type,\n-then you can use the `.new()` function, which acts the same as a normal tensor\n-constructor. This is the recommended practice when creating modules in which\n-new tensors/variables need to be created internally during the forward pass::\n+If you have a tensor and would like to create a new tensor of the same type on", "path": "docs/source/notes/cuda.rst", "position": null, "original_position": 28, "commit_id": "6e601f3b99d6c2ade77ecfbb2805f640e697b124", "original_commit_id": "9ccd3f30ff8bbf6a9357e82fd7357539b0b0f34f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I think a better way to structure this would be to list all methods, and then mention that they all have the downside that they depend on the GPU context. Then, show `torch.cuda.device` (and please remove `torch.cuda.set_device`, it's mostly meant to be a helper for IPython notebooks and not for scripts in general where you can use `CUDA_VISIBLE_DEVICES`). Then, mention `new` and say that it preserves everything", "created_at": "2017-10-24T10:44:03Z", "updated_at": "2018-11-23T15:35:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/3227#discussion_r146520365", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3227", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/146520365"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3227#discussion_r146520365"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3227"}}, "body_html": "<p>I think a better way to structure this would be to list all methods, and then mention that they all have the downside that they depend on the GPU context. Then, show <code>torch.cuda.device</code> (and please remove <code>torch.cuda.set_device</code>, it's mostly meant to be a helper for IPython notebooks and not for scripts in general where you can use <code>CUDA_VISIBLE_DEVICES</code>). Then, mention <code>new</code> and say that it preserves everything</p>", "body_text": "I think a better way to structure this would be to list all methods, and then mention that they all have the downside that they depend on the GPU context. Then, show torch.cuda.device (and please remove torch.cuda.set_device, it's mostly meant to be a helper for IPython notebooks and not for scripts in general where you can use CUDA_VISIBLE_DEVICES). Then, mention new and say that it preserves everything"}