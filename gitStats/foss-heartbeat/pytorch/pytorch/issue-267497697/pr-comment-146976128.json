{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/146976128", "pull_request_review_id": 72000108, "id": 146976128, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0Njk3NjEyOA==", "diff_hunk": "@@ -75,18 +75,32 @@ follows::\n       x = x.cuda()\n       net.cuda()\n \n-To avoid the if statement for tensors, an alternative is to have a default\n+When working with multiple GPUs on a system, you can use the\n+`CUDA_VISIBLE_DEVICES` environment flag to manage which GPUs are available to\n+PyTorch. To manually control which GPU a tensor is created on, the best practice\n+is to use the `torch.cuda.device()` context manager::\n+\n+    torch.cuda.set_device(0)\n+    print(\"Outside device is 0\")  # On device 0\n+    with torch.cuda.device(1):\n+        print(\"Inside device is 1\")  # On device 1\n+    print(\"Outside device is still 0\")  # On device 0\n+\n+When creating tensors, an alternative to the if statement is to have a default\n datatype defined, and cast all tensors using that. An example when using a\n dataloader would be as follows::\n \n     dtype = torch.cuda.FloatTensor\n     for i, x in enumerate(train_loader):\n         x = Variable(x.type(dtype))\n \n-If you have a tensor and would like to create a new tensor of the same type,\n-then you can use the `.new()` function, which acts the same as a normal tensor\n-constructor. This is the recommended practice when creating modules in which\n-new tensors/variables need to be created internally during the forward pass::\n+If you have a tensor and would like to create a new tensor of the same type on", "path": "docs/source/notes/cuda.rst", "position": null, "original_position": 28, "commit_id": "6e601f3b99d6c2ade77ecfbb2805f640e697b124", "original_commit_id": "9ccd3f30ff8bbf6a9357e82fd7357539b0b0f34f", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "body": "Done. I now also noted that `ones_like` and `zeros_like` also preserve device - can you confirm?", "created_at": "2017-10-25T20:24:07Z", "updated_at": "2018-11-23T15:35:41Z", "html_url": "https://github.com/pytorch/pytorch/pull/3227#discussion_r146976128", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3227", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/146976128"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3227#discussion_r146976128"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3227"}}, "body_html": "<p>Done. I now also noted that <code>ones_like</code> and <code>zeros_like</code> also preserve device - can you confirm?</p>", "body_text": "Done. I now also noted that ones_like and zeros_like also preserve device - can you confirm?", "in_reply_to_id": 146520365}