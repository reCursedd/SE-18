{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7321", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7321/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7321/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7321/events", "html_url": "https://github.com/pytorch/pytorch/issues/7321", "id": 320536377, "node_id": "MDU6SXNzdWUzMjA1MzYzNzc=", "number": 7321, "title": "Adagrad not working with GPU", "user": {"login": "NiccoloSacchi", "id": 26500542, "node_id": "MDQ6VXNlcjI2NTAwNTQy", "avatar_url": "https://avatars1.githubusercontent.com/u/26500542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NiccoloSacchi", "html_url": "https://github.com/NiccoloSacchi", "followers_url": "https://api.github.com/users/NiccoloSacchi/followers", "following_url": "https://api.github.com/users/NiccoloSacchi/following{/other_user}", "gists_url": "https://api.github.com/users/NiccoloSacchi/gists{/gist_id}", "starred_url": "https://api.github.com/users/NiccoloSacchi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NiccoloSacchi/subscriptions", "organizations_url": "https://api.github.com/users/NiccoloSacchi/orgs", "repos_url": "https://api.github.com/users/NiccoloSacchi/repos", "events_url": "https://api.github.com/users/NiccoloSacchi/events{/privacy}", "received_events_url": "https://api.github.com/users/NiccoloSacchi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-05T19:44:20Z", "updated_at": "2018-05-06T09:15:35Z", "closed_at": "2018-05-06T00:57:26Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>The code below is a simple example which raises</p>\n<blockquote>\n<p>RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171522963\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4\">#4</a> 'tensor1'</p>\n</blockquote>\n<p>when calling .step().<br>\nIt looks like Adagrad works correctly when using the cpu while Adam optimizer works correctly with both cpu and gpu.<br>\nMoreover, Adagrad works correctly if initialized after moving the parameters of the model (in this case a Linear) to the gpu.</p>\n<h2>Code example</h2>\n<p>import torch<br>\nfrom torch import nn<br>\nfrom torch import optim</p>\n<p>device = torch.device(\"cuda:0\")<br>\n#device = torch.device(\"cpu\") # works correctly on cpu</p>\n<p>x = torch.Tensor(10, 2).to(device)<br>\nlinear = nn.Linear(2, 4)#.to(device) # works correctly when moving the parameters to gpu before initializing Adagrad</p>\n<p>o = optim.Adagrad(linear.parameters())<br>\n#o = optim.Adam(linear.parameters()) # works correctly with Adam</p>\n<p>linear.to(device)</p>\n<p>linear(x).mean().backward()<br>\no.step()</p>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 16.04.3 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 8.0.44<br>\nGPU models and configuration:<br>\nGPU 0: TITAN X (Pascal)<br>\nGPU 1: TITAN X (Pascal)<br>\nGPU 2: TITAN X (Pascal)<br>\nGPU 3: TITAN X (Pascal)</p>\n<p>Nvidia driver version: 384.130<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/MATLAB/R2016a/bin/glnxa64/libcudnn.so.7.0.64</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.11.3)<br>\n[pip] numpydoc (0.6.0)<br>\n[pip] torch (0.4.0)<br>\n[pip] torchvision (0.1.9)<br>\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch<br>\n[conda] torchvision               0.1.9            py36h7584368_1    soumith</p>", "body_text": "Issue description\nThe code below is a simple example which raises\n\nRuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #4 'tensor1'\n\nwhen calling .step().\nIt looks like Adagrad works correctly when using the cpu while Adam optimizer works correctly with both cpu and gpu.\nMoreover, Adagrad works correctly if initialized after moving the parameters of the model (in this case a Linear) to the gpu.\nCode example\nimport torch\nfrom torch import nn\nfrom torch import optim\ndevice = torch.device(\"cuda:0\")\n#device = torch.device(\"cpu\") # works correctly on cpu\nx = torch.Tensor(10, 2).to(device)\nlinear = nn.Linear(2, 4)#.to(device) # works correctly when moving the parameters to gpu before initializing Adagrad\no = optim.Adagrad(linear.parameters())\n#o = optim.Adam(linear.parameters()) # works correctly with Adam\nlinear.to(device)\nlinear(x).mean().backward()\no.step()\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.44\nGPU models and configuration:\nGPU 0: TITAN X (Pascal)\nGPU 1: TITAN X (Pascal)\nGPU 2: TITAN X (Pascal)\nGPU 3: TITAN X (Pascal)\nNvidia driver version: 384.130\ncuDNN version: Probably one of the following:\n/usr/local/MATLAB/R2016a/bin/glnxa64/libcudnn.so.7.0.64\nVersions of relevant libraries:\n[pip] numpy (1.11.3)\n[pip] numpydoc (0.6.0)\n[pip] torch (0.4.0)\n[pip] torchvision (0.1.9)\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch\n[conda] torchvision               0.1.9            py36h7584368_1    soumith", "body": "## Issue description\r\n\r\nThe code below is a simple example which raises \r\n\r\n> RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #4 'tensor1'\r\n\r\nwhen calling .step(). \r\nIt looks like Adagrad works correctly when using the cpu while Adam optimizer works correctly with both cpu and gpu. \r\nMoreover, Adagrad works correctly if initialized after moving the parameters of the model (in this case a Linear) to the gpu.\r\n\r\n## Code example\r\n\r\nimport torch\r\nfrom torch import nn\r\nfrom torch import optim\r\n\r\ndevice = torch.device(\"cuda:0\")\r\n#device = torch.device(\"cpu\") # works correctly on cpu\r\n\r\nx = torch.Tensor(10, 2).to(device)\r\nlinear = nn.Linear(2, 4)#.to(device) # works correctly when moving the parameters to gpu before initializing Adagrad\r\n\r\no = optim.Adagrad(linear.parameters())\r\n#o = optim.Adam(linear.parameters()) # works correctly with Adam\r\n\r\nlinear.to(device)\r\n\r\nlinear(x).mean().backward()\r\no.step()\r\n\r\n## System Info\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.44\r\nGPU models and configuration: \r\nGPU 0: TITAN X (Pascal)\r\nGPU 1: TITAN X (Pascal)\r\nGPU 2: TITAN X (Pascal)\r\nGPU 3: TITAN X (Pascal)\r\n\r\nNvidia driver version: 384.130\r\ncuDNN version: Probably one of the following:\r\n/usr/local/MATLAB/R2016a/bin/glnxa64/libcudnn.so.7.0.64\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.11.3)\r\n[pip] numpydoc (0.6.0)\r\n[pip] torch (0.4.0)\r\n[pip] torchvision (0.1.9)\r\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch\r\n[conda] torchvision               0.1.9            py36h7584368_1    soumith"}