{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/298182853", "html_url": "https://github.com/pytorch/pytorch/pull/1349#issuecomment-298182853", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1349", "id": 298182853, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODE4Mjg1Mw==", "user": {"login": "bodokaiser", "id": 1780466, "node_id": "MDQ6VXNlcjE3ODA0NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1780466?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bodokaiser", "html_url": "https://github.com/bodokaiser", "followers_url": "https://api.github.com/users/bodokaiser/followers", "following_url": "https://api.github.com/users/bodokaiser/following{/other_user}", "gists_url": "https://api.github.com/users/bodokaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/bodokaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bodokaiser/subscriptions", "organizations_url": "https://api.github.com/users/bodokaiser/orgs", "repos_url": "https://api.github.com/users/bodokaiser/repos", "events_url": "https://api.github.com/users/bodokaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/bodokaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-29T17:33:20Z", "updated_at": "2017-04-29T17:33:28Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a></p>\n<p>I also thought of a version which would supports arbitrary dimensions (passes tests too).</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">center_crop</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">args</span>):\n    size <span class=\"pl-k\">=</span> x.size()[<span class=\"pl-c1\">2</span>:]\n    ndim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(size)\n    <span class=\"pl-k\">assert</span> ndim <span class=\"pl-k\">==</span> <span class=\"pl-c1\">len</span>(args), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Crop dimensions do not match input dimensions<span class=\"pl-pds\">'</span></span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">crop</span>(<span class=\"pl-smi\">y</span>, <span class=\"pl-smi\">dim</span>):\n        offset <span class=\"pl-k\">=</span> math.ceil((size[dim] <span class=\"pl-k\">-</span> args[dim]) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">2</span>)\n        length <span class=\"pl-k\">=</span> size[dim] <span class=\"pl-k\">-</span> offset\n        indices <span class=\"pl-k\">=</span> torch.arange(offset, length)\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(x, autograd.Variable):\n            indices <span class=\"pl-k\">=</span> autograd.Variable(indices)\n        y <span class=\"pl-k\">=</span> y.index_select(<span class=\"pl-c1\">2</span> <span class=\"pl-k\">+</span> dim, indices.long())\n        <span class=\"pl-k\">if</span> dim <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n            <span class=\"pl-k\">return</span> y\n        <span class=\"pl-k\">return</span> crop(y, dim <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">return</span> crop(x, ndim <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)</pre></div>", "body_text": "@apaszke @fmassa\nI also thought of a version which would supports arbitrary dimensions (passes tests too).\ndef center_crop(x, *args):\n    size = x.size()[2:]\n    ndim = len(size)\n    assert ndim == len(args), 'Crop dimensions do not match input dimensions'\n    def crop(y, dim):\n        offset = math.ceil((size[dim] - args[dim]) / 2)\n        length = size[dim] - offset\n        indices = torch.arange(offset, length)\n        if isinstance(x, autograd.Variable):\n            indices = autograd.Variable(indices)\n        y = y.index_select(2 + dim, indices.long())\n        if dim == 0:\n            return y\n        return crop(y, dim - 1)\n    return crop(x, ndim - 1)", "body": "@apaszke @fmassa \r\n\r\nI also thought of a version which would supports arbitrary dimensions (passes tests too).\r\n\r\n```python\r\ndef center_crop(x, *args):\r\n    size = x.size()[2:]\r\n    ndim = len(size)\r\n    assert ndim == len(args), 'Crop dimensions do not match input dimensions'\r\n    def crop(y, dim):\r\n        offset = math.ceil((size[dim] - args[dim]) / 2)\r\n        length = size[dim] - offset\r\n        indices = torch.arange(offset, length)\r\n        if isinstance(x, autograd.Variable):\r\n            indices = autograd.Variable(indices)\r\n        y = y.index_select(2 + dim, indices.long())\r\n        if dim == 0:\r\n            return y\r\n        return crop(y, dim - 1)\r\n    return crop(x, ndim - 1)\r\n```"}