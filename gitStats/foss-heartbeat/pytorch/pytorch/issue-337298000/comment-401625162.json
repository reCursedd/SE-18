{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/401625162", "html_url": "https://github.com/pytorch/pytorch/issues/9079#issuecomment-401625162", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9079", "id": 401625162, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTYyNTE2Mg==", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-01T18:46:07Z", "updated_at": "2018-07-01T18:46:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>No, it's broken for square matrices too.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> U, S, V <span class=\"pl-k\">=</span> a.svd()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Without CUDA</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> U_c, S_c, V_c <span class=\"pl-k\">=</span> a.cuda().svd()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> With CUDA</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> (U <span class=\"pl-k\">-</span> U_c.cpu()).norm()\ntensor(<span class=\"pl-c1\">1.4447</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> (S <span class=\"pl-k\">-</span> S_c.cpu()).norm()\ntensor(<span class=\"pl-c1\">6.9510e-07</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> (V <span class=\"pl-k\">-</span> V_c.cpu()).norm()\ntensor(<span class=\"pl-c1\">1.4447</span>)</pre></div>", "body_text": "No, it's broken for square matrices too.\n>>> import torch\n>>> a = torch.randn(3, 3)\n>>> U, S, V = a.svd()  # Without CUDA\n>>> U_c, S_c, V_c = a.cuda().svd()  # With CUDA\n>>> (U - U_c.cpu()).norm()\ntensor(1.4447)\n>>> (S - S_c.cpu()).norm()\ntensor(6.9510e-07)\n>>> (V - V_c.cpu()).norm()\ntensor(1.4447)", "body": "No, it's broken for square matrices too.\r\n\r\n```python\r\n>>> import torch\r\n>>> a = torch.randn(3, 3)\r\n>>> U, S, V = a.svd()  # Without CUDA\r\n>>> U_c, S_c, V_c = a.cuda().svd()  # With CUDA\r\n>>> (U - U_c.cpu()).norm()\r\ntensor(1.4447)\r\n>>> (S - S_c.cpu()).norm()\r\ntensor(6.9510e-07)\r\n>>> (V - V_c.cpu()).norm()\r\ntensor(1.4447)\r\n```"}