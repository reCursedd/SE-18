{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166075339", "pull_request_review_id": 94102327, "id": 166075339, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjA3NTMzOQ==", "diff_hunk": "@@ -116,29 +97,37 @@ static Value* createZerosLike(Value *v) {\n static Value* createUndefGuard(Value * dv, Value * alternative) {\n   Graph* graph = dv->owningGraph();\n   Node * n = graph->create(kReplaceIfUndef, {dv, alternative});\n-  return graph->appendNode(n)->output();\n+  return graph->insertNode(n)->output();\n }\n \n struct ReverseDetails {\n-  ReverseDetails(value_map&& grad_map, value_set&& requires_grad_set)\n+  ReverseDetails(value_map&& grad_map, value_set&& requires_grad_set, Block * reverse_block)\n     : grad_map(std::move(grad_map))\n-    , requires_grad_set(std::move(requires_grad_set)) {}\n+    , requires_grad_set(std::move(requires_grad_set))\n+    , reverse_block(reverse_block) {}\n \n   value_map grad_map;\n   value_set requires_grad_set;\n+  Block * reverse_block;\n };\n \n // Before:\n-//   - graph has only stage 0\n-//   - grad_desc doesn't have any fields initialized\n+//   - grad_desc has field f initialized to the original 0-stage graph\n // After:\n-//   - graph has stage 0 and stage 1 that computes its vjp\n+//   - the last node of f (f->nodes().reverse()[0]) is a gradient node\n+//     whose block has vjp inputs for all outputs that require_grad\n+//     and vjp outputs for all primal inputs that require_grad\n //   - grad_desc has df_input_vjps and df_output_vjps set\n //     (but df_input_vjps will be modified later as well)\n-static ReverseDetails addReverseInline(Graph& graph, Gradient& grad_desc,\n+static ReverseDetails addReverseInline(Gradient& grad_desc,\n                                   const std::vector<bool>& input_requires_grad) {\n-  JIT_ASSERT(graph.stage() == 0);\n-  graph.advanceStage();\n+  auto & graph = *grad_desc.f;\n+  // note: reverse_node is intentionally not inserted to avoid\n+  // accidentally acting on it (e.g. in elminate dead code),\n+  // std::cout << *reverse_node << to view its state.\n+  auto reverse_node = graph.create(\"Reverse\"_sym, 0);", "path": "torch/csrc/jit/autodiff.cpp", "position": 83, "original_position": 83, "commit_id": "6f27a41a86b8da8934947f2ad37d0c8efff17d6d", "original_commit_id": "6f27a41a86b8da8934947f2ad37d0c8efff17d6d", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Would be nicer to cache the value of this symbol. We'll be looking it up every time we call `differentiate` ", "created_at": "2018-02-05T18:56:58Z", "updated_at": "2018-11-23T15:39:06Z", "html_url": "https://github.com/pytorch/pytorch/pull/5036#discussion_r166075339", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5036", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166075339"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5036#discussion_r166075339"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5036"}}, "body_html": "<p>Would be nicer to cache the value of this symbol. We'll be looking it up every time we call <code>differentiate</code></p>", "body_text": "Would be nicer to cache the value of this symbol. We'll be looking it up every time we call differentiate"}