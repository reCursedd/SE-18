{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/367496677", "html_url": "https://github.com/pytorch/pytorch/pull/5313#issuecomment-367496677", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5313", "id": 367496677, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzQ5NjY3Nw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-21T22:23:19Z", "updated_at": "2018-02-21T22:23:19Z", "author_association": "MEMBER", "body_html": "<p>Even if there's little overhead in caching I still think that raising an out of memory is a good way to indicate that someone is trying to run a computation larger that can fit on the GPU, so they should e.g. consider shrinking their model sizes. If we were to do this by default, they would only see that it runs horribly slow, and wouldn't get immediate feedback about the cause.</p>", "body_text": "Even if there's little overhead in caching I still think that raising an out of memory is a good way to indicate that someone is trying to run a computation larger that can fit on the GPU, so they should e.g. consider shrinking their model sizes. If we were to do this by default, they would only see that it runs horribly slow, and wouldn't get immediate feedback about the cause.", "body": "Even if there's little overhead in caching I still think that raising an out of memory is a good way to indicate that someone is trying to run a computation larger that can fit on the GPU, so they should e.g. consider shrinking their model sizes. If we were to do this by default, they would only see that it runs horribly slow, and wouldn't get immediate feedback about the cause."}