{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/367530623", "html_url": "https://github.com/pytorch/pytorch/pull/5313#issuecomment-367530623", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5313", "id": 367530623, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzUzMDYyMw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-22T00:55:03Z", "updated_at": "2018-02-22T00:56:32Z", "author_association": "MEMBER", "body_html": "<p>I would be surprised if checkpointing via managed memory would actually work. My guess would be that the paging algorithm would do a pretty bad job because it doesn't have the information that we can exploit when implementing checkpointing via higher-level algorithms.</p>\n<p>Also yes, it's likely that doing a bit of recompute is waaay faster than paging. Memory is a significant bottleneck on the GPU, and the PCIe will absolutely thrash the performance. Can't tell for NVLink.</p>\n<p>NB: we shouldn't be comparing checkpointing to multiple passes with smaller batch sizes. If it doesn't end up being faster, then the latter is much easier to code and should be preferred. The whole point of checkpointing is that you can pay only a logarithmic/sqrt  (sublinear!) factor in compute and space for a linear increase in batch size</p>", "body_text": "I would be surprised if checkpointing via managed memory would actually work. My guess would be that the paging algorithm would do a pretty bad job because it doesn't have the information that we can exploit when implementing checkpointing via higher-level algorithms.\nAlso yes, it's likely that doing a bit of recompute is waaay faster than paging. Memory is a significant bottleneck on the GPU, and the PCIe will absolutely thrash the performance. Can't tell for NVLink.\nNB: we shouldn't be comparing checkpointing to multiple passes with smaller batch sizes. If it doesn't end up being faster, then the latter is much easier to code and should be preferred. The whole point of checkpointing is that you can pay only a logarithmic/sqrt  (sublinear!) factor in compute and space for a linear increase in batch size", "body": "I would be surprised if checkpointing via managed memory would actually work. My guess would be that the paging algorithm would do a pretty bad job because it doesn't have the information that we can exploit when implementing checkpointing via higher-level algorithms.\r\n\r\nAlso yes, it's likely that doing a bit of recompute is waaay faster than paging. Memory is a significant bottleneck on the GPU, and the PCIe will absolutely thrash the performance. Can't tell for NVLink.\r\n\r\nNB: we shouldn't be comparing checkpointing to multiple passes with smaller batch sizes. If it doesn't end up being faster, then the latter is much easier to code and should be preferred. The whole point of checkpointing is that you can pay only a logarithmic/sqrt  (sublinear!) factor in compute and space for a linear increase in batch size"}