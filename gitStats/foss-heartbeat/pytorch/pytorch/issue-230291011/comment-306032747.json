{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/306032747", "html_url": "https://github.com/pytorch/pytorch/issues/1607#issuecomment-306032747", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1607", "id": 306032747, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjAzMjc0Nw==", "user": {"login": "alykhantejani", "id": 687194, "node_id": "MDQ6VXNlcjY4NzE5NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/687194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alykhantejani", "html_url": "https://github.com/alykhantejani", "followers_url": "https://api.github.com/users/alykhantejani/followers", "following_url": "https://api.github.com/users/alykhantejani/following{/other_user}", "gists_url": "https://api.github.com/users/alykhantejani/gists{/gist_id}", "starred_url": "https://api.github.com/users/alykhantejani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alykhantejani/subscriptions", "organizations_url": "https://api.github.com/users/alykhantejani/orgs", "repos_url": "https://api.github.com/users/alykhantejani/repos", "events_url": "https://api.github.com/users/alykhantejani/events{/privacy}", "received_events_url": "https://api.github.com/users/alykhantejani/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-04T10:51:03Z", "updated_at": "2017-06-04T10:51:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8563573\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zklgame\">@zklgame</a> can you provide an MWE, I have tried the following (with master) and this is what I get:</p>\n<pre><code>import torch\nimport torchvision\nfrom torch.autograd import Variable \n\ndtype = torch.cuda.FloatTensor\ncnn = torchvision.models.squeezenet1_1(pretrained=True).features\ncnn.type(dtype)\n\n\nprev_feat = Variable(torch.Tensor(1, 3, 255, 255))\n\nprint(type(prev_feat))\nprint(len(cnn._modules.values()))\nfor i, module in enumerate(cnn._modules.values()):\n        print(i, module)\n        next_feat = module(prev_feat)\n        prev_feat = next_feat\nprint('done all')\n</code></pre>\n<p>Gives a informative runtime error <code>RuntimeError: expected CPU tensor (got CUDA tensor)</code></p>\n<p>If I change <code>prev_feat</code> to a cuda tensor (<code>prev_feat = prev_feat.cuda()</code>) everything works as expected.  And as you stated in the original post, you could alternatively put the model back on the cpu (by changing <code>dtype</code> to <code>torch.FloatTensor</code>)</p>", "body_text": "@zklgame can you provide an MWE, I have tried the following (with master) and this is what I get:\nimport torch\nimport torchvision\nfrom torch.autograd import Variable \n\ndtype = torch.cuda.FloatTensor\ncnn = torchvision.models.squeezenet1_1(pretrained=True).features\ncnn.type(dtype)\n\n\nprev_feat = Variable(torch.Tensor(1, 3, 255, 255))\n\nprint(type(prev_feat))\nprint(len(cnn._modules.values()))\nfor i, module in enumerate(cnn._modules.values()):\n        print(i, module)\n        next_feat = module(prev_feat)\n        prev_feat = next_feat\nprint('done all')\n\nGives a informative runtime error RuntimeError: expected CPU tensor (got CUDA tensor)\nIf I change prev_feat to a cuda tensor (prev_feat = prev_feat.cuda()) everything works as expected.  And as you stated in the original post, you could alternatively put the model back on the cpu (by changing dtype to torch.FloatTensor)", "body": "@zklgame can you provide an MWE, I have tried the following (with master) and this is what I get:\r\n\r\n```\r\nimport torch\r\nimport torchvision\r\nfrom torch.autograd import Variable \r\n\r\ndtype = torch.cuda.FloatTensor\r\ncnn = torchvision.models.squeezenet1_1(pretrained=True).features\r\ncnn.type(dtype)\r\n\r\n\r\nprev_feat = Variable(torch.Tensor(1, 3, 255, 255))\r\n\r\nprint(type(prev_feat))\r\nprint(len(cnn._modules.values()))\r\nfor i, module in enumerate(cnn._modules.values()):\r\n        print(i, module)\r\n        next_feat = module(prev_feat)\r\n        prev_feat = next_feat\r\nprint('done all')\r\n```\r\nGives a informative runtime error `RuntimeError: expected CPU tensor (got CUDA tensor)`\r\n\r\nIf I change `prev_feat` to a cuda tensor (`prev_feat = prev_feat.cuda()`) everything works as expected.  And as you stated in the original post, you could alternatively put the model back on the cpu (by changing `dtype` to `torch.FloatTensor`)"}