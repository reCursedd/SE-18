{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6294", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6294/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6294/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6294/events", "html_url": "https://github.com/pytorch/pytorch/issues/6294", "id": 311439624, "node_id": "MDU6SXNzdWUzMTE0Mzk2MjQ=", "number": 6294, "title": "[feature request] AttentionCellWrapper", "user": {"login": "jendrikjoe", "id": 9658781, "node_id": "MDQ6VXNlcjk2NTg3ODE=", "avatar_url": "https://avatars0.githubusercontent.com/u/9658781?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jendrikjoe", "html_url": "https://github.com/jendrikjoe", "followers_url": "https://api.github.com/users/jendrikjoe/followers", "following_url": "https://api.github.com/users/jendrikjoe/following{/other_user}", "gists_url": "https://api.github.com/users/jendrikjoe/gists{/gist_id}", "starred_url": "https://api.github.com/users/jendrikjoe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jendrikjoe/subscriptions", "organizations_url": "https://api.github.com/users/jendrikjoe/orgs", "repos_url": "https://api.github.com/users/jendrikjoe/repos", "events_url": "https://api.github.com/users/jendrikjoe/events{/privacy}", "received_events_url": "https://api.github.com/users/jendrikjoe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-04-05T00:58:31Z", "updated_at": "2018-05-14T19:44:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Dear PyTorch Community,</p>\n<p>I am currently implementing RNNs with an attention mechanism out of interest.<br>\nSince I wanted to implement it in pyTorch I came up with the following class to wrap RNNCells:</p>\n<pre><code>class AttentionCellWrapper(Module):\n    r\"\"\"Create a cell with attention to past data samples.\n    Args:\n\n        cell: an RNNCell, an attention is added to it.\n        attnWindowSize: integer, the size of an attention window.\n        mlpLayerSize: integer, the size of the neural network\n        to determine the attention weights.\n\n    Attributes:\n        weightList: the weighting of the inputs from the last forward pass\n\n    Examples::\n        encoder = LSTMCell(inputSize, 64)\n        decoderCell = LSTMCell(hiddenSize, encoder.hidden_size)\n        decoder = AttentionCellWrapper(decoderCell,\n                                12, 128)\n        outputs = []\n        h_t = Variable(torch.zeros(x.size(1),\n                                   encoder.hidden_size).float(),\n                       requires_grad=False).cuda()\n        c_t = Variable(torch.zeros(x.size(1),\n                                   encoder.hidden_size).float(),\n                       requires_grad=False).cuda()\n        for i in range(x.size(0)):\n            h_t, c_t = encoder(x[i], (h_t, c_t))\n            outputs += [h_t.clone()]\n        outputs = torch.stack(outputs, 0).squeeze(2)\n        outputs = decoder(outputs)\n        weightList = decoder.weightList\n    \"\"\"\n\n    def __init__(self, cell, attnWindowSize, mlpLayerSize=100):\n        super(AttentionCellWrapper, self).__init__()\n        self.cell = cell\n        self.attnLength = cell.input_size\n        self.attnMlp = Linear(self.cell.hidden_size, mlpLayerSize)\n        self.weightMlp = Linear(2*mlpLayerSize, 1)\n        self.attnWindowSize = attnWindowSize\n        self.reset_parameters()\n        self.weightList = []\n\n    def reset_parameters(self):\n        self.attnMlp.reset_parameters()\n        self.weightMlp.reset_parameters()\n\n    def forward(self, inputVec):\n        hT = Variable(\n            torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\n            requires_grad=False).cuda()\n        cT = Variable(\n            torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\n            requires_grad=False).cuda()\n        outputs = []\n        weightList = []\n        # Parameterize Input\n        inputVec = self.attnMlp(inputVec)\n        for i in range(inputVec.size(0)):\n            if i == 0:\n                hT, cT = self.cell(inputVec[i], (hT, cT))\n                outputs += [hT.clone()]\n            else:\n                # Parameterize LSTM State\n                attnVec = self.attnMlp(hT)\n                # Stack all previous inputs\n                if i-self.attnWindowSize &gt;= 0:\n                    stackedInputs = inputVec[i-self.attnWindowSize+1:i+1]\n                else:\n                    stackedInputs = inputVec[:i+1]\n                # Calculate the weights for the previous inputs\n                attnVec = attnVec.unsqueeze(0).expand(*stackedInputs.size())\n                catenated = torch.cat((attnVec, stackedInputs), dim=2)\n                weights = ELU()(self.weightMlp(catenated))\n                weights = Softmax(dim=0)(weights)\n                weightedInput = torch.sum(weights*stackedInputs, dim=0)\n                # Run LSTM step\n                hT, cT = self.cell(weightedInput, (hT, cT))\n                outputs += [hT.clone()]\n                if i - self.attnWindowSize &gt;= 0:\n                    # Store weights, if more than attnWindowSize \n                    # timesteps are in the input\n                    weightList.extend(weights.clone().permute(1, 0, 2).cpu().data.numpy())\n        self.weightList = weightList\n        return torch.stack(outputs, dim=0)\n</code></pre>\n<p>The class currently only supports attention on past features, so it is probably more interesting for people dealing with time series, but I think it could be polished to be used for NLPs as well.<br>\nFurthermore, the alignment model is currently based on a linear network, which maybe should be changeable to other options.<br>\nHowever, is this generally something that I should add using a PR request?<br>\nIf so, are there any changes I should do before-hand (I assume yes ;) )?</p>\n<p>Cheers and thanks for any feedback,</p>\n<p>Jendrik</p>", "body_text": "Dear PyTorch Community,\nI am currently implementing RNNs with an attention mechanism out of interest.\nSince I wanted to implement it in pyTorch I came up with the following class to wrap RNNCells:\nclass AttentionCellWrapper(Module):\n    r\"\"\"Create a cell with attention to past data samples.\n    Args:\n\n        cell: an RNNCell, an attention is added to it.\n        attnWindowSize: integer, the size of an attention window.\n        mlpLayerSize: integer, the size of the neural network\n        to determine the attention weights.\n\n    Attributes:\n        weightList: the weighting of the inputs from the last forward pass\n\n    Examples::\n        encoder = LSTMCell(inputSize, 64)\n        decoderCell = LSTMCell(hiddenSize, encoder.hidden_size)\n        decoder = AttentionCellWrapper(decoderCell,\n                                12, 128)\n        outputs = []\n        h_t = Variable(torch.zeros(x.size(1),\n                                   encoder.hidden_size).float(),\n                       requires_grad=False).cuda()\n        c_t = Variable(torch.zeros(x.size(1),\n                                   encoder.hidden_size).float(),\n                       requires_grad=False).cuda()\n        for i in range(x.size(0)):\n            h_t, c_t = encoder(x[i], (h_t, c_t))\n            outputs += [h_t.clone()]\n        outputs = torch.stack(outputs, 0).squeeze(2)\n        outputs = decoder(outputs)\n        weightList = decoder.weightList\n    \"\"\"\n\n    def __init__(self, cell, attnWindowSize, mlpLayerSize=100):\n        super(AttentionCellWrapper, self).__init__()\n        self.cell = cell\n        self.attnLength = cell.input_size\n        self.attnMlp = Linear(self.cell.hidden_size, mlpLayerSize)\n        self.weightMlp = Linear(2*mlpLayerSize, 1)\n        self.attnWindowSize = attnWindowSize\n        self.reset_parameters()\n        self.weightList = []\n\n    def reset_parameters(self):\n        self.attnMlp.reset_parameters()\n        self.weightMlp.reset_parameters()\n\n    def forward(self, inputVec):\n        hT = Variable(\n            torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\n            requires_grad=False).cuda()\n        cT = Variable(\n            torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\n            requires_grad=False).cuda()\n        outputs = []\n        weightList = []\n        # Parameterize Input\n        inputVec = self.attnMlp(inputVec)\n        for i in range(inputVec.size(0)):\n            if i == 0:\n                hT, cT = self.cell(inputVec[i], (hT, cT))\n                outputs += [hT.clone()]\n            else:\n                # Parameterize LSTM State\n                attnVec = self.attnMlp(hT)\n                # Stack all previous inputs\n                if i-self.attnWindowSize >= 0:\n                    stackedInputs = inputVec[i-self.attnWindowSize+1:i+1]\n                else:\n                    stackedInputs = inputVec[:i+1]\n                # Calculate the weights for the previous inputs\n                attnVec = attnVec.unsqueeze(0).expand(*stackedInputs.size())\n                catenated = torch.cat((attnVec, stackedInputs), dim=2)\n                weights = ELU()(self.weightMlp(catenated))\n                weights = Softmax(dim=0)(weights)\n                weightedInput = torch.sum(weights*stackedInputs, dim=0)\n                # Run LSTM step\n                hT, cT = self.cell(weightedInput, (hT, cT))\n                outputs += [hT.clone()]\n                if i - self.attnWindowSize >= 0:\n                    # Store weights, if more than attnWindowSize \n                    # timesteps are in the input\n                    weightList.extend(weights.clone().permute(1, 0, 2).cpu().data.numpy())\n        self.weightList = weightList\n        return torch.stack(outputs, dim=0)\n\nThe class currently only supports attention on past features, so it is probably more interesting for people dealing with time series, but I think it could be polished to be used for NLPs as well.\nFurthermore, the alignment model is currently based on a linear network, which maybe should be changeable to other options.\nHowever, is this generally something that I should add using a PR request?\nIf so, are there any changes I should do before-hand (I assume yes ;) )?\nCheers and thanks for any feedback,\nJendrik", "body": "Dear PyTorch Community,\r\n\r\nI am currently implementing RNNs with an attention mechanism out of interest.\r\nSince I wanted to implement it in pyTorch I came up with the following class to wrap RNNCells:\r\n\r\n    class AttentionCellWrapper(Module):\r\n        r\"\"\"Create a cell with attention to past data samples.\r\n        Args:\r\n    \r\n            cell: an RNNCell, an attention is added to it.\r\n            attnWindowSize: integer, the size of an attention window.\r\n            mlpLayerSize: integer, the size of the neural network\r\n            to determine the attention weights.\r\n    \r\n        Attributes:\r\n            weightList: the weighting of the inputs from the last forward pass\r\n    \r\n        Examples::\r\n            encoder = LSTMCell(inputSize, 64)\r\n            decoderCell = LSTMCell(hiddenSize, encoder.hidden_size)\r\n            decoder = AttentionCellWrapper(decoderCell,\r\n                                    12, 128)\r\n            outputs = []\r\n            h_t = Variable(torch.zeros(x.size(1),\r\n                                       encoder.hidden_size).float(),\r\n                           requires_grad=False).cuda()\r\n            c_t = Variable(torch.zeros(x.size(1),\r\n                                       encoder.hidden_size).float(),\r\n                           requires_grad=False).cuda()\r\n            for i in range(x.size(0)):\r\n                h_t, c_t = encoder(x[i], (h_t, c_t))\r\n                outputs += [h_t.clone()]\r\n            outputs = torch.stack(outputs, 0).squeeze(2)\r\n            outputs = decoder(outputs)\r\n            weightList = decoder.weightList\r\n        \"\"\"\r\n    \r\n        def __init__(self, cell, attnWindowSize, mlpLayerSize=100):\r\n            super(AttentionCellWrapper, self).__init__()\r\n            self.cell = cell\r\n            self.attnLength = cell.input_size\r\n            self.attnMlp = Linear(self.cell.hidden_size, mlpLayerSize)\r\n            self.weightMlp = Linear(2*mlpLayerSize, 1)\r\n            self.attnWindowSize = attnWindowSize\r\n            self.reset_parameters()\r\n            self.weightList = []\r\n    \r\n        def reset_parameters(self):\r\n            self.attnMlp.reset_parameters()\r\n            self.weightMlp.reset_parameters()\r\n    \r\n        def forward(self, inputVec):\r\n            hT = Variable(\r\n                torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\r\n                requires_grad=False).cuda()\r\n            cT = Variable(\r\n                torch.zeros(inputVec.size(1), self.cell.hidden_size).float(),\r\n                requires_grad=False).cuda()\r\n            outputs = []\r\n            weightList = []\r\n            # Parameterize Input\r\n            inputVec = self.attnMlp(inputVec)\r\n            for i in range(inputVec.size(0)):\r\n                if i == 0:\r\n                    hT, cT = self.cell(inputVec[i], (hT, cT))\r\n                    outputs += [hT.clone()]\r\n                else:\r\n                    # Parameterize LSTM State\r\n                    attnVec = self.attnMlp(hT)\r\n                    # Stack all previous inputs\r\n                    if i-self.attnWindowSize >= 0:\r\n                        stackedInputs = inputVec[i-self.attnWindowSize+1:i+1]\r\n                    else:\r\n                        stackedInputs = inputVec[:i+1]\r\n                    # Calculate the weights for the previous inputs\r\n                    attnVec = attnVec.unsqueeze(0).expand(*stackedInputs.size())\r\n                    catenated = torch.cat((attnVec, stackedInputs), dim=2)\r\n                    weights = ELU()(self.weightMlp(catenated))\r\n                    weights = Softmax(dim=0)(weights)\r\n                    weightedInput = torch.sum(weights*stackedInputs, dim=0)\r\n                    # Run LSTM step\r\n                    hT, cT = self.cell(weightedInput, (hT, cT))\r\n                    outputs += [hT.clone()]\r\n                    if i - self.attnWindowSize >= 0:\r\n                        # Store weights, if more than attnWindowSize \r\n                        # timesteps are in the input\r\n                        weightList.extend(weights.clone().permute(1, 0, 2).cpu().data.numpy())\r\n            self.weightList = weightList\r\n            return torch.stack(outputs, dim=0)\r\n\r\nThe class currently only supports attention on past features, so it is probably more interesting for people dealing with time series, but I think it could be polished to be used for NLPs as well.\r\nFurthermore, the alignment model is currently based on a linear network, which maybe should be changeable to other options. \r\nHowever, is this generally something that I should add using a PR request?\r\nIf so, are there any changes I should do before-hand (I assume yes ;) )?\r\n\r\nCheers and thanks for any feedback,\r\n\r\nJendrik"}