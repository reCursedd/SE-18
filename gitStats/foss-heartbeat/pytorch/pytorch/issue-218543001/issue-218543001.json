{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1155", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1155/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1155/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1155/events", "html_url": "https://github.com/pytorch/pytorch/issues/1155", "id": 218543001, "node_id": "MDU6SXNzdWUyMTg1NDMwMDE=", "number": 1155, "title": "gradoutput shapes not being resized for some functions in backward", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2017-03-31T15:51:08Z", "updated_at": "2017-04-03T14:39:16Z", "closed_at": "2017-04-03T14:39:16Z", "author_association": "MEMBER", "body_html": "<p>As Timothee Lacroix reports:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n\ndtype<span class=\"pl-k\">=</span>torch.FloatTensor\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Test</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">N</span>, <span class=\"pl-smi\">R</span>, <span class=\"pl-smi\">A</span>, <span class=\"pl-smi\">P</span>, <span class=\"pl-smi\">k</span>):\n        <span class=\"pl-c1\">super</span>(Test, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n\n        <span class=\"pl-c1\">self</span>.k <span class=\"pl-k\">=</span> k             <span class=\"pl-c\"><span class=\"pl-c\">#</span> maximum subgraph size</span>\n        <span class=\"pl-c1\">self</span>.at <span class=\"pl-k\">=</span> nn.Parameter(torch.randn(R, k, k).type(dtype), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        <span class=\"pl-c1\">self</span>.perm <span class=\"pl-k\">=</span> nn.Parameter(torch.randn(N, k).type(dtype), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, (<span class=\"pl-smi\">s</span>, <span class=\"pl-smi\">o</span>, <span class=\"pl-smi\">r</span>)):\n        res <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.perm[s, :].dot(<span class=\"pl-c1\">self</span>.at[r, :, :].mm(<span class=\"pl-c1\">self</span>.perm[o, :].view(<span class=\"pl-c1\">self</span>.k, <span class=\"pl-c1\">1</span>)))\n        <span class=\"pl-k\">return</span> res\n\n\nmodel <span class=\"pl-k\">=</span> Test(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>)\n\npred <span class=\"pl-k\">=</span> model.forward((<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>))\npred.backward()</pre></div>\n<pre><code>Traceback (most recent call last):\n  File \"a.py\", line 21, in &lt;module&gt;\n    pred.backward()\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/variable.py\", line 146, in backward\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/blas.py\", line 40, in backward\n    grad_matrix1 = torch.mm(grad_output, matrix2.t())\nRuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/miniconda2/conda-bld/pytorch_1490902430884/work/torch/lib/TH/generic/THTensorMath.c:1224\n</code></pre>", "body_text": "As Timothee Lacroix reports:\nimport torch\nfrom torch import nn\n\ndtype=torch.FloatTensor\nclass Test(nn.Module):\n    def __init__(self, N, R, A, P, k):\n        super(Test, self).__init__()\n\n        self.k = k             # maximum subgraph size\n        self.at = nn.Parameter(torch.randn(R, k, k).type(dtype), requires_grad=True)\n        self.perm = nn.Parameter(torch.randn(N, k).type(dtype), requires_grad=True)\n\n    def forward(self, (s, o, r)):\n        res = self.perm[s, :].dot(self.at[r, :, :].mm(self.perm[o, :].view(self.k, 1)))\n        return res\n\n\nmodel = Test(5, 3, 1, 1, 3)\n\npred = model.forward((0,0,0))\npred.backward()\nTraceback (most recent call last):\n  File \"a.py\", line 21, in <module>\n    pred.backward()\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/variable.py\", line 146, in backward\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/blas.py\", line 40, in backward\n    grad_matrix1 = torch.mm(grad_output, matrix2.t())\nRuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/miniconda2/conda-bld/pytorch_1490902430884/work/torch/lib/TH/generic/THTensorMath.c:1224", "body": "As Timothee Lacroix reports:\r\n\r\n```python\r\nimport torch\r\nfrom torch import nn\r\n\r\ndtype=torch.FloatTensor\r\nclass Test(nn.Module):\r\n    def __init__(self, N, R, A, P, k):\r\n        super(Test, self).__init__()\r\n\r\n        self.k = k             # maximum subgraph size\r\n        self.at = nn.Parameter(torch.randn(R, k, k).type(dtype), requires_grad=True)\r\n        self.perm = nn.Parameter(torch.randn(N, k).type(dtype), requires_grad=True)\r\n\r\n    def forward(self, (s, o, r)):\r\n        res = self.perm[s, :].dot(self.at[r, :, :].mm(self.perm[o, :].view(self.k, 1)))\r\n        return res\r\n\r\n\r\nmodel = Test(5, 3, 1, 1, 3)\r\n\r\npred = model.forward((0,0,0))\r\npred.backward()\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"a.py\", line 21, in <module>\r\n    pred.backward()\r\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/variable.py\", line 146, in backward\r\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\r\n  File \"/Users/chinso/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/blas.py\", line 40, in backward\r\n    grad_matrix1 = torch.mm(grad_output, matrix2.t())\r\nRuntimeError: matrices expected, got 1D, 2D tensors at /Users/soumith/miniconda2/conda-bld/pytorch_1490902430884/work/torch/lib/TH/generic/THTensorMath.c:1224\r\n```"}