{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/423765466", "html_url": "https://github.com/pytorch/pytorch/pull/8010#issuecomment-423765466", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8010", "id": 423765466, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzc2NTQ2Ng==", "user": {"login": "AnesBenmerzoug", "id": 27914730, "node_id": "MDQ6VXNlcjI3OTE0NzMw", "avatar_url": "https://avatars3.githubusercontent.com/u/27914730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AnesBenmerzoug", "html_url": "https://github.com/AnesBenmerzoug", "followers_url": "https://api.github.com/users/AnesBenmerzoug/followers", "following_url": "https://api.github.com/users/AnesBenmerzoug/following{/other_user}", "gists_url": "https://api.github.com/users/AnesBenmerzoug/gists{/gist_id}", "starred_url": "https://api.github.com/users/AnesBenmerzoug/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AnesBenmerzoug/subscriptions", "organizations_url": "https://api.github.com/users/AnesBenmerzoug/orgs", "repos_url": "https://api.github.com/users/AnesBenmerzoug/repos", "events_url": "https://api.github.com/users/AnesBenmerzoug/events{/privacy}", "received_events_url": "https://api.github.com/users/AnesBenmerzoug/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-22T18:54:02Z", "updated_at": "2018-09-22T18:54:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4994518\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/johncava\">@johncava</a> The way that this optimizer works is that you use two different models: a main model that has the parameters you're training and a snapshot model that gets a snapshot of the main model's parameters at the beginning of every epoch.</p>\n<p>You can see how it is used in this example script:</p>\n<div class=\"highlight highlight-source-python\"><pre>main_model <span class=\"pl-k\">=</span> Network()\nsnapshot_model <span class=\"pl-k\">=</span> Network()\nsnapshot_model.load_state_dict(main_model.state_dict()) <span class=\"pl-c\"><span class=\"pl-c\">#</span> deepcopy could be used instead of this</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Instantiate the optimizer with the main model's as well as the snapshot model's parameters</span>\noptimizer <span class=\"pl-k\">=</span> torch.optim.SVRG(main_model.parameters(), snapshot_model.parameters(), <span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-3</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> We need to define a closure that will be used in the update_snapshot method of the optimizer</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">snapshot_closure</span>():\n      <span class=\"pl-k\">def</span> <span class=\"pl-en\">closure</span>(<span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">target</span>):\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Forward step</span>\n            output <span class=\"pl-k\">=</span> snapshot_model(<span class=\"pl-c1\">input</span>)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss computation</span>\n            snapshot_loss <span class=\"pl-k\">=</span> criterion(output, target)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Zero the optimizer gradient</span>\n            <span class=\"pl-c1\">self</span>.optimizer.zero_grad()\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Backward step</span>\n            snapshot_loss.backward()\n            <span class=\"pl-k\">return</span> snapshot_loss\n      <span class=\"pl-k\">return</span> closure\n\n<span class=\"pl-k\">for</span> epoch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_epochs):\n     <span class=\"pl-c\"><span class=\"pl-c\">#</span> Call the update_snapshot method to take a new snapshot and compute the average gradient</span>\n     optimizer.update_snapshot(dataloader, snapshot_closure)\n     <span class=\"pl-k\">for</span> (<span class=\"pl-c1\">input</span>, target) <span class=\"pl-k\">in</span> dataloader:\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Forward + Backward for main model</span>\n          output <span class=\"pl-k\">=</span> main_model(<span class=\"pl-c1\">input</span>)\n          loss <span class=\"pl-k\">=</span> criterion(output, target)\n          main_model.zero_grad()\n          loss.backward()\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Forward + Backward for snapshot model</span>\n          snapshot_output <span class=\"pl-k\">=</span> snapshot_model(<span class=\"pl-c1\">input</span>)\n          snapshot_loss <span class=\"pl-k\">=</span> criterion(snapshot_output, target)\n          snapshot_model.zero_grad()\n          snapshot_loss.backward()\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> Update parameters</span>\n          optimizer.step()</pre></div>\n<p>If the user can iterate only over 'm' samples by just changing the inner loop inside in the epoch loop.<br>\ngrad_phi_it(W(t-1)) and grad_phi_it(W_tilda) are computed using the same sample by using two models.</p>\n<p>I know that it is not optimal to use two models, but for this optimizer this was the simplest implementation that I could think of.</p>", "body_text": "@johncava The way that this optimizer works is that you use two different models: a main model that has the parameters you're training and a snapshot model that gets a snapshot of the main model's parameters at the beginning of every epoch.\nYou can see how it is used in this example script:\nmain_model = Network()\nsnapshot_model = Network()\nsnapshot_model.load_state_dict(main_model.state_dict()) # deepcopy could be used instead of this\n\n# Instantiate the optimizer with the main model's as well as the snapshot model's parameters\noptimizer = torch.optim.SVRG(main_model.parameters(), snapshot_model.parameters(), lr=1e-3)\n\n# We need to define a closure that will be used in the update_snapshot method of the optimizer\ndef snapshot_closure():\n      def closure(input, target):\n            # Forward step\n            output = snapshot_model(input)\n            # Loss computation\n            snapshot_loss = criterion(output, target)\n            # Zero the optimizer gradient\n            self.optimizer.zero_grad()\n            # Backward step\n            snapshot_loss.backward()\n            return snapshot_loss\n      return closure\n\nfor epoch in range(num_epochs):\n     # Call the update_snapshot method to take a new snapshot and compute the average gradient\n     optimizer.update_snapshot(dataloader, snapshot_closure)\n     for (input, target) in dataloader:\n          # Forward + Backward for main model\n          output = main_model(input)\n          loss = criterion(output, target)\n          main_model.zero_grad()\n          loss.backward()\n          # Forward + Backward for snapshot model\n          snapshot_output = snapshot_model(input)\n          snapshot_loss = criterion(snapshot_output, target)\n          snapshot_model.zero_grad()\n          snapshot_loss.backward()\n          # Update parameters\n          optimizer.step()\nIf the user can iterate only over 'm' samples by just changing the inner loop inside in the epoch loop.\ngrad_phi_it(W(t-1)) and grad_phi_it(W_tilda) are computed using the same sample by using two models.\nI know that it is not optimal to use two models, but for this optimizer this was the simplest implementation that I could think of.", "body": "@johncava The way that this optimizer works is that you use two different models: a main model that has the parameters you're training and a snapshot model that gets a snapshot of the main model's parameters at the beginning of every epoch.\r\n\r\nYou can see how it is used in this example script:\r\n\r\n```python\r\nmain_model = Network()\r\nsnapshot_model = Network()\r\nsnapshot_model.load_state_dict(main_model.state_dict()) # deepcopy could be used instead of this\r\n\r\n# Instantiate the optimizer with the main model's as well as the snapshot model's parameters\r\noptimizer = torch.optim.SVRG(main_model.parameters(), snapshot_model.parameters(), lr=1e-3)\r\n\r\n# We need to define a closure that will be used in the update_snapshot method of the optimizer\r\ndef snapshot_closure():\r\n      def closure(input, target):\r\n            # Forward step\r\n            output = snapshot_model(input)\r\n            # Loss computation\r\n            snapshot_loss = criterion(output, target)\r\n            # Zero the optimizer gradient\r\n            self.optimizer.zero_grad()\r\n            # Backward step\r\n            snapshot_loss.backward()\r\n            return snapshot_loss\r\n      return closure\r\n\r\nfor epoch in range(num_epochs):\r\n     # Call the update_snapshot method to take a new snapshot and compute the average gradient\r\n     optimizer.update_snapshot(dataloader, snapshot_closure)\r\n     for (input, target) in dataloader:\r\n          # Forward + Backward for main model\r\n          output = main_model(input)\r\n          loss = criterion(output, target)\r\n          main_model.zero_grad()\r\n          loss.backward()\r\n          # Forward + Backward for snapshot model\r\n          snapshot_output = snapshot_model(input)\r\n          snapshot_loss = criterion(snapshot_output, target)\r\n          snapshot_model.zero_grad()\r\n          snapshot_loss.backward()\r\n          # Update parameters\r\n          optimizer.step()\r\n```\r\n\r\nIf the user can iterate only over 'm' samples by just changing the inner loop inside in the epoch loop.\r\ngrad_phi_it(W(t-1)) and grad_phi_it(W_tilda) are computed using the same sample by using two models.\r\n\r\nI know that it is not optimal to use two models, but for this optimizer this was the simplest implementation that I could think of.\r\n"}