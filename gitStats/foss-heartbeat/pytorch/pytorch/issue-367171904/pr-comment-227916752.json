{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227916752", "pull_request_review_id": 168065022, "id": 227916752, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzkxNjc1Mg==", "diff_hunk": "@@ -91,56 +94,80 @@ class TensorAccessor<T,1,PtrTraits> : public TensorAccessorBase<T,1,PtrTraits> {\n // Use RestrictPtrTraits as PtrTraits if you want the tensor's data pointer to be marked as __restrict__.\n // Instantiation from data, sizes, strides is only needed on the host and std::copy isn't available\n // on the device, so those functions are host only.\n-template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits>\n+template<typename T, size_t N, template <typename U> class PtrTraits = DefaultPtrTraits, typename index_t = int64_t>\n class PackedTensorAccessorBase {\n public:\n   typedef typename PtrTraits<T>::PtrType PtrType;\n-  AT_HOST PackedTensorAccessorBase(PtrType data_, const int64_t * sizes_, const   int64_t * strides_)\n+  AT_HOST PackedTensorAccessorBase(PtrType data_, const index_t * sizes_, const index_t * strides_)\n   : data_(data_)\n   {\n     std::copy(sizes_, sizes_ + N, std::begin(this->sizes_));\n     std::copy(strides_, strides_ + N, std::begin(this->strides_));\n   }\n-  AT_HOST_DEVICE int64_t stride(int64_t i) const { return strides_[i]; }\n-  AT_HOST_DEVICE int64_t size(int64_t i) const { return sizes_[i]; }\n+\n+  // if index_t is not int64_t, we want to have an int64_t constructor\n+  template <typename source_index_t, class = typename std::enable_if<std::is_same<source_index_t, int64_t>::value>::type>", "path": "aten/src/ATen/core/TensorAccessor.h", "position": 103, "original_position": 103, "commit_id": "0d7aac942b890f4b345f3511c14ab41fede97741", "original_commit_id": "35e104ace7d41449b21e851ac1e16072f1aea005", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "No. I did try that. :) It gives:\r\n`TensorAccessor.h(109): error: class \"std::enable_if<false, void>\" has no member \"type\"`\r\nAs far as I understand it, the reason is that you can have an \"impossible template\" (which is what enable_if produces in the false case) only as long as the template parameters are not fully given. So I need some unspecified bit, and after trying out various variants and trying to take something that looks similar to what `rgrep enable_if` gives, I settled on this. I don't like it, but it seems to not be too harmful.\r\n", "created_at": "2018-10-24T18:50:10Z", "updated_at": "2018-11-23T15:53:32Z", "html_url": "https://github.com/pytorch/pytorch/pull/12368#discussion_r227916752", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12368", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227916752"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12368#discussion_r227916752"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12368"}}, "body_html": "<p>No. I did try that. :) It gives:<br>\n<code>TensorAccessor.h(109): error: class \"std::enable_if&lt;false, void&gt;\" has no member \"type\"</code><br>\nAs far as I understand it, the reason is that you can have an \"impossible template\" (which is what enable_if produces in the false case) only as long as the template parameters are not fully given. So I need some unspecified bit, and after trying out various variants and trying to take something that looks similar to what <code>rgrep enable_if</code> gives, I settled on this. I don't like it, but it seems to not be too harmful.</p>", "body_text": "No. I did try that. :) It gives:\nTensorAccessor.h(109): error: class \"std::enable_if<false, void>\" has no member \"type\"\nAs far as I understand it, the reason is that you can have an \"impossible template\" (which is what enable_if produces in the false case) only as long as the template parameters are not fully given. So I need some unspecified bit, and after trying out various variants and trying to take something that looks similar to what rgrep enable_if gives, I settled on this. I don't like it, but it seems to not be too harmful.", "in_reply_to_id": 227456574}