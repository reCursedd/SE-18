{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/429718594", "html_url": "https://github.com/pytorch/pytorch/pull/12368#issuecomment-429718594", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12368", "id": 429718594, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTcxODU5NA==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-15T06:03:28Z", "updated_at": "2018-10-15T06:10:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The CPU kernels are quite literally adapted from THNN.<br>\nI'll try to get a cleanish before/after benchmark (so far, I've mostly compared to cudnn).</p>\n<p>Regarding further optimization:</p>\n<ul>\n<li>The welford-style forward statistics is the obvious thing I've not done. (I didn't change much kernel code except that immediately required).</li>\n<li>The backward would get a similar surgery (splitting into \"reduction\" and \"pointwise\") that seems, in extreme shapes (32x10x40_000) can have a rather large (10-100x) impact. Based on my discussion with the <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7799218\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mcarilli\">@mcarilli</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3709243\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jjsjann123\">@jjsjann123</a>, my main focus for the backward kernel was getting the numerical precision a bit up for fp32 (and also we hope to share kernels between sync bn and this here).<br>\n(I have an implementation of the kernel as an external module that looks correctish at <a href=\"https://gist.github.com/t-vi/82a46dc87eceae303a4f805147f82310\">https://gist.github.com/t-vi/82a46dc87eceae303a4f805147f82310</a> , but I didn't benchmark yet.)</li>\n</ul>", "body_text": "The CPU kernels are quite literally adapted from THNN.\nI'll try to get a cleanish before/after benchmark (so far, I've mostly compared to cudnn).\nRegarding further optimization:\n\nThe welford-style forward statistics is the obvious thing I've not done. (I didn't change much kernel code except that immediately required).\nThe backward would get a similar surgery (splitting into \"reduction\" and \"pointwise\") that seems, in extreme shapes (32x10x40_000) can have a rather large (10-100x) impact. Based on my discussion with the @mcarilli and @jjsjann123, my main focus for the backward kernel was getting the numerical precision a bit up for fp32 (and also we hope to share kernels between sync bn and this here).\n(I have an implementation of the kernel as an external module that looks correctish at https://gist.github.com/t-vi/82a46dc87eceae303a4f805147f82310 , but I didn't benchmark yet.)", "body": "The CPU kernels are quite literally adapted from THNN.\r\nI'll try to get a cleanish before/after benchmark (so far, I've mostly compared to cudnn).\r\n\r\nRegarding further optimization:\r\n- The welford-style forward statistics is the obvious thing I've not done. (I didn't change much kernel code except that immediately required).\r\n- The backward would get a similar surgery (splitting into \"reduction\" and \"pointwise\") that seems, in extreme shapes (32x10x40_000) can have a rather large (10-100x) impact. Based on my discussion with the @mcarilli and @jjsjann123, my main focus for the backward kernel was getting the numerical precision a bit up for fp32 (and also we hope to share kernels between sync bn and this here).\r\n(I have an implementation of the kernel as an external module that looks correctish at https://gist.github.com/t-vi/82a46dc87eceae303a4f805147f82310 , but I didn't benchmark yet.)\r\n"}