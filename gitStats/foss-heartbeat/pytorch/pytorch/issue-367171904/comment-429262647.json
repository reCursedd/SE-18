{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/429262647", "html_url": "https://github.com/pytorch/pytorch/pull/12368#issuecomment-429262647", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12368", "id": 429262647, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTI2MjY0Nw==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T09:22:06Z", "updated_at": "2018-10-12T09:22:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>No worries, thanks for looking!<br>\nThe kernel logic itself didn't change much, I mostly switched from DeviceTensor to PackedTensorAccessors. However, I changed the splitting of the kernel.<br>\nThe kernel bits that changed:</p>\n<ul>\n<li>I amended the old \"inference\" kernel to the <code>batch_norm_transform_input_kernel</code> to deal both with<br>\nrunning_mean/running_var (train=False) and save_mean/save_invstd (train=True).<br>\nThe former needs to calculate invstd from running_var, while the latter takes it directly.<br>\nSo now this is the only thing calculating out = w * (inp - mean) * invstd + b.</li>\n<li>I removed the bit done by <code>batch_norm_transform_input_kernel</code> from the old training forward kernel<br>\nand renamed it to <code>batch_norm_collect_statistics_kernel</code>. It now only computes save_mean / save_var and  updates the running_mean / running_var as needed.</li>\n<li>This splitting of the training forward allows a favourable thread/block-parametrisation in the<br>\ntransform_input call, which used to be one main bottleneck in the forward.</li>\n</ul>\n<p><code>save_mean</code>/<code>save_std</code> have been changed to accscalar_t because we need the precision (previously, this was in a single kernel and also kept as accscalar_t and no-one cared about the poor backward). One might ask whether it would be desirable to (optionally) support accscalar_t weights for half (as cudnn does), but I didn't do this yet.</p>\n<p>Finally, I also changed how the statistics gathering is parallelised by swapping dimensions 0 and 2 to have the larger as 2 in the calculation of the packed_accessor. This is because the parallelisation is done based on dimension 2 only.</p>", "body_text": "No worries, thanks for looking!\nThe kernel logic itself didn't change much, I mostly switched from DeviceTensor to PackedTensorAccessors. However, I changed the splitting of the kernel.\nThe kernel bits that changed:\n\nI amended the old \"inference\" kernel to the batch_norm_transform_input_kernel to deal both with\nrunning_mean/running_var (train=False) and save_mean/save_invstd (train=True).\nThe former needs to calculate invstd from running_var, while the latter takes it directly.\nSo now this is the only thing calculating out = w * (inp - mean) * invstd + b.\nI removed the bit done by batch_norm_transform_input_kernel from the old training forward kernel\nand renamed it to batch_norm_collect_statistics_kernel. It now only computes save_mean / save_var and  updates the running_mean / running_var as needed.\nThis splitting of the training forward allows a favourable thread/block-parametrisation in the\ntransform_input call, which used to be one main bottleneck in the forward.\n\nsave_mean/save_std have been changed to accscalar_t because we need the precision (previously, this was in a single kernel and also kept as accscalar_t and no-one cared about the poor backward). One might ask whether it would be desirable to (optionally) support accscalar_t weights for half (as cudnn does), but I didn't do this yet.\nFinally, I also changed how the statistics gathering is parallelised by swapping dimensions 0 and 2 to have the larger as 2 in the calculation of the packed_accessor. This is because the parallelisation is done based on dimension 2 only.", "body": "No worries, thanks for looking!\r\nThe kernel logic itself didn't change much, I mostly switched from DeviceTensor to PackedTensorAccessors. However, I changed the splitting of the kernel.\r\nThe kernel bits that changed:\r\n- I amended the old \"inference\" kernel to the `batch_norm_transform_input_kernel` to deal both with\r\n  running_mean/running_var (train=False) and save_mean/save_invstd (train=True).\r\n  The former needs to calculate invstd from running_var, while the latter takes it directly.\r\n  So now this is the only thing calculating out = w * (inp - mean) * invstd + b.\r\n- I removed the bit done by `batch_norm_transform_input_kernel` from the old training forward kernel\r\n  and renamed it to `batch_norm_collect_statistics_kernel`. It now only computes save_mean / save_var and  updates the running_mean / running_var as needed.\r\n- This splitting of the training forward allows a favourable thread/block-parametrisation in the\r\n  transform_input call, which used to be one main bottleneck in the forward.\r\n\r\n`save_mean`/`save_std` have been changed to accscalar_t because we need the precision (previously, this was in a single kernel and also kept as accscalar_t and no-one cared about the poor backward). One might ask whether it would be desirable to (optionally) support accscalar_t weights for half (as cudnn does), but I didn't do this yet.\r\n\r\nFinally, I also changed how the statistics gathering is parallelised by swapping dimensions 0 and 2 to have the larger as 2 in the calculation of the packed_accessor. This is because the parallelisation is done based on dimension 2 only.\r\n"}