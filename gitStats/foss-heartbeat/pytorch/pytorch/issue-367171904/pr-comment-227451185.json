{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227451185", "pull_request_review_id": 167494597, "id": 227451185, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzQ1MTE4NQ==", "diff_hunk": "@@ -405,12 +406,13 @@ std::tuple<Tensor, Tensor, Tensor> batch_norm_cuda_template(const Tensor& input_\n   int64_t n_input = input_.size(1);\n   Tensor save_mean_;\n   Tensor save_invstd_;\n-  auto input_cont = input_.reshape({input_.size(0), input_.size(1), -1}); // internally we merge the feature dimensions\n-  auto output_cont = at::empty_like(input_cont);\n+  auto input_reshaped = input_.reshape({input_.size(0), input_.size(1), -1}); // internally we merge the feature dimensions\n+  auto output_reshaped = at::empty_like(input_reshaped);\n \n-  auto bs = input_cont.size(0);\n-  auto features = input_cont.size(2);\n-  auto input = input_cont.packed_accessor<scalar_t, 3, RestrictPtrTraits>();\n+  AT_CHECK(cuda::detail::canUse32BitIndexMath(input_reshaped), \"Input is too large for batch_norm\");", "path": "aten/src/ATen/native/cuda/Normalization.cu", "position": null, "original_position": 156, "commit_id": "0d7aac942b890f4b345f3511c14ab41fede97741", "original_commit_id": "35e104ace7d41449b21e851ac1e16072f1aea005", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "hmm can you instead template the whole thing and use `int32_t` if `canUse32BitIndexMath` and `int64_t` otherwise?", "created_at": "2018-10-23T15:39:55Z", "updated_at": "2018-11-23T15:53:25Z", "html_url": "https://github.com/pytorch/pytorch/pull/12368#discussion_r227451185", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12368", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227451185"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12368#discussion_r227451185"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12368"}}, "body_html": "<p>hmm can you instead template the whole thing and use <code>int32_t</code> if <code>canUse32BitIndexMath</code> and <code>int64_t</code> otherwise?</p>", "body_text": "hmm can you instead template the whole thing and use int32_t if canUse32BitIndexMath and int64_t otherwise?"}