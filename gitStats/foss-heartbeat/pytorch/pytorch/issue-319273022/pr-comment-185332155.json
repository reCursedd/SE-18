{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185332155", "pull_request_review_id": 116699751, "id": 185332155, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTMzMjE1NQ==", "diff_hunk": "@@ -1,18 +1,44 @@\n-cmake_minimum_required(VERSION 3.0)\n-set(CMAKE_MODULE_PATH\n-  ${CMAKE_CURRENT_SOURCE_DIR}/cmake\n+if (CAFFE2_CMAKE_BUILDING_WITH_MAIN_REPO)\n+  if (NOT BUILD_ATEN)\n+    return()\n+  endif()\n+else()\n+  cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n+  project(ATen CXX C)\n+  include(CMakeDependentOption)\n+  option(USE_CUDA \"Use CUDA\" ON)\n+  cmake_dependent_option(\n+      USE_CUDNN \"Use cuDNN\" ON\n+      \"USE_CUDA\" OFF)\n+  option(USE_NATIVE_ARCH \"Use -march=native\" OFF)\n+\n+  # Legacy options, which we will eventually remove\n+  cmake_dependent_option(", "path": "aten/CMakeLists.txt", "position": 19, "original_position": 19, "commit_id": "41e49b1f11ffd055d6d9e48f8da62f523ad89453", "original_commit_id": "41e49b1f11ffd055d6d9e48f8da62f523ad89453", "user": {"login": "orionr", "id": 79994, "node_id": "MDQ6VXNlcjc5OTk0", "avatar_url": "https://avatars3.githubusercontent.com/u/79994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orionr", "html_url": "https://github.com/orionr", "followers_url": "https://api.github.com/users/orionr/followers", "following_url": "https://api.github.com/users/orionr/following{/other_user}", "gists_url": "https://api.github.com/users/orionr/gists{/gist_id}", "starred_url": "https://api.github.com/users/orionr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orionr/subscriptions", "organizations_url": "https://api.github.com/users/orionr/orgs", "repos_url": "https://api.github.com/users/orionr/repos", "events_url": "https://api.github.com/users/orionr/events{/privacy}", "received_events_url": "https://api.github.com/users/orionr/received_events", "type": "User", "site_admin": false}, "body": "`USE_CUDA=OFF` is what you'd need in that case.\r\n\r\nSeems like we have `WITH_CUDA`, `NO_CUDA`, and `USE_CUDA` and (I think) they all mean the same thing or opposite? Please confirm. If so, the goal is to standardize on `USE_CUDA` eventually.", "created_at": "2018-05-01T20:57:43Z", "updated_at": "2018-11-23T15:43:30Z", "html_url": "https://github.com/pytorch/pytorch/pull/7143#discussion_r185332155", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7143", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185332155"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7143#discussion_r185332155"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7143"}}, "body_html": "<p><code>USE_CUDA=OFF</code> is what you'd need in that case.</p>\n<p>Seems like we have <code>WITH_CUDA</code>, <code>NO_CUDA</code>, and <code>USE_CUDA</code> and (I think) they all mean the same thing or opposite? Please confirm. If so, the goal is to standardize on <code>USE_CUDA</code> eventually.</p>", "body_text": "USE_CUDA=OFF is what you'd need in that case.\nSeems like we have WITH_CUDA, NO_CUDA, and USE_CUDA and (I think) they all mean the same thing or opposite? Please confirm. If so, the goal is to standardize on USE_CUDA eventually.", "in_reply_to_id": 185294033}