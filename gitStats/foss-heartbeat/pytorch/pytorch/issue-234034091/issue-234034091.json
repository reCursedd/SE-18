{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1740", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1740/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1740/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1740/events", "html_url": "https://github.com/pytorch/pytorch/pull/1740", "id": 234034091, "node_id": "MDExOlB1bGxSZXF1ZXN0MTI0Mjk1MDIw", "number": 1740, "title": "Make sure the number of MKL and OpenMP threads match", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-06-06T21:43:56Z", "updated_at": "2017-06-07T18:55:23Z", "closed_at": "2017-06-07T18:55:23Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1740", "html_url": "https://github.com/pytorch/pytorch/pull/1740", "diff_url": "https://github.com/pytorch/pytorch/pull/1740.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1740.patch"}, "body_html": "<p>Otherwise, on many machines, the size of the OpenMP thread pool will<br>\nchange between MKL and our OpenMP enabled functions. The constant thread<br>\ncreation and destruction results in worse performance and leaks memory<br>\non GCC 5.4</p>\n<p>Here's an example program which triggers this behavior:<br>\n<a href=\"https://gist.github.com/colesbury/9ac92dfe5346bb71dee885af9c8cdd5d\">https://gist.github.com/colesbury/9ac92dfe5346bb71dee885af9c8cdd5d</a></p>\n<p><code>torch.add</code>/<code>THTensor_(cadd)</code> with a destination tensor is an OpenMP-enabled TH function. <code>torch.mm</code>/<code>THTensor_(addmm)</code> uses MKL. On my machine, MKL defaults to 24 threads while OpenMP defaults to 48 threads. Without this fix, the example gets about 200 itrs/sec. With the fix, the example gets about 3000 itrs/sec.</p>", "body_text": "Otherwise, on many machines, the size of the OpenMP thread pool will\nchange between MKL and our OpenMP enabled functions. The constant thread\ncreation and destruction results in worse performance and leaks memory\non GCC 5.4\nHere's an example program which triggers this behavior:\nhttps://gist.github.com/colesbury/9ac92dfe5346bb71dee885af9c8cdd5d\ntorch.add/THTensor_(cadd) with a destination tensor is an OpenMP-enabled TH function. torch.mm/THTensor_(addmm) uses MKL. On my machine, MKL defaults to 24 threads while OpenMP defaults to 48 threads. Without this fix, the example gets about 200 itrs/sec. With the fix, the example gets about 3000 itrs/sec.", "body": "Otherwise, on many machines, the size of the OpenMP thread pool will\r\nchange between MKL and our OpenMP enabled functions. The constant thread\r\ncreation and destruction results in worse performance and leaks memory\r\non GCC 5.4\r\n\r\nHere's an example program which triggers this behavior:\r\nhttps://gist.github.com/colesbury/9ac92dfe5346bb71dee885af9c8cdd5d\r\n\r\n`torch.add`/`THTensor_(cadd)` with a destination tensor is an OpenMP-enabled TH function. `torch.mm`/`THTensor_(addmm)` uses MKL. On my machine, MKL defaults to 24 threads while OpenMP defaults to 48 threads. Without this fix, the example gets about 200 itrs/sec. With the fix, the example gets about 3000 itrs/sec."}