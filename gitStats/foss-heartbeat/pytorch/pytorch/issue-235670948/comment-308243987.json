{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/308243987", "html_url": "https://github.com/pytorch/pytorch/issues/1794#issuecomment-308243987", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1794", "id": 308243987, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODI0Mzk4Nw==", "user": {"login": "rdipietro", "id": 5150559, "node_id": "MDQ6VXNlcjUxNTA1NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5150559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdipietro", "html_url": "https://github.com/rdipietro", "followers_url": "https://api.github.com/users/rdipietro/followers", "following_url": "https://api.github.com/users/rdipietro/following{/other_user}", "gists_url": "https://api.github.com/users/rdipietro/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdipietro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdipietro/subscriptions", "organizations_url": "https://api.github.com/users/rdipietro/orgs", "repos_url": "https://api.github.com/users/rdipietro/repos", "events_url": "https://api.github.com/users/rdipietro/events{/privacy}", "received_events_url": "https://api.github.com/users/rdipietro/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-13T20:48:34Z", "updated_at": "2017-06-13T20:49:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Possible implementation:</p>\n<pre><code>def reverse_padded_sequence(inputs, lengths, batch_first=False):\n  if batch_first:\n    inputs = inputs.transpose(0, 1)\n  if inputs.size(1) != len(lengths):\n    raise ValueError('inputs incompatible with lengths.')\n  reversed_inputs = Variable(inputs.data.clone())\n  for i, length in enumerate(lengths):\n    time_ind = torch.LongTensor(list(reversed(range(length))))\n    reversed_inputs[:length, i] = inputs[:, i][time_ind]\n  if batch_first:\n    reversed_inputs = reversed_inputs.transpose(0, 1)\n  return reversed_inputs\n</code></pre>", "body_text": "Possible implementation:\ndef reverse_padded_sequence(inputs, lengths, batch_first=False):\n  if batch_first:\n    inputs = inputs.transpose(0, 1)\n  if inputs.size(1) != len(lengths):\n    raise ValueError('inputs incompatible with lengths.')\n  reversed_inputs = Variable(inputs.data.clone())\n  for i, length in enumerate(lengths):\n    time_ind = torch.LongTensor(list(reversed(range(length))))\n    reversed_inputs[:length, i] = inputs[:, i][time_ind]\n  if batch_first:\n    reversed_inputs = reversed_inputs.transpose(0, 1)\n  return reversed_inputs", "body": "Possible implementation:\r\n\r\n```\r\ndef reverse_padded_sequence(inputs, lengths, batch_first=False):\r\n  if batch_first:\r\n    inputs = inputs.transpose(0, 1)\r\n  if inputs.size(1) != len(lengths):\r\n    raise ValueError('inputs incompatible with lengths.')\r\n  reversed_inputs = Variable(inputs.data.clone())\r\n  for i, length in enumerate(lengths):\r\n    time_ind = torch.LongTensor(list(reversed(range(length))))\r\n    reversed_inputs[:length, i] = inputs[:, i][time_ind]\r\n  if batch_first:\r\n    reversed_inputs = reversed_inputs.transpose(0, 1)\r\n  return reversed_inputs\r\n```"}