{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6166", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6166/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6166/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6166/events", "html_url": "https://github.com/pytorch/pytorch/issues/6166", "id": 310288588, "node_id": "MDU6SXNzdWUzMTAyODg1ODg=", "number": 6166, "title": "3D loss from Fully Convolution Network (for Segmentation) backward error", "user": {"login": "Shaunlipy", "id": 2243270, "node_id": "MDQ6VXNlcjIyNDMyNzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/2243270?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shaunlipy", "html_url": "https://github.com/Shaunlipy", "followers_url": "https://api.github.com/users/Shaunlipy/followers", "following_url": "https://api.github.com/users/Shaunlipy/following{/other_user}", "gists_url": "https://api.github.com/users/Shaunlipy/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shaunlipy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shaunlipy/subscriptions", "organizations_url": "https://api.github.com/users/Shaunlipy/orgs", "repos_url": "https://api.github.com/users/Shaunlipy/repos", "events_url": "https://api.github.com/users/Shaunlipy/events{/privacy}", "received_events_url": "https://api.github.com/users/Shaunlipy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-01T02:51:36Z", "updated_at": "2018-04-01T04:19:10Z", "closed_at": "2018-04-01T04:19:06Z", "author_association": "NONE", "body_html": "<p>Hi, I'm using LogSoftmax(dim=1) for 4D input (batch_size, num_classes, height, width), and with NLLLoss, and generated a 3D tensor.</p>\n<p>But when calling loss.backward(), I got error:<br>\n''<br>\nRuntimeError: grad can be implicitly created only for scalar outputs<br>\n''<br>\nfrom the line loss.backward().</p>\n<p>Can anyone help?</p>\n<p>logsoftmax = nn.LogSoftmax(dim=1).cuda()<br>\ncriterion = torch.nn.NLLLoss(reduce = False).cuda()</p>\n<p>outputs = logsoftmax(outputs)<br>\nloss = criterion(outputs, labels)<br>\nloss.backward()</p>\n<p>Thanks.</p>\n<h2>PyTorch GitHub Issues Guidelines</h2>\n<p>We like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: <a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">https://discuss.pytorch.org/</a></p>\n<p>If you are submitting a feature request, please preface the title with [feature request].</p>\n<p>When submitting a bug report, please include the following information (where relevant):</p>\n<ul>\n<li>PyTorch or Caffe2:</li>\n<li>OS:</li>\n<li>PyTorch version:</li>\n<li>How you installed PyTorch (conda, pip, source):</li>\n<li>Python version:</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU models and configuration:</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Build command you used (if compiling from source):</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>\n<p>In addition, including the following information will also be very helpful for us to diagnose the problem:</p>\n<ul>\n<li>A script to reproduce the bug. Please try to provide as minimal of a test case as possible.</li>\n<li>Error messages and/or stack traces of the bug</li>\n<li>Context around what you are trying to do</li>\n</ul>", "body_text": "Hi, I'm using LogSoftmax(dim=1) for 4D input (batch_size, num_classes, height, width), and with NLLLoss, and generated a 3D tensor.\nBut when calling loss.backward(), I got error:\n''\nRuntimeError: grad can be implicitly created only for scalar outputs\n''\nfrom the line loss.backward().\nCan anyone help?\nlogsoftmax = nn.LogSoftmax(dim=1).cuda()\ncriterion = torch.nn.NLLLoss(reduce = False).cuda()\noutputs = logsoftmax(outputs)\nloss = criterion(outputs, labels)\nloss.backward()\nThanks.\nPyTorch GitHub Issues Guidelines\nWe like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: https://discuss.pytorch.org/\nIf you are submitting a feature request, please preface the title with [feature request].\nWhen submitting a bug report, please include the following information (where relevant):\n\nPyTorch or Caffe2:\nOS:\nPyTorch version:\nHow you installed PyTorch (conda, pip, source):\nPython version:\nCUDA/cuDNN version:\nGPU models and configuration:\nGCC version (if compiling from source):\nCMake version:\nBuild command you used (if compiling from source):\nVersions of any other relevant libraries:\n\nIn addition, including the following information will also be very helpful for us to diagnose the problem:\n\nA script to reproduce the bug. Please try to provide as minimal of a test case as possible.\nError messages and/or stack traces of the bug\nContext around what you are trying to do", "body": "Hi, I'm using LogSoftmax(dim=1) for 4D input (batch_size, num_classes, height, width), and with NLLLoss, and generated a 3D tensor.\r\n\r\nBut when calling loss.backward(), I got error:\r\n''\r\nRuntimeError: grad can be implicitly created only for scalar outputs\r\n''\r\nfrom the line loss.backward().\r\n\r\nCan anyone help?\r\n\r\n\r\n\r\nlogsoftmax = nn.LogSoftmax(dim=1).cuda()\r\ncriterion = torch.nn.NLLLoss(reduce = False).cuda()\r\n\r\noutputs = logsoftmax(outputs)\r\nloss = criterion(outputs, labels)\r\nloss.backward()\r\n \r\nThanks.\r\n\r\nPyTorch GitHub Issues Guidelines\r\n--------------------------------\r\n\r\nWe like to limit our issues to bug reports and feature requests. If you have a question or would like help and support, please visit our forums: https://discuss.pytorch.org/\r\n\r\nIf you are submitting a feature request, please preface the title with [feature request].\r\n\r\nWhen submitting a bug report, please include the following information (where relevant):\r\n- PyTorch or Caffe2:\r\n- OS:\r\n- PyTorch version:\r\n- How you installed PyTorch (conda, pip, source):\r\n- Python version:\r\n- CUDA/cuDNN version:\r\n- GPU models and configuration:\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Build command you used (if compiling from source):\r\n- Versions of any other relevant libraries:\r\n\r\nIn addition, including the following information will also be very helpful for us to diagnose the problem:\r\n- A script to reproduce the bug. Please try to provide as minimal of a test case as possible.\r\n- Error messages and/or stack traces of the bug\r\n- Context around what you are trying to do\r\n"}