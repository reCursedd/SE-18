{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10996", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10996/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10996/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10996/events", "html_url": "https://github.com/pytorch/pytorch/issues/10996", "id": 355143392, "node_id": "MDU6SXNzdWUzNTUxNDMzOTI=", "number": 10996, "title": "Multiprocess Deadlock when using np.transpose and torch.stack ", "user": {"login": "jayhenry", "id": 4285375, "node_id": "MDQ6VXNlcjQyODUzNzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/4285375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jayhenry", "html_url": "https://github.com/jayhenry", "followers_url": "https://api.github.com/users/jayhenry/followers", "following_url": "https://api.github.com/users/jayhenry/following{/other_user}", "gists_url": "https://api.github.com/users/jayhenry/gists{/gist_id}", "starred_url": "https://api.github.com/users/jayhenry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jayhenry/subscriptions", "organizations_url": "https://api.github.com/users/jayhenry/orgs", "repos_url": "https://api.github.com/users/jayhenry/repos", "events_url": "https://api.github.com/users/jayhenry/events{/privacy}", "received_events_url": "https://api.github.com/users/jayhenry/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1040695894, "node_id": "MDU6TGFiZWwxMDQwNjk1ODk0", "url": "https://api.github.com/repos/pytorch/pytorch/labels/multiprocessing", "name": "multiprocessing", "color": "9bc910", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-29T12:46:09Z", "updated_at": "2018-09-05T12:35:43Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Environment:<br>\nUbuntu 16.04.4 LTS<br>\nPython 3.5.2<br>\npytorch 0.4.0<br>\nnumpy 1.14.5<br>\nOr just use horovod image <code>uber/horovod:0.13.10-tf1.9.0-torch0.4.0-py3.5</code></p>\n<p>I run np.transpose and torch.stack first in parent process,  then run np.transpose and torch.stack in the subprocess, then subprocess hangs at torch.stack.<br>\nWhen I comment any np.transpose or torch.stack in parent process or subprocess, it run normally.<br>\nThe minimal code to reproduce is</p>\n<pre><code>import torch.multiprocessing as t_mp\nimport time\nimport numpy as np\nimport torch\n\n\nif __name__ == '__main__':\n    # hangs at stack tensor in subprocess\uff0ceach of Method1-4 can run normally\n    # Python3.5 torch0.4.0\n    start = time.time()\n    print(\"Some ops in main process\")\n    batch = np.random.rand(300, 300, 300)\n    # Method1: Common following one line\n    batch = batch.transpose((2, 0, 1))\n    batch = [torch.from_numpy(b) for b in batch]\n    # Method2: Common following one line\n    batch = torch.stack(batch, 0)\n    print(\"batch type \", type(batch))\n\n    print(\"Multiprocessing with 1 workers\")\n    def _read_worker():\n        batch = np.random.rand(300, 300, 300)\n        print(\"transpose\")\n        # Method3: Common following one line\n        batch = batch.transpose((2, 0, 1))\n        print(\"numpy to tensor\")\n        batch = [torch.from_numpy(b) for b in batch]\n        print(\"torch stack tensor\")\n        # Method4: Common following one line\n        batch = torch.stack(batch, 0)\n        print(\"batch type in worker\", type(batch))\n\n    w = t_mp.Process(\n        target=_read_worker,\n    )\n    w.daemon = True  # ensure that the worker exits on process exit\n    w.start()\n    w.join()\n    print(\"done\")\n</code></pre>\n<p>It really confused me. I didn't even know how to debug it. Can anyone shed a light?</p>", "body_text": "Environment:\nUbuntu 16.04.4 LTS\nPython 3.5.2\npytorch 0.4.0\nnumpy 1.14.5\nOr just use horovod image uber/horovod:0.13.10-tf1.9.0-torch0.4.0-py3.5\nI run np.transpose and torch.stack first in parent process,  then run np.transpose and torch.stack in the subprocess, then subprocess hangs at torch.stack.\nWhen I comment any np.transpose or torch.stack in parent process or subprocess, it run normally.\nThe minimal code to reproduce is\nimport torch.multiprocessing as t_mp\nimport time\nimport numpy as np\nimport torch\n\n\nif __name__ == '__main__':\n    # hangs at stack tensor in subprocess\uff0ceach of Method1-4 can run normally\n    # Python3.5 torch0.4.0\n    start = time.time()\n    print(\"Some ops in main process\")\n    batch = np.random.rand(300, 300, 300)\n    # Method1: Common following one line\n    batch = batch.transpose((2, 0, 1))\n    batch = [torch.from_numpy(b) for b in batch]\n    # Method2: Common following one line\n    batch = torch.stack(batch, 0)\n    print(\"batch type \", type(batch))\n\n    print(\"Multiprocessing with 1 workers\")\n    def _read_worker():\n        batch = np.random.rand(300, 300, 300)\n        print(\"transpose\")\n        # Method3: Common following one line\n        batch = batch.transpose((2, 0, 1))\n        print(\"numpy to tensor\")\n        batch = [torch.from_numpy(b) for b in batch]\n        print(\"torch stack tensor\")\n        # Method4: Common following one line\n        batch = torch.stack(batch, 0)\n        print(\"batch type in worker\", type(batch))\n\n    w = t_mp.Process(\n        target=_read_worker,\n    )\n    w.daemon = True  # ensure that the worker exits on process exit\n    w.start()\n    w.join()\n    print(\"done\")\n\nIt really confused me. I didn't even know how to debug it. Can anyone shed a light?", "body": "Environment: \r\nUbuntu 16.04.4 LTS\r\nPython 3.5.2\r\npytorch 0.4.0\r\nnumpy 1.14.5\r\nOr just use horovod image `uber/horovod:0.13.10-tf1.9.0-torch0.4.0-py3.5`\r\n\r\nI run np.transpose and torch.stack first in parent process,  then run np.transpose and torch.stack in the subprocess, then subprocess hangs at torch.stack.\r\nWhen I comment any np.transpose or torch.stack in parent process or subprocess, it run normally.\r\nThe minimal code to reproduce is \r\n```\r\nimport torch.multiprocessing as t_mp\r\nimport time\r\nimport numpy as np\r\nimport torch\r\n\r\n\r\nif __name__ == '__main__':\r\n    # hangs at stack tensor in subprocess\uff0ceach of Method1-4 can run normally\r\n    # Python3.5 torch0.4.0\r\n    start = time.time()\r\n    print(\"Some ops in main process\")\r\n    batch = np.random.rand(300, 300, 300)\r\n    # Method1: Common following one line\r\n    batch = batch.transpose((2, 0, 1))\r\n    batch = [torch.from_numpy(b) for b in batch]\r\n    # Method2: Common following one line\r\n    batch = torch.stack(batch, 0)\r\n    print(\"batch type \", type(batch))\r\n\r\n    print(\"Multiprocessing with 1 workers\")\r\n    def _read_worker():\r\n        batch = np.random.rand(300, 300, 300)\r\n        print(\"transpose\")\r\n        # Method3: Common following one line\r\n        batch = batch.transpose((2, 0, 1))\r\n        print(\"numpy to tensor\")\r\n        batch = [torch.from_numpy(b) for b in batch]\r\n        print(\"torch stack tensor\")\r\n        # Method4: Common following one line\r\n        batch = torch.stack(batch, 0)\r\n        print(\"batch type in worker\", type(batch))\r\n\r\n    w = t_mp.Process(\r\n        target=_read_worker,\r\n    )\r\n    w.daemon = True  # ensure that the worker exits on process exit\r\n    w.start()\r\n    w.join()\r\n    print(\"done\")\r\n```\r\n\r\nIt really confused me. I didn't even know how to debug it. Can anyone shed a light?"}