{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/406786188", "html_url": "https://github.com/pytorch/pytorch/issues/9533#issuecomment-406786188", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9533", "id": 406786188, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjc4NjE4OA==", "user": {"login": "BIGBALLON", "id": 7837172, "node_id": "MDQ6VXNlcjc4MzcxNzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/7837172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BIGBALLON", "html_url": "https://github.com/BIGBALLON", "followers_url": "https://api.github.com/users/BIGBALLON/followers", "following_url": "https://api.github.com/users/BIGBALLON/following{/other_user}", "gists_url": "https://api.github.com/users/BIGBALLON/gists{/gist_id}", "starred_url": "https://api.github.com/users/BIGBALLON/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BIGBALLON/subscriptions", "organizations_url": "https://api.github.com/users/BIGBALLON/orgs", "repos_url": "https://api.github.com/users/BIGBALLON/repos", "events_url": "https://api.github.com/users/BIGBALLON/events{/privacy}", "received_events_url": "https://api.github.com/users/BIGBALLON/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-21T10:22:11Z", "updated_at": "2018-07-21T10:32:42Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25825048\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/CarlosYeverino\">@CarlosYeverino</a>,</p>\n<p><strong>pros:</strong></p>\n<ul>\n<li>\n<p>high-performance</p>\n<ul>\n<li>very fast speed, faster than pytorch, tensorflow(tf is very slow)</li>\n</ul>\n</li>\n<li>\n<p>for production</p>\n<ul>\n<li>you are able to use pure C++ to deploy such models without having to use Python in your final product. Also, as the community develops enhanced and high-performance modules you are able to easily swap these modules into your Caffe2 project.</li>\n</ul>\n</li>\n<li>\n<p>you can train model by python, than load weight by C++</p>\n</li>\n<li>\n<p>also, you can build model in PyTorch then export to Caffe2 with ONNX for production / mobile</p>\n</li>\n</ul>\n<p><strong>cons:</strong></p>\n<ul>\n<li>no cons, if you just want use python, just ignore it.</li>\n</ul>", "body_text": "Hi @CarlosYeverino,\npros:\n\n\nhigh-performance\n\nvery fast speed, faster than pytorch, tensorflow(tf is very slow)\n\n\n\nfor production\n\nyou are able to use pure C++ to deploy such models without having to use Python in your final product. Also, as the community develops enhanced and high-performance modules you are able to easily swap these modules into your Caffe2 project.\n\n\n\nyou can train model by python, than load weight by C++\n\n\nalso, you can build model in PyTorch then export to Caffe2 with ONNX for production / mobile\n\n\ncons:\n\nno cons, if you just want use python, just ignore it.", "body": "Hi @CarlosYeverino,\r\n\r\n**pros:**\r\n\r\n- high-performance\r\n    - very fast speed, faster than pytorch, tensorflow(tf is very slow)\r\n-  for production \r\n    - you are able to use pure C++ to deploy such models without having to use Python in your final product. Also, as the community develops enhanced and high-performance modules you are able to easily swap these modules into your Caffe2 project.\r\n\r\n- you can train model by python, than load weight by C++\r\n- also, you can build model in PyTorch then export to Caffe2 with ONNX for production / mobile\r\n\r\n**cons:**\r\n\r\n- no cons, if you just want use python, just ignore it."}