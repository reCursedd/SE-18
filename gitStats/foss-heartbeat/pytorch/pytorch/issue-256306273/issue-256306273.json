{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2674", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2674/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2674/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2674/events", "html_url": "https://github.com/pytorch/pytorch/issues/2674", "id": 256306273, "node_id": "MDU6SXNzdWUyNTYzMDYyNzM=", "number": 2674, "title": "Sentiment analysis with LSTM in IMDB dataset", "user": {"login": "miguelgfierro", "id": 3491412, "node_id": "MDQ6VXNlcjM0OTE0MTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/3491412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miguelgfierro", "html_url": "https://github.com/miguelgfierro", "followers_url": "https://api.github.com/users/miguelgfierro/followers", "following_url": "https://api.github.com/users/miguelgfierro/following{/other_user}", "gists_url": "https://api.github.com/users/miguelgfierro/gists{/gist_id}", "starred_url": "https://api.github.com/users/miguelgfierro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miguelgfierro/subscriptions", "organizations_url": "https://api.github.com/users/miguelgfierro/orgs", "repos_url": "https://api.github.com/users/miguelgfierro/repos", "events_url": "https://api.github.com/users/miguelgfierro/events{/privacy}", "received_events_url": "https://api.github.com/users/miguelgfierro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-08T16:26:48Z", "updated_at": "2017-09-09T01:19:03Z", "closed_at": "2017-09-09T01:19:03Z", "author_association": "NONE", "body_html": "<p>Hi, we are trying to compare many frameworks in <a href=\"https://github.com/ilkarman/DeepLearningFrameworks\">this repo</a>. The idea is to compare first CNNs, as we already did. We are now trying to compare GRU/LSTMs. The problem is sentiment analysis with IMDB, here there are the <a href=\"https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_MXNet_IMDB.ipynb\">MXNET</a>, <a href=\"https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_Tensorflow_IMDB.ipynb\">TF</a> and <a href=\"https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_Keras_CNTK_IMDB.ipynb\">Keras</a> examples.</p>\n<p>We have an issue when replicating the problem for pytorch.</p>\n<p>This is how we defined the network:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">SymbolModule</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> MINIBATCH in: [64, 150]</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> LABEL: [64]</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(SymbolModule, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Output: (mini-batch, W, embedding_dim)</span>\n        <span class=\"pl-c1\">self</span>.embedding <span class=\"pl-k\">=</span> nn.Embedding(<span class=\"pl-v\">num_embeddings</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">MAXFEATURES</span>,\n                                      <span class=\"pl-v\">embedding_dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">EMBEDSIZE</span>)\n        <span class=\"pl-c1\">self</span>.lstm <span class=\"pl-k\">=</span> nn.LSTM(<span class=\"pl-v\">input_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">EMBEDSIZE</span>, \n                            <span class=\"pl-v\">hidden_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">NUMHIDDEN</span>)\n        <span class=\"pl-c1\">self</span>.l_out <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">NUMHIDDEN</span>, <span class=\"pl-c1\">2</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        embeds <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.embedding(x)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>print(embeds.size(0), embeds.size(1), embeds.size(2))</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> (64, 150, 125)</span>\n        _batch_size <span class=\"pl-k\">=</span> embeds.size(<span class=\"pl-c1\">1</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 150</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> init hidden-state for each element in batch</span>\n        h0 <span class=\"pl-k\">=</span> Variable(torch.zeros(<span class=\"pl-c1\">1</span>, _batch_size, <span class=\"pl-c1\">NUMHIDDEN</span>).cuda())\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> init cell-state for each element in batch</span>\n        c0 <span class=\"pl-k\">=</span> Variable(torch.zeros(<span class=\"pl-c1\">1</span>, _batch_size, <span class=\"pl-c1\">NUMHIDDEN</span>).cuda())\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> output for each t, (last_hidden-state, last_cell-state)</span>\n        lstm_out, (hn, cn) <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.lstm(embeds, (h0, c0))\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>print(hn.size(0), hn.size(1))</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> (1, 150)</span>\n        hn1 <span class=\"pl-k\">=</span> hn.transpose(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>).contiguous().view(_batch_size, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>print(hn1.size(0))</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> 150</span>\n        out <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.l_out(hn1)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>print(out.size(0), out.size(1))</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> (150, 2)</span>\n        <span class=\"pl-k\">return</span> out</pre></div>\n<p>The data has this size:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">print</span>(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n(<span class=\"pl-c1\">25000</span>, <span class=\"pl-c1\">150</span>) (<span class=\"pl-c1\">25000</span>, <span class=\"pl-c1\">150</span>) (<span class=\"pl-c1\">25000</span>,) (<span class=\"pl-c1\">25000</span>,)</pre></div>\n<p>150 is the sequence size and 25000 is the number of items in the dataset.<br>\nthen the training function is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">EPOCHS</span>):\n    <span class=\"pl-k\">for</span> data, target <span class=\"pl-k\">in</span> yield_mb(x_train, y_train, <span class=\"pl-c1\">BATCHSIZE</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Get samples</span>\n        data <span class=\"pl-k\">=</span> Variable(torch.LongTensor(data).cuda())\n        target <span class=\"pl-k\">=</span> Variable(torch.LongTensor(target).cuda())\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Init</span>\n        optimizer.zero_grad()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Clear out hidden state of lstm</span>\n        sym.hidden <span class=\"pl-k\">=</span> sym.init_hidden()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Forwards</span>\n        output <span class=\"pl-k\">=</span> sym(data)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss</span>\n        loss <span class=\"pl-k\">=</span> criterion(output, target)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Back-prop</span>\n        loss.backward()\n        optimizer.step()\n</pre></div>\n<p>the generator yeilds data of size (BATCHSIZE, 150). And we got this error:</p>\n<div class=\"highlight highlight-source-shell\"><pre>RuntimeError                              Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython-input-19-d76fe9a05bc<span class=\"pl-k\">4&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">&lt;module&gt;</span>()\n     11         sym.hidden = <span class=\"pl-en\">sym.init_hidden</span>()\n     12         <span class=\"pl-c\"><span class=\"pl-c\">#</span> Forwards</span>\n---<span class=\"pl-k\">&gt;</span> 13         output = sym(data)\n     14         <span class=\"pl-c\"><span class=\"pl-c\">#</span> Loss</span>\n     15         loss = criterion(output, target)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py <span class=\"pl-k\">in</span> __call__(self, <span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    222         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_pre_hooks.values</span>():\n    223             hook(self, input)\n--<span class=\"pl-k\">&gt;</span> 224         result = self.forward(<span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    225         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_hooks.values</span>():\n    226             hook_result = hook(self, input, result)\n\n<span class=\"pl-k\">&lt;</span>ipython-input-4-f6357c537b<span class=\"pl-k\">05&gt;</span> <span class=\"pl-k\">in</span> forward(self, x)\n     18     def forward(self, x):\n     19         embeds = self.embed(x)\n---<span class=\"pl-k\">&gt;</span> 20         lstm_out, self.hidden = self.lstm(embeds.view(MAXLEN, 1, -1), self.hidden)\n     21         tag_space = self.hidden2tag(lstm_out.view(MAXLEN, -1))\n     22         <span class=\"pl-k\">return</span> tag_space\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py <span class=\"pl-k\">in</span> __call__(self, <span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    222         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_pre_hooks.values</span>():\n    223             hook(self, input)\n--<span class=\"pl-k\">&gt;</span> 224         result = self.forward(<span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    225         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_hooks.values</span>():\n    226             hook_result = hook(self, input, result)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py <span class=\"pl-k\">in</span> forward(self, input, hx)\n    160             flat_weight=flat_weight\n    161         )\n--<span class=\"pl-k\">&gt;</span> 162         output, hidden = func(input, self.all_weights, hx)\n    163         <span class=\"pl-k\">if</span> is_packed:\n    164             output = PackedSequence(output, batch_sizes)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py <span class=\"pl-k\">in</span> forward(input, <span class=\"pl-k\">*</span>fargs, <span class=\"pl-k\">**</span>fkwargs)\n    349         else:\n    350             func = AutogradRNN(<span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n--<span class=\"pl-k\">&gt;</span> 351         <span class=\"pl-k\">return</span> func(input, <span class=\"pl-k\">*</span>fargs, <span class=\"pl-k\">**</span>fkwargs)\n    352 \n    353     <span class=\"pl-k\">return</span> forward\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py <span class=\"pl-k\">in</span> _do_forward(self, <span class=\"pl-k\">*</span>input)\n    282         self._nested_input = input\n    283         flat_input = tuple(_iter_variables(input))\n--<span class=\"pl-k\">&gt;</span> 284         flat_output = super(NestedIOFunction, self)._do_forward(<span class=\"pl-k\">*</span>flat_input)\n    285         nested_output = self._nested_output\n    286         nested_variables = _unflatten(flat_output, self._nested_output)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py <span class=\"pl-k\">in</span> forward(self, <span class=\"pl-k\">*</span>args)\n    304     def forward(self, <span class=\"pl-k\">*</span>args):\n    305         nested_tensors = _map_variable_tensor(self._nested_input)\n--<span class=\"pl-k\">&gt;</span> 306         result = self.forward_extended(<span class=\"pl-k\">*</span>nested_tensors)\n    307         del self._nested_input\n    308         self._nested_output = result\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py <span class=\"pl-k\">in</span> forward_extended(self, input, weight, hx)\n    291             hy = <span class=\"pl-en\">tuple(h.new</span>() <span class=\"pl-k\">for</span> <span class=\"pl-smi\">h</span> <span class=\"pl-k\">in</span> hx)\n    292 \n--<span class=\"pl-k\">&gt;</span> 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)\n    294 \n    295         self.save_for_backward(input, hx, weight, output)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py <span class=\"pl-k\">in</span> forward(fn, input, hx, weight, output, hy)\n    209         <span class=\"pl-k\">if</span> fn.input_size <span class=\"pl-k\">!</span>= input.size(-1):\n    210             raise RuntimeError(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input.size(-1) must be equal to input_size. Expected {}, got {}<span class=\"pl-pds\">'</span></span>.format(\n--<span class=\"pl-k\">&gt;</span> 211                 fn.input_size, input.size(-1)\n    212             ))\n    213         <span class=\"pl-k\">if</span> fn.dropout <span class=\"pl-k\">!</span>= 0 and <span class=\"pl-en\">cudnn.version</span>() <span class=\"pl-k\">&lt;</span> 5103:\n\nRuntimeError: input.size(-1) must be equal to input_size. Expected 150, got 9600</pre></div>\n<p>Any idea?</p>", "body_text": "Hi, we are trying to compare many frameworks in this repo. The idea is to compare first CNNs, as we already did. We are now trying to compare GRU/LSTMs. The problem is sentiment analysis with IMDB, here there are the MXNET, TF and Keras examples.\nWe have an issue when replicating the problem for pytorch.\nThis is how we defined the network:\nclass SymbolModule(nn.Module):\n    # MINIBATCH in: [64, 150]\n    # LABEL: [64]\n    def __init__(self):\n        super(SymbolModule, self).__init__()\n        # Output: (mini-batch, W, embedding_dim)\n        self.embedding = nn.Embedding(num_embeddings=MAXFEATURES,\n                                      embedding_dim=EMBEDSIZE)\n        self.lstm = nn.LSTM(input_size=EMBEDSIZE, \n                            hidden_size=NUMHIDDEN)\n        self.l_out = nn.Linear(NUMHIDDEN, 2)\n\n    def forward(self, x):\n        embeds = self.embedding(x)\n        #print(embeds.size(0), embeds.size(1), embeds.size(2))\n        # (64, 150, 125)\n        _batch_size = embeds.size(1)  # 150\n        # init hidden-state for each element in batch\n        h0 = Variable(torch.zeros(1, _batch_size, NUMHIDDEN).cuda())\n        # init cell-state for each element in batch\n        c0 = Variable(torch.zeros(1, _batch_size, NUMHIDDEN).cuda())\n        # output for each t, (last_hidden-state, last_cell-state)\n        lstm_out, (hn, cn) = self.lstm(embeds, (h0, c0))\n        #print(hn.size(0), hn.size(1))\n        # (1, 150)\n        hn1 = hn.transpose(0, 1).contiguous().view(_batch_size, -1)\n        #print(hn1.size(0))\n        # 150\n        out = self.l_out(hn1)\n        #print(out.size(0), out.size(1))\n        # (150, 2)\n        return out\nThe data has this size:\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n(25000, 150) (25000, 150) (25000,) (25000,)\n150 is the sequence size and 25000 is the number of items in the dataset.\nthen the training function is:\nfor j in range(EPOCHS):\n    for data, target in yield_mb(x_train, y_train, BATCHSIZE, shuffle=True):\n        # Get samples\n        data = Variable(torch.LongTensor(data).cuda())\n        target = Variable(torch.LongTensor(target).cuda())\n        # Init\n        optimizer.zero_grad()\n        # Clear out hidden state of lstm\n        sym.hidden = sym.init_hidden()\n        # Forwards\n        output = sym(data)\n        # Loss\n        loss = criterion(output, target)\n        # Back-prop\n        loss.backward()\n        optimizer.step()\n\nthe generator yeilds data of size (BATCHSIZE, 150). And we got this error:\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-19-d76fe9a05bc4> in <module>()\n     11         sym.hidden = sym.init_hidden()\n     12         # Forwards\n---> 13         output = sym(data)\n     14         # Loss\n     15         loss = criterion(output, target)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n<ipython-input-4-f6357c537b05> in forward(self, x)\n     18     def forward(self, x):\n     19         embeds = self.embed(x)\n---> 20         lstm_out, self.hidden = self.lstm(embeds.view(MAXLEN, 1, -1), self.hidden)\n     21         tag_space = self.hidden2tag(lstm_out.view(MAXLEN, -1))\n     22         return tag_space\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\n    160             flat_weight=flat_weight\n    161         )\n--> 162         output, hidden = func(input, self.all_weights, hx)\n    163         if is_packed:\n    164             output = PackedSequence(output, batch_sizes)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py in forward(input, *fargs, **fkwargs)\n    349         else:\n    350             func = AutogradRNN(*args, **kwargs)\n--> 351         return func(input, *fargs, **fkwargs)\n    352 \n    353     return forward\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py in _do_forward(self, *input)\n    282         self._nested_input = input\n    283         flat_input = tuple(_iter_variables(input))\n--> 284         flat_output = super(NestedIOFunction, self)._do_forward(*flat_input)\n    285         nested_output = self._nested_output\n    286         nested_variables = _unflatten(flat_output, self._nested_output)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py in forward(self, *args)\n    304     def forward(self, *args):\n    305         nested_tensors = _map_variable_tensor(self._nested_input)\n--> 306         result = self.forward_extended(*nested_tensors)\n    307         del self._nested_input\n    308         self._nested_output = result\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py in forward_extended(self, input, weight, hx)\n    291             hy = tuple(h.new() for h in hx)\n    292 \n--> 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)\n    294 \n    295         self.save_for_backward(input, hx, weight, output)\n\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py in forward(fn, input, hx, weight, output, hy)\n    209         if fn.input_size != input.size(-1):\n    210             raise RuntimeError('input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n--> 211                 fn.input_size, input.size(-1)\n    212             ))\n    213         if fn.dropout != 0 and cudnn.version() < 5103:\n\nRuntimeError: input.size(-1) must be equal to input_size. Expected 150, got 9600\nAny idea?", "body": "Hi, we are trying to compare many frameworks in [this repo](https://github.com/ilkarman/DeepLearningFrameworks). The idea is to compare first CNNs, as we already did. We are now trying to compare GRU/LSTMs. The problem is sentiment analysis with IMDB, here there are the [MXNET](https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_MXNet_IMDB.ipynb), [TF](https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_Tensorflow_IMDB.ipynb) and [Keras](https://github.com/ilkarman/DeepLearningFrameworks/blob/lstm/LSTM_Keras_CNTK_IMDB.ipynb) examples. \r\n\r\nWe have an issue when replicating the problem for pytorch.\r\n\r\nThis is how we defined the network:\r\n```python\r\nclass SymbolModule(nn.Module):\r\n    # MINIBATCH in: [64, 150]\r\n    # LABEL: [64]\r\n    def __init__(self):\r\n        super(SymbolModule, self).__init__()\r\n        # Output: (mini-batch, W, embedding_dim)\r\n        self.embedding = nn.Embedding(num_embeddings=MAXFEATURES,\r\n                                      embedding_dim=EMBEDSIZE)\r\n        self.lstm = nn.LSTM(input_size=EMBEDSIZE, \r\n                            hidden_size=NUMHIDDEN)\r\n        self.l_out = nn.Linear(NUMHIDDEN, 2)\r\n\r\n    def forward(self, x):\r\n        embeds = self.embedding(x)\r\n        #print(embeds.size(0), embeds.size(1), embeds.size(2))\r\n        # (64, 150, 125)\r\n        _batch_size = embeds.size(1)  # 150\r\n        # init hidden-state for each element in batch\r\n        h0 = Variable(torch.zeros(1, _batch_size, NUMHIDDEN).cuda())\r\n        # init cell-state for each element in batch\r\n        c0 = Variable(torch.zeros(1, _batch_size, NUMHIDDEN).cuda())\r\n        # output for each t, (last_hidden-state, last_cell-state)\r\n        lstm_out, (hn, cn) = self.lstm(embeds, (h0, c0))\r\n        #print(hn.size(0), hn.size(1))\r\n        # (1, 150)\r\n        hn1 = hn.transpose(0, 1).contiguous().view(_batch_size, -1)\r\n        #print(hn1.size(0))\r\n        # 150\r\n        out = self.l_out(hn1)\r\n        #print(out.size(0), out.size(1))\r\n        # (150, 2)\r\n        return out\r\n```\r\nThe data has this size:\r\n```python\r\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\r\n(25000, 150) (25000, 150) (25000,) (25000,)\r\n```\r\n150 is the sequence size and 25000 is the number of items in the dataset.\r\nthen the training function is:\r\n```python\r\nfor j in range(EPOCHS):\r\n    for data, target in yield_mb(x_train, y_train, BATCHSIZE, shuffle=True):\r\n        # Get samples\r\n        data = Variable(torch.LongTensor(data).cuda())\r\n        target = Variable(torch.LongTensor(target).cuda())\r\n        # Init\r\n        optimizer.zero_grad()\r\n        # Clear out hidden state of lstm\r\n        sym.hidden = sym.init_hidden()\r\n        # Forwards\r\n        output = sym(data)\r\n        # Loss\r\n        loss = criterion(output, target)\r\n        # Back-prop\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n```\r\nthe generator yeilds data of size (BATCHSIZE, 150). And we got this error:\r\n\r\n```bash\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-19-d76fe9a05bc4> in <module>()\r\n     11         sym.hidden = sym.init_hidden()\r\n     12         # Forwards\r\n---> 13         output = sym(data)\r\n     14         # Loss\r\n     15         loss = criterion(output, target)\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-4-f6357c537b05> in forward(self, x)\r\n     18     def forward(self, x):\r\n     19         embeds = self.embed(x)\r\n---> 20         lstm_out, self.hidden = self.lstm(embeds.view(MAXLEN, 1, -1), self.hidden)\r\n     21         tag_space = self.hidden2tag(lstm_out.view(MAXLEN, -1))\r\n     22         return tag_space\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\r\n    160             flat_weight=flat_weight\r\n    161         )\r\n--> 162         output, hidden = func(input, self.all_weights, hx)\r\n    163         if is_packed:\r\n    164             output = PackedSequence(output, batch_sizes)\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py in forward(input, *fargs, **fkwargs)\r\n    349         else:\r\n    350             func = AutogradRNN(*args, **kwargs)\r\n--> 351         return func(input, *fargs, **fkwargs)\r\n    352 \r\n    353     return forward\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py in _do_forward(self, *input)\r\n    282         self._nested_input = input\r\n    283         flat_input = tuple(_iter_variables(input))\r\n--> 284         flat_output = super(NestedIOFunction, self)._do_forward(*flat_input)\r\n    285         nested_output = self._nested_output\r\n    286         nested_variables = _unflatten(flat_output, self._nested_output)\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/function.py in forward(self, *args)\r\n    304     def forward(self, *args):\r\n    305         nested_tensors = _map_variable_tensor(self._nested_input)\r\n--> 306         result = self.forward_extended(*nested_tensors)\r\n    307         del self._nested_input\r\n    308         self._nested_output = result\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/rnn.py in forward_extended(self, input, weight, hx)\r\n    291             hy = tuple(h.new() for h in hx)\r\n    292 \r\n--> 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)\r\n    294 \r\n    295         self.save_for_backward(input, hx, weight, output)\r\n\r\n/anaconda/envs/py35/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py in forward(fn, input, hx, weight, output, hy)\r\n    209         if fn.input_size != input.size(-1):\r\n    210             raise RuntimeError('input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\r\n--> 211                 fn.input_size, input.size(-1)\r\n    212             ))\r\n    213         if fn.dropout != 0 and cudnn.version() < 5103:\r\n\r\nRuntimeError: input.size(-1) must be equal to input_size. Expected 150, got 9600\r\n```\r\n\r\n\r\n\r\n\r\nAny idea?"}