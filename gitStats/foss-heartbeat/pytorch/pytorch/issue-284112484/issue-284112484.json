{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4313", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4313/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4313/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4313/events", "html_url": "https://github.com/pytorch/pytorch/issues/4313", "id": 284112484, "node_id": "MDU6SXNzdWUyODQxMTI0ODQ=", "number": 4313, "title": "Feature request: any(dim) all(dim)", "user": {"login": "stefdoerr", "id": 7935362, "node_id": "MDQ6VXNlcjc5MzUzNjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7935362?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stefdoerr", "html_url": "https://github.com/stefdoerr", "followers_url": "https://api.github.com/users/stefdoerr/followers", "following_url": "https://api.github.com/users/stefdoerr/following{/other_user}", "gists_url": "https://api.github.com/users/stefdoerr/gists{/gist_id}", "starred_url": "https://api.github.com/users/stefdoerr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stefdoerr/subscriptions", "organizations_url": "https://api.github.com/users/stefdoerr/orgs", "repos_url": "https://api.github.com/users/stefdoerr/repos", "events_url": "https://api.github.com/users/stefdoerr/events{/privacy}", "received_events_url": "https://api.github.com/users/stefdoerr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-22T09:18:25Z", "updated_at": "2018-07-06T20:35:29Z", "closed_at": "2018-07-06T20:35:29Z", "author_association": "NONE", "body_html": "<p>Right now it seems that the <code>.any</code> and <code>.all</code> methods of <code>ByteTensor</code> don't accept a dimension and only operate on the whole array. It would be useful to be able to do these operations over a specific dimension only like <code>tf.reduce_all</code> does since now it forces me to do <code>x.float().sum(dim=1) == x.shape[1]</code></p>", "body_text": "Right now it seems that the .any and .all methods of ByteTensor don't accept a dimension and only operate on the whole array. It would be useful to be able to do these operations over a specific dimension only like tf.reduce_all does since now it forces me to do x.float().sum(dim=1) == x.shape[1]", "body": "Right now it seems that the `.any` and `.all` methods of `ByteTensor` don't accept a dimension and only operate on the whole array. It would be useful to be able to do these operations over a specific dimension only like `tf.reduce_all` does since now it forces me to do `x.float().sum(dim=1) == x.shape[1]`"}