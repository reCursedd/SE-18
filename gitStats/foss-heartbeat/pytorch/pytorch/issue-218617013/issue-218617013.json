{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1164", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1164/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1164/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1164/events", "html_url": "https://github.com/pytorch/pytorch/issues/1164", "id": 218617013, "node_id": "MDU6SXNzdWUyMTg2MTcwMTM=", "number": 1164, "title": "Incorrect output for remainder function on integer type tensors", "user": {"login": "bunelr", "id": 3354626, "node_id": "MDQ6VXNlcjMzNTQ2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3354626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bunelr", "html_url": "https://github.com/bunelr", "followers_url": "https://api.github.com/users/bunelr/followers", "following_url": "https://api.github.com/users/bunelr/following{/other_user}", "gists_url": "https://api.github.com/users/bunelr/gists{/gist_id}", "starred_url": "https://api.github.com/users/bunelr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bunelr/subscriptions", "organizations_url": "https://api.github.com/users/bunelr/orgs", "repos_url": "https://api.github.com/users/bunelr/repos", "events_url": "https://api.github.com/users/bunelr/events{/privacy}", "received_events_url": "https://api.github.com/users/bunelr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 491934870, "node_id": "MDU6TGFiZWw0OTE5MzQ4NzA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/dependency%20bug", "name": "dependency bug", "color": "b60205", "default": false}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bunelr", "id": 3354626, "node_id": "MDQ6VXNlcjMzNTQ2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3354626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bunelr", "html_url": "https://github.com/bunelr", "followers_url": "https://api.github.com/users/bunelr/followers", "following_url": "https://api.github.com/users/bunelr/following{/other_user}", "gists_url": "https://api.github.com/users/bunelr/gists{/gist_id}", "starred_url": "https://api.github.com/users/bunelr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bunelr/subscriptions", "organizations_url": "https://api.github.com/users/bunelr/orgs", "repos_url": "https://api.github.com/users/bunelr/repos", "events_url": "https://api.github.com/users/bunelr/events{/privacy}", "received_events_url": "https://api.github.com/users/bunelr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bunelr", "id": 3354626, "node_id": "MDQ6VXNlcjMzNTQ2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3354626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bunelr", "html_url": "https://github.com/bunelr", "followers_url": "https://api.github.com/users/bunelr/followers", "following_url": "https://api.github.com/users/bunelr/following{/other_user}", "gists_url": "https://api.github.com/users/bunelr/gists{/gist_id}", "starred_url": "https://api.github.com/users/bunelr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bunelr/subscriptions", "organizations_url": "https://api.github.com/users/bunelr/orgs", "repos_url": "https://api.github.com/users/bunelr/repos", "events_url": "https://api.github.com/users/bunelr/events{/privacy}", "received_events_url": "https://api.github.com/users/bunelr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-03-31T21:05:26Z", "updated_at": "2017-04-08T00:25:05Z", "closed_at": "2017-04-08T00:25:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Reproduction code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\nnb_elts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\n\ncoords <span class=\"pl-k\">=</span> torch.range(<span class=\"pl-c1\">0</span>, nb_elts<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>)\nx_coord <span class=\"pl-k\">=</span> coords.unsqueeze(<span class=\"pl-c1\">1</span>).expand(nb_elts, nb_elts)\ny_coord <span class=\"pl-k\">=</span> coords.unsqueeze(<span class=\"pl-c1\">0</span>).expand(nb_elts, nb_elts)\n\nto_diagonal <span class=\"pl-k\">=</span> (x_coord <span class=\"pl-k\">-</span> y_coord)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>To diagonal:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(to_diagonal)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Remainder - Floating point:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(to_diagonal.remainder(nb_elts))\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Fmod - Floating point:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(to_diagonal.fmod(nb_elts))\n\n\nto_diagonal <span class=\"pl-k\">=</span> to_diagonal.long()\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Remainder - Long:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(to_diagonal.remainder(nb_elts))\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Fmod - Long:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(to_diagonal.fmod(nb_elts))</pre></div>\n<p>Generated output:</p>\n<pre><code>$ python bug.py \nTo diagonal:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nRemainder - Floating point:\n\n 0  2  1\n 1  0  2\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nFmod - Floating point:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nRemainder - Long:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.LongTensor of size 3x3]\n\nFmod - Long:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.LongTensor of size 3x3]\n</code></pre>\n<p>The interesting section to look at is <strong>Remainder - Long</strong>. You observe that it gets the same output as with <code>fmod</code>, while for a floating point tensor, you get different results.</p>\n<p>According to the docs, <em>The remainder has the same sign as the divisor.</em>, which is not the case here.</p>\n<p>The weekend is coming up, so I can look at fixing + adding test to avoid regression if you want.<br>\nI imagine that looking around the neighbourhood of <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/f16a624b35dd28fbd4cdcd3bd08dfc2421c3e2b0/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/f16a624b35dd28fbd4cdcd3bd08dfc2421c3e2b0\"><tt>f16a624</tt></a> would be the place to start.</p>", "body_text": "Reproduction code:\nimport torch\n\nnb_elts = 3\n\ncoords = torch.range(0, nb_elts-1, 1)\nx_coord = coords.unsqueeze(1).expand(nb_elts, nb_elts)\ny_coord = coords.unsqueeze(0).expand(nb_elts, nb_elts)\n\nto_diagonal = (x_coord - y_coord)\n\nprint(\"To diagonal:\")\nprint(to_diagonal)\n\nprint(\"Remainder - Floating point:\")\nprint(to_diagonal.remainder(nb_elts))\nprint(\"Fmod - Floating point:\")\nprint(to_diagonal.fmod(nb_elts))\n\n\nto_diagonal = to_diagonal.long()\nprint(\"Remainder - Long:\")\nprint(to_diagonal.remainder(nb_elts))\nprint(\"Fmod - Long:\")\nprint(to_diagonal.fmod(nb_elts))\nGenerated output:\n$ python bug.py \nTo diagonal:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nRemainder - Floating point:\n\n 0  2  1\n 1  0  2\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nFmod - Floating point:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.FloatTensor of size 3x3]\n\nRemainder - Long:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.LongTensor of size 3x3]\n\nFmod - Long:\n\n 0 -1 -2\n 1  0 -1\n 2  1  0\n[torch.LongTensor of size 3x3]\n\nThe interesting section to look at is Remainder - Long. You observe that it gets the same output as with fmod, while for a floating point tensor, you get different results.\nAccording to the docs, The remainder has the same sign as the divisor., which is not the case here.\nThe weekend is coming up, so I can look at fixing + adding test to avoid regression if you want.\nI imagine that looking around the neighbourhood of f16a624 would be the place to start.", "body": "Reproduction code:\r\n\r\n```python\r\nimport torch\r\n\r\nnb_elts = 3\r\n\r\ncoords = torch.range(0, nb_elts-1, 1)\r\nx_coord = coords.unsqueeze(1).expand(nb_elts, nb_elts)\r\ny_coord = coords.unsqueeze(0).expand(nb_elts, nb_elts)\r\n\r\nto_diagonal = (x_coord - y_coord)\r\n\r\nprint(\"To diagonal:\")\r\nprint(to_diagonal)\r\n\r\nprint(\"Remainder - Floating point:\")\r\nprint(to_diagonal.remainder(nb_elts))\r\nprint(\"Fmod - Floating point:\")\r\nprint(to_diagonal.fmod(nb_elts))\r\n\r\n\r\nto_diagonal = to_diagonal.long()\r\nprint(\"Remainder - Long:\")\r\nprint(to_diagonal.remainder(nb_elts))\r\nprint(\"Fmod - Long:\")\r\nprint(to_diagonal.fmod(nb_elts))\r\n```\r\n\r\nGenerated output:\r\n\r\n```\r\n$ python bug.py \r\nTo diagonal:\r\n\r\n 0 -1 -2\r\n 1  0 -1\r\n 2  1  0\r\n[torch.FloatTensor of size 3x3]\r\n\r\nRemainder - Floating point:\r\n\r\n 0  2  1\r\n 1  0  2\r\n 2  1  0\r\n[torch.FloatTensor of size 3x3]\r\n\r\nFmod - Floating point:\r\n\r\n 0 -1 -2\r\n 1  0 -1\r\n 2  1  0\r\n[torch.FloatTensor of size 3x3]\r\n\r\nRemainder - Long:\r\n\r\n 0 -1 -2\r\n 1  0 -1\r\n 2  1  0\r\n[torch.LongTensor of size 3x3]\r\n\r\nFmod - Long:\r\n\r\n 0 -1 -2\r\n 1  0 -1\r\n 2  1  0\r\n[torch.LongTensor of size 3x3]\r\n```\r\n\r\nThe interesting section to look at is **Remainder - Long**. You observe that it gets the same output as with `fmod`, while for a floating point tensor, you get different results.\r\n\r\nAccording to the docs, _The remainder has the same sign as the divisor._, which is not the case here.\r\n\r\nThe weekend is coming up, so I can look at fixing + adding test to avoid regression if you want.\r\nI imagine that looking around the neighbourhood of f16a624b35dd28fbd4cdcd3bd08dfc2421c3e2b0 would be the place to start."}