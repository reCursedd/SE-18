{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422091610", "html_url": "https://github.com/pytorch/pytorch/issues/11340#issuecomment-422091610", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11340", "id": 422091610, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjA5MTYxMA==", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-17T16:56:56Z", "updated_at": "2018-09-17T16:56:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have couple of questions:</p>\n<ol>\n<li>Regarding generator UX: when we set the seed of the generator engine (for instance: philox), do we reset its state, i.e. for instance philox needs an <code>offset</code>, do we set the offset to zero when we set the seed everytime? For the CPU side, if we were to use <code>std:mt19937</code> and called <code>seed(123)</code> on it, <code>std</code> does a re-init before seeding the engine.</li>\n</ol>\n<pre><code>g = torch.Generator()\ng.seed(123)\n</code></pre>\n<ol start=\"2\">\n<li>The default engines for CPU and CUDA will diverge with this PR, i.e. CPU will use mersenne twister (as it does now, except use it from <code>std</code>) and CUDA will use Philox. This means that <code>torch.Generator()</code> and <code>torch.cuda.Generator()</code> will produce different sequences of random numbers if given the same seed. How concerning is it? If it's a problem, do we need a CPU version of Philox engine?</li>\n</ol>", "body_text": "I have couple of questions:\n\nRegarding generator UX: when we set the seed of the generator engine (for instance: philox), do we reset its state, i.e. for instance philox needs an offset, do we set the offset to zero when we set the seed everytime? For the CPU side, if we were to use std:mt19937 and called seed(123) on it, std does a re-init before seeding the engine.\n\ng = torch.Generator()\ng.seed(123)\n\n\nThe default engines for CPU and CUDA will diverge with this PR, i.e. CPU will use mersenne twister (as it does now, except use it from std) and CUDA will use Philox. This means that torch.Generator() and torch.cuda.Generator() will produce different sequences of random numbers if given the same seed. How concerning is it? If it's a problem, do we need a CPU version of Philox engine?", "body": "I have couple of questions:\r\n1. Regarding generator UX: when we set the seed of the generator engine (for instance: philox), do we reset its state, i.e. for instance philox needs an `offset`, do we set the offset to zero when we set the seed everytime? For the CPU side, if we were to use `std:mt19937` and called `seed(123)` on it, `std` does a re-init before seeding the engine. \r\n```\r\ng = torch.Generator()\r\ng.seed(123)\r\n```\r\n2. The default engines for CPU and CUDA will diverge with this PR, i.e. CPU will use mersenne twister (as it does now, except use it from `std`) and CUDA will use Philox. This means that `torch.Generator()` and `torch.cuda.Generator()` will produce different sequences of random numbers if given the same seed. How concerning is it? If it's a problem, do we need a CPU version of Philox engine?"}