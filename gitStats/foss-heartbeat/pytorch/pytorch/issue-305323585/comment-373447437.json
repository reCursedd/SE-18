{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/373447437", "html_url": "https://github.com/pytorch/pytorch/issues/5790#issuecomment-373447437", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5790", "id": 373447437, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzQ0NzQzNw==", "user": {"login": "daemon", "id": 6188572, "node_id": "MDQ6VXNlcjYxODg1NzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/6188572?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daemon", "html_url": "https://github.com/daemon", "followers_url": "https://api.github.com/users/daemon/followers", "following_url": "https://api.github.com/users/daemon/following{/other_user}", "gists_url": "https://api.github.com/users/daemon/gists{/gist_id}", "starred_url": "https://api.github.com/users/daemon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daemon/subscriptions", "organizations_url": "https://api.github.com/users/daemon/orgs", "repos_url": "https://api.github.com/users/daemon/repos", "events_url": "https://api.github.com/users/daemon/events{/privacy}", "received_events_url": "https://api.github.com/users/daemon/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-15T16:54:49Z", "updated_at": "2018-03-15T16:56:39Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> We could register a <code>forward_pre_hook</code> and modify the weights there, but it'd be better to distinguish between the actual module weights and what's provided by our custom ops, which might have parameters themselves. I guess we could then revert to the original weights in a <code>forward_hook</code>, but that's not as concise as having explicit weight hooks/providers.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> Yes, that would work, but then we have to worry about bias, stride, etc. It's definitely a viable solution; it just adds some boilerplate. Actually, that amounts to writing a weight hooking layer:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">HookedConv2d</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">weight_provider</span>, <span class=\"pl-smi\">registry</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.weight_provider <span class=\"pl-k\">=</span> weight_provider\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">hook_weight</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">weight_hook</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n        <span class=\"pl-c1\">self</span>.weight_provider <span class=\"pl-k\">=</span> weight_hook(<span class=\"pl-c1\">self</span>.weight_provider, <span class=\"pl-k\">**</span>kwargs)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        weights <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.weight_provider()\n        <span class=\"pl-k\">return</span> F.conv2d(x, <span class=\"pl-k\">*</span>weights, <span class=\"pl-k\">**</span><span class=\"pl-c1\">...</span>)</pre></div>", "body_text": "@apaszke We could register a forward_pre_hook and modify the weights there, but it'd be better to distinguish between the actual module weights and what's provided by our custom ops, which might have parameters themselves. I guess we could then revert to the original weights in a forward_hook, but that's not as concise as having explicit weight hooks/providers.\n@fmassa Yes, that would work, but then we have to worry about bias, stride, etc. It's definitely a viable solution; it just adds some boilerplate. Actually, that amounts to writing a weight hooking layer:\nclass HookedConv2d(nn.Module):\n    def __init__(self, weight_provider, registry=None):\n        super().__init__()\n        self.weight_provider = weight_provider\n\n    def hook_weight(self, weight_hook, **kwargs):\n        self.weight_provider = weight_hook(self.weight_provider, **kwargs)\n\n    def forward(self, x):\n        weights = self.weight_provider()\n        return F.conv2d(x, *weights, **...)", "body": "@apaszke We could register a `forward_pre_hook` and modify the weights there, but it'd be better to distinguish between the actual module weights and what's provided by our custom ops, which might have parameters themselves. I guess we could then revert to the original weights in a `forward_hook`, but that's not as concise as having explicit weight hooks/providers.\r\n\r\n@fmassa Yes, that would work, but then we have to worry about bias, stride, etc. It's definitely a viable solution; it just adds some boilerplate. Actually, that amounts to writing a weight hooking layer:\r\n```python\r\nclass HookedConv2d(nn.Module):\r\n    def __init__(self, weight_provider, registry=None):\r\n        super().__init__()\r\n        self.weight_provider = weight_provider\r\n\r\n    def hook_weight(self, weight_hook, **kwargs):\r\n        self.weight_provider = weight_hook(self.weight_provider, **kwargs)\r\n\r\n    def forward(self, x):\r\n        weights = self.weight_provider()\r\n        return F.conv2d(x, *weights, **...)\r\n```\r\n"}