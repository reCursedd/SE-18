{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11174", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11174/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11174/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11174/events", "html_url": "https://github.com/pytorch/pytorch/issues/11174", "id": 356219855, "node_id": "MDU6SXNzdWUzNTYyMTk4NTU=", "number": 11174, "title": "SVD very very slow and GELS gives nans, -inf", "user": {"login": "danielhanchen", "id": 23090290, "node_id": "MDQ6VXNlcjIzMDkwMjkw", "avatar_url": "https://avatars0.githubusercontent.com/u/23090290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielhanchen", "html_url": "https://github.com/danielhanchen", "followers_url": "https://api.github.com/users/danielhanchen/followers", "following_url": "https://api.github.com/users/danielhanchen/following{/other_user}", "gists_url": "https://api.github.com/users/danielhanchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielhanchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielhanchen/subscriptions", "organizations_url": "https://api.github.com/users/danielhanchen/orgs", "repos_url": "https://api.github.com/users/danielhanchen/repos", "events_url": "https://api.github.com/users/danielhanchen/events{/privacy}", "received_events_url": "https://api.github.com/users/danielhanchen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2018-09-01T17:33:19Z", "updated_at": "2018-09-09T13:53:40Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hey PyTorch devs! First ever issue from me! :)<br>\nAnyways, I was investigating the speed of many libraries including Numpy, Numba JIT, PyTorch, Scipy, and figuring out which libraries perform the best on 3 tasks so I could make ML faster for HyperLearn! <a href=\"https://github.com/danielhanchen/hyperlearn/\">https://github.com/danielhanchen/hyperlearn/</a>.</p>\n<ol>\n<li>SVD / Pseudoinverses</li>\n<li>Eigh, Eigenvalue decomp</li>\n<li>Lstsq Solve, Least Squares solving.</li>\n</ol>\n<p>Results in seconds are below given N=5,000 and P=6,000</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://raw.githubusercontent.com/danielhanchen/hyperlearn/master/Images/Preliminary%20Results%20N%3D5000%20P%3D6000.png\"><img src=\"https://raw.githubusercontent.com/danielhanchen/hyperlearn/master/Images/Preliminary%20Results%20N%3D5000%20P%3D6000.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>Now, as you can see for all functions, PyTorch is slower. SVD is really shocking, taking approx 2 or so minutes, whilst Scipy takes approx 30ish seconds. I'm guessing it's because I used the divide and conquer SVD, and assuming that PyTorch is not divide and conquer (hence maybe why I'm seeing not &gt;60% CPU usage --&gt; I set num_threads == max, I'm only seeing 30%)</p>\n<p>Also, Eigh is ok. It's very close to Numpy's Eigh, but still a bit suspicious for XXT, where over 10seconds difference is seen.</p>\n<p>Finally, Gels is really bad. I do have to disclose I am using a rank deficient matrix (maybe that's why gels is failing?), but there are nans and -infs. I'm assuming division by 0 is causing the error. If you can't fix this, maybe placing   theta_hat[ np.isnan(theta_hat) | np.isinf(theta_hat) ] = 0 can solve 1/2 of the problem. However, Gels is surprisingly fast when compared to say Scipy / Numpy's lstsq. Just its super unstable and MSE of the results are really high.</p>\n<p>Anyways great work on the package! An extra longer prelim results is @ <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"356202316\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/danielhanchen/hyperlearn/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/danielhanchen/hyperlearn/issues/7/hovercard\" href=\"https://github.com/danielhanchen/hyperlearn/issues/7\">danielhanchen/hyperlearn#7</a></p>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): conda</li>\n<li>Build command you used (if compiling from source): --</li>\n<li>OS: Windows 10</li>\n<li>PyTorch version: 0.4.1  --&gt; used set_num_threads to max</li>\n<li>Python version: 3.6.6</li>\n<li>CUDA/cuDNN version: -- (using CPU)</li>\n<li>GPU models and configuration: --</li>\n<li>GCC version (if compiling from source): --</li>\n<li>CMake version: --</li>\n<li>Versions of any other relevant libraries: MKL latest (i hope)</li>\n</ul>", "body_text": "Hey PyTorch devs! First ever issue from me! :)\nAnyways, I was investigating the speed of many libraries including Numpy, Numba JIT, PyTorch, Scipy, and figuring out which libraries perform the best on 3 tasks so I could make ML faster for HyperLearn! https://github.com/danielhanchen/hyperlearn/.\n\nSVD / Pseudoinverses\nEigh, Eigenvalue decomp\nLstsq Solve, Least Squares solving.\n\nResults in seconds are below given N=5,000 and P=6,000\n\nNow, as you can see for all functions, PyTorch is slower. SVD is really shocking, taking approx 2 or so minutes, whilst Scipy takes approx 30ish seconds. I'm guessing it's because I used the divide and conquer SVD, and assuming that PyTorch is not divide and conquer (hence maybe why I'm seeing not >60% CPU usage --> I set num_threads == max, I'm only seeing 30%)\nAlso, Eigh is ok. It's very close to Numpy's Eigh, but still a bit suspicious for XXT, where over 10seconds difference is seen.\nFinally, Gels is really bad. I do have to disclose I am using a rank deficient matrix (maybe that's why gels is failing?), but there are nans and -infs. I'm assuming division by 0 is causing the error. If you can't fix this, maybe placing   theta_hat[ np.isnan(theta_hat) | np.isinf(theta_hat) ] = 0 can solve 1/2 of the problem. However, Gels is surprisingly fast when compared to say Scipy / Numpy's lstsq. Just its super unstable and MSE of the results are really high.\nAnyways great work on the package! An extra longer prelim results is @ danielhanchen/hyperlearn#7\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): conda\nBuild command you used (if compiling from source): --\nOS: Windows 10\nPyTorch version: 0.4.1  --> used set_num_threads to max\nPython version: 3.6.6\nCUDA/cuDNN version: -- (using CPU)\nGPU models and configuration: --\nGCC version (if compiling from source): --\nCMake version: --\nVersions of any other relevant libraries: MKL latest (i hope)", "body": "Hey PyTorch devs! First ever issue from me! :)\r\nAnyways, I was investigating the speed of many libraries including Numpy, Numba JIT, PyTorch, Scipy, and figuring out which libraries perform the best on 3 tasks so I could make ML faster for HyperLearn! https://github.com/danielhanchen/hyperlearn/.\r\n1. SVD / Pseudoinverses\r\n2. Eigh, Eigenvalue decomp\r\n3. Lstsq Solve, Least Squares solving.\r\n\r\nResults in seconds are below given N=5,000 and P=6,000\r\n\r\n![image](https://raw.githubusercontent.com/danielhanchen/hyperlearn/master/Images/Preliminary%20Results%20N%3D5000%20P%3D6000.png)\r\n\r\nNow, as you can see for all functions, PyTorch is slower. SVD is really shocking, taking approx 2 or so minutes, whilst Scipy takes approx 30ish seconds. I'm guessing it's because I used the divide and conquer SVD, and assuming that PyTorch is not divide and conquer (hence maybe why I'm seeing not >60% CPU usage --> I set num_threads == max, I'm only seeing 30%)\r\n\r\nAlso, Eigh is ok. It's very close to Numpy's Eigh, but still a bit suspicious for XXT, where over 10seconds difference is seen.\r\n\r\nFinally, Gels is really bad. I do have to disclose I am using a rank deficient matrix (maybe that's why gels is failing?), but there are nans and -infs. I'm assuming division by 0 is causing the error. If you can't fix this, maybe placing   theta_hat[ np.isnan(theta_hat) | np.isinf(theta_hat) ] = 0 can solve 1/2 of the problem. However, Gels is surprisingly fast when compared to say Scipy / Numpy's lstsq. Just its super unstable and MSE of the results are really high.\r\n\r\nAnyways great work on the package! An extra longer prelim results is @ https://github.com/danielhanchen/hyperlearn/issues/7\r\n\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): conda\r\n- Build command you used (if compiling from source): --\r\n- OS: Windows 10\r\n- PyTorch version: 0.4.1  --> used set_num_threads to max\r\n- Python version: 3.6.6\r\n- CUDA/cuDNN version: -- (using CPU)\r\n- GPU models and configuration: --\r\n- GCC version (if compiling from source): --\r\n- CMake version: --\r\n- Versions of any other relevant libraries: MKL latest (i hope)\r\n"}