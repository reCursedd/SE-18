{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/417908185", "html_url": "https://github.com/pytorch/pytorch/issues/11174#issuecomment-417908185", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11174", "id": 417908185, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzkwODE4NQ==", "user": {"login": "danielhanchen", "id": 23090290, "node_id": "MDQ6VXNlcjIzMDkwMjkw", "avatar_url": "https://avatars0.githubusercontent.com/u/23090290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielhanchen", "html_url": "https://github.com/danielhanchen", "followers_url": "https://api.github.com/users/danielhanchen/followers", "following_url": "https://api.github.com/users/danielhanchen/following{/other_user}", "gists_url": "https://api.github.com/users/danielhanchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielhanchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielhanchen/subscriptions", "organizations_url": "https://api.github.com/users/danielhanchen/orgs", "repos_url": "https://api.github.com/users/danielhanchen/repos", "events_url": "https://api.github.com/users/danielhanchen/events{/privacy}", "received_events_url": "https://api.github.com/users/danielhanchen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-02T06:23:45Z", "updated_at": "2018-09-02T06:23:45Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23639302\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vishwakftw\">@vishwakftw</a>  <a href=\"https://math.stackexchange.com/questions/2076244/find-the-pseudo-inverse-of-the-matrix-a-without-computing-singular-values-of?rq=1\" rel=\"nofollow\">https://math.stackexchange.com/questions/2076244/find-the-pseudo-inverse-of-the-matrix-a-without-computing-singular-values-of?rq=1</a><br>\nThis might interest you.</p>\n<p>Also I'm researching on approximate Pseudoinverse computation. I'm using regularized eigenvalue decomp and I'm seeing extremely promising results where EigH Pinv implementation takes just under 3.5seconds for N=1,000,000 P = 200. Whilst Scipy/Numpy's Gesdd takes 12.5 seconds (approx 4x faster).</p>\n<p>However, a cost is paid. Numercial stability is sacrificed, with approx 200% more error when compared to exact SVD, where eigH sum(abs(inv @ X)) = 554, whilst SVD's = 217 (so double). Diagonal entries sum to 159.883 and SVD is 159.071 so really really close. Testing on a Least Squares problem, X \\ y, EigH pinv's MSE is 35901.710336, whilst  SVD is 35908.968448 (so SVD is higher...)</p>\n<p>So new EigH solution is approx 4x faster + a bit better accuracy on least squares soln, at the cost of 2x numerical precision errors.</p>", "body_text": "@vishwakftw  https://math.stackexchange.com/questions/2076244/find-the-pseudo-inverse-of-the-matrix-a-without-computing-singular-values-of?rq=1\nThis might interest you.\nAlso I'm researching on approximate Pseudoinverse computation. I'm using regularized eigenvalue decomp and I'm seeing extremely promising results where EigH Pinv implementation takes just under 3.5seconds for N=1,000,000 P = 200. Whilst Scipy/Numpy's Gesdd takes 12.5 seconds (approx 4x faster).\nHowever, a cost is paid. Numercial stability is sacrificed, with approx 200% more error when compared to exact SVD, where eigH sum(abs(inv @ X)) = 554, whilst SVD's = 217 (so double). Diagonal entries sum to 159.883 and SVD is 159.071 so really really close. Testing on a Least Squares problem, X \\ y, EigH pinv's MSE is 35901.710336, whilst  SVD is 35908.968448 (so SVD is higher...)\nSo new EigH solution is approx 4x faster + a bit better accuracy on least squares soln, at the cost of 2x numerical precision errors.", "body": "@vishwakftw  https://math.stackexchange.com/questions/2076244/find-the-pseudo-inverse-of-the-matrix-a-without-computing-singular-values-of?rq=1\r\nThis might interest you.\r\n\r\nAlso I'm researching on approximate Pseudoinverse computation. I'm using regularized eigenvalue decomp and I'm seeing extremely promising results where EigH Pinv implementation takes just under 3.5seconds for N=1,000,000 P = 200. Whilst Scipy/Numpy's Gesdd takes 12.5 seconds (approx 4x faster).\r\n\r\nHowever, a cost is paid. Numercial stability is sacrificed, with approx 200% more error when compared to exact SVD, where eigH sum(abs(inv @ X)) = 554, whilst SVD's = 217 (so double). Diagonal entries sum to 159.883 and SVD is 159.071 so really really close. Testing on a Least Squares problem, X \\ y, EigH pinv's MSE is 35901.710336, whilst  SVD is 35908.968448 (so SVD is higher...)\r\n\r\nSo new EigH solution is approx 4x faster + a bit better accuracy on least squares soln, at the cost of 2x numerical precision errors."}