{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4382", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4382/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4382/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4382/events", "html_url": "https://github.com/pytorch/pytorch/issues/4382", "id": 284935542, "node_id": "MDU6SXNzdWUyODQ5MzU1NDI=", "number": 4382, "title": "Synchronized communication with workers", "user": {"login": "0phoff", "id": 11853089, "node_id": "MDQ6VXNlcjExODUzMDg5", "avatar_url": "https://avatars3.githubusercontent.com/u/11853089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/0phoff", "html_url": "https://github.com/0phoff", "followers_url": "https://api.github.com/users/0phoff/followers", "following_url": "https://api.github.com/users/0phoff/following{/other_user}", "gists_url": "https://api.github.com/users/0phoff/gists{/gist_id}", "starred_url": "https://api.github.com/users/0phoff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/0phoff/subscriptions", "organizations_url": "https://api.github.com/users/0phoff/orgs", "repos_url": "https://api.github.com/users/0phoff/repos", "events_url": "https://api.github.com/users/0phoff/events{/privacy}", "received_events_url": "https://api.github.com/users/0phoff/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-28T15:22:21Z", "updated_at": "2018-01-02T13:20:44Z", "closed_at": "2018-01-02T13:20:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The full extend of my problem can be read <a href=\"https://discuss.pytorch.org/t/communicating-with-dataloader-workers/11473\" rel=\"nofollow\">here</a> on the forums.<br>\nBut what I basically need, is a way to communicate with my worker threads before they start preparing the next batch.</p>\n<p>I think the easiest way to implement this is to pass a function as an argument to your <em>DataLoader</em>.<br>\nThe <em>DataLoaderIter</em> object can then call this function before sending the new indices on the Queu,<br>\nlike <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L291\">here</a> in the code maybe?<br>\nIn that function you could then communicate with your workers via <em>multiprocessing</em> variables.</p>\n<p>I think this is a problem others will encounter as well and is therefore worth implementing...<br>\nHowever, I noticed you guys are reworking the dataloader code, so let me know if that fits in with your vision on how things will evolve for pytorch!</p>\n<p>If you think this is worth adding and if my method of solving looks good to you, I can take a look at implementing this and sending in a PR. <g-emoji class=\"g-emoji\" alias=\"construction_worker_man\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f477.png\">\ud83d\udc77</g-emoji></p>", "body_text": "The full extend of my problem can be read here on the forums.\nBut what I basically need, is a way to communicate with my worker threads before they start preparing the next batch.\nI think the easiest way to implement this is to pass a function as an argument to your DataLoader.\nThe DataLoaderIter object can then call this function before sending the new indices on the Queu,\nlike here in the code maybe?\nIn that function you could then communicate with your workers via multiprocessing variables.\nI think this is a problem others will encounter as well and is therefore worth implementing...\nHowever, I noticed you guys are reworking the dataloader code, so let me know if that fits in with your vision on how things will evolve for pytorch!\nIf you think this is worth adding and if my method of solving looks good to you, I can take a look at implementing this and sending in a PR. \ud83d\udc77", "body": "The full extend of my problem can be read [here](https://discuss.pytorch.org/t/communicating-with-dataloader-workers/11473) on the forums.\r\nBut what I basically need, is a way to communicate with my worker threads before they start preparing the next batch.\r\n\r\nI think the easiest way to implement this is to pass a function as an argument to your _DataLoader_.\r\nThe _DataLoaderIter_ object can then call this function before sending the new indices on the Queu,\r\n like [here](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L291) in the code maybe?  \r\nIn that function you could then communicate with your workers via _multiprocessing_ variables.\r\n\r\nI think this is a problem others will encounter as well and is therefore worth implementing...\r\nHowever, I noticed you guys are reworking the dataloader code, so let me know if that fits in with your vision on how things will evolve for pytorch!\r\n\r\nIf you think this is worth adding and if my method of solving looks good to you, I can take a look at implementing this and sending in a PR. :construction_worker:\r\n"}