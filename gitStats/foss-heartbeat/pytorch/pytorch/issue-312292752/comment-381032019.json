{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/381032019", "html_url": "https://github.com/pytorch/pytorch/issues/6402#issuecomment-381032019", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6402", "id": 381032019, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTAzMjAxOQ==", "user": {"login": "jimmyoic", "id": 7804036, "node_id": "MDQ6VXNlcjc4MDQwMzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/7804036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jimmyoic", "html_url": "https://github.com/jimmyoic", "followers_url": "https://api.github.com/users/jimmyoic/followers", "following_url": "https://api.github.com/users/jimmyoic/following{/other_user}", "gists_url": "https://api.github.com/users/jimmyoic/gists{/gist_id}", "starred_url": "https://api.github.com/users/jimmyoic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jimmyoic/subscriptions", "organizations_url": "https://api.github.com/users/jimmyoic/orgs", "repos_url": "https://api.github.com/users/jimmyoic/repos", "events_url": "https://api.github.com/users/jimmyoic/events{/privacy}", "received_events_url": "https://api.github.com/users/jimmyoic/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-13T05:57:27Z", "updated_at": "2018-04-13T05:57:27Z", "author_association": "NONE", "body_html": "<p>How do you generate your training prototxt?<br>\nMy first quick idea follows pytorch way <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3186211\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Erotemic\">@Erotemic</a> mentioned is that you can set the input of lr as 0<br>\nFor example<br>\n<code>op { input: \"gpu_1/conv1_b_grad\" input: \"gpu_1/conv1_b_momentum\" input: \"gpu_1/lr\" input: \"gpu_1/conv1_b\" output: \"gpu_1/conv1_b_grad\" output: \"gpu_1/conv1_b_momentum\" output: \"gpu_1/conv1_b\" name: \"\" type: \"MomentumSGDUpdate\" arg { name: \"nesterov\" i: 1 } arg { name: \"momentum\" f: 0.899999976158 } device_option { device_type: 1 cuda_gpu_id: 1 } }</code></p>\n<p>This updates the bias of conv1 by MomentumSGDUpdate with learning rate as gpu_1/lr. We can replace this input by ZERO . I'm not sure is this the best way but I think it might work.</p>", "body_text": "How do you generate your training prototxt?\nMy first quick idea follows pytorch way @Erotemic mentioned is that you can set the input of lr as 0\nFor example\nop { input: \"gpu_1/conv1_b_grad\" input: \"gpu_1/conv1_b_momentum\" input: \"gpu_1/lr\" input: \"gpu_1/conv1_b\" output: \"gpu_1/conv1_b_grad\" output: \"gpu_1/conv1_b_momentum\" output: \"gpu_1/conv1_b\" name: \"\" type: \"MomentumSGDUpdate\" arg { name: \"nesterov\" i: 1 } arg { name: \"momentum\" f: 0.899999976158 } device_option { device_type: 1 cuda_gpu_id: 1 } }\nThis updates the bias of conv1 by MomentumSGDUpdate with learning rate as gpu_1/lr. We can replace this input by ZERO . I'm not sure is this the best way but I think it might work.", "body": "How do you generate your training prototxt?\r\nMy first quick idea follows pytorch way @Erotemic mentioned is that you can set the input of lr as 0\r\nFor example\r\n`op {\r\n  input: \"gpu_1/conv1_b_grad\"\r\n  input: \"gpu_1/conv1_b_momentum\"\r\n  input: \"gpu_1/lr\"\r\n  input: \"gpu_1/conv1_b\"\r\n  output: \"gpu_1/conv1_b_grad\"\r\n  output: \"gpu_1/conv1_b_momentum\"\r\n  output: \"gpu_1/conv1_b\"\r\n  name: \"\"\r\n  type: \"MomentumSGDUpdate\"\r\n  arg {\r\n    name: \"nesterov\"\r\n    i: 1\r\n  }\r\n  arg {\r\n    name: \"momentum\"\r\n    f: 0.899999976158\r\n  }\r\n  device_option {\r\n    device_type: 1\r\n    cuda_gpu_id: 1\r\n  }\r\n}`\r\n\r\nThis updates the bias of conv1 by MomentumSGDUpdate with learning rate as gpu_1/lr. We can replace this input by ZERO . I'm not sure is this the best way but I think it might work.\r\n"}