{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7883", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7883/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7883/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7883/events", "html_url": "https://github.com/pytorch/pytorch/issues/7883", "id": 326817068, "node_id": "MDU6SXNzdWUzMjY4MTcwNjg=", "number": 7883, "title": "[PyTorch] torch.stft is slow on cpu compared to numpy", "user": {"login": "Rikorose", "id": 16517898, "node_id": "MDQ6VXNlcjE2NTE3ODk4", "avatar_url": "https://avatars0.githubusercontent.com/u/16517898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rikorose", "html_url": "https://github.com/Rikorose", "followers_url": "https://api.github.com/users/Rikorose/followers", "following_url": "https://api.github.com/users/Rikorose/following{/other_user}", "gists_url": "https://api.github.com/users/Rikorose/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rikorose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rikorose/subscriptions", "organizations_url": "https://api.github.com/users/Rikorose/orgs", "repos_url": "https://api.github.com/users/Rikorose/repos", "events_url": "https://api.github.com/users/Rikorose/events{/privacy}", "received_events_url": "https://api.github.com/users/Rikorose/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-27T13:35:48Z", "updated_at": "2018-07-17T17:57:55Z", "closed_at": "2018-07-17T17:56:33Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>The pytorch stft implementation and thus the <a href=\"https://github.com/pytorch/audio/blob/5787787edcc82ce505a5d8869b5d09022b46503e/torchaudio/transforms.py#L172\">pytorch/audio SPECTROGRAM transform</a> is pretty slow (factor x10) in comparison with the librosa (numpy based) spectrogram computation.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    n_fft <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4096</span>\n    hop_length <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\n    n_mels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>\n    f_min <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\n    f_max <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8192</span>\n\n    <span class=\"pl-k\">import</span> librosa\n    <span class=\"pl-k\">import</span> time\n    <span class=\"pl-k\">from</span> torchaudio.transforms <span class=\"pl-k\">import</span> <span class=\"pl-c1\">SPECTROGRAM</span>\n\n    sig, sr <span class=\"pl-k\">=</span> librosa.load(librosa.util.example_audio_file())\n    torch_spec_tranform <span class=\"pl-k\">=</span> SPECTROGRAM(<span class=\"pl-v\">ws</span><span class=\"pl-k\">=</span>n_fft, <span class=\"pl-v\">hop</span><span class=\"pl-k\">=</span>hop_length)\n    <span class=\"pl-k\">with</span> torch.no_grad():\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>librosa: <span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">end</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        start <span class=\"pl-k\">=</span> time.time()\n        <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n            spec <span class=\"pl-k\">=</span> librosa.core.stft(sig, <span class=\"pl-v\">n_fft</span><span class=\"pl-k\">=</span>n_fft, <span class=\"pl-v\">hop_length</span><span class=\"pl-k\">=</span>hop_length)\n        <span class=\"pl-c1\">print</span>(time.time() <span class=\"pl-k\">-</span> start)\n        <span class=\"pl-c1\">print</span>(spec.shape)\n\n        sig <span class=\"pl-k\">=</span> torch.from_numpy(sig)\n        sig <span class=\"pl-k\">=</span> sig.expand(<span class=\"pl-c1\">10</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch: <span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">end</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>)\n        start <span class=\"pl-k\">=</span> time.time()\n        spec <span class=\"pl-k\">=</span> torch_spec_tranform(sig)\n        <span class=\"pl-c1\">print</span>(time.time() <span class=\"pl-k\">-</span> start)\n        <span class=\"pl-c1\">print</span>(spec.shape)</pre></div>\n<p>out:</p>\n<div class=\"highlight highlight-source-shell\"><pre>Warning: volatile was removed and now has no effect. Use <span class=\"pl-s\"><span class=\"pl-pds\">`</span>with <span class=\"pl-en\">torch.no_grad</span>():<span class=\"pl-s\"><span class=\"pl-pds\">`</span> instead.</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">  self.window = Variable(self.window, volatile=True)</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">librosa: 1.6748952865600586</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">(2049, 2647)</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">torch: 15.748203754425049</span></span>\n<span class=\"pl-s\"><span class=\"pl-s\">torch.Size([10, 2639, 2049])</span></span></pre></div>\n<h2>System Info</h2>\n<div class=\"highlight highlight-source-shell\"><pre>python collect_env.py\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Fedora release 28 (Twenty Eight)\nGCC version: (GCC) 8.1.1 20180502 (Red Hat 8.1.1-1)\nCMake version: version 3.11.2\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] torch (0.4.0)\n[pip3] torchaudio (0.1)\n[pip3] torchvision (0.2.1)\n[conda] Could not collect</pre></div>\n<p>My CPU:<br>\nIntel(R) Core(TM) i5-5200U CPU @ 2.20GHz<br>\nwith 16 GB RAM</p>", "body_text": "Issue description\nThe pytorch stft implementation and thus the pytorch/audio SPECTROGRAM transform is pretty slow (factor x10) in comparison with the librosa (numpy based) spectrogram computation.\nCode example\nif __name__ == \"__main__\":\n    n_fft = 4096\n    hop_length = 512\n    n_mels = 128\n    f_min = 512\n    f_max = 8192\n\n    import librosa\n    import time\n    from torchaudio.transforms import SPECTROGRAM\n\n    sig, sr = librosa.load(librosa.util.example_audio_file())\n    torch_spec_tranform = SPECTROGRAM(ws=n_fft, hop=hop_length)\n    with torch.no_grad():\n        print(\"librosa: \", end=\"\")\n        start = time.time()\n        for _ in range(10):\n            spec = librosa.core.stft(sig, n_fft=n_fft, hop_length=hop_length)\n        print(time.time() - start)\n        print(spec.shape)\n\n        sig = torch.from_numpy(sig)\n        sig = sig.expand(10, -1)\n        print(\"torch: \", end=\"\")\n        start = time.time()\n        spec = torch_spec_tranform(sig)\n        print(time.time() - start)\n        print(spec.shape)\nout:\nWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n  self.window = Variable(self.window, volatile=True)\nlibrosa: 1.6748952865600586\n(2049, 2647)\ntorch: 15.748203754425049\ntorch.Size([10, 2639, 2049])\nSystem Info\npython collect_env.py\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Fedora release 28 (Twenty Eight)\nGCC version: (GCC) 8.1.1 20180502 (Red Hat 8.1.1-1)\nCMake version: version 3.11.2\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] torch (0.4.0)\n[pip3] torchaudio (0.1)\n[pip3] torchvision (0.2.1)\n[conda] Could not collect\nMy CPU:\nIntel(R) Core(TM) i5-5200U CPU @ 2.20GHz\nwith 16 GB RAM", "body": "## Issue description\r\nThe pytorch stft implementation and thus the [pytorch/audio SPECTROGRAM transform](https://github.com/pytorch/audio/blob/5787787edcc82ce505a5d8869b5d09022b46503e/torchaudio/transforms.py#L172) is pretty slow (factor x10) in comparison with the librosa (numpy based) spectrogram computation.\r\n\r\n## Code example\r\n\r\n```py\r\nif __name__ == \"__main__\":\r\n    n_fft = 4096\r\n    hop_length = 512\r\n    n_mels = 128\r\n    f_min = 512\r\n    f_max = 8192\r\n\r\n    import librosa\r\n    import time\r\n    from torchaudio.transforms import SPECTROGRAM\r\n\r\n    sig, sr = librosa.load(librosa.util.example_audio_file())\r\n    torch_spec_tranform = SPECTROGRAM(ws=n_fft, hop=hop_length)\r\n    with torch.no_grad():\r\n        print(\"librosa: \", end=\"\")\r\n        start = time.time()\r\n        for _ in range(10):\r\n            spec = librosa.core.stft(sig, n_fft=n_fft, hop_length=hop_length)\r\n        print(time.time() - start)\r\n        print(spec.shape)\r\n\r\n        sig = torch.from_numpy(sig)\r\n        sig = sig.expand(10, -1)\r\n        print(\"torch: \", end=\"\")\r\n        start = time.time()\r\n        spec = torch_spec_tranform(sig)\r\n        print(time.time() - start)\r\n        print(spec.shape)\r\n```\r\nout:\r\n```bash\r\nWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n  self.window = Variable(self.window, volatile=True)\r\nlibrosa: 1.6748952865600586\r\n(2049, 2647)\r\ntorch: 15.748203754425049\r\ntorch.Size([10, 2639, 2049])\r\n```\r\n\r\n## System Info\r\n```bash\r\npython collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Fedora release 28 (Twenty Eight)\r\nGCC version: (GCC) 8.1.1 20180502 (Red Hat 8.1.1-1)\r\nCMake version: version 3.11.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.3)\r\n[pip3] torch (0.4.0)\r\n[pip3] torchaudio (0.1)\r\n[pip3] torchvision (0.2.1)\r\n[conda] Could not collect\r\n```\r\nMy CPU:\r\nIntel(R) Core(TM) i5-5200U CPU @ 2.20GHz\r\nwith 16 GB RAM"}