{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143155169", "pull_request_review_id": 67623475, "id": 143155169, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MzE1NTE2OQ==", "diff_hunk": "@@ -580,5 +567,85 @@ def _time(trace_name, name, time=True):\n         print(\"{} {} time: {} ms\".format(trace_name, name, start.elapsed_time(end)))\n \n \n+def verify(model, args, loss_fn=torch.sum, devices=None):\n+    \"\"\"\n+    Verify that a JIT compiled model has the same behavior as its uncompiled\n+    version along with its backwards pass.\n+\n+    This function has side-effects (e.g., it executes your model / saves and loads\n+    parameters), so don't expect the model to come out exactly the same as what\n+    you passed in.\n+\n+    Arguments:\n+        model (compiled torch.nn.Module): the compiled module/function to be\n+            verified.  The module/function definition MUST have been decorated with\n+            `@torch.jit.compile`.\n+        args (tuple or Variable): the positional arguments to pass to the\n+            compiled function/module to be verified.  A non-tuple is assumed to\n+            be a single positional argument to be passed to the model.\n+        loss_fn (function, optional): the loss function to be applied to\n+            the output of the model, before backwards is invoked.  By default,\n+            we assume that a model returns a single result, and we :func:`torch.sum`\n+            before calling backwards; if this is inappropriate, you can pass your\n+            own loss function.  Note that if a model returns a tuple of results,\n+            these are passed as separate arguments to `loss_fn`.\n+        devices (iterable of device IDs, optional): the GPU devices which the\n+            compiled module will be run on.  This determines the RNG state we\n+            must save when running both compiled and uncompiled versions of the model.\n+    \"\"\"\n+    # TODO: In principle, we track device information in our trace, so it\n+    # should be possible to check if our execution actually obeyed the 'devices'\n+    # the user provided.\n+\n+    # TODO: Consider adding a utility function to torch.jit to test\n+    # for this case\n+    if not isinstance(model, _CompiledMixin):\n+        raise TypeError(\"Cannot verify an uncompiled module.  Add @torch.jit.compile to compile it\")\n+\n+    if not isinstance(args, tuple):\n+        args = (args,)\n+\n+    verify_args = _clone_inputs(args)\n+\n+    verify_state = model.state_dict()\n+    model.zero_grad()\n+\n+    # We use a special API to reset the trace and compile it from scratch.\n+\n+    with torch.random.fork_rng(devices, _caller=\"torch.jit.verify\"):\n+        out = model(*args, _force_trace=True)\n+        if not isinstance(out, tuple):\n+            out = (out, )\n+        out_vars, _ = _flatten(out)\n+        saved_outs = [v.data.clone() for v in out_vars]\n+        loss = loss_fn(*out)\n+        loss.backward()\n+        saved_grads = [v.grad.data.clone() for v in model.parameters()]\n+        assert model.has_trace_for(*args)\n+\n+    model.load_state_dict(verify_state)\n+    verify_out = model(*verify_args)", "path": "torch/jit/__init__.py", "position": null, "original_position": 207, "commit_id": "672a20149aada1a999056fd6074d3726fe8b1d8d", "original_commit_id": "7735ba1f8eabf3506cfc416fc04621266be7fbec", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "`out` and `verify_out` give you absolutely no information about what they are. Which one is the original and which one is from the JIT?", "created_at": "2017-10-06T10:11:31Z", "updated_at": "2018-11-23T15:35:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/2995#discussion_r143155169", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2995", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143155169"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2995#discussion_r143155169"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2995"}}, "body_html": "<p><code>out</code> and <code>verify_out</code> give you absolutely no information about what they are. Which one is the original and which one is from the JIT?</p>", "body_text": "out and verify_out give you absolutely no information about what they are. Which one is the original and which one is from the JIT?"}