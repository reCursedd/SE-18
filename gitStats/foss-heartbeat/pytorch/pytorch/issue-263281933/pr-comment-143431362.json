{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143431362", "pull_request_review_id": 67940577, "id": 143431362, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MzQzMTM2Mg==", "diff_hunk": "@@ -580,5 +570,77 @@ def _time(trace_name, name, time=True):\n         print(\"{} {} time: {} ms\".format(trace_name, name, start.elapsed_time(end)))\n \n \n+def verify(model, args, loss_fn=torch.sum, devices=None):\n+    \"\"\"\n+    Verify that a JIT compiled model has the same behavior as its uncompiled\n+    version along with its backwards pass.\n+\n+    This function has side-effects (e.g., it executes your model / saves and loads\n+    parameters), so don't expect the model to come out exactly the same as what\n+    you passed in.\n+\n+    Arguments:\n+        model (compiled torch.nn.Module or function): the module/function to be\n+            verified.  The module/function definition MUST have been decorated with\n+            `@torch.jit.compile`.\n+        args (tuple or Variable): the positional arguments to pass to the\n+            compiled function/module to be verified.  A non-tuple is assumed to\n+            be a single positional argument to be passed to the model.\n+        loss_fn (function, optional): the loss function to be applied to\n+            the output of the model, before backwards is invoked.  By default,\n+            we assume that a model returns a single result, and we :func:`torch.sum`\n+            before calling backwards; if this is inappropriate, you can pass your\n+            own loss function.  Note that if a model returns a tuple of results,\n+            these are passed as separate arguments to `loss_fn`.\n+        devices (iterable of device IDs, optional): the GPU devices which the\n+            compiled module will be run on.  This determines the RNG state we\n+            must save when running both compiled and uncompiled versions of the model.\n+    \"\"\"\n+    # TODO: In principle, we track device information in our trace, so it\n+    # should be possible to check if our execution actually obeyed the 'devices'\n+    # the user provided.\n+\n+    # TODO: Consider adding a utility function to torch.jit to test\n+    # for this case\n+    if not isinstance(model, _CompiledMixin):\n+        raise TypeError(\"Cannot verify an uncompiled module.  Add @torch.jit.compile to compile it\")\n+\n+    if not isinstance(args, tuple):\n+        args = (args,)\n+\n+    saved_args = _clone_inputs(args)\n+    saved_state = copy.deepcopy(model.state_dict())\n+\n+    def run_fwd_bwd(args, force_trace=False):\n+        in_vars, _ = _flatten(args, model.state_dict(keep_vars=True).values())\n+        # We use a special API to reset the trace and compile it from scratch.\n+        out = model(*args, _force_trace=force_trace)\n+        if not isinstance(out, tuple):\n+            out = (out, )\n+        out_vars, _ = _flatten(out)\n+        saved_outs = [v.data.clone() for v in out_vars]\n+        loss = loss_fn(*out)\n+        grads = torch.autograd.grad([loss], in_vars)\n+        # TODO: I'm not sure if the clone here is necessary but it is safer\n+        saved_grads = [v.data.clone() for v in grads]\n+        return (saved_outs, saved_grads)\n+\n+    with torch.random.fork_rng(devices, _caller=\"torch.jit.verify\"):\n+        uncompiled_outs, uncompiled_grads = run_fwd_bwd(args, force_trace=True)\n+        assert model.has_trace_for(*args)\n+\n+    model.load_state_dict(saved_state)", "path": "torch/jit/__init__.py", "position": 215, "original_position": 210, "commit_id": "672a20149aada1a999056fd6074d3726fe8b1d8d", "original_commit_id": "96f9ed9f65d62c65a59f3047e476605ca8a4590e", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Ah my bad. Thanks @fmassa ", "created_at": "2017-10-09T10:27:18Z", "updated_at": "2018-11-23T15:35:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/2995#discussion_r143431362", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2995", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143431362"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2995#discussion_r143431362"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2995"}}, "body_html": "<p>Ah my bad. Thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a></p>", "body_text": "Ah my bad. Thanks @fmassa", "in_reply_to_id": 143411664}