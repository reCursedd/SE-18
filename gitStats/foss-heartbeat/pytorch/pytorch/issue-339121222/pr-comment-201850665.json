{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/201850665", "pull_request_review_id": 136384362, "id": 201850665, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMTg1MDY2NQ==", "diff_hunk": "@@ -0,0 +1,179 @@\n+#include <catch.hpp>\n+\n+#include <torch/csrc/autograd/functions/comm.h>\n+#include <torch/nn/module.h>\n+#include <torch/nn/modules/linear.h>\n+#include <torch/nn/parallel/data_parallel.h>\n+#include <torch/nn/pimpl.h>\n+#include <torch/tensor.h>\n+\n+#include <iostream>\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n+using namespace torch::autograd;\n+using namespace torch::nn;\n+\n+TEST_CASE(\"Parallel/DifferentiableScatter\", \"[cuda]\") {\n+  Scatter scatter(\n+      {torch::Device(torch::kCUDA, 0), torch::Device(torch::kCUDA, 1)});\n+\n+  auto input = torch::ones(10, torch::requires_grad(true));\n+  auto output = scatter.apply({input});\n+\n+  REQUIRE(output.size() == 2);\n+  REQUIRE(output[0].size(0) == 5);\n+  REQUIRE(output[1].size(0) == 5);\n+\n+  auto sum = output[0].to({torch::kCUDA, 1}) + output[1];\n+  sum.backward();\n+\n+  REQUIRE(input.grad().defined());\n+  REQUIRE(input.grad().device().is_cpu());\n+  REQUIRE(input.grad().sum().toCInt() == 10);\n+}\n+\n+TEST_CASE(\"Parallel/DifferentiableGather\", \"[cuda]\") {\n+  Gather gather(torch::Device(torch::kCUDA, 1));\n+\n+  auto a = torch::ones(5, torch::requires_grad(true).device({torch::kCUDA, 0}));\n+  auto b = torch::ones(5, torch::requires_grad(true).device({torch::kCUDA, 1}));\n+  auto output = gather.apply({a, b});\n+\n+  REQUIRE(output.size() == 1);\n+  REQUIRE(output[0].size(0) == 10);\n+  REQUIRE(output[0].device() == torch::Device(torch::kCUDA, 1));\n+\n+  output[0].backward();\n+\n+  REQUIRE(a.grad().defined());\n+  REQUIRE(a.grad().device() == torch::Device(torch::kCUDA, 0));\n+  REQUIRE(a.grad().sum().toCInt() == 5);\n+\n+  REQUIRE(b.grad().defined());\n+  REQUIRE(b.grad().device() == torch::Device(torch::kCUDA, 1));\n+  REQUIRE(b.grad().sum().toCInt() == 5);", "path": "test/cpp/api/parallel.cpp", "position": 67, "original_position": 56, "commit_id": "bcaacf8be9df7fd32007e3528295943a9be46e14", "original_commit_id": "ee79272a6c9444f83f74b66005f86369e9120edf", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We should have sth like `.eq(1).all()` in ATen, and it's a stronger check than this. Also, ideally you'd pass in a random output and check that the grads here are just slices", "created_at": "2018-07-11T21:48:39Z", "updated_at": "2018-11-23T15:47:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/9234#discussion_r201850665", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9234", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/201850665"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9234#discussion_r201850665"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9234"}}, "body_html": "<p>We should have sth like <code>.eq(1).all()</code> in ATen, and it's a stronger check than this. Also, ideally you'd pass in a random output and check that the grads here are just slices</p>", "body_text": "We should have sth like .eq(1).all() in ATen, and it's a stronger check than this. Also, ideally you'd pass in a random output and check that the grads here are just slices"}