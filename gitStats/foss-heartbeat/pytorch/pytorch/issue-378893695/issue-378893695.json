{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13739", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13739/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13739/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13739/events", "html_url": "https://github.com/pytorch/pytorch/issues/13739", "id": 378893695, "node_id": "MDU6SXNzdWUzNzg4OTM2OTU=", "number": 13739, "title": "Creating sparse tensor inside child process deadlocks when using numpy from conda-forge ", "user": {"login": "ostrokach", "id": 5614375, "node_id": "MDQ6VXNlcjU2MTQzNzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/5614375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ostrokach", "html_url": "https://github.com/ostrokach", "followers_url": "https://api.github.com/users/ostrokach/followers", "following_url": "https://api.github.com/users/ostrokach/following{/other_user}", "gists_url": "https://api.github.com/users/ostrokach/gists{/gist_id}", "starred_url": "https://api.github.com/users/ostrokach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ostrokach/subscriptions", "organizations_url": "https://api.github.com/users/ostrokach/orgs", "repos_url": "https://api.github.com/users/ostrokach/repos", "events_url": "https://api.github.com/users/ostrokach/events{/privacy}", "received_events_url": "https://api.github.com/users/ostrokach/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-08T20:00:27Z", "updated_at": "2018-11-12T20:40:07Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<p>When using PyTorch in combination with numpy from the conda-forge channel, creating a sparse tensor in a child process after an <code>os.fork</code> leads to a deadlock.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<p>Create conda environment:</p>\n<div class=\"highlight highlight-source-shell\"><pre>conda create -n pytorch-deadlock -c conda-forge \\\n    conda-forge::numpy \\\n    pytorch::pytorch-nightly-cpu=1.0.0.dev20181108=py3.6_cpu_0\n<span class=\"pl-c1\">source</span> activate pytorch-deadlock</pre></div>\n<p>Create a <code>demo.py</code> file to demonstrate the problem:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">import</span> torch\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">check</span>():\n    indices <span class=\"pl-k\">=</span> torch.LongTensor([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>]])\n    values <span class=\"pl-k\">=</span> torch.FloatTensor([<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>])\n    tensor <span class=\"pl-k\">=</span> torch.sparse_coo_tensor(indices, values, torch.Size([<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">4</span>]))\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    check()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note: this line is required to reproduce behavior!</span>\n    pid <span class=\"pl-k\">=</span> os.fork()\n    <span class=\"pl-k\">if</span> pid:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">\"</span><span class=\"pl-s\">Starting check pid: </span><span class=\"pl-c1\">{</span>pid<span class=\"pl-c1\">}</span><span class=\"pl-pds\">\"</span>)\n        check()\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">\"</span><span class=\"pl-s\">Done check pid: </span><span class=\"pl-c1\">{</span>pid<span class=\"pl-c1\">}</span><span class=\"pl-pds\">\"</span>)\n        time.sleep(<span class=\"pl-c1\">10</span>)\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">\"</span><span class=\"pl-s\">Starting check pid: </span><span class=\"pl-c1\">{</span>pid<span class=\"pl-c1\">}</span><span class=\"pl-pds\">\"</span>)\n        check()\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">\"</span><span class=\"pl-s\">Done check pid: </span><span class=\"pl-c1\">{</span>pid<span class=\"pl-c1\">}</span><span class=\"pl-pds\">\"</span>)\n        time.sleep(<span class=\"pl-c1\">10</span>)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>\n<p>Run <code>demo.py</code>:</p>\n<pre><code>$ python demo.py\nStarting check pid: 0\nStarting check pid: 85604\nDone check pid: 85604\n</code></pre>\n<p>The forked process never gets past the <code>check()</code> step.</p>\n<h2>Expected behavior</h2>\n<p>The expected output is shown below. This is the output that is produced when using numpy from the defaults channel.</p>\n<pre><code>$ python demo.py\nStarting check pid: 84364\nStarting check pid: 0\nDone check pid: 84364\nDone check pid: 0\n</code></pre>\n<h2>Environment</h2>\n<pre><code>PyTorch version: 1.0.0.dev20181108\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: CentOS Linux 7 (Core)\nGCC version: Could not collect\nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] pytorch-nightly-cpu       1.0.0.dev20181108     py3.6_cpu_0    pytorch\n</code></pre>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\n\nWhen using PyTorch in combination with numpy from the conda-forge channel, creating a sparse tensor in a child process after an os.fork leads to a deadlock.\nTo Reproduce\nSteps to reproduce the behavior:\nCreate conda environment:\nconda create -n pytorch-deadlock -c conda-forge \\\n    conda-forge::numpy \\\n    pytorch::pytorch-nightly-cpu=1.0.0.dev20181108=py3.6_cpu_0\nsource activate pytorch-deadlock\nCreate a demo.py file to demonstrate the problem:\nimport os\nimport time\n\nimport torch\n\n\ndef check():\n    indices = torch.LongTensor([[0, 1, 1], [2, 0, 2]])\n    values = torch.FloatTensor([3, 4, 5])\n    tensor = torch.sparse_coo_tensor(indices, values, torch.Size([2,4]))\n\n\ndef main():\n    check()  # Note: this line is required to reproduce behavior!\n    pid = os.fork()\n    if pid:\n        print(f\"Starting check pid: {pid}\")\n        check()\n        print(f\"Done check pid: {pid}\")\n        time.sleep(10)\n    else:\n        print(f\"Starting check pid: {pid}\")\n        check()\n        print(f\"Done check pid: {pid}\")\n        time.sleep(10)\n\n\nif __name__ == '__main__':\n    main()\nRun demo.py:\n$ python demo.py\nStarting check pid: 0\nStarting check pid: 85604\nDone check pid: 85604\n\nThe forked process never gets past the check() step.\nExpected behavior\nThe expected output is shown below. This is the output that is produced when using numpy from the defaults channel.\n$ python demo.py\nStarting check pid: 84364\nStarting check pid: 0\nDone check pid: 84364\nDone check pid: 0\n\nEnvironment\nPyTorch version: 1.0.0.dev20181108\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: CentOS Linux 7 (Core)\nGCC version: Could not collect\nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] pytorch-nightly-cpu       1.0.0.dev20181108     py3.6_cpu_0    pytorch\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nWhen using PyTorch in combination with numpy from the conda-forge channel, creating a sparse tensor in a child process after an `os.fork` leads to a deadlock.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nCreate conda environment:\r\n\r\n```bash\r\nconda create -n pytorch-deadlock -c conda-forge \\\r\n    conda-forge::numpy \\\r\n    pytorch::pytorch-nightly-cpu=1.0.0.dev20181108=py3.6_cpu_0\r\nsource activate pytorch-deadlock\r\n```\r\n\r\nCreate a `demo.py` file to demonstrate the problem:\r\n\r\n```python\r\nimport os\r\nimport time\r\n\r\nimport torch\r\n\r\n\r\ndef check():\r\n    indices = torch.LongTensor([[0, 1, 1], [2, 0, 2]])\r\n    values = torch.FloatTensor([3, 4, 5])\r\n    tensor = torch.sparse_coo_tensor(indices, values, torch.Size([2,4]))\r\n\r\n\r\ndef main():\r\n    check()  # Note: this line is required to reproduce behavior!\r\n    pid = os.fork()\r\n    if pid:\r\n        print(f\"Starting check pid: {pid}\")\r\n        check()\r\n        print(f\"Done check pid: {pid}\")\r\n        time.sleep(10)\r\n    else:\r\n        print(f\"Starting check pid: {pid}\")\r\n        check()\r\n        print(f\"Done check pid: {pid}\")\r\n        time.sleep(10)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nRun `demo.py`:\r\n\r\n```\r\n$ python demo.py\r\nStarting check pid: 0\r\nStarting check pid: 85604\r\nDone check pid: 85604\r\n```\r\n\r\nThe forked process never gets past the `check()` step. \r\n\r\n## Expected behavior\r\n\r\nThe expected output is shown below. This is the output that is produced when using numpy from the defaults channel.\r\n\r\n```\r\n$ python demo.py\r\nStarting check pid: 84364\r\nStarting check pid: 0\r\nDone check pid: 84364\r\nDone check pid: 0\r\n```\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.0.0.dev20181108\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: CentOS Linux 7 (Core)\r\nGCC version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] pytorch-nightly-cpu       1.0.0.dev20181108     py3.6_cpu_0    pytorch\r\n```\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}