{"url": "https://api.github.com/repos/pytorch/pytorch/issues/729", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/729/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/729/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/729/events", "html_url": "https://github.com/pytorch/pytorch/issues/729", "id": 207110871, "node_id": "MDU6SXNzdWUyMDcxMTA4NzE=", "number": 729, "title": "Cast to host memory does not work", "user": {"login": "Atcold", "id": 2119355, "node_id": "MDQ6VXNlcjIxMTkzNTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2119355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Atcold", "html_url": "https://github.com/Atcold", "followers_url": "https://api.github.com/users/Atcold/followers", "following_url": "https://api.github.com/users/Atcold/following{/other_user}", "gists_url": "https://api.github.com/users/Atcold/gists{/gist_id}", "starred_url": "https://api.github.com/users/Atcold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Atcold/subscriptions", "organizations_url": "https://api.github.com/users/Atcold/orgs", "repos_url": "https://api.github.com/users/Atcold/repos", "events_url": "https://api.github.com/users/Atcold/events{/privacy}", "received_events_url": "https://api.github.com/users/Atcold/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-13T02:56:19Z", "updated_at": "2017-02-13T03:23:42Z", "closed_at": "2017-02-13T03:16:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Cast to host memory does not work.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> myTensor <span class=\"pl-k\">=</span> torch.cuda.FloatTensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>])\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(myTensor)\n <span class=\"pl-c1\">1</span>\n <span class=\"pl-c1\">2</span>\n <span class=\"pl-c1\">3</span>\n <span class=\"pl-c1\">4</span>\n[torch.cuda.FloatTensor of size <span class=\"pl-c1\">4</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)]\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(myTensor.float())\n <span class=\"pl-c1\">1</span>\n <span class=\"pl-c1\">2</span>\n <span class=\"pl-c1\">3</span>\n <span class=\"pl-c1\">4</span>\n[torch.cuda.FloatTensor of size <span class=\"pl-c1\">4</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)]</pre></div>\n<p>Cast to device memory works fine.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> myTensor <span class=\"pl-k\">=</span> torch.FloatTensor([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>])\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(myTensor)\n <span class=\"pl-c1\">1</span>\n <span class=\"pl-c1\">2</span>\n <span class=\"pl-c1\">3</span>\n <span class=\"pl-c1\">4</span>\n[torch.FloatTensor of size <span class=\"pl-c1\">4</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(myTensor.cuda())\n <span class=\"pl-c1\">1</span>\n <span class=\"pl-c1\">2</span>\n <span class=\"pl-c1\">3</span>\n <span class=\"pl-c1\">4</span>\n[torch.cuda.FloatTensor of size <span class=\"pl-c1\">4</span> (<span class=\"pl-c1\">GPU</span> <span class=\"pl-c1\">0</span>)]</pre></div>", "body_text": "Cast to host memory does not work.\n>>> myTensor = torch.cuda.FloatTensor([1, 2, 3, 4])\n>>> print(myTensor)\n 1\n 2\n 3\n 4\n[torch.cuda.FloatTensor of size 4 (GPU 0)]\n>>> print(myTensor.float())\n 1\n 2\n 3\n 4\n[torch.cuda.FloatTensor of size 4 (GPU 0)]\nCast to device memory works fine.\n>>> myTensor = torch.FloatTensor([1, 2, 3, 4])\n>>> print(myTensor)\n 1\n 2\n 3\n 4\n[torch.FloatTensor of size 4\n>>> print(myTensor.cuda())\n 1\n 2\n 3\n 4\n[torch.cuda.FloatTensor of size 4 (GPU 0)]", "body": "Cast to host memory does not work.\r\n```python\r\n>>> myTensor = torch.cuda.FloatTensor([1, 2, 3, 4])\r\n>>> print(myTensor)\r\n 1\r\n 2\r\n 3\r\n 4\r\n[torch.cuda.FloatTensor of size 4 (GPU 0)]\r\n>>> print(myTensor.float())\r\n 1\r\n 2\r\n 3\r\n 4\r\n[torch.cuda.FloatTensor of size 4 (GPU 0)]\r\n```\r\nCast to device memory works fine.\r\n```python\r\n>>> myTensor = torch.FloatTensor([1, 2, 3, 4])\r\n>>> print(myTensor)\r\n 1\r\n 2\r\n 3\r\n 4\r\n[torch.FloatTensor of size 4\r\n>>> print(myTensor.cuda())\r\n 1\r\n 2\r\n 3\r\n 4\r\n[torch.cuda.FloatTensor of size 4 (GPU 0)]\r\n```"}