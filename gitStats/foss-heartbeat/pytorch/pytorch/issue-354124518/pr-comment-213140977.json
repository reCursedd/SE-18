{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213140977", "pull_request_review_id": 149914711, "id": 213140977, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMzE0MDk3Nw==", "diff_hunk": "@@ -0,0 +1,54 @@\n+#include \"ATen/ATen.h\"\n+\n+namespace at { namespace native {\n+\n+Tensor constant_pad_nd(const Tensor& input, IntList pad, Scalar value) {\n+    auto input_sizes = input.sizes();\n+    auto l_inp = input.dim();\n+\n+    auto l_pad = pad.size() / 2;\n+    auto l_diff = l_inp - l_pad;\n+    AT_CHECK(l_inp >= l_pad, \"Padding length too large\");\n+\n+    std::vector<int64_t> new_shape;\n+\n+    for (int i = 0; i < l_diff; i ++) {\n+        new_shape.push_back(input_sizes[i]);\n+    }\n+\n+    for (int i = 0; i < l_pad; i++) {\n+        auto pad_idx = pad.size() - ((i + 1) * 2);\n+        auto new_dim = input_sizes[l_diff + i] + pad[pad_idx] + pad[pad_idx + 1];\n+        AT_CHECK(new_dim > 0, \"input is too small\");\n+        new_shape.push_back(new_dim);\n+    }\n+\n+    auto output = at::empty(new_shape, input.options());\n+    output.fill_(value);\n+\n+    auto c_input = input;\n+    for (int i = l_diff; i < l_inp; i++) {\n+        auto pad_idx = pad.size() - (i - l_diff + 1) * 2;\n+        if (pad[pad_idx] < 0) {\n+            c_input = c_input.narrow(i, -pad[pad_idx], c_input.sizes()[i] + pad[pad_idx]);\n+        }\n+        if (pad[pad_idx + 1] < 0) {\n+            c_input = c_input.narrow(i, 0, c_input.sizes()[i] + pad[pad_idx + 1]);\n+        }\n+    }\n+\n+    auto c_output = output;\n+    for (int i = l_diff; i < l_inp; i++) {\n+        auto pad_idx = pad.size() - (i - l_diff + 1) * 2;\n+        if (pad[pad_idx] > 0) {\n+            c_output = c_output.narrow(i, pad[pad_idx], c_output.sizes()[i] - pad[pad_idx]);\n+        }\n+        if (pad[pad_idx + 1] > 0) {\n+            c_output = c_output.narrow(i, 0, c_output.sizes()[i] - pad[pad_idx + 1]);\n+        }\n+    }\n+    c_output.copy_(c_input);", "path": "aten/src/ATen/native/ConstantPadNd.cpp", "position": 70, "original_position": 50, "commit_id": "f2109c4136c379834d616724b6373791fabc8cee", "original_commit_id": "701095b70cc5bc018511e2b71681755999ca0a0b", "user": {"login": "wdhorton", "id": 13503072, "node_id": "MDQ6VXNlcjEzNTAzMDcy", "avatar_url": "https://avatars1.githubusercontent.com/u/13503072?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wdhorton", "html_url": "https://github.com/wdhorton", "followers_url": "https://api.github.com/users/wdhorton/followers", "following_url": "https://api.github.com/users/wdhorton/following{/other_user}", "gists_url": "https://api.github.com/users/wdhorton/gists{/gist_id}", "starred_url": "https://api.github.com/users/wdhorton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wdhorton/subscriptions", "organizations_url": "https://api.github.com/users/wdhorton/orgs", "repos_url": "https://api.github.com/users/wdhorton/repos", "events_url": "https://api.github.com/users/wdhorton/events{/privacy}", "received_events_url": "https://api.github.com/users/wdhorton/received_events", "type": "User", "site_admin": false}, "body": "Calling `copy_` is what was done in the python version of ConstantPadNd: https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/padding.py. If you look at what happens to `c_output`, the only changes made are to its dimensions (with `narrow`). So I think it's ok that all the values are replaced.", "created_at": "2018-08-27T22:59:35Z", "updated_at": "2018-11-23T15:50:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/10885#discussion_r213140977", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10885", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213140977"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10885#discussion_r213140977"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10885"}}, "body_html": "<p>Calling <code>copy_</code> is what was done in the python version of ConstantPadNd: <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/padding.py\">https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/padding.py</a>. If you look at what happens to <code>c_output</code>, the only changes made are to its dimensions (with <code>narrow</code>). So I think it's ok that all the values are replaced.</p>", "body_text": "Calling copy_ is what was done in the python version of ConstantPadNd: https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/padding.py. If you look at what happens to c_output, the only changes made are to its dimensions (with narrow). So I think it's ok that all the values are replaced.", "in_reply_to_id": 212879603}