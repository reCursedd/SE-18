{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/390036707", "html_url": "https://github.com/pytorch/pytorch/pull/7606#issuecomment-390036707", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7606", "id": 390036707, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MDAzNjcwNw==", "user": {"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-17T22:43:49Z", "updated_at": "2018-05-17T23:02:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>New perf numbers with warmup:</p>\n<pre><code>def warmup(device):\n    import torch\n    torch.manual_seed(1)\n    for i in range(1000):\n        torch.randperm(100000, device=device)\n        if 'cuda' in device.type:\n            torch.cuda.synchronize()\n\n\n&gt;&gt;&gt; timeit.timeit('torch.randperm(10, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\n1.5460697002708912e-06\n&gt;&gt;&gt; timeit.timeit('torch.randperm(10, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\n1.5897609503008425e-05\n\n&gt;&gt;&gt; timeit.timeit('torch.randperm(1000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\n1.734363290015608e-05\n&gt;&gt;&gt; timeit.timeit('torch.randperm(1000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\n3.378083289135248e-05\n\n&gt;&gt;&gt; timeit.timeit('torch.randperm(30000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\n0.00047304581699427216\n&gt;&gt;&gt; timeit.timeit('torch.randperm(30000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\n0.00048103344393894074\n\n&gt;&gt;&gt; timeit.timeit('torch.randperm(100000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\n0.0016381454940419644\n&gt;&gt;&gt; timeit.timeit('torch.randperm(100000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\n0.0009089858660008758\n\n&gt;&gt;&gt; timeit.timeit('torch.randperm(10000000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10) / 10\n0.25579753069905564\n&gt;&gt;&gt; timeit.timeit('torch.randperm(10000000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10) / 10\n0.00019850831013172864\n</code></pre>", "body_text": "New perf numbers with warmup:\ndef warmup(device):\n    import torch\n    torch.manual_seed(1)\n    for i in range(1000):\n        torch.randperm(100000, device=device)\n        if 'cuda' in device.type:\n            torch.cuda.synchronize()\n\n\n>>> timeit.timeit('torch.randperm(10, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\n1.5460697002708912e-06\n>>> timeit.timeit('torch.randperm(10, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\n1.5897609503008425e-05\n\n>>> timeit.timeit('torch.randperm(1000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\n1.734363290015608e-05\n>>> timeit.timeit('torch.randperm(1000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\n3.378083289135248e-05\n\n>>> timeit.timeit('torch.randperm(30000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\n0.00047304581699427216\n>>> timeit.timeit('torch.randperm(30000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\n0.00048103344393894074\n\n>>> timeit.timeit('torch.randperm(100000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\n0.0016381454940419644\n>>> timeit.timeit('torch.randperm(100000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\n0.0009089858660008758\n\n>>> timeit.timeit('torch.randperm(10000000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10) / 10\n0.25579753069905564\n>>> timeit.timeit('torch.randperm(10000000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10) / 10\n0.00019850831013172864", "body": "New perf numbers with warmup:\r\n\r\n```\r\ndef warmup(device):\r\n    import torch\r\n    torch.manual_seed(1)\r\n    for i in range(1000):\r\n        torch.randperm(100000, device=device)\r\n        if 'cuda' in device.type:\r\n            torch.cuda.synchronize()\r\n\r\n\r\n>>> timeit.timeit('torch.randperm(10, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\r\n1.5460697002708912e-06\r\n>>> timeit.timeit('torch.randperm(10, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\r\n1.5897609503008425e-05\r\n\r\n>>> timeit.timeit('torch.randperm(1000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10000) / 10000\r\n1.734363290015608e-05\r\n>>> timeit.timeit('torch.randperm(1000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10000) / 10000\r\n3.378083289135248e-05\r\n\r\n>>> timeit.timeit('torch.randperm(30000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\r\n0.00047304581699427216\r\n>>> timeit.timeit('torch.randperm(30000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\r\n0.00048103344393894074\r\n\r\n>>> timeit.timeit('torch.randperm(100000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=1000) / 1000\r\n0.0016381454940419644\r\n>>> timeit.timeit('torch.randperm(100000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=1000) / 1000\r\n0.0009089858660008758\r\n\r\n>>> timeit.timeit('torch.randperm(10000000, device=cpu)', setup='import torch; cpu = torch.device(\"cpu\"); from __main__ import warmup; warmup(cpu)', number=10) / 10\r\n0.25579753069905564\r\n>>> timeit.timeit('torch.randperm(10000000, device=cuda)', setup='import torch; cuda = torch.device(\"cuda:0\"); from __main__ import warmup; warmup(cuda)', number=10) / 10\r\n0.00019850831013172864\r\n```"}