{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/191886198", "pull_request_review_id": 124548325, "id": 191886198, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MTg4NjE5OA==", "diff_hunk": "@@ -26,4 +35,37 @@ Tensor& eye_out_cuda(Tensor& result, int64_t n, int64_t m) {\n   return result;\n }\n \n+Tensor& randperm_out_cuda(Tensor& result, int64_t n, Generator* generator) {\n+  if (n < 0) {\n+    std::ostringstream oss;\n+    oss << \"n must be non-negative, got \" << n;\n+    throw std::runtime_error(oss.str());\n+  }\n+\n+  result.resize_({n});\n+\n+  if (n < 30000) {  // For small inputs, we offload it to CPU instead.\n+    auto result_cpu = result.type().toBackend(kCPU).tensor({n});\n+    randperm_out(result_cpu, n, generator);\n+    result = result.type().copy(result_cpu);", "path": "aten/src/ATen/native/cuda/TensorFactories.cu", "position": null, "original_position": 30, "commit_id": "5070abda6dfc0435f77d611710d0a5ee27a26bd3", "original_commit_id": "879219286fdbef1026b3d37319b416f8b7bb12d0", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We surely want to support randperm for half on CUDA, but we don't want to do that for CPU, so we might need to generate it in float on CPU, and then do a copy to a half CUDA tensor.", "created_at": "2018-05-30T19:02:49Z", "updated_at": "2018-11-23T15:44:44Z", "html_url": "https://github.com/pytorch/pytorch/pull/7606#discussion_r191886198", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7606", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/191886198"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7606#discussion_r191886198"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7606"}}, "body_html": "<p>We surely want to support randperm for half on CUDA, but we don't want to do that for CPU, so we might need to generate it in float on CPU, and then do a copy to a half CUDA tensor.</p>", "body_text": "We surely want to support randperm for half on CUDA, but we don't want to do that for CPU, so we might need to generate it in float on CPU, and then do a copy to a half CUDA tensor.", "in_reply_to_id": 189950992}