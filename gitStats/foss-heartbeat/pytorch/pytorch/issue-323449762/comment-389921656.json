{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/389921656", "html_url": "https://github.com/pytorch/pytorch/pull/7606#issuecomment-389921656", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7606", "id": 389921656, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTkyMTY1Ng==", "user": {"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-17T16:09:14Z", "updated_at": "2018-05-17T16:09:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The benchmarking script is as follows:</p>\n<pre><code>timeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10000)\ntimeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10000)\n\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\n\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\n\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10)\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10)\n</code></pre>\n<p>I measured how long each step takes and it seems that <code>thrust::sort_by_key(policy, keys_data, keys_data + n, result_data);</code> takes ~80% of the time. So I believe offloading to CPU would help.</p>", "body_text": "The benchmarking script is as follows:\ntimeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10000)\ntimeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10000)\n\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\n\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\n\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10)\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10)\n\nI measured how long each step takes and it seems that thrust::sort_by_key(policy, keys_data, keys_data + n, result_data); takes ~80% of the time. So I believe offloading to CPU would help.", "body": "The benchmarking script is as follows:\r\n\r\n```\r\ntimeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10000)\r\ntimeit.timeit('torch.randperm(10)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10000)\r\n\r\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\r\ntimeit.timeit('torch.randperm(1000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\r\n\r\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=1000)\r\ntimeit.timeit('torch.randperm(100000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=1000)\r\n\r\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.FloatTensor\"); torch.manual_seed(1); torch.randperm(10)', number=10)\r\ntimeit.timeit('torch.randperm(10000000)', setup='import torch; torch.set_default_tensor_type(\"torch.cuda.FloatTensor\"); torch.manual_seed(1);torch.randperm(10)', number=10)\r\n```\r\n\r\nI measured how long each step takes and it seems that `thrust::sort_by_key(policy, keys_data, keys_data + n, result_data);` takes ~80% of the time. So I believe offloading to CPU would help."}