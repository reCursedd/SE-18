{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193557412", "pull_request_review_id": 126553164, "id": 193557412, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MzU1NzQxMg==", "diff_hunk": "@@ -26,4 +36,57 @@ Tensor& eye_out_cuda(Tensor& result, int64_t n, int64_t m) {\n   return result;\n }\n \n+Tensor& randperm_out_cuda(Tensor& result, int64_t n, Generator* generator) {\n+  if (n < 0) {\n+    std::ostringstream oss;\n+    oss << \"n must be non-negative, got \" << n;\n+    throw std::runtime_error(oss.str());\n+  }\n+\n+  if (n > 0) {\n+    AT_DISPATCH_ALL_TYPES_AND_HALF(\n+      result.type(), \"randperm_out_cuda\", [&] {\n+        AT_CHECK(Scalar(n).to<scalar_t>(),\n+          \"n is too large for result tensor type: '\", result.type().toString(), \"'\");\n+      }\n+    );\n+  }\n+\n+  result.resize_({n});\n+\n+  if (result.type().scalarType() == at::ScalarType::Half) {\n+    auto result_float = CUDA(kFloat).tensor({n});\n+    result.copy_(randperm_out_cuda(result_float, n, generator));\n+  } else {\n+    if (n < 30000) {  // For small inputs, we offload it to CPU instead.\n+      auto result_cpu = result.type().toBackend(kCPU).tensor({n});\n+      randperm_out(result_cpu, n, generator);\n+      result.copy_(result_cpu);\n+    } else {\n+      // Generate random values for the keys array\n+      AT_DISPATCH_ALL_TYPES(\n+        result.type(), \"randperm_out_cuda\", [&] {\n+          using cuda_scalar_t = cuda::into_type<scalar_t>;\n+\n+          auto keys = result.type().tensor(result.sizes()).random_(generator);", "path": "aten/src/ATen/native/cuda/TensorFactories.cu", "position": 51, "original_position": 51, "commit_id": "5070abda6dfc0435f77d611710d0a5ee27a26bd3", "original_commit_id": "5070abda6dfc0435f77d611710d0a5ee27a26bd3", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Did you try `keys.sort()`? The sorting in PyTorch (written by Jeff) is very fast for small tensors. IIRC, it uses thrust internally for large tensors.\r\n\r\nMuch better small tensor perf:\r\n```\r\n%timeit x = torch.cuda.LongTensor(10); x.random_(); x.sort(); torch.cuda.synchronize()\r\n10000 loops, best of 3: 48.8 \u00b5s per loop\r\n```\r\n\r\nSame large tensor perf:\r\n```\r\n%timeit x = torch.cuda.LongTensor(10000000); x.random_(); x.sort(); torch.cuda.synchronize()\r\n10 loops, best of 3: 58.4 ms per loop\r\n```", "created_at": "2018-06-06T20:59:34Z", "updated_at": "2018-11-23T15:45:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/7606#discussion_r193557412", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7606", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193557412"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7606#discussion_r193557412"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7606"}}, "body_html": "<p>Did you try <code>keys.sort()</code>? The sorting in PyTorch (written by Jeff) is very fast for small tensors. IIRC, it uses thrust internally for large tensors.</p>\n<p>Much better small tensor perf:</p>\n<pre><code>%timeit x = torch.cuda.LongTensor(10); x.random_(); x.sort(); torch.cuda.synchronize()\n10000 loops, best of 3: 48.8 \u00b5s per loop\n</code></pre>\n<p>Same large tensor perf:</p>\n<pre><code>%timeit x = torch.cuda.LongTensor(10000000); x.random_(); x.sort(); torch.cuda.synchronize()\n10 loops, best of 3: 58.4 ms per loop\n</code></pre>", "body_text": "Did you try keys.sort()? The sorting in PyTorch (written by Jeff) is very fast for small tensors. IIRC, it uses thrust internally for large tensors.\nMuch better small tensor perf:\n%timeit x = torch.cuda.LongTensor(10); x.random_(); x.sort(); torch.cuda.synchronize()\n10000 loops, best of 3: 48.8 \u00b5s per loop\n\nSame large tensor perf:\n%timeit x = torch.cuda.LongTensor(10000000); x.random_(); x.sort(); torch.cuda.synchronize()\n10 loops, best of 3: 58.4 ms per loop"}