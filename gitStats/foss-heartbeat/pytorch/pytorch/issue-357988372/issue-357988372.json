{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11373", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11373/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11373/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11373/events", "html_url": "https://github.com/pytorch/pytorch/pull/11373", "id": 357988372, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEzODY3MzEw", "number": 11373, "title": "Cuda TensorAccessor", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2018-09-07T09:23:02Z", "updated_at": "2018-11-23T15:50:58Z", "closed_at": "2018-09-11T20:10:50Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11373", "html_url": "https://github.com/pytorch/pytorch/pull/11373", "diff_url": "https://github.com/pytorch/pytorch/pull/11373.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11373.patch"}, "body_html": "<p>Provide a TensorAccessor-Like interface for CUDA as discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"331496197\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/8366\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/8366/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/8366\">#8366</a>.</p>\n<p>Compared to TensorAccessor</p>\n<ul>\n<li>the CUDATensorAccessor copies the sizes and strides while on the host (I didn't implement a host indexing function, though) to enable transfer to the device, on the device, <code>[]</code> works like for TensorAccessors,</li>\n<li>instantiation is from TensorAccessors in order to allow using <code>.accessor&lt;..&gt;</code>. The drawback is that it you cannot use <code>auto</code> for the variable declaration, but the alternative would be a cuda-specific <code>.accessor</code>-like function,</li>\n<li>there is a PtrTraits argument to enable <code>__restrict__</code>,</li>\n</ul>\n<p>Example for the intended use:</p>\n<pre><code>#include &lt;ATen/cuda/CUDATensorAccessor.cuh&gt;\n...\ntemplate &lt;typename scalar_t&gt;\n__global__ void\napply_homography_2d_kernel(cuda::CUDATensorAccessor&lt;scalar_t, 4&gt; dest_a,\n\t\t\t   cuda::CUDATensorAccessor&lt;scalar_t, 4&gt; src_a,\n\t\t\t   cuda::CUDATensorAccessor&lt;float, 2&gt; transform) {\n...\n}\n\ntemplate &lt;typename scalar_t&gt;\nTensor apply_homography_2d_template(Tensor&amp; res, const Tensor&amp; image, const Tensor&amp; transform) {\n  ...\n  cuda::CUDATensorAccessor&lt;scalar_t, 4&gt; image_a(image.accessor&lt;scalar_t, 4&gt;());\n  cuda::CUDATensorAccessor&lt;scalar_t, 4&gt; res_a(res.accessor&lt;scalar_t, 4&gt;());\n  cuda::CUDATensorAccessor&lt;float, 2&gt; transform_a(transform.accessor&lt;float, 2&gt;());\n  auto stream = at::cuda::getCurrentCUDAStream();\n\n  apply_homography_2d_kernel&lt;scalar_t&gt;\n    &lt;&lt;&lt;grid, block, 0, stream&gt;&gt;&gt;(res_a, image_a, transform_a);\n  return res;\n}\n\n...\n</code></pre>\n<p>I could use a hint where to put a test for this (e.g. doing a plain vanilla matrix multiplication with a custom kernel) and comparing with the aten mm.</p>", "body_text": "Provide a TensorAccessor-Like interface for CUDA as discussed in #8366.\nCompared to TensorAccessor\n\nthe CUDATensorAccessor copies the sizes and strides while on the host (I didn't implement a host indexing function, though) to enable transfer to the device, on the device, [] works like for TensorAccessors,\ninstantiation is from TensorAccessors in order to allow using .accessor<..>. The drawback is that it you cannot use auto for the variable declaration, but the alternative would be a cuda-specific .accessor-like function,\nthere is a PtrTraits argument to enable __restrict__,\n\nExample for the intended use:\n#include <ATen/cuda/CUDATensorAccessor.cuh>\n...\ntemplate <typename scalar_t>\n__global__ void\napply_homography_2d_kernel(cuda::CUDATensorAccessor<scalar_t, 4> dest_a,\n\t\t\t   cuda::CUDATensorAccessor<scalar_t, 4> src_a,\n\t\t\t   cuda::CUDATensorAccessor<float, 2> transform) {\n...\n}\n\ntemplate <typename scalar_t>\nTensor apply_homography_2d_template(Tensor& res, const Tensor& image, const Tensor& transform) {\n  ...\n  cuda::CUDATensorAccessor<scalar_t, 4> image_a(image.accessor<scalar_t, 4>());\n  cuda::CUDATensorAccessor<scalar_t, 4> res_a(res.accessor<scalar_t, 4>());\n  cuda::CUDATensorAccessor<float, 2> transform_a(transform.accessor<float, 2>());\n  auto stream = at::cuda::getCurrentCUDAStream();\n\n  apply_homography_2d_kernel<scalar_t>\n    <<<grid, block, 0, stream>>>(res_a, image_a, transform_a);\n  return res;\n}\n\n...\n\nI could use a hint where to put a test for this (e.g. doing a plain vanilla matrix multiplication with a custom kernel) and comparing with the aten mm.", "body": "Provide a TensorAccessor-Like interface for CUDA as discussed in #8366.\r\n\r\nCompared to TensorAccessor\r\n- the CUDATensorAccessor copies the sizes and strides while on the host (I didn't implement a host indexing function, though) to enable transfer to the device, on the device, `[]` works like for TensorAccessors,\r\n- instantiation is from TensorAccessors in order to allow using `.accessor<..>`. The drawback is that it you cannot use `auto` for the variable declaration, but the alternative would be a cuda-specific `.accessor`-like function,\r\n- there is a PtrTraits argument to enable `__restrict__`,\r\n\r\nExample for the intended use:\r\n```\r\n#include <ATen/cuda/CUDATensorAccessor.cuh>\r\n...\r\ntemplate <typename scalar_t>\r\n__global__ void\r\napply_homography_2d_kernel(cuda::CUDATensorAccessor<scalar_t, 4> dest_a,\r\n\t\t\t   cuda::CUDATensorAccessor<scalar_t, 4> src_a,\r\n\t\t\t   cuda::CUDATensorAccessor<float, 2> transform) {\r\n...\r\n}\r\n\r\ntemplate <typename scalar_t>\r\nTensor apply_homography_2d_template(Tensor& res, const Tensor& image, const Tensor& transform) {\r\n  ...\r\n  cuda::CUDATensorAccessor<scalar_t, 4> image_a(image.accessor<scalar_t, 4>());\r\n  cuda::CUDATensorAccessor<scalar_t, 4> res_a(res.accessor<scalar_t, 4>());\r\n  cuda::CUDATensorAccessor<float, 2> transform_a(transform.accessor<float, 2>());\r\n  auto stream = at::cuda::getCurrentCUDAStream();\r\n\r\n  apply_homography_2d_kernel<scalar_t>\r\n    <<<grid, block, 0, stream>>>(res_a, image_a, transform_a);\r\n  return res;\r\n}\r\n\r\n...\r\n```\r\n\r\nI could use a hint where to put a test for this (e.g. doing a plain vanilla matrix multiplication with a custom kernel) and comparing with the aten mm.\r\n\r\n"}