{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/403739352", "html_url": "https://github.com/pytorch/pytorch/issues/9298#issuecomment-403739352", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9298", "id": 403739352, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzczOTM1Mg==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-10T08:16:26Z", "updated_at": "2018-07-10T08:16:26Z", "author_association": "MEMBER", "body_html": "<p>In PyTorch we don't currently support tensors having different sizes in the same dimension.<br>\nYou might be able to simulate that using <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/rnn.py#L12\"><code>PackedSequence</code></a>, or with the experimental <a href=\"https://github.com/pytorch/pytorch/pull/9198\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9198/hovercard\"><code>BatchTensor</code></a>, but I'm not sure that we will be adding explicit support for that in PyTorch core soon.</p>", "body_text": "In PyTorch we don't currently support tensors having different sizes in the same dimension.\nYou might be able to simulate that using PackedSequence, or with the experimental BatchTensor, but I'm not sure that we will be adding explicit support for that in PyTorch core soon.", "body": "In PyTorch we don't currently support tensors having different sizes in the same dimension.\r\nYou might be able to simulate that using [`PackedSequence`](https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/rnn.py#L12), or with the experimental [`BatchTensor`](https://github.com/pytorch/pytorch/pull/9198), but I'm not sure that we will be adding explicit support for that in PyTorch core soon."}