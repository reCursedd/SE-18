{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5249", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5249/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5249/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5249/events", "html_url": "https://github.com/pytorch/pytorch/issues/5249", "id": 297281626, "node_id": "MDU6SXNzdWUyOTcyODE2MjY=", "number": 5249, "title": "cuda runtime error (2) : out of memory at Siamese Network", "user": {"login": "MaximArtemev", "id": 17458320, "node_id": "MDQ6VXNlcjE3NDU4MzIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17458320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaximArtemev", "html_url": "https://github.com/MaximArtemev", "followers_url": "https://api.github.com/users/MaximArtemev/followers", "following_url": "https://api.github.com/users/MaximArtemev/following{/other_user}", "gists_url": "https://api.github.com/users/MaximArtemev/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaximArtemev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaximArtemev/subscriptions", "organizations_url": "https://api.github.com/users/MaximArtemev/orgs", "repos_url": "https://api.github.com/users/MaximArtemev/repos", "events_url": "https://api.github.com/users/MaximArtemev/events{/privacy}", "received_events_url": "https://api.github.com/users/MaximArtemev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-02-14T23:24:09Z", "updated_at": "2018-02-16T12:29:53Z", "closed_at": "2018-02-16T12:29:53Z", "author_association": "NONE", "body_html": "<p>Hi<br>\nI'm trying to implement Siamese Network in pytorch with gpu support but constantly getting RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102</p>\n<p>My model is defined as follows</p>\n<pre><code>class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        \n        self.embedding = nn.Embedding(ru.vectors.size(0), ru.vectors.size(1), padding_idx=2)\n        self.embedding.weight = nn.Parameter(ru.vectors)\n        self.embedding.weight.requires_grad = False\n        \n        self.lstm = nn.LSTM(300, 300, 2, batch_first=True, bidirectional=True, dropout=.05)\n        \n        self.dropout = nn.Dropout(p=.2)\n            #nn.LSTM(300, 300, 30, batch_first=True, bidirectional=True, dropout=.05),\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(300*2*300, 1500),\n            nn.Sigmoid(),#inplace=True),\n\n            nn.Linear(1500, 100),\n            nn.Sigmoid()\n        )\n\n    def forward_once(self, x):\n        output = self.embedding(x)\n        output, _ = self.lstm(output)\n        output = self.dropout(output)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2\n</code></pre>\n<p>and I'm using a custom loss:</p>\n<pre><code>class ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                       (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return loss_contrastive\n</code></pre>\n<p>Then after</p>\n<pre><code>net = SiameseNetwork().cuda(1)\ncriterion = ContrastiveLoss()\nparameters = filter(lambda p: p.requires_grad, net.parameters())\noptimizer = optim.Adam(parameters, lr=0.1)\nloss_history = [] \niteration_number= 0\n\nnet.train()\n\nfor epoch in range(100):\n    epoch_end = time()\n    for i, data in enumerate(train_dataloader, 0):\n        text1, text2 , label = data\n        text1, text2 , label = Variable(text1).cuda(1), Variable(text2).cuda(1) , Variable(label).cuda(1)\n        output1,output2 = net(text1,text2)\n        optimizer.zero_grad()\n        loss_contrastive = criterion(output1,output2,label)\n        loss_contrastive.backward()\n\n        loss_history.append(loss_contrastive.data[0])\n        optimizer.step()\n\n</code></pre>\n<p>I'm getting</p>\n<pre><code>RuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-33-e2c1dc9f69ec&gt; in &lt;module&gt;()\n     12         optimizer.zero_grad()\n     13         loss_contrastive = criterion(output1,output2,label)\n---&gt; 14         loss_contrastive.backward()\n     15 \n     16         writer.add_scalar('data/step_loss', loss_contrastive.data[0])\n\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/variable.py in backward(self, gradient, retain_graph, create_graph, retain_variables)\n    165                 Variable.\n    166         \"\"\"\n--&gt; 167         torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n    168 \n    169     def register_hook(self, hook):\n\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(variables, grad_variables, retain_graph, create_graph, retain_variables)\n     97 \n     98     Variable._execution_engine.run_backward(\n---&gt; 99         variables, grad_variables, retain_graph)\n    100 \n    101 \n\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102\n</code></pre>\n<p>I'm using cuda 8.0 and cudann 5, installed pytorch with conda.</p>", "body_text": "Hi\nI'm trying to implement Siamese Network in pytorch with gpu support but constantly getting RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102\nMy model is defined as follows\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        \n        self.embedding = nn.Embedding(ru.vectors.size(0), ru.vectors.size(1), padding_idx=2)\n        self.embedding.weight = nn.Parameter(ru.vectors)\n        self.embedding.weight.requires_grad = False\n        \n        self.lstm = nn.LSTM(300, 300, 2, batch_first=True, bidirectional=True, dropout=.05)\n        \n        self.dropout = nn.Dropout(p=.2)\n            #nn.LSTM(300, 300, 30, batch_first=True, bidirectional=True, dropout=.05),\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(300*2*300, 1500),\n            nn.Sigmoid(),#inplace=True),\n\n            nn.Linear(1500, 100),\n            nn.Sigmoid()\n        )\n\n    def forward_once(self, x):\n        output = self.embedding(x)\n        output, _ = self.lstm(output)\n        output = self.dropout(output)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2\n\nand I'm using a custom loss:\nclass ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                       (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return loss_contrastive\n\nThen after\nnet = SiameseNetwork().cuda(1)\ncriterion = ContrastiveLoss()\nparameters = filter(lambda p: p.requires_grad, net.parameters())\noptimizer = optim.Adam(parameters, lr=0.1)\nloss_history = [] \niteration_number= 0\n\nnet.train()\n\nfor epoch in range(100):\n    epoch_end = time()\n    for i, data in enumerate(train_dataloader, 0):\n        text1, text2 , label = data\n        text1, text2 , label = Variable(text1).cuda(1), Variable(text2).cuda(1) , Variable(label).cuda(1)\n        output1,output2 = net(text1,text2)\n        optimizer.zero_grad()\n        loss_contrastive = criterion(output1,output2,label)\n        loss_contrastive.backward()\n\n        loss_history.append(loss_contrastive.data[0])\n        optimizer.step()\n\n\nI'm getting\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-33-e2c1dc9f69ec> in <module>()\n     12         optimizer.zero_grad()\n     13         loss_contrastive = criterion(output1,output2,label)\n---> 14         loss_contrastive.backward()\n     15 \n     16         writer.add_scalar('data/step_loss', loss_contrastive.data[0])\n\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/variable.py in backward(self, gradient, retain_graph, create_graph, retain_variables)\n    165                 Variable.\n    166         \"\"\"\n--> 167         torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n    168 \n    169     def register_hook(self, hook):\n\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(variables, grad_variables, retain_graph, create_graph, retain_variables)\n     97 \n     98     Variable._execution_engine.run_backward(\n---> 99         variables, grad_variables, retain_graph)\n    100 \n    101 \n\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102\n\nI'm using cuda 8.0 and cudann 5, installed pytorch with conda.", "body": "Hi\r\nI'm trying to implement Siamese Network in pytorch with gpu support but constantly getting RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102\r\n\r\nMy model is defined as follows\r\n\r\n```\r\nclass SiameseNetwork(nn.Module):\r\n    def __init__(self):\r\n        super(SiameseNetwork, self).__init__()\r\n        \r\n        self.embedding = nn.Embedding(ru.vectors.size(0), ru.vectors.size(1), padding_idx=2)\r\n        self.embedding.weight = nn.Parameter(ru.vectors)\r\n        self.embedding.weight.requires_grad = False\r\n        \r\n        self.lstm = nn.LSTM(300, 300, 2, batch_first=True, bidirectional=True, dropout=.05)\r\n        \r\n        self.dropout = nn.Dropout(p=.2)\r\n            #nn.LSTM(300, 300, 30, batch_first=True, bidirectional=True, dropout=.05),\r\n\r\n        self.fc1 = nn.Sequential(\r\n            nn.Linear(300*2*300, 1500),\r\n            nn.Sigmoid(),#inplace=True),\r\n\r\n            nn.Linear(1500, 100),\r\n            nn.Sigmoid()\r\n        )\r\n\r\n    def forward_once(self, x):\r\n        output = self.embedding(x)\r\n        output, _ = self.lstm(output)\r\n        output = self.dropout(output)\r\n        output = output.view(output.size()[0], -1)\r\n        output = self.fc1(output)\r\n        return output\r\n\r\n    def forward(self, input1, input2):\r\n        output1 = self.forward_once(input1)\r\n        output2 = self.forward_once(input2)\r\n        return output1, output2\r\n```\r\n\r\nand I'm using a custom loss:\r\n\r\n```\r\nclass ContrastiveLoss(torch.nn.Module):\r\n    \"\"\"\r\n    Contrastive loss function.\r\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\r\n    \"\"\"\r\n\r\n    def __init__(self, margin=2.0):\r\n        super(ContrastiveLoss, self).__init__()\r\n        self.margin = margin\r\n\r\n    def forward(self, output1, output2, label):\r\n        euclidean_distance = F.pairwise_distance(output1, output2)\r\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\r\n                                       (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\r\n        return loss_contrastive\r\n```\r\n\r\n\r\nThen after\r\n\r\n```\r\nnet = SiameseNetwork().cuda(1)\r\ncriterion = ContrastiveLoss()\r\nparameters = filter(lambda p: p.requires_grad, net.parameters())\r\noptimizer = optim.Adam(parameters, lr=0.1)\r\nloss_history = [] \r\niteration_number= 0\r\n\r\nnet.train()\r\n\r\nfor epoch in range(100):\r\n    epoch_end = time()\r\n    for i, data in enumerate(train_dataloader, 0):\r\n        text1, text2 , label = data\r\n        text1, text2 , label = Variable(text1).cuda(1), Variable(text2).cuda(1) , Variable(label).cuda(1)\r\n        output1,output2 = net(text1,text2)\r\n        optimizer.zero_grad()\r\n        loss_contrastive = criterion(output1,output2,label)\r\n        loss_contrastive.backward()\r\n\r\n        loss_history.append(loss_contrastive.data[0])\r\n        optimizer.step()\r\n\r\n```\r\n\r\nI'm getting \r\n\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-33-e2c1dc9f69ec> in <module>()\r\n     12         optimizer.zero_grad()\r\n     13         loss_contrastive = criterion(output1,output2,label)\r\n---> 14         loss_contrastive.backward()\r\n     15 \r\n     16         writer.add_scalar('data/step_loss', loss_contrastive.data[0])\r\n\r\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/variable.py in backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n    165                 Variable.\r\n    166         \"\"\"\r\n--> 167         torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n    168 \r\n    169     def register_hook(self, hook):\r\n\r\n~/anaconda3/envs/mrartemev/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(variables, grad_variables, retain_graph, create_graph, retain_variables)\r\n     97 \r\n     98     Variable._execution_engine.run_backward(\r\n---> 99         variables, grad_variables, retain_graph)\r\n    100 \r\n    101 \r\n\r\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathPairwise.cu:102\r\n```\r\n\r\nI'm using cuda 8.0 and cudann 5, installed pytorch with conda."}