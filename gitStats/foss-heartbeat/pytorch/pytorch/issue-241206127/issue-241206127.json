{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2002", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2002/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2002/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2002/events", "html_url": "https://github.com/pytorch/pytorch/issues/2002", "id": 241206127, "node_id": "MDU6SXNzdWUyNDEyMDYxMjc=", "number": 2002, "title": "distributed tests failed on MAC", "user": {"login": "lynic", "id": 3202036, "node_id": "MDQ6VXNlcjMyMDIwMzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/3202036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lynic", "html_url": "https://github.com/lynic", "followers_url": "https://api.github.com/users/lynic/followers", "following_url": "https://api.github.com/users/lynic/following{/other_user}", "gists_url": "https://api.github.com/users/lynic/gists{/gist_id}", "starred_url": "https://api.github.com/users/lynic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lynic/subscriptions", "organizations_url": "https://api.github.com/users/lynic/orgs", "repos_url": "https://api.github.com/users/lynic/repos", "events_url": "https://api.github.com/users/lynic/events{/privacy}", "received_events_url": "https://api.github.com/users/lynic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-07T09:19:00Z", "updated_at": "2017-07-07T15:06:57Z", "closed_at": "2017-07-07T15:06:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I build pytorch from source.</p>\n<p>All distributed tests failed on MAC:<br>\nRunning distributed tests for the TCP backend<br>\nProcess process 0:<br>\nProcess process 1:<br>\nProcess process 2:<br>\nTraceback (most recent call last):<br>\nFile \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap<br>\nself.run()<br>\nFile \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 93, in run<br>\nself._target(*self._args, **self._kwargs)<br>\nFile \"./test_distributed.py\", line 534, in _run<br>\ngetattr(self, self.id().split(\".\")[2])()<br>\nFile \"./test_distributed.py\", line 493, in wrapper<br>\nfn(self)<br>\nFile \"./test_distributed.py\", line 445, in test_all_gather<br>\ngroup, group_id, rank = self._init_global_test()<br>\nFile \"./test_distributed.py\", line 90, in _init_global_test<br>\ngroup = [i for i in range(0, dist.get_world_size())]<br>\nAttributeError: module 'torch.distributed' has no attribute 'get_world_size'<br>\n......<br>\nFAILED (failures=31, skipped=2)</p>\n<p>Is it normal?</p>", "body_text": "I build pytorch from source.\nAll distributed tests failed on MAC:\nRunning distributed tests for the TCP backend\nProcess process 0:\nProcess process 1:\nProcess process 2:\nTraceback (most recent call last):\nFile \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\nself.run()\nFile \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 93, in run\nself._target(*self._args, **self._kwargs)\nFile \"./test_distributed.py\", line 534, in _run\ngetattr(self, self.id().split(\".\")[2])()\nFile \"./test_distributed.py\", line 493, in wrapper\nfn(self)\nFile \"./test_distributed.py\", line 445, in test_all_gather\ngroup, group_id, rank = self._init_global_test()\nFile \"./test_distributed.py\", line 90, in _init_global_test\ngroup = [i for i in range(0, dist.get_world_size())]\nAttributeError: module 'torch.distributed' has no attribute 'get_world_size'\n......\nFAILED (failures=31, skipped=2)\nIs it normal?", "body": "I build pytorch from source.\r\n\r\nAll distributed tests failed on MAC:\r\nRunning distributed tests for the TCP backend\r\nProcess process 0:\r\nProcess process 1:\r\nProcess process 2:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\r\n    self.run()\r\n  File \"/usr/local/anaconda3/envs/pytorch-dev/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"./test_distributed.py\", line 534, in _run\r\n    getattr(self, self.id().split(\".\")[2])()\r\n  File \"./test_distributed.py\", line 493, in wrapper\r\n    fn(self)\r\n  File \"./test_distributed.py\", line 445, in test_all_gather\r\n    group, group_id, rank = self._init_global_test()\r\n  File \"./test_distributed.py\", line 90, in _init_global_test\r\n    group = [i for i in range(0, dist.get_world_size())]\r\nAttributeError: module 'torch.distributed' has no attribute 'get_world_size'\r\n......\r\nFAILED (failures=31, skipped=2)\r\n\r\nIs it normal?"}