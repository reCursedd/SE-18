{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212131198", "pull_request_review_id": 148698908, "id": 212131198, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMjEzMTE5OA==", "diff_hunk": "@@ -40,62 +42,83 @@ class RNNImplBase : public torch::nn::Cloneable<Derived> {\n   // https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNMode_t\n   enum class CuDNNMode { RNN_RELU = 0, RNN_TANH = 1, LSTM = 2, GRU = 3 };\n \n-  RNNImplBase(\n+  explicit RNNImplBase(\n       RNNOptionsBase options_,\n       at::optional<CuDNNMode> cudnn_mode = at::nullopt,\n-      int64_t number_of_gates = 1,\n-      bool has_cell_state = false);\n-\n-  RNNOutput forward(Tensor input, Tensor state = {});\n+      int64_t number_of_gates = 1);\n \n+  /// Initializes the parameters of the RNN module.\n   void reset() override;\n \n-  /// Recursively casts all parameters to the given device and dtype.\n+  /// Overrides `nn::Module::to()` to call `flatten_parameters()` after the\n+  /// original operation.\n   void to(torch::Device device, torch::Dtype dtype, bool non_blocking = false)\n       override;\n-\n-  /// Recursively casts all parameters to the given dtype.\n   void to(torch::Dtype dtype, bool non_blocking = false) override;\n-\n-  /// Recursively moves all parameters to the given device.\n   void to(torch::Device device, bool non_blocking = false) override;\n \n-  /// Fills the internal flattened parameter buffers passed to cuDNN. Call this\n-  /// method if you mess around with the variable storages and want to use\n-  /// cuDNN.\n-  void flatten_parameters_for_cudnn();\n+  /// Modifies the internal storage of weights for optimization purposes.\n+  ///\n+  /// On CPU, this method should be called if any of the weight or bias vectors\n+  /// are changed. On GPU, it should be called __any time the storage of any\n+  /// parameter is modified__, e.g. any time a parameter is assigned a new\n+  /// value. This allows using the fast path in cuDNN implementations of\n+  /// respective RNN `forward()` methods. It is called once upon construction,\n+  /// inside `reset()`.\n+  void flatten_parameters();\n+\n+  /// Returns the cuDNN mode of the RNN subclass if it has one. See\n+  /// https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNMode_t\n+  /// for a list of all cuDNN modes.\n+  at::optional<CuDNNMode> cudnn_mode() const noexcept;\n \n   RNNOptionsBase options;\n \n+  /// The weights for `input x hidden` gates.\n   std::vector<Tensor> w_ih;\n+  /// The weights for `hidden x hidden` gates.\n   std::vector<Tensor> w_hh;\n+  /// The biases for `input x hidden` gates.\n   std::vector<Tensor> b_ih;\n+  /// The biases for `hidden x hidden` gates.\n   std::vector<Tensor> b_hh;\n \n-  Dropout dropout;\n+  /// The dropout module, if dropout is used.\n+  Dropout dropout{nullptr};\n \n  protected:\n-  virtual Tensor cell_forward(Tensor input, Tensor state, int64_t layer) = 0;\n-\n-  RNNOutput CUDNN_forward(Tensor input, Tensor state);\n-  RNNOutput autograd_forward(Tensor input, Tensor state);\n-\n+  /// The function signature of `at::lstm`, `at::rnn_relu`, `at::gru` etc.", "path": "torch/csrc/api/include/torch/nn/modules/rnn.h", "position": null, "original_position": 78, "commit_id": "1474faaf96f2466af81ee8bf5f4d9ab8a2eb095b", "original_commit_id": "f72a058c5a1d39e53f806688ab480701cb9d3b00", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "true, thanks", "created_at": "2018-08-22T22:31:31Z", "updated_at": "2018-11-23T15:49:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/10761#discussion_r212131198", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10761", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/212131198"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10761#discussion_r212131198"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10761"}}, "body_html": "<p>true, thanks</p>", "body_text": "true, thanks", "in_reply_to_id": 212127945}