{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/299977790", "html_url": "https://github.com/pytorch/pytorch/issues/1513#issuecomment-299977790", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1513", "id": 299977790, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTk3Nzc5MA==", "user": {"login": "vzhong", "id": 1855260, "node_id": "MDQ6VXNlcjE4NTUyNjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1855260?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vzhong", "html_url": "https://github.com/vzhong", "followers_url": "https://api.github.com/users/vzhong/followers", "following_url": "https://api.github.com/users/vzhong/following{/other_user}", "gists_url": "https://api.github.com/users/vzhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/vzhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vzhong/subscriptions", "organizations_url": "https://api.github.com/users/vzhong/orgs", "repos_url": "https://api.github.com/users/vzhong/repos", "events_url": "https://api.github.com/users/vzhong/events{/privacy}", "received_events_url": "https://api.github.com/users/vzhong/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-08T20:14:48Z", "updated_at": "2017-05-08T20:15:04Z", "author_association": "NONE", "body_html": "<p>Well <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> that is certainly a solution, however I still think it is not intuitive that if my current GPU is 0, <code>list(torch.Tensor(5).gpu(2))</code> allocates memory on GPU0 at all.</p>", "body_text": "Well @apaszke @colesbury that is certainly a solution, however I still think it is not intuitive that if my current GPU is 0, list(torch.Tensor(5).gpu(2)) allocates memory on GPU0 at all.", "body": "Well @apaszke @colesbury that is certainly a solution, however I still think it is not intuitive that if my current GPU is 0, `list(torch.Tensor(5).gpu(2))` allocates memory on GPU0 at all. "}