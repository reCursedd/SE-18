{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/299978621", "html_url": "https://github.com/pytorch/pytorch/issues/1512#issuecomment-299978621", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1512", "id": 299978621, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTk3ODYyMQ==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-08T20:18:09Z", "updated_at": "2017-05-08T20:19:55Z", "author_association": "NONE", "body_html": "<p>I don't consider function composition a monkey-patching either. It's just I failed to find a nice function composition solution and had to redefine <code>default_collate</code>. If there's a function composition way, I agree it's probably not worth modifying the original collate to support this scenario.</p>\n<p>I tried your proposed way like this (please correct me if I got it wrong!):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.utils.data\n<span class=\"pl-k\">from</span> torch.utils.data.dataloader <span class=\"pl-k\">import</span> default_collate\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">BBoxList</span>(<span class=\"pl-c1\">list</span>): <span class=\"pl-k\">pass</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">collate_fn</span>(<span class=\"pl-smi\">batch</span>):\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(batch, BBoxList):\n        <span class=\"pl-k\">return</span> batch\n    <span class=\"pl-k\">return</span> default_collate(batch)\n\nloader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(<span class=\"pl-v\">dataset</span> <span class=\"pl-k\">=</span> [(torch.zeros(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), BBoxList(<span class=\"pl-c1\">list</span>(torch.zeros(i, <span class=\"pl-c1\">4</span>)))) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>)], <span class=\"pl-v\">batch_size</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">collate_fn</span> <span class=\"pl-k\">=</span> collate_fn)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> these don't work either:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([list(torch.zeros(i, 4))])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([torch.zeros(i, 4)])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)</span>\n\n<span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> loader:\n    <span class=\"pl-c1\">print</span>(batch)</pre></div>\n<p>The first example will have a BBoxList with 3  bboxes, the second example will have a BBoxList with 4 bboxes.</p>\n<p>on my machine this prints:</p>\n<pre><code>[\n(0 ,.,.) =\n  0  0\n  0  0\n\n(1 ,.,.) =\n  0  0\n  0  0\n[torch.FloatTensor of size 2x2x2]\n,  [\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n,\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n,\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n]]\n</code></pre>\n<p>The first element of batch is returned correctly: two stacked images.  The second is incorrect. It should have been an array of two elements with two tensors inside (of dims 3x2 and 4x2), the 4 bboxes seems sort of lost.</p>", "body_text": "I don't consider function composition a monkey-patching either. It's just I failed to find a nice function composition solution and had to redefine default_collate. If there's a function composition way, I agree it's probably not worth modifying the original collate to support this scenario.\nI tried your proposed way like this (please correct me if I got it wrong!):\nimport torch.utils.data\nfrom torch.utils.data.dataloader import default_collate\n\nclass BBoxList(list): pass\n\ndef collate_fn(batch):\n    if isinstance(batch, BBoxList):\n        return batch\n    return default_collate(batch)\n\nloader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList(list(torch.zeros(i, 4)))) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\n\n# these don't work either:\n# loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([list(torch.zeros(i, 4))])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\n# loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([torch.zeros(i, 4)])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\n\nfor batch in loader:\n    print(batch)\nThe first example will have a BBoxList with 3  bboxes, the second example will have a BBoxList with 4 bboxes.\non my machine this prints:\n[\n(0 ,.,.) =\n  0  0\n  0  0\n\n(1 ,.,.) =\n  0  0\n  0  0\n[torch.FloatTensor of size 2x2x2]\n,  [\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n,\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n,\n 0  0\n 0  0\n[torch.FloatTensor of size 2x2]\n]]\n\nThe first element of batch is returned correctly: two stacked images.  The second is incorrect. It should have been an array of two elements with two tensors inside (of dims 3x2 and 4x2), the 4 bboxes seems sort of lost.", "body": "I don't consider function composition a monkey-patching either. It's just I failed to find a nice function composition solution and had to redefine `default_collate`. If there's a function composition way, I agree it's probably not worth modifying the original collate to support this scenario.\r\n\r\nI tried your proposed way like this (please correct me if I got it wrong!):\r\n```python\r\nimport torch.utils.data\r\nfrom torch.utils.data.dataloader import default_collate\r\n\r\nclass BBoxList(list): pass\r\n\r\ndef collate_fn(batch):\r\n    if isinstance(batch, BBoxList):\r\n        return batch\r\n    return default_collate(batch)\r\n\r\nloader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList(list(torch.zeros(i, 4)))) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\r\n\r\n# these don't work either:\r\n# loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([list(torch.zeros(i, 4))])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\r\n# loader = torch.utils.data.DataLoader(dataset = [(torch.zeros(2, 2), BBoxList([torch.zeros(i, 4)])) for i in range(3, 5)], batch_size = 2, collate_fn = collate_fn)\r\n\r\nfor batch in loader:\r\n    print(batch)\r\n```\r\n\r\nThe first example will have a BBoxList with 3  bboxes, the second example will have a BBoxList with 4 bboxes.\r\n\r\non my machine this prints:\r\n```\r\n[\r\n(0 ,.,.) =\r\n  0  0\r\n  0  0\r\n\r\n(1 ,.,.) =\r\n  0  0\r\n  0  0\r\n[torch.FloatTensor of size 2x2x2]\r\n,  [\r\n 0  0\r\n 0  0\r\n[torch.FloatTensor of size 2x2]\r\n,\r\n 0  0\r\n 0  0\r\n[torch.FloatTensor of size 2x2]\r\n,\r\n 0  0\r\n 0  0\r\n[torch.FloatTensor of size 2x2]\r\n]]\r\n```\r\n\r\nThe first element of batch is returned correctly: two stacked images.  The second is incorrect. It should have been an array of two elements with two tensors inside (of dims 3x2 and 4x2), the 4 bboxes seems sort of lost."}