{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/94058657", "pull_request_review_id": 14589181, "id": 94058657, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk0MDU4NjU3", "diff_hunk": "@@ -0,0 +1,129 @@\n+import torch\n+import os\n+import weakref\n+import multiprocessing\n+from multiprocessing.reduction import ForkingPickler\n+import sys\n+try:\n+    # Early load resource_sharer to prevent a partially initialized instance\n+    # from being inherited in a forked child process. The reduce_storage method\n+    # requires this module indirectly through DupFd(). The built-in mp.Queue\n+    # class pickles arguments in a background thread which may overlap with the\n+    # fork.\n+    import multiprocessing.resource_sharer\n+except ImportError:\n+    pass\n+\n+\n+class StorageRef(object):\n+    # An object with a cdata field which may be set to None. We subclass object\n+    # instead of using a dict() to support weak references.\n+    def __init__(self, ptr):\n+        self.cdata = ptr\n+\n+\n+# mapping from handles to StorageRef objects\n+shared_cache = weakref.WeakValueDictionary()\n+\n+\n+def rebuild_event(handle):\n+    return torch.cuda.Event(_handle=handle)\n+\n+\n+def reduce_event(event):\n+    return (rebuild_event, (event.ipc_handle(),))\n+\n+\n+def rebuild_tensor(cls, storage, metadata):\n+    storage_offset, size, stride = metadata\n+    new_tensor = cls()\n+    new_tensor.set_(storage, storage_offset, size, stride)\n+    return new_tensor\n+\n+\n+def reduce_tensor(tensor):\n+    metadata = (tensor.storage_offset(), tensor.size(), tensor.stride())\n+    storage = tensor.storage()\n+    return (rebuild_tensor, (type(tensor), storage, metadata))\n+\n+\n+def fd_id(fd):\n+    # Returns a tuple which uniquely identifies a file descriptor. In Mac OS,\n+    # this doesn't work with shared memory handles, which is why we don't\n+    # support the \"file_descriptor\" sharing method on that platform.\n+    stat = os.fstat(fd)\n+    return (stat.st_ino, stat.st_dev)\n+\n+\n+def storage_from_cache(cls, key):\n+    storage_ref = shared_cache.get(key)\n+    if storage_ref is None:\n+        return None\n+    return cls._new_with_weak_ptr(storage_ref)\n+\n+\n+def rebuild_storage_fd(cls, df, size):\n+    if sys.version_info[0] == 2:\n+        fd = multiprocessing.reduction.rebuild_handle(df)\n+    else:\n+        fd = df.detach()\n+    storage = storage_from_cache(cls, fd_id(fd))\n+    if storage is not None:\n+        return storage", "path": "torch/multiprocessing/reductions.py", "position": null, "original_position": 72, "commit_id": "fe300c504147d8947010c885b45d6ad7bca8a3ea", "original_commit_id": "50ec819b95f66b8e6b0860a070f7f649c5098578", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Yeah, it's leaked. As we discussed over messenger, the leak checker doesn't catch it because it only checks if the next available file descriptor. To catch this we need to check the next available ten or twenty descriptors.\r\n\r\nI've added that check. Unfortunately, it now triggers a bunch of false positives: one-time initializations of things that hold on to file descriptors. I'm working on fixing these.", "created_at": "2016-12-28T17:44:06Z", "updated_at": "2018-11-23T15:32:06Z", "html_url": "https://github.com/pytorch/pytorch/pull/344#discussion_r94058657", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/344", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/94058657"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/344#discussion_r94058657"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/344"}}, "body_html": "<p>Yeah, it's leaked. As we discussed over messenger, the leak checker doesn't catch it because it only checks if the next available file descriptor. To catch this we need to check the next available ten or twenty descriptors.</p>\n<p>I've added that check. Unfortunately, it now triggers a bunch of false positives: one-time initializations of things that hold on to file descriptors. I'm working on fixing these.</p>", "body_text": "Yeah, it's leaked. As we discussed over messenger, the leak checker doesn't catch it because it only checks if the next available file descriptor. To catch this we need to check the next available ten or twenty descriptors.\nI've added that check. Unfortunately, it now triggers a bunch of false positives: one-time initializations of things that hold on to file descriptors. I'm working on fixing these.", "in_reply_to_id": 93977690}