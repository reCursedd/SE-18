{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93958033", "pull_request_review_id": 14486153, "id": 93958033, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDkzOTU4MDMz", "diff_hunk": "@@ -92,13 +97,14 @@ def __init__(self, loader):\n         self.sampler = loader.sampler\n         self.num_workers = loader.num_workers\n         self.pin_memory = loader.pin_memory\n+        self.done_event = threading.Event()\n \n         self.samples_remaining = len(self.sampler)\n         self.sample_iter = iter(self.sampler)\n \n         if self.num_workers > 0:\n-            self.index_queue = multiprocessing.Queue()\n-            self.data_queue = multiprocessing.Queue()\n+            self.index_queue = multiprocessing.SimpleQueue()", "path": "torch/utils/data/dataloader.py", "position": 29, "original_position": 29, "commit_id": "fe300c504147d8947010c885b45d6ad7bca8a3ea", "original_commit_id": "f44dea548f411ab8fda601766b4e7a2c12642758", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Python's `SimpleQueue` is a lot like what `torch.multiprocessing.Queue` was: a Pipe with a lock to ensure that writing objects is atomic.\r\n\r\n`multiprocessing.Queue` is too clever: when you `put` an object it sticks it in a list and a background thread serializes and sticks in the pipe. This makes `put` non-blocking which seems nice, but is a **terrible** design considering that multiprocessing usually relies on `fork` (without exec). Simple code like:\r\n\r\n```\r\nq = mp.Queue()\r\nq.put(obj)  # starts background thread\r\np = mp.Process(..., args=(q,))  # forks\r\np.start()\r\n``` \r\n\r\ncan lead to deadlocks if the `reduce` for `obj` imports a new module or calls `print` or some other things. Of course, some Python objects import modules (which is why there's an early call to `import multiprocessing.resource_sharer` in reductions.py.\r\n\r\nThis code works with multiprocessing.Queue too, but it seemed safer to stick to the SimpleQueue which doesn't use threads.", "created_at": "2016-12-27T18:29:32Z", "updated_at": "2018-11-23T15:32:06Z", "html_url": "https://github.com/pytorch/pytorch/pull/344#discussion_r93958033", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/344", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93958033"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/344#discussion_r93958033"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/344"}}, "body_html": "<p>Python's <code>SimpleQueue</code> is a lot like what <code>torch.multiprocessing.Queue</code> was: a Pipe with a lock to ensure that writing objects is atomic.</p>\n<p><code>multiprocessing.Queue</code> is too clever: when you <code>put</code> an object it sticks it in a list and a background thread serializes and sticks in the pipe. This makes <code>put</code> non-blocking which seems nice, but is a <strong>terrible</strong> design considering that multiprocessing usually relies on <code>fork</code> (without exec). Simple code like:</p>\n<pre><code>q = mp.Queue()\nq.put(obj)  # starts background thread\np = mp.Process(..., args=(q,))  # forks\np.start()\n</code></pre>\n<p>can lead to deadlocks if the <code>reduce</code> for <code>obj</code> imports a new module or calls <code>print</code> or some other things. Of course, some Python objects import modules (which is why there's an early call to <code>import multiprocessing.resource_sharer</code> in reductions.py.</p>\n<p>This code works with multiprocessing.Queue too, but it seemed safer to stick to the SimpleQueue which doesn't use threads.</p>", "body_text": "Python's SimpleQueue is a lot like what torch.multiprocessing.Queue was: a Pipe with a lock to ensure that writing objects is atomic.\nmultiprocessing.Queue is too clever: when you put an object it sticks it in a list and a background thread serializes and sticks in the pipe. This makes put non-blocking which seems nice, but is a terrible design considering that multiprocessing usually relies on fork (without exec). Simple code like:\nq = mp.Queue()\nq.put(obj)  # starts background thread\np = mp.Process(..., args=(q,))  # forks\np.start()\n\ncan lead to deadlocks if the reduce for obj imports a new module or calls print or some other things. Of course, some Python objects import modules (which is why there's an early call to import multiprocessing.resource_sharer in reductions.py.\nThis code works with multiprocessing.Queue too, but it seemed safer to stick to the SimpleQueue which doesn't use threads.", "in_reply_to_id": 93883247}