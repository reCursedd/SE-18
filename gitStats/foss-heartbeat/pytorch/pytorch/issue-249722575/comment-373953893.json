{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/373953893", "html_url": "https://github.com/pytorch/pytorch/issues/2389#issuecomment-373953893", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2389", "id": 373953893, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Mzk1Mzg5Mw==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-17T21:27:57Z", "updated_at": "2018-03-17T21:27:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12697801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ortasa\">@ortasa</a> I'm not sure. The main use case of sparse ops is embedding, which is already fully supported. Since there are many other very crucial tasks, extending autograd to other sparse ops is also quite important, but is not the top of our priorities.</p>", "body_text": "@ortasa I'm not sure. The main use case of sparse ops is embedding, which is already fully supported. Since there are many other very crucial tasks, extending autograd to other sparse ops is also quite important, but is not the top of our priorities.", "body": "@ortasa I'm not sure. The main use case of sparse ops is embedding, which is already fully supported. Since there are many other very crucial tasks, extending autograd to other sparse ops is also quite important, but is not the top of our priorities."}