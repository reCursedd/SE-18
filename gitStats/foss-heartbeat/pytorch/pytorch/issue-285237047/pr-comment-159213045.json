{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159213045", "pull_request_review_id": 86124642, "id": 159213045, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTIxMzA0NQ==", "diff_hunk": "@@ -73,7 +73,7 @@\n - name: addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value)\n   self: grad\n   tensor1: grad * value / tensor2\n-  tensor2: -grad * value * tensor1 / (tensor2 * tensor2)\n+  tensor2: grad * (self - result) / tensor2", "path": "tools/autograd/derivatives.yaml", "position": null, "original_position": 23, "commit_id": "bbb503aebddc63ed9b55db92cbc03243a43bbe5f", "original_commit_id": "8707cbf702537f71a65f4a225c9c544b0ed4b9d2", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "body": "I don't think so. `addcmul` is `self + value * tensor1 * tensor2`. Derivatives would be:\r\n- `self` => `grad`\r\n- `tensor1` => `grad * value * tensor2` (And the other way for `tensor2`). These are the best possible (I think).", "created_at": "2018-01-02T11:51:26Z", "updated_at": "2018-11-23T15:37:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/4415#discussion_r159213045", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4415", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159213045"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4415#discussion_r159213045"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4415"}}, "body_html": "<p>I don't think so. <code>addcmul</code> is <code>self + value * tensor1 * tensor2</code>. Derivatives would be:</p>\n<ul>\n<li><code>self</code> =&gt; <code>grad</code></li>\n<li><code>tensor1</code> =&gt; <code>grad * value * tensor2</code> (And the other way for <code>tensor2</code>). These are the best possible (I think).</li>\n</ul>", "body_text": "I don't think so. addcmul is self + value * tensor1 * tensor2. Derivatives would be:\n\nself => grad\ntensor1 => grad * value * tensor2 (And the other way for tensor2). These are the best possible (I think).", "in_reply_to_id": 159209524}