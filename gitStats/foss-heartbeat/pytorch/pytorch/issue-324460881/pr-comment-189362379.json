{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189362379", "pull_request_review_id": 121534124, "id": 189362379, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTM2MjM3OQ==", "diff_hunk": "@@ -0,0 +1,99 @@\n+import torch\n+\n+\n+class detect_anomaly(object):\n+    r\"\"\"Context-manager that enable anomaly detection for the autograd engine.\n+\n+    This does two things:\n+    - Running the forward pass with detection enabled will allow the backward\n+    pass to print the traceback of the forward operation that created the failing\n+    backward function.\n+    - Any backward computation that generate \"nan\" value will raise an error.\n+\n+    Example:\n+\n+        >>> import torch\n+        >>> from torch import autograd\n+        >>> class MyFunc(autograd.Function):\n+        ...     @staticmethod\n+        ...     def forward(ctx, inp):\n+        ...         return inp.clone()\n+        ...     @staticmethod\n+        ...     def backward(ctx, gO):\n+        ...         # Error during the backward pass\n+        ...         raise RuntimeError(\"Some error in backward\")\n+        ...         return gO.clone()\n+        >>> def run_fn(a):\n+        ...     out = MyFunc.apply(a)\n+        ...     return out.sum()\n+        >>> inp = torch.rand(10, 10, requires_grad=True)\n+        >>> out = run_fn(inp)\n+        >>> out.backward()\n+            Traceback (most recent call last):\n+              File \"<stdin>\", line 1, in <module>\n+              File \"/your/pytorch/intall/torch/tensor.py\", line 93, in backward\n+                torch.autograd.backward(self, gradient, retain_graph, create_graph)\n+              File \"/your/pytorch/intall/torch/autograd/__init__.py\", line 90, in backward\n+                allow_unreachable=True)  # allow_unreachable flag\n+              File \"/your/pytorch/intall/torch/autograd/function.py\", line 76, in apply\n+                return self._forward_cls.backward(self, *args)\n+              File \"<stdin>\", line 8, in backward\n+            RuntimeError: Some error in backward\n+        >>> with autograd.detect_anomaly():\n+        ...     inp = torch.rand(10, 10, requires_grad=True)\n+        ...     out = run_fn(inp)\n+        ...     out.backward()\n+            Traceback of forward call that caused the error:", "path": "torch/autograd/anomaly_mode.py", "position": 46, "original_position": 46, "commit_id": "ff608fec1da7f98b52ff290917865e6fd6fa8ec0", "original_commit_id": "312e4ab87895811bdef0eb71cc9dfdaa9df71e9c", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "this is the opposite order of what I'd expect (although I can see an argument for it).   The error message contains a dangling reference \"Traceback of forward call that caused the error\", but no error has yet been referenced.  It does seem a bit more natural to me to look at where the error occurred, and then see what forward caused it, otherwise I'm trying to go back and stitch up what happened in my mind later.", "created_at": "2018-05-18T18:52:02Z", "updated_at": "2018-11-23T15:44:16Z", "html_url": "https://github.com/pytorch/pytorch/pull/7677#discussion_r189362379", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7677", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189362379"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7677#discussion_r189362379"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7677"}}, "body_html": "<p>this is the opposite order of what I'd expect (although I can see an argument for it).   The error message contains a dangling reference \"Traceback of forward call that caused the error\", but no error has yet been referenced.  It does seem a bit more natural to me to look at where the error occurred, and then see what forward caused it, otherwise I'm trying to go back and stitch up what happened in my mind later.</p>", "body_text": "this is the opposite order of what I'd expect (although I can see an argument for it).   The error message contains a dangling reference \"Traceback of forward call that caused the error\", but no error has yet been referenced.  It does seem a bit more natural to me to look at where the error occurred, and then see what forward caused it, otherwise I'm trying to go back and stitch up what happened in my mind later."}