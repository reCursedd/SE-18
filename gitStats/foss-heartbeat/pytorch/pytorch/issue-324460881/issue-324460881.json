{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7677", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7677/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7677/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7677/events", "html_url": "https://github.com/pytorch/pytorch/pull/7677", "id": 324460881, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg5MDY0ODEx", "number": 7677, "title": "Add autograd automatic anomaly detection", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-18T15:43:40Z", "updated_at": "2018-11-23T15:45:38Z", "closed_at": "2018-06-12T01:26:18Z", "author_association": "COLLABORATOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/7677", "html_url": "https://github.com/pytorch/pytorch/pull/7677", "diff_url": "https://github.com/pytorch/pytorch/pull/7677.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/7677.patch"}, "body_html": "<p>This PR contains two main features:</p>\n<ul>\n<li>A metadata dictionary is associated to every C Function. If not used, this cost a single if statement in the Function destructor. This dictionary will remain even if the python Function object goes out of scope. This is not documented as this can only be used from python by recovering the Function object by traversing the graph which is not documented either.</li>\n<li>New anomaly detection feature for the autograd. If not used, this cost one if statement on Function creation and on autograd function execution during backward. This can be enabled with a context manager or a global flag switch. When enabled, this has two effect:\n<ul>\n<li>If any function returns nan during the backward pass, an error will be raised.</li>\n<li>If an error is raised during the backward pass, will print the traceback for the forward call that created the failing backward function.</li>\n</ul>\n</li>\n</ul>\n<p>Please double check the python refcounting as I'm not used to write this code and I might have missed one.</p>\n<p>To be done in a future PR:</p>\n<ul>\n<li>Add checks for nan during <code>nn.Module</code> forwarding. I can't find a good way to do this check for generic forward that does not use <code>nn.Module</code> especially when no grad are required.</li>\n<li>Use the metadata to instrument an <code>nn.Module</code>-based forward to allow better graph printing (like collapsing modules).</li>\n</ul>", "body_text": "This PR contains two main features:\n\nA metadata dictionary is associated to every C Function. If not used, this cost a single if statement in the Function destructor. This dictionary will remain even if the python Function object goes out of scope. This is not documented as this can only be used from python by recovering the Function object by traversing the graph which is not documented either.\nNew anomaly detection feature for the autograd. If not used, this cost one if statement on Function creation and on autograd function execution during backward. This can be enabled with a context manager or a global flag switch. When enabled, this has two effect:\n\nIf any function returns nan during the backward pass, an error will be raised.\nIf an error is raised during the backward pass, will print the traceback for the forward call that created the failing backward function.\n\n\n\nPlease double check the python refcounting as I'm not used to write this code and I might have missed one.\nTo be done in a future PR:\n\nAdd checks for nan during nn.Module forwarding. I can't find a good way to do this check for generic forward that does not use nn.Module especially when no grad are required.\nUse the metadata to instrument an nn.Module-based forward to allow better graph printing (like collapsing modules).", "body": "This PR contains two main features:\r\n- A metadata dictionary is associated to every C Function. If not used, this cost a single if statement in the Function destructor. This dictionary will remain even if the python Function object goes out of scope. This is not documented as this can only be used from python by recovering the Function object by traversing the graph which is not documented either.\r\n- New anomaly detection feature for the autograd. If not used, this cost one if statement on Function creation and on autograd function execution during backward. This can be enabled with a context manager or a global flag switch. When enabled, this has two effect:\r\n    - If any function returns nan during the backward pass, an error will be raised.\r\n    - If an error is raised during the backward pass, will print the traceback for the forward call that created the failing backward function.\r\n\r\nPlease double check the python refcounting as I'm not used to write this code and I might have missed one.\r\n\r\nTo be done in a future PR:\r\n- Add checks for nan during `nn.Module` forwarding. I can't find a good way to do this check for generic forward that does not use `nn.Module` especially when no grad are required.\r\n- Use the metadata to instrument an `nn.Module`-based forward to allow better graph printing (like collapsing modules)."}