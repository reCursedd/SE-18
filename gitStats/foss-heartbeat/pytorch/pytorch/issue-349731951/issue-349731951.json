{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10433", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10433/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10433/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10433/events", "html_url": "https://github.com/pytorch/pytorch/issues/10433", "id": 349731951, "node_id": "MDU6SXNzdWUzNDk3MzE5NTE=", "number": 10433, "title": "Accessing grad_fn throws when re-executing a loaded script module", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-11T12:50:29Z", "updated_at": "2018-08-13T17:38:30Z", "closed_at": null, "author_association": "COLLABORATOR", "body_html": "<h2>Issue description</h2>\n<p>Exporting a traced model, importing it back, running it on some input and printing the output fails with</p>\n<pre><code>TypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\n</code></pre>\n<h2>Code example</h2>\n<h3>Exporting a traced model</h3>\n<pre><code>import torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(1,1)\n\n    def forward(self, x):\n        return self.linear(x)\n\nmodel = Model()\nx = torch.zeros(1)\ntrace = torch.jit.trace(x)(model)\ntrace.save('foobar.pt')\n</code></pre>\n<h3>Importing the traced model</h3>\n<pre><code>import torch\nmodel = torch.jit.load('foobar.pt')\nx = torch.zeros(1)\nz = model(x)\nprint(z)\n</code></pre>\n<p>produces</p>\n<pre><code>Traceback (most recent call last):\n  File \"run_model_new.py\", line 10, in &lt;module&gt;\n    print(z)\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 60, in __repr__\n    return torch._tensor_str._str(self)\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\", line 259, in _str\n    if self.grad_fn is not None:\nTypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\n</code></pre>\n<p>In fact, just accessing <code>z.grad_fn</code> outside the print statement triggers the exception.</p>\n<p>The exception doesn't show up if the imported model is run in a <code>torch.no_grad()</code> context:</p>\n<pre><code>import torch\nmodel = torch.jit.load('foobar.pt')\nx = torch.zeros(1)\nwith torch.no_grad():\n    z = model(x)\nprint(z)\n</code></pre>\n<p>In this case, accessing <code>z.grad_fn</code> correctly returns <code>None</code>.</p>\n<h2>System Info</h2>\n<p>PyTorch version: 0.5.0a0+ab6afc2<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Mac OSX 10.13.6<br>\nGCC version: Could not collect<br>\nCMake version: version 3.9.4</p>\n<p>Python version: 3.6<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>", "body_text": "Issue description\nExporting a traced model, importing it back, running it on some input and printing the output fails with\nTypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\n\nCode example\nExporting a traced model\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(1,1)\n\n    def forward(self, x):\n        return self.linear(x)\n\nmodel = Model()\nx = torch.zeros(1)\ntrace = torch.jit.trace(x)(model)\ntrace.save('foobar.pt')\n\nImporting the traced model\nimport torch\nmodel = torch.jit.load('foobar.pt')\nx = torch.zeros(1)\nz = model(x)\nprint(z)\n\nproduces\nTraceback (most recent call last):\n  File \"run_model_new.py\", line 10, in <module>\n    print(z)\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 60, in __repr__\n    return torch._tensor_str._str(self)\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\", line 259, in _str\n    if self.grad_fn is not None:\nTypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\n\nIn fact, just accessing z.grad_fn outside the print statement triggers the exception.\nThe exception doesn't show up if the imported model is run in a torch.no_grad() context:\nimport torch\nmodel = torch.jit.load('foobar.pt')\nx = torch.zeros(1)\nwith torch.no_grad():\n    z = model(x)\nprint(z)\n\nIn this case, accessing z.grad_fn correctly returns None.\nSystem Info\nPyTorch version: 0.5.0a0+ab6afc2\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Mac OSX 10.13.6\nGCC version: Could not collect\nCMake version: version 3.9.4\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA", "body": "## Issue description\r\n\r\nExporting a traced model, importing it back, running it on some input and printing the output fails with \r\n```\r\nTypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\r\n```\r\n\r\n## Code example\r\n\r\n### Exporting a traced model\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass Model(nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.linear = nn.Linear(1,1)\r\n\r\n    def forward(self, x):\r\n        return self.linear(x)\r\n\r\nmodel = Model()\r\nx = torch.zeros(1)\r\ntrace = torch.jit.trace(x)(model)\r\ntrace.save('foobar.pt')\r\n```\r\n\r\n### Importing the traced model\r\n\r\n```\r\nimport torch\r\nmodel = torch.jit.load('foobar.pt')\r\nx = torch.zeros(1)\r\nz = model(x)\r\nprint(z)\r\n```\r\nproduces\r\n```\r\nTraceback (most recent call last):\r\n  File \"run_model_new.py\", line 10, in <module>\r\n    print(z)\r\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 60, in __repr__\r\n    return torch._tensor_str._str(self)\r\n  File \"/Users/lantiga/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\", line 259, in _str\r\n    if self.grad_fn is not None:\r\nTypeError: Don't know how to create Python object for N5torch3jit12_GLOBAL__N_129ExecutionPlanAutogradFunctionE\r\n```\r\nIn fact, just accessing `z.grad_fn` outside the print statement triggers the exception.\r\n\r\nThe exception doesn't show up if the imported model is run in a `torch.no_grad()` context:\r\n```\r\nimport torch\r\nmodel = torch.jit.load('foobar.pt')\r\nx = torch.zeros(1)\r\nwith torch.no_grad():\r\n    z = model(x)\r\nprint(z)\r\n```\r\nIn this case, accessing `z.grad_fn` correctly returns `None`.\r\n\r\n## System Info\r\nPyTorch version: 0.5.0a0+ab6afc2\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.6\r\nGCC version: Could not collect\r\nCMake version: version 3.9.4\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n"}