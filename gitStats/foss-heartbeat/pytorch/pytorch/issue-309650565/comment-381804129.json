{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/381804129", "html_url": "https://github.com/pytorch/pytorch/pull/6104#issuecomment-381804129", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6104", "id": 381804129, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTgwNDEyOQ==", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-17T01:51:49Z", "updated_at": "2018-04-17T01:51:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a> on the GPU side, two types of LSTM optimization are available, cudnn from ATen and FusedRNNKernel.cu from THCUNN. Current code actually chose cudnn over THCUNN so THCUNN won't be touched when cudnn is available.</p>\n<p>My plan is to provide equivalent logic on the CPU side. THNN/FusedRNNKernel.c will work as a backup path when mkldnn is not available, or mkldnn can not handle particular input configuration etc. Later i will provide mkldnn rnn code.</p>\n<p>Once the test failure is fixed, i will post performance comparison on <a href=\"https://github.com/pytorch/examples/tree/master/word_language_model\">word_language_model</a> and also the complete training loss curve so as to validate the math...</p>", "body_text": "@cpuhrsch on the GPU side, two types of LSTM optimization are available, cudnn from ATen and FusedRNNKernel.cu from THCUNN. Current code actually chose cudnn over THCUNN so THCUNN won't be touched when cudnn is available.\nMy plan is to provide equivalent logic on the CPU side. THNN/FusedRNNKernel.c will work as a backup path when mkldnn is not available, or mkldnn can not handle particular input configuration etc. Later i will provide mkldnn rnn code.\nOnce the test failure is fixed, i will post performance comparison on word_language_model and also the complete training loss curve so as to validate the math...", "body": "@cpuhrsch on the GPU side, two types of LSTM optimization are available, cudnn from ATen and FusedRNNKernel.cu from THCUNN. Current code actually chose cudnn over THCUNN so THCUNN won't be touched when cudnn is available.\r\n\r\nMy plan is to provide equivalent logic on the CPU side. THNN/FusedRNNKernel.c will work as a backup path when mkldnn is not available, or mkldnn can not handle particular input configuration etc. Later i will provide mkldnn rnn code.\r\n\r\nOnce the test failure is fixed, i will post performance comparison on [word_language_model](https://github.com/pytorch/examples/tree/master/word_language_model) and also the complete training loss curve so as to validate the math..."}