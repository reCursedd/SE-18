{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/6104", "id": 178249451, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc4MjQ5NDUx", "html_url": "https://github.com/pytorch/pytorch/pull/6104", "diff_url": "https://github.com/pytorch/pytorch/pull/6104.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/6104.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6104", "number": 6104, "state": "closed", "locked": false, "title": "implement fusedRNNKernel for THNN module", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "body": "#4186 this PR provides fused GRU and LSTM implementation in aten/src/THNN/generic/FusedRNNKernel.c\r\nto speedup CPU rnn performance.\r\nOn my test machine, Xeon skylake 8180 (56 core @ 2.5GHz), the performance comparison of this PR is listed in the table below:\r\n(**B**: batch size, **T**: time step, **I**: input size, **H**: hidden size)\r\nthe [benchmark](https://github.com/xhzhao/pytorch-rnn-benchmark) is a pytorch version of baidu's [deep-bench](https://github.com/baidu-research/DeepBench), unit is **SPS** sentences per second, the higher the better.\r\n\r\nB |T |I |H |original (SPS) | fused (SPS)\r\n---|---|---|---|---|---\r\n64 |15 |500 |500 | 876| 2427\r\n64 | 20 | 500 | 500 | 689 | 2140\r\n64 | 25 | 500 | 500 | 479 | 1445\r\n64 | 30 | 500 | 500 | 460 | 1262\r\n64 | 35 | 500 | 500 | 398 | 1308\r\n64 | 40 | 500 | 500 | 350 | 1107\r\n64 | 45 | 500 | 500 | 309 | 1011\r\n64 | 50 | 500 | 500 | 280 | 915\r\n16 | 25 | 512 | 512 | 340 | 657\r\n32 | 25 | 512 | 512 | 416 | 921\r\n64 | 25 | 512 | 512 | 492 | 1236\r\n128 | 25 | 512 | 512 | 582 | 1765\r\n16 | 25 | 1024 | 1024 | 93 | 149\r\n32 | 25 | 1024 | 1024 | 140 | 215\r\n64 | 25 | 1024 | 1024 | 197 | 335\r\n128 | 25 | 1024 | 1024 | 532 | 606\r\n16 | 25 | 2048 | 2048 | 23 | 28\r\n32 | 25 | 2048 | 2048 | 41 | 51\r\n64 | 25 | 2048 | 2048 | 88 | 97\r\n128 | 25 | 2048 | 2048 | 162 | 174\r\n16 | 25 | 4096 | 4096 | 6.7 | 7.0\r\n32| 25| 4096| 4096 | 13.5 | 13.7\r\n64 | 25 | 4096 | 4096 | 24.9 | 25.3\r\n128 | 25 | 4096 | 4096 | 45.1 | 47.8\r\n\r\n@yf225, the [word_language_model](https://github.com/yf225/examples/tree/benchmark_test/word_language_model) performance pretty much doubles on my machine. \r\n\r\nSome environment settings are needed to regulate OpenMP threads behavior so as to achieve better performance,\r\n```bash\r\n## take Xeon for example\r\nexport OMP_NUM_THREADS=[number of physical cores]\r\nexport KMP_AFFINITY=granularity=fine,compact,1,0\r\n```\r\ngenerally, fused rnn kernel receives more benefit when input size / hidden size are small, as gemm will donate in case of large input size / hidden size. By comparing the last four rows,  we can see increasing batch size is almost a free launch.\r\n\r\nHowever, aten/src/THNN/generic/FusedRNNKernel.c is fusing only element wise operation such as sigmoid, add, mul. To achieve more performance speedup, need to further fuse **x*W** gemm accross different time steps, this type of optimization is WIP.", "created_at": "2018-03-29T07:40:35Z", "updated_at": "2018-11-23T15:41:21Z", "closed_at": "2018-09-10T01:52:40Z", "merged_at": null, "merge_commit_sha": "598bdb6506e18198eddd2a8f987e12649e135ec7", "assignee": null, "assignees": [], "requested_reviewers": [{"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}], "requested_teams": [], "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6104/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6104/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6104/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/97585172a5522a6e826401338d5c9f7920fc0405", "head": {"label": "intel:pr-fused_rnn_kernel", "ref": "pr-fused_rnn_kernel", "sha": "97585172a5522a6e826401338d5c9f7920fc0405", "user": {"login": "intel", "id": 17888862, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE3ODg4ODYy", "avatar_url": "https://avatars3.githubusercontent.com/u/17888862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/intel", "html_url": "https://github.com/intel", "followers_url": "https://api.github.com/users/intel/followers", "following_url": "https://api.github.com/users/intel/following{/other_user}", "gists_url": "https://api.github.com/users/intel/gists{/gist_id}", "starred_url": "https://api.github.com/users/intel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/intel/subscriptions", "organizations_url": "https://api.github.com/users/intel/orgs", "repos_url": "https://api.github.com/users/intel/repos", "events_url": "https://api.github.com/users/intel/events{/privacy}", "received_events_url": "https://api.github.com/users/intel/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 91489517, "node_id": "MDEwOlJlcG9zaXRvcnk5MTQ4OTUxNw==", "name": "pytorch", "full_name": "intel/pytorch", "private": false, "owner": {"login": "intel", "id": 17888862, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE3ODg4ODYy", "avatar_url": "https://avatars3.githubusercontent.com/u/17888862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/intel", "html_url": "https://github.com/intel", "followers_url": "https://api.github.com/users/intel/followers", "following_url": "https://api.github.com/users/intel/following{/other_user}", "gists_url": "https://api.github.com/users/intel/gists{/gist_id}", "starred_url": "https://api.github.com/users/intel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/intel/subscriptions", "organizations_url": "https://api.github.com/users/intel/orgs", "repos_url": "https://api.github.com/users/intel/repos", "events_url": "https://api.github.com/users/intel/events{/privacy}", "received_events_url": "https://api.github.com/users/intel/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/intel/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/intel/pytorch", "forks_url": "https://api.github.com/repos/intel/pytorch/forks", "keys_url": "https://api.github.com/repos/intel/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/intel/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/intel/pytorch/teams", "hooks_url": "https://api.github.com/repos/intel/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/intel/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/intel/pytorch/events", "assignees_url": "https://api.github.com/repos/intel/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/intel/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/intel/pytorch/tags", "blobs_url": "https://api.github.com/repos/intel/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/intel/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/intel/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/intel/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/intel/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/intel/pytorch/languages", "stargazers_url": "https://api.github.com/repos/intel/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/intel/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/intel/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/intel/pytorch/subscription", "commits_url": "https://api.github.com/repos/intel/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/intel/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/intel/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/intel/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/intel/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/intel/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/intel/pytorch/merges", "archive_url": "https://api.github.com/repos/intel/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/intel/pytorch/downloads", "issues_url": "https://api.github.com/repos/intel/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/intel/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/intel/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/intel/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/intel/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/intel/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/intel/pytorch/deployments", "created_at": "2017-05-16T18:08:26Z", "updated_at": "2018-11-22T02:32:24Z", "pushed_at": "2018-11-22T02:31:15Z", "git_url": "git://github.com/intel/pytorch.git", "ssh_url": "git@github.com:intel/pytorch.git", "clone_url": "https://github.com/intel/pytorch.git", "svn_url": "https://github.com/intel/pytorch", "homepage": "http://pytorch.org", "size": 84997, "stargazers_count": 25, "watchers_count": 25, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 2, "mirror_url": null, "archived": false, "open_issues_count": 0, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 2, "open_issues": 0, "watchers": 25, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "fc6a846cc5db92f5d011d450dd6ea605d5688533", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T12:35:43Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21589, "watchers_count": 21589, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5153, "mirror_url": null, "archived": false, "open_issues_count": 2196, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5153, "open_issues": 2196, "watchers": 21589, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6104"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6104"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/6104"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/6104/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6104/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6104/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/97585172a5522a6e826401338d5c9f7920fc0405"}}, "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"282297290\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4186\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4186/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4186\">#4186</a> this PR provides fused GRU and LSTM implementation in aten/src/THNN/generic/FusedRNNKernel.c<br>\nto speedup CPU rnn performance.<br>\nOn my test machine, Xeon skylake 8180 (56 core @ 2.5GHz), the performance comparison of this PR is listed in the table below:<br>\n(<strong>B</strong>: batch size, <strong>T</strong>: time step, <strong>I</strong>: input size, <strong>H</strong>: hidden size)<br>\nthe <a href=\"https://github.com/xhzhao/pytorch-rnn-benchmark\">benchmark</a> is a pytorch version of baidu's <a href=\"https://github.com/baidu-research/DeepBench\">deep-bench</a>, unit is <strong>SPS</strong> sentences per second, the higher the better.</p>\n<table>\n<thead>\n<tr>\n<th>B</th>\n<th>T</th>\n<th>I</th>\n<th>H</th>\n<th>original (SPS)</th>\n<th>fused (SPS)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>64</td>\n<td>15</td>\n<td>500</td>\n<td>500</td>\n<td>876</td>\n<td>2427</td>\n</tr>\n<tr>\n<td>64</td>\n<td>20</td>\n<td>500</td>\n<td>500</td>\n<td>689</td>\n<td>2140</td>\n</tr>\n<tr>\n<td>64</td>\n<td>25</td>\n<td>500</td>\n<td>500</td>\n<td>479</td>\n<td>1445</td>\n</tr>\n<tr>\n<td>64</td>\n<td>30</td>\n<td>500</td>\n<td>500</td>\n<td>460</td>\n<td>1262</td>\n</tr>\n<tr>\n<td>64</td>\n<td>35</td>\n<td>500</td>\n<td>500</td>\n<td>398</td>\n<td>1308</td>\n</tr>\n<tr>\n<td>64</td>\n<td>40</td>\n<td>500</td>\n<td>500</td>\n<td>350</td>\n<td>1107</td>\n</tr>\n<tr>\n<td>64</td>\n<td>45</td>\n<td>500</td>\n<td>500</td>\n<td>309</td>\n<td>1011</td>\n</tr>\n<tr>\n<td>64</td>\n<td>50</td>\n<td>500</td>\n<td>500</td>\n<td>280</td>\n<td>915</td>\n</tr>\n<tr>\n<td>16</td>\n<td>25</td>\n<td>512</td>\n<td>512</td>\n<td>340</td>\n<td>657</td>\n</tr>\n<tr>\n<td>32</td>\n<td>25</td>\n<td>512</td>\n<td>512</td>\n<td>416</td>\n<td>921</td>\n</tr>\n<tr>\n<td>64</td>\n<td>25</td>\n<td>512</td>\n<td>512</td>\n<td>492</td>\n<td>1236</td>\n</tr>\n<tr>\n<td>128</td>\n<td>25</td>\n<td>512</td>\n<td>512</td>\n<td>582</td>\n<td>1765</td>\n</tr>\n<tr>\n<td>16</td>\n<td>25</td>\n<td>1024</td>\n<td>1024</td>\n<td>93</td>\n<td>149</td>\n</tr>\n<tr>\n<td>32</td>\n<td>25</td>\n<td>1024</td>\n<td>1024</td>\n<td>140</td>\n<td>215</td>\n</tr>\n<tr>\n<td>64</td>\n<td>25</td>\n<td>1024</td>\n<td>1024</td>\n<td>197</td>\n<td>335</td>\n</tr>\n<tr>\n<td>128</td>\n<td>25</td>\n<td>1024</td>\n<td>1024</td>\n<td>532</td>\n<td>606</td>\n</tr>\n<tr>\n<td>16</td>\n<td>25</td>\n<td>2048</td>\n<td>2048</td>\n<td>23</td>\n<td>28</td>\n</tr>\n<tr>\n<td>32</td>\n<td>25</td>\n<td>2048</td>\n<td>2048</td>\n<td>41</td>\n<td>51</td>\n</tr>\n<tr>\n<td>64</td>\n<td>25</td>\n<td>2048</td>\n<td>2048</td>\n<td>88</td>\n<td>97</td>\n</tr>\n<tr>\n<td>128</td>\n<td>25</td>\n<td>2048</td>\n<td>2048</td>\n<td>162</td>\n<td>174</td>\n</tr>\n<tr>\n<td>16</td>\n<td>25</td>\n<td>4096</td>\n<td>4096</td>\n<td>6.7</td>\n<td>7.0</td>\n</tr>\n<tr>\n<td>32</td>\n<td>25</td>\n<td>4096</td>\n<td>4096</td>\n<td>13.5</td>\n<td>13.7</td>\n</tr>\n<tr>\n<td>64</td>\n<td>25</td>\n<td>4096</td>\n<td>4096</td>\n<td>24.9</td>\n<td>25.3</td>\n</tr>\n<tr>\n<td>128</td>\n<td>25</td>\n<td>4096</td>\n<td>4096</td>\n<td>45.1</td>\n<td>47.8</td>\n</tr>\n</tbody>\n</table>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a>, the <a href=\"https://github.com/yf225/examples/tree/benchmark_test/word_language_model\">word_language_model</a> performance pretty much doubles on my machine.</p>\n<p>Some environment settings are needed to regulate OpenMP threads behavior so as to achieve better performance,</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span># take Xeon for example</span>\n<span class=\"pl-k\">export</span> OMP_NUM_THREADS=[number of physical cores]\n<span class=\"pl-k\">export</span> KMP_AFFINITY=granularity=fine,compact,1,0</pre></div>\n<p>generally, fused rnn kernel receives more benefit when input size / hidden size are small, as gemm will donate in case of large input size / hidden size. By comparing the last four rows,  we can see increasing batch size is almost a free launch.</p>\n<p>However, aten/src/THNN/generic/FusedRNNKernel.c is fusing only element wise operation such as sigmoid, add, mul. To achieve more performance speedup, need to further fuse <strong>x*W</strong> gemm accross different time steps, this type of optimization is WIP.</p>", "body_text": "#4186 this PR provides fused GRU and LSTM implementation in aten/src/THNN/generic/FusedRNNKernel.c\nto speedup CPU rnn performance.\nOn my test machine, Xeon skylake 8180 (56 core @ 2.5GHz), the performance comparison of this PR is listed in the table below:\n(B: batch size, T: time step, I: input size, H: hidden size)\nthe benchmark is a pytorch version of baidu's deep-bench, unit is SPS sentences per second, the higher the better.\n\n\n\nB\nT\nI\nH\noriginal (SPS)\nfused (SPS)\n\n\n\n\n64\n15\n500\n500\n876\n2427\n\n\n64\n20\n500\n500\n689\n2140\n\n\n64\n25\n500\n500\n479\n1445\n\n\n64\n30\n500\n500\n460\n1262\n\n\n64\n35\n500\n500\n398\n1308\n\n\n64\n40\n500\n500\n350\n1107\n\n\n64\n45\n500\n500\n309\n1011\n\n\n64\n50\n500\n500\n280\n915\n\n\n16\n25\n512\n512\n340\n657\n\n\n32\n25\n512\n512\n416\n921\n\n\n64\n25\n512\n512\n492\n1236\n\n\n128\n25\n512\n512\n582\n1765\n\n\n16\n25\n1024\n1024\n93\n149\n\n\n32\n25\n1024\n1024\n140\n215\n\n\n64\n25\n1024\n1024\n197\n335\n\n\n128\n25\n1024\n1024\n532\n606\n\n\n16\n25\n2048\n2048\n23\n28\n\n\n32\n25\n2048\n2048\n41\n51\n\n\n64\n25\n2048\n2048\n88\n97\n\n\n128\n25\n2048\n2048\n162\n174\n\n\n16\n25\n4096\n4096\n6.7\n7.0\n\n\n32\n25\n4096\n4096\n13.5\n13.7\n\n\n64\n25\n4096\n4096\n24.9\n25.3\n\n\n128\n25\n4096\n4096\n45.1\n47.8\n\n\n\n@yf225, the word_language_model performance pretty much doubles on my machine.\nSome environment settings are needed to regulate OpenMP threads behavior so as to achieve better performance,\n## take Xeon for example\nexport OMP_NUM_THREADS=[number of physical cores]\nexport KMP_AFFINITY=granularity=fine,compact,1,0\ngenerally, fused rnn kernel receives more benefit when input size / hidden size are small, as gemm will donate in case of large input size / hidden size. By comparing the last four rows,  we can see increasing batch size is almost a free launch.\nHowever, aten/src/THNN/generic/FusedRNNKernel.c is fusing only element wise operation such as sigmoid, add, mul. To achieve more performance speedup, need to further fuse x*W gemm accross different time steps, this type of optimization is WIP.", "merged": false, "mergeable": false, "rebaseable": false, "mergeable_state": "dirty", "merged_by": null, "comments": 15, "review_comments": 4, "maintainer_can_modify": false, "commits": 2, "additions": 299, "deletions": 6, "changed_files": 2}