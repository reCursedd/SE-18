{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4497", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4497/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4497/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4497/events", "html_url": "https://github.com/pytorch/pytorch/issues/4497", "id": 286321034, "node_id": "MDU6SXNzdWUyODYzMjEwMzQ=", "number": 4497, "title": "MaxPool3d cannot be differentiated twice", "user": {"login": "PascalCeccaldi", "id": 10080840, "node_id": "MDQ6VXNlcjEwMDgwODQw", "avatar_url": "https://avatars2.githubusercontent.com/u/10080840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PascalCeccaldi", "html_url": "https://github.com/PascalCeccaldi", "followers_url": "https://api.github.com/users/PascalCeccaldi/followers", "following_url": "https://api.github.com/users/PascalCeccaldi/following{/other_user}", "gists_url": "https://api.github.com/users/PascalCeccaldi/gists{/gist_id}", "starred_url": "https://api.github.com/users/PascalCeccaldi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PascalCeccaldi/subscriptions", "organizations_url": "https://api.github.com/users/PascalCeccaldi/orgs", "repos_url": "https://api.github.com/users/PascalCeccaldi/repos", "events_url": "https://api.github.com/users/PascalCeccaldi/events{/privacy}", "received_events_url": "https://api.github.com/users/PascalCeccaldi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 796293477, "node_id": "MDU6TGFiZWw3OTYyOTM0Nzc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/double-backwards", "name": "double-backwards", "color": "e99695", "default": false}, {"id": 838476895, "node_id": "MDU6TGFiZWw4Mzg0NzY4OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/hackamonth", "name": "hackamonth", "color": "0e8a16", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-05T15:33:13Z", "updated_at": "2018-03-08T11:15:08Z", "closed_at": "2018-03-08T11:15:08Z", "author_association": "NONE", "body_html": "<p>While trying to implement WGan with gradient penalty for 3D volumes, I realized that MaxPool3d cannot be differentiated twice, while it works for MaxPool2d or even AvgPool3d.</p>\n<p>Here is the code I am using :</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Network</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.main <span class=\"pl-k\">=</span> nn.AvgPool3d(<span class=\"pl-c1\">2</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Works</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> self.main = nn.MaxPool3d(2) # Does not work</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> self.main = nn.MaxPool2d(2) # Works for 2d</span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.main(x)\n\nnet <span class=\"pl-k\">=</span> Network()\nnet.cuda()\nin_var <span class=\"pl-k\">=</span> Variable(torch.Tensor(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>).cuda(), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\ngrad_out <span class=\"pl-k\">=</span> Variable(torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>).cuda())\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> in_var = Variable(torch.Tensor(2, 2, 2, 2).cuda(), requires_grad=True) # Works for 2d</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> grad_out = Variable(torch.ones(2, 2, 1, 1).cuda()) # Works for 2d</span>\n\n\ngradient <span class=\"pl-k\">=</span> autograd.grad(<span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>net(in_var), <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>in_var,\n                         <span class=\"pl-v\">grad_outputs</span><span class=\"pl-k\">=</span>grad_out,\n                         <span class=\"pl-v\">create_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">retain_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                         <span class=\"pl-v\">only_inputs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)[<span class=\"pl-c1\">0</span>]\ngradient.mean().backward()\n</pre></div>\n<p>Thanks</p>", "body_text": "While trying to implement WGan with gradient penalty for 3D volumes, I realized that MaxPool3d cannot be differentiated twice, while it works for MaxPool2d or even AvgPool3d.\nHere is the code I am using :\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.AvgPool3d(2) # Works\n        # self.main = nn.MaxPool3d(2) # Does not work\n        # self.main = nn.MaxPool2d(2) # Works for 2d\n\n    def forward(self, x):\n        return self.main(x)\n\nnet = Network()\nnet.cuda()\nin_var = Variable(torch.Tensor(2, 2, 2, 2, 2).cuda(), requires_grad=True)\ngrad_out = Variable(torch.ones(2, 2, 1, 1, 1).cuda())\n\n# in_var = Variable(torch.Tensor(2, 2, 2, 2).cuda(), requires_grad=True) # Works for 2d\n# grad_out = Variable(torch.ones(2, 2, 1, 1).cuda()) # Works for 2d\n\n\ngradient = autograd.grad(outputs=net(in_var), inputs=in_var,\n                         grad_outputs=grad_out,\n                         create_graph=True, retain_graph=True,\n                         only_inputs=True)[0]\ngradient.mean().backward()\n\nThanks", "body": "While trying to implement WGan with gradient penalty for 3D volumes, I realized that MaxPool3d cannot be differentiated twice, while it works for MaxPool2d or even AvgPool3d.\r\n\r\nHere is the code I am using :\r\n\r\n```python\r\n\r\nclass Network(nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.main = nn.AvgPool3d(2) # Works\r\n        # self.main = nn.MaxPool3d(2) # Does not work\r\n        # self.main = nn.MaxPool2d(2) # Works for 2d\r\n\r\n    def forward(self, x):\r\n        return self.main(x)\r\n\r\nnet = Network()\r\nnet.cuda()\r\nin_var = Variable(torch.Tensor(2, 2, 2, 2, 2).cuda(), requires_grad=True)\r\ngrad_out = Variable(torch.ones(2, 2, 1, 1, 1).cuda())\r\n\r\n# in_var = Variable(torch.Tensor(2, 2, 2, 2).cuda(), requires_grad=True) # Works for 2d\r\n# grad_out = Variable(torch.ones(2, 2, 1, 1).cuda()) # Works for 2d\r\n\r\n\r\ngradient = autograd.grad(outputs=net(in_var), inputs=in_var,\r\n                         grad_outputs=grad_out,\r\n                         create_graph=True, retain_graph=True,\r\n                         only_inputs=True)[0]\r\ngradient.mean().backward()\r\n\r\n```\r\nThanks"}