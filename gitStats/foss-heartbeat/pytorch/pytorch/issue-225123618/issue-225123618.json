{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1391", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1391/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1391/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1391/events", "html_url": "https://github.com/pytorch/pytorch/issues/1391", "id": 225123618, "node_id": "MDU6SXNzdWUyMjUxMjM2MTg=", "number": 1391, "title": "min behaves strangely over Variables", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-28T15:58:56Z", "updated_at": "2017-05-08T21:24:24Z", "closed_at": "2017-05-08T21:24:24Z", "author_association": "NONE", "body_html": "<p>Can standard Python's <code>min</code> be used on Variables? (I'm currently using it to find indices of the minimal element in a matrix on a path that doesn't need backprop)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.autograd\n\na <span class=\"pl-k\">=</span> torch.Tensor([[<span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.9075691103935242</span>, <span class=\"pl-c1\">0.8794320821762085</span>, <span class=\"pl-c1\">0.8809098601341248</span>, <span class=\"pl-c1\">0.8780722618103027</span>, <span class=\"pl-c1\">0.8403401374816</span>\n<span class=\"pl-c1\">895</span>, <span class=\"pl-c1\">0.865680456161499</span>, <span class=\"pl-c1\">0.825861394405365</span>, <span class=\"pl-c1\">0.856471598148346</span>, <span class=\"pl-c1\">0.8442185521125793</span>, <span class=\"pl-c1\">0.8678421974182129</span>, <span class=\"pl-c1\">0.8693640828132629</span>, <span class=\"pl-c1\">0.794446527</span>\n<span class=\"pl-c1\">9579163</span>, <span class=\"pl-c1\">0.881320059299469</span>, <span class=\"pl-c1\">0.8641207814216614</span>, <span class=\"pl-c1\">0.8334723114967346</span>], [<span class=\"pl-c1\">0.9075691103935242</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8587400913238525</span>, <span class=\"pl-c1\">0.88</span>\n<span class=\"pl-c1\">29082250595093</span>, <span class=\"pl-c1\">0.9015069603919983</span>, <span class=\"pl-c1\">0.8339723944664001</span>, <span class=\"pl-c1\">0.8852984309196472</span>, <span class=\"pl-c1\">0.8081797957420349</span>, <span class=\"pl-c1\">0.8971441388130188</span>, <span class=\"pl-c1\">0.837138712406158</span>\n<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">0.8504025340080261</span>, <span class=\"pl-c1\">0.8904311656951904</span>, <span class=\"pl-c1\">0.8334468007087708</span>, <span class=\"pl-c1\">0.8594257235527039</span>, <span class=\"pl-c1\">0.8932617902755737</span>, <span class=\"pl-c1\">0.8583635687828064</span>], [<span class=\"pl-c1\">0.879432</span>\n<span class=\"pl-c1\">0<span class=\"pl-ii\">821762085</span></span>, <span class=\"pl-c1\">0.8587400913238525</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8784974813461304</span>, <span class=\"pl-c1\">0.8284645080566406</span>, <span class=\"pl-c1\">0.8203730583190918</span>, <span class=\"pl-c1\">0.8673781156539917</span>, <span class=\"pl-c1\">0</span>.\n<span class=\"pl-c1\">8032702207565308</span>, <span class=\"pl-c1\">0.8286477327346802</span>, <span class=\"pl-c1\">0.821304202079773</span>, <span class=\"pl-c1\">0.8044344782829285</span>, <span class=\"pl-c1\">0.8060423135757446</span>, <span class=\"pl-c1\">0.8033348321914673</span>, <span class=\"pl-c1\">0.84030467271804</span>\n<span class=\"pl-c1\">81</span>, <span class=\"pl-c1\">0.8742191791534424</span>, <span class=\"pl-c1\">0.8333759307861328</span>], [<span class=\"pl-c1\">0.8809098601341248</span>, <span class=\"pl-c1\">0.8829082250595093</span>, <span class=\"pl-c1\">0.8784974813461304</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.863275</span>\n<span class=\"pl-c1\">7067680359</span>, <span class=\"pl-c1\">0.7921271324157715</span>, <span class=\"pl-c1\">0.8418437242507935</span>, <span class=\"pl-c1\">0.7885733246803284</span>, <span class=\"pl-c1\">0.8346586227416992</span>, <span class=\"pl-c1\">0.901179313659668</span>, <span class=\"pl-c1\">0.8190244436264038</span>, <span class=\"pl-c1\">0</span>.\n<span class=\"pl-c1\">9161911010742188</span>, <span class=\"pl-c1\">0.7806306481361389</span>, <span class=\"pl-c1\">0.8873835802078247</span>, <span class=\"pl-c1\">0.8541255593299866</span>, <span class=\"pl-c1\">0.891790509223938</span>], [<span class=\"pl-c1\">0.8780722618103027</span>, <span class=\"pl-c1\">0.901506960391</span>\n<span class=\"pl-c1\">9983</span>, <span class=\"pl-c1\">0.8284645080566406</span>, <span class=\"pl-c1\">0.8632757067680359</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8408827185630798</span>, <span class=\"pl-c1\">0.8164740800857544</span>, <span class=\"pl-c1\">0.8205516934394836</span>, <span class=\"pl-c1\">0.812684</span>\n<span class=\"pl-c1\">4763755798</span>, <span class=\"pl-c1\">0.8436079621315002</span>, <span class=\"pl-c1\">0.8955596685409546</span>, <span class=\"pl-c1\">0.8400647044181824</span>, <span class=\"pl-c1\">0.8292648792266846</span>, <span class=\"pl-c1\">0.873343288898468</span>, <span class=\"pl-c1\">0.8440033793449402</span>, <span class=\"pl-c1\">0</span>.\n<span class=\"pl-c1\">8641085624694824</span>], [<span class=\"pl-c1\">0.8403401374816895</span>, <span class=\"pl-c1\">0.8339723944664001</span>, <span class=\"pl-c1\">0.8203730583190918</span>, <span class=\"pl-c1\">0.7921271324157715</span>, <span class=\"pl-c1\">0.8408827185630798</span>, <span class=\"pl-c1\">98.0392227172</span>\n<span class=\"pl-c1\">8516</span>, <span class=\"pl-c1\">0.8066961169242859</span>, <span class=\"pl-c1\">0.8447725176811218</span>, <span class=\"pl-c1\">0.8550190329551697</span>, <span class=\"pl-c1\">0.8070523142814636</span>, <span class=\"pl-c1\">0.8541778326034546</span>, <span class=\"pl-c1\">0.8299628496170044</span>, <span class=\"pl-c1\">0.81846</span>\n<span class=\"pl-c1\">73190116882</span>, <span class=\"pl-c1\">0.8346939086914062</span>, <span class=\"pl-c1\">0.8207554221153259</span>, <span class=\"pl-c1\">0.8015121817588806</span>], [<span class=\"pl-c1\">0.865680456161499</span>, <span class=\"pl-c1\">0.8852984309196472</span>, <span class=\"pl-c1\">0.8673781156539917</span>,\n <span class=\"pl-c1\">0.8418437242507935</span>, <span class=\"pl-c1\">0.8164740800857544</span>, <span class=\"pl-c1\">0.8066961169242859</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8031378984451294</span>, <span class=\"pl-c1\">0.8421551585197449</span>, <span class=\"pl-c1\">0.81201559305</span>\n<span class=\"pl-c1\">19104</span>, <span class=\"pl-c1\">0.802409291267395</span>, <span class=\"pl-c1\">0.8641816973686218</span>, <span class=\"pl-c1\">0.8173614144325256</span>, <span class=\"pl-c1\">0.8221943974494934</span>, <span class=\"pl-c1\">0.8877925276756287</span>, <span class=\"pl-c1\">0.8327846527099609</span>], [<span class=\"pl-c1\">0.825</span>\n<span class=\"pl-c1\">861394405365</span>, <span class=\"pl-c1\">0.8081797957420349</span>, <span class=\"pl-c1\">0.8032702207565308</span>, <span class=\"pl-c1\">0.7885733246803284</span>, <span class=\"pl-c1\">0.8205516934394836</span>, <span class=\"pl-c1\">0.8447725176811218</span>, <span class=\"pl-c1\">0.8031378984451294</span>,\n <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.7995796799659729</span>, <span class=\"pl-c1\">0.7713688015937805</span>, <span class=\"pl-c1\">0.7866989374160767</span>, <span class=\"pl-c1\">0.8077518343925476</span>, <span class=\"pl-c1\">0.823494017124176</span>, <span class=\"pl-c1\">0.818936169147</span>\n<span class=\"pl-c1\">4915</span>, <span class=\"pl-c1\">0.8200157880783081</span>, <span class=\"pl-c1\">0.8054004311561584</span>], [<span class=\"pl-c1\">0.856471598148346</span>, <span class=\"pl-c1\">0.8971441388130188</span>, <span class=\"pl-c1\">0.8286477327346802</span>, <span class=\"pl-c1\">0.8346586227416992</span>, <span class=\"pl-c1\">0.8126</span>\n<span class=\"pl-c1\">844763755798</span>, <span class=\"pl-c1\">0.8550190329551697</span>, <span class=\"pl-c1\">0.8421551585197449</span>, <span class=\"pl-c1\">0.7995796799659729</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8822442889213562</span>, <span class=\"pl-c1\">0.9148916006088257</span>, \n<span class=\"pl-c1\">0.9795987606048584</span>, <span class=\"pl-c1\">0.8635246157646179</span>, <span class=\"pl-c1\">0.8411056399345398</span>, <span class=\"pl-c1\">0.8074549436569214</span>, <span class=\"pl-c1\">0.8455122113227844</span>], [<span class=\"pl-c1\">0.8442185521125793</span>, <span class=\"pl-c1\">0.837138712</span>\n<span class=\"pl-c1\">4061584</span>, <span class=\"pl-c1\">0.821304202079773</span>, <span class=\"pl-c1\">0.901179313659668</span>, <span class=\"pl-c1\">0.8436079621315002</span>, <span class=\"pl-c1\">0.8070523142814636</span>, <span class=\"pl-c1\">0.8120155930519104</span>, <span class=\"pl-c1\">0.7713688015937805</span>, <span class=\"pl-c1\">0.8822</span>\n<span class=\"pl-c1\">442889213562</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8344431519508362</span>, <span class=\"pl-c1\">0.8873037695884705</span>, <span class=\"pl-c1\">0.8003842234611511</span>, <span class=\"pl-c1\">0.8740262985229492</span>, <span class=\"pl-c1\">0.8314799070358276</span>, \n<span class=\"pl-c1\">0.8557705879211426</span>], [<span class=\"pl-c1\">0.8678421974182129</span>, <span class=\"pl-c1\">0.8504025340080261</span>, <span class=\"pl-c1\">0.8044344782829285</span>, <span class=\"pl-c1\">0.8190244436264038</span>, <span class=\"pl-c1\">0.8955596685409546</span>, <span class=\"pl-c1\">0.854177832</span>\n<span class=\"pl-c1\">6034546</span>, <span class=\"pl-c1\">0.802409291267395</span>, <span class=\"pl-c1\">0.7866989374160767</span>, <span class=\"pl-c1\">0.9148916006088257</span>, <span class=\"pl-c1\">0.8344431519508362</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.9491904377937317</span>, <span class=\"pl-c1\">0.8363</span>\n<span class=\"pl-c1\">339304924011</span>, <span class=\"pl-c1\">0.870711624622345</span>, <span class=\"pl-c1\">0.8325743675231934</span>, <span class=\"pl-c1\">0.847017765045166</span>], [<span class=\"pl-c1\">0.8693640828132629</span>, <span class=\"pl-c1\">0.8904311656951904</span>, <span class=\"pl-c1\">0.8060423135757446</span>,\n <span class=\"pl-c1\">0.9161911010742188</span>, <span class=\"pl-c1\">0.8400647044181824</span>, <span class=\"pl-c1\">0.8299628496170044</span>, <span class=\"pl-c1\">0.8641816973686218</span>, <span class=\"pl-c1\">0.8077518343925476</span>, <span class=\"pl-c1\">0.9795987606048584</span>, <span class=\"pl-c1\">0.8873037695</span>\n<span class=\"pl-c1\">884705</span>, <span class=\"pl-c1\">0.9491904377937317</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8319265246391296</span>, <span class=\"pl-c1\">0.8944578766822815</span>, <span class=\"pl-c1\">0.8562427163124084</span>, <span class=\"pl-c1\">0.8630687594413757</span>], [<span class=\"pl-c1\">0.79</span>\n<span class=\"pl-c1\">44465279579163</span>, <span class=\"pl-c1\">0.8334468007087708</span>, <span class=\"pl-c1\">0.8033348321914673</span>, <span class=\"pl-c1\">0.7806306481361389</span>, <span class=\"pl-c1\">0.8292648792266846</span>, <span class=\"pl-c1\">0.8184673190116882</span>, <span class=\"pl-c1\">0.817361414432525</span>\n<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">0.823494017124176</span>, <span class=\"pl-c1\">0.8635246157646179</span>, <span class=\"pl-c1\">0.8003842234611511</span>, <span class=\"pl-c1\">0.8363339304924011</span>, <span class=\"pl-c1\">0.8319265246391296</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8457390069</span>\n<span class=\"pl-c1\">961548</span>, <span class=\"pl-c1\">0.8433489203453064</span>, <span class=\"pl-c1\">0.8118476867675781</span>], [<span class=\"pl-c1\">0.881320059299469</span>, <span class=\"pl-c1\">0.8594257235527039</span>, <span class=\"pl-c1\">0.8403046727180481</span>, <span class=\"pl-c1\">0.8873835802078247</span>, <span class=\"pl-c1\">0.87</span>\n<span class=\"pl-c1\">3343288898468</span>, <span class=\"pl-c1\">0.8346939086914062</span>, <span class=\"pl-c1\">0.8221943974494934</span>, <span class=\"pl-c1\">0.8189361691474915</span>, <span class=\"pl-c1\">0.8411056399345398</span>, <span class=\"pl-c1\">0.8740262985229492</span>, <span class=\"pl-c1\">0.870711624622345</span>,\n <span class=\"pl-c1\">0.8944578766822815</span>, <span class=\"pl-c1\">0.8457390069961548</span>, <span class=\"pl-c1\">98.03922271728516</span>, <span class=\"pl-c1\">0.8667164444923401</span>, <span class=\"pl-c1\">0.8241456747055054</span>], [<span class=\"pl-c1\">0.8641207814216614</span>, <span class=\"pl-c1\">0.893261790</span>\n<span class=\"pl-c1\">2755737</span>, <span class=\"pl-c1\">0.8742191791534424</span>, <span class=\"pl-c1\">0.8541255593299866</span>, <span class=\"pl-c1\">0.8440033793449402</span>, <span class=\"pl-c1\">0.8207554221153259</span>, <span class=\"pl-c1\">0.8877925276756287</span>, <span class=\"pl-c1\">0.8200157880783081</span>, <span class=\"pl-c1\">0.80</span>\n<span class=\"pl-c1\">74549436569214</span>, <span class=\"pl-c1\">0.8314799070358276</span>, <span class=\"pl-c1\">0.8325743675231934</span>, <span class=\"pl-c1\">0.8562427163124084</span>, <span class=\"pl-c1\">0.8433489203453064</span>, <span class=\"pl-c1\">0.8667164444923401</span>, <span class=\"pl-c1\">98.03922271728516</span>\n, <span class=\"pl-c1\">0.8262801170349121</span>], [<span class=\"pl-c1\">0.8334723114967346</span>, <span class=\"pl-c1\">0.8583635687828064</span>, <span class=\"pl-c1\">0.8333759307861328</span>, <span class=\"pl-c1\">0.891790509223938</span>, <span class=\"pl-c1\">0.8641085624694824</span>, <span class=\"pl-c1\">0.80151218</span>\n<span class=\"pl-c1\">17588806</span>, <span class=\"pl-c1\">0.8327846527099609</span>, <span class=\"pl-c1\">0.8054004311561584</span>, <span class=\"pl-c1\">0.8455122113227844</span>, <span class=\"pl-c1\">0.8557705879211426</span>, <span class=\"pl-c1\">0.847017765045166</span>, <span class=\"pl-c1\">0.8630687594413757</span>, <span class=\"pl-c1\">0.81</span>\n<span class=\"pl-c1\">18476867675781</span>, <span class=\"pl-c1\">0.8241456747055054</span>, <span class=\"pl-c1\">0.8262801170349121</span>, <span class=\"pl-c1\">98.03922271728516</span>]])\n\nb <span class=\"pl-k\">=</span> torch.autograd.Variable(a)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">min</span>([b[i, j].data[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">for</span> i, j <span class=\"pl-k\">in</span> [(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>), (<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">4</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>)]])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints 0.840882718563</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">min</span>([b[i, j] <span class=\"pl-k\">for</span> i, j <span class=\"pl-k\">in</span> [(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>), (<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">4</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>)]])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints Variable containing: 98.0392</span>\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">min</span>([b[i, j].data[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">for</span> i, j <span class=\"pl-k\">in</span> [(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>), (<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">4</span>)]])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints 0.840882718563</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">min</span>([b[i, j] <span class=\"pl-k\">for</span> i, j <span class=\"pl-k\">in</span> [(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>), (<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>), (<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">4</span>)]])) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints Variable containing: 0.8409</span></pre></div>", "body_text": "Can standard Python's min be used on Variables? (I'm currently using it to find indices of the minimal element in a matrix on a path that doesn't need backprop)\nimport torch\nimport torch.autograd\n\na = torch.Tensor([[98.03922271728516, 0.9075691103935242, 0.8794320821762085, 0.8809098601341248, 0.8780722618103027, 0.8403401374816\n895, 0.865680456161499, 0.825861394405365, 0.856471598148346, 0.8442185521125793, 0.8678421974182129, 0.8693640828132629, 0.794446527\n9579163, 0.881320059299469, 0.8641207814216614, 0.8334723114967346], [0.9075691103935242, 98.03922271728516, 0.8587400913238525, 0.88\n29082250595093, 0.9015069603919983, 0.8339723944664001, 0.8852984309196472, 0.8081797957420349, 0.8971441388130188, 0.837138712406158\n4, 0.8504025340080261, 0.8904311656951904, 0.8334468007087708, 0.8594257235527039, 0.8932617902755737, 0.8583635687828064], [0.879432\n0821762085, 0.8587400913238525, 98.03922271728516, 0.8784974813461304, 0.8284645080566406, 0.8203730583190918, 0.8673781156539917, 0.\n8032702207565308, 0.8286477327346802, 0.821304202079773, 0.8044344782829285, 0.8060423135757446, 0.8033348321914673, 0.84030467271804\n81, 0.8742191791534424, 0.8333759307861328], [0.8809098601341248, 0.8829082250595093, 0.8784974813461304, 98.03922271728516, 0.863275\n7067680359, 0.7921271324157715, 0.8418437242507935, 0.7885733246803284, 0.8346586227416992, 0.901179313659668, 0.8190244436264038, 0.\n9161911010742188, 0.7806306481361389, 0.8873835802078247, 0.8541255593299866, 0.891790509223938], [0.8780722618103027, 0.901506960391\n9983, 0.8284645080566406, 0.8632757067680359, 98.03922271728516, 0.8408827185630798, 0.8164740800857544, 0.8205516934394836, 0.812684\n4763755798, 0.8436079621315002, 0.8955596685409546, 0.8400647044181824, 0.8292648792266846, 0.873343288898468, 0.8440033793449402, 0.\n8641085624694824], [0.8403401374816895, 0.8339723944664001, 0.8203730583190918, 0.7921271324157715, 0.8408827185630798, 98.0392227172\n8516, 0.8066961169242859, 0.8447725176811218, 0.8550190329551697, 0.8070523142814636, 0.8541778326034546, 0.8299628496170044, 0.81846\n73190116882, 0.8346939086914062, 0.8207554221153259, 0.8015121817588806], [0.865680456161499, 0.8852984309196472, 0.8673781156539917,\n 0.8418437242507935, 0.8164740800857544, 0.8066961169242859, 98.03922271728516, 0.8031378984451294, 0.8421551585197449, 0.81201559305\n19104, 0.802409291267395, 0.8641816973686218, 0.8173614144325256, 0.8221943974494934, 0.8877925276756287, 0.8327846527099609], [0.825\n861394405365, 0.8081797957420349, 0.8032702207565308, 0.7885733246803284, 0.8205516934394836, 0.8447725176811218, 0.8031378984451294,\n 98.03922271728516, 0.7995796799659729, 0.7713688015937805, 0.7866989374160767, 0.8077518343925476, 0.823494017124176, 0.818936169147\n4915, 0.8200157880783081, 0.8054004311561584], [0.856471598148346, 0.8971441388130188, 0.8286477327346802, 0.8346586227416992, 0.8126\n844763755798, 0.8550190329551697, 0.8421551585197449, 0.7995796799659729, 98.03922271728516, 0.8822442889213562, 0.9148916006088257, \n0.9795987606048584, 0.8635246157646179, 0.8411056399345398, 0.8074549436569214, 0.8455122113227844], [0.8442185521125793, 0.837138712\n4061584, 0.821304202079773, 0.901179313659668, 0.8436079621315002, 0.8070523142814636, 0.8120155930519104, 0.7713688015937805, 0.8822\n442889213562, 98.03922271728516, 0.8344431519508362, 0.8873037695884705, 0.8003842234611511, 0.8740262985229492, 0.8314799070358276, \n0.8557705879211426], [0.8678421974182129, 0.8504025340080261, 0.8044344782829285, 0.8190244436264038, 0.8955596685409546, 0.854177832\n6034546, 0.802409291267395, 0.7866989374160767, 0.9148916006088257, 0.8344431519508362, 98.03922271728516, 0.9491904377937317, 0.8363\n339304924011, 0.870711624622345, 0.8325743675231934, 0.847017765045166], [0.8693640828132629, 0.8904311656951904, 0.8060423135757446,\n 0.9161911010742188, 0.8400647044181824, 0.8299628496170044, 0.8641816973686218, 0.8077518343925476, 0.9795987606048584, 0.8873037695\n884705, 0.9491904377937317, 98.03922271728516, 0.8319265246391296, 0.8944578766822815, 0.8562427163124084, 0.8630687594413757], [0.79\n44465279579163, 0.8334468007087708, 0.8033348321914673, 0.7806306481361389, 0.8292648792266846, 0.8184673190116882, 0.817361414432525\n6, 0.823494017124176, 0.8635246157646179, 0.8003842234611511, 0.8363339304924011, 0.8319265246391296, 98.03922271728516, 0.8457390069\n961548, 0.8433489203453064, 0.8118476867675781], [0.881320059299469, 0.8594257235527039, 0.8403046727180481, 0.8873835802078247, 0.87\n3343288898468, 0.8346939086914062, 0.8221943974494934, 0.8189361691474915, 0.8411056399345398, 0.8740262985229492, 0.870711624622345,\n 0.8944578766822815, 0.8457390069961548, 98.03922271728516, 0.8667164444923401, 0.8241456747055054], [0.8641207814216614, 0.893261790\n2755737, 0.8742191791534424, 0.8541255593299866, 0.8440033793449402, 0.8207554221153259, 0.8877925276756287, 0.8200157880783081, 0.80\n74549436569214, 0.8314799070358276, 0.8325743675231934, 0.8562427163124084, 0.8433489203453064, 0.8667164444923401, 98.03922271728516\n, 0.8262801170349121], [0.8334723114967346, 0.8583635687828064, 0.8333759307861328, 0.891790509223938, 0.8641085624694824, 0.80151218\n17588806, 0.8327846527099609, 0.8054004311561584, 0.8455122113227844, 0.8557705879211426, 0.847017765045166, 0.8630687594413757, 0.81\n18476867675781, 0.8241456747055054, 0.8262801170349121, 98.03922271728516]])\n\nb = torch.autograd.Variable(a)\n\nprint(min([b[i, j].data[0] for i, j in [(0, 0), (4, 5), (5, 4), (5, 5)]])) # prints 0.840882718563\nprint(min([b[i, j] for i, j in [(0, 0), (4, 5), (5, 4), (5, 5)]])) # prints Variable containing: 98.0392\n\nprint(min([b[i, j].data[0] for i, j in [(0, 0), (4, 5), (5, 4)]])) # prints 0.840882718563\nprint(min([b[i, j] for i, j in [(0, 0), (4, 5), (5, 4)]])) # prints Variable containing: 0.8409", "body": "Can standard Python's `min` be used on Variables? (I'm currently using it to find indices of the minimal element in a matrix on a path that doesn't need backprop)\r\n\r\n```python\r\nimport torch\r\nimport torch.autograd\r\n\r\na = torch.Tensor([[98.03922271728516, 0.9075691103935242, 0.8794320821762085, 0.8809098601341248, 0.8780722618103027, 0.8403401374816\r\n895, 0.865680456161499, 0.825861394405365, 0.856471598148346, 0.8442185521125793, 0.8678421974182129, 0.8693640828132629, 0.794446527\r\n9579163, 0.881320059299469, 0.8641207814216614, 0.8334723114967346], [0.9075691103935242, 98.03922271728516, 0.8587400913238525, 0.88\r\n29082250595093, 0.9015069603919983, 0.8339723944664001, 0.8852984309196472, 0.8081797957420349, 0.8971441388130188, 0.837138712406158\r\n4, 0.8504025340080261, 0.8904311656951904, 0.8334468007087708, 0.8594257235527039, 0.8932617902755737, 0.8583635687828064], [0.879432\r\n0821762085, 0.8587400913238525, 98.03922271728516, 0.8784974813461304, 0.8284645080566406, 0.8203730583190918, 0.8673781156539917, 0.\r\n8032702207565308, 0.8286477327346802, 0.821304202079773, 0.8044344782829285, 0.8060423135757446, 0.8033348321914673, 0.84030467271804\r\n81, 0.8742191791534424, 0.8333759307861328], [0.8809098601341248, 0.8829082250595093, 0.8784974813461304, 98.03922271728516, 0.863275\r\n7067680359, 0.7921271324157715, 0.8418437242507935, 0.7885733246803284, 0.8346586227416992, 0.901179313659668, 0.8190244436264038, 0.\r\n9161911010742188, 0.7806306481361389, 0.8873835802078247, 0.8541255593299866, 0.891790509223938], [0.8780722618103027, 0.901506960391\r\n9983, 0.8284645080566406, 0.8632757067680359, 98.03922271728516, 0.8408827185630798, 0.8164740800857544, 0.8205516934394836, 0.812684\r\n4763755798, 0.8436079621315002, 0.8955596685409546, 0.8400647044181824, 0.8292648792266846, 0.873343288898468, 0.8440033793449402, 0.\r\n8641085624694824], [0.8403401374816895, 0.8339723944664001, 0.8203730583190918, 0.7921271324157715, 0.8408827185630798, 98.0392227172\r\n8516, 0.8066961169242859, 0.8447725176811218, 0.8550190329551697, 0.8070523142814636, 0.8541778326034546, 0.8299628496170044, 0.81846\r\n73190116882, 0.8346939086914062, 0.8207554221153259, 0.8015121817588806], [0.865680456161499, 0.8852984309196472, 0.8673781156539917,\r\n 0.8418437242507935, 0.8164740800857544, 0.8066961169242859, 98.03922271728516, 0.8031378984451294, 0.8421551585197449, 0.81201559305\r\n19104, 0.802409291267395, 0.8641816973686218, 0.8173614144325256, 0.8221943974494934, 0.8877925276756287, 0.8327846527099609], [0.825\r\n861394405365, 0.8081797957420349, 0.8032702207565308, 0.7885733246803284, 0.8205516934394836, 0.8447725176811218, 0.8031378984451294,\r\n 98.03922271728516, 0.7995796799659729, 0.7713688015937805, 0.7866989374160767, 0.8077518343925476, 0.823494017124176, 0.818936169147\r\n4915, 0.8200157880783081, 0.8054004311561584], [0.856471598148346, 0.8971441388130188, 0.8286477327346802, 0.8346586227416992, 0.8126\r\n844763755798, 0.8550190329551697, 0.8421551585197449, 0.7995796799659729, 98.03922271728516, 0.8822442889213562, 0.9148916006088257, \r\n0.9795987606048584, 0.8635246157646179, 0.8411056399345398, 0.8074549436569214, 0.8455122113227844], [0.8442185521125793, 0.837138712\r\n4061584, 0.821304202079773, 0.901179313659668, 0.8436079621315002, 0.8070523142814636, 0.8120155930519104, 0.7713688015937805, 0.8822\r\n442889213562, 98.03922271728516, 0.8344431519508362, 0.8873037695884705, 0.8003842234611511, 0.8740262985229492, 0.8314799070358276, \r\n0.8557705879211426], [0.8678421974182129, 0.8504025340080261, 0.8044344782829285, 0.8190244436264038, 0.8955596685409546, 0.854177832\r\n6034546, 0.802409291267395, 0.7866989374160767, 0.9148916006088257, 0.8344431519508362, 98.03922271728516, 0.9491904377937317, 0.8363\r\n339304924011, 0.870711624622345, 0.8325743675231934, 0.847017765045166], [0.8693640828132629, 0.8904311656951904, 0.8060423135757446,\r\n 0.9161911010742188, 0.8400647044181824, 0.8299628496170044, 0.8641816973686218, 0.8077518343925476, 0.9795987606048584, 0.8873037695\r\n884705, 0.9491904377937317, 98.03922271728516, 0.8319265246391296, 0.8944578766822815, 0.8562427163124084, 0.8630687594413757], [0.79\r\n44465279579163, 0.8334468007087708, 0.8033348321914673, 0.7806306481361389, 0.8292648792266846, 0.8184673190116882, 0.817361414432525\r\n6, 0.823494017124176, 0.8635246157646179, 0.8003842234611511, 0.8363339304924011, 0.8319265246391296, 98.03922271728516, 0.8457390069\r\n961548, 0.8433489203453064, 0.8118476867675781], [0.881320059299469, 0.8594257235527039, 0.8403046727180481, 0.8873835802078247, 0.87\r\n3343288898468, 0.8346939086914062, 0.8221943974494934, 0.8189361691474915, 0.8411056399345398, 0.8740262985229492, 0.870711624622345,\r\n 0.8944578766822815, 0.8457390069961548, 98.03922271728516, 0.8667164444923401, 0.8241456747055054], [0.8641207814216614, 0.893261790\r\n2755737, 0.8742191791534424, 0.8541255593299866, 0.8440033793449402, 0.8207554221153259, 0.8877925276756287, 0.8200157880783081, 0.80\r\n74549436569214, 0.8314799070358276, 0.8325743675231934, 0.8562427163124084, 0.8433489203453064, 0.8667164444923401, 98.03922271728516\r\n, 0.8262801170349121], [0.8334723114967346, 0.8583635687828064, 0.8333759307861328, 0.891790509223938, 0.8641085624694824, 0.80151218\r\n17588806, 0.8327846527099609, 0.8054004311561584, 0.8455122113227844, 0.8557705879211426, 0.847017765045166, 0.8630687594413757, 0.81\r\n18476867675781, 0.8241456747055054, 0.8262801170349121, 98.03922271728516]])\r\n\r\nb = torch.autograd.Variable(a)\r\n\r\nprint(min([b[i, j].data[0] for i, j in [(0, 0), (4, 5), (5, 4), (5, 5)]])) # prints 0.840882718563\r\nprint(min([b[i, j] for i, j in [(0, 0), (4, 5), (5, 4), (5, 5)]])) # prints Variable containing: 98.0392\r\n\r\nprint(min([b[i, j].data[0] for i, j in [(0, 0), (4, 5), (5, 4)]])) # prints 0.840882718563\r\nprint(min([b[i, j] for i, j in [(0, 0), (4, 5), (5, 4)]])) # prints Variable containing: 0.8409\r\n```"}