{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/418697619", "html_url": "https://github.com/pytorch/pytorch/issues/8974#issuecomment-418697619", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8974", "id": 418697619, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODY5NzYxOQ==", "user": {"login": "alanderex", "id": 1356401, "node_id": "MDQ6VXNlcjEzNTY0MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1356401?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanderex", "html_url": "https://github.com/alanderex", "followers_url": "https://api.github.com/users/alanderex/followers", "following_url": "https://api.github.com/users/alanderex/following{/other_user}", "gists_url": "https://api.github.com/users/alanderex/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanderex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanderex/subscriptions", "organizations_url": "https://api.github.com/users/alanderex/orgs", "repos_url": "https://api.github.com/users/alanderex/repos", "events_url": "https://api.github.com/users/alanderex/events{/privacy}", "received_events_url": "https://api.github.com/users/alanderex/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-05T11:31:14Z", "updated_at": "2018-09-05T11:31:14Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a> According to the CUDA docs Xcode <strong>9</strong>.2 incl. LLVM 9.0.0 is required, isn't it:<br>\n<a href=\"https://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html#system-requirements\" rel=\"nofollow\">https://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html#system-requirements</a></p>\n<p>I was forced to recompile PyTorch for<br>\nMacOS 10.13.6 (17G65)<br>\nEverything <strong>worked</strong><br>\nI have the same message labeled <em>please report to PyTorch</em>, please see below:</p>\n<p>python torch/utils/collect_env.py<br>\nCollecting environment information...<br>\nPyTorch version: 0.5.0a0+a24163a<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2</p>\n<pre><code>  OS: Mac OSX 10.13.6\n  GCC version: \n        Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-            dir=/usr/include/c++/4.2.1\n        Apple LLVM version 9.0.0 (clang-900.0.39.2)\n        Target: x86_64-apple-darwin17.7.0\n        Thread model: posix\n        InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n  CMake version: version 3.12.0\n\n  Python version: 3.6\n  Is CUDA available: Yes\n  CUDA runtime version: 9.2.148\n  GPU models and configuration: Could not collect\n  Nvidia driver version: 387.10.10.10.40.105\n  cuDNN version: Probably one of the following:\n  /usr/local/cuda/lib/libcudnn.7.dylib\n  /usr/local/cuda/lib/libcudnn.dylib\n  /usr/local/cuda/lib/libcudnn_static.a\n\n  Versions of relevant libraries:\n  [pip] numpy (1.15.1)\n  [pip] torch (0.5.0a0+a24163a)\n  [conda] torch                     0.5.0a0+a24163a           &lt;pip&gt;\n</code></pre>\n<p>NVIDIA GeForce GTX 1080:</p>\n<pre><code>  Chipset Model: NVIDIA GeForce GTX 1080\n  Type: External GPU\n  Bus: PCIe\n  PCIe Lane Width: x4\n  VRAM (Dynamic, Max): 8191 MB\n  Vendor: NVIDIA (0x10de)\n  Device ID: 0x1b80\n  Revision ID: 0x00a1\n  ROM Revision: VBIOS 86.04.60.00.4a\n  Metal: Supported, feature set macOS GPUFamily1 v3\n</code></pre>\n<p><code>/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu:222:134: warning: self-comparison always evaluates to true [-Wtautological-compare] switch (memType) { case CUDAHistogramMemoryType::SHARED:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::SHARED == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D&lt; output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::SHARED&gt; (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; case CUDAHistogramMemoryType::MULTI_BLOCK:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::MULTI_BLOCK == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D&lt; output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::MULTI_BLOCK&gt; (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; default:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::GLOBAL == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D&lt; output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::GLOBAL&gt; (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; }  </code></p>", "body_text": "@yf225 According to the CUDA docs Xcode 9.2 incl. LLVM 9.0.0 is required, isn't it:\nhttps://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html#system-requirements\nI was forced to recompile PyTorch for\nMacOS 10.13.6 (17G65)\nEverything worked\nI have the same message labeled please report to PyTorch, please see below:\npython torch/utils/collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+a24163a\nIs debug build: No\nCUDA used to build PyTorch: 9.2\n  OS: Mac OSX 10.13.6\n  GCC version: \n        Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-            dir=/usr/include/c++/4.2.1\n        Apple LLVM version 9.0.0 (clang-900.0.39.2)\n        Target: x86_64-apple-darwin17.7.0\n        Thread model: posix\n        InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n  CMake version: version 3.12.0\n\n  Python version: 3.6\n  Is CUDA available: Yes\n  CUDA runtime version: 9.2.148\n  GPU models and configuration: Could not collect\n  Nvidia driver version: 387.10.10.10.40.105\n  cuDNN version: Probably one of the following:\n  /usr/local/cuda/lib/libcudnn.7.dylib\n  /usr/local/cuda/lib/libcudnn.dylib\n  /usr/local/cuda/lib/libcudnn_static.a\n\n  Versions of relevant libraries:\n  [pip] numpy (1.15.1)\n  [pip] torch (0.5.0a0+a24163a)\n  [conda] torch                     0.5.0a0+a24163a           <pip>\n\nNVIDIA GeForce GTX 1080:\n  Chipset Model: NVIDIA GeForce GTX 1080\n  Type: External GPU\n  Bus: PCIe\n  PCIe Lane Width: x4\n  VRAM (Dynamic, Max): 8191 MB\n  Vendor: NVIDIA (0x10de)\n  Device ID: 0x1b80\n  Revision ID: 0x00a1\n  ROM Revision: VBIOS 86.04.60.00.4a\n  Metal: Supported, feature set macOS GPUFamily1 v3\n\n/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu:222:134: warning: self-comparison always evaluates to true [-Wtautological-compare] switch (memType) { case CUDAHistogramMemoryType::SHARED:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::SHARED == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::SHARED> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; case CUDAHistogramMemoryType::MULTI_BLOCK:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::MULTI_BLOCK == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::MULTI_BLOCK> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; default:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::GLOBAL == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::GLOBAL> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; }", "body": "@yf225 According to the CUDA docs Xcode **9**.2 incl. LLVM 9.0.0 is required, isn't it:\r\nhttps://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html#system-requirements\r\n\r\nI was forced to recompile PyTorch for\r\nMacOS 10.13.6 (17G65)\r\nEverything **worked**\r\nI have the same message labeled *please report to PyTorch*, please see below:\r\n\r\npython torch/utils/collect_env.py\r\n      Collecting environment information...\r\n      PyTorch version: 0.5.0a0+a24163a\r\n      Is debug build: No\r\n      CUDA used to build PyTorch: 9.2\r\n\r\n      OS: Mac OSX 10.13.6\r\n      GCC version: \r\n            Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-            dir=/usr/include/c++/4.2.1\r\n            Apple LLVM version 9.0.0 (clang-900.0.39.2)\r\n            Target: x86_64-apple-darwin17.7.0\r\n            Thread model: posix\r\n            InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n      CMake version: version 3.12.0\r\n\r\n      Python version: 3.6\r\n      Is CUDA available: Yes\r\n      CUDA runtime version: 9.2.148\r\n      GPU models and configuration: Could not collect\r\n      Nvidia driver version: 387.10.10.10.40.105\r\n      cuDNN version: Probably one of the following:\r\n      /usr/local/cuda/lib/libcudnn.7.dylib\r\n      /usr/local/cuda/lib/libcudnn.dylib\r\n      /usr/local/cuda/lib/libcudnn_static.a\r\n\r\n      Versions of relevant libraries:\r\n      [pip] numpy (1.15.1)\r\n      [pip] torch (0.5.0a0+a24163a)\r\n      [conda] torch                     0.5.0a0+a24163a           <pip>\r\n\r\nNVIDIA GeForce GTX 1080:\r\n\r\n      Chipset Model: NVIDIA GeForce GTX 1080\r\n      Type: External GPU\r\n      Bus: PCIe\r\n      PCIe Lane Width: x4\r\n      VRAM (Dynamic, Max): 8191 MB\r\n      Vendor: NVIDIA (0x10de)\r\n      Device ID: 0x1b80\r\n      Revision ID: 0x00a1\r\n      ROM Revision: VBIOS 86.04.60.00.4a\r\n      Metal: Supported, feature set macOS GPUFamily1 v3\r\n\r\n`/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu:222:134: warning: self-comparison always evaluates to true [-Wtautological-compare]\r\nswitch (memType) { case CUDAHistogramMemoryType::SHARED:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::SHARED == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::SHARED> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; case CUDAHistogramMemoryType::MULTI_BLOCK:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::MULTI_BLOCK == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::MULTI_BLOCK> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; break; default:  (__cudaPushCallConfiguration(grid, block, (CUDAHistogramMemoryType::GLOBAL == CUDAHistogramMemoryType::SHARED) ? sharedMem : (0), (at::globalContext().getCurrentCUDAStream()))) ? (void)0 : kernelHistogram1D< output_t, input_t, int64_t, 1, 2, 1, CUDAHistogramMemoryType::GLOBAL> (aInfo, pInfo, bInfo, binsize, totalElements, getWeightsOp); if (!((cudaGetLastError()) == (cudaSuccess))) { throw Error({__func__, \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", 222}, at::str(at::str(\"cudaGetLastError() == cudaSuccess\", \" ASSERT FAILED at \", \"/Users/hendorf/code/audiodrama/pytorch-compile/aten/src/ATen/native/cuda/SummaryOps.cu\", \":\", 222, \", please report a bug to PyTorch. \", \"kernelHistogram1D failed\"))); }  ; ; }  `\r\n"}