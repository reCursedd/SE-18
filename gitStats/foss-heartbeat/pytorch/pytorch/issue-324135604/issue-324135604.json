{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7650", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7650/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7650/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7650/events", "html_url": "https://github.com/pytorch/pytorch/issues/7650", "id": 324135604, "node_id": "MDU6SXNzdWUzMjQxMzU2MDQ=", "number": 7650, "title": "Errors exporting model from PyTorch to Caffe2", "user": {"login": "peastman", "id": 4379786, "node_id": "MDQ6VXNlcjQzNzk3ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4379786?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peastman", "html_url": "https://github.com/peastman", "followers_url": "https://api.github.com/users/peastman/followers", "following_url": "https://api.github.com/users/peastman/following{/other_user}", "gists_url": "https://api.github.com/users/peastman/gists{/gist_id}", "starred_url": "https://api.github.com/users/peastman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peastman/subscriptions", "organizations_url": "https://api.github.com/users/peastman/orgs", "repos_url": "https://api.github.com/users/peastman/repos", "events_url": "https://api.github.com/users/peastman/events{/privacy}", "received_events_url": "https://api.github.com/users/peastman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-05-17T18:27:58Z", "updated_at": "2018-05-29T22:52:10Z", "closed_at": "2018-05-29T22:52:10Z", "author_association": "NONE", "body_html": "<h2>System Info</h2>\n<p>PyTorch 0.4.0 (installed with conda)<br>\nCaffe2 0.8.dev (installed with conda)<br>\nonnx-caffe2 1.0.0 (installed with pip)<br>\nmacOS 10.13.4<br>\nPython 3.6.5<br>\nno CUDA</p>\n<h2>Issue description</h2>\n<p>I'm trying to build a model with PyTorch, export it as a Caffe2 model, then use it in a C++ program.  I'm pretty sure the C++ code is correct.  At any rate, it works correctly if I use a model built directly with Caffe2.  But I run into various problems when using a PyTorch model.  Here is the code I use to generate it:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Compute</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">return</span> torch.sum(x<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>)\n\nx <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>)\ntorch.onnx.export(Compute(), x, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test.onnx<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">input_names</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>positions<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">output_names</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>energy<span class=\"pl-pds\">'</span></span>])</pre></div>\n<p>I convert it to a Caffe2 model with <code>convert-onnx-to-caffe2</code>, then try to execute it in my C++ program.  It fails with this error:</p>\n<pre><code>exception: [enforce fail at tensor.h:495] IsType&lt;T&gt;(). Tensor type mismatch, caller expects elements to be float while tensor contains long long Error from operator: \ninput: \"positions\" input: \"1\" output: \"2\" name: \"\" type: \"Pow\" device_option { device_type: 0 cuda_gpu_id: 0 }\n** while accessing input: 1\n</code></pre>\n<p>The problem appears to be the operation <code>x**2</code>.  PyTorch is recording the exponent as being a <code>long long</code>, but Caffe2 insists it must be a <code>float</code>.</p>\n<p>As a temporary workaround, I tried eliminating the power operation by changing the line to <code>return torch.sum(x*x)</code>.  With that change I can run the model, but when I query the \"energy\" output, it's wrong.  It ought to be a scalar containing the sum of squares of all the input elements.  Instead, it comes out as a (10, 3) matrix containing the square of each element.  That is, the sum operation is never getting run.</p>", "body_text": "System Info\nPyTorch 0.4.0 (installed with conda)\nCaffe2 0.8.dev (installed with conda)\nonnx-caffe2 1.0.0 (installed with pip)\nmacOS 10.13.4\nPython 3.6.5\nno CUDA\nIssue description\nI'm trying to build a model with PyTorch, export it as a Caffe2 model, then use it in a C++ program.  I'm pretty sure the C++ code is correct.  At any rate, it works correctly if I use a model built directly with Caffe2.  But I run into various problems when using a PyTorch model.  Here is the code I use to generate it:\nimport torch\nimport torch.nn as nn\n\nclass Compute(nn.Module):\n    def forward(self, x):\n        return torch.sum(x**2)\n\nx = torch.rand(10, 3)\ntorch.onnx.export(Compute(), x, \"test.onnx\", verbose=True, input_names=['positions'], output_names=['energy'])\nI convert it to a Caffe2 model with convert-onnx-to-caffe2, then try to execute it in my C++ program.  It fails with this error:\nexception: [enforce fail at tensor.h:495] IsType<T>(). Tensor type mismatch, caller expects elements to be float while tensor contains long long Error from operator: \ninput: \"positions\" input: \"1\" output: \"2\" name: \"\" type: \"Pow\" device_option { device_type: 0 cuda_gpu_id: 0 }\n** while accessing input: 1\n\nThe problem appears to be the operation x**2.  PyTorch is recording the exponent as being a long long, but Caffe2 insists it must be a float.\nAs a temporary workaround, I tried eliminating the power operation by changing the line to return torch.sum(x*x).  With that change I can run the model, but when I query the \"energy\" output, it's wrong.  It ought to be a scalar containing the sum of squares of all the input elements.  Instead, it comes out as a (10, 3) matrix containing the square of each element.  That is, the sum operation is never getting run.", "body": "## System Info\r\n\r\nPyTorch 0.4.0 (installed with conda)\r\nCaffe2 0.8.dev (installed with conda)\r\nonnx-caffe2 1.0.0 (installed with pip)\r\nmacOS 10.13.4\r\nPython 3.6.5\r\nno CUDA\r\n\r\n## Issue description\r\n\r\nI'm trying to build a model with PyTorch, export it as a Caffe2 model, then use it in a C++ program.  I'm pretty sure the C++ code is correct.  At any rate, it works correctly if I use a model built directly with Caffe2.  But I run into various problems when using a PyTorch model.  Here is the code I use to generate it:\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass Compute(nn.Module):\r\n    def forward(self, x):\r\n        return torch.sum(x**2)\r\n\r\nx = torch.rand(10, 3)\r\ntorch.onnx.export(Compute(), x, \"test.onnx\", verbose=True, input_names=['positions'], output_names=['energy'])\r\n```\r\n\r\nI convert it to a Caffe2 model with `convert-onnx-to-caffe2`, then try to execute it in my C++ program.  It fails with this error:\r\n\r\n```\r\nexception: [enforce fail at tensor.h:495] IsType<T>(). Tensor type mismatch, caller expects elements to be float while tensor contains long long Error from operator: \r\ninput: \"positions\" input: \"1\" output: \"2\" name: \"\" type: \"Pow\" device_option { device_type: 0 cuda_gpu_id: 0 }\r\n** while accessing input: 1\r\n```\r\n\r\nThe problem appears to be the operation `x**2`.  PyTorch is recording the exponent as being a `long long`, but Caffe2 insists it must be a `float`.\r\n\r\nAs a temporary workaround, I tried eliminating the power operation by changing the line to `return torch.sum(x*x)`.  With that change I can run the model, but when I query the \"energy\" output, it's wrong.  It ought to be a scalar containing the sum of squares of all the input elements.  Instead, it comes out as a (10, 3) matrix containing the square of each element.  That is, the sum operation is never getting run."}