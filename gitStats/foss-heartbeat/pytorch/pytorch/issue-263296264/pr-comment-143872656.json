{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143872656", "pull_request_review_id": 68439502, "id": 143872656, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0Mzg3MjY1Ng==", "diff_hunk": "@@ -537,23 +537,23 @@ PyObject *THPModule_hasDistributed(PyObject *_unused)\n #endif\n }\n \n-void destroy_DLPack_PyCapsule(PyObject * obj) {\n-  delete (DLTensor*)PyCapsule_GetPointer(obj, \"tensor\");\n+void DLPackPyCapsule_destroy(PyObject * obj) {\n+  DLManagedTensor * dlMTensor = (DLManagedTensor*)PyCapsule_GetPointer(obj, \"dltensor\");", "path": "torch/csrc/Module.cpp", "position": null, "original_position": 7, "commit_id": "284521837e00213f0f826cfd5b5cb02fe5d796ad", "original_commit_id": "78facc4c5e27fb3c7ea2dd7ad80564c9aaa15bc4", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "Recap of in-person discussion: PyCapsules holding DLManagedTensors should not do anything on deletion. They are just a container to transfer ownership of the DLManagedTensor from one framework to another. The expectation is that once you call `to_dlpack` the caller becomes responsible for ensuring that the deletor on the returned tensor gets called precisely once after it done with its use. That can be done by passing the DLManagedTensor to something that steals ownership (e.g. a  `from_dlpack` call) or by manually calling it. Because there is this manual behavior we will make to/from_dlpack a utility function and expect that higher-level functions public like to_caffe2 and from_pytorch compose them correctly.", "created_at": "2017-10-10T22:44:33Z", "updated_at": "2018-11-23T15:35:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/2998#discussion_r143872656", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2998", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143872656"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2998#discussion_r143872656"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2998"}}, "body_html": "<p>Recap of in-person discussion: PyCapsules holding DLManagedTensors should not do anything on deletion. They are just a container to transfer ownership of the DLManagedTensor from one framework to another. The expectation is that once you call <code>to_dlpack</code> the caller becomes responsible for ensuring that the deletor on the returned tensor gets called precisely once after it done with its use. That can be done by passing the DLManagedTensor to something that steals ownership (e.g. a  <code>from_dlpack</code> call) or by manually calling it. Because there is this manual behavior we will make to/from_dlpack a utility function and expect that higher-level functions public like to_caffe2 and from_pytorch compose them correctly.</p>", "body_text": "Recap of in-person discussion: PyCapsules holding DLManagedTensors should not do anything on deletion. They are just a container to transfer ownership of the DLManagedTensor from one framework to another. The expectation is that once you call to_dlpack the caller becomes responsible for ensuring that the deletor on the returned tensor gets called precisely once after it done with its use. That can be done by passing the DLManagedTensor to something that steals ownership (e.g. a  from_dlpack call) or by manually calling it. Because there is this manual behavior we will make to/from_dlpack a utility function and expect that higher-level functions public like to_caffe2 and from_pytorch compose them correctly."}