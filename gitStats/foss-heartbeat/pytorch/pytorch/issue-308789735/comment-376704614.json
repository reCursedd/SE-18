{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/376704614", "html_url": "https://github.com/pytorch/pytorch/pull/6031#issuecomment-376704614", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6031", "id": 376704614, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NjcwNDYxNA==", "user": {"login": "codinfox", "id": 2647449, "node_id": "MDQ6VXNlcjI2NDc0NDk=", "avatar_url": "https://avatars0.githubusercontent.com/u/2647449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codinfox", "html_url": "https://github.com/codinfox", "followers_url": "https://api.github.com/users/codinfox/followers", "following_url": "https://api.github.com/users/codinfox/following{/other_user}", "gists_url": "https://api.github.com/users/codinfox/gists{/gist_id}", "starred_url": "https://api.github.com/users/codinfox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codinfox/subscriptions", "organizations_url": "https://api.github.com/users/codinfox/orgs", "repos_url": "https://api.github.com/users/codinfox/repos", "events_url": "https://api.github.com/users/codinfox/events{/privacy}", "received_events_url": "https://api.github.com/users/codinfox/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-27T23:07:55Z", "updated_at": "2018-03-27T23:07:55Z", "author_association": "NONE", "body_html": "<p>Nice work.</p>\n<p>One little suggestion to the pytorch team: I think it would be better if we can assign each parameter a unique identifier (based on its hierarchy in the graph). By current design, the <code>optimizer.load_state_dict()</code> function assumes that the order of the stored state_dict is the same as the order currently defined in the network. This design is very fragile and error-prone. I would prefer this function to be implemented in a way like <code>module.load_state_dict()</code>, which does not rely on the order. Is there any reason why pytorch does not assign identifiers to parameters?</p>", "body_text": "Nice work.\nOne little suggestion to the pytorch team: I think it would be better if we can assign each parameter a unique identifier (based on its hierarchy in the graph). By current design, the optimizer.load_state_dict() function assumes that the order of the stored state_dict is the same as the order currently defined in the network. This design is very fragile and error-prone. I would prefer this function to be implemented in a way like module.load_state_dict(), which does not rely on the order. Is there any reason why pytorch does not assign identifiers to parameters?", "body": "Nice work.\r\n\r\nOne little suggestion to the pytorch team: I think it would be better if we can assign each parameter a unique identifier (based on its hierarchy in the graph). By current design, the `optimizer.load_state_dict()` function assumes that the order of the stored state_dict is the same as the order currently defined in the network. This design is very fragile and error-prone. I would prefer this function to be implemented in a way like `module.load_state_dict()`, which does not rely on the order. Is there any reason why pytorch does not assign identifiers to parameters?"}