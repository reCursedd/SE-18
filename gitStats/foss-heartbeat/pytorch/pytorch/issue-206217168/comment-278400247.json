{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/278400247", "html_url": "https://github.com/pytorch/pytorch/issues/700#issuecomment-278400247", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/700", "id": 278400247, "node_id": "MDEyOklzc3VlQ29tbWVudDI3ODQwMDI0Nw==", "user": {"login": "shawnjhenry", "id": 9464836, "node_id": "MDQ6VXNlcjk0NjQ4MzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9464836?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shawnjhenry", "html_url": "https://github.com/shawnjhenry", "followers_url": "https://api.github.com/users/shawnjhenry/followers", "following_url": "https://api.github.com/users/shawnjhenry/following{/other_user}", "gists_url": "https://api.github.com/users/shawnjhenry/gists{/gist_id}", "starred_url": "https://api.github.com/users/shawnjhenry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shawnjhenry/subscriptions", "organizations_url": "https://api.github.com/users/shawnjhenry/orgs", "repos_url": "https://api.github.com/users/shawnjhenry/repos", "events_url": "https://api.github.com/users/shawnjhenry/events{/privacy}", "received_events_url": "https://api.github.com/users/shawnjhenry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-08T17:30:37Z", "updated_at": "2017-02-08T17:30:37Z", "author_association": "NONE", "body_html": "<p>This isn't a functional net, but it'll show the issue:</p>\n<pre><code>import torch as th\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.autograd import Variable\n\nfrom torch.nn.functional import log_softmax, nll_loss\n\n\nclass Net(nn.Module):\n\n\tdef __init__(self):\n\t\tsuper(Net, self).__init__()\n\n\t\tself.rnn = LocalRNN(16, 512)\n\t\tself.lin = nn.Linear(512, 6)\n\n\tdef forward(self, input, hx=None):\n\t\thx = [Variable(th.zeros(50, 1, 512))]*16\n\t\t\n\t\toutput = self.rnn(input, hx)\n\t\toutput = th.sum(output, 0).squeeze()\n\t\toutput = self.lin(output)\n\t\toutput = log_softmax(output)\n\n\t\treturn output \n\t\t\n\nmodel = Net()\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nx = Variable(th.Tensor(100, 50, 512).normal_())\ny = Variable(th.LongTensor([0, 1, 2, 4, 5]*10))\n\noptimizer.zero_grad()\n\nimport time\n\ntimer = time.time()\n\noutput = model(x)\n\nloss = nll_loss(output, y)\n\nloss.backward()\n\noptimizer.step()\n\ntimer = time.time()-timer \n\nprint(timer)\n</code></pre>", "body_text": "This isn't a functional net, but it'll show the issue:\nimport torch as th\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.autograd import Variable\n\nfrom torch.nn.functional import log_softmax, nll_loss\n\n\nclass Net(nn.Module):\n\n\tdef __init__(self):\n\t\tsuper(Net, self).__init__()\n\n\t\tself.rnn = LocalRNN(16, 512)\n\t\tself.lin = nn.Linear(512, 6)\n\n\tdef forward(self, input, hx=None):\n\t\thx = [Variable(th.zeros(50, 1, 512))]*16\n\t\t\n\t\toutput = self.rnn(input, hx)\n\t\toutput = th.sum(output, 0).squeeze()\n\t\toutput = self.lin(output)\n\t\toutput = log_softmax(output)\n\n\t\treturn output \n\t\t\n\nmodel = Net()\n\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nx = Variable(th.Tensor(100, 50, 512).normal_())\ny = Variable(th.LongTensor([0, 1, 2, 4, 5]*10))\n\noptimizer.zero_grad()\n\nimport time\n\ntimer = time.time()\n\noutput = model(x)\n\nloss = nll_loss(output, y)\n\nloss.backward()\n\noptimizer.step()\n\ntimer = time.time()-timer \n\nprint(timer)", "body": "This isn't a functional net, but it'll show the issue:\r\n```\r\nimport torch as th\r\n\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\n\r\nfrom torch.autograd import Variable\r\n\r\nfrom torch.nn.functional import log_softmax, nll_loss\r\n\r\n\r\nclass Net(nn.Module):\r\n\r\n\tdef __init__(self):\r\n\t\tsuper(Net, self).__init__()\r\n\r\n\t\tself.rnn = LocalRNN(16, 512)\r\n\t\tself.lin = nn.Linear(512, 6)\r\n\r\n\tdef forward(self, input, hx=None):\r\n\t\thx = [Variable(th.zeros(50, 1, 512))]*16\r\n\t\t\r\n\t\toutput = self.rnn(input, hx)\r\n\t\toutput = th.sum(output, 0).squeeze()\r\n\t\toutput = self.lin(output)\r\n\t\toutput = log_softmax(output)\r\n\r\n\t\treturn output \r\n\t\t\r\n\r\nmodel = Net()\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=0.001)\r\n\r\nx = Variable(th.Tensor(100, 50, 512).normal_())\r\ny = Variable(th.LongTensor([0, 1, 2, 4, 5]*10))\r\n\r\noptimizer.zero_grad()\r\n\r\nimport time\r\n\r\ntimer = time.time()\r\n\r\noutput = model(x)\r\n\r\nloss = nll_loss(output, y)\r\n\r\nloss.backward()\r\n\r\noptimizer.step()\r\n\r\ntimer = time.time()-timer \r\n\r\nprint(timer)\r\n```"}