{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/315147975", "html_url": "https://github.com/pytorch/pytorch/issues/2085#issuecomment-315147975", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2085", "id": 315147975, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTE0Nzk3NQ==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-13T17:33:06Z", "updated_at": "2017-07-13T17:33:06Z", "author_association": "MEMBER", "body_html": "<p>it makes sense for something like <code>Adam</code> to have a default learning rate, but it doesn't make sense at all for <code>SGD</code>. The range of learning rates usually explored for Adam (for example) are very small and some discrete choices, within very close values of each other. It's not the case for SGD.<br>\nI dont think it makes sense for us to make the <code>lr</code> be consistently required or not-required (some optimizers like YellowFin dont even have a learning rate).</p>", "body_text": "it makes sense for something like Adam to have a default learning rate, but it doesn't make sense at all for SGD. The range of learning rates usually explored for Adam (for example) are very small and some discrete choices, within very close values of each other. It's not the case for SGD.\nI dont think it makes sense for us to make the lr be consistently required or not-required (some optimizers like YellowFin dont even have a learning rate).", "body": "it makes sense for something like `Adam` to have a default learning rate, but it doesn't make sense at all for `SGD`. The range of learning rates usually explored for Adam (for example) are very small and some discrete choices, within very close values of each other. It's not the case for SGD.\r\nI dont think it makes sense for us to make the `lr` be consistently required or not-required (some optimizers like YellowFin dont even have a learning rate)."}