{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422863248", "html_url": "https://github.com/pytorch/pytorch/issues/11800#issuecomment-422863248", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11800", "id": 422863248, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjg2MzI0OA==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T16:11:44Z", "updated_at": "2018-09-19T16:11:44Z", "author_association": "CONTRIBUTOR", "body_html": "<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = 'cuda:0'\nembed_dim = 2\nhidden_dim = 2\nB = 4\nT = 1\n\ndata = torch.randn(B,T,embed_dim, device=device)\nh0 = torch.randn(B, embed_dim, device=device)\nh0 = (h0, h0)\n\nw_hh = torch.randn(4*hidden_dim, hidden_dim, device=device, requires_grad=True)\nw_ih = torch.randn(4*embed_dim, hidden_dim, device=device, requires_grad=True)\nb_hh = torch.randn(4*hidden_dim, device=device, requires_grad=True)\nb_ih = torch.randn(4*embed_dim, device=device, requires_grad=True)\n\nhiddens = h0\ninput = data\nT = input.size(1) # check if time is actually the first dim\nfor t in range(T): \n    hiddens = torch.lstm_cell(input[:, t, :], hiddens, w_ih, w_hh, b_ih, b_hh)\n\nh, c = hiddens\nloss = c.sum() #+0*h.sum()\nloss.backward()\n</code></pre>\n<p><code>_thnn_fused_lstm_cell_cuda</code> doesn't deal well with undefined grad_hx, I'll send a PR.</p>", "body_text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = 'cuda:0'\nembed_dim = 2\nhidden_dim = 2\nB = 4\nT = 1\n\ndata = torch.randn(B,T,embed_dim, device=device)\nh0 = torch.randn(B, embed_dim, device=device)\nh0 = (h0, h0)\n\nw_hh = torch.randn(4*hidden_dim, hidden_dim, device=device, requires_grad=True)\nw_ih = torch.randn(4*embed_dim, hidden_dim, device=device, requires_grad=True)\nb_hh = torch.randn(4*hidden_dim, device=device, requires_grad=True)\nb_ih = torch.randn(4*embed_dim, device=device, requires_grad=True)\n\nhiddens = h0\ninput = data\nT = input.size(1) # check if time is actually the first dim\nfor t in range(T): \n    hiddens = torch.lstm_cell(input[:, t, :], hiddens, w_ih, w_hh, b_ih, b_hh)\n\nh, c = hiddens\nloss = c.sum() #+0*h.sum()\nloss.backward()\n\n_thnn_fused_lstm_cell_cuda doesn't deal well with undefined grad_hx, I'll send a PR.", "body": "```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\ndevice = 'cuda:0'\r\nembed_dim = 2\r\nhidden_dim = 2\r\nB = 4\r\nT = 1\r\n\r\ndata = torch.randn(B,T,embed_dim, device=device)\r\nh0 = torch.randn(B, embed_dim, device=device)\r\nh0 = (h0, h0)\r\n\r\nw_hh = torch.randn(4*hidden_dim, hidden_dim, device=device, requires_grad=True)\r\nw_ih = torch.randn(4*embed_dim, hidden_dim, device=device, requires_grad=True)\r\nb_hh = torch.randn(4*hidden_dim, device=device, requires_grad=True)\r\nb_ih = torch.randn(4*embed_dim, device=device, requires_grad=True)\r\n\r\nhiddens = h0\r\ninput = data\r\nT = input.size(1) # check if time is actually the first dim\r\nfor t in range(T): \r\n    hiddens = torch.lstm_cell(input[:, t, :], hiddens, w_ih, w_hh, b_ih, b_hh)\r\n\r\nh, c = hiddens\r\nloss = c.sum() #+0*h.sum()\r\nloss.backward()\r\n```\r\n`_thnn_fused_lstm_cell_cuda` doesn't deal well with undefined grad_hx, I'll send a PR."}