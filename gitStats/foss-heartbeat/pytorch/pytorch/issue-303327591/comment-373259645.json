{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/373259645", "html_url": "https://github.com/pytorch/pytorch/pull/5624#issuecomment-373259645", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5624", "id": 373259645, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzI1OTY0NQ==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-15T04:46:40Z", "updated_at": "2018-03-15T04:51:03Z", "author_association": "NONE", "body_html": "<p>Preserving a list when the batch can't be converted to a tensor is useful to, say, return a list of ground truth boxes without having to keep the packing logic in the data loader.</p>\n<p>Previously discussed in: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"227097304\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1512\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1512/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1512\">#1512</a>, my current workaround is:</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.utils.data.dataloader.default_collate <span class=\"pl-k\">=</span> (<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">default_collate</span> <span class=\"pl-k\">=</span> torch.utils.data.dataloader.default_collate: <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">batch</span>: batch <span class=\"pl-k\">if</span> <span class=\"pl-c1\">all</span>(<span class=\"pl-c1\">map</span>(torch.is_tensor, batch)) <span class=\"pl-k\">and</span> <span class=\"pl-c1\">any</span>([tensor.size() <span class=\"pl-k\">!=</span> batch[<span class=\"pl-c1\">0</span>].size() <span class=\"pl-k\">for</span> tensor <span class=\"pl-k\">in</span> batch]) <span class=\"pl-k\">else</span> default_collate(batch))()</pre></div>\n<p>and and it's not elegant at all.</p>\n<p>If this PR is accepted, this scenario can be supported by changing the first if condition of <code>default_collate</code> from <code>torch.is_tensor(batch[0])</code> to  <code>all(map(torch.is_tensor, batch)) and all(tensor.size() == batch[0].size() for tensor in batch)</code></p>", "body_text": "Preserving a list when the batch can't be converted to a tensor is useful to, say, return a list of ground truth boxes without having to keep the packing logic in the data loader.\nPreviously discussed in: #1512, my current workaround is:\ntorch.utils.data.dataloader.default_collate = (lambda default_collate = torch.utils.data.dataloader.default_collate: lambda batch: batch if all(map(torch.is_tensor, batch)) and any([tensor.size() != batch[0].size() for tensor in batch]) else default_collate(batch))()\nand and it's not elegant at all.\nIf this PR is accepted, this scenario can be supported by changing the first if condition of default_collate from torch.is_tensor(batch[0]) to  all(map(torch.is_tensor, batch)) and all(tensor.size() == batch[0].size() for tensor in batch)", "body": "Preserving a list when the batch can't be converted to a tensor is useful to, say, return a list of ground truth boxes without having to keep the packing logic in the data loader.\r\n\r\nPreviously discussed in: https://github.com/pytorch/pytorch/issues/1512, my current workaround is: \r\n\r\n```python\r\ntorch.utils.data.dataloader.default_collate = (lambda default_collate = torch.utils.data.dataloader.default_collate: lambda batch: batch if all(map(torch.is_tensor, batch)) and any([tensor.size() != batch[0].size() for tensor in batch]) else default_collate(batch))()\r\n```\r\n\r\nand and it's not elegant at all.\r\n\r\nIf this PR is accepted, this scenario can be supported by changing the first if condition of `default_collate` from `torch.is_tensor(batch[0])` to  `all(map(torch.is_tensor, batch)) and all(tensor.size() == batch[0].size() for tensor in batch)`"}