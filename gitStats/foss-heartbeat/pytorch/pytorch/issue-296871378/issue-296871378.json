{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5221", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5221/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5221/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5221/events", "html_url": "https://github.com/pytorch/pytorch/pull/5221", "id": 296871378, "node_id": "MDExOlB1bGxSZXF1ZXN0MTY4OTQ1NDUz", "number": 5221, "title": "Improve Function interface", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-02-13T20:17:35Z", "updated_at": "2018-11-23T15:39:44Z", "closed_at": "2018-02-21T21:37:53Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5221", "html_url": "https://github.com/pytorch/pytorch/pull/5221", "diff_url": "https://github.com/pytorch/pytorch/pull/5221.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5221.patch"}, "body_html": "<p>This PR is the second (and final) refactoring of the autograd internals. After <code>Variable</code>, I now took on <code>Function</code> to give it a nice API and make it easier to work with from the JIT and interoperate better with the new <code>Variable</code> API.</p>\n<p>This change was actually a lot easier than for <code>Variable</code>. I basically proceeded by making the public fields protected one-by-one, and adding proper accessors for the operations that user code were making. I then renamed <code>next_functions</code> to <code>next_edges</code> everywhere. Finally, I fixed some includes and added a ton of documentation.</p>\n<p>There is now a discrepancy between the Python API and the C++ <code>Function</code> class in that for Python I kept the <code>next_functions</code> name, but used <code>next_edges</code> in C++, which is more accurate in light of the introduction of the <code>Edge</code> class.</p>\n<p>I ran into a slightly interesting/controversial design decision for how to create gradient edges (i.e. connecting <code>Variable</code>s to <code>Function</code>s), especially when the number of inputs of the gradient function had to be incremented as well (i.e. a new gradient edge). Before this PR we had a lot of places like this:</p>\n<pre><code>variable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\n</code></pre>\n<p>It's certainly suboptimal that the user (even if it's just us) would have to mutate both <code>variable</code> and <code>grad_fn</code> to create the edge, and <em>especially</em> not forget to increment the <code>grad_fn</code>'s number of inputs! So I wrapped it in a free function:</p>\n<pre><code>void add_gradient_edge(Variable&amp; variable, Function&amp; function) {\n\tvariable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\n}\n</code></pre>\n<p>That left the case for when <code>grad_fn.num_inputs</code> wouldn't need to be incremented, i.e. when the input number to the gradient function would be known ahead of time. Here, calling <code>variable.set_gradient_edge({grad_fn, input_nr})</code> would be fine. However, that would require us to use/remember two different APIs for the same action of adding a gradient edge. For this reason, I've made <code>set_gradient_edge</code> private in <code>Variable</code>, added an overload to <code>add_gradient_edge</code> to call <code>set_gradient_edge</code> and made that overload a <code>friend</code> of <code>Variable</code>. This way, <code>autograd::add_gradient_edge</code> is the one and only way to connect variables with their gradient edges.</p>\n<p>Happy to hear thoughts on naming and the API of the <code>Function</code> class. Recommended order of reviewing is <code>torch/csrc/autograd/function.h</code> and <code>torch/csrc/autograd/variable.h</code>, then everything else.</p>\n<p>Btw, at the end of these two PRs (including the <code>Variable</code> one), we will have gone from:</p>\n<pre><code>// TODO: this kinda stuff is _way_ to low level to the public API of variable.\n// Why do I have to care here whether v has a grad_fn or grad accumulator?\n// Why do I have to care here about output_nr? I just want to say\n// grad_fn-&gt;setOutputTo(i, v.input_port());\ngrad_fn-&gt;next_functions.emplace_back(v.grad_fn() ? v.grad_fn() : v.grad_accumulator(), v.output_nr());\n</code></pre>\n<p>to</p>\n<pre><code>grad_fn-&gt;add_next_edge(v.gradient_edge());\n</code></pre>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a></p>", "body_text": "This PR is the second (and final) refactoring of the autograd internals. After Variable, I now took on Function to give it a nice API and make it easier to work with from the JIT and interoperate better with the new Variable API.\nThis change was actually a lot easier than for Variable. I basically proceeded by making the public fields protected one-by-one, and adding proper accessors for the operations that user code were making. I then renamed next_functions to next_edges everywhere. Finally, I fixed some includes and added a ton of documentation.\nThere is now a discrepancy between the Python API and the C++ Function class in that for Python I kept the next_functions name, but used next_edges in C++, which is more accurate in light of the introduction of the Edge class.\nI ran into a slightly interesting/controversial design decision for how to create gradient edges (i.e. connecting Variables to Functions), especially when the number of inputs of the gradient function had to be incremented as well (i.e. a new gradient edge). Before this PR we had a lot of places like this:\nvariable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\n\nIt's certainly suboptimal that the user (even if it's just us) would have to mutate both variable and grad_fn to create the edge, and especially not forget to increment the grad_fn's number of inputs! So I wrapped it in a free function:\nvoid add_gradient_edge(Variable& variable, Function& function) {\n\tvariable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\n}\n\nThat left the case for when grad_fn.num_inputs wouldn't need to be incremented, i.e. when the input number to the gradient function would be known ahead of time. Here, calling variable.set_gradient_edge({grad_fn, input_nr}) would be fine. However, that would require us to use/remember two different APIs for the same action of adding a gradient edge. For this reason, I've made set_gradient_edge private in Variable, added an overload to add_gradient_edge to call set_gradient_edge and made that overload a friend of Variable. This way, autograd::add_gradient_edge is the one and only way to connect variables with their gradient edges.\nHappy to hear thoughts on naming and the API of the Function class. Recommended order of reviewing is torch/csrc/autograd/function.h and torch/csrc/autograd/variable.h, then everything else.\nBtw, at the end of these two PRs (including the Variable one), we will have gone from:\n// TODO: this kinda stuff is _way_ to low level to the public API of variable.\n// Why do I have to care here whether v has a grad_fn or grad accumulator?\n// Why do I have to care here about output_nr? I just want to say\n// grad_fn->setOutputTo(i, v.input_port());\ngrad_fn->next_functions.emplace_back(v.grad_fn() ? v.grad_fn() : v.grad_accumulator(), v.output_nr());\n\nto\ngrad_fn->add_next_edge(v.gradient_edge());\n\n@zdevito @apaszke @colesbury @ezyang", "body": "This PR is the second (and final) refactoring of the autograd internals. After `Variable`, I now took on `Function` to give it a nice API and make it easier to work with from the JIT and interoperate better with the new `Variable` API. \r\n\r\nThis change was actually a lot easier than for `Variable`. I basically proceeded by making the public fields protected one-by-one, and adding proper accessors for the operations that user code were making. I then renamed `next_functions` to `next_edges` everywhere. Finally, I fixed some includes and added a ton of documentation.\r\n\r\nThere is now a discrepancy between the Python API and the C++ `Function` class in that for Python I kept the `next_functions` name, but used `next_edges` in C++, which is more accurate in light of the introduction of the `Edge` class.\r\n\r\nI ran into a slightly interesting/controversial design decision for how to create gradient edges (i.e. connecting `Variable`s to `Function`s), especially when the number of inputs of the gradient function had to be incremented as well (i.e. a new gradient edge). Before this PR we had a lot of places like this:\r\n\r\n```\r\nvariable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\r\n```\r\n\r\nIt's certainly suboptimal that the user (even if it's just us) would have to mutate both `variable` and `grad_fn` to create the edge, and *especially* not forget to increment the `grad_fn`'s number of inputs! So I wrapped it in a free function:\r\n\r\n```\r\nvoid add_gradient_edge(Variable& variable, Function& function) {\r\n\tvariable.set_gradient_edge(Edge(grad_fn, grad_fn.num_inputs++));\r\n}\r\n```\r\n\r\nThat left the case for when `grad_fn.num_inputs` wouldn't need to be incremented, i.e. when the input number to the gradient function would be known ahead of time. Here, calling `variable.set_gradient_edge({grad_fn, input_nr})` would be fine. However, that would require us to use/remember two different APIs for the same action of adding a gradient edge. For this reason, I've made `set_gradient_edge` private in `Variable`, added an overload to `add_gradient_edge` to call `set_gradient_edge` and made that overload a `friend` of `Variable`. This way, `autograd::add_gradient_edge` is the one and only way to connect variables with their gradient edges.\r\n\r\nHappy to hear thoughts on naming and the API of the `Function` class. Recommended order of reviewing is `torch/csrc/autograd/function.h` and `torch/csrc/autograd/variable.h`, then everything else.\r\n\r\nBtw, at the end of these two PRs (including the `Variable` one), we will have gone from:\r\n\r\n```\r\n// TODO: this kinda stuff is _way_ to low level to the public API of variable.\r\n// Why do I have to care here whether v has a grad_fn or grad accumulator?\r\n// Why do I have to care here about output_nr? I just want to say\r\n// grad_fn->setOutputTo(i, v.input_port());\r\ngrad_fn->next_functions.emplace_back(v.grad_fn() ? v.grad_fn() : v.grad_accumulator(), v.output_nr());\r\n```\r\n\r\nto\r\n\r\n```\r\ngrad_fn->add_next_edge(v.gradient_edge());\r\n```\r\n\r\n@zdevito @apaszke @colesbury @ezyang "}