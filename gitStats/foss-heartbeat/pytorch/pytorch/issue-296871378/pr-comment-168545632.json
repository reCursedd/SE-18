{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/168545632", "pull_request_review_id": 96869478, "id": 168545632, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2ODU0NTYzMg==", "diff_hunk": "@@ -189,8 +185,13 @@ struct Variable : public at::Tensor {\n     }\n   }\n \n-  /// Returns the input index of the gradient `Function` to which this `Variable`\n-  /// is connected.\n+  /// Unset the gradient edge of the `Variable`.\n+  /// This will unset either the gradient function or gradient accumulator,\n+  /// depending on whether this `Variable` is a leaf or interior node.\n+  void remove_gradient_edge();", "path": "torch/csrc/autograd/variable.h", "position": null, "original_position": 60, "commit_id": "2820cf70a401e759ae67f8169c15f64b6dd628d0", "original_commit_id": "fbbfe675810f79e9d87f0239c892c3e16a23b976", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "How is that different from `detach_()`? Also, it seems like it's only used in a single place, that wasn't too bad, and I'd err on keeping the interface as small as possible. It will be much harder to write code in autograd when you'll have to remember the names of all accessors and setters/modifiers", "created_at": "2018-02-15T17:15:25Z", "updated_at": "2018-11-23T15:39:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/5221#discussion_r168545632", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5221", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/168545632"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5221#discussion_r168545632"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5221"}}, "body_html": "<p>How is that different from <code>detach_()</code>? Also, it seems like it's only used in a single place, that wasn't too bad, and I'd err on keeping the interface as small as possible. It will be much harder to write code in autograd when you'll have to remember the names of all accessors and setters/modifiers</p>", "body_text": "How is that different from detach_()? Also, it seems like it's only used in a single place, that wasn't too bad, and I'd err on keeping the interface as small as possible. It will be much harder to write code in autograd when you'll have to remember the names of all accessors and setters/modifiers"}