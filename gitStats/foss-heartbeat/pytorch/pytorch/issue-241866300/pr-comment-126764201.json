{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/126764201", "pull_request_review_id": 49279911, "id": 126764201, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyNjc2NDIwMQ==", "diff_hunk": "@@ -202,20 +202,20 @@ def normfn_attr(t, dim, keepdim=False):\n             fn_attr = getattr(torch, fn_name) if fn_name != \"norm\" else normfn_attr\n \n             def fn(t, dim, keepdim=False):\n-                ans = fn_attr(x, dim, keepdim)\n+                ans = fn_attr(x, dim, keepdim=keepdim)\n                 return ans if not isinstance(ans, tuple) else ans[0]\n \n             dim = random.randint(0, 2)\n-            self.assertEqual(fn(x, dim).unsqueeze(dim), fn(x, dim, True))\n+            self.assertEqual(fn(x, dim).unsqueeze(dim), fn(x, dim, keepdim=True))\n             self.assertEqual(x.ndimension() - 1, fn(x, dim).ndimension())\n-            self.assertEqual(x.ndimension(), fn(x, dim, True).ndimension())\n+            self.assertEqual(x.ndimension(), fn(x, dim, keepdim=True).ndimension())\n \n             # check 1-d behavior\n             x = torch.randn(1)\n             dim = 0\n-            self.assertEqual(fn(x, dim), fn(x, dim, True))\n+            self.assertEqual(fn(x, dim), fn(x, dim, keepdim=True))\n             self.assertEqual(x.ndimension(), fn(x, dim).ndimension())\n-            self.assertEqual(x.ndimension(), fn(x, dim, True).ndimension())\n+            self.assertEqual(x.ndimension(), fn(x, dim, keepdim=True).ndimension())", "path": "test/test_torch.py", "position": 22, "original_position": 22, "commit_id": "07b9aefa3da05f3ef108110cff0d9ebe43ab1b7a", "original_commit_id": "db5c110cb8e895891b5275ffa79c44b1162f2aca", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "body": "They weren't. I just kept commits separated before opening the PR, but the changes were in fact done in one sweep. Would you like me to squash the commits?", "created_at": "2017-07-11T18:01:00Z", "updated_at": "2018-11-23T15:34:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/2043#discussion_r126764201", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2043", "author_association": "COLLABORATOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/126764201"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2043#discussion_r126764201"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2043"}}, "body_html": "<p>They weren't. I just kept commits separated before opening the PR, but the changes were in fact done in one sweep. Would you like me to squash the commits?</p>", "body_text": "They weren't. I just kept commits separated before opening the PR, but the changes were in fact done in one sweep. Would you like me to squash the commits?", "in_reply_to_id": 126748898}