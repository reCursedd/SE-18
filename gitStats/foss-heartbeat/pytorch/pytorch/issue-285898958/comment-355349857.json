{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355349857", "html_url": "https://github.com/pytorch/pytorch/pull/4471#issuecomment-355349857", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4471", "id": 355349857, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTM0OTg1Nw==", "user": {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T17:46:19Z", "updated_at": "2018-01-04T17:46:19Z", "author_association": "MEMBER", "body_html": "<p>And we can see the threshold_forward in AlexNet, DenseNet, Inception, ResNet, SqueezeNet, VGG.<br>\nHere I only post AlextNet trace:</p>\n<pre><code>ERROR: test_alexnet (__main__.TestModels)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test_models.py\", line 101, in test_alexnet\n    self.exportTest(toC(AlexNet()), toC(x))\n  File \"test_models.py\", line 48, in exportTest\n    binary_pb = export_to_string(model, inputs, export_params=False)\n  File \"test_models.py\", line 42, in export_to_string\n    torch.onnx.export(model, inputs, f, *args, **kwargs)\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 83, in export\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 152, in _export\n    proto = trace.export([], _onnx_opset_version)\nRuntimeError: ONNX export failed: Couldn't export operator threshold_forward\n\nGraph we tried to export:\ngraph(%0 : Float(2, 3, 224, 224)\n      %1 : Float(64, 3, 11, 11)\n      %2 : Float(64)\n      %3 : Float(192, 64, 5, 5)\n      %4 : Float(192)\n      %5 : Float(384, 192, 3, 3)\n      %6 : Float(384)\n      %7 : Float(256, 384, 3, 3)\n      %8 : Float(256)\n      %9 : Float(256, 256, 3, 3)\n      %10 : Float(256)\n      %11 : Float(4096, 9216)\n      %12 : Float(4096)\n      %13 : Float(4096, 4096)\n      %14 : Float(4096)\n      %15 : Float(1000, 4096)\n      %16 : Float(1000)) {\n  %17 : Float(2, 64, 55, 55) = Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%0, %1, %2), scope: AlexNet/Sequential[features]/Conv2d[0]\n  %18 : Float(2, 64, 55, 55) = threshold_forward[threshold={0}, value={0}](%17), scope: AlexNet/Sequential[features]/ReLU[1]\n  %19 : Float(2, 64, 55, 55) = Relu(%18), scope: AlexNet/Sequential[features]/ReLU[1]\n  %20 : Float(2, 64, 27, 27) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%19), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n  %21 : Float(2, 192, 27, 27) = Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%20, %3, %4), scope: AlexNet/Sequential[features]/Conv2d[3]\n  %22 : Float(2, 192, 27, 27) = threshold_forward[threshold={0}, value={0}](%21), scope: AlexNet/Sequential[features]/ReLU[4]\n  %23 : Float(2, 192, 27, 27) = Relu(%22), scope: AlexNet/Sequential[features]/ReLU[4]\n  %24 : Float(2, 192, 13, 13) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%23), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n  %25 : Float(2, 384, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %5, %6), scope: AlexNet/Sequential[features]/Conv2d[6]\n  %26 : Float(2, 384, 13, 13) = threshold_forward[threshold={0}, value={0}](%25), scope: AlexNet/Sequential[features]/ReLU[7]\n  %27 : Float(2, 384, 13, 13) = Relu(%26), scope: AlexNet/Sequential[features]/ReLU[7]\n  %28 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%27, %7, %8), scope: AlexNet/Sequential[features]/Conv2d[8]\n  %29 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%28), scope: AlexNet/Sequential[features]/ReLU[9]\n  %30 : Float(2, 256, 13, 13) = Relu(%29), scope: AlexNet/Sequential[features]/ReLU[9]\n  %31 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%30, %9, %10), scope: AlexNet/Sequential[features]/Conv2d[10]\n  %32 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%31), scope: AlexNet/Sequential[features]/ReLU[11]\n  %33 : Float(2, 256, 13, 13) = Relu(%32), scope: AlexNet/Sequential[features]/ReLU[11]\n  %34 : Float(2, 256, 6, 6) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%33), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n  %35 : Float(2, 9216) = Flatten[axis=1](%34), scope: AlexNet\n  %36 : Float(2, 9216), %37 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%35), scope: AlexNet/Sequential[classifier]/Dropout[0]\n  %38 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%36, %11, %12), scope: AlexNet/Sequential[classifier]/Linear[1]\n  %39 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%38), scope: AlexNet/Sequential[classifier]/ReLU[2]\n  %40 : Float(2, 4096) = Relu(%39), scope: AlexNet/Sequential[classifier]/ReLU[2]\n  %41 : Float(2, 4096), %42 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%40), scope: AlexNet/Sequential[classifier]/Dropout[3]\n  %43 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%41, %13, %14), scope: AlexNet/Sequential[classifier]/Linear[4]\n  %44 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%43), scope: AlexNet/Sequential[classifier]/ReLU[5]\n  %45 : Float(2, 4096) = Relu(%44), scope: AlexNet/Sequential[classifier]/ReLU[5]\n  %46 : Float(2, 1000) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %15, %16), scope: AlexNet/Sequential[classifier]/Linear[6]\n  return (%46);\n}\n</code></pre>", "body_text": "And we can see the threshold_forward in AlexNet, DenseNet, Inception, ResNet, SqueezeNet, VGG.\nHere I only post AlextNet trace:\nERROR: test_alexnet (__main__.TestModels)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test_models.py\", line 101, in test_alexnet\n    self.exportTest(toC(AlexNet()), toC(x))\n  File \"test_models.py\", line 48, in exportTest\n    binary_pb = export_to_string(model, inputs, export_params=False)\n  File \"test_models.py\", line 42, in export_to_string\n    torch.onnx.export(model, inputs, f, *args, **kwargs)\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 83, in export\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 152, in _export\n    proto = trace.export([], _onnx_opset_version)\nRuntimeError: ONNX export failed: Couldn't export operator threshold_forward\n\nGraph we tried to export:\ngraph(%0 : Float(2, 3, 224, 224)\n      %1 : Float(64, 3, 11, 11)\n      %2 : Float(64)\n      %3 : Float(192, 64, 5, 5)\n      %4 : Float(192)\n      %5 : Float(384, 192, 3, 3)\n      %6 : Float(384)\n      %7 : Float(256, 384, 3, 3)\n      %8 : Float(256)\n      %9 : Float(256, 256, 3, 3)\n      %10 : Float(256)\n      %11 : Float(4096, 9216)\n      %12 : Float(4096)\n      %13 : Float(4096, 4096)\n      %14 : Float(4096)\n      %15 : Float(1000, 4096)\n      %16 : Float(1000)) {\n  %17 : Float(2, 64, 55, 55) = Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%0, %1, %2), scope: AlexNet/Sequential[features]/Conv2d[0]\n  %18 : Float(2, 64, 55, 55) = threshold_forward[threshold={0}, value={0}](%17), scope: AlexNet/Sequential[features]/ReLU[1]\n  %19 : Float(2, 64, 55, 55) = Relu(%18), scope: AlexNet/Sequential[features]/ReLU[1]\n  %20 : Float(2, 64, 27, 27) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%19), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n  %21 : Float(2, 192, 27, 27) = Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%20, %3, %4), scope: AlexNet/Sequential[features]/Conv2d[3]\n  %22 : Float(2, 192, 27, 27) = threshold_forward[threshold={0}, value={0}](%21), scope: AlexNet/Sequential[features]/ReLU[4]\n  %23 : Float(2, 192, 27, 27) = Relu(%22), scope: AlexNet/Sequential[features]/ReLU[4]\n  %24 : Float(2, 192, 13, 13) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%23), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n  %25 : Float(2, 384, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %5, %6), scope: AlexNet/Sequential[features]/Conv2d[6]\n  %26 : Float(2, 384, 13, 13) = threshold_forward[threshold={0}, value={0}](%25), scope: AlexNet/Sequential[features]/ReLU[7]\n  %27 : Float(2, 384, 13, 13) = Relu(%26), scope: AlexNet/Sequential[features]/ReLU[7]\n  %28 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%27, %7, %8), scope: AlexNet/Sequential[features]/Conv2d[8]\n  %29 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%28), scope: AlexNet/Sequential[features]/ReLU[9]\n  %30 : Float(2, 256, 13, 13) = Relu(%29), scope: AlexNet/Sequential[features]/ReLU[9]\n  %31 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%30, %9, %10), scope: AlexNet/Sequential[features]/Conv2d[10]\n  %32 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%31), scope: AlexNet/Sequential[features]/ReLU[11]\n  %33 : Float(2, 256, 13, 13) = Relu(%32), scope: AlexNet/Sequential[features]/ReLU[11]\n  %34 : Float(2, 256, 6, 6) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%33), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n  %35 : Float(2, 9216) = Flatten[axis=1](%34), scope: AlexNet\n  %36 : Float(2, 9216), %37 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%35), scope: AlexNet/Sequential[classifier]/Dropout[0]\n  %38 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%36, %11, %12), scope: AlexNet/Sequential[classifier]/Linear[1]\n  %39 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%38), scope: AlexNet/Sequential[classifier]/ReLU[2]\n  %40 : Float(2, 4096) = Relu(%39), scope: AlexNet/Sequential[classifier]/ReLU[2]\n  %41 : Float(2, 4096), %42 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%40), scope: AlexNet/Sequential[classifier]/Dropout[3]\n  %43 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%41, %13, %14), scope: AlexNet/Sequential[classifier]/Linear[4]\n  %44 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%43), scope: AlexNet/Sequential[classifier]/ReLU[5]\n  %45 : Float(2, 4096) = Relu(%44), scope: AlexNet/Sequential[classifier]/ReLU[5]\n  %46 : Float(2, 1000) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %15, %16), scope: AlexNet/Sequential[classifier]/Linear[6]\n  return (%46);\n}", "body": "And we can see the threshold_forward in AlexNet, DenseNet, Inception, ResNet, SqueezeNet, VGG.\r\nHere I only post AlextNet trace:\r\n```\r\nERROR: test_alexnet (__main__.TestModels)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test_models.py\", line 101, in test_alexnet\r\n    self.exportTest(toC(AlexNet()), toC(x))\r\n  File \"test_models.py\", line 48, in exportTest\r\n    binary_pb = export_to_string(model, inputs, export_params=False)\r\n  File \"test_models.py\", line 42, in export_to_string\r\n    torch.onnx.export(model, inputs, f, *args, **kwargs)\r\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 83, in export\r\n    _export(model, args, f, export_params, verbose, training, input_names, output_names)\r\n  File \"/home/lufang/gitrepos/onnx-fb-universe/repos/pytorch/torch/onnx/__init__.py\", line 152, in _export\r\n    proto = trace.export([], _onnx_opset_version)\r\nRuntimeError: ONNX export failed: Couldn't export operator threshold_forward\r\n\r\nGraph we tried to export:\r\ngraph(%0 : Float(2, 3, 224, 224)\r\n      %1 : Float(64, 3, 11, 11)\r\n      %2 : Float(64)\r\n      %3 : Float(192, 64, 5, 5)\r\n      %4 : Float(192)\r\n      %5 : Float(384, 192, 3, 3)\r\n      %6 : Float(384)\r\n      %7 : Float(256, 384, 3, 3)\r\n      %8 : Float(256)\r\n      %9 : Float(256, 256, 3, 3)\r\n      %10 : Float(256)\r\n      %11 : Float(4096, 9216)\r\n      %12 : Float(4096)\r\n      %13 : Float(4096, 4096)\r\n      %14 : Float(4096)\r\n      %15 : Float(1000, 4096)\r\n      %16 : Float(1000)) {\r\n  %17 : Float(2, 64, 55, 55) = Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%0, %1, %2), scope: AlexNet/Sequential[features]/Conv2d[0]\r\n  %18 : Float(2, 64, 55, 55) = threshold_forward[threshold={0}, value={0}](%17), scope: AlexNet/Sequential[features]/ReLU[1]\r\n  %19 : Float(2, 64, 55, 55) = Relu(%18), scope: AlexNet/Sequential[features]/ReLU[1]\r\n  %20 : Float(2, 64, 27, 27) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%19), scope: AlexNet/Sequential[features]/MaxPool2d[2]\r\n  %21 : Float(2, 192, 27, 27) = Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%20, %3, %4), scope: AlexNet/Sequential[features]/Conv2d[3]\r\n  %22 : Float(2, 192, 27, 27) = threshold_forward[threshold={0}, value={0}](%21), scope: AlexNet/Sequential[features]/ReLU[4]\r\n  %23 : Float(2, 192, 27, 27) = Relu(%22), scope: AlexNet/Sequential[features]/ReLU[4]\r\n  %24 : Float(2, 192, 13, 13) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%23), scope: AlexNet/Sequential[features]/MaxPool2d[5]\r\n  %25 : Float(2, 384, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %5, %6), scope: AlexNet/Sequential[features]/Conv2d[6]\r\n  %26 : Float(2, 384, 13, 13) = threshold_forward[threshold={0}, value={0}](%25), scope: AlexNet/Sequential[features]/ReLU[7]\r\n  %27 : Float(2, 384, 13, 13) = Relu(%26), scope: AlexNet/Sequential[features]/ReLU[7]\r\n  %28 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%27, %7, %8), scope: AlexNet/Sequential[features]/Conv2d[8]\r\n  %29 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%28), scope: AlexNet/Sequential[features]/ReLU[9]\r\n  %30 : Float(2, 256, 13, 13) = Relu(%29), scope: AlexNet/Sequential[features]/ReLU[9]\r\n  %31 : Float(2, 256, 13, 13) = Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%30, %9, %10), scope: AlexNet/Sequential[features]/Conv2d[10]\r\n  %32 : Float(2, 256, 13, 13) = threshold_forward[threshold={0}, value={0}](%31), scope: AlexNet/Sequential[features]/ReLU[11]\r\n  %33 : Float(2, 256, 13, 13) = Relu(%32), scope: AlexNet/Sequential[features]/ReLU[11]\r\n  %34 : Float(2, 256, 6, 6) = MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%33), scope: AlexNet/Sequential[features]/MaxPool2d[12]\r\n  %35 : Float(2, 9216) = Flatten[axis=1](%34), scope: AlexNet\r\n  %36 : Float(2, 9216), %37 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%35), scope: AlexNet/Sequential[classifier]/Dropout[0]\r\n  %38 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%36, %11, %12), scope: AlexNet/Sequential[classifier]/Linear[1]\r\n  %39 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%38), scope: AlexNet/Sequential[classifier]/ReLU[2]\r\n  %40 : Float(2, 4096) = Relu(%39), scope: AlexNet/Sequential[classifier]/ReLU[2]\r\n  %41 : Float(2, 4096), %42 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%40), scope: AlexNet/Sequential[classifier]/Dropout[3]\r\n  %43 : Float(2, 4096) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%41, %13, %14), scope: AlexNet/Sequential[classifier]/Linear[4]\r\n  %44 : Float(2, 4096) = threshold_forward[threshold={0}, value={0}](%43), scope: AlexNet/Sequential[classifier]/ReLU[5]\r\n  %45 : Float(2, 4096) = Relu(%44), scope: AlexNet/Sequential[classifier]/ReLU[5]\r\n  %46 : Float(2, 1000) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %15, %16), scope: AlexNet/Sequential[classifier]/Linear[6]\r\n  return (%46);\r\n}\r\n```"}