{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422104539", "html_url": "https://github.com/pytorch/pytorch/issues/975#issuecomment-422104539", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/975", "id": 422104539, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjEwNDUzOQ==", "user": {"login": "streamnsight", "id": 10981776, "node_id": "MDQ6VXNlcjEwOTgxNzc2", "avatar_url": "https://avatars1.githubusercontent.com/u/10981776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/streamnsight", "html_url": "https://github.com/streamnsight", "followers_url": "https://api.github.com/users/streamnsight/followers", "following_url": "https://api.github.com/users/streamnsight/following{/other_user}", "gists_url": "https://api.github.com/users/streamnsight/gists{/gist_id}", "starred_url": "https://api.github.com/users/streamnsight/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/streamnsight/subscriptions", "organizations_url": "https://api.github.com/users/streamnsight/orgs", "repos_url": "https://api.github.com/users/streamnsight/repos", "events_url": "https://api.github.com/users/streamnsight/events{/privacy}", "received_events_url": "https://api.github.com/users/streamnsight/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-17T17:35:56Z", "updated_at": "2018-09-17T17:35:56Z", "author_association": "NONE", "body_html": "<p>I can also report that I see <code>set_num_thread</code> has no effect</p>\n<p>Another 'funny' behavior I notice using the <code>OMP_NUM_THREADS</code> and <code>MKL_NUM_THREADS</code> variables, is that with my machine, a Dual Xeon, setting those to <code>N</code> ends up spinning <code>2N</code> threads except for N=1, so <code>OMP_NUM_THREADS=2</code> results in 4 threads, <code>OMP_NUM_THREADS=3</code> results in 6 threads etc...</p>\n<p>I'm using a simple nn.Linear layer for testing and I don't see a drastic improvement using multiple threads. It actually seems to saturate at 12 threads (i.e. no further gain in speed) and the speed gain is definitely not linear (i.e. from 1-&gt;2 threads I get a 50% gain, 2-&gt;4 ~20%, 4-&gt;6, ~10%)</p>\n<p>I'm confused about what I can expect as a gain from the multi processing capability. It seems to bring a LOT of overhead.</p>", "body_text": "I can also report that I see set_num_thread has no effect\nAnother 'funny' behavior I notice using the OMP_NUM_THREADS and MKL_NUM_THREADS variables, is that with my machine, a Dual Xeon, setting those to N ends up spinning 2N threads except for N=1, so OMP_NUM_THREADS=2 results in 4 threads, OMP_NUM_THREADS=3 results in 6 threads etc...\nI'm using a simple nn.Linear layer for testing and I don't see a drastic improvement using multiple threads. It actually seems to saturate at 12 threads (i.e. no further gain in speed) and the speed gain is definitely not linear (i.e. from 1->2 threads I get a 50% gain, 2->4 ~20%, 4->6, ~10%)\nI'm confused about what I can expect as a gain from the multi processing capability. It seems to bring a LOT of overhead.", "body": "I can also report that I see `set_num_thread` has no effect\r\n\r\nAnother 'funny' behavior I notice using the `OMP_NUM_THREADS` and `MKL_NUM_THREADS` variables, is that with my machine, a Dual Xeon, setting those to `N` ends up spinning `2N` threads except for N=1, so `OMP_NUM_THREADS=2` results in 4 threads, `OMP_NUM_THREADS=3` results in 6 threads etc...\r\n\r\nI'm using a simple nn.Linear layer for testing and I don't see a drastic improvement using multiple threads. It actually seems to saturate at 12 threads (i.e. no further gain in speed) and the speed gain is definitely not linear (i.e. from 1->2 threads I get a 50% gain, 2->4 ~20%, 4->6, ~10%)\r\n\r\nI'm confused about what I can expect as a gain from the multi processing capability. It seems to bring a LOT of overhead.\r\n"}