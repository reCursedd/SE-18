{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/286254092", "html_url": "https://github.com/pytorch/pytorch/issues/975#issuecomment-286254092", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/975", "id": 286254092, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjI1NDA5Mg==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-13T21:46:48Z", "updated_at": "2017-03-13T21:46:48Z", "author_association": "MEMBER", "body_html": "<p>Actually, it looks like things work with <code>libiomp5.so</code>. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.</p>\n<p>After <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a>'s change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.</p>\n<p>The other thing is that <code>torch.set_num_threads()</code> only affects the current process. If you launch a child process, then you have to call <code>torch.set_num_threads()</code> in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable <code>OMP_NUM_THREADS</code> is inherited by child processes, like other environment variables.</p>", "body_text": "Actually, it looks like things work with libiomp5.so. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.\nAfter @ngimel's change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.\nThe other thing is that torch.set_num_threads() only affects the current process. If you launch a child process, then you have to call torch.set_num_threads() in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable OMP_NUM_THREADS is inherited by child processes, like other environment variables.", "body": "Actually, it looks like things work with `libiomp5.so`. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.\r\n\r\nAfter @ngimel's change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.\r\n\r\nThe other thing is that `torch.set_num_threads()` only affects the current process. If you launch a child process, then you have to call `torch.set_num_threads()` in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable `OMP_NUM_THREADS` is inherited by child processes, like other environment variables."}