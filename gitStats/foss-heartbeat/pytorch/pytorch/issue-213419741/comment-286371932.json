{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/286371932", "html_url": "https://github.com/pytorch/pytorch/issues/975#issuecomment-286371932", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/975", "id": 286371932, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjM3MTkzMg==", "user": {"login": "floringogianu", "id": 1670348, "node_id": "MDQ6VXNlcjE2NzAzNDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1670348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/floringogianu", "html_url": "https://github.com/floringogianu", "followers_url": "https://api.github.com/users/floringogianu/followers", "following_url": "https://api.github.com/users/floringogianu/following{/other_user}", "gists_url": "https://api.github.com/users/floringogianu/gists{/gist_id}", "starred_url": "https://api.github.com/users/floringogianu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/floringogianu/subscriptions", "organizations_url": "https://api.github.com/users/floringogianu/orgs", "repos_url": "https://api.github.com/users/floringogianu/repos", "events_url": "https://api.github.com/users/floringogianu/events{/privacy}", "received_events_url": "https://api.github.com/users/floringogianu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-14T09:50:13Z", "updated_at": "2017-03-14T09:51:06Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>Actually, it looks like things work with libiomp5.so. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.</p>\n</blockquote>\n<p>Is there anything besides <code>export CMAKE_PREFIX_PATH=[anaconda root directory]</code> you are doing to control the installation environment? Maybe you are also creating a conda virtual env? Because for some reasons <code>libTH.so.1</code> is not linking properly for me (see above.)</p>\n<blockquote>\n<p>After <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a>'s change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.</p>\n</blockquote>\n<p>Yes, this is what I am seeing too. That on the backward pass torch launches more threads than optimal. And that in multiprocessing programs <code>set.num.threads()</code> has no effect. Setting <code>OMP_NUM_THREADS</code> helps but compared to @761d679 it's still about 3x slower.</p>\n<blockquote>\n<p>The other thing is that torch.set_num_threads() only affects the current process. If you launch a child process, then you have to call torch.set_num_threads() in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable OMP_NUM_THREADS is inherited by child processes, like other environment variables.</p>\n</blockquote>\n<p>Yes, I'm careful to <code>set_num_threads()</code> on each process I launch. However with the most recent commits I also need to set <code>OMP_NUM_THREADS</code>.</p>\n<p>But what's more baffling is that for some reason @761d679 is the only recent commit that:</p>\n<ul>\n<li>consistently builds properly,</li>\n<li>uses the correct no of threads on the backward pass,</li>\n<li>picks the correct no of OpenMP threads (without setting any flags) and</li>\n<li>offers the best performance figures in the benchmarks we posted and with the programs we are running.</li>\n</ul>\n<p>This despite the fact that <code>ldd</code> shows that <code>libTH.so.1</code> links the same as in all other cases.</p>", "body_text": "Actually, it looks like things work with libiomp5.so. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.\n\nIs there anything besides export CMAKE_PREFIX_PATH=[anaconda root directory] you are doing to control the installation environment? Maybe you are also creating a conda virtual env? Because for some reasons libTH.so.1 is not linking properly for me (see above.)\n\nAfter @ngimel's change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.\n\nYes, this is what I am seeing too. That on the backward pass torch launches more threads than optimal. And that in multiprocessing programs set.num.threads() has no effect. Setting OMP_NUM_THREADS helps but compared to @761d679 it's still about 3x slower.\n\nThe other thing is that torch.set_num_threads() only affects the current process. If you launch a child process, then you have to call torch.set_num_threads() in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable OMP_NUM_THREADS is inherited by child processes, like other environment variables.\n\nYes, I'm careful to set_num_threads() on each process I launch. However with the most recent commits I also need to set OMP_NUM_THREADS.\nBut what's more baffling is that for some reason @761d679 is the only recent commit that:\n\nconsistently builds properly,\nuses the correct no of threads on the backward pass,\npicks the correct no of OpenMP threads (without setting any flags) and\noffers the best performance figures in the benchmarks we posted and with the programs we are running.\n\nThis despite the fact that ldd shows that libTH.so.1 links the same as in all other cases.", "body": "> Actually, it looks like things work with libiomp5.so. I've tested the latest PyTorch on a clean Anaconda installation on EC2's Ubunut 16.04 instance. Both forward and backward use the correct number of OpenMP threads.\r\n\r\nIs there anything besides `export CMAKE_PREFIX_PATH=[anaconda root directory]` you are doing to control the installation environment? Maybe you are also creating a conda virtual env? Because for some reasons `libTH.so.1` is not linking properly for me (see above.)\r\n\r\n> After @ngimel's change, MKL now uses more than one thread by default. OpenMP by default uses the same number of threads as CPUs which is often too many and slows things down. Perhaps this is what you saw.\r\n\r\nYes, this is what I am seeing too. That on the backward pass torch launches more threads than optimal. And that in multiprocessing programs `set.num.threads()` has no effect. Setting `OMP_NUM_THREADS` helps but compared to @761d679 it's still about 3x slower.\r\n\r\n> The other thing is that torch.set_num_threads() only affects the current process. If you launch a child process, then you have to call torch.set_num_threads() in that process as well. (I see you're doing this in mp_benchmark.py) The environment variable OMP_NUM_THREADS is inherited by child processes, like other environment variables.\r\n\r\nYes, I'm careful to `set_num_threads()` on each process I launch. However with the most recent commits I also need to set `OMP_NUM_THREADS`. \r\n\r\nBut what's more baffling is that for some reason @761d679 is the only recent commit that: \r\n- consistently builds properly, \r\n- uses the correct no of threads on the backward pass, \r\n- picks the correct no of OpenMP threads (without setting any flags) and\r\n- offers the best performance figures in the benchmarks we posted and with the programs we are running.\r\n\r\nThis despite the fact that `ldd` shows that `libTH.so.1` links the same as in all other cases."}