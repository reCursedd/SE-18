{"url": "https://api.github.com/repos/pytorch/pytorch/issues/975", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/975/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/975/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/975/events", "html_url": "https://github.com/pytorch/pytorch/issues/975", "id": 213419741, "node_id": "MDU6SXNzdWUyMTM0MTk3NDE=", "number": 975, "title": "pytorch not respecting torch.set_num_threads", "user": {"login": "tudor-berariu", "id": 1908458, "node_id": "MDQ6VXNlcjE5MDg0NTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1908458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tudor-berariu", "html_url": "https://github.com/tudor-berariu", "followers_url": "https://api.github.com/users/tudor-berariu/followers", "following_url": "https://api.github.com/users/tudor-berariu/following{/other_user}", "gists_url": "https://api.github.com/users/tudor-berariu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tudor-berariu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tudor-berariu/subscriptions", "organizations_url": "https://api.github.com/users/tudor-berariu/orgs", "repos_url": "https://api.github.com/users/tudor-berariu/repos", "events_url": "https://api.github.com/users/tudor-berariu/events{/privacy}", "received_events_url": "https://api.github.com/users/tudor-berariu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 42, "created_at": "2017-03-10T18:42:35Z", "updated_at": "2018-09-17T17:35:56Z", "closed_at": "2018-04-10T14:30:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In a recent update we observed an important performance fall in the backward phase on all our projects.</p>\n<p>We used this <a href=\"https://github.com/bit-ml/tensor-benchmarks/blob/master/nn_benchmark.py\">benchmark</a> to measure the computation times for the forward and the backward phases in a simple neural model.</p>\n<p>In summary we observed that the oldest commit with good performance is @761d679. The following commit (@65b6626) introduces a huge amount of extra time during error backpropagation. The current performance (which we belive dates from commit @15a9fbd) is a bit better than that, but still worse than @761d679.</p>\n<p>Here are some running times we got with our benchmark on a Lenovo Y50 with Intel i7-4710HQ CPU @ 2.50GHz and nVidia GeForce 860M. We got similar results on GeForce 960M and Titan X (not shown here). (edited)</p>\n<ul>\n<li>commit @761d679</li>\n</ul>\n<pre><code>---------- FORWARD ----------\nFORWARD @ CPU ===&gt; 4.0940 s.\nFORWARD @ GPU ===&gt; 1.2921 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===&gt; 9.2027 s.\nBACKWARD @ GPU ===&gt; 2.1065 s.\n</code></pre>\n<ul>\n<li>commit @65b6626</li>\n</ul>\n<pre><code>---------- FORWARD ----------\nFORWARD @ CPU ===&gt; 13.5454 s.\nFORWARD @ GPU ===&gt; 1.3190 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===&gt; 22.9335 s.\nBACKWARD @ GPU ===&gt; 2.1490 s.\n</code></pre>\n<ul>\n<li>commit @15a9fbd</li>\n</ul>\n<pre><code>---------- FORWARD ----------\nFORWARD @ CPU ===&gt; 4.1922 s.\nFORWARD @ GPU ===&gt; 1.2867 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===&gt; 15.0562 s.\nBACKWARD @ GPU ===&gt; 2.2064 s.\n</code></pre>\n<ul>\n<li>latest version (performance is similar with @15a9fbd)</li>\n</ul>\n<pre><code>---------- FORWARD ----------\nFORWARD @ CPU ===&gt; 4.2619 s.\nFORWARD @ GPU ===&gt; 1.2833 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===&gt; 16.4800 s.\nBACKWARD @ GPU ===&gt; 2.0648 s.\n</code></pre>\n<p>Is this performance trade-off expected and accounted for?</p>", "body_text": "In a recent update we observed an important performance fall in the backward phase on all our projects.\nWe used this benchmark to measure the computation times for the forward and the backward phases in a simple neural model.\nIn summary we observed that the oldest commit with good performance is @761d679. The following commit (@65b6626) introduces a huge amount of extra time during error backpropagation. The current performance (which we belive dates from commit @15a9fbd) is a bit better than that, but still worse than @761d679.\nHere are some running times we got with our benchmark on a Lenovo Y50 with Intel i7-4710HQ CPU @ 2.50GHz and nVidia GeForce 860M. We got similar results on GeForce 960M and Titan X (not shown here). (edited)\n\ncommit @761d679\n\n---------- FORWARD ----------\nFORWARD @ CPU ===> 4.0940 s.\nFORWARD @ GPU ===> 1.2921 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===> 9.2027 s.\nBACKWARD @ GPU ===> 2.1065 s.\n\n\ncommit @65b6626\n\n---------- FORWARD ----------\nFORWARD @ CPU ===> 13.5454 s.\nFORWARD @ GPU ===> 1.3190 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===> 22.9335 s.\nBACKWARD @ GPU ===> 2.1490 s.\n\n\ncommit @15a9fbd\n\n---------- FORWARD ----------\nFORWARD @ CPU ===> 4.1922 s.\nFORWARD @ GPU ===> 1.2867 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===> 15.0562 s.\nBACKWARD @ GPU ===> 2.2064 s.\n\n\nlatest version (performance is similar with @15a9fbd)\n\n---------- FORWARD ----------\nFORWARD @ CPU ===> 4.2619 s.\nFORWARD @ GPU ===> 1.2833 s.\n---------- BACKWARD ----------\nBACKWARD @ CPU ===> 16.4800 s.\nBACKWARD @ GPU ===> 2.0648 s.\n\nIs this performance trade-off expected and accounted for?", "body": "In a recent update we observed an important performance fall in the backward phase on all our projects.\r\n\r\nWe used this [benchmark](https://github.com/bit-ml/tensor-benchmarks/blob/master/nn_benchmark.py) to measure the computation times for the forward and the backward phases in a simple neural model.\r\n\r\nIn summary we observed that the oldest commit with good performance is @761d679. The following commit (@65b6626) introduces a huge amount of extra time during error backpropagation. The current performance (which we belive dates from commit @15a9fbd) is a bit better than that, but still worse than @761d679.\r\n\r\n\r\nHere are some running times we got with our benchmark on a Lenovo Y50 with Intel i7-4710HQ CPU @ 2.50GHz and nVidia GeForce 860M. We got similar results on GeForce 960M and Titan X (not shown here). (edited)\r\n\r\n- commit @761d679\r\n```\r\n---------- FORWARD ----------\r\nFORWARD @ CPU ===> 4.0940 s.\r\nFORWARD @ GPU ===> 1.2921 s.\r\n---------- BACKWARD ----------\r\nBACKWARD @ CPU ===> 9.2027 s.\r\nBACKWARD @ GPU ===> 2.1065 s.\r\n```\r\n- commit @65b6626\r\n```\r\n---------- FORWARD ----------\r\nFORWARD @ CPU ===> 13.5454 s.\r\nFORWARD @ GPU ===> 1.3190 s.\r\n---------- BACKWARD ----------\r\nBACKWARD @ CPU ===> 22.9335 s.\r\nBACKWARD @ GPU ===> 2.1490 s.\r\n```\r\n\r\n- commit @15a9fbd\r\n```\r\n---------- FORWARD ----------\r\nFORWARD @ CPU ===> 4.1922 s.\r\nFORWARD @ GPU ===> 1.2867 s.\r\n---------- BACKWARD ----------\r\nBACKWARD @ CPU ===> 15.0562 s.\r\nBACKWARD @ GPU ===> 2.2064 s.\r\n```\r\n\r\n- latest version (performance is similar with @15a9fbd)\r\n```\r\n---------- FORWARD ----------\r\nFORWARD @ CPU ===> 4.2619 s.\r\nFORWARD @ GPU ===> 1.2833 s.\r\n---------- BACKWARD ----------\r\nBACKWARD @ CPU ===> 16.4800 s.\r\nBACKWARD @ GPU ===> 2.0648 s.\r\n```\r\n\r\nIs this performance trade-off expected and accounted for?"}