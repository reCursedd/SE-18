{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/313075000", "html_url": "https://github.com/pytorch/pytorch/issues/1979#issuecomment-313075000", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1979", "id": 313075000, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzA3NTAwMA==", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-05T11:19:11Z", "updated_at": "2017-07-05T11:19:11Z", "author_association": "COLLABORATOR", "body_html": "<p>The <code>ConvNd</code> that is used here is an <code>autograd.Function</code> not an <code>nn.Module</code> (this is not the <code>_ConvNd</code> from nn/modules/conv.py<code>but a function declared from cpp), it does not have a state nor knows about</code>nn.Parameter<code>. The </code>weight<code>s are given at the same time as the </code>input` when performing the computation.</p>\n<p>In your previous question, the backend (cpp library) that contains the embedding layer is <code>thnn</code>, you can find it in <code>torch.nn.backends.thnn.backend</code> where you can access the <code>autograd.Function</code> called <code>Embedding</code> thus replacing <code>self._backend.Embedding</code> with <code>nn.backends.thnn.backend.Embedding</code>.</p>", "body_text": "The ConvNd that is used here is an autograd.Function not an nn.Module (this is not the _ConvNd from nn/modules/conv.pybut a function declared from cpp), it does not have a state nor knows aboutnn.Parameter. The weights are given at the same time as the input` when performing the computation.\nIn your previous question, the backend (cpp library) that contains the embedding layer is thnn, you can find it in torch.nn.backends.thnn.backend where you can access the autograd.Function called Embedding thus replacing self._backend.Embedding with nn.backends.thnn.backend.Embedding.", "body": "The `ConvNd` that is used here is an `autograd.Function` not an `nn.Module` (this is not the `_ConvNd` from nn/modules/conv.py` but a function declared from cpp), it does not have a state nor knows about `nn.Parameter`.\r\nThe `weight`s are given at the same time as the `input` when performing the computation.\r\n\r\nIn your previous question, the backend (cpp library) that contains the embedding layer is `thnn`, you can find it in `torch.nn.backends.thnn.backend` where you can access the `autograd.Function` called `Embedding` thus replacing `self._backend.Embedding` with `nn.backends.thnn.backend.Embedding`."}