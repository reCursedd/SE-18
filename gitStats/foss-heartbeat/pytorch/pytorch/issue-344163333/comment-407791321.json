{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407791321", "html_url": "https://github.com/pytorch/pytorch/issues/9778#issuecomment-407791321", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9778", "id": 407791321, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzc5MTMyMQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-25T15:17:07Z", "updated_at": "2018-07-25T15:21:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am relatively sure because I double checked. What happens is that <code>a[m] = something</code> translates to the Python <code>__setitem__</code> method, where the slicing is handled as a view. When you have <code>a[m]</code> \"anywhere else than in an assignment\", it will translate to <code>__getitem__</code>. That returns a tensor with new storage when used with boolean indexing. It's not limited to <code>clamp_</code>, either, any inplace (e.g. <code>.add_(1000)</code>) will have the same behaviour.<br>\nTo implement the behaviour you expect, you would essentially need to introduce a new \"tensor view\" object (or extend tensor to be able to use one), which is a rather hefty feature request. I'm not saying that it's unreasonable to desire that behaviour, it's just that for implementation you essentially have to wrap a whole \"viewing that cannot be represented by strides\" layer around what PyTorch currently has.</p>\n<p>(If you're curious: <code>torch/csrc/autograd/python_variable_indexing.cpp</code> has <code>THPVariable_getitem</code> and <code>THPVariable_setitem</code>.)</p>", "body_text": "I am relatively sure because I double checked. What happens is that a[m] = something translates to the Python __setitem__ method, where the slicing is handled as a view. When you have a[m] \"anywhere else than in an assignment\", it will translate to __getitem__. That returns a tensor with new storage when used with boolean indexing. It's not limited to clamp_, either, any inplace (e.g. .add_(1000)) will have the same behaviour.\nTo implement the behaviour you expect, you would essentially need to introduce a new \"tensor view\" object (or extend tensor to be able to use one), which is a rather hefty feature request. I'm not saying that it's unreasonable to desire that behaviour, it's just that for implementation you essentially have to wrap a whole \"viewing that cannot be represented by strides\" layer around what PyTorch currently has.\n(If you're curious: torch/csrc/autograd/python_variable_indexing.cpp has THPVariable_getitem and THPVariable_setitem.)", "body": "I am relatively sure because I double checked. What happens is that `a[m] = something` translates to the Python `__setitem__` method, where the slicing is handled as a view. When you have `a[m]` \"anywhere else than in an assignment\", it will translate to `__getitem__`. That returns a tensor with new storage when used with boolean indexing. It's not limited to `clamp_`, either, any inplace (e.g. `.add_(1000)`) will have the same behaviour.\r\nTo implement the behaviour you expect, you would essentially need to introduce a new \"tensor view\" object (or extend tensor to be able to use one), which is a rather hefty feature request. I'm not saying that it's unreasonable to desire that behaviour, it's just that for implementation you essentially have to wrap a whole \"viewing that cannot be represented by strides\" layer around what PyTorch currently has.\r\n\r\n(If you're curious: `torch/csrc/autograd/python_variable_indexing.cpp` has `THPVariable_getitem` and `THPVariable_setitem`.)"}