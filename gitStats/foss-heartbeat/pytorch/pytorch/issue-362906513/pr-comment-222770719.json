{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222770719", "pull_request_review_id": 161714244, "id": 222770719, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMjc3MDcxOQ==", "diff_hunk": "@@ -246,6 +278,171 @@ def handler(signum, frame):\n class _DataLoaderIter(object):\n     r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler\"\"\"\n \n+    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n+    #\n+    # Preliminary:\n+    #\n+    # Our data model looks like this (queues are indicated with curly brackets):\n+    #\n+    #                main process                              ||\n+    #                     |                                    ||\n+    #               {index_queue}                              ||\n+    #                     |                                    ||\n+    #              worker processes                            ||     DATA\n+    #                     |                                    ||\n+    #            {worker_result_queue}                         ||     FLOW\n+    #                     |                                    ||\n+    #      pin_memory_thread of main process                   ||   DIRECTION\n+    #                     |                                    ||\n+    #               {data_queue}                               ||\n+    #                     |                                    ||\n+    #                data output                               \\/\n+    #\n+    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n+    #      `pin_memory=False`.\n+    #\n+    #\n+    # Terminating multiprocessing logic requires very careful design. In\n+    # particular, we need to make sure that\n+    #\n+    #   1. The iterator gracefully exits the workers when its last reference is\n+    #      gone.\n+    #\n+    #      In this case, the workers should be gracefully exited because the\n+    #      main process may still need to continue to run, and we want cleaning\n+    #      up code in the workers to be executed (e.g., releasing GPU memory).\n+    #      Naturally, we implement the shutdown logic in `__del__` of\n+    #      DataLoaderIterator.\n+    #\n+    #      We delay the discussion on the logic in this case until later.\n+    #\n+    #   2. The iterator exits the workers when the problem ends\n+    #\n+    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n+    #      Doing so means that when the program ends, it shuts the workers down\n+    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\n+    #      mechanism.\n+    #\n+    #      You may ask, why don't we just not set the workers as daemonic, and\n+    #      gracefully exit using the same logic as we have in `__del__` when the\n+    #      iterator gets deleted (see 1 above)? The answer requires a bit\n+    #      understanding of Python multiprocessing design. As of Python 3.7, for\n+    #      reasons I have yet to understand, in a subprocess, Python runs the\n+    #      given function (e.g., the `target` argument passed to a `mp.Process`)\n+    #      using this pattern (unrelated code removed for clarity):\n+    #\n+    #          # These are run the sub-process\n+    #          try:\n+    #              user_provided_function()\n+    #          finally:\n+    #              multiprocessing.util._exit_function()\n+    #\n+    #      In `_exit_function`, Python joins all non-daemonic subprocesses of\n+    #      this process (which is a subprocess of a Python process itself), and\n+    #      sends SIGTERM to the daemonic ones. Therefore, if a DataLoader is\n+    #      used in a subprocess (i.e., used in `user_provided_function` above),\n+    #      and an error is raised containing frames that references the\n+    #      DataLoaderIter (Python exception traces keeps local objects in\n+    #      relevant frames alive), workers will be joined in `_exit_function`\n+    #      before the `__del__` is called (which starts the shutdown logic). And\n+    #      unfortunately the DataLoaderIter process will hang. E.g., such errors\n+    #      can be timeout, or arbitrary error if users hold a reference to an\n+    #      iterator.\n+    #\n+    #      For context, `_exit_function` is also registered as an `atexit` call.\n+    #      So I really don't understand the need to do this in a finally block\n+    #      The code dates back to 2008 and there is no comment on the original\n+    #      PEP 371 or patch https://bugs.python.org/issue3050 (containing both\n+    #      the finally block and the `atexit` registration) that explains this.\n+    #\n+    #      Another choice is to just shutdown workers with logic in 1 above\n+    #      whenever we see an error in `next`. This isn't ideal because\n+    #        a. It prevents users from using try-catch to resume data loading.\n+    #        b. It doesn't prevent hanging if users have references to the\n+    #           iterator.\n+    #\n+    #   3. All processes exit if any of them die unexpectedly (e.g., SIGKILL).\n+    #\n+    #      As shown above, the workers are set as daemonic children of the main\n+    #      process. However, automatic cleaning-up of such child processes only\n+    #      happen if the parent process exits gracefully (e.g., SIGTERM). So we\n+    #      must ensure that each process will exit even the process that should\n+    #      send/receive data to/from it were killed, i.e.,\n+    #\n+    #        a. A process won't hang when getting from a queue.\n+    #\n+    #           Even with carefully designed data dependencies (i.e., a `put()`\n+    #           always corresponding to a `get()`), hanging on `get()` can still\n+    #           happen when data in queue is corrupted (e.g., due to\n+    #           `cancel_join_thread` or unexpected exit).\n+    #\n+    #           For child exit, we register SIGCHLD handler on main process,\n+    #           and checks if any of the workers fail in the (Python) handler.\n+    #           See DataLoader.cpp.\n+    #\n+    #           For other `.get()` calls, we guard them with timeouts, and check\n+    #           the status of the sender when timeout happens. E.g., in the\n+    #           workers, the `ManagerWatchdog` class is used to check main\n+    #           process status.\n+    #\n+    #        b. A process won't hang when putting into a queue;\n+    #\n+    #           We use `mp.Queue` which has a separate background thread to put\n+    #           objects. The background thread is usually automatically joined\n+    #           when the process exits.\n+    #\n+    #           However, in case that the receiver has ended abruptly while\n+    #           reading from the pipe, the join will hang forever. Therefore,\n+    #           for both `worker_result_queue` (worker -> main process/pin_memory_thread)\n+    #           and each `index_queue` (main process -> worker), we use\n+    #           `q.cancel_join_thread()` in sender process before any `q.put` to\n+    #           prevent this automatic join.\n+    #\n+    #           Note that this may leave corrupted data in the queue, but we\n+    #           don't care about the data anyways once we are shutting down.\n+    #\n+    #\n+    # Now let's get back to 1:\n+    #   how we gracefully exit the workers when the last reference to the\n+    #   iteartor is gone.", "path": "torch/utils/data/dataloader.py", "position": 319, "original_position": 307, "commit_id": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "original_commit_id": "9ce8d93d03726f874260cb5c132438243b810ffc", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Maybe simply make this point 3. instead of 1., and put the discussion in there instead of delaying it until now.", "created_at": "2018-10-04T17:59:52Z", "updated_at": "2018-11-23T15:52:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222770719", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222770719"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222770719"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}}, "body_html": "<p>Maybe simply make this point 3. instead of 1., and put the discussion in there instead of delaying it until now.</p>", "body_text": "Maybe simply make this point 3. instead of 1., and put the discussion in there instead of delaying it until now."}