{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "id": 217488401, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE3NDg4NDAx", "html_url": "https://github.com/pytorch/pytorch/pull/11985", "diff_url": "https://github.com/pytorch/pytorch/pull/11985.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11985.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11985", "number": 11985, "state": "closed", "locked": false, "title": "Prevent hanging in data loader altogether", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Test plan:\r\n\r\nTrained 16000 LeNets (total) on MNIST on 160 processes. Previously some of them will either hang during training or during program exiting. Now every process finishes successfully.\r\n\r\n```\r\n    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\r\n    #\r\n    # Preliminary:\r\n    #\r\n    # Our data model looks like this (queues are indicated with curly brackets):\r\n    #\r\n    #                main process                              ||\r\n    #                     |                                    ||\r\n    #               {index_queue}                              ||\r\n    #                     |                                    ||\r\n    #              worker processes                            ||     DATA\r\n    #                     |                                    ||\r\n    #            {worker_result_queue}                         ||     FLOW\r\n    #                     |                                    ||\r\n    #      pin_memory_thread of main process                   ||   DIRECTION\r\n    #                     |                                    ||\r\n    #               {data_queue}                               ||\r\n    #                     |                                    ||\r\n    #                data output                               \\/\r\n    #\r\n    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\r\n    #      `pin_memory=False`.\r\n    #\r\n    #\r\n    # Terminating multiprocessing logic requires very careful design. In\r\n    # particular, we need to make sure that\r\n    #\r\n    #   1. The iterator gracefully exits the workers when its last reference is\r\n    #      gone.\r\n    #\r\n    #      In this case, the workers should be gracefully exited because the\r\n    #      main process may still need to continue to run, and we want cleaning\r\n    #      up code in the workers to be executed (e.g., releasing GPU memory).\r\n    #      Naturally, we implement the shutdown logic in `__del__` of\r\n    #      DataLoaderIterator.\r\n    #\r\n    #      We delay the discussion on the logic in this case until later.\r\n    #\r\n    #   2. The iterator exits the workers when the problem ends\r\n    #\r\n    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\r\n    #      Doing so means that when the program ends, it shuts the workers down\r\n    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\r\n    #      mechanism.\r\n    #\r\n    #      You may ask, why don't we just not set the workers as daemonic, and\r\n    #      gracefully exit using the same logic as we have in `__del__` when the\r\n    #      iterator gets deleted (see 1 above)? The answer requires a bit\r\n    #      understanding of Python multiprocessing design. As of Python 3.7, for\r\n    #      reasons I have yet to understand, in a subprocess, Python runs the\r\n    #      given function (e.g., the `target` argument passed to a `mp.Process`)\r\n    #      using this pattern (unrelated code removed for clarity):\r\n    #\r\n    #          # These are run the sub-process\r\n    #          try:\r\n    #              user_provided_function()\r\n    #          finally:\r\n    #              multiprocessing.util._exit_function()\r\n    #\r\n    #      In `_exit_function`, Python joins all non-daemonic subprocesses of\r\n    #      this process (which is a subprocess of a Python process itself), and\r\n    #      sends SIGTERM to the daemonic ones. Therefore, if a DataLoader is\r\n    #      used in a subprocess (i.e., used in `user_provided_function` above),\r\n    #      and an error is raised containing frames that references the\r\n    #      DataLoaderIter (Python exception traces keeps local objects in\r\n    #      relevant frames alive), workers will be joined in `_exit_function`\r\n    #      before the `__del__` is called (which starts the shutdown logic). And\r\n    #      unfortunately the DataLoaderIter process will hang. E.g., such errors\r\n    #      can be timeout, or arbitrary error if users hold a reference to an\r\n    #      iterator.\r\n    #\r\n    #      For context, `_exit_function` is also registered as an `atexit` call.\r\n    #      So I really don't understand the need to do this in a finally block\r\n    #      The code dates back to 2008 and there is no comment on the original\r\n    #      PEP 371 or patch https://bugs.python.org/issue3050 (containing both\r\n    #      the finally block and the `atexit` registration) that explains this.\r\n    #\r\n    #      Another choice is to just shutdown workers with logic in 1 above\r\n    #      whenever we see an error in `next`. This isn't ideal because\r\n    #        a. It prevents users from using try-catch to resume data loading.\r\n    #        b. It doesn't prevent hanging if users have references to the\r\n    #           iterator.\r\n    #\r\n    #   3. All processes exit if any of them die unexpectedly (e.g., error,\r\n    #      SIGKILL).\r\n    #\r\n    #      As shown above, the workers are set as daemonic children of the main\r\n    #      process. However, automatic cleaning-up of such child processes only\r\n    #      happen if the parent process exits gracefully (e.g., SIGTERM). So we\r\n    #      must ensure that each process will exit even the process that should\r\n    #      send/receive data to/from it were killed, i.e.,\r\n    #\r\n    #        a. A process won't hang when getting from a queue.\r\n    #\r\n    #           Even with carefully designed data dependencies (i.e., a `put()`\r\n    #           always corresponding to a `get()`), hanging on `get()` can still\r\n    #           happen when data in queue is corrupted (e.g., due to\r\n    #           `cancel_join_thread` or unexpected exit).\r\n    #\r\n    #           For child exit, we register SIGCHLD handler on main process,\r\n    #           which checks if any of the workers fail in the (Python) handler.\r\n    #           See DataLoader.cpp.\r\n    #\r\n    #           For `.get()` calls where the sender(s) is not the workers, we\r\n    #           guard them with timeouts, and check the status of the sender\r\n    #           when timeout happens:\r\n    #             + in the workers, the `ManagerWatchdog` class checks the main\r\n    #               process status.\r\n    #             + if `pin_memory=True`, when getting from `pin_memory_thread`,\r\n    #               check `pin_memory_thread` status periodically until `.get()`\r\n    #               returns or see that `pin_memory_thread` died.\r\n    #\r\n    #        b. A process won't hang when putting into a queue;\r\n    #\r\n    #           We use `mp.Queue` which has a separate background thread to put\r\n    #           objects. The background thread is usually automatically joined\r\n    #           when the process exits.\r\n    #\r\n    #           However, in case that the receiver has ended abruptly while\r\n    #           reading from the pipe, the join will hang forever. Therefore,\r\n    #           for both `worker_result_queue` (worker -> main process/pin_memory_thread)\r\n    #           and each `index_queue` (main process -> worker), we use\r\n    #           `q.cancel_join_thread()` in sender process before any `q.put` to\r\n    #           prevent this automatic join.\r\n    #\r\n    #           Moreover, having all queues called `cancel_join_thread` makes\r\n    #           implementing graceful shutdown logic in `__del__` much easier.\r\n    #           It won't need to get from any queue, which would also need to be\r\n    #           guarded by periodic status checks.\r\n    #\r\n    #           Note that this may leave corrupted data in the queue, but we\r\n    #           don't care about the data anyways once we are shutting down.\r\n    #\r\n    #\r\n    # Now let's get back to 1:\r\n    #   how we gracefully exit the workers when the last reference to the\r\n    #   iteartor is gone.\r\n    #\r\n    # To achieve this, we implement the following logic along with the design\r\n    # choices mentioned above:\r\n    #\r\n    # [pin_memory_thread] and [worker processes]\r\n    #   When getting from queues,\r\n    #     if get a `None`, exit.\r\n    #     if get anything else or time out, check `done_event`,\r\n    #        if set, keep getting until see the `None`, then exit.\r\n    #        otherwise, process the data.\r\n    #\r\n    # [main process]\r\n    #   In the DataLoader Iter's `__del__`\r\n    #     a. Set `done_event` (shared with `pin_memory_thread` and workers).\r\n    #\r\n    #        Note: from here on, the workers & `pin_memory_thread` may exit at\r\n    #              any time after they receive `None`.\r\n    #\r\n    #     b. Exit `pin_memory_thread`\r\n    #          i.   Put `None` in `worker_result_queue`.\r\n    #          ii.  Join the `pin_memory_thread`.\r\n    #\r\n    #     c. Exit the workers.\r\n    #          i.   Put `None` in each worker's `index_queue`.\r\n    #          ii.  Join the workers.\r\n    #\r\n    #        Note: This has to be after (b) because it may leave corrupted data\r\n    #              in `worker_result_queue`, which `pin_memory_thread` reads\r\n    #              from.\r\n    #\r\n    #   Note: If `pin_memory=False`, there is no `pin_memory_thread` and (b)\r\n    #         can be omitted\r\n    #\r\n    # NB: `done_event`s isn't strictly needed. E.g., we can just check for\r\n    #     `None` from `index_queue`, but it allows us to skip wasting resources\r\n    #     processing indices already in `index_queue` if we are already shutting\r\n    #     down.\r\n```\r\n\r\nOriginal desc:\r\n\r\nIn `DataLoaderIter` `__del__`, ensure that `None` is sent to `pin_memory_thread` before joining workers.\r\n\r\n\r\nTrace when interrupted at such a hang:\r\n```\r\n Exception ignored in: <function _DataLoaderIter.__del__ at 0x7facf66760d0>\r\n Traceback (most recent call last):\r\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 412, in __del__\r\n     self._shutdown_workers()\r\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 408, in _shutdown_worke\r\n\r\n     self.pin_memory_thread.join()\r\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\r\n     self._wait_for_tstate_lock()\r\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\r\n     elif lock.acquire(block, timeout):\r\n KeyboardInterrupt\r\n\r\n```\r\n\r\nThe 1st commit solves majority of the hang, but uncovers another problem:\r\n```\r\n36: Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f214fa412f0>\r\n36: Traceback (most recent call last):\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 416, in __\r\ndel__\r\n36:     self._shutdown_workers()\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 401, in _s\r\nhutdown_workers\r\n36:     self.worker_result_queue.join_thread()\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 145, in join_thread\r\n36:     self._jointhread()\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\r\n36:     res = self._callback(*self._args, **self._kwargs)\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\r\n36:     thread.join()\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\r\n36:     self._wait_for_tstate_lock()\r\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\r\n36:     elif lock.acquire(block, timeout):\r\n36: KeyboardInterrupt\r\n```", "created_at": "2018-09-23T02:11:10Z", "updated_at": "2018-11-23T15:52:36Z", "closed_at": "2018-10-09T16:55:47Z", "merged_at": null, "merge_commit_sha": "aa6227659927e7a81f96348a85797d714fa8010f", "assignee": null, "assignees": [], "requested_reviewers": [{"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}], "requested_teams": [], "labels": [{"id": 1002715609, "node_id": "MDU6TGFiZWwxMDAyNzE1NjA5", "url": "https://api.github.com/repos/pytorch/pytorch/labels/blocker", "name": "blocker", "color": "b60205", "default": false}], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11985/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/d3c4ffa092580d5b15ef2705bd3904f7b685e511", "head": {"label": "SsnL:join_queue", "ref": "join_queue", "sha": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "repo": {"id": 103305558, "node_id": "MDEwOlJlcG9zaXRvcnkxMDMzMDU1NTg=", "name": "pytorch", "full_name": "SsnL/pytorch", "private": false, "owner": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/SsnL/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/SsnL/pytorch", "forks_url": "https://api.github.com/repos/SsnL/pytorch/forks", "keys_url": "https://api.github.com/repos/SsnL/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/SsnL/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/SsnL/pytorch/teams", "hooks_url": "https://api.github.com/repos/SsnL/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/SsnL/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/SsnL/pytorch/events", "assignees_url": "https://api.github.com/repos/SsnL/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/SsnL/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/SsnL/pytorch/tags", "blobs_url": "https://api.github.com/repos/SsnL/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/SsnL/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/SsnL/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/SsnL/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/SsnL/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/SsnL/pytorch/languages", "stargazers_url": "https://api.github.com/repos/SsnL/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/SsnL/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/SsnL/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/SsnL/pytorch/subscription", "commits_url": "https://api.github.com/repos/SsnL/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/SsnL/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/SsnL/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/SsnL/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/SsnL/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/SsnL/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/SsnL/pytorch/merges", "archive_url": "https://api.github.com/repos/SsnL/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/SsnL/pytorch/downloads", "issues_url": "https://api.github.com/repos/SsnL/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/SsnL/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/SsnL/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/SsnL/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/SsnL/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/SsnL/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/SsnL/pytorch/deployments", "created_at": "2017-09-12T18:13:43Z", "updated_at": "2018-11-04T15:36:18Z", "pushed_at": "2018-11-09T18:32:11Z", "git_url": "git://github.com/SsnL/pytorch.git", "ssh_url": "git@github.com:SsnL/pytorch.git", "clone_url": "https://github.com/SsnL/pytorch.git", "svn_url": "https://github.com/SsnL/pytorch", "homepage": "http://pytorch.org", "size": 83933, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 1, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "d0e1dca0f520967f0f1953390b4a2b2e13e6affc", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T15:34:47Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21592, "watchers_count": 21592, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5154, "mirror_url": null, "archived": false, "open_issues_count": 2196, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5154, "open_issues": 2196, "watchers": 21592, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/11985"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/11985/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/d3c4ffa092580d5b15ef2705bd3904f7b685e511"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>Test plan:</p>\n<p>Trained 16000 LeNets (total) on MNIST on 160 processes. Previously some of them will either hang during training or during program exiting. Now every process finishes successfully.</p>\n<pre><code>    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n    #\n    # Preliminary:\n    #\n    # Our data model looks like this (queues are indicated with curly brackets):\n    #\n    #                main process                              ||\n    #                     |                                    ||\n    #               {index_queue}                              ||\n    #                     |                                    ||\n    #              worker processes                            ||     DATA\n    #                     |                                    ||\n    #            {worker_result_queue}                         ||     FLOW\n    #                     |                                    ||\n    #      pin_memory_thread of main process                   ||   DIRECTION\n    #                     |                                    ||\n    #               {data_queue}                               ||\n    #                     |                                    ||\n    #                data output                               \\/\n    #\n    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n    #      `pin_memory=False`.\n    #\n    #\n    # Terminating multiprocessing logic requires very careful design. In\n    # particular, we need to make sure that\n    #\n    #   1. The iterator gracefully exits the workers when its last reference is\n    #      gone.\n    #\n    #      In this case, the workers should be gracefully exited because the\n    #      main process may still need to continue to run, and we want cleaning\n    #      up code in the workers to be executed (e.g., releasing GPU memory).\n    #      Naturally, we implement the shutdown logic in `__del__` of\n    #      DataLoaderIterator.\n    #\n    #      We delay the discussion on the logic in this case until later.\n    #\n    #   2. The iterator exits the workers when the problem ends\n    #\n    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n    #      Doing so means that when the program ends, it shuts the workers down\n    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\n    #      mechanism.\n    #\n    #      You may ask, why don't we just not set the workers as daemonic, and\n    #      gracefully exit using the same logic as we have in `__del__` when the\n    #      iterator gets deleted (see 1 above)? The answer requires a bit\n    #      understanding of Python multiprocessing design. As of Python 3.7, for\n    #      reasons I have yet to understand, in a subprocess, Python runs the\n    #      given function (e.g., the `target` argument passed to a `mp.Process`)\n    #      using this pattern (unrelated code removed for clarity):\n    #\n    #          # These are run the sub-process\n    #          try:\n    #              user_provided_function()\n    #          finally:\n    #              multiprocessing.util._exit_function()\n    #\n    #      In `_exit_function`, Python joins all non-daemonic subprocesses of\n    #      this process (which is a subprocess of a Python process itself), and\n    #      sends SIGTERM to the daemonic ones. Therefore, if a DataLoader is\n    #      used in a subprocess (i.e., used in `user_provided_function` above),\n    #      and an error is raised containing frames that references the\n    #      DataLoaderIter (Python exception traces keeps local objects in\n    #      relevant frames alive), workers will be joined in `_exit_function`\n    #      before the `__del__` is called (which starts the shutdown logic). And\n    #      unfortunately the DataLoaderIter process will hang. E.g., such errors\n    #      can be timeout, or arbitrary error if users hold a reference to an\n    #      iterator.\n    #\n    #      For context, `_exit_function` is also registered as an `atexit` call.\n    #      So I really don't understand the need to do this in a finally block\n    #      The code dates back to 2008 and there is no comment on the original\n    #      PEP 371 or patch https://bugs.python.org/issue3050 (containing both\n    #      the finally block and the `atexit` registration) that explains this.\n    #\n    #      Another choice is to just shutdown workers with logic in 1 above\n    #      whenever we see an error in `next`. This isn't ideal because\n    #        a. It prevents users from using try-catch to resume data loading.\n    #        b. It doesn't prevent hanging if users have references to the\n    #           iterator.\n    #\n    #   3. All processes exit if any of them die unexpectedly (e.g., error,\n    #      SIGKILL).\n    #\n    #      As shown above, the workers are set as daemonic children of the main\n    #      process. However, automatic cleaning-up of such child processes only\n    #      happen if the parent process exits gracefully (e.g., SIGTERM). So we\n    #      must ensure that each process will exit even the process that should\n    #      send/receive data to/from it were killed, i.e.,\n    #\n    #        a. A process won't hang when getting from a queue.\n    #\n    #           Even with carefully designed data dependencies (i.e., a `put()`\n    #           always corresponding to a `get()`), hanging on `get()` can still\n    #           happen when data in queue is corrupted (e.g., due to\n    #           `cancel_join_thread` or unexpected exit).\n    #\n    #           For child exit, we register SIGCHLD handler on main process,\n    #           which checks if any of the workers fail in the (Python) handler.\n    #           See DataLoader.cpp.\n    #\n    #           For `.get()` calls where the sender(s) is not the workers, we\n    #           guard them with timeouts, and check the status of the sender\n    #           when timeout happens:\n    #             + in the workers, the `ManagerWatchdog` class checks the main\n    #               process status.\n    #             + if `pin_memory=True`, when getting from `pin_memory_thread`,\n    #               check `pin_memory_thread` status periodically until `.get()`\n    #               returns or see that `pin_memory_thread` died.\n    #\n    #        b. A process won't hang when putting into a queue;\n    #\n    #           We use `mp.Queue` which has a separate background thread to put\n    #           objects. The background thread is usually automatically joined\n    #           when the process exits.\n    #\n    #           However, in case that the receiver has ended abruptly while\n    #           reading from the pipe, the join will hang forever. Therefore,\n    #           for both `worker_result_queue` (worker -&gt; main process/pin_memory_thread)\n    #           and each `index_queue` (main process -&gt; worker), we use\n    #           `q.cancel_join_thread()` in sender process before any `q.put` to\n    #           prevent this automatic join.\n    #\n    #           Moreover, having all queues called `cancel_join_thread` makes\n    #           implementing graceful shutdown logic in `__del__` much easier.\n    #           It won't need to get from any queue, which would also need to be\n    #           guarded by periodic status checks.\n    #\n    #           Note that this may leave corrupted data in the queue, but we\n    #           don't care about the data anyways once we are shutting down.\n    #\n    #\n    # Now let's get back to 1:\n    #   how we gracefully exit the workers when the last reference to the\n    #   iteartor is gone.\n    #\n    # To achieve this, we implement the following logic along with the design\n    # choices mentioned above:\n    #\n    # [pin_memory_thread] and [worker processes]\n    #   When getting from queues,\n    #     if get a `None`, exit.\n    #     if get anything else or time out, check `done_event`,\n    #        if set, keep getting until see the `None`, then exit.\n    #        otherwise, process the data.\n    #\n    # [main process]\n    #   In the DataLoader Iter's `__del__`\n    #     a. Set `done_event` (shared with `pin_memory_thread` and workers).\n    #\n    #        Note: from here on, the workers &amp; `pin_memory_thread` may exit at\n    #              any time after they receive `None`.\n    #\n    #     b. Exit `pin_memory_thread`\n    #          i.   Put `None` in `worker_result_queue`.\n    #          ii.  Join the `pin_memory_thread`.\n    #\n    #     c. Exit the workers.\n    #          i.   Put `None` in each worker's `index_queue`.\n    #          ii.  Join the workers.\n    #\n    #        Note: This has to be after (b) because it may leave corrupted data\n    #              in `worker_result_queue`, which `pin_memory_thread` reads\n    #              from.\n    #\n    #   Note: If `pin_memory=False`, there is no `pin_memory_thread` and (b)\n    #         can be omitted\n    #\n    # NB: `done_event`s isn't strictly needed. E.g., we can just check for\n    #     `None` from `index_queue`, but it allows us to skip wasting resources\n    #     processing indices already in `index_queue` if we are already shutting\n    #     down.\n</code></pre>\n<p>Original desc:</p>\n<p>In <code>DataLoaderIter</code> <code>__del__</code>, ensure that <code>None</code> is sent to <code>pin_memory_thread</code> before joining workers.</p>\n<p>Trace when interrupted at such a hang:</p>\n<pre><code> Exception ignored in: &lt;function _DataLoaderIter.__del__ at 0x7facf66760d0&gt;\n Traceback (most recent call last):\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 412, in __del__\n     self._shutdown_workers()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 408, in _shutdown_worke\n\n     self.pin_memory_thread.join()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\n     self._wait_for_tstate_lock()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n     elif lock.acquire(block, timeout):\n KeyboardInterrupt\n\n</code></pre>\n<p>The 1st commit solves majority of the hang, but uncovers another problem:</p>\n<pre><code>36: Exception ignored in: &lt;function _DataLoaderIter.__del__ at 0x7f214fa412f0&gt;\n36: Traceback (most recent call last):\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 416, in __\ndel__\n36:     self._shutdown_workers()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 401, in _s\nhutdown_workers\n36:     self.worker_result_queue.join_thread()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 145, in join_thread\n36:     self._jointhread()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n36:     res = self._callback(*self._args, **self._kwargs)\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n36:     thread.join()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\n36:     self._wait_for_tstate_lock()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n36:     elif lock.acquire(block, timeout):\n36: KeyboardInterrupt\n</code></pre>", "body_text": "Test plan:\nTrained 16000 LeNets (total) on MNIST on 160 processes. Previously some of them will either hang during training or during program exiting. Now every process finishes successfully.\n    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n    #\n    # Preliminary:\n    #\n    # Our data model looks like this (queues are indicated with curly brackets):\n    #\n    #                main process                              ||\n    #                     |                                    ||\n    #               {index_queue}                              ||\n    #                     |                                    ||\n    #              worker processes                            ||     DATA\n    #                     |                                    ||\n    #            {worker_result_queue}                         ||     FLOW\n    #                     |                                    ||\n    #      pin_memory_thread of main process                   ||   DIRECTION\n    #                     |                                    ||\n    #               {data_queue}                               ||\n    #                     |                                    ||\n    #                data output                               \\/\n    #\n    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n    #      `pin_memory=False`.\n    #\n    #\n    # Terminating multiprocessing logic requires very careful design. In\n    # particular, we need to make sure that\n    #\n    #   1. The iterator gracefully exits the workers when its last reference is\n    #      gone.\n    #\n    #      In this case, the workers should be gracefully exited because the\n    #      main process may still need to continue to run, and we want cleaning\n    #      up code in the workers to be executed (e.g., releasing GPU memory).\n    #      Naturally, we implement the shutdown logic in `__del__` of\n    #      DataLoaderIterator.\n    #\n    #      We delay the discussion on the logic in this case until later.\n    #\n    #   2. The iterator exits the workers when the problem ends\n    #\n    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n    #      Doing so means that when the program ends, it shuts the workers down\n    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\n    #      mechanism.\n    #\n    #      You may ask, why don't we just not set the workers as daemonic, and\n    #      gracefully exit using the same logic as we have in `__del__` when the\n    #      iterator gets deleted (see 1 above)? The answer requires a bit\n    #      understanding of Python multiprocessing design. As of Python 3.7, for\n    #      reasons I have yet to understand, in a subprocess, Python runs the\n    #      given function (e.g., the `target` argument passed to a `mp.Process`)\n    #      using this pattern (unrelated code removed for clarity):\n    #\n    #          # These are run the sub-process\n    #          try:\n    #              user_provided_function()\n    #          finally:\n    #              multiprocessing.util._exit_function()\n    #\n    #      In `_exit_function`, Python joins all non-daemonic subprocesses of\n    #      this process (which is a subprocess of a Python process itself), and\n    #      sends SIGTERM to the daemonic ones. Therefore, if a DataLoader is\n    #      used in a subprocess (i.e., used in `user_provided_function` above),\n    #      and an error is raised containing frames that references the\n    #      DataLoaderIter (Python exception traces keeps local objects in\n    #      relevant frames alive), workers will be joined in `_exit_function`\n    #      before the `__del__` is called (which starts the shutdown logic). And\n    #      unfortunately the DataLoaderIter process will hang. E.g., such errors\n    #      can be timeout, or arbitrary error if users hold a reference to an\n    #      iterator.\n    #\n    #      For context, `_exit_function` is also registered as an `atexit` call.\n    #      So I really don't understand the need to do this in a finally block\n    #      The code dates back to 2008 and there is no comment on the original\n    #      PEP 371 or patch https://bugs.python.org/issue3050 (containing both\n    #      the finally block and the `atexit` registration) that explains this.\n    #\n    #      Another choice is to just shutdown workers with logic in 1 above\n    #      whenever we see an error in `next`. This isn't ideal because\n    #        a. It prevents users from using try-catch to resume data loading.\n    #        b. It doesn't prevent hanging if users have references to the\n    #           iterator.\n    #\n    #   3. All processes exit if any of them die unexpectedly (e.g., error,\n    #      SIGKILL).\n    #\n    #      As shown above, the workers are set as daemonic children of the main\n    #      process. However, automatic cleaning-up of such child processes only\n    #      happen if the parent process exits gracefully (e.g., SIGTERM). So we\n    #      must ensure that each process will exit even the process that should\n    #      send/receive data to/from it were killed, i.e.,\n    #\n    #        a. A process won't hang when getting from a queue.\n    #\n    #           Even with carefully designed data dependencies (i.e., a `put()`\n    #           always corresponding to a `get()`), hanging on `get()` can still\n    #           happen when data in queue is corrupted (e.g., due to\n    #           `cancel_join_thread` or unexpected exit).\n    #\n    #           For child exit, we register SIGCHLD handler on main process,\n    #           which checks if any of the workers fail in the (Python) handler.\n    #           See DataLoader.cpp.\n    #\n    #           For `.get()` calls where the sender(s) is not the workers, we\n    #           guard them with timeouts, and check the status of the sender\n    #           when timeout happens:\n    #             + in the workers, the `ManagerWatchdog` class checks the main\n    #               process status.\n    #             + if `pin_memory=True`, when getting from `pin_memory_thread`,\n    #               check `pin_memory_thread` status periodically until `.get()`\n    #               returns or see that `pin_memory_thread` died.\n    #\n    #        b. A process won't hang when putting into a queue;\n    #\n    #           We use `mp.Queue` which has a separate background thread to put\n    #           objects. The background thread is usually automatically joined\n    #           when the process exits.\n    #\n    #           However, in case that the receiver has ended abruptly while\n    #           reading from the pipe, the join will hang forever. Therefore,\n    #           for both `worker_result_queue` (worker -> main process/pin_memory_thread)\n    #           and each `index_queue` (main process -> worker), we use\n    #           `q.cancel_join_thread()` in sender process before any `q.put` to\n    #           prevent this automatic join.\n    #\n    #           Moreover, having all queues called `cancel_join_thread` makes\n    #           implementing graceful shutdown logic in `__del__` much easier.\n    #           It won't need to get from any queue, which would also need to be\n    #           guarded by periodic status checks.\n    #\n    #           Note that this may leave corrupted data in the queue, but we\n    #           don't care about the data anyways once we are shutting down.\n    #\n    #\n    # Now let's get back to 1:\n    #   how we gracefully exit the workers when the last reference to the\n    #   iteartor is gone.\n    #\n    # To achieve this, we implement the following logic along with the design\n    # choices mentioned above:\n    #\n    # [pin_memory_thread] and [worker processes]\n    #   When getting from queues,\n    #     if get a `None`, exit.\n    #     if get anything else or time out, check `done_event`,\n    #        if set, keep getting until see the `None`, then exit.\n    #        otherwise, process the data.\n    #\n    # [main process]\n    #   In the DataLoader Iter's `__del__`\n    #     a. Set `done_event` (shared with `pin_memory_thread` and workers).\n    #\n    #        Note: from here on, the workers & `pin_memory_thread` may exit at\n    #              any time after they receive `None`.\n    #\n    #     b. Exit `pin_memory_thread`\n    #          i.   Put `None` in `worker_result_queue`.\n    #          ii.  Join the `pin_memory_thread`.\n    #\n    #     c. Exit the workers.\n    #          i.   Put `None` in each worker's `index_queue`.\n    #          ii.  Join the workers.\n    #\n    #        Note: This has to be after (b) because it may leave corrupted data\n    #              in `worker_result_queue`, which `pin_memory_thread` reads\n    #              from.\n    #\n    #   Note: If `pin_memory=False`, there is no `pin_memory_thread` and (b)\n    #         can be omitted\n    #\n    # NB: `done_event`s isn't strictly needed. E.g., we can just check for\n    #     `None` from `index_queue`, but it allows us to skip wasting resources\n    #     processing indices already in `index_queue` if we are already shutting\n    #     down.\n\nOriginal desc:\nIn DataLoaderIter __del__, ensure that None is sent to pin_memory_thread before joining workers.\nTrace when interrupted at such a hang:\n Exception ignored in: <function _DataLoaderIter.__del__ at 0x7facf66760d0>\n Traceback (most recent call last):\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 412, in __del__\n     self._shutdown_workers()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 408, in _shutdown_worke\n\n     self.pin_memory_thread.join()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\n     self._wait_for_tstate_lock()\n   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n     elif lock.acquire(block, timeout):\n KeyboardInterrupt\n\n\nThe 1st commit solves majority of the hang, but uncovers another problem:\n36: Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f214fa412f0>\n36: Traceback (most recent call last):\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 416, in __\ndel__\n36:     self._shutdown_workers()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 401, in _s\nhutdown_workers\n36:     self.worker_result_queue.join_thread()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 145, in join_thread\n36:     self._jointhread()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n36:     res = self._callback(*self._args, **self._kwargs)\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n36:     thread.join()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1032, in join\n36:     self._wait_for_tstate_lock()\n36:   File \"/private/home/ssnl/miniconda3/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n36:     elif lock.acquire(block, timeout):\n36: KeyboardInterrupt", "merged": false, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": null, "comments": 13, "review_comments": 62, "maintainer_can_modify": false, "commits": 29, "additions": 523, "deletions": 141, "changed_files": 4}