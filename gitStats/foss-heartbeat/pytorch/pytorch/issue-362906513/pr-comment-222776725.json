{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222776725", "pull_request_review_id": 161746182, "id": 222776725, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMjc3NjcyNQ==", "diff_hunk": "@@ -246,6 +278,171 @@ def handler(signum, frame):\n class _DataLoaderIter(object):\n     r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler\"\"\"\n \n+    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n+    #\n+    # Preliminary:\n+    #\n+    # Our data model looks like this (queues are indicated with curly brackets):\n+    #\n+    #                main process                              ||\n+    #                     |                                    ||\n+    #               {index_queue}                              ||\n+    #                     |                                    ||\n+    #              worker processes                            ||     DATA\n+    #                     |                                    ||\n+    #            {worker_result_queue}                         ||     FLOW\n+    #                     |                                    ||\n+    #      pin_memory_thread of main process                   ||   DIRECTION\n+    #                     |                                    ||\n+    #               {data_queue}                               ||\n+    #                     |                                    ||\n+    #                data output                               \\/\n+    #\n+    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n+    #      `pin_memory=False`.\n+    #\n+    #\n+    # Terminating multiprocessing logic requires very careful design. In\n+    # particular, we need to make sure that\n+    #\n+    #   1. The iterator gracefully exits the workers when its last reference is\n+    #      gone.\n+    #\n+    #      In this case, the workers should be gracefully exited because the\n+    #      main process may still need to continue to run, and we want cleaning\n+    #      up code in the workers to be executed (e.g., releasing GPU memory).\n+    #      Naturally, we implement the shutdown logic in `__del__` of\n+    #      DataLoaderIterator.\n+    #\n+    #      We delay the discussion on the logic in this case until later.\n+    #\n+    #   2. The iterator exits the workers when the problem ends\n+    #\n+    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n+    #      Doing so means that when the program ends, it shuts the workers down\n+    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\n+    #      mechanism.\n+    #\n+    #      You may ask, why don't we just not set the workers as daemonic, and\n+    #      gracefully exit using the same logic as we have in `__del__` when the\n+    #      iterator gets deleted (see 1 above)? The answer requires a bit\n+    #      understanding of Python multiprocessing design. As of Python 3.7, for\n+    #      reasons I have yet to understand, in a subprocess, Python runs the\n+    #      given function (e.g., the `target` argument passed to a `mp.Process`)\n+    #      using this pattern (unrelated code removed for clarity):\n+    #\n+    #          # These are run the sub-process\n+    #          try:\n+    #              user_provided_function()\n+    #          finally:\n+    #              multiprocessing.util._exit_function()\n+    #\n+    #      In `_exit_function`, Python joins all non-daemonic subprocesses of\n+    #      this process (which is a subprocess of a Python process itself), and\n+    #      sends SIGTERM to the daemonic ones. Therefore, if a DataLoader is\n+    #      used in a subprocess (i.e., used in `user_provided_function` above),\n+    #      and an error is raised containing frames that references the\n+    #      DataLoaderIter (Python exception traces keeps local objects in\n+    #      relevant frames alive), workers will be joined in `_exit_function`\n+    #      before the `__del__` is called (which starts the shutdown logic). And\n+    #      unfortunately the DataLoaderIter process will hang. E.g., such errors\n+    #      can be timeout, or arbitrary error if users hold a reference to an\n+    #      iterator.\n+    #\n+    #      For context, `_exit_function` is also registered as an `atexit` call.\n+    #      So I really don't understand the need to do this in a finally block\n+    #      The code dates back to 2008 and there is no comment on the original\n+    #      PEP 371 or patch https://bugs.python.org/issue3050 (containing both\n+    #      the finally block and the `atexit` registration) that explains this.\n+    #\n+    #      Another choice is to just shutdown workers with logic in 1 above\n+    #      whenever we see an error in `next`. This isn't ideal because\n+    #        a. It prevents users from using try-catch to resume data loading.\n+    #        b. It doesn't prevent hanging if users have references to the\n+    #           iterator.\n+    #\n+    #   3. All processes exit if any of them die unexpectedly (e.g., SIGKILL).\n+    #\n+    #      As shown above, the workers are set as daemonic children of the main\n+    #      process. However, automatic cleaning-up of such child processes only\n+    #      happen if the parent process exits gracefully (e.g., SIGTERM). So we", "path": "torch/utils/data/dataloader.py", "position": null, "original_position": 268, "commit_id": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "original_commit_id": "9ce8d93d03726f874260cb5c132438243b810ffc", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Yep you are right. I didn't know why I wrote SIGTERM... ", "created_at": "2018-10-04T18:18:09Z", "updated_at": "2018-11-23T15:52:23Z", "html_url": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222776725", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222776725"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222776725"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}}, "body_html": "<p>Yep you are right. I didn't know why I wrote SIGTERM...</p>", "body_text": "Yep you are right. I didn't know why I wrote SIGTERM...", "in_reply_to_id": 222769940}