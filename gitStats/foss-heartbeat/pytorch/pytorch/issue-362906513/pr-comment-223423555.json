{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223423555", "pull_request_review_id": 162545735, "id": 223423555, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMzQyMzU1NQ==", "diff_hunk": "@@ -558,51 +624,92 @@ def _is_process_alive(pid, pname):\n         output = output.decode('utf-8')\n         return pname in output\n \n-    @unittest.skipIf(NO_MULTIPROCESSING_SPAWN, \"Disabled for environments that \\\n-                     don't support multiprocessing with spawn start method\")\n-    @unittest.skipIf(sys.version_info[0] == 2,\n-                     \"spawn start method is not supported in Python 2, \\\n-                     but we need it for creating another process with CUDA\")\n-    @unittest.skipIf(not TEST_CUDA, \"CUDA unavailable\")\n     @skipIfRocm\n-    def test_main_process_unclean_exit(self):\n-        r'''There might be ConnectionResetError or leaked semaphore warning (due to dirty process exit), \\\n-but they are all safe to ignore'''\n-\n-        # `raise_error` controls if the main process is KILL-ed by OS or just\n-        # simply raises an error. Both cases are interesting because\n-        # 1. In case of it is KILL-ed by OS, the workers need to automatically\n-        #    discover that their parent is dead and exit gracefully.\n-        # 2. In case of it raises an error itself, the parent process needs to\n-        #    take care of exiting the worker and then exits itself gracefully.\n-        for raise_error in (True, False):\n-            worker_pids = mp.Array('i', [0] * 4)\n-\n-            main_exit_event = mp.Event()\n-            p = mp.Process(target=TestDataLoader._main_process,\n-                           args=(self.dataset, worker_pids, main_exit_event, raise_error))\n-            p.start()\n-            worker_pids[-1] = p.pid\n+    def test_proper_exit(self):\n+        r'''There might be ConnectionResetError or leaked semaphore warning\n+        (due to dirty process exit), but they are all safe to ignore'''\n+\n+        # TODO: test the case where the pin_memory_thread triggers an\n+        #       error/fatal signal. I haven't found out how to properly do that.\n \n-            main_exit_event.wait()\n+        # Array to store the worker pids.\n+        worker_pids = mp.Array('i', [-1 for _ in range(10)])\n \n-            exit_status = [False] * len(worker_pids)\n+        def wait_pids(pids, timeout):\n+            r\"\"\"Wait for all process specified in pids to exit in given timeout.\"\"\"\n+            exit_status = [False for _ in pids]\n             start_time = time.time()\n             pname = 'python'\n             while True:\n-                for i in range(len(worker_pids)):\n-                    pid = worker_pids[i]\n+                for i in range(len(pids)):\n+                    pid = pids[i]\n                     if not exit_status[i]:\n                         if not TestDataLoader._is_process_alive(pid, pname):\n                             exit_status[i] = True\n                 if all(exit_status):\n                     break\n                 else:\n-                    if time.time() - start_time > MANAGER_STATUS_CHECK_INTERVAL + JOIN_TIMEOUT:\n-                        self.fail('subprocess not terminated')\n-                    time.sleep(1)\n-            p.join(MANAGER_STATUS_CHECK_INTERVAL + JOIN_TIMEOUT - (time.time() - start_time))\n-            self.assertFalse(p.is_alive(), 'main process not terminated')\n+                    if time.time() - start_time > timeout:\n+                        break\n+                    time.sleep(0.5)\n+            return exit_status\n+\n+        for use_workers, pin_memory, hold_iter_reference in itertools.product([True, False], repeat=3):\n+            # `hold_iter_reference` specifies whether we hold a reference to the\n+            # iterator. This is interesting because Python3 error traces holds a\n+            # reference to the frames, which hold references to all the local\n+            # variables. It is important to see that the processes still exit.", "path": "test/test_dataloader.py", "position": null, "original_position": 295, "commit_id": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "original_commit_id": "398578667ab67c1b09c73456159eead852177cc1", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "\"variables *, which include the error trace*.\" Otherwise it might not be immediately clear why is that a problem.", "created_at": "2018-10-08T16:22:08Z", "updated_at": "2018-11-23T15:52:33Z", "html_url": "https://github.com/pytorch/pytorch/pull/11985#discussion_r223423555", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223423555"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985#discussion_r223423555"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}}, "body_html": "<p>\"variables <em>, which include the error trace</em>.\" Otherwise it might not be immediately clear why is that a problem.</p>", "body_text": "\"variables , which include the error trace.\" Otherwise it might not be immediately clear why is that a problem."}