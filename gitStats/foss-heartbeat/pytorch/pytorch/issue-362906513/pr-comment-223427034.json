{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223427034", "pull_request_review_id": 162545735, "id": 223427034, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMzQyNzAzNA==", "diff_hunk": "@@ -246,6 +281,200 @@ def handler(signum, frame):\n class _DataLoaderIter(object):\n     r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler\"\"\"\n \n+    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n+    #\n+    # Preliminary:\n+    #\n+    # Our data model looks like this (queues are indicated with curly brackets):\n+    #\n+    #                main process                              ||\n+    #                     |                                    ||\n+    #               {index_queue}                              ||\n+    #                     |                                    ||\n+    #              worker processes                            ||     DATA\n+    #                     |                                    ||\n+    #            {worker_result_queue}                         ||     FLOW\n+    #                     |                                    ||\n+    #      pin_memory_thread of main process                   ||   DIRECTION\n+    #                     |                                    ||\n+    #               {data_queue}                               ||\n+    #                     |                                    ||\n+    #                data output                               \\/\n+    #\n+    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n+    #      `pin_memory=False`.\n+    #\n+    #\n+    # Terminating multiprocessing logic requires very careful design. In\n+    # particular, we need to make sure that\n+    #\n+    #   1. The iterator gracefully exits the workers when its last reference is\n+    #      gone.\n+    #\n+    #      In this case, the workers should be gracefully exited because the\n+    #      main process may still need to continue to run, and we want cleaning\n+    #      up code in the workers to be executed (e.g., releasing GPU memory).\n+    #      Naturally, we implement the shutdown logic in `__del__` of\n+    #      DataLoaderIterator.\n+    #\n+    #      We delay the discussion on the logic in this case until later.\n+    #\n+    #   2. The iterator exits the workers when the program ends without error.\n+    #\n+    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n+    #\n+    #      When a process ends, it shuts the all its daemonic children down with\n+    #      a SIGTERM (instead of joining them without a timeout). Simiarly for\n+    #      threads, but by a different mechanism.\n+    #\n+    #      You may ask, why can't we make the workers non-daemonic, and\n+    #      gracefully exit using the same logic as we have in `__del__` when the\n+    #      iterator gets deleted (see 1 above)?\n+    #\n+    #      When a process exits, Python joins all its non-daemonic subprocesses,\n+    #      and terminates (via SIGTERM) all daemonic ones. This fact, together", "path": "torch/utils/data/dataloader.py", "position": null, "original_position": 234, "commit_id": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "original_commit_id": "398578667ab67c1b09c73456159eead852177cc1", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "First sentence repeats the paragraph above. Let's put the one immediately above before it, and then concatenate the one that explains daemonic processes with this one.", "created_at": "2018-10-08T16:33:11Z", "updated_at": "2018-11-23T15:52:33Z", "html_url": "https://github.com/pytorch/pytorch/pull/11985#discussion_r223427034", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223427034"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985#discussion_r223427034"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}}, "body_html": "<p>First sentence repeats the paragraph above. Let's put the one immediately above before it, and then concatenate the one that explains daemonic processes with this one.</p>", "body_text": "First sentence repeats the paragraph above. Let's put the one immediately above before it, and then concatenate the one that explains daemonic processes with this one."}