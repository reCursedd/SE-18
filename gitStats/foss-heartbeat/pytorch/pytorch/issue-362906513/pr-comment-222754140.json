{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222754140", "pull_request_review_id": 161714244, "id": 222754140, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMjc1NDE0MA==", "diff_hunk": "@@ -246,6 +278,171 @@ def handler(signum, frame):\n class _DataLoaderIter(object):\n     r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler\"\"\"\n \n+    # NOTE [ Data Loader Multiprocessing Shutdown Logic ]\n+    #\n+    # Preliminary:\n+    #\n+    # Our data model looks like this (queues are indicated with curly brackets):\n+    #\n+    #                main process                              ||\n+    #                     |                                    ||\n+    #               {index_queue}                              ||\n+    #                     |                                    ||\n+    #              worker processes                            ||     DATA\n+    #                     |                                    ||\n+    #            {worker_result_queue}                         ||     FLOW\n+    #                     |                                    ||\n+    #      pin_memory_thread of main process                   ||   DIRECTION\n+    #                     |                                    ||\n+    #               {data_queue}                               ||\n+    #                     |                                    ||\n+    #                data output                               \\/\n+    #\n+    # P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if\n+    #      `pin_memory=False`.\n+    #\n+    #\n+    # Terminating multiprocessing logic requires very careful design. In\n+    # particular, we need to make sure that\n+    #\n+    #   1. The iterator gracefully exits the workers when its last reference is\n+    #      gone.\n+    #\n+    #      In this case, the workers should be gracefully exited because the\n+    #      main process may still need to continue to run, and we want cleaning\n+    #      up code in the workers to be executed (e.g., releasing GPU memory).\n+    #      Naturally, we implement the shutdown logic in `__del__` of\n+    #      DataLoaderIterator.\n+    #\n+    #      We delay the discussion on the logic in this case until later.\n+    #\n+    #   2. The iterator exits the workers when the problem ends\n+    #\n+    #      We set all workers and `pin_memory_thread` to have `daemon=True`.\n+    #      Doing so means that when the program ends, it shuts the workers down\n+    #      with a SIGTERM. `pin_memory_thread` will exit too, but by a different\n+    #      mechanism.\n+    #\n+    #      You may ask, why don't we just not set the workers as daemonic, and", "path": "torch/utils/data/dataloader.py", "position": null, "original_position": 226, "commit_id": "d3c4ffa092580d5b15ef2705bd3904f7b685e511", "original_commit_id": "9ce8d93d03726f874260cb5c132438243b810ffc", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "It would be also good to briefly explain what does it mean that a process is daemonic. Tbh I don't know what mechanism does `multiprocessing` use to ensure it is killed.", "created_at": "2018-10-04T17:11:04Z", "updated_at": "2018-11-23T15:52:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222754140", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11985", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/222754140"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11985#discussion_r222754140"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11985"}}, "body_html": "<p>It would be also good to briefly explain what does it mean that a process is daemonic. Tbh I don't know what mechanism does <code>multiprocessing</code> use to ensure it is killed.</p>", "body_text": "It would be also good to briefly explain what does it mean that a process is daemonic. Tbh I don't know what mechanism does multiprocessing use to ensure it is killed.", "in_reply_to_id": 222753923}