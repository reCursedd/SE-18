{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13008", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13008/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13008/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13008/events", "html_url": "https://github.com/pytorch/pytorch/issues/13008", "id": 373225556, "node_id": "MDU6SXNzdWUzNzMyMjU1NTY=", "number": 13008, "title": "Computing conv grads via nn.grad raises ValueError when using dilation>1", "user": {"login": "bbartoldson", "id": 15717529, "node_id": "MDQ6VXNlcjE1NzE3NTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15717529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bbartoldson", "html_url": "https://github.com/bbartoldson", "followers_url": "https://api.github.com/users/bbartoldson/followers", "following_url": "https://api.github.com/users/bbartoldson/following{/other_user}", "gists_url": "https://api.github.com/users/bbartoldson/gists{/gist_id}", "starred_url": "https://api.github.com/users/bbartoldson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bbartoldson/subscriptions", "organizations_url": "https://api.github.com/users/bbartoldson/orgs", "repos_url": "https://api.github.com/users/bbartoldson/repos", "events_url": "https://api.github.com/users/bbartoldson/events{/privacy}", "received_events_url": "https://api.github.com/users/bbartoldson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-23T22:14:45Z", "updated_at": "2018-10-28T07:08:19Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>The conv grads computed by <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/grad.py\">https://github.com/pytorch/pytorch/blob/master/torch/nn/grad.py</a> rely on the function <code>_grad_input_padding()</code> (from the same file). <code>_grad_input_padding()</code> raises a ValueError when <code>dilation</code>&gt;1 because  it does not account for <code>dilation</code> when computing its expected input size.</p>\n<h2>To Reproduce</h2>\n<p>The following snippet appears to correctly create a grad with respect to the input  via <code>torch.autograd.grad</code> with dilation=2 (stored in <code>grad_input</code>). We should be able to get the same grad by using <code>torch.nn.grad.conv2d_input()</code>, but attempting to do so leads to a ValueError raised by <code>_grad_input_padding()</code> when dilation&gt;1:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn.functional <span class=\"pl-k\">as</span> F\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">5</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nweight <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\noutput <span class=\"pl-k\">=</span> F.conv2d(<span class=\"pl-c1\">input</span>, weight, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\ngrad_output <span class=\"pl-k\">=</span> torch.randn(output.shape)\ngrad_input <span class=\"pl-k\">=</span> torch.autograd.grad(output, <span class=\"pl-c1\">input</span>, grad_output)\ntorch.nn.grad.conv2d_input(<span class=\"pl-c1\">input</span>.shape, weight, grad_output, <span class=\"pl-v\">dilation</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)</pre></div>\n<h2>Error message:</h2>\n<blockquote>\n<p>File \"/home/.../anaconda3/lib/python3.7/site-packages/torch/nn/grad.py\", line 29, <strong>in _grad_input_padding</strong><br>\ngrad_output.size()[2:]))</p>\n</blockquote>\n<blockquote>\n<p>ValueError: requested an input grad size of [5, 5], but valid sizes range from [3, 3] to [3, 3] (for a grad_output of torch.Size([1, 1]))</p>\n</blockquote>\n<p><a href=\"https://ezyang.github.io/convolution-visualizer/index.html\" rel=\"nofollow\">As we would expect with a 5x5 input, 3x3 kernel, and dilation=2</a>, the output size is [1,1]. According to <code>_grad_input_padding()</code>, the only possible input size was [3,3]. I believe the fix is to make <code>_grad_input_padding()</code> account for <code>dilation</code>. In this case, accounting for dilation would allow this function to know that  [5,5] is the only acceptable input size.</p>\n<ul>\n<li>PyTorch 0.4.1 installed via conda</li>\n<li>Ubuntu 18</li>\n<li>Python 3.7</li>\n</ul>", "body_text": "\ud83d\udc1b Bug\nThe conv grads computed by https://github.com/pytorch/pytorch/blob/master/torch/nn/grad.py rely on the function _grad_input_padding() (from the same file). _grad_input_padding() raises a ValueError when dilation>1 because  it does not account for dilation when computing its expected input size.\nTo Reproduce\nThe following snippet appears to correctly create a grad with respect to the input  via torch.autograd.grad with dilation=2 (stored in grad_input). We should be able to get the same grad by using torch.nn.grad.conv2d_input(), but attempting to do so leads to a ValueError raised by _grad_input_padding() when dilation>1:\nimport torch\nimport torch.nn.functional as F\ninput = torch.randn(1,1,5,5, requires_grad=True)\nweight = torch.randn(1,1,3,3, requires_grad=True)\noutput = F.conv2d(input, weight, dilation=2)\ngrad_output = torch.randn(output.shape)\ngrad_input = torch.autograd.grad(output, input, grad_output)\ntorch.nn.grad.conv2d_input(input.shape, weight, grad_output, dilation=2)\nError message:\n\nFile \"/home/.../anaconda3/lib/python3.7/site-packages/torch/nn/grad.py\", line 29, in _grad_input_padding\ngrad_output.size()[2:]))\n\n\nValueError: requested an input grad size of [5, 5], but valid sizes range from [3, 3] to [3, 3] (for a grad_output of torch.Size([1, 1]))\n\nAs we would expect with a 5x5 input, 3x3 kernel, and dilation=2, the output size is [1,1]. According to _grad_input_padding(), the only possible input size was [3,3]. I believe the fix is to make _grad_input_padding() account for dilation. In this case, accounting for dilation would allow this function to know that  [5,5] is the only acceptable input size.\n\nPyTorch 0.4.1 installed via conda\nUbuntu 18\nPython 3.7", "body": "## \ud83d\udc1b Bug\r\n\r\nThe conv grads computed by https://github.com/pytorch/pytorch/blob/master/torch/nn/grad.py rely on the function ```_grad_input_padding()``` (from the same file). ```_grad_input_padding()``` raises a ValueError when ```dilation```>1 because  it does not account for ```dilation``` when computing its expected input size.\r\n\r\n## To Reproduce\r\n\r\nThe following snippet appears to correctly create a grad with respect to the input  via ```torch.autograd.grad``` with dilation=2 (stored in ```grad_input```). We should be able to get the same grad by using ```torch.nn.grad.conv2d_input()```, but attempting to do so leads to a ValueError raised by ```_grad_input_padding()``` when dilation>1:\r\n\r\n```python\r\nimport torch\r\nimport torch.nn.functional as F\r\ninput = torch.randn(1,1,5,5, requires_grad=True)\r\nweight = torch.randn(1,1,3,3, requires_grad=True)\r\noutput = F.conv2d(input, weight, dilation=2)\r\ngrad_output = torch.randn(output.shape)\r\ngrad_input = torch.autograd.grad(output, input, grad_output)\r\ntorch.nn.grad.conv2d_input(input.shape, weight, grad_output, dilation=2)\r\n```\r\n\r\n## Error message: \r\n\r\n>File \"/home/.../anaconda3/lib/python3.7/site-packages/torch/nn/grad.py\", line 29, **in _grad_input_padding**\r\n    grad_output.size()[2:]))\r\n\r\n>ValueError: requested an input grad size of [5, 5], but valid sizes range from [3, 3] to [3, 3] (for a grad_output of torch.Size([1, 1]))\r\n\r\n[As we would expect with a 5x5 input, 3x3 kernel, and dilation=2](https://ezyang.github.io/convolution-visualizer/index.html), the output size is [1,1]. According to ```_grad_input_padding()```, the only possible input size was [3,3]. I believe the fix is to make ```_grad_input_padding()``` account for ```dilation```. In this case, accounting for dilation would allow this function to know that  [5,5] is the only acceptable input size.\r\n\r\n - PyTorch 0.4.1 installed via conda\r\n - Ubuntu 18\r\n - Python 3.7"}