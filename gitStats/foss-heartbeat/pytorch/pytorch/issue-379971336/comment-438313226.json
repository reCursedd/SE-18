{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/438313226", "html_url": "https://github.com/pytorch/pytorch/pull/13862#issuecomment-438313226", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13862", "id": 438313226, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODMxMzIyNg==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-13T15:43:56Z", "updated_at": "2018-11-13T15:43:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm still reading through this, but to respond to your points <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1617424\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suo\">@suo</a> -- it might be, we should think about the complexity and run some benchmarks on sample models (or maybe construct something). The previous complexity bounds made it so that this pass was effectively linear in the number of nodes. Once upon a time ago our autograd profiler used O(n^2) printing (n = # of nodes). On large models printing the autograd profiler result would take hours instead of seconds...</p>", "body_text": "I'm still reading through this, but to respond to your points @suo -- it might be, we should think about the complexity and run some benchmarks on sample models (or maybe construct something). The previous complexity bounds made it so that this pass was effectively linear in the number of nodes. Once upon a time ago our autograd profiler used O(n^2) printing (n = # of nodes). On large models printing the autograd profiler result would take hours instead of seconds...", "body": "I'm still reading through this, but to respond to your points @suo -- it might be, we should think about the complexity and run some benchmarks on sample models (or maybe construct something). The previous complexity bounds made it so that this pass was effectively linear in the number of nodes. Once upon a time ago our autograd profiler used O(n^2) printing (n = # of nodes). On large models printing the autograd profiler result would take hours instead of seconds..."}