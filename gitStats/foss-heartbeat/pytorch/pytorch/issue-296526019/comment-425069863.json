{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/425069863", "html_url": "https://github.com/pytorch/pytorch/issues/5198#issuecomment-425069863", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5198", "id": 425069863, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTA2OTg2Mw==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-27T12:21:15Z", "updated_at": "2018-09-27T12:27:48Z", "author_association": "MEMBER", "body_html": "<p>Oh, I see (I hadn't checked the documentation of TF before, my bad :-) )</p>\n<p>Indeed, an equivalent to <code>tensorflow.matrix_diag</code> is currently not implemented in PyTorch, but can be implemented with a few lines:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">matrix_diag</span>(<span class=\"pl-smi\">diagonal</span>):\n    N <span class=\"pl-k\">=</span> diagonal.shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n    shape <span class=\"pl-k\">=</span> diagonal.shape[:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> (N, N)\n    device, dtype <span class=\"pl-k\">=</span> diagonal.device, diagonal.dtype\n    result <span class=\"pl-k\">=</span> torch.zeros(shape, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>device)\n    indices <span class=\"pl-k\">=</span> torch.arange(result.numel(), <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>device).reshape(shape)\n    indices <span class=\"pl-k\">=</span> indices.diagonal(<span class=\"pl-v\">dim1</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dim2</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    result.view(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)[indices] <span class=\"pl-k\">=</span> diagonal\n    <span class=\"pl-k\">return</span> result</pre></div>\n<hr>\n<p>EDIT: there is probably a way of avoiding creating a full <code>indices</code> matrix as big as the result, and directly creating it using smarter operations, but I was too lazy to do it :-) )</p>", "body_text": "Oh, I see (I hadn't checked the documentation of TF before, my bad :-) )\nIndeed, an equivalent to tensorflow.matrix_diag is currently not implemented in PyTorch, but can be implemented with a few lines:\ndef matrix_diag(diagonal):\n    N = diagonal.shape[-1]\n    shape = diagonal.shape[:-1] + (N, N)\n    device, dtype = diagonal.device, diagonal.dtype\n    result = torch.zeros(shape, dtype=dtype, device=device)\n    indices = torch.arange(result.numel(), device=device).reshape(shape)\n    indices = indices.diagonal(dim1=-2, dim2=-1)\n    result.view(-1)[indices] = diagonal\n    return result\n\nEDIT: there is probably a way of avoiding creating a full indices matrix as big as the result, and directly creating it using smarter operations, but I was too lazy to do it :-) )", "body": "Oh, I see (I hadn't checked the documentation of TF before, my bad :-) )\r\n\r\nIndeed, an equivalent to `tensorflow.matrix_diag` is currently not implemented in PyTorch, but can be implemented with a few lines:\r\n```python\r\ndef matrix_diag(diagonal):\r\n    N = diagonal.shape[-1]\r\n    shape = diagonal.shape[:-1] + (N, N)\r\n    device, dtype = diagonal.device, diagonal.dtype\r\n    result = torch.zeros(shape, dtype=dtype, device=device)\r\n    indices = torch.arange(result.numel(), device=device).reshape(shape)\r\n    indices = indices.diagonal(dim1=-2, dim2=-1)\r\n    result.view(-1)[indices] = diagonal\r\n    return result\r\n```\r\n\r\n---\r\nEDIT: there is probably a way of avoiding creating a full `indices` matrix as big as the result, and directly creating it using smarter operations, but I was too lazy to do it :-) )"}