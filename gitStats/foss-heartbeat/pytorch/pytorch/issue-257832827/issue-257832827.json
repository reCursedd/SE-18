{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2739", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2739/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2739/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2739/events", "html_url": "https://github.com/pytorch/pytorch/issues/2739", "id": 257832827, "node_id": "MDU6SXNzdWUyNTc4MzI4Mjc=", "number": 2739, "title": "Proposal: simplify overloaded Tensor function signatures", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-09-14T19:39:14Z", "updated_at": "2018-04-03T19:29:32Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>Currently we have a few functions on Tensor with multiple overloads. This makes parsing, documentation, and error messages more complicated.</p>\n<p>These overloads get ambiguous with zero-dim tensors (scalars) because they can bind to either the \"float\" or \"Tensor\" overloads.</p>\n<p>We should combine the Tensor/scalar overloads and move optional arguments to the end of the function (as keyword-only args). The old signatures will be deprecated (issue a warning) and removed from the documentation and error messages.</p>\n<p>Functions which accept a <code>Tensor</code> arguments will also accept Python numbers in their place. The numbers will automatically get promoted to zero-dim tensors.</p>\n<p><code>torch.max</code> currently has three overloads:</p>\n<pre><code>torch.max(input) -&gt; Tensor\ntorch.max(input, dim, keepdim=False) -&gt; Tensor, LongTensor\ntorch.max(input, other)\n</code></pre>\n<p>We should combine the first two overloads and make the third overload (element-wise max) a separate function (<code>fmax</code>). Eventual <code>max</code> over an array should only return the max elements (not the indices) unless <code>return_indices=True</code>. For backwards compatibility, if <code>return_indices</code> is unspecified,</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">max</span>(<span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">keepdim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-smi\">return_indices</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(dim, torch.Tensor):\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> raise deprecation warning</span>\n      <span class=\"pl-k\">return</span> fmax(<span class=\"pl-c1\">input</span>, other)\n  <span class=\"pl-k\">if</span> return_indices <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n     <span class=\"pl-k\">if</span> dim <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n       <span class=\"pl-c\"><span class=\"pl-c\">#</span> raise deprecation warning about return_indices</span>\n     return_indices <span class=\"pl-k\">=</span> dim <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> dispatch to ATen implementation</span>\n  <span class=\"pl-c1\">...</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">fmax</span>(<span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">other</span>):\n   <span class=\"pl-c\"><span class=\"pl-c\">#</span> element-wise maximum preferring non-NaN</span></pre></div>\n<p>We should also do the same for <code>torch.min</code>.</p>\n<p>We have already updated <code>add</code>, <code>addmm</code>, <code>addbmm</code>, <code>addcmul</code>, <code>sub</code>.</p>", "body_text": "Currently we have a few functions on Tensor with multiple overloads. This makes parsing, documentation, and error messages more complicated.\nThese overloads get ambiguous with zero-dim tensors (scalars) because they can bind to either the \"float\" or \"Tensor\" overloads.\nWe should combine the Tensor/scalar overloads and move optional arguments to the end of the function (as keyword-only args). The old signatures will be deprecated (issue a warning) and removed from the documentation and error messages.\nFunctions which accept a Tensor arguments will also accept Python numbers in their place. The numbers will automatically get promoted to zero-dim tensors.\ntorch.max currently has three overloads:\ntorch.max(input) -> Tensor\ntorch.max(input, dim, keepdim=False) -> Tensor, LongTensor\ntorch.max(input, other)\n\nWe should combine the first two overloads and make the third overload (element-wise max) a separate function (fmax). Eventual max over an array should only return the max elements (not the indices) unless return_indices=True. For backwards compatibility, if return_indices is unspecified,\ndef max(input, dim=None, keepdim=False, return_indices=None):\n  if isinstance(dim, torch.Tensor):\n      # raise deprecation warning\n      return fmax(input, other)\n  if return_indices is None:\n     if dim is not None:\n       # raise deprecation warning about return_indices\n     return_indices = dim is not None\n  # dispatch to ATen implementation\n  ...\n\ndef fmax(input, other):\n   # element-wise maximum preferring non-NaN\nWe should also do the same for torch.min.\nWe have already updated add, addmm, addbmm, addcmul, sub.", "body": "Currently we have a few functions on Tensor with multiple overloads. This makes parsing, documentation, and error messages more complicated.\r\n\r\nThese overloads get ambiguous with zero-dim tensors (scalars) because they can bind to either the \"float\" or \"Tensor\" overloads.\r\n\r\nWe should combine the Tensor/scalar overloads and move optional arguments to the end of the function (as keyword-only args). The old signatures will be deprecated (issue a warning) and removed from the documentation and error messages.\r\n\r\nFunctions which accept a `Tensor` arguments will also accept Python numbers in their place. The numbers will automatically get promoted to zero-dim tensors.\r\n\r\n`torch.max` currently has three overloads:\r\n\r\n```\r\ntorch.max(input) -> Tensor\r\ntorch.max(input, dim, keepdim=False) -> Tensor, LongTensor\r\ntorch.max(input, other)\r\n```\r\n\r\nWe should combine the first two overloads and make the third overload (element-wise max) a separate function (`fmax`). Eventual `max` over an array should only return the max elements (not the indices) unless `return_indices=True`. For backwards compatibility, if `return_indices` is unspecified, \r\n\r\n\r\n\r\n```python\r\ndef max(input, dim=None, keepdim=False, return_indices=None):\r\n  if isinstance(dim, torch.Tensor):\r\n      # raise deprecation warning\r\n      return fmax(input, other)\r\n  if return_indices is None:\r\n     if dim is not None:\r\n       # raise deprecation warning about return_indices\r\n     return_indices = dim is not None\r\n  # dispatch to ATen implementation\r\n  ...\r\n\r\ndef fmax(input, other):\r\n   # element-wise maximum preferring non-NaN\r\n```\r\n\r\nWe should also do the same for `torch.min`.\r\n\r\nWe have already updated `add`, `addmm`, `addbmm`, `addcmul`, `sub`."}