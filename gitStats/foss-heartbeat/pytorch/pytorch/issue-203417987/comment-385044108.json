{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/385044108", "html_url": "https://github.com/pytorch/pytorch/issues/598#issuecomment-385044108", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/598", "id": 385044108, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTA0NDEwOA==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-27T17:46:34Z", "updated_at": "2018-04-27T17:46:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>So here is a copypaste from the duplicate I filed today.</p>\n<p>The <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Module.register_backward_hook\" rel=\"nofollow\">pytorch documentation for <code>nn.Module.register_backward_hook</code></a> says:</p>\n<blockquote>\n<p>The grad_input and grad_output may be tuples if the module has multiple inputs or outputs. The hook should not modify its arguments, but it can optionally return a new gradient with respect to input that will be used in place of grad_input in subsequent computation.</p>\n</blockquote>\n<p>This is not quite accurate:</p>\n<ul>\n<li><code>grad_output</code> is indeed the gradient of the loss w.r.t. the layer output. So if you have a layer l and do, say, <code>y = l(x) ; loss = y.sum(); loss.backward()</code>, you get the gradient of <code>loss</code> w.r.t. <code>y</code>. So far so good.</li>\n<li>What is unexpected to most users is that <code>grad_input</code> are the inputs to the last operation in the layer. For linear layers, this is fairly complete, as the last op is <code>torch.addmm</code> multiplying the input with the weight and adding the bias. For other layers (e.g. do a Sequential, it\u2019ll be the last op of the last layer, the inputs not even remotely related to the sequential layer\u2019s inputs). You can see what will be used by looking at <code>y.grad_fn</code>.</li>\n</ul>\n<p>This may be confusing to users, e.g. <a href=\"https://discuss.pytorch.org/t/exact-meaning-of-grad-input-and-grad-output/14186\" rel=\"nofollow\">https://discuss.pytorch.org/t/exact-meaning-of-grad-input-and-grad-output/14186</a></p>\n<p>So improving the docs is one thing, but should we make the hook actually live up to the description?</p>\n<p>I see three strategies:</p>\n<ul>\n<li>Documentation only.</li>\n<li>The straightforward way of providing input gradients: collect the grad_ins with variable hooks and call the module hook when we have all of them. We loose the ability to return a different gradient.</li>\n<li>The somewhat convoluted way: If the module has hooks, wrap the module forward in a autograd function - similar to checkpointing. The the variable hook for the output would do the right thing.</li>\n</ul>", "body_text": "So here is a copypaste from the duplicate I filed today.\nThe pytorch documentation for nn.Module.register_backward_hook says:\n\nThe grad_input and grad_output may be tuples if the module has multiple inputs or outputs. The hook should not modify its arguments, but it can optionally return a new gradient with respect to input that will be used in place of grad_input in subsequent computation.\n\nThis is not quite accurate:\n\ngrad_output is indeed the gradient of the loss w.r.t. the layer output. So if you have a layer l and do, say, y = l(x) ; loss = y.sum(); loss.backward(), you get the gradient of loss w.r.t. y. So far so good.\nWhat is unexpected to most users is that grad_input are the inputs to the last operation in the layer. For linear layers, this is fairly complete, as the last op is torch.addmm multiplying the input with the weight and adding the bias. For other layers (e.g. do a Sequential, it\u2019ll be the last op of the last layer, the inputs not even remotely related to the sequential layer\u2019s inputs). You can see what will be used by looking at y.grad_fn.\n\nThis may be confusing to users, e.g. https://discuss.pytorch.org/t/exact-meaning-of-grad-input-and-grad-output/14186\nSo improving the docs is one thing, but should we make the hook actually live up to the description?\nI see three strategies:\n\nDocumentation only.\nThe straightforward way of providing input gradients: collect the grad_ins with variable hooks and call the module hook when we have all of them. We loose the ability to return a different gradient.\nThe somewhat convoluted way: If the module has hooks, wrap the module forward in a autograd function - similar to checkpointing. The the variable hook for the output would do the right thing.", "body": "So here is a copypaste from the duplicate I filed today.\r\n\r\nThe [pytorch documentation for `nn.Module.register_backward_hook`](http://pytorch.org/docs/master/nn.html#torch.nn.Module.register_backward_hook) says:\r\n\r\n> The grad_input and grad_output may be tuples if the module has multiple inputs or outputs. The hook should not modify its arguments, but it can optionally return a new gradient with respect to input that will be used in place of grad_input in subsequent computation.\r\n\r\nThis is not quite accurate:\r\n- `grad_output` is indeed the gradient of the loss w.r.t. the layer output. So if you have a layer l and do, say, `y = l(x) ; loss = y.sum(); loss.backward()`, you get the gradient of `loss` w.r.t. `y`. So far so good.\r\n-  What is unexpected to most users is that `grad_input` are the inputs to the last operation in the layer. For linear layers, this is fairly complete, as the last op is `torch.addmm` multiplying the input with the weight and adding the bias. For other layers (e.g. do a Sequential, it\u2019ll be the last op of the last layer, the inputs not even remotely related to the sequential layer\u2019s inputs). You can see what will be used by looking at `y.grad_fn`.\r\n\r\nThis may be confusing to users, e.g. https://discuss.pytorch.org/t/exact-meaning-of-grad-input-and-grad-output/14186\r\n\r\nSo improving the docs is one thing, but should we make the hook actually live up to the description?\r\n\r\nI see three strategies:\r\n- Documentation only.\r\n- The straightforward way of providing input gradients: collect the grad_ins with variable hooks and call the module hook when we have all of them. We loose the ability to return a different gradient.\r\n- The somewhat convoluted way: If the module has hooks, wrap the module forward in a autograd function - similar to checkpointing. The the variable hook for the output would do the right thing.\r\n"}