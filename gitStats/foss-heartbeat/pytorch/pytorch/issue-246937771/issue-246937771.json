{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2264", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2264/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2264/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2264/events", "html_url": "https://github.com/pytorch/pytorch/issues/2264", "id": 246937771, "node_id": "MDU6SXNzdWUyNDY5Mzc3NzE=", "number": 2264, "title": "Segfault when double backward on BatchNorm2d", "user": {"login": "hongyi-zhang", "id": 3592602, "node_id": "MDQ6VXNlcjM1OTI2MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3592602?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hongyi-zhang", "html_url": "https://github.com/hongyi-zhang", "followers_url": "https://api.github.com/users/hongyi-zhang/followers", "following_url": "https://api.github.com/users/hongyi-zhang/following{/other_user}", "gists_url": "https://api.github.com/users/hongyi-zhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/hongyi-zhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hongyi-zhang/subscriptions", "organizations_url": "https://api.github.com/users/hongyi-zhang/orgs", "repos_url": "https://api.github.com/users/hongyi-zhang/repos", "events_url": "https://api.github.com/users/hongyi-zhang/events{/privacy}", "received_events_url": "https://api.github.com/users/hongyi-zhang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-01T02:28:28Z", "updated_at": "2017-08-02T21:54:20Z", "closed_at": "2017-08-02T21:54:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I got <em>segmentation fault</em> when trying to twice differentiate BatchNorm2d. A simple example to reproduce the error is the network:</p>\n<p>BatchNorm2d --&gt; Linear --&gt; exp --&gt; sum</p>\n<p>Removing either BatchNorm2d or exp fixes the problem.</p>\n<p>I am on the master branch, using Python 2.7, cuda 8.0, cudnn 6.0. The error can be reproduced with the following code:</p>\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BatchNormTest(nn.Module):\n    def __init__(self, num_classes=2):\n        super(BatchNormTest, self).__init__()\n        self.bn = nn.BatchNorm2d(3)\n        self.linear = nn.Linear(3*4*4, num_classes)\n\n    def forward(self, x):\n        out = x\n        # the following line leads to SEGFAULT\n        # no SEGFAULT when commented out\n        out = self.bn(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\nb = 4\nnet = BatchNormTest()\nuse_cuda = True\ninputs = Variable(torch.rand(b,3,4,4), requires_grad=True)\nif use_cuda:\n    net.cuda()\n    inputs = inputs.cuda()\n\noutput = net(inputs)\n# this line leads to SEGFAULT\nloss1 = torch.sum(torch.exp(output))\n## whereas this line does not\n# loss1 = torch.sum(output)\ngrad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\n\ngrad = grad_params[0]\nloss = torch.sum(grad)\n\nloss.backward()\n</code></pre>\n<p>gdb information:</p>\n<pre><code>Program received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fffb698d700 (LWP 701)]\ntorch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\nwarning: Source file is more recent than executable.\n177             grad_weight,\n(gdb) where\n#0  torch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\n#1  0x00007fffecf0a392 in call_function (task=...) at torch/csrc/autograd/engine.cpp:162\n#2  torch::autograd::Engine::evaluate_function (this=this@entry=0x7fffedf93b00 &lt;engine&gt;, task=...) at torch/csrc/autograd/engine.cpp:167\n#3  0x00007fffecf0bf39 in torch::autograd::Engine::thread_main (this=this@entry=0x7fffedf93b00 &lt;engine&gt;, queue=..., device=device@entry=0) at torch/csrc/autograd/engine.cpp:117\n#4  0x00007fffecf27d1a in PythonEngine::thread_main (this=0x7fffedf93b00 &lt;engine&gt;, queue=..., device=0) at torch/csrc/autograd/python_engine.cpp:23\n#5  0x00007fffecf106ee in operator()&lt;std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;, int, void&gt; (__object=&lt;optimized out&gt;, this=&lt;optimized out&gt;)\n    at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:601\n#6  _M_invoke&lt;0ul, 1ul, 2ul&gt; (this=&lt;optimized out&gt;) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1732\n#7  operator() (this=&lt;optimized out&gt;) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1720\n#8  std::thread::_Impl&lt;std::_Bind_simple&lt;std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;, int)&gt; (torch::autograd::Engine*, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;, int)\n&gt; &gt;::_M_run() (this=&lt;optimized out&gt;) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/thread:115\n#9  0x00007fffcf81d260 in ?? () from /private/home/hongyizmit/.conda/envs/torchmaster/lib/libstdc++.so.6\n#10 0x00007ffff77c8184 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0\n</code></pre>", "body_text": "I got segmentation fault when trying to twice differentiate BatchNorm2d. A simple example to reproduce the error is the network:\nBatchNorm2d --> Linear --> exp --> sum\nRemoving either BatchNorm2d or exp fixes the problem.\nI am on the master branch, using Python 2.7, cuda 8.0, cudnn 6.0. The error can be reproduced with the following code:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BatchNormTest(nn.Module):\n    def __init__(self, num_classes=2):\n        super(BatchNormTest, self).__init__()\n        self.bn = nn.BatchNorm2d(3)\n        self.linear = nn.Linear(3*4*4, num_classes)\n\n    def forward(self, x):\n        out = x\n        # the following line leads to SEGFAULT\n        # no SEGFAULT when commented out\n        out = self.bn(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\nb = 4\nnet = BatchNormTest()\nuse_cuda = True\ninputs = Variable(torch.rand(b,3,4,4), requires_grad=True)\nif use_cuda:\n    net.cuda()\n    inputs = inputs.cuda()\n\noutput = net(inputs)\n# this line leads to SEGFAULT\nloss1 = torch.sum(torch.exp(output))\n## whereas this line does not\n# loss1 = torch.sum(output)\ngrad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\n\ngrad = grad_params[0]\nloss = torch.sum(grad)\n\nloss.backward()\n\ngdb information:\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fffb698d700 (LWP 701)]\ntorch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\nwarning: Source file is more recent than executable.\n177             grad_weight,\n(gdb) where\n#0  torch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\n#1  0x00007fffecf0a392 in call_function (task=...) at torch/csrc/autograd/engine.cpp:162\n#2  torch::autograd::Engine::evaluate_function (this=this@entry=0x7fffedf93b00 <engine>, task=...) at torch/csrc/autograd/engine.cpp:167\n#3  0x00007fffecf0bf39 in torch::autograd::Engine::thread_main (this=this@entry=0x7fffedf93b00 <engine>, queue=..., device=device@entry=0) at torch/csrc/autograd/engine.cpp:117\n#4  0x00007fffecf27d1a in PythonEngine::thread_main (this=0x7fffedf93b00 <engine>, queue=..., device=0) at torch/csrc/autograd/python_engine.cpp:23\n#5  0x00007fffecf106ee in operator()<std::shared_ptr<torch::autograd::ReadyQueue>, int, void> (__object=<optimized out>, this=<optimized out>)\n    at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:601\n#6  _M_invoke<0ul, 1ul, 2ul> (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1732\n#7  operator() (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1720\n#8  std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>, int)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>, int)\n> >::_M_run() (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/thread:115\n#9  0x00007fffcf81d260 in ?? () from /private/home/hongyizmit/.conda/envs/torchmaster/lib/libstdc++.so.6\n#10 0x00007ffff77c8184 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0", "body": "I got *segmentation fault* when trying to twice differentiate BatchNorm2d. A simple example to reproduce the error is the network:\r\n\r\nBatchNorm2d --> Linear --> exp --> sum\r\n\r\nRemoving either BatchNorm2d or exp fixes the problem.\r\n\r\nI am on the master branch, using Python 2.7, cuda 8.0, cudnn 6.0. The error can be reproduced with the following code:\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\n\r\nclass BatchNormTest(nn.Module):\r\n    def __init__(self, num_classes=2):\r\n        super(BatchNormTest, self).__init__()\r\n        self.bn = nn.BatchNorm2d(3)\r\n        self.linear = nn.Linear(3*4*4, num_classes)\r\n\r\n    def forward(self, x):\r\n        out = x\r\n        # the following line leads to SEGFAULT\r\n        # no SEGFAULT when commented out\r\n        out = self.bn(out)\r\n        out = out.view(out.size(0), -1)\r\n        out = self.linear(out)\r\n        return out\r\n\r\nb = 4\r\nnet = BatchNormTest()\r\nuse_cuda = True\r\ninputs = Variable(torch.rand(b,3,4,4), requires_grad=True)\r\nif use_cuda:\r\n    net.cuda()\r\n    inputs = inputs.cuda()\r\n\r\noutput = net(inputs)\r\n# this line leads to SEGFAULT\r\nloss1 = torch.sum(torch.exp(output))\r\n## whereas this line does not\r\n# loss1 = torch.sum(output)\r\ngrad_params = torch.autograd.grad(loss1, inputs, create_graph=True)\r\n\r\ngrad = grad_params[0]\r\nloss = torch.sum(grad)\r\n\r\nloss.backward()\r\n```\r\n\r\ngdb information:\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7fffb698d700 (LWP 701)]\r\ntorch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\r\nwarning: Source file is more recent than executable.\r\n177             grad_weight,\r\n(gdb) where\r\n#0  torch::autograd::BatchNormBackward::apply (this=0x4edfc718, grad_outputs=...) at torch/csrc/autograd/functions/batch_normalization.cpp:177\r\n#1  0x00007fffecf0a392 in call_function (task=...) at torch/csrc/autograd/engine.cpp:162\r\n#2  torch::autograd::Engine::evaluate_function (this=this@entry=0x7fffedf93b00 <engine>, task=...) at torch/csrc/autograd/engine.cpp:167\r\n#3  0x00007fffecf0bf39 in torch::autograd::Engine::thread_main (this=this@entry=0x7fffedf93b00 <engine>, queue=..., device=device@entry=0) at torch/csrc/autograd/engine.cpp:117\r\n#4  0x00007fffecf27d1a in PythonEngine::thread_main (this=0x7fffedf93b00 <engine>, queue=..., device=0) at torch/csrc/autograd/python_engine.cpp:23\r\n#5  0x00007fffecf106ee in operator()<std::shared_ptr<torch::autograd::ReadyQueue>, int, void> (__object=<optimized out>, this=<optimized out>)\r\n    at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:601\r\n#6  _M_invoke<0ul, 1ul, 2ul> (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1732\r\n#7  operator() (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/functional:1720\r\n#8  std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>, int)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>, int)\r\n> >::_M_run() (this=<optimized out>) at /private/home/hongyizmit/.conda/envs/torchmaster/gcc/include/c++/thread:115\r\n#9  0x00007fffcf81d260 in ?? () from /private/home/hongyizmit/.conda/envs/torchmaster/lib/libstdc++.so.6\r\n#10 0x00007ffff77c8184 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n```"}