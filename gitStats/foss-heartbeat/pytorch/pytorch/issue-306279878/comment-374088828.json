{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/374088828", "html_url": "https://github.com/pytorch/pytorch/issues/5863#issuecomment-374088828", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5863", "id": 374088828, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDA4ODgyOA==", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-19T03:10:00Z", "updated_at": "2018-03-19T03:11:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The behavior of <code>ByteTensor</code> has changed on <code>master</code>. Overflows are taken care of, and hence the value is restricted to the range [0, 255].</p>\n<p>For instance:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> torch.ByteTensor(<span class=\"pl-c1\">40</span>, <span class=\"pl-c1\">500</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(torch.sum(a))\n\n <span class=\"pl-c1\">213</span>\n[torch.ByteTensor of size ()]\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(torch.sum(torch.sum(a, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)))\n\n <span class=\"pl-c1\">213</span>\n[torch.ByteTensor of size ()]</pre></div>", "body_text": "The behavior of ByteTensor has changed on master. Overflows are taken care of, and hence the value is restricted to the range [0, 255].\nFor instance:\n>>> a = torch.ByteTensor(40, 500)\n>>> print(torch.sum(a))\n\n 213\n[torch.ByteTensor of size ()]\n\n>>> print(torch.sum(torch.sum(a, dim=1)))\n\n 213\n[torch.ByteTensor of size ()]", "body": "The behavior of `ByteTensor` has changed on `master`. Overflows are taken care of, and hence the value is restricted to the range [0, 255].\r\n\r\nFor instance:\r\n```python\r\n>>> a = torch.ByteTensor(40, 500)\r\n>>> print(torch.sum(a))\r\n\r\n 213\r\n[torch.ByteTensor of size ()]\r\n\r\n>>> print(torch.sum(torch.sum(a, dim=1)))\r\n\r\n 213\r\n[torch.ByteTensor of size ()]\r\n```"}