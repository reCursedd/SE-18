{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234307196", "pull_request_review_id": 175928776, "id": 234307196, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDMwNzE5Ng==", "diff_hunk": "@@ -148,51 +134,84 @@ void bernoulli_scalar_cuda_kernel(\n   // The template argument `4` below indicates that we want to operate on four\n   // element at each time. See NOTE [ CUDA_tensor_applyN helpers ] for details.\n   at::cuda::CUDA_tensor_apply1<scalar_t, 4>(\n-      ret, [seeds, p] __device__(\n-        int n, scalar_t& v1, scalar_t& v2, scalar_t& v3, scalar_t& v4) {\n-        curandStatePhilox4_32_10_t state;\n-        curand_init(\n-            seeds.first,\n-            blockIdx.x * blockDim.x + threadIdx.x,\n-            seeds.second,\n-            &state);\n-        float4 rand = curand_uniform4(&state);\n-        switch (n) {\n-          case 4: {\n-            v4 = static_cast<scalar_t>(rand.w <= p);\n-            // fallthrough\n-          }\n-          case 3: {\n-            v3 = static_cast<scalar_t>(rand.z <= p);\n-            // fallthrough\n-          }\n-          case 2: {\n-            v2 = static_cast<scalar_t>(rand.y <= p);\n-            // fallthrough\n-          }\n-          case 1: {\n-            v1 = static_cast<scalar_t>(rand.x <= p);\n-          }\n+      ret, \n+      [seeds, p] __device__(\n+      int n, scalar_t& v1, scalar_t& v2, scalar_t& v3, scalar_t& v4) {\n+      at::cuda::Philox4_32_10 engine(\n+                                seeds.first,\n+                                blockIdx.x * blockDim.x + threadIdx.x,\n+                                seeds.second);\n+      auto w = at::cuda::standard_uniform_distribution(engine);", "path": "aten/src/ATen/native/cuda/Distributions.cu", "position": null, "original_position": 183, "commit_id": "a4279c73de70eb5a87260df7f5ede98c05f4e320", "original_commit_id": "992d302ff90714182d533472c2a9f090ad79d3d8", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "body": "Fixed this by not using step=4 in the CUDA_tensor_apply1, removing the switch-case and adjusting the num_engine_calls in incrementPhiloxSeed from 4 to 1.", "created_at": "2018-11-16T18:36:56Z", "updated_at": "2018-11-23T15:55:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/13070#discussion_r234307196", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13070", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234307196"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13070#discussion_r234307196"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13070"}}, "body_html": "<p>Fixed this by not using step=4 in the CUDA_tensor_apply1, removing the switch-case and adjusting the num_engine_calls in incrementPhiloxSeed from 4 to 1.</p>", "body_text": "Fixed this by not using step=4 in the CUDA_tensor_apply1, removing the switch-case and adjusting the num_engine_calls in incrementPhiloxSeed from 4 to 1.", "in_reply_to_id": 233686272}