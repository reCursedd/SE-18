{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233676506", "pull_request_review_id": 175147402, "id": 233676506, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMzY3NjUwNg==", "diff_hunk": "@@ -0,0 +1,310 @@\n+#include \"ATen/core/Generator.h\"\n+\n+namespace at {\n+\n+/*\n+* GeneratorState copy and assign constructor implementations\n+*/\n+GeneratorState::GeneratorState(const GeneratorState& other) {\n+  this->device = other.device;\n+  this->current_seed = other.current_seed;\n+  this->device_type = other.device_type;\n+  this->philox_offset_per_thread.exchange(other.philox_offset_per_thread);\n+  new (&(this->cpu_engine)) std::mt19937_64(other.cpu_engine);\n+}\n+\n+GeneratorState& GeneratorState::operator=(const GeneratorState& other) {\n+  if(&other == this) return *this;\n+  this->device = other.device;\n+  this->current_seed = other.current_seed;\n+  this->device_type = other.device_type;\n+  this->philox_offset_per_thread.exchange(other.philox_offset_per_thread);\n+  new (&(this->cpu_engine)) std::mt19937_64(other.cpu_engine);\n+  return *this;\n+}\n+\n+/*\n+* Internal Generator API\n+*/\n+namespace detail {\n+\n+// Global generator state and constants\n+static std::once_flag cpu_device_flag;\n+static GeneratorState* default_gen_state_cpu;\n+static std::unique_ptr<Generator> default_gen_cpu;\n+\n+static int64_t num_gpus = -1;\n+static std::once_flag num_gpu_init_flag;\n+static std::deque<std::once_flag> cuda_device_flags;\n+static std::vector<GeneratorState*> default_gen_states_cuda;\n+static std::vector<std::unique_ptr<Generator>> default_gens_cuda;\n+\n+/* \n+* Populates global values and creates a generator for CPU.\n+* Note: the generator on CPU is a 64 bit Mersenne Twister Engine.\n+* Warning: this function must only be called once!\n+*/\n+static void initGlobalCPUGeneratorState(){\n+  default_gen_state_cpu = new GeneratorState();\n+  default_gen_state_cpu->philox_offset_per_thread = 0;\n+  default_gen_state_cpu->device = -1;\n+  default_gen_state_cpu->device_type = at::kCPU;\n+  default_gen_state_cpu->current_seed = 123456;\n+  std::seed_seq seq({123456});\n+  new (&(default_gen_state_cpu->cpu_engine)) std::mt19937_64(seq);\n+  default_gen_cpu.reset(new Generator(default_gen_state_cpu));\n+}\n+\n+/* \n+* Populates the global variables related to CUDA generators\n+* Warning: this function must only be called once!\n+*/\n+static void initCUDAGenVector(){\n+  num_gpus = at::detail::getCUDAHooks().getNumGPUs();\n+  cuda_device_flags.resize(num_gpus);\n+  default_gen_states_cuda.resize(num_gpus);\n+  default_gens_cuda.resize(num_gpus);\n+}\n+\n+/* \n+* Populates global values and creates a generator for CUDA\n+* Note: the engine in a CUDA generator is instantiated inside\n+* kernel and here we are only setting up the state for that\n+* engine\n+* Warning: this function must only be called once!\n+*/\n+static void initGlobalCUDAGeneratorState(int64_t device = -1){\n+  // Switches to the requested device so engines are properly associated\n+  // with it.\n+  default_gen_states_cuda[device] = new GeneratorState();\n+  default_gen_states_cuda[device]->philox_offset_per_thread = 0;\n+  default_gen_states_cuda[device]->device = device;\n+  default_gen_states_cuda[device]->device_type = at::kCUDA;\n+  default_gen_states_cuda[device]->current_seed = 123456; // keep cpu/cuda default seed same;\n+  default_gens_cuda[device].reset(new Generator(default_gen_states_cuda[device]));\n+}\n+\n+/*\n+* Gets the default generators. Lazily creates one if\n+* there is none.\n+*/\n+Generator& getDefaultGenerator(DeviceType device_type, int64_t device) {\n+  if(device_type == kCPU){\n+    std::call_once(cpu_device_flag, initGlobalCPUGeneratorState);\n+    return *(default_gen_cpu.get());\n+  }else if(device_type == kCUDA){\n+    std::call_once(num_gpu_init_flag, initCUDAGenVector);\n+    if (device == -1) device = at::detail::getCUDAHooks().current_device();\n+    AT_ASSERT(device >= 0 && device < num_gpus);\n+    std::call_once(cuda_device_flags[device], initGlobalCUDAGeneratorState, device);\n+    return *(default_gens_cuda[device].get());\n+  }else{ \n+    AT_ERROR(DeviceTypeName(device_type), \" backend type not available or is not enabled.\");\n+  }\n+}\n+\n+/*\n+* Creates a GeneratorState instance. \n+*/\n+GeneratorState* createGenerator(DeviceType device_type, int64_t device) {\n+  if(device_type == kCUDA){\n+    std::call_once(num_gpu_init_flag, initCUDAGenVector);\n+    if (device == -1) device = at::detail::getCUDAHooks().current_device();\n+    AT_ASSERT(device >= 0 && device < num_gpus);\n+  }\n+  GeneratorState* new_gen_state = new GeneratorState();\n+  new_gen_state->philox_offset_per_thread = 0;\n+  new_gen_state->device = device;\n+  new_gen_state->device_type = device_type;\n+  new_gen_state->current_seed = 123456;\n+  if(device_type == kCPU){\n+    std::seed_seq seq({123456});\n+    new (&(new_gen_state->cpu_engine)) std::mt19937_64(seq);\n+  }\n+  return new_gen_state;\n+}\n+\n+/*\n+* Utility function used in tensor implementations, which\n+* supplies the default generator to tensors, if an input generator\n+* is not supplied\n+*/\n+Generator* checkGeneratorWithDefault(Generator* gen, DeviceType device) {\n+  auto default_gen = &getDefaultGenerator(device);\n+  auto gen_ = checkGenerator(gen, default_gen);\n+  return gen_;\n+}\n+\n+/*\n+* Utility function used in tensor implementations, which\n+* performs a dynamic cast on the input generator and throws\n+* an error if the input generator is not the right type\n+*/\n+Generator* checkGenerator(Generator* expr, Generator* defaultValue) {\n+  if (!expr)\n+    expr = defaultValue;\n+  if(auto result = dynamic_cast<Generator*>(expr))\n+    return result;\n+    AT_ERROR(\"Expected a '\", typeid(Generator).name(), \"' but found '\", typeid(expr).name(), \"'\");\n+}\n+\n+} // namespace detail\n+\n+/*\n+* Generator class implementation\n+*/\n+\n+/* \n+* Gets the generator state\n+*/\n+GeneratorState* Generator::getState() {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  return this->state_; \n+}\n+\n+/* \n+* Sets the generator state. Calls state's assign constructor\n+*/ \n+void Generator::setState(GeneratorState* state_in) {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  *this->state_ = *state_in;\n+}\n+\n+/* \n+* Returns the current seed of the generator\n+*/\n+uint64_t Generator::getCurrentSeed() {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  return this->state_->current_seed;\n+}\n+\n+/* \n+* Manually seeds the engine with the seed input\n+*/\n+void Generator::setCurrentSeed(uint64_t seed) {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  this->state_->current_seed = seed;\n+  this->state_->philox_offset_per_thread = 0;\n+  if(this->state_->device_type == at::kCPU) {\n+    // Check this out: http://www.pcg-random.org/posts/cpp-seeding-surprises.html\n+    std::seed_seq seq({seed});\n+    this->state_->cpu_engine.seed(seq);\n+  }\n+}\n+\n+/* \n+* Gets the CPU engine. Throws error for other engines\n+*/\n+std::mt19937_64& Generator::getCPUEngine() {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  if(this->state_->device_type != at::kCPU) {\n+    AT_ERROR(\"getCPUEngine() function called for this Generator. it is only valid in CPU Generator\");\n+  }\n+  return this->state_->cpu_engine;\n+}\n+\n+/* \n+* Sets the CPU engine. Throws error for other engines\n+*/\n+void Generator::setCPUEngine(std::mt19937_64 engine) {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  if(this->state_->device_type != at::kCPU) {\n+    AT_ERROR(\"setCPUEngine(std::mt19937_64 engine) Invalid function called for this Generator. It is only valid in CPU Generator\");\n+  }\n+  new (&(this->state_->cpu_engine)) std::mt19937_64(engine);\n+}\n+\n+/* \n+* Gets a 64 bit random number.\n+* Throws error for other engines\n+*/\n+uint64_t Generator::random64() {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  if(this->state_->device_type != at::kCPU) {\n+    AT_ERROR(\"random64() function called for this Generator. It is only valid in CPU Generator\");\n+  }\n+  return this->state_->cpu_engine();\n+}\n+\n+/* \n+* Increments the philox offset of CUDA Generator when called in a kernel launch \n+* returns the current seed and the old offset (before increment) as a std::pair \n+* for the kernel to use\n+*\n+* Throws error when used with non-CUDA generator\n+* Inputs:\n+*   total_elements: should be *.numel() call on a Tensor\n+*   grid_size:         Total number of blocks used in a kernel\n+*   block_size:        Total number of threads used in a block\n+*   step:              loop unrolling number in a thread\n+*   num_engine_calls:  Total number of operator() calls made in a kernel\n+*\n+* How is incrementPhiloxOffset Calculated?\n+* This function takes care of the calculation AFTER Step 1. It is the\n+* kernel writer's responsibility to provide step 1, before using this function.\n+*\n+* Step 1: find how many elements per thread your kernel will produce?\n+*   - To do that, you need the grid size, block size and number of elements\n+*   - Define a block size, b. For instance, block size = 16\n+*   - Get you output tensor size, t. For instance a.numel() = 1024\n+*   - Grid size, g = t / b (make sure to use integer ceil div formula: (t + b - 1)/t)\n+*   - Ask, is grid size greater than what is available? Find that out by:\n+*     - unsigned int blocks_per_sm = \n+*        at::cuda::getCurrentDeviceProperties()->maxThreadsPerMultiProcessor/block_size;\n+*     - g_new = std::min(\n+*                 (unsigned int)at::cuda::getCurrentDeviceProperties()->multiProcessorCount * blocks_per_sm, \n+*                  grid.x);\n+*   - Now count the number of operator() calls you make to PhiloxEngine in your kernel.\n+*     Let this number be m.\n+*\n+* Step 2: This is what Generator::incrementPhiloxOffset implements. You DON'T have to do this\n+*         step if you use this function.\n+*   - Now that you have the actual grid_size, block_size and number of elements,\n+*     find out how many elements per thread your kernel will actually produce, by:\n+*     Number of Elements per Thread, n = t / (g_new * b * step)\n+*   - Therefore, the total number of randoms we need in a thread is (m x n).\n+*   - Hence, since a PhiloxEngine is launched in parallel and assigned a unique thread index \n+*     (i.e. each thread is a subsequence of the engine and has a max 2^64 random values available\n+*     per thread), we want to ensure that we have the right spacing/offset in that subsequence, when\n+*     a random number is requested. In other words, if we don't have the right spacing, we may\n+*     end up reusing some random numbers, which is undesired. The offset variable in PhiloxEngine \n+*     decides how many 128-bit random numbers to skip (i.e. how many groups of 4, 32-bit numbers to skip) \n+*     and hence makes sure that random numbers are not reused in the subsequences that the blocks use.\n+*   - Therefore, the increment formula for the following function is: \n+*       (total_elements / (grid_size * block_size * step)) * num_engine_calls\n+*   - Here is a visual of how this function works (if it explains better), when increment is 4:\n+*   - a subsequent kernel launch starts from the incremented offset value\n+*   thread 0 randoms            thread 1 randoms             thread 2 randoms\n+*   [2,1,3,7,5,8...10]          [11,2,3,5,...99]             [187,298,398...236]\n+*   ^      ^                    ^       ^                     ^          ^\n+*   |      | incremented offset |       | incremented offset  |          | incremented offset\n+*   |                           |                             |\n+*   current offset              current offset                current offset\n+*/\n+std::pair<uint64_t, uint64_t> Generator::incrementPhiloxOffset(uint64_t total_elements, \n+                                                         uint64_t grid_size,\n+                                                         uint64_t block_size,\n+                                                         uint64_t step,\n+                                                         uint64_t num_engine_calls) {\n+  std::lock_guard<std::mutex> lock(this->mutex);\n+  if(this->state_->device_type != at::kCUDA) {\n+    AT_ERROR(\"incrementPhiloxOffset() function called for this Generator. It is only valid in CUDA Generator\");\n+  }\n+  // ceil integer division\n+  uint64_t numel_per_thread = (total_elements - 1)/(block_size * grid_size * step) + 1;\n+  uint64_t increment = numel_per_thread * num_engine_calls;\n+  // we do a fetch_add such that, the philox_offset_per_thread is in a running state.\n+  // i.e. if you want to fork the philox RNG, you should create a new generator instance\n+  // philox_offset_per_thread is the only way we are exposing the state of the engine from the cuda\n+  // generator.\n+  // Each kernel using philox has to sensibly increment offset for future users of philox. So it gets the \n+  // \"old\" value for itself (before atomic add), and tells subsequent users which offset they should use, \n+  // since only the kernel knows how many randoms it intends to generate.\n+  // `fetch_add` for atomic variables returns `The value immediately preceding the effects of fetch_add function`\n+  // hence, you start with zero offset, and for each subsequent call you need `The value immediately preceding the \n+  // effects of fetch_add function`\n+  uint64_t offset = this->state_->philox_offset_per_thread.fetch_add(increment);\n+  return std::make_pair(this->state_->current_seed, offset);", "path": "aten/src/ATen/core/Generator.cpp", "position": 277, "original_position": 307, "commit_id": "a4279c73de70eb5a87260df7f5ede98c05f4e320", "original_commit_id": "992d302ff90714182d533472c2a9f090ad79d3d8", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "body": "but this does not take into account that incrementing offset by 1 will actually allow you to call () 4 times? (e.g. if numel_per_thread is 1, and num_engine_calls is 4, `increment` should be 1. Also, I'd rather not have `step` argument here, instead rolling everything into `num_engine_calls` - whether you are unrolling or not, it is still elements that a given thread processes. ", "created_at": "2018-11-15T00:44:12Z", "updated_at": "2018-11-23T15:54:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/13070#discussion_r233676506", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13070", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233676506"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13070#discussion_r233676506"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13070"}}, "body_html": "<p>but this does not take into account that incrementing offset by 1 will actually allow you to call () 4 times? (e.g. if numel_per_thread is 1, and num_engine_calls is 4, <code>increment</code> should be 1. Also, I'd rather not have <code>step</code> argument here, instead rolling everything into <code>num_engine_calls</code> - whether you are unrolling or not, it is still elements that a given thread processes.</p>", "body_text": "but this does not take into account that incrementing offset by 1 will actually allow you to call () 4 times? (e.g. if numel_per_thread is 1, and num_engine_calls is 4, increment should be 1. Also, I'd rather not have step argument here, instead rolling everything into num_engine_calls - whether you are unrolling or not, it is still elements that a given thread processes."}