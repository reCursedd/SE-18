{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/409502421", "html_url": "https://github.com/pytorch/pytorch/pull/9960#issuecomment-409502421", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9960", "id": 409502421, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTUwMjQyMQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-01T08:54:36Z", "updated_at": "2018-08-01T08:54:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>So I took the liberty of condensing your example to the following:</p>\n<pre><code>import torch\nprint (torch.__version__)\nbatch_size = 1024\ndist_size = 2048\nk = 16095\ntorch.cuda.manual_seed(k)\ntorch.manual_seed(k)\nweights = torch.empty(batch_size, dist_size, device='cuda')\nweights.uniform_(0.4, 0.6)\nweights[:, :int(dist_size/2)] = 0\nweights[:, int(dist_size/2)+4:] = 0\ns = weights.multinomial(1).squeeze(1)\nselected_probs = weights[torch.arange(batch_size), s]\nassert not (selected_probs==0).any()\n</code></pre>\n<p>(and it really fails with <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/e5c5ae302b60339ec50438885060b96479c32df8/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/e5c5ae302b60339ec50438885060b96479c32df8\"><tt>e5c5ae3</tt></a> , I had just realized I had another branch when I first posted this).</p>", "body_text": "So I took the liberty of condensing your example to the following:\nimport torch\nprint (torch.__version__)\nbatch_size = 1024\ndist_size = 2048\nk = 16095\ntorch.cuda.manual_seed(k)\ntorch.manual_seed(k)\nweights = torch.empty(batch_size, dist_size, device='cuda')\nweights.uniform_(0.4, 0.6)\nweights[:, :int(dist_size/2)] = 0\nweights[:, int(dist_size/2)+4:] = 0\ns = weights.multinomial(1).squeeze(1)\nselected_probs = weights[torch.arange(batch_size), s]\nassert not (selected_probs==0).any()\n\n(and it really fails with e5c5ae3 , I had just realized I had another branch when I first posted this).", "body": "So I took the liberty of condensing your example to the following:\r\n```\r\nimport torch\r\nprint (torch.__version__)\r\nbatch_size = 1024\r\ndist_size = 2048\r\nk = 16095\r\ntorch.cuda.manual_seed(k)\r\ntorch.manual_seed(k)\r\nweights = torch.empty(batch_size, dist_size, device='cuda')\r\nweights.uniform_(0.4, 0.6)\r\nweights[:, :int(dist_size/2)] = 0\r\nweights[:, int(dist_size/2)+4:] = 0\r\ns = weights.multinomial(1).squeeze(1)\r\nselected_probs = weights[torch.arange(batch_size), s]\r\nassert not (selected_probs==0).any()\r\n```\r\n(and it really fails with e5c5ae302b60339ec50438885060b96479c32df8 , I had just realized I had another branch when I first posted this)."}