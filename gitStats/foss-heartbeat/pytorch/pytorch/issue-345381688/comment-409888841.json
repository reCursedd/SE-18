{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/409888841", "html_url": "https://github.com/pytorch/pytorch/pull/9960#issuecomment-409888841", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9960", "id": 409888841, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTg4ODg0MQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-02T11:00:00Z", "updated_at": "2018-08-02T11:23:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>So I think the root cause is the <a href=\"https://github.com/pytorch/pytorch/blob/4a5cd4f6ab2cc9d48663189ec43e8ac20a4bb252/aten/src/THC/THCTensorRandom.cuh#L237\">inclusive prefix sum (in the comment)</a>. Here, the summation order is totally different for adjacent elements, that might lead to the observed non-monotonicity and other effects.<br>\nNow how to fix this? I see the following options:</p>\n<ul>\n<li>There is the minimal size <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=345348\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rfejgin\">@rfejgin</a> suggests at <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"291717947\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4858\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4858/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4858\">#4858</a>.</li>\n<li>One elaborate option (which I'm not 100% certain that it will suffice) would be to improve the summing - I tested using the powers of two in the bit pattern as summation units and it looks like it might help.</li>\n<li>Rounding the inputs would also likely work.</li>\n<li>My favourite solution would be to just test dist &gt; 0 in the same place as Roy would check the distances. I implemented that.<br>\nA final observation: the prefix sum is done using T instead of AccT. I'm not sure why given that shared memory of AccT type is available but I didn't change it for</li>\n</ul>", "body_text": "So I think the root cause is the inclusive prefix sum (in the comment). Here, the summation order is totally different for adjacent elements, that might lead to the observed non-monotonicity and other effects.\nNow how to fix this? I see the following options:\n\nThere is the minimal size @rfejgin suggests at #4858.\nOne elaborate option (which I'm not 100% certain that it will suffice) would be to improve the summing - I tested using the powers of two in the bit pattern as summation units and it looks like it might help.\nRounding the inputs would also likely work.\nMy favourite solution would be to just test dist > 0 in the same place as Roy would check the distances. I implemented that.\nA final observation: the prefix sum is done using T instead of AccT. I'm not sure why given that shared memory of AccT type is available but I didn't change it for", "body": "So I think the root cause is the [inclusive prefix sum (in the comment)](https://github.com/pytorch/pytorch/blob/4a5cd4f6ab2cc9d48663189ec43e8ac20a4bb252/aten/src/THC/THCTensorRandom.cuh#L237). Here, the summation order is totally different for adjacent elements, that might lead to the observed non-monotonicity and other effects.\r\nNow how to fix this? I see the following options:\r\n- There is the minimal size @rfejgin suggests at #4858.\r\n- One elaborate option (which I'm not 100% certain that it will suffice) would be to improve the summing - I tested using the powers of two in the bit pattern as summation units and it looks like it might help.\r\n- Rounding the inputs would also likely work.\r\n- My favourite solution would be to just test dist > 0 in the same place as Roy would check the distances. I implemented that.\r\nA final observation: the prefix sum is done using T instead of AccT. I'm not sure why given that shared memory of AccT type is available but I didn't change it for "}