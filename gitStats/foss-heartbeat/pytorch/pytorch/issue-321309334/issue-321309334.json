{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7386", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7386/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7386/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7386/events", "html_url": "https://github.com/pytorch/pytorch/issues/7386", "id": 321309334, "node_id": "MDU6SXNzdWUzMjEzMDkzMzQ=", "number": 7386, "title": "Tensor._version isn't updated when wrapped in a Parameter", "user": {"login": "cbcase", "id": 238403, "node_id": "MDQ6VXNlcjIzODQwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/238403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cbcase", "html_url": "https://github.com/cbcase", "followers_url": "https://api.github.com/users/cbcase/followers", "following_url": "https://api.github.com/users/cbcase/following{/other_user}", "gists_url": "https://api.github.com/users/cbcase/gists{/gist_id}", "starred_url": "https://api.github.com/users/cbcase/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cbcase/subscriptions", "organizations_url": "https://api.github.com/users/cbcase/orgs", "repos_url": "https://api.github.com/users/cbcase/repos", "events_url": "https://api.github.com/users/cbcase/events{/privacy}", "received_events_url": "https://api.github.com/users/cbcase/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-08T19:04:33Z", "updated_at": "2018-05-08T20:01:04Z", "closed_at": "2018-05-08T19:11:05Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>When you perform an in-place operation on a <code>torch.Tensor</code> that's been wrapped in a <code>torch.nn.Parameter</code>, its version counter isn't bumped -- I'd expect that it would be incremented just as if you'd acted in-place on a raw tensor.</p>\n<p>(I recognize <code>Tensor._version</code> is an internal detail, but it's really useful!)</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">3</span>,)\nx.add_(<span class=\"pl-c1\">1</span>.)\n<span class=\"pl-c1\">print</span>(x._version)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> prints \"1\" -- expected</span>\n\np <span class=\"pl-k\">=</span> torch.nn.Parameter(torch.randn(<span class=\"pl-c1\">3</span>,))\np.data.add_(<span class=\"pl-c1\">1</span>.)\n<span class=\"pl-c1\">print</span>(p.data._version)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> prints \"0\" -- \"1\" is expected</span></pre></div>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.5.0a0+9ed46c6<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.3 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: Graphics Device</p>\n<p>Nvidia driver version: 387.34<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5<br>\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.14.2)<br>\n[pip] numpydoc (0.8.0)<br>\n[pip] torch (0.5.0a0+9ed46c6)<br>\n[pip] torchtext (0.2.3)<br>\n[pip] torchvision (0.2.0)<br>\n[conda] magma-cuda90              2.3.0                         1    soumith<br>\n[conda] torch                     0.5.0a0+9ed46c6           <br>\n[conda] torchtext                 0.2.3                     <br>\n[conda] torchvision               0.2.0                     </p>", "body_text": "Issue description\nWhen you perform an in-place operation on a torch.Tensor that's been wrapped in a torch.nn.Parameter, its version counter isn't bumped -- I'd expect that it would be incremented just as if you'd acted in-place on a raw tensor.\n(I recognize Tensor._version is an internal detail, but it's really useful!)\nCode example\nx = torch.randn(3,)\nx.add_(1.)\nprint(x._version)\n# prints \"1\" -- expected\n\np = torch.nn.Parameter(torch.randn(3,))\np.data.add_(1.)\nprint(p.data._version)\n# prints \"0\" -- \"1\" is expected\nSystem Info\nCollecting environment information...\nPyTorch version: 0.5.0a0+9ed46c6\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.3 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: Graphics Device\nNvidia driver version: 387.34\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\nVersions of relevant libraries:\n[pip] numpy (1.14.2)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.5.0a0+9ed46c6)\n[pip] torchtext (0.2.3)\n[pip] torchvision (0.2.0)\n[conda] magma-cuda90              2.3.0                         1    soumith\n[conda] torch                     0.5.0a0+9ed46c6           \n[conda] torchtext                 0.2.3                     \n[conda] torchvision               0.2.0", "body": "## Issue description\r\n\r\nWhen you perform an in-place operation on a `torch.Tensor` that's been wrapped in a `torch.nn.Parameter`, its version counter isn't bumped -- I'd expect that it would be incremented just as if you'd acted in-place on a raw tensor.\r\n\r\n(I recognize `Tensor._version` is an internal detail, but it's really useful!)\r\n\r\n## Code example\r\n\r\n```python\r\nx = torch.randn(3,)\r\nx.add_(1.)\r\nprint(x._version)\r\n# prints \"1\" -- expected\r\n\r\np = torch.nn.Parameter(torch.randn(3,))\r\np.data.add_(1.)\r\nprint(p.data._version)\r\n# prints \"0\" -- \"1\" is expected\r\n```\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.5.0a0+9ed46c6\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: \r\nGPU 0: Graphics Device\r\n\r\nNvidia driver version: 387.34\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.2)\r\n[pip] numpydoc (0.8.0)\r\n[pip] torch (0.5.0a0+9ed46c6)\r\n[pip] torchtext (0.2.3)\r\n[pip] torchvision (0.2.0)\r\n[conda] magma-cuda90              2.3.0                         1    soumith\r\n[conda] torch                     0.5.0a0+9ed46c6           <pip>\r\n[conda] torchtext                 0.2.3                     <pip>\r\n[conda] torchvision               0.2.0                     <pip>"}