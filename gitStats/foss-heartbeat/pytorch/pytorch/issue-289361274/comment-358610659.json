{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/358610659", "html_url": "https://github.com/pytorch/pytorch/issues/4710#issuecomment-358610659", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4710", "id": 358610659, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODYxMDY1OQ==", "user": {"login": "berzjackson", "id": 1171221, "node_id": "MDQ6VXNlcjExNzEyMjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/1171221?v=4", "gravatar_id": "", "url": "https://api.github.com/users/berzjackson", "html_url": "https://github.com/berzjackson", "followers_url": "https://api.github.com/users/berzjackson/followers", "following_url": "https://api.github.com/users/berzjackson/following{/other_user}", "gists_url": "https://api.github.com/users/berzjackson/gists{/gist_id}", "starred_url": "https://api.github.com/users/berzjackson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/berzjackson/subscriptions", "organizations_url": "https://api.github.com/users/berzjackson/orgs", "repos_url": "https://api.github.com/users/berzjackson/repos", "events_url": "https://api.github.com/users/berzjackson/events{/privacy}", "received_events_url": "https://api.github.com/users/berzjackson/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-18T10:52:09Z", "updated_at": "2018-01-18T10:52:09Z", "author_association": "NONE", "body_html": "<p>Understood :)<br>\nLet me give it a shot then. One question though. I believe what the PyTorch team prefer here is not these workarounds but implementations that are pushed down to ATen.  Or maybe these workarounds are also acceptable as long as they are almost as efficient?</p>", "body_text": "Understood :)\nLet me give it a shot then. One question though. I believe what the PyTorch team prefer here is not these workarounds but implementations that are pushed down to ATen.  Or maybe these workarounds are also acceptable as long as they are almost as efficient?", "body": "Understood :)\r\nLet me give it a shot then. One question though. I believe what the PyTorch team prefer here is not these workarounds but implementations that are pushed down to ATen.  Or maybe these workarounds are also acceptable as long as they are almost as efficient?"}