{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8400", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8400/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8400/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8400/events", "html_url": "https://github.com/pytorch/pytorch/pull/8400", "id": 331757113, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk0NDEwNTMw", "number": 8400, "title": "More efficient kernels that avoid deprecated shuffles in Embedding and LookupTable", "user": {"login": "mcarilli", "id": 7799218, "node_id": "MDQ6VXNlcjc3OTkyMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7799218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarilli", "html_url": "https://github.com/mcarilli", "followers_url": "https://api.github.com/users/mcarilli/followers", "following_url": "https://api.github.com/users/mcarilli/following{/other_user}", "gists_url": "https://api.github.com/users/mcarilli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarilli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarilli/subscriptions", "organizations_url": "https://api.github.com/users/mcarilli/orgs", "repos_url": "https://api.github.com/users/mcarilli/repos", "events_url": "https://api.github.com/users/mcarilli/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarilli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-06-12T21:17:45Z", "updated_at": "2018-06-14T04:03:36Z", "closed_at": "2018-06-14T01:29:51Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8400", "html_url": "https://github.com/pytorch/pytorch/pull/8400", "diff_url": "https://github.com/pytorch/pytorch/pull/8400.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8400.patch"}, "body_html": "<p>I set out to clean up the deprecated shuffles that were causing warnings in ATen/native/cuda/Embedding.cu and THCUNN/LookupTable.cu, and in the process I noticed the existing implementations that did not use presorting (<code>embedding_backward_feature_kernel</code> and <code>cunn_LookupTable_accGradParametersKernelByFeature</code>) were very inefficient.  They suffered from uncoalesced memory accesses, 32-way divergence if different threads in the warp wrote to the same (colliding) row of the embedding weight matrix, and more intrinsic calls than was necessary to check for such collisions.</p>\n<p>This pull request replaces those kernels with more efficient implementations that also avoid any deprecated shuffles.  Deprecation warnings for these shuffles will no longer appear in the build.  The new implementation is fully deterministic, as required by the old kernel.  It outperforms the old kernel by between 2 and 8X across the range of parameters I tried, with especially significant improvements observed for large embedding sizes and many collisions.  My kernel's blocks do some aggregation of colliding updates in shared memory before writing them out, so it actually performs better in the case of collisions.</p>\n<p>I may be able to squeeze some more performance out of the kernel in future updates.  Currently, the kernel uses int64 where necessary (indexing into the big gradient matrices) but in my profiling tests I played with relaxing that requirement, and observed a speedup of 5%ish in some cases.  If we don't anticipate people using embedding matrices with &gt;2 billion elements, int32 indexing is low-hanging fruit for performance.</p>\n<p>The kernel launches have also been updated with appropriate arguments.</p>\n<p>Finally, I changed <code>WARP_BALLOT</code> in THCDeviceUtils.cuh to return an unsigned int, for consistency with the description of <code>__ballot_sync()</code> in the CUDA API.</p>", "body_text": "I set out to clean up the deprecated shuffles that were causing warnings in ATen/native/cuda/Embedding.cu and THCUNN/LookupTable.cu, and in the process I noticed the existing implementations that did not use presorting (embedding_backward_feature_kernel and cunn_LookupTable_accGradParametersKernelByFeature) were very inefficient.  They suffered from uncoalesced memory accesses, 32-way divergence if different threads in the warp wrote to the same (colliding) row of the embedding weight matrix, and more intrinsic calls than was necessary to check for such collisions.\nThis pull request replaces those kernels with more efficient implementations that also avoid any deprecated shuffles.  Deprecation warnings for these shuffles will no longer appear in the build.  The new implementation is fully deterministic, as required by the old kernel.  It outperforms the old kernel by between 2 and 8X across the range of parameters I tried, with especially significant improvements observed for large embedding sizes and many collisions.  My kernel's blocks do some aggregation of colliding updates in shared memory before writing them out, so it actually performs better in the case of collisions.\nI may be able to squeeze some more performance out of the kernel in future updates.  Currently, the kernel uses int64 where necessary (indexing into the big gradient matrices) but in my profiling tests I played with relaxing that requirement, and observed a speedup of 5%ish in some cases.  If we don't anticipate people using embedding matrices with >2 billion elements, int32 indexing is low-hanging fruit for performance.\nThe kernel launches have also been updated with appropriate arguments.\nFinally, I changed WARP_BALLOT in THCDeviceUtils.cuh to return an unsigned int, for consistency with the description of __ballot_sync() in the CUDA API.", "body": "I set out to clean up the deprecated shuffles that were causing warnings in ATen/native/cuda/Embedding.cu and THCUNN/LookupTable.cu, and in the process I noticed the existing implementations that did not use presorting (`embedding_backward_feature_kernel` and `cunn_LookupTable_accGradParametersKernelByFeature`) were very inefficient.  They suffered from uncoalesced memory accesses, 32-way divergence if different threads in the warp wrote to the same (colliding) row of the embedding weight matrix, and more intrinsic calls than was necessary to check for such collisions.\r\n\r\nThis pull request replaces those kernels with more efficient implementations that also avoid any deprecated shuffles.  Deprecation warnings for these shuffles will no longer appear in the build.  The new implementation is fully deterministic, as required by the old kernel.  It outperforms the old kernel by between 2 and 8X across the range of parameters I tried, with especially significant improvements observed for large embedding sizes and many collisions.  My kernel's blocks do some aggregation of colliding updates in shared memory before writing them out, so it actually performs better in the case of collisions.\r\n\r\nI may be able to squeeze some more performance out of the kernel in future updates.  Currently, the kernel uses int64 where necessary (indexing into the big gradient matrices) but in my profiling tests I played with relaxing that requirement, and observed a speedup of 5%ish in some cases.  If we don't anticipate people using embedding matrices with >2 billion elements, int32 indexing is low-hanging fruit for performance.\r\n\r\nThe kernel launches have also been updated with appropriate arguments.\r\n\r\nFinally, I changed `WARP_BALLOT` in THCDeviceUtils.cuh to return an unsigned int, for consistency with the description of `__ballot_sync()` in the CUDA API."}