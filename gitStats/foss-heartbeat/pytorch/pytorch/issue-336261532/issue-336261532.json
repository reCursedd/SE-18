{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8938", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8938/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8938/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8938/events", "html_url": "https://github.com/pytorch/pytorch/issues/8938", "id": 336261532, "node_id": "MDU6SXNzdWUzMzYyNjE1MzI=", "number": 8938, "title": "[Feature request] Get cell state from the last layer for each t when using LSTM", "user": {"login": "valsworthen", "id": 18659328, "node_id": "MDQ6VXNlcjE4NjU5MzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/18659328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/valsworthen", "html_url": "https://github.com/valsworthen", "followers_url": "https://api.github.com/users/valsworthen/followers", "following_url": "https://api.github.com/users/valsworthen/following{/other_user}", "gists_url": "https://api.github.com/users/valsworthen/gists{/gist_id}", "starred_url": "https://api.github.com/users/valsworthen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/valsworthen/subscriptions", "organizations_url": "https://api.github.com/users/valsworthen/orgs", "repos_url": "https://api.github.com/users/valsworthen/repos", "events_url": "https://api.github.com/users/valsworthen/events{/privacy}", "received_events_url": "https://api.github.com/users/valsworthen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-06-27T14:45:17Z", "updated_at": "2018-09-06T07:03:40Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello there,</p>\n<p>from the doc of <code>nn.LSTM</code>, the forward method outputs <code>output, (h_n, c_n)</code>.<br>\nCurrently <code>output</code> contains the \"output features (h_t) from the last layer of the LSTM, for each t\". I'd find it interesting if output also returned the cell state from the last layer for each t.</p>\n<p>Indeed, when trying to feed a LSTM with its predictions (for time series) you need to also provide the \"new initial\" hidden state, which is <em>not</em> (<code>h_n</code>, <code>c_n</code>).</p>\n<p>For example, for a sequence of length n, if you want to predict values t+1 for each t, you just have to input a null hidden state and the LSTM will output the predicted values. However, if now you want to predict values t+2 from the previously predicted values, you need to input a non-zero hidden state, which is (<code>h_1</code>,<code> c_1</code>) (compared to <code>h_n</code>, <code>c_n</code>).</p>\n<p>You can easily get <code>h_1</code> from <code>output</code>, but not <code>c_1</code>. Then you have to use LSTMCell which is much slower. Not that this is not a problem for RNN / GRU.</p>\n<p>I hope I'm making myself clear in the example and request.</p>\n<p>Thanks</p>", "body_text": "Hello there,\nfrom the doc of nn.LSTM, the forward method outputs output, (h_n, c_n).\nCurrently output contains the \"output features (h_t) from the last layer of the LSTM, for each t\". I'd find it interesting if output also returned the cell state from the last layer for each t.\nIndeed, when trying to feed a LSTM with its predictions (for time series) you need to also provide the \"new initial\" hidden state, which is not (h_n, c_n).\nFor example, for a sequence of length n, if you want to predict values t+1 for each t, you just have to input a null hidden state and the LSTM will output the predicted values. However, if now you want to predict values t+2 from the previously predicted values, you need to input a non-zero hidden state, which is (h_1, c_1) (compared to h_n, c_n).\nYou can easily get h_1 from output, but not c_1. Then you have to use LSTMCell which is much slower. Not that this is not a problem for RNN / GRU.\nI hope I'm making myself clear in the example and request.\nThanks", "body": "Hello there, \r\n\r\nfrom the doc of `nn.LSTM`, the forward method outputs `output, (h_n, c_n)`. \r\nCurrently `output` contains the \"output features (h_t) from the last layer of the LSTM, for each t\". I'd find it interesting if output also returned the cell state from the last layer for each t.\r\n\r\nIndeed, when trying to feed a LSTM with its predictions (for time series) you need to also provide the \"new initial\" hidden state, which is *not* (`h_n`, `c_n`).\r\n\r\nFor example, for a sequence of length n, if you want to predict values t+1 for each t, you just have to input a null hidden state and the LSTM will output the predicted values. However, if now you want to predict values t+2 from the previously predicted values, you need to input a non-zero hidden state, which is (`h_1`,` c_1`) (compared to `h_n`, `c_n`).\r\n\r\nYou can easily get `h_1` from `output`, but not `c_1`. Then you have to use LSTMCell which is much slower. Not that this is not a problem for RNN / GRU.\r\n\r\nI hope I'm making myself clear in the example and request.\r\n\r\nThanks\r\n\r\n"}