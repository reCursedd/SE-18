{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5107", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5107/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5107/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5107/events", "html_url": "https://github.com/pytorch/pytorch/issues/5107", "id": 295176833, "node_id": "MDU6SXNzdWUyOTUxNzY4MzM=", "number": 5107, "title": "Random ctypes.ArgumentError: Don't know how to convert parameter 8", "user": {"login": "antspy", "id": 625297, "node_id": "MDQ6VXNlcjYyNTI5Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/625297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/antspy", "html_url": "https://github.com/antspy", "followers_url": "https://api.github.com/users/antspy/followers", "following_url": "https://api.github.com/users/antspy/following{/other_user}", "gists_url": "https://api.github.com/users/antspy/gists{/gist_id}", "starred_url": "https://api.github.com/users/antspy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/antspy/subscriptions", "organizations_url": "https://api.github.com/users/antspy/orgs", "repos_url": "https://api.github.com/users/antspy/repos", "events_url": "https://api.github.com/users/antspy/events{/privacy}", "received_events_url": "https://api.github.com/users/antspy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 806617721, "node_id": "MDU6TGFiZWw4MDY2MTc3MjE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/cudnn", "name": "cudnn", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-07T15:20:19Z", "updated_at": "2018-05-14T23:23:24Z", "closed_at": "2018-05-14T23:23:24Z", "author_association": "NONE", "body_html": "<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: 3.6</li>\n<li>Pytorch installation method: conda</li>\n<li>Python version: 0.3</li>\n<li>CUDA/cuDNN version: 8</li>\n<li>GPU models and configuration: Titan X (Pascal)</li>\n</ul>\n<p>I am battling with a weird bug now. I start training a model, and everything works fine for a certain numbers of epochs. At what appears to be a random epoch, the following error occurs:</p>\n<p><code>ctypes.ArgumentError: argument 8: &lt;class 'TypeError'&gt;: Don't know how to convert parameter 8 </code><br>\nThis is the full traceback of the error:</p>\n<pre><code>Traceback (most recent call last):\n    File \"/home/code/train.py\", line 100 in train\nloss.backward()\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\", line 167, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n    variables, grad_variables, retain_graph)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 335, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 343, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 325, in backward_extended\n    grad_hx)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\", line 401, in backward_grad\n    ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\nctypes.ArgumentError: argument 8: &lt;class 'TypeError'&gt;: Don't know how to convert parameter 8\n\n</code></pre>\n<p>I encountered this bug the first time about a week ago, when a run was stopped after 10 epochs.<br>\nI restarted it, and it went through all 15 epochs. Then I started another run with different parameters, and it ran for 5 epochs. I restarted it, and it stopped after 1 epoch. Now I am restarting it again, but I have no idea how to debug this! Does somebody have any idea?</p>", "body_text": "OS: Ubuntu 16.04\nPyTorch version: 3.6\nPytorch installation method: conda\nPython version: 0.3\nCUDA/cuDNN version: 8\nGPU models and configuration: Titan X (Pascal)\n\nI am battling with a weird bug now. I start training a model, and everything works fine for a certain numbers of epochs. At what appears to be a random epoch, the following error occurs:\nctypes.ArgumentError: argument 8: <class 'TypeError'>: Don't know how to convert parameter 8 \nThis is the full traceback of the error:\nTraceback (most recent call last):\n    File \"/home/code/train.py\", line 100 in train\nloss.backward()\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\", line 167, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n    variables, grad_variables, retain_graph)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 335, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 343, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 325, in backward_extended\n    grad_hx)\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\", line 401, in backward_grad\n    ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\nctypes.ArgumentError: argument 8: <class 'TypeError'>: Don't know how to convert parameter 8\n\n\nI encountered this bug the first time about a week ago, when a run was stopped after 10 epochs.\nI restarted it, and it went through all 15 epochs. Then I started another run with different parameters, and it ran for 5 epochs. I restarted it, and it stopped after 1 epoch. Now I am restarting it again, but I have no idea how to debug this! Does somebody have any idea?", "body": "- OS: Ubuntu 16.04 \r\n- PyTorch version: 3.6 \r\n- Pytorch installation method: conda\r\n- Python version: 0.3\r\n- CUDA/cuDNN version: 8\r\n- GPU models and configuration: Titan X (Pascal)\r\n\r\nI am battling with a weird bug now. I start training a model, and everything works fine for a certain numbers of epochs. At what appears to be a random epoch, the following error occurs:\r\n\r\n`ctypes.ArgumentError: argument 8: <class 'TypeError'>: Don't know how to convert parameter 8\r\n`\r\nThis is the full traceback of the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n    File \"/home/code/train.py\", line 100 in train\r\nloss.backward()\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\", line 167, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\r\n    variables, grad_variables, retain_graph)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 335, in _do_backward\r\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 343, in backward\r\n    result = self.backward_extended(*nested_gradients)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 325, in backward_extended\r\n    grad_hx)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\", line 401, in backward_grad\r\n    ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\r\nctypes.ArgumentError: argument 8: <class 'TypeError'>: Don't know how to convert parameter 8\r\n\r\n```\r\n\r\nI encountered this bug the first time about a week ago, when a run was stopped after 10 epochs. \r\nI restarted it, and it went through all 15 epochs. Then I started another run with different parameters, and it ran for 5 epochs. I restarted it, and it stopped after 1 epoch. Now I am restarting it again, but I have no idea how to debug this! Does somebody have any idea?"}