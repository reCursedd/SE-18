{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1918", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1918/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1918/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1918/events", "html_url": "https://github.com/pytorch/pytorch/issues/1918", "id": 238702942, "node_id": "MDU6SXNzdWUyMzg3MDI5NDI=", "number": 1918, "title": "Check if models have same weights", "user": {"login": "lwang77", "id": 16731124, "node_id": "MDQ6VXNlcjE2NzMxMTI0", "avatar_url": "https://avatars1.githubusercontent.com/u/16731124?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lwang77", "html_url": "https://github.com/lwang77", "followers_url": "https://api.github.com/users/lwang77/followers", "following_url": "https://api.github.com/users/lwang77/following{/other_user}", "gists_url": "https://api.github.com/users/lwang77/gists{/gist_id}", "starred_url": "https://api.github.com/users/lwang77/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lwang77/subscriptions", "organizations_url": "https://api.github.com/users/lwang77/orgs", "repos_url": "https://api.github.com/users/lwang77/repos", "events_url": "https://api.github.com/users/lwang77/events{/privacy}", "received_events_url": "https://api.github.com/users/lwang77/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-27T00:06:14Z", "updated_at": "2017-06-27T00:11:03Z", "closed_at": "2017-06-27T00:11:00Z", "author_association": "NONE", "body_html": "<p>Hello, I want to be able to check if two models have the same weights in their layers. After poking around, I couldn't find a function that did this, so I implemented my own.</p>\n<pre><code>def compareModelWeights(model_a, model_b):\n    module_a = model_a._modules\n    module_b = model_b._modules\n    if len(list(module_a.keys())) != len(list(module_b.keys())):\n        return False\n    a_modules_names = list(module_a.keys())\n    b_modules_names = list(module_b.keys())\n    for i in range(len(a_modules_names)):\n        layer_name_a = a_modules_names[i]\n        layer_name_b = b_modules_names[i]\n        if layer_name_a != layer_name_b:\n            return False\n        layer_a = module_a[layer_name_a]\n        layer_b = module_b[layer_name_b]\n        if (\n            (type(layer_a) == nn.Module) or (type(layer_b) == nn.Module) or\n            (type(layer_a) == nn.Sequential) or (type(layer_b) == nn.Sequential)\n            ):\n            if not compareModelWeights(layer_a, layer_b):\n                return False\n        if hasattr(layer_a, 'weight') and hasattr(layer_b, 'weight'):\n            if not torch.equal(layer_a.weight.data, layer_b.weight.data):\n                return False\n    return True\n</code></pre>\n<p>It's recursive because modules can have a tree structure.<br>\nIf there is already a function that does this, I would love to use it in my code. If not, this might be a useful addition. Please let me know if there are any errors.</p>", "body_text": "Hello, I want to be able to check if two models have the same weights in their layers. After poking around, I couldn't find a function that did this, so I implemented my own.\ndef compareModelWeights(model_a, model_b):\n    module_a = model_a._modules\n    module_b = model_b._modules\n    if len(list(module_a.keys())) != len(list(module_b.keys())):\n        return False\n    a_modules_names = list(module_a.keys())\n    b_modules_names = list(module_b.keys())\n    for i in range(len(a_modules_names)):\n        layer_name_a = a_modules_names[i]\n        layer_name_b = b_modules_names[i]\n        if layer_name_a != layer_name_b:\n            return False\n        layer_a = module_a[layer_name_a]\n        layer_b = module_b[layer_name_b]\n        if (\n            (type(layer_a) == nn.Module) or (type(layer_b) == nn.Module) or\n            (type(layer_a) == nn.Sequential) or (type(layer_b) == nn.Sequential)\n            ):\n            if not compareModelWeights(layer_a, layer_b):\n                return False\n        if hasattr(layer_a, 'weight') and hasattr(layer_b, 'weight'):\n            if not torch.equal(layer_a.weight.data, layer_b.weight.data):\n                return False\n    return True\n\nIt's recursive because modules can have a tree structure.\nIf there is already a function that does this, I would love to use it in my code. If not, this might be a useful addition. Please let me know if there are any errors.", "body": "Hello, I want to be able to check if two models have the same weights in their layers. After poking around, I couldn't find a function that did this, so I implemented my own.\r\n```\r\ndef compareModelWeights(model_a, model_b):\r\n    module_a = model_a._modules\r\n    module_b = model_b._modules\r\n    if len(list(module_a.keys())) != len(list(module_b.keys())):\r\n        return False\r\n    a_modules_names = list(module_a.keys())\r\n    b_modules_names = list(module_b.keys())\r\n    for i in range(len(a_modules_names)):\r\n        layer_name_a = a_modules_names[i]\r\n        layer_name_b = b_modules_names[i]\r\n        if layer_name_a != layer_name_b:\r\n            return False\r\n        layer_a = module_a[layer_name_a]\r\n        layer_b = module_b[layer_name_b]\r\n        if (\r\n            (type(layer_a) == nn.Module) or (type(layer_b) == nn.Module) or\r\n            (type(layer_a) == nn.Sequential) or (type(layer_b) == nn.Sequential)\r\n            ):\r\n            if not compareModelWeights(layer_a, layer_b):\r\n                return False\r\n        if hasattr(layer_a, 'weight') and hasattr(layer_b, 'weight'):\r\n            if not torch.equal(layer_a.weight.data, layer_b.weight.data):\r\n                return False\r\n    return True\r\n```\r\n\r\nIt's recursive because modules can have a tree structure.\r\nIf there is already a function that does this, I would love to use it in my code. If not, this might be a useful addition. Please let me know if there are any errors."}