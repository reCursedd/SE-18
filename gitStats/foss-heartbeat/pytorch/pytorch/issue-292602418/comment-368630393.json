{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368630393", "html_url": "https://github.com/pytorch/pytorch/pull/4921#issuecomment-368630393", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4921", "id": 368630393, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODYzMDM5Mw==", "user": {"login": "Yi-Li", "id": 30933421, "node_id": "MDQ6VXNlcjMwOTMzNDIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30933421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yi-Li", "html_url": "https://github.com/Yi-Li", "followers_url": "https://api.github.com/users/Yi-Li/followers", "following_url": "https://api.github.com/users/Yi-Li/following{/other_user}", "gists_url": "https://api.github.com/users/Yi-Li/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yi-Li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yi-Li/subscriptions", "organizations_url": "https://api.github.com/users/Yi-Li/orgs", "repos_url": "https://api.github.com/users/Yi-Li/repos", "events_url": "https://api.github.com/users/Yi-Li/events{/privacy}", "received_events_url": "https://api.github.com/users/Yi-Li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-26T19:59:29Z", "updated_at": "2018-02-26T19:59:29Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Hi Adam,\n\nI also downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:\n\nbefore init\nafter init\nbegin rank 1\nTraceback (most recent call last):\n  File \"toy.py\", line 32, in &lt;module&gt;\n    init_processes(args.rank, size, run, 'nccl')\n  File \"toy.py\", line 23, in init_processes\n    fn(rank, size)\n  File \"toy.py\", line 11, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/home/liy/programs/pytorch/torch/distributed/__init__.py\", line 326, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error\n\nAm I using something wrongly?\n\nBest Regards,\nLissa\n\ncat toy.py:\nimport torch\nimport torch.distributed as dist\nimport argparse\n\ndef run(rank, size):\n    \"\"\" Simple point-to-point communication. \"\"\"\n    print('begin rank', rank)\n    group = dist.new_group([0, 1])\n    tensor = torch.ones(1).cuda()\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n    print('Rank ', rank, ' has data ', tensor[0])\n\ndef init_processes(rank, size, fn, backend):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    print('before init')\n    init_method=\"tcp://10.6.48.150:13530\"\n    dist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)\n    print('after init')\n    fn(rank, size)\n\n\nif __name__ == \"__main__\":\n    size = 2\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--rank', default=-1, type=int,\n                        help='rank')\n   args = parser.parse_args()\n    init_processes(args.rank, size, run, 'nccl')\n\n====================================\n\nFrom: Adam Paszke [mailto:notifications@github.com]\nSent: Monday, February 26, 2018 2:27 PM\nTo: pytorch/pytorch &lt;pytorch@noreply.github.com&gt;\nCc: Yi Li &lt;Yi.Li@jax.org&gt;; Comment &lt;comment@noreply.github.com&gt;\nSubject: Re: [pytorch/pytorch] Release NCCL distributed backend from experimental (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"292602418\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4921\" href=\"https://github.com/pytorch/pytorch/pull/4921\">#4921</a>)\n\n\nThe NCCL library provided in the repo is version 1. Version 2 is closed source and you have to download it from NVIDIA and use WITH_SYSTEM_NCCL=1\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub&lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"292602418\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4921\" href=\"https://github.com/pytorch/pytorch/pull/4921#issuecomment-368619250\">#4921 (comment)</a>&gt;, or mute the thread&lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AdgBrfU6YBGkrGJiYd4Fhvxh_qockX2wks5tYwVlgaJpZM4Rxif7\">https://github.com/notifications/unsubscribe-auth/AdgBrfU6YBGkrGJiYd4Fhvxh_qockX2wks5tYwVlgaJpZM4Rxif7</a>&gt;.\n---\n\nThe information in this email, including attachments, may be confidential and is intended solely for the addressee(s). If you believe you received this email by mistake, please notify the sender by return email as soon as possible.</div>", "body_text": "Hi Adam,\n\nI also downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:\n\nbefore init\nafter init\nbegin rank 1\nTraceback (most recent call last):\n  File \"toy.py\", line 32, in <module>\n    init_processes(args.rank, size, run, 'nccl')\n  File \"toy.py\", line 23, in init_processes\n    fn(rank, size)\n  File \"toy.py\", line 11, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/home/liy/programs/pytorch/torch/distributed/__init__.py\", line 326, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error\n\nAm I using something wrongly?\n\nBest Regards,\nLissa\n\ncat toy.py:\nimport torch\nimport torch.distributed as dist\nimport argparse\n\ndef run(rank, size):\n    \"\"\" Simple point-to-point communication. \"\"\"\n    print('begin rank', rank)\n    group = dist.new_group([0, 1])\n    tensor = torch.ones(1).cuda()\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n    print('Rank ', rank, ' has data ', tensor[0])\n\ndef init_processes(rank, size, fn, backend):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    print('before init')\n    init_method=\"tcp://10.6.48.150:13530\"\n    dist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)\n    print('after init')\n    fn(rank, size)\n\n\nif __name__ == \"__main__\":\n    size = 2\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--rank', default=-1, type=int,\n                        help='rank')\n   args = parser.parse_args()\n    init_processes(args.rank, size, run, 'nccl')\n\n====================================\n\nFrom: Adam Paszke [mailto:notifications@github.com]\nSent: Monday, February 26, 2018 2:27 PM\nTo: pytorch/pytorch <pytorch@noreply.github.com>\nCc: Yi Li <Yi.Li@jax.org>; Comment <comment@noreply.github.com>\nSubject: Re: [pytorch/pytorch] Release NCCL distributed backend from experimental (#4921)\n\n\nThe NCCL library provided in the repo is version 1. Version 2 is closed source and you have to download it from NVIDIA and use WITH_SYSTEM_NCCL=1\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub<#4921 (comment)>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AdgBrfU6YBGkrGJiYd4Fhvxh_qockX2wks5tYwVlgaJpZM4Rxif7>.\n---\n\nThe information in this email, including attachments, may be confidential and is intended solely for the addressee(s). If you believe you received this email by mistake, please notify the sender by return email as soon as possible.", "body": "Hi Adam,\r\n\r\nI also downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:\r\n\r\nbefore init\r\nafter init\r\nbegin rank 1\r\nTraceback (most recent call last):\r\n  File \"toy.py\", line 32, in <module>\r\n    init_processes(args.rank, size, run, 'nccl')\r\n  File \"toy.py\", line 23, in init_processes\r\n    fn(rank, size)\r\n  File \"toy.py\", line 11, in run\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n  File \"/home/liy/programs/pytorch/torch/distributed/__init__.py\", line 326, in all_reduce\r\n    return torch._C._dist_all_reduce(tensor, op, group)\r\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error\r\n\r\nAm I using something wrongly?\r\n\r\nBest Regards,\r\nLissa\r\n\r\ncat toy.py:\r\nimport torch\r\nimport torch.distributed as dist\r\nimport argparse\r\n\r\ndef run(rank, size):\r\n    \"\"\" Simple point-to-point communication. \"\"\"\r\n    print('begin rank', rank)\r\n    group = dist.new_group([0, 1])\r\n    tensor = torch.ones(1).cuda()\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n    print('Rank ', rank, ' has data ', tensor[0])\r\n\r\ndef init_processes(rank, size, fn, backend):\r\n    \"\"\" Initialize the distributed environment. \"\"\"\r\n    print('before init')\r\n    init_method=\"tcp://10.6.48.150:13530\"\r\n    dist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)\r\n    print('after init')\r\n    fn(rank, size)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    size = 2\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--rank', default=-1, type=int,\r\n                        help='rank')\r\n   args = parser.parse_args()\r\n    init_processes(args.rank, size, run, 'nccl')\r\n\r\n====================================\r\n\r\nFrom: Adam Paszke [mailto:notifications@github.com]\r\nSent: Monday, February 26, 2018 2:27 PM\r\nTo: pytorch/pytorch <pytorch@noreply.github.com>\r\nCc: Yi Li <Yi.Li@jax.org>; Comment <comment@noreply.github.com>\r\nSubject: Re: [pytorch/pytorch] Release NCCL distributed backend from experimental (#4921)\r\n\r\n\r\nThe NCCL library provided in the repo is version 1. Version 2 is closed source and you have to download it from NVIDIA and use WITH_SYSTEM_NCCL=1\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://github.com/pytorch/pytorch/pull/4921#issuecomment-368619250>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AdgBrfU6YBGkrGJiYd4Fhvxh_qockX2wks5tYwVlgaJpZM4Rxif7>.\r\n---\n\nThe information in this email, including attachments, may be confidential and is intended solely for the addressee(s). If you believe you received this email by mistake, please notify the sender by return email as soon as possible.\n"}