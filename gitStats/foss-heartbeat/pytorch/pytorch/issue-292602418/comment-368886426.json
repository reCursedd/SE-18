{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368886426", "html_url": "https://github.com/pytorch/pytorch/pull/4921#issuecomment-368886426", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4921", "id": 368886426, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODg4NjQyNg==", "user": {"login": "Yi-Li", "id": 30933421, "node_id": "MDQ6VXNlcjMwOTMzNDIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30933421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yi-Li", "html_url": "https://github.com/Yi-Li", "followers_url": "https://api.github.com/users/Yi-Li/followers", "following_url": "https://api.github.com/users/Yi-Li/following{/other_user}", "gists_url": "https://api.github.com/users/Yi-Li/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yi-Li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yi-Li/subscriptions", "organizations_url": "https://api.github.com/users/Yi-Li/orgs", "repos_url": "https://api.github.com/users/Yi-Li/repos", "events_url": "https://api.github.com/users/Yi-Li/events{/privacy}", "received_events_url": "https://api.github.com/users/Yi-Li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-27T13:58:29Z", "updated_at": "2018-02-27T13:58:29Z", "author_association": "NONE", "body_html": "<p>Hi Adam,</p>\n<p>Yes, I downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:</p>\n<p>before init<br>\nafter init<br>\nbegin rank 1<br>\nTraceback (most recent call last):<br>\nFile \"toy.py\", line 32, in <br>\ninit_processes(args.rank, size, run, 'nccl')<br>\nFile \"toy.py\", line 23, in init_processes<br>\nfn(rank, size)<br>\nFile \"toy.py\", line 11, in run<br>\ndist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)<br>\nFile \"/home/liy/programs/pytorch/torch/distributed/<strong>init</strong>.py\", line 326, in all_reduce<br>\nreturn torch._C._dist_all_reduce(tensor, op, group)<br>\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error</p>\n<p>Am I using something wrongly?</p>\n<p>==========================<br>\ncat toy.py:<br>\nimport torch<br>\nimport torch.distributed as dist<br>\nimport argparse</p>\n<p>def run(rank, size):<br>\n\"\"\" Simple point-to-point communication. \"\"\"<br>\nprint('begin rank', rank)<br>\ngroup = dist.new_group([0, 1])<br>\ntensor = torch.ones(1).cuda()<br>\ndist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)<br>\nprint('Rank ', rank, ' has data ', tensor[0])</p>\n<p>def init_processes(rank, size, fn, backend):<br>\n\"\"\" Initialize the distributed environment. \"\"\"<br>\nprint('before init')<br>\ninit_method=\"tcp://10.6.48.150:13530\"<br>\ndist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)<br>\nprint('after init')<br>\nfn(rank, size)</p>\n<p>if <strong>name</strong> == \"<strong>main</strong>\":<br>\nsize = 2<br>\nparser = argparse.ArgumentParser()<br>\nparser.add_argument('--rank', default=-1, type=int,<br>\nhelp='rank')<br>\nargs = parser.parse_args()<br>\ninit_processes(args.rank, size, run, 'nccl')</p>", "body_text": "Hi Adam,\nYes, I downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:\nbefore init\nafter init\nbegin rank 1\nTraceback (most recent call last):\nFile \"toy.py\", line 32, in \ninit_processes(args.rank, size, run, 'nccl')\nFile \"toy.py\", line 23, in init_processes\nfn(rank, size)\nFile \"toy.py\", line 11, in run\ndist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\nFile \"/home/liy/programs/pytorch/torch/distributed/init.py\", line 326, in all_reduce\nreturn torch._C._dist_all_reduce(tensor, op, group)\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error\nAm I using something wrongly?\n==========================\ncat toy.py:\nimport torch\nimport torch.distributed as dist\nimport argparse\ndef run(rank, size):\n\"\"\" Simple point-to-point communication. \"\"\"\nprint('begin rank', rank)\ngroup = dist.new_group([0, 1])\ntensor = torch.ones(1).cuda()\ndist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\nprint('Rank ', rank, ' has data ', tensor[0])\ndef init_processes(rank, size, fn, backend):\n\"\"\" Initialize the distributed environment. \"\"\"\nprint('before init')\ninit_method=\"tcp://10.6.48.150:13530\"\ndist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)\nprint('after init')\nfn(rank, size)\nif name == \"main\":\nsize = 2\nparser = argparse.ArgumentParser()\nparser.add_argument('--rank', default=-1, type=int,\nhelp='rank')\nargs = parser.parse_args()\ninit_processes(args.rank, size, run, 'nccl')", "body": "Hi Adam,\r\n\r\nYes, I downloaded NCCL2 from Nvidia website, tried WITH_SYSTEM_NCCL=1, and specified NCCL_INCLUDE_DIR, NCCL_LIB_DIR, NCCL_ROOT_DIR to install pytorch. The installed pytorch version is 0.4.0a0+7703670. When I run the following simple test example (toy.py), an error message was thrown:\r\n\r\nbefore init\r\nafter init\r\nbegin rank 1\r\nTraceback (most recent call last):\r\n  File \"toy.py\", line 32, in <module>\r\n    init_processes(args.rank, size, run, 'nccl')\r\n  File \"toy.py\", line 23, in init_processes\r\n    fn(rank, size)\r\n  File \"toy.py\", line 11, in run\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n  File \"/home/liy/programs/pytorch/torch/distributed/__init__.py\", line 326, in all_reduce\r\n    return torch._C._dist_all_reduce(tensor, op, group)\r\nRuntimeError: NCCL error in: /home/liy/programs/pytorch/torch/lib/THD/base/data_channels/DataChannelNccl.cpp:324, unhandled system error\r\n\r\nAm I using something wrongly?\r\n\r\n==========================\r\ncat toy.py:\r\nimport torch\r\nimport torch.distributed as dist\r\nimport argparse\r\n\r\ndef run(rank, size):\r\n    \"\"\" Simple point-to-point communication. \"\"\"\r\n    print('begin rank', rank)\r\n    group = dist.new_group([0, 1])\r\n    tensor = torch.ones(1).cuda()\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n    print('Rank ', rank, ' has data ', tensor[0])\r\n\r\ndef init_processes(rank, size, fn, backend):\r\n    \"\"\" Initialize the distributed environment. \"\"\"\r\n    print('before init')\r\n    init_method=\"tcp://10.6.48.150:13530\"\r\n    dist.init_process_group(backend,rank=rank,world_size=size,init_method=init_method)\r\n    print('after init')\r\n    fn(rank, size)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    size = 2\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--rank', default=-1, type=int,\r\n                        help='rank')\r\n   args = parser.parse_args()\r\n    init_processes(args.rank, size, run, 'nccl')\r\n\r\n"}