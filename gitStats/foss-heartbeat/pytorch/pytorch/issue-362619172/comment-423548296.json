{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/423548296", "html_url": "https://github.com/pytorch/pytorch/pull/11934#issuecomment-423548296", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11934", "id": 423548296, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzU0ODI5Ng==", "user": {"login": "csarofeen", "id": 22205833, "node_id": "MDQ6VXNlcjIyMjA1ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/22205833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csarofeen", "html_url": "https://github.com/csarofeen", "followers_url": "https://api.github.com/users/csarofeen/followers", "following_url": "https://api.github.com/users/csarofeen/following{/other_user}", "gists_url": "https://api.github.com/users/csarofeen/gists{/gist_id}", "starred_url": "https://api.github.com/users/csarofeen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csarofeen/subscriptions", "organizations_url": "https://api.github.com/users/csarofeen/orgs", "repos_url": "https://api.github.com/users/csarofeen/repos", "events_url": "https://api.github.com/users/csarofeen/events{/privacy}", "received_events_url": "https://api.github.com/users/csarofeen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-21T14:21:06Z", "updated_at": "2018-09-21T14:21:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>What do you mean for limiting the threads?<br>\nThe max number of threads were set here <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/8333f474a6a5258d5373c8e0c5abe9f17794326e/aten/src/ATen/native/cuda/LossCTC.cu#L511\">pytorch/aten/src/ATen/native/cuda/LossCTC.cu</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 511\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/8333f474a6a5258d5373c8e0c5abe9f17794326e\">8333f47</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L511\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"511\"></td>\n          <td id=\"LC511\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">constexpr</span> <span class=\"pl-k\">int</span> max_threads = std::is_same&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-k\">float</span>&gt;::value ? <span class=\"pl-c1\">1024</span> : <span class=\"pl-c1\">896</span>; <span class=\"pl-c\"><span class=\"pl-c\">//</span> we need 72 or so 32 bit registers for double</span> </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<p>So all we're doing is letting launch bounds know when compiling the kernel to expect that we need to run either 896 or 1024 threads (depending on template specialization) and that we need to be able to run at least 1 block on an SM. This will limit the number of registers available during compilation so that when we call the kernel we know it will be able to run.</p>", "body_text": "What do you mean for limiting the threads?\nThe max number of threads were set here \n  \n    \n      pytorch/aten/src/ATen/native/cuda/LossCTC.cu\n    \n    \n         Line 511\n      in\n      8333f47\n    \n    \n    \n    \n\n        \n          \n           constexpr int max_threads = std::is_same<scalar_t, float>::value ? 1024 : 896; // we need 72 or so 32 bit registers for double \n        \n    \n  \n\n\nSo all we're doing is letting launch bounds know when compiling the kernel to expect that we need to run either 896 or 1024 threads (depending on template specialization) and that we need to be able to run at least 1 block on an SM. This will limit the number of registers available during compilation so that when we call the kernel we know it will be able to run.", "body": "What do you mean for limiting the threads?\r\nThe max number of threads were set here https://github.com/pytorch/pytorch/blob/8333f474a6a5258d5373c8e0c5abe9f17794326e/aten/src/ATen/native/cuda/LossCTC.cu#L511\r\n\r\nSo all we're doing is letting launch bounds know when compiling the kernel to expect that we need to run either 896 or 1024 threads (depending on template specialization) and that we need to be able to run at least 1 block on an SM. This will limit the number of registers available during compilation so that when we call the kernel we know it will be able to run.\r\n"}