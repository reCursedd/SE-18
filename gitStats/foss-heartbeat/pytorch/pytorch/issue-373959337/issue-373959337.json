{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13119", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13119/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13119/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13119/events", "html_url": "https://github.com/pytorch/pytorch/issues/13119", "id": 373959337, "node_id": "MDU6SXNzdWUzNzM5NTkzMzc=", "number": 13119, "title": "When tensors/modules are assigned to a device they are assigned to several", "user": {"login": "lferraz", "id": 7938375, "node_id": "MDQ6VXNlcjc5MzgzNzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/7938375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lferraz", "html_url": "https://github.com/lferraz", "followers_url": "https://api.github.com/users/lferraz/followers", "following_url": "https://api.github.com/users/lferraz/following{/other_user}", "gists_url": "https://api.github.com/users/lferraz/gists{/gist_id}", "starred_url": "https://api.github.com/users/lferraz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lferraz/subscriptions", "organizations_url": "https://api.github.com/users/lferraz/orgs", "repos_url": "https://api.github.com/users/lferraz/repos", "events_url": "https://api.github.com/users/lferraz/events{/privacy}", "received_events_url": "https://api.github.com/users/lferraz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-25T13:53:15Z", "updated_at": "2018-10-29T17:46:38Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>I have 2 GPU. When I send a tensor/module to the device 1 a process is also created in the device 0.</p>\n<p>Code to reproduce the error:<br>\nimport torch<br>\na = torch.FloatTensor(3,3)<br>\nd = torch.device('cuda:1')<br>\na.to(d)</p>\n<p>The output of nvidia-dmi with the 2 processes<br>\n+------------------------------------------------------ -------------+<br>\n| NVIDIA-SMI 390.30                 Driver Version: 390.30                            |<br>\n|-------------------------------+----------------------+-------------+<br>\n|   0  GeForce GTX TIT...  Off  | 00000000:00:06.0 Off |                  N/A |<br>\n+-------------------------------+----------------------+----------+<br>\n|   1  GeForce GTX 980 Ti  Off  | 00000000:00:07.0 Off |                  N/A |<br>\n+-------------------------------+----------------------+----------+<br>\n+--------------------------------------------------------------------+<br>\n| Processes:                                                                      GPU Memory      |<br>\n|  GPU       PID   Type   Process name                             Usage                  |<br>\n|=========================== =======================|<br>\n|    0     15327      C   /home/luis/anaconda3/bin/python              354MiB |<br>\n|    1     15327      C   /home/luis/anaconda3/bin/python              346MiB |<br>\n+---------------------------------------------------------------------+</p>\n<ul>\n<li>PyTorch Version (e.g., 1.0): 0.4.1 and 1.0</li>\n<li>OS (e.g., Linux): Linux</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): conda</li>\n<li>Python version: 3.6.5</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU models and configuration: 980 Ti and 1080 Ti</li>\n<li>Any other relevant information:</li>\n</ul>", "body_text": "\ud83d\udc1b Bug\nI have 2 GPU. When I send a tensor/module to the device 1 a process is also created in the device 0.\nCode to reproduce the error:\nimport torch\na = torch.FloatTensor(3,3)\nd = torch.device('cuda:1')\na.to(d)\nThe output of nvidia-dmi with the 2 processes\n+------------------------------------------------------ -------------+\n| NVIDIA-SMI 390.30                 Driver Version: 390.30                            |\n|-------------------------------+----------------------+-------------+\n|   0  GeForce GTX TIT...  Off  | 00000000:00:06.0 Off |                  N/A |\n+-------------------------------+----------------------+----------+\n|   1  GeForce GTX 980 Ti  Off  | 00000000:00:07.0 Off |                  N/A |\n+-------------------------------+----------------------+----------+\n+--------------------------------------------------------------------+\n| Processes:                                                                      GPU Memory      |\n|  GPU       PID   Type   Process name                             Usage                  |\n|=========================== =======================|\n|    0     15327      C   /home/luis/anaconda3/bin/python              354MiB |\n|    1     15327      C   /home/luis/anaconda3/bin/python              346MiB |\n+---------------------------------------------------------------------+\n\nPyTorch Version (e.g., 1.0): 0.4.1 and 1.0\nOS (e.g., Linux): Linux\nHow you installed PyTorch (conda, pip, source): conda\nPython version: 3.6.5\nCUDA/cuDNN version:\nGPU models and configuration: 980 Ti and 1080 Ti\nAny other relevant information:", "body": "## \ud83d\udc1b Bug\r\n\r\nI have 2 GPU. When I send a tensor/module to the device 1 a process is also created in the device 0.\r\n\r\nCode to reproduce the error:\r\nimport torch\r\na = torch.FloatTensor(3,3)\r\nd = torch.device('cuda:1')\r\na.to(d)\r\n\r\nThe output of nvidia-dmi with the 2 processes\r\n+------------------------------------------------------ -------------+\r\n| NVIDIA-SMI 390.30                 Driver Version: 390.30                            |\r\n|-------------------------------+----------------------+-------------+\r\n|   0  GeForce GTX TIT...  Off  | 00000000:00:06.0 Off |                  N/A |\r\n+-------------------------------+----------------------+----------+\r\n|   1  GeForce GTX 980 Ti  Off  | 00000000:00:07.0 Off |                  N/A |\r\n+-------------------------------+----------------------+----------+                                                                               \r\n+--------------------------------------------------------------------+\r\n| Processes:                                                                      GPU Memory      |\r\n|  GPU       PID   Type   Process name                             Usage                  |\r\n|=========================== =======================|\r\n|    0     15327      C   /home/luis/anaconda3/bin/python              354MiB |\r\n|    1     15327      C   /home/luis/anaconda3/bin/python              346MiB |\r\n+---------------------------------------------------------------------+\r\n\r\n - PyTorch Version (e.g., 1.0): 0.4.1 and 1.0\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Python version: 3.6.5\r\n - CUDA/cuDNN version: \r\n - GPU models and configuration: 980 Ti and 1080 Ti\r\n - Any other relevant information:\r\n"}