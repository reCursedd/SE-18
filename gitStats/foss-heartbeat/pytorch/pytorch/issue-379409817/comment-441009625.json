{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/441009625", "html_url": "https://github.com/pytorch/pytorch/issues/13807#issuecomment-441009625", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13807", "id": 441009625, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTAwOTYyNQ==", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-22T12:03:53Z", "updated_at": "2018-11-22T12:03:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm just curious about why <code>addmm</code> is taking so much time while the underlying function <code>_th_addmm</code> is performing normally. From the implementation, <code>addmm</code> should be the same with <code>_th_addmm</code> when the matrix is not sparse.</p>\n<div class=\"highlight highlight-source-c++\"><pre>Tensor&amp; <span class=\"pl-en\">addmm_</span>(Tensor&amp; self, <span class=\"pl-k\">const</span> Tensor&amp; mat1, <span class=\"pl-k\">const</span> Tensor&amp; mat2, Scalar beta, Scalar alpha) {\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span> See Note [Multiple dispatch to sparse]</span>\n  <span class=\"pl-k\">auto</span> mat1_sparse = mat1.<span class=\"pl-c1\">is_sparse</span>();\n  <span class=\"pl-k\">if</span> (mat1_sparse) {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> inplace is not broadcasting</span>\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">s_native_addmm_</span>(self, mat1, mat2, beta, alpha);\n  } <span class=\"pl-k\">else</span> {\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">_th_addmm_</span>(self, mat1, mat2, beta, alpha);\n  }\n}</pre></div>", "body_text": "I'm just curious about why addmm is taking so much time while the underlying function _th_addmm is performing normally. From the implementation, addmm should be the same with _th_addmm when the matrix is not sparse.\nTensor& addmm_(Tensor& self, const Tensor& mat1, const Tensor& mat2, Scalar beta, Scalar alpha) {\n  // See Note [Multiple dispatch to sparse]\n  auto mat1_sparse = mat1.is_sparse();\n  if (mat1_sparse) {\n    // inplace is not broadcasting\n    return s_native_addmm_(self, mat1, mat2, beta, alpha);\n  } else {\n    return _th_addmm_(self, mat1, mat2, beta, alpha);\n  }\n}", "body": "I'm just curious about why `addmm` is taking so much time while the underlying function `_th_addmm` is performing normally. From the implementation, `addmm` should be the same with `_th_addmm` when the matrix is not sparse.\r\n```cpp\r\nTensor& addmm_(Tensor& self, const Tensor& mat1, const Tensor& mat2, Scalar beta, Scalar alpha) {\r\n  // See Note [Multiple dispatch to sparse]\r\n  auto mat1_sparse = mat1.is_sparse();\r\n  if (mat1_sparse) {\r\n    // inplace is not broadcasting\r\n    return s_native_addmm_(self, mat1, mat2, beta, alpha);\r\n  } else {\r\n    return _th_addmm_(self, mat1, mat2, beta, alpha);\r\n  }\r\n}\r\n```"}