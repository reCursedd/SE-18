{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/437646603", "html_url": "https://github.com/pytorch/pytorch/issues/13807#issuecomment-437646603", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13807", "id": 437646603, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzY0NjYwMw==", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-11T06:15:30Z", "updated_at": "2018-11-11T06:15:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I ran this script on Windows with a GTX 1080 Ti and it took 19 ms per pass. So I don't think the difference is so significant. Could you tell me something more on your cudnn installation? Have you enabled it on Windows? You can test using the following python script:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.backends.cudnn\n\ntorch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor([<span class=\"pl-c1\">1</span>.]))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> If it returns True, then cudnn is enabled.</span></pre></div>", "body_text": "I ran this script on Windows with a GTX 1080 Ti and it took 19 ms per pass. So I don't think the difference is so significant. Could you tell me something more on your cudnn installation? Have you enabled it on Windows? You can test using the following python script:\nimport torch\nimport torch.backends.cudnn\n\ntorch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor([1.]))\n# If it returns True, then cudnn is enabled.", "body": "I ran this script on Windows with a GTX 1080 Ti and it took 19 ms per pass. So I don't think the difference is so significant. Could you tell me something more on your cudnn installation? Have you enabled it on Windows? You can test using the following python script:\r\n```python\r\nimport torch\r\nimport torch.backends.cudnn\r\n\r\ntorch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor([1.]))\r\n# If it returns True, then cudnn is enabled.\r\n```"}