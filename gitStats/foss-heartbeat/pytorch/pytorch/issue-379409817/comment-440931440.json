{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/440931440", "html_url": "https://github.com/pytorch/pytorch/issues/13807#issuecomment-440931440", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13807", "id": 440931440, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDkzMTQ0MA==", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-22T06:58:01Z", "updated_at": "2018-11-22T06:58:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Here is the output of the script at my side. I have a 1080ti. I have PyTorch 0.4.1 with CUDA 9.0 and cuDNN 7.1.2.<br>\n<a href=\"https://github.com/pytorch/pytorch/files/2606625/profiling.txt\">profiling.txt</a></p>\n<pre><code>Forward pass: 0.525s\nForward pass: 0.142s\nForward pass: 0.146s\nForward pass: 0.144s\nForward pass: 0.141s\nForward pass: 0.141s\nForward pass: 0.140s\nForward pass: 0.146s\nForward pass: 0.139s\nForward pass: 0.154s\nForward pass: 0.149s\nForward pass: 0.139s\nForward pass: 0.139s\nForward pass: 0.138s\nForward pass: 0.141s\nForward pass: 0.145s\nForward pass: 0.139s\nForward pass: 0.140s\nForward pass: 0.143s\nForward pass: 0.147s\nAverage forward pass: 0.162s\n</code></pre>\n<p>Although the output shows that I'm running 2x-3x slower than you, the profiling log shows that it's actually 2x faster. From the profiling log, I can see some significant time differences in some functions like <code>_add</code> (3x slower), <code>threshold_</code> (2.5x-4x slower) and <code>addmm</code> (100x slower) in GPU time between the two OS. The functions that has a <code>cudnn</code> or <code>_th</code> prefix are not running statistically faster or slower on my side, but the these functions are actually running 2x-3x slower on your Windows PC compared to your Ubuntu PC both in CPU time(3.5x) and GPU time(1.5x).</p>", "body_text": "Here is the output of the script at my side. I have a 1080ti. I have PyTorch 0.4.1 with CUDA 9.0 and cuDNN 7.1.2.\nprofiling.txt\nForward pass: 0.525s\nForward pass: 0.142s\nForward pass: 0.146s\nForward pass: 0.144s\nForward pass: 0.141s\nForward pass: 0.141s\nForward pass: 0.140s\nForward pass: 0.146s\nForward pass: 0.139s\nForward pass: 0.154s\nForward pass: 0.149s\nForward pass: 0.139s\nForward pass: 0.139s\nForward pass: 0.138s\nForward pass: 0.141s\nForward pass: 0.145s\nForward pass: 0.139s\nForward pass: 0.140s\nForward pass: 0.143s\nForward pass: 0.147s\nAverage forward pass: 0.162s\n\nAlthough the output shows that I'm running 2x-3x slower than you, the profiling log shows that it's actually 2x faster. From the profiling log, I can see some significant time differences in some functions like _add (3x slower), threshold_ (2.5x-4x slower) and addmm (100x slower) in GPU time between the two OS. The functions that has a cudnn or _th prefix are not running statistically faster or slower on my side, but the these functions are actually running 2x-3x slower on your Windows PC compared to your Ubuntu PC both in CPU time(3.5x) and GPU time(1.5x).", "body": "Here is the output of the script at my side. I have a 1080ti. I have PyTorch 0.4.1 with CUDA 9.0 and cuDNN 7.1.2.\r\n[profiling.txt](https://github.com/pytorch/pytorch/files/2606625/profiling.txt)\r\n```\r\nForward pass: 0.525s\r\nForward pass: 0.142s\r\nForward pass: 0.146s\r\nForward pass: 0.144s\r\nForward pass: 0.141s\r\nForward pass: 0.141s\r\nForward pass: 0.140s\r\nForward pass: 0.146s\r\nForward pass: 0.139s\r\nForward pass: 0.154s\r\nForward pass: 0.149s\r\nForward pass: 0.139s\r\nForward pass: 0.139s\r\nForward pass: 0.138s\r\nForward pass: 0.141s\r\nForward pass: 0.145s\r\nForward pass: 0.139s\r\nForward pass: 0.140s\r\nForward pass: 0.143s\r\nForward pass: 0.147s\r\nAverage forward pass: 0.162s\r\n```\r\nAlthough the output shows that I'm running 2x-3x slower than you, the profiling log shows that it's actually 2x faster. From the profiling log, I can see some significant time differences in some functions like `_add` (3x slower), `threshold_` (2.5x-4x slower) and `addmm` (100x slower) in GPU time between the two OS. The functions that has a `cudnn` or `_th` prefix are not running statistically faster or slower on my side, but the these functions are actually running 2x-3x slower on your Windows PC compared to your Ubuntu PC both in CPU time(3.5x) and GPU time(1.5x). "}