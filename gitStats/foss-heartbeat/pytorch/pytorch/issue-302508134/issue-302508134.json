{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5581", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5581/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5581/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5581/events", "html_url": "https://github.com/pytorch/pytorch/pull/5581", "id": 302508134, "node_id": "MDExOlB1bGxSZXF1ZXN0MTczMDE5NDE0", "number": 5581, "title": "Fix Variable conversion on the way to/from Python", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2018-03-05T23:43:13Z", "updated_at": "2018-11-23T15:40:32Z", "closed_at": "2018-03-09T22:31:05Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5581", "html_url": "https://github.com/pytorch/pytorch/pull/5581", "diff_url": "https://github.com/pytorch/pytorch/pull/5581.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5581.patch"}, "body_html": "<p>This PR changes the behavior of how Python variables (<code>torch.tensor</code>) are converted to ATen Tensors/autograd Variables. Previously, we were unwrapping variables into plain tensors on the Python-&gt;C++ path, therefore losing autograd history. We would then create <em>new</em> variables from the tensors on the C++ -&gt; Python path. The major drawback of this is that it is currently not possible for users to define tensors from C++ (e.g. in extensions) and have them work with the autograd.</p>\n<p>Now, Python variables are dynamically converted (i.e. \"upcast\") to tensors on the Python-&gt;C++ path, and then re-wrapped into variables (i.e. without creating a new variable, just using the <code>Variable</code> constructor).</p>\n<p>For this, I had to add a function to our public C++ api that wraps tensors into variables. To avoid confusion, we want to keep users unaware of the concept of a Variable in C++. Therefore we're not using <code>torch::autograd::make_variable</code> which returns a <code>Variable</code>, but instead <code>torch::as_variable()</code> which returns a <code>Tensor</code> and is declared inside <code>torch/torch.h</code> and defined out-of-sight in <code>torch/csrc/torch.cpp</code> (new file). I went for <code>as_variable</code> because it's a bit clearer and also to avoid confusion with <code>make_variable</code> on our side (users never see <code>torch::autograd::make_variable</code>). Happy to hear thoughts on this.</p>\n<p>In the JIT we do want to unwrap/rewrap (according to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a>), so we do that manually there.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>", "body_text": "This PR changes the behavior of how Python variables (torch.tensor) are converted to ATen Tensors/autograd Variables. Previously, we were unwrapping variables into plain tensors on the Python->C++ path, therefore losing autograd history. We would then create new variables from the tensors on the C++ -> Python path. The major drawback of this is that it is currently not possible for users to define tensors from C++ (e.g. in extensions) and have them work with the autograd.\nNow, Python variables are dynamically converted (i.e. \"upcast\") to tensors on the Python->C++ path, and then re-wrapped into variables (i.e. without creating a new variable, just using the Variable constructor).\nFor this, I had to add a function to our public C++ api that wraps tensors into variables. To avoid confusion, we want to keep users unaware of the concept of a Variable in C++. Therefore we're not using torch::autograd::make_variable which returns a Variable, but instead torch::as_variable() which returns a Tensor and is declared inside torch/torch.h and defined out-of-sight in torch/csrc/torch.cpp (new file). I went for as_variable because it's a bit clearer and also to avoid confusion with make_variable on our side (users never see torch::autograd::make_variable). Happy to hear thoughts on this.\nIn the JIT we do want to unwrap/rewrap (according to @zdevito), so we do that manually there.\n@zdevito @colesbury @ezyang @apaszke", "body": "This PR changes the behavior of how Python variables (`torch.tensor`) are converted to ATen Tensors/autograd Variables. Previously, we were unwrapping variables into plain tensors on the Python->C++ path, therefore losing autograd history. We would then create *new* variables from the tensors on the C++ -> Python path. The major drawback of this is that it is currently not possible for users to define tensors from C++ (e.g. in extensions) and have them work with the autograd.\r\n\r\nNow, Python variables are dynamically converted (i.e. \"upcast\") to tensors on the Python->C++ path, and then re-wrapped into variables (i.e. without creating a new variable, just using the `Variable` constructor).\r\n\r\nFor this, I had to add a function to our public C++ api that wraps tensors into variables. To avoid confusion, we want to keep users unaware of the concept of a Variable in C++. Therefore we're not using `torch::autograd::make_variable` which returns a `Variable`, but instead `torch::as_variable()` which returns a `Tensor` and is declared inside `torch/torch.h` and defined out-of-sight in `torch/csrc/torch.cpp` (new file). I went for `as_variable` because it's a bit clearer and also to avoid confusion with `make_variable` on our side (users never see `torch::autograd::make_variable`). Happy to hear thoughts on this.\r\n\r\nIn the JIT we do want to unwrap/rewrap (according to @zdevito), so we do that manually there.\r\n\r\n@zdevito @colesbury @ezyang @apaszke "}