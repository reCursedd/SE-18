{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/371177242", "html_url": "https://github.com/pytorch/pytorch/pull/5581#issuecomment-371177242", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5581", "id": 371177242, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTE3NzI0Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-07T15:34:03Z", "updated_at": "2018-03-07T15:34:03Z", "author_association": "MEMBER", "body_html": "<p>And no, variables inside forward don\u2019t require grad and their history is irrelevant (forward runs in no grad mode). If you used the extension in backward you should have used once_differentiable or implemented and applied a backward autograd function.</p>", "body_text": "And no, variables inside forward don\u2019t require grad and their history is irrelevant (forward runs in no grad mode). If you used the extension in backward you should have used once_differentiable or implemented and applied a backward autograd function.", "body": "And no, variables inside forward don\u2019t require grad and their history is irrelevant (forward runs in no grad mode). If you used the extension in backward you should have used once_differentiable or implemented and applied a backward autograd function."}