{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/369730085", "html_url": "https://github.com/pytorch/pytorch/pull/5503#issuecomment-369730085", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5503", "id": 369730085, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTczMDA4NQ==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-01T21:03:59Z", "updated_at": "2018-03-01T21:03:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>On your questions:</p>\n<ol>\n<li>Look at the dispatch functions in Dispatch.h</li>\n<li>You can write a test in test/test_autograd.py; if you need an explicit gradient you can add it in derivatives.yaml</li>\n<li>You can use a dispatch: declaration in native_functions.yaml; see CUDA: examples in that file.</li>\n</ol>", "body_text": "On your questions:\n\nLook at the dispatch functions in Dispatch.h\nYou can write a test in test/test_autograd.py; if you need an explicit gradient you can add it in derivatives.yaml\nYou can use a dispatch: declaration in native_functions.yaml; see CUDA: examples in that file.", "body": "On your questions:\r\n1) Look at the dispatch functions in Dispatch.h\r\n2) You can write a test in test/test_autograd.py; if you need an explicit gradient you can add it in derivatives.yaml\r\n3) You can use a dispatch: declaration in native_functions.yaml; see CUDA: examples in that file."}