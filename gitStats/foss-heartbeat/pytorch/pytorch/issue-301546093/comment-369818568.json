{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/369818568", "html_url": "https://github.com/pytorch/pytorch/pull/5503#issuecomment-369818568", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5503", "id": 369818568, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTgxODU2OA==", "user": {"login": "theweiho", "id": 6696956, "node_id": "MDQ6VXNlcjY2OTY5NTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/6696956?v=4", "gravatar_id": "", "url": "https://api.github.com/users/theweiho", "html_url": "https://github.com/theweiho", "followers_url": "https://api.github.com/users/theweiho/followers", "following_url": "https://api.github.com/users/theweiho/following{/other_user}", "gists_url": "https://api.github.com/users/theweiho/gists{/gist_id}", "starred_url": "https://api.github.com/users/theweiho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/theweiho/subscriptions", "organizations_url": "https://api.github.com/users/theweiho/orgs", "repos_url": "https://api.github.com/users/theweiho/repos", "events_url": "https://api.github.com/users/theweiho/events{/privacy}", "received_events_url": "https://api.github.com/users/theweiho/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-02T04:42:59Z", "updated_at": "2018-03-02T04:42:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Fixed merge. Documentations added and exposed unique as function as well. In order to do so, it turns out using <code>IndexTensor</code> in <code>native_functions.yaml</code> makes it so that the fn is not exposed as <code>torch.unique()</code>, but only as <code>torch.autograd.Variable.unique()</code> (thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a>!) - so changed to generic Tensor and also added dispatch to other types.</p>\n<p>On further thought, realized that there's not really a sensible way to do gradients for this, so explicitly declared it as not implemented.</p>\n<p>Regarding CUDA support, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> - I pinged you, but it seems you're off the grid? In any case, I'd probably prefer to defer that - so is there a way to explicitly warn/catch CUDA usage for more graceful failure than segfault?</p>", "body_text": "Fixed merge. Documentations added and exposed unique as function as well. In order to do so, it turns out using IndexTensor in native_functions.yaml makes it so that the fn is not exposed as torch.unique(), but only as torch.autograd.Variable.unique() (thanks @gchanan!) - so changed to generic Tensor and also added dispatch to other types.\nOn further thought, realized that there's not really a sensible way to do gradients for this, so explicitly declared it as not implemented.\nRegarding CUDA support, @SsnL - I pinged you, but it seems you're off the grid? In any case, I'd probably prefer to defer that - so is there a way to explicitly warn/catch CUDA usage for more graceful failure than segfault?", "body": "Fixed merge. Documentations added and exposed unique as function as well. In order to do so, it turns out using `IndexTensor` in `native_functions.yaml` makes it so that the fn is not exposed as `torch.unique()`, but only as `torch.autograd.Variable.unique()` (thanks @gchanan!) - so changed to generic Tensor and also added dispatch to other types.\r\n\r\nOn further thought, realized that there's not really a sensible way to do gradients for this, so explicitly declared it as not implemented.\r\n\r\nRegarding CUDA support, @SsnL - I pinged you, but it seems you're off the grid? In any case, I'd probably prefer to defer that - so is there a way to explicitly warn/catch CUDA usage for more graceful failure than segfault?"}