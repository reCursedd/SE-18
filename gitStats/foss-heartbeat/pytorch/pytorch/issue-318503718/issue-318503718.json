{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7044", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7044/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7044/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7044/events", "html_url": "https://github.com/pytorch/pytorch/pull/7044", "id": 318503718, "node_id": "MDExOlB1bGxSZXF1ZXN0MTg0NjkzMTU2", "number": 7044, "title": "[JIT][ONNX] Fixes for interpreter and ONNX export for MT use case", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-27T18:21:21Z", "updated_at": "2018-11-23T15:43:26Z", "closed_at": "2018-04-28T05:23:57Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/7044", "html_url": "https://github.com/pytorch/pytorch/pull/7044", "diff_url": "https://github.com/pytorch/pytorch/pull/7044.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/7044.patch"}, "body_html": "<p>thisisfine.jpg</p>\n<p>Batched fixes:</p>\n<ul>\n<li><code>propagate_and_assign_input_and_output_shapes</code> on <code>Method</code>. We need concrete shapes for 1) inputs and outputs of the net for ONNX export 2) Some symbolics require shape information. This method first propagates shapes through the graph, then it assigns the known input and output shapes to the inputs and outputs of the net. Output shapes are required for ONNX export, so we need to assign them even if they were set to <code>Dynamic</code> by shape propagation. TODO: figure out coherent strategy here. This is pretty much a mess</li>\n<li>Implement <code>onnx::Shape</code> and <code>onnx::Reshape</code> in the interpreter. These are \"operators\" introduced in <code>torch.onnx.operators</code> that work for direct ONNX export but not for JIT tracing. This is a hacky fix, where the long-term fix is probably to re-implement these in terms of having the staged symbolic shit we had to do for PackPadded/RNN/PadPacked</li>\n<li>In ONNX export, cast sub-32 bit integral types to 32 bit before export (as required by the spec). TODO: half precision float export, see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"318240841\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/onnx/onnx/issues/838\" data-hovercard-type=\"issue\" data-hovercard-url=\"/onnx/onnx/issues/838/hovercard\" href=\"https://github.com/onnx/onnx/issues/838\">onnx/onnx#838</a></li>\n<li>in <code>encodeTypeProtoTensorType</code> skip emitting type info if the tensor type is <code>Dynamic</code></li>\n<li>In the ONNX export (<code>passes/onnx.cpp</code>), copy over <code>Value</code> types when we clone a node</li>\n<li>Implement shape propagation for <code>onnx::Shape</code> and <code>onnx::Reshape</code></li>\n<li>Implement an <code>is_concrete</code> method on <code>Type</code> and use that in various symbolics to check if we actually have a tensor type. This is used for those symbolics where a type allows us to emit a more efficient set of operators</li>\n<li>import <code>torch.onnx.utils</code> in torch/onnx/operators.py so we get the <code>g.op</code> monkey-patched shit. Monkey-patching is some garbage</li>\n<li>Take example outputs in the onnx <code>export</code> method so we can assign them, as mentioned before</li>\n<li>Added a pass to fixup the ONNX loops by inserting the <code>cond</code> input as input 1 to the loop block. This was previously removed for reasons</li>\n</ul>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>", "body_text": "thisisfine.jpg\nBatched fixes:\n\npropagate_and_assign_input_and_output_shapes on Method. We need concrete shapes for 1) inputs and outputs of the net for ONNX export 2) Some symbolics require shape information. This method first propagates shapes through the graph, then it assigns the known input and output shapes to the inputs and outputs of the net. Output shapes are required for ONNX export, so we need to assign them even if they were set to Dynamic by shape propagation. TODO: figure out coherent strategy here. This is pretty much a mess\nImplement onnx::Shape and onnx::Reshape in the interpreter. These are \"operators\" introduced in torch.onnx.operators that work for direct ONNX export but not for JIT tracing. This is a hacky fix, where the long-term fix is probably to re-implement these in terms of having the staged symbolic shit we had to do for PackPadded/RNN/PadPacked\nIn ONNX export, cast sub-32 bit integral types to 32 bit before export (as required by the spec). TODO: half precision float export, see onnx/onnx#838\nin encodeTypeProtoTensorType skip emitting type info if the tensor type is Dynamic\nIn the ONNX export (passes/onnx.cpp), copy over Value types when we clone a node\nImplement shape propagation for onnx::Shape and onnx::Reshape\nImplement an is_concrete method on Type and use that in various symbolics to check if we actually have a tensor type. This is used for those symbolics where a type allows us to emit a more efficient set of operators\nimport torch.onnx.utils in torch/onnx/operators.py so we get the g.op monkey-patched shit. Monkey-patching is some garbage\nTake example outputs in the onnx export method so we can assign them, as mentioned before\nAdded a pass to fixup the ONNX loops by inserting the cond input as input 1 to the loop block. This was previously removed for reasons\n\ncc @zdevito @apaszke", "body": "thisisfine.jpg\r\n\r\nBatched fixes:\r\n* `propagate_and_assign_input_and_output_shapes` on `Method`. We need concrete shapes for 1) inputs and outputs of the net for ONNX export 2) Some symbolics require shape information. This method first propagates shapes through the graph, then it assigns the known input and output shapes to the inputs and outputs of the net. Output shapes are required for ONNX export, so we need to assign them even if they were set to `Dynamic` by shape propagation. TODO: figure out coherent strategy here. This is pretty much a mess\r\n* Implement `onnx::Shape` and `onnx::Reshape` in the interpreter. These are \"operators\" introduced in `torch.onnx.operators` that work for direct ONNX export but not for JIT tracing. This is a hacky fix, where the long-term fix is probably to re-implement these in terms of having the staged symbolic shit we had to do for PackPadded/RNN/PadPacked\r\n* In ONNX export, cast sub-32 bit integral types to 32 bit before export (as required by the spec). TODO: half precision float export, see https://github.com/onnx/onnx/issues/838\r\n* in `encodeTypeProtoTensorType` skip emitting type info if the tensor type is `Dynamic`\r\n* In the ONNX export (`passes/onnx.cpp`), copy over `Value` types when we clone a node\r\n* Implement shape propagation for `onnx::Shape` and `onnx::Reshape`\r\n* Implement an `is_concrete` method on `Type` and use that in various symbolics to check if we actually have a tensor type. This is used for those symbolics where a type allows us to emit a more efficient set of operators\r\n* import `torch.onnx.utils` in torch/onnx/operators.py so we get the `g.op` monkey-patched shit. Monkey-patching is some garbage\r\n* Take example outputs in the onnx `export` method so we can assign them, as mentioned before\r\n* Added a pass to fixup the ONNX loops by inserting the `cond` input as input 1 to the loop block. This was previously removed for reasons\r\n\r\ncc @zdevito @apaszke "}