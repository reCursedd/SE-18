{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9468", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9468/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9468/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9468/events", "html_url": "https://github.com/pytorch/pytorch/issues/9468", "id": 341630103, "node_id": "MDU6SXNzdWUzNDE2MzAxMDM=", "number": 9468, "title": "[bug] Multiplication of tensor with numpy scalar does not always work", "user": {"login": "krishnap25", "id": 6386753, "node_id": "MDQ6VXNlcjYzODY3NTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6386753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/krishnap25", "html_url": "https://github.com/krishnap25", "followers_url": "https://api.github.com/users/krishnap25/followers", "following_url": "https://api.github.com/users/krishnap25/following{/other_user}", "gists_url": "https://api.github.com/users/krishnap25/gists{/gist_id}", "starred_url": "https://api.github.com/users/krishnap25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/krishnap25/subscriptions", "organizations_url": "https://api.github.com/users/krishnap25/orgs", "repos_url": "https://api.github.com/users/krishnap25/repos", "events_url": "https://api.github.com/users/krishnap25/events{/privacy}", "received_events_url": "https://api.github.com/users/krishnap25/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-07-16T18:36:38Z", "updated_at": "2018-09-05T17:35:05Z", "closed_at": "2018-09-05T17:35:05Z", "author_association": "NONE", "body_html": "<p>Thanks for the amazing software. I stumbled across (what I believe is a) bug when multiplying a torch tensor with a numpy scalar.</p>\n<h2>Issue description</h2>\n<p>Multiplication of a torch tensor with numpy scalars exhibits unexpected behavior depending on the order of multiplication and datatypes. Specifically, multiplication of torch.FloatTensor with np.float32 does not work. Multiplication of torch.FloatTensor with np.float64 only works when written as <code>tensor * scalar</code> when tensor.requires_grad = True.</p>\n<h2>Code example</h2>\n<h3>Trial 1: right multiplication with np.float64: the only setting that works:</h3>\n<div class=\"highlight highlight-source-python\"><pre>tensor <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32)\nscalar <span class=\"pl-k\">=</span> np.float64(<span class=\"pl-c1\">2.0</span>)\nprod <span class=\"pl-k\">=</span> tensor <span class=\"pl-k\">*</span> scalar\n<span class=\"pl-c1\">print</span>(prod, prod.requires_grad, prod.dtype)</pre></div>\n<p>The output is:</p>\n<pre><code>tensor([ 2.,  2.]) True torch.float32\n</code></pre>\n<h3>Trial 2: left multiplication with np.float64: does not work when tensor.requires_grad=True</h3>\n<div class=\"highlight highlight-source-python\"><pre>tensor <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32)\nscalar <span class=\"pl-k\">=</span> np.float64(<span class=\"pl-c1\">2.0</span>)\nprod <span class=\"pl-k\">=</span> scalar <span class=\"pl-k\">*</span> tensor\n<span class=\"pl-c1\">print</span>(prod, prod.requires_grad, prod.dtype)</pre></div>\n<p>The error message is:</p>\n<pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-26-58039673906b&gt; in &lt;module&gt;()\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\n      2 scalar = np.float64(2.0)\n----&gt; 3 prod = scalar * tensor\n      4 print(prod, prod.requires_grad, prod.dtype)\n\n~/software/anaconda3/envs/pyt4/lib/python3.6/site-packages/torch/tensor.py in __array__(self, dtype)\n    374     def __array__(self, dtype=None):\n    375         if dtype is None:\n--&gt; 376             return self.cpu().numpy()\n    377         else:\n    378             return self.cpu().numpy().astype(dtype, copy=False)\n\nRuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\n</code></pre>\n<h3>Trial 3: right multiplication with np.float32: does not work:</h3>\n<div class=\"highlight highlight-source-python\"><pre>tensor <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32)\nscalar <span class=\"pl-k\">=</span> np.float32(<span class=\"pl-c1\">2.0</span>)\nprod <span class=\"pl-k\">=</span> tensor <span class=\"pl-k\">*</span> scalar\n<span class=\"pl-c1\">print</span>(prod, prod.requires_grad, prod.dtype)</pre></div>\n<p>The error message is:</p>\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-29-1eb8188d0e28&gt; in &lt;module&gt;()\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\n      2 scalar = np.float32(2.0)\n----&gt; 3 prod = tensor * scalar\n      4 print(prod, prod.requires_grad, prod.dtype)\n\nTypeError: mul() received an invalid combination of arguments - got (numpy.float32), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\n * (float other)\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\n</code></pre>\n<h3>Trial 4: left multiplication with np.float32: does not work when tensor.requires_grad=True</h3>\n<div class=\"highlight highlight-source-python\"><pre>tensor <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32)\nscalar <span class=\"pl-k\">=</span> np.float32(<span class=\"pl-c1\">2.0</span>)\nprod <span class=\"pl-k\">=</span> scalar <span class=\"pl-k\">*</span> tensor\n<span class=\"pl-c1\">print</span>(prod, prod.requires_grad, prod.dtype)</pre></div>\n<p>Same error message as Trial 2.</p>\n<h2>System Info</h2>\n<pre><code>PyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 9.1.85\n\nOS: Ubuntu 17.10\nGCC version: (Ubuntu 6.4.0-8ubuntu1) 6.4.0 20171010\nCMake version: version 3.9.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: TITAN Xp\nGPU 1: TITAN Xp\n\nNvidia driver version: 390.30\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.14.3)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda91                    1.0                  h4c16780_0    pytorch\n[conda] pytorch                   0.4.0           py36_cuda9.1.85_cudnn7.1.2_1  [cuda91]  pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch\n</code></pre>", "body_text": "Thanks for the amazing software. I stumbled across (what I believe is a) bug when multiplying a torch tensor with a numpy scalar.\nIssue description\nMultiplication of a torch tensor with numpy scalars exhibits unexpected behavior depending on the order of multiplication and datatypes. Specifically, multiplication of torch.FloatTensor with np.float32 does not work. Multiplication of torch.FloatTensor with np.float64 only works when written as tensor * scalar when tensor.requires_grad = True.\nCode example\nTrial 1: right multiplication with np.float64: the only setting that works:\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\nscalar = np.float64(2.0)\nprod = tensor * scalar\nprint(prod, prod.requires_grad, prod.dtype)\nThe output is:\ntensor([ 2.,  2.]) True torch.float32\n\nTrial 2: left multiplication with np.float64: does not work when tensor.requires_grad=True\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\nscalar = np.float64(2.0)\nprod = scalar * tensor\nprint(prod, prod.requires_grad, prod.dtype)\nThe error message is:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-26-58039673906b> in <module>()\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\n      2 scalar = np.float64(2.0)\n----> 3 prod = scalar * tensor\n      4 print(prod, prod.requires_grad, prod.dtype)\n\n~/software/anaconda3/envs/pyt4/lib/python3.6/site-packages/torch/tensor.py in __array__(self, dtype)\n    374     def __array__(self, dtype=None):\n    375         if dtype is None:\n--> 376             return self.cpu().numpy()\n    377         else:\n    378             return self.cpu().numpy().astype(dtype, copy=False)\n\nRuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\n\nTrial 3: right multiplication with np.float32: does not work:\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\nscalar = np.float32(2.0)\nprod = tensor * scalar\nprint(prod, prod.requires_grad, prod.dtype)\nThe error message is:\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-29-1eb8188d0e28> in <module>()\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\n      2 scalar = np.float32(2.0)\n----> 3 prod = tensor * scalar\n      4 print(prod, prod.requires_grad, prod.dtype)\n\nTypeError: mul() received an invalid combination of arguments - got (numpy.float32), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\n * (float other)\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\n\nTrial 4: left multiplication with np.float32: does not work when tensor.requires_grad=True\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\nscalar = np.float32(2.0)\nprod = scalar * tensor\nprint(prod, prod.requires_grad, prod.dtype)\nSame error message as Trial 2.\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 9.1.85\n\nOS: Ubuntu 17.10\nGCC version: (Ubuntu 6.4.0-8ubuntu1) 6.4.0 20171010\nCMake version: version 3.9.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: TITAN Xp\nGPU 1: TITAN Xp\n\nNvidia driver version: 390.30\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.14.3)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda91                    1.0                  h4c16780_0    pytorch\n[conda] pytorch                   0.4.0           py36_cuda9.1.85_cudnn7.1.2_1  [cuda91]  pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch", "body": "Thanks for the amazing software. I stumbled across (what I believe is a) bug when multiplying a torch tensor with a numpy scalar. \r\n\r\n## Issue description\r\n\r\nMultiplication of a torch tensor with numpy scalars exhibits unexpected behavior depending on the order of multiplication and datatypes. Specifically, multiplication of torch.FloatTensor with np.float32 does not work. Multiplication of torch.FloatTensor with np.float64 only works when written as `tensor * scalar` when tensor.requires_grad = True.\r\n\r\n## Code example\r\n\r\n### Trial 1: right multiplication with np.float64: the only setting that works:\r\n```python\r\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\nscalar = np.float64(2.0)\r\nprod = tensor * scalar\r\nprint(prod, prod.requires_grad, prod.dtype)\r\n```\r\nThe output is:\r\n```\r\ntensor([ 2.,  2.]) True torch.float32\r\n```\r\n\r\n### Trial 2: left multiplication with np.float64: does not work when tensor.requires_grad=True\r\n```python\r\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\nscalar = np.float64(2.0)\r\nprod = scalar * tensor\r\nprint(prod, prod.requires_grad, prod.dtype)\r\n```\r\nThe error message is:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-26-58039673906b> in <module>()\r\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\n      2 scalar = np.float64(2.0)\r\n----> 3 prod = scalar * tensor\r\n      4 print(prod, prod.requires_grad, prod.dtype)\r\n\r\n~/software/anaconda3/envs/pyt4/lib/python3.6/site-packages/torch/tensor.py in __array__(self, dtype)\r\n    374     def __array__(self, dtype=None):\r\n    375         if dtype is None:\r\n--> 376             return self.cpu().numpy()\r\n    377         else:\r\n    378             return self.cpu().numpy().astype(dtype, copy=False)\r\n\r\nRuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\r\n```\r\n### Trial 3: right multiplication with np.float32: does not work:\r\n```python\r\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\nscalar = np.float32(2.0)\r\nprod = tensor * scalar\r\nprint(prod, prod.requires_grad, prod.dtype)\r\n```\r\nThe error message is:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-29-1eb8188d0e28> in <module>()\r\n      1 tensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\n      2 scalar = np.float32(2.0)\r\n----> 3 prod = tensor * scalar\r\n      4 print(prod, prod.requires_grad, prod.dtype)\r\n\r\nTypeError: mul() received an invalid combination of arguments - got (numpy.float32), but expected one of:\r\n * (Tensor other)\r\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\r\n * (float other)\r\n      didn't match because some of the arguments have invalid types: (!numpy.float32!)\r\n```\r\n\r\n### Trial 4: left multiplication with np.float32: does not work when tensor.requires_grad=True\r\n```python\r\ntensor = torch.ones(2, requires_grad=True, dtype=torch.float32)\r\nscalar = np.float32(2.0)\r\nprod = scalar * tensor\r\nprint(prod, prod.requires_grad, prod.dtype)\r\n```\r\nSame error message as Trial 2.\r\n\r\n\r\n## System Info\r\n```\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.1.85\r\n\r\nOS: Ubuntu 17.10\r\nGCC version: (Ubuntu 6.4.0-8ubuntu1) 6.4.0 20171010\r\nCMake version: version 3.9.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: \r\nGPU 0: TITAN Xp\r\nGPU 1: TITAN Xp\r\n\r\nNvidia driver version: 390.30\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.3)\r\n[pip] numpydoc (0.8.0)\r\n[pip] torch (0.4.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda91                    1.0                  h4c16780_0    pytorch\r\n[conda] pytorch                   0.4.0           py36_cuda9.1.85_cudnn7.1.2_1  [cuda91]  pytorch\r\n[conda] torchvision               0.2.1                    py36_1    pytorch\r\n```"}