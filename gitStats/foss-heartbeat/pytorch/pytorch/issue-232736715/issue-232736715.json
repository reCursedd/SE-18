{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1691", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1691/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1691/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1691/events", "html_url": "https://github.com/pytorch/pytorch/pull/1691", "id": 232736715, "node_id": "MDExOlB1bGxSZXF1ZXN0MTIzMzk4OTMx", "number": 1691, "title": "tensor coalescing dance to avoid copy for cudnn rnn parameters", "user": {"login": "jekbradbury", "id": 11729078, "node_id": "MDQ6VXNlcjExNzI5MDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11729078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jekbradbury", "html_url": "https://github.com/jekbradbury", "followers_url": "https://api.github.com/users/jekbradbury/followers", "following_url": "https://api.github.com/users/jekbradbury/following{/other_user}", "gists_url": "https://api.github.com/users/jekbradbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/jekbradbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jekbradbury/subscriptions", "organizations_url": "https://api.github.com/users/jekbradbury/orgs", "repos_url": "https://api.github.com/users/jekbradbury/repos", "events_url": "https://api.github.com/users/jekbradbury/events{/privacy}", "received_events_url": "https://api.github.com/users/jekbradbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2017-06-01T00:50:34Z", "updated_at": "2017-06-22T21:40:43Z", "closed_at": "2017-06-22T21:40:43Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1691", "html_url": "https://github.com/pytorch/pytorch/pull/1691", "diff_url": "https://github.com/pytorch/pytorch/pull/1691.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1691.patch"}, "body_html": "<p>Intended to solve <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"211777412\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/914\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/914/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/914\">#914</a>, and currently passing tests.<br>\nI haven't yet run memory/performance comparisons, but I wanted to see if <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> and others are okay with the approach I've taken. I also coalesce on the gradients during the backward pass, which should save a memcpy but doesn't save any memory unless we can get the tensors that will receive the weight gradients to persist between calls.</p>", "body_text": "Intended to solve #914, and currently passing tests.\nI haven't yet run memory/performance comparisons, but I wanted to see if @apaszke and others are okay with the approach I've taken. I also coalesce on the gradients during the backward pass, which should save a memcpy but doesn't save any memory unless we can get the tensors that will receive the weight gradients to persist between calls.", "body": "Intended to solve #914, and currently passing tests.\r\nI haven't yet run memory/performance comparisons, but I wanted to see if @apaszke and others are okay with the approach I've taken. I also coalesce on the gradients during the backward pass, which should save a memcpy but doesn't save any memory unless we can get the tensors that will receive the weight gradients to persist between calls."}