{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2754", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2754/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2754/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2754/events", "html_url": "https://github.com/pytorch/pytorch/issues/2754", "id": 258175893, "node_id": "MDU6SXNzdWUyNTgxNzU4OTM=", "number": 2754, "title": "ppc64le test_cuda.py failures", "user": {"login": "avmgithub", "id": 9083746, "node_id": "MDQ6VXNlcjkwODM3NDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9083746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avmgithub", "html_url": "https://github.com/avmgithub", "followers_url": "https://api.github.com/users/avmgithub/followers", "following_url": "https://api.github.com/users/avmgithub/following{/other_user}", "gists_url": "https://api.github.com/users/avmgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/avmgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avmgithub/subscriptions", "organizations_url": "https://api.github.com/users/avmgithub/orgs", "repos_url": "https://api.github.com/users/avmgithub/repos", "events_url": "https://api.github.com/users/avmgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/avmgithub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-09-15T22:02:03Z", "updated_at": "2017-10-02T21:41:17Z", "closed_at": "2017-10-02T21:41:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am using ppc64 Ubuntu 16.04.<br>\nI compiled pytorch version 0.2.0 and am running into some problems with test_cuda.py.<br>\nTo isolate the failures I commented out some of the types and float_types like so:</p>\n<p>types = [<br>\n#    torch.FloatTensor,<br>\n#    torch.DoubleTensor,<br>\n#    torch.LongTensor,<br>\n#    torch.IntTensor,<br>\n#    torch.ShortTensor,<br>\ntorch.CharTensor,<br>\n#    torch.ByteTensor,<br>\n]</p>\n<p>float_types = [<br>\ntorch.FloatTensor,<br>\n#   torch.DoubleTensor<br>\n]  # TODO: add half...</p>\n<p>Then I run \"python test_cuda.py\"<br>\nI get a bunch of these errors:<br>\n/opt/pytorch/torch/lib/THC/THCTensorTopK.cuh:431: void gatherTopK(TensorInfo&lt;T, IndexType&gt;, IndexType, IndexType, IndexType, IndexType, TensorInfo&lt;T, IndexType&gt;, IndexType, IndexType, TensorInfo&lt;long, IndexType&gt;, IndexType) [with T = char, IndexType = unsigned int, Dim = 3, Order = true]: block: [64,0,0], thread: [9,0,0] Assertion <code>writeIndex &lt; outputSliceSize</code> failed.</p>\n<p>the only difference in each line are the block and thread data</p>\n<p>I also get a bunch of these for different tests:</p>\n<p>ERROR: test_CharTensor_tril (<strong>main</strong>.TestCuda)</p>\n<hr>\n<p>Traceback (most recent call last):<br>\nFile \"mytest_cuda.py\", line 358, in tmp<br>\ngpu_tensor = to_gpu(cpu_tensor)<br>\nFile \"/opt/pytorch/test/common.py\", line 89, in to_gpu<br>\nreturn obj.clone().type(t)<br>\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 35, in <em>type<br>\nreturn new_type(self.size()).copy</em>(self, async)<br>\nRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/pytorch/torch/lib/THC/generic/THCTensorCopy.c:18</p>\n<p>all failing at the same THCTensorCopy.c:18</p>\n<p>All these failures only happen with type = torch.CharTensor</p>\n<p>here is output of nvidia-smi<br>\n# nvidia-smi<br>\nFri Sep 15 21:54:54 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla K80           Off  | 00000000:03:00.0 Off |                    0 |<br>\n| N/A   45C    P0    59W / 149W |    426MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |<br>\n| N/A   30C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   2  Tesla K80           Off  | 00000002:03:00.0 Off |                    0 |<br>\n| N/A   32C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   3  Tesla K80           Off  | 00000002:04:00.0 Off |                    0 |<br>\n| N/A   25C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n+-----------------------------------------------------------------------------+</p>", "body_text": "I am using ppc64 Ubuntu 16.04.\nI compiled pytorch version 0.2.0 and am running into some problems with test_cuda.py.\nTo isolate the failures I commented out some of the types and float_types like so:\ntypes = [\n#    torch.FloatTensor,\n#    torch.DoubleTensor,\n#    torch.LongTensor,\n#    torch.IntTensor,\n#    torch.ShortTensor,\ntorch.CharTensor,\n#    torch.ByteTensor,\n]\nfloat_types = [\ntorch.FloatTensor,\n#   torch.DoubleTensor\n]  # TODO: add half...\nThen I run \"python test_cuda.py\"\nI get a bunch of these errors:\n/opt/pytorch/torch/lib/THC/THCTensorTopK.cuh:431: void gatherTopK(TensorInfo<T, IndexType>, IndexType, IndexType, IndexType, IndexType, TensorInfo<T, IndexType>, IndexType, IndexType, TensorInfo<long, IndexType>, IndexType) [with T = char, IndexType = unsigned int, Dim = 3, Order = true]: block: [64,0,0], thread: [9,0,0] Assertion writeIndex < outputSliceSize failed.\nthe only difference in each line are the block and thread data\nI also get a bunch of these for different tests:\nERROR: test_CharTensor_tril (main.TestCuda)\n\nTraceback (most recent call last):\nFile \"mytest_cuda.py\", line 358, in tmp\ngpu_tensor = to_gpu(cpu_tensor)\nFile \"/opt/pytorch/test/common.py\", line 89, in to_gpu\nreturn obj.clone().type(t)\nFile \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 35, in type\nreturn new_type(self.size()).copy(self, async)\nRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/pytorch/torch/lib/THC/generic/THCTensorCopy.c:18\nall failing at the same THCTensorCopy.c:18\nAll these failures only happen with type = torch.CharTensor\nhere is output of nvidia-smi\n# nvidia-smi\nFri Sep 15 21:54:54 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 00000000:03:00.0 Off |                    0 |\n| N/A   45C    P0    59W / 149W |    426MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |\n| N/A   30C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           Off  | 00000002:03:00.0 Off |                    0 |\n| N/A   32C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           Off  | 00000002:04:00.0 Off |                    0 |\n| N/A   25C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+", "body": "I am using ppc64 Ubuntu 16.04. \r\nI compiled pytorch version 0.2.0 and am running into some problems with test_cuda.py.\r\nTo isolate the failures I commented out some of the types and float_types like so:\r\n\r\ntypes = [\r\n\\#    torch.FloatTensor,\r\n\\#    torch.DoubleTensor,\r\n\\#    torch.LongTensor,\r\n\\#    torch.IntTensor,\r\n\\#    torch.ShortTensor,\r\n    torch.CharTensor,\r\n\\#    torch.ByteTensor,\r\n]\r\n\r\nfloat_types = [\r\n   torch.FloatTensor,\r\n\\#   torch.DoubleTensor\r\n]  # TODO: add half...\r\n\r\nThen I run \"python test_cuda.py\"\r\nI get a bunch of these errors:\r\n/opt/pytorch/torch/lib/THC/THCTensorTopK.cuh:431: void gatherTopK(TensorInfo<T, IndexType>, IndexType, IndexType, IndexType, IndexType, TensorInfo<T, IndexType>, IndexType, IndexType, TensorInfo<long, IndexType>, IndexType) [with T = char, IndexType = unsigned int, Dim = 3, Order = true]: block: [64,0,0], thread: [9,0,0] Assertion `writeIndex < outputSliceSize` failed.\r\n\r\nthe only difference in each line are the block and thread data \r\n\r\nI also get a bunch of these for different tests:\r\n\r\n  ERROR: test_CharTensor_tril (__main__.TestCuda)\r\n\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"mytest_cuda.py\", line 358, in tmp\r\n    gpu_tensor = to_gpu(cpu_tensor)\r\n  File \"/opt/pytorch/test/common.py\", line 89, in to_gpu\r\n    return obj.clone().type(t)\r\n  File \"/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/_utils.py\", line 35, in _type\r\n    return new_type(self.size()).copy_(self, async)\r\nRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/pytorch/torch/lib/THC/generic/THCTensorCopy.c:18\r\n\r\nall failing at the same THCTensorCopy.c:18\r\n\r\nAll these failures only happen with type = torch.CharTensor\r\n\r\nhere is output of nvidia-smi\r\n\\# nvidia-smi\r\nFri Sep 15 21:54:54 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:03:00.0 Off |                    0 |\r\n| N/A   45C    P0    59W / 149W |    426MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |\r\n| N/A   30C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           Off  | 00000002:03:00.0 Off |                    0 |\r\n| N/A   32C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           Off  | 00000002:04:00.0 Off |                    0 |\r\n| N/A   25C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n\r\n"}