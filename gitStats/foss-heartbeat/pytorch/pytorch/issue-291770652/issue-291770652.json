{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4864", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4864/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4864/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4864/events", "html_url": "https://github.com/pytorch/pytorch/issues/4864", "id": 291770652, "node_id": "MDU6SXNzdWUyOTE3NzA2NTI=", "number": 4864, "title": "\"CUDA error: out of memory\" for the last Batch", "user": {"login": "jiecaoyu", "id": 10011346, "node_id": "MDQ6VXNlcjEwMDExMzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/10011346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiecaoyu", "html_url": "https://github.com/jiecaoyu", "followers_url": "https://api.github.com/users/jiecaoyu/followers", "following_url": "https://api.github.com/users/jiecaoyu/following{/other_user}", "gists_url": "https://api.github.com/users/jiecaoyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiecaoyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiecaoyu/subscriptions", "organizations_url": "https://api.github.com/users/jiecaoyu/orgs", "repos_url": "https://api.github.com/users/jiecaoyu/repos", "events_url": "https://api.github.com/users/jiecaoyu/events{/privacy}", "received_events_url": "https://api.github.com/users/jiecaoyu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-26T01:16:06Z", "updated_at": "2018-10-25T16:19:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I am trying to train ResNet-18 on two GTX Titan X GPU.</p>\n<p>In each epoch, it runs fine for the first 5004 iterations (batch size: 256). However, for the last batch with a batch size of 143, the training breaks due to \"CUDA error: out of memory\".</p>\n<p>Here is the error message:</p>\n<pre><code>Traceback (most recent call last):\n  File \"main.py\", line 404, in &lt;module&gt;\n    train(train_loader, model, criterion, optimizer, epoch)\n  File \"main.py\", line 119, in train\n    loss.backward()\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/variable.py\", line 127, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/__init__.py\", line 83, in backward\n    variables, grad_variables, retain_graph, create_graph)\nRuntimeError: CUDA error: out of memory\n</code></pre>\n<p>Decreasing the batch size does not help since a batch size of 256 runs well for the first 5000 iterations.<br>\nAnother interesting thing is sometimes this problem may disappear.</p>\n<hr>\n<p>I tried to use</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.cuda.empty_cache()</pre></div>\n<p>to release unnecessary GPU memory caching before the last batch but it does not help.</p>\n<hr>\n<p>Environment info:</p>\n<ul>\n<li>OS: Ubuntu 14.04</li>\n<li>PyTorch version: 0.4.0a0+4970e73</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: 2.7.6</li>\n<li>CUDA/cuDNN version: 8.0 / 7.0.5</li>\n<li>GPU models and configuration: GTX Titan X</li>\n<li>GCC version (if compiling from source): 4.8.4</li>\n</ul>", "body_text": "I am trying to train ResNet-18 on two GTX Titan X GPU.\nIn each epoch, it runs fine for the first 5004 iterations (batch size: 256). However, for the last batch with a batch size of 143, the training breaks due to \"CUDA error: out of memory\".\nHere is the error message:\nTraceback (most recent call last):\n  File \"main.py\", line 404, in <module>\n    train(train_loader, model, criterion, optimizer, epoch)\n  File \"main.py\", line 119, in train\n    loss.backward()\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/variable.py\", line 127, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/__init__.py\", line 83, in backward\n    variables, grad_variables, retain_graph, create_graph)\nRuntimeError: CUDA error: out of memory\n\nDecreasing the batch size does not help since a batch size of 256 runs well for the first 5000 iterations.\nAnother interesting thing is sometimes this problem may disappear.\n\nI tried to use\ntorch.cuda.empty_cache()\nto release unnecessary GPU memory caching before the last batch but it does not help.\n\nEnvironment info:\n\nOS: Ubuntu 14.04\nPyTorch version: 0.4.0a0+4970e73\nHow you installed PyTorch (conda, pip, source): source\nPython version: 2.7.6\nCUDA/cuDNN version: 8.0 / 7.0.5\nGPU models and configuration: GTX Titan X\nGCC version (if compiling from source): 4.8.4", "body": "I am trying to train ResNet-18 on two GTX Titan X GPU.\r\n\r\nIn each epoch, it runs fine for the first 5004 iterations (batch size: 256). However, for the last batch with a batch size of 143, the training breaks due to \"CUDA error: out of memory\".\r\n\r\nHere is the error message:\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 404, in <module>\r\n    train(train_loader, model, criterion, optimizer, epoch)\r\n  File \"main.py\", line 119, in train\r\n    loss.backward()\r\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/variable.py\", line 127, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/home/jiecaoyu/.local/lib/python2.7/site-packages/torch/autograd/__init__.py\", line 83, in backward\r\n    variables, grad_variables, retain_graph, create_graph)\r\nRuntimeError: CUDA error: out of memory\r\n```\r\n\r\nDecreasing the batch size does not help since a batch size of 256 runs well for the first 5000 iterations.\r\nAnother interesting thing is sometimes this problem may disappear.\r\n\r\n---------------------------------------------------\r\nI tried to use\r\n```python\r\ntorch.cuda.empty_cache()\r\n```\r\nto release unnecessary GPU memory caching before the last batch but it does not help.\r\n\r\n---------------------------------------------------\r\nEnvironment info:\r\n- OS: Ubuntu 14.04\r\n- PyTorch version: 0.4.0a0+4970e73\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: 2.7.6\r\n- CUDA/cuDNN version: 8.0 / 7.0.5\r\n- GPU models and configuration: GTX Titan X\r\n- GCC version (if compiling from source): 4.8.4\r\n\r\n"}