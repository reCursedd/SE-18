{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4190", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4190/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4190/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4190/events", "html_url": "https://github.com/pytorch/pytorch/issues/4190", "id": 282313652, "node_id": "MDU6SXNzdWUyODIzMTM2NTI=", "number": 4190, "title": "Print FloatTensor is extremely slow", "user": {"login": "Prinsphield", "id": 12531720, "node_id": "MDQ6VXNlcjEyNTMxNzIw", "avatar_url": "https://avatars0.githubusercontent.com/u/12531720?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Prinsphield", "html_url": "https://github.com/Prinsphield", "followers_url": "https://api.github.com/users/Prinsphield/followers", "following_url": "https://api.github.com/users/Prinsphield/following{/other_user}", "gists_url": "https://api.github.com/users/Prinsphield/gists{/gist_id}", "starred_url": "https://api.github.com/users/Prinsphield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Prinsphield/subscriptions", "organizations_url": "https://api.github.com/users/Prinsphield/orgs", "repos_url": "https://api.github.com/users/Prinsphield/repos", "events_url": "https://api.github.com/users/Prinsphield/events{/privacy}", "received_events_url": "https://api.github.com/users/Prinsphield/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-12-15T04:01:19Z", "updated_at": "2017-12-15T14:31:09Z", "closed_at": "2017-12-15T14:31:09Z", "author_association": "NONE", "body_html": "<p>I am trying to build up my own dataset using <code>DataLoader</code>, however, I found it extremely slow.<br>\nMy pics are all <code>256*256*3</code> and in the <code>align_5p</code> dir.</p>\n<p>Here is my code</p>\n<pre><code>import torch, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import misc\n\nclass CelebADataset(Dataset):\n    def __init__(self, attribute, positive, config=config):\n    \u00a6   self.attribute = attribute\n    \u00a6   self.positive = positive\n    \u00a6   self.config = config\n\n    \u00a6   with open(os.path.join(self.config.data_dir, 'list_attr_celeba.txt'), 'r') as f:\n    \u00a6   \u00a6   lines = f.read().strip().split('\\n')\n    \u00a6   \u00a6   col_id = lines[1].split().index(self.attribute) + 1\n    \u00a6   \u00a6   self.attr_list = list(map(int, [x.split()[col_id] for x in lines[2:]]))\n\n    \u00a6   if self.positive:\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] ==  1, range(len(self.attr_list))))\n    \u00a6   else:\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] == -1, range(len(self.attr_list))))\n\n    \u00a6   self.filenames = [os.path.join(self.config.data_dir, 'align_5p/{:06d}.jpg'.format(idx+1)) for idx in self.idxs]\n\n    def __len__(self):\n    \u00a6   return len(self.filenames)\n\n    def __getitem__(self, idx):\n    \u00a6   img = misc.imread(self.filenames[idx])\n    \u00a6   img = misc.imresize(img, (self.config.nchw[2], self.config.nchw[3]))\n    \u00a6   img = img.transpose((2,0,1)) / 255.\n    \u00a6   img = img.astype(np.float32)\n    \u00a6   return img\n\nif __name__ == \"__main__\":\n    celeba = CelebADataset('Bangs', 1)\n    dataloader = DataLoader(celeba, batch_size=config.nchw[0], shuffle=config.shuffle, num_workers=config.num_workers)\n    data = iter(dataloader)\n\n    import cProfile\n    pr = cProfile.Profile()\n    pr.enable()\n    for i in range(10):\n    \u00a6   print(i)\n    \u00a6   torch.from_numpy(np.random.rand(64,3,256,256).astype(np.float32))\n    pr.disable()\n    pr.print_stats(sort='tottime')\n\n</code></pre>\n<p>Here is the time profile.</p>\n<pre><code>251735415 function calls (251734618 primitive calls) in 67.067 seconds\n\n   Ordered by: internal time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n125836680   28.481    0.000   43.915    0.000 tensor.py:158(&lt;lambda&gt;)\n     3270   17.636    0.005   61.551    0.019 {map}\n125829120   15.432    0.000   15.432    0.000 {method 'select' of 'torch._C.DoubleTensorBase' objects}\n       10    1.515    0.151   66.741    6.674 _tensor_str.py:76(_number_format)\n     3464    1.417    0.000    1.417    0.000 {range}\n     2530    0.765    0.000   63.733    0.025 tensor.py:156(__iter__)\n       10    0.381    0.038    0.381    0.038 {method 'copy_' of 'torch._C.DoubleTensorBase' objects}\n       20    0.325    0.016    0.325    0.016 {method 'eq' of 'torch._C.DoubleTensorBase' objects}\n       40    0.271    0.007    0.271    0.007 {method 'recv_bytes' of '_multiprocessing.Connection' objects}\n       10    0.200    0.020    0.200    0.020 {method 'ne' of 'torch._C.DoubleTensorBase' objects}\n       10    0.109    0.011    0.109    0.011 {method 'eq' of 'torch._C.ByteTensorBase' objects}\n       10    0.103    0.010    0.103    0.010 {method 'min' of 'torch._C.DoubleTensorBase' objects}\n       10    0.100    0.010    0.100    0.010 {method 'abs_' of 'torch._C.DoubleTensorBase' objects}\n       10    0.096    0.010    0.096    0.010 {method 'max' of 'torch._C.DoubleTensorBase' objects}\n       10    0.083    0.008    0.083    0.008 {method 'all' of 'torch._C.ByteTensorBase' objects}\n       10    0.069    0.007    0.069    0.007 {method 'any' of 'torch._C.ByteTensorBase' objects}\n       20    0.040    0.002    0.040    0.002 {method 'add' of 'torch._C.ByteTensorBase' objects}\n       10    0.007    0.001   66.781    6.678 _tensor_str.py:142(_tensor_str)\n     8480    0.004    0.000    0.004    0.000 {method 'format' of 'str' objects}\n     1080    0.004    0.000    0.022    0.000 _tensor_str.py:196(__repr_row)\n      180    0.003    0.000    0.028    0.000 _tensor_str.py:208(_matrix_str)\n     2533    0.003    0.000    0.010    0.000 {method 'join' of 'str' objects}\n        1    0.003    0.003    0.003    0.003 {posix.fork}\n     7920    0.002    0.000    0.002    0.000 {method 'select' of 'torch._C.FloatTensorBase' objects}\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:200(&lt;genexpr&gt;)\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:202(&lt;genexpr&gt;)\n     3460    0.001    0.000    1.417    0.000 _utils.py:79(_range)\n804/12    0.001    0.000    0.003    0.000 pickle.py:269(save)\n      740    0.001    0.000    0.002    0.000 storage.py:16(__iter__)\n      780    0.001    0.000    0.001    0.000 pickle.py:443(save_int)\n       10    0.001    0.000    0.008    0.001 pickle.py:851(load)\n       12    0.000    0.000    0.002    0.000 pickle.py:614(_batch_appends)\n     2530    0.000    0.000    0.000    0.000 {method 'nelement' of 'torch._C.FloatTensorBase' objects}\n3285/3281    0.000    0.000    0.005    0.000 {iter}\n       12    0.000    0.000    0.001    0.000 sampler.py:117(__iter__)\n     3260    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatTensorBase' objects}\n       10    0.000    0.000    0.003    0.000 connection.py:429(answer_challenge)\n       10    0.000    0.000    0.000    0.000 {_multiprocessing.recvfd}\n     1746    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n      300    0.000    0.000    0.000    0.000 {method 'format' of 'unicode' objects}\n      180    0.000    0.000    0.001    0.000 {_functools.reduce}\n       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n       10    0.000    0.000    0.001    0.000 connection.py:297(SocketClient)\n       20    0.000    0.000    0.000    0.000 hmac.py:30(__init__)\n     1480    0.000    0.000    0.000    0.000 storage.py:17(&lt;lambda&gt;)\n       42    0.000    0.000    0.000    0.000 {method 'send_bytes' of '_multiprocessing.Connection' objects}\n       10    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.DoubleTensorBase' objects}\n       10    0.000    0.000   66.781    6.678 _tensor_str.py:291(_str)\n       10    0.000    0.000    0.006    0.001 reductions.py:66(rebuild_storage_fd)\n       10    0.000    0.000    0.005    0.001 reduction.py:150(rebuild_handle)\n       90    0.000    0.000    0.000    0.000 pickle.py:1340(decode_long)\n       10    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n       12    0.000    0.000    0.003    0.000 queue.py:15(send)\n       10    0.000    0.000    0.000    0.000 socket.py:189(__init__)\n      540    0.000    0.000    0.000    0.000 _tensor_str.py:190(&lt;genexpr&gt;)\n      920    0.000    0.000    0.000    0.000 {method 'read' of 'cStringIO.StringI' objects}\n       10    0.000    0.000    0.281    0.028 dataloader.py:185(__next__)\n     1608    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n      170    0.000    0.000    0.000    0.000 pickle.py:1174(load_binput)\n       10    0.000    0.000    0.000    0.000 {_new_shared_fd}\n       90    0.000    0.000    0.000    0.000 pickle.py:947(load_long1)\n        4    0.000    0.000    0.000    0.000 synchronize.py:74(__init__)\n       10    0.000    0.000    0.000    0.000 {method 'encode' of 'unicode' objects}\n       10    0.000    0.000    0.008    0.001 pickle.py:1386(loads)\n      876    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n1208/1207    0.000    0.000    0.000    0.000 {len}\n      172    0.000    0.000    0.000    0.000 {getattr}\n      360    0.000    0.000    0.000    0.000 _tensor_str.py:191(&lt;lambda&gt;)\n       50    0.000    0.000    0.000    0.000 {__import__}\n750    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n        1    0.000    0.000    0.000    0.000 hmac.py:4(&lt;module&gt;)\n       50    0.000    0.000    0.000    0.000 pickle.py:1093(load_global)\n      836    0.000    0.000    0.000    0.000 {chr}\n       10    0.000    0.000   66.781    6.678 tensor.py:135(__str__)\n       10    0.000    0.000    0.278    0.028 queue.py:20(recv)\n       10    0.000    0.000    0.001    0.000 connection.py:416(deliver_challenge)\n       10    0.000    0.000    0.004    0.000 connection.py:161(Client)\n       80    0.000    0.000    0.000    0.000 {hasattr}\n      804    0.000    0.000    0.000    0.000 pickle.py:333(persistent_id)\n       10    0.000    0.000    0.278    0.028 queues.py:375(get)\n       12    0.000    0.000    0.005    0.000 dataloader.py:217(_put_indices)\n       10    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.FloatTensorBase' objects}\n       12    0.000    0.000    0.003    0.000 pickle.py:220(dump)\n       50    0.000    0.000    0.000    0.000 _tensor_str.py:150(&lt;genexpr&gt;)\n       10    0.000    0.000    0.000    0.000 {method 'send' of '_multiprocessing.Connection' objects}\n       80    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n       14    0.000    0.000    0.000    0.000 weakref.py:105(__setitem__)\n       12    0.000    0.000    0.004    0.000 queues.py:389(put)\n       10    0.000    0.000    0.000    0.000 _tensor_str.py:69(_get_min_log_scale)\n       50    0.000    0.000    0.000    0.000 pickle.py:1128(find_class)\n       10    0.000    0.000    0.000    0.000 weakref.py:55(remove)\n       12    0.000    0.000    0.003    0.000 pickle.py:538(save_tuple)\n       12    0.000    0.000    0.002    0.000 pickle.py:597(save_list)\n       10    0.000    0.000    0.000    0.000 reductions.py:38(rebuild_tensor)\n      360    0.000    0.000    0.000    0.000 {any}\n       24    0.000    0.000    0.000    0.000 pickle.py:227(memoize)\n       10    0.000    0.000    0.000    0.000 __init__.py:71(typename)\n        1    0.000    0.000    0.005    0.005 dataloader.py:140(__init__)\n       40    0.000    0.000    0.000    0.000 {max}\n       20    0.000    0.000    0.000    0.000 pickle.py:999(load_tuple)\n       10    0.000    0.000    0.000    0.000 weakref.py:134(get)\n       20    0.000    0.000    0.040    0.002 tensor.py:292(__add__)\n      868    0.000    0.000    0.000    0.000 {id}\n       22    0.000    0.000    0.000    0.000 queue.py:24(__getattr__)\n       10    0.000    0.000    0.000    0.000 {method 'close' of '_multiprocessing.Connection' objects}\n       40    0.000    0.000    0.000    0.000 {_hashlib.openssl_md5}\n       20    0.000    0.000    0.000    0.000 connection.py:98(address_type)\n        1    0.000    0.000    0.003    0.003 process.py:116(start)\n       10    0.000    0.000    0.000    0.000 {posix.urandom}\n       12    0.000    0.000    0.000    0.000 pickle.py:173(__init__)\n      190    0.000    0.000    0.000    0.000 {math.floor}\n       20    0.000    0.000    0.006    0.000 pickle.py:1135(load_reduce)\n\n........\n\n</code></pre>\n<p>It took so long for 10 batches. I found that the operation <code>torch.from_numpy()</code>  is very slow, about 0.15s for a <code>3*256*256</code> ndarray. I doubt that torch would convert each image to torch.FloatTensor, therefore renders the time delay.</p>\n<p>I am not sure of the right way to providing image dataset. I just followed the <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html?\" rel=\"nofollow\">tutorial</a>.</p>\n<p>Looking for help.</p>\n<p>My torch version is <code>'0.3.0.post4'</code></p>", "body_text": "I am trying to build up my own dataset using DataLoader, however, I found it extremely slow.\nMy pics are all 256*256*3 and in the align_5p dir.\nHere is my code\nimport torch, time\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import misc\n\nclass CelebADataset(Dataset):\n    def __init__(self, attribute, positive, config=config):\n    \u00a6   self.attribute = attribute\n    \u00a6   self.positive = positive\n    \u00a6   self.config = config\n\n    \u00a6   with open(os.path.join(self.config.data_dir, 'list_attr_celeba.txt'), 'r') as f:\n    \u00a6   \u00a6   lines = f.read().strip().split('\\n')\n    \u00a6   \u00a6   col_id = lines[1].split().index(self.attribute) + 1\n    \u00a6   \u00a6   self.attr_list = list(map(int, [x.split()[col_id] for x in lines[2:]]))\n\n    \u00a6   if self.positive:\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] ==  1, range(len(self.attr_list))))\n    \u00a6   else:\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] == -1, range(len(self.attr_list))))\n\n    \u00a6   self.filenames = [os.path.join(self.config.data_dir, 'align_5p/{:06d}.jpg'.format(idx+1)) for idx in self.idxs]\n\n    def __len__(self):\n    \u00a6   return len(self.filenames)\n\n    def __getitem__(self, idx):\n    \u00a6   img = misc.imread(self.filenames[idx])\n    \u00a6   img = misc.imresize(img, (self.config.nchw[2], self.config.nchw[3]))\n    \u00a6   img = img.transpose((2,0,1)) / 255.\n    \u00a6   img = img.astype(np.float32)\n    \u00a6   return img\n\nif __name__ == \"__main__\":\n    celeba = CelebADataset('Bangs', 1)\n    dataloader = DataLoader(celeba, batch_size=config.nchw[0], shuffle=config.shuffle, num_workers=config.num_workers)\n    data = iter(dataloader)\n\n    import cProfile\n    pr = cProfile.Profile()\n    pr.enable()\n    for i in range(10):\n    \u00a6   print(i)\n    \u00a6   torch.from_numpy(np.random.rand(64,3,256,256).astype(np.float32))\n    pr.disable()\n    pr.print_stats(sort='tottime')\n\n\nHere is the time profile.\n251735415 function calls (251734618 primitive calls) in 67.067 seconds\n\n   Ordered by: internal time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n125836680   28.481    0.000   43.915    0.000 tensor.py:158(<lambda>)\n     3270   17.636    0.005   61.551    0.019 {map}\n125829120   15.432    0.000   15.432    0.000 {method 'select' of 'torch._C.DoubleTensorBase' objects}\n       10    1.515    0.151   66.741    6.674 _tensor_str.py:76(_number_format)\n     3464    1.417    0.000    1.417    0.000 {range}\n     2530    0.765    0.000   63.733    0.025 tensor.py:156(__iter__)\n       10    0.381    0.038    0.381    0.038 {method 'copy_' of 'torch._C.DoubleTensorBase' objects}\n       20    0.325    0.016    0.325    0.016 {method 'eq' of 'torch._C.DoubleTensorBase' objects}\n       40    0.271    0.007    0.271    0.007 {method 'recv_bytes' of '_multiprocessing.Connection' objects}\n       10    0.200    0.020    0.200    0.020 {method 'ne' of 'torch._C.DoubleTensorBase' objects}\n       10    0.109    0.011    0.109    0.011 {method 'eq' of 'torch._C.ByteTensorBase' objects}\n       10    0.103    0.010    0.103    0.010 {method 'min' of 'torch._C.DoubleTensorBase' objects}\n       10    0.100    0.010    0.100    0.010 {method 'abs_' of 'torch._C.DoubleTensorBase' objects}\n       10    0.096    0.010    0.096    0.010 {method 'max' of 'torch._C.DoubleTensorBase' objects}\n       10    0.083    0.008    0.083    0.008 {method 'all' of 'torch._C.ByteTensorBase' objects}\n       10    0.069    0.007    0.069    0.007 {method 'any' of 'torch._C.ByteTensorBase' objects}\n       20    0.040    0.002    0.040    0.002 {method 'add' of 'torch._C.ByteTensorBase' objects}\n       10    0.007    0.001   66.781    6.678 _tensor_str.py:142(_tensor_str)\n     8480    0.004    0.000    0.004    0.000 {method 'format' of 'str' objects}\n     1080    0.004    0.000    0.022    0.000 _tensor_str.py:196(__repr_row)\n      180    0.003    0.000    0.028    0.000 _tensor_str.py:208(_matrix_str)\n     2533    0.003    0.000    0.010    0.000 {method 'join' of 'str' objects}\n        1    0.003    0.003    0.003    0.003 {posix.fork}\n     7920    0.002    0.000    0.002    0.000 {method 'select' of 'torch._C.FloatTensorBase' objects}\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:200(<genexpr>)\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:202(<genexpr>)\n     3460    0.001    0.000    1.417    0.000 _utils.py:79(_range)\n804/12    0.001    0.000    0.003    0.000 pickle.py:269(save)\n      740    0.001    0.000    0.002    0.000 storage.py:16(__iter__)\n      780    0.001    0.000    0.001    0.000 pickle.py:443(save_int)\n       10    0.001    0.000    0.008    0.001 pickle.py:851(load)\n       12    0.000    0.000    0.002    0.000 pickle.py:614(_batch_appends)\n     2530    0.000    0.000    0.000    0.000 {method 'nelement' of 'torch._C.FloatTensorBase' objects}\n3285/3281    0.000    0.000    0.005    0.000 {iter}\n       12    0.000    0.000    0.001    0.000 sampler.py:117(__iter__)\n     3260    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatTensorBase' objects}\n       10    0.000    0.000    0.003    0.000 connection.py:429(answer_challenge)\n       10    0.000    0.000    0.000    0.000 {_multiprocessing.recvfd}\n     1746    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n      300    0.000    0.000    0.000    0.000 {method 'format' of 'unicode' objects}\n      180    0.000    0.000    0.001    0.000 {_functools.reduce}\n       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n       10    0.000    0.000    0.001    0.000 connection.py:297(SocketClient)\n       20    0.000    0.000    0.000    0.000 hmac.py:30(__init__)\n     1480    0.000    0.000    0.000    0.000 storage.py:17(<lambda>)\n       42    0.000    0.000    0.000    0.000 {method 'send_bytes' of '_multiprocessing.Connection' objects}\n       10    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.DoubleTensorBase' objects}\n       10    0.000    0.000   66.781    6.678 _tensor_str.py:291(_str)\n       10    0.000    0.000    0.006    0.001 reductions.py:66(rebuild_storage_fd)\n       10    0.000    0.000    0.005    0.001 reduction.py:150(rebuild_handle)\n       90    0.000    0.000    0.000    0.000 pickle.py:1340(decode_long)\n       10    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n       12    0.000    0.000    0.003    0.000 queue.py:15(send)\n       10    0.000    0.000    0.000    0.000 socket.py:189(__init__)\n      540    0.000    0.000    0.000    0.000 _tensor_str.py:190(<genexpr>)\n      920    0.000    0.000    0.000    0.000 {method 'read' of 'cStringIO.StringI' objects}\n       10    0.000    0.000    0.281    0.028 dataloader.py:185(__next__)\n     1608    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n      170    0.000    0.000    0.000    0.000 pickle.py:1174(load_binput)\n       10    0.000    0.000    0.000    0.000 {_new_shared_fd}\n       90    0.000    0.000    0.000    0.000 pickle.py:947(load_long1)\n        4    0.000    0.000    0.000    0.000 synchronize.py:74(__init__)\n       10    0.000    0.000    0.000    0.000 {method 'encode' of 'unicode' objects}\n       10    0.000    0.000    0.008    0.001 pickle.py:1386(loads)\n      876    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n1208/1207    0.000    0.000    0.000    0.000 {len}\n      172    0.000    0.000    0.000    0.000 {getattr}\n      360    0.000    0.000    0.000    0.000 _tensor_str.py:191(<lambda>)\n       50    0.000    0.000    0.000    0.000 {__import__}\n750    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n        1    0.000    0.000    0.000    0.000 hmac.py:4(<module>)\n       50    0.000    0.000    0.000    0.000 pickle.py:1093(load_global)\n      836    0.000    0.000    0.000    0.000 {chr}\n       10    0.000    0.000   66.781    6.678 tensor.py:135(__str__)\n       10    0.000    0.000    0.278    0.028 queue.py:20(recv)\n       10    0.000    0.000    0.001    0.000 connection.py:416(deliver_challenge)\n       10    0.000    0.000    0.004    0.000 connection.py:161(Client)\n       80    0.000    0.000    0.000    0.000 {hasattr}\n      804    0.000    0.000    0.000    0.000 pickle.py:333(persistent_id)\n       10    0.000    0.000    0.278    0.028 queues.py:375(get)\n       12    0.000    0.000    0.005    0.000 dataloader.py:217(_put_indices)\n       10    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.FloatTensorBase' objects}\n       12    0.000    0.000    0.003    0.000 pickle.py:220(dump)\n       50    0.000    0.000    0.000    0.000 _tensor_str.py:150(<genexpr>)\n       10    0.000    0.000    0.000    0.000 {method 'send' of '_multiprocessing.Connection' objects}\n       80    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n       14    0.000    0.000    0.000    0.000 weakref.py:105(__setitem__)\n       12    0.000    0.000    0.004    0.000 queues.py:389(put)\n       10    0.000    0.000    0.000    0.000 _tensor_str.py:69(_get_min_log_scale)\n       50    0.000    0.000    0.000    0.000 pickle.py:1128(find_class)\n       10    0.000    0.000    0.000    0.000 weakref.py:55(remove)\n       12    0.000    0.000    0.003    0.000 pickle.py:538(save_tuple)\n       12    0.000    0.000    0.002    0.000 pickle.py:597(save_list)\n       10    0.000    0.000    0.000    0.000 reductions.py:38(rebuild_tensor)\n      360    0.000    0.000    0.000    0.000 {any}\n       24    0.000    0.000    0.000    0.000 pickle.py:227(memoize)\n       10    0.000    0.000    0.000    0.000 __init__.py:71(typename)\n        1    0.000    0.000    0.005    0.005 dataloader.py:140(__init__)\n       40    0.000    0.000    0.000    0.000 {max}\n       20    0.000    0.000    0.000    0.000 pickle.py:999(load_tuple)\n       10    0.000    0.000    0.000    0.000 weakref.py:134(get)\n       20    0.000    0.000    0.040    0.002 tensor.py:292(__add__)\n      868    0.000    0.000    0.000    0.000 {id}\n       22    0.000    0.000    0.000    0.000 queue.py:24(__getattr__)\n       10    0.000    0.000    0.000    0.000 {method 'close' of '_multiprocessing.Connection' objects}\n       40    0.000    0.000    0.000    0.000 {_hashlib.openssl_md5}\n       20    0.000    0.000    0.000    0.000 connection.py:98(address_type)\n        1    0.000    0.000    0.003    0.003 process.py:116(start)\n       10    0.000    0.000    0.000    0.000 {posix.urandom}\n       12    0.000    0.000    0.000    0.000 pickle.py:173(__init__)\n      190    0.000    0.000    0.000    0.000 {math.floor}\n       20    0.000    0.000    0.006    0.000 pickle.py:1135(load_reduce)\n\n........\n\n\nIt took so long for 10 batches. I found that the operation torch.from_numpy()  is very slow, about 0.15s for a 3*256*256 ndarray. I doubt that torch would convert each image to torch.FloatTensor, therefore renders the time delay.\nI am not sure of the right way to providing image dataset. I just followed the tutorial.\nLooking for help.\nMy torch version is '0.3.0.post4'", "body": "I am trying to build up my own dataset using `DataLoader`, however, I found it extremely slow.\r\nMy pics are all `256*256*3` and in the `align_5p` dir.\r\n\r\nHere is my code\r\n\r\n```\r\nimport torch, time\r\nfrom torch.utils.data import Dataset, DataLoader\r\nfrom scipy import misc\r\n\r\nclass CelebADataset(Dataset):\r\n    def __init__(self, attribute, positive, config=config):\r\n    \u00a6   self.attribute = attribute\r\n    \u00a6   self.positive = positive\r\n    \u00a6   self.config = config\r\n\r\n    \u00a6   with open(os.path.join(self.config.data_dir, 'list_attr_celeba.txt'), 'r') as f:\r\n    \u00a6   \u00a6   lines = f.read().strip().split('\\n')\r\n    \u00a6   \u00a6   col_id = lines[1].split().index(self.attribute) + 1\r\n    \u00a6   \u00a6   self.attr_list = list(map(int, [x.split()[col_id] for x in lines[2:]]))\r\n\r\n    \u00a6   if self.positive:\r\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] ==  1, range(len(self.attr_list))))\r\n    \u00a6   else:\r\n    \u00a6   \u00a6   self.idxs = list(filter(lambda x: self.attr_list[x] == -1, range(len(self.attr_list))))\r\n\r\n    \u00a6   self.filenames = [os.path.join(self.config.data_dir, 'align_5p/{:06d}.jpg'.format(idx+1)) for idx in self.idxs]\r\n\r\n    def __len__(self):\r\n    \u00a6   return len(self.filenames)\r\n\r\n    def __getitem__(self, idx):\r\n    \u00a6   img = misc.imread(self.filenames[idx])\r\n    \u00a6   img = misc.imresize(img, (self.config.nchw[2], self.config.nchw[3]))\r\n    \u00a6   img = img.transpose((2,0,1)) / 255.\r\n    \u00a6   img = img.astype(np.float32)\r\n    \u00a6   return img\r\n\r\nif __name__ == \"__main__\":\r\n    celeba = CelebADataset('Bangs', 1)\r\n    dataloader = DataLoader(celeba, batch_size=config.nchw[0], shuffle=config.shuffle, num_workers=config.num_workers)\r\n    data = iter(dataloader)\r\n\r\n    import cProfile\r\n    pr = cProfile.Profile()\r\n    pr.enable()\r\n    for i in range(10):\r\n    \u00a6   print(i)\r\n    \u00a6   torch.from_numpy(np.random.rand(64,3,256,256).astype(np.float32))\r\n    pr.disable()\r\n    pr.print_stats(sort='tottime')\r\n\r\n```\r\n\r\nHere is the time profile.\r\n\r\n```\r\n251735415 function calls (251734618 primitive calls) in 67.067 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n125836680   28.481    0.000   43.915    0.000 tensor.py:158(<lambda>)\r\n     3270   17.636    0.005   61.551    0.019 {map}\r\n125829120   15.432    0.000   15.432    0.000 {method 'select' of 'torch._C.DoubleTensorBase' objects}\r\n       10    1.515    0.151   66.741    6.674 _tensor_str.py:76(_number_format)\r\n     3464    1.417    0.000    1.417    0.000 {range}\r\n     2530    0.765    0.000   63.733    0.025 tensor.py:156(__iter__)\r\n       10    0.381    0.038    0.381    0.038 {method 'copy_' of 'torch._C.DoubleTensorBase' objects}\r\n       20    0.325    0.016    0.325    0.016 {method 'eq' of 'torch._C.DoubleTensorBase' objects}\r\n       40    0.271    0.007    0.271    0.007 {method 'recv_bytes' of '_multiprocessing.Connection' objects}\r\n       10    0.200    0.020    0.200    0.020 {method 'ne' of 'torch._C.DoubleTensorBase' objects}\r\n       10    0.109    0.011    0.109    0.011 {method 'eq' of 'torch._C.ByteTensorBase' objects}\r\n       10    0.103    0.010    0.103    0.010 {method 'min' of 'torch._C.DoubleTensorBase' objects}\r\n       10    0.100    0.010    0.100    0.010 {method 'abs_' of 'torch._C.DoubleTensorBase' objects}\r\n       10    0.096    0.010    0.096    0.010 {method 'max' of 'torch._C.DoubleTensorBase' objects}\r\n       10    0.083    0.008    0.083    0.008 {method 'all' of 'torch._C.ByteTensorBase' objects}\r\n       10    0.069    0.007    0.069    0.007 {method 'any' of 'torch._C.ByteTensorBase' objects}\r\n       20    0.040    0.002    0.040    0.002 {method 'add' of 'torch._C.ByteTensorBase' objects}\r\n       10    0.007    0.001   66.781    6.678 _tensor_str.py:142(_tensor_str)\r\n     8480    0.004    0.000    0.004    0.000 {method 'format' of 'str' objects}\r\n     1080    0.004    0.000    0.022    0.000 _tensor_str.py:196(__repr_row)\r\n      180    0.003    0.000    0.028    0.000 _tensor_str.py:208(_matrix_str)\r\n     2533    0.003    0.000    0.010    0.000 {method 'join' of 'str' objects}\r\n        1    0.003    0.003    0.003    0.003 {posix.fork}\r\n     7920    0.002    0.000    0.002    0.000 {method 'select' of 'torch._C.FloatTensorBase' objects}\r\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:200(<genexpr>)\r\n     4320    0.001    0.000    0.003    0.000 _tensor_str.py:202(<genexpr>)\r\n     3460    0.001    0.000    1.417    0.000 _utils.py:79(_range)\r\n804/12    0.001    0.000    0.003    0.000 pickle.py:269(save)\r\n      740    0.001    0.000    0.002    0.000 storage.py:16(__iter__)\r\n      780    0.001    0.000    0.001    0.000 pickle.py:443(save_int)\r\n       10    0.001    0.000    0.008    0.001 pickle.py:851(load)\r\n       12    0.000    0.000    0.002    0.000 pickle.py:614(_batch_appends)\r\n     2530    0.000    0.000    0.000    0.000 {method 'nelement' of 'torch._C.FloatTensorBase' objects}\r\n3285/3281    0.000    0.000    0.005    0.000 {iter}\r\n       12    0.000    0.000    0.001    0.000 sampler.py:117(__iter__)\r\n     3260    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatTensorBase' objects}\r\n       10    0.000    0.000    0.003    0.000 connection.py:429(answer_challenge)\r\n       10    0.000    0.000    0.000    0.000 {_multiprocessing.recvfd}\r\n     1746    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n      300    0.000    0.000    0.000    0.000 {method 'format' of 'unicode' objects}\r\n      180    0.000    0.000    0.001    0.000 {_functools.reduce}\r\n       22    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\r\n       10    0.000    0.000    0.001    0.000 connection.py:297(SocketClient)\r\n       20    0.000    0.000    0.000    0.000 hmac.py:30(__init__)\r\n     1480    0.000    0.000    0.000    0.000 storage.py:17(<lambda>)\r\n       42    0.000    0.000    0.000    0.000 {method 'send_bytes' of '_multiprocessing.Connection' objects}\r\n       10    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.DoubleTensorBase' objects}\r\n       10    0.000    0.000   66.781    6.678 _tensor_str.py:291(_str)\r\n       10    0.000    0.000    0.006    0.001 reductions.py:66(rebuild_storage_fd)\r\n       10    0.000    0.000    0.005    0.001 reduction.py:150(rebuild_handle)\r\n       90    0.000    0.000    0.000    0.000 pickle.py:1340(decode_long)\r\n       10    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\r\n       12    0.000    0.000    0.003    0.000 queue.py:15(send)\r\n       10    0.000    0.000    0.000    0.000 socket.py:189(__init__)\r\n      540    0.000    0.000    0.000    0.000 _tensor_str.py:190(<genexpr>)\r\n      920    0.000    0.000    0.000    0.000 {method 'read' of 'cStringIO.StringI' objects}\r\n       10    0.000    0.000    0.281    0.028 dataloader.py:185(__next__)\r\n     1608    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n      170    0.000    0.000    0.000    0.000 pickle.py:1174(load_binput)\r\n       10    0.000    0.000    0.000    0.000 {_new_shared_fd}\r\n       90    0.000    0.000    0.000    0.000 pickle.py:947(load_long1)\r\n        4    0.000    0.000    0.000    0.000 synchronize.py:74(__init__)\r\n       10    0.000    0.000    0.000    0.000 {method 'encode' of 'unicode' objects}\r\n       10    0.000    0.000    0.008    0.001 pickle.py:1386(loads)\r\n      876    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\r\n1208/1207    0.000    0.000    0.000    0.000 {len}\r\n      172    0.000    0.000    0.000    0.000 {getattr}\r\n      360    0.000    0.000    0.000    0.000 _tensor_str.py:191(<lambda>)\r\n       50    0.000    0.000    0.000    0.000 {__import__}\r\n750    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\r\n        1    0.000    0.000    0.000    0.000 hmac.py:4(<module>)\r\n       50    0.000    0.000    0.000    0.000 pickle.py:1093(load_global)\r\n      836    0.000    0.000    0.000    0.000 {chr}\r\n       10    0.000    0.000   66.781    6.678 tensor.py:135(__str__)\r\n       10    0.000    0.000    0.278    0.028 queue.py:20(recv)\r\n       10    0.000    0.000    0.001    0.000 connection.py:416(deliver_challenge)\r\n       10    0.000    0.000    0.004    0.000 connection.py:161(Client)\r\n       80    0.000    0.000    0.000    0.000 {hasattr}\r\n      804    0.000    0.000    0.000    0.000 pickle.py:333(persistent_id)\r\n       10    0.000    0.000    0.278    0.028 queues.py:375(get)\r\n       12    0.000    0.000    0.005    0.000 dataloader.py:217(_put_indices)\r\n       10    0.000    0.000    0.000    0.000 {method 'set_' of 'torch._C.FloatTensorBase' objects}\r\n       12    0.000    0.000    0.003    0.000 pickle.py:220(dump)\r\n       50    0.000    0.000    0.000    0.000 _tensor_str.py:150(<genexpr>)\r\n       10    0.000    0.000    0.000    0.000 {method 'send' of '_multiprocessing.Connection' objects}\r\n       80    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\r\n       14    0.000    0.000    0.000    0.000 weakref.py:105(__setitem__)\r\n       12    0.000    0.000    0.004    0.000 queues.py:389(put)\r\n       10    0.000    0.000    0.000    0.000 _tensor_str.py:69(_get_min_log_scale)\r\n       50    0.000    0.000    0.000    0.000 pickle.py:1128(find_class)\r\n       10    0.000    0.000    0.000    0.000 weakref.py:55(remove)\r\n       12    0.000    0.000    0.003    0.000 pickle.py:538(save_tuple)\r\n       12    0.000    0.000    0.002    0.000 pickle.py:597(save_list)\r\n       10    0.000    0.000    0.000    0.000 reductions.py:38(rebuild_tensor)\r\n      360    0.000    0.000    0.000    0.000 {any}\r\n       24    0.000    0.000    0.000    0.000 pickle.py:227(memoize)\r\n       10    0.000    0.000    0.000    0.000 __init__.py:71(typename)\r\n        1    0.000    0.000    0.005    0.005 dataloader.py:140(__init__)\r\n       40    0.000    0.000    0.000    0.000 {max}\r\n       20    0.000    0.000    0.000    0.000 pickle.py:999(load_tuple)\r\n       10    0.000    0.000    0.000    0.000 weakref.py:134(get)\r\n       20    0.000    0.000    0.040    0.002 tensor.py:292(__add__)\r\n      868    0.000    0.000    0.000    0.000 {id}\r\n       22    0.000    0.000    0.000    0.000 queue.py:24(__getattr__)\r\n       10    0.000    0.000    0.000    0.000 {method 'close' of '_multiprocessing.Connection' objects}\r\n       40    0.000    0.000    0.000    0.000 {_hashlib.openssl_md5}\r\n       20    0.000    0.000    0.000    0.000 connection.py:98(address_type)\r\n        1    0.000    0.000    0.003    0.003 process.py:116(start)\r\n       10    0.000    0.000    0.000    0.000 {posix.urandom}\r\n       12    0.000    0.000    0.000    0.000 pickle.py:173(__init__)\r\n      190    0.000    0.000    0.000    0.000 {math.floor}\r\n       20    0.000    0.000    0.006    0.000 pickle.py:1135(load_reduce)\r\n\r\n........\r\n\r\n```\r\n\r\nIt took so long for 10 batches. I found that the operation `torch.from_numpy()`  is very slow, about 0.15s for a `3*256*256` ndarray. I doubt that torch would convert each image to torch.FloatTensor, therefore renders the time delay. \r\n\r\nI am not sure of the right way to providing image dataset. I just followed the [tutorial](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html?).\r\n\r\nLooking for help.\r\n\r\nMy torch version is `'0.3.0.post4'`\r\n"}