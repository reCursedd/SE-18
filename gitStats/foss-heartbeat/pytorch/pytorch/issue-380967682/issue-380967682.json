{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14007", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14007/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14007/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14007/events", "html_url": "https://github.com/pytorch/pytorch/issues/14007", "id": 380967682, "node_id": "MDU6SXNzdWUzODA5Njc2ODI=", "number": 14007, "title": "gradient difference between single GPU and multi-GPU DataParallel", "user": {"login": "haipeng00", "id": 16497148, "node_id": "MDQ6VXNlcjE2NDk3MTQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/16497148?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haipeng00", "html_url": "https://github.com/haipeng00", "followers_url": "https://api.github.com/users/haipeng00/followers", "following_url": "https://api.github.com/users/haipeng00/following{/other_user}", "gists_url": "https://api.github.com/users/haipeng00/gists{/gist_id}", "starred_url": "https://api.github.com/users/haipeng00/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haipeng00/subscriptions", "organizations_url": "https://api.github.com/users/haipeng00/orgs", "repos_url": "https://api.github.com/users/haipeng00/repos", "events_url": "https://api.github.com/users/haipeng00/events{/privacy}", "received_events_url": "https://api.github.com/users/haipeng00/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-15T02:05:43Z", "updated_at": "2018-11-15T05:33:36Z", "closed_at": "2018-11-15T05:33:36Z", "author_association": "NONE", "body_html": "<p>Running the following scripts with pytorch0.4.1, cuda8 and cudnn5, gives different gradients between single GPU and multi GPU. (scripts quoted from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"305208924\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5778\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/5778/hovercard?comment_id=373086192&amp;comment_type=issue_comment\" href=\"https://github.com/pytorch/pytorch/issues/5778#issuecomment-373086192\">#5778 (comment)</a>)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">128</span>).cuda()\nlinear <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">128</span>).cuda()\ndp <span class=\"pl-k\">=</span> torch.nn.DataParallel(linear, [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>])\n\nlinear(<span class=\"pl-c1\">input</span>).sum().backward()\n<span class=\"pl-c1\">print</span>(linear.weight.grad)\n\nlinear.zero_grad()\ndp(<span class=\"pl-c1\">input</span>).sum().backward()\n<span class=\"pl-c1\">print</span>(linear.weight.grad)</pre></div>\n<p>Single-GPU gradients:<br>\ntensor([[ 38.8789596558, -21.8231239319,  24.4459419250,  ...,<br>\n16.9406051636,  16.2471446991, -39.3904113770],<br>\n[ 38.8789596558, -21.8231239319,  24.4459419250,  ...,)</p>\n<p>Multi-gpu DataParallel gradients:<br>\ntensor([[ 38.8789596558, -21.8231220245,  24.4459438324,  ...,<br>\n16.9406070709,  16.2471446991, -39.3904151917],<br>\n[ 38.8789596558, -21.8231220245,  24.4459438324,  ...,)</p>\n<p>There are tiny differences between the gradients.  Any idea where does the difference come from? Thanks a lot!</p>", "body_text": "Running the following scripts with pytorch0.4.1, cuda8 and cudnn5, gives different gradients between single GPU and multi GPU. (scripts quoted from #5778 (comment))\nimport torch\ninput = torch.randn(4, 128, 128).cuda()\nlinear = torch.nn.Linear(128, 128).cuda()\ndp = torch.nn.DataParallel(linear, [0, 1])\n\nlinear(input).sum().backward()\nprint(linear.weight.grad)\n\nlinear.zero_grad()\ndp(input).sum().backward()\nprint(linear.weight.grad)\nSingle-GPU gradients:\ntensor([[ 38.8789596558, -21.8231239319,  24.4459419250,  ...,\n16.9406051636,  16.2471446991, -39.3904113770],\n[ 38.8789596558, -21.8231239319,  24.4459419250,  ...,)\nMulti-gpu DataParallel gradients:\ntensor([[ 38.8789596558, -21.8231220245,  24.4459438324,  ...,\n16.9406070709,  16.2471446991, -39.3904151917],\n[ 38.8789596558, -21.8231220245,  24.4459438324,  ...,)\nThere are tiny differences between the gradients.  Any idea where does the difference come from? Thanks a lot!", "body": "Running the following scripts with pytorch0.4.1, cuda8 and cudnn5, gives different gradients between single GPU and multi GPU. (scripts quoted from https://github.com/pytorch/pytorch/issues/5778#issuecomment-373086192)\r\n\r\n```python\r\nimport torch\r\ninput = torch.randn(4, 128, 128).cuda()\r\nlinear = torch.nn.Linear(128, 128).cuda()\r\ndp = torch.nn.DataParallel(linear, [0, 1])\r\n\r\nlinear(input).sum().backward()\r\nprint(linear.weight.grad)\r\n\r\nlinear.zero_grad()\r\ndp(input).sum().backward()\r\nprint(linear.weight.grad)\r\n```\r\n\r\nSingle-GPU gradients:\r\ntensor([[ 38.8789596558, -21.8231239319,  24.4459419250,  ...,\r\n          16.9406051636,  16.2471446991, -39.3904113770],\r\n        [ 38.8789596558, -21.8231239319,  24.4459419250,  ...,)\r\n\r\nMulti-gpu DataParallel gradients:\r\ntensor([[ 38.8789596558, -21.8231220245,  24.4459438324,  ...,\r\n          16.9406070709,  16.2471446991, -39.3904151917],\r\n        [ 38.8789596558, -21.8231220245,  24.4459438324,  ...,)\r\n\r\nThere are tiny differences between the gradients.  Any idea where does the difference come from? Thanks a lot!"}