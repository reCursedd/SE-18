{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/298789191", "html_url": "https://github.com/pytorch/pytorch/issues/1433#issuecomment-298789191", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1433", "id": 298789191, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODc4OTE5MQ==", "user": {"login": "oleg-trott", "id": 2914939, "node_id": "MDQ6VXNlcjI5MTQ5Mzk=", "avatar_url": "https://avatars1.githubusercontent.com/u/2914939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oleg-trott", "html_url": "https://github.com/oleg-trott", "followers_url": "https://api.github.com/users/oleg-trott/followers", "following_url": "https://api.github.com/users/oleg-trott/following{/other_user}", "gists_url": "https://api.github.com/users/oleg-trott/gists{/gist_id}", "starred_url": "https://api.github.com/users/oleg-trott/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oleg-trott/subscriptions", "organizations_url": "https://api.github.com/users/oleg-trott/orgs", "repos_url": "https://api.github.com/users/oleg-trott/repos", "events_url": "https://api.github.com/users/oleg-trott/events{/privacy}", "received_events_url": "https://api.github.com/users/oleg-trott/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-02T23:27:44Z", "updated_at": "2017-05-02T23:27:44Z", "author_association": "NONE", "body_html": "<p>Scalars are tensors of dim=0.</p>\n<p>PyTorch (unlike Numpy) seems to have an internally inconsistent interpretation here:</p>\n<pre><code>&gt;&gt;&gt; shape = [2, 3]\n&gt;&gt;&gt; torch.ones(shape).nelement() == np.prod(shape)\nTrue\n\n&gt;&gt;&gt; shape = []\n&gt;&gt;&gt; torch.ones(shape).nelement() == np.prod(shape)\nFalse\n</code></pre>\n<p>If this (as well as broadcasting) were fixed, perhaps there wouldn't be a need for the special <code>torch.Scalar</code> class?</p>", "body_text": "Scalars are tensors of dim=0.\nPyTorch (unlike Numpy) seems to have an internally inconsistent interpretation here:\n>>> shape = [2, 3]\n>>> torch.ones(shape).nelement() == np.prod(shape)\nTrue\n\n>>> shape = []\n>>> torch.ones(shape).nelement() == np.prod(shape)\nFalse\n\nIf this (as well as broadcasting) were fixed, perhaps there wouldn't be a need for the special torch.Scalar class?", "body": "Scalars are tensors of dim=0.\r\n\r\nPyTorch (unlike Numpy) seems to have an internally inconsistent interpretation here:\r\n\r\n```\r\n>>> shape = [2, 3]\r\n>>> torch.ones(shape).nelement() == np.prod(shape)\r\nTrue\r\n\r\n>>> shape = []\r\n>>> torch.ones(shape).nelement() == np.prod(shape)\r\nFalse\r\n```\r\n\r\nIf this (as well as broadcasting) were fixed, perhaps there wouldn't be a need for the special `torch.Scalar` class?\r\n"}