{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10610", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10610/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10610/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10610/events", "html_url": "https://github.com/pytorch/pytorch/pull/10610", "id": 351438145, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA5MDMyNTY2", "number": 10610, "title": "[JIT] Support custom ops in ScriptModule and tidy up test files", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-08-17T02:46:15Z", "updated_at": "2018-11-23T15:49:50Z", "closed_at": "2018-08-22T01:43:25Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10610", "html_url": "https://github.com/pytorch/pytorch/pull/10610", "diff_url": "https://github.com/pytorch/pytorch/pull/10610.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10610.patch"}, "body_html": "<p>This PR adds support for using custom ops in ScriptModules, the last step for our custom op strategy. You can now write</p>\n<pre><code>import torch\n\ntorch.ops.load_library('libcustom_ops.so')\n\nclass Model(torch.jit.ScriptModule):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, input):\n        return torch.ops.custom.op(input) + 1\n\nmodel = Model()\nmodel.forward(torch.ones(5)) # Works\nmodel.save(\"model.pt\") # Works\nmodel = torch.jit.load(\"model.pt\") # Works\n</code></pre>\n<p>You can then load the <code>model.pt</code> in C++ and execute its <code>forward</code> method!</p>\n<p>Missing for this was the fact that the script compiler didn't know to convert <code>ops.custom.op</code> into a <code>BuiltinFunction</code> which then emits a function call. For this I came up with  the following strategy inside <code>torch/csrc/jit/scrip/init.cpp</code>:</p>\n<ol>\n<li>When we access <code>torch.ops</code>, we return a <code>CustomOpValue</code> (subclass of <code>PythonValue</code>), whose purpose is only to return a <code>CustomOpNamespaceValue</code> (subclass of <code>PythonValue</code>) whenever something under it is accessed.</li>\n<li><code>CustomOpNamespaceValue</code> will then for each field accessed on it return a <code>BuiltinFunction</code>.</li>\n</ol>\n<p>This doesn't reduce performance for any calls that are not to <code>torch.ops</code> (as opposed to inspecting every function call's name the call site, for example).</p>\n<p>I also had to fix <code>BuiltinFunction</code> to not assume the namespace is always <code>aten::</code>.</p>\n<p>A lot of other changes are just tidying up the Python and C++ test harness before I integrate it in CI.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17890620\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dzhulgakov\">@dzhulgakov</a></p>", "body_text": "This PR adds support for using custom ops in ScriptModules, the last step for our custom op strategy. You can now write\nimport torch\n\ntorch.ops.load_library('libcustom_ops.so')\n\nclass Model(torch.jit.ScriptModule):\n    def __init__(self):\n        super(Model, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, input):\n        return torch.ops.custom.op(input) + 1\n\nmodel = Model()\nmodel.forward(torch.ones(5)) # Works\nmodel.save(\"model.pt\") # Works\nmodel = torch.jit.load(\"model.pt\") # Works\n\nYou can then load the model.pt in C++ and execute its forward method!\nMissing for this was the fact that the script compiler didn't know to convert ops.custom.op into a BuiltinFunction which then emits a function call. For this I came up with  the following strategy inside torch/csrc/jit/scrip/init.cpp:\n\nWhen we access torch.ops, we return a CustomOpValue (subclass of PythonValue), whose purpose is only to return a CustomOpNamespaceValue (subclass of PythonValue) whenever something under it is accessed.\nCustomOpNamespaceValue will then for each field accessed on it return a BuiltinFunction.\n\nThis doesn't reduce performance for any calls that are not to torch.ops (as opposed to inspecting every function call's name the call site, for example).\nI also had to fix BuiltinFunction to not assume the namespace is always aten::.\nA lot of other changes are just tidying up the Python and C++ test harness before I integrate it in CI.\n@zdevito @dzhulgakov", "body": "This PR adds support for using custom ops in ScriptModules, the last step for our custom op strategy. You can now write\r\n\r\n```\r\nimport torch\r\n\r\ntorch.ops.load_library('libcustom_ops.so')\r\n\r\nclass Model(torch.jit.ScriptModule):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n\r\n    @torch.jit.script_method\r\n    def forward(self, input):\r\n        return torch.ops.custom.op(input) + 1\r\n\r\nmodel = Model()\r\nmodel.forward(torch.ones(5)) # Works\r\nmodel.save(\"model.pt\") # Works\r\nmodel = torch.jit.load(\"model.pt\") # Works\r\n```\r\n\r\nYou can then load the `model.pt` in C++ and execute its `forward` method!\r\n\r\nMissing for this was the fact that the script compiler didn't know to convert `ops.custom.op` into a `BuiltinFunction` which then emits a function call. For this I came up with  the following strategy inside `torch/csrc/jit/scrip/init.cpp`:\r\n\r\n1. When we access `torch.ops`, we return a `CustomOpValue` (subclass of `PythonValue`), whose purpose is only to return a `CustomOpNamespaceValue` (subclass of `PythonValue`) whenever something under it is accessed.\r\n2. `CustomOpNamespaceValue` will then for each field accessed on it return a `BuiltinFunction`.\r\n\r\nThis doesn't reduce performance for any calls that are not to `torch.ops` (as opposed to inspecting every function call's name the call site, for example).\r\n\r\nI also had to fix `BuiltinFunction` to not assume the namespace is always `aten::`.\r\n\r\nA lot of other changes are just tidying up the Python and C++ test harness before I integrate it in CI.\r\n\r\n@zdevito @dzhulgakov "}