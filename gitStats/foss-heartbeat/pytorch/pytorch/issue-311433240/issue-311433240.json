{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6292", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6292/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6292/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6292/events", "html_url": "https://github.com/pytorch/pytorch/issues/6292", "id": 311433240, "node_id": "MDU6SXNzdWUzMTE0MzMyNDA=", "number": 6292, "title": "Handling of overflows for half tensors ", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-05T00:15:53Z", "updated_at": "2018-04-20T15:50:48Z", "closed_at": "2018-04-20T15:50:48Z", "author_association": "CONTRIBUTOR", "body_html": "<ul>\n<li>PyTorch or Caffe2: Pytorch</li>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: master</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version: n/a</li>\n<li>GPU models and configuration: n/a</li>\n<li>GCC version (if compiling from source): 5.4</li>\n<li>CMake version:</li>\n<li>Build command you used (if compiling from source): python setup.py build develop</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>\n<p>Right now, handling of overflow in half tensors is very inconsistent, as demonstrated by a following script</p>\n<pre><code>import torch\na=torch.cuda.HalfTensor([33000, 33000])\na.sum() #runtime error, value cannot be converted etc\na.sum(0) #ok, returns scalar inf\na[0]=float('inf') #used to work for tensors, not doesn't, runtime error\nb=torch.cuda.FloatTensor([100000])\na[0]=b[0] #ok, a[0] is set to inf\na[0]=100000 #runtime error\n</code></pre>\n<p>Generally, when an element or a slice of a half tensor is assigned to unrepresentable python scalar, runtime error results (this is the case with .sum() too, because the way it happens first tensor is reduced to a host-side scalar, and then result tensor is filled with this scalar value). In many cases, we prefer postponing handling of overlows in half tensors, so throwing runtime error right away is inconvenient. Catching and ignoring any runtime error would lead to ignoring legitimate errors. Can we just disable overflow checks in <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L38\">https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L38</a> or make them smarter to recognize that half actually has_infinity and return false here <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L28-L30\">https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L28-L30</a>?</p>", "body_text": "PyTorch or Caffe2: Pytorch\nOS: Ubuntu 16.04\nPyTorch version: master\nHow you installed PyTorch (conda, pip, source): source\nPython version: 3.6\nCUDA/cuDNN version: n/a\nGPU models and configuration: n/a\nGCC version (if compiling from source): 5.4\nCMake version:\nBuild command you used (if compiling from source): python setup.py build develop\nVersions of any other relevant libraries:\n\nRight now, handling of overflow in half tensors is very inconsistent, as demonstrated by a following script\nimport torch\na=torch.cuda.HalfTensor([33000, 33000])\na.sum() #runtime error, value cannot be converted etc\na.sum(0) #ok, returns scalar inf\na[0]=float('inf') #used to work for tensors, not doesn't, runtime error\nb=torch.cuda.FloatTensor([100000])\na[0]=b[0] #ok, a[0] is set to inf\na[0]=100000 #runtime error\n\nGenerally, when an element or a slice of a half tensor is assigned to unrepresentable python scalar, runtime error results (this is the case with .sum() too, because the way it happens first tensor is reduced to a host-side scalar, and then result tensor is filled with this scalar value). In many cases, we prefer postponing handling of overlows in half tensors, so throwing runtime error right away is inconvenient. Catching and ignoring any runtime error would lead to ignoring legitimate errors. Can we just disable overflow checks in https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L38 or make them smarter to recognize that half actually has_infinity and return false here https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L28-L30?", "body": "- PyTorch or Caffe2: Pytorch\r\n- OS: Ubuntu 16.04\r\n- PyTorch version: master\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: n/a\r\n- GPU models and configuration: n/a\r\n- GCC version (if compiling from source): 5.4\r\n- CMake version:\r\n- Build command you used (if compiling from source): python setup.py build develop\r\n- Versions of any other relevant libraries:\r\n\r\nRight now, handling of overflow in half tensors is very inconsistent, as demonstrated by a following script\r\n```\r\nimport torch\r\na=torch.cuda.HalfTensor([33000, 33000])\r\na.sum() #runtime error, value cannot be converted etc\r\na.sum(0) #ok, returns scalar inf\r\na[0]=float('inf') #used to work for tensors, not doesn't, runtime error\r\nb=torch.cuda.FloatTensor([100000])\r\na[0]=b[0] #ok, a[0] is set to inf\r\na[0]=100000 #runtime error\r\n```\r\nGenerally, when an element or a slice of a half tensor is assigned to unrepresentable python scalar, runtime error results (this is the case with .sum() too, because the way it happens first tensor is reduced to a host-side scalar, and then result tensor is filled with this scalar value). In many cases, we prefer postponing handling of overlows in half tensors, so throwing runtime error right away is inconvenient. Catching and ignoring any runtime error would lead to ignoring legitimate errors. Can we just disable overflow checks in https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L38 or make them smarter to recognize that half actually has_infinity and return false here https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Half.h#L28-L30?"}