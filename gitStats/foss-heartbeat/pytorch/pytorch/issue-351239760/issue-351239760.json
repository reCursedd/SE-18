{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10582", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10582/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10582/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10582/events", "html_url": "https://github.com/pytorch/pytorch/issues/10582", "id": 351239760, "node_id": "MDU6SXNzdWUzNTEyMzk3NjA=", "number": 10582, "title": "[Caffe2] Unable to use MPI rendezvous in Caffe2", "user": {"login": "gyani91", "id": 4917261, "node_id": "MDQ6VXNlcjQ5MTcyNjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/4917261?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gyani91", "html_url": "https://github.com/gyani91", "followers_url": "https://api.github.com/users/gyani91/followers", "following_url": "https://api.github.com/users/gyani91/following{/other_user}", "gists_url": "https://api.github.com/users/gyani91/gists{/gist_id}", "starred_url": "https://api.github.com/users/gyani91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gyani91/subscriptions", "organizations_url": "https://api.github.com/users/gyani91/orgs", "repos_url": "https://api.github.com/users/gyani91/repos", "events_url": "https://api.github.com/users/gyani91/events{/privacy}", "received_events_url": "https://api.github.com/users/gyani91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-16T14:50:46Z", "updated_at": "2018-08-20T17:47:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Unable to use MPI rendezvous in Caffe2.</p>\n<p>I understand that this information may not be sufficient for helping me out. Hence, I request you to ask to perform whatever steps that are required to get more information about the situation.</p>\n<p>I am grateful for your help.</p>\n<h2>Code example</h2>\n<p>Details:<br>\nFor reproducibility, I am using a container made using the following the Dockerfile:</p>\n<pre><code>FROM nvidia/cuda:8.0-cudnn7-devel-ubuntu16.04\nLABEL maintainer=\"aaronmarkham@fb.com\"\n\n# caffe2 install with gpu support\n\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libgflags-dev \\\n    libgoogle-glog-dev \\\n    libgtest-dev \\\n    libiomp-dev \\\n    libleveldb-dev \\\n    liblmdb-dev \\\n    libopencv-dev \\\n    libprotobuf-dev \\\n    libsnappy-dev \\\n    protobuf-compiler \\\n    python-dev \\\n    python-numpy \\\n    python-pip \\\n    python-pydot \\\n    python-setuptools \\\n    python-scipy \\\n    wget \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nRUN wget -q http://www.mpich.org/static/downloads/3.1.4/mpich-3.1.4.tar.gz \\\n    &amp;&amp; tar xf mpich-3.1.4.tar.gz \\\n    &amp;&amp; cd mpich-3.1.4 \\\n    &amp;&amp; ./configure --disable-fortran --enable-fast=all,O3 --prefix=/usr \\\n    &amp;&amp; make -j$(nproc) \\\n    &amp;&amp; make install \\\n    &amp;&amp; ldconfig \\\n    &amp;&amp; cd .. \\\n    &amp;&amp; rm -rf mpich-3.1.4 \\\n    &amp;&amp; rm mpich-3.1.4.tar.gz\n\nRUN pip install --no-cache-dir --upgrade pip==9.0.3 setuptools wheel\nRUN pip install --no-cache-dir \\\n    flask \\\n    future \\\n    graphviz \\\n    hypothesis \\\n    jupyter \\\n    matplotlib \\\n    numpy \\\n    protobuf \\\n    pydot \\\n    python-nvd3 \\\n    pyyaml \\\n    requests \\\n    scikit-image \\\n    scipy \\\n    setuptools \\\n    six \\\n    tornado\n\n########## INSTALLATION STEPS ###################\nRUN git clone --branch master --recursive https://github.com/pytorch/pytorch.git\nRUN cd pytorch &amp;&amp; mkdir build &amp;&amp; cd build \\\n    &amp;&amp; cmake .. \\\n    -DCUDA_ARCH_NAME=Manual \\\n    -DCUDA_ARCH_BIN=\"35 52 60 61\" \\\n    -DCUDA_ARCH_PTX=\"61\" \\\n    -DUSE_NNPACK=OFF \\\n    -DUSE_ROCKSDB=OFF \\\n    &amp;&amp; make -j\"$(nproc)\" install \\\n    &amp;&amp; ldconfig \\\n    &amp;&amp; make clean \\\n    &amp;&amp; cd .. \\\n    &amp;&amp; rm -rf build\n\nENV PYTHONPATH /usr/local\n</code></pre>\n<p>The command:</p>\n<pre><code>srun -N 4 -n 4 -C gpu \\\nshifter run --mpi load/library/caffe2_container_diff \\\npython resnet50_trainer.py \\\n--train_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_train \\\n--test_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_val \\\n--db_type=lmdb \\\n--num_shards=4 \\\n--num_gpu=1 \\\n--num_labels=2 \\\n--batch_size=2 \\\n--epoch_size=150 \\\n--num_epochs=2 \\\n--distributed_transport ibverbs \\\n--distributed_interface mlx5_0\n</code></pre>\n<p>The output/error:</p>\n<pre><code>srun: job 9059937 queued and waiting for resources\nsrun: job 9059937 has been allocated resources\nE0816 14:14:20.081552  7042 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.081637  7042 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.081642  7042 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083420  6442 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083504  6442 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083509  6442 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nE0816 14:14:20.087043  5987 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.087126  5987 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.087131  5987 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nE0816 14:14:20.102372 11086 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.102452 11086 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.102457 11086 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Creating barrier net\nINFO:data_parallel_model:Creating barrier net\nINFO:data_parallel_model:Creating barrier net\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\nINFO:data_parallel_model:Creating barrier net\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n*** SIGSEGV (@0x8) received by PID 5987 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n*** SIGSEGV (@0x8) received by PID 7042 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\n*** SIGSEGV (@0x8) received by PID 6442 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n    @     0x2aaab0af78d3 std::_Function_handler&lt;&gt;::_M_invoke()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n    @     0x2aaab0af78d3 std::_Function_handler&lt;&gt;::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab0af78d3 std::_Function_handler&lt;&gt;::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n*** SIGSEGV (@0x8) received by PID 11086 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @                0x0 (unknown)\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaaaace4390 (unknown)\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase&lt;&gt;::TensorInferenceForConv()\n    @                0x0 (unknown)\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @                0x0 (unknown)\n    @     0x2aaab0af78d3 std::_Function_handler&lt;&gt;::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @                0x0 (unknown)\nsrun: error: nid06499: task 2: Segmentation fault\nsrun: Terminating job step 9059937.0\nsrun: error: nid06497: task 0: Segmentation fault\nsrun: error: nid06498: task 1: Segmentation fault\nsrun: error: nid06500: task 3: Segmentation fault\n</code></pre>\n<h2>System Info</h2>\n<ul>\n<li>Caffe2:</li>\n<li>How you installed Caffe2 (conda, pip, source): Modified Dockerfile mentioned above</li>\n<li>CUDA/cuDNN version: 8.0/7.0</li>\n<li>GPU models and configuration: Cray XC40/XC50 supercomputer, uses SLURM!</li>\n</ul>", "body_text": "Issue description\nUnable to use MPI rendezvous in Caffe2.\nI understand that this information may not be sufficient for helping me out. Hence, I request you to ask to perform whatever steps that are required to get more information about the situation.\nI am grateful for your help.\nCode example\nDetails:\nFor reproducibility, I am using a container made using the following the Dockerfile:\nFROM nvidia/cuda:8.0-cudnn7-devel-ubuntu16.04\nLABEL maintainer=\"aaronmarkham@fb.com\"\n\n# caffe2 install with gpu support\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    libgflags-dev \\\n    libgoogle-glog-dev \\\n    libgtest-dev \\\n    libiomp-dev \\\n    libleveldb-dev \\\n    liblmdb-dev \\\n    libopencv-dev \\\n    libprotobuf-dev \\\n    libsnappy-dev \\\n    protobuf-compiler \\\n    python-dev \\\n    python-numpy \\\n    python-pip \\\n    python-pydot \\\n    python-setuptools \\\n    python-scipy \\\n    wget \\\n    && rm -rf /var/lib/apt/lists/*\n\nRUN wget -q http://www.mpich.org/static/downloads/3.1.4/mpich-3.1.4.tar.gz \\\n    && tar xf mpich-3.1.4.tar.gz \\\n    && cd mpich-3.1.4 \\\n    && ./configure --disable-fortran --enable-fast=all,O3 --prefix=/usr \\\n    && make -j$(nproc) \\\n    && make install \\\n    && ldconfig \\\n    && cd .. \\\n    && rm -rf mpich-3.1.4 \\\n    && rm mpich-3.1.4.tar.gz\n\nRUN pip install --no-cache-dir --upgrade pip==9.0.3 setuptools wheel\nRUN pip install --no-cache-dir \\\n    flask \\\n    future \\\n    graphviz \\\n    hypothesis \\\n    jupyter \\\n    matplotlib \\\n    numpy \\\n    protobuf \\\n    pydot \\\n    python-nvd3 \\\n    pyyaml \\\n    requests \\\n    scikit-image \\\n    scipy \\\n    setuptools \\\n    six \\\n    tornado\n\n########## INSTALLATION STEPS ###################\nRUN git clone --branch master --recursive https://github.com/pytorch/pytorch.git\nRUN cd pytorch && mkdir build && cd build \\\n    && cmake .. \\\n    -DCUDA_ARCH_NAME=Manual \\\n    -DCUDA_ARCH_BIN=\"35 52 60 61\" \\\n    -DCUDA_ARCH_PTX=\"61\" \\\n    -DUSE_NNPACK=OFF \\\n    -DUSE_ROCKSDB=OFF \\\n    && make -j\"$(nproc)\" install \\\n    && ldconfig \\\n    && make clean \\\n    && cd .. \\\n    && rm -rf build\n\nENV PYTHONPATH /usr/local\n\nThe command:\nsrun -N 4 -n 4 -C gpu \\\nshifter run --mpi load/library/caffe2_container_diff \\\npython resnet50_trainer.py \\\n--train_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_train \\\n--test_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_val \\\n--db_type=lmdb \\\n--num_shards=4 \\\n--num_gpu=1 \\\n--num_labels=2 \\\n--batch_size=2 \\\n--epoch_size=150 \\\n--num_epochs=2 \\\n--distributed_transport ibverbs \\\n--distributed_interface mlx5_0\n\nThe output/error:\nsrun: job 9059937 queued and waiting for resources\nsrun: job 9059937 has been allocated resources\nE0816 14:14:20.081552  7042 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.081637  7042 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.081642  7042 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083420  6442 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083504  6442 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.083509  6442 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nE0816 14:14:20.087043  5987 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.087126  5987 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.087131  5987 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nE0816 14:14:20.102372 11086 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.102452 11086 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nE0816 14:14:20.102457 11086 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:resnet50_trainer:Running on GPUs: [0]\nINFO:resnet50_trainer:Using epoch size: 144\nINFO:data_parallel_model:Parallelizing model for devices: [0]\nINFO:data_parallel_model:Create input and model training operators\nINFO:data_parallel_model:Model for GPU : 0\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Adding gradient operators\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Post-iteration operators for updating params\nINFO:data_parallel_model:Calling optimizer builder function\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Add initial parameter sync\nINFO:data_parallel_model:Creating barrier net\nINFO:data_parallel_model:Creating barrier net\nINFO:data_parallel_model:Creating barrier net\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\nINFO:data_parallel_model:Creating barrier net\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n*** SIGSEGV (@0x8) received by PID 5987 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n*** SIGSEGV (@0x8) received by PID 7042 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\n*** SIGSEGV (@0x8) received by PID 6442 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaaaace4390 (unknown)\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n*** SIGSEGV (@0x8) received by PID 11086 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @                0x0 (unknown)\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaaaace4390 (unknown)\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\n    @                0x0 (unknown)\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @                0x0 (unknown)\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\n    @           0x4bc3fa PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c16e7 PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4c1e6f PyEval_EvalFrameEx\n    @           0x4b9ab6 PyEval_EvalCodeEx\n    @           0x4eb30f (unknown)\n    @           0x4e5422 PyRun_FileExFlags\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\n    @           0x493ae2 Py_Main\n    @     0x2aaaaaf10830 __libc_start_main\n    @           0x4933e9 _start\n    @                0x0 (unknown)\nsrun: error: nid06499: task 2: Segmentation fault\nsrun: Terminating job step 9059937.0\nsrun: error: nid06497: task 0: Segmentation fault\nsrun: error: nid06498: task 1: Segmentation fault\nsrun: error: nid06500: task 3: Segmentation fault\n\nSystem Info\n\nCaffe2:\nHow you installed Caffe2 (conda, pip, source): Modified Dockerfile mentioned above\nCUDA/cuDNN version: 8.0/7.0\nGPU models and configuration: Cray XC40/XC50 supercomputer, uses SLURM!", "body": "## Issue description\r\nUnable to use MPI rendezvous in Caffe2.\r\n\r\nI understand that this information may not be sufficient for helping me out. Hence, I request you to ask to perform whatever steps that are required to get more information about the situation.\r\n\r\nI am grateful for your help.\r\n\r\n## Code example\r\nDetails:\r\nFor reproducibility, I am using a container made using the following the Dockerfile:\r\n\r\n```\r\nFROM nvidia/cuda:8.0-cudnn7-devel-ubuntu16.04\r\nLABEL maintainer=\"aaronmarkham@fb.com\"\r\n\r\n# caffe2 install with gpu support\r\n\r\nRUN apt-get update && apt-get install -y --no-install-recommends \\\r\n    build-essential \\\r\n    cmake \\\r\n    git \\\r\n    libgflags-dev \\\r\n    libgoogle-glog-dev \\\r\n    libgtest-dev \\\r\n    libiomp-dev \\\r\n    libleveldb-dev \\\r\n    liblmdb-dev \\\r\n    libopencv-dev \\\r\n    libprotobuf-dev \\\r\n    libsnappy-dev \\\r\n    protobuf-compiler \\\r\n    python-dev \\\r\n    python-numpy \\\r\n    python-pip \\\r\n    python-pydot \\\r\n    python-setuptools \\\r\n    python-scipy \\\r\n    wget \\\r\n    && rm -rf /var/lib/apt/lists/*\r\n\r\nRUN wget -q http://www.mpich.org/static/downloads/3.1.4/mpich-3.1.4.tar.gz \\\r\n    && tar xf mpich-3.1.4.tar.gz \\\r\n    && cd mpich-3.1.4 \\\r\n    && ./configure --disable-fortran --enable-fast=all,O3 --prefix=/usr \\\r\n    && make -j$(nproc) \\\r\n    && make install \\\r\n    && ldconfig \\\r\n    && cd .. \\\r\n    && rm -rf mpich-3.1.4 \\\r\n    && rm mpich-3.1.4.tar.gz\r\n\r\nRUN pip install --no-cache-dir --upgrade pip==9.0.3 setuptools wheel\r\nRUN pip install --no-cache-dir \\\r\n    flask \\\r\n    future \\\r\n    graphviz \\\r\n    hypothesis \\\r\n    jupyter \\\r\n    matplotlib \\\r\n    numpy \\\r\n    protobuf \\\r\n    pydot \\\r\n    python-nvd3 \\\r\n    pyyaml \\\r\n    requests \\\r\n    scikit-image \\\r\n    scipy \\\r\n    setuptools \\\r\n    six \\\r\n    tornado\r\n\r\n########## INSTALLATION STEPS ###################\r\nRUN git clone --branch master --recursive https://github.com/pytorch/pytorch.git\r\nRUN cd pytorch && mkdir build && cd build \\\r\n    && cmake .. \\\r\n    -DCUDA_ARCH_NAME=Manual \\\r\n    -DCUDA_ARCH_BIN=\"35 52 60 61\" \\\r\n    -DCUDA_ARCH_PTX=\"61\" \\\r\n    -DUSE_NNPACK=OFF \\\r\n    -DUSE_ROCKSDB=OFF \\\r\n    && make -j\"$(nproc)\" install \\\r\n    && ldconfig \\\r\n    && make clean \\\r\n    && cd .. \\\r\n    && rm -rf build\r\n\r\nENV PYTHONPATH /usr/local\r\n```\r\n\r\nThe command:\r\n\r\n```\r\nsrun -N 4 -n 4 -C gpu \\\r\nshifter run --mpi load/library/caffe2_container_diff \\\r\npython resnet50_trainer.py \\\r\n--train_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_train \\\r\n--test_data=$SCRATCH/caffe2_notebooks/tutorial_data/resnet_trainer/imagenet_cars_boats_val \\\r\n--db_type=lmdb \\\r\n--num_shards=4 \\\r\n--num_gpu=1 \\\r\n--num_labels=2 \\\r\n--batch_size=2 \\\r\n--epoch_size=150 \\\r\n--num_epochs=2 \\\r\n--distributed_transport ibverbs \\\r\n--distributed_interface mlx5_0\r\n```\r\n\r\nThe output/error:\r\n\r\n```\r\nsrun: job 9059937 queued and waiting for resources\r\nsrun: job 9059937 has been allocated resources\r\nE0816 14:14:20.081552  7042 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.081637  7042 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.081642  7042 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.083420  6442 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.083504  6442 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.083509  6442 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nINFO:resnet50_trainer:Running on GPUs: [0]\r\nINFO:resnet50_trainer:Using epoch size: 144\r\nINFO:resnet50_trainer:Running on GPUs: [0]\r\nINFO:resnet50_trainer:Using epoch size: 144\r\nE0816 14:14:20.087043  5987 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.087126  5987 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.087131  5987 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nINFO:resnet50_trainer:Running on GPUs: [0]\r\nINFO:resnet50_trainer:Using epoch size: 144\r\nINFO:data_parallel_model:Parallelizing model for devices: [0]\r\nINFO:data_parallel_model:Create input and model training operators\r\nINFO:data_parallel_model:Model for GPU : 0\r\nINFO:data_parallel_model:Parallelizing model for devices: [0]\r\nINFO:data_parallel_model:Create input and model training operators\r\nINFO:data_parallel_model:Model for GPU : 0\r\nE0816 14:14:20.102372 11086 init_intrinsics_check.cc:43] CPU feature avx is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.102452 11086 init_intrinsics_check.cc:43] CPU feature avx2 is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nE0816 14:14:20.102457 11086 init_intrinsics_check.cc:43] CPU feature fma is present on your machine, but the Caffe2 binary is not compiled with it. It means you may not get the full speed of your CPU.\r\nINFO:data_parallel_model:Parallelizing model for devices: [0]\r\nINFO:data_parallel_model:Create input and model training operators\r\nINFO:data_parallel_model:Model for GPU : 0\r\nINFO:resnet50_trainer:Running on GPUs: [0]\r\nINFO:resnet50_trainer:Using epoch size: 144\r\nINFO:data_parallel_model:Parallelizing model for devices: [0]\r\nINFO:data_parallel_model:Create input and model training operators\r\nINFO:data_parallel_model:Model for GPU : 0\r\nINFO:data_parallel_model:Adding gradient operators\r\nINFO:data_parallel_model:Adding gradient operators\r\nINFO:data_parallel_model:Adding gradient operators\r\nINFO:data_parallel_model:Adding gradient operators\r\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\r\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\r\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\r\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\r\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\r\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\r\nINFO:data_parallel_model:Add gradient all-reduces for SyncSGD\r\nWARNING:data_parallel_model:Distributed broadcast of computed params is not implemented yet\r\nINFO:data_parallel_model:Post-iteration operators for updating params\r\nINFO:data_parallel_model:Calling optimizer builder function\r\nINFO:data_parallel_model:Post-iteration operators for updating params\r\nINFO:data_parallel_model:Post-iteration operators for updating params\r\nINFO:data_parallel_model:Calling optimizer builder function\r\nINFO:data_parallel_model:Calling optimizer builder function\r\nINFO:data_parallel_model:Post-iteration operators for updating params\r\nINFO:data_parallel_model:Calling optimizer builder function\r\nINFO:data_parallel_model:Add initial parameter sync\r\nINFO:data_parallel_model:Add initial parameter sync\r\nINFO:data_parallel_model:Add initial parameter sync\r\nINFO:data_parallel_model:Add initial parameter sync\r\nINFO:data_parallel_model:Creating barrier net\r\nINFO:data_parallel_model:Creating barrier net\r\nINFO:data_parallel_model:Creating barrier net\r\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\r\nINFO:data_parallel_model:Creating barrier net\r\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\r\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\r\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n*** SIGSEGV (@0x8) received by PID 5987 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\r\n    @     0x2aaaaace4390 (unknown)\r\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n*** SIGSEGV (@0x8) received by PID 7042 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\r\n    @     0x2aaaaace4390 (unknown)\r\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n*** Aborted at 1534428860 (unix time) try \"date -d @1534428860\" if you are using GNU date ***\r\n*** SIGSEGV (@0x8) received by PID 6442 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\r\n    @     0x2aaaaace4390 (unknown)\r\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\r\nPC: @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\r\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\r\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\r\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\r\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\r\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\r\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\r\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x2aaaaaf10830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\r\n*** SIGSEGV (@0x8) received by PID 11086 (TID 0x2aaaaaae5480) from PID 8; stack trace: ***\r\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\r\n    @                0x0 (unknown)\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\r\n    @     0x2aaaaace4390 (unknown)\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x2aaaaaf10830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @     0x2aaab0afb108 caffe2::ConvPoolOpBase<>::TensorInferenceForConv()\r\n    @                0x0 (unknown)\r\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x2aaaaaf10830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @                0x0 (unknown)\r\n    @     0x2aaab0af78d3 std::_Function_handler<>::_M_invoke()\r\n    @     0x2aaab09e8094 caffe2::InferBlobShapesAndTypes()\r\n    @     0x2aaab09e9659 caffe2::InferBlobShapesAndTypesFromMap()\r\n    @     0x2aaab032588e _ZZN8pybind1112cpp_function10initializeIZN6caffe26python16addGlobalMethodsERNS_6moduleEEUlRKSt6vectorINS_5bytesESaIS7_EESt3mapINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES6_IlSaIlEESt4lessISI_ESaISt4pairIKSI_SK_EEEE36_S7_JSB_SR_EJNS_4nameENS_5scopeENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES19_\r\n    @     0x2aaab035273e pybind11::cpp_function::dispatcher()\r\n    @           0x4bc3fa PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c16e7 PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4c1e6f PyEval_EvalFrameEx\r\n    @           0x4b9ab6 PyEval_EvalCodeEx\r\n    @           0x4eb30f (unknown)\r\n    @           0x4e5422 PyRun_FileExFlags\r\n    @           0x4e3cd6 PyRun_SimpleFileExFlags\r\n    @           0x493ae2 Py_Main\r\n    @     0x2aaaaaf10830 __libc_start_main\r\n    @           0x4933e9 _start\r\n    @                0x0 (unknown)\r\nsrun: error: nid06499: task 2: Segmentation fault\r\nsrun: Terminating job step 9059937.0\r\nsrun: error: nid06497: task 0: Segmentation fault\r\nsrun: error: nid06498: task 1: Segmentation fault\r\nsrun: error: nid06500: task 3: Segmentation fault\r\n```\r\n\r\n## System Info\r\n\r\n- Caffe2:\r\n- How you installed Caffe2 (conda, pip, source): Modified Dockerfile mentioned above\r\n- CUDA/cuDNN version: 8.0/7.0\r\n- GPU models and configuration: Cray XC40/XC50 supercomputer, uses SLURM!\r\n\r\n"}