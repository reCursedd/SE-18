{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/402877941", "html_url": "https://github.com/pytorch/pytorch/issues/9105#issuecomment-402877941", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9105", "id": 402877941, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjg3Nzk0MQ==", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-05T23:10:14Z", "updated_at": "2018-07-05T23:10:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7424737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/PetrochukM\">@PetrochukM</a> , for the first question, it's a suggestion instead of a requirement. In DDP we only run <code>len(inputs)</code> modules in parallel. In another word, if you only have batch 1 but device_ids=[0,1,2,3] in DDP, it will not break but only waste resources.<br>\nFor your use case, if the evaluation step is in model train, it's safe to call DistributedDataParallel.</p>", "body_text": "Hi @PetrochukM , for the first question, it's a suggestion instead of a requirement. In DDP we only run len(inputs) modules in parallel. In another word, if you only have batch 1 but device_ids=[0,1,2,3] in DDP, it will not break but only waste resources.\nFor your use case, if the evaluation step is in model train, it's safe to call DistributedDataParallel.", "body": "Hi @PetrochukM , for the first question, it's a suggestion instead of a requirement. In DDP we only run `len(inputs)` modules in parallel. In another word, if you only have batch 1 but device_ids=[0,1,2,3] in DDP, it will not break but only waste resources. \r\nFor your use case, if the evaluation step is in model train, it's safe to call DistributedDataParallel. "}