{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12108", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12108/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12108/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12108/events", "html_url": "https://github.com/pytorch/pytorch/pull/12108", "id": 364153039, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE4NDEwNDY5", "number": 12108, "title": "Use atomicAdd from cuda_fp16 header when building with CUDA 10", "user": {"login": "syed-ahmed", "id": 8906225, "node_id": "MDQ6VXNlcjg5MDYyMjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8906225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syed-ahmed", "html_url": "https://github.com/syed-ahmed", "followers_url": "https://api.github.com/users/syed-ahmed/followers", "following_url": "https://api.github.com/users/syed-ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/syed-ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/syed-ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syed-ahmed/subscriptions", "organizations_url": "https://api.github.com/users/syed-ahmed/orgs", "repos_url": "https://api.github.com/users/syed-ahmed/repos", "events_url": "https://api.github.com/users/syed-ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/syed-ahmed/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-26T18:22:35Z", "updated_at": "2018-09-26T23:17:39Z", "closed_at": "2018-09-26T22:29:37Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/12108", "html_url": "https://github.com/pytorch/pytorch/pull/12108", "diff_url": "https://github.com/pytorch/pytorch/pull/12108.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/12108.patch"}, "body_html": "<p>An efficient atomicAdd for halfs has been added in <code>cuda_fp16.h</code> in CUDA 10:<br>\n<code>__CUDA_FP16_DECL__ __half atomicAdd(__half *address, __half val);</code></p>\n<p>Through this change, PyTorch will be able to utilize efficient atomicAdd when building with CUDA 10.</p>", "body_text": "An efficient atomicAdd for halfs has been added in cuda_fp16.h in CUDA 10:\n__CUDA_FP16_DECL__ __half atomicAdd(__half *address, __half val);\nThrough this change, PyTorch will be able to utilize efficient atomicAdd when building with CUDA 10.", "body": "An efficient atomicAdd for halfs has been added in `cuda_fp16.h` in CUDA 10: \r\n```__CUDA_FP16_DECL__ __half atomicAdd(__half *address, __half val);```\r\n\r\nThrough this change, PyTorch will be able to utilize efficient atomicAdd when building with CUDA 10."}