{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9674", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9674/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9674/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9674/events", "html_url": "https://github.com/pytorch/pytorch/issues/9674", "id": 343294880, "node_id": "MDU6SXNzdWUzNDMyOTQ4ODA=", "number": 9674, "title": "The state of sparse Tensors", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679954154, "node_id": "MDU6TGFiZWw2Nzk5NTQxNTQ=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/sparse", "name": "sparse", "color": "bfd4f2", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2018-07-21T04:03:19Z", "updated_at": "2018-11-02T13:00:16Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>This note tries to summarize the current state of sparse tensor in pytorch. It describes important invariance and properties of sparse tensor, and various things need to be fixed (e.g. empty sparse tensor). It also shows some details of sparse operators.</p>\n<h2>Semantics</h2>\n<h3>Construct a sparse tensor</h3>\n<pre><code># create a float sparse tensor in CPU\n&gt;&gt;&gt; indices = torch.LongTensor([[0, 0, 1], [0, 1, 1]])\n&gt;&gt;&gt; values = torch.FloatTensor([2, 3, 4])\n&gt;&gt;&gt; sizes = [2, 2]\n&gt;&gt;&gt; torch.sparse_coo_tensor(indices, values, sizes)\ntorch.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]])\nand values:\ntensor([2., 3., 4.])\n\n# to_dense\n&gt;&gt;&gt; torch.sparse_coo_tensor(indices, values, sizes).to_dense()\ntensor([[2., 3.],\n        [0., 4.]])\n\n# in CUDA\n&gt;&gt;&gt; torch.sparse_coo_tensor(indices, values, sizes, device=torch.device('cuda'))\ntorch.cuda.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]], device='cuda:0')\nand values:\ntensor([2., 3., 4.], device='cuda:0')\n</code></pre>\n<h3>More approaches in creating a sparse tensor</h3>\n<pre><code>torch.sparse.FloatTensor()\ntorch.sparse.DoubleTensor()\ntorch.zeros(..., layout=torch.sparse_coo, ...)\n</code></pre>\n<p>Should we unify/reduce different approaches?</p>\n<h2>Sparse representation</h2>\n<p>Currently, our sparse tensors are hybrid tensors, with a mix of sparse dims and dense dims. We keep track of <code>nnz</code>, <code>sparseDims</code>, <code>denseDims</code>, a <code>indices tensor of size = (sparseDims, nnz)</code>, and a <code>values tensor of size (nnz, size[sparseDims:])</code>. Additionally, we have a flag to note if the tensor is <code>coalesced</code>.</p>\n<h3>Should we keep this representation?</h3>\n<ul>\n<li>\n<p>Our currently hybrid representation has some issues. It's difficult to support operators on hybrid tensors, <em>especially because only embedding uses hybrid</em>. Furthermore, some functions have ambiguous outputs on hybrid tensors (e.g. transposing a dense dim and a sparse dim is ambiguous). Because of this, it makes sense to have embedding has a special case, and only support \u201ctrue\u201d sparse tensors with denseDims = 0.</p>\n</li>\n<li>\n<p>Many sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?</p>\n</li>\n<li>\n<p>Caffe2 uses per-row counts to represent sparse tensors, and they have some level of sparse support.</p>\n</li>\n</ul>\n<h3>A couple caveats with our current system</h3>\n<ul>\n<li>Things we should always keep in mind</li>\n</ul>\n<pre><code>Ideal INVARIANTS:\n  _sparseDims: range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\n  _denseDims : range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\n  _indices.shape: dimensionality: 2,  shape: (_sparseDims, nnz)\n  _values.shape:  dimensionality: 1 + _denseDims.  shape: (nnz, shape[_sparseDims:])\n\nActual INVARIANT differences:\n  1) _sparseDims: range [1, len(shape)] (i.e. we don't allow 0 sparse dimensions)\n  2) when nnz = 0, there is strange behavior because we lack 0-dimensional sparse tensors.  Namely:\n     dimensionality == 0, _sparseDims == 0, _denseDims == 0, _indices.shape == {0}, _values.shape == {0}\n  3) For both _indices.shape and _values.shape, the nnz dimension may be larger than nnz\n  4) For _values.shape, the non-nnz dimensions may be smaller than the corresponding dimension size, e.g.\n     a shape (2,3) sparse tensor with _sparseDims == 1, may have _values.shape: (nnz, &lt;=2, &lt;=3).\n</code></pre>\n<ul>\n<li>We're keeping track of nnz, sparseDims, denseDims and coalesced independently of the indices and values tensors. For instance, we may need to write the following code to maintain the invariance:</li>\n</ul>\n<pre><code>_get_sparse_impl(r)-&gt;set_indices_and_values(r_indices, r_values);\n_get_sparse_impl(r)-&gt;set_nnz(t._nnz());\n_get_sparse_impl(r)-&gt;set_coalesced(t.is_coalesced());\n</code></pre>\n<ul>\n<li>\n<p>Without support for 0-dim tensors, we cannot have proper support for scalar sparse tensors. This makes it unclear how to implement ops like reduction ops, which is currently represented as a dense scalar. Maybe there is nothing wrong with the current representation, we just need to be minded that sparse ops can return a scalar.</p>\n</li>\n<li>\n<p>The nnz and the nnz dimension in two indices and value tensors may not be the same, some cuda kernels rely on this.</p>\n</li>\n<li>\n<p>In values, the non-nnz dimensions might not actually match the dimensions of the sparse tensor</p>\n</li>\n<li>\n<p>We have dim == sparseDims + denseDims, but sparseDims cannot be 0. On one hand, this makes sense because a sparse tensor should have at least one sparse dim, but at the same time, it's in conflict with the idea of a scalar sparse tensor.</p>\n</li>\n<li>\n<p>An empty sparse tensor has indices of dim = 1, which means we have to check <code>nnz != 0</code> everywhere in using a TensorAccessor of indices.</p>\n</li>\n</ul>\n<h3>Some of these issues are fixed by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a>  PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"339577414\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9279\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9279/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9279\">#9279</a></h3>\n<p>Current behavoir of an empty sparse tensor:</p>\n<pre><code>&gt;&gt;&gt; a = torch.sparse_coo_tensor([], [], [2, 3])\n&gt;&gt;&gt; i = a._indices()\n&gt;&gt;&gt; v = a._values()\n\n&gt;&gt;&gt; print(a)\ntorch.sparse.FloatTensor of size (2,3) with indices:\ntensor([], dtype=torch.int64)\nand values:\ntensor([])\n\n&gt;&gt;&gt; print('i = %s' % i)\ni = tensor([], dtype=torch.int64)\n\n&gt;&gt;&gt; print('v = %s' % v)\nv = tensor([])\n\n&gt;&gt;&gt; print('a.dim = %d, i.dim = %d, v.dim = %d' % (a.dim(), i.dim(), v.dim()))\na.dim = 2, i.dim = 1, v.dim = 1\n\n&gt;&gt;&gt; print('a._dimI = %d, a._sparseDims = %d, a._dimV = %d, a._denseDims = %d, a._nnz = %d' % \n          (a._dimI(), a._sparseDims(), a._dimV(), a._denseDims(), a._nnz()))\na._dimI = 0, a._sparseDims = 2, a._dimV = 0, a._denseDims = 0, a._nnz = 0\n</code></pre>\n<p>When properly supported:</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; a=torch.sparse.DoubleTensor()\n&gt;&gt;&gt; a\ntorch.sparse.DoubleTensor of size (0,) with indices:\ntensor([], size=(1, 0), dtype=torch.int64)\nand values:\ntensor([], dtype=torch.float64)\n\n# empty sparse tensor to be a 1-dimensional tensor of size [0], \n# with sparseDims == 1 and denseDims == 0\n\n# invariants:\n#   _sparseDims + _denseDims = len(shape)\n#   _indices.dim = 2, shape = (_sparseDims, nnz)\n#   _values.dim = 1 + _denseDims, shape = (nnz, shape[_sparseDims:])\n</code></pre>\n<p>This fixes:</p>\n<ul>\n<li>An empty sparse tensor has indices of dim = 1, which means we have to check <code>nnz != 0</code> everywhere in using a TensorAccessor of indices.</li>\n</ul>\n<h3>Autograd support</h3>\n<pre><code>&gt;&gt;&gt; a = torch.sparse_coo_tensor(indices, values, sizes, requires_grad=True)\n&gt;&gt;&gt; b = a * 2\n&gt;&gt;&gt; b.backward(torch.sparse_coo_tensor(indices, values, sizes))\n&gt;&gt;&gt; print(a)\n\ntorch.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]])\nand values:\ntensor([4., 6., 8.])\n</code></pre>\n<p>A lot of operators on sparse tensors have densified gradients. e.g., <code>log1p</code> would make all 0 inputs have a gradient of 1, and it densifies the sparse tensor gradients. Currently we have to raise errors in the backward of these operators. Some potential ways to fix:</p>\n<ul>\n<li>\n<p>Define special sparse operations so that they operate only on the nnz. This works well for functions that take a single input tensor. For example, we can define sparse log1p such that implicit 0s do not participate, and it would allow us to have a sparse gradient tensor. We can call this operator <code>s_log1p</code> or <code>nnz_log1p</code> (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"224611346\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1369\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1369/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1369\">#1369</a> has similar discussions). However, we are not sure if they are really what users want, because these operators have different behaviors to their dense counterpart.</p>\n</li>\n<li>\n<p>Return a dense gradient. We can have backward functions able to handle both of dense and sparse gradients. No special treatment needed during autograd, just more functions to be written.</p>\n</li>\n<li>\n<p>Return the gradient as a sparse tensor. Even though we know a tensor might be completely dense, we can still choose to return its sparse form. This is awful for performance.</p>\n</li>\n<li>\n<p>No backward for densified gradients of sparse operator. Users need to call <code>to_dense</code> and apply dense operators instead. This will not work without backward for <code>to_dense</code>, which itself will have a densified gradients, and it brings us back to the 2nd proposal.</p>\n</li>\n</ul>\n<h2>Functions</h2>\n<h3>Pointwise one tensor math</h3>\n<table>\n<thead>\n<tr>\n<th>functions</th>\n<th align=\"center\">dense grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pow</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>log1p</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>div_ / div(Sparse, Scalar)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>mul_ /\u00a0mul(Sparse, Scalar)</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>All pointwise one tensor calls dense couterpart ops on <code>_values</code>, so maybe a macro can be written to cover them all.</p>\n<h3>Pointwise two tensor math</h3>\n<table>\n<thead>\n<tr>\n<th>functions</th>\n<th>formula</th>\n<th align=\"center\">dense grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>add_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse</td>\n<td>add(T, S, alpha) = T + alpha * S</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>add_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense</td>\n<td>add(T, S, alpha) = T + alpha * S</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>sub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse</td>\n<td>sub(T, S, alpha) = T - alpha * S</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>mul_ / mul(Sparse, Sparse) \u2192 Sparse</td>\n<td>mul(T, S) = T * S</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>All pointwise two tensor functions have properly optimized CUDA kernel except for <code>mul_ / mul</code>:</p>\n<ul>\n<li><code>add_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse</code> returns cat(Sparse, Scalar * Sparse)</li>\n<li><code>add_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense</code> parallelizes over nnz</li>\n<li><code>sub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse</code> calls <code>add</code></li>\n</ul>\n<p><code>mul_ / mul(Sparse, Sparse) \u2192 Sparse</code> needs parallelized CUDA kernels, possible directions:</p>\n<ol>\n<li>write customized kernel to parallelized over nnz of 1st sparse tensor</li>\n<li>use cuSPARSE?</li>\n</ol>\n<h3>BLAS</h3>\n<table>\n<thead>\n<tr>\n<th>functions</th>\n<th>formula</th>\n<th align=\"center\">dense grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>addmm(Dense, Sparse, Dense, Scalar, Scalar) \u2192 Dense</td>\n<td>addmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>sspaddmm(Sparse, Sparse, Dense, Scalar, Scalar) \u2192 Sparse</td>\n<td>sspaddmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>mm(Sparse, Dense) \u2192 Dense</td>\n<td>mm(S, D) = mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>smm(Sparse, Dense) \u2192 Sparse</td>\n<td>smm(S, D) = mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>hspmm(Sparse, Dense) \u2192 HybridSparse</td>\n<td>hspmm(S, D) = mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>spmm(Sparse, Dense) \u2192 Dense</td>\n<td>spmm(S, D) = mm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<p>Functions with CUDA kernel optimized are <code>mm</code>, <code>addmm</code> and <code>hspmm</code>. <code>addmm</code> and <code>hspmm</code> use cuSPARSE (cusparseScsrmm2 and cusparseDcsrmm2) in CUDA kernel, and <code>mm</code> calls <code>addmm</code>. However, <code>smm</code> and <code>sspaddmm</code> don't have CUDA support (gets removed?).</p>\n<h3>Others</h3>\n<table>\n<thead>\n<tr>\n<th>functions</th>\n<th align=\"center\">dense grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>clone</td>\n<td align=\"center\">NA</td>\n</tr>\n<tr>\n<td>norm</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>zero_</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>t_ / t</td>\n<td align=\"center\">N</td>\n</tr>\n</tbody>\n</table>\n<h2>Optimizers</h2>\n<ul>\n<li>optim.SGD (CUDA and CPU)</li>\n<li>optim.SparseAdam (CUDA and CPU) - lazy version of Adam algorithm</li>\n<li>optim.Adagrad (CPU)</li>\n</ul>\n<h2>Future work</h2>\n<h3>TODO functions</h3>\n<table>\n<thead>\n<tr>\n<th>Functions</th>\n<th align=\"center\">dense grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>nonzero</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>sum</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>copy_</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>narrow</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>select_index</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>mul_ / mul(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>cuda</td>\n<td align=\"center\">NA</td>\n</tr>\n<tr>\n<td>F.linear</td>\n<td align=\"center\">Y</td>\n</tr>\n<tr>\n<td>softmax</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>cat</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>max</td>\n<td align=\"center\">N</td>\n</tr>\n<tr>\n<td>bmm(S, D)</td>\n<td align=\"center\">Y</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>There is a list of pointwise functions for sparse can be implemented by calling dense ops on their <code>_values</code>, some helpers or macros can be written to make all of these ops available for sparse.</li>\n</ul>\n<pre><code>abs, acos, asin, atan, ceil, cos, cosh, erf, exp, expm1, floor, \nlog, log10, log2, round, sin, sinh, sqrt, rsqrt, tan, trunc\n</code></pre>\n<p>This note was summarized by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8813817\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/li-roy\">@li-roy</a> and me. All suggestions/comments are more than welcomed!</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a></p>", "body_text": "This note tries to summarize the current state of sparse tensor in pytorch. It describes important invariance and properties of sparse tensor, and various things need to be fixed (e.g. empty sparse tensor). It also shows some details of sparse operators.\nSemantics\nConstruct a sparse tensor\n# create a float sparse tensor in CPU\n>>> indices = torch.LongTensor([[0, 0, 1], [0, 1, 1]])\n>>> values = torch.FloatTensor([2, 3, 4])\n>>> sizes = [2, 2]\n>>> torch.sparse_coo_tensor(indices, values, sizes)\ntorch.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]])\nand values:\ntensor([2., 3., 4.])\n\n# to_dense\n>>> torch.sparse_coo_tensor(indices, values, sizes).to_dense()\ntensor([[2., 3.],\n        [0., 4.]])\n\n# in CUDA\n>>> torch.sparse_coo_tensor(indices, values, sizes, device=torch.device('cuda'))\ntorch.cuda.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]], device='cuda:0')\nand values:\ntensor([2., 3., 4.], device='cuda:0')\n\nMore approaches in creating a sparse tensor\ntorch.sparse.FloatTensor()\ntorch.sparse.DoubleTensor()\ntorch.zeros(..., layout=torch.sparse_coo, ...)\n\nShould we unify/reduce different approaches?\nSparse representation\nCurrently, our sparse tensors are hybrid tensors, with a mix of sparse dims and dense dims. We keep track of nnz, sparseDims, denseDims, a indices tensor of size = (sparseDims, nnz), and a values tensor of size (nnz, size[sparseDims:]). Additionally, we have a flag to note if the tensor is coalesced.\nShould we keep this representation?\n\n\nOur currently hybrid representation has some issues. It's difficult to support operators on hybrid tensors, especially because only embedding uses hybrid. Furthermore, some functions have ambiguous outputs on hybrid tensors (e.g. transposing a dense dim and a sparse dim is ambiguous). Because of this, it makes sense to have embedding has a special case, and only support \u201ctrue\u201d sparse tensors with denseDims = 0.\n\n\nMany sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?\n\n\nCaffe2 uses per-row counts to represent sparse tensors, and they have some level of sparse support.\n\n\nA couple caveats with our current system\n\nThings we should always keep in mind\n\nIdeal INVARIANTS:\n  _sparseDims: range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\n  _denseDims : range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\n  _indices.shape: dimensionality: 2,  shape: (_sparseDims, nnz)\n  _values.shape:  dimensionality: 1 + _denseDims.  shape: (nnz, shape[_sparseDims:])\n\nActual INVARIANT differences:\n  1) _sparseDims: range [1, len(shape)] (i.e. we don't allow 0 sparse dimensions)\n  2) when nnz = 0, there is strange behavior because we lack 0-dimensional sparse tensors.  Namely:\n     dimensionality == 0, _sparseDims == 0, _denseDims == 0, _indices.shape == {0}, _values.shape == {0}\n  3) For both _indices.shape and _values.shape, the nnz dimension may be larger than nnz\n  4) For _values.shape, the non-nnz dimensions may be smaller than the corresponding dimension size, e.g.\n     a shape (2,3) sparse tensor with _sparseDims == 1, may have _values.shape: (nnz, <=2, <=3).\n\n\nWe're keeping track of nnz, sparseDims, denseDims and coalesced independently of the indices and values tensors. For instance, we may need to write the following code to maintain the invariance:\n\n_get_sparse_impl(r)->set_indices_and_values(r_indices, r_values);\n_get_sparse_impl(r)->set_nnz(t._nnz());\n_get_sparse_impl(r)->set_coalesced(t.is_coalesced());\n\n\n\nWithout support for 0-dim tensors, we cannot have proper support for scalar sparse tensors. This makes it unclear how to implement ops like reduction ops, which is currently represented as a dense scalar. Maybe there is nothing wrong with the current representation, we just need to be minded that sparse ops can return a scalar.\n\n\nThe nnz and the nnz dimension in two indices and value tensors may not be the same, some cuda kernels rely on this.\n\n\nIn values, the non-nnz dimensions might not actually match the dimensions of the sparse tensor\n\n\nWe have dim == sparseDims + denseDims, but sparseDims cannot be 0. On one hand, this makes sense because a sparse tensor should have at least one sparse dim, but at the same time, it's in conflict with the idea of a scalar sparse tensor.\n\n\nAn empty sparse tensor has indices of dim = 1, which means we have to check nnz != 0 everywhere in using a TensorAccessor of indices.\n\n\nSome of these issues are fixed by @yf225  PR #9279\nCurrent behavoir of an empty sparse tensor:\n>>> a = torch.sparse_coo_tensor([], [], [2, 3])\n>>> i = a._indices()\n>>> v = a._values()\n\n>>> print(a)\ntorch.sparse.FloatTensor of size (2,3) with indices:\ntensor([], dtype=torch.int64)\nand values:\ntensor([])\n\n>>> print('i = %s' % i)\ni = tensor([], dtype=torch.int64)\n\n>>> print('v = %s' % v)\nv = tensor([])\n\n>>> print('a.dim = %d, i.dim = %d, v.dim = %d' % (a.dim(), i.dim(), v.dim()))\na.dim = 2, i.dim = 1, v.dim = 1\n\n>>> print('a._dimI = %d, a._sparseDims = %d, a._dimV = %d, a._denseDims = %d, a._nnz = %d' % \n          (a._dimI(), a._sparseDims(), a._dimV(), a._denseDims(), a._nnz()))\na._dimI = 0, a._sparseDims = 2, a._dimV = 0, a._denseDims = 0, a._nnz = 0\n\nWhen properly supported:\n>>> import torch\n>>> a=torch.sparse.DoubleTensor()\n>>> a\ntorch.sparse.DoubleTensor of size (0,) with indices:\ntensor([], size=(1, 0), dtype=torch.int64)\nand values:\ntensor([], dtype=torch.float64)\n\n# empty sparse tensor to be a 1-dimensional tensor of size [0], \n# with sparseDims == 1 and denseDims == 0\n\n# invariants:\n#   _sparseDims + _denseDims = len(shape)\n#   _indices.dim = 2, shape = (_sparseDims, nnz)\n#   _values.dim = 1 + _denseDims, shape = (nnz, shape[_sparseDims:])\n\nThis fixes:\n\nAn empty sparse tensor has indices of dim = 1, which means we have to check nnz != 0 everywhere in using a TensorAccessor of indices.\n\nAutograd support\n>>> a = torch.sparse_coo_tensor(indices, values, sizes, requires_grad=True)\n>>> b = a * 2\n>>> b.backward(torch.sparse_coo_tensor(indices, values, sizes))\n>>> print(a)\n\ntorch.sparse.FloatTensor of size (2,2) with indices:\ntensor([[0, 0, 1],\n        [0, 1, 1]])\nand values:\ntensor([4., 6., 8.])\n\nA lot of operators on sparse tensors have densified gradients. e.g., log1p would make all 0 inputs have a gradient of 1, and it densifies the sparse tensor gradients. Currently we have to raise errors in the backward of these operators. Some potential ways to fix:\n\n\nDefine special sparse operations so that they operate only on the nnz. This works well for functions that take a single input tensor. For example, we can define sparse log1p such that implicit 0s do not participate, and it would allow us to have a sparse gradient tensor. We can call this operator s_log1p or nnz_log1p (#1369 has similar discussions). However, we are not sure if they are really what users want, because these operators have different behaviors to their dense counterpart.\n\n\nReturn a dense gradient. We can have backward functions able to handle both of dense and sparse gradients. No special treatment needed during autograd, just more functions to be written.\n\n\nReturn the gradient as a sparse tensor. Even though we know a tensor might be completely dense, we can still choose to return its sparse form. This is awful for performance.\n\n\nNo backward for densified gradients of sparse operator. Users need to call to_dense and apply dense operators instead. This will not work without backward for to_dense, which itself will have a densified gradients, and it brings us back to the 2nd proposal.\n\n\nFunctions\nPointwise one tensor math\n\n\n\nfunctions\ndense grad\n\n\n\n\npow\nN\n\n\nlog1p\nY\n\n\ndiv_ / div(Sparse, Scalar)\nY\n\n\nmul_ /\u00a0mul(Sparse, Scalar)\nY\n\n\n\nAll pointwise one tensor calls dense couterpart ops on _values, so maybe a macro can be written to cover them all.\nPointwise two tensor math\n\n\n\nfunctions\nformula\ndense grad\n\n\n\n\nadd_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse\nadd(T, S, alpha) = T + alpha * S\nY\n\n\nadd_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense\nadd(T, S, alpha) = T + alpha * S\nY\n\n\nsub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse\nsub(T, S, alpha) = T - alpha * S\nY\n\n\nmul_ / mul(Sparse, Sparse) \u2192 Sparse\nmul(T, S) = T * S\nY\n\n\n\nAll pointwise two tensor functions have properly optimized CUDA kernel except for mul_ / mul:\n\nadd_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse returns cat(Sparse, Scalar * Sparse)\nadd_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense parallelizes over nnz\nsub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse calls add\n\nmul_ / mul(Sparse, Sparse) \u2192 Sparse needs parallelized CUDA kernels, possible directions:\n\nwrite customized kernel to parallelized over nnz of 1st sparse tensor\nuse cuSPARSE?\n\nBLAS\n\n\n\nfunctions\nformula\ndense grad\n\n\n\n\naddmm(Dense, Sparse, Dense, Scalar, Scalar) \u2192 Dense\naddmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)\nY\n\n\nsspaddmm(Sparse, Sparse, Dense, Scalar, Scalar) \u2192 Sparse\nsspaddmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)\nY\n\n\nmm(Sparse, Dense) \u2192 Dense\nmm(S, D) = mm(S, D)\nY\n\n\nsmm(Sparse, Dense) \u2192 Sparse\nsmm(S, D) = mm(S, D)\nY\n\n\nhspmm(Sparse, Dense) \u2192 HybridSparse\nhspmm(S, D) = mm(S, D)\nY\n\n\nspmm(Sparse, Dense) \u2192 Dense\nspmm(S, D) = mm(S, D)\nY\n\n\n\nFunctions with CUDA kernel optimized are mm, addmm and hspmm. addmm and hspmm use cuSPARSE (cusparseScsrmm2 and cusparseDcsrmm2) in CUDA kernel, and mm calls addmm. However, smm and sspaddmm don't have CUDA support (gets removed?).\nOthers\n\n\n\nfunctions\ndense grad\n\n\n\n\nclone\nNA\n\n\nnorm\nN\n\n\nzero_\nN\n\n\nt_ / t\nN\n\n\n\nOptimizers\n\noptim.SGD (CUDA and CPU)\noptim.SparseAdam (CUDA and CPU) - lazy version of Adam algorithm\noptim.Adagrad (CPU)\n\nFuture work\nTODO functions\n\n\n\nFunctions\ndense grad\n\n\n\n\nnonzero\nN\n\n\nsum\nY\n\n\ncopy_\nN\n\n\nnarrow\nN\n\n\nselect_index\nN\n\n\nmul_ / mul(S, D)\nY\n\n\ncuda\nNA\n\n\nF.linear\nY\n\n\nsoftmax\nN\n\n\ncat\nN\n\n\nmax\nN\n\n\nbmm(S, D)\nY\n\n\n\n\nThere is a list of pointwise functions for sparse can be implemented by calling dense ops on their _values, some helpers or macros can be written to make all of these ops available for sparse.\n\nabs, acos, asin, atan, ceil, cos, cosh, erf, exp, expm1, floor, \nlog, log10, log2, round, sin, sinh, sqrt, rsqrt, tan, trunc\n\nThis note was summarized by @li-roy and me. All suggestions/comments are more than welcomed!\ncc @soumith @ezyang @colesbury @gchanan @SsnL @zou3519 @yf225", "body": "This note tries to summarize the current state of sparse tensor in pytorch. It describes important invariance and properties of sparse tensor, and various things need to be fixed (e.g. empty sparse tensor). It also shows some details of sparse operators.\r\n\r\n\r\n## Semantics\r\n\r\n### Construct a sparse tensor\r\n```\r\n# create a float sparse tensor in CPU\r\n>>> indices = torch.LongTensor([[0, 0, 1], [0, 1, 1]])\r\n>>> values = torch.FloatTensor([2, 3, 4])\r\n>>> sizes = [2, 2]\r\n>>> torch.sparse_coo_tensor(indices, values, sizes)\r\ntorch.sparse.FloatTensor of size (2,2) with indices:\r\ntensor([[0, 0, 1],\r\n        [0, 1, 1]])\r\nand values:\r\ntensor([2., 3., 4.])\r\n\r\n# to_dense\r\n>>> torch.sparse_coo_tensor(indices, values, sizes).to_dense()\r\ntensor([[2., 3.],\r\n        [0., 4.]])\r\n\r\n# in CUDA\r\n>>> torch.sparse_coo_tensor(indices, values, sizes, device=torch.device('cuda'))\r\ntorch.cuda.sparse.FloatTensor of size (2,2) with indices:\r\ntensor([[0, 0, 1],\r\n        [0, 1, 1]], device='cuda:0')\r\nand values:\r\ntensor([2., 3., 4.], device='cuda:0')\r\n```\r\n\r\n### More approaches in creating a sparse tensor\r\n```\r\ntorch.sparse.FloatTensor()\r\ntorch.sparse.DoubleTensor()\r\ntorch.zeros(..., layout=torch.sparse_coo, ...)\r\n```\r\nShould we unify/reduce different approaches?\r\n\r\n\r\n## Sparse representation\r\n\r\nCurrently, our sparse tensors are hybrid tensors, with a mix of sparse dims and dense dims. We keep track of `nnz`, `sparseDims`, `denseDims`, a `indices tensor of size = (sparseDims, nnz)`, and a `values tensor of size (nnz, size[sparseDims:])`. Additionally, we have a flag to note if the tensor is `coalesced`.\r\n\r\n### Should we keep this representation?\r\n\r\n- Our currently hybrid representation has some issues. It's difficult to support operators on hybrid tensors, *especially because only embedding uses hybrid*. Furthermore, some functions have ambiguous outputs on hybrid tensors (e.g. transposing a dense dim and a sparse dim is ambiguous). Because of this, it makes sense to have embedding has a special case, and only support \u201ctrue\u201d sparse tensors with denseDims = 0.\r\n\r\n- Many sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?\r\n\r\n- Caffe2 uses per-row counts to represent sparse tensors, and they have some level of sparse support.\r\n\r\n### A couple caveats with our current system\r\n\r\n- Things we should always keep in mind\r\n```\r\nIdeal INVARIANTS:\r\n  _sparseDims: range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\r\n  _denseDims : range [0, len(shape)]; _sparseDims + _denseDims = len(shape)\r\n  _indices.shape: dimensionality: 2,  shape: (_sparseDims, nnz)\r\n  _values.shape:  dimensionality: 1 + _denseDims.  shape: (nnz, shape[_sparseDims:])\r\n\r\nActual INVARIANT differences:\r\n  1) _sparseDims: range [1, len(shape)] (i.e. we don't allow 0 sparse dimensions)\r\n  2) when nnz = 0, there is strange behavior because we lack 0-dimensional sparse tensors.  Namely:\r\n     dimensionality == 0, _sparseDims == 0, _denseDims == 0, _indices.shape == {0}, _values.shape == {0}\r\n  3) For both _indices.shape and _values.shape, the nnz dimension may be larger than nnz\r\n  4) For _values.shape, the non-nnz dimensions may be smaller than the corresponding dimension size, e.g.\r\n     a shape (2,3) sparse tensor with _sparseDims == 1, may have _values.shape: (nnz, <=2, <=3).\r\n```\r\n\r\n- We're keeping track of nnz, sparseDims, denseDims and coalesced independently of the indices and values tensors. For instance, we may need to write the following code to maintain the invariance:\r\n```\r\n_get_sparse_impl(r)->set_indices_and_values(r_indices, r_values);\r\n_get_sparse_impl(r)->set_nnz(t._nnz());\r\n_get_sparse_impl(r)->set_coalesced(t.is_coalesced());\r\n```\r\n\r\n- Without support for 0-dim tensors, we cannot have proper support for scalar sparse tensors. This makes it unclear how to implement ops like reduction ops, which is currently represented as a dense scalar. Maybe there is nothing wrong with the current representation, we just need to be minded that sparse ops can return a scalar. \r\n\r\n- The nnz and the nnz dimension in two indices and value tensors may not be the same, some cuda kernels rely on this.\r\n\r\n- In values, the non-nnz dimensions might not actually match the dimensions of the sparse tensor\r\n\r\n- We have dim == sparseDims + denseDims, but sparseDims cannot be 0. On one hand, this makes sense because a sparse tensor should have at least one sparse dim, but at the same time, it's in conflict with the idea of a scalar sparse tensor.\r\n\r\n- An empty sparse tensor has indices of dim = 1, which means we have to check `nnz != 0` everywhere in using a TensorAccessor of indices.\r\n\r\n### Some of these issues are fixed by @yf225  PR https://github.com/pytorch/pytorch/pull/9279\r\n\r\nCurrent behavoir of an empty sparse tensor:\r\n```\r\n>>> a = torch.sparse_coo_tensor([], [], [2, 3])\r\n>>> i = a._indices()\r\n>>> v = a._values()\r\n\r\n>>> print(a)\r\ntorch.sparse.FloatTensor of size (2,3) with indices:\r\ntensor([], dtype=torch.int64)\r\nand values:\r\ntensor([])\r\n\r\n>>> print('i = %s' % i)\r\ni = tensor([], dtype=torch.int64)\r\n\r\n>>> print('v = %s' % v)\r\nv = tensor([])\r\n\r\n>>> print('a.dim = %d, i.dim = %d, v.dim = %d' % (a.dim(), i.dim(), v.dim()))\r\na.dim = 2, i.dim = 1, v.dim = 1\r\n\r\n>>> print('a._dimI = %d, a._sparseDims = %d, a._dimV = %d, a._denseDims = %d, a._nnz = %d' % \r\n          (a._dimI(), a._sparseDims(), a._dimV(), a._denseDims(), a._nnz()))\r\na._dimI = 0, a._sparseDims = 2, a._dimV = 0, a._denseDims = 0, a._nnz = 0\r\n```\r\n\r\nWhen properly supported:\r\n```\r\n>>> import torch\r\n>>> a=torch.sparse.DoubleTensor()\r\n>>> a\r\ntorch.sparse.DoubleTensor of size (0,) with indices:\r\ntensor([], size=(1, 0), dtype=torch.int64)\r\nand values:\r\ntensor([], dtype=torch.float64)\r\n\r\n# empty sparse tensor to be a 1-dimensional tensor of size [0], \r\n# with sparseDims == 1 and denseDims == 0\r\n\r\n# invariants:\r\n#   _sparseDims + _denseDims = len(shape)\r\n#   _indices.dim = 2, shape = (_sparseDims, nnz)\r\n#   _values.dim = 1 + _denseDims, shape = (nnz, shape[_sparseDims:])\r\n```\r\n\r\nThis fixes:\r\n\r\n- An empty sparse tensor has indices of dim = 1, which means we have to check `nnz != 0` everywhere in using a TensorAccessor of indices.\r\n\r\n\r\n### Autograd support\r\n```\r\n>>> a = torch.sparse_coo_tensor(indices, values, sizes, requires_grad=True)\r\n>>> b = a * 2\r\n>>> b.backward(torch.sparse_coo_tensor(indices, values, sizes))\r\n>>> print(a)\r\n\r\ntorch.sparse.FloatTensor of size (2,2) with indices:\r\ntensor([[0, 0, 1],\r\n        [0, 1, 1]])\r\nand values:\r\ntensor([4., 6., 8.])\r\n```\r\n\r\nA lot of operators on sparse tensors have densified gradients. e.g., `log1p` would make all 0 inputs have a gradient of 1, and it densifies the sparse tensor gradients. Currently we have to raise errors in the backward of these operators. Some potential ways to fix:\r\n\r\n- Define special sparse operations so that they operate only on the nnz. This works well for functions that take a single input tensor. For example, we can define sparse log1p such that implicit 0s do not participate, and it would allow us to have a sparse gradient tensor. We can call this operator `s_log1p` or `nnz_log1p` (https://github.com/pytorch/pytorch/issues/1369 has similar discussions). However, we are not sure if they are really what users want, because these operators have different behaviors to their dense counterpart.\r\n\r\n- Return a dense gradient. We can have backward functions able to handle both of dense and sparse gradients. No special treatment needed during autograd, just more functions to be written.\r\n\r\n- Return the gradient as a sparse tensor. Even though we know a tensor might be completely dense, we can still choose to return its sparse form. This is awful for performance.\r\n\r\n- No backward for densified gradients of sparse operator. Users need to call `to_dense` and apply dense operators instead. This will not work without backward for `to_dense`, which itself will have a densified gradients, and it brings us back to the 2nd proposal.\r\n\r\n\r\n## Functions\r\n\r\n### Pointwise one tensor math\r\n\r\n|functions|dense grad|\r\n|---|:---:|\r\n|pow|N|\r\n|log1p|Y|\r\n|div_ / div(Sparse, Scalar)|Y|\r\n|mul_ /\u00a0mul(Sparse, Scalar)|Y|\r\n\r\nAll pointwise one tensor calls dense couterpart ops on `_values`, so maybe a macro can be written to cover them all.\r\n\r\n\r\n### Pointwise two tensor math\r\n\r\n|functions|formula|dense grad|\r\n|---|---|:---:|\r\n|add_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse|add(T, S, alpha) = T + alpha * S|Y|\r\n|add_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense|add(T, S, alpha) = T + alpha * S|Y|\r\n|sub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse|sub(T, S, alpha) = T - alpha * S|Y|\r\n|mul_ / mul(Sparse, Sparse) \u2192 Sparse|mul(T, S) = T * S|Y|\r\n\r\nAll pointwise two tensor functions have properly optimized CUDA kernel except for `mul_ / mul`:\r\n- `add_ / add(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse` returns cat(Sparse, Scalar * Sparse)\r\n- `add_ / add(Dense, Sparse, Scalar)\u00a0\u2192 Dense` parallelizes over nnz\r\n- `sub_ / sub(Sparse, Sparse, Scalar)\u00a0\u2192 Sparse` calls `add`\r\n\r\n`mul_ / mul(Sparse, Sparse) \u2192 Sparse` needs parallelized CUDA kernels, possible directions:\r\n1. write customized kernel to parallelized over nnz of 1st sparse tensor\r\n2. use cuSPARSE?\r\n\r\n### BLAS\r\n\r\n|functions|formula|dense grad|\r\n|---|---|:---:|\r\n|addmm(Dense, Sparse, Dense, Scalar, Scalar) \u2192 Dense|addmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)|Y|\r\n|sspaddmm(Sparse, Sparse, Dense, Scalar, Scalar) \u2192 Sparse|sspaddmm(T, S, D, beta, alpha) = beta * T + alpha * mm(S, D)|Y|\r\n|mm(Sparse, Dense) \u2192 Dense|mm(S, D) = mm(S, D)|Y|\r\n|smm(Sparse, Dense) \u2192 Sparse|smm(S, D) = mm(S, D)|Y|\r\n|hspmm(Sparse, Dense) \u2192 HybridSparse|hspmm(S, D) = mm(S, D)|Y|\r\n|spmm(Sparse, Dense) \u2192 Dense|spmm(S, D) = mm(S, D)|Y|\r\n\r\nFunctions with CUDA kernel optimized are `mm`, `addmm` and `hspmm`. `addmm` and `hspmm` use cuSPARSE (cusparseScsrmm2 and cusparseDcsrmm2) in CUDA kernel, and `mm` calls `addmm`. However, `smm` and `sspaddmm` don't have CUDA support (gets removed?).\r\n\r\n\r\n### Others\r\n\r\n|functions|dense grad|\r\n|---|:---:|\r\n|clone|NA|\r\n|norm|N|\r\n|zero_|N|\r\n|t_ / t|N|\r\n\r\n\r\n## Optimizers\r\n\r\n- optim.SGD (CUDA and CPU)\r\n- optim.SparseAdam (CUDA and CPU) - lazy version of Adam algorithm\r\n- optim.Adagrad (CPU)\r\n\r\n\r\n## Future work\r\n\r\n### TODO functions\r\n\r\n|Functions|dense grad|\r\n|---|:---:|\r\n|nonzero|           N|\r\n|sum|               Y|\r\n|copy_|             N|\r\n|narrow|            N|\r\n|select_index|      N|\r\n|mul_ / mul(S, D)|  Y|\r\n|cuda|              NA|\r\n|F.linear|          Y|\r\n|softmax|           N|\r\n|cat|               N|\r\n|max|               N|\r\n|bmm(S, D)|         Y|\r\n\r\n- There is a list of pointwise functions for sparse can be implemented by calling dense ops on their `_values`, some helpers or macros can be written to make all of these ops available for sparse.\r\n```\r\nabs, acos, asin, atan, ceil, cos, cosh, erf, exp, expm1, floor, \r\nlog, log10, log2, round, sin, sinh, sqrt, rsqrt, tan, trunc\r\n```\r\n\r\n\r\nThis note was summarized by @li-roy and me. All suggestions/comments are more than welcomed!\r\n\r\ncc @soumith @ezyang @colesbury @gchanan @SsnL @zou3519 @yf225 "}