{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/409028303", "html_url": "https://github.com/pytorch/pytorch/issues/9674#issuecomment-409028303", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9674", "id": 409028303, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTAyODMwMw==", "user": {"login": "jspark1105", "id": 5545022, "node_id": "MDQ6VXNlcjU1NDUwMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5545022?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jspark1105", "html_url": "https://github.com/jspark1105", "followers_url": "https://api.github.com/users/jspark1105/followers", "following_url": "https://api.github.com/users/jspark1105/following{/other_user}", "gists_url": "https://api.github.com/users/jspark1105/gists{/gist_id}", "starred_url": "https://api.github.com/users/jspark1105/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jspark1105/subscriptions", "organizations_url": "https://api.github.com/users/jspark1105/orgs", "repos_url": "https://api.github.com/users/jspark1105/repos", "events_url": "https://api.github.com/users/jspark1105/events{/privacy}", "received_events_url": "https://api.github.com/users/jspark1105/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-30T22:09:29Z", "updated_at": "2018-07-30T22:09:29Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>Many sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?</p>\n</blockquote>\n<p>There's a generalization of CSR to tensors called compressed sparse fiber (<a href=\"http://glaros.dtc.umn.edu/gkhome/fetch/papers/2015-Smith-CSF.pdf\" rel=\"nofollow\">http://glaros.dtc.umn.edu/gkhome/fetch/papers/2015-Smith-CSF.pdf</a>) . I'm not saying we should implement this because this is still complex and with little library support yet.</p>\n<p>I want to learn more about \"coalesced hybrid COO tensor\". Any pointers to it?</p>", "body_text": "Many sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?\n\nThere's a generalization of CSR to tensors called compressed sparse fiber (http://glaros.dtc.umn.edu/gkhome/fetch/papers/2015-Smith-CSF.pdf) . I'm not saying we should implement this because this is still complex and with little library support yet.\nI want to learn more about \"coalesced hybrid COO tensor\". Any pointers to it?", "body": "> Many sparse libraries use CSR because it's really efficient for ops such as mm. Ideally, we'd like to make use of these libraries, but it's difficult: CSR can't represent more than 2D, but COO requires a lot of conversions. Potential solution: caching CSR representations?\r\n\r\nThere's a generalization of CSR to tensors called compressed sparse fiber (http://glaros.dtc.umn.edu/gkhome/fetch/papers/2015-Smith-CSF.pdf) . I'm not saying we should implement this because this is still complex and with little library support yet.\r\n\r\nI want to learn more about \"coalesced hybrid COO tensor\". Any pointers to it?"}