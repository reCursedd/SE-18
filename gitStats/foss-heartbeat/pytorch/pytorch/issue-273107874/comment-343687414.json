{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/343687414", "html_url": "https://github.com/pytorch/pytorch/issues/3636#issuecomment-343687414", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3636", "id": 343687414, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MzY4NzQxNA==", "user": {"login": "w4nderlust", "id": 349256, "node_id": "MDQ6VXNlcjM0OTI1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/349256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/w4nderlust", "html_url": "https://github.com/w4nderlust", "followers_url": "https://api.github.com/users/w4nderlust/followers", "following_url": "https://api.github.com/users/w4nderlust/following{/other_user}", "gists_url": "https://api.github.com/users/w4nderlust/gists{/gist_id}", "starred_url": "https://api.github.com/users/w4nderlust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/w4nderlust/subscriptions", "organizations_url": "https://api.github.com/users/w4nderlust/orgs", "repos_url": "https://api.github.com/users/w4nderlust/repos", "events_url": "https://api.github.com/users/w4nderlust/events{/privacy}", "received_events_url": "https://api.github.com/users/w4nderlust/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-11T19:13:37Z", "updated_at": "2017-11-11T19:13:37Z", "author_association": "NONE", "body_html": "<p>Got it so <code>IndexError</code> or <code>StopIteration</code> are catched and they stop the iteration.<br>\nMy case was actually different from that code I posted, it would return <code>ValueError: result of slicing is an empty tensor</code>.</p>\n<p>This is a more faithful code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> math\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> Dataset\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">PatchDataLoader</span>(<span class=\"pl-e\">Dataset</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">image_dataset</span>, <span class=\"pl-smi\">patch_shape</span>, <span class=\"pl-smi\">strides</span>, <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n        <span class=\"pl-c1\">self</span>.image_dataset <span class=\"pl-k\">=</span> image_dataset\n        <span class=\"pl-c1\">self</span>.patch_shape <span class=\"pl-k\">=</span> patch_shape\n        <span class=\"pl-c1\">self</span>.strides <span class=\"pl-k\">=</span> strides\n        <span class=\"pl-c1\">self</span>.batch_size <span class=\"pl-k\">=</span> batch_size\n        <span class=\"pl-c1\">self</span>.num_images <span class=\"pl-k\">=</span> image_dataset.size()[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-c1\">self</span>.num_patches_x <span class=\"pl-k\">=</span> math.ceil((image_dataset.size()[<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">-</span> patch_shape[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">/</span> strides[<span class=\"pl-c1\">0</span>])\n        <span class=\"pl-c1\">self</span>.num_patches_y <span class=\"pl-k\">=</span> math.ceil((image_dataset.size()[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">-</span> patch_shape[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">/</span> strides[<span class=\"pl-c1\">1</span>])\n        <span class=\"pl-c1\">self</span>.num_patches <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.num_images <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.num_patches_x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.num_patches_y\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__len__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.num_patches_x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.num_patches_y <span class=\"pl-k\">*</span> math.ceil(<span class=\"pl-c1\">self</span>.num_images <span class=\"pl-k\">/</span> <span class=\"pl-c1\">self</span>.batch_size)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> convert index -&gt; i,j,k</span>\n        i, j, k <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.map_index(index)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> return some patch from the image dataset</span>\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.image_dataset[k <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.batch_size:(k<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.batch_size, i:i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.patch_shape[<span class=\"pl-c1\">1</span>], j:j <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.patch_shape[<span class=\"pl-c1\">0</span>]]\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">map_index</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        k <span class=\"pl-k\">=</span> index <span class=\"pl-k\">//</span> (<span class=\"pl-c1\">self</span>.num_patches_x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.num_patches_y)\n        k_mod <span class=\"pl-k\">=</span> index <span class=\"pl-k\">%</span> (<span class=\"pl-c1\">self</span>.num_patches_x <span class=\"pl-k\">*</span> <span class=\"pl-c1\">self</span>.num_patches_y)\n        i <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.strides[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> (k_mod <span class=\"pl-k\">//</span> <span class=\"pl-c1\">self</span>.num_patches_x)\n        j <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.strides[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> (k_mod <span class=\"pl-k\">%</span> <span class=\"pl-c1\">self</span>.num_patches_x)\n        <span class=\"pl-k\">return</span> i, j, k\n\n\nimages <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>)\n\npdl1 <span class=\"pl-k\">=</span> PatchDataLoader(images, [<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>], [<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>])\np1 <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(pdl1)):\n    p1.append(pdl1[i])\npatches1 <span class=\"pl-k\">=</span> torch.cat(p1)\n\npdl2 <span class=\"pl-k\">=</span> PatchDataLoader(images, [<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>], [<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>])\np2 <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> pdl2:\n    p2.append(i)\npatches2 <span class=\"pl-k\">=</span> torch.cat(p2)</pre></div>\n<p>I guess I can put the slicing operation inside a <code>try</code> and <code>except ValueError</code> and raise a <code>StopIteration</code> inside the except clause to solve my problem.<br>\nBut maybe pytorch could raise a <code>IndexError</code> when the result of slicing is an empty tensor instead of a <code>ValueError</code>? Ultimately the problem is with the indexing of the tensor rather than it's values, like trying to access an index that is not there.</p>", "body_text": "Got it so IndexError or StopIteration are catched and they stop the iteration.\nMy case was actually different from that code I posted, it would return ValueError: result of slicing is an empty tensor.\nThis is a more faithful code:\nimport math\nimport torch\nfrom torch.utils.data import Dataset\n\n\nclass PatchDataLoader(Dataset):\n    def __init__(self, image_dataset, patch_shape, strides, batch_size=1):\n        self.image_dataset = image_dataset\n        self.patch_shape = patch_shape\n        self.strides = strides\n        self.batch_size = batch_size\n        self.num_images = image_dataset.size()[0]\n        self.num_patches_x = math.ceil((image_dataset.size()[2] - patch_shape[0] + 1) / strides[0])\n        self.num_patches_y = math.ceil((image_dataset.size()[1] - patch_shape[1] + 1) / strides[1])\n        self.num_patches = self.num_images * self.num_patches_x * self.num_patches_y\n\n    def __len__(self):\n        return self.num_patches_x * self.num_patches_y * math.ceil(self.num_images / self.batch_size)\n\n    def __getitem__(self, index):\n        # convert index -> i,j,k\n        i, j, k = self.map_index(index)\n\n        # return some patch from the image dataset\n        return self.image_dataset[k * self.batch_size:(k+1) * self.batch_size, i:i + self.patch_shape[1], j:j + self.patch_shape[0]]\n\n    def map_index(self, index):\n        k = index // (self.num_patches_x * self.num_patches_y)\n        k_mod = index % (self.num_patches_x * self.num_patches_y)\n        i = self.strides[1] * (k_mod // self.num_patches_x)\n        j = self.strides[0] * (k_mod % self.num_patches_x)\n        return i, j, k\n\n\nimages = torch.randn(2, 4, 4)\n\npdl1 = PatchDataLoader(images, [2,2], [2,2])\np1 = []\nfor i in range(len(pdl1)):\n    p1.append(pdl1[i])\npatches1 = torch.cat(p1)\n\npdl2 = PatchDataLoader(images, [2,2], [2,2])\np2 = []\nfor i in pdl2:\n    p2.append(i)\npatches2 = torch.cat(p2)\nI guess I can put the slicing operation inside a try and except ValueError and raise a StopIteration inside the except clause to solve my problem.\nBut maybe pytorch could raise a IndexError when the result of slicing is an empty tensor instead of a ValueError? Ultimately the problem is with the indexing of the tensor rather than it's values, like trying to access an index that is not there.", "body": "Got it so `IndexError` or `StopIteration` are catched and they stop the iteration.\r\nMy case was actually different from that code I posted, it would return `ValueError: result of slicing is an empty tensor`.\r\n\r\nThis is a more faithful code:\r\n\r\n```python\r\nimport math\r\nimport torch\r\nfrom torch.utils.data import Dataset\r\n\r\n\r\nclass PatchDataLoader(Dataset):\r\n    def __init__(self, image_dataset, patch_shape, strides, batch_size=1):\r\n        self.image_dataset = image_dataset\r\n        self.patch_shape = patch_shape\r\n        self.strides = strides\r\n        self.batch_size = batch_size\r\n        self.num_images = image_dataset.size()[0]\r\n        self.num_patches_x = math.ceil((image_dataset.size()[2] - patch_shape[0] + 1) / strides[0])\r\n        self.num_patches_y = math.ceil((image_dataset.size()[1] - patch_shape[1] + 1) / strides[1])\r\n        self.num_patches = self.num_images * self.num_patches_x * self.num_patches_y\r\n\r\n    def __len__(self):\r\n        return self.num_patches_x * self.num_patches_y * math.ceil(self.num_images / self.batch_size)\r\n\r\n    def __getitem__(self, index):\r\n        # convert index -> i,j,k\r\n        i, j, k = self.map_index(index)\r\n\r\n        # return some patch from the image dataset\r\n        return self.image_dataset[k * self.batch_size:(k+1) * self.batch_size, i:i + self.patch_shape[1], j:j + self.patch_shape[0]]\r\n\r\n    def map_index(self, index):\r\n        k = index // (self.num_patches_x * self.num_patches_y)\r\n        k_mod = index % (self.num_patches_x * self.num_patches_y)\r\n        i = self.strides[1] * (k_mod // self.num_patches_x)\r\n        j = self.strides[0] * (k_mod % self.num_patches_x)\r\n        return i, j, k\r\n\r\n\r\nimages = torch.randn(2, 4, 4)\r\n\r\npdl1 = PatchDataLoader(images, [2,2], [2,2])\r\np1 = []\r\nfor i in range(len(pdl1)):\r\n    p1.append(pdl1[i])\r\npatches1 = torch.cat(p1)\r\n\r\npdl2 = PatchDataLoader(images, [2,2], [2,2])\r\np2 = []\r\nfor i in pdl2:\r\n    p2.append(i)\r\npatches2 = torch.cat(p2)\r\n```\r\n\r\nI guess I can put the slicing operation inside a `try` and `except ValueError` and raise a `StopIteration` inside the except clause to solve my problem.\r\nBut maybe pytorch could raise a `IndexError` when the result of slicing is an empty tensor instead of a `ValueError`? Ultimately the problem is with the indexing of the tensor rather than it's values, like trying to access an index that is not there."}