{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/343693231", "html_url": "https://github.com/pytorch/pytorch/issues/3636#issuecomment-343693231", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3636", "id": 343693231, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MzY5MzIzMQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-11T20:49:44Z", "updated_at": "2017-11-11T20:49:44Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=349256\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/w4nderlust\">@w4nderlust</a> I think that the semantics of indexing will change in this case once zero-dimensional tensors are exposed to pytorch, making it more consistent. I think in this particular case <code>ValueError</code> is justified, because there is no out-of-range scenario (just that PyTorch doesn't support zero-dim tensors yet).<br>\nFor example</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">3</span>)\nb <span class=\"pl-k\">=</span> a.numpy()\n<span class=\"pl-c1\">print</span>(a[:<span class=\"pl-c1\">0</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ValueError</span>\n<span class=\"pl-c1\">print</span>(b[:<span class=\"pl-c1\">0</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> works fine</span></pre></div>\n<p>Also, small tip for your use-case: you can use two dalaloaders, one for loading the images, and the other one for loading the patches in each image. This way you can still have multithreaded image loading, and single-threaded patch extraction.</p>", "body_text": "@w4nderlust I think that the semantics of indexing will change in this case once zero-dimensional tensors are exposed to pytorch, making it more consistent. I think in this particular case ValueError is justified, because there is no out-of-range scenario (just that PyTorch doesn't support zero-dim tensors yet).\nFor example\na = torch.rand(3)\nb = a.numpy()\nprint(a[:0])  # ValueError\nprint(b[:0])  # works fine\nAlso, small tip for your use-case: you can use two dalaloaders, one for loading the images, and the other one for loading the patches in each image. This way you can still have multithreaded image loading, and single-threaded patch extraction.", "body": "@w4nderlust I think that the semantics of indexing will change in this case once zero-dimensional tensors are exposed to pytorch, making it more consistent. I think in this particular case `ValueError` is justified, because there is no out-of-range scenario (just that PyTorch doesn't support zero-dim tensors yet).\r\nFor example\r\n```python\r\na = torch.rand(3)\r\nb = a.numpy()\r\nprint(a[:0])  # ValueError\r\nprint(b[:0])  # works fine\r\n```\r\n\r\nAlso, small tip for your use-case: you can use two dalaloaders, one for loading the images, and the other one for loading the patches in each image. This way you can still have multithreaded image loading, and single-threaded patch extraction."}