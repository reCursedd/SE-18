{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12299", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12299/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12299/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12299/events", "html_url": "https://github.com/pytorch/pytorch/issues/12299", "id": 366545007, "node_id": "MDU6SXNzdWUzNjY1NDUwMDc=", "number": 12299, "title": "CrossEntropyLoss", "user": {"login": "jy1993", "id": 18455572, "node_id": "MDQ6VXNlcjE4NDU1NTcy", "avatar_url": "https://avatars0.githubusercontent.com/u/18455572?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jy1993", "html_url": "https://github.com/jy1993", "followers_url": "https://api.github.com/users/jy1993/followers", "following_url": "https://api.github.com/users/jy1993/following{/other_user}", "gists_url": "https://api.github.com/users/jy1993/gists{/gist_id}", "starred_url": "https://api.github.com/users/jy1993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jy1993/subscriptions", "organizations_url": "https://api.github.com/users/jy1993/orgs", "repos_url": "https://api.github.com/users/jy1993/repos", "events_url": "https://api.github.com/users/jy1993/events{/privacy}", "received_events_url": "https://api.github.com/users/jy1993/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1076923012, "node_id": "MDU6TGFiZWwxMDc2OTIzMDEy", "url": "https://api.github.com/repos/pytorch/pytorch/labels/loss", "name": "loss", "color": "56ce06", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-03T21:54:18Z", "updated_at": "2018-10-04T01:52:26Z", "closed_at": "2018-10-04T01:52:26Z", "author_association": "NONE", "body_html": "<p>Code:<br>\nimport numpy as np<br>\nimport torch<br>\nfrom sklearn.metrics import log_loss<br>\nfrom torch import nn</p>\n<p>y_pred = np.array([[0.2, 0.3, 0.5], [0.2, 0.3, 0.5], [0.2, 0.3, 0.5]])<br>\ny_true = [0, 1, 2]<br>\nsklearn_loss = log_loss(y_true, y_pred)<br>\nloss_fun = nn.CrossEntropyLoss()<br>\npytorch_loss = loss_fun(torch.Tensor(y_pred), torch.Tensor(y_true).long())<br>\nloss = -(np.log(0.2) + np.log(0.3) + np.log(0.5))/3<br>\nprint(f'sklearn log loss : {sklearn_loss}, pytorch loss: {pytorch_loss}, loss: {loss}')</p>\n<p>Result:<br>\nsklearn log loss : 1.168852632439994, pytorch loss: 1.1064976453781128, loss: 1.168852632439994</p>\n<p>The CrossEntropyLoss gives a log_loss differs from the one calculated by sklearn. Is there something wrong?</p>\n<p>Pytorch Version: 0.4.1<br>\nWindows 10</p>", "body_text": "Code:\nimport numpy as np\nimport torch\nfrom sklearn.metrics import log_loss\nfrom torch import nn\ny_pred = np.array([[0.2, 0.3, 0.5], [0.2, 0.3, 0.5], [0.2, 0.3, 0.5]])\ny_true = [0, 1, 2]\nsklearn_loss = log_loss(y_true, y_pred)\nloss_fun = nn.CrossEntropyLoss()\npytorch_loss = loss_fun(torch.Tensor(y_pred), torch.Tensor(y_true).long())\nloss = -(np.log(0.2) + np.log(0.3) + np.log(0.5))/3\nprint(f'sklearn log loss : {sklearn_loss}, pytorch loss: {pytorch_loss}, loss: {loss}')\nResult:\nsklearn log loss : 1.168852632439994, pytorch loss: 1.1064976453781128, loss: 1.168852632439994\nThe CrossEntropyLoss gives a log_loss differs from the one calculated by sklearn. Is there something wrong?\nPytorch Version: 0.4.1\nWindows 10", "body": "Code:\r\nimport numpy as np\r\nimport torch\r\nfrom sklearn.metrics import log_loss\r\nfrom torch import nn\r\n\r\ny_pred = np.array([[0.2, 0.3, 0.5], [0.2, 0.3, 0.5], [0.2, 0.3, 0.5]])\r\ny_true = [0, 1, 2]\r\nsklearn_loss = log_loss(y_true, y_pred)\r\nloss_fun = nn.CrossEntropyLoss()\r\npytorch_loss = loss_fun(torch.Tensor(y_pred), torch.Tensor(y_true).long())\r\nloss = -(np.log(0.2) + np.log(0.3) + np.log(0.5))/3\r\nprint(f'sklearn log loss : {sklearn_loss}, pytorch loss: {pytorch_loss}, loss: {loss}')\r\n\r\nResult:\r\nsklearn log loss : 1.168852632439994, pytorch loss: 1.1064976453781128, loss: 1.168852632439994\r\n\r\nThe CrossEntropyLoss gives a log_loss differs from the one calculated by sklearn. Is there something wrong?\r\n\r\nPytorch Version: 0.4.1\r\nWindows 10\r\n\r\n"}