{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187363799", "pull_request_review_id": 119129407, "id": 187363799, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NzM2Mzc5OQ==", "diff_hunk": "@@ -6261,18 +6261,31 @@ def map_location(storage, loc):\n \n         def load_bytes():\n             with open(test_file_path, 'rb') as f:\n-                data = io.BytesIO(f.read())\n-            return data\n+                return io.BytesIO(f.read())\n \n         fileobject_lambdas = [lambda: test_file_path, load_bytes]\n-        map_locations = [map_location, {'cuda:0': 'cpu'}, 'cpu']\n+        cpu_map_locations = [map_location, {'cuda:0': 'cpu'}, 'cpu', torch.device('cpu')]\n+        gpu_map_locations = [\n+            {'cuda:0': 'cuda:0'},\n+            'cuda',\n+            'cuda:{}'.format(torch.cuda.device_count() - 1),\n+            'cuda:0',\n+            torch.device('cuda'),\n+            torch.device('cuda', 0)\n+        ]\n \n         for fileobject_lambda in fileobject_lambdas:\n-            for map_location in map_locations:\n+            for map_location in cpu_map_locations:\n                 tensor = torch.load(fileobject_lambda(), map_location=map_location)\n                 self.assertIsInstance(tensor, torch.FloatTensor)\n                 self.assertEqual(tensor, torch.FloatTensor([[1.0, 2.0], [3.0, 4.0]]))\n \n+            if torch.cuda.is_available():\n+                for map_location in gpu_map_locations:\n+                    tensor = torch.load(fileobject_lambda(), map_location=map_location)\n+                    self.assertIsInstance(tensor, torch.cuda.FloatTensor)\n+                    self.assertEqual(tensor, torch.cuda.FloatTensor([[1.0, 2.0], [3.0, 4.0]]))", "path": "test/test_torch.py", "position": null, "original_position": 31, "commit_id": "42ca998298e509ba4dca616aa8014d2ed6d097ca", "original_commit_id": "fa1b382e5a781651e019b274cd4182250dcc1493", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "No, it should remain like that. `device(type='cuda')` means \"the current CUDA device\", and we shouldn't have the value of equality depend on the context. Can we just special case that in this test? `device('cuda').index` is `None`, so it should be possible.", "created_at": "2018-05-10T15:21:39Z", "updated_at": "2018-11-23T15:43:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/7339#discussion_r187363799", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7339", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187363799"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7339#discussion_r187363799"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7339"}}, "body_html": "<p>No, it should remain like that. <code>device(type='cuda')</code> means \"the current CUDA device\", and we shouldn't have the value of equality depend on the context. Can we just special case that in this test? <code>device('cuda').index</code> is <code>None</code>, so it should be possible.</p>", "body_text": "No, it should remain like that. device(type='cuda') means \"the current CUDA device\", and we shouldn't have the value of equality depend on the context. Can we just special case that in this test? device('cuda').index is None, so it should be possible.", "in_reply_to_id": 187360719}