{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7271", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7271/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7271/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7271/events", "html_url": "https://github.com/pytorch/pytorch/issues/7271", "id": 320117578, "node_id": "MDU6SXNzdWUzMjAxMTc1Nzg=", "number": 7271, "title": "FloatTensor constructor bug", "user": {"login": "jrwalsh1", "id": 9166900, "node_id": "MDQ6VXNlcjkxNjY5MDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9166900?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrwalsh1", "html_url": "https://github.com/jrwalsh1", "followers_url": "https://api.github.com/users/jrwalsh1/followers", "following_url": "https://api.github.com/users/jrwalsh1/following{/other_user}", "gists_url": "https://api.github.com/users/jrwalsh1/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrwalsh1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrwalsh1/subscriptions", "organizations_url": "https://api.github.com/users/jrwalsh1/orgs", "repos_url": "https://api.github.com/users/jrwalsh1/repos", "events_url": "https://api.github.com/users/jrwalsh1/events{/privacy}", "received_events_url": "https://api.github.com/users/jrwalsh1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-05-03T23:54:07Z", "updated_at": "2018-05-24T04:18:50Z", "closed_at": "2018-05-24T04:18:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have come across a strange bug building a <code>FloatTensor</code> from a <code>numpy</code> array, where I get garbage entries in the <code>FloatTensor</code> compared to the <code>numpy</code> array.</p>\n<p>This happens if the <code>numpy</code> array is read directly from a <code>pandas.HDFStore</code>, <strong>only</strong> when the data is saved in the <code>HDFStore</code> with a non-default index and with <code>HDFStore.append</code>.  The problem goes way if any of the following are true:</p>\n<ul>\n<li>I save with <code>put</code> rather than <code>append</code>.</li>\n<li>The <code>DataFrame</code> is saved with the default <code>index</code>.</li>\n<li>The <code>numpy</code> array is copied before being sent into <code>FloatTensor</code>.</li>\n</ul>\n<p>This seems extremely specific and like it may be a <code>pandas</code>/<code>pytables</code> problem, but working with the objects from the <code>HDFStore</code> as <code>numpy</code> arrays do not give any problems.</p>\n<p>Below is a MWE.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> pandas <span class=\"pl-k\">as</span> pd\n<span class=\"pl-k\">import</span> torch\n\nnp.random.seed(<span class=\"pl-c1\">137</span>)\n\nx <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>initial numpy array:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(x)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>---<span class=\"pl-pds\">\"</span></span>)\n\ndf <span class=\"pl-k\">=</span> pd.DataFrame(x, <span class=\"pl-v\">index</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>c<span class=\"pl-pds\">'</span></span>]) <span class=\"pl-c\"><span class=\"pl-c\">#</span> creates a problem when saved with \"append\"</span>\ndf_bare <span class=\"pl-k\">=</span> pd.DataFrame(x) <span class=\"pl-c\"><span class=\"pl-c\">#</span> OK</span>\n\n<span class=\"pl-k\">with</span> pd.HDFStore(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>foo.h5<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>w<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> store:\n    store.append(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>, df)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> store.append(\"x\", df_bare) # OK</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> store.put(\"x\", df) # OK</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> store.put(\"x\", df_bare) # OK</span>\n\ny <span class=\"pl-k\">=</span> pd.read_hdf(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>foo.h5<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>x<span class=\"pl-pds\">\"</span></span>).values\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>loaded numpy array:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(y)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>---<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> y = np.array(y) # this fixes the problem</span>\nt <span class=\"pl-k\">=</span> torch.FloatTensor(y)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch tensor:<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-c1\">print</span>(t)</pre></div>\n<p>On my system I get the output</p>\n<pre><code>initial numpy array:\n[[0.94385021 0.08854403 0.69537097]\n [0.69999035 0.49960034 0.50270302]\n [0.89180317 0.08895364 0.84749637]]\n---\nloaded numpy array:\n[[0.94385021 0.08854403 0.69537097]\n [0.69999035 0.49960034 0.50270302]\n [0.89180317 0.08895364 0.84749637]]\n---\ntorch tensor:\ntensor([[ 9.4385e-01,  8.8544e-02,  6.9537e-01],\n        [       -inf,        -inf,        -inf],\n        [-0.0000e+00, -4.0896e+27,  0.0000e+00]])\n</code></pre>\n<h2>System Info</h2>\n<p>Here is the output of <code>collect_env</code>:</p>\n<pre><code>Collecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.12.6\nGCC version: Could not collect\nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.14.1)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] pytorch                   0.4.0           py36_cuda0.0_cudnn0.0_1    pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch\n</code></pre>\n<p>Additionally, my <code>pandas</code> version is 0.22.0 and <code>tables</code> version is <code>3.4.2</code>.</p>", "body_text": "I have come across a strange bug building a FloatTensor from a numpy array, where I get garbage entries in the FloatTensor compared to the numpy array.\nThis happens if the numpy array is read directly from a pandas.HDFStore, only when the data is saved in the HDFStore with a non-default index and with HDFStore.append.  The problem goes way if any of the following are true:\n\nI save with put rather than append.\nThe DataFrame is saved with the default index.\nThe numpy array is copied before being sent into FloatTensor.\n\nThis seems extremely specific and like it may be a pandas/pytables problem, but working with the objects from the HDFStore as numpy arrays do not give any problems.\nBelow is a MWE.\nCode example\nimport numpy as np\nimport pandas as pd\nimport torch\n\nnp.random.seed(137)\n\nx = np.random.rand(3,3)\nprint(\"initial numpy array:\")\nprint(x)\nprint(\"---\")\n\ndf = pd.DataFrame(x, index=['a','b','c']) # creates a problem when saved with \"append\"\ndf_bare = pd.DataFrame(x) # OK\n\nwith pd.HDFStore(\"foo.h5\", \"w\") as store:\n    store.append(\"x\", df)\n    # store.append(\"x\", df_bare) # OK\n    # store.put(\"x\", df) # OK\n    # store.put(\"x\", df_bare) # OK\n\ny = pd.read_hdf(\"foo.h5\", \"x\").values\nprint(\"loaded numpy array:\")\nprint(y)\nprint(\"---\")\n\n# y = np.array(y) # this fixes the problem\nt = torch.FloatTensor(y)\nprint(\"torch tensor:\")\nprint(t)\nOn my system I get the output\ninitial numpy array:\n[[0.94385021 0.08854403 0.69537097]\n [0.69999035 0.49960034 0.50270302]\n [0.89180317 0.08895364 0.84749637]]\n---\nloaded numpy array:\n[[0.94385021 0.08854403 0.69537097]\n [0.69999035 0.49960034 0.50270302]\n [0.89180317 0.08895364 0.84749637]]\n---\ntorch tensor:\ntensor([[ 9.4385e-01,  8.8544e-02,  6.9537e-01],\n        [       -inf,        -inf,        -inf],\n        [-0.0000e+00, -4.0896e+27,  0.0000e+00]])\n\nSystem Info\nHere is the output of collect_env:\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.12.6\nGCC version: Could not collect\nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.14.1)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] pytorch                   0.4.0           py36_cuda0.0_cudnn0.0_1    pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch\n\nAdditionally, my pandas version is 0.22.0 and tables version is 3.4.2.", "body": "I have come across a strange bug building a `FloatTensor` from a `numpy` array, where I get garbage entries in the `FloatTensor` compared to the `numpy` array.\r\n\r\nThis happens if the `numpy` array is read directly from a `pandas.HDFStore`, **only** when the data is saved in the `HDFStore` with a non-default index and with `HDFStore.append`.  The problem goes way if any of the following are true:\r\n- I save with `put` rather than `append`.\r\n- The `DataFrame` is saved with the default `index`.\r\n- The `numpy` array is copied before being sent into `FloatTensor`.\r\n\r\nThis seems extremely specific and like it may be a `pandas`/`pytables` problem, but working with the objects from the `HDFStore` as `numpy` arrays do not give any problems.\r\n\r\nBelow is a MWE.\r\n\r\n## Code example\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport torch\r\n\r\nnp.random.seed(137)\r\n\r\nx = np.random.rand(3,3)\r\nprint(\"initial numpy array:\")\r\nprint(x)\r\nprint(\"---\")\r\n\r\ndf = pd.DataFrame(x, index=['a','b','c']) # creates a problem when saved with \"append\"\r\ndf_bare = pd.DataFrame(x) # OK\r\n\r\nwith pd.HDFStore(\"foo.h5\", \"w\") as store:\r\n    store.append(\"x\", df)\r\n    # store.append(\"x\", df_bare) # OK\r\n    # store.put(\"x\", df) # OK\r\n    # store.put(\"x\", df_bare) # OK\r\n\r\ny = pd.read_hdf(\"foo.h5\", \"x\").values\r\nprint(\"loaded numpy array:\")\r\nprint(y)\r\nprint(\"---\")\r\n\r\n# y = np.array(y) # this fixes the problem\r\nt = torch.FloatTensor(y)\r\nprint(\"torch tensor:\")\r\nprint(t)\r\n```\r\n\r\nOn my system I get the output\r\n```\r\ninitial numpy array:\r\n[[0.94385021 0.08854403 0.69537097]\r\n [0.69999035 0.49960034 0.50270302]\r\n [0.89180317 0.08895364 0.84749637]]\r\n---\r\nloaded numpy array:\r\n[[0.94385021 0.08854403 0.69537097]\r\n [0.69999035 0.49960034 0.50270302]\r\n [0.89180317 0.08895364 0.84749637]]\r\n---\r\ntorch tensor:\r\ntensor([[ 9.4385e-01,  8.8544e-02,  6.9537e-01],\r\n        [       -inf,        -inf,        -inf],\r\n        [-0.0000e+00, -4.0896e+27,  0.0000e+00]])\r\n```\r\n\r\n## System Info\r\nHere is the output of `collect_env`:\r\n```\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.12.6\r\nGCC version: Could not collect\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.1)\r\n[pip] numpydoc (0.7.0)\r\n[pip] torch (0.4.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] pytorch                   0.4.0           py36_cuda0.0_cudnn0.0_1    pytorch\r\n[conda] torchvision               0.2.1                    py36_1    pytorch\r\n```\r\nAdditionally, my `pandas` version is 0.22.0 and `tables` version is `3.4.2`."}