{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1927", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1927/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1927/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1927/events", "html_url": "https://github.com/pytorch/pytorch/issues/1927", "id": 239155747, "node_id": "MDU6SXNzdWUyMzkxNTU3NDc=", "number": 1927, "title": "[feature request] time-distributed layers for application of normal layers to sequence data", "user": {"login": "erogol", "id": 1402048, "node_id": "MDQ6VXNlcjE0MDIwNDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1402048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erogol", "html_url": "https://github.com/erogol", "followers_url": "https://api.github.com/users/erogol/followers", "following_url": "https://api.github.com/users/erogol/following{/other_user}", "gists_url": "https://api.github.com/users/erogol/gists{/gist_id}", "starred_url": "https://api.github.com/users/erogol/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erogol/subscriptions", "organizations_url": "https://api.github.com/users/erogol/orgs", "repos_url": "https://api.github.com/users/erogol/repos", "events_url": "https://api.github.com/users/erogol/events{/privacy}", "received_events_url": "https://api.github.com/users/erogol/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-06-28T12:59:25Z", "updated_at": "2018-06-07T09:22:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>As we move from images to videos, it seems imperative to feed sequential data into common image layers. However, the problem of dealing sequential data with such layers is not clears on Pytorch. I suggest here to devise something like -time-distributed layers for wrapping normal layers and aligning them for sequential inputs and outputs. I think in the course of time, it is going to be a more important pattern to have in Pytorch. Hope, I explain the problem clearly?</p>\n<p>Lately, I solved that problem for 1D feat vectors as follows; I wait some comments to generalize it if necessary.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">TimeDistributed</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">module</span>):\n        <span class=\"pl-c1\">super</span>(TimeDistributed, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.module <span class=\"pl-k\">=</span> module\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(x.size()) <span class=\"pl-k\">&lt;=</span> <span class=\"pl-c1\">2</span>:\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.module(x)\n        t, n <span class=\"pl-k\">=</span> x.size(<span class=\"pl-c1\">0</span>), x.size(<span class=\"pl-c1\">1</span>) \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> merge batch and seq dimensions</span>\n        x_reshape <span class=\"pl-k\">=</span> x.contiguous().view(t <span class=\"pl-k\">*</span> n, x.size(<span class=\"pl-c1\">2</span>))\n        y <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.module(x_reshape)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> We have to reshape Y</span>\n        y <span class=\"pl-k\">=</span> y.contiguous().view(t, n, y.size()[<span class=\"pl-c1\">1</span>])\n        <span class=\"pl-k\">return</span> y</pre></div>", "body_text": "As we move from images to videos, it seems imperative to feed sequential data into common image layers. However, the problem of dealing sequential data with such layers is not clears on Pytorch. I suggest here to devise something like -time-distributed layers for wrapping normal layers and aligning them for sequential inputs and outputs. I think in the course of time, it is going to be a more important pattern to have in Pytorch. Hope, I explain the problem clearly?\nLately, I solved that problem for 1D feat vectors as follows; I wait some comments to generalize it if necessary.\nclass TimeDistributed(nn.Module):\n    def __init__(self, module):\n        super(TimeDistributed, self).__init__()\n        self.module = module\n\n    def forward(self, x):\n        if len(x.size()) <= 2:\n            return self.module(x)\n        t, n = x.size(0), x.size(1) \n        # merge batch and seq dimensions\n        x_reshape = x.contiguous().view(t * n, x.size(2))\n        y = self.module(x_reshape)\n        # We have to reshape Y\n        y = y.contiguous().view(t, n, y.size()[1])\n        return y", "body": "As we move from images to videos, it seems imperative to feed sequential data into common image layers. However, the problem of dealing sequential data with such layers is not clears on Pytorch. I suggest here to devise something like -time-distributed layers for wrapping normal layers and aligning them for sequential inputs and outputs. I think in the course of time, it is going to be a more important pattern to have in Pytorch. Hope, I explain the problem clearly?\r\n\r\nLately, I solved that problem for 1D feat vectors as follows; I wait some comments to generalize it if necessary. \r\n```python\r\nclass TimeDistributed(nn.Module):\r\n    def __init__(self, module):\r\n        super(TimeDistributed, self).__init__()\r\n        self.module = module\r\n\r\n    def forward(self, x):\r\n        if len(x.size()) <= 2:\r\n            return self.module(x)\r\n        t, n = x.size(0), x.size(1) \r\n        # merge batch and seq dimensions\r\n        x_reshape = x.contiguous().view(t * n, x.size(2))\r\n        y = self.module(x_reshape)\r\n        # We have to reshape Y\r\n        y = y.contiguous().view(t, n, y.size()[1])\r\n        return y\r\n```"}