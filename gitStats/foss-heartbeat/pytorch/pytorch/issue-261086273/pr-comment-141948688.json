{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/141948688", "pull_request_review_id": 66248698, "id": 141948688, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MTk0ODY4OA==", "diff_hunk": "@@ -769,13 +779,23 @@ def test_cuda(self, test_case):\n             cpu_module = self.constructor(*self.constructor_args)\n             gpu_module = self.constructor(*self.constructor_args).float().cuda()\n \n-            cpu_output = test_case._forward_criterion(cpu_module, cpu_input, cpu_target)\n-            gpu_output = test_case._forward_criterion(gpu_module, gpu_input, gpu_target)\n+            reduce = get_reduce(cpu_module)\n+            cpu_output = test_case._forward_criterion(\n+                cpu_module, cpu_input, cpu_target, reduce=reduce)\n+            gpu_output = test_case._forward_criterion(\n+                gpu_module, gpu_input, gpu_target, reduce=reduce)\n             test_case.assertEqual(cpu_output, gpu_output, 4e-4)\n \n-            cpu_gradInput = test_case._backward_criterion(cpu_module, cpu_input, cpu_target)\n-            gpu_gradInput = test_case._backward_criterion(gpu_module, gpu_input, gpu_target)\n+            cpu_gradOutput = \\\n+                None if reduce else torch.randn(cpu_input.size()).double()\n+            gpu_gradOutput = \\\n+                None if reduce else to_gpu(cpu_gradOutput, type_map=type_map)", "path": "test/common_nn.py", "position": null, "original_position": 63, "commit_id": "9ff333a197516414192eb192aacd6b55705b72e5", "original_commit_id": "2995079ffca4e425f2d2c5b7d65baf3f972ae4ce", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "The legacy cuda test for `MSECriterion` (`TestNN.test_MSECriterion_cuda`) also runs through this code. Right now I'm having the legacy test code [assume that `gradOutput` is `None`](https://github.com/pytorch/pytorch/pull/2878/files?diff=split#diff-b366aa5d4d0d6672aa91c10b561eaaf1R639) because I'm leaving the legacy code as-is and I don't think the legacy code supports having a `gradOutput`. \r\n\r\nI do agree that having `None` here is pretty confusing to read. I could change [the legacy test code](https://github.com/pytorch/pytorch/pull/2878/files?diff=split#diff-b366aa5d4d0d6672aa91c10b561eaaf1R639) to just ignore `gradOutput` instead of asserting that it's `None` -- what do you think about that?\r\n\r\n", "created_at": "2017-09-29T19:27:45Z", "updated_at": "2018-11-23T15:34:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/2878#discussion_r141948688", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2878", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/141948688"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2878#discussion_r141948688"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2878"}}, "body_html": "<p>The legacy cuda test for <code>MSECriterion</code> (<code>TestNN.test_MSECriterion_cuda</code>) also runs through this code. Right now I'm having the legacy test code <a href=\"https://github.com/pytorch/pytorch/pull/2878/files?diff=split#diff-b366aa5d4d0d6672aa91c10b561eaaf1R639\">assume that <code>gradOutput</code> is <code>None</code></a> because I'm leaving the legacy code as-is and I don't think the legacy code supports having a <code>gradOutput</code>.</p>\n<p>I do agree that having <code>None</code> here is pretty confusing to read. I could change <a href=\"https://github.com/pytorch/pytorch/pull/2878/files?diff=split#diff-b366aa5d4d0d6672aa91c10b561eaaf1R639\">the legacy test code</a> to just ignore <code>gradOutput</code> instead of asserting that it's <code>None</code> -- what do you think about that?</p>", "body_text": "The legacy cuda test for MSECriterion (TestNN.test_MSECriterion_cuda) also runs through this code. Right now I'm having the legacy test code assume that gradOutput is None because I'm leaving the legacy code as-is and I don't think the legacy code supports having a gradOutput.\nI do agree that having None here is pretty confusing to read. I could change the legacy test code to just ignore gradOutput instead of asserting that it's None -- what do you think about that?", "in_reply_to_id": 141910219}