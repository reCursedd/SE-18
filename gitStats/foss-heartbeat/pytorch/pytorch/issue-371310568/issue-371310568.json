{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12798", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12798/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12798/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12798/events", "html_url": "https://github.com/pytorch/pytorch/issues/12798", "id": 371310568, "node_id": "MDU6SXNzdWUzNzEzMTA1Njg=", "number": 12798, "title": "torch._utils.rebuild_cuda_tensor doesn't work with BN.num_batch_tracked", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-10-17T23:57:29Z", "updated_at": "2018-10-30T17:21:36Z", "closed_at": "2018-10-30T17:21:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Reported at <a href=\"https://discuss.pytorch.org/t/torch-multiprocessing-rebuild-cuda-tensor-having-trouble-with-bn-num-batches-tracked/27453\" rel=\"nofollow\">https://discuss.pytorch.org/t/torch-multiprocessing-rebuild-cuda-tensor-having-trouble-with-bn-num-batches-tracked/27453</a></p>\n<p>Post copied below:</p>\n<p>I am trying to pass a set of gpu models to a pool of processes, so something like the example code below:<br>\n(torch version 1.0.0.dev20181015)</p>\n<pre><code>import torch.multiprocessing as mp\nmp.set_start_method('spawn', force=True)\nimport torch\nimport torch.nn as nn\nimport time\n\n\ndef run(inpt):\n    workers, worker_queue = inpt\n    while worker_queue.empty():\n        time.sleep(0.1)\n    worker_id = worker_queue.get()\n    model = workers[worker_id]\n    data = torch.rand(5, 10)\n    data = data.cuda()\n    with torch.no_grad():\n        result = model(data)\n    worker_queue.put(worker_id)\n    return result\n\n\ndef main():\n    workers = []\n    worker_queue = mp.Manager().Queue()  # mp.Queue()\n    for worker_id in range(10):\n        worker_model = nn.BatchNorm1d(10)\n        worker_model.cuda()\n        worker_model.eval()\n        workers.append(worker_model)\n        worker_queue.put(worker_id)\n\n    pools = mp.Pool(10)\n\n    jobs = [(workers, worker_queue) for _ in range(20)]  # jobs\n    result = []\n    for res_id, res in enumerate(pools.imap_unordered(run, jobs)):\n        result.append(res)\n    print(result)\n\n\nif __name__==\"__main__\":\n    main()\n</code></pre>\n<p>However, when there is BatchNorm, the following error is raised in torch._utils.rebuild_cuda_tensor:</p>\n<p>RuntimeError: Expected object of data type 4 but got data type 6 for argument <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a> 'source'<br>\nIt is probably caused by the attribute bn.num_batches_tracked, which is supposed to be type 4 (int64_t), but looks like the error message is reporting data type 6 (float). What is likely the cause of this issue? Is there any way to fix it?</p>", "body_text": "Reported at https://discuss.pytorch.org/t/torch-multiprocessing-rebuild-cuda-tensor-having-trouble-with-bn-num-batches-tracked/27453\nPost copied below:\nI am trying to pass a set of gpu models to a pool of processes, so something like the example code below:\n(torch version 1.0.0.dev20181015)\nimport torch.multiprocessing as mp\nmp.set_start_method('spawn', force=True)\nimport torch\nimport torch.nn as nn\nimport time\n\n\ndef run(inpt):\n    workers, worker_queue = inpt\n    while worker_queue.empty():\n        time.sleep(0.1)\n    worker_id = worker_queue.get()\n    model = workers[worker_id]\n    data = torch.rand(5, 10)\n    data = data.cuda()\n    with torch.no_grad():\n        result = model(data)\n    worker_queue.put(worker_id)\n    return result\n\n\ndef main():\n    workers = []\n    worker_queue = mp.Manager().Queue()  # mp.Queue()\n    for worker_id in range(10):\n        worker_model = nn.BatchNorm1d(10)\n        worker_model.cuda()\n        worker_model.eval()\n        workers.append(worker_model)\n        worker_queue.put(worker_id)\n\n    pools = mp.Pool(10)\n\n    jobs = [(workers, worker_queue) for _ in range(20)]  # jobs\n    result = []\n    for res_id, res in enumerate(pools.imap_unordered(run, jobs)):\n        result.append(res)\n    print(result)\n\n\nif __name__==\"__main__\":\n    main()\n\nHowever, when there is BatchNorm, the following error is raised in torch._utils.rebuild_cuda_tensor:\nRuntimeError: Expected object of data type 4 but got data type 6 for argument #2 'source'\nIt is probably caused by the attribute bn.num_batches_tracked, which is supposed to be type 4 (int64_t), but looks like the error message is reporting data type 6 (float). What is likely the cause of this issue? Is there any way to fix it?", "body": "Reported at https://discuss.pytorch.org/t/torch-multiprocessing-rebuild-cuda-tensor-having-trouble-with-bn-num-batches-tracked/27453\r\n\r\nPost copied below:\r\n\r\nI am trying to pass a set of gpu models to a pool of processes, so something like the example code below:\r\n(torch version 1.0.0.dev20181015)\r\n\r\n```\r\nimport torch.multiprocessing as mp\r\nmp.set_start_method('spawn', force=True)\r\nimport torch\r\nimport torch.nn as nn\r\nimport time\r\n\r\n\r\ndef run(inpt):\r\n    workers, worker_queue = inpt\r\n    while worker_queue.empty():\r\n        time.sleep(0.1)\r\n    worker_id = worker_queue.get()\r\n    model = workers[worker_id]\r\n    data = torch.rand(5, 10)\r\n    data = data.cuda()\r\n    with torch.no_grad():\r\n        result = model(data)\r\n    worker_queue.put(worker_id)\r\n    return result\r\n\r\n\r\ndef main():\r\n    workers = []\r\n    worker_queue = mp.Manager().Queue()  # mp.Queue()\r\n    for worker_id in range(10):\r\n        worker_model = nn.BatchNorm1d(10)\r\n        worker_model.cuda()\r\n        worker_model.eval()\r\n        workers.append(worker_model)\r\n        worker_queue.put(worker_id)\r\n\r\n    pools = mp.Pool(10)\r\n\r\n    jobs = [(workers, worker_queue) for _ in range(20)]  # jobs\r\n    result = []\r\n    for res_id, res in enumerate(pools.imap_unordered(run, jobs)):\r\n        result.append(res)\r\n    print(result)\r\n\r\n\r\nif __name__==\"__main__\":\r\n    main()\r\n```\r\n\r\nHowever, when there is BatchNorm, the following error is raised in torch._utils.rebuild_cuda_tensor:\r\n\r\nRuntimeError: Expected object of data type 4 but got data type 6 for argument #2 'source'\r\nIt is probably caused by the attribute bn.num_batches_tracked, which is supposed to be type 4 (int64_t), but looks like the error message is reporting data type 6 (float). What is likely the cause of this issue? Is there any way to fix it?"}