{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204828236", "pull_request_review_id": 139957190, "id": 204828236, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDgyODIzNg==", "diff_hunk": "@@ -0,0 +1,313 @@\n+// Copyright (c) 2018 MathInf GmbH, Thomas Viehmann\n+// Licensed under the BSD-3-Clause license\n+\n+#include <ATen/ATen.h>\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/TensorUtils.h\"\n+\n+#include <numeric>\n+\n+namespace at {\n+namespace native {\n+\n+namespace {\n+\n+inline int64_t get_target_prime(int64_t* target, int64_t offset, int64_t stride, int64_t idx, int64_t BLANK) {\n+  if (idx % 2 == 0) {\n+    return BLANK;\n+  } else {\n+    return target[offset + stride * (idx / 2)];\n+  }\n+}\n+\n+template<typename scalar_t>\n+std::tuple<Tensor, Tensor> ctc_loss_cpu_template(const Tensor& log_probs, const Tensor& targets, const Tensor& input_lengths, const Tensor& target_lengths, int64_t BLANK) {\n+  // log_probs: input_len x batch_size x num_labels\n+  // targets [int64]: batch_size x target_length\n+  constexpr scalar_t neginf = -std::numeric_limits<scalar_t>::infinity();\n+\n+  CheckedFrom c = \"ctc_loss_cpu\";\n+  auto log_probs_arg = TensorArg(log_probs, \"log_probs\", 1);\n+  auto targets_arg = TensorArg(targets, \"targets\", 2);\n+  auto input_lengths_arg = TensorArg(input_lengths, \"input_lengths\", 3);\n+  auto target_lengths_arg = TensorArg(target_lengths, \"target_lengths\", 4);\n+  checkScalarType(c, targets_arg, kLong);\n+  checkScalarType(c, input_lengths_arg, kLong);\n+  checkScalarType(c, target_lengths_arg, kLong);\n+  checkDim(c, log_probs_arg, 3);\n+  checkDimRange(c, targets_arg, 1, 3);\n+\n+  int64_t batch_size = log_probs.size(1);\n+  int64_t num_labels = log_probs.size(2);\n+  AT_CHECK(BLANK < num_labels, \"blank must be in label range\");\n+  checkSize(c, input_lengths_arg, {batch_size});\n+  checkSize(c, target_lengths_arg, {batch_size});\n+\n+  size_t tg_target_stride;\n+  int64_t max_target_length;\n+  Tensor tg_batch_offsets;\n+  if (targets.dim() == 1) { // concatenated targets\n+    tg_batch_offsets = at::zeros_like(target_lengths);\n+    auto tmp = tg_batch_offsets.narrow(0, 1, batch_size-1);\n+    at::cumsum_out(tmp, target_lengths, 0);\n+    max_target_length = at::max(target_lengths).toCLong();\n+    tg_target_stride = targets.stride(0);\n+    checkSize(c, targets_arg, 0, tmp[batch_size-1].toCLong()+target_lengths[batch_size-1].toCLong());\n+  }\n+  else { // batch x max_target_length\n+    // dim is 2\n+    tg_batch_offsets = at::arange(0, targets.stride(0)*batch_size, targets.stride(0), target_lengths.options());\n+    tg_target_stride = targets.stride(1);\n+    max_target_length = targets.size(1);\n+    checkSize(c, targets_arg, 0, batch_size);\n+    AT_CHECK(targets.size(1) >= max_target_length,\n+             \"Expected tensor to have size at least \", max_target_length, \" at dimension 1, but got size \", targets.size(1), \" for \", targets_arg,\n+             \" (while checking arguments for \", c, \")\");\n+  }\n+  int max_input_length = at::max(input_lengths).toCLong();\n+  AT_CHECK(log_probs.size(0) >= max_input_length,\n+           \"Expected tensor to have size at least \", max_input_length, \" at dimension 1, but got size \", targets.size(0), \" for \", targets_arg,\n+           \" (while checking arguments for \", c, \")\");\n+\n+  Tensor log_alpha = at::empty({batch_size, log_probs.size(0), 2*max_target_length+1}, log_probs.options());\n+  Tensor neg_log_likelihood = at::empty({batch_size}, log_probs.options());\n+\n+\n+  auto log_probs_data = log_probs.data<scalar_t>();\n+  auto log_alpha_data = log_alpha.data<scalar_t>();\n+  auto targets_data = targets.data<int64_t>();\n+  auto neg_log_likelihood_data = neg_log_likelihood.data<scalar_t>(); // we assume stride one for the only dimension for freshly allocated tensor\n+  size_t lp_input_stride = log_probs.stride(0);\n+  size_t lp_char_stride = log_probs.stride(2);\n+  size_t la_input_stride = log_alpha.stride(1);\n+  size_t la_target_stride = log_alpha.stride(2);\n+\n+  log_alpha.narrow(1, 0, 1).fill_(neginf); // or do this inside the batch loop?\n+  #pragma omp parallel for\n+  for (int64_t b = 0; b < batch_size; b++) {\n+    int64_t input_length = input_lengths[b].toCLong();", "path": "aten/src/ATen/native/LossCTC.cpp", "position": null, "original_position": 88, "commit_id": "11b97f7337172d5bfef0e2af792569597aafaee1", "original_commit_id": "77eb0e5d50dfaab028894081e65f13f822c8fe0f", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "This creates a tensor at every iteration and is very slow even on CPU. Can you get the data pointer before the loop and use `input_length = input_lenghts_data[b]` inside? Similar for `target_lengths` and `tg_batch_offsets `.", "created_at": "2018-07-24T16:39:17Z", "updated_at": "2018-11-23T15:47:58Z", "html_url": "https://github.com/pytorch/pytorch/pull/9628#discussion_r204828236", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9628", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204828236"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9628#discussion_r204828236"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9628"}}, "body_html": "<p>This creates a tensor at every iteration and is very slow even on CPU. Can you get the data pointer before the loop and use <code>input_length = input_lenghts_data[b]</code> inside? Similar for <code>target_lengths</code> and <code>tg_batch_offsets </code>.</p>", "body_text": "This creates a tensor at every iteration and is very slow even on CPU. Can you get the data pointer before the loop and use input_length = input_lenghts_data[b] inside? Similar for target_lengths and tg_batch_offsets ."}