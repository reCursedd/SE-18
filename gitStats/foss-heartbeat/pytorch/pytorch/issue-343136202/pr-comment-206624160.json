{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/206624160", "pull_request_review_id": 142072230, "id": 206624160, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNjYyNDE2MA==", "diff_hunk": "@@ -1123,6 +1123,61 @@ def forward(self, anchor, positive, negative):\n         return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,\n                                      eps=self.eps, swap=self.swap, reduction=self.reduction)\n \n+\n+class CTCLoss(_Loss):\n+    r\"\"\"The Connectionist Temporal Classification loss.\n+\n+    Args:\n+        blank (int, optional): blank label. Default :math:`0`.\n+        reduction (string, optional): Specifies the reduction to apply to the output:\n+            'none' | 'elementwise_mean' | 'sum'. 'none': no reduction will be applied,\n+            'elementwise_mean': the output losses will be divided by the target lengths and\n+            then the mean over the batch is taken. Default: 'elementwise_mean'\n+\n+    Inputs:\n+        log_probs: :math:`(T, N, C)` where `C = number of characters in alphabet including blank`,\n+            `T = input length`, and `N = batch size`.\n+            The logarithmized probabilities of the outputs\n+            (e.g. obtained with :func:`torch.nn.functional.log_softmax`).\n+        targets: :math:`(N, S)` or `(sum(target_lenghts))`.\n+            Targets (cannot be blank). In the second form, the targets are assumed to be concatenated.\n+        input_lengths: :math:`(N)`.\n+            Lengths of the inputs (must each be :math:`\\leq T`)\n+        target_lengths: :math:`(N)`.\n+            Lengths of the targets\n+\n+\n+    Example::\n+\n+        >>> ctc_loss = nn.CTCLoss()\n+        >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()\n+        >>> targets = torch.randint(1, 21, (16, 30), dtype=torch.long)\n+        >>> input_lengths = torch.full((16,), 50, dtype=torch.long)\n+        >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n+        >>> loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n+        >>> loss.backward()\n+\n+    Reference:\n+        A. Graves et al.: Connectionist Temporal Classification:\n+        Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n+        https://www.cs.toronto.edu/~graves/icml_2006.pdf\n+\n+    .. Note::\n+        In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n+        in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n+        :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n+        :class:`torch.IntTensor`.", "path": "torch/nn/modules/loss.py", "position": 47, "original_position": 47, "commit_id": "11b97f7337172d5bfef0e2af792569597aafaee1", "original_commit_id": "11b97f7337172d5bfef0e2af792569597aafaee1", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "question: doest it work if the integral args are IntTensors, but `target_lengths > 256`?\r\n\r\nAlso a minor nit is to use `torch.int32` instead of `IntTensor`", "created_at": "2018-07-31T17:52:22Z", "updated_at": "2018-11-23T15:48:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/9628#discussion_r206624160", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9628", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/206624160"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9628#discussion_r206624160"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9628"}}, "body_html": "<p>question: doest it work if the integral args are IntTensors, but <code>target_lengths &gt; 256</code>?</p>\n<p>Also a minor nit is to use <code>torch.int32</code> instead of <code>IntTensor</code></p>", "body_text": "question: doest it work if the integral args are IntTensors, but target_lengths > 256?\nAlso a minor nit is to use torch.int32 instead of IntTensor"}