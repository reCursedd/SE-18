{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/272226407", "html_url": "https://github.com/pytorch/pytorch/issues/437#issuecomment-272226407", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/437", "id": 272226407, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjIyNjQwNw==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-12T17:25:43Z", "updated_at": "2017-01-12T17:25:43Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a>, it also does shuffling. The problem is that if you move batching to your dataset you also have to move shuffling, since you typically want to batch after you shuffle. Shuffling is broken in a major way in torchnet, which is why we avoided that design. For example, in the common patterns are often not what you want.</p>\n<ol>\n<li>The torchnet engine doesn't shuffle between epochs</li>\n<li>If you do manually shuffle, it's hard to ensure that each thread/process shuffles in the same order</li>\n</ol>", "body_text": "@fmassa, it also does shuffling. The problem is that if you move batching to your dataset you also have to move shuffling, since you typically want to batch after you shuffle. Shuffling is broken in a major way in torchnet, which is why we avoided that design. For example, in the common patterns are often not what you want.\n\nThe torchnet engine doesn't shuffle between epochs\nIf you do manually shuffle, it's hard to ensure that each thread/process shuffles in the same order", "body": "@fmassa, it also does shuffling. The problem is that if you move batching to your dataset you also have to move shuffling, since you typically want to batch after you shuffle. Shuffling is broken in a major way in torchnet, which is why we avoided that design. For example, in the common patterns are often not what you want.\r\n\r\n1.  The torchnet engine doesn't shuffle between epochs\r\n2. If you do manually shuffle, it's hard to ensure that each thread/process shuffles in the same order"}