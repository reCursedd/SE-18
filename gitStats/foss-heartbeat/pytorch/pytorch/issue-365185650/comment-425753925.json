{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/425753925", "html_url": "https://github.com/pytorch/pytorch/issues/12201#issuecomment-425753925", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12201", "id": 425753925, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTc1MzkyNQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-30T21:35:09Z", "updated_at": "2018-09-30T21:35:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I must admit that I don't have much of an idea what happens here, and I cannot test multi-gpu at the moment. There is a switch between GPU backward kernels that depends on the size. Are you sure it only happens with multiple GPU?</p>\n<p>When you say 0.5, do you mean current master (which should report 1.0a)? I fixed some bugs a month ago or so.</p>", "body_text": "I must admit that I don't have much of an idea what happens here, and I cannot test multi-gpu at the moment. There is a switch between GPU backward kernels that depends on the size. Are you sure it only happens with multiple GPU?\nWhen you say 0.5, do you mean current master (which should report 1.0a)? I fixed some bugs a month ago or so.", "body": "I must admit that I don't have much of an idea what happens here, and I cannot test multi-gpu at the moment. There is a switch between GPU backward kernels that depends on the size. Are you sure it only happens with multiple GPU?\r\n\r\nWhen you say 0.5, do you mean current master (which should report 1.0a)? I fixed some bugs a month ago or so."}