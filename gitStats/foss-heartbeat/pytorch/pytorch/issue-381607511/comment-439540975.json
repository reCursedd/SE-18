{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/439540975", "html_url": "https://github.com/pytorch/pytorch/pull/14097#issuecomment-439540975", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/14097", "id": 439540975, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTU0MDk3NQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-16T21:54:08Z", "updated_at": "2018-11-16T21:54:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>So the error for <code>TestJit.test_export_tensoroption_to</code> is because this</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">foo</span>(<span class=\"pl-smi\">x</span>):\n   <span class=\"pl-k\">return</span> x.new_tensor(x[<span class=\"pl-c1\">1</span>]).cpu() <span class=\"pl-k\">+</span> x\na <span class=\"pl-k\">=</span> torch.randn([<span class=\"pl-c1\">2</span>])\ny <span class=\"pl-k\">=</span> torch.jit.trace(foo, (a,))\nb <span class=\"pl-k\">=</span> y(a)\n<span class=\"pl-c1\">print</span> (torch.onnx._export_to_pretty_string(y, (a,), <span class=\"pl-c1\">None</span>, <span class=\"pl-v\">example_outputs</span><span class=\"pl-k\">=</span>b))</pre></div>\n<p>now gives</p>\n<pre><code>ModelProto {\n  producer_name: \"pytorch\"\n  domain: \"\"\n  doc_string: \"\"\n  graph:\n    GraphProto {\n      name: \"torch-jit-export\"\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\n      outputs: [{name: \"2\", type:Tensor dims: 2}]\n      initializers: []\n      nodes: [\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Add\", inputs: [1,x], outputs: [2], attributes: []}\n      ]\n    }\n  opset_import: [OperatorSetIdProto { domain: }],\n}\n</code></pre>\n<p>rather than the following output for master:</p>\n<pre><code>ModelProto {\n  producer_name: \"pytorch\"\n  domain: \"\"\n  doc_string: \"\"\n  graph:\n    GraphProto {\n      name: \"torch-jit-export\"\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\n      outputs: [{name: \"7\", type:Tensor dims: 2}]\n      initializers: []\n      nodes: [\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Gather\", inputs: [x,1], outputs: [2], attributes: [{ name: 'axis', type: int, value: 0}]},\n        Node {type: \"Constant\", inputs: [], outputs: [3], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Shape\", inputs: [3], outputs: [4], attributes: []},\n        Node {type: \"Expand\", inputs: [2,4], outputs: [5], attributes: []},\n        Node {type: \"Cast\", inputs: [5], outputs: [6], attributes: [{ name: 'to', type: int, value: 11}]},\n        Node {type: \"Add\", inputs: [6,x], outputs: [7], attributes: []}\n      ]\n    }\n  opset_import: [OperatorSetIdProto { domain: }],\n}\n</code></pre>\n<p>The JIT graph (<code>y.graph_for(a)</code>) looks perfectly good to me, but how can I be sure whether ONNX needs the reshape?</p>", "body_text": "So the error for TestJit.test_export_tensoroption_to is because this\nimport torch\ndef foo(x):\n   return x.new_tensor(x[1]).cpu() + x\na = torch.randn([2])\ny = torch.jit.trace(foo, (a,))\nb = y(a)\nprint (torch.onnx._export_to_pretty_string(y, (a,), None, example_outputs=b))\nnow gives\nModelProto {\n  producer_name: \"pytorch\"\n  domain: \"\"\n  doc_string: \"\"\n  graph:\n    GraphProto {\n      name: \"torch-jit-export\"\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\n      outputs: [{name: \"2\", type:Tensor dims: 2}]\n      initializers: []\n      nodes: [\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Add\", inputs: [1,x], outputs: [2], attributes: []}\n      ]\n    }\n  opset_import: [OperatorSetIdProto { domain: }],\n}\n\nrather than the following output for master:\nModelProto {\n  producer_name: \"pytorch\"\n  domain: \"\"\n  doc_string: \"\"\n  graph:\n    GraphProto {\n      name: \"torch-jit-export\"\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\n      outputs: [{name: \"7\", type:Tensor dims: 2}]\n      initializers: []\n      nodes: [\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Gather\", inputs: [x,1], outputs: [2], attributes: [{ name: 'axis', type: int, value: 0}]},\n        Node {type: \"Constant\", inputs: [], outputs: [3], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\n        Node {type: \"Shape\", inputs: [3], outputs: [4], attributes: []},\n        Node {type: \"Expand\", inputs: [2,4], outputs: [5], attributes: []},\n        Node {type: \"Cast\", inputs: [5], outputs: [6], attributes: [{ name: 'to', type: int, value: 11}]},\n        Node {type: \"Add\", inputs: [6,x], outputs: [7], attributes: []}\n      ]\n    }\n  opset_import: [OperatorSetIdProto { domain: }],\n}\n\nThe JIT graph (y.graph_for(a)) looks perfectly good to me, but how can I be sure whether ONNX needs the reshape?", "body": "So the error for `TestJit.test_export_tensoroption_to` is because this\r\n```python\r\nimport torch\r\ndef foo(x):\r\n   return x.new_tensor(x[1]).cpu() + x\r\na = torch.randn([2])\r\ny = torch.jit.trace(foo, (a,))\r\nb = y(a)\r\nprint (torch.onnx._export_to_pretty_string(y, (a,), None, example_outputs=b))\r\n```\r\nnow gives\r\n```\r\nModelProto {\r\n  producer_name: \"pytorch\"\r\n  domain: \"\"\r\n  doc_string: \"\"\r\n  graph:\r\n    GraphProto {\r\n      name: \"torch-jit-export\"\r\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\r\n      outputs: [{name: \"2\", type:Tensor dims: 2}]\r\n      initializers: []\r\n      nodes: [\r\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\r\n        Node {type: \"Add\", inputs: [1,x], outputs: [2], attributes: []}\r\n      ]\r\n    }\r\n  opset_import: [OperatorSetIdProto { domain: }],\r\n}\r\n```\r\nrather than the following output for master:\r\n```\r\nModelProto {\r\n  producer_name: \"pytorch\"\r\n  domain: \"\"\r\n  doc_string: \"\"\r\n  graph:\r\n    GraphProto {\r\n      name: \"torch-jit-export\"\r\n      inputs: [{name: \"x\", type:Tensor dims: 2}]\r\n      outputs: [{name: \"7\", type:Tensor dims: 2}]\r\n      initializers: []\r\n      nodes: [\r\n        Node {type: \"Constant\", inputs: [], outputs: [1], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\r\n        Node {type: \"Gather\", inputs: [x,1], outputs: [2], attributes: [{ name: 'axis', type: int, value: 0}]},\r\n        Node {type: \"Constant\", inputs: [], outputs: [3], attributes: [{ name: 'value', type: tensor, value:TensorProto shape: []}]},\r\n        Node {type: \"Shape\", inputs: [3], outputs: [4], attributes: []},\r\n        Node {type: \"Expand\", inputs: [2,4], outputs: [5], attributes: []},\r\n        Node {type: \"Cast\", inputs: [5], outputs: [6], attributes: [{ name: 'to', type: int, value: 11}]},\r\n        Node {type: \"Add\", inputs: [6,x], outputs: [7], attributes: []}\r\n      ]\r\n    }\r\n  opset_import: [OperatorSetIdProto { domain: }],\r\n}\r\n```\r\nThe JIT graph (`y.graph_for(a)`) looks perfectly good to me, but how can I be sure whether ONNX needs the reshape?\r\n"}