{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/235614752", "pull_request_review_id": 177519424, "id": 235614752, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNTYxNDc1Mg==", "diff_hunk": "@@ -206,45 +189,42 @@ Tensor internal_new_from_data(\n     bool copy_variables,\n     bool copy_numpy,\n     bool type_inference) {\n-  int32_t device_index = -1;\n-  if (device_opt.has_value()) {\n-    device_index = device_opt->index();\n-  }\n   if (THPUtils_checkString(data)) {\n     throw TypeError(\"new(): invalid data type '%s'\", Py_TYPE(data)->tp_name);\n   }\n \n   if (THPVariable_Check(data)) {\n     auto var = reinterpret_cast<THPVariable*>(data)->cdata;\n-    auto type_inference_device_type = device_opt.has_value() ? device_opt->type()\n-                                                             : torch::getDeviceType(var.type());\n+    if (copy_variables) {\n+      var = autograd::make_variable(var.data(), /*requires_grad=*/false);", "path": "torch/csrc/utils/tensor_new.cpp", "position": 49, "original_position": 41, "commit_id": "c6b53a6f952de29e0d420118d032066684b7b351", "original_commit_id": "631f376b4a6f7e942198a831152ef9438e460876", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "It's to disconnect it hard in the autograd graph when using `torch.tensor(...)`. My theory is that previously we used `Type.copy` which is autograd-breaking. Of course, one might ask whether it'd be cleaner to use `.detach()`.\r\n", "created_at": "2018-11-22T06:40:08Z", "updated_at": "2018-11-23T15:55:23Z", "html_url": "https://github.com/pytorch/pytorch/pull/14097#discussion_r235614752", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/14097", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/235614752"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/14097#discussion_r235614752"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/14097"}}, "body_html": "<p>It's to disconnect it hard in the autograd graph when using <code>torch.tensor(...)</code>. My theory is that previously we used <code>Type.copy</code> which is autograd-breaking. Of course, one might ask whether it'd be cleaner to use <code>.detach()</code>.</p>", "body_text": "It's to disconnect it hard in the autograd graph when using torch.tensor(...). My theory is that previously we used Type.copy which is autograd-breaking. Of course, one might ask whether it'd be cleaner to use .detach().", "in_reply_to_id": 235559507}