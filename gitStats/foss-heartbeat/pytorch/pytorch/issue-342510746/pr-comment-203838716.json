{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203838716", "pull_request_review_id": 138810761, "id": 203838716, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzgzODcxNg==", "diff_hunk": "@@ -79,4 +98,146 @@ def test_conv_graph(self):\n         Y = workspace.FetchBlob(\"Y\")\n         np.testing.assert_almost_equal(Y, Y_without_padding)\n \n+class OnnxifiTransformTest(TestCase):\n+    def _model_dir(self, model):\n+        caffe2_home = os.path.expanduser(os.getenv('CAFFE2_HOME', '~/.caffe2'))\n+        models_dir = os.getenv('CAFFE2_MODELS', os.path.join(caffe2_home, 'models'))\n+        return os.path.join(models_dir, model)\n+\n+    def _download(self, model):\n+        model_dir = self._model_dir(model)\n+        assert not os.path.exists(model_dir)\n+        os.makedirs(model_dir)\n+        for f in ['predict_net.pb', 'init_net.pb', 'value_info.json']:\n+            url = getURLFromName(model, f)\n+            dest = os.path.join(model_dir, f)\n+            try:\n+                try:\n+                    downloadFromURLToFile(url, dest,\n+                                          show_progress=False)\n+                except TypeError:\n+                    # show_progress not supported prior to\n+                    # Caffe2 78c014e752a374d905ecfb465d44fa16e02a28f1\n+                    # (Sep 17, 2017)\n+                    downloadFromURLToFile(url, dest)\n+            except Exception as e:\n+                print(\"Abort: {reason}\".format(reason=e))\n+                print(\"Cleaning up...\")\n+                deleteDirectory(model_dir)\n+                exit(1)\n+\n+    def _get_c2_model(self, model_name):\n+        model_dir = self._model_dir(model_name)\n+        if not os.path.exists(model_dir):\n+            self._download(model_name)\n+        c2_predict_pb = os.path.join(model_dir, 'predict_net.pb')\n+        c2_predict_net = caffe2_pb2.NetDef()\n+        with open(c2_predict_pb, 'rb') as f:\n+            c2_predict_net.ParseFromString(f.read())\n+        c2_predict_net.name = model_name\n+\n+        c2_init_pb = os.path.join(model_dir, 'init_net.pb')\n+        c2_init_net = caffe2_pb2.NetDef()\n+        with open(c2_init_pb, 'rb') as f:\n+            c2_init_net.ParseFromString(f.read())\n+        c2_init_net.name = model_name + '_init'\n+\n+        value_info = json.load(open(os.path.join(model_dir, 'value_info.json')))\n+        return c2_init_net, c2_predict_net, value_info\n+\n+    def _add_head_tail(self, pred_net, new_head, new_tail):\n+        orig_head = pred_net.external_input[0]\n+        orig_tail = pred_net.external_output[0]\n+\n+        # Add head\n+        head = caffe2_pb2.OperatorDef()\n+        head.type = \"Copy\"\n+        head.input.append(new_head)\n+        head.output.append(orig_head)\n+        dummy = caffe2_pb2.NetDef()\n+        dummy.op.extend(pred_net.op)\n+        del pred_net.op[:]\n+        pred_net.op.extend([head])\n+        pred_net.op.extend(dummy.op)\n+        pred_net.external_input[0] = new_head\n+\n+        # Add tail\n+        tail = caffe2_pb2.OperatorDef()\n+        tail.type = \"Copy\"\n+        tail.input.append(orig_tail)\n+        tail.output.append(new_tail)\n+        pred_net.op.extend([tail])\n+        pred_net.external_output[0] = new_tail\n+\n+\n+    @unittest.skip(\"Need ONNXIFI backend support\")\n+    def test_resnet50_core(self):\n+        N = 1\n+        warmup = 0\n+        repeat = 1\n+        print(\"Batch size: {}, repeat inference {} times, warmup {} times\".format(N, repeat, warmup))\n+        init_net, pred_net, _  = self._get_c2_model('resnet50')\n+        self._add_head_tail(pred_net, 'real_data', 'real_softmax')\n+        input_blob_dims = (N, 3, 224, 224)\n+        input_name = \"real_data\"\n+\n+        device_option = core.DeviceOption(caffe2_pb2.CPU, 0)\n+        init_net.device_option.CopyFrom(device_option)\n+        pred_net.device_option.CopyFrom(device_option)\n+        for op in pred_net.op:\n+            op.device_option.CopyFrom(device_option)\n+        net_outputs = pred_net.external_output\n+        Y_c2 = None\n+        data =  np.random.randn(*input_blob_dims).astype(np.float32)\n+        c2_time = 0\n+        workspace.SwitchWorkspace(\"gpu_test\", True)\n+        with core.DeviceScope(device_option):\n+            workspace.FeedBlob(input_name, data)\n+            workspace.RunNetOnce(init_net)\n+            workspace.CreateNet(pred_net)\n+            for _ in range(warmup):\n+                workspace.RunNet(pred_net.name)\n+            start = time.time()\n+            for _ in range(repeat):\n+                workspace.RunNet(pred_net.name)\n+            end = time.time()\n+            c2_time = end - start\n+            output_values = [workspace.FetchBlob(name) for name in net_outputs]\n+            Y_c2 = namedtupledict('Outputs', net_outputs)(*output_values)\n+        workspace.ResetWorkspace()\n+\n+        # Fill the workspace with the weights\n+        with core.DeviceScope(device_option):\n+            workspace.RunNetOnce(init_net)\n+\n+        # Cut the graph\n+        start = time.time()\n+        pred_net_cut = onnxifi_caffe2_net(pred_net,\n+                                          {input_name: input_blob_dims})\n+        del init_net, pred_net\n+        pred_net_cut.device_option.CopyFrom(device_option)\n+        #_print_net(pred_net_cut)\n+\n+        Y_trt = None\n+        input_name = pred_net_cut.external_input[0]\n+        print(\"C2 runtime: {}s\".format(c2_time))\n+        np.set_printoptions(threshold=np.nan)\n+        with core.DeviceScope(device_option):\n+            workspace.FeedBlob(input_name, data)\n+            workspace.CreateNet(pred_net_cut)\n+            end = time.time()\n+            print(\"Conversion time: {:.2f}s\".format(end -start))", "path": "caffe2/python/onnx/test_onnxifi.py", "position": null, "original_position": 168, "commit_id": "bcd44f8d733ba2703a40e9cbd823efcb67115750", "original_commit_id": "60b4564185daf7f45c20956e3ecaaa020bba9207", "user": {"login": "yinghai", "id": 1100089, "node_id": "MDQ6VXNlcjExMDAwODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1100089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinghai", "html_url": "https://github.com/yinghai", "followers_url": "https://api.github.com/users/yinghai/followers", "following_url": "https://api.github.com/users/yinghai/following{/other_user}", "gists_url": "https://api.github.com/users/yinghai/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinghai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinghai/subscriptions", "organizations_url": "https://api.github.com/users/yinghai/orgs", "repos_url": "https://api.github.com/users/yinghai/repos", "events_url": "https://api.github.com/users/yinghai/events{/privacy}", "received_events_url": "https://api.github.com/users/yinghai/received_events", "type": "User", "site_admin": false}, "body": "Yes, and it is what I wanted to count too. Name might be a bit misleading. ", "created_at": "2018-07-19T19:04:55Z", "updated_at": "2018-11-23T15:47:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/9569#discussion_r203838716", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9569", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203838716"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9569#discussion_r203838716"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9569"}}, "body_html": "<p>Yes, and it is what I wanted to count too. Name might be a bit misleading.</p>", "body_text": "Yes, and it is what I wanted to count too. Name might be a bit misleading.", "in_reply_to_id": 203825967}