{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8867", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8867/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8867/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8867/events", "html_url": "https://github.com/pytorch/pytorch/issues/8867", "id": 335551529, "node_id": "MDU6SXNzdWUzMzU1NTE1Mjk=", "number": 8867, "title": "[JIT] Normalize representation of traced and scripted functions/modules ", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-06-25T20:15:05Z", "updated_at": "2018-06-28T23:45:23Z", "closed_at": "2018-06-28T23:45:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Currently we have a mix of actual types when we script/trace a function/module:</p>\n<pre><code>import torch\n\n@torch.jit.script\ndef script_fn(x):\n    return x\n\nprint('*****Script function*****')\nprint(type(script_fn))\nprint(isinstance(script_fn, torch._C.GraphExecutor))\n\n@torch.jit.trace(torch.zeros(3, 3))\ndef trace_fn(x):\n    return x\n\nprint('*****Traced function*****')\nprint(type(trace_fn))\nprint(isinstance(trace_fn, torch._C.GraphExecutor))\n\nclass ScriptModule(torch.jit.ScriptModule):\n    @torch.jit.script_method\n    def forward(self, x):\n        return x\nsm = ScriptModule()\n\nprint('*****Script module*****')\nprint(type(sm))\nprint(isinstance(sm, torch._C.GraphExecutor))\n\nclass TracedModule(torch.nn.Module):\n    def forward(self, x):\n        return x\ntm = torch.jit.trace(torch.zeros(3, 3))(TracedModule())\n\nprint('*****Traced module*****')\nprint(type(tm))\nprint(isinstance(tm, torch._C.GraphExecutor))\n\n</code></pre>\n<pre><code>*****Script function*****\n&lt;class 'torch._C.GraphExecutor'&gt;\nTrue\n*****Traced function*****\n&lt;class 'torch._C.GraphExecutor'&gt;\nTrue\n*****Script module*****\n&lt;class '__main__.ScriptModule'&gt;\nFalse\n*****Traced module*****\n&lt;class 'torch.jit.TopLevelTracedModule'&gt;\nFalse\n</code></pre>\n<p>This causes issues, for example, since we can only inline a <code>PythonValue</code> into a ScriptModule if it's an instance of GraphExecutor(<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/2b926aafb09575dd83ebf4fe2a76cbe239596f0b/torch/csrc/jit/script/init.cpp#L82\">pytorch/torch/csrc/jit/script/init.cpp</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 82\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/2b926aafb09575dd83ebf4fe2a76cbe239596f0b\">2b926aa</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L82\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"82\"></td>\n          <td id=\"LC82\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">if</span>(py::isinstance&lt;GraphExecutor&gt;(self)) { </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n). This causes problems in the case of calling Script/Traced modules from script functions -- they show up as <code>PythonOp</code>s.</p>\n<p>Let's make it so that all of {script,traced} {function,module} produce a Module, and re-work the inlining logic to merge modules in all cases. This will greatly simplify the logic and make things easier to understand and maintain</p>", "body_text": "Currently we have a mix of actual types when we script/trace a function/module:\nimport torch\n\n@torch.jit.script\ndef script_fn(x):\n    return x\n\nprint('*****Script function*****')\nprint(type(script_fn))\nprint(isinstance(script_fn, torch._C.GraphExecutor))\n\n@torch.jit.trace(torch.zeros(3, 3))\ndef trace_fn(x):\n    return x\n\nprint('*****Traced function*****')\nprint(type(trace_fn))\nprint(isinstance(trace_fn, torch._C.GraphExecutor))\n\nclass ScriptModule(torch.jit.ScriptModule):\n    @torch.jit.script_method\n    def forward(self, x):\n        return x\nsm = ScriptModule()\n\nprint('*****Script module*****')\nprint(type(sm))\nprint(isinstance(sm, torch._C.GraphExecutor))\n\nclass TracedModule(torch.nn.Module):\n    def forward(self, x):\n        return x\ntm = torch.jit.trace(torch.zeros(3, 3))(TracedModule())\n\nprint('*****Traced module*****')\nprint(type(tm))\nprint(isinstance(tm, torch._C.GraphExecutor))\n\n\n*****Script function*****\n<class 'torch._C.GraphExecutor'>\nTrue\n*****Traced function*****\n<class 'torch._C.GraphExecutor'>\nTrue\n*****Script module*****\n<class '__main__.ScriptModule'>\nFalse\n*****Traced module*****\n<class 'torch.jit.TopLevelTracedModule'>\nFalse\n\nThis causes issues, for example, since we can only inline a PythonValue into a ScriptModule if it's an instance of GraphExecutor(\n  \n    \n      pytorch/torch/csrc/jit/script/init.cpp\n    \n    \n         Line 82\n      in\n      2b926aa\n    \n    \n    \n    \n\n        \n          \n           if(py::isinstance<GraphExecutor>(self)) { \n        \n    \n  \n\n). This causes problems in the case of calling Script/Traced modules from script functions -- they show up as PythonOps.\nLet's make it so that all of {script,traced} {function,module} produce a Module, and re-work the inlining logic to merge modules in all cases. This will greatly simplify the logic and make things easier to understand and maintain", "body": "Currently we have a mix of actual types when we script/trace a function/module:\r\n\r\n```\r\nimport torch\r\n\r\n@torch.jit.script\r\ndef script_fn(x):\r\n    return x\r\n\r\nprint('*****Script function*****')\r\nprint(type(script_fn))\r\nprint(isinstance(script_fn, torch._C.GraphExecutor))\r\n\r\n@torch.jit.trace(torch.zeros(3, 3))\r\ndef trace_fn(x):\r\n    return x\r\n\r\nprint('*****Traced function*****')\r\nprint(type(trace_fn))\r\nprint(isinstance(trace_fn, torch._C.GraphExecutor))\r\n\r\nclass ScriptModule(torch.jit.ScriptModule):\r\n    @torch.jit.script_method\r\n    def forward(self, x):\r\n        return x\r\nsm = ScriptModule()\r\n\r\nprint('*****Script module*****')\r\nprint(type(sm))\r\nprint(isinstance(sm, torch._C.GraphExecutor))\r\n\r\nclass TracedModule(torch.nn.Module):\r\n    def forward(self, x):\r\n        return x\r\ntm = torch.jit.trace(torch.zeros(3, 3))(TracedModule())\r\n\r\nprint('*****Traced module*****')\r\nprint(type(tm))\r\nprint(isinstance(tm, torch._C.GraphExecutor))\r\n\r\n```\r\n\r\n\r\n```\r\n*****Script function*****\r\n<class 'torch._C.GraphExecutor'>\r\nTrue\r\n*****Traced function*****\r\n<class 'torch._C.GraphExecutor'>\r\nTrue\r\n*****Script module*****\r\n<class '__main__.ScriptModule'>\r\nFalse\r\n*****Traced module*****\r\n<class 'torch.jit.TopLevelTracedModule'>\r\nFalse\r\n```\r\n\r\nThis causes issues, for example, since we can only inline a `PythonValue` into a ScriptModule if it's an instance of GraphExecutor(https://github.com/pytorch/pytorch/blob/2b926aafb09575dd83ebf4fe2a76cbe239596f0b/torch/csrc/jit/script/init.cpp#L82). This causes problems in the case of calling Script/Traced modules from script functions -- they show up as `PythonOp`s.\r\n\r\nLet's make it so that all of {script,traced} {function,module} produce a Module, and re-work the inlining logic to merge modules in all cases. This will greatly simplify the logic and make things easier to understand and maintain"}