{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2408", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2408/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2408/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2408/events", "html_url": "https://github.com/pytorch/pytorch/issues/2408", "id": 249971999, "node_id": "MDU6SXNzdWUyNDk5NzE5OTk=", "number": 2408, "title": "Should treat CPU as one of the CUDA device?", "user": {"login": "xuancong84", "id": 10172392, "node_id": "MDQ6VXNlcjEwMTcyMzky", "avatar_url": "https://avatars0.githubusercontent.com/u/10172392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xuancong84", "html_url": "https://github.com/xuancong84", "followers_url": "https://api.github.com/users/xuancong84/followers", "following_url": "https://api.github.com/users/xuancong84/following{/other_user}", "gists_url": "https://api.github.com/users/xuancong84/gists{/gist_id}", "starred_url": "https://api.github.com/users/xuancong84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xuancong84/subscriptions", "organizations_url": "https://api.github.com/users/xuancong84/orgs", "repos_url": "https://api.github.com/users/xuancong84/repos", "events_url": "https://api.github.com/users/xuancong84/events{/privacy}", "received_events_url": "https://api.github.com/users/xuancong84/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-08-14T09:05:09Z", "updated_at": "2017-08-16T02:44:07Z", "closed_at": "2017-08-15T14:07:36Z", "author_association": "NONE", "body_html": "<p>Currently, torch.cuda.set_device(-1) performs no operation.<br>\nTo be more systematic, I think it would be more convenient to treat cpu as one of the cuda devices, so that after executing torch.cuda.set_device(-1), Tensor.cuda() will transfer the data into CPU memory.</p>\n<p>Otherwise, every time we need to call object.data.new().zero_() in order to allocate an object in the same device. This is because the object can be in any GPU memory or CPU memory, but the function calls are different between GPU and CPU.</p>", "body_text": "Currently, torch.cuda.set_device(-1) performs no operation.\nTo be more systematic, I think it would be more convenient to treat cpu as one of the cuda devices, so that after executing torch.cuda.set_device(-1), Tensor.cuda() will transfer the data into CPU memory.\nOtherwise, every time we need to call object.data.new().zero_() in order to allocate an object in the same device. This is because the object can be in any GPU memory or CPU memory, but the function calls are different between GPU and CPU.", "body": "Currently, torch.cuda.set_device(-1) performs no operation.\r\nTo be more systematic, I think it would be more convenient to treat cpu as one of the cuda devices, so that after executing torch.cuda.set_device(-1), Tensor.cuda() will transfer the data into CPU memory.\r\n\r\nOtherwise, every time we need to call object.data.new().zero_() in order to allocate an object in the same device. This is because the object can be in any GPU memory or CPU memory, but the function calls are different between GPU and CPU."}