{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197289397", "pull_request_review_id": 131007702, "id": 197289397, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzI4OTM5Nw==", "diff_hunk": "@@ -278,58 +287,57 @@ def distributed_data_parallel_hook(*unused):\n \n             # Current device's bucket is full\n             if len(bucket) == self.bucket_sizes[bucket_idx]:\n-                self.devs_ready[bucket_idx].append(device_idx)\n-                if len(self.devs_ready[bucket_idx]) < len(self.device_ids):\n+                self.devs_ready[bucket_idx] += 1\n+                if self.devs_ready[bucket_idx] < len(self.device_ids):\n                     return\n-                #print(\"bucket: {} is full. bucket size: {}\".format(bucket_idx, len(bucket)))\n-                self.buckets_ready.append(bucket_idx)\n-                if len(self.buckets_to_reduce) > 0 and self.buckets_to_reduce[0] == bucket_idx:\n-                    # Reduce the bucket\n-                    self._queue_reduction(bucket_idx)\n-                    self.buckets_to_reduce.pop(0)\n-\n-                # If all buckets are ready\n-                if len(self.buckets_ready) == len(self.bucket_order):\n-                    #print(\"ready # of buckets: {}\".format(self.buckets_ready))\n-                    # In case there are unreduced buckets,reduce them all\n-                    if len(self.buckets_to_reduce) > 0:\n-                        for b_idx in self.buckets_to_reduce:\n-                            self._queue_reduction(b_idx)\n-                    # A final sync for all the reduction works\n-                    self._sync_reduction_works()\n+\n+                if bucket_idx not in self.buckets_ready:", "path": "torch/nn/parallel/distributed_c10d.py", "position": null, "original_position": 83, "commit_id": "25389601de502db312299893f3c69bbe00f4ffca", "original_commit_id": "08e1a377d40afe4d7c6b1d41e3811e950effd56c", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "body": "Can we assert instead? If we hit this twice it must be a logic error.", "created_at": "2018-06-21T21:55:33Z", "updated_at": "2018-11-23T15:46:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/8584#discussion_r197289397", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8584", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197289397"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8584#discussion_r197289397"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8584"}}, "body_html": "<p>Can we assert instead? If we hit this twice it must be a logic error.</p>", "body_text": "Can we assert instead? If we hit this twice it must be a logic error.", "in_reply_to_id": 197277073}