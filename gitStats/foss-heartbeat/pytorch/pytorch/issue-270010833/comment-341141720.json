{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/341141720", "html_url": "https://github.com/pytorch/pytorch/issues/3396#issuecomment-341141720", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3396", "id": 341141720, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTE0MTcyMA==", "user": {"login": "wickedfoo", "id": 1911637, "node_id": "MDQ6VXNlcjE5MTE2Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1911637?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wickedfoo", "html_url": "https://github.com/wickedfoo", "followers_url": "https://api.github.com/users/wickedfoo/followers", "following_url": "https://api.github.com/users/wickedfoo/following{/other_user}", "gists_url": "https://api.github.com/users/wickedfoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/wickedfoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wickedfoo/subscriptions", "organizations_url": "https://api.github.com/users/wickedfoo/orgs", "repos_url": "https://api.github.com/users/wickedfoo/repos", "events_url": "https://api.github.com/users/wickedfoo/events{/privacy}", "received_events_url": "https://api.github.com/users/wickedfoo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-01T15:31:44Z", "updated_at": "2017-11-01T15:31:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>topk is slow when it is not run in the innermost dimension.</p>\n<p>The way for us to fix this within Torch would be to transpose the tensor in temporary memory such that the selection dimension is innermost, run topk, then transpose the results back.</p>\n<p>If there is a reasonably large pool of temporary memory now within Torch (say, 100s of MB), then this approach is worth taking. Suffering the synchronization hit by calling cudaMalloc to get the temporary memory is probably worth taking in this situation as well.</p>", "body_text": "topk is slow when it is not run in the innermost dimension.\nThe way for us to fix this within Torch would be to transpose the tensor in temporary memory such that the selection dimension is innermost, run topk, then transpose the results back.\nIf there is a reasonably large pool of temporary memory now within Torch (say, 100s of MB), then this approach is worth taking. Suffering the synchronization hit by calling cudaMalloc to get the temporary memory is probably worth taking in this situation as well.", "body": "topk is slow when it is not run in the innermost dimension.\r\n\r\nThe way for us to fix this within Torch would be to transpose the tensor in temporary memory such that the selection dimension is innermost, run topk, then transpose the results back.\r\n\r\nIf there is a reasonably large pool of temporary memory now within Torch (say, 100s of MB), then this approach is worth taking. Suffering the synchronization hit by calling cudaMalloc to get the temporary memory is probably worth taking in this situation as well."}