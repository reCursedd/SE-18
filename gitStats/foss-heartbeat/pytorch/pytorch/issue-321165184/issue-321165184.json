{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7372", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7372/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7372/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7372/events", "html_url": "https://github.com/pytorch/pytorch/issues/7372", "id": 321165184, "node_id": "MDU6SXNzdWUzMjExNjUxODQ=", "number": 7372, "title": "Print a warning when PTX JIT compilation occurs", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-08T12:26:54Z", "updated_at": "2018-05-08T22:50:01Z", "closed_at": "2018-05-08T22:50:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Occasionally, we have users building PyTorch from source will be cross-compiling for a GPU which is not present on their machine, and in this case it is very easy to end up in a case where you are running PyTorch without precompiled PTX for the GPU you want. In this case, PyTorch will start very, very slowly (as the PTX compiler JIT compiles PTX for the GPU in question). There isn't any indication that this has occurred unless you happen to know that this is a thing.</p>\n<p>It would be great if there was some way to detect if this has occurred at runtime and print a warning to the user.</p>", "body_text": "Occasionally, we have users building PyTorch from source will be cross-compiling for a GPU which is not present on their machine, and in this case it is very easy to end up in a case where you are running PyTorch without precompiled PTX for the GPU you want. In this case, PyTorch will start very, very slowly (as the PTX compiler JIT compiles PTX for the GPU in question). There isn't any indication that this has occurred unless you happen to know that this is a thing.\nIt would be great if there was some way to detect if this has occurred at runtime and print a warning to the user.", "body": "Occasionally, we have users building PyTorch from source will be cross-compiling for a GPU which is not present on their machine, and in this case it is very easy to end up in a case where you are running PyTorch without precompiled PTX for the GPU you want. In this case, PyTorch will start very, very slowly (as the PTX compiler JIT compiles PTX for the GPU in question). There isn't any indication that this has occurred unless you happen to know that this is a thing.\r\n\r\nIt would be great if there was some way to detect if this has occurred at runtime and print a warning to the user."}