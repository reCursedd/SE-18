{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121264392", "pull_request_review_id": 43304058, "id": 121264392, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTI2NDM5Mg==", "diff_hunk": "@@ -0,0 +1,42 @@\n+#include \"Context.h\"\n+#include <thread>\n+#include <mutex>\n+\n+#ifdef TENSORLIB_CUDA_ENABLED\n+#include \"THC/THC.h\"\n+#include \"TensorLib/CUDAGenerator.h\"\n+#endif\n+#include \"TensorLib/CPUGenerator.h\"\n+\n+namespace tlib {\n+\n+Context::Context() {\n+\n+#ifdef TENSORLIB_CUDA_ENABLED\n+  thc_state = THCState_alloc();", "path": "torch/lib/TensorLib/Context.cpp", "position": null, "original_position": 16, "commit_id": "dadf12e892b69bca8457a4be963fece8328f2393", "original_commit_id": "a5c86f848213f4877fae40e248a0b7b20d25a458", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Not sure how well is it going to play with the code we already have. This will make us have two THCStates, using two separate caching allocators, and two free mutexes, which can lead to deadlocks, and every THCState holds a few hundred MBs of per-GPU state.", "created_at": "2017-06-10T19:17:53Z", "updated_at": "2018-11-23T15:33:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/1766#discussion_r121264392", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1766", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121264392"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1766#discussion_r121264392"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1766"}}, "body_html": "<p>Not sure how well is it going to play with the code we already have. This will make us have two THCStates, using two separate caching allocators, and two free mutexes, which can lead to deadlocks, and every THCState holds a few hundred MBs of per-GPU state.</p>", "body_text": "Not sure how well is it going to play with the code we already have. This will make us have two THCStates, using two separate caching allocators, and two free mutexes, which can lead to deadlocks, and every THCState holds a few hundred MBs of per-GPU state."}