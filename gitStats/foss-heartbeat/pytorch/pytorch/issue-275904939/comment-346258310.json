{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/346258310", "html_url": "https://github.com/pytorch/pytorch/pull/3821#issuecomment-346258310", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3821", "id": 346258310, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NjI1ODMxMA==", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-22T06:45:01Z", "updated_at": "2017-11-22T06:45:01Z", "author_association": "COLLABORATOR", "body_html": "<p>Thank you <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a>. I'm good with sticking to the specification.<br>\nHowever storage is so seldom used explicitly in PyTorch, contrarily to Lua Torch, that it feels like the analogous of the <code>data</code> buffer in NumPy.</p>", "body_text": "Thank you @colesbury. I'm good with sticking to the specification.\nHowever storage is so seldom used explicitly in PyTorch, contrarily to Lua Torch, that it feels like the analogous of the data buffer in NumPy.", "body": "Thank you @colesbury. I'm good with sticking to the specification. \r\nHowever storage is so seldom used explicitly in PyTorch, contrarily to Lua Torch, that it feels like the analogous of the `data` buffer in NumPy."}