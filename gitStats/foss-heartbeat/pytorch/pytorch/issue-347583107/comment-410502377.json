{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/410502377", "html_url": "https://github.com/pytorch/pytorch/issues/10229#issuecomment-410502377", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229", "id": 410502377, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDUwMjM3Nw==", "user": {"login": "Johnccl", "id": 26398121, "node_id": "MDQ6VXNlcjI2Mzk4MTIx", "avatar_url": "https://avatars2.githubusercontent.com/u/26398121?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Johnccl", "html_url": "https://github.com/Johnccl", "followers_url": "https://api.github.com/users/Johnccl/followers", "following_url": "https://api.github.com/users/Johnccl/following{/other_user}", "gists_url": "https://api.github.com/users/Johnccl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Johnccl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Johnccl/subscriptions", "organizations_url": "https://api.github.com/users/Johnccl/orgs", "repos_url": "https://api.github.com/users/Johnccl/repos", "events_url": "https://api.github.com/users/Johnccl/events{/privacy}", "received_events_url": "https://api.github.com/users/Johnccl/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-05T07:45:08Z", "updated_at": "2018-08-05T07:45:08Z", "author_association": "NONE", "body_html": "<p>The timings with new methods are just followed by your advise <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> : <br>\nmy first try is run script with:</p>\n<div class=\"highlight highlight-source-shell\"><pre>CUDA_LAUNCH_BLOCKING=1 python3 speed_test.py</pre></div>\n<p>I also tried to change the timings :</p>\n<div class=\"highlight highlight-source-shell\"><pre>def count(a, m):\n    <span class=\"pl-en\">torch.cuda.synchronize</span>()\n    t0 = <span class=\"pl-en\">time.time</span>()\n    <span class=\"pl-k\">for</span> <span class=\"pl-smi\">i</span> <span class=\"pl-k\">in</span> range(1000):\n        b = m(a)\n    <span class=\"pl-en\">torch.cuda.synchronize</span>()\n    <span class=\"pl-k\">return</span> <span class=\"pl-en\">time.time</span>() - t0</pre></div>\n<p>The result shows that both the two methods take more time in group convolution, only when groups==input_channels it runs very fast (input tensor is (1, 1024, 19, 19)). The output is like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>Pytorch testing:\nOutChannel:256, Group:1, Time:0.49562525749206543\nOutChannel:256, Group:2, Time:0.2684659957885742\nOutChannel:256, Group:4, Time:0.19190192222595215\nOutChannel:256, Group:8, Time:0.23194408416748047\nOutChannel:256, Group:16, Time:0.3203761577606201\nOutChannel:256, Group:32, Time:0.5373902320861816\nOutChannel:256, Group:64, Time:0.9720823764801025\nOutChannel:256, Group:128, Time:1.801313877105713\nOutChannel:256, Group:256, Time:3.6272590160369873\nOutChannel:512, Group:1, Time:1.0002150535583496\nOutChannel:512, Group:2, Time:0.4958508014678955\nOutChannel:512, Group:4, Time:0.2823457717895508\nOutChannel:512, Group:8, Time:0.24367904663085938\nOutChannel:512, Group:16, Time:0.3579528331756592\nOutChannel:512, Group:32, Time:0.5675616264343262\nOutChannel:512, Group:64, Time:0.9823338985443115\nOutChannel:512, Group:128, Time:1.8257930278778076\nOutChannel:512, Group:256, Time:3.641608476638794\nOutChannel:512, Group:512, Time:7.346875190734863\nOutChannel:1024, Group:1, Time:2.176182746887207\nOutChannel:1024, Group:2, Time:1.009695291519165\nOutChannel:1024, Group:4, Time:0.5244359970092773\nOutChannel:1024, Group:8, Time:0.363513708114624\nOutChannel:1024, Group:16, Time:0.3781554698944092\nOutChannel:1024, Group:32, Time:0.5965301990509033\nOutChannel:1024, Group:64, Time:1.01088547706604\nOutChannel:1024, Group:128, Time:1.898212194442749\nOutChannel:1024, Group:256, Time:3.7377984523773193\nOutChannel:1024, Group:512, Time:7.350734233856201\nOutChannel:1024, Group:1024, Time:0.044171810150146484\nOutChannel:2048, Group:1, Time:4.684430837631226\nOutChannel:2048, Group:2, Time:2.1917829513549805\nOutChannel:2048, Group:4, Time:1.1301765441894531\nOutChannel:2048, Group:8, Time:0.6398894786834717\nOutChannel:2048, Group:16, Time:0.5236623287200928\nOutChannel:2048, Group:32, Time:0.6961493492126465\nOutChannel:2048, Group:64, Time:1.1796467304229736\nOutChannel:2048, Group:128, Time:2.0464370250701904\nOutChannel:2048, Group:256, Time:3.7772271633148193\nOutChannel:2048, Group:512, Time:7.414055824279785\nOutChannel:2048, Group:1024, Time:0.09024667739868164</pre></div>\n<p>And here is the information of my pytorch:</p>\n<ul>\n<li>I installed pytorch by: sudo pip3 install torch</li>\n<li>The mxnet was compiled by source</li>\n<li>the output of python3 collect_env.py is</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>Collecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Ubuntu 14.04.3 LTS\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4\nCMake version: version 3.5.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: GPU 0: GeForce GTX TITAN X\nNvidia driver version: 375.66\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7\n/usr/local/cuda-7.5/lib64/libcudnn.so.5.1.3\n/usr/local/cuda-7.5/lib64/libcudnn_static.a\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect</pre></div>\n<p>I checked cudnn version by: cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2. It's version is 5.0.5.<br>\nAny advise? Thank you.</p>", "body_text": "The timings with new methods are just followed by your advise @soumith : \nmy first try is run script with:\nCUDA_LAUNCH_BLOCKING=1 python3 speed_test.py\nI also tried to change the timings :\ndef count(a, m):\n    torch.cuda.synchronize()\n    t0 = time.time()\n    for i in range(1000):\n        b = m(a)\n    torch.cuda.synchronize()\n    return time.time() - t0\nThe result shows that both the two methods take more time in group convolution, only when groups==input_channels it runs very fast (input tensor is (1, 1024, 19, 19)). The output is like this:\nPytorch testing:\nOutChannel:256, Group:1, Time:0.49562525749206543\nOutChannel:256, Group:2, Time:0.2684659957885742\nOutChannel:256, Group:4, Time:0.19190192222595215\nOutChannel:256, Group:8, Time:0.23194408416748047\nOutChannel:256, Group:16, Time:0.3203761577606201\nOutChannel:256, Group:32, Time:0.5373902320861816\nOutChannel:256, Group:64, Time:0.9720823764801025\nOutChannel:256, Group:128, Time:1.801313877105713\nOutChannel:256, Group:256, Time:3.6272590160369873\nOutChannel:512, Group:1, Time:1.0002150535583496\nOutChannel:512, Group:2, Time:0.4958508014678955\nOutChannel:512, Group:4, Time:0.2823457717895508\nOutChannel:512, Group:8, Time:0.24367904663085938\nOutChannel:512, Group:16, Time:0.3579528331756592\nOutChannel:512, Group:32, Time:0.5675616264343262\nOutChannel:512, Group:64, Time:0.9823338985443115\nOutChannel:512, Group:128, Time:1.8257930278778076\nOutChannel:512, Group:256, Time:3.641608476638794\nOutChannel:512, Group:512, Time:7.346875190734863\nOutChannel:1024, Group:1, Time:2.176182746887207\nOutChannel:1024, Group:2, Time:1.009695291519165\nOutChannel:1024, Group:4, Time:0.5244359970092773\nOutChannel:1024, Group:8, Time:0.363513708114624\nOutChannel:1024, Group:16, Time:0.3781554698944092\nOutChannel:1024, Group:32, Time:0.5965301990509033\nOutChannel:1024, Group:64, Time:1.01088547706604\nOutChannel:1024, Group:128, Time:1.898212194442749\nOutChannel:1024, Group:256, Time:3.7377984523773193\nOutChannel:1024, Group:512, Time:7.350734233856201\nOutChannel:1024, Group:1024, Time:0.044171810150146484\nOutChannel:2048, Group:1, Time:4.684430837631226\nOutChannel:2048, Group:2, Time:2.1917829513549805\nOutChannel:2048, Group:4, Time:1.1301765441894531\nOutChannel:2048, Group:8, Time:0.6398894786834717\nOutChannel:2048, Group:16, Time:0.5236623287200928\nOutChannel:2048, Group:32, Time:0.6961493492126465\nOutChannel:2048, Group:64, Time:1.1796467304229736\nOutChannel:2048, Group:128, Time:2.0464370250701904\nOutChannel:2048, Group:256, Time:3.7772271633148193\nOutChannel:2048, Group:512, Time:7.414055824279785\nOutChannel:2048, Group:1024, Time:0.09024667739868164\nAnd here is the information of my pytorch:\n\nI installed pytorch by: sudo pip3 install torch\nThe mxnet was compiled by source\nthe output of python3 collect_env.py is\n\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Ubuntu 14.04.3 LTS\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4\nCMake version: version 3.5.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: GPU 0: GeForce GTX TITAN X\nNvidia driver version: 375.66\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7\n/usr/local/cuda-7.5/lib64/libcudnn.so.5.1.3\n/usr/local/cuda-7.5/lib64/libcudnn_static.a\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect\nI checked cudnn version by: cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2. It's version is 5.0.5.\nAny advise? Thank you.", "body": "The timings with new methods are just followed by your advise @soumith : \\\r\nmy first try is run script with:\r\n```Shell\r\nCUDA_LAUNCH_BLOCKING=1 python3 speed_test.py\r\n```\r\nI also tried to change the timings :\r\n```Shell\r\ndef count(a, m):\r\n    torch.cuda.synchronize()\r\n    t0 = time.time()\r\n    for i in range(1000):\r\n        b = m(a)\r\n    torch.cuda.synchronize()\r\n    return time.time() - t0\r\n```\r\nThe result shows that both the two methods take more time in group convolution, only when groups==input_channels it runs very fast (input tensor is (1, 1024, 19, 19)). The output is like this:\r\n```Shell\r\nPytorch testing:\r\nOutChannel:256, Group:1, Time:0.49562525749206543\r\nOutChannel:256, Group:2, Time:0.2684659957885742\r\nOutChannel:256, Group:4, Time:0.19190192222595215\r\nOutChannel:256, Group:8, Time:0.23194408416748047\r\nOutChannel:256, Group:16, Time:0.3203761577606201\r\nOutChannel:256, Group:32, Time:0.5373902320861816\r\nOutChannel:256, Group:64, Time:0.9720823764801025\r\nOutChannel:256, Group:128, Time:1.801313877105713\r\nOutChannel:256, Group:256, Time:3.6272590160369873\r\nOutChannel:512, Group:1, Time:1.0002150535583496\r\nOutChannel:512, Group:2, Time:0.4958508014678955\r\nOutChannel:512, Group:4, Time:0.2823457717895508\r\nOutChannel:512, Group:8, Time:0.24367904663085938\r\nOutChannel:512, Group:16, Time:0.3579528331756592\r\nOutChannel:512, Group:32, Time:0.5675616264343262\r\nOutChannel:512, Group:64, Time:0.9823338985443115\r\nOutChannel:512, Group:128, Time:1.8257930278778076\r\nOutChannel:512, Group:256, Time:3.641608476638794\r\nOutChannel:512, Group:512, Time:7.346875190734863\r\nOutChannel:1024, Group:1, Time:2.176182746887207\r\nOutChannel:1024, Group:2, Time:1.009695291519165\r\nOutChannel:1024, Group:4, Time:0.5244359970092773\r\nOutChannel:1024, Group:8, Time:0.363513708114624\r\nOutChannel:1024, Group:16, Time:0.3781554698944092\r\nOutChannel:1024, Group:32, Time:0.5965301990509033\r\nOutChannel:1024, Group:64, Time:1.01088547706604\r\nOutChannel:1024, Group:128, Time:1.898212194442749\r\nOutChannel:1024, Group:256, Time:3.7377984523773193\r\nOutChannel:1024, Group:512, Time:7.350734233856201\r\nOutChannel:1024, Group:1024, Time:0.044171810150146484\r\nOutChannel:2048, Group:1, Time:4.684430837631226\r\nOutChannel:2048, Group:2, Time:2.1917829513549805\r\nOutChannel:2048, Group:4, Time:1.1301765441894531\r\nOutChannel:2048, Group:8, Time:0.6398894786834717\r\nOutChannel:2048, Group:16, Time:0.5236623287200928\r\nOutChannel:2048, Group:32, Time:0.6961493492126465\r\nOutChannel:2048, Group:64, Time:1.1796467304229736\r\nOutChannel:2048, Group:128, Time:2.0464370250701904\r\nOutChannel:2048, Group:256, Time:3.7772271633148193\r\nOutChannel:2048, Group:512, Time:7.414055824279785\r\nOutChannel:2048, Group:1024, Time:0.09024667739868164\r\n```\r\nAnd here is the information of my pytorch:\r\n- I installed pytorch by: sudo pip3 install torch\r\n- The mxnet was compiled by source\r\n- the output of python3 collect_env.py is\r\n```Shell\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 14.04.3 LTS\r\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4\r\nCMake version: version 3.5.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: GPU 0: GeForce GTX TITAN X\r\nNvidia driver version: 375.66\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21\r\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudnn.so.4.0.7\r\n/usr/local/cuda-7.5/lib64/libcudnn.so.5.1.3\r\n/usr/local/cuda-7.5/lib64/libcudnn_static.a\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\r\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-900fef33.so.7.0.5\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n```\r\nI checked cudnn version by: cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2. It's version is 5.0.5.\r\nAny advise? Thank you."}