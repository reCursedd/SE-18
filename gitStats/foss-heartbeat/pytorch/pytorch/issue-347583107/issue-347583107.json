{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10229", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229/events", "html_url": "https://github.com/pytorch/pytorch/issues/10229", "id": 347583107, "node_id": "MDU6SXNzdWUzNDc1ODMxMDc=", "number": 10229, "title": "Speed of group convolution", "user": {"login": "Johnccl", "id": 26398121, "node_id": "MDQ6VXNlcjI2Mzk4MTIx", "avatar_url": "https://avatars2.githubusercontent.com/u/26398121?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Johnccl", "html_url": "https://github.com/Johnccl", "followers_url": "https://api.github.com/users/Johnccl/followers", "following_url": "https://api.github.com/users/Johnccl/following{/other_user}", "gists_url": "https://api.github.com/users/Johnccl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Johnccl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Johnccl/subscriptions", "organizations_url": "https://api.github.com/users/Johnccl/orgs", "repos_url": "https://api.github.com/users/Johnccl/repos", "events_url": "https://api.github.com/users/Johnccl/events{/privacy}", "received_events_url": "https://api.github.com/users/Johnccl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2018-08-04T03:39:03Z", "updated_at": "2018-08-14T18:15:18Z", "closed_at": "2018-08-14T18:15:18Z", "author_association": "NONE", "body_html": "<p>I'm trying to use group convolution in my model, but I find that the speed of group convolution layer is too slow. I tested different groups settings on titan x maxwell. The result shows that when groups==input_channels, the speed is very fast even with different output_channels. But other groups will slow down the forward heavily. Here is my test code, if I was wrong, please correct me.</p>\n<div class=\"highlight highlight-source-shell\"><pre>import <span class=\"pl-k\">time</span>\nimport math\n\n\ndef count(a, m):\n    t0 = <span class=\"pl-en\">time.time</span>()\n    <span class=\"pl-k\">for</span> <span class=\"pl-smi\">i</span> <span class=\"pl-k\">in</span> range(1000):\n        b = m(a)\n    <span class=\"pl-k\">return</span> <span class=\"pl-en\">time.time</span>() - t0\n\ndef th_test(in_channel=1024, size=19, batch=1):\n    import torch as th\n    import torch.nn as nn\n    x = th.rand<span class=\"pl-s\"><span class=\"pl-pds\">((</span>batch<span class=\"pl-k\">,</span> in_channel<span class=\"pl-k\">,</span> size<span class=\"pl-k\">,</span> size<span class=\"pl-pds\">))</span></span>\n    x = <span class=\"pl-en\">x.cuda</span>()\n    out_channels_lsit = [256, 512, 1024, 2048]\n    <span class=\"pl-k\">for</span> <span class=\"pl-smi\">out_channels</span> <span class=\"pl-k\">in</span> out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2))+1\n        <span class=\"pl-k\">for</span> <span class=\"pl-smi\">i</span> <span class=\"pl-k\">in</span> range(n):\n            g = int(math.pow(2, i))\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\n            t = count(x, m)\n            print(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>OutChannel:{}, Group:{}, Time:{}<span class=\"pl-pds\">'</span></span>.format(out_channels, g, t))\n\ndef mx_test(in_channel=1024, size=19, batch=1):\n    import mxnet as mx\n    import mxnet.ndarray as nd\n    from mxnet.gluon import nn\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\n\n    out_channels_lsit = [256, 512, 1024, 2048]\n    <span class=\"pl-k\">for</span> <span class=\"pl-smi\">out_channels</span> <span class=\"pl-k\">in</span> out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\n        <span class=\"pl-k\">for</span> <span class=\"pl-smi\">i</span> <span class=\"pl-k\">in</span> range(n):\n            g = int(math.pow(2, i))\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\n            m.initialize(ctx=[mx.gpu(0)])\n            t = count(x, m)\n            print(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>OutChannel:{}, Group:{}, Time:{}<span class=\"pl-pds\">'</span></span>.format(out_channels, g, t))\n\n<span class=\"pl-k\">if</span> __name__==<span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    print(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Pytorch testing:<span class=\"pl-pds\">'</span></span>)\n    th_test(1024, 19, 1)\n    print(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Mxnet testing:<span class=\"pl-pds\">'</span></span>)\n    mx_test(1024, 19, 1)</pre></div>\n<p>The input tensor is (1, 1024, 19, 19), and the output is:</p>\n<div class=\"highlight highlight-source-shell\"><pre>Pytorch testing:\nOutChannel:256, Group:1, Time:0.33240747451782227\nOutChannel:256, Group:2, Time:0.20134592056274414\nOutChannel:256, Group:4, Time:0.17717289924621582\nOutChannel:256, Group:8, Time:0.22671079635620117\nOutChannel:256, Group:16, Time:0.31947803497314453\nOutChannel:256, Group:32, Time:0.5367441177368164\nOutChannel:256, Group:64, Time:1.0223586559295654\nOutChannel:256, Group:128, Time:1.7879347801208496\nOutChannel:256, Group:256, Time:3.656572103500366\nOutChannel:512, Group:1, Time:0.6438479423522949\nOutChannel:512, Group:2, Time:0.39124298095703125\nOutChannel:512, Group:4, Time:0.2587141990661621\nOutChannel:512, Group:8, Time:0.2279491424560547\nOutChannel:512, Group:16, Time:0.3441953659057617\nOutChannel:512, Group:32, Time:0.5649154186248779\nOutChannel:512, Group:64, Time:0.9861962795257568\nOutChannel:512, Group:128, Time:1.8548946380615234\nOutChannel:512, Group:256, Time:3.8017823696136475\nOutChannel:512, Group:512, Time:7.314914703369141\nOutChannel:1024, Group:1, Time:1.4008221626281738\nOutChannel:1024, Group:2, Time:0.7930033206939697\nOutChannel:1024, Group:4, Time:0.46567654609680176\nOutChannel:1024, Group:8, Time:0.34047675132751465\nOutChannel:1024, Group:16, Time:0.3591480255126953\nOutChannel:1024, Group:32, Time:0.5814201831817627\nOutChannel:1024, Group:64, Time:1.0014891624450684\nOutChannel:1024, Group:128, Time:1.896963119506836\nOutChannel:1024, Group:256, Time:3.7428271770477295\nOutChannel:1024, Group:512, Time:7.297173023223877\nOutChannel:1024, Group:1024, Time:0.03275704383850098\nOutChannel:2048, Group:1, Time:3.1169140338897705\nOutChannel:2048, Group:2, Time:1.7458274364471436\nOutChannel:2048, Group:4, Time:0.9465909004211426\nOutChannel:2048, Group:8, Time:0.5486705303192139\nOutChannel:2048, Group:16, Time:0.4627697467803955\nOutChannel:2048, Group:32, Time:0.6334977149963379\nOutChannel:2048, Group:64, Time:1.0478804111480713\nOutChannel:2048, Group:128, Time:1.9274232387542725\nOutChannel:2048, Group:256, Time:3.762500524520874\nOutChannel:2048, Group:512, Time:7.371256113052368\nOutChannel:2048, Group:1024, Time:0.032269954681396484\nMxnet testing:\nOutChannel:256, Group:1, Time:0.09648561477661133\nOutChannel:256, Group:2, Time:0.09166908264160156\nOutChannel:256, Group:4, Time:0.1002199649810791\nOutChannel:256, Group:8, Time:0.09164929389953613\nOutChannel:256, Group:16, Time:0.09277224540710449\nOutChannel:256, Group:32, Time:0.09213089942932129\nOutChannel:256, Group:64, Time:0.09251523017883301\nOutChannel:256, Group:128, Time:0.09215164184570312\nOutChannel:256, Group:256, Time:0.09244847297668457\nOutChannel:512, Group:1, Time:0.09291553497314453\nOutChannel:512, Group:2, Time:0.0935969352722168\nOutChannel:512, Group:4, Time:0.09287786483764648\nOutChannel:512, Group:8, Time:0.09386038780212402\nOutChannel:512, Group:16, Time:0.09314537048339844\nOutChannel:512, Group:32, Time:0.09238576889038086\nOutChannel:512, Group:64, Time:0.09345221519470215\nOutChannel:512, Group:128, Time:0.09265351295471191\nOutChannel:512, Group:256, Time:0.09274530410766602\nOutChannel:512, Group:512, Time:0.0929572582244873\nOutChannel:1024, Group:1, Time:0.09283661842346191\nOutChannel:1024, Group:2, Time:0.0920555591583252\nOutChannel:1024, Group:4, Time:0.09308600425720215\nOutChannel:1024, Group:8, Time:0.09451031684875488\nOutChannel:1024, Group:16, Time:0.09326553344726562\nOutChannel:1024, Group:32, Time:0.09737563133239746\nOutChannel:1024, Group:64, Time:0.09368896484375\nOutChannel:1024, Group:128, Time:0.09325265884399414\nOutChannel:1024, Group:256, Time:0.09457755088806152\nOutChannel:1024, Group:512, Time:0.0924680233001709\nOutChannel:1024, Group:1024, Time:0.09270071983337402\nOutChannel:2048, Group:1, Time:0.09429264068603516\nOutChannel:2048, Group:2, Time:0.09288167953491211\nOutChannel:2048, Group:4, Time:0.09360265731811523\nOutChannel:2048, Group:8, Time:0.10918331146240234\nOutChannel:2048, Group:16, Time:0.10007429122924805\nOutChannel:2048, Group:32, Time:0.09536433219909668\nOutChannel:2048, Group:64, Time:0.09516191482543945\nOutChannel:2048, Group:128, Time:0.09293746948242188\nOutChannel:2048, Group:256, Time:0.09230923652648926\nOutChannel:2048, Group:512, Time:0.09552860260009766\nOutChannel:2048, Group:1024, Time:0.09382128715515137</pre></div>\n<p>I noticed that the groups is very sensitive to pytoch, why is this happened? Is there anything I missed? Please correct me. Thanks.</p>", "body_text": "I'm trying to use group convolution in my model, but I find that the speed of group convolution layer is too slow. I tested different groups settings on titan x maxwell. The result shows that when groups==input_channels, the speed is very fast even with different output_channels. But other groups will slow down the forward heavily. Here is my test code, if I was wrong, please correct me.\nimport time\nimport math\n\n\ndef count(a, m):\n    t0 = time.time()\n    for i in range(1000):\n        b = m(a)\n    return time.time() - t0\n\ndef th_test(in_channel=1024, size=19, batch=1):\n    import torch as th\n    import torch.nn as nn\n    x = th.rand((batch, in_channel, size, size))\n    x = x.cuda()\n    out_channels_lsit = [256, 512, 1024, 2048]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2))+1\n        for i in range(n):\n            g = int(math.pow(2, i))\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\ndef mx_test(in_channel=1024, size=19, batch=1):\n    import mxnet as mx\n    import mxnet.ndarray as nd\n    from mxnet.gluon import nn\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\n\n    out_channels_lsit = [256, 512, 1024, 2048]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\n        for i in range(n):\n            g = int(math.pow(2, i))\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\n            m.initialize(ctx=[mx.gpu(0)])\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\nif __name__=='__main__':\n    print('Pytorch testing:')\n    th_test(1024, 19, 1)\n    print('Mxnet testing:')\n    mx_test(1024, 19, 1)\nThe input tensor is (1, 1024, 19, 19), and the output is:\nPytorch testing:\nOutChannel:256, Group:1, Time:0.33240747451782227\nOutChannel:256, Group:2, Time:0.20134592056274414\nOutChannel:256, Group:4, Time:0.17717289924621582\nOutChannel:256, Group:8, Time:0.22671079635620117\nOutChannel:256, Group:16, Time:0.31947803497314453\nOutChannel:256, Group:32, Time:0.5367441177368164\nOutChannel:256, Group:64, Time:1.0223586559295654\nOutChannel:256, Group:128, Time:1.7879347801208496\nOutChannel:256, Group:256, Time:3.656572103500366\nOutChannel:512, Group:1, Time:0.6438479423522949\nOutChannel:512, Group:2, Time:0.39124298095703125\nOutChannel:512, Group:4, Time:0.2587141990661621\nOutChannel:512, Group:8, Time:0.2279491424560547\nOutChannel:512, Group:16, Time:0.3441953659057617\nOutChannel:512, Group:32, Time:0.5649154186248779\nOutChannel:512, Group:64, Time:0.9861962795257568\nOutChannel:512, Group:128, Time:1.8548946380615234\nOutChannel:512, Group:256, Time:3.8017823696136475\nOutChannel:512, Group:512, Time:7.314914703369141\nOutChannel:1024, Group:1, Time:1.4008221626281738\nOutChannel:1024, Group:2, Time:0.7930033206939697\nOutChannel:1024, Group:4, Time:0.46567654609680176\nOutChannel:1024, Group:8, Time:0.34047675132751465\nOutChannel:1024, Group:16, Time:0.3591480255126953\nOutChannel:1024, Group:32, Time:0.5814201831817627\nOutChannel:1024, Group:64, Time:1.0014891624450684\nOutChannel:1024, Group:128, Time:1.896963119506836\nOutChannel:1024, Group:256, Time:3.7428271770477295\nOutChannel:1024, Group:512, Time:7.297173023223877\nOutChannel:1024, Group:1024, Time:0.03275704383850098\nOutChannel:2048, Group:1, Time:3.1169140338897705\nOutChannel:2048, Group:2, Time:1.7458274364471436\nOutChannel:2048, Group:4, Time:0.9465909004211426\nOutChannel:2048, Group:8, Time:0.5486705303192139\nOutChannel:2048, Group:16, Time:0.4627697467803955\nOutChannel:2048, Group:32, Time:0.6334977149963379\nOutChannel:2048, Group:64, Time:1.0478804111480713\nOutChannel:2048, Group:128, Time:1.9274232387542725\nOutChannel:2048, Group:256, Time:3.762500524520874\nOutChannel:2048, Group:512, Time:7.371256113052368\nOutChannel:2048, Group:1024, Time:0.032269954681396484\nMxnet testing:\nOutChannel:256, Group:1, Time:0.09648561477661133\nOutChannel:256, Group:2, Time:0.09166908264160156\nOutChannel:256, Group:4, Time:0.1002199649810791\nOutChannel:256, Group:8, Time:0.09164929389953613\nOutChannel:256, Group:16, Time:0.09277224540710449\nOutChannel:256, Group:32, Time:0.09213089942932129\nOutChannel:256, Group:64, Time:0.09251523017883301\nOutChannel:256, Group:128, Time:0.09215164184570312\nOutChannel:256, Group:256, Time:0.09244847297668457\nOutChannel:512, Group:1, Time:0.09291553497314453\nOutChannel:512, Group:2, Time:0.0935969352722168\nOutChannel:512, Group:4, Time:0.09287786483764648\nOutChannel:512, Group:8, Time:0.09386038780212402\nOutChannel:512, Group:16, Time:0.09314537048339844\nOutChannel:512, Group:32, Time:0.09238576889038086\nOutChannel:512, Group:64, Time:0.09345221519470215\nOutChannel:512, Group:128, Time:0.09265351295471191\nOutChannel:512, Group:256, Time:0.09274530410766602\nOutChannel:512, Group:512, Time:0.0929572582244873\nOutChannel:1024, Group:1, Time:0.09283661842346191\nOutChannel:1024, Group:2, Time:0.0920555591583252\nOutChannel:1024, Group:4, Time:0.09308600425720215\nOutChannel:1024, Group:8, Time:0.09451031684875488\nOutChannel:1024, Group:16, Time:0.09326553344726562\nOutChannel:1024, Group:32, Time:0.09737563133239746\nOutChannel:1024, Group:64, Time:0.09368896484375\nOutChannel:1024, Group:128, Time:0.09325265884399414\nOutChannel:1024, Group:256, Time:0.09457755088806152\nOutChannel:1024, Group:512, Time:0.0924680233001709\nOutChannel:1024, Group:1024, Time:0.09270071983337402\nOutChannel:2048, Group:1, Time:0.09429264068603516\nOutChannel:2048, Group:2, Time:0.09288167953491211\nOutChannel:2048, Group:4, Time:0.09360265731811523\nOutChannel:2048, Group:8, Time:0.10918331146240234\nOutChannel:2048, Group:16, Time:0.10007429122924805\nOutChannel:2048, Group:32, Time:0.09536433219909668\nOutChannel:2048, Group:64, Time:0.09516191482543945\nOutChannel:2048, Group:128, Time:0.09293746948242188\nOutChannel:2048, Group:256, Time:0.09230923652648926\nOutChannel:2048, Group:512, Time:0.09552860260009766\nOutChannel:2048, Group:1024, Time:0.09382128715515137\nI noticed that the groups is very sensitive to pytoch, why is this happened? Is there anything I missed? Please correct me. Thanks.", "body": "I'm trying to use group convolution in my model, but I find that the speed of group convolution layer is too slow. I tested different groups settings on titan x maxwell. The result shows that when groups==input_channels, the speed is very fast even with different output_channels. But other groups will slow down the forward heavily. Here is my test code, if I was wrong, please correct me.\r\n```Shell\r\nimport time\r\nimport math\r\n\r\n\r\ndef count(a, m):\r\n    t0 = time.time()\r\n    for i in range(1000):\r\n        b = m(a)\r\n    return time.time() - t0\r\n\r\ndef th_test(in_channel=1024, size=19, batch=1):\r\n    import torch as th\r\n    import torch.nn as nn\r\n    x = th.rand((batch, in_channel, size, size))\r\n    x = x.cuda()\r\n    out_channels_lsit = [256, 512, 1024, 2048]\r\n    for out_channels in out_channels_lsit:\r\n        n = int(math.log(min(in_channel, out_channels), 2))+1\r\n        for i in range(n):\r\n            g = int(math.pow(2, i))\r\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\r\n            t = count(x, m)\r\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\r\n\r\ndef mx_test(in_channel=1024, size=19, batch=1):\r\n    import mxnet as mx\r\n    import mxnet.ndarray as nd\r\n    from mxnet.gluon import nn\r\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\r\n\r\n    out_channels_lsit = [256, 512, 1024, 2048]\r\n    for out_channels in out_channels_lsit:\r\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\r\n        for i in range(n):\r\n            g = int(math.pow(2, i))\r\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\r\n            m.initialize(ctx=[mx.gpu(0)])\r\n            t = count(x, m)\r\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\r\n\r\nif __name__=='__main__':\r\n    print('Pytorch testing:')\r\n    th_test(1024, 19, 1)\r\n    print('Mxnet testing:')\r\n    mx_test(1024, 19, 1)\r\n```\r\nThe input tensor is (1, 1024, 19, 19), and the output is:\r\n```Shell\r\nPytorch testing:\r\nOutChannel:256, Group:1, Time:0.33240747451782227\r\nOutChannel:256, Group:2, Time:0.20134592056274414\r\nOutChannel:256, Group:4, Time:0.17717289924621582\r\nOutChannel:256, Group:8, Time:0.22671079635620117\r\nOutChannel:256, Group:16, Time:0.31947803497314453\r\nOutChannel:256, Group:32, Time:0.5367441177368164\r\nOutChannel:256, Group:64, Time:1.0223586559295654\r\nOutChannel:256, Group:128, Time:1.7879347801208496\r\nOutChannel:256, Group:256, Time:3.656572103500366\r\nOutChannel:512, Group:1, Time:0.6438479423522949\r\nOutChannel:512, Group:2, Time:0.39124298095703125\r\nOutChannel:512, Group:4, Time:0.2587141990661621\r\nOutChannel:512, Group:8, Time:0.2279491424560547\r\nOutChannel:512, Group:16, Time:0.3441953659057617\r\nOutChannel:512, Group:32, Time:0.5649154186248779\r\nOutChannel:512, Group:64, Time:0.9861962795257568\r\nOutChannel:512, Group:128, Time:1.8548946380615234\r\nOutChannel:512, Group:256, Time:3.8017823696136475\r\nOutChannel:512, Group:512, Time:7.314914703369141\r\nOutChannel:1024, Group:1, Time:1.4008221626281738\r\nOutChannel:1024, Group:2, Time:0.7930033206939697\r\nOutChannel:1024, Group:4, Time:0.46567654609680176\r\nOutChannel:1024, Group:8, Time:0.34047675132751465\r\nOutChannel:1024, Group:16, Time:0.3591480255126953\r\nOutChannel:1024, Group:32, Time:0.5814201831817627\r\nOutChannel:1024, Group:64, Time:1.0014891624450684\r\nOutChannel:1024, Group:128, Time:1.896963119506836\r\nOutChannel:1024, Group:256, Time:3.7428271770477295\r\nOutChannel:1024, Group:512, Time:7.297173023223877\r\nOutChannel:1024, Group:1024, Time:0.03275704383850098\r\nOutChannel:2048, Group:1, Time:3.1169140338897705\r\nOutChannel:2048, Group:2, Time:1.7458274364471436\r\nOutChannel:2048, Group:4, Time:0.9465909004211426\r\nOutChannel:2048, Group:8, Time:0.5486705303192139\r\nOutChannel:2048, Group:16, Time:0.4627697467803955\r\nOutChannel:2048, Group:32, Time:0.6334977149963379\r\nOutChannel:2048, Group:64, Time:1.0478804111480713\r\nOutChannel:2048, Group:128, Time:1.9274232387542725\r\nOutChannel:2048, Group:256, Time:3.762500524520874\r\nOutChannel:2048, Group:512, Time:7.371256113052368\r\nOutChannel:2048, Group:1024, Time:0.032269954681396484\r\nMxnet testing:\r\nOutChannel:256, Group:1, Time:0.09648561477661133\r\nOutChannel:256, Group:2, Time:0.09166908264160156\r\nOutChannel:256, Group:4, Time:0.1002199649810791\r\nOutChannel:256, Group:8, Time:0.09164929389953613\r\nOutChannel:256, Group:16, Time:0.09277224540710449\r\nOutChannel:256, Group:32, Time:0.09213089942932129\r\nOutChannel:256, Group:64, Time:0.09251523017883301\r\nOutChannel:256, Group:128, Time:0.09215164184570312\r\nOutChannel:256, Group:256, Time:0.09244847297668457\r\nOutChannel:512, Group:1, Time:0.09291553497314453\r\nOutChannel:512, Group:2, Time:0.0935969352722168\r\nOutChannel:512, Group:4, Time:0.09287786483764648\r\nOutChannel:512, Group:8, Time:0.09386038780212402\r\nOutChannel:512, Group:16, Time:0.09314537048339844\r\nOutChannel:512, Group:32, Time:0.09238576889038086\r\nOutChannel:512, Group:64, Time:0.09345221519470215\r\nOutChannel:512, Group:128, Time:0.09265351295471191\r\nOutChannel:512, Group:256, Time:0.09274530410766602\r\nOutChannel:512, Group:512, Time:0.0929572582244873\r\nOutChannel:1024, Group:1, Time:0.09283661842346191\r\nOutChannel:1024, Group:2, Time:0.0920555591583252\r\nOutChannel:1024, Group:4, Time:0.09308600425720215\r\nOutChannel:1024, Group:8, Time:0.09451031684875488\r\nOutChannel:1024, Group:16, Time:0.09326553344726562\r\nOutChannel:1024, Group:32, Time:0.09737563133239746\r\nOutChannel:1024, Group:64, Time:0.09368896484375\r\nOutChannel:1024, Group:128, Time:0.09325265884399414\r\nOutChannel:1024, Group:256, Time:0.09457755088806152\r\nOutChannel:1024, Group:512, Time:0.0924680233001709\r\nOutChannel:1024, Group:1024, Time:0.09270071983337402\r\nOutChannel:2048, Group:1, Time:0.09429264068603516\r\nOutChannel:2048, Group:2, Time:0.09288167953491211\r\nOutChannel:2048, Group:4, Time:0.09360265731811523\r\nOutChannel:2048, Group:8, Time:0.10918331146240234\r\nOutChannel:2048, Group:16, Time:0.10007429122924805\r\nOutChannel:2048, Group:32, Time:0.09536433219909668\r\nOutChannel:2048, Group:64, Time:0.09516191482543945\r\nOutChannel:2048, Group:128, Time:0.09293746948242188\r\nOutChannel:2048, Group:256, Time:0.09230923652648926\r\nOutChannel:2048, Group:512, Time:0.09552860260009766\r\nOutChannel:2048, Group:1024, Time:0.09382128715515137\r\n```\r\nI noticed that the groups is very sensitive to pytoch, why is this happened? Is there anything I missed? Please correct me. Thanks."}