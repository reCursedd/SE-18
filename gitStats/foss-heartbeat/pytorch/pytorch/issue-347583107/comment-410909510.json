{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/410909510", "html_url": "https://github.com/pytorch/pytorch/issues/10229#issuecomment-410909510", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229", "id": 410909510, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDkwOTUxMA==", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-07T02:08:30Z", "updated_at": "2018-08-07T02:10:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I can repro a similar perf with cuda9.0 cudnn7.0.<br>\nI profiled both pytorch and mxnet on a single input(in_channel=1024, size=19, batch=1, kernel_size=3, padding=1). outchannel=64, group=1<br>\nFor Pytorch, we have 92% compute spent on <code>maxwell_scudnn_winograd_128*128_ldg1_ldg4_tile148n_nt</code>, with 773 invocations and avg duration of 256us.<br>\nFor mxnet, we have 22.4% compute spent on <code>maxwell_cgemm_32*64_tn</code>, with only 2 invocations and avg duration of 2.78ms.<br>\nIn general Pytorch seems to be launching a lot more kernels than mxnet for the same input/output pair.<br>\ncc: <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> do you have any insight on this?</p>", "body_text": "I can repro a similar perf with cuda9.0 cudnn7.0.\nI profiled both pytorch and mxnet on a single input(in_channel=1024, size=19, batch=1, kernel_size=3, padding=1). outchannel=64, group=1\nFor Pytorch, we have 92% compute spent on maxwell_scudnn_winograd_128*128_ldg1_ldg4_tile148n_nt, with 773 invocations and avg duration of 256us.\nFor mxnet, we have 22.4% compute spent on maxwell_cgemm_32*64_tn, with only 2 invocations and avg duration of 2.78ms.\nIn general Pytorch seems to be launching a lot more kernels than mxnet for the same input/output pair.\ncc: @ngimel @apaszke do you have any insight on this?", "body": "I can repro a similar perf with cuda9.0 cudnn7.0. \r\nI profiled both pytorch and mxnet on a single input(in_channel=1024, size=19, batch=1, kernel_size=3, padding=1). outchannel=64, group=1\r\nFor Pytorch, we have 92% compute spent on `maxwell_scudnn_winograd_128*128_ldg1_ldg4_tile148n_nt`, with 773 invocations and avg duration of 256us.\r\nFor mxnet, we have 22.4% compute spent on `maxwell_cgemm_32*64_tn`, with only 2 invocations and avg duration of 2.78ms.\r\nIn general Pytorch seems to be launching a lot more kernels than mxnet for the same input/output pair. \r\ncc: @ngimel @apaszke do you have any insight on this?"}