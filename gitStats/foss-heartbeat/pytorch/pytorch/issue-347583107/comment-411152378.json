{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/411152378", "html_url": "https://github.com/pytorch/pytorch/issues/10229#issuecomment-411152378", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10229", "id": 411152378, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTE1MjM3OA==", "user": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-07T18:17:32Z", "updated_at": "2018-08-07T18:17:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> , thanks for confirming. Yea I also saw mxnet error out with some arguments. I just picked one that worked fine and did the profiling.</p>\n<p>Here is my script just in case it helps. I'm taking a look at mxnet implementation to see if they have any customized kernel for <code>groups != input_channels</code>, since in those cases mxnet is much faster.</p>\n<pre><code>import time\nimport math\n\n\ndef count(a, m):\n    t0 = time.time()\n    for i in range(1000):\n        b = m(a)\n    return time.time() - t0\n\ndef th_test(in_channel=1024, size=19, batch=1):\n    import torch as th\n    import torch.nn as nn\n    x = th.rand((batch, in_channel, size, size))\n    x = x.cuda()\n    # out_channels_lsit = [256, 512, 1024, 2048]\n    out_channels_lsit = [64]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2))+1\n        for i in range(1):\n            g = int(math.pow(2, i))\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\ndef mx_test(in_channel=1024, size=19, batch=1):\n    import mxnet as mx\n    import mxnet.ndarray as nd\n    from mxnet.gluon import nn\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\n\n    # out_channels_lsit = [256, 512, 1024, 2048]\n    out_channels_lsit = [64]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\n        for i in range(1):\n            g = int(math.pow(2, i))\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\n            m.initialize(ctx=[mx.gpu(0)])\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\nif __name__=='__main__':\n    # print('Pytorch testing:')\n    # th_test(1024, 19, 1)\n    print('Mxnet testing:')\n    mx_test(1024, 19, 1)\n</code></pre>", "body_text": "Hi @ngimel , thanks for confirming. Yea I also saw mxnet error out with some arguments. I just picked one that worked fine and did the profiling.\nHere is my script just in case it helps. I'm taking a look at mxnet implementation to see if they have any customized kernel for groups != input_channels, since in those cases mxnet is much faster.\nimport time\nimport math\n\n\ndef count(a, m):\n    t0 = time.time()\n    for i in range(1000):\n        b = m(a)\n    return time.time() - t0\n\ndef th_test(in_channel=1024, size=19, batch=1):\n    import torch as th\n    import torch.nn as nn\n    x = th.rand((batch, in_channel, size, size))\n    x = x.cuda()\n    # out_channels_lsit = [256, 512, 1024, 2048]\n    out_channels_lsit = [64]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2))+1\n        for i in range(1):\n            g = int(math.pow(2, i))\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\ndef mx_test(in_channel=1024, size=19, batch=1):\n    import mxnet as mx\n    import mxnet.ndarray as nd\n    from mxnet.gluon import nn\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\n\n    # out_channels_lsit = [256, 512, 1024, 2048]\n    out_channels_lsit = [64]\n    for out_channels in out_channels_lsit:\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\n        for i in range(1):\n            g = int(math.pow(2, i))\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\n            m.initialize(ctx=[mx.gpu(0)])\n            t = count(x, m)\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\n\nif __name__=='__main__':\n    # print('Pytorch testing:')\n    # th_test(1024, 19, 1)\n    print('Mxnet testing:')\n    mx_test(1024, 19, 1)", "body": "Hi @ngimel , thanks for confirming. Yea I also saw mxnet error out with some arguments. I just picked one that worked fine and did the profiling. \r\n\r\nHere is my script just in case it helps. I'm taking a look at mxnet implementation to see if they have any customized kernel for `groups != input_channels`, since in those cases mxnet is much faster. \r\n```\r\nimport time\r\nimport math\r\n\r\n\r\ndef count(a, m):\r\n    t0 = time.time()\r\n    for i in range(1000):\r\n        b = m(a)\r\n    return time.time() - t0\r\n\r\ndef th_test(in_channel=1024, size=19, batch=1):\r\n    import torch as th\r\n    import torch.nn as nn\r\n    x = th.rand((batch, in_channel, size, size))\r\n    x = x.cuda()\r\n    # out_channels_lsit = [256, 512, 1024, 2048]\r\n    out_channels_lsit = [64]\r\n    for out_channels in out_channels_lsit:\r\n        n = int(math.log(min(in_channel, out_channels), 2))+1\r\n        for i in range(1):\r\n            g = int(math.pow(2, i))\r\n            m = nn.Conv2d(in_channel, out_channels=out_channels, kernel_size=3, padding=1, groups=g).cuda()\r\n            t = count(x, m)\r\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\r\n\r\ndef mx_test(in_channel=1024, size=19, batch=1):\r\n    import mxnet as mx\r\n    import mxnet.ndarray as nd\r\n    from mxnet.gluon import nn\r\n    x = nd.uniform(-1, 1, (batch, in_channel, size, size), mx.gpu(0))\r\n\r\n    # out_channels_lsit = [256, 512, 1024, 2048]\r\n    out_channels_lsit = [64]\r\n    for out_channels in out_channels_lsit:\r\n        n = int(math.log(min(in_channel, out_channels), 2)) + 1\r\n        for i in range(1):\r\n            g = int(math.pow(2, i))\r\n            m = nn.Conv2D(out_channels, kernel_size=3, padding=(1, 1), groups=g)\r\n            m.initialize(ctx=[mx.gpu(0)])\r\n            t = count(x, m)\r\n            print('OutChannel:{}, Group:{}, Time:{}'.format(out_channels, g, t))\r\n\r\nif __name__=='__main__':\r\n    # print('Pytorch testing:')\r\n    # th_test(1024, 19, 1)\r\n    print('Mxnet testing:')\r\n    mx_test(1024, 19, 1)\r\n```"}