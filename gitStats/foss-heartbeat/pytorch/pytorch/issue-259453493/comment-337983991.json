{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/337983991", "html_url": "https://github.com/pytorch/pytorch/issues/2816#issuecomment-337983991", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2816", "id": 337983991, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzk4Mzk5MQ==", "user": {"login": "csarofeen", "id": 22205833, "node_id": "MDQ6VXNlcjIyMjA1ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/22205833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csarofeen", "html_url": "https://github.com/csarofeen", "followers_url": "https://api.github.com/users/csarofeen/followers", "following_url": "https://api.github.com/users/csarofeen/following{/other_user}", "gists_url": "https://api.github.com/users/csarofeen/gists{/gist_id}", "starred_url": "https://api.github.com/users/csarofeen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csarofeen/subscriptions", "organizations_url": "https://api.github.com/users/csarofeen/orgs", "repos_url": "https://api.github.com/users/csarofeen/repos", "events_url": "https://api.github.com/users/csarofeen/events{/privacy}", "received_events_url": "https://api.github.com/users/csarofeen/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-19T17:45:09Z", "updated_at": "2017-10-19T17:54:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This a CUDA &lt;9 issue. CUDA may be trying to drop the entire THCTensorInfo object into register space (This may happen with -1 indexing). If this is the case it makes sense that smaller blocks would help. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1279573\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ducksoup\">@ducksoup</a> can you try...</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> time\n\nN, C, H, W <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">64</span>\nrepetitions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n\nx <span class=\"pl-k\">=</span> torch.randn(N, C, H, W).cuda()\nw <span class=\"pl-k\">=</span> torch.randn(C).cuda().expand(N, C).contiguous()\n\nt0 <span class=\"pl-k\">=</span> time.time()\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(repetitions):\n    y <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> w.view(N, C, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>)\n    torch.cuda.synchronize()\n<span class=\"pl-c1\">print</span>( (time.time() <span class=\"pl-k\">-</span> t0) <span class=\"pl-k\">/</span> repetitions )\n</pre></div>", "body_text": "This a CUDA <9 issue. CUDA may be trying to drop the entire THCTensorInfo object into register space (This may happen with -1 indexing). If this is the case it makes sense that smaller blocks would help. @ducksoup can you try...\nimport torch\nimport time\n\nN, C, H, W = 64, 256, 64, 64\nrepetitions = 100\n\nx = torch.randn(N, C, H, W).cuda()\nw = torch.randn(C).cuda().expand(N, C).contiguous()\n\nt0 = time.time()\nfor _ in range(repetitions):\n    y = x * w.view(N, C, 1, 1)\n    torch.cuda.synchronize()\nprint( (time.time() - t0) / repetitions )", "body": "This a CUDA <9 issue. CUDA may be trying to drop the entire THCTensorInfo object into register space (This may happen with -1 indexing). If this is the case it makes sense that smaller blocks would help. @ducksoup can you try... \r\n\r\n```python\r\nimport torch\r\nimport time\r\n\r\nN, C, H, W = 64, 256, 64, 64\r\nrepetitions = 100\r\n\r\nx = torch.randn(N, C, H, W).cuda()\r\nw = torch.randn(C).cuda().expand(N, C).contiguous()\r\n\r\nt0 = time.time()\r\nfor _ in range(repetitions):\r\n    y = x * w.view(N, C, 1, 1)\r\n    torch.cuda.synchronize()\r\nprint( (time.time() - t0) / repetitions )\r\n\r\n```"}