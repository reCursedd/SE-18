{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216820909", "pull_request_review_id": 154394896, "id": 216820909, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNjgyMDkwOQ==", "diff_hunk": "@@ -6781,29 +6836,45 @@ def forward(self, x):\n \n         self.checkTrace(TransformerNet(), (torch.rand(5, 3, 224, 224),))\n \n+    @staticmethod\n+    def _test_mnist(self, device, check_export_import=True):\n+        # eval() is present because dropout makes this nondeterministic\n+        self.checkTrace(MnistNet().to(device).eval(), (torch.rand(5, 1, 28, 28, device=device),),\n+                        export_import=check_export_import)\n+\n     def test_mnist(self):\n-        class Net(nn.Module):\n-            def __init__(self):\n-                super(Net, self).__init__()\n-                self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n-                self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n-                self.conv2_drop = nn.Dropout2d()\n-                self.fc1 = nn.Linear(320, 50)\n-                self.fc2 = nn.Linear(50, 10)\n+        self._test_mnist(self, device='cpu')\n \n-            def forward(self, x):\n-                x = F.relu(F.max_pool2d(self.conv1(x), 2))\n-                x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n-                x = x.view(-1, 320)\n-                x = F.relu(self.fc1(x))\n-                x = F.dropout(x, training=self.training)\n-                x = self.fc2(x)\n-                return F.log_softmax(x, dim=1)\n+    @unittest.skipIf(not RUN_CUDA, \"no CUDA\")\n+    def test_mnist_cuda(self):\n+        # XXX: export_import on CUDA modules doesn't work (#11480)\n+        self._test_mnist(self, device='cuda', check_export_import=False)\n \n-        # eval() is present because dropout makes this nondeterministic\n-        self.checkTrace(Net().eval(), (torch.rand(5, 1, 28, 28),))\n+    @unittest.skipIf(not RUN_CUDA, \"no CUDA\")\n+    def test_mnist_training_leaks_no_memory_cuda(self):", "path": "test/test_jit.py", "position": 124, "original_position": 124, "commit_id": "fda5ea40103f028949d27f8b5ea35eda08aa8474", "original_commit_id": "3d8c0c0f27db59b2c22c94c8af0c417865018cf3", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "It takes 7 seconds to run so it is not too much. I'll shorten it; we'll probably write more tests like this in the future", "created_at": "2018-09-11T21:00:43Z", "updated_at": "2018-11-23T15:51:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/11544#discussion_r216820909", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11544", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216820909"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11544#discussion_r216820909"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11544"}}, "body_html": "<p>It takes 7 seconds to run so it is not too much. I'll shorten it; we'll probably write more tests like this in the future</p>", "body_text": "It takes 7 seconds to run so it is not too much. I'll shorten it; we'll probably write more tests like this in the future", "in_reply_to_id": 216818581}