{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3472", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3472/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3472/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3472/events", "html_url": "https://github.com/pytorch/pytorch/issues/3472", "id": 271113042, "node_id": "MDU6SXNzdWUyNzExMTMwNDI=", "number": 3472, "title": "Sparse-dense matrix multiple not using multiple threads on CPU", "user": {"login": "bryan-he", "id": 2773922, "node_id": "MDQ6VXNlcjI3NzM5MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/2773922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bryan-he", "html_url": "https://github.com/bryan-he", "followers_url": "https://api.github.com/users/bryan-he/followers", "following_url": "https://api.github.com/users/bryan-he/following{/other_user}", "gists_url": "https://api.github.com/users/bryan-he/gists{/gist_id}", "starred_url": "https://api.github.com/users/bryan-he/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bryan-he/subscriptions", "organizations_url": "https://api.github.com/users/bryan-he/orgs", "repos_url": "https://api.github.com/users/bryan-he/repos", "events_url": "https://api.github.com/users/bryan-he/events{/privacy}", "received_events_url": "https://api.github.com/users/bryan-he/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679954154, "node_id": "MDU6TGFiZWw2Nzk5NTQxNTQ=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/sparse", "name": "sparse", "color": "bfd4f2", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-03T20:42:26Z", "updated_at": "2018-10-01T01:46:23Z", "closed_at": "2018-10-01T01:46:23Z", "author_association": "NONE", "body_html": "<p>I am running a dense-sparse matrix multiply on CPU with a multicore machine.</p>\n<p>Code:<br>\nimport torch</p>\n<pre><code>print torch.get_num_threads()\n\nn = 10000\nnnz = 1000000\n\nv = torch.randn([nnz]).type(torch.DoubleTensor)\n\nind = torch.rand(2, nnz).type(torch.LongTensor)\n\nA = torch.sparse.DoubleTensor(ind, v, torch.Size([n, n])).coalesce()\nB = torch.randn(n, n).type(torch.DoubleTensor)\n\nC = torch.mm(A, B)\n</code></pre>\n<p><code>get_num_threads()</code> gives 28, and when I run the mm, 28 threads are started as expected.<br>\nHowever, running <code>top</code> shows that only one of the threads actually does any work, and all of the other threads have 0% CPU usage.</p>\n<p>Tested on Python 2.7 with Pytorch built from source (commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/0e38d3bbb3dc3ea677ad24ac3aeef79fb7acdab6/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/0e38d3bbb3dc3ea677ad24ac3aeef79fb7acdab6\"><tt>0e38d3b</tt></a>).</p>", "body_text": "I am running a dense-sparse matrix multiply on CPU with a multicore machine.\nCode:\nimport torch\nprint torch.get_num_threads()\n\nn = 10000\nnnz = 1000000\n\nv = torch.randn([nnz]).type(torch.DoubleTensor)\n\nind = torch.rand(2, nnz).type(torch.LongTensor)\n\nA = torch.sparse.DoubleTensor(ind, v, torch.Size([n, n])).coalesce()\nB = torch.randn(n, n).type(torch.DoubleTensor)\n\nC = torch.mm(A, B)\n\nget_num_threads() gives 28, and when I run the mm, 28 threads are started as expected.\nHowever, running top shows that only one of the threads actually does any work, and all of the other threads have 0% CPU usage.\nTested on Python 2.7 with Pytorch built from source (commit 0e38d3b).", "body": "I am running a dense-sparse matrix multiply on CPU with a multicore machine.\r\n\r\nCode:\r\n    import torch\r\n\r\n    print torch.get_num_threads()\r\n\r\n    n = 10000\r\n    nnz = 1000000\r\n\r\n    v = torch.randn([nnz]).type(torch.DoubleTensor)\r\n\r\n    ind = torch.rand(2, nnz).type(torch.LongTensor)\r\n\r\n    A = torch.sparse.DoubleTensor(ind, v, torch.Size([n, n])).coalesce()\r\n    B = torch.randn(n, n).type(torch.DoubleTensor)\r\n\r\n    C = torch.mm(A, B)\r\n\r\n`get_num_threads()` gives 28, and when I run the mm, 28 threads are started as expected.\r\nHowever, running `top` shows that only one of the threads actually does any work, and all of the other threads have 0% CPU usage.\r\n\r\nTested on Python 2.7 with Pytorch built from source (commit 0e38d3bbb3dc3ea677ad24ac3aeef79fb7acdab6).\r\n\r\n"}