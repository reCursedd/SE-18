{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/435244175", "html_url": "https://github.com/pytorch/pytorch/issues/13494#issuecomment-435244175", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13494", "id": 435244175, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTI0NDE3NQ==", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-02T01:43:08Z", "updated_at": "2018-11-02T01:43:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Ailing brought up a good point in person: typically when you accidentally have a gradient graph lying around that you have already used, you will get an error because you cannot backward twice.  This is a good error! You were most likely doing something wrong and if silently works, your grads will accumulate in unexpected cases. But in this particular case, the error never appears for basically implementation-defined reasons (at least, reasons that are more complicated than we expect our users to understand).</p>", "body_text": "Ailing brought up a good point in person: typically when you accidentally have a gradient graph lying around that you have already used, you will get an error because you cannot backward twice.  This is a good error! You were most likely doing something wrong and if silently works, your grads will accumulate in unexpected cases. But in this particular case, the error never appears for basically implementation-defined reasons (at least, reasons that are more complicated than we expect our users to understand).", "body": "Ailing brought up a good point in person: typically when you accidentally have a gradient graph lying around that you have already used, you will get an error because you cannot backward twice.  This is a good error! You were most likely doing something wrong and if silently works, your grads will accumulate in unexpected cases. But in this particular case, the error never appears for basically implementation-defined reasons (at least, reasons that are more complicated than we expect our users to understand)."}