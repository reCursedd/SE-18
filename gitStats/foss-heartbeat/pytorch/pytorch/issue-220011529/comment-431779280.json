{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/431779280", "html_url": "https://github.com/pytorch/pytorch/issues/1204#issuecomment-431779280", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1204", "id": 431779280, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTc3OTI4MA==", "user": {"login": "woaichipinngguo", "id": 15664013, "node_id": "MDQ6VXNlcjE1NjY0MDEz", "avatar_url": "https://avatars3.githubusercontent.com/u/15664013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woaichipinngguo", "html_url": "https://github.com/woaichipinngguo", "followers_url": "https://api.github.com/users/woaichipinngguo/followers", "following_url": "https://api.github.com/users/woaichipinngguo/following{/other_user}", "gists_url": "https://api.github.com/users/woaichipinngguo/gists{/gist_id}", "starred_url": "https://api.github.com/users/woaichipinngguo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woaichipinngguo/subscriptions", "organizations_url": "https://api.github.com/users/woaichipinngguo/orgs", "repos_url": "https://api.github.com/users/woaichipinngguo/repos", "events_url": "https://api.github.com/users/woaichipinngguo/events{/privacy}", "received_events_url": "https://api.github.com/users/woaichipinngguo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-22T09:03:42Z", "updated_at": "2018-10-22T09:03:42Z", "author_association": "NONE", "body_html": "<p>When train my Unet model for binary segmentation with NLLLoss() loss, I have encountered an  error on Tesla K80, but it's OK for  GeForce GTX 108... . Need I update the version of cuda or cudnn?<br>\n<strong>Tesla K80 on linux</strong></p>\n<pre><code>CUDA Version 8.0.61\nCUDNN_MAJOR -A 2\n#define CUDNN_MAJOR      6\n#define CUDNN_MINOR      0\n#define CUDNN_PATCHLEVEL 21\n--\n#define CUDNN_VERSION    (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n</code></pre>\n<p><strong>cuda version error:</strong><br>\n<code>anRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THC/THCTensorCopy.cu:100</code><br>\n<strong>cpu version error:</strong><br>\n<code>RuntimeError: Assertion </code>cur_target &gt;= 0 &amp;&amp; cur_target &lt; n_classes' failed.  at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THNN/generic/SpatialClassNLLCriterion.c:111`</p>\n<p><strong>GeForce GTX 108...: on win10</strong><br>\n<code>Cuda compilation tools, release 10.0, V10.0.130</code></p>\n<pre><code>class UNet(nn.Module):  \n    def __init__(self, n_channels=3, n_classes=1):  \n        super(UNet, self).__init__()  \n        self.down=resnet18()  \n        self.inc = inconv(n_channels, 16)  \n        self.down1 = down(64, 128)  \n        self.down2 = down(128, 256)   \n        self.down3 = down(256, 512)   \n        self.down4 = down(512, 512)   \n        self.up1 = up(96, 64,64,drop=0.2)      \n        self.up2 = up(80, 32,64,drop=0.2)\n        self.up3 = up(48, 16,32,drop=0.1)\n        self.up4 = up(32, 16,16,drop=0.1)\n        self.outc = outconv(16, n_classes)\n        self.reset_params()\n</code></pre>\n<pre><code>     myNet=myNet.to(device)#numclass=1\n        criterion=nn.NLLLoss()\n        myNet.train()\n        for ii,(data,mask,_)in enumerate(trainloader):\n            #\u8bad\u7ec3\u6a21\u578b\n            data,mask=data.to(device),mask.to(device)\n            mask=mask.long()\n            optimizer.zero_grad()\n            out=myNet(data)\n            out = F.log_softmax(out, dim=1)\n            loss=criterion(out,mask)\n</code></pre>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=18660165\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/panfengli\">@panfengli</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7247925\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/onlytailei\">@onlytailei</a></p>", "body_text": "When train my Unet model for binary segmentation with NLLLoss() loss, I have encountered an  error on Tesla K80, but it's OK for  GeForce GTX 108... . Need I update the version of cuda or cudnn?\nTesla K80 on linux\nCUDA Version 8.0.61\nCUDNN_MAJOR -A 2\n#define CUDNN_MAJOR      6\n#define CUDNN_MINOR      0\n#define CUDNN_PATCHLEVEL 21\n--\n#define CUDNN_VERSION    (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n\ncuda version error:\nanRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THC/THCTensorCopy.cu:100\ncpu version error:\nRuntimeError: Assertion cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THNN/generic/SpatialClassNLLCriterion.c:111`\nGeForce GTX 108...: on win10\nCuda compilation tools, release 10.0, V10.0.130\nclass UNet(nn.Module):  \n    def __init__(self, n_channels=3, n_classes=1):  \n        super(UNet, self).__init__()  \n        self.down=resnet18()  \n        self.inc = inconv(n_channels, 16)  \n        self.down1 = down(64, 128)  \n        self.down2 = down(128, 256)   \n        self.down3 = down(256, 512)   \n        self.down4 = down(512, 512)   \n        self.up1 = up(96, 64,64,drop=0.2)      \n        self.up2 = up(80, 32,64,drop=0.2)\n        self.up3 = up(48, 16,32,drop=0.1)\n        self.up4 = up(32, 16,16,drop=0.1)\n        self.outc = outconv(16, n_classes)\n        self.reset_params()\n\n     myNet=myNet.to(device)#numclass=1\n        criterion=nn.NLLLoss()\n        myNet.train()\n        for ii,(data,mask,_)in enumerate(trainloader):\n            #\u8bad\u7ec3\u6a21\u578b\n            data,mask=data.to(device),mask.to(device)\n            mask=mask.long()\n            optimizer.zero_grad()\n            out=myNet(data)\n            out = F.log_softmax(out, dim=1)\n            loss=criterion(out,mask)\n\n@soumith @panfengli @onlytailei", "body": "When train my Unet model for binary segmentation with NLLLoss() loss, I have encountered an  error on Tesla K80, but it's OK for  GeForce GTX 108... . Need I update the version of cuda or cudnn? \r\n**Tesla K80 on linux**\r\n```\r\nCUDA Version 8.0.61\r\nCUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR      6\r\n#define CUDNN_MINOR      0\r\n#define CUDNN_PATCHLEVEL 21\r\n--\r\n#define CUDNN_VERSION    (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n```\r\n**cuda version error:**\r\n`anRuntimeError: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THC/THCTensorCopy.cu:100`\r\n**cpu version error:**\r\n`RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THNN/generic/SpatialClassNLLCriterion.c:111`\r\n\r\n **GeForce GTX 108...: on win10**\r\n`Cuda compilation tools, release 10.0, V10.0.130`\r\n\r\n```\r\nclass UNet(nn.Module):  \r\n    def __init__(self, n_channels=3, n_classes=1):  \r\n        super(UNet, self).__init__()  \r\n        self.down=resnet18()  \r\n        self.inc = inconv(n_channels, 16)  \r\n        self.down1 = down(64, 128)  \r\n        self.down2 = down(128, 256)   \r\n        self.down3 = down(256, 512)   \r\n        self.down4 = down(512, 512)   \r\n        self.up1 = up(96, 64,64,drop=0.2)      \r\n        self.up2 = up(80, 32,64,drop=0.2)\r\n        self.up3 = up(48, 16,32,drop=0.1)\r\n        self.up4 = up(32, 16,16,drop=0.1)\r\n        self.outc = outconv(16, n_classes)\r\n        self.reset_params()\r\n```\r\n\r\n\r\n```\r\n     myNet=myNet.to(device)#numclass=1\r\n        criterion=nn.NLLLoss()\r\n        myNet.train()\r\n        for ii,(data,mask,_)in enumerate(trainloader):\r\n            #\u8bad\u7ec3\u6a21\u578b\r\n            data,mask=data.to(device),mask.to(device)\r\n            mask=mask.long()\r\n            optimizer.zero_grad()\r\n            out=myNet(data)\r\n            out = F.log_softmax(out, dim=1)\r\n            loss=criterion(out,mask)\r\n```\r\n@soumith @panfengli @onlytailei \r\n\r\n"}