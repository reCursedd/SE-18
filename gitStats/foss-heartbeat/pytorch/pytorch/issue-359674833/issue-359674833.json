{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11605", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11605/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11605/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11605/events", "html_url": "https://github.com/pytorch/pytorch/pull/11605", "id": 359674833, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE1MTEzODQ5", "number": 11605, "title": "[caffe2] Change the mutex protection scope in AtomicFetchAddOp.", "user": {"login": "JerryShih", "id": 5842681, "node_id": "MDQ6VXNlcjU4NDI2ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5842681?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JerryShih", "html_url": "https://github.com/JerryShih", "followers_url": "https://api.github.com/users/JerryShih/followers", "following_url": "https://api.github.com/users/JerryShih/following{/other_user}", "gists_url": "https://api.github.com/users/JerryShih/gists{/gist_id}", "starred_url": "https://api.github.com/users/JerryShih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JerryShih/subscriptions", "organizations_url": "https://api.github.com/users/JerryShih/orgs", "repos_url": "https://api.github.com/users/JerryShih/repos", "events_url": "https://api.github.com/users/JerryShih/events{/privacy}", "received_events_url": "https://api.github.com/users/JerryShih/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1069014618, "node_id": "MDU6TGFiZWwxMDY5MDE0NjE4", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2-op", "name": "caffe2-op", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-12T22:26:28Z", "updated_at": "2018-10-12T11:19:40Z", "closed_at": "2018-10-12T11:19:40Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11605", "html_url": "https://github.com/pytorch/pytorch/pull/11605", "diff_url": "https://github.com/pytorch/pytorch/pull/11605.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11605.patch"}, "body_html": "<p>There is a potential data racing in AtomicFetchAddOp. The Output(n) call includes some memory operations. If we run the AtomicFetchAddOp object simultaneously in different threads, we might hit the problem.</p>\n<p>I saw a test failed in \"<a href=\"https://github.com/pytorch/pytorch/blob/d4e05f4e1e276055cd3d3e1a2a1e186e6c6405ee/caffe2/python/operator_test/atomic_ops_test.py#L31\">caffe2/python/operator_test/atomic_ops_test.py</a>\" for this problem. And I can reproduce locally.<br>\nHere is the call stack for the crash:<br>\nIt calls Output(n) simultaneously in different threads. Then, cause the assertion checking in aten.</p>\n<pre><code>[I plan_executor.cc:511] Step init took 0.000375997 seconds.\nlibc++abi.dylib: terminating with uncaught exception of type at::Error: refcount_.load() == 0 ASSERT FAILED at ../aten/src/ATen/core/intrusive_ptr.h:83, please report a bug to PyTorch. Tried to destruct an intrusive_ptr_target that still has intrusive_ptr to it (~intrusive_ptr_target at ../aten/src/ATen/core/intrusive_ptr.h:83)\nframe #0: caffe2::TensorImpl::~TensorImpl() + 134 (0x10ffa6386 in libcaffe2.dylib)\nframe #1: void caffe2::Blob::Destroy&lt;caffe2::Tensor&gt;(void*) + 91 (0x10ffa5f1b in libcaffe2.dylib)\nframe #2: caffe2::Blob::GetMutableTensor(at::DeviceType) + 378 (0x10ffa5e1a in libcaffe2.dylib)\nframe #3: caffe2::fb::(anonymous namespace)::AtomicFetchAddOp::RunOnDevice() + 149 (0x1102f7c65 in libcaffe2.dylib)\nframe #4: caffe2::Operator&lt;caffe2::CPUContext&gt;::Run(int) + 90 (0x10ff9f8ea in libcaffe2.dylib)\nframe #5: caffe2::SimpleNet::Run() + 447 (0x11016215f in libcaffe2.dylib)\nframe #6: caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&amp;) + 889 (0x11017efc9 in libcaffe2.dylib)\nframe #7: void* std::__1::__thread_proxy&lt;std::__1::tuple&lt;std::__1::unique_ptr&lt;std::__1::__thread_struct, std::__1::default_delete&lt;std::__1::__thread_struct&gt; &gt;, caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&amp;)::$_5&gt; &gt;(void*) + 156 (0x11018581c in libcaffe2.dylib)\nframe #8: _pthread_body + 340 (0x7fff64bea661 in libsystem_pthread.dylib)\nframe #9: _pthread_body + 0 (0x7fff64bea50d in libsystem_pthread.dylib)\nframe #10: thread_start + 13 (0x7fff64be9bf9 in libsystem_pthread.dylib)\n\nProcess 16280 stopped\n* thread #5, stop reason = signal SIGABRT\n    frame #0: 0x00007fff64a22b66 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n-&gt;  0x7fff64a22b66 &lt;+10&gt;: jae    0x7fff64a22b70            ; &lt;+20&gt;\n    0x7fff64a22b68 &lt;+12&gt;: movq   %rax, %rdi\n    0x7fff64a22b6b &lt;+15&gt;: jmp    0x7fff64a19ae9            ; cerror_nocancel\n    0x7fff64a22b70 &lt;+20&gt;: retq\nTarget 0: (Python) stopped.\n</code></pre>", "body_text": "There is a potential data racing in AtomicFetchAddOp. The Output(n) call includes some memory operations. If we run the AtomicFetchAddOp object simultaneously in different threads, we might hit the problem.\nI saw a test failed in \"caffe2/python/operator_test/atomic_ops_test.py\" for this problem. And I can reproduce locally.\nHere is the call stack for the crash:\nIt calls Output(n) simultaneously in different threads. Then, cause the assertion checking in aten.\n[I plan_executor.cc:511] Step init took 0.000375997 seconds.\nlibc++abi.dylib: terminating with uncaught exception of type at::Error: refcount_.load() == 0 ASSERT FAILED at ../aten/src/ATen/core/intrusive_ptr.h:83, please report a bug to PyTorch. Tried to destruct an intrusive_ptr_target that still has intrusive_ptr to it (~intrusive_ptr_target at ../aten/src/ATen/core/intrusive_ptr.h:83)\nframe #0: caffe2::TensorImpl::~TensorImpl() + 134 (0x10ffa6386 in libcaffe2.dylib)\nframe #1: void caffe2::Blob::Destroy<caffe2::Tensor>(void*) + 91 (0x10ffa5f1b in libcaffe2.dylib)\nframe #2: caffe2::Blob::GetMutableTensor(at::DeviceType) + 378 (0x10ffa5e1a in libcaffe2.dylib)\nframe #3: caffe2::fb::(anonymous namespace)::AtomicFetchAddOp::RunOnDevice() + 149 (0x1102f7c65 in libcaffe2.dylib)\nframe #4: caffe2::Operator<caffe2::CPUContext>::Run(int) + 90 (0x10ff9f8ea in libcaffe2.dylib)\nframe #5: caffe2::SimpleNet::Run() + 447 (0x11016215f in libcaffe2.dylib)\nframe #6: caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&) + 889 (0x11017efc9 in libcaffe2.dylib)\nframe #7: void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&)::$_5> >(void*) + 156 (0x11018581c in libcaffe2.dylib)\nframe #8: _pthread_body + 340 (0x7fff64bea661 in libsystem_pthread.dylib)\nframe #9: _pthread_body + 0 (0x7fff64bea50d in libsystem_pthread.dylib)\nframe #10: thread_start + 13 (0x7fff64be9bf9 in libsystem_pthread.dylib)\n\nProcess 16280 stopped\n* thread #5, stop reason = signal SIGABRT\n    frame #0: 0x00007fff64a22b66 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff64a22b66 <+10>: jae    0x7fff64a22b70            ; <+20>\n    0x7fff64a22b68 <+12>: movq   %rax, %rdi\n    0x7fff64a22b6b <+15>: jmp    0x7fff64a19ae9            ; cerror_nocancel\n    0x7fff64a22b70 <+20>: retq\nTarget 0: (Python) stopped.", "body": "There is a potential data racing in AtomicFetchAddOp. The Output(n) call includes some memory operations. If we run the AtomicFetchAddOp object simultaneously in different threads, we might hit the problem.\r\n\r\nI saw a test failed in \"[caffe2/python/operator_test/atomic_ops_test.py](https://github.com/pytorch/pytorch/blob/d4e05f4e1e276055cd3d3e1a2a1e186e6c6405ee/caffe2/python/operator_test/atomic_ops_test.py#L31)\" for this problem. And I can reproduce locally.\r\nHere is the call stack for the crash:\r\nIt calls Output(n) simultaneously in different threads. Then, cause the assertion checking in aten.\r\n```\r\n[I plan_executor.cc:511] Step init took 0.000375997 seconds.\r\nlibc++abi.dylib: terminating with uncaught exception of type at::Error: refcount_.load() == 0 ASSERT FAILED at ../aten/src/ATen/core/intrusive_ptr.h:83, please report a bug to PyTorch. Tried to destruct an intrusive_ptr_target that still has intrusive_ptr to it (~intrusive_ptr_target at ../aten/src/ATen/core/intrusive_ptr.h:83)\r\nframe #0: caffe2::TensorImpl::~TensorImpl() + 134 (0x10ffa6386 in libcaffe2.dylib)\r\nframe #1: void caffe2::Blob::Destroy<caffe2::Tensor>(void*) + 91 (0x10ffa5f1b in libcaffe2.dylib)\r\nframe #2: caffe2::Blob::GetMutableTensor(at::DeviceType) + 378 (0x10ffa5e1a in libcaffe2.dylib)\r\nframe #3: caffe2::fb::(anonymous namespace)::AtomicFetchAddOp::RunOnDevice() + 149 (0x1102f7c65 in libcaffe2.dylib)\r\nframe #4: caffe2::Operator<caffe2::CPUContext>::Run(int) + 90 (0x10ff9f8ea in libcaffe2.dylib)\r\nframe #5: caffe2::SimpleNet::Run() + 447 (0x11016215f in libcaffe2.dylib)\r\nframe #6: caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&) + 889 (0x11017efc9 in libcaffe2.dylib)\r\nframe #7: void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, caffe2::(anonymous namespace)::ExecuteStepRecursive(caffe2::(anonymous namespace)::ExecutionStepWrapper&)::$_5> >(void*) + 156 (0x11018581c in libcaffe2.dylib)\r\nframe #8: _pthread_body + 340 (0x7fff64bea661 in libsystem_pthread.dylib)\r\nframe #9: _pthread_body + 0 (0x7fff64bea50d in libsystem_pthread.dylib)\r\nframe #10: thread_start + 13 (0x7fff64be9bf9 in libsystem_pthread.dylib)\r\n\r\nProcess 16280 stopped\r\n* thread #5, stop reason = signal SIGABRT\r\n    frame #0: 0x00007fff64a22b66 libsystem_kernel.dylib`__pthread_kill + 10\r\nlibsystem_kernel.dylib`__pthread_kill:\r\n->  0x7fff64a22b66 <+10>: jae    0x7fff64a22b70            ; <+20>\r\n    0x7fff64a22b68 <+12>: movq   %rax, %rdi\r\n    0x7fff64a22b6b <+15>: jmp    0x7fff64a19ae9            ; cerror_nocancel\r\n    0x7fff64a22b70 <+20>: retq\r\nTarget 0: (Python) stopped.\r\n```\r\n\r\n\r\n"}