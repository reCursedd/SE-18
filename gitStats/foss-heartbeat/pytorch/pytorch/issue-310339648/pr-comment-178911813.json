{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178911813", "pull_request_review_id": 109055702, "id": 178911813, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODkxMTgxMw==", "diff_hunk": "@@ -1,12 +1,12 @@\n \n-def clip_grad_norm(parameters, max_norm, norm_type=2):\n+def clip_grad_norm_(parameters, max_norm, norm_type=2):", "path": "torch/nn/utils/clip_grad.py", "position": null, "original_position": 3, "commit_id": "ca944d8c43174097157b94e8e297a82bd569277c", "original_commit_id": "8bdb61bc68d5cff8550a77e4b48d13699e7e19c2", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "This needs a deprecating version. Something like below should work:\r\n```python \r\ndef clip_grad_norm(parameters, max_norm, norm_type=2):\r\n    r\"\"\"Clips gradient norm of an iterable of parameters.\r\n    \r\n    .. warning:: This method is now deprecated in favor of :func:`torch.nn.utils.clip_grad_norm_`.\r\n    \"\"\"\r\n    warnings.warn(\"nn.utils.clip_grad_norm is now deprecated in favor of nn.init.nn.utils.clip_grad_norm_.\",\r\n                  stacklevel=2)\r\n    return clip_grad_norm_(parameters, max_norm, norm_type)\r\n```", "created_at": "2018-04-03T18:01:06Z", "updated_at": "2018-11-23T15:41:34Z", "html_url": "https://github.com/pytorch/pytorch/pull/6173#discussion_r178911813", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6173", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178911813"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6173#discussion_r178911813"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6173"}}, "body_html": "<p>This needs a deprecating version. Something like below should work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">clip_grad_norm</span>(<span class=\"pl-smi\">parameters</span>, <span class=\"pl-smi\">max_norm</span>, <span class=\"pl-smi\">norm_type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>):\n    <span class=\"pl-s\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">\"\"\"</span>Clips gradient norm of an iterable of parameters.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    .. warning:: This method is now deprecated in favor of :func:`torch.nn.utils.clip_grad_norm_`.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    warnings.warn(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>nn.utils.clip_grad_norm is now deprecated in favor of nn.init.nn.utils.clip_grad_norm_.<span class=\"pl-pds\">\"</span></span>,\n                  <span class=\"pl-v\">stacklevel</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n    <span class=\"pl-k\">return</span> clip_grad_norm_(parameters, max_norm, norm_type)</pre></div>", "body_text": "This needs a deprecating version. Something like below should work:\ndef clip_grad_norm(parameters, max_norm, norm_type=2):\n    r\"\"\"Clips gradient norm of an iterable of parameters.\n    \n    .. warning:: This method is now deprecated in favor of :func:`torch.nn.utils.clip_grad_norm_`.\n    \"\"\"\n    warnings.warn(\"nn.utils.clip_grad_norm is now deprecated in favor of nn.init.nn.utils.clip_grad_norm_.\",\n                  stacklevel=2)\n    return clip_grad_norm_(parameters, max_norm, norm_type)"}