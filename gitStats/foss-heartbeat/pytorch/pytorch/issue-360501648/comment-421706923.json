{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/421706923", "html_url": "https://github.com/pytorch/pytorch/issues/11727#issuecomment-421706923", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11727", "id": 421706923, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTcwNjkyMw==", "user": {"login": "chengs", "id": 824529, "node_id": "MDQ6VXNlcjgyNDUyOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/824529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chengs", "html_url": "https://github.com/chengs", "followers_url": "https://api.github.com/users/chengs/followers", "following_url": "https://api.github.com/users/chengs/following{/other_user}", "gists_url": "https://api.github.com/users/chengs/gists{/gist_id}", "starred_url": "https://api.github.com/users/chengs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chengs/subscriptions", "organizations_url": "https://api.github.com/users/chengs/orgs", "repos_url": "https://api.github.com/users/chengs/repos", "events_url": "https://api.github.com/users/chengs/events{/privacy}", "received_events_url": "https://api.github.com/users/chengs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-16T06:14:44Z", "updated_at": "2018-09-16T06:34:24Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7424737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/PetrochukM\">@PetrochukM</a></p>\n<p>You said</p>\n<blockquote>\n<p>The code would still break if everything was moved inside the if <strong>name</strong> == '<strong>main</strong>': statement.</p>\n</blockquote>\n<p>Could you show me the code that still breaks with moving things inside <code>__main__</code>?</p>\n<p>On my enviroment (py36, tqdm4.26, pytorch 0.4.1), the following code works well (no warning output):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n<span class=\"pl-k\">from</span> tqdm <span class=\"pl-k\">import</span> tqdm\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-k\">try</span>:\n        multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n        <span class=\"pl-k\">pass</span>\n    \n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> tqdm(data_iterator):\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>So does this</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n    <span class=\"pl-k\">from</span> tqdm <span class=\"pl-k\">import</span> tqdm\n    <span class=\"pl-k\">import</span> torch\n    <span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n\n    <span class=\"pl-k\">try</span>:\n        multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n        <span class=\"pl-k\">pass</span>\n    \n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> tqdm(data_iterator):\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>So does this</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> tqdm <span class=\"pl-k\">import</span> tqdm\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n    <span class=\"pl-k\">import</span> torch\n    <span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n\n    <span class=\"pl-k\">try</span>:\n        multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n        <span class=\"pl-k\">pass</span>\n    \n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> tqdm(data_iterator):\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>And also replacing <code>from tqdm import tqdm</code> by <code>mp_lock = multiprocessing.RLock()</code> does not cause any warnings.</p>\n<p>For instance, this works well</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    <span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n    <span class=\"pl-k\">try</span>:\n        multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n        <span class=\"pl-k\">pass</span>\n\n    mp_lock <span class=\"pl-k\">=</span> multiprocessing.RLock()\n\n    <span class=\"pl-k\">import</span> torch\n    <span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> data_iterator:\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>IMHO, moving <code>set_start_method</code> into <code>__main__</code> should be added into pytorch's document.</p>\n<p>Regarding <code>tqdm</code>, try <code>tqdm==v4.17.1</code> if you want to avoid <code>RLock</code>.</p>", "body_text": "@PetrochukM\nYou said\n\nThe code would still break if everything was moved inside the if name == 'main': statement.\n\nCould you show me the code that still breaks with moving things inside __main__?\nOn my enviroment (py36, tqdm4.26, pytorch 0.4.1), the following code works well (no warning output):\nfrom torch import multiprocessing\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import DataLoader\n\nif __name__ == '__main__':\n    try:\n        multiprocessing.set_start_method('spawn')\n    except RuntimeError:\n        pass\n    \n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in tqdm(data_iterator):\n        pass\nSo does this\nif __name__ == '__main__':\n    from torch import multiprocessing\n    from tqdm import tqdm\n    import torch\n    from torch.utils.data import DataLoader\n\n    try:\n        multiprocessing.set_start_method('spawn')\n    except RuntimeError:\n        pass\n    \n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in tqdm(data_iterator):\n        pass\nSo does this\nfrom tqdm import tqdm\nif __name__ == '__main__':\n    from torch import multiprocessing\n    import torch\n    from torch.utils.data import DataLoader\n\n    try:\n        multiprocessing.set_start_method('spawn')\n    except RuntimeError:\n        pass\n    \n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in tqdm(data_iterator):\n        pass\nAnd also replacing from tqdm import tqdm by mp_lock = multiprocessing.RLock() does not cause any warnings.\nFor instance, this works well\nif __name__ == '__main__':\n    from torch import multiprocessing\n    try:\n        multiprocessing.set_start_method('spawn')\n    except RuntimeError:\n        pass\n\n    mp_lock = multiprocessing.RLock()\n\n    import torch\n    from torch.utils.data import DataLoader\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in data_iterator:\n        pass\nIMHO, moving set_start_method into __main__ should be added into pytorch's document.\nRegarding tqdm, try tqdm==v4.17.1 if you want to avoid RLock.", "body": "@PetrochukM \r\n\r\nYou said\r\n> The code would still break if everything was moved inside the if __name__ == '__main__': statement.\r\n\r\nCould you show me the code that still breaks with moving things inside ``__main__``? \r\n\r\nOn my enviroment (py36, tqdm4.26, pytorch 0.4.1), the following code works well (no warning output):\r\n```python\r\nfrom torch import multiprocessing\r\nfrom tqdm import tqdm\r\nimport torch\r\nfrom torch.utils.data import DataLoader\r\n\r\nif __name__ == '__main__':\r\n    try:\r\n        multiprocessing.set_start_method('spawn')\r\n    except RuntimeError:\r\n        pass\r\n    \r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in tqdm(data_iterator):\r\n        pass\r\n```\r\nSo does this\r\n```python\r\nif __name__ == '__main__':\r\n    from torch import multiprocessing\r\n    from tqdm import tqdm\r\n    import torch\r\n    from torch.utils.data import DataLoader\r\n\r\n    try:\r\n        multiprocessing.set_start_method('spawn')\r\n    except RuntimeError:\r\n        pass\r\n    \r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in tqdm(data_iterator):\r\n        pass\r\n```\r\nSo does this\r\n```python\r\nfrom tqdm import tqdm\r\nif __name__ == '__main__':\r\n    from torch import multiprocessing\r\n    import torch\r\n    from torch.utils.data import DataLoader\r\n\r\n    try:\r\n        multiprocessing.set_start_method('spawn')\r\n    except RuntimeError:\r\n        pass\r\n    \r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in tqdm(data_iterator):\r\n        pass\r\n```\r\nAnd also replacing ``from tqdm import tqdm`` by ``mp_lock = multiprocessing.RLock()`` does not cause any warnings.\r\n\r\nFor instance, this works well\r\n```python\r\nif __name__ == '__main__':\r\n    from torch import multiprocessing\r\n    try:\r\n        multiprocessing.set_start_method('spawn')\r\n    except RuntimeError:\r\n        pass\r\n\r\n    mp_lock = multiprocessing.RLock()\r\n\r\n    import torch\r\n    from torch.utils.data import DataLoader\r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in data_iterator:\r\n        pass\r\n```\r\n\r\nIMHO, moving ``set_start_method`` into ``__main__`` should be added into pytorch's document.\r\n\r\n\r\nRegarding ``tqdm``, try ``tqdm==v4.17.1`` if you want to avoid ``RLock``."}