{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/421720593", "html_url": "https://github.com/pytorch/pytorch/issues/11727#issuecomment-421720593", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11727", "id": 421720593, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTcyMDU5Mw==", "user": {"login": "chengs", "id": 824529, "node_id": "MDQ6VXNlcjgyNDUyOQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/824529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chengs", "html_url": "https://github.com/chengs", "followers_url": "https://api.github.com/users/chengs/followers", "following_url": "https://api.github.com/users/chengs/following{/other_user}", "gists_url": "https://api.github.com/users/chengs/gists{/gist_id}", "starred_url": "https://api.github.com/users/chengs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chengs/subscriptions", "organizations_url": "https://api.github.com/users/chengs/orgs", "repos_url": "https://api.github.com/users/chengs/repos", "events_url": "https://api.github.com/users/chengs/events{/privacy}", "received_events_url": "https://api.github.com/users/chengs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-16T08:07:36Z", "updated_at": "2018-09-16T08:07:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7424737\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/PetrochukM\">@PetrochukM</a> if you add a marker output before <code>set_start_method</code> like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> DEPENDANCY: This is required for ``DistributedDataParallel``</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel</span>\n<span class=\"pl-k\">try</span>:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>marker output</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>I am setting.<span class=\"pl-pds\">'</span></span>)\n    multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n    <span class=\"pl-k\">pass</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> DEPENDANCY: This is required for ``from tqdm import tqdm``</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74</span>\nmp_lock <span class=\"pl-k\">=</span> multiprocessing.RLock()\n\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> data_iterator:\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>You will see that <code>I am setting</code> appears 5 times, <strong>which means <code>set_start_method</code> is called FIVE times. However, I think we agree that <code>set_start_method</code> should be called ONLY one time according to the document. (<a href=\"https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_start_method\" rel=\"nofollow\">https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_start_method</a>)</strong></p>", "body_text": "@PetrochukM if you add a marker output before set_start_method like this:\nimport torch\nfrom torch import multiprocessing\n\n# DEPENDANCY: This is required for ``DistributedDataParallel``\n# https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\ntry:\n    #marker output\n    print('I am setting.')\n    multiprocessing.set_start_method('spawn')\nexcept RuntimeError:\n    pass\n\n# DEPENDANCY: This is required for ``from tqdm import tqdm``\n# https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74\nmp_lock = multiprocessing.RLock()\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nif __name__ == '__main__':\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in data_iterator:\n        pass\nYou will see that I am setting appears 5 times, which means set_start_method is called FIVE times. However, I think we agree that set_start_method should be called ONLY one time according to the document. (https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_start_method)", "body": "@PetrochukM if you add a marker output before ``set_start_method`` like this:\r\n```python\r\nimport torch\r\nfrom torch import multiprocessing\r\n\r\n# DEPENDANCY: This is required for ``DistributedDataParallel``\r\n# https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\r\ntry:\r\n    #marker output\r\n    print('I am setting.')\r\n    multiprocessing.set_start_method('spawn')\r\nexcept RuntimeError:\r\n    pass\r\n\r\n# DEPENDANCY: This is required for ``from tqdm import tqdm``\r\n# https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74\r\nmp_lock = multiprocessing.RLock()\r\n\r\nimport torch\r\nfrom torch.utils.data import DataLoader\r\n\r\nif __name__ == '__main__':\r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in data_iterator:\r\n        pass\r\n```\r\n\r\nYou will see that ``I am setting`` appears 5 times, **which means ``set_start_method`` is called FIVE times. However, I think we agree that ``set_start_method`` should be called ONLY one time according to the document. (https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_start_method)**"}