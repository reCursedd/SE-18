{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109046851", "pull_request_review_id": 30124023, "id": 109046851, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwOTA0Njg1MQ==", "diff_hunk": "@@ -190,7 +196,11 @@ def forward(fn, input, hx, weight, output, hy):\n         handle = cudnn.get_handle()\n         fn.datatype = cudnn._typemap[input.type()]\n         is_input_packed = fn.batch_sizes is not None\n-\n+        if is_input_packed:\n+            warnings.warn(\n+                \"Warning: persistent algorithm not supported for variable length input.\"\n+                \"Switching to standard\")\n+            fn.persistent = False  # persistent algo is not supported for variable length input", "path": "torch/backends/cudnn/rnn.py", "position": 41, "original_position": 41, "commit_id": "738ebd1be1c0444730a96ce650e85496a0f8444e", "original_commit_id": "738ebd1be1c0444730a96ce650e85496a0f8444e", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "body": "Ok, and what do you suggest if benchmark mode is not enabled? Have a crude heuristic, or always default to standard? Another question - is there a way to query compute capability from python? Persistent is available on Pascal only. \r\nI'm somewhat afraid of benchmarking overhead, esp if sequences with very different lengths or batchsizes are passed through. And binning with size 50 does seem arbitrary, but we can start with that, I guess.  ", "created_at": "2017-03-30T21:52:28Z", "updated_at": "2018-11-23T15:32:54Z", "html_url": "https://github.com/pytorch/pytorch/pull/1141#discussion_r109046851", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1141", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/109046851"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1141#discussion_r109046851"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1141"}}, "body_html": "<p>Ok, and what do you suggest if benchmark mode is not enabled? Have a crude heuristic, or always default to standard? Another question - is there a way to query compute capability from python? Persistent is available on Pascal only.<br>\nI'm somewhat afraid of benchmarking overhead, esp if sequences with very different lengths or batchsizes are passed through. And binning with size 50 does seem arbitrary, but we can start with that, I guess.</p>", "body_text": "Ok, and what do you suggest if benchmark mode is not enabled? Have a crude heuristic, or always default to standard? Another question - is there a way to query compute capability from python? Persistent is available on Pascal only.\nI'm somewhat afraid of benchmarking overhead, esp if sequences with very different lengths or batchsizes are passed through. And binning with size 50 does seem arbitrary, but we can start with that, I guess.", "in_reply_to_id": 109042245}