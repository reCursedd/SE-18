{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/383900481", "html_url": "https://github.com/pytorch/pytorch/issues/5310#issuecomment-383900481", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5310", "id": 383900481, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzkwMDQ4MQ==", "user": {"login": "jaidmin", "id": 18241545, "node_id": "MDQ6VXNlcjE4MjQxNTQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/18241545?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaidmin", "html_url": "https://github.com/jaidmin", "followers_url": "https://api.github.com/users/jaidmin/followers", "following_url": "https://api.github.com/users/jaidmin/following{/other_user}", "gists_url": "https://api.github.com/users/jaidmin/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaidmin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaidmin/subscriptions", "organizations_url": "https://api.github.com/users/jaidmin/orgs", "repos_url": "https://api.github.com/users/jaidmin/repos", "events_url": "https://api.github.com/users/jaidmin/events{/privacy}", "received_events_url": "https://api.github.com/users/jaidmin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-24T11:41:42Z", "updated_at": "2018-04-24T11:41:42Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7606451\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Scitator\">@Scitator</a> !<br>\nYes, as long as you are just using adaptive pooling to do global pooling you can simply define the following module:</p>\n<pre><code>class MyAdaptiveMaxPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n       \n\n    def forward(self, x): \n        inp_size = x.size()\n        return nn.functional.max_pool2d(input=x,\n                  kernel_size= (inp_size[2], inp_size[3]))\n</code></pre>\n<p>I also recently opened a discussion in the forums about how to replace adaptive pooling in general:<br>\n<a href=\"https://discuss.pytorch.org/t/how-to-replicate-f-adaptive-max-pool-using-f-max-pool/16851\" rel=\"nofollow\">https://discuss.pytorch.org/t/how-to-replicate-f-adaptive-max-pool-using-f-max-pool/16851</a></p>\n<p>Cheers!</p>", "body_text": "Hi @Scitator !\nYes, as long as you are just using adaptive pooling to do global pooling you can simply define the following module:\nclass MyAdaptiveMaxPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n       \n\n    def forward(self, x): \n        inp_size = x.size()\n        return nn.functional.max_pool2d(input=x,\n                  kernel_size= (inp_size[2], inp_size[3]))\n\nI also recently opened a discussion in the forums about how to replace adaptive pooling in general:\nhttps://discuss.pytorch.org/t/how-to-replicate-f-adaptive-max-pool-using-f-max-pool/16851\nCheers!", "body": "Hi @Scitator !\r\nYes, as long as you are just using adaptive pooling to do global pooling you can simply define the following module:\r\n```\r\nclass MyAdaptiveMaxPool2d(nn.Module):\r\n    def __init__(self, sz=None):\r\n        super().__init__()\r\n       \r\n\r\n    def forward(self, x): \r\n        inp_size = x.size()\r\n        return nn.functional.max_pool2d(input=x,\r\n                  kernel_size= (inp_size[2], inp_size[3]))\r\n```\r\n\r\nI also recently opened a discussion in the forums about how to replace adaptive pooling in general:\r\nhttps://discuss.pytorch.org/t/how-to-replicate-f-adaptive-max-pool-using-f-max-pool/16851 \r\n\r\nCheers!\r\n"}