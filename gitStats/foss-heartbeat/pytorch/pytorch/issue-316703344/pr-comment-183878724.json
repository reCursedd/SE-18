{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183878724", "pull_request_review_id": 114963750, "id": 183878724, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4Mzg3ODcyNA==", "diff_hunk": "@@ -0,0 +1,215 @@\n+#include \"TH/THMath.h\"\n+#include \"ATen/Half.h\"\n+#ifdef __CUDA_ARCH__\n+#include <nvfunctional>\n+#endif\n+\n+namespace {\n+\n+#ifdef __CUDA_ARCH__\n+#define nvfunction_or_function nvstd::function\n+#define deviceforcuda __device__\n+#else\n+#define nvfunction_or_function std::function\n+#define deviceforcuda\n+// we cannot use std::isnan directly due to some incompatibility of\n+// gcc constexpr'ing and nvcc\n+#define isnan std::isnan\n+#endif\n+\n+template<typename scalar_t>\n+struct BaseSampler {\n+  nvfunction_or_function<scalar_t(void)> sampler;\n+  deviceforcuda BaseSampler(nvfunction_or_function<scalar_t(void)> sampler): sampler(sampler) {}\n+  deviceforcuda scalar_t sample() {\n+    return sampler();\n+  }\n+};\n+\n+// The function `sample_gamma` is\n+// is adapted from Numpy's distributions.c implementation.\n+// It is MIT licensed, so here is the copyright:\n+\n+/* Copyright 2005 Robert Kern (robert.kern@gmail.com)\n+ *\n+ * Permission is hereby granted, free of charge, to any person obtaining a\n+ * copy of this software and associated documentation files (the\n+ * \"Software\"), to deal in the Software without restriction, including\n+ * without limitation the rights to use, copy, modify, merge, publish,\n+ * distribute, sublicense, and/or sell copies of the Software, and to\n+ * permit persons to whom the Software is furnished to do so, subject to\n+ * the following conditions:\n+ *\n+ * The above copyright notice and this permission notice shall be included\n+ * in all copies or substantial portions of the Software.\n+ *\n+ * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n+ * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n+*/\n+\n+template<typename scalar_t>\n+deviceforcuda scalar_t sample_gamma(scalar_t alpha, BaseSampler<scalar_t>& standard_uniform, BaseSampler<scalar_t>& standard_normal) {\n+  scalar_t scale = 1.0;\n+\n+  // Boost alpha for higher acceptance probability.\n+  if (alpha < 1.0) {\n+    scale *= std::pow(1 - standard_uniform.sample(), static_cast<scalar_t>(1.0) / alpha);", "path": "aten/src/ATen/native/Distributions.h", "position": null, "original_position": 61, "commit_id": "c225a925ee93b8d1db2eb489b16b2d1601eb63e6", "original_commit_id": "5b32203f4e2323a506d930f7312a0440f9f1990e", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "body": "- So to have some more safety margin, say 32 calls for a gamma sample as a probable upper bound. Do we want to do something for like that poisson as well?\r\n- I think we would need to multiply this by round_up(alpha.numel() / number of threads) to capture we are sampling tensors. What is our assumption about the number of threads here?\r\n", "created_at": "2018-04-24T21:03:01Z", "updated_at": "2018-11-23T15:43:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/6855#discussion_r183878724", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6855", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183878724"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6855#discussion_r183878724"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6855"}}, "body_html": "<ul>\n<li>So to have some more safety margin, say 32 calls for a gamma sample as a probable upper bound. Do we want to do something for like that poisson as well?</li>\n<li>I think we would need to multiply this by round_up(alpha.numel() / number of threads) to capture we are sampling tensors. What is our assumption about the number of threads here?</li>\n</ul>", "body_text": "So to have some more safety margin, say 32 calls for a gamma sample as a probable upper bound. Do we want to do something for like that poisson as well?\nI think we would need to multiply this by round_up(alpha.numel() / number of threads) to capture we are sampling tensors. What is our assumption about the number of threads here?", "in_reply_to_id": 183542859}