{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183967906", "pull_request_review_id": 115066830, "id": 183967906, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4Mzk2NzkwNg==", "diff_hunk": "@@ -31,28 +41,85 @@ void poisson_cuda_kernel(\n     at::Tensor& ret,\n     const at::Tensor& lambda,\n     std::pair<uint64_t, uint64_t> seeds) {\n-  at::cuda::CUDA_tensor_apply2<scalar_t, float>(\n+  at::cuda::CUDA_tensor_apply2<scalar_t, scalar_t>(\n       ret,\n       lambda,\n       [seeds] __device__(\n-          scalar_t & ret_val, const float& lambda, bool early_exit) {\n+          scalar_t & ret_val, const scalar_t& lambda, bool early_exit) {\n+        curandStatePhilox4_32_10_t state;\n+        curand_init(\n+            seeds.first,\n+            blockIdx.x * blockDim.x + threadIdx.x,\n+            seeds.second,\n+            &state);\n+        ret_val = scalar_cast<scalar_t>(curand_poisson(&state, scalar_cast<float>(lambda)));\n+      });\n+}\n+\n+template <typename scalar_t>\n+void gamma_cuda_kernel(\n+    at::Tensor& ret,\n+    const at::Tensor& alpha,\n+    std::pair<uint64_t, uint64_t> seeds) {\n+  using accscalar_t = at::cuda::acc_type<scalar_t>;\n+  at::cuda::CUDA_tensor_apply2<scalar_t, scalar_t>(\n+      ret,\n+      alpha,\n+      [seeds] __device__(\n+          scalar_t & ret_val, const scalar_t& alpha, bool early_exit) {\n         curandStatePhilox4_32_10_t state;\n         curand_init(\n             seeds.first,\n             blockIdx.x * blockDim.x + threadIdx.x,\n             seeds.second,\n             &state);\n-        ret_val = scalar_cast<scalar_t>(curand_poisson(&state, lambda));\n+        BaseSampler<accscalar_t> standard_uniform([&state] __device__ () {\n+          return curand_uniform(&state);\n+        });\n+        BaseSampler<accscalar_t> standard_normal([&state] __device__ () {\n+          return curand_normal(&state);\n+        });\n+        auto sample = sample_gamma<scalar_t, accscalar_t>(alpha, standard_uniform, standard_normal);\n+        ret_val = ((THCNumerics<scalar_t>::min() > sample) ? (THCNumerics<scalar_t>::min()) : sample);\n+      });\n+}\n+\n+template <typename scalar_t>\n+void gamma_grad_cuda_kernel(\n+    at::Tensor& ret,\n+    const at::Tensor& self,\n+    const at::Tensor& output) {\n+  using accscalar_t = at::cuda::acc_type<scalar_t>;\n+  at::cuda::CUDA_tensor_apply3<scalar_t, scalar_t, scalar_t>(\n+      ret, self, output,\n+      [] __device__ (scalar_t& ret_val, const scalar_t& self_val, const scalar_t &output_val) {\n+        ret_val = standard_gamma_grad_one<scalar_t, accscalar_t>(self_val, output_val);\n       });\n }\n+\n } // namespace\n \n namespace at { namespace native {\n Tensor _s_poisson_cuda(const Tensor& lambda, Generator* gen) {\n   Tensor ret = lambda.type().tensor(lambda.sizes());\n-  auto lambda_ = lambda.toType(ScalarType::Float);\n-  AT_DISPATCH_FLOATING_TYPES(ret.type(), \"poisson\", [&] {\n-     poisson_cuda_kernel<scalar_t>(ret, lambda_, next_philox_seed(gen));\n+  AT_DISPATCH_FLOATING_TYPES_AND_HALF(ret.type(), \"poisson\", [&] {\n+    poisson_cuda_kernel<cuda::type<scalar_t>>(ret, lambda, next_philox_seed(gen, 20));", "path": "aten/src/ATen/native/cuda/Distributions.cu", "position": 105, "original_position": 105, "commit_id": "c225a925ee93b8d1db2eb489b16b2d1601eb63e6", "original_commit_id": "e1857074d59285707f728fa8b11a654f72474c02", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "@ngimel shouldn't the increment be `#threads * 20` here?", "created_at": "2018-04-25T07:52:29Z", "updated_at": "2018-11-23T15:43:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/6855#discussion_r183967906", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6855", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/183967906"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6855#discussion_r183967906"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6855"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> shouldn't the increment be <code>#threads * 20</code> here?</p>", "body_text": "@ngimel shouldn't the increment be #threads * 20 here?"}