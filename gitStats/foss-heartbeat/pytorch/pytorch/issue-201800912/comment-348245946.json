{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/348245946", "html_url": "https://github.com/pytorch/pytorch/issues/494#issuecomment-348245946", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/494", "id": 348245946, "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODI0NTk0Ng==", "user": {"login": "SpaceCowboy850", "id": 12373859, "node_id": "MDQ6VXNlcjEyMzczODU5", "avatar_url": "https://avatars2.githubusercontent.com/u/12373859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SpaceCowboy850", "html_url": "https://github.com/SpaceCowboy850", "followers_url": "https://api.github.com/users/SpaceCowboy850/followers", "following_url": "https://api.github.com/users/SpaceCowboy850/following{/other_user}", "gists_url": "https://api.github.com/users/SpaceCowboy850/gists{/gist_id}", "starred_url": "https://api.github.com/users/SpaceCowboy850/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SpaceCowboy850/subscriptions", "organizations_url": "https://api.github.com/users/SpaceCowboy850/orgs", "repos_url": "https://api.github.com/users/SpaceCowboy850/repos", "events_url": "https://api.github.com/users/SpaceCowboy850/events{/privacy}", "received_events_url": "https://api.github.com/users/SpaceCowboy850/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-30T16:40:18Z", "updated_at": "2017-11-30T16:40:18Z", "author_association": "NONE", "body_html": "<p>Looking at dataloader.py, setting num_worker to 0 simply stops the multiprocessing from ever starting, but there doesn't appear to be a single threaded fallback that I'm seeing.</p>\n<p>In any case, on Windows 10 x64, Visual Studio 2017, Cuda9, Python 3.6.3, setting num_workers to 0 causes an error to pop up in windows \"Python has stopped working\", and setting it to anything larger results in a broken pipe.</p>\n<p>I'll continue to investigate it as well.  My suspicion is a queue is getting filled and breaking improperly, since the error happens with a large amount of data, but not a small amount of data.</p>", "body_text": "Looking at dataloader.py, setting num_worker to 0 simply stops the multiprocessing from ever starting, but there doesn't appear to be a single threaded fallback that I'm seeing.\nIn any case, on Windows 10 x64, Visual Studio 2017, Cuda9, Python 3.6.3, setting num_workers to 0 causes an error to pop up in windows \"Python has stopped working\", and setting it to anything larger results in a broken pipe.\nI'll continue to investigate it as well.  My suspicion is a queue is getting filled and breaking improperly, since the error happens with a large amount of data, but not a small amount of data.", "body": "Looking at dataloader.py, setting num_worker to 0 simply stops the multiprocessing from ever starting, but there doesn't appear to be a single threaded fallback that I'm seeing.\r\n\r\nIn any case, on Windows 10 x64, Visual Studio 2017, Cuda9, Python 3.6.3, setting num_workers to 0 causes an error to pop up in windows \"Python has stopped working\", and setting it to anything larger results in a broken pipe. \r\n\r\nI'll continue to investigate it as well.  My suspicion is a queue is getting filled and breaking improperly, since the error happens with a large amount of data, but not a small amount of data."}