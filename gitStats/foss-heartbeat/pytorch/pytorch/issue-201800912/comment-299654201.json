{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/299654201", "html_url": "https://github.com/pytorch/pytorch/issues/494#issuecomment-299654201", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/494", "id": 299654201, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTY1NDIwMQ==", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-06T17:24:34Z", "updated_at": "2017-05-06T17:24:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4969356\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tylergenter\">@tylergenter</a> I used Python 3.6 and the test_mnist.py is just a modified version of the one in the example repo. The original version is listed <a href=\"https://github.com/pytorch/examples/blob/master/mnist/main.py\">here</a>. The multiprocessing part is broken, causing the redefinition of the data loaders and then the process hangs. So i wrapped them with an if statement.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    train_loader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(\n    datasets.MNIST(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">download</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                   <span class=\"pl-v\">transform</span><span class=\"pl-k\">=</span>transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((<span class=\"pl-c1\">0.1307</span>,), (<span class=\"pl-c1\">0.3081</span>,))\n                   ])),\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>args.batch_size, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-k\">**</span>kwargs)\n    test_loader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(\n    datasets.MNIST(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">transform</span><span class=\"pl-k\">=</span>transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((<span class=\"pl-c1\">0.1307</span>,), (<span class=\"pl-c1\">0.3081</span>,))\n                   ])),\n    <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>args.batch_size, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-k\">**</span>kwargs)</pre></div>", "body_text": "@tylergenter I used Python 3.6 and the test_mnist.py is just a modified version of the one in the example repo. The original version is listed here. The multiprocessing part is broken, causing the redefinition of the data loaders and then the process hangs. So i wrapped them with an if statement.\nif __name__ == '__main__':\n    train_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)", "body": "@tylergenter I used Python 3.6 and the test_mnist.py is just a modified version of the one in the example repo. The original version is listed [here](https://github.com/pytorch/examples/blob/master/mnist/main.py). The multiprocessing part is broken, causing the redefinition of the data loaders and then the process hangs. So i wrapped them with an if statement.\r\n```python\r\nif __name__ == '__main__':\r\n    train_loader = torch.utils.data.DataLoader(\r\n    datasets.MNIST('../data', train=True, download=True,\r\n                   transform=transforms.Compose([\r\n                       transforms.ToTensor(),\r\n                       transforms.Normalize((0.1307,), (0.3081,))\r\n                   ])),\r\n    batch_size=args.batch_size, shuffle=True, **kwargs)\r\n    test_loader = torch.utils.data.DataLoader(\r\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\r\n                       transforms.ToTensor(),\r\n                       transforms.Normalize((0.1307,), (0.3081,))\r\n                   ])),\r\n    batch_size=args.batch_size, shuffle=True, **kwargs)\r\n```"}