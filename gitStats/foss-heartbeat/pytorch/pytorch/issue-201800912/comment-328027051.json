{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/328027051", "html_url": "https://github.com/pytorch/pytorch/issues/494#issuecomment-328027051", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/494", "id": 328027051, "node_id": "MDEyOklzc3VlQ29tbWVudDMyODAyNzA1MQ==", "user": {"login": "albu", "id": 1128788, "node_id": "MDQ6VXNlcjExMjg3ODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1128788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albu", "html_url": "https://github.com/albu", "followers_url": "https://api.github.com/users/albu/followers", "following_url": "https://api.github.com/users/albu/following{/other_user}", "gists_url": "https://api.github.com/users/albu/gists{/gist_id}", "starred_url": "https://api.github.com/users/albu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albu/subscriptions", "organizations_url": "https://api.github.com/users/albu/orgs", "repos_url": "https://api.github.com/users/albu/repos", "events_url": "https://api.github.com/users/albu/events{/privacy}", "received_events_url": "https://api.github.com/users/albu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-08T07:42:50Z", "updated_at": "2017-09-08T07:42:50Z", "author_association": "NONE", "body_html": "<p>Hello, where was problem mentioned here about MemoryError and possible memory leak using num_workers more then 0. Just simple test to reproduce this error.</p>\n<pre><code>from torch.utils.data.dataloader import DataLoader as PytorchDataLoader\nimport numpy as np\n\nclass MockDataset:\n    def __getitem__(self, item):\n        return np.random.random((1000, 1000, 1))\n\n    def __len__(self):\n        return 10000\n\ndef memory_error():\n    dataset = MockDataset()\n    dl = PytorchDataLoader(dataset, batch_size=8, num_workers=2)\n    for i in dl:\n        pass\n\nif __name__ == \"__main__\":\n    memory_error()\n</code></pre>\n<p>In task manager memory usage goes up.<br>\nI also tried memory profiler on this, but it says everything OK (peak usage about 250M per process) so I have no ideas.</p>\n<pre><code>$ mprof run -M python profile_dataloader.py\n$ mprof plot\n</code></pre>\n<p>torch version: '0.2.1+40afd13' (gpu) installed from appveyor<br>\nWindows 10<br>\npython 3.5.3 and 3.6.1 (miniconda)</p>", "body_text": "Hello, where was problem mentioned here about MemoryError and possible memory leak using num_workers more then 0. Just simple test to reproduce this error.\nfrom torch.utils.data.dataloader import DataLoader as PytorchDataLoader\nimport numpy as np\n\nclass MockDataset:\n    def __getitem__(self, item):\n        return np.random.random((1000, 1000, 1))\n\n    def __len__(self):\n        return 10000\n\ndef memory_error():\n    dataset = MockDataset()\n    dl = PytorchDataLoader(dataset, batch_size=8, num_workers=2)\n    for i in dl:\n        pass\n\nif __name__ == \"__main__\":\n    memory_error()\n\nIn task manager memory usage goes up.\nI also tried memory profiler on this, but it says everything OK (peak usage about 250M per process) so I have no ideas.\n$ mprof run -M python profile_dataloader.py\n$ mprof plot\n\ntorch version: '0.2.1+40afd13' (gpu) installed from appveyor\nWindows 10\npython 3.5.3 and 3.6.1 (miniconda)", "body": "Hello, where was problem mentioned here about MemoryError and possible memory leak using num_workers more then 0. Just simple test to reproduce this error.\r\n```\r\nfrom torch.utils.data.dataloader import DataLoader as PytorchDataLoader\r\nimport numpy as np\r\n\r\nclass MockDataset:\r\n    def __getitem__(self, item):\r\n        return np.random.random((1000, 1000, 1))\r\n\r\n    def __len__(self):\r\n        return 10000\r\n\r\ndef memory_error():\r\n    dataset = MockDataset()\r\n    dl = PytorchDataLoader(dataset, batch_size=8, num_workers=2)\r\n    for i in dl:\r\n        pass\r\n\r\nif __name__ == \"__main__\":\r\n    memory_error()\r\n```\r\nIn task manager memory usage goes up.\r\nI also tried memory profiler on this, but it says everything OK (peak usage about 250M per process) so I have no ideas.\r\n```\r\n$ mprof run -M python profile_dataloader.py\r\n$ mprof plot\r\n```\r\n\r\ntorch version: '0.2.1+40afd13' (gpu) installed from appveyor\r\nWindows 10\r\npython 3.5.3 and 3.6.1 (miniconda)"}