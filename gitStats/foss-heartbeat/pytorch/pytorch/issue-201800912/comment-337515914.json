{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/337515914", "html_url": "https://github.com/pytorch/pytorch/issues/494#issuecomment-337515914", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/494", "id": 337515914, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzUxNTkxNA==", "user": {"login": "cptay", "id": 28792472, "node_id": "MDQ6VXNlcjI4NzkyNDcy", "avatar_url": "https://avatars2.githubusercontent.com/u/28792472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cptay", "html_url": "https://github.com/cptay", "followers_url": "https://api.github.com/users/cptay/followers", "following_url": "https://api.github.com/users/cptay/following{/other_user}", "gists_url": "https://api.github.com/users/cptay/gists{/gist_id}", "starred_url": "https://api.github.com/users/cptay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cptay/subscriptions", "organizations_url": "https://api.github.com/users/cptay/orgs", "repos_url": "https://api.github.com/users/cptay/repos", "events_url": "https://api.github.com/users/cptay/events{/privacy}", "received_events_url": "https://api.github.com/users/cptay/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-18T09:07:58Z", "updated_at": "2017-10-18T09:07:58Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9998726\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/peterjc123\">@peterjc123</a> I wanna first say a big thank to you for the great effort you have put in to run Pytorch under Windows. I have installed Pytorch using this command 'Conda install -c peterjc123 pytorch', and with the rest of the necessary python packages, Python 3.6, and Cuda 8.0. The system is mostly running fine, and I can run my project. A happy guy until I ran into the following problem.</p>\n<p>The major issue right now is of course the memory leakage problem. The dataloader is eating up my ram, and on my system I can run the most 20 epochs. It affects my evaluation test also as I have big test set. The only option now for me is to set worker to zero. But it is slowing down my processing...</p>\n<p>Wonder if you have overcome this problem? I have tried to browse through all the previous posts, but they are not obvious to me whether there is a solution to it or not?</p>\n<p>Thanks in advance!</p>", "body_text": "@peterjc123 I wanna first say a big thank to you for the great effort you have put in to run Pytorch under Windows. I have installed Pytorch using this command 'Conda install -c peterjc123 pytorch', and with the rest of the necessary python packages, Python 3.6, and Cuda 8.0. The system is mostly running fine, and I can run my project. A happy guy until I ran into the following problem.\nThe major issue right now is of course the memory leakage problem. The dataloader is eating up my ram, and on my system I can run the most 20 epochs. It affects my evaluation test also as I have big test set. The only option now for me is to set worker to zero. But it is slowing down my processing...\nWonder if you have overcome this problem? I have tried to browse through all the previous posts, but they are not obvious to me whether there is a solution to it or not?\nThanks in advance!", "body": "@peterjc123 I wanna first say a big thank to you for the great effort you have put in to run Pytorch under Windows. I have installed Pytorch using this command 'Conda install -c peterjc123 pytorch', and with the rest of the necessary python packages, Python 3.6, and Cuda 8.0. The system is mostly running fine, and I can run my project. A happy guy until I ran into the following problem.\r\n\r\nThe major issue right now is of course the memory leakage problem. The dataloader is eating up my ram, and on my system I can run the most 20 epochs. It affects my evaluation test also as I have big test set. The only option now for me is to set worker to zero. But it is slowing down my processing...\r\n\r\nWonder if you have overcome this problem? I have tried to browse through all the previous posts, but they are not obvious to me whether there is a solution to it or not?\r\n\r\nThanks in advance!"}