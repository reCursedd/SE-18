{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/334476326", "html_url": "https://github.com/pytorch/pytorch/issues/2968#issuecomment-334476326", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2968", "id": 334476326, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDQ3NjMyNg==", "user": {"login": "dmarnerides", "id": 7605917, "node_id": "MDQ6VXNlcjc2MDU5MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7605917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dmarnerides", "html_url": "https://github.com/dmarnerides", "followers_url": "https://api.github.com/users/dmarnerides/followers", "following_url": "https://api.github.com/users/dmarnerides/following{/other_user}", "gists_url": "https://api.github.com/users/dmarnerides/gists{/gist_id}", "starred_url": "https://api.github.com/users/dmarnerides/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dmarnerides/subscriptions", "organizations_url": "https://api.github.com/users/dmarnerides/orgs", "repos_url": "https://api.github.com/users/dmarnerides/repos", "events_url": "https://api.github.com/users/dmarnerides/events{/privacy}", "received_events_url": "https://api.github.com/users/dmarnerides/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-05T14:09:12Z", "updated_at": "2017-10-05T14:10:32Z", "author_association": "NONE", "body_html": "<p>What would the best approach be theoretically, converting to half on a loader thread on the cpu and then copying (async) to gpu or letting the conversion happen while copying?</p>\n<pre><code>gpu_tensor = torch.HalfTensor(1000).cuda()\n# Is this:\ngpu_tensor.copy_(loaded_float_tensor) \n\n# better than this?\ngpu_tensor.copy_(loaded_half_tensor) \n</code></pre>\n<p>If the second option is faster then it might be useful for dataloader to be able to cast to half.</p>\n<p>Is the type coercion happening on cpu or gpu in the first case?</p>", "body_text": "What would the best approach be theoretically, converting to half on a loader thread on the cpu and then copying (async) to gpu or letting the conversion happen while copying?\ngpu_tensor = torch.HalfTensor(1000).cuda()\n# Is this:\ngpu_tensor.copy_(loaded_float_tensor) \n\n# better than this?\ngpu_tensor.copy_(loaded_half_tensor) \n\nIf the second option is faster then it might be useful for dataloader to be able to cast to half.\nIs the type coercion happening on cpu or gpu in the first case?", "body": "What would the best approach be theoretically, converting to half on a loader thread on the cpu and then copying (async) to gpu or letting the conversion happen while copying?\r\n```\r\ngpu_tensor = torch.HalfTensor(1000).cuda()\r\n# Is this:\r\ngpu_tensor.copy_(loaded_float_tensor) \r\n\r\n# better than this?\r\ngpu_tensor.copy_(loaded_half_tensor) \r\n```\r\n\r\nIf the second option is faster then it might be useful for dataloader to be able to cast to half.\r\n\r\nIs the type coercion happening on cpu or gpu in the first case? \r\n"}