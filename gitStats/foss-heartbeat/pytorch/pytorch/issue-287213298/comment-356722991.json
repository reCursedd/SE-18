{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/356722991", "html_url": "https://github.com/pytorch/pytorch/issues/4564#issuecomment-356722991", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4564", "id": 356722991, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjcyMjk5MQ==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-10T20:14:50Z", "updated_at": "2018-01-10T20:14:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p><strong>Step 1: handle mixed Tensor/TensorList inputs.</strong></p>\n<p>Here's what the codegen produces today:</p>\n<pre><code>std::vector&lt;Tensor&gt; VariableType::_smoketest_cons(const Tensor &amp; x, TensorList xs) const {\n    profiler::RecordFunction profiler(\"_smoketest_cons\");\n    auto&amp; x_ = unpack(x, \"x\", 0);\n    auto xs_ = unpack(xs, \"xs\", 1);\n    std::shared_ptr&lt;SmoketestConsBackward&gt; grad_fn;\n    auto requires_grad = compute_requires_grad({ x, xs });\n    if (requires_grad) {\n      grad_fn = std::make_shared&lt;SmoketestConsBackward&gt;();\n      grad_fn-&gt;next_functions = compute_next_functions({ x, xs });\n    }\n    auto ret = as_variable(baseType-&gt;_smoketest_cons(x_, xs_));\n    set_history(ret, grad_fn);\n    if (jit::tracer::isTracing( x, xs )) {\n      jit::Node *n = jit::tracer::recordTrace( \"_smoketest_cons\", flatten( x, xs ), ret );\n      (void)n;\n    }\n    return as_tensor_list(ret);\n}\n</code></pre>\n<p>Things to fix:</p>\n<ol>\n<li><code>compute_requires_grad</code> doesn't typecheck. We'll replace it with a templated variadic thing (similar to <code>isTracing</code>) and remove the initializer list</li>\n<li><code>compute_next_functions</code> doesn't typecheck. Also replace it with a templated variadic thing.</li>\n</ol>", "body_text": "Step 1: handle mixed Tensor/TensorList inputs.\nHere's what the codegen produces today:\nstd::vector<Tensor> VariableType::_smoketest_cons(const Tensor & x, TensorList xs) const {\n    profiler::RecordFunction profiler(\"_smoketest_cons\");\n    auto& x_ = unpack(x, \"x\", 0);\n    auto xs_ = unpack(xs, \"xs\", 1);\n    std::shared_ptr<SmoketestConsBackward> grad_fn;\n    auto requires_grad = compute_requires_grad({ x, xs });\n    if (requires_grad) {\n      grad_fn = std::make_shared<SmoketestConsBackward>();\n      grad_fn->next_functions = compute_next_functions({ x, xs });\n    }\n    auto ret = as_variable(baseType->_smoketest_cons(x_, xs_));\n    set_history(ret, grad_fn);\n    if (jit::tracer::isTracing( x, xs )) {\n      jit::Node *n = jit::tracer::recordTrace( \"_smoketest_cons\", flatten( x, xs ), ret );\n      (void)n;\n    }\n    return as_tensor_list(ret);\n}\n\nThings to fix:\n\ncompute_requires_grad doesn't typecheck. We'll replace it with a templated variadic thing (similar to isTracing) and remove the initializer list\ncompute_next_functions doesn't typecheck. Also replace it with a templated variadic thing.", "body": "**Step 1: handle mixed Tensor/TensorList inputs.**\r\n\r\nHere's what the codegen produces today:\r\n\r\n```\r\nstd::vector<Tensor> VariableType::_smoketest_cons(const Tensor & x, TensorList xs) const {\r\n    profiler::RecordFunction profiler(\"_smoketest_cons\");\r\n    auto& x_ = unpack(x, \"x\", 0);\r\n    auto xs_ = unpack(xs, \"xs\", 1);\r\n    std::shared_ptr<SmoketestConsBackward> grad_fn;\r\n    auto requires_grad = compute_requires_grad({ x, xs });\r\n    if (requires_grad) {\r\n      grad_fn = std::make_shared<SmoketestConsBackward>();\r\n      grad_fn->next_functions = compute_next_functions({ x, xs });\r\n    }\r\n    auto ret = as_variable(baseType->_smoketest_cons(x_, xs_));\r\n    set_history(ret, grad_fn);\r\n    if (jit::tracer::isTracing( x, xs )) {\r\n      jit::Node *n = jit::tracer::recordTrace( \"_smoketest_cons\", flatten( x, xs ), ret );\r\n      (void)n;\r\n    }\r\n    return as_tensor_list(ret);\r\n}\r\n```\r\n\r\nThings to fix:\r\n1. `compute_requires_grad` doesn't typecheck. We'll replace it with a templated variadic thing (similar to `isTracing`) and remove the initializer list\r\n2. `compute_next_functions` doesn't typecheck. Also replace it with a templated variadic thing."}