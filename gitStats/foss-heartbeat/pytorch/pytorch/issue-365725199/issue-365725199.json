{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12248", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12248/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12248/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12248/events", "html_url": "https://github.com/pytorch/pytorch/issues/12248", "id": 365725199, "node_id": "MDU6SXNzdWUzNjU3MjUxOTk=", "number": 12248, "title": ".cuda() changes a module's behavior when there are registered buffers with requires_grad=True", "user": {"login": "oleg-trott", "id": 2914939, "node_id": "MDQ6VXNlcjI5MTQ5Mzk=", "avatar_url": "https://avatars1.githubusercontent.com/u/2914939?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oleg-trott", "html_url": "https://github.com/oleg-trott", "followers_url": "https://api.github.com/users/oleg-trott/followers", "following_url": "https://api.github.com/users/oleg-trott/following{/other_user}", "gists_url": "https://api.github.com/users/oleg-trott/gists{/gist_id}", "starred_url": "https://api.github.com/users/oleg-trott/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oleg-trott/subscriptions", "organizations_url": "https://api.github.com/users/oleg-trott/orgs", "repos_url": "https://api.github.com/users/oleg-trott/repos", "events_url": "https://api.github.com/users/oleg-trott/events{/privacy}", "received_events_url": "https://api.github.com/users/oleg-trott/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}, {"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-10-02T03:21:12Z", "updated_at": "2018-10-17T22:53:55Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>When a module that has a registered buffer with <code>requires_grad=True</code> is moved to the GPU, the buffer no longer accumulates gradients.</p>\n<h2>To Reproduce</h2>\n<p>Run the code below with and without the specified line commented out:</p>\n<pre><code>import torch\nfrom torch.autograd import Function, Variable\n\nm = torch.nn.Module()\nm.register_buffer('b', Variable(torch.ones(3), requires_grad=True)) # need the gradient\nm = m.cuda() # works when this line is commented out\nm.b.sum().backward()\nassert m.b.grad is not None\n</code></pre>\n<h2>Expected behavior</h2>\n<p>I think people generally expect a module to behave the same way after it's been moved to the GPU with <code>.cuda()</code></p>\n<h2>Environment</h2>\n<p>Torch 0.4.1</p>", "body_text": "\ud83d\udc1b Bug\nWhen a module that has a registered buffer with requires_grad=True is moved to the GPU, the buffer no longer accumulates gradients.\nTo Reproduce\nRun the code below with and without the specified line commented out:\nimport torch\nfrom torch.autograd import Function, Variable\n\nm = torch.nn.Module()\nm.register_buffer('b', Variable(torch.ones(3), requires_grad=True)) # need the gradient\nm = m.cuda() # works when this line is commented out\nm.b.sum().backward()\nassert m.b.grad is not None\n\nExpected behavior\nI think people generally expect a module to behave the same way after it's been moved to the GPU with .cuda()\nEnvironment\nTorch 0.4.1", "body": "## \ud83d\udc1b Bug\r\n\r\nWhen a module that has a registered buffer with `requires_grad=True` is moved to the GPU, the buffer no longer accumulates gradients.\r\n\r\n## To Reproduce\r\n\r\nRun the code below with and without the specified line commented out:\r\n\r\n```\r\nimport torch\r\nfrom torch.autograd import Function, Variable\r\n\r\nm = torch.nn.Module()\r\nm.register_buffer('b', Variable(torch.ones(3), requires_grad=True)) # need the gradient\r\nm = m.cuda() # works when this line is commented out\r\nm.b.sum().backward()\r\nassert m.b.grad is not None\r\n```\r\n\r\n## Expected behavior\r\n\r\nI think people generally expect a module to behave the same way after it's been moved to the GPU with `.cuda()`\r\n\r\n## Environment\r\n\r\nTorch 0.4.1\r\n"}