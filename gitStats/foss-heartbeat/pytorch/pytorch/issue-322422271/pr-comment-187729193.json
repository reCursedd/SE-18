{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187729193", "pull_request_review_id": 119575555, "id": 187729193, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NzcyOTE5Mw==", "diff_hunk": "@@ -1090,3 +884,133 @@ def symbolic_flattened_wrapper(g, input, *args):\n         symbolic_flattened_wrapper\n     )\n     return tuple(o for o in outputs)\n+\n+\n+def RNN_variant_symbolic_builder(\n+        variant, input_size, hidden_size, num_layers, batch_first, dropout, bidirectional, **kwargs):\n+    def symbolic(g, input, all_weights, initial_states, batch_sizes):\n+        if batch_first:\n+            return _unimplemented(\"RNN/GRU/LSTM\", \"batch_first\")\n+        if dropout and kwargs['train']:\n+            return _unimplemented(\"RNN/GRU/LSTM\", \"dropout in training mode\")\n+\n+        unidirectional = not bidirectional\n+\n+        prev_output = input\n+\n+        if variant == 'RNN' or variant == 'GRU':\n+            h0 = initial_states\n+            h_outs = []\n+        elif variant == 'LSTM':\n+            h0, c0 = initial_states\n+            h_outs = []\n+            c_outs = []\n+\n+        sequence_lens = unused(g) if batch_sizes is None else batch_sizes\n+\n+        for i in range(num_layers):\n+            if unidirectional:\n+                if variant == 'RNN':\n+                    weight_ih, weight_hh, bias_ih, bias_hh = all_weights[i]\n+                elif variant == 'GRU':\n+                    # pytorch is reset, input, hidden\n+                    # onnx is    input, reset, hidden\n+                    weight_ih, weight_hh, bias_ih, bias_hh = \\\n+                        [reform_weights(g, w, hidden_size, [(1, 2), (0, 1), (2, 3)]) for w in all_weights[i]]\n+                elif variant == 'LSTM':\n+                    # pytorch is input, forget, cell, output.\n+                    # onnx is    input, output, forget, cell.\n+                    weight_ih, weight_hh, bias_ih, bias_hh = \\\n+                        [reform_weights(g, w, hidden_size, [(0, 1), (3, 4), (1, 3)]) for w in all_weights[i]]\n+                bias_concat = g.op('Concat', bias_ih, bias_hh, axis_i=0)\n+\n+                # Unidirectional weights in PyTorch omit the\n+                # directionality dimension (dim=0), whereas in ONNX it\n+                # is required even for unidirectional RNN; thus,\n+                # insert a dimension of size at dim=0.\n+                weight_ih = g.op('Unsqueeze', weight_ih, axes_i=[0])\n+                weight_hh = g.op('Unsqueeze', weight_hh, axes_i=[0])\n+                bias_concat = g.op('Unsqueeze', bias_concat, axes_i=[0])\n+\n+                if variant == 'RNN' or variant == 'GRU':\n+                    state_inputs = [\n+                        h0 if num_layers == 1 else g.op('Slice', h0, axes_i=[0], starts_i=[i], ends_i=[i + 1])\n+                    ]\n+                elif variant == 'LSTM':\n+                    state_inputs = [\n+                        h0 if num_layers == 1 else g.op('Slice', h0, axes_i=[0], starts_i=[i], ends_i=[i + 1]),\n+                        c0 if num_layers == 1 else g.op('Slice', c0, axes_i=[0], starts_i=[i], ends_i=[i + 1])\n+                    ]\n+            else:\n+                if variant == 'RNN':\n+                    weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f = all_weights[2 * i]\n+                    weight_ih_b, weight_hh_b, bias_ih_b, bias_hh_b = all_weights[2 * i + 1]\n+                elif variant == 'GRU':\n+                    # pytorch is reset, input, hidden\n+                    # onnx is    input, reset, hidden\n+                    weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f = \\\n+                        [reform_weights(g, w, hidden_size, [(1, 2), (0, 1), (2, 3)]) for w in all_weights[2 * i]]", "path": "torch/onnx/symbolic.py", "position": null, "original_position": 297, "commit_id": "1dd664d41ca3e52b60e6aebf7afbc773be650974", "original_commit_id": "2fa42d57d6108c145496609c92949bf3804c415a", "user": {"login": "anderspapitto", "id": 1388690, "node_id": "MDQ6VXNlcjEzODg2OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1388690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anderspapitto", "html_url": "https://github.com/anderspapitto", "followers_url": "https://api.github.com/users/anderspapitto/followers", "following_url": "https://api.github.com/users/anderspapitto/following{/other_user}", "gists_url": "https://api.github.com/users/anderspapitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/anderspapitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anderspapitto/subscriptions", "organizations_url": "https://api.github.com/users/anderspapitto/orgs", "repos_url": "https://api.github.com/users/anderspapitto/repos", "events_url": "https://api.github.com/users/anderspapitto/events{/privacy}", "received_events_url": "https://api.github.com/users/anderspapitto/received_events", "type": "User", "site_admin": false}, "body": "well, this does generate a ton of operators in the resulting graph, so I would like to skip it entirely in the RNN case (but I can add a comment saying this). Otherwise yes should be possible", "created_at": "2018-05-11T20:48:59Z", "updated_at": "2018-11-23T15:43:58Z", "html_url": "https://github.com/pytorch/pytorch/pull/7506#discussion_r187729193", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7506", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/187729193"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7506#discussion_r187729193"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7506"}}, "body_html": "<p>well, this does generate a ton of operators in the resulting graph, so I would like to skip it entirely in the RNN case (but I can add a comment saying this). Otherwise yes should be possible</p>", "body_text": "well, this does generate a ton of operators in the resulting graph, so I would like to skip it entirely in the RNN case (but I can add a comment saying this). Otherwise yes should be possible", "in_reply_to_id": 187727187}