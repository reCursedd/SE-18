{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/306001441", "html_url": "https://github.com/pytorch/pytorch/issues/630#issuecomment-306001441", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/630", "id": 306001441, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjAwMTQ0MQ==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-03T21:06:37Z", "updated_at": "2017-06-03T21:06:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I would like to take this opportunity to once again bring up the discussion of more flexible RNN APIs. While it is easy to write a custom recurrent cell in pytorch to use in a single layer unidirectional net, if one wants to use non-standard cell implementations (or modify existing implementations) with stacking and bidirectional, it becomes quite cumbersome and clutters the API, as this PR and skip_input PRs demonstrate. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22205833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/csarofeen\">@csarofeen</a> had a proposal for more flexible APIs in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"206652810\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/711\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/711/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/711\">#711</a>, and while ultimately we may decide to take some other route, it is time to start thinking about it, or we will come to major releases that would freeze the APIs without working it out.</p>", "body_text": "I would like to take this opportunity to once again bring up the discussion of more flexible RNN APIs. While it is easy to write a custom recurrent cell in pytorch to use in a single layer unidirectional net, if one wants to use non-standard cell implementations (or modify existing implementations) with stacking and bidirectional, it becomes quite cumbersome and clutters the API, as this PR and skip_input PRs demonstrate. @csarofeen had a proposal for more flexible APIs in #711, and while ultimately we may decide to take some other route, it is time to start thinking about it, or we will come to major releases that would freeze the APIs without working it out.", "body": "I would like to take this opportunity to once again bring up the discussion of more flexible RNN APIs. While it is easy to write a custom recurrent cell in pytorch to use in a single layer unidirectional net, if one wants to use non-standard cell implementations (or modify existing implementations) with stacking and bidirectional, it becomes quite cumbersome and clutters the API, as this PR and skip_input PRs demonstrate. @csarofeen had a proposal for more flexible APIs in #711, and while ultimately we may decide to take some other route, it is time to start thinking about it, or we will come to major releases that would freeze the APIs without working it out. "}