{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10715", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10715/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10715/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10715/events", "html_url": "https://github.com/pytorch/pytorch/issues/10715", "id": 352355590, "node_id": "MDU6SXNzdWUzNTIzNTU1OTA=", "number": 10715, "title": "[JIT] Making JIT work with Pyro's VAE example", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-08-21T01:49:10Z", "updated_at": "2018-09-19T18:52:03Z", "closed_at": "2018-09-19T18:52:03Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>Currently most Pyro <a href=\"https://github.com/uber/pyro/tree/dev/examples\">examples</a> fail when run with JIT, and one of the common errors is the following:</p>\n<pre><code>RuntimeError: nDim &lt;= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\n</code></pre>\n<h2>Code example</h2>\n<p>You can run the VAE example in Pyro as follows:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ git checkout pytorch-0.4.1\n$ python examples/vae/vae.py --num-epochs 1 --jit</pre></div>\n<p>, which throws the following error on PyTorch master.</p>\n<details><summary> Error Trace </summary>\n<pre><code>clang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\nTraceback (most recent call last):\n  File \"examples/vae/vae.py\", line 212, in &lt;module&gt;\n    model = main(args)\n  File \"examples/vae/vae.py\", line 154, in main\n    epoch_loss += svi.step(x)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\n    ret = self.compiled[argc](*params_and_args)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\n    return self._get_method('forward')(*args, **kwargs)\nRuntimeError: nDim &lt;= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\nframe #0: torch::jit::CompiledFusionFunction::launch_with_tensors(at::ArrayRef&lt;at::Tensor&gt;, at::ArrayRef&lt;at::Tensor&gt;) + 1980 (0x113bcc8dc in libtorch.dylib)\nframe #1: torch::jit::CompiledFusionFunction::launch(at::ArrayRef&lt;at::Tensor&gt;, std::__1::vector&lt;at::Tensor, std::__1::allocator&lt;at::Tensor&gt; &gt;&amp;) + 525 (0x113bce4dd in libtorch.dylib)\nframe #2: std::__1::__function::__func&lt;torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;), std::__1::allocator&lt;torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;, int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 379 (0x113d3c67b in libtorch.dylib)\nframe #3: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 139 (0x113ce933b in libtorch.dylib)\nframe #4: torch::jit::GraphExecutorImpl::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 5756 (0x113cc456c in libtorch.dylib)\nframe #5: std::__1::__function::__func&lt;torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;), std::__1::allocator&lt;torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;, int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 45 (0x113cf143d in libtorch.dylib)\nframe #6: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 139 (0x113ce933b in libtorch.dylib)\nframe #7: torch::jit::GraphExecutorImpl::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 187 (0x113cc2fab in libtorch.dylib)\nframe #8: torch::jit::script::Method::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 346 (0x10e2ad5da in _C.cpython-36m-darwin.so)\nframe #9: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&amp;, pybind11::args) + 279 (0x10e2a4ec7 in _C.cpython-36m-darwin.so)\nframe #10: pybind11::object pybind11::detail::argument_loader&lt;torch::jit::script::Method&amp;, pybind11::args&gt;::call_impl&lt;pybind11::object, pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args), 0ul, 1ul, pybind11::detail::void_type&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args), pybind11::detail::index_sequence&lt;0ul, 1ul&gt;, pybind11::detail::void_type&amp;&amp;) + 54 (0x10e2bf5c6 in _C.cpython-36m-darwin.so)\nframe #11: void pybind11::cpp_function::initialize&lt;pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args), pybind11::object, torch::jit::script::Method&amp;, pybind11::args, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args), pybind11::object (*)(torch::jit::script::Method&amp;, pybind11::args), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(pybind11::detail::function_call&amp;)::operator()(pybind11::detail::function_call&amp;) const + 212 (0x10e2bf4c4 in _C.cpython-36m-darwin.so)\nframe #12: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3392 (0x10df06ce0 in _C.cpython-36m-darwin.so)\n&lt;omitting python frames&gt;\nframe #60: start + 1 (0x7fff53648115 in libdyld.dylib)\n</code></pre>\n</details>\n<p><br>\nTo run all Pyro examples and record the output / error traces, you could also simply run:</p>\n<pre><code>$ make test-jit\n</code></pre>\n<p>Notice from the output of <code>jit.log</code> that most of our unit tests pass with JIT, but the bigger examples are all failing except for the simpler <code>bayesian_regression.py</code> example. I am not entirely sure under what conditions this error is triggered, but I am happy to debug more if you provide me with some pointers.</p>\n<h2>System Info</h2>\n<pre><code>$ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+e449a27\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] pyro-ppl (0.2.1+a547dcbc, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\n[pip] torch (0.5.0a0+e449a27)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+e449a27           &lt;pip&gt;\n[conda] torch                     0.5.0a0+64a6003           &lt;pip&gt;\n[conda] torch                     0.5.0a0+6456b94           &lt;pip&gt;\n[conda] torch                     0.5.0a0+cd53b78           &lt;pip&gt;\n[conda] torchfile                 0.1.0                     &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>\n<p>cc. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a></p>", "body_text": "Issue description\nCurrently most Pyro examples fail when run with JIT, and one of the common errors is the following:\nRuntimeError: nDim <= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\n\nCode example\nYou can run the VAE example in Pyro as follows:\n$ git checkout pytorch-0.4.1\n$ python examples/vae/vae.py --num-epochs 1 --jit\n, which throws the following error on PyTorch master.\n Error Trace \nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\nTraceback (most recent call last):\n  File \"examples/vae/vae.py\", line 212, in <module>\n    model = main(args)\n  File \"examples/vae/vae.py\", line 154, in main\n    epoch_loss += svi.step(x)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\n    ret = self.compiled[argc](*params_and_args)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\n    return self._get_method('forward')(*args, **kwargs)\nRuntimeError: nDim <= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\nframe #0: torch::jit::CompiledFusionFunction::launch_with_tensors(at::ArrayRef<at::Tensor>, at::ArrayRef<at::Tensor>) + 1980 (0x113bcc8dc in libtorch.dylib)\nframe #1: torch::jit::CompiledFusionFunction::launch(at::ArrayRef<at::Tensor>, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor> >&) + 525 (0x113bce4dd in libtorch.dylib)\nframe #2: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 379 (0x113d3c67b in libtorch.dylib)\nframe #3: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 139 (0x113ce933b in libtorch.dylib)\nframe #4: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 5756 (0x113cc456c in libtorch.dylib)\nframe #5: std::__1::__function::__func<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 45 (0x113cf143d in libtorch.dylib)\nframe #6: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 139 (0x113ce933b in libtorch.dylib)\nframe #7: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 187 (0x113cc2fab in libtorch.dylib)\nframe #8: torch::jit::script::Method::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 346 (0x10e2ad5da in _C.cpython-36m-darwin.so)\nframe #9: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&, pybind11::args) + 279 (0x10e2a4ec7 in _C.cpython-36m-darwin.so)\nframe #10: pybind11::object pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args>::call_impl<pybind11::object, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args), 0ul, 1ul, pybind11::detail::void_type>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args), pybind11::detail::index_sequence<0ul, 1ul>, pybind11::detail::void_type&&) + 54 (0x10e2bf5c6 in _C.cpython-36m-darwin.so)\nframe #11: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args), pybind11::object (*)(torch::jit::script::Method&, pybind11::args), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 212 (0x10e2bf4c4 in _C.cpython-36m-darwin.so)\nframe #12: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3392 (0x10df06ce0 in _C.cpython-36m-darwin.so)\n<omitting python frames>\nframe #60: start + 1 (0x7fff53648115 in libdyld.dylib)\n\n\n\nTo run all Pyro examples and record the output / error traces, you could also simply run:\n$ make test-jit\n\nNotice from the output of jit.log that most of our unit tests pass with JIT, but the bigger examples are all failing except for the simpler bayesian_regression.py example. I am not entirely sure under what conditions this error is triggered, but I am happy to debug more if you provide me with some pointers.\nSystem Info\n$ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+e449a27\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] pyro-ppl (0.2.1+a547dcbc, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\n[pip] torch (0.5.0a0+e449a27)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+e449a27           <pip>\n[conda] torch                     0.5.0a0+64a6003           <pip>\n[conda] torch                     0.5.0a0+6456b94           <pip>\n[conda] torch                     0.5.0a0+cd53b78           <pip>\n[conda] torchfile                 0.1.0                     <pip>\n[conda] torchvision               0.2.1                     <pip>\n\ncc. @fritzo, @apaszke, @soumith", "body": "## Issue description\r\n\r\nCurrently most Pyro [examples](https://github.com/uber/pyro/tree/dev/examples) fail when run with JIT, and one of the common errors is the following:\r\n\r\n```\r\nRuntimeError: nDim <= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\r\n```\r\n\r\n## Code example\r\nYou can run the VAE example in Pyro as follows:\r\n\r\n```sh\r\n$ git checkout pytorch-0.4.1\r\n$ python examples/vae/vae.py --num-epochs 1 --jit\r\n```\r\n, which throws the following error on PyTorch master.\r\n<details><Summary> Error Trace </Summary>\r\n\r\n```\r\nclang: error: unsupported option '-fopenmp'\r\nclang: error: unsupported option '-fopenmp'\r\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\r\nTraceback (most recent call last):\r\n  File \"examples/vae/vae.py\", line 212, in <module>\r\n    model = main(args)\r\n  File \"examples/vae/vae.py\", line 154, in main\r\n    epoch_loss += svi.step(x)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\r\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\r\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\r\n    ret = self.compiled[argc](*params_and_args)\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\r\n    return self._get_method('forward')(*args, **kwargs)\r\nRuntimeError: nDim <= uncompressedDim ASSERT FAILED at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724, please report a bug to PyTorch. (operator() at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/torch/csrc/jit/fusion_compiler.cpp:724)\r\nframe #0: torch::jit::CompiledFusionFunction::launch_with_tensors(at::ArrayRef<at::Tensor>, at::ArrayRef<at::Tensor>) + 1980 (0x113bcc8dc in libtorch.dylib)\r\nframe #1: torch::jit::CompiledFusionFunction::launch(at::ArrayRef<at::Tensor>, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor> >&) + 525 (0x113bce4dd in libtorch.dylib)\r\nframe #2: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 379 (0x113d3c67b in libtorch.dylib)\r\nframe #3: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 139 (0x113ce933b in libtorch.dylib)\r\nframe #4: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 5756 (0x113cc456c in libtorch.dylib)\r\nframe #5: std::__1::__function::__func<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 45 (0x113cf143d in libtorch.dylib)\r\nframe #6: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 139 (0x113ce933b in libtorch.dylib)\r\nframe #7: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 187 (0x113cc2fab in libtorch.dylib)\r\nframe #8: torch::jit::script::Method::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 346 (0x10e2ad5da in _C.cpython-36m-darwin.so)\r\nframe #9: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&, pybind11::args) + 279 (0x10e2a4ec7 in _C.cpython-36m-darwin.so)\r\nframe #10: pybind11::object pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args>::call_impl<pybind11::object, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args), 0ul, 1ul, pybind11::detail::void_type>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args), pybind11::detail::index_sequence<0ul, 1ul>, pybind11::detail::void_type&&) + 54 (0x10e2bf5c6 in _C.cpython-36m-darwin.so)\r\nframe #11: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args), pybind11::object (*)(torch::jit::script::Method&, pybind11::args), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 212 (0x10e2bf4c4 in _C.cpython-36m-darwin.so)\r\nframe #12: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3392 (0x10df06ce0 in _C.cpython-36m-darwin.so)\r\n<omitting python frames>\r\nframe #60: start + 1 (0x7fff53648115 in libdyld.dylib)\r\n```\r\n\r\n</details>\r\n\r\n\\\r\nTo run all Pyro examples and record the output / error traces, you could also simply run:\r\n\r\n```\r\n$ make test-jit\r\n```\r\nNotice from the output of `jit.log` that most of our unit tests pass with JIT, but the bigger examples are all failing except for the simpler `bayesian_regression.py` example. I am not entirely sure under what conditions this error is triggered, but I am happy to debug more if you provide me with some pointers.\r\n\r\n## System Info\r\n\r\n```\r\n$ python collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 0.5.0a0+e449a27\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.0)\r\n[pip] pyro-ppl (0.2.1+a547dcbc, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\r\n[pip] torch (0.5.0a0+e449a27)\r\n[pip] torchfile (0.1.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] torch                     0.5.0a0+e449a27           <pip>\r\n[conda] torch                     0.5.0a0+64a6003           <pip>\r\n[conda] torch                     0.5.0a0+6456b94           <pip>\r\n[conda] torch                     0.5.0a0+cd53b78           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n\r\ncc. @fritzo, @apaszke, @soumith "}