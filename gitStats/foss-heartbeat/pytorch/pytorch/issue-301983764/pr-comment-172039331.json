{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/172039331", "pull_request_review_id": 100996970, "id": 172039331, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MjAzOTMzMQ==", "diff_hunk": "@@ -0,0 +1,1020 @@\n+C++ Extensions\n+==============\n+\n+PyTorch provides a plethora of operations related to neural networks, arbitrary\n+tensor algebra, data wrangling and other purposes. However, you may still find\n+yourself in need of a more customized operation. For example, you might want to\n+use a novel activation function you found in a paper, or implement an operation\n+you developed as part of your research.\n+\n+The easiest way of integrating such a custom operation in PyTorch is to write it\n+in Python by extending :class:`Function` and :class:`Module` as outlined `here\n+<http://pytorch.org/docs/master/notes/extending.html>`_. This gives you the full\n+power of automatic differentiation (spares you from writing derivative\n+functions) as well as the usual expressiveness of Python. However, there may be\n+times when your operation is better implemented in C++. For example, your code\n+may need to be *really* fast because it is called very frequently in your model\n+or is very expensive even for few calls. Another plausible reason is that it\n+depends on or interacts with other C or C++ libraries. To address such cases,\n+PyTorch provides a very easy way of writing custom *C++ extensions*.\n+\n+C++ extensions are a mechanism we have developed to allow users (you) to create\n+PyTorch operators defined *out-of-source*, i.e. separate from the PyTorch\n+backend. This approach is *different* from the way native PyTorch operations are\n+implemented. C++ extensions are intended to spare you much of the boilerplate\n+associated with integrating an operation with PyTorch's backend while providing\n+you with a high degree of flexibility for your PyTorch-based projects.\n+Nevertheless, once you have defined your operation as a C++ extension, turning\n+it into a native PyTorch function is largely a matter of code organization,\n+which you can tackle after the fact if you decide to contribute your operation\n+upstream.\n+\n+Motivation and Example\n+----------------------\n+\n+The rest of this note will walk through a practical example of writing and using\n+a C++ (and CUDA) extension. If you are being chased or someone will fire you if\n+you don't get that op done by the end of the day, you can skip this section and\n+head straight to the implementation details in the next section.\n+\n+Let's say you've come up with a new kind of recurrent unit that you found to\n+have superior properties compared to the state of the art. This recurrent unit\n+is similar to an LSTM, but differs in that it lacks a *forget gate* and uses an\n+*Exponential Linear Unit* (ELU) as its internal activation function. Because\n+this unit never forgets, we'll call it *LLTM*, or *Long-Long-Term-Memory* unit.", "path": "docs/source/notes/cpp-extensions.rst", "position": 44, "original_position": 44, "commit_id": "99b1615503e34d176d98e4c3a48041ee0b1c115b", "original_commit_id": "99b1615503e34d176d98e4c3a48041ee0b1c115b", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "loooool", "created_at": "2018-03-04T07:12:54Z", "updated_at": "2018-11-23T15:40:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/5541#discussion_r172039331", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5541", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/172039331"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5541#discussion_r172039331"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5541"}}, "body_html": "<p>loooool</p>", "body_text": "loooool"}