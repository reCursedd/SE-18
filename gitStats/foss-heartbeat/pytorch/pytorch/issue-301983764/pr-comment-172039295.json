{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/172039295", "pull_request_review_id": 100996921, "id": 172039295, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MjAzOTI5NQ==", "diff_hunk": "@@ -0,0 +1,1020 @@\n+C++ Extensions\n+==============\n+\n+PyTorch provides a plethora of operations related to neural networks, arbitrary\n+tensor algebra, data wrangling and other purposes. However, you may still find\n+yourself in need of a more customized operation. For example, you might want to\n+use a novel activation function you found in a paper, or implement an operation\n+you developed as part of your research.\n+\n+The easiest way of integrating such a custom operation in PyTorch is to write it\n+in Python by extending :class:`Function` and :class:`Module` as outlined `here\n+<http://pytorch.org/docs/master/notes/extending.html>`_. This gives you the full\n+power of automatic differentiation (spares you from writing derivative\n+functions) as well as the usual expressiveness of Python. However, there may be\n+times when your operation is better implemented in C++. For example, your code\n+may need to be *really* fast because it is called very frequently in your model\n+or is very expensive even for few calls. Another plausible reason is that it\n+depends on or interacts with other C or C++ libraries. To address such cases,\n+PyTorch provides a very easy way of writing custom *C++ extensions*.\n+\n+C++ extensions are a mechanism we have developed to allow users (you) to create\n+PyTorch operators defined *out-of-source*, i.e. separate from the PyTorch\n+backend. This approach is *different* from the way native PyTorch operations are", "path": "docs/source/notes/cpp-extensions.rst", "position": 23, "original_position": 23, "commit_id": "99b1615503e34d176d98e4c3a48041ee0b1c115b", "original_commit_id": "bef221f425ba4e4592c9d98750d80e15b37d9dee", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Nit: I'm not sure how important it is for the reader to know how native PyTorch ops are implemented, except maybe as an aside.", "created_at": "2018-03-04T07:10:55Z", "updated_at": "2018-11-23T15:40:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/5541#discussion_r172039295", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5541", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/172039295"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5541#discussion_r172039295"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5541"}}, "body_html": "<p>Nit: I'm not sure how important it is for the reader to know how native PyTorch ops are implemented, except maybe as an aside.</p>", "body_text": "Nit: I'm not sure how important it is for the reader to know how native PyTorch ops are implemented, except maybe as an aside."}