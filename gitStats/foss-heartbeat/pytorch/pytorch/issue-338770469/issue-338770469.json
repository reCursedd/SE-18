{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9199", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9199/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9199/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9199/events", "html_url": "https://github.com/pytorch/pytorch/pull/9199", "id": 338770469, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk5NjIwMzY5", "number": 9199, "title": "Fix shape inference bug", "user": {"login": "hlu1", "id": 14827759, "node_id": "MDQ6VXNlcjE0ODI3NzU5", "avatar_url": "https://avatars2.githubusercontent.com/u/14827759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hlu1", "html_url": "https://github.com/hlu1", "followers_url": "https://api.github.com/users/hlu1/followers", "following_url": "https://api.github.com/users/hlu1/following{/other_user}", "gists_url": "https://api.github.com/users/hlu1/gists{/gist_id}", "starred_url": "https://api.github.com/users/hlu1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hlu1/subscriptions", "organizations_url": "https://api.github.com/users/hlu1/orgs", "repos_url": "https://api.github.com/users/hlu1/repos", "events_url": "https://api.github.com/users/hlu1/events{/privacy}", "received_events_url": "https://api.github.com/users/hlu1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-07-06T00:54:15Z", "updated_at": "2018-07-06T22:17:12Z", "closed_at": "2018-07-06T22:17:12Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9199", "html_url": "https://github.com/pytorch/pytorch/pull/9199", "diff_url": "https://github.com/pytorch/pytorch/pull/9199.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9199.patch"}, "body_html": "<p>Summary:<br>\nThe input shapes are not logged correctly in production because <code>PerfNetObserver::Stop()</code> only gets called after the inference is done for the net and in the mobile models, it's common practice to reuse the blobs as much as possible to save memory. And the shapes of the blobs keep changing during inference. By the time you you query <code>InputTensorShapes()</code> in <code>PerfNetObserver::Stop()</code>, you only get the final shape of the blobs.</p>\n<p>To fix this bug, I moved the 'InputTensorShapes()' query from <code>PerfNetObserver::Stop()</code> to <code>PerfOperatorObserver::Stop()</code>. The latter gets called at the end of operator-&gt;run() whereas <code>PerfNetObserver::Stop()</code> gets called at the end of net-&gt;run().</p>\n<p>Also remove <code>PerfOperatorObserver::getAnalyticalCost()</code> since it's now done on the server side and no longer needed on mobile</p>\n<p>Differential Revision: D8743346</p>", "body_text": "Summary:\nThe input shapes are not logged correctly in production because PerfNetObserver::Stop() only gets called after the inference is done for the net and in the mobile models, it's common practice to reuse the blobs as much as possible to save memory. And the shapes of the blobs keep changing during inference. By the time you you query InputTensorShapes() in PerfNetObserver::Stop(), you only get the final shape of the blobs.\nTo fix this bug, I moved the 'InputTensorShapes()' query from PerfNetObserver::Stop() to PerfOperatorObserver::Stop(). The latter gets called at the end of operator->run() whereas PerfNetObserver::Stop() gets called at the end of net->run().\nAlso remove PerfOperatorObserver::getAnalyticalCost() since it's now done on the server side and no longer needed on mobile\nDifferential Revision: D8743346", "body": "Summary:\nThe input shapes are not logged correctly in production because `PerfNetObserver::Stop()` only gets called after the inference is done for the net and in the mobile models, it's common practice to reuse the blobs as much as possible to save memory. And the shapes of the blobs keep changing during inference. By the time you you query `InputTensorShapes()` in `PerfNetObserver::Stop()`, you only get the final shape of the blobs.\n\nTo fix this bug, I moved the 'InputTensorShapes()' query from `PerfNetObserver::Stop()` to `PerfOperatorObserver::Stop()`. The latter gets called at the end of operator->run() whereas `PerfNetObserver::Stop()` gets called at the end of net->run().\n\nAlso remove `PerfOperatorObserver::getAnalyticalCost()` since it's now done on the server side and no longer needed on mobile\n\nDifferential Revision: D8743346\n"}