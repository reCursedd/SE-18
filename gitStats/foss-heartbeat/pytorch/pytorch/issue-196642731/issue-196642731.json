{"url": "https://api.github.com/repos/pytorch/pytorch/issues/333", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/333/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/333/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/333/events", "html_url": "https://github.com/pytorch/pytorch/pull/333", "id": 196642731, "node_id": "MDExOlB1bGxSZXF1ZXN0OTg3MjY1MTg=", "number": 333, "title": "Sparse Library", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-12-20T10:54:39Z", "updated_at": "2018-11-23T15:32:11Z", "closed_at": "2017-01-04T23:43:42Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/333", "html_url": "https://github.com/pytorch/pytorch/pull/333", "diff_url": "https://github.com/pytorch/pytorch/pull/333.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/333.patch"}, "body_html": "<p>I redid this PR, since the last one was old and I did not want to rebase everything just to change up the module format. For reference: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"182381746\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/116\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/116/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/116\">#116</a></p>\n<p>Having sparse modules in csrc/Modules.cpp allows us unify calling functions that require sparse and non-sparse arguments. In the previous PR, <code>sparse.addmm</code> is now just <code>torch.addmm</code> and torch will call the correct functions.</p>\n<p>This is added as a \"Sparse=True\" flag to the Embedding Module. The modifications for the training loop is given in <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/ebetica/examples/commit/3c41e571cf4883dfb9c15a647dfdfe7a740c189d/hovercard\" href=\"https://github.com/ebetica/examples/commit/3c41e571cf4883dfb9c15a647dfdfe7a740c189d\">ebetica/examples@<tt>3c41e57</tt></a></p>\n<p>The list of implemented functions are in <code>torch/csrc/generic/methods/SparseTensor.cwrap</code></p>", "body_text": "I redid this PR, since the last one was old and I did not want to rebase everything just to change up the module format. For reference: #116\nHaving sparse modules in csrc/Modules.cpp allows us unify calling functions that require sparse and non-sparse arguments. In the previous PR, sparse.addmm is now just torch.addmm and torch will call the correct functions.\nThis is added as a \"Sparse=True\" flag to the Embedding Module. The modifications for the training loop is given in ebetica/examples@3c41e57\nThe list of implemented functions are in torch/csrc/generic/methods/SparseTensor.cwrap", "body": "I redid this PR, since the last one was old and I did not want to rebase everything just to change up the module format. For reference: https://github.com/pytorch/pytorch/pull/116\r\n\r\nHaving sparse modules in csrc/Modules.cpp allows us unify calling functions that require sparse and non-sparse arguments. In the previous PR, `sparse.addmm` is now just `torch.addmm` and torch will call the correct functions.\r\n\r\nThis is added as a \"Sparse=True\" flag to the Embedding Module. The modifications for the training loop is given in https://github.com/ebetica/examples/commit/3c41e571cf4883dfb9c15a647dfdfe7a740c189d\r\n\r\nThe list of implemented functions are in `torch/csrc/generic/methods/SparseTensor.cwrap`"}