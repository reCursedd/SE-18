{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93302627", "pull_request_review_id": 13827392, "id": 93302627, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDkzMzAyNjI3", "diff_hunk": "@@ -38,6 +38,22 @@ static bool THCPModule_loadClasses(PyObject *module_dict)\n #undef ASSERT_NOT_NULL\n }\n \n+static bool THCSPModule_loadClasses(PyObject *module_dict)\n+{\n+#define ASSERT_NOT_NULL(ptr) if (!(ptr)) { THPUtils_setError(\"couldn't load classes\"); return false; }\n+  ASSERT_NOT_NULL(THCSPDoubleTensorClass  = PyMapping_GetItemString(module_dict, (char*)\"DoubleTensor\"));\n+  //ASSERT_NOT_NULL(THCSPHalfTensorClass    = PyMapping_GetItemString(module_dict, (char*)\"HalfTensor\"));", "path": "torch/csrc/cuda/Module.cpp", "position": null, "original_position": 8, "commit_id": "faf9836c10da24d1d5ca51639780bd34a0a414dd", "original_commit_id": "c8b8d1a447ee21655f2e2ba282ba7b23478db4f0", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "body": "CUDA sparse tensor operations aren't implemented. They are stubbed out for now (this is most useful for large vocab, in which case you'd keep the tensors on the CPU anyway). I'll still uncomment this but it shouldn't do anything.", "created_at": "2016-12-20T19:02:23Z", "updated_at": "2018-11-23T15:32:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/333#discussion_r93302627", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/333", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93302627"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/333#discussion_r93302627"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/333"}}, "body_html": "<p>CUDA sparse tensor operations aren't implemented. They are stubbed out for now (this is most useful for large vocab, in which case you'd keep the tensors on the CPU anyway). I'll still uncomment this but it shouldn't do anything.</p>", "body_text": "CUDA sparse tensor operations aren't implemented. They are stubbed out for now (this is most useful for large vocab, in which case you'd keep the tensors on the CPU anyway). I'll still uncomment this but it shouldn't do anything.", "in_reply_to_id": 93221713}