{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2418", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2418/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2418/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2418/events", "html_url": "https://github.com/pytorch/pytorch/issues/2418", "id": 250217234, "node_id": "MDU6SXNzdWUyNTAyMTcyMzQ=", "number": 2418, "title": "Training with nn.GRU on multi-gpu causes CUDNN_STATUS_EXECUTION_FAILED", "user": {"login": "hwchong", "id": 392690, "node_id": "MDQ6VXNlcjM5MjY5MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/392690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hwchong", "html_url": "https://github.com/hwchong", "followers_url": "https://api.github.com/users/hwchong/followers", "following_url": "https://api.github.com/users/hwchong/following{/other_user}", "gists_url": "https://api.github.com/users/hwchong/gists{/gist_id}", "starred_url": "https://api.github.com/users/hwchong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hwchong/subscriptions", "organizations_url": "https://api.github.com/users/hwchong/orgs", "repos_url": "https://api.github.com/users/hwchong/repos", "events_url": "https://api.github.com/users/hwchong/events{/privacy}", "received_events_url": "https://api.github.com/users/hwchong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-15T04:10:16Z", "updated_at": "2017-08-15T05:32:24Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I've been trying to train recurrent neural network using nn.GRU on a multi-GPU setup and am randomly getting crashes caused by CuDNN.</p>\n<p>I'm using PyTorch 0.2 on Linux running in an nvidia-docker container with the latest nvidia/cuda image.</p>\n<p>This is the error message that comes up:</p>\n<p>CuDNNError                                Traceback (most recent call last)<br>\n in ()<br>\n7         optimizer.zero_grad()<br>\n8         model.module.hidden = model.module.init_hidden()<br>\n----&gt; 9         outputs = model(inputs)<br>\n10         outputs = outputs.view((-1))<br>\n11         loss = criterion(outputs, labels)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in <strong>call</strong>(self, *input, **kwargs)<br>\n222         for hook in self._forward_pre_hooks.values():<br>\n223             hook(self, input)<br>\n--&gt; 224         result = self.forward(*input, **kwargs)<br>\n225         for hook in self._forward_hooks.values():<br>\n226             hook_result = hook(self, input, result)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in forward(self, *inputs, **kwargs)<br>\n58             return self.module(*inputs[0], **kwargs[0])<br>\n59         replicas = self.replicate(self.module, self.device_ids[:len(inputs)])<br>\n---&gt; 60         outputs = self.parallel_apply(replicas, inputs, kwargs)<br>\n61         return self.gather(outputs, self.output_device)<br>\n62</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in parallel_apply(self, replicas, inputs, kwargs)<br>\n68<br>\n69     def parallel_apply(self, replicas, inputs, kwargs):<br>\n---&gt; 70         return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])<br>\n71<br>\n72     def gather(self, outputs, output_device):</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in parallel_apply(modules, inputs, kwargs_tup, devices)<br>\n65         output = results[i]<br>\n66         if isinstance(output, Exception):<br>\n---&gt; 67             raise output<br>\n68         outputs.append(output)<br>\n69     return outputs</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in _worker(i, module, input, kwargs, results, lock, device)<br>\n40         try:<br>\n41             with torch.cuda.device(device):<br>\n---&gt; 42                 output = module(*input, **kwargs)<br>\n43             with lock:<br>\n44                 results[i] = output</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in <strong>call</strong>(self, *input, **kwargs)<br>\n222         for hook in self._forward_pre_hooks.values():<br>\n223             hook(self, input)<br>\n--&gt; 224         result = self.forward(*input, **kwargs)<br>\n225         for hook in self._forward_hooks.values():<br>\n226             hook_result = hook(self, input, result)</p>\n<p> in forward(self, input)<br>\n15     def forward(self, input):<br>\n16         #self.hidden = self.init_hidden()<br>\n---&gt; 17         gru_out, self.hidden = self.gru(input, self.hidden)<br>\n18         x = gru_out[:, -1]<br>\n19         x = self.dropout(x)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in <strong>call</strong>(self, *input, **kwargs)<br>\n222         for hook in self._forward_pre_hooks.values():<br>\n223             hook(self, input)<br>\n--&gt; 224         result = self.forward(*input, **kwargs)<br>\n225         for hook in self._forward_hooks.values():<br>\n226             hook_result = hook(self, input, result)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py in forward(self, input, hx)<br>\n160             flat_weight=flat_weight<br>\n161         )<br>\n--&gt; 162         output, hidden = func(input, self.all_weights, hx)<br>\n163         if is_packed:<br>\n164             output = PackedSequence(output, batch_sizes)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward(input, *fargs, **fkwargs)<br>\n349         else:<br>\n350             func = AutogradRNN(*args, **kwargs)<br>\n--&gt; 351         return func(input, *fargs, **fkwargs)<br>\n352<br>\n353     return forward</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in _do_forward(self, *input)<br>\n282         self._nested_input = input<br>\n283         flat_input = tuple(_iter_variables(input))<br>\n--&gt; 284         flat_output = super(NestedIOFunction, self)._do_forward(*flat_input)<br>\n285         nested_output = self._nested_output<br>\n286         nested_variables = _unflatten(flat_output, self._nested_output)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in forward(self, *args)<br>\n304     def forward(self, *args):<br>\n305         nested_tensors = _map_variable_tensor(self._nested_input)<br>\n--&gt; 306         result = self.forward_extended(*nested_tensors)<br>\n307         del self._nested_input<br>\n308         self._nested_output = result</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward_extended(self, input, weight, hx)<br>\n291             hy = tuple(h.new() for h in hx)<br>\n292<br>\n--&gt; 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)<br>\n294<br>\n295         self.save_for_backward(input, hx, weight, output)</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py in forward(fn, input, hx, weight, output, hy)<br>\n303                 fn.cy_desc, ctypes.c_void_p(cy.data_ptr()) if cx is not None else None,<br>\n304                 ctypes.c_void_p(workspace.data_ptr()), workspace.size(0),<br>\n--&gt; 305                 ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)<br>\n306             ))<br>\n307         else:  # inference</p>\n<p>/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/<strong>init</strong>.py in check_error(status)<br>\n253 def check_error(status):<br>\n254     if status is not 0:<br>\n--&gt; 255         raise CuDNNError(status)<br>\n256<br>\n257</p>\n<p>CuDNNError: 8: b'CUDNN_STATUS_EXECUTION_FAILED'</p>", "body_text": "I've been trying to train recurrent neural network using nn.GRU on a multi-GPU setup and am randomly getting crashes caused by CuDNN.\nI'm using PyTorch 0.2 on Linux running in an nvidia-docker container with the latest nvidia/cuda image.\nThis is the error message that comes up:\nCuDNNError                                Traceback (most recent call last)\n in ()\n7         optimizer.zero_grad()\n8         model.module.hidden = model.module.init_hidden()\n----> 9         outputs = model(inputs)\n10         outputs = outputs.view((-1))\n11         loss = criterion(outputs, labels)\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)\n222         for hook in self._forward_pre_hooks.values():\n223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n225         for hook in self._forward_hooks.values():\n226             hook_result = hook(self, input, result)\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in forward(self, *inputs, **kwargs)\n58             return self.module(*inputs[0], **kwargs[0])\n59         replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n---> 60         outputs = self.parallel_apply(replicas, inputs, kwargs)\n61         return self.gather(outputs, self.output_device)\n62\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in parallel_apply(self, replicas, inputs, kwargs)\n68\n69     def parallel_apply(self, replicas, inputs, kwargs):\n---> 70         return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n71\n72     def gather(self, outputs, output_device):\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in parallel_apply(modules, inputs, kwargs_tup, devices)\n65         output = results[i]\n66         if isinstance(output, Exception):\n---> 67             raise output\n68         outputs.append(output)\n69     return outputs\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in _worker(i, module, input, kwargs, results, lock, device)\n40         try:\n41             with torch.cuda.device(device):\n---> 42                 output = module(*input, **kwargs)\n43             with lock:\n44                 results[i] = output\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)\n222         for hook in self._forward_pre_hooks.values():\n223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n225         for hook in self._forward_hooks.values():\n226             hook_result = hook(self, input, result)\n in forward(self, input)\n15     def forward(self, input):\n16         #self.hidden = self.init_hidden()\n---> 17         gru_out, self.hidden = self.gru(input, self.hidden)\n18         x = gru_out[:, -1]\n19         x = self.dropout(x)\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)\n222         for hook in self._forward_pre_hooks.values():\n223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n225         for hook in self._forward_hooks.values():\n226             hook_result = hook(self, input, result)\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\n160             flat_weight=flat_weight\n161         )\n--> 162         output, hidden = func(input, self.all_weights, hx)\n163         if is_packed:\n164             output = PackedSequence(output, batch_sizes)\n/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward(input, *fargs, **fkwargs)\n349         else:\n350             func = AutogradRNN(*args, **kwargs)\n--> 351         return func(input, *fargs, **fkwargs)\n352\n353     return forward\n/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in _do_forward(self, *input)\n282         self._nested_input = input\n283         flat_input = tuple(_iter_variables(input))\n--> 284         flat_output = super(NestedIOFunction, self)._do_forward(*flat_input)\n285         nested_output = self._nested_output\n286         nested_variables = _unflatten(flat_output, self._nested_output)\n/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in forward(self, *args)\n304     def forward(self, *args):\n305         nested_tensors = _map_variable_tensor(self._nested_input)\n--> 306         result = self.forward_extended(*nested_tensors)\n307         del self._nested_input\n308         self._nested_output = result\n/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward_extended(self, input, weight, hx)\n291             hy = tuple(h.new() for h in hx)\n292\n--> 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)\n294\n295         self.save_for_backward(input, hx, weight, output)\n/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py in forward(fn, input, hx, weight, output, hy)\n303                 fn.cy_desc, ctypes.c_void_p(cy.data_ptr()) if cx is not None else None,\n304                 ctypes.c_void_p(workspace.data_ptr()), workspace.size(0),\n--> 305                 ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\n306             ))\n307         else:  # inference\n/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/init.py in check_error(status)\n253 def check_error(status):\n254     if status is not 0:\n--> 255         raise CuDNNError(status)\n256\n257\nCuDNNError: 8: b'CUDNN_STATUS_EXECUTION_FAILED'", "body": "I've been trying to train recurrent neural network using nn.GRU on a multi-GPU setup and am randomly getting crashes caused by CuDNN. \r\n\r\nI'm using PyTorch 0.2 on Linux running in an nvidia-docker container with the latest nvidia/cuda image. \r\n\r\nThis is the error message that comes up:\r\n\r\nCuDNNError                                Traceback (most recent call last)\r\n<ipython-input-13-673bb6670e9d> in <module>()\r\n      7         optimizer.zero_grad()\r\n      8         model.module.hidden = model.module.init_hidden()\r\n----> 9         outputs = model(inputs)\r\n     10         outputs = outputs.view((-1))\r\n     11         loss = criterion(outputs, labels)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in forward(self, *inputs, **kwargs)\r\n     58             return self.module(*inputs[0], **kwargs[0])\r\n     59         replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n---> 60         outputs = self.parallel_apply(replicas, inputs, kwargs)\r\n     61         return self.gather(outputs, self.output_device)\r\n     62 \r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py in parallel_apply(self, replicas, inputs, kwargs)\r\n     68 \r\n     69     def parallel_apply(self, replicas, inputs, kwargs):\r\n---> 70         return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\r\n     71 \r\n     72     def gather(self, outputs, output_device):\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in parallel_apply(modules, inputs, kwargs_tup, devices)\r\n     65         output = results[i]\r\n     66         if isinstance(output, Exception):\r\n---> 67             raise output\r\n     68         outputs.append(output)\r\n     69     return outputs\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py in _worker(i, module, input, kwargs, results, lock, device)\r\n     40         try:\r\n     41             with torch.cuda.device(device):\r\n---> 42                 output = module(*input, **kwargs)\r\n     43             with lock:\r\n     44                 results[i] = output\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-10-5c1e51b6922e> in forward(self, input)\r\n     15     def forward(self, input):\r\n     16         #self.hidden = self.init_hidden()\r\n---> 17         gru_out, self.hidden = self.gru(input, self.hidden)\r\n     18         x = gru_out[:, -1]\r\n     19         x = self.dropout(x)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\r\n    160             flat_weight=flat_weight\r\n    161         )\r\n--> 162         output, hidden = func(input, self.all_weights, hx)\r\n    163         if is_packed:\r\n    164             output = PackedSequence(output, batch_sizes)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward(input, *fargs, **fkwargs)\r\n    349         else:\r\n    350             func = AutogradRNN(*args, **kwargs)\r\n--> 351         return func(input, *fargs, **fkwargs)\r\n    352 \r\n    353     return forward\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in _do_forward(self, *input)\r\n    282         self._nested_input = input\r\n    283         flat_input = tuple(_iter_variables(input))\r\n--> 284         flat_output = super(NestedIOFunction, self)._do_forward(*flat_input)\r\n    285         nested_output = self._nested_output\r\n    286         nested_variables = _unflatten(flat_output, self._nested_output)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py in forward(self, *args)\r\n    304     def forward(self, *args):\r\n    305         nested_tensors = _map_variable_tensor(self._nested_input)\r\n--> 306         result = self.forward_extended(*nested_tensors)\r\n    307         del self._nested_input\r\n    308         self._nested_output = result\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py in forward_extended(self, input, weight, hx)\r\n    291             hy = tuple(h.new() for h in hx)\r\n    292 \r\n--> 293         cudnn.rnn.forward(self, input, hx, weight, output, hy)\r\n    294 \r\n    295         self.save_for_backward(input, hx, weight, output)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py in forward(fn, input, hx, weight, output, hy)\r\n    303                 fn.cy_desc, ctypes.c_void_p(cy.data_ptr()) if cx is not None else None,\r\n    304                 ctypes.c_void_p(workspace.data_ptr()), workspace.size(0),\r\n--> 305                 ctypes.c_void_p(fn.reserve.data_ptr()), fn.reserve.size(0)\r\n    306             ))\r\n    307         else:  # inference\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py in check_error(status)\r\n    253 def check_error(status):\r\n    254     if status is not 0:\r\n--> 255         raise CuDNNError(status)\r\n    256 \r\n    257 \r\n\r\nCuDNNError: 8: b'CUDNN_STATUS_EXECUTION_FAILED'"}