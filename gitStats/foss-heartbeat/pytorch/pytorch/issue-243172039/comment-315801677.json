{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/315801677", "html_url": "https://github.com/pytorch/pytorch/pull/2112#issuecomment-315801677", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2112", "id": 315801677, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTgwMTY3Nw==", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-17T16:13:16Z", "updated_at": "2017-07-17T16:15:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Layer norm and instance norm are similar normalisation strategies that are batch-independent and therefore should not require running statistics. As noted above, this was not working for <code>nn.InstanceNorm{1,2,3}d</code> anyway. Hence, we can move away from using batch norm as a backend, and furthermore, we can make them parameterless by default.</p>\n<p>To clarify the difference between these two, layer norm works on 2D inputs, normalising over the 2nd dim, whilst instance norm works on 3/4/5D inputs, normalising over all except for the first 2 dims.</p>\n<p>There I propose the following for this PR:</p>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Replace the batch norm backend for instance norm with a separate function (<code>F.instance_norm</code>), which is by default parameterless and hence can work with arbitrary 3+D inputs.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Implement layer norm using <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11729078\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jekbradbury\">@jekbradbury</a>'s simple code from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"239878202\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1959\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1959/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1959\">#1959</a>. It seems simpler to do this separately (in <code>F.layer_norm</code>), rather than adapt <code>F.instance_norm</code> to work with less than 3 dimensions.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Add basic module tests for <code>nn.LayerNorm</code> and <code>nn.InstanceNorm{1,2,3}d</code>.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Fix <code>test_LayerNorm</code>.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Fix <code>_test_InstanceNorm</code>.</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Tidy up the normalisation docs to make what happens in layer and instance norm clear.</li>\n</ul>", "body_text": "Layer norm and instance norm are similar normalisation strategies that are batch-independent and therefore should not require running statistics. As noted above, this was not working for nn.InstanceNorm{1,2,3}d anyway. Hence, we can move away from using batch norm as a backend, and furthermore, we can make them parameterless by default.\nTo clarify the difference between these two, layer norm works on 2D inputs, normalising over the 2nd dim, whilst instance norm works on 3/4/5D inputs, normalising over all except for the first 2 dims.\nThere I propose the following for this PR:\n\n Replace the batch norm backend for instance norm with a separate function (F.instance_norm), which is by default parameterless and hence can work with arbitrary 3+D inputs.\n Implement layer norm using @jekbradbury's simple code from #1959. It seems simpler to do this separately (in F.layer_norm), rather than adapt F.instance_norm to work with less than 3 dimensions.\n Add basic module tests for nn.LayerNorm and nn.InstanceNorm{1,2,3}d.\n Fix test_LayerNorm.\n Fix _test_InstanceNorm.\n Tidy up the normalisation docs to make what happens in layer and instance norm clear.", "body": "Layer norm and instance norm are similar normalisation strategies that are batch-independent and therefore should not require running statistics. As noted above, this was not working for `nn.InstanceNorm{1,2,3}d` anyway. Hence, we can move away from using batch norm as a backend, and furthermore, we can make them parameterless by default.\r\n\r\nTo clarify the difference between these two, layer norm works on 2D inputs, normalising over the 2nd dim, whilst instance norm works on 3/4/5D inputs, normalising over all except for the first 2 dims.\r\n\r\nThere I propose the following for this PR:\r\n\r\n- [x] Replace the batch norm backend for instance norm with a separate function (`F.instance_norm`), which is by default parameterless and hence can work with arbitrary 3+D inputs.\r\n- [x] Implement layer norm using @jekbradbury's simple code from https://github.com/pytorch/pytorch/issues/1959. It seems simpler to do this separately (in `F.layer_norm`), rather than adapt `F.instance_norm` to work with less than 3 dimensions.\r\n- [x] Add basic module tests for `nn.LayerNorm` and `nn.InstanceNorm{1,2,3}d`.\r\n- [ ] Fix `test_LayerNorm`.\r\n- [ ] Fix `_test_InstanceNorm`.\r\n- [x] Tidy up the normalisation docs to make what happens in layer and instance norm clear."}