{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1054", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1054/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1054/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1054/events", "html_url": "https://github.com/pytorch/pytorch/issues/1054", "id": 215839633, "node_id": "MDU6SXNzdWUyMTU4Mzk2MzM=", "number": 1054, "title": "Feature request: ability even not to sum up over all batches in loss functions", "user": {"login": "kefirski", "id": 8404265, "node_id": "MDQ6VXNlcjg0MDQyNjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/8404265?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kefirski", "html_url": "https://github.com/kefirski", "followers_url": "https://api.github.com/users/kefirski/followers", "following_url": "https://api.github.com/users/kefirski/following{/other_user}", "gists_url": "https://api.github.com/users/kefirski/gists{/gist_id}", "starred_url": "https://api.github.com/users/kefirski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kefirski/subscriptions", "organizations_url": "https://api.github.com/users/kefirski/orgs", "repos_url": "https://api.github.com/users/kefirski/repos", "events_url": "https://api.github.com/users/kefirski/events{/privacy}", "received_events_url": "https://api.github.com/users/kefirski/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-21T18:40:25Z", "updated_at": "2017-03-22T12:01:56Z", "closed_at": "2017-03-22T12:01:56Z", "author_association": "NONE", "body_html": "<p>Hi</p>\n<p>One may want to evaluate perplexity in language modelling task. In this case it is necessary to average over sequence length, then take exponent and only then average over batch size.</p>\n<p>For now it is impossible to implement such logic with <code>torch.nn.NLLLoss</code> in case of implicitly result averaging or summing up.</p>\n<p>From my point of view, it may be reasonable not to perform any implicitly operations with result of loss functions to make them more flexible.</p>\n<p>Cheers!</p>", "body_text": "Hi\nOne may want to evaluate perplexity in language modelling task. In this case it is necessary to average over sequence length, then take exponent and only then average over batch size.\nFor now it is impossible to implement such logic with torch.nn.NLLLoss in case of implicitly result averaging or summing up.\nFrom my point of view, it may be reasonable not to perform any implicitly operations with result of loss functions to make them more flexible.\nCheers!", "body": "Hi\r\n\r\nOne may want to evaluate perplexity in language modelling task. In this case it is necessary to average over sequence length, then take exponent and only then average over batch size.\r\n\r\nFor now it is impossible to implement such logic with `torch.nn.NLLLoss` in case of implicitly result averaging or summing up.\r\n\r\nFrom my point of view, it may be reasonable not to perform any implicitly operations with result of loss functions to make them more flexible.\r\n\r\nCheers!"}