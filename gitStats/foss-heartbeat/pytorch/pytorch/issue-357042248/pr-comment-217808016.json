{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/217808016", "pull_request_review_id": 155616671, "id": 217808016, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNzgwODAxNg==", "diff_hunk": "@@ -599,3 +600,111 @@ def argsort(input, dim=None, descending=False):\n     if dim is None:\n         return torch.sort(input, -1, descending)[1]\n     return torch.sort(input, dim, descending)[1]\n+\n+\n+def norm(input, p=\"fro\", dim=None, keepdim=False, out=None):\n+    r\"\"\"Returns the matrix norm or vector norm of a given tensor.\n+\n+    Args:\n+        input (Tensor): the input tensor\n+        p ({int, float, inf, -inf, 'fro', 'nuc'}): the order of norm\n+            The following norms can be calculated:\n+            =====  ============================  ==========================\n+            ord    matrix norm                   vector norm\n+            =====  ============================  ==========================\n+            None   Frobenius norm                2-norm\n+            'fro'  Frobenius norm                --\n+            'nuc'  nuclear norm                  --\n+            other  as vec norm when dim is None  sum(abs(x)**ord)**(1./ord)\n+            =====  ============================  ==========================\n+        dim ({int, 2-tuple of ints, 2-list of ints}, optional): If it is a int,\n+        vector norm will be calculated, if it is 2-tuple of ints, matrix norm\n+        will be calculated. If the value is None, matrix norm will be calculated\n+        when the input tensor only has two dimensions, vector norm will be\n+        calculated when the input tensor only has one dimension. If the input\n+        tensor has more than two dimensions, the vector norm will be applied to\n+        last dimension.\n+        keepdim (bool): whether the output tensors have :attr:`dim`\n+            retained or not. Ignored if ``dim=None and out=None``.\n+        out (Tensor, optional) \u2013 the output tensor. Ignored if\n+        ``dim=None and out=None``.\n+\n+    Example::\n+        >>> import torch\n+        >>> a = torch.arange(9, dtype= torch.float) - 4\n+        >>> b = a.reshape((3, 3))\n+        >>> torch.norm(a)\n+        tensor(7.7460)\n+        >>> torch.norm(b)\n+        tensor(7.7460)\n+        >>> torch.norm(a, float('inf'))\n+        tensor(4.)\n+        >>> torch.norm(b, float('inf'))\n+        tensor([4., 3., 4.])\n+        >>> torch.norm(a, 1)\n+        tensor(20.)\n+        >>> torch.norm(b, 1)\n+        tensor(20.)\n+        >>> torch.norm(a, -1)\n+        tensor(0.)\n+        >>> torch.norm(b, -1)\n+        tensor(0.)\n+        >>> torch.norm(a, 2)\n+        tensor(7.7460)\n+        >>> torch.norm(b, 2)\n+        tensor(7.7460)\n+        >>> torch.norm(a, -2)\n+        tensor(0.)\n+        >>> torch.norm(b, -2)\n+        tensor(0.)\n+        >>> torch.norm(a, 3)\n+        tensor(5.8480)\n+        >>> torch.norm(a, -3)\n+        tensor(0.)\n+        >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n+        >>> torch.norm(c, dim=0)\n+        tensor([1.4142, 2.2361, 5.0000])\n+        >>> torch.norm(c, dim=1)\n+        tensor([3.7417, 4.2426])\n+        >>> torch.norm(c, p=1, dim=1)\n+        tensor([6., 6.])\n+        >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n+        >>> torch.norm(d, dim=(1,2))\n+        tensor([ 3.7417, 11.2250])\n+        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n+        (tensor(3.7417), tensor(11.2250))\n+    \"\"\"\n+    ndim = input.dim()\n+\n+    # catch default case\n+    if dim is None and out is None:\n+        if isinstance(p, int) or (isinstance(p, float) and p != inf and p != -inf):\n+            return torch._C._VariableFunctions.norm(input, p)\n+        if p == \"fro\":\n+            return torch._C._VariableFunctions.frobenius_norm(input)\n+\n+    if dim is None:\n+        dim = tuple(range(ndim))\n+    elif isinstance(dim, list):\n+        dim = tuple(dim)\n+    elif not isinstance(dim, tuple):\n+        try:\n+            dim = int(dim)\n+        except Exception:\n+            raise TypeError(\n+                \"'dim' must be None, an integer or a tuple/list of integers\"\n+            )\n+        dim = (dim,)", "path": "torch/functional.py", "position": null, "original_position": 106, "commit_id": "757e6d8d507c44e454fe5f507ca2266b67acab2d", "original_commit_id": "7f77dd9902a023e17e97efc8ca1ed082fe577363", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Why do we need to parse `dim` ourselves? Can't we just always passing it to the C functions, except in `nuc` case we can do some manual checking because it doesn't support `dim` argument.", "created_at": "2018-09-14T18:44:46Z", "updated_at": "2018-11-23T15:51:25Z", "html_url": "https://github.com/pytorch/pytorch/pull/11261#discussion_r217808016", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11261", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/217808016"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11261#discussion_r217808016"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11261"}}, "body_html": "<p>Why do we need to parse <code>dim</code> ourselves? Can't we just always passing it to the C functions, except in <code>nuc</code> case we can do some manual checking because it doesn't support <code>dim</code> argument.</p>", "body_text": "Why do we need to parse dim ourselves? Can't we just always passing it to the C functions, except in nuc case we can do some manual checking because it doesn't support dim argument."}