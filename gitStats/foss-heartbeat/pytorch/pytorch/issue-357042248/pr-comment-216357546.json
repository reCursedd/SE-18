{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216357546", "pull_request_review_id": 153819205, "id": 216357546, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNjM1NzU0Ng==", "diff_hunk": "@@ -543,3 +544,241 @@ def argsort(input, dim=None, descending=False):\n     if dim is None:\n         return torch.sort(input, -1, descending)[1]\n     return torch.sort(input, dim, descending)[1]\n+\n+\n+def norm(input, p=\"fro\", dim=None, keepdim=False, out=None):\n+    r\"\"\"Returns the matrix norm or vector norm of a given tensor.\n+\n+    Args:\n+        input (Tensor): the input tensor\n+        p ({int, float, inf, -inf, 'fro', 'nuc'}): the order of norm\n+            The following norms can be calculated:\n+            =====  ============================  ==========================\n+            ord    matrix norm                   vector norm\n+            =====  ============================  ==========================\n+            None   Frobenius norm                2-norm\n+            'fro'  Frobenius norm                --\n+            'nuc'  nuclear norm                  --\n+            inf    max(sum(abs(x), dim=1))       max(abs(x))\n+            -inf   min(sum(abs(x), dim=1))       min(abs(x))\n+            0      --                            sum(x != 0)\n+            1      max(sum(abs(x), dim=0))       as below\n+            -1     min(sum(abs(x), dim=0))       as below\n+            2      largest singular value        as below\n+            -2     smallest singular value       as below\n+            other  as vec norm when dim is None  sum(abs(x)**ord)**(1./ord)\n+            =====  ============================  ==========================\n+        dim ({int, 2-tuple of ints, 2-list of ints}): If it is a int, vector norm\n+        will be calculated, if it is 2-tuple of ints, matrix norm will be\n+        calculated.\n+        keepdim (bool): whether the output tensors have :attr:`dim`\n+            retained or not. Ignored if ``dim=None``.\n+        out (Tensor, optional) \u2013 the output tensor\n+\n+    Example::\n+        >>> import torch\n+        >>> a = torch.arange(9, dtype= torch.float) - 4\n+        >>> b = a.reshape((3, 3))\n+        >>> torch.norm(a)\n+        tensor(7.7460)\n+        >>> torch.norm(b)\n+        tensor(7.7460)\n+        >>> torch.norm(a, float('inf'))\n+        tensor(4.)\n+        >>> torch.norm(b, float('inf'))\n+        tensor(9.)\n+        >>> torch.norm(a, float('-inf'))\n+        tensor(0.)\n+        >>> torch.norm(b, float('-inf'))\n+        tensor(2.)\n+        >>> torch.norm(a, 1)\n+        tensor(20.)\n+        >>> torch.norm(b, 1)\n+        tensor(20.)\n+        >>> torch.norm(a, -1)\n+        tensor(0.)\n+        >>> torch.norm(b, -1)\n+        tensor(0.)\n+        >>> torch.norm(a, 2)\n+        tensor(7.7460)\n+        >>> torch.norm(b, 2)\n+        tensor(7.7460)\n+        >>> torch.norm(a, -2)\n+        tensor(0.)\n+        >>> torch.norm(b, -2)\n+        tensor(0.)\n+        >>> torch.norm(a, 3)\n+        tensor(5.8480)\n+        >>> torch.norm(a, -3)\n+        tensor(0.)\n+        >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n+        >>> torch.norm(c, dim=0)\n+        tensor([1.4142, 2.2361, 5.0000])\n+        >>> torch.norm(c, dim=1)\n+        tensor([3.7417, 4.2426])\n+        >>> torch.norm(c, p=1, dim=1)\n+        tensor([6., 6.])\n+        >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n+        >>> torch.norm(d, dim=(1,2))\n+        tensor([ 3.7417, 11.2250])\n+        >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n+        (tensor(3.7417), tensor(11.2250))\n+    \"\"\"\n+    ndim = input.dim()\n+\n+    # catch default case\n+    if dim is None and out is None:\n+        if p == \"fro\":\n+            return torch._C._VariableFunctions.norm(input, 2)\n+        if isinstance(p, int):\n+            return torch._C._VariableFunctions.norm(input, p)\n+        if isinstance(p, float) and p != inf and p != -inf:\n+            return torch._C._VariableFunctions.norm(input, p)", "path": "torch/functional.py", "position": null, "original_position": 101, "commit_id": "757e6d8d507c44e454fe5f507ca2266b67acab2d", "original_commit_id": "f97623c871fe74e6a9e46947ee829f6304b0aaea", "user": {"login": "erikbrinkman", "id": 858926, "node_id": "MDQ6VXNlcjg1ODkyNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/858926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erikbrinkman", "html_url": "https://github.com/erikbrinkman", "followers_url": "https://api.github.com/users/erikbrinkman/followers", "following_url": "https://api.github.com/users/erikbrinkman/following{/other_user}", "gists_url": "https://api.github.com/users/erikbrinkman/gists{/gist_id}", "starred_url": "https://api.github.com/users/erikbrinkman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erikbrinkman/subscriptions", "organizations_url": "https://api.github.com/users/erikbrinkman/orgs", "repos_url": "https://api.github.com/users/erikbrinkman/repos", "events_url": "https://api.github.com/users/erikbrinkman/events{/privacy}", "received_events_url": "https://api.github.com/users/erikbrinkman/received_events", "type": "User", "site_admin": false}, "body": "@ezyang when it comes to computing arbitrary norms (or distances) it seems like the appropriate c++ style is just to have different names for the functions i.e. how this PR is structured. Given that absent a reason for a better api torch should probably follow numpy's i.e. lgtm!\r\n\r\nI will second @SsnL that python should probably just convert strings to appropriate c++ calls, maybe with some extra checking for places where python doesn't enforce the same typing that c++ does.", "created_at": "2018-09-10T15:05:22Z", "updated_at": "2018-11-23T15:50:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/11261#discussion_r216357546", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11261", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216357546"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11261#discussion_r216357546"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11261"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> when it comes to computing arbitrary norms (or distances) it seems like the appropriate c++ style is just to have different names for the functions i.e. how this PR is structured. Given that absent a reason for a better api torch should probably follow numpy's i.e. lgtm!</p>\n<p>I will second <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> that python should probably just convert strings to appropriate c++ calls, maybe with some extra checking for places where python doesn't enforce the same typing that c++ does.</p>", "body_text": "@ezyang when it comes to computing arbitrary norms (or distances) it seems like the appropriate c++ style is just to have different names for the functions i.e. how this PR is structured. Given that absent a reason for a better api torch should probably follow numpy's i.e. lgtm!\nI will second @SsnL that python should probably just convert strings to appropriate c++ calls, maybe with some extra checking for places where python doesn't enforce the same typing that c++ does.", "in_reply_to_id": 216194050}