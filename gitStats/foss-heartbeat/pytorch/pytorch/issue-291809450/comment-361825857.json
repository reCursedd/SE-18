{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/361825857", "html_url": "https://github.com/pytorch/pytorch/issues/4865#issuecomment-361825857", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4865", "id": 361825857, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTgyNTg1Nw==", "user": {"login": "khanrc", "id": 3657248, "node_id": "MDQ6VXNlcjM2NTcyNDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/3657248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/khanrc", "html_url": "https://github.com/khanrc", "followers_url": "https://api.github.com/users/khanrc/followers", "following_url": "https://api.github.com/users/khanrc/following{/other_user}", "gists_url": "https://api.github.com/users/khanrc/gists{/gist_id}", "starred_url": "https://api.github.com/users/khanrc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/khanrc/subscriptions", "organizations_url": "https://api.github.com/users/khanrc/orgs", "repos_url": "https://api.github.com/users/khanrc/repos", "events_url": "https://api.github.com/users/khanrc/events{/privacy}", "received_events_url": "https://api.github.com/users/khanrc/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-31T05:11:49Z", "updated_at": "2018-01-31T05:12:09Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> How many GPUs did you use? The numbers are same as #GPU=1 case in my test. The numbers are small when #GPU=1 because replicate function is not called.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> As you can see in <a href=\"https://nbviewer.jupyter.org/gist/khanrc/a21dbe0dc316c31387a56b683b94aa2d\" rel=\"nofollow\">the above code</a>, there is no cycle in my data structure (more precisely, there is no custom data structure).</p>\n<p>In my experiments, the number of garbages are depends on the number of GPUs and the number of layers (the number of parameters is likely to be the factor). I don't think there is a problem with my very simple code.</p>", "body_text": "@zou3519 How many GPUs did you use? The numbers are same as #GPU=1 case in my test. The numbers are small when #GPU=1 because replicate function is not called.\n@apaszke As you can see in the above code, there is no cycle in my data structure (more precisely, there is no custom data structure).\nIn my experiments, the number of garbages are depends on the number of GPUs and the number of layers (the number of parameters is likely to be the factor). I don't think there is a problem with my very simple code.", "body": "@zou3519 How many GPUs did you use? The numbers are same as #GPU=1 case in my test. The numbers are small when #GPU=1 because replicate function is not called.\r\n\r\n@apaszke As you can see in [the above code](https://nbviewer.jupyter.org/gist/khanrc/a21dbe0dc316c31387a56b683b94aa2d), there is no cycle in my data structure (more precisely, there is no custom data structure).\r\n\r\nIn my experiments, the number of garbages are depends on the number of GPUs and the number of layers (the number of parameters is likely to be the factor). I don't think there is a problem with my very simple code. "}