{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377705812", "html_url": "https://github.com/pytorch/pytorch/issues/6139#issuecomment-377705812", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6139", "id": 377705812, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzcwNTgxMg==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-31T16:37:49Z", "updated_at": "2018-03-31T16:38:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm not sure if this is useful or if it's exactly what you're saying <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> , but I've noticed there's a special case in the shape analysis for <code>unsqueeze</code>:<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L188-L200\">https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L188-L200</a></p>\n<p>Tracing <code>unsqueeze(dim=0)</code> causes different behavior than <code>unsqueeze(0)</code>: <code>unsqueeze(dim=0)</code> results in the Node having 1 input, while <code>unsqueeze(0)</code> results in the node having 2 inputs. The <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L189-L190\">check_overload</a> returns false in the case of <code>unsqueeze(0)</code> because it has 2 inputs instead of 1, breaking out of this case and keeping the type of the outputs as DynamicType instead of inferring the sizes of the outputs. In the case of <code>unsqueeze(dim=0)</code>, <code>check_overload</code> returns True and the sizes of the outputs get inferred.</p>", "body_text": "I'm not sure if this is useful or if it's exactly what you're saying @apaszke , but I've noticed there's a special case in the shape analysis for unsqueeze:\nhttps://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L188-L200\nTracing unsqueeze(dim=0) causes different behavior than unsqueeze(0): unsqueeze(dim=0) results in the Node having 1 input, while unsqueeze(0) results in the node having 2 inputs. The check_overload returns false in the case of unsqueeze(0) because it has 2 inputs instead of 1, breaking out of this case and keeping the type of the outputs as DynamicType instead of inferring the sizes of the outputs. In the case of unsqueeze(dim=0), check_overload returns True and the sizes of the outputs get inferred.", "body": "I'm not sure if this is useful or if it's exactly what you're saying @apaszke , but I've noticed there's a special case in the shape analysis for `unsqueeze`:\r\nhttps://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L188-L200\r\n\r\nTracing `unsqueeze(dim=0)` causes different behavior than `unsqueeze(0)`: `unsqueeze(dim=0)` results in the Node having 1 input, while `unsqueeze(0)` results in the node having 2 inputs. The [check_overload](https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/shape_analysis.cpp#L189-L190) returns false in the case of `unsqueeze(0)` because it has 2 inputs instead of 1, breaking out of this case and keeping the type of the outputs as DynamicType instead of inferring the sizes of the outputs. In the case of `unsqueeze(dim=0)`, `check_overload` returns True and the sizes of the outputs get inferred."}