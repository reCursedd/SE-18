{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14147", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14147/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14147/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14147/events", "html_url": "https://github.com/pytorch/pytorch/issues/14147", "id": 381845065, "node_id": "MDU6SXNzdWUzODE4NDUwNjU=", "number": 14147, "title": "torch.argmin behaves differently on CPU and GPU", "user": {"login": "carefree0910", "id": 15677328, "node_id": "MDQ6VXNlcjE1Njc3MzI4", "avatar_url": "https://avatars1.githubusercontent.com/u/15677328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carefree0910", "html_url": "https://github.com/carefree0910", "followers_url": "https://api.github.com/users/carefree0910/followers", "following_url": "https://api.github.com/users/carefree0910/following{/other_user}", "gists_url": "https://api.github.com/users/carefree0910/gists{/gist_id}", "starred_url": "https://api.github.com/users/carefree0910/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carefree0910/subscriptions", "organizations_url": "https://api.github.com/users/carefree0910/orgs", "repos_url": "https://api.github.com/users/carefree0910/repos", "events_url": "https://api.github.com/users/carefree0910/events{/privacy}", "received_events_url": "https://api.github.com/users/carefree0910/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-17T09:13:08Z", "updated_at": "2018-11-17T16:57:48Z", "closed_at": "2018-11-17T16:57:48Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>torch.argmin behaves differently on cpu (which is correct) and gpu (which is wrong)</p>\n<p>I'm not sure whether this 'bug' (or 'feature') is expected or not...</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<p>import torch<br>\nbase = torch.randint(0, 2, (128, 100)).type(torch.LongTensor).cuda()<br>\nprint(torch.argmin(base, dim=1))           # Produce wrong answer<br>\nprint(torch.argmin(base.cpu(), dim=1))  # Produce correct answer</p>\n\n<h2>Expected behavior</h2>\n\n<p>GPU behavior should be the same as CPU behavior</p>\n<h2>Environment</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176<br>\nOS: Ubuntu 16.04 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: Could not collect<br>\nPython version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti<br>\nGPU 3: GeForce GTX 1080 Ti<br>\nGPU 4: GeForce GTX 1080 Ti<br>\nGPU 5: GeForce GTX 1080 Ti<br>\nGPU 6: GeForce GTX 1080 Ti<br>\nGPU 7: GeForce GTX 1080 Ti<br>\nNvidia driver version: 390.77<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5<br>\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a<br>\nVersions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] Could not collect</p>\n<h2>Additional context</h2>\n\n<p>torch.argmax will also behave differently, and maybe other functions as well</p>", "body_text": "\ud83d\udc1b Bug\ntorch.argmin behaves differently on cpu (which is correct) and gpu (which is wrong)\nI'm not sure whether this 'bug' (or 'feature') is expected or not...\nTo Reproduce\nSteps to reproduce the behavior:\nimport torch\nbase = torch.randint(0, 2, (128, 100)).type(torch.LongTensor).cuda()\nprint(torch.argmin(base, dim=1))           # Produce wrong answer\nprint(torch.argmin(base.cpu(), dim=1))  # Produce correct answer\n\nExpected behavior\n\nGPU behavior should be the same as CPU behavior\nEnvironment\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: Could not collect\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\nGPU 4: GeForce GTX 1080 Ti\nGPU 5: GeForce GTX 1080 Ti\nGPU 6: GeForce GTX 1080 Ti\nGPU 7: GeForce GTX 1080 Ti\nNvidia driver version: 390.77\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect\nAdditional context\n\ntorch.argmax will also behave differently, and maybe other functions as well", "body": "## \ud83d\udc1b Bug\r\n\r\ntorch.argmin behaves differently on cpu (which is correct) and gpu (which is wrong)\r\n\r\nI'm not sure whether this 'bug' (or 'feature') is expected or not...\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nimport torch\r\nbase = torch.randint(0, 2, (128, 100)).type(torch.LongTensor).cuda()\r\nprint(torch.argmin(base, dim=1))           # Produce wrong answer\r\nprint(torch.argmin(base.cpu(), dim=1))  # Produce correct answer\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nGPU behavior should be the same as CPU behavior\r\n\r\n## Environment\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\nOS: Ubuntu 16.04 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: Could not collect\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\nGPU 4: GeForce GTX 1080 Ti\r\nGPU 5: GeForce GTX 1080 Ti\r\nGPU 6: GeForce GTX 1080 Ti\r\nGPU 7: GeForce GTX 1080 Ti\r\nNvidia driver version: 390.77\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.0.5\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\ntorch.argmax will also behave differently, and maybe other functions as well\r\n"}