{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/393323572", "html_url": "https://github.com/pytorch/pytorch/pull/7921#issuecomment-393323572", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7921", "id": 393323572, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MzMyMzU3Mg==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-30T21:21:24Z", "updated_at": "2018-05-30T21:25:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I was able to fake a tensor for one of the tests (the cuda:9 one). It's harder to fake a cuda tensor given the serialized output of a cpu tensor, so I just copied the bytes into the test file to avoid having a binary file.</p>\n<p>To avoid having the bytes in the test, I could hack <code>torch.cuda.is_available()</code> to return false:</p>\n<pre><code>import torch\ntorch.cuda.is_available = lambda: False\n</code></pre>\n<p>But the downside to this is that we won't be able to run tests in parallel (if we ever wanted to do that in the future).  Let me know what you think</p>", "body_text": "@apaszke I was able to fake a tensor for one of the tests (the cuda:9 one). It's harder to fake a cuda tensor given the serialized output of a cpu tensor, so I just copied the bytes into the test file to avoid having a binary file.\nTo avoid having the bytes in the test, I could hack torch.cuda.is_available() to return false:\nimport torch\ntorch.cuda.is_available = lambda: False\n\nBut the downside to this is that we won't be able to run tests in parallel (if we ever wanted to do that in the future).  Let me know what you think", "body": "@apaszke I was able to fake a tensor for one of the tests (the cuda:9 one). It's harder to fake a cuda tensor given the serialized output of a cpu tensor, so I just copied the bytes into the test file to avoid having a binary file. \r\n\r\nTo avoid having the bytes in the test, I could hack `torch.cuda.is_available()` to return false:\r\n```\r\nimport torch\r\ntorch.cuda.is_available = lambda: False\r\n```\r\n\r\nBut the downside to this is that we won't be able to run tests in parallel (if we ever wanted to do that in the future).  Let me know what you think"}