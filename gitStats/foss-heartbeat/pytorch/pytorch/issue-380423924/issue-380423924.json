{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13929", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13929/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13929/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13929/events", "html_url": "https://github.com/pytorch/pytorch/issues/13929", "id": 380423924, "node_id": "MDU6SXNzdWUzODA0MjM5MjQ=", "number": 13929, "title": "Maturing JIT Optimization Framework", "user": {"login": "ArmenAg", "id": 4429794, "node_id": "MDQ6VXNlcjQ0Mjk3OTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4429794?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArmenAg", "html_url": "https://github.com/ArmenAg", "followers_url": "https://api.github.com/users/ArmenAg/followers", "following_url": "https://api.github.com/users/ArmenAg/following{/other_user}", "gists_url": "https://api.github.com/users/ArmenAg/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArmenAg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArmenAg/subscriptions", "organizations_url": "https://api.github.com/users/ArmenAg/orgs", "repos_url": "https://api.github.com/users/ArmenAg/repos", "events_url": "https://api.github.com/users/ArmenAg/events{/privacy}", "received_events_url": "https://api.github.com/users/ArmenAg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-13T21:07:59Z", "updated_at": "2018-11-14T00:43:34Z", "closed_at": "2018-11-13T23:24:36Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"rocket\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f680.png\">\ud83d\ude80</g-emoji> Feature</h2>\n<p>Taking a current look at the JIT optimization framework there are a couple of feature missing.</p>\n<p>We do not have a structure that captures post pass analysis of the optimization pass. Analysis are fundamental in optimization as they allow us to understand the necessary passes better. For example if PyTorch had a simple analysis per pass that calculated the number of nodes in the computational graph changed we could introduce features such as fixed point optimization. We could mature even further to Immutable passes (analysis passes) which outline in what order to apply passes to maximize performance. Currently we have a very trivial implementation of optimization which simply runs <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/graph_executor.cpp#L458\">passes in linear order</a>.</p>\n<p>Another feature are pass managers. PyTorch implicitly does this by defining families of optimization passes (e.g. PeepholeOptimizeImpl implements a family of peephole optimization). An explicit OO implementation of pass managers will substantially clean up the code.</p>\n<p>Simplifying the implementation of passes will increase agility. There's a lot of code reuse happening with respect to iterating the graph and checking for a pattern to apply a transform. If we could implement type's of passes (e.g. PredicatePass/PatternMatchPass, LoopPass), we could simplify code and reduce code reuse.</p>\n<h2>Motivation</h2>\n<p>I'm hoping by introducing these concepts to PyTorch's JIT we could mature the optimization framework and increase the performance of PyTorch in general.</p>\n<h2>Pitch</h2>\n<p>This same approach and features I've implemented in the <a href=\"https://github.com/onnx/onnx/tree/master/onnx/optimizer\">ONNX optimization framework</a>. If we agree that PyTorch needs these features I can start working on this.</p>", "body_text": "\ud83d\ude80 Feature\nTaking a current look at the JIT optimization framework there are a couple of feature missing.\nWe do not have a structure that captures post pass analysis of the optimization pass. Analysis are fundamental in optimization as they allow us to understand the necessary passes better. For example if PyTorch had a simple analysis per pass that calculated the number of nodes in the computational graph changed we could introduce features such as fixed point optimization. We could mature even further to Immutable passes (analysis passes) which outline in what order to apply passes to maximize performance. Currently we have a very trivial implementation of optimization which simply runs passes in linear order.\nAnother feature are pass managers. PyTorch implicitly does this by defining families of optimization passes (e.g. PeepholeOptimizeImpl implements a family of peephole optimization). An explicit OO implementation of pass managers will substantially clean up the code.\nSimplifying the implementation of passes will increase agility. There's a lot of code reuse happening with respect to iterating the graph and checking for a pattern to apply a transform. If we could implement type's of passes (e.g. PredicatePass/PatternMatchPass, LoopPass), we could simplify code and reduce code reuse.\nMotivation\nI'm hoping by introducing these concepts to PyTorch's JIT we could mature the optimization framework and increase the performance of PyTorch in general.\nPitch\nThis same approach and features I've implemented in the ONNX optimization framework. If we agree that PyTorch needs these features I can start working on this.", "body": "## \ud83d\ude80 Feature\r\nTaking a current look at the JIT optimization framework there are a couple of feature missing. \r\n\r\nWe do not have a structure that captures post pass analysis of the optimization pass. Analysis are fundamental in optimization as they allow us to understand the necessary passes better. For example if PyTorch had a simple analysis per pass that calculated the number of nodes in the computational graph changed we could introduce features such as fixed point optimization. We could mature even further to Immutable passes (analysis passes) which outline in what order to apply passes to maximize performance. Currently we have a very trivial implementation of optimization which simply runs [passes in linear order](https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/graph_executor.cpp#L458).\r\n\r\nAnother feature are pass managers. PyTorch implicitly does this by defining families of optimization passes (e.g. PeepholeOptimizeImpl implements a family of peephole optimization). An explicit OO implementation of pass managers will substantially clean up the code.\r\n\r\nSimplifying the implementation of passes will increase agility. There's a lot of code reuse happening with respect to iterating the graph and checking for a pattern to apply a transform. If we could implement type's of passes (e.g. PredicatePass/PatternMatchPass, LoopPass), we could simplify code and reduce code reuse. \r\n\r\n## Motivation\r\nI'm hoping by introducing these concepts to PyTorch's JIT we could mature the optimization framework and increase the performance of PyTorch in general.\r\n\r\n## Pitch\r\n\r\nThis same approach and features I've implemented in the [ONNX optimization framework](https://github.com/onnx/onnx/tree/master/onnx/optimizer). If we agree that PyTorch needs these features I can start working on this."}