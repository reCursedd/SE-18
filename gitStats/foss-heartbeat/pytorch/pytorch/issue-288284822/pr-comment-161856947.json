{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/161856947", "pull_request_review_id": 89213516, "id": 161856947, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MTg1Njk0Nw==", "diff_hunk": "@@ -635,6 +635,9 @@\n - name: _standard_gamma_grad(Tensor self, Tensor output)\n   self: not_implemented(\"_standard_gamma_grad\")\n \n+- name: _scalar_sum(Tensor self)\n+  self: _scalar_sum_backward(grad, self)", "path": "tools/autograd/derivatives.yaml", "position": null, "original_position": 5, "commit_id": "a282bc980a0b482aff3712e8db609ad09e542191", "original_commit_id": "066b58ca82cfddc8bc3a58aec5894fd96f79a62c", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "hehe, this actually doesn't work and one of the reasons I disabled the test for being too fragile.  The reason is we change the size of things inplace (to get around the scalar blocks) so you actually need the tensor to get the right size, not the saved sizes of tensor.", "created_at": "2018-01-16T19:10:13Z", "updated_at": "2018-11-23T15:38:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/4647#discussion_r161856947", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4647", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/161856947"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4647#discussion_r161856947"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4647"}}, "body_html": "<p>hehe, this actually doesn't work and one of the reasons I disabled the test for being too fragile.  The reason is we change the size of things inplace (to get around the scalar blocks) so you actually need the tensor to get the right size, not the saved sizes of tensor.</p>", "body_text": "hehe, this actually doesn't work and one of the reasons I disabled the test for being too fragile.  The reason is we change the size of things inplace (to get around the scalar blocks) so you actually need the tensor to get the right size, not the saved sizes of tensor.", "in_reply_to_id": 161853499}