{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/358828342", "html_url": "https://github.com/pytorch/pytorch/issues/4679#issuecomment-358828342", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4679", "id": 358828342, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODgyODM0Mg==", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T00:30:50Z", "updated_at": "2018-01-19T02:34:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4532062\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Zrachel\">@Zrachel</a>, trying to repro with your program, when I switched to \"nccl\", I got this expected error</p>\n<pre><code>/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\nProcess Process-2:\nProcess Process-1:\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"./test.py\", line 18, in init_processes\n    fn(rank, size)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"./test.py\", line 10, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\n  File \"./test.py\", line 18, in init_processes\n    fn(rank, size)\n  File \"./test.py\", line 10, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\n</code></pre>\n<p>Since NCCL only support CUDA tensors, I changed<br>\n<code>tensor = torch.ones(1) </code>to<br>\n<code>tensor = torch.ones(1).cuda() </code><br>\nand it works fine for me</p>\n<pre><code>/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n\nRank  1  has data  2.0\nRank  0  has data  2.0\n\n</code></pre>\n<p>Could you try to change your tensor to CUDA tensor and see if it helps?</p>", "body_text": "@Zrachel, trying to repro with your program, when I switched to \"nccl\", I got this expected error\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\nProcess Process-2:\nProcess Process-1:\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"./test.py\", line 18, in init_processes\n    fn(rank, size)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"./test.py\", line 10, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\n  File \"./test.py\", line 18, in init_processes\n    fn(rank, size)\n  File \"./test.py\", line 10, in run\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\n    return torch._C._dist_all_reduce(tensor, op, group)\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\n\nSince NCCL only support CUDA tensors, I changed\ntensor = torch.ones(1) to\ntensor = torch.ones(1).cuda() \nand it works fine for me\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\n        ================================================================================\n                                            WARNING\n        ================================================================================\n        NCCL backend is still experimental. The APIs will change without\n        notice and we're can't guarantee full correctness and expected performance yet.\n        We'll announce it once it's ready.\n\n  \"\"\")\n\nRank  1  has data  2.0\nRank  0  has data  2.0\n\n\nCould you try to change your tensor to CUDA tensor and see if it helps?", "body": "@Zrachel, trying to repro with your program, when I switched to \"nccl\", I got this expected error\r\n\r\n```\r\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\r\n        ================================================================================\r\n                                            WARNING\r\n        ================================================================================\r\n        NCCL backend is still experimental. The APIs will change without\r\n        notice and we're can't guarantee full correctness and expected performance yet.\r\n        We'll announce it once it's ready.\r\n\r\n  \"\"\")\r\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\r\n        ================================================================================\r\n                                            WARNING\r\n        ================================================================================\r\n        NCCL backend is still experimental. The APIs will change without\r\n        notice and we're can't guarantee full correctness and expected performance yet.\r\n        We'll announce it once it's ready.\r\n\r\n  \"\"\")\r\nProcess Process-2:\r\nProcess Process-1:\r\nTraceback (most recent call last):\r\nTraceback (most recent call last):\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\r\n    self.run()\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\r\n    self.run()\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"./test.py\", line 18, in init_processes\r\n    fn(rank, size)\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"./test.py\", line 10, in run\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\r\n    return torch._C._dist_all_reduce(tensor, op, group)\r\n  File \"./test.py\", line 18, in init_processes\r\n    fn(rank, size)\r\n  File \"./test.py\", line 10, in run\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n  File \"/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py\", line 344, in all_reduce\r\n    return torch._C._dist_all_reduce(tensor, op, group)\r\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\r\nRuntimeError: Only CUDA dense tensor is supported for NCCL collective operations\r\n```\r\n\r\nSince NCCL only support CUDA tensors, I changed \r\n`tensor = torch.ones(1)\r\n`to\r\n`tensor = torch.ones(1).cuda()\r\n`\r\nand it works fine for me\r\n```\r\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\r\n        ================================================================================\r\n                                            WARNING\r\n        ================================================================================\r\n        NCCL backend is still experimental. The APIs will change without\r\n        notice and we're can't guarantee full correctness and expected performance yet.\r\n        We'll announce it once it's ready.\r\n\r\n  \"\"\")\r\n/private/home/tengli/miniconda3/lib/python3.6/site-packages/torch/distributed/__init__.py:105: UserWarning:\r\n        ================================================================================\r\n                                            WARNING\r\n        ================================================================================\r\n        NCCL backend is still experimental. The APIs will change without\r\n        notice and we're can't guarantee full correctness and expected performance yet.\r\n        We'll announce it once it's ready.\r\n\r\n  \"\"\")\r\n\r\nRank  1  has data  2.0\r\nRank  0  has data  2.0\r\n\r\n```\r\n\r\nCould you try to change your tensor to CUDA tensor and see if it helps?"}