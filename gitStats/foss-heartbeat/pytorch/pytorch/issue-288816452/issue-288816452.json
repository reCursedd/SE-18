{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4679", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4679/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4679/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4679/events", "html_url": "https://github.com/pytorch/pytorch/issues/4679", "id": 288816452, "node_id": "MDU6SXNzdWUyODg4MTY0NTI=", "number": 4679, "title": "Bugs in adding `nccl` into compiling", "user": {"login": "Zrachel", "id": 4532062, "node_id": "MDQ6VXNlcjQ1MzIwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4532062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zrachel", "html_url": "https://github.com/Zrachel", "followers_url": "https://api.github.com/users/Zrachel/followers", "following_url": "https://api.github.com/users/Zrachel/following{/other_user}", "gists_url": "https://api.github.com/users/Zrachel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zrachel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zrachel/subscriptions", "organizations_url": "https://api.github.com/users/Zrachel/orgs", "repos_url": "https://api.github.com/users/Zrachel/repos", "events_url": "https://api.github.com/users/Zrachel/events{/privacy}", "received_events_url": "https://api.github.com/users/Zrachel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 30, "created_at": "2018-01-16T08:04:16Z", "updated_at": "2018-01-23T02:20:09Z", "closed_at": "2018-01-23T02:20:09Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8120856\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/teng-li\">@teng-li</a></p>\n<p>As shown below, pytorch with <code>nccl</code> cannot run a simple reduce program.<br>\nHere <code>~/tools/anaconda3/bin/python</code> is compiled without nccl, and <code>~/tools/anaconda3_torch_distributed/bin/python</code> is compiled with nccl (install log is here: <a href=\"https://drive.google.com/open?id=1tKTZXXSUAq7E8O_TmisKp2asPHerYoBE\" rel=\"nofollow\">https://drive.google.com/open?id=1tKTZXXSUAq7E8O_TmisKp2asPHerYoBE</a>)</p>\n<div class=\"highlight highlight-source-shell\"><pre>[zhangruiqing01@szwg-rp-szwg01.com:<span class=\"pl-k\">~</span>/Study/pytorch/distribute/test]\n$ <span class=\"pl-k\">~</span>/tools/anaconda3/bin/python reduce_sum.py\nRank  0  has data  2.0\nRank  1  has data  2.0\n[zhangruiqing01@szwg-rp-szwg01.com:<span class=\"pl-k\">~</span>/Study/pytorch/distribute/test]\n$ <span class=\"pl-k\">~</span>/tools/anaconda3_torch_distributed/bin/python reduce_sum.py\n^CTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>reduce_sum.py<span class=\"pl-pds\">\"</span></span>, line 44, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    <span class=\"pl-en\">p.join</span>()\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/process.py<span class=\"pl-pds\">\"</span></span>, line 121, <span class=\"pl-k\">in</span> join\n    res = self._popen.wait(timeout)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py<span class=\"pl-pds\">\"</span></span>, line 51, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">wait</span>\n    <span class=\"pl-k\">return</span> self.poll(os.WNOHANG <span class=\"pl-k\">if</span> timeout == 0.0 <span class=\"pl-k\">else</span> 0)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py<span class=\"pl-pds\">\"</span></span>, line 29, <span class=\"pl-k\">in</span> poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt\n^CError <span class=\"pl-k\">in</span> atexit._run_exitfuncs:\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py<span class=\"pl-pds\">\"</span></span>, line 29, <span class=\"pl-k\">in</span> poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt</pre></div>\n<p><strong>KeyboardInterrupt is because program get stuck here.</strong></p>\n<hr>\n<p>reduce_sum.py:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.distributed <span class=\"pl-k\">as</span> dist\n<span class=\"pl-k\">from</span> torch.multiprocessing <span class=\"pl-k\">import</span> Process\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\">rank</span>, <span class=\"pl-smi\">size</span>):                                             \n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Simple point-to-point communication. <span class=\"pl-pds\">\"\"\"</span></span>\n    group <span class=\"pl-k\">=</span> dist.new_group([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>])\n    tensor <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">1</span>)\n    dist.all_reduce(tensor, <span class=\"pl-v\">op</span><span class=\"pl-k\">=</span>dist.reduce_op.<span class=\"pl-c1\">SUM</span>, <span class=\"pl-v\">group</span><span class=\"pl-k\">=</span>group)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Rank <span class=\"pl-pds\">'</span></span>, rank, <span class=\"pl-s\"><span class=\"pl-pds\">'</span> has data <span class=\"pl-pds\">'</span></span>, tensor[<span class=\"pl-c1\">0</span>])\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">init_processes</span>(<span class=\"pl-smi\">rank</span>, <span class=\"pl-smi\">size</span>, <span class=\"pl-smi\">fn</span>, <span class=\"pl-smi\">backend</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>tcp<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Initialize the distributed environment. <span class=\"pl-pds\">\"\"\"</span></span>\n    os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>MASTER_ADDR<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>127.0.0.1<span class=\"pl-pds\">'</span></span>\n    os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>MASTER_PORT<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>29500<span class=\"pl-pds\">'</span></span>\n    dist.init_process_group(backend, <span class=\"pl-v\">rank</span><span class=\"pl-k\">=</span>rank, <span class=\"pl-v\">world_size</span><span class=\"pl-k\">=</span>size)\n    fn(rank, size)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n    processes <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> rank <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(size):\n        p <span class=\"pl-k\">=</span> Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>init_processes, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(rank, size, run, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>tcp<span class=\"pl-pds\">'</span></span>))\n        p.start()\n        processes.append(p)\n\n    <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> processes:\n        p.join()</pre></div>\n<p>BTW, substitute function <code>run</code> to only send and recv would perform normally for both python with and without nccl.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\">rank</span>, <span class=\"pl-smi\">size</span>):\n    tensor <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">if</span> rank <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        tensor <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Send the tensor to process 1</span>\n        dist.send(<span class=\"pl-v\">tensor</span><span class=\"pl-k\">=</span>tensor, <span class=\"pl-v\">dst</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Receive tensor from process 0</span>\n        dist.recv(<span class=\"pl-v\">tensor</span><span class=\"pl-k\">=</span>tensor, <span class=\"pl-v\">src</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Rank <span class=\"pl-pds\">'</span></span>, rank, <span class=\"pl-s\"><span class=\"pl-pds\">'</span> has data <span class=\"pl-pds\">'</span></span>, tensor[<span class=\"pl-c1\">0</span>])</pre></div>", "body_text": "Hi @teng-li\nAs shown below, pytorch with nccl cannot run a simple reduce program.\nHere ~/tools/anaconda3/bin/python is compiled without nccl, and ~/tools/anaconda3_torch_distributed/bin/python is compiled with nccl (install log is here: https://drive.google.com/open?id=1tKTZXXSUAq7E8O_TmisKp2asPHerYoBE)\n[zhangruiqing01@szwg-rp-szwg01.com:~/Study/pytorch/distribute/test]\n$ ~/tools/anaconda3/bin/python reduce_sum.py\nRank  0  has data  2.0\nRank  1  has data  2.0\n[zhangruiqing01@szwg-rp-szwg01.com:~/Study/pytorch/distribute/test]\n$ ~/tools/anaconda3_torch_distributed/bin/python reduce_sum.py\n^CTraceback (most recent call last):\n  File \"reduce_sum.py\", line 44, in <module>\n    p.join()\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/process.py\", line 121, in join\n    res = self._popen.wait(timeout)\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 51, in wait\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 29, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt\n^CError in atexit._run_exitfuncs:\nTraceback (most recent call last):\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 29, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt\nKeyboardInterrupt is because program get stuck here.\n\nreduce_sum.py:\nimport os\nimport torch\nimport torch.distributed as dist\nfrom torch.multiprocessing import Process\n\ndef run(rank, size):                                             \n    \"\"\" Simple point-to-point communication. \"\"\"\n    group = dist.new_group([0, 1])\n    tensor = torch.ones(1)\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n    print('Rank ', rank, ' has data ', tensor[0])\n\ndef init_processes(rank, size, fn, backend='tcp'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank, world_size=size)\n    fn(rank, size)\n\n\nif __name__ == \"__main__\":\n    size = 2\n    processes = []\n    for rank in range(size):\n        p = Process(target=init_processes, args=(rank, size, run, 'tcp'))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\nBTW, substitute function run to only send and recv would perform normally for both python with and without nccl.\ndef run(rank, size):\n    tensor = torch.zeros(1)\n    if rank == 0:\n        tensor += 1\n        # Send the tensor to process 1\n        dist.send(tensor=tensor, dst=1)\n    else:\n        # Receive tensor from process 0\n        dist.recv(tensor=tensor, src=0)\n    print('Rank ', rank, ' has data ', tensor[0])", "body": "Hi @teng-li \r\n\r\nAs shown below, pytorch with `nccl` cannot run a simple reduce program.\r\nHere `~/tools/anaconda3/bin/python` is compiled without nccl, and `~/tools/anaconda3_torch_distributed/bin/python` is compiled with nccl (install log is here: https://drive.google.com/open?id=1tKTZXXSUAq7E8O_TmisKp2asPHerYoBE)\r\n\r\n\r\n```bash\r\n[zhangruiqing01@szwg-rp-szwg01.com:~/Study/pytorch/distribute/test]\r\n$ ~/tools/anaconda3/bin/python reduce_sum.py\r\nRank  0  has data  2.0\r\nRank  1  has data  2.0\r\n[zhangruiqing01@szwg-rp-szwg01.com:~/Study/pytorch/distribute/test]\r\n$ ~/tools/anaconda3_torch_distributed/bin/python reduce_sum.py\r\n^CTraceback (most recent call last):\r\n  File \"reduce_sum.py\", line 44, in <module>\r\n    p.join()\r\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/process.py\", line 121, in join\r\n    res = self._popen.wait(timeout)\r\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 51, in wait\r\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\r\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 29, in poll\r\n    pid, sts = os.waitpid(self.pid, flag)\r\nKeyboardInterrupt\r\n^CError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\n  File \"/home/zhangruiqing01/tools/anaconda3_torch_distributed/lib/python3.6/multiprocessing/popen_fork.py\", line 29, in poll\r\n    pid, sts = os.waitpid(self.pid, flag)\r\nKeyboardInterrupt\r\n```\r\n\r\n**KeyboardInterrupt is because program get stuck here.**\r\n\r\n\r\n\r\n----------\r\nreduce_sum.py:\r\n```python\r\nimport os\r\nimport torch\r\nimport torch.distributed as dist\r\nfrom torch.multiprocessing import Process\r\n\r\ndef run(rank, size):                                             \r\n    \"\"\" Simple point-to-point communication. \"\"\"\r\n    group = dist.new_group([0, 1])\r\n    tensor = torch.ones(1)\r\n    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\r\n    print('Rank ', rank, ' has data ', tensor[0])\r\n\r\ndef init_processes(rank, size, fn, backend='tcp'):\r\n    \"\"\" Initialize the distributed environment. \"\"\"\r\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\r\n    os.environ['MASTER_PORT'] = '29500'\r\n    dist.init_process_group(backend, rank=rank, world_size=size)\r\n    fn(rank, size)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    size = 2\r\n    processes = []\r\n    for rank in range(size):\r\n        p = Process(target=init_processes, args=(rank, size, run, 'tcp'))\r\n        p.start()\r\n        processes.append(p)\r\n\r\n    for p in processes:\r\n        p.join()\r\n```\r\n\r\nBTW, substitute function `run` to only send and recv would perform normally for both python with and without nccl.\r\n\r\n```python\r\ndef run(rank, size):\r\n    tensor = torch.zeros(1)\r\n    if rank == 0:\r\n        tensor += 1\r\n        # Send the tensor to process 1\r\n        dist.send(tensor=tensor, dst=1)\r\n    else:\r\n        # Receive tensor from process 0\r\n        dist.recv(tensor=tensor, src=0)\r\n    print('Rank ', rank, ' has data ', tensor[0])\r\n```\r\n"}