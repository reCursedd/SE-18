{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3257", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3257/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3257/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3257/events", "html_url": "https://github.com/pytorch/pytorch/issues/3257", "id": 267994111, "node_id": "MDU6SXNzdWUyNjc5OTQxMTE=", "number": 3257, "title": "Why torch.nn.Linear is split into Transpose and Gemm layers in torch.onnx.export()?", "user": {"login": "imai-lm", "id": 31943828, "node_id": "MDQ6VXNlcjMxOTQzODI4", "avatar_url": "https://avatars0.githubusercontent.com/u/31943828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/imai-lm", "html_url": "https://github.com/imai-lm", "followers_url": "https://api.github.com/users/imai-lm/followers", "following_url": "https://api.github.com/users/imai-lm/following{/other_user}", "gists_url": "https://api.github.com/users/imai-lm/gists{/gist_id}", "starred_url": "https://api.github.com/users/imai-lm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/imai-lm/subscriptions", "organizations_url": "https://api.github.com/users/imai-lm/orgs", "repos_url": "https://api.github.com/users/imai-lm/repos", "events_url": "https://api.github.com/users/imai-lm/events{/privacy}", "received_events_url": "https://api.github.com/users/imai-lm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2017-10-24T11:23:58Z", "updated_at": "2017-12-28T21:57:36Z", "closed_at": "2017-12-28T21:57:36Z", "author_association": "NONE", "body_html": "<p>I looked into the output of <code>torch.onnx.export()</code> and found that every layers declared as <code>torch.nn.Linear()</code> was split into two layers; <code>Transpose</code> then <code>Gemm</code>. I think it is redundant, because <code>Gemm</code> operator of ONNX has <code>transB</code> attribute, which transposes the second argument.<br>\nWhy wouldn't you use the attribute and simply translate it to <code>Gemm</code> only?</p>", "body_text": "I looked into the output of torch.onnx.export() and found that every layers declared as torch.nn.Linear() was split into two layers; Transpose then Gemm. I think it is redundant, because Gemm operator of ONNX has transB attribute, which transposes the second argument.\nWhy wouldn't you use the attribute and simply translate it to Gemm only?", "body": "I looked into the output of `torch.onnx.export()` and found that every layers declared as `torch.nn.Linear()` was split into two layers; `Transpose` then `Gemm`. I think it is redundant, because `Gemm` operator of ONNX has `transB` attribute, which transposes the second argument.\r\nWhy wouldn't you use the attribute and simply translate it to `Gemm` only?"}