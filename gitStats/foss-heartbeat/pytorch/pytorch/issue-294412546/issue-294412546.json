{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5047", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5047/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5047/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5047/events", "html_url": "https://github.com/pytorch/pytorch/issues/5047", "id": 294412546, "node_id": "MDU6SXNzdWUyOTQ0MTI1NDY=", "number": 5047, "title": "slow addmm which comes from bug with CPU backend", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-05T14:31:02Z", "updated_at": "2018-02-05T18:58:29Z", "closed_at": "2018-02-05T18:58:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think the <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L1936\">addmm</a> implementation must have a bug.<br>\nActually, I am confused by the the matrix tranpose. If  a matrix with size <code>m x k</code>,  why the matrix is transpose if <code>stride[1] == 1 &amp;&amp; LDC_COND(r_-&gt;size[1], r_-&gt;size[0], r_-&gt;stride[0])</code>? The stride in the second dimension is 1 means that the matrix is no-transpose. do I misunderstand that? Or do I miss some usage rules which are established? Or does the code obey CblasColMajor?</p>\n<p>However,  the <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L2007\">comment</a>  conflict with <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L2028\">the other</a>. And the corresponding code is also not right.</p>\n<p>If I misunderstand the matrix transpose, the code between L2006~L2025 should be below:</p>\n<div class=\"highlight highlight-source-c\"><pre>  <span class=\"pl-c\"><span class=\"pl-c\">/*</span> m1 <span class=\"pl-c\">*/</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">/*</span> Need ldm1_ &gt;= max(1, (transpose_m1 == 't' ? k : m)) <span class=\"pl-c\">*/</span></span>\n  <span class=\"pl-k\">if</span>(m1-&gt;stride[(transpose_r == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span> ? <span class=\"pl-c1\">0</span> : <span class=\"pl-c1\">1</span>)] == <span class=\"pl-c1\">1</span> &amp;&amp;\n     m1-&gt;stride[(transpose_r == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span> ? <span class=\"pl-c1\">1</span> : <span class=\"pl-c1\">0</span>)] &gt;= THMax(<span class=\"pl-c1\">1</span>, m))\n  {\n    transpose_m1 = <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span>;\n    m1_ = m1;\n  }\n  <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span>(m1-&gt;stride[(transpose_r == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span> ? <span class=\"pl-c1\">1</span> : <span class=\"pl-c1\">0</span>)] == <span class=\"pl-c1\">1</span> &amp;&amp;\n          m1-&gt;stride[(transpose_r == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span> ? <span class=\"pl-c1\">0</span> : <span class=\"pl-c1\">1</span>)] &gt;= THMax(<span class=\"pl-c1\">1</span>, k))\n  {\n    transpose_m1 = <span class=\"pl-s\"><span class=\"pl-pds\">'</span>t<span class=\"pl-pds\">'</span></span>;\n    m1_ = m1;\n  }\n  <span class=\"pl-k\">else</span>\n  {\n    transpose_m1 = (transpose_r == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span> ? <span class=\"pl-s\"><span class=\"pl-pds\">'</span>t<span class=\"pl-pds\">'</span></span> : <span class=\"pl-s\"><span class=\"pl-pds\">'</span>n<span class=\"pl-pds\">'</span></span>);\n    m1_ = <span class=\"pl-c1\">THTensor_</span>(newContiguous)(m1);\n    free_m1 = <span class=\"pl-c1\">1</span>;\n}</pre></div>", "body_text": "I think the addmm implementation must have a bug.\nActually, I am confused by the the matrix tranpose. If  a matrix with size m x k,  why the matrix is transpose if stride[1] == 1 && LDC_COND(r_->size[1], r_->size[0], r_->stride[0])? The stride in the second dimension is 1 means that the matrix is no-transpose. do I misunderstand that? Or do I miss some usage rules which are established? Or does the code obey CblasColMajor?\nHowever,  the comment  conflict with the other. And the corresponding code is also not right.\nIf I misunderstand the matrix transpose, the code between L2006~L2025 should be below:\n  /* m1 */\n  /* Need ldm1_ >= max(1, (transpose_m1 == 't' ? k : m)) */\n  if(m1->stride[(transpose_r == 'n' ? 0 : 1)] == 1 &&\n     m1->stride[(transpose_r == 'n' ? 1 : 0)] >= THMax(1, m))\n  {\n    transpose_m1 = 'n';\n    m1_ = m1;\n  }\n  else if(m1->stride[(transpose_r == 'n' ? 1 : 0)] == 1 &&\n          m1->stride[(transpose_r == 'n' ? 0 : 1)] >= THMax(1, k))\n  {\n    transpose_m1 = 't';\n    m1_ = m1;\n  }\n  else\n  {\n    transpose_m1 = (transpose_r == 'n' ? 't' : 'n');\n    m1_ = THTensor_(newContiguous)(m1);\n    free_m1 = 1;\n}", "body": "I think the [addmm](https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L1936) implementation must have a bug. \r\nActually, I am confused by the the matrix tranpose. If  a matrix with size `m x k`,  why the matrix is transpose if `stride[1] == 1 && LDC_COND(r_->size[1], r_->size[0], r_->stride[0])`? The stride in the second dimension is 1 means that the matrix is no-transpose. do I misunderstand that? Or do I miss some usage rules which are established? Or does the code obey CblasColMajor? \r\n\r\nHowever,  the [comment](https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L2007)  conflict with [the other](https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMath.c#L2028). And the corresponding code is also not right.\r\n\r\nIf I misunderstand the matrix transpose, the code between L2006~L2025 should be below:\r\n```c\r\n  /* m1 */\r\n  /* Need ldm1_ >= max(1, (transpose_m1 == 't' ? k : m)) */\r\n  if(m1->stride[(transpose_r == 'n' ? 0 : 1)] == 1 &&\r\n     m1->stride[(transpose_r == 'n' ? 1 : 0)] >= THMax(1, m))\r\n  {\r\n    transpose_m1 = 'n';\r\n    m1_ = m1;\r\n  }\r\n  else if(m1->stride[(transpose_r == 'n' ? 1 : 0)] == 1 &&\r\n          m1->stride[(transpose_r == 'n' ? 0 : 1)] >= THMax(1, k))\r\n  {\r\n    transpose_m1 = 't';\r\n    m1_ = m1;\r\n  }\r\n  else\r\n  {\r\n    transpose_m1 = (transpose_r == 'n' ? 't' : 'n');\r\n    m1_ = THTensor_(newContiguous)(m1);\r\n    free_m1 = 1;\r\n}\r\n```\r\n\r\n\r\n"}