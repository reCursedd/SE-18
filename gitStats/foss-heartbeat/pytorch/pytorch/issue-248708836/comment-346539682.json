{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/346539682", "html_url": "https://github.com/pytorch/pytorch/issues/2341#issuecomment-346539682", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2341", "id": 346539682, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NjUzOTY4Mg==", "user": {"login": "karmus89", "id": 17722707, "node_id": "MDQ6VXNlcjE3NzIyNzA3", "avatar_url": "https://avatars0.githubusercontent.com/u/17722707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmus89", "html_url": "https://github.com/karmus89", "followers_url": "https://api.github.com/users/karmus89/followers", "following_url": "https://api.github.com/users/karmus89/following{/other_user}", "gists_url": "https://api.github.com/users/karmus89/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmus89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmus89/subscriptions", "organizations_url": "https://api.github.com/users/karmus89/orgs", "repos_url": "https://api.github.com/users/karmus89/repos", "events_url": "https://api.github.com/users/karmus89/events{/privacy}", "received_events_url": "https://api.github.com/users/karmus89/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-23T06:29:58Z", "updated_at": "2017-11-23T06:30:36Z", "author_association": "NONE", "body_html": "<p>I can actually verify that setting the <code>num_workers</code> to <code>0</code> <em>or</em> <code>1</code> helped out. No matter the case, DataLoader always failed with me regardless of dataset with a higher value. The error has to do with multiprocessing with DataLoader:</p>\n<pre><code>\n  File \"D:/Opiskelu/PyTorch Tutorials/cnn_transfer_learning_cuda.py\", line 76, in &lt;module&gt;\n    inputs, classes = next(iter(dataloaders['train']))\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 301, in __iter__\n    return DataLoaderIter(self)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 158, in __init__\n    w.start()\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\process.py\", line 105, in start\n    self._popen = self._Popen(self)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 212, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 313, in _Popen\n    return Popen(process_obj)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\n    reduction.dump(process_obj, to_child)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\reduction.py\", line 59, in dump\n    ForkingPickler(file, protocol).dump(obj)\n\nBrokenPipeError: [Errno 32] Broken pipe\n</code></pre>", "body_text": "I can actually verify that setting the num_workers to 0 or 1 helped out. No matter the case, DataLoader always failed with me regardless of dataset with a higher value. The error has to do with multiprocessing with DataLoader:\n\n  File \"D:/Opiskelu/PyTorch Tutorials/cnn_transfer_learning_cuda.py\", line 76, in <module>\n    inputs, classes = next(iter(dataloaders['train']))\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 301, in __iter__\n    return DataLoaderIter(self)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 158, in __init__\n    w.start()\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\process.py\", line 105, in start\n    self._popen = self._Popen(self)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 212, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 313, in _Popen\n    return Popen(process_obj)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\n    reduction.dump(process_obj, to_child)\n\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\reduction.py\", line 59, in dump\n    ForkingPickler(file, protocol).dump(obj)\n\nBrokenPipeError: [Errno 32] Broken pipe", "body": "I can actually verify that setting the `num_workers` to `0` *or* `1` helped out. No matter the case, DataLoader always failed with me regardless of dataset with a higher value. The error has to do with multiprocessing with DataLoader:\r\n\r\n```\r\n\r\n  File \"D:/Opiskelu/PyTorch Tutorials/cnn_transfer_learning_cuda.py\", line 76, in <module>\r\n    inputs, classes = next(iter(dataloaders['train']))\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 301, in __iter__\r\n    return DataLoaderIter(self)\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 158, in __init__\r\n    w.start()\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 212, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\context.py\", line 313, in _Popen\r\n    return Popen(process_obj)\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n\r\n  File \"C:\\Anaconda3\\envs\\ml\\lib\\multiprocessing\\reduction.py\", line 59, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n```"}