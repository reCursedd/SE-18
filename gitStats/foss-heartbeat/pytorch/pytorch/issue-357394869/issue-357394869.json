{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11296", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11296/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11296/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11296/events", "html_url": "https://github.com/pytorch/pytorch/issues/11296", "id": 357394869, "node_id": "MDU6SXNzdWUzNTczOTQ4Njk=", "number": 11296, "title": "ONNX converts scalar to Tensor, doesn't works with torch.nn.functional.max_pool1d()", "user": {"login": "thlinh", "id": 1904846, "node_id": "MDQ6VXNlcjE5MDQ4NDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1904846?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thlinh", "html_url": "https://github.com/thlinh", "followers_url": "https://api.github.com/users/thlinh/followers", "following_url": "https://api.github.com/users/thlinh/following{/other_user}", "gists_url": "https://api.github.com/users/thlinh/gists{/gist_id}", "starred_url": "https://api.github.com/users/thlinh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thlinh/subscriptions", "organizations_url": "https://api.github.com/users/thlinh/orgs", "repos_url": "https://api.github.com/users/thlinh/repos", "events_url": "https://api.github.com/users/thlinh/events{/privacy}", "received_events_url": "https://api.github.com/users/thlinh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-09-05T20:42:45Z", "updated_at": "2018-09-10T22:07:12Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>If you have a question or would like help and support, please ask at our<br>\n<a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">forums</a>.</p>\n<p>If you are submitting a feature request, please preface the title with [feature request].<br>\nIf you are submitting a bug report, please fill in the following details.</p>\n<h2>Issue description</h2>\n<p>I have a model including a character/word embedder implemented in PyTorch., which uses torch.nn.functional.max_pool1d() function. When trying to convert the model to ONXX (using torch.onxx.export() ), it generates error (during the 1st phase when the model is run with an input to generate the graph) like this:</p>\n<pre><code>x5 = F.max_pool1d(x4, x4.size(2)).squeeze()\n</code></pre>\n<p>File \"/home/py3env/lib/python3.5/site-packages/torch/nn/functional.py\", line 385, in max_pool1d<br>\nret = torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)<br>\nTypeError: max_pool1d_with_indices(): argument 'kernel_size' (position 2) must be tuple of ints, not Tensor</p>\n<p>I have checked, and the problem is with \"x4.size(2)\". When running my model in Python, the result is a scalar, which is OK for max_pool1d. But when torch.onxx.export() runs my model, x4.size(2) is a tensor<br>\n(type torch.LongTensor) and max_pool1d cannot process it.</p>\n<p>Could you help to fix it? Many thanks in advance!</p>\n<h2>Code example</h2>\n<p>x4 = self.char_conv(x3).squeeze(2)                  # x4.type() returns 'torch.cuda.FloatTensor',<br>\n# x4.size() returns torch.Size([1200, 100, 15])<br>\nx5 = F.max_pool1d(x4, x4.size(2)).squeeze()</p>\n<h2>System Info</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 7.5.17<br>\nGPU models and configuration: GPU 0: Tesla K40c<br>\nNvidia driver version: 396.51<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.4<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn.so.7.1.1<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn_static.a<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.1.4<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] pip 18.0<br>\n[conda] Could not collect</p>", "body_text": "If you have a question or would like help and support, please ask at our\nforums.\nIf you are submitting a feature request, please preface the title with [feature request].\nIf you are submitting a bug report, please fill in the following details.\nIssue description\nI have a model including a character/word embedder implemented in PyTorch., which uses torch.nn.functional.max_pool1d() function. When trying to convert the model to ONXX (using torch.onxx.export() ), it generates error (during the 1st phase when the model is run with an input to generate the graph) like this:\nx5 = F.max_pool1d(x4, x4.size(2)).squeeze()\n\nFile \"/home/py3env/lib/python3.5/site-packages/torch/nn/functional.py\", line 385, in max_pool1d\nret = torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\nTypeError: max_pool1d_with_indices(): argument 'kernel_size' (position 2) must be tuple of ints, not Tensor\nI have checked, and the problem is with \"x4.size(2)\". When running my model in Python, the result is a scalar, which is OK for max_pool1d. But when torch.onxx.export() runs my model, x4.size(2) is a tensor\n(type torch.LongTensor) and max_pool1d cannot process it.\nCould you help to fix it? Many thanks in advance!\nCode example\nx4 = self.char_conv(x3).squeeze(2)                  # x4.type() returns 'torch.cuda.FloatTensor',\n# x4.size() returns torch.Size([1200, 100, 15])\nx5 = F.max_pool1d(x4, x4.size(2)).squeeze()\nSystem Info\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\nCMake version: version 3.5.1\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 7.5.17\nGPU models and configuration: GPU 0: Tesla K40c\nNvidia driver version: 396.51\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.4\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn.so.7.1.1\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn_static.a\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.1.4\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a\nVersions of relevant libraries:\n[pip] pip 18.0\n[conda] Could not collect", "body": "If you have a question or would like help and support, please ask at our\r\n[forums](https://discuss.pytorch.org/).\r\n\r\nIf you are submitting a feature request, please preface the title with [feature request].\r\nIf you are submitting a bug report, please fill in the following details.\r\n\r\n## Issue description\r\n\r\nI have a model including a character/word embedder implemented in PyTorch., which uses torch.nn.functional.max_pool1d() function. When trying to convert the model to ONXX (using torch.onxx.export() ), it generates error (during the 1st phase when the model is run with an input to generate the graph) like this:\r\n\r\n    x5 = F.max_pool1d(x4, x4.size(2)).squeeze()\r\n  File \"/home/py3env/lib/python3.5/site-packages/torch/nn/functional.py\", line 385, in max_pool1d\r\n    ret = torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\r\nTypeError: max_pool1d_with_indices(): argument 'kernel_size' (position 2) must be tuple of ints, not Tensor\r\n\r\nI have checked, and the problem is with \"x4.size(2)\". When running my model in Python, the result is a scalar, which is OK for max_pool1d. But when torch.onxx.export() runs my model, x4.size(2) is a tensor \r\n(type torch.LongTensor) and max_pool1d cannot process it.\r\n\r\nCould you help to fix it? Many thanks in advance!\r\n \r\n## Code example\r\nx4 = self.char_conv(x3).squeeze(2)                  # x4.type() returns 'torch.cuda.FloatTensor', \r\n                                                                        # x4.size() returns torch.Size([1200, 100, 15])\r\nx5 = F.max_pool1d(x4, x4.size(2)).squeeze()\r\n\r\n## System Info\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 7.5.17\r\nGPU models and configuration: GPU 0: Tesla K40c\r\nNvidia driver version: 396.51\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.4\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn.so.7.1.1\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn_static.a\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.1.4\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a\r\n\r\nVersions of relevant libraries:\r\n[pip] pip 18.0 \r\n[conda] Could not collect"}