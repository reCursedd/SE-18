{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368693766", "html_url": "https://github.com/pytorch/pytorch/issues/5412#issuecomment-368693766", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5412", "id": 368693766, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODY5Mzc2Ng==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-26T23:52:42Z", "updated_at": "2018-02-26T23:52:42Z", "author_association": "NONE", "body_html": "<p>Good guess...pinning to single socket makes TF-allocated version slower and PyTorch-allocated faster so that they are same speed</p>\n<p>Using <a href=\"https://github.com/diux-dev/cluster/blob/master/yuxin_numpy/get_cores_per_socket.py\">get_cores_per_socket.py</a> to get core ids</p>\n<pre><code>python tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\npytorch_add                   :  17.1 GB/sec, min: 59.78, median: 62.48, mean: 62.68\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\npytorch_add                   :  27.9 GB/sec, min: 36.65, median: 37.33, mean: 38.29\n\nexport GOMP_CPU_AFFINITY=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\npytorch_add                   :  20.5 GB/sec, min: 50.06, median: 50.14, mean: 50.18\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\npytorch_add                   :  20.3 GB/sec, min: 50.43, median: 50.57, mean: 51.50\n</code></pre>", "body_text": "Good guess...pinning to single socket makes TF-allocated version slower and PyTorch-allocated faster so that they are same speed\nUsing get_cores_per_socket.py to get core ids\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\npytorch_add                   :  17.1 GB/sec, min: 59.78, median: 62.48, mean: 62.68\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\npytorch_add                   :  27.9 GB/sec, min: 36.65, median: 37.33, mean: 38.29\n\nexport GOMP_CPU_AFFINITY=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\npytorch_add                   :  20.5 GB/sec, min: 50.06, median: 50.14, mean: 50.18\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\npytorch_add                   :  20.3 GB/sec, min: 50.43, median: 50.57, mean: 51.50", "body": "Good guess...pinning to single socket makes TF-allocated version slower and PyTorch-allocated faster so that they are same speed\r\n\r\nUsing [get_cores_per_socket.py](https://github.com/diux-dev/cluster/blob/master/yuxin_numpy/get_cores_per_socket.py) to get core ids\r\n\r\n```\r\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\r\npytorch_add                   :  17.1 GB/sec, min: 59.78, median: 62.48, mean: 62.68\r\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\r\npytorch_add                   :  27.9 GB/sec, min: 36.65, median: 37.33, mean: 38.29\r\n\r\nexport GOMP_CPU_AFFINITY=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47\r\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=pytorch --num-iters=11 --size-mb=1024\r\npytorch_add                   :  20.5 GB/sec, min: 50.06, median: 50.14, mean: 50.18\r\npython tf_numpy_benchmark.py --benchmark=pytorch_add --allocator=tf --num-iters=11 --size-mb=1024\r\npytorch_add                   :  20.3 GB/sec, min: 50.43, median: 50.57, mean: 51.50\r\n```\r\n\r\n"}