{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/385324641", "html_url": "https://github.com/pytorch/pytorch/pull/7052#issuecomment-385324641", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7052", "id": 385324641, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTMyNDY0MQ==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-30T06:59:00Z", "updated_at": "2018-04-30T07:00:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My conclusion would be measurable in isolation (in the order 10%-20% slowdown), negligible in any other context. Just like <code>max</code> probably wasn't the bottleneck before, doing twice as many comparisons in max doesn't really matter if you do any nontrivial stuff elsewhere.</p>\n<p>So I run this several times (to avoid init topics, the first run takes longer than the others). I lifted this from somewhere in the pytorch/benchmark repository - if you have a better methodology, I'd be happy to apply it.</p>\n<pre><code>import gc, torch, time\nwith torch.no_grad():\n    a = torch.empty(100, 1000, 1000, device='cuda')\n    a.normal_()\n    start = torch.cuda.Event(enable_timing=True)\n    end = torch.cuda.Event(enable_timing=True)\n    gc.collect()\n    torch.cuda.synchronize()\n    start.record()\n    start_cpu_secs = time.time()\n    b = a.max()\n    end_cpu_secs = time.time()\n    end.record()\n    torch.cuda.synchronize()\n    gpu_msecs = start.elapsed_time(end)\n    print(torch.__version__, \"msecs maxall gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\n    if 1:\n        a = torch.empty(100, 1000, 1000, device='cuda')\n        a.normal_()\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        gc.collect()\n        torch.cuda.synchronize()\n        start.record()\n        start_cpu_secs = time.time()\n        b = a.max(1)\n        end_cpu_secs = time.time()\n        end.record()\n        torch.cuda.synchronize()\n        gpu_msecs = start.elapsed_time(end)\n        print(torch.__version__, \"msecs max[1] gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\n</code></pre>\n<p>And I get:</p>\n<pre><code>0.4.0 msecs maxall gpu 1.6861120462417603 cpu 1.6646385192871094\n0.4.0 msecs max[1] gpu 2.239487886428833 cpu 0.07939338684082031\n</code></pre>\n<p>vs.</p>\n<pre><code>0.5.0a0+497ff06 msecs maxall gpu 1.8479679822921753 cpu 1.8224716186523438\n0.5.0a0+497ff06 msecs max[1] gpu 1.922752022743225 cpu 0.054836273193359375\n</code></pre>", "body_text": "My conclusion would be measurable in isolation (in the order 10%-20% slowdown), negligible in any other context. Just like max probably wasn't the bottleneck before, doing twice as many comparisons in max doesn't really matter if you do any nontrivial stuff elsewhere.\nSo I run this several times (to avoid init topics, the first run takes longer than the others). I lifted this from somewhere in the pytorch/benchmark repository - if you have a better methodology, I'd be happy to apply it.\nimport gc, torch, time\nwith torch.no_grad():\n    a = torch.empty(100, 1000, 1000, device='cuda')\n    a.normal_()\n    start = torch.cuda.Event(enable_timing=True)\n    end = torch.cuda.Event(enable_timing=True)\n    gc.collect()\n    torch.cuda.synchronize()\n    start.record()\n    start_cpu_secs = time.time()\n    b = a.max()\n    end_cpu_secs = time.time()\n    end.record()\n    torch.cuda.synchronize()\n    gpu_msecs = start.elapsed_time(end)\n    print(torch.__version__, \"msecs maxall gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\n    if 1:\n        a = torch.empty(100, 1000, 1000, device='cuda')\n        a.normal_()\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        gc.collect()\n        torch.cuda.synchronize()\n        start.record()\n        start_cpu_secs = time.time()\n        b = a.max(1)\n        end_cpu_secs = time.time()\n        end.record()\n        torch.cuda.synchronize()\n        gpu_msecs = start.elapsed_time(end)\n        print(torch.__version__, \"msecs max[1] gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\n\nAnd I get:\n0.4.0 msecs maxall gpu 1.6861120462417603 cpu 1.6646385192871094\n0.4.0 msecs max[1] gpu 2.239487886428833 cpu 0.07939338684082031\n\nvs.\n0.5.0a0+497ff06 msecs maxall gpu 1.8479679822921753 cpu 1.8224716186523438\n0.5.0a0+497ff06 msecs max[1] gpu 1.922752022743225 cpu 0.054836273193359375", "body": "My conclusion would be measurable in isolation (in the order 10%-20% slowdown), negligible in any other context. Just like `max` probably wasn't the bottleneck before, doing twice as many comparisons in max doesn't really matter if you do any nontrivial stuff elsewhere.\r\n\r\nSo I run this several times (to avoid init topics, the first run takes longer than the others). I lifted this from somewhere in the pytorch/benchmark repository - if you have a better methodology, I'd be happy to apply it.\r\n```\r\nimport gc, torch, time\r\nwith torch.no_grad():\r\n    a = torch.empty(100, 1000, 1000, device='cuda')\r\n    a.normal_()\r\n    start = torch.cuda.Event(enable_timing=True)\r\n    end = torch.cuda.Event(enable_timing=True)\r\n    gc.collect()\r\n    torch.cuda.synchronize()\r\n    start.record()\r\n    start_cpu_secs = time.time()\r\n    b = a.max()\r\n    end_cpu_secs = time.time()\r\n    end.record()\r\n    torch.cuda.synchronize()\r\n    gpu_msecs = start.elapsed_time(end)\r\n    print(torch.__version__, \"msecs maxall gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\r\n    if 1:\r\n        a = torch.empty(100, 1000, 1000, device='cuda')\r\n        a.normal_()\r\n        start = torch.cuda.Event(enable_timing=True)\r\n        end = torch.cuda.Event(enable_timing=True)\r\n        gc.collect()\r\n        torch.cuda.synchronize()\r\n        start.record()\r\n        start_cpu_secs = time.time()\r\n        b = a.max(1)\r\n        end_cpu_secs = time.time()\r\n        end.record()\r\n        torch.cuda.synchronize()\r\n        gpu_msecs = start.elapsed_time(end)\r\n        print(torch.__version__, \"msecs max[1] gpu\", gpu_msecs, \"cpu\", (end_cpu_secs - start_cpu_secs)*1000)\r\n```\r\n\r\nAnd I get:\r\n```\r\n0.4.0 msecs maxall gpu 1.6861120462417603 cpu 1.6646385192871094\r\n0.4.0 msecs max[1] gpu 2.239487886428833 cpu 0.07939338684082031\r\n```\r\nvs.\r\n```\r\n0.5.0a0+497ff06 msecs maxall gpu 1.8479679822921753 cpu 1.8224716186523438\r\n0.5.0a0+497ff06 msecs max[1] gpu 1.922752022743225 cpu 0.054836273193359375\r\n```\r\n"}