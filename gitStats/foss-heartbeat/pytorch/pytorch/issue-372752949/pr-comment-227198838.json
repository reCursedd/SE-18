{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227198838", "pull_request_review_id": 167183077, "id": 227198838, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzE5ODgzOA==", "diff_hunk": "@@ -14,48 +10,24 @@ namespace data {\n namespace samplers {\n \n /// A `Sampler` that returns random indices.\n-class RandomSampler : public Sampler {\n+class RandomSampler : public Sampler<> {\n  public:\n   /// Constructs a `RandomSampler` with a size and dtype for the stored indices.\n   ///\n   /// The constructor will eagerly allocate all required indices, which is the\n   /// sequence `0 ... size - 1`. `index_dtype` is the data type of the stored\n   /// indices. You can change it to influence memory usage.\n-  explicit RandomSampler(int64_t size, Dtype index_dtype = torch::kInt64)\n-      : indices_(torch::randperm(size, index_dtype)) {}\n+  explicit RandomSampler(int64_t size, Dtype index_dtype = torch::kInt64);\n \n   /// Resets the `RandomSampler` to a new set of indices.\n-  void reset() override {\n-    // This allocates a new chunk of memory every time (just FYI). It should be\n-    // amortized over the entire epoch hopefully.\n-    indices_ = torch::randperm(indices_.numel(), indices_.options());\n-    index_ = 0;\n-  }\n+  void reset() override;\n \n   /// Returns the next batch of indices.\n-  optional<std::vector<size_t>> next(size_t batch_size) override {\n-    AT_ASSERT(index_ <= indices_.numel());\n-    const size_t remaining_indices = indices_.numel() - index_;\n-    if (remaining_indices == 0) {\n-      return nullopt;\n-    }\n-    std::vector<size_t> index_batch(std::min(batch_size, remaining_indices));\n-    auto slice = indices_.slice(/*dim=*/0, index_, index_ + index_batch.size());\n-    // You may want to store your indices with 32-bit or less, but here we need\n-    // to upcast to 64-bit. A batch itself won't hold too many indices, so that\n-    // should be ok. Note that if this indeed results in a type promotion, there\n-    // will be two allocations: one for the upcast slice, and one for the\n-    // returned `index_batch` vector.\n-    slice = slice.to(torch::kInt64);\n-    const auto* data = slice.data<int64_t>();\n-    std::copy(data, data + index_batch.size(), index_batch.begin());\n-    index_ += index_batch.size();\n-    return index_batch;\n-  }\n+  optional<std::vector<size_t>> next(size_t batch_size) override;", "path": "torch/csrc/api/include/torch/data/samplers/random.h", "position": 66, "original_position": 57, "commit_id": "ca8bf7cb1600b77f543744f5c0e5a5fd750be324", "original_commit_id": "63f50dbac5a6771ff40424f0ed2265d37cd11605", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "dumb question and probably never relevant in practice: does optional support nesting, i.e., `optional<optional<my_index_t>>`?", "created_at": "2018-10-23T02:10:05Z", "updated_at": "2018-11-23T15:53:24Z", "html_url": "https://github.com/pytorch/pytorch/pull/12960#discussion_r227198838", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12960", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227198838"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12960#discussion_r227198838"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12960"}}, "body_html": "<p>dumb question and probably never relevant in practice: does optional support nesting, i.e., <code>optional&lt;optional&lt;my_index_t&gt;&gt;</code>?</p>", "body_text": "dumb question and probably never relevant in practice: does optional support nesting, i.e., optional<optional<my_index_t>>?"}