{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/303615141", "html_url": "https://github.com/pytorch/pytorch/issues/1630#issuecomment-303615141", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1630", "id": 303615141, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzYxNTE0MQ==", "user": {"login": "rosinality", "id": 4343568, "node_id": "MDQ6VXNlcjQzNDM1Njg=", "avatar_url": "https://avatars2.githubusercontent.com/u/4343568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rosinality", "html_url": "https://github.com/rosinality", "followers_url": "https://api.github.com/users/rosinality/followers", "following_url": "https://api.github.com/users/rosinality/following{/other_user}", "gists_url": "https://api.github.com/users/rosinality/gists{/gist_id}", "starred_url": "https://api.github.com/users/rosinality/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rosinality/subscriptions", "organizations_url": "https://api.github.com/users/rosinality/orgs", "repos_url": "https://api.github.com/users/rosinality/repos", "events_url": "https://api.github.com/users/rosinality/events{/privacy}", "received_events_url": "https://api.github.com/users/rosinality/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-24T04:33:55Z", "updated_at": "2017-05-24T13:47:32Z", "author_association": "NONE", "body_html": "<p><del>Autodifferentiaion engine of PyTorch is very fast (so performance is similar or even better than the other frameworks), but it can be slower than raw numpy forward/backward implementation, especially when network is small. I think performance will be better if you implement same network with torch.Tensor like numpy, instead of Variable.</del></p>\n<p>Sorry, this was my mistake. I've tested your code with smaller datasets and PyTorch implementation was 2 times faster</p>", "body_text": "Autodifferentiaion engine of PyTorch is very fast (so performance is similar or even better than the other frameworks), but it can be slower than raw numpy forward/backward implementation, especially when network is small. I think performance will be better if you implement same network with torch.Tensor like numpy, instead of Variable.\nSorry, this was my mistake. I've tested your code with smaller datasets and PyTorch implementation was 2 times faster", "body": "~~Autodifferentiaion engine of PyTorch is very fast (so performance is similar or even better than the other frameworks), but it can be slower than raw numpy forward/backward implementation, especially when network is small. I think performance will be better if you implement same network with torch.Tensor like numpy, instead of Variable.~~\r\n\r\nSorry, this was my mistake. I've tested your code with smaller datasets and PyTorch implementation was 2 times faster"}