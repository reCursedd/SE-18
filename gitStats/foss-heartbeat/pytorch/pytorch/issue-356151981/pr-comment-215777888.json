{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215777888", "pull_request_review_id": 153120082, "id": 215777888, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNTc3Nzg4OA==", "diff_hunk": "@@ -0,0 +1,599 @@\n+syntax = \"proto2\";\n+\n+package torch;\n+\n+// Overview\n+//\n+// ONNX is an open specification that is comprised of the following components:\n+//\n+// 1)  A definition of an extensible computation graph model.\n+// 2)  Definitions of standard data types.\n+// 3)  Definitions of built-in operators.\n+//\n+// This document describes the syntax of models and their computation graphs,\n+// as well as the standard data types. Together, they are referred to as the ONNX\n+// Intermediate Representation, or 'IR' for short. \n+//\n+// The normative semantic specification of the ONNX IR is found in docs/IR.md.\n+// Definitions of the built-in neural network operators may be found in docs/Operators.md.\n+\n+// Notes\n+//\n+// Release\n+//\n+// We are still in the very early stage of defining ONNX. The current\n+// version of ONNX is a starting point. While we are actively working\n+// towards a complete spec, we would like to get the community involved\n+// by sharing our working version of ONNX.\n+//\n+// Protobuf compatibility\n+//\n+// To simplify framework compatibility, ONNX is defined using the subset of\n+// protobuf that is compatible with both protobuf v2 and v3. This means that we\n+// do not use any protobuf features that are only available in one of the two\n+// versions.\n+//\n+// Here are the most notable contortions we have to carry out to work around\n+// these limitations:\n+//\n+//   - No 'map' (added protobuf 3.0). We instead represent mappings as lists\n+//     of key-value pairs, where order does not matter and duplicates\n+//     are not allowed.\n+\n+// Versioning\n+//\n+// ONNX versioning is specified in docs/IR.md and elaborated on in docs/Versioning.md\n+//\n+// To be compatible with both proto2 and proto3, we will use a version number\n+// that is not defined by the default value but an explicit enum number.\n+enum Version {\n+  // proto3 requires the first enum value to be zero.\n+  // We add this just to appease the compiler.\n+  _START_VERSION = 0;\n+  // The version field is always serialized and we will use it to store the\n+  // version that the  graph is generated from. This helps us set up version\n+  // control.\n+  // For the IR, we are using simple numbers starting with with 0x00000001,\n+  // which was the version we published on Oct 10, 2017.\n+  IR_VERSION_2017_10_10 = 0x0000000000000001;\n+\n+  // IR_VERSION 2 published on Oct 30, 2017\n+  // - Added type discriminator to AttributeProto to support proto3 users\n+  IR_VERSION_2017_10_30 = 0x0000000000000002;\n+\n+  // IR VERSION 3 published on Nov 3, 2017\n+  // - For operator versioning:\n+  //    - Added new message OperatorSetIdProto\n+  //    - Added opset_import in ModelProto\n+  // - For vendor extensions, added domain in NodeProto\n+  IR_VERSION_NEWEST_ONNX = 0x0000000000000003;\n+\n+  // PYTORCH IR VERSION\n+  IR_VERSION_NEWEST = 0x0000000000000103;\n+}\n+\n+// Attributes\n+//\n+// A named attribute containing either singular float, integer, string, graph,\n+// and tensor values, or repeated float, integer, string, graph, and tensor values.\n+// An AttributeProto MUST contain the name field, and *only one* of the\n+// following content fields, effectively enforcing a C/C++ union equivalent.\n+message AttributeProto {\n+\n+  // Note: this enum is structurally identical to the OpSchema::AttrType\n+  // enum defined in schema.h.  If you rev one, you likely need to rev the other.\n+  enum AttributeType {\n+    UNDEFINED = 0;\n+    FLOAT = 1;\n+    INT = 2;\n+    STRING = 3;\n+    TENSOR = 4;\n+    GRAPH = 5;\n+\n+    FLOATS = 6;\n+    INTS = 7;\n+    STRINGS = 8;\n+    TENSORS = 9;\n+    GRAPHS = 10;\n+  }\n+\n+  // The name field MUST be present for this version of the IR.\n+  optional string name = 1;           // namespace Attribute\n+ \n+  // if ref_attr_name is not empty, ref_attr_name is the attribute name in parent function.\n+  // In this case, this AttributeProto does not contain data, and it's a reference of attribute\n+  // in parent scope.\n+  // NOTE: This should ONLY be used in function (sub-graph). It's invalid to be used in main graph.\n+  optional string ref_attr_name = 21;\n+\n+  // A human-readable documentation for this attribute. Markdown is allowed.\n+  optional string doc_string = 13;\n+\n+  // The type field MUST be present for this version of the IR.\n+  // For 0.0.1 versions of the IR, this field was not defined, and\n+  // implementations needed to use has_field hueristics to determine\n+  // which value field was in use.  For IR_VERSION 0.0.2 or later, this\n+  // field MUST be set and match the f|i|s|t|... field in use.  This\n+  // change was made to accomodate proto3 implementations.\n+  optional AttributeType type = 20;   // discriminator that indicates which field below is in use\n+\n+  // Exactly ONE of the following fields must be present for this version of the IR\n+  optional float f = 2;               // float\n+  optional int64 i = 3;               // int\n+  optional bytes s = 4;               // UTF-8 string\n+  optional TensorProto t = 5;         // tensor value\n+  optional GraphProto g = 6;          // graph\n+  // Do not use field below, it's deprecated.\n+  // optional ValueProto v = 12;         // value - subsumes everything but graph\n+\n+  repeated float floats = 7;          // list of floats\n+  repeated int64 ints = 8;            // list of ints\n+  repeated bytes strings = 9;         // list of UTF-8 strings\n+  repeated TensorProto tensors = 10;  // list of tensors\n+  repeated GraphProto graphs = 11;    // list of graph\n+}\n+\n+// Defines information on value, including the name, the type, and\n+// the shape of the value.\n+message ValueInfoProto {\n+  // This field MUST be present in this version of the IR.\n+  optional string name = 1;     // namespace Value\n+  // This field MUST be present in this version of the IR.\n+  optional TypeProto type = 2;\n+  // A human-readable documentation for this value. Markdown is allowed.\n+  optional string doc_string = 3;\n+}\n+\n+// Nodes\n+//\n+// Computation graphs are made up of a DAG of nodes, which represent what is\n+// commonly called a \"layer\" or \"pipeline stage\" in machine learning frameworks.\n+//\n+// For example, it can be a node of type \"Conv\" that takes in an image, a filter \n+// tensor and a bias tensor, and produces the convolved output.\n+message NodeProto {\n+  repeated string input = 1;    // namespace Value\n+  repeated string output = 2;   // namespace Value\n+\n+  // An optional identifier for this node in a graph.\n+  // This field MAY be absent in ths version of the IR.\n+  optional string name = 3;     // namespace Node\n+\n+  // The symbolic identifier of the Operator to execute.\n+  optional string op_type = 4;  // namespace Operator\n+  // The domain of the OperatorSet that specifies the operator named by op_type.\n+  optional string domain = 7;   // namespace Domain\n+\n+  // Additional named attributes.\n+  repeated AttributeProto attribute = 5;\n+\n+  // A human-readable documentation for this node. Markdown is allowed.\n+  optional string doc_string = 6;\n+\n+  // Additional annotations, attributes are defined in Schema\n+  // To be added as annotations:\n+  //    string engine\n+  //    string list control_input\n+  //    int64 is_gradient_op\n+  //    string debug_info\n+  repeated AttributeProto annotations = 8;\n+\n+  // Node type, like PythonOp, etc, purely for PyTorch\n+  optional string node_type = 51;", "path": "caffe2/proto/torch.proto", "position": null, "original_position": 182, "commit_id": "31b0cb981c1b664df13bc133df123d7c407a3ca4", "original_commit_id": "b197b19f055cbf9bab4b45cf43697122ea558888", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "how is it different from op_type?", "created_at": "2018-09-06T21:04:08Z", "updated_at": "2018-11-23T15:50:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/11166#discussion_r215777888", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11166", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215777888"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11166#discussion_r215777888"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11166"}}, "body_html": "<p>how is it different from op_type?</p>", "body_text": "how is it different from op_type?"}