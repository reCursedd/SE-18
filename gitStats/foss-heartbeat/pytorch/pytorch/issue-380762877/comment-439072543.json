{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/439072543", "html_url": "https://github.com/pytorch/pytorch/issues/13969#issuecomment-439072543", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13969", "id": 439072543, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTA3MjU0Mw==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T15:08:34Z", "updated_at": "2018-11-15T15:08:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have a tentative fix, that, unless someone explains me that this is a bad idea, I'll make into a PR.<br>\nThe basic idea is to use a bit more tensor methods (in particular <code>Tensor.to(...)</code>) instead of doing this manually.</p>\n<pre><code>iff --git a/torch/csrc/utils/tensor_new.cpp b/torch/csrc/utils/tensor_new.cpp\nindex f9d6ffc62..d8c939232 100644\n--- a/torch/csrc/utils/tensor_new.cpp\n+++ b/torch/csrc/utils/tensor_new.cpp\n@@ -244,7 +244,9 @@ Tensor internal_new_from_data(\n       (char*)tensor.data_ptr(), tensor.sizes(), tensor.strides(), 0,\n       scalarType, tensor.type().elementSizeInBytes(), data);\n   const auto&amp; type_to_use = type_inference ? type.toScalarType(scalarType) : type;\n-  return new_with_type_conversion(type_to_use, tensor, device_index);\n+  auto device = device_opt.has_value() ? *device_opt : tensor.device();\n+  return tensor.to(device, type_to_use.scalarType(), /*blocking=*/false, /*copy=*/false);\n+  //return new_with_type_conversion(type_to_use, tensor, device_index);\n }\n \n Tensor new_from_data_copy(\n</code></pre>", "body_text": "I have a tentative fix, that, unless someone explains me that this is a bad idea, I'll make into a PR.\nThe basic idea is to use a bit more tensor methods (in particular Tensor.to(...)) instead of doing this manually.\niff --git a/torch/csrc/utils/tensor_new.cpp b/torch/csrc/utils/tensor_new.cpp\nindex f9d6ffc62..d8c939232 100644\n--- a/torch/csrc/utils/tensor_new.cpp\n+++ b/torch/csrc/utils/tensor_new.cpp\n@@ -244,7 +244,9 @@ Tensor internal_new_from_data(\n       (char*)tensor.data_ptr(), tensor.sizes(), tensor.strides(), 0,\n       scalarType, tensor.type().elementSizeInBytes(), data);\n   const auto& type_to_use = type_inference ? type.toScalarType(scalarType) : type;\n-  return new_with_type_conversion(type_to_use, tensor, device_index);\n+  auto device = device_opt.has_value() ? *device_opt : tensor.device();\n+  return tensor.to(device, type_to_use.scalarType(), /*blocking=*/false, /*copy=*/false);\n+  //return new_with_type_conversion(type_to_use, tensor, device_index);\n }\n \n Tensor new_from_data_copy(", "body": "I have a tentative fix, that, unless someone explains me that this is a bad idea, I'll make into a PR.\r\nThe basic idea is to use a bit more tensor methods (in particular `Tensor.to(...)`) instead of doing this manually.\r\n\r\n```\r\niff --git a/torch/csrc/utils/tensor_new.cpp b/torch/csrc/utils/tensor_new.cpp\r\nindex f9d6ffc62..d8c939232 100644\r\n--- a/torch/csrc/utils/tensor_new.cpp\r\n+++ b/torch/csrc/utils/tensor_new.cpp\r\n@@ -244,7 +244,9 @@ Tensor internal_new_from_data(\r\n       (char*)tensor.data_ptr(), tensor.sizes(), tensor.strides(), 0,\r\n       scalarType, tensor.type().elementSizeInBytes(), data);\r\n   const auto& type_to_use = type_inference ? type.toScalarType(scalarType) : type;\r\n-  return new_with_type_conversion(type_to_use, tensor, device_index);\r\n+  auto device = device_opt.has_value() ? *device_opt : tensor.device();\r\n+  return tensor.to(device, type_to_use.scalarType(), /*blocking=*/false, /*copy=*/false);\r\n+  //return new_with_type_conversion(type_to_use, tensor, device_index);\r\n }\r\n \r\n Tensor new_from_data_copy(\r\n```\r\n"}