{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/365839468", "html_url": "https://github.com/pytorch/pytorch/issues/5234#issuecomment-365839468", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5234", "id": 365839468, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTgzOTQ2OA==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-15T06:46:44Z", "updated_at": "2018-02-15T06:46:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We had some fixes on master to improve support for RNNs that were not backported to 0.3.1, and indeed it seems to work on master.</p>\n<pre><code>(/home/ezyang/Dev/pytorch-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch] python export_rnn.py \ngraph(%0 : Long(256, 1)\n      %1 : Float(2, 1, 128)\n      %2 : Float(64, 128)\n      %3 : Float(128, 128)\n      %4 : Float(128, 128)\n      %5 : Float(128)\n      %6 : Float(128)\n      %7 : Float(128, 128)\n      %8 : Float(128, 128)\n      %9 : Float(128)\n      %10 : Float(128)\n      %11 : Float(64, 128)\n      %12 : Float(64)) {\n  %13 : Float(256, 1, 128) = Gather(%2, %0), scope: RNNModel/Embedding[encoder]\n  %14 : Float(256, 1, 128), %15 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%13), scope: RNNModel/Dropout[drop]\n  %16 : UNKNOWN_TYPE = Undefined(), scope: RNNModel/RNN[rnn]\n  %17 : UNKNOWN_TYPE = Concat[axis=0](%5, %6), scope: RNNModel/RNN[rnn]\n  %18 : UNKNOWN_TYPE = Slice[axes=[0], ends=[1], starts=[0]](%1), scope: RNNModel/RNN[rnn]\n  %19 : UNKNOWN_TYPE, %20 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%14, %3, %4, %17, %16, %18), scope: RNNModel/RNN[rnn]\n  %21 : UNKNOWN_TYPE = Concat[axis=0](%9, %10), scope: RNNModel/RNN[rnn]\n  %22 : UNKNOWN_TYPE = Slice[axes=[0], ends=[2], starts=[1]](%1), scope: RNNModel/RNN[rnn]\n  %23 : Float(256, 1, 128), %24 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%19, %7, %8, %21, %16, %22), scope: RNNModel/RNN[rnn]\n  %25 : Float(2, 1, 128) = Concat[axis=0](%20, %24), scope: RNNModel/RNN[rnn]\n  %26 : Float(256, 1, 128), %27 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%14), scope: RNNModel/Dropout[drop]\n  %28 : Float(256, 128) = Flatten[axis=1](%26), scope: RNNModel\n  %29 : Float(256, 64) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%28, %11, %12), scope: RNNModel/Linear[decoder]\n  %30 : Float(256, 1, 64) = Reshape[shape=[256, 1, 64]](%29), scope: RNNModel\n  return (%30, %25);\n}\n</code></pre>\n<p>Please give it a try there.</p>", "body_text": "We had some fixes on master to improve support for RNNs that were not backported to 0.3.1, and indeed it seems to work on master.\n(/home/ezyang/Dev/pytorch-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch] python export_rnn.py \ngraph(%0 : Long(256, 1)\n      %1 : Float(2, 1, 128)\n      %2 : Float(64, 128)\n      %3 : Float(128, 128)\n      %4 : Float(128, 128)\n      %5 : Float(128)\n      %6 : Float(128)\n      %7 : Float(128, 128)\n      %8 : Float(128, 128)\n      %9 : Float(128)\n      %10 : Float(128)\n      %11 : Float(64, 128)\n      %12 : Float(64)) {\n  %13 : Float(256, 1, 128) = Gather(%2, %0), scope: RNNModel/Embedding[encoder]\n  %14 : Float(256, 1, 128), %15 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%13), scope: RNNModel/Dropout[drop]\n  %16 : UNKNOWN_TYPE = Undefined(), scope: RNNModel/RNN[rnn]\n  %17 : UNKNOWN_TYPE = Concat[axis=0](%5, %6), scope: RNNModel/RNN[rnn]\n  %18 : UNKNOWN_TYPE = Slice[axes=[0], ends=[1], starts=[0]](%1), scope: RNNModel/RNN[rnn]\n  %19 : UNKNOWN_TYPE, %20 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%14, %3, %4, %17, %16, %18), scope: RNNModel/RNN[rnn]\n  %21 : UNKNOWN_TYPE = Concat[axis=0](%9, %10), scope: RNNModel/RNN[rnn]\n  %22 : UNKNOWN_TYPE = Slice[axes=[0], ends=[2], starts=[1]](%1), scope: RNNModel/RNN[rnn]\n  %23 : Float(256, 1, 128), %24 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%19, %7, %8, %21, %16, %22), scope: RNNModel/RNN[rnn]\n  %25 : Float(2, 1, 128) = Concat[axis=0](%20, %24), scope: RNNModel/RNN[rnn]\n  %26 : Float(256, 1, 128), %27 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%14), scope: RNNModel/Dropout[drop]\n  %28 : Float(256, 128) = Flatten[axis=1](%26), scope: RNNModel\n  %29 : Float(256, 64) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%28, %11, %12), scope: RNNModel/Linear[decoder]\n  %30 : Float(256, 1, 64) = Reshape[shape=[256, 1, 64]](%29), scope: RNNModel\n  return (%30, %25);\n}\n\nPlease give it a try there.", "body": "We had some fixes on master to improve support for RNNs that were not backported to 0.3.1, and indeed it seems to work on master.\r\n\r\n```\r\n(/home/ezyang/Dev/pytorch-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch] python export_rnn.py \r\ngraph(%0 : Long(256, 1)\r\n      %1 : Float(2, 1, 128)\r\n      %2 : Float(64, 128)\r\n      %3 : Float(128, 128)\r\n      %4 : Float(128, 128)\r\n      %5 : Float(128)\r\n      %6 : Float(128)\r\n      %7 : Float(128, 128)\r\n      %8 : Float(128, 128)\r\n      %9 : Float(128)\r\n      %10 : Float(128)\r\n      %11 : Float(64, 128)\r\n      %12 : Float(64)) {\r\n  %13 : Float(256, 1, 128) = Gather(%2, %0), scope: RNNModel/Embedding[encoder]\r\n  %14 : Float(256, 1, 128), %15 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%13), scope: RNNModel/Dropout[drop]\r\n  %16 : UNKNOWN_TYPE = Undefined(), scope: RNNModel/RNN[rnn]\r\n  %17 : UNKNOWN_TYPE = Concat[axis=0](%5, %6), scope: RNNModel/RNN[rnn]\r\n  %18 : UNKNOWN_TYPE = Slice[axes=[0], ends=[1], starts=[0]](%1), scope: RNNModel/RNN[rnn]\r\n  %19 : UNKNOWN_TYPE, %20 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%14, %3, %4, %17, %16, %18), scope: RNNModel/RNN[rnn]\r\n  %21 : UNKNOWN_TYPE = Concat[axis=0](%9, %10), scope: RNNModel/RNN[rnn]\r\n  %22 : UNKNOWN_TYPE = Slice[axes=[0], ends=[2], starts=[1]](%1), scope: RNNModel/RNN[rnn]\r\n  %23 : Float(256, 1, 128), %24 : UNKNOWN_TYPE = RNN[activations=[tanh], hidden_size=128](%19, %7, %8, %21, %16, %22), scope: RNNModel/RNN[rnn]\r\n  %25 : Float(2, 1, 128) = Concat[axis=0](%20, %24), scope: RNNModel/RNN[rnn]\r\n  %26 : Float(256, 1, 128), %27 : UNKNOWN_TYPE = Dropout[is_test=1, ratio=0.5](%14), scope: RNNModel/Dropout[drop]\r\n  %28 : Float(256, 128) = Flatten[axis=1](%26), scope: RNNModel\r\n  %29 : Float(256, 64) = Gemm[alpha=1, beta=1, broadcast=1, transB=1](%28, %11, %12), scope: RNNModel/Linear[decoder]\r\n  %30 : Float(256, 1, 64) = Reshape[shape=[256, 1, 64]](%29), scope: RNNModel\r\n  return (%30, %25);\r\n}\r\n```\r\n\r\nPlease give it a try there."}