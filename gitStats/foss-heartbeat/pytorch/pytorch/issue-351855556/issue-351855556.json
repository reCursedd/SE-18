{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10661", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10661/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10661/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10661/events", "html_url": "https://github.com/pytorch/pytorch/issues/10661", "id": 351855556, "node_id": "MDU6SXNzdWUzNTE4NTU1NTY=", "number": 10661, "title": "torch.einsum 400x slower than numpy.einsum on a simple contraction", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-08-18T22:03:59Z", "updated_at": "2018-09-05T18:31:44Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p><code>torch.einsum</code> is 400x slower than <code>numpy.einsum</code> on a simple contraction. This is making some Pyro models very slow.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch, numpy, timeit\nx <span class=\"pl-k\">=</span> torch.randn((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2000</span>))\ny <span class=\"pl-k\">=</span> torch.randn((<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2000</span>))\nequation <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ac,abc-&gt;cb<span class=\"pl-pds\">'</span></span>\n\ntime0 <span class=\"pl-k\">=</span> timeit.default_timer()\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n    _ <span class=\"pl-k\">=</span> torch.einsum(equation, [x, y])\n\ntime1 <span class=\"pl-k\">=</span> timeit.default_timer()\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n    _ <span class=\"pl-k\">=</span> numpy.einsum(equation, x.numpy(), y.numpy())\n\ntime2 <span class=\"pl-k\">=</span> timeit.default_timer()\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(time1 <span class=\"pl-k\">-</span> time0))\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>numpy: <span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(time2 <span class=\"pl-k\">-</span> time1))</pre></div>\n<pre><code>torch: 3.97460007668\nnumpy: 0.00863790512085\n</code></pre>\n<h2>System Info</h2>\n<pre><code>$ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 2.7\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     0.4.0                     &lt;pip&gt;\n[conda] torchfile                 0.1.0                     &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "Issue description\ntorch.einsum is 400x slower than numpy.einsum on a simple contraction. This is making some Pyro models very slow.\nCode example\nimport torch, numpy, timeit\nx = torch.randn((2, 2000))\ny = torch.randn((2, 2, 2000))\nequation = 'ac,abc->cb'\n\ntime0 = timeit.default_timer()\nfor _ in range(1000):\n    _ = torch.einsum(equation, [x, y])\n\ntime1 = timeit.default_timer()\nfor _ in range(1000):\n    _ = numpy.einsum(equation, x.numpy(), y.numpy())\n\ntime2 = timeit.default_timer()\nprint('torch: {}'.format(time1 - time0))\nprint('numpy: {}'.format(time2 - time1))\ntorch: 3.97460007668\nnumpy: 0.00863790512085\n\nSystem Info\n$ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 2.7\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     0.4.0                     <pip>\n[conda] torchfile                 0.1.0                     <pip>\n[conda] torchvision               0.2.1                     <pip>", "body": "## Issue description\r\n\r\n`torch.einsum` is 400x slower than `numpy.einsum` on a simple contraction. This is making some Pyro models very slow.\r\n\r\n## Code example\r\n\r\n```py\r\nimport torch, numpy, timeit\r\nx = torch.randn((2, 2000))\r\ny = torch.randn((2, 2, 2000))\r\nequation = 'ac,abc->cb'\r\n\r\ntime0 = timeit.default_timer()\r\nfor _ in range(1000):\r\n    _ = torch.einsum(equation, [x, y])\r\n\r\ntime1 = timeit.default_timer()\r\nfor _ in range(1000):\r\n    _ = numpy.einsum(equation, x.numpy(), y.numpy())\r\n\r\ntime2 = timeit.default_timer()\r\nprint('torch: {}'.format(time1 - time0))\r\nprint('numpy: {}'.format(time2 - time1))\r\n```\r\n```\r\ntorch: 3.97460007668\r\nnumpy: 0.00863790512085\r\n```\r\n\r\n## System Info\r\n\r\n```\r\n$ python collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.12.0\r\n\r\nPython version: 2.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] torch                     0.4.0                     <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```"}