{"url": "https://api.github.com/repos/pytorch/pytorch/issues/544", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/544/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/544/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/544/events", "html_url": "https://github.com/pytorch/pytorch/issues/544", "id": 202367106, "node_id": "MDU6SXNzdWUyMDIzNjcxMDY=", "number": 544, "title": "CUDA error for some Conv2d dimensions", "user": {"login": "jcjohnson", "id": 2718714, "node_id": "MDQ6VXNlcjI3MTg3MTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2718714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcjohnson", "html_url": "https://github.com/jcjohnson", "followers_url": "https://api.github.com/users/jcjohnson/followers", "following_url": "https://api.github.com/users/jcjohnson/following{/other_user}", "gists_url": "https://api.github.com/users/jcjohnson/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcjohnson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcjohnson/subscriptions", "organizations_url": "https://api.github.com/users/jcjohnson/orgs", "repos_url": "https://api.github.com/users/jcjohnson/repos", "events_url": "https://api.github.com/users/jcjohnson/events{/privacy}", "received_events_url": "https://api.github.com/users/jcjohnson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-01-22T07:41:21Z", "updated_at": "2018-05-11T14:10:46Z", "closed_at": "2017-01-24T14:11:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've run into some specific sizes of convolutions that work on CPU but crash on GPU:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\ndtype <span class=\"pl-k\">=</span> torch.cuda.FloatTensor\n\nbad_sizes <span class=\"pl-k\">=</span> [\n  (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">109</span>, <span class=\"pl-c1\">175</span>),\n  (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">80</span>, <span class=\"pl-c1\">128</span>),\n  (<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">120</span>, <span class=\"pl-c1\">192</span>),\n]\n\nx <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-k\">*</span>bad_sizes[<span class=\"pl-c1\">2</span>]).type(dtype)\nx_var <span class=\"pl-k\">=</span> torch.autograd.Variable(x)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>x.size() = <span class=\"pl-pds\">'</span></span>, x.size())\n\nconv <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nconv.type(dtype)\n\ny <span class=\"pl-k\">=</span> conv(x_var)\n<span class=\"pl-c1\">print</span>(y.size())</pre></div>\n<p>Any of the bad sizes results in:</p>\n<pre><code>Traceback (most recent call last):\n  File \"foo.py\", line 19, in &lt;module&gt;\n    y = conv(x_var)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 210, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 235, in forward\n    self.padding, self.dilation, self.groups)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/functional.py\", line 37, in conv2d\n    return f(input, weight, bias) if bias is not None else f(input, weight)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 33, in forward\n    output = self._update_output(input, weight, bias)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 84, in _update_output\n    self.groups, cudnn.benchmark)\nRuntimeError: CUDA error\n</code></pre>\n<p>I'm using PyTorch installed from source at <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/f8e89fbe1123f6788992b70361f13ad498665327/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/f8e89fbe1123f6788992b70361f13ad498665327\"><tt>f8e89fb</tt></a> on Ubuntu 16.04 with CUDA 8.0.44, CUDA driver 367.57, and cuDNN 5.1.5.</p>\n<p>I get the same error on a Pascal Titan X and a Maxwell Titan X, and on both Python 2.7.12 and Python 3.5.2.</p>", "body_text": "I've run into some specific sizes of convolutions that work on CPU but crash on GPU:\nimport torch\n\ndtype = torch.cuda.FloatTensor\n\nbad_sizes = [\n  (1, 256, 109, 175),\n  (1, 256, 80, 128),\n  (1, 256, 120, 192),\n]\n\nx = torch.randn(*bad_sizes[2]).type(dtype)\nx_var = torch.autograd.Variable(x)\nprint('x.size() = ', x.size())\n\nconv = torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\nconv.type(dtype)\n\ny = conv(x_var)\nprint(y.size())\nAny of the bad sizes results in:\nTraceback (most recent call last):\n  File \"foo.py\", line 19, in <module>\n    y = conv(x_var)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 210, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 235, in forward\n    self.padding, self.dilation, self.groups)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/functional.py\", line 37, in conv2d\n    return f(input, weight, bias) if bias is not None else f(input, weight)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 33, in forward\n    output = self._update_output(input, weight, bias)\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 84, in _update_output\n    self.groups, cudnn.benchmark)\nRuntimeError: CUDA error\n\nI'm using PyTorch installed from source at f8e89fb on Ubuntu 16.04 with CUDA 8.0.44, CUDA driver 367.57, and cuDNN 5.1.5.\nI get the same error on a Pascal Titan X and a Maxwell Titan X, and on both Python 2.7.12 and Python 3.5.2.", "body": "I've run into some specific sizes of convolutions that work on CPU but crash on GPU:\r\n\r\n```python\r\nimport torch\r\n\r\ndtype = torch.cuda.FloatTensor\r\n\r\nbad_sizes = [\r\n  (1, 256, 109, 175),\r\n  (1, 256, 80, 128),\r\n  (1, 256, 120, 192),\r\n]\r\n\r\nx = torch.randn(*bad_sizes[2]).type(dtype)\r\nx_var = torch.autograd.Variable(x)\r\nprint('x.size() = ', x.size())\r\n\r\nconv = torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\r\nconv.type(dtype)\r\n\r\ny = conv(x_var)\r\nprint(y.size())\r\n```\r\n\r\nAny of the bad sizes results in:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"foo.py\", line 19, in <module>\r\n    y = conv(x_var)\r\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 210, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/modules/conv.py\", line 235, in forward\r\n    self.padding, self.dilation, self.groups)\r\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/functional.py\", line 37, in conv2d\r\n    return f(input, weight, bias) if bias is not None else f(input, weight)\r\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 33, in forward\r\n    output = self._update_output(input, weight, bias)\r\n  File \"/home/justin/code/env3/lib/python3.5/site-packages/torch/nn/_functions/conv.py\", line 84, in _update_output\r\n    self.groups, cudnn.benchmark)\r\nRuntimeError: CUDA error\r\n```\r\n\r\nI'm using PyTorch installed from source at https://github.com/pytorch/pytorch/commit/f8e89fbe1123f6788992b70361f13ad498665327 on Ubuntu 16.04 with CUDA 8.0.44, CUDA driver 367.57, and cuDNN 5.1.5.\r\n\r\nI get the same error on a Pascal Titan X and a Maxwell Titan X, and on both Python 2.7.12 and Python 3.5.2."}