{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1240", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1240/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1240/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1240/events", "html_url": "https://github.com/pytorch/pytorch/issues/1240", "id": 221152616, "node_id": "MDU6SXNzdWUyMjExNTI2MTY=", "number": 1240, "title": "Segfault when passing invalid tensor into a model", "user": {"login": "eklitzke", "id": 2734, "node_id": "MDQ6VXNlcjI3MzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2734?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eklitzke", "html_url": "https://github.com/eklitzke", "followers_url": "https://api.github.com/users/eklitzke/followers", "following_url": "https://api.github.com/users/eklitzke/following{/other_user}", "gists_url": "https://api.github.com/users/eklitzke/gists{/gist_id}", "starred_url": "https://api.github.com/users/eklitzke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eklitzke/subscriptions", "organizations_url": "https://api.github.com/users/eklitzke/orgs", "repos_url": "https://api.github.com/users/eklitzke/repos", "events_url": "https://api.github.com/users/eklitzke/events{/privacy}", "received_events_url": "https://api.github.com/users/eklitzke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-04-12T05:05:14Z", "updated_at": "2017-08-08T21:17:57Z", "closed_at": "2017-08-08T21:17:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is a minimal test case to reproduce the issue I am seeing:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\nmodel <span class=\"pl-k\">=</span> torch.nn.Sequential(torch.nn.Linear(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">10</span>))\nx <span class=\"pl-k\">=</span> torch.autograd.Variable(torch.randn(<span class=\"pl-c1\">5</span>))\nmodel(x)</pre></div>\n<p>The code is obviously wrong here: the model expects a 2D tensor, but the input is only 1D. But I expect this to throw a Python exception. I am getting a segfault both with the version of pytorch from conda, and one I installed with <code>pip</code> from <a href=\"http://download.pytorch.org/whl/cu75/torch-0.1.11.post5-cp36-cp36m-linux_x86_64.whl\" rel=\"nofollow\">http://download.pytorch.org/whl/cu75/torch-0.1.11.post5-cp36-cp36m-linux_x86_64.whl</a></p>\n<p>More info about my system:</p>\n<ul>\n<li>64-bit Linux, Python 3.6.0</li>\n<li>for conda installation I'm using python 0.1.11 py36_5 from soumith</li>\n<li>glibc 2.25</li>\n</ul>\n<p>You should be able to reproduce this easily, but here's what GDB is showing me in the back trace:</p>\n<pre><code>#0  0x00007fe4e3e2d125 in _int_malloc () from /lib64/libc.so.6\n#1  0x00007fe4e3e309f8 in malloc () from /lib64/libc.so.6\n#2  0x00007fe4e51d0455 in tls_get_addr_tail () from /lib64/ld-linux-x86-64.so.2\n#3  0x00007fe4d40084bc in __cxa_get_globals () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\n#4  0x00007fe4d4007c06 in __cxa_throw () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\n#5  0x00007fe4d4474017 in errorHandler (\n    msg=0x7fffe9365480 \"matrices expected, got 1D, 2D tensors at /py/conda-bld/pytorch_1490980628440/work/torch/lib/TH/generic/THTensorMath.c:1224\", data=&lt;optimized out&gt;) from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\n#6  0x00007fe4ce0c0880 in _THError () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\n#7  0x00007fe4ce155b15 in THFloatTensor_addmm () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\n#8  0x00007fe4d448910d in THPFloatTensor_addmm_ (self=0x7fe4b04d64c8, args=&lt;optimized out&gt;, kwargs=&lt;optimized out&gt;)\n   from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\n#9  0x00007fe4e4d7a902 in _PyCFunction_FastCallDict (func_obj=0x7fe4b0c114c8, args=0x7fe4d51c67a8, nargs=&lt;optimized out&gt;, kwargs=0x0)\n    at Objects/methodobject.c:231\n#10 0x00007fe4e4dfff4c in call_function (pp_stack=0x7fffe93661e8, oparg=&lt;optimized out&gt;, kwnames=0x0) at Python/ceval.c:4788\n</code></pre>\n<p>What's interesting here is that as you can see from the backtrace, libTH is correctly detecting that the input tensor has invalid dimensions, and is trying to throw a C++ exception. Throwing the exception causes memory to be allocated, and the segfault happens from within malloc.</p>\n<p>I tried running this under Valgrind, and the results are pretty interesting. The program does <strong>not</strong> segfault in Valgrind, and I see a valid Python exception thrown. Of course, this isn't that unexpected, because Valgrind has its own malloc implementation. However, I <strong>do</strong> see a lot of errors about accessing uninitialized memory! They are all in <code>libiomp5.so</code>, and generally look like this:</p>\n<pre><code>==18172==    at 0x37A8708F: __intel_sse2_strrchr (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A25411: _INTERNAL_45_______src_thirdparty_tbb_omp_dynamic_link_cpp_7b148ce4::__kmp::init_dl_data() (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A25366: __sti__$E (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A97F25: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x3799748A: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0xFFEFFFC87: ???\n==18172==    by 0x4010ACB: _dl_init (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x4015A49: dl_open_worker (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\n==18172==    by 0x4014F58: _dl_open (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x5532F25: dlopen_doit (in /usr/lib64/libdl-2.25.so)\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\n</code></pre>\n<p>I see a bunch of these, I think from each thread. So it seems plausible that MKL is to blame here, but I don't know how to build my own MKL to confirm.</p>", "body_text": "This is a minimal test case to reproduce the issue I am seeing:\nimport torch\n\nmodel = torch.nn.Sequential(torch.nn.Linear(5, 10))\nx = torch.autograd.Variable(torch.randn(5))\nmodel(x)\nThe code is obviously wrong here: the model expects a 2D tensor, but the input is only 1D. But I expect this to throw a Python exception. I am getting a segfault both with the version of pytorch from conda, and one I installed with pip from http://download.pytorch.org/whl/cu75/torch-0.1.11.post5-cp36-cp36m-linux_x86_64.whl\nMore info about my system:\n\n64-bit Linux, Python 3.6.0\nfor conda installation I'm using python 0.1.11 py36_5 from soumith\nglibc 2.25\n\nYou should be able to reproduce this easily, but here's what GDB is showing me in the back trace:\n#0  0x00007fe4e3e2d125 in _int_malloc () from /lib64/libc.so.6\n#1  0x00007fe4e3e309f8 in malloc () from /lib64/libc.so.6\n#2  0x00007fe4e51d0455 in tls_get_addr_tail () from /lib64/ld-linux-x86-64.so.2\n#3  0x00007fe4d40084bc in __cxa_get_globals () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\n#4  0x00007fe4d4007c06 in __cxa_throw () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\n#5  0x00007fe4d4474017 in errorHandler (\n    msg=0x7fffe9365480 \"matrices expected, got 1D, 2D tensors at /py/conda-bld/pytorch_1490980628440/work/torch/lib/TH/generic/THTensorMath.c:1224\", data=<optimized out>) from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\n#6  0x00007fe4ce0c0880 in _THError () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\n#7  0x00007fe4ce155b15 in THFloatTensor_addmm () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\n#8  0x00007fe4d448910d in THPFloatTensor_addmm_ (self=0x7fe4b04d64c8, args=<optimized out>, kwargs=<optimized out>)\n   from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\n#9  0x00007fe4e4d7a902 in _PyCFunction_FastCallDict (func_obj=0x7fe4b0c114c8, args=0x7fe4d51c67a8, nargs=<optimized out>, kwargs=0x0)\n    at Objects/methodobject.c:231\n#10 0x00007fe4e4dfff4c in call_function (pp_stack=0x7fffe93661e8, oparg=<optimized out>, kwnames=0x0) at Python/ceval.c:4788\n\nWhat's interesting here is that as you can see from the backtrace, libTH is correctly detecting that the input tensor has invalid dimensions, and is trying to throw a C++ exception. Throwing the exception causes memory to be allocated, and the segfault happens from within malloc.\nI tried running this under Valgrind, and the results are pretty interesting. The program does not segfault in Valgrind, and I see a valid Python exception thrown. Of course, this isn't that unexpected, because Valgrind has its own malloc implementation. However, I do see a lot of errors about accessing uninitialized memory! They are all in libiomp5.so, and generally look like this:\n==18172==    at 0x37A8708F: __intel_sse2_strrchr (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A25411: _INTERNAL_45_______src_thirdparty_tbb_omp_dynamic_link_cpp_7b148ce4::__kmp::init_dl_data() (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A25366: __sti__$E (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x37A97F25: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0x3799748A: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\n==18172==    by 0xFFEFFFC87: ???\n==18172==    by 0x4010ACB: _dl_init (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x4015A49: dl_open_worker (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\n==18172==    by 0x4014F58: _dl_open (in /usr/lib64/ld-2.25.so)\n==18172==    by 0x5532F25: dlopen_doit (in /usr/lib64/libdl-2.25.so)\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\n\nI see a bunch of these, I think from each thread. So it seems plausible that MKL is to blame here, but I don't know how to build my own MKL to confirm.", "body": "This is a minimal test case to reproduce the issue I am seeing:\r\n\r\n```python\r\nimport torch\r\n\r\nmodel = torch.nn.Sequential(torch.nn.Linear(5, 10))\r\nx = torch.autograd.Variable(torch.randn(5))\r\nmodel(x)\r\n```\r\n\r\nThe code is obviously wrong here: the model expects a 2D tensor, but the input is only 1D. But I expect this to throw a Python exception. I am getting a segfault both with the version of pytorch from conda, and one I installed with `pip` from http://download.pytorch.org/whl/cu75/torch-0.1.11.post5-cp36-cp36m-linux_x86_64.whl\r\n\r\n More info about my system:\r\n\r\n * 64-bit Linux, Python 3.6.0\r\n * for conda installation I'm using python 0.1.11 py36_5 from soumith\r\n * glibc 2.25\r\n\r\nYou should be able to reproduce this easily, but here's what GDB is showing me in the back trace:\r\n\r\n```\r\n#0  0x00007fe4e3e2d125 in _int_malloc () from /lib64/libc.so.6\r\n#1  0x00007fe4e3e309f8 in malloc () from /lib64/libc.so.6\r\n#2  0x00007fe4e51d0455 in tls_get_addr_tail () from /lib64/ld-linux-x86-64.so.2\r\n#3  0x00007fe4d40084bc in __cxa_get_globals () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\r\n#4  0x00007fe4d4007c06 in __cxa_throw () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libshm.so\r\n#5  0x00007fe4d4474017 in errorHandler (\r\n    msg=0x7fffe9365480 \"matrices expected, got 1D, 2D tensors at /py/conda-bld/pytorch_1490980628440/work/torch/lib/TH/generic/THTensorMath.c:1224\", data=<optimized out>) from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\r\n#6  0x00007fe4ce0c0880 in _THError () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\r\n#7  0x00007fe4ce155b15 in THFloatTensor_addmm () from /home/evan/miniconda3/lib/python3.6/site-packages/torch/lib/libTH.so.1\r\n#8  0x00007fe4d448910d in THPFloatTensor_addmm_ (self=0x7fe4b04d64c8, args=<optimized out>, kwargs=<optimized out>)\r\n   from /home/evan/miniconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so\r\n#9  0x00007fe4e4d7a902 in _PyCFunction_FastCallDict (func_obj=0x7fe4b0c114c8, args=0x7fe4d51c67a8, nargs=<optimized out>, kwargs=0x0)\r\n    at Objects/methodobject.c:231\r\n#10 0x00007fe4e4dfff4c in call_function (pp_stack=0x7fffe93661e8, oparg=<optimized out>, kwnames=0x0) at Python/ceval.c:4788\r\n```\r\n\r\nWhat's interesting here is that as you can see from the backtrace, libTH is correctly detecting that the input tensor has invalid dimensions, and is trying to throw a C++ exception. Throwing the exception causes memory to be allocated, and the segfault happens from within malloc.\r\n\r\nI tried running this under Valgrind, and the results are pretty interesting. The program does **not** segfault in Valgrind, and I see a valid Python exception thrown. Of course, this isn't that unexpected, because Valgrind has its own malloc implementation. However, I **do** see a lot of errors about accessing uninitialized memory! They are all in `libiomp5.so`, and generally look like this:\r\n\r\n```\r\n==18172==    at 0x37A8708F: __intel_sse2_strrchr (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\r\n==18172==    by 0x37A25411: _INTERNAL_45_______src_thirdparty_tbb_omp_dynamic_link_cpp_7b148ce4::__kmp::init_dl_data() (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\r\n==18172==    by 0x37A25366: __sti__$E (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\r\n==18172==    by 0x37A97F25: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\r\n==18172==    by 0x3799748A: ??? (in /home/evan/code/polo/.venv/lib/python3.6/site-packages/torch/lib/libiomp5.so)\r\n==18172==    by 0xFFEFFFC87: ???\r\n==18172==    by 0x4010ACB: _dl_init (in /usr/lib64/ld-2.25.so)\r\n==18172==    by 0x4015A49: dl_open_worker (in /usr/lib64/ld-2.25.so)\r\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\r\n==18172==    by 0x4014F58: _dl_open (in /usr/lib64/ld-2.25.so)\r\n==18172==    by 0x5532F25: dlopen_doit (in /usr/lib64/libdl-2.25.so)\r\n==18172==    by 0x5DA0A8E: _dl_catch_error (in /usr/lib64/libc-2.25.so)\r\n```\r\n\r\nI see a bunch of these, I think from each thread. So it seems plausible that MKL is to blame here, but I don't know how to build my own MKL to confirm."}