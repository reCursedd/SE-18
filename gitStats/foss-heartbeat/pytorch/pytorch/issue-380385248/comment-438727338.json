{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/438727338", "html_url": "https://github.com/pytorch/pytorch/pull/13915#issuecomment-438727338", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13915", "id": 438727338, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODcyNzMzOA==", "user": {"login": "nairbv", "id": 582713, "node_id": "MDQ6VXNlcjU4MjcxMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/582713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairbv", "html_url": "https://github.com/nairbv", "followers_url": "https://api.github.com/users/nairbv/followers", "following_url": "https://api.github.com/users/nairbv/following{/other_user}", "gists_url": "https://api.github.com/users/nairbv/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairbv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairbv/subscriptions", "organizations_url": "https://api.github.com/users/nairbv/orgs", "repos_url": "https://api.github.com/users/nairbv/repos", "events_url": "https://api.github.com/users/nairbv/events{/privacy}", "received_events_url": "https://api.github.com/users/nairbv/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-14T16:33:03Z", "updated_at": "2018-11-14T16:33:03Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=582713\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nairbv\">@nairbv</a> I don't understand PyTorch's internals very well. Is <code>_th_arange_out</code> also handled by (the now fixed) <code>THTensor_(arange)(THTensor *r_, accreal xmin, accreal xmax, accreal step)</code>?</p>\n</blockquote>\n<p>yes, I'm new to this as well but the easiest way to see it is if you build the code, it'll appear in the generated file CPUFloatType.cpp (generated by aten/src/ATen/gen.py).</p>\n<p>All of the <code>_th_arange*</code> functions call THFLoatTensor_arange(result_, start_, end_, step_); where sometimes start_ defaults to 0 and sometimes step defaults to 1... where sometimes result_ is a parameter and sometimes result is created. macro expansions lead from the THTensor_(arange) changed here to the THFloatTEnsor_arange being called.</p>", "body_text": "@nairbv I don't understand PyTorch's internals very well. Is _th_arange_out also handled by (the now fixed) THTensor_(arange)(THTensor *r_, accreal xmin, accreal xmax, accreal step)?\n\nyes, I'm new to this as well but the easiest way to see it is if you build the code, it'll appear in the generated file CPUFloatType.cpp (generated by aten/src/ATen/gen.py).\nAll of the _th_arange* functions call THFLoatTensor_arange(result_, start_, end_, step_); where sometimes start_ defaults to 0 and sometimes step defaults to 1... where sometimes result_ is a parameter and sometimes result is created. macro expansions lead from the THTensor_(arange) changed here to the THFloatTEnsor_arange being called.", "body": "> @nairbv I don't understand PyTorch's internals very well. Is `_th_arange_out` also handled by (the now fixed) `THTensor_(arange)(THTensor *r_, accreal xmin, accreal xmax, accreal step)`?\r\n\r\nyes, I'm new to this as well but the easiest way to see it is if you build the code, it'll appear in the generated file CPUFloatType.cpp (generated by aten/src/ATen/gen.py).\r\n\r\nAll of the `_th_arange*` functions call THFLoatTensor_arange(result_, start_, end_, step_); where sometimes start_ defaults to 0 and sometimes step defaults to 1... where sometimes result_ is a parameter and sometimes result is created. macro expansions lead from the THTensor_(arange) changed here to the THFloatTEnsor_arange being called.\r\n"}