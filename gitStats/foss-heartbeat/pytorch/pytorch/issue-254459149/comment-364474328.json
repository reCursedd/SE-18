{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/364474328", "html_url": "https://github.com/pytorch/pytorch/issues/2591#issuecomment-364474328", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2591", "id": 364474328, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDQ3NDMyOA==", "user": {"login": "rdipietro", "id": 5150559, "node_id": "MDQ6VXNlcjUxNTA1NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5150559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdipietro", "html_url": "https://github.com/rdipietro", "followers_url": "https://api.github.com/users/rdipietro/followers", "following_url": "https://api.github.com/users/rdipietro/following{/other_user}", "gists_url": "https://api.github.com/users/rdipietro/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdipietro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdipietro/subscriptions", "organizations_url": "https://api.github.com/users/rdipietro/orgs", "repos_url": "https://api.github.com/users/rdipietro/repos", "events_url": "https://api.github.com/users/rdipietro/events{/privacy}", "received_events_url": "https://api.github.com/users/rdipietro/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-09T15:57:26Z", "updated_at": "2018-02-09T15:57:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Throwing my version here too. Not sure if there are any tradeoffs with the version above, though the name is consistent with scipy's <code>logsumexp</code>, it's a bit shorter, and <code>dim=None</code> works.</p>\n<pre><code>def logsumexp(inputs, dim=None, keepdim=False):\n    \"\"\"Numerically stable logsumexp.\n\n    Args:\n        inputs: A Variable with any shape.\n        dim: An integer.\n        keepdim: A boolean.\n\n    Returns:\n        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\n    \"\"\"\n    # For a 1-D array x (any array along a single dimension),\n    # log sum exp(x) = s + log sum exp(x - s)\n    # with s = max(x) being a common choice.\n    if dim is None:\n        inputs = inputs.view(-1)\n        dim = 0\n    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n    if not keepdim:\n        outputs = outputs.squeeze(dim)\n    return outputs\n</code></pre>", "body_text": "Throwing my version here too. Not sure if there are any tradeoffs with the version above, though the name is consistent with scipy's logsumexp, it's a bit shorter, and dim=None works.\ndef logsumexp(inputs, dim=None, keepdim=False):\n    \"\"\"Numerically stable logsumexp.\n\n    Args:\n        inputs: A Variable with any shape.\n        dim: An integer.\n        keepdim: A boolean.\n\n    Returns:\n        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\n    \"\"\"\n    # For a 1-D array x (any array along a single dimension),\n    # log sum exp(x) = s + log sum exp(x - s)\n    # with s = max(x) being a common choice.\n    if dim is None:\n        inputs = inputs.view(-1)\n        dim = 0\n    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n    if not keepdim:\n        outputs = outputs.squeeze(dim)\n    return outputs", "body": "Throwing my version here too. Not sure if there are any tradeoffs with the version above, though the name is consistent with scipy's `logsumexp`, it's a bit shorter, and `dim=None` works.\r\n\r\n```\r\ndef logsumexp(inputs, dim=None, keepdim=False):\r\n    \"\"\"Numerically stable logsumexp.\r\n\r\n    Args:\r\n        inputs: A Variable with any shape.\r\n        dim: An integer.\r\n        keepdim: A boolean.\r\n\r\n    Returns:\r\n        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\r\n    \"\"\"\r\n    # For a 1-D array x (any array along a single dimension),\r\n    # log sum exp(x) = s + log sum exp(x - s)\r\n    # with s = max(x) being a common choice.\r\n    if dim is None:\r\n        inputs = inputs.view(-1)\r\n        dim = 0\r\n    s, _ = torch.max(inputs, dim=dim, keepdim=True)\r\n    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\r\n    if not keepdim:\r\n        outputs = outputs.squeeze(dim)\r\n    return outputs\r\n```"}