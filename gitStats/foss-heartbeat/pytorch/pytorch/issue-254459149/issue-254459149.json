{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2591", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2591/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2591/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2591/events", "html_url": "https://github.com/pytorch/pytorch/issues/2591", "id": 254459149, "node_id": "MDU6SXNzdWUyNTQ0NTkxNDk=", "number": 2591, "title": "Feature request: logsumexp", "user": {"login": "rdipietro", "id": 5150559, "node_id": "MDQ6VXNlcjUxNTA1NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5150559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rdipietro", "html_url": "https://github.com/rdipietro", "followers_url": "https://api.github.com/users/rdipietro/followers", "following_url": "https://api.github.com/users/rdipietro/following{/other_user}", "gists_url": "https://api.github.com/users/rdipietro/gists{/gist_id}", "starred_url": "https://api.github.com/users/rdipietro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rdipietro/subscriptions", "organizations_url": "https://api.github.com/users/rdipietro/orgs", "repos_url": "https://api.github.com/users/rdipietro/repos", "events_url": "https://api.github.com/users/rdipietro/events{/privacy}", "received_events_url": "https://api.github.com/users/rdipietro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-08-31T20:32:16Z", "updated_at": "2018-09-07T18:11:24Z", "closed_at": "2018-05-15T02:08:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The numerically stable version of <code>logsumexp</code> is simple but often useful. Thoughts on including this in PyTorch?</p>\n<p>My thought is that it'd follow a call signature(s) that's similar to that of <code>sum</code>, but <code>logsumexp</code> wouldn't have the <code>out</code> keyword, and it'd also use the NumPy-consistent <code>keepdims</code> keyword instead of <code>sum</code>'s <code>keepdim</code> keyword. So</p>\n<pre><code>def logsumexp(inputs, dim=None, keepdims=False):\n    ...\n</code></pre>", "body_text": "The numerically stable version of logsumexp is simple but often useful. Thoughts on including this in PyTorch?\nMy thought is that it'd follow a call signature(s) that's similar to that of sum, but logsumexp wouldn't have the out keyword, and it'd also use the NumPy-consistent keepdims keyword instead of sum's keepdim keyword. So\ndef logsumexp(inputs, dim=None, keepdims=False):\n    ...", "body": "The numerically stable version of `logsumexp` is simple but often useful. Thoughts on including this in PyTorch?\r\n\r\nMy thought is that it'd follow a call signature(s) that's similar to that of `sum`, but `logsumexp` wouldn't have the `out` keyword, and it'd also use the NumPy-consistent `keepdims` keyword instead of `sum`'s `keepdim` keyword. So\r\n\r\n```\r\ndef logsumexp(inputs, dim=None, keepdims=False):\r\n    ...\r\n```"}