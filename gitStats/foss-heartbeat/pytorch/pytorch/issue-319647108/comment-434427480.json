{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/434427480", "html_url": "https://github.com/pytorch/pytorch/issues/7181#issuecomment-434427480", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7181", "id": 434427480, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDQyNzQ4MA==", "user": {"login": "neighthan", "id": 12573501, "node_id": "MDQ6VXNlcjEyNTczNTAx", "avatar_url": "https://avatars3.githubusercontent.com/u/12573501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neighthan", "html_url": "https://github.com/neighthan", "followers_url": "https://api.github.com/users/neighthan/followers", "following_url": "https://api.github.com/users/neighthan/following{/other_user}", "gists_url": "https://api.github.com/users/neighthan/gists{/gist_id}", "starred_url": "https://api.github.com/users/neighthan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neighthan/subscriptions", "organizations_url": "https://api.github.com/users/neighthan/orgs", "repos_url": "https://api.github.com/users/neighthan/repos", "events_url": "https://api.github.com/users/neighthan/events{/privacy}", "received_events_url": "https://api.github.com/users/neighthan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-30T18:57:19Z", "updated_at": "2018-10-30T18:57:19Z", "author_association": "NONE", "body_html": "<p>I had this same problem and was about to post asking for an idea of how such synchronization might work, but I figured out a solution that worked in my case. I thought I'd share in case somebody else comes here and isn't sure how to do the necessary synchronization.</p>\n<p>Here's a trivial problem which lines up with my use case (needing to pass some tensor to several workers who each compute something based on it). There may be a better way to do this than using 3 queues, but this way is very simple and makes it easy to reason about what's happening with each queue.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.multiprocessing <span class=\"pl-k\">import</span> Process, Queue, set_start_method\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">worker</span>(<span class=\"pl-smi\">input_queue</span>, <span class=\"pl-smi\">results_queue</span>, <span class=\"pl-smi\">exit_queue</span>):\n    start, end, tensor <span class=\"pl-k\">=</span> input_queue.get()\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> I put start, end too as an identifier for this process/result</span>\n    results_queue.put((start, end, tensor[start:end].float().mean()))\n    exit_queue.get()\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>spawn<span class=\"pl-pds\">\"</span></span>)\n\n    input_queue <span class=\"pl-k\">=</span> Queue()\n    results_queue <span class=\"pl-k\">=</span> Queue()\n    exit_queue <span class=\"pl-k\">=</span> Queue()\n\n    tensor <span class=\"pl-k\">=</span> torch.arange(<span class=\"pl-c1\">100</span>)\n    step <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n    n_procs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    <span class=\"pl-k\">for</span> start <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">len</span>(tensor), step):\n        end <span class=\"pl-k\">=</span> start <span class=\"pl-k\">+</span> step <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\n        input_queue.put((start, end, tensor))\n        n_procs <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n\n    procs <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n_procs):\n        proc <span class=\"pl-k\">=</span> Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>worker, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(input_queue, results_queue, exit_queue))\n        proc.start()\n        procs.append(proc)\n\n    results <span class=\"pl-k\">=</span> [results_queue.get() <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n_procs)]\n    <span class=\"pl-c1\">print</span>(results)\n\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n_procs):\n        exit_queue.put(<span class=\"pl-c1\">1</span>)\n\n    <span class=\"pl-k\">for</span> proc <span class=\"pl-k\">in</span> procs:\n        proc.join()</pre></div>", "body_text": "I had this same problem and was about to post asking for an idea of how such synchronization might work, but I figured out a solution that worked in my case. I thought I'd share in case somebody else comes here and isn't sure how to do the necessary synchronization.\nHere's a trivial problem which lines up with my use case (needing to pass some tensor to several workers who each compute something based on it). There may be a better way to do this than using 3 queues, but this way is very simple and makes it easy to reason about what's happening with each queue.\nimport torch\nfrom torch.multiprocessing import Process, Queue, set_start_method\n\ndef worker(input_queue, results_queue, exit_queue):\n    start, end, tensor = input_queue.get()\n    # I put start, end too as an identifier for this process/result\n    results_queue.put((start, end, tensor[start:end].float().mean()))\n    exit_queue.get()\n\nif __name__ == \"__main__\":\n    set_start_method(\"spawn\")\n\n    input_queue = Queue()\n    results_queue = Queue()\n    exit_queue = Queue()\n\n    tensor = torch.arange(100)\n    step = 10\n    n_procs = 0\n    for start in range(0, len(tensor), step):\n        end = start + step - 1\n        input_queue.put((start, end, tensor))\n        n_procs += 1\n\n    procs = []\n    for _ in range(n_procs):\n        proc = Process(target=worker, args=(input_queue, results_queue, exit_queue))\n        proc.start()\n        procs.append(proc)\n\n    results = [results_queue.get() for _ in range(n_procs)]\n    print(results)\n\n    for _ in range(n_procs):\n        exit_queue.put(1)\n\n    for proc in procs:\n        proc.join()", "body": "I had this same problem and was about to post asking for an idea of how such synchronization might work, but I figured out a solution that worked in my case. I thought I'd share in case somebody else comes here and isn't sure how to do the necessary synchronization.\r\n\r\nHere's a trivial problem which lines up with my use case (needing to pass some tensor to several workers who each compute something based on it). There may be a better way to do this than using 3 queues, but this way is very simple and makes it easy to reason about what's happening with each queue.\r\n\r\n```python\r\nimport torch\r\nfrom torch.multiprocessing import Process, Queue, set_start_method\r\n\r\ndef worker(input_queue, results_queue, exit_queue):\r\n    start, end, tensor = input_queue.get()\r\n    # I put start, end too as an identifier for this process/result\r\n    results_queue.put((start, end, tensor[start:end].float().mean()))\r\n    exit_queue.get()\r\n\r\nif __name__ == \"__main__\":\r\n    set_start_method(\"spawn\")\r\n\r\n    input_queue = Queue()\r\n    results_queue = Queue()\r\n    exit_queue = Queue()\r\n\r\n    tensor = torch.arange(100)\r\n    step = 10\r\n    n_procs = 0\r\n    for start in range(0, len(tensor), step):\r\n        end = start + step - 1\r\n        input_queue.put((start, end, tensor))\r\n        n_procs += 1\r\n\r\n    procs = []\r\n    for _ in range(n_procs):\r\n        proc = Process(target=worker, args=(input_queue, results_queue, exit_queue))\r\n        proc.start()\r\n        procs.append(proc)\r\n\r\n    results = [results_queue.get() for _ in range(n_procs)]\r\n    print(results)\r\n\r\n    for _ in range(n_procs):\r\n        exit_queue.put(1)\r\n\r\n    for proc in procs:\r\n        proc.join()\r\n```"}