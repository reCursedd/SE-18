{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4228", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4228/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4228/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4228/events", "html_url": "https://github.com/pytorch/pytorch/issues/4228", "id": 282920599, "node_id": "MDU6SXNzdWUyODI5MjA1OTk=", "number": 4228, "title": "RuntimeError: the number of sizes provided must be greater or equal to the number of dimensions in the tensor", "user": {"login": "hbredin", "id": 1080837, "node_id": "MDQ6VXNlcjEwODA4Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1080837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hbredin", "html_url": "https://github.com/hbredin", "followers_url": "https://api.github.com/users/hbredin/followers", "following_url": "https://api.github.com/users/hbredin/following{/other_user}", "gists_url": "https://api.github.com/users/hbredin/gists{/gist_id}", "starred_url": "https://api.github.com/users/hbredin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hbredin/subscriptions", "organizations_url": "https://api.github.com/users/hbredin/orgs", "repos_url": "https://api.github.com/users/hbredin/repos", "events_url": "https://api.github.com/users/hbredin/events{/privacy}", "received_events_url": "https://api.github.com/users/hbredin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-12-18T15:35:29Z", "updated_at": "2018-01-14T23:35:03Z", "closed_at": "2017-12-18T21:31:47Z", "author_association": "NONE", "body_html": "<p>I am trying to compute a differentiable version of <code>scipy.spatial.distance.pdist</code> for use in a custom loss.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> Tensor\n<span class=\"pl-k\">import</span> torch.nn.functional <span class=\"pl-k\">as</span> F\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> one hundred 3-dimensional vectors</span>\nX <span class=\"pl-k\">=</span> Variable(Tensor(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">3</span>).normal_(), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> compute the equivalent of scipy.spatial.distance.pdist(X, metric='cosine')</span>\nd <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">100</span>):\n   d.append(F.cosine_similarity(X[i,:].expand(i, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>), X[:i]))\npdist <span class=\"pl-k\">=</span> torch.cat(d) </pre></div>\n<p>Up to this point, everything seems to work fine. However, when trying to use this <code>pdist</code> in a custom loss and back-propagate the gradient, a <code>RuntimeError</code> occurs:</p>\n<div class=\"highlight highlight-source-python\"><pre>loss <span class=\"pl-k\">=</span> torch.mean(pdist)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> this is where things go wrong</span>\nloss.backward()</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">RuntimeError</span>: invalid argument <span class=\"pl-c1\">1</span>: the number of sizes provided must be greater <span class=\"pl-k\">or</span> equal to the number of dimensions <span class=\"pl-k\">in</span> the tensor at <span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>minicondabuild3<span class=\"pl-k\">/</span>conda<span class=\"pl-k\">-</span>bld<span class=\"pl-k\">/</span>pytorch_1512381214802<span class=\"pl-k\">/</span>work<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span><span class=\"pl-c1\">TH</span><span class=\"pl-k\">/</span>generic<span class=\"pl-k\">/</span>THTensor.c:<span class=\"pl-c1\">299</span></pre></div>\n<p>I am pretty sure I did a stupid mistake (been playing with pytorch for only a few days) but I must confess I am completely at a loss (pun intended) here. Any idea what I did wrong? I am using version <code>0.3.0.post4</code>.</p>", "body_text": "I am trying to compute a differentiable version of scipy.spatial.distance.pdist for use in a custom loss.\nimport torch\nfrom torch.autograd import Variable\nfrom torch import Tensor\nimport torch.nn.functional as F\n\n# one hundred 3-dimensional vectors\nX = Variable(Tensor(100, 3).normal_(), requires_grad=True)\n\n# compute the equivalent of scipy.spatial.distance.pdist(X, metric='cosine')\nd = []\nfor i in range(1, 100):\n   d.append(F.cosine_similarity(X[i,:].expand(i, -1), X[:i]))\npdist = torch.cat(d) \nUp to this point, everything seems to work fine. However, when trying to use this pdist in a custom loss and back-propagate the gradient, a RuntimeError occurs:\nloss = torch.mean(pdist)\n\n# this is where things go wrong\nloss.backward()\nRuntimeError: invalid argument 1: the number of sizes provided must be greater or equal to the number of dimensions in the tensor at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512381214802/work/torch/lib/TH/generic/THTensor.c:299\nI am pretty sure I did a stupid mistake (been playing with pytorch for only a few days) but I must confess I am completely at a loss (pun intended) here. Any idea what I did wrong? I am using version 0.3.0.post4.", "body": "I am trying to compute a differentiable version of `scipy.spatial.distance.pdist` for use in a custom loss.  \r\n\r\n```python\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom torch import Tensor\r\nimport torch.nn.functional as F\r\n\r\n# one hundred 3-dimensional vectors\r\nX = Variable(Tensor(100, 3).normal_(), requires_grad=True)\r\n\r\n# compute the equivalent of scipy.spatial.distance.pdist(X, metric='cosine')\r\nd = []\r\nfor i in range(1, 100):\r\n   d.append(F.cosine_similarity(X[i,:].expand(i, -1), X[:i]))\r\npdist = torch.cat(d) \r\n```\r\n\r\nUp to this point, everything seems to work fine. However, when trying to use this `pdist` in a custom loss and back-propagate the gradient, a `RuntimeError` occurs:\r\n\r\n```python\r\nloss = torch.mean(pdist)\r\n\r\n# this is where things go wrong\r\nloss.backward()\r\n```\r\n\r\n```python\r\nRuntimeError: invalid argument 1: the number of sizes provided must be greater or equal to the number of dimensions in the tensor at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512381214802/work/torch/lib/TH/generic/THTensor.c:299\r\n```\r\n\r\nI am pretty sure I did a stupid mistake (been playing with pytorch for only a few days) but I must confess I am completely at a loss (pun intended) here. Any idea what I did wrong? I am using version `0.3.0.post4`."}