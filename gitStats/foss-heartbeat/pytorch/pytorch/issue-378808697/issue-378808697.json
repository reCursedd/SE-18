{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13722", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13722/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13722/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13722/events", "html_url": "https://github.com/pytorch/pytorch/issues/13722", "id": 378808697, "node_id": "MDU6SXNzdWUzNzg4MDg2OTc=", "number": 13722, "title": "Extremely high GPU memory usage for a simple architecture", "user": {"login": "kamilkk852", "id": 36404581, "node_id": "MDQ6VXNlcjM2NDA0NTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/36404581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kamilkk852", "html_url": "https://github.com/kamilkk852", "followers_url": "https://api.github.com/users/kamilkk852/followers", "following_url": "https://api.github.com/users/kamilkk852/following{/other_user}", "gists_url": "https://api.github.com/users/kamilkk852/gists{/gist_id}", "starred_url": "https://api.github.com/users/kamilkk852/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kamilkk852/subscriptions", "organizations_url": "https://api.github.com/users/kamilkk852/orgs", "repos_url": "https://api.github.com/users/kamilkk852/repos", "events_url": "https://api.github.com/users/kamilkk852/events{/privacy}", "received_events_url": "https://api.github.com/users/kamilkk852/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-08T16:17:55Z", "updated_at": "2018-11-13T13:35:22Z", "closed_at": "2018-11-13T13:35:21Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>When using a particular architecture, pytorch is throwing CUDA OOME much faster (with \"batch_size\" of 10k) than tensorflow (which runs smoothly with \"batch_size\" of 200k-500k).</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<p>I wrote two almost identical implementations of a problematic NN architecture in both pytorch and tensorflow.</p>\n<p>Here is PyTorch version:</p>\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, **params):\n        super(Model, self).__init__()\n        self.windows = [1, 2, 3]\n\n        self.region_emb_layers = nn.ModuleList([nn.Conv2d(1, 150,\n                                                kernel_size=(window, 300), stride=1) \\\n                                                for window in self.windows])\n        self.beg_conv_layers = nn.ModuleList([nn.Conv2d(450, 450, \\\n                                              kernel_size=(3, 1), stride=1) \\\n                                              for _ in range(2)])                                   \n\n        self.pooling = nn.MaxPool2d(kernel_size=(3, 1), stride=2)\n        self.padding_conv = nn.ZeroPad2d((0, 0, 0, 2))\n        self.act_fun = nn.ReLU()\n        self.linear_out = nn.Linear(450, 2)\n\n    def forward(self, out, emb):\n        outs = [None]*len(self.windows)\n        out = emb(out)\n        out = out.unsqueeze(1)\n        \n        for i, (window, region_emb_layer) in enumerate(zip(self.windows, self.region_emb_layers)):\n            out_ = region_emb_layer(out)\n            out_ = nn.ZeroPad2d((0, 0, 0, window - 1))(out_)\n            outs[i] = out_\n\n        out = torch.cat(outs, dim=1)\n        \n        for beg_conv_layer in self.beg_conv_layers:\n            out = self.padding_conv(out)\n            out = beg_conv_layer(out)\n            out = self.act_fun(out)\n            \n        out = F.adaptive_max_pool2d(out, (1, 1))\n        out = out.view(out.size(0), -1)\n        out = self.linear_out(out)\n        \n        return out\n\nimport numpy as np\n\ndef gen(dataset_size, batch_size):\n    for i in range(dataset_size // batch_size):\n        b = np.random.choice([10, 30, 70, 200, 500, 1000])\n        a = batch_size // b\n\n        x = np.random.randint(0, 42000, (a, b))\n        y = np.random.randint(0, 2, (a,))\n        \n        yield x, y\n\n\ndevice = torch.device('cuda:0')\n\nmodel = Model().to(device)\nmodel = model.to(device)\n\nprint('Model parameters cnt: {}'.format(sum(p.numel() for p in model.parameters())))\n\nemb = nn.Embedding(42000, 300).to(device)\nemb.weight.requires_grad_(False)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\ndataset_size = int(1e6)\nbatch_size = 10000\n\nfor i, (x, y) in enumerate(gen(dataset_size, batch_size)):\n    if i % 10 == 0:\n        print(i)\n\n    x = torch.from_numpy(x).to(device)\n    y = torch.from_numpy(y).to(device)\n\n    out = model(x, emb=emb)\n\n    crit = nn.CrossEntropyLoss()\n    loss = crit(out, y)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n</code></pre>\n<p>And tensorflow:</p>\n<pre><code>import tensorflow\nimport numpy as np\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Lambda, Input, Conv2D, Dense, Flatten, \\\nEmbedding, Concatenate, ZeroPadding2D\nfrom keras.optimizers import Adam\nimport keras.backend as K\n\n\nx_in = Input((None,))\n\nx = x_in\n\nx = Embedding(42000, 300, trainable=False)(x)\nx = Lambda(lambda x: K.expand_dims(x, axis=3))(x)\n\nx1 = ZeroPadding2D(((0, 2), (0, 0)))(x)\nx1 = Conv2D(150, (3, 300), activation='relu')(x1)\nx2 = ZeroPadding2D(((0, 1), (0, 0)))(x)\nx2 = Conv2D(150, (2, 300), activation='relu')(x2)\nx3 = Conv2D(150, (1, 300), activation='relu')(x)\n\nx = Concatenate(axis=3)([x1, x2, x3])\n\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\n\nx = Lambda(lambda x: K.max(x, axis=1))(x)\n\nx = Flatten()(x)\nx = Dense(1, activation='sigmoid')(x)\n\nx_out = x\n\nmodel = Model(inputs=x_in, outputs=x_out)\nopt = Adam(lr=1e-3)\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\n\nprint(model.summary())\n\ndef gen(batch_size):\n  while True:\n    b = np.random.choice([10, 30, 70, 200, 500, 1000])\n    a = batch_size // b\n    x = np.random.randint(0, 42000, (a, b))\n    y = np.random.randint(0, 2, (a,))\n    \n    yield x, y\n\ndataset_size = int(1e6)\nbatch_size = 200000\n\nmodel.fit_generator(gen(batch_size), steps_per_epoch=dataset_size//batch_size)\n</code></pre>\n<p>If you run both scripts on 11GB GPU you should see CUDA OOME in pytorch (on loss.backward() line), but not in tensorflow script.</p>\n<h2>Expected behavior</h2>\n<p>I would expect adequate GPU memory usage for such a simple architecture and small input size (10k numbers), which is the case in tensorflow, but not in pytorch.</p>\n<h2>Environment</h2>\n<p>(This is the environment of Google Colaboratory, but the same issue on two other machines)</p>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.148<br>\nGPU models and configuration: GPU 0: Tesla K80<br>\nNvidia driver version: 396.44<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.3.1</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] Could not collect</p>", "body_text": "\ud83d\udc1b Bug\nWhen using a particular architecture, pytorch is throwing CUDA OOME much faster (with \"batch_size\" of 10k) than tensorflow (which runs smoothly with \"batch_size\" of 200k-500k).\nTo Reproduce\nSteps to reproduce the behavior:\nI wrote two almost identical implementations of a problematic NN architecture in both pytorch and tensorflow.\nHere is PyTorch version:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self, **params):\n        super(Model, self).__init__()\n        self.windows = [1, 2, 3]\n\n        self.region_emb_layers = nn.ModuleList([nn.Conv2d(1, 150,\n                                                kernel_size=(window, 300), stride=1) \\\n                                                for window in self.windows])\n        self.beg_conv_layers = nn.ModuleList([nn.Conv2d(450, 450, \\\n                                              kernel_size=(3, 1), stride=1) \\\n                                              for _ in range(2)])                                   \n\n        self.pooling = nn.MaxPool2d(kernel_size=(3, 1), stride=2)\n        self.padding_conv = nn.ZeroPad2d((0, 0, 0, 2))\n        self.act_fun = nn.ReLU()\n        self.linear_out = nn.Linear(450, 2)\n\n    def forward(self, out, emb):\n        outs = [None]*len(self.windows)\n        out = emb(out)\n        out = out.unsqueeze(1)\n        \n        for i, (window, region_emb_layer) in enumerate(zip(self.windows, self.region_emb_layers)):\n            out_ = region_emb_layer(out)\n            out_ = nn.ZeroPad2d((0, 0, 0, window - 1))(out_)\n            outs[i] = out_\n\n        out = torch.cat(outs, dim=1)\n        \n        for beg_conv_layer in self.beg_conv_layers:\n            out = self.padding_conv(out)\n            out = beg_conv_layer(out)\n            out = self.act_fun(out)\n            \n        out = F.adaptive_max_pool2d(out, (1, 1))\n        out = out.view(out.size(0), -1)\n        out = self.linear_out(out)\n        \n        return out\n\nimport numpy as np\n\ndef gen(dataset_size, batch_size):\n    for i in range(dataset_size // batch_size):\n        b = np.random.choice([10, 30, 70, 200, 500, 1000])\n        a = batch_size // b\n\n        x = np.random.randint(0, 42000, (a, b))\n        y = np.random.randint(0, 2, (a,))\n        \n        yield x, y\n\n\ndevice = torch.device('cuda:0')\n\nmodel = Model().to(device)\nmodel = model.to(device)\n\nprint('Model parameters cnt: {}'.format(sum(p.numel() for p in model.parameters())))\n\nemb = nn.Embedding(42000, 300).to(device)\nemb.weight.requires_grad_(False)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\ndataset_size = int(1e6)\nbatch_size = 10000\n\nfor i, (x, y) in enumerate(gen(dataset_size, batch_size)):\n    if i % 10 == 0:\n        print(i)\n\n    x = torch.from_numpy(x).to(device)\n    y = torch.from_numpy(y).to(device)\n\n    out = model(x, emb=emb)\n\n    crit = nn.CrossEntropyLoss()\n    loss = crit(out, y)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\nAnd tensorflow:\nimport tensorflow\nimport numpy as np\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Lambda, Input, Conv2D, Dense, Flatten, \\\nEmbedding, Concatenate, ZeroPadding2D\nfrom keras.optimizers import Adam\nimport keras.backend as K\n\n\nx_in = Input((None,))\n\nx = x_in\n\nx = Embedding(42000, 300, trainable=False)(x)\nx = Lambda(lambda x: K.expand_dims(x, axis=3))(x)\n\nx1 = ZeroPadding2D(((0, 2), (0, 0)))(x)\nx1 = Conv2D(150, (3, 300), activation='relu')(x1)\nx2 = ZeroPadding2D(((0, 1), (0, 0)))(x)\nx2 = Conv2D(150, (2, 300), activation='relu')(x2)\nx3 = Conv2D(150, (1, 300), activation='relu')(x)\n\nx = Concatenate(axis=3)([x1, x2, x3])\n\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\n\nx = Lambda(lambda x: K.max(x, axis=1))(x)\n\nx = Flatten()(x)\nx = Dense(1, activation='sigmoid')(x)\n\nx_out = x\n\nmodel = Model(inputs=x_in, outputs=x_out)\nopt = Adam(lr=1e-3)\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\n\nprint(model.summary())\n\ndef gen(batch_size):\n  while True:\n    b = np.random.choice([10, 30, 70, 200, 500, 1000])\n    a = batch_size // b\n    x = np.random.randint(0, 42000, (a, b))\n    y = np.random.randint(0, 2, (a,))\n    \n    yield x, y\n\ndataset_size = int(1e6)\nbatch_size = 200000\n\nmodel.fit_generator(gen(batch_size), steps_per_epoch=dataset_size//batch_size)\n\nIf you run both scripts on 11GB GPU you should see CUDA OOME in pytorch (on loss.backward() line), but not in tensorflow script.\nExpected behavior\nI would expect adequate GPU memory usage for such a simple architecture and small input size (10k numbers), which is the case in tensorflow, but not in pytorch.\nEnvironment\n(This is the environment of Google Colaboratory, but the same issue on two other machines)\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\nCMake version: Could not collect\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.148\nGPU models and configuration: GPU 0: Tesla K80\nNvidia driver version: 396.44\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.3.1\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect", "body": "## \ud83d\udc1b Bug\r\n\r\nWhen using a particular architecture, pytorch is throwing CUDA OOME much faster (with \"batch_size\" of 10k) than tensorflow (which runs smoothly with \"batch_size\" of 200k-500k).\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nI wrote two almost identical implementations of a problematic NN architecture in both pytorch and tensorflow.\r\n\r\nHere is PyTorch version:\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nclass Model(nn.Module):\r\n    def __init__(self, **params):\r\n        super(Model, self).__init__()\r\n        self.windows = [1, 2, 3]\r\n\r\n        self.region_emb_layers = nn.ModuleList([nn.Conv2d(1, 150,\r\n                                                kernel_size=(window, 300), stride=1) \\\r\n                                                for window in self.windows])\r\n        self.beg_conv_layers = nn.ModuleList([nn.Conv2d(450, 450, \\\r\n                                              kernel_size=(3, 1), stride=1) \\\r\n                                              for _ in range(2)])                                   \r\n\r\n        self.pooling = nn.MaxPool2d(kernel_size=(3, 1), stride=2)\r\n        self.padding_conv = nn.ZeroPad2d((0, 0, 0, 2))\r\n        self.act_fun = nn.ReLU()\r\n        self.linear_out = nn.Linear(450, 2)\r\n\r\n    def forward(self, out, emb):\r\n        outs = [None]*len(self.windows)\r\n        out = emb(out)\r\n        out = out.unsqueeze(1)\r\n        \r\n        for i, (window, region_emb_layer) in enumerate(zip(self.windows, self.region_emb_layers)):\r\n            out_ = region_emb_layer(out)\r\n            out_ = nn.ZeroPad2d((0, 0, 0, window - 1))(out_)\r\n            outs[i] = out_\r\n\r\n        out = torch.cat(outs, dim=1)\r\n        \r\n        for beg_conv_layer in self.beg_conv_layers:\r\n            out = self.padding_conv(out)\r\n            out = beg_conv_layer(out)\r\n            out = self.act_fun(out)\r\n            \r\n        out = F.adaptive_max_pool2d(out, (1, 1))\r\n        out = out.view(out.size(0), -1)\r\n        out = self.linear_out(out)\r\n        \r\n        return out\r\n\r\nimport numpy as np\r\n\r\ndef gen(dataset_size, batch_size):\r\n    for i in range(dataset_size // batch_size):\r\n        b = np.random.choice([10, 30, 70, 200, 500, 1000])\r\n        a = batch_size // b\r\n\r\n        x = np.random.randint(0, 42000, (a, b))\r\n        y = np.random.randint(0, 2, (a,))\r\n        \r\n        yield x, y\r\n\r\n\r\ndevice = torch.device('cuda:0')\r\n\r\nmodel = Model().to(device)\r\nmodel = model.to(device)\r\n\r\nprint('Model parameters cnt: {}'.format(sum(p.numel() for p in model.parameters())))\r\n\r\nemb = nn.Embedding(42000, 300).to(device)\r\nemb.weight.requires_grad_(False)\r\n\r\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\r\n\r\ndataset_size = int(1e6)\r\nbatch_size = 10000\r\n\r\nfor i, (x, y) in enumerate(gen(dataset_size, batch_size)):\r\n    if i % 10 == 0:\r\n        print(i)\r\n\r\n    x = torch.from_numpy(x).to(device)\r\n    y = torch.from_numpy(y).to(device)\r\n\r\n    out = model(x, emb=emb)\r\n\r\n    crit = nn.CrossEntropyLoss()\r\n    loss = crit(out, y)\r\n    \r\n    optimizer.zero_grad()\r\n    loss.backward()\r\n    optimizer.step()\r\n```\r\n\r\nAnd tensorflow:\r\n```\r\nimport tensorflow\r\nimport numpy as np\r\nimport keras\r\nfrom keras.models import Model\r\nfrom keras.layers import Lambda, Input, Conv2D, Dense, Flatten, \\\r\nEmbedding, Concatenate, ZeroPadding2D\r\nfrom keras.optimizers import Adam\r\nimport keras.backend as K\r\n\r\n\r\nx_in = Input((None,))\r\n\r\nx = x_in\r\n\r\nx = Embedding(42000, 300, trainable=False)(x)\r\nx = Lambda(lambda x: K.expand_dims(x, axis=3))(x)\r\n\r\nx1 = ZeroPadding2D(((0, 2), (0, 0)))(x)\r\nx1 = Conv2D(150, (3, 300), activation='relu')(x1)\r\nx2 = ZeroPadding2D(((0, 1), (0, 0)))(x)\r\nx2 = Conv2D(150, (2, 300), activation='relu')(x2)\r\nx3 = Conv2D(150, (1, 300), activation='relu')(x)\r\n\r\nx = Concatenate(axis=3)([x1, x2, x3])\r\n\r\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\r\nx = Conv2D(450, (3, 1), activation='relu', padding='same')(x)\r\n\r\nx = Lambda(lambda x: K.max(x, axis=1))(x)\r\n\r\nx = Flatten()(x)\r\nx = Dense(1, activation='sigmoid')(x)\r\n\r\nx_out = x\r\n\r\nmodel = Model(inputs=x_in, outputs=x_out)\r\nopt = Adam(lr=1e-3)\r\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\r\n\r\nprint(model.summary())\r\n\r\ndef gen(batch_size):\r\n  while True:\r\n    b = np.random.choice([10, 30, 70, 200, 500, 1000])\r\n    a = batch_size // b\r\n    x = np.random.randint(0, 42000, (a, b))\r\n    y = np.random.randint(0, 2, (a,))\r\n    \r\n    yield x, y\r\n\r\ndataset_size = int(1e6)\r\nbatch_size = 200000\r\n\r\nmodel.fit_generator(gen(batch_size), steps_per_epoch=dataset_size//batch_size)\r\n```\r\nIf you run both scripts on 11GB GPU you should see CUDA OOME in pytorch (on loss.backward() line), but not in tensorflow script.\r\n\r\n## Expected behavior\r\n\r\nI would expect adequate GPU memory usage for such a simple architecture and small input size (10k numbers), which is the case in tensorflow, but not in pytorch.\r\n\r\n## Environment\r\n\r\n(This is the environment of Google Colaboratory, but the same issue on two other machines)\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: Tesla K80\r\nNvidia driver version: 396.44\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.3.1\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect"}