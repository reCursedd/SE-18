{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/409436146", "html_url": "https://github.com/pytorch/pytorch/issues/10062#issuecomment-409436146", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10062", "id": 409436146, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTQzNjE0Ng==", "user": {"login": "veepersgit", "id": 19464374, "node_id": "MDQ6VXNlcjE5NDY0Mzc0", "avatar_url": "https://avatars1.githubusercontent.com/u/19464374?v=4", "gravatar_id": "", "url": "https://api.github.com/users/veepersgit", "html_url": "https://github.com/veepersgit", "followers_url": "https://api.github.com/users/veepersgit/followers", "following_url": "https://api.github.com/users/veepersgit/following{/other_user}", "gists_url": "https://api.github.com/users/veepersgit/gists{/gist_id}", "starred_url": "https://api.github.com/users/veepersgit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/veepersgit/subscriptions", "organizations_url": "https://api.github.com/users/veepersgit/orgs", "repos_url": "https://api.github.com/users/veepersgit/repos", "events_url": "https://api.github.com/users/veepersgit/events{/privacy}", "received_events_url": "https://api.github.com/users/veepersgit/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-01T03:17:41Z", "updated_at": "2018-08-01T03:20:01Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=30275821\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/houseroad\">@houseroad</a> Hi\uff5eThanks for your reply! I'v taken your advice to use the onnx model from the model zoo. However,  a new issue comes when I transfer the onnx model to caffe2 model and try to inference. Here's the error log:</p>\n<p>E0801 10:47:45.208793  4411 operator_schema.cc:82] Argument 'is_test' is required for Operator 'SpatialBN'.<br>\nTraceback (most recent call last):<br>\nFile \"main.py\", line 21, in <br>\np=workspace.Predictor(init_net, predict_net)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/caffe2/python/workspace.py\", line 157, in Predictor<br>\nreturn C.Predictor(StringifyProto(init_net), StringifyProto(predict_net))<br>\nRuntimeError: [enforce fail at operator.cc:113] schema-&gt;Verify(operator_def). Operator def did not pass schema checking: input: \"gpu_0/conv3_0_1\" input: \"gpu_0/conv3_0_bn_s_0\" input: \"gpu_0/conv3_0_bn_b_0\" input: \"gpu_0/conv3_0_bn_rm_0\" input: \"gpu_0/conv3_0_bn_riv_0\" output: \"gpu_0/conv3_0_bn_1\" name: \"\" type: \"SpatialBN\" device_option { device_type: 0 cuda_gpu_id: 0 }</p>\n<p>My inference code is here:<br>\n############<br>\n#!/usr/bin/env python2.7<br>\n#-<em>- coding:utf-8 -</em>-</p>\n<p>import io, os<br>\nimport numpy as np<br>\nimport onnx<br>\nimport onnx_caffe2.backend<br>\nfrom onnx_caffe2.backend import Caffe2Backend as c2<br>\nfrom caffe2.python import workspace</p>\n<p>model = onnx.load('model.onnx')<br>\n#model = onnx.load('squeezenet.onnx')<br>\nonnx.checker.check_model(model)<br>\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)<br>\nwith open(\"init_net_org.pb\",\"wb\") as f:<br>\nf.write(init_net.SerializeToString())</p>\n<p>with open(\"predict_net_org.pb\",\"wb\") as f:<br>\nf.write(predict_net.SerializeToString())</p>\n<p>p=workspace.Predictor(init_net, predict_net)<br>\ntry:<br>\nimg = np.random.rand(1, 3, 224, 224).astype(np.float32)<br>\nresult, = p.run([img])<br>\nprint result<br>\nexcept Exception as e:<br>\nprint('Unexpected Error: {}'.format(e))<br>\nfinally:<br>\nprint('')<br>\nprint('Congratulations!')<br>\n###########<br>\nThe code works for squeezeNet from pytorch document.<br>\nLook forward to your reply!</p>", "body_text": "@houseroad Hi\uff5eThanks for your reply! I'v taken your advice to use the onnx model from the model zoo. However,  a new issue comes when I transfer the onnx model to caffe2 model and try to inference. Here's the error log:\nE0801 10:47:45.208793  4411 operator_schema.cc:82] Argument 'is_test' is required for Operator 'SpatialBN'.\nTraceback (most recent call last):\nFile \"main.py\", line 21, in \np=workspace.Predictor(init_net, predict_net)\nFile \"/usr/local/lib/python2.7/dist-packages/caffe2/python/workspace.py\", line 157, in Predictor\nreturn C.Predictor(StringifyProto(init_net), StringifyProto(predict_net))\nRuntimeError: [enforce fail at operator.cc:113] schema->Verify(operator_def). Operator def did not pass schema checking: input: \"gpu_0/conv3_0_1\" input: \"gpu_0/conv3_0_bn_s_0\" input: \"gpu_0/conv3_0_bn_b_0\" input: \"gpu_0/conv3_0_bn_rm_0\" input: \"gpu_0/conv3_0_bn_riv_0\" output: \"gpu_0/conv3_0_bn_1\" name: \"\" type: \"SpatialBN\" device_option { device_type: 0 cuda_gpu_id: 0 }\nMy inference code is here:\n############\n#!/usr/bin/env python2.7\n#-- coding:utf-8 --\nimport io, os\nimport numpy as np\nimport onnx\nimport onnx_caffe2.backend\nfrom onnx_caffe2.backend import Caffe2Backend as c2\nfrom caffe2.python import workspace\nmodel = onnx.load('model.onnx')\n#model = onnx.load('squeezenet.onnx')\nonnx.checker.check_model(model)\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\nwith open(\"init_net_org.pb\",\"wb\") as f:\nf.write(init_net.SerializeToString())\nwith open(\"predict_net_org.pb\",\"wb\") as f:\nf.write(predict_net.SerializeToString())\np=workspace.Predictor(init_net, predict_net)\ntry:\nimg = np.random.rand(1, 3, 224, 224).astype(np.float32)\nresult, = p.run([img])\nprint result\nexcept Exception as e:\nprint('Unexpected Error: {}'.format(e))\nfinally:\nprint('')\nprint('Congratulations!')\n###########\nThe code works for squeezeNet from pytorch document.\nLook forward to your reply!", "body": "@houseroad Hi\uff5eThanks for your reply! I'v taken your advice to use the onnx model from the model zoo. However,  a new issue comes when I transfer the onnx model to caffe2 model and try to inference. Here's the error log:\r\n \r\nE0801 10:47:45.208793  4411 operator_schema.cc:82] Argument 'is_test' is required for Operator 'SpatialBN'.\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 21, in <module>\r\n    p=workspace.Predictor(init_net, predict_net)\r\n  File \"/usr/local/lib/python2.7/dist-packages/caffe2/python/workspace.py\", line 157, in Predictor\r\n    return C.Predictor(StringifyProto(init_net), StringifyProto(predict_net))\r\nRuntimeError: [enforce fail at operator.cc:113] schema->Verify(operator_def). Operator def did not pass schema checking: input: \"gpu_0/conv3_0_1\" input: \"gpu_0/conv3_0_bn_s_0\" input: \"gpu_0/conv3_0_bn_b_0\" input: \"gpu_0/conv3_0_bn_rm_0\" input: \"gpu_0/conv3_0_bn_riv_0\" output: \"gpu_0/conv3_0_bn_1\" name: \"\" type: \"SpatialBN\" device_option { device_type: 0 cuda_gpu_id: 0 } \r\n\r\n\r\n\r\n\r\nMy inference code is here:\r\n############\r\n#!/usr/bin/env python2.7\r\n#-*- coding:utf-8 -*-\r\n\r\nimport io, os\r\nimport numpy as np\r\nimport onnx\r\nimport onnx_caffe2.backend\r\nfrom onnx_caffe2.backend import Caffe2Backend as c2\r\nfrom caffe2.python import workspace\r\n\r\nmodel = onnx.load('model.onnx')\r\n#model = onnx.load('squeezenet.onnx')\r\nonnx.checker.check_model(model)\r\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\r\nwith open(\"init_net_org.pb\",\"wb\") as f:\r\n\tf.write(init_net.SerializeToString())\r\n\r\nwith open(\"predict_net_org.pb\",\"wb\") as f:\r\n\tf.write(predict_net.SerializeToString())\r\n\r\np=workspace.Predictor(init_net, predict_net)\r\ntry:\r\n  img = np.random.rand(1, 3, 224, 224).astype(np.float32)\r\n  result, = p.run([img])\r\n  print result\r\nexcept Exception as e:\r\n        print('Unexpected Error: {}'.format(e))  \r\nfinally:\r\n        print('')\r\n        print('Congratulations!')\r\n###########\r\nThe code works for squeezeNet from pytorch document.\r\nLook forward to your reply!"}