{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181546818", "pull_request_review_id": 112202173, "id": 181546818, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTU0NjgxOA==", "diff_hunk": "@@ -138,178 +132,79 @@ def _number_format(tensor, min_sz=-1):\n     return format, scale, sz\n \n \n-def _tensor_str(self):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size()[-1] > 2 * n\n-    has_vdots = self.size()[-2] > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n-    formatter = _number_format(self, min_sz=3 if not print_full_mat else 0)\n-    print_dots = self.numel() >= PRINT_OPTS.threshold\n-\n-    dim_sz = max(2, max(len(str(x)) for x in self.size()))\n-    dim_fmt = \"{:^\" + str(dim_sz) + \"}\"\n-    dot_fmt = u\"{:^\" + str(dim_sz + 1) + \"}\"\n-\n-    counter_dim = self.ndimension() - 2\n-    counter = torch.LongStorage(counter_dim).fill_(0)\n-    counter[counter.size() - 1] = -1\n-    finished = False\n-    strt = ''\n-    while True:\n-        nrestarted = [False for i in counter]\n-        nskipped = [False for i in counter]\n-        for i in range(counter_dim - 1, -1, -1):\n-            counter[i] += 1\n-            if print_dots and counter[i] == n and self.size(i) > 2 * n:\n-                counter[i] = self.size(i) - n\n-                nskipped[i] = True\n-            if counter[i] == self.size(i):\n-                if i == 0:\n-                    finished = True\n-                counter[i] = 0\n-                nrestarted[i] = True\n-            else:\n-                break\n-        if finished:\n-            break\n-        elif print_dots:\n-            if any(nskipped):\n-                for hdot in nskipped:\n-                    strt += dot_fmt.format('...') if hdot \\\n-                        else dot_fmt.format('')\n-                strt += '\\n'\n-            if any(nrestarted):\n-                strt += ' '\n-                for vdot in nrestarted:\n-                    strt += dot_fmt.format(u'\\u22EE' if vdot else '')\n-                strt += '\\n'\n-        if strt != '':\n-            strt += '\\n'\n-        strt += '({},.,.) = \\n'.format(\n-            ','.join(dim_fmt.format(i) for i in counter))\n-        submatrix = reduce(lambda t, i: t.select(0, i), counter, self)\n-        strt += _matrix_str(submatrix, ' ', formatter, print_dots)\n-    return strt\n-\n-\n-def __repr_row(row, indent, fmt, scale, sz, truncate=None):\n-    if truncate is not None:\n-        dotfmt = \" {:^5} \"\n-        return (indent +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[:truncate]) +\n-                dotfmt.format('...') +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[-truncate:]) +\n-                '\\n')\n-    else:\n-        return indent + ' '.join(fmt.format(val.item() / scale) for val in row) + '\\n'\n+def _scalar_str(self, fmt, scale):\n+    scalar_str = fmt.format(self.item() / scale)\n+    # The leading space for positives is ugly on scalars, so we strip it\n+    return scalar_str.lstrip()\n \n \n-def _matrix_str(self, indent='', formatter=None, force_truncate=False):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size(1) > 2 * n\n-    has_vdots = self.size(0) > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n+def _vector_str(self, indent, fmt, scale, sz, summarize):\n+    element_length = sz + 2\n+    elements_per_line = int(math.floor((PRINT_OPTS.linewidth - indent) / (element_length)))\n+    char_per_line = element_length * elements_per_line\n \n-    if formatter is None:\n-        fmt, scale, sz = _number_format(self,\n-                                        min_sz=5 if not print_full_mat else 0)\n+    if summarize and self.size(0) > 2 * PRINT_OPTS.edgeitems:\n+        data = ([fmt.format(val.item() / scale) for val in self[:PRINT_OPTS.edgeitems]] +", "path": "torch/_tensor_str.py", "position": 110, "original_position": 110, "commit_id": "5d948cf80f4d5c56e19bb555f3b83a2cc6d76718", "original_commit_id": "a667f8dd3e94999ecc784e2c9caa761de6e3d310", "user": {"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}, "body": "Okay, I went ahead and added a space, but I won't be able to update the docs with the new spaces until next week.", "created_at": "2018-04-14T09:04:58Z", "updated_at": "2018-11-23T15:42:27Z", "html_url": "https://github.com/pytorch/pytorch/pull/6370#discussion_r181546818", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6370", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181546818"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6370#discussion_r181546818"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6370"}}, "body_html": "<p>Okay, I went ahead and added a space, but I won't be able to update the docs with the new spaces until next week.</p>", "body_text": "Okay, I went ahead and added a space, but I won't be able to update the docs with the new spaces until next week.", "in_reply_to_id": 181529228}