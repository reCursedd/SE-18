{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181219684", "pull_request_review_id": 111791132, "id": 181219684, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTIxOTY4NA==", "diff_hunk": "@@ -138,178 +139,73 @@ def _number_format(tensor, min_sz=-1):\n     return format, scale, sz\n \n \n-def _tensor_str(self):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size()[-1] > 2 * n\n-    has_vdots = self.size()[-2] > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n-    formatter = _number_format(self, min_sz=3 if not print_full_mat else 0)\n-    print_dots = self.numel() >= PRINT_OPTS.threshold\n-\n-    dim_sz = max(2, max(len(str(x)) for x in self.size()))\n-    dim_fmt = \"{:^\" + str(dim_sz) + \"}\"\n-    dot_fmt = u\"{:^\" + str(dim_sz + 1) + \"}\"\n-\n-    counter_dim = self.ndimension() - 2\n-    counter = torch.LongStorage(counter_dim).fill_(0)\n-    counter[counter.size() - 1] = -1\n-    finished = False\n-    strt = ''\n-    while True:\n-        nrestarted = [False for i in counter]\n-        nskipped = [False for i in counter]\n-        for i in range(counter_dim - 1, -1, -1):\n-            counter[i] += 1\n-            if print_dots and counter[i] == n and self.size(i) > 2 * n:\n-                counter[i] = self.size(i) - n\n-                nskipped[i] = True\n-            if counter[i] == self.size(i):\n-                if i == 0:\n-                    finished = True\n-                counter[i] = 0\n-                nrestarted[i] = True\n-            else:\n-                break\n-        if finished:\n-            break\n-        elif print_dots:\n-            if any(nskipped):\n-                for hdot in nskipped:\n-                    strt += dot_fmt.format('...') if hdot \\\n-                        else dot_fmt.format('')\n-                strt += '\\n'\n-            if any(nrestarted):\n-                strt += ' '\n-                for vdot in nrestarted:\n-                    strt += dot_fmt.format(u'\\u22EE' if vdot else '')\n-                strt += '\\n'\n-        if strt != '':\n-            strt += '\\n'\n-        strt += '({},.,.) = \\n'.format(\n-            ','.join(dim_fmt.format(i) for i in counter))\n-        submatrix = reduce(lambda t, i: t.select(0, i), counter, self)\n-        strt += _matrix_str(submatrix, ' ', formatter, print_dots)\n-    return strt\n-\n-\n-def __repr_row(row, indent, fmt, scale, sz, truncate=None):\n-    if truncate is not None:\n-        dotfmt = \" {:^5} \"\n-        return (indent +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[:truncate]) +\n-                dotfmt.format('...') +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[-truncate:]) +\n-                '\\n')\n-    else:\n-        return indent + ' '.join(fmt.format(val.item() / scale) for val in row) + '\\n'\n+def _scalar_str(self, fmt, scale):\n+    scalar_str = fmt.format(self.item() / scale)\n+    # The leading space for positives is ugly on scalars, so we strip it\n+    if scalar_str[0] == ' ':\n+        return scalar_str[1:]\n+    return scalar_str\n \n \n-def _matrix_str(self, indent='', formatter=None, force_truncate=False):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size(1) > 2 * n\n-    has_vdots = self.size(0) > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n+def _vector_str(self, indent, fmt, scale, sz):\n+    element_length = sz + 2\n+    elements_per_line = int(math.floor((PRINT_OPTS.linewidth - indent) / (element_length)))\n+    char_per_line = element_length * elements_per_line\n \n-    if formatter is None:\n-        fmt, scale, sz = _number_format(self,\n-                                        min_sz=5 if not print_full_mat else 0)\n+    if self.size(0) > PRINT_OPTS.threshold:\n+        data = ([fmt.format(val.item() / scale) for val in self[:PRINT_OPTS.edgeitems]] +\n+                [' ...'] +\n+                [fmt.format(val.item() / scale) for val in self[-PRINT_OPTS.edgeitems:]])\n     else:\n-        fmt, scale, sz = formatter\n-    nColumnPerLine = int(math.floor((PRINT_OPTS.linewidth - len(indent)) / (sz + 1)))\n-    strt = ''\n-    firstColumn = 0\n-\n-    if not force_truncate and \\\n-       (self.numel() < PRINT_OPTS.threshold or print_full_mat):\n-        while firstColumn < self.size(1):\n-            lastColumn = min(firstColumn + nColumnPerLine - 1, self.size(1) - 1)\n-            if nColumnPerLine < self.size(1):\n-                strt += '\\n' if firstColumn != 1 else ''\n-                strt += 'Columns {} to {} \\n{}'.format(\n-                    firstColumn, lastColumn, indent)\n-            if scale != 1:\n-                strt += SCALE_FORMAT.format(scale)\n-            for l in range(self.size(0)):\n-                strt += indent + (' ' if scale != 1 else '')\n-                row_slice = self[l, firstColumn:lastColumn + 1]\n-                strt += ' '.join(fmt.format(val.item() / scale) for val in row_slice)\n-                strt += '\\n'\n-            firstColumn = lastColumn + 1\n-    else:\n-        if scale != 1:\n-            strt += SCALE_FORMAT.format(scale)\n-        if has_vdots and has_hdots:\n-            vdotfmt = \"{:^\" + str((sz + 1) * n - 1) + \"}\"\n-            ddotfmt = u\"{:^5}\"\n-            for row in self[:n]:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-            strt += indent + ' '.join([vdotfmt.format('...'),\n-                                       ddotfmt.format(u'\\u22F1'),\n-                                       vdotfmt.format('...')]) + \"\\n\"\n-            for row in self[-n:]:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-        elif not has_vdots and has_hdots:\n-            for row in self:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-        elif has_vdots and not has_hdots:\n-            vdotfmt = u\"{:^\" + \\\n-                str(len(__repr_row(self[0], '', fmt, scale, sz))) + \\\n-                \"}\\n\"\n-            for row in self[:n]:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-            strt += vdotfmt.format(u'\\u22EE')\n-            for row in self[-n:]:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-        else:\n-            for row in self:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-    return strt\n-\n-\n-def _vector_str(self):\n-    fmt, scale, sz = _number_format(self)\n-    strt = ''\n-    ident = ''\n-    n = PRINT_OPTS.edgeitems\n-    dotfmt = u\"{:^\" + str(sz) + \"}\\n\"\n-    if scale != 1:\n-        strt += SCALE_FORMAT.format(scale)\n-        ident = ' '\n-    if self.numel() < PRINT_OPTS.threshold:\n-        return (strt +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self) +\n-                '\\n')\n+        data = [fmt.format(val.item() / scale) for val in self]\n+\n+    data_lines = [data[i:i + elements_per_line] for i in range(0, len(data), elements_per_line)]\n+    lines = [','.join(line) for line in data_lines]\n+    return '[' + (',' + '\\n' + ' ' * (indent + 1)).join(lines) + ']'\n+\n+\n+def _tensor_str(self, indent, fmt, scale, sz):\n+    dim = self.dim()\n+\n+    if dim == 0:\n+        return _scalar_str(self, fmt, scale)\n+    if dim == 1:\n+        return _vector_str(self, indent, fmt, scale, sz)\n+\n+    if self.size(0) > PRINT_OPTS.threshold:\n+        slices = ([_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(0, PRINT_OPTS.edgeitems)] +\n+                  ['...'] +\n+                  [_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(len(self) - PRINT_OPTS.edgeitems,\n+                                                                                   len(self))])\n     else:\n-        return (strt +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self[:n]) +\n-                '\\n' + (ident + dotfmt.format(u\"\\u22EE\")) +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self[-n:]) +\n-                '\\n')\n+        slices = [_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(0, self.size(0))]\n+\n+    tensor_str = (',' + '\\n' * (dim - 1) + ' ' * (indent + 1)).join(slices)\n+    return '[' + tensor_str + ']'\n \n \n-def _str(self, include_footer=True):\n+def _str(self):\n     if self.is_sparse:\n         size_str = str(tuple(self.shape)).replace(' ', '')\n         return '{} of size {} with indices:\\n{}and values:\\n{}'.format(\n             self.type(), size_str, self._indices(), self._values())\n \n-    empty = self.numel() == 0\n-    dim = self.dim()\n+    type_str = 'tensor'\n+    prefix = type_str + '('\n+    indent = len(prefix)\n+\n+    suffix = ')'\n+    if str(self.device.type) != 'cpu':", "path": "torch/_tensor_str.py", "position": null, "original_position": 224, "commit_id": "5d948cf80f4d5c56e19bb555f3b83a2cc6d76718", "original_commit_id": "49911628606a6f55796c9236d4edc233a15a5675", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "Also, the integeral-vs-floating printing is wrong, for example:\r\n```\r\n>>> a=torch.tensor((1., 2, 3))\r\n>>> a\r\ntensor([ 1, 2, 3])\r\n>>> b=torch.tensor([ 1, 2, 3])\r\n>>> a.dtype == b.dtype\r\nFalse\r\n```", "created_at": "2018-04-12T20:57:29Z", "updated_at": "2018-11-23T15:42:21Z", "html_url": "https://github.com/pytorch/pytorch/pull/6370#discussion_r181219684", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6370", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181219684"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6370#discussion_r181219684"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6370"}}, "body_html": "<p>Also, the integeral-vs-floating printing is wrong, for example:</p>\n<pre><code>&gt;&gt;&gt; a=torch.tensor((1., 2, 3))\n&gt;&gt;&gt; a\ntensor([ 1, 2, 3])\n&gt;&gt;&gt; b=torch.tensor([ 1, 2, 3])\n&gt;&gt;&gt; a.dtype == b.dtype\nFalse\n</code></pre>", "body_text": "Also, the integeral-vs-floating printing is wrong, for example:\n>>> a=torch.tensor((1., 2, 3))\n>>> a\ntensor([ 1, 2, 3])\n>>> b=torch.tensor([ 1, 2, 3])\n>>> a.dtype == b.dtype\nFalse", "in_reply_to_id": 181217941}