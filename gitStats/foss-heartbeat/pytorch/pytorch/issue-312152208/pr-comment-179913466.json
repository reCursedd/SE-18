{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179913466", "pull_request_review_id": 110251947, "id": 179913466, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTkxMzQ2Ng==", "diff_hunk": "@@ -138,178 +139,72 @@ def _number_format(tensor, min_sz=-1):\n     return format, scale, sz\n \n \n-def _tensor_str(self):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size()[-1] > 2 * n\n-    has_vdots = self.size()[-2] > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n-    formatter = _number_format(self, min_sz=3 if not print_full_mat else 0)\n-    print_dots = self.numel() >= PRINT_OPTS.threshold\n-\n-    dim_sz = max(2, max(len(str(x)) for x in self.size()))\n-    dim_fmt = \"{:^\" + str(dim_sz) + \"}\"\n-    dot_fmt = u\"{:^\" + str(dim_sz + 1) + \"}\"\n-\n-    counter_dim = self.ndimension() - 2\n-    counter = torch.LongStorage(counter_dim).fill_(0)\n-    counter[counter.size() - 1] = -1\n-    finished = False\n-    strt = ''\n-    while True:\n-        nrestarted = [False for i in counter]\n-        nskipped = [False for i in counter]\n-        for i in range(counter_dim - 1, -1, -1):\n-            counter[i] += 1\n-            if print_dots and counter[i] == n and self.size(i) > 2 * n:\n-                counter[i] = self.size(i) - n\n-                nskipped[i] = True\n-            if counter[i] == self.size(i):\n-                if i == 0:\n-                    finished = True\n-                counter[i] = 0\n-                nrestarted[i] = True\n-            else:\n-                break\n-        if finished:\n-            break\n-        elif print_dots:\n-            if any(nskipped):\n-                for hdot in nskipped:\n-                    strt += dot_fmt.format('...') if hdot \\\n-                        else dot_fmt.format('')\n-                strt += '\\n'\n-            if any(nrestarted):\n-                strt += ' '\n-                for vdot in nrestarted:\n-                    strt += dot_fmt.format(u'\\u22EE' if vdot else '')\n-                strt += '\\n'\n-        if strt != '':\n-            strt += '\\n'\n-        strt += '({},.,.) = \\n'.format(\n-            ','.join(dim_fmt.format(i) for i in counter))\n-        submatrix = reduce(lambda t, i: t.select(0, i), counter, self)\n-        strt += _matrix_str(submatrix, ' ', formatter, print_dots)\n-    return strt\n-\n-\n-def __repr_row(row, indent, fmt, scale, sz, truncate=None):\n-    if truncate is not None:\n-        dotfmt = \" {:^5} \"\n-        return (indent +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[:truncate]) +\n-                dotfmt.format('...') +\n-                ' '.join(fmt.format(val.item() / scale) for val in row[-truncate:]) +\n-                '\\n')\n-    else:\n-        return indent + ' '.join(fmt.format(val.item() / scale) for val in row) + '\\n'\n+def _scalar_str(self):\n+    fmt, _, _ = _number_format(self)\n+    scalar_str = fmt.format(self.item())\n+    # The leading space for positives is ugly on scalars, so we strip it\n+    if scalar_str[0] == ' ':\n+        return scalar_str[1:]\n+    return scalar_str\n \n \n-def _matrix_str(self, indent='', formatter=None, force_truncate=False):\n-    n = PRINT_OPTS.edgeitems\n-    has_hdots = self.size(1) > 2 * n\n-    has_vdots = self.size(0) > 2 * n\n-    print_full_mat = not has_hdots and not has_vdots\n+def _vector_str(self, indent, fmt, scale, sz):\n+    element_length = sz + 2\n+    elements_per_line = int(math.floor((PRINT_OPTS.linewidth - indent) / (element_length)))\n+    char_per_line = element_length * elements_per_line\n \n-    if formatter is None:\n-        fmt, scale, sz = _number_format(self,\n-                                        min_sz=5 if not print_full_mat else 0)\n+    if self.size(0) > PRINT_OPTS.threshold:\n+        data = ([fmt.format(val.item() / scale) for val in self[:PRINT_OPTS.edgeitems]] +\n+                [' ...'] +\n+                [fmt.format(val.item() / scale) for val in self[-PRINT_OPTS.edgeitems:]])\n     else:\n-        fmt, scale, sz = formatter\n-    nColumnPerLine = int(math.floor((PRINT_OPTS.linewidth - len(indent)) / (sz + 1)))\n-    strt = ''\n-    firstColumn = 0\n-\n-    if not force_truncate and \\\n-       (self.numel() < PRINT_OPTS.threshold or print_full_mat):\n-        while firstColumn < self.size(1):\n-            lastColumn = min(firstColumn + nColumnPerLine - 1, self.size(1) - 1)\n-            if nColumnPerLine < self.size(1):\n-                strt += '\\n' if firstColumn != 1 else ''\n-                strt += 'Columns {} to {} \\n{}'.format(\n-                    firstColumn, lastColumn, indent)\n-            if scale != 1:\n-                strt += SCALE_FORMAT.format(scale)\n-            for l in range(self.size(0)):\n-                strt += indent + (' ' if scale != 1 else '')\n-                row_slice = self[l, firstColumn:lastColumn + 1]\n-                strt += ' '.join(fmt.format(val.item() / scale) for val in row_slice)\n-                strt += '\\n'\n-            firstColumn = lastColumn + 1\n-    else:\n-        if scale != 1:\n-            strt += SCALE_FORMAT.format(scale)\n-        if has_vdots and has_hdots:\n-            vdotfmt = \"{:^\" + str((sz + 1) * n - 1) + \"}\"\n-            ddotfmt = u\"{:^5}\"\n-            for row in self[:n]:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-            strt += indent + ' '.join([vdotfmt.format('...'),\n-                                       ddotfmt.format(u'\\u22F1'),\n-                                       vdotfmt.format('...')]) + \"\\n\"\n-            for row in self[-n:]:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-        elif not has_vdots and has_hdots:\n-            for row in self:\n-                strt += __repr_row(row, indent, fmt, scale, sz, n)\n-        elif has_vdots and not has_hdots:\n-            vdotfmt = u\"{:^\" + \\\n-                str(len(__repr_row(self[0], '', fmt, scale, sz))) + \\\n-                \"}\\n\"\n-            for row in self[:n]:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-            strt += vdotfmt.format(u'\\u22EE')\n-            for row in self[-n:]:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-        else:\n-            for row in self:\n-                strt += __repr_row(row, indent, fmt, scale, sz)\n-    return strt\n-\n-\n-def _vector_str(self):\n-    fmt, scale, sz = _number_format(self)\n-    strt = ''\n-    ident = ''\n-    n = PRINT_OPTS.edgeitems\n-    dotfmt = u\"{:^\" + str(sz) + \"}\\n\"\n-    if scale != 1:\n-        strt += SCALE_FORMAT.format(scale)\n-        ident = ' '\n-    if self.numel() < PRINT_OPTS.threshold:\n-        return (strt +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self) +\n-                '\\n')\n+        data = [fmt.format(val.item() / scale) for val in self]\n+\n+    data_lines = [data[i:i + elements_per_line] for i in range(0, len(data), elements_per_line)]\n+    lines = [','.join(line) for line in data_lines]\n+    return '[' + (',' + '\\n' + ' ' * (indent + 1)).join(lines) + ']'\n+\n+\n+def _tensor_str(self, indent, fmt, scale, sz):\n+    dim = self.dim()\n+\n+    if dim == 0:\n+        return _scalar_str(self)\n+    if dim == 1:\n+        return _vector_str(self, indent, fmt, scale, sz)\n+\n+    if self.size(0) > PRINT_OPTS.threshold:\n+        slices = ([_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(0, PRINT_OPTS.edgeitems)] +\n+                  ['...'] +\n+                  [_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(len(self) - PRINT_OPTS.edgeitems,\n+                                                                                   len(self))])\n     else:\n-        return (strt +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self[:n]) +\n-                '\\n' + (ident + dotfmt.format(u\"\\u22EE\")) +\n-                '\\n'.join(ident + fmt.format(val.item() / scale) for val in self[-n:]) +\n-                '\\n')\n+        slices = [_tensor_str(self[i], indent + 1, fmt, scale, sz) for i in range(0, self.size(0))]\n+\n+    tensor_str = (',' + '\\n' * (dim - 1) + ' ' * (indent + 1)).join(slices)\n+    return '[' + tensor_str + ']'\n \n \n-def _str(self, include_footer=True):\n+def _str(self):\n     if self.is_sparse:\n         size_str = str(tuple(self.shape)).replace(' ', '')\n         return '{} of size {} with indices:\\n{}and values:\\n{}'.format(\n             self.type(), size_str, self._indices(), self._values())\n \n-    empty = self.numel() == 0\n-    dim = self.dim()\n+    type_str = 'tensor'\n+    prefix = type_str + '('\n+    indent = len(prefix)\n+    if str(self.dtype) not in IMPLICIT_DTYPES:\n+        suffix = ', dtype=' + str(self.dtype) + ')'", "path": "torch/_tensor_str.py", "position": null, "original_position": 224, "commit_id": "5d948cf80f4d5c56e19bb555f3b83a2cc6d76718", "original_commit_id": "40c8a1c127f21c1b6cf75a30131acd1c11fb458a", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "A drawback of adding the shape representation in that case is that our `repr` doesn't match the constructor anymore.\r\nBut the same happens in numpy:\r\n```python\r\nprint(np.zeros((0, 4)))\r\n# returns\r\n# array([], shape=(4, 0), dtype=float64)\r\n\r\nnp.array([], shape=(4, 0), dtype=np.float64)\r\n# raises\r\n# 'shape' is an invalid keyword argument for this function\r\n```", "created_at": "2018-04-07T10:08:53Z", "updated_at": "2018-11-23T15:41:59Z", "html_url": "https://github.com/pytorch/pytorch/pull/6370#discussion_r179913466", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6370", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179913466"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6370#discussion_r179913466"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6370"}}, "body_html": "<p>A drawback of adding the shape representation in that case is that our <code>repr</code> doesn't match the constructor anymore.<br>\nBut the same happens in numpy:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">print</span>(np.zeros((<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">4</span>)))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> returns</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> array([], shape=(4, 0), dtype=float64)</span>\n\nnp.array([], <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">0</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float64)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> raises</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 'shape' is an invalid keyword argument for this function</span></pre></div>", "body_text": "A drawback of adding the shape representation in that case is that our repr doesn't match the constructor anymore.\nBut the same happens in numpy:\nprint(np.zeros((0, 4)))\n# returns\n# array([], shape=(4, 0), dtype=float64)\n\nnp.array([], shape=(4, 0), dtype=np.float64)\n# raises\n# 'shape' is an invalid keyword argument for this function", "in_reply_to_id": 179910795}