{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/321582383", "html_url": "https://github.com/pytorch/pytorch/pull/2364#issuecomment-321582383", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2364", "id": 321582383, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTU4MjM4Mw==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-10T15:16:07Z", "updated_at": "2017-08-10T15:16:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4529377\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/killeent\">@killeent</a> There's a few cases, I'll just pick a representative one of an out-of-place 2 tensor operation with matching types (i.e. x + y) and pointwise fallback (i.e. 1-d view semantics).  Also I'm only showing the pre function call code for simplicity.</p>\n<p>Previously:</p>\n<pre><code>THTensorPtr arg_self_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\nTHTensorPtr arg_other_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\n\nbool expand_success = false;\ntry {\n   expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\n         arg_self, arg_other,...)\n   expand_success = true;\n}\ncatch (std::exception &amp;e) {}\nif(expand_success) {\n  arg_self = arg_self_guard.get();\n  arg_other = arg_other_guard.get();\n}\n// call THTensor_(add) as usual...\n</code></pre>\n<p>Now:</p>\n<pre><code>THTensorPtr arg_self_guard(nullptr);\nTHTensorPtr arg_other_guard(nullptr);\n\nbool try_expand = !THSize_isSameSizeAs(arg_self-&gt;size, arg_self-&gt;nDimension,\n     arg_other-&gt;size, arg_other-&gt;nDimension);\nif (try_expand) {\n  bool expand_success = false;\n  try {\n    arg_self_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\n    arg_other_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\n\n     expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\n         arg_self, arg_other,...)\n     expand_success = true;\n  }\n  catch (std::exception &amp;e) {}\n   if(expand_success) {\n     arg_self = arg_self_guard.get();\n     arg_other = arg_other_guard.get();\n   }\n}\n// call THTensor_(add) as usual...\n</code></pre>\n<p>So previously we were always creating new tensors and expanding them to the correct size, now we are only doing that if the sizes don't match (there are further optimizations one could make e.g. if self's expanded size is the same as the other's size, we could not expand other's).</p>", "body_text": "@killeent There's a few cases, I'll just pick a representative one of an out-of-place 2 tensor operation with matching types (i.e. x + y) and pointwise fallback (i.e. 1-d view semantics).  Also I'm only showing the pre function call code for simplicity.\nPreviously:\nTHTensorPtr arg_self_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\nTHTensorPtr arg_other_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\n\nbool expand_success = false;\ntry {\n   expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\n         arg_self, arg_other,...)\n   expand_success = true;\n}\ncatch (std::exception &e) {}\nif(expand_success) {\n  arg_self = arg_self_guard.get();\n  arg_other = arg_other_guard.get();\n}\n// call THTensor_(add) as usual...\n\nNow:\nTHTensorPtr arg_self_guard(nullptr);\nTHTensorPtr arg_other_guard(nullptr);\n\nbool try_expand = !THSize_isSameSizeAs(arg_self->size, arg_self->nDimension,\n     arg_other->size, arg_other->nDimension);\nif (try_expand) {\n  bool expand_success = false;\n  try {\n    arg_self_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\n    arg_other_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\n\n     expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\n         arg_self, arg_other,...)\n     expand_success = true;\n  }\n  catch (std::exception &e) {}\n   if(expand_success) {\n     arg_self = arg_self_guard.get();\n     arg_other = arg_other_guard.get();\n   }\n}\n// call THTensor_(add) as usual...\n\nSo previously we were always creating new tensors and expanding them to the correct size, now we are only doing that if the sizes don't match (there are further optimizations one could make e.g. if self's expanded size is the same as the other's size, we could not expand other's).", "body": "@killeent There's a few cases, I'll just pick a representative one of an out-of-place 2 tensor operation with matching types (i.e. x + y) and pointwise fallback (i.e. 1-d view semantics).  Also I'm only showing the pre function call code for simplicity.\r\n\r\nPreviously:\r\n```\r\nTHTensorPtr arg_self_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\r\nTHTensorPtr arg_other_guard(THTensor_(new)(LIBRARY_STATE_NOARGS));\r\n\r\nbool expand_success = false;\r\ntry {\r\n   expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\r\n         arg_self, arg_other,...)\r\n   expand_success = true;\r\n}\r\ncatch (std::exception &e) {}\r\nif(expand_success) {\r\n  arg_self = arg_self_guard.get();\r\n  arg_other = arg_other_guard.get();\r\n}\r\n// call THTensor_(add) as usual...\r\n```\r\n\r\nNow:\r\n```\r\nTHTensorPtr arg_self_guard(nullptr);\r\nTHTensorPtr arg_other_guard(nullptr);\r\n\r\nbool try_expand = !THSize_isSameSizeAs(arg_self->size, arg_self->nDimension,\r\n     arg_other->size, arg_other->nDimension);\r\nif (try_expand) {\r\n  bool expand_success = false;\r\n  try {\r\n    arg_self_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\r\n    arg_other_guard = THTensor_(new)(LIBRARY_STATE_NOARGS);\r\n\r\n     expand_outplace2(LIBRARY_STATE arg_self_guard.get(), arg_other_guard.get(),\r\n         arg_self, arg_other,...)\r\n     expand_success = true;\r\n  }\r\n  catch (std::exception &e) {}\r\n   if(expand_success) {\r\n     arg_self = arg_self_guard.get();\r\n     arg_other = arg_other_guard.get();\r\n   }\r\n}\r\n// call THTensor_(add) as usual...\r\n```\r\n\r\nSo previously we were always creating new tensors and expanding them to the correct size, now we are only doing that if the sizes don't match (there are further optimizations one could make e.g. if self's expanded size is the same as the other's size, we could not expand other's)."}