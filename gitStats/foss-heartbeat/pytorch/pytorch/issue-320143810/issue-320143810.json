{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7274", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7274/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7274/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7274/events", "html_url": "https://github.com/pytorch/pytorch/issues/7274", "id": 320143810, "node_id": "MDU6SXNzdWUzMjAxNDM4MTA=", "number": 7274, "title": "[feature request] make DataParallel and DistributedDataParallel's module as public", "user": {"login": "acgtyrant", "id": 3921062, "node_id": "MDQ6VXNlcjM5MjEwNjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3921062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acgtyrant", "html_url": "https://github.com/acgtyrant", "followers_url": "https://api.github.com/users/acgtyrant/followers", "following_url": "https://api.github.com/users/acgtyrant/following{/other_user}", "gists_url": "https://api.github.com/users/acgtyrant/gists{/gist_id}", "starred_url": "https://api.github.com/users/acgtyrant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acgtyrant/subscriptions", "organizations_url": "https://api.github.com/users/acgtyrant/orgs", "repos_url": "https://api.github.com/users/acgtyrant/repos", "events_url": "https://api.github.com/users/acgtyrant/events{/privacy}", "received_events_url": "https://api.github.com/users/acgtyrant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-04T03:25:15Z", "updated_at": "2018-05-10T03:02:50Z", "closed_at": "2018-05-09T08:30:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>After training the DataParallel or DistributedDataParallel's model, we may resume the trained model, however <a href=\"https://github.com/pytorch/examples/blob/83f1b5c2667c820b672852d8a5b6971835e6406f/imagenet/main.py#L104\">resume the parallel model while not unpack it</a> is not a good idea while DataParallel and DistributedDataParallel are just used to accelerate training via parallel. So we would like to unpack them first and save the raw model sometimes.</p>\n<p>However, although the <code>module</code> is public in the source code, this is not explicit in the doc. If we only reference the explicit and public code, we have to unpack the model like <code>a = list(b.modules())[0]</code> while <code>b</code> is the paralleled model, it is ugly. So I advice that make DataParallel and DistributedDataParallel's module as public so that we can unpack it comfortably.</p>", "body_text": "After training the DataParallel or DistributedDataParallel's model, we may resume the trained model, however resume the parallel model while not unpack it is not a good idea while DataParallel and DistributedDataParallel are just used to accelerate training via parallel. So we would like to unpack them first and save the raw model sometimes.\nHowever, although the module is public in the source code, this is not explicit in the doc. If we only reference the explicit and public code, we have to unpack the model like a = list(b.modules())[0] while b is the paralleled model, it is ugly. So I advice that make DataParallel and DistributedDataParallel's module as public so that we can unpack it comfortably.", "body": "After training the DataParallel or DistributedDataParallel's model, we may resume the trained model, however [resume the parallel model while not unpack it](https://github.com/pytorch/examples/blob/83f1b5c2667c820b672852d8a5b6971835e6406f/imagenet/main.py#L104) is not a good idea while DataParallel and DistributedDataParallel are just used to accelerate training via parallel. So we would like to unpack them first and save the raw model sometimes.\r\n\r\nHowever, although the `module` is public in the source code, this is not explicit in the doc. If we only reference the explicit and public code, we have to unpack the model like `a = list(b.modules())[0]` while `b` is the paralleled model, it is ugly. So I advice that make DataParallel and DistributedDataParallel's module as public so that we can unpack it comfortably."}