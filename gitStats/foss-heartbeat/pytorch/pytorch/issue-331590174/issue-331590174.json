{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8376", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8376/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8376/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8376/events", "html_url": "https://github.com/pytorch/pytorch/issues/8376", "id": 331590174, "node_id": "MDU6SXNzdWUzMzE1OTAxNzQ=", "number": 8376, "title": "Something wrong with torch 0.4.0 in C3D?", "user": {"login": "bb12346", "id": 40205293, "node_id": "MDQ6VXNlcjQwMjA1Mjkz", "avatar_url": "https://avatars3.githubusercontent.com/u/40205293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bb12346", "html_url": "https://github.com/bb12346", "followers_url": "https://api.github.com/users/bb12346/followers", "following_url": "https://api.github.com/users/bb12346/following{/other_user}", "gists_url": "https://api.github.com/users/bb12346/gists{/gist_id}", "starred_url": "https://api.github.com/users/bb12346/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bb12346/subscriptions", "organizations_url": "https://api.github.com/users/bb12346/orgs", "repos_url": "https://api.github.com/users/bb12346/repos", "events_url": "https://api.github.com/users/bb12346/events{/privacy}", "received_events_url": "https://api.github.com/users/bb12346/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-06-12T13:34:41Z", "updated_at": "2018-06-12T17:02:16Z", "closed_at": "2018-06-12T17:02:15Z", "author_association": "NONE", "body_html": "<p>I built a C3D network.<br>\n<strong>self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))</strong><br>\nself.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))<br>\nself.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))<br>\nself.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))<br>\n...............<br>\nWhen I enter the color picture sequence can be normal stitching.<br>\nclip = np.array([resize(io.imread(frame), output_shape=(112, 200), preserve_range=True) for frame in clip])<br>\n<strong>clip = clip[:, :, 44:44+112, :]</strong><br>\nBut when I enter a grayscale image sequence\uff0ccan cause<br>\nIndexError: too many indices for array<br>\nso I change  it<br>\n<strong>clip = clip[:, :, 44:44+112]</strong><br>\nso that can stitching.</p>\n<p>Meanwhile I change network<br>\n<strong>self.conv1 = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))</strong><br>\nBut still making mistakes<br>\nexpected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[1, 1, 1]<br>\nShould I expand the channel and if so, how do I do it?</p>", "body_text": "I built a C3D network.\nself.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\nself.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\nself.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\nself.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n...............\nWhen I enter the color picture sequence can be normal stitching.\nclip = np.array([resize(io.imread(frame), output_shape=(112, 200), preserve_range=True) for frame in clip])\nclip = clip[:, :, 44:44+112, :]\nBut when I enter a grayscale image sequence\uff0ccan cause\nIndexError: too many indices for array\nso I change  it\nclip = clip[:, :, 44:44+112]\nso that can stitching.\nMeanwhile I change network\nself.conv1 = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\nBut still making mistakes\nexpected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[1, 1, 1]\nShould I expand the channel and if so, how do I do it?", "body": "I built a C3D network.\r\n        **self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))**\r\n        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\r\n        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\r\n        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\r\n        ...............\r\nWhen I enter the color picture sequence can be normal stitching.\r\nclip = np.array([resize(io.imread(frame), output_shape=(112, 200), preserve_range=True) for frame in clip])\r\n**clip = clip[:, :, 44:44+112, :]**\r\nBut when I enter a grayscale image sequence\uff0ccan cause\r\nIndexError: too many indices for array\r\nso I change  it\r\n**clip = clip[:, :, 44:44+112]**\r\nso that can stitching.\r\n\r\nMeanwhile I change network \r\n**self.conv1 = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))**\r\nBut still making mistakes\r\nexpected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[1, 1, 1]\r\nShould I expand the channel and if so, how do I do it?\r\n\r\n\r\n        "}