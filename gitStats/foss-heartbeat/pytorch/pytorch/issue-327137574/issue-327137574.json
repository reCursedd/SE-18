{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7903", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7903/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7903/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7903/events", "html_url": "https://github.com/pytorch/pytorch/issues/7903", "id": 327137574, "node_id": "MDU6SXNzdWUzMjcxMzc1NzQ=", "number": 7903, "title": "Serious perf drop on CPU ", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2018-05-29T00:29:33Z", "updated_at": "2018-07-02T22:32:55Z", "closed_at": "2018-07-02T22:32:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have tracked performance of <a href=\"https://github.com/MlWoo/PyTorch-benchmark/tree/master/rnn_benchmark\">our rnn benchmark</a> of PyTorch on CPU. Here are some critical logs. The first column is the commit id of PyTorch. The second one is  the perf(sentence per second) of my benchmark, the larger the number is, the better perf PyTorch achieves.</p>\n<pre><code>197412fa8f2d3c280afa06a07e2025e77a8efc54  442.7792\n619a56bf21897fca2ed794cf1d9e596ebbc6361f  447.3579\n88a705555ae88d2f3302b6227010b82a857b8eb1  433.6706\n4d2693973e638d5b8a8fe4e11bb4da85d1698596  1015.3741\n19040583702377c6f5f60e88477424a113a27565  1009.2084\ne6330559c8769d4f9bfe4e1a11301a8cbfd63081  1024.4980\n</code></pre>\n<p>It is very clear that the commit <code>88a705555ae88d2f3302b6227010b82a857b8eb1</code> results in serious perf drop on CPU.  But I did not find any coding problems of the commit.<br>\nHowever, profiling results of Vtune shows<code> tbb</code> works in the comimit but does not do that in previous commit. I suspect that the introduction of <code>tbb</code> may cause that serious perf drop although I am not an expert on parallel solutions. Because I have heared that <a href=\"https://software.intel.com/en-us/forums/intel-threading-building-blocks/topic/281761\" rel=\"nofollow\">openmp could not cooperates very well with other parallel solution</a>. Different parallel solutions may race the computation resource because they has their own mechanism of resource management.<br>\nSimilar perf problems also occurs in CNN benchmark.</p>\n<p>Maybe some more infos listed below is useful.<br>\nPlatform:</p>\n<table>\n<thead>\n<tr>\n<th>CPU Model</th>\n<th>Sockets</th>\n<th>Cores/Socket</th>\n<th>Frequency</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Intel(R) Core(TM) i7-5960X CPU</td>\n<td>1</td>\n<td>8</td>\n<td>3.00GHz</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th>OMP_NUM_THREADS</th>\n<th>Perf(SPS)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>4</td>\n<td>557</td>\n</tr>\n<tr>\n<td>6</td>\n<td>685</td>\n</tr>\n<tr>\n<td>8</td>\n<td>433</td>\n</tr>\n</tbody>\n</table>\n<p>I think the abnorm phenomenon could reflect the results of resource race. When threads of openmp is set to cores of platform, contrary the perf would be worse.<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a> Do you have some suggestion for us?</p>", "body_text": "I have tracked performance of our rnn benchmark of PyTorch on CPU. Here are some critical logs. The first column is the commit id of PyTorch. The second one is  the perf(sentence per second) of my benchmark, the larger the number is, the better perf PyTorch achieves.\n197412fa8f2d3c280afa06a07e2025e77a8efc54  442.7792\n619a56bf21897fca2ed794cf1d9e596ebbc6361f  447.3579\n88a705555ae88d2f3302b6227010b82a857b8eb1  433.6706\n4d2693973e638d5b8a8fe4e11bb4da85d1698596  1015.3741\n19040583702377c6f5f60e88477424a113a27565  1009.2084\ne6330559c8769d4f9bfe4e1a11301a8cbfd63081  1024.4980\n\nIt is very clear that the commit 88a705555ae88d2f3302b6227010b82a857b8eb1 results in serious perf drop on CPU.  But I did not find any coding problems of the commit.\nHowever, profiling results of Vtune shows tbb works in the comimit but does not do that in previous commit. I suspect that the introduction of tbb may cause that serious perf drop although I am not an expert on parallel solutions. Because I have heared that openmp could not cooperates very well with other parallel solution. Different parallel solutions may race the computation resource because they has their own mechanism of resource management.\nSimilar perf problems also occurs in CNN benchmark.\nMaybe some more infos listed below is useful.\nPlatform:\n\n\n\nCPU Model\nSockets\nCores/Socket\nFrequency\n\n\n\n\nIntel(R) Core(TM) i7-5960X CPU\n1\n8\n3.00GHz\n\n\n\n\n\n\nOMP_NUM_THREADS\nPerf(SPS)\n\n\n\n\n4\n557\n\n\n6\n685\n\n\n8\n433\n\n\n\nI think the abnorm phenomenon could reflect the results of resource race. When threads of openmp is set to cores of platform, contrary the perf would be worse.\n@cpuhrsch Do you have some suggestion for us?", "body": "I have tracked performance of [our rnn benchmark](https://github.com/MlWoo/PyTorch-benchmark/tree/master/rnn_benchmark) of PyTorch on CPU. Here are some critical logs. The first column is the commit id of PyTorch. The second one is  the perf(sentence per second) of my benchmark, the larger the number is, the better perf PyTorch achieves.\r\n```\r\n197412fa8f2d3c280afa06a07e2025e77a8efc54  442.7792\r\n619a56bf21897fca2ed794cf1d9e596ebbc6361f  447.3579\r\n88a705555ae88d2f3302b6227010b82a857b8eb1  433.6706\r\n4d2693973e638d5b8a8fe4e11bb4da85d1698596  1015.3741\r\n19040583702377c6f5f60e88477424a113a27565  1009.2084\r\ne6330559c8769d4f9bfe4e1a11301a8cbfd63081  1024.4980\r\n```\r\nIt is very clear that the commit `88a705555ae88d2f3302b6227010b82a857b8eb1` results in serious perf drop on CPU.  But I did not find any coding problems of the commit.   \r\nHowever, profiling results of Vtune shows` tbb` works in the comimit but does not do that in previous commit. I suspect that the introduction of `tbb` may cause that serious perf drop although I am not an expert on parallel solutions. Because I have heared that [openmp could not cooperates very well with other parallel solution](https://software.intel.com/en-us/forums/intel-threading-building-blocks/topic/281761 ). Different parallel solutions may race the computation resource because they has their own mechanism of resource management.\r\nSimilar perf problems also occurs in CNN benchmark.\r\n\r\nMaybe some more infos listed below is useful.\r\nPlatform:\r\n\r\n|CPU Model|Sockets|Cores/Socket|Frequency|  \r\n|---|---|---|---|  \r\n|Intel(R) Core(TM) i7-5960X CPU |1|8|3.00GHz|  \r\n\r\n|OMP_NUM_THREADS| Perf(SPS)|\r\n|---|---|\r\n|4|557|\r\n|6|685 |\r\n|8|433|\r\n\r\nI think the abnorm phenomenon could reflect the results of resource race. When threads of openmp is set to cores of platform, contrary the perf would be worse. \r\n@cpuhrsch Do you have some suggestion for us?"}