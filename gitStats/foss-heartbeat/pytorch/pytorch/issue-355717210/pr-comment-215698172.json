{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215698172", "pull_request_review_id": 153020597, "id": 215698172, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNTY5ODE3Mg==", "diff_hunk": "@@ -0,0 +1,217 @@\n+#include \"ATen/ATen.h\"\n+#include <THC/THCTensorMathReduce.cuh>\n+#include <math.h>\n+\n+#include \"ATen/native/Distance.h\"\n+\n+\n+namespace at { namespace native {\n+\n+namespace {\n+\n+static const int warp_size = 32;\n+static const int forward_warps = 8;\n+\n+template <typename scalar_t>\n+static __forceinline__ __device__ scalar_t device_sqrt(scalar_t val);\n+\n+template <>\n+__forceinline__ __device__ float device_sqrt(float val) {\n+  return ::sqrtf(val);\n+}\n+\n+template <>\n+__forceinline__ __device__ double device_sqrt(double val) {\n+  return ::sqrt(val);\n+}\n+\n+template <typename scalar_t>\n+struct dists {\n+\n+  static __forceinline__ __device__ scalar_t sign(scalar_t val) {\n+    return (0 < val) - (val < 0);\n+  }\n+\n+  // Zero norm\n+  struct zero {\n+    static __forceinline__ __device__ void inc(scalar_t& agg, const scalar_t diff, const scalar_t p) { agg += diff != 0.0; }\n+    static __forceinline__ __device__ scalar_t finish(const scalar_t agg, const scalar_t p) { return agg; }\n+    static __forceinline__ __device__ void agg(scalar_t& update, const scalar_t other) { update += other; }\n+  };\n+\n+  // One norm\n+  struct one {\n+    static __forceinline__ __device__ void inc(scalar_t& agg, const scalar_t diff, const scalar_t p) { agg += diff; }\n+    static __forceinline__ __device__ scalar_t finish(const scalar_t agg, const scalar_t p) { return agg; }\n+    static __forceinline__ __device__ void agg(scalar_t& update, const scalar_t other) { update += other; }\n+    static __forceinline__ __device__ scalar_t backward(const scalar_t diff, const scalar_t grad, const scalar_t dist, const scalar_t p) { return grad * sign(diff); }\n+  };\n+\n+  // Special case backward when p is less than two\n+  struct lt_two {\n+    static __forceinline__ __device__ scalar_t backward(const scalar_t diff, const scalar_t grad, const scalar_t dist, const scalar_t p) { return dist == 0.0 ? 0 : sign(diff) * std::pow(std::abs(diff), p - 1) * grad / std::pow(dist, p - 1); }\n+  };\n+\n+  // Two norm\n+  struct two {\n+    static __forceinline__ __device__ void inc(scalar_t& agg, const scalar_t diff, const scalar_t p) { agg += diff * diff; }\n+    static __forceinline__ __device__ scalar_t finish(const scalar_t agg, const scalar_t p) { return device_sqrt<scalar_t>(agg); }\n+    static __forceinline__ __device__ void agg(scalar_t& update, const scalar_t other) { update += other; }\n+    static __forceinline__ __device__ scalar_t backward(const scalar_t diff, const scalar_t grad, const scalar_t dist, const scalar_t p) { return dist == 0.0 ? 0 : grad * diff / dist; }\n+  };\n+\n+  // General p norm\n+  struct p {\n+    static __forceinline__ __device__ void inc(scalar_t& agg, const scalar_t diff, const scalar_t p) { agg += std::pow(diff, p); }\n+    static __forceinline__ __device__ scalar_t finish(const scalar_t agg, const scalar_t p) { return std::pow(agg, static_cast<scalar_t>(1) / p); }\n+    static __forceinline__ __device__ void agg(scalar_t& update, const scalar_t other) { update += other; }\n+    static __forceinline__ __device__ scalar_t backward(const scalar_t diff, const scalar_t grad, const scalar_t dist, const scalar_t p) { return dist == 0.0 ? 0 : diff * std::pow(std::abs(diff), p - 2) * grad / std::pow(dist, p - 1); }\n+  };\n+\n+  // Inf norm\n+  struct inf {\n+    static __forceinline__ __device__ void inc(scalar_t& agg, const scalar_t diff, const scalar_t p) { if (diff > agg) { agg = diff; } }\n+    static __forceinline__ __device__ scalar_t finish(const scalar_t agg, const scalar_t p) { return agg; }\n+    static __forceinline__ __device__ void agg(scalar_t& update, const scalar_t other) { if (other > update) { update = other; } }\n+    static __forceinline__ __device__ scalar_t backward(const scalar_t diff, const scalar_t grad, const scalar_t dist, const scalar_t p) { return grad * sign(diff) * (std::abs(diff) == dist); }\n+  };\n+\n+};\n+\n+template <typename scalar_t, typename F>\n+__global__ static void pdist_kernel_cuda_impl(scalar_t * result, const scalar_t * self, const int64_t n, const int64_t m, const scalar_t p) {\n+  const int k = blockIdx.x;\n+  const int stride = blockDim.x;\n+\n+  float n2 = n - .5;\n+  // The -1 accounts for floating point truncation issues\n+  int64_t i = static_cast<int64_t>((n2 - device_sqrt<scalar_t>(n2 * n2 - 2 * k - 1)));\n+  int64_t j = k - n * i + i * (i + 1) / 2 + i + 1;\n+\n+  const scalar_t * const start = self + i * m;\n+  const scalar_t * const end = start + m;\n+  const scalar_t * a = start + threadIdx.x;\n+  const scalar_t * b = self + j * m + threadIdx.x;\n+  scalar_t agg = 0.0;\n+  for (; a < end; a += stride, b += stride) {\n+    F::inc(agg, std::abs(*a - *b), p);\n+  }\n+  \n+  // Reduce warps\n+  for (int offset = warp_size / 2; offset > 0; offset /= 2) {\n+    F::agg(agg, WARP_SHFL_DOWN(agg, offset));\n+  }\n+\n+  // Reduce block\n+  __shared__ scalar_t shared[forward_warps];\n+  int lane = threadIdx.x % warp_size;\n+  int warp_id = threadIdx.x / warp_size;\n+  if (lane == 0) {\n+    shared[warp_id] = agg;\n+  }\n+  __syncthreads();\n+  agg = (threadIdx.x < blockDim.x / warp_size) ? shared[lane] : 0.0;\n+  if (warp_id == 0) {\n+    // Only reduce theads with nonzero data\n+    for (int offset = blockDim.x / warp_size / 2; offset > 0; offset /= 2) {\n+      F::agg(agg, WARP_SHFL_DOWN(agg, offset));\n+    }\n+  }\n+  if (threadIdx.x == 0) {\n+    result[k] = F::finish(agg, p);\n+  }\n+}\n+\n+template <typename scalar_t, typename F>\n+__global__ static void pdist_backward_kernel_cuda_impl(scalar_t * buffer, const scalar_t * grad, const scalar_t * self, const scalar_t * dist, int64_t gs, const int64_t n, const int64_t m, const int64_t combs, const scalar_t p) {\n+  const int k = blockIdx.y * blockDim.y + threadIdx.y;\n+  const int init = blockIdx.x * blockDim.x + threadIdx.x;\n+  const int stride = blockDim.x * gridDim.x;\n+\n+  if (k >= combs) {\n+    return;\n+  }\n+\n+  float n2 = n - .5;\n+  // The -1 accounts for floating point truncation issues\n+  int64_t i = static_cast<int64_t>((n2 - device_sqrt<scalar_t>(n2 * n2 - 2 * k - 1)));\n+  int64_t j = k - n * i + i * (i + 1) / 2 + i + 1;\n+  int64_t ib = j - i - 1;\n+  int64_t jb = n - 2 - i;\n+\n+  const scalar_t grad_k = grad[k * gs];\n+  const scalar_t dist_k = dist[k];\n+\n+  const scalar_t * const start = self + i * m;\n+  const scalar_t * const end = start + m;\n+  const scalar_t * self_i = start + init;\n+  const scalar_t * self_j = self + j * m + init;\n+  scalar_t * buff_i = buffer + (ib * n + i) * m + init;\n+  scalar_t * buff_j = buffer + (jb * n + j) * m + init;\n+  for (; self_i < end; self_i += stride, self_j += stride, buff_i += stride, buff_j += stride) {\n+    const scalar_t res = F::backward(*self_i - *self_j, grad_k, dist_k, p);\n+    *buff_i = res;\n+    *buff_j = -res;\n+  }\n+}\n+\n+void pdist_forward_kernel_impl(Tensor& result, const Tensor& self, double p) {\n+  const dim3 blocks(result.numel());\n+  const dim3 per_block(forward_warps * warp_size);\n+  int64_t n = self.size(0);\n+  int64_t m = self.size(1);\n+\n+  AT_DISPATCH_FLOATING_TYPES(self.type(), \"pdist_cuda\", [&] {\n+    if (p == 0.0) {\n+      pdist_kernel_cuda_impl<scalar_t, dists<scalar_t>::zero><<<blocks, per_block>>>(result.data<scalar_t>(), self.data<scalar_t>(), n, m, p);\n+    } else if (p == 1.0) {\n+      pdist_kernel_cuda_impl<scalar_t, dists<scalar_t>::one><<<blocks, per_block>>>(result.data<scalar_t>(), self.data<scalar_t>(), n, m, p);\n+    } else if (p == 2.0) {\n+      pdist_kernel_cuda_impl<scalar_t, dists<scalar_t>::two><<<blocks, per_block>>>(result.data<scalar_t>(), self.data<scalar_t>(), n, m, p);\n+    } else if (std::isinf(p)) {\n+      pdist_kernel_cuda_impl<scalar_t, dists<scalar_t>::inf><<<blocks, per_block>>>(result.data<scalar_t>(), self.data<scalar_t>(), n, m, p);\n+    } else {\n+      pdist_kernel_cuda_impl<scalar_t, dists<scalar_t>::p><<<blocks, per_block>>>(result.data<scalar_t>(), self.data<scalar_t>(), n, m, p);\n+    }\n+  });\n+}\n+\n+void pdist_backward_kernel_impl(Tensor& result, const Tensor& grad, const Tensor& self, const double p, const Tensor& dist) {\n+  if (p == 0.0 || grad.numel() == 0 || self.numel() == 0) {\n+    result.fill_(0);\n+    return;\n+  }\n+\n+  const int64_t n = result.size(0);\n+  int64_t m = self.size(1);\n+  const int horiz_per_block = 2 * warp_size;\n+  const int vert_per_block = 4;\n+  const int horiz_blocks = (m + horiz_per_block * 8 - 1) / (horiz_per_block * 8);\n+  const int vert_blocks = (dist.numel() + vert_per_block - 1) / vert_per_block;\n+  const dim3 blocks(horiz_blocks, vert_blocks);", "path": "aten/src/ATen/native/cuda/DistanceKernel.cu", "position": null, "original_position": 191, "commit_id": "32aafbf523153ab581e6029db69458ef42eee148", "original_commit_id": "27dcdb85fdf5cf2fae9cb3815c2bf997937662bd", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "The predominant convention in PyTorch is to name these `grid` and `block`", "created_at": "2018-09-06T16:45:07Z", "updated_at": "2018-11-23T15:50:40Z", "html_url": "https://github.com/pytorch/pytorch/pull/11102#discussion_r215698172", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11102", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215698172"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11102#discussion_r215698172"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11102"}}, "body_html": "<p>The predominant convention in PyTorch is to name these <code>grid</code> and <code>block</code></p>", "body_text": "The predominant convention in PyTorch is to name these grid and block"}