{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188685376", "pull_request_review_id": 120714221, "id": 188685376, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4ODY4NTM3Ng==", "diff_hunk": "@@ -1,121 +1,113 @@\n #pragma once\n \n-#include <torch/detail.h>\n #include <torch/nn/module.h>\n \n #include <torch/csrc/autograd/variable.h>\n \n #include <ATen/Error.h>\n+#include <ATen/optional.h>\n \n #include <cstdint>\n+#include <functional>\n #include <memory>\n #include <vector>\n \n+namespace torch { namespace nn {\n+class Dropout;\n+}} // namespace torch::nn\n+\n namespace torch { namespace nn {\n template <typename Derived>\n class RNNBase : public CloneableModule<Derived> {\n  public:\n-  // These must line up with the CUDNN mode codes\n-  enum RNNMode { RNN_RELU = 0, RNN_TANH = 1, LSTM = 2, GRU = 3 };\n+  // These must line up with the CUDNN mode codes:\n+  // https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNMode_t\n+  enum class CuDNNMode { RNN_RELU, RNN_TANH, LSTM, GRU };\n \n   RNNBase(\n-      uint32_t input_size,\n-      uint32_t hidden_size,\n-      int mode,\n-      uint32_t nlayers,\n-      bool with_bias,\n-      float dropout);\n-\n-  using CloneableModule<Derived>::parameters;\n-  using CloneableModule<Derived>::is_training;\n+      int64_t input_size,\n+      int64_t hidden_size,\n+      at::optional<CuDNNMode> cudnn_mode = at::nullopt,\n+      size_t number_of_gates = 1,\n+      bool has_cell_state = false);\n \n-  bool flatten_parameters(); // Flatten for cudnn\n+  void reset() override;\n \n   variable_list forward(variable_list) override;\n \n-  void cpu() override;\n-  void cuda() override;\n+  void to(at::Type& type) override;\n+  void to(at::ScalarType scalar_type) override;\n+  void to(at::Backend backend) override;\n \n-  std::vector<Variable> ihw;\n-  std::vector<Variable> ihb;\n-  std::vector<Variable> hhw;\n-  std::vector<Variable> hhb;\n+  TORCH_PARAMETER(int64_t, input_size);\n+  TORCH_PARAMETER(int64_t, hidden_size);\n+  TORCH_PARAMETER(int64_t, layers) = 1;\n+  TORCH_PARAMETER(bool, with_bias) = true;\n+  TORCH_PARAMETER(double, dropout) = 0.0;\n \n- private:\n-  using CloneableModule<Derived>::add;\n-\n-  uint32_t input_size_;\n-  uint32_t hidden_size_;\n-  uint32_t gate_size_;\n-  RNNMode mode_;\n-  uint32_t nlayers_;\n-  bool with_bias_;\n-  float dropout_;\n-\n-  // This is copied from pytorch, to determine whether weights are flat for\n-  // the fast CUDNN route. Otherwise, we have to use non flattened weights,\n-  // which\n+ protected:\n+  virtual variable_list cell_forward(variable_list, size_t layer) = 0;\n+\n+  variable_list CUDNN_forward(variable_list);\n+  variable_list autograd_forward(variable_list);\n+\n+  void flatten_parameters_for_cudnn();", "path": "torch/csrc/api/include/torch/nn/modules/rnn.h", "position": 87, "original_position": 87, "commit_id": "994d74d21af6b1a2712a58c7ca15146c0166f1d3", "original_commit_id": "0028a7088f029ea74c4f8a96426a921bd926ea53", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "Oh sorry, I answered a different question :P I will make this method public again", "created_at": "2018-05-16T16:13:09Z", "updated_at": "2018-11-23T15:44:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/7597#discussion_r188685376", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7597", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188685376"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7597#discussion_r188685376"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7597"}}, "body_html": "<p>Oh sorry, I answered a different question :P I will make this method public again</p>", "body_text": "Oh sorry, I answered a different question :P I will make this method public again", "in_reply_to_id": 188458539}