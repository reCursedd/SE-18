{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188460099", "pull_request_review_id": 120441490, "id": 188460099, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4ODQ2MDA5OQ==", "diff_hunk": "@@ -1,121 +1,113 @@\n #pragma once\n \n-#include <torch/detail.h>\n #include <torch/nn/module.h>\n \n #include <torch/csrc/autograd/variable.h>\n \n #include <ATen/Error.h>\n+#include <ATen/optional.h>\n \n #include <cstdint>\n+#include <functional>\n #include <memory>\n #include <vector>\n \n+namespace torch { namespace nn {\n+class Dropout;\n+}} // namespace torch::nn\n+\n namespace torch { namespace nn {\n template <typename Derived>\n class RNNBase : public CloneableModule<Derived> {\n  public:\n-  // These must line up with the CUDNN mode codes\n-  enum RNNMode { RNN_RELU = 0, RNN_TANH = 1, LSTM = 2, GRU = 3 };\n+  // These must line up with the CUDNN mode codes:\n+  // https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNMode_t\n+  enum class CuDNNMode { RNN_RELU, RNN_TANH, LSTM, GRU };\n \n   RNNBase(\n-      uint32_t input_size,\n-      uint32_t hidden_size,\n-      int mode,\n-      uint32_t nlayers,\n-      bool with_bias,\n-      float dropout);\n-\n-  using CloneableModule<Derived>::parameters;\n-  using CloneableModule<Derived>::is_training;\n+      int64_t input_size,\n+      int64_t hidden_size,\n+      at::optional<CuDNNMode> cudnn_mode = at::nullopt,\n+      size_t number_of_gates = 1,\n+      bool has_cell_state = false);\n \n-  bool flatten_parameters(); // Flatten for cudnn\n+  void reset() override;\n \n   variable_list forward(variable_list) override;\n \n-  void cpu() override;\n-  void cuda() override;\n+  void to(at::Type& type) override;\n+  void to(at::ScalarType scalar_type) override;\n+  void to(at::Backend backend) override;\n \n-  std::vector<Variable> ihw;\n-  std::vector<Variable> ihb;\n-  std::vector<Variable> hhw;\n-  std::vector<Variable> hhb;\n+  TORCH_PARAMETER(int64_t, input_size);\n+  TORCH_PARAMETER(int64_t, hidden_size);\n+  TORCH_PARAMETER(int64_t, layers) = 1;\n+  TORCH_PARAMETER(bool, with_bias) = true;\n+  TORCH_PARAMETER(double, dropout) = 0.0;\n \n- private:\n-  using CloneableModule<Derived>::add;\n-\n-  uint32_t input_size_;\n-  uint32_t hidden_size_;\n-  uint32_t gate_size_;\n-  RNNMode mode_;\n-  uint32_t nlayers_;\n-  bool with_bias_;\n-  float dropout_;\n-\n-  // This is copied from pytorch, to determine whether weights are flat for\n-  // the fast CUDNN route. Otherwise, we have to use non flattened weights,\n-  // which\n+ protected:\n+  virtual variable_list cell_forward(variable_list, size_t layer) = 0;\n+\n+  variable_list CUDNN_forward(variable_list);\n+  variable_list autograd_forward(variable_list);\n+\n+  void flatten_parameters_for_cudnn();\n+  std::vector<Tensor> flat_weights() const;\n+\n+  std::vector<Variable> ihw_;\n+  std::vector<Variable> ihb_;\n+  std::vector<Variable> hhw_;\n+  std::vector<Variable> hhb_;\n+\n+  size_t number_of_gates_;\n+  bool has_cell_state_;", "path": "torch/csrc/api/include/torch/nn/modules/rnn.h", "position": null, "original_position": 96, "commit_id": "994d74d21af6b1a2712a58c7ca15146c0166f1d3", "original_commit_id": "0028a7088f029ea74c4f8a96426a921bd926ea53", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "body": "Not entirely sure whether this is more or less confusing for people to read. What does \"cell_state\" mean? If I don't know what it means, how will I associate it? It's currently only specific to LSTMs, my opinion is that it's less confusing to just name it something like `is_LSTM_`.", "created_at": "2018-05-15T22:53:22Z", "updated_at": "2018-11-23T15:44:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/7597#discussion_r188460099", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7597", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188460099"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7597#discussion_r188460099"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7597"}}, "body_html": "<p>Not entirely sure whether this is more or less confusing for people to read. What does \"cell_state\" mean? If I don't know what it means, how will I associate it? It's currently only specific to LSTMs, my opinion is that it's less confusing to just name it something like <code>is_LSTM_</code>.</p>", "body_text": "Not entirely sure whether this is more or less confusing for people to read. What does \"cell_state\" mean? If I don't know what it means, how will I associate it? It's currently only specific to LSTMs, my opinion is that it's less confusing to just name it something like is_LSTM_."}