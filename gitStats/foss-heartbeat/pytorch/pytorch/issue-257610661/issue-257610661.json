{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2732", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2732/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2732/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2732/events", "html_url": "https://github.com/pytorch/pytorch/issues/2732", "id": 257610661, "node_id": "MDU6SXNzdWUyNTc2MTA2NjE=", "number": 2732, "title": "support grid_sample with batch=1 but supprting batch affine parameters", "user": {"login": "D-X-Y", "id": 9547057, "node_id": "MDQ6VXNlcjk1NDcwNTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/9547057?v=4", "gravatar_id": "", "url": "https://api.github.com/users/D-X-Y", "html_url": "https://github.com/D-X-Y", "followers_url": "https://api.github.com/users/D-X-Y/followers", "following_url": "https://api.github.com/users/D-X-Y/following{/other_user}", "gists_url": "https://api.github.com/users/D-X-Y/gists{/gist_id}", "starred_url": "https://api.github.com/users/D-X-Y/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/D-X-Y/subscriptions", "organizations_url": "https://api.github.com/users/D-X-Y/orgs", "repos_url": "https://api.github.com/users/D-X-Y/repos", "events_url": "https://api.github.com/users/D-X-Y/events{/privacy}", "received_events_url": "https://api.github.com/users/D-X-Y/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-14T06:37:56Z", "updated_at": "2017-09-20T01:00:07Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I'm trying to use the grid_affine with grid_sample to do the ROIAlign operation.<br>\nIn my cases, one feature tensor is accompanied with many boxes, and one box means one affine parameter. Therefore, I use <code>feature.expand(number_of_box, C, H, W)</code> to expand the feature to the same batch as the affine parameter.  In this way, it cost much GPU memory.</p>\n<pre><code>feature = feature.expand(number_of_box,C, H, W)\ngrid_size = torch.Size([number_of_box, 1, 7,7])\ngrid = F.affine_grid(theta, grid_size)\nsub_feature = F.grid_sample(feature, grid)\n</code></pre>\n<p>If I use a loop to do these operations, the memory usage is less than the above one.</p>\n<pre><code>all_roi = []\nfor j in range(number_of_box):\n  _grid = grid.narrow(0, j, 1)\n  _roi_feature = F.grid_sample(feature, _grid)\n  all_roi.append( _roi_feature )\n</code></pre>\n<p>What causes this problem? Is it possible to support affine_sample with batch size = 1, but shared for the batched affine_parameters?</p>", "body_text": "I'm trying to use the grid_affine with grid_sample to do the ROIAlign operation.\nIn my cases, one feature tensor is accompanied with many boxes, and one box means one affine parameter. Therefore, I use feature.expand(number_of_box, C, H, W) to expand the feature to the same batch as the affine parameter.  In this way, it cost much GPU memory.\nfeature = feature.expand(number_of_box,C, H, W)\ngrid_size = torch.Size([number_of_box, 1, 7,7])\ngrid = F.affine_grid(theta, grid_size)\nsub_feature = F.grid_sample(feature, grid)\n\nIf I use a loop to do these operations, the memory usage is less than the above one.\nall_roi = []\nfor j in range(number_of_box):\n  _grid = grid.narrow(0, j, 1)\n  _roi_feature = F.grid_sample(feature, _grid)\n  all_roi.append( _roi_feature )\n\nWhat causes this problem? Is it possible to support affine_sample with batch size = 1, but shared for the batched affine_parameters?", "body": "I'm trying to use the grid_affine with grid_sample to do the ROIAlign operation.\r\nIn my cases, one feature tensor is accompanied with many boxes, and one box means one affine parameter. Therefore, I use `feature.expand(number_of_box, C, H, W)` to expand the feature to the same batch as the affine parameter.  In this way, it cost much GPU memory.\r\n```\r\nfeature = feature.expand(number_of_box,C, H, W)\r\ngrid_size = torch.Size([number_of_box, 1, 7,7])\r\ngrid = F.affine_grid(theta, grid_size)\r\nsub_feature = F.grid_sample(feature, grid)\r\n```\r\nIf I use a loop to do these operations, the memory usage is less than the above one.\r\n```\r\nall_roi = []\r\nfor j in range(number_of_box):\r\n  _grid = grid.narrow(0, j, 1)\r\n  _roi_feature = F.grid_sample(feature, _grid)\r\n  all_roi.append( _roi_feature )\r\n```\r\nWhat causes this problem? Is it possible to support affine_sample with batch size = 1, but shared for the batched affine_parameters?"}