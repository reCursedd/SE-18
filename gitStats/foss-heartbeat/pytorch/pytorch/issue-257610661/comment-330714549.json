{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/330714549", "html_url": "https://github.com/pytorch/pytorch/issues/2732#issuecomment-330714549", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2732", "id": 330714549, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDcxNDU0OQ==", "user": {"login": "D-X-Y", "id": 9547057, "node_id": "MDQ6VXNlcjk1NDcwNTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/9547057?v=4", "gravatar_id": "", "url": "https://api.github.com/users/D-X-Y", "html_url": "https://github.com/D-X-Y", "followers_url": "https://api.github.com/users/D-X-Y/followers", "following_url": "https://api.github.com/users/D-X-Y/following{/other_user}", "gists_url": "https://api.github.com/users/D-X-Y/gists{/gist_id}", "starred_url": "https://api.github.com/users/D-X-Y/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/D-X-Y/subscriptions", "organizations_url": "https://api.github.com/users/D-X-Y/orgs", "repos_url": "https://api.github.com/users/D-X-Y/repos", "events_url": "https://api.github.com/users/D-X-Y/events{/privacy}", "received_events_url": "https://api.github.com/users/D-X-Y/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-20T00:57:13Z", "updated_at": "2017-09-20T01:00:07Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> for example</p>\n<pre><code>grid_size = torch.Size([number_of_box, 1, 7,7])\ngrid = F.affine_grid(theta, grid_size)           # the shape of theta is number_of_box * 2 * 3\ncropped_images = F.grid_sample(image, grid)      # the shape of image is 1xCxHxW or CxHxW\n</code></pre>\n<p>The results are <code>number_of_box</code> cropped images from the same image.<br>\nI feel this would be very useful for object detection since each image has many region proposals.</p>", "body_text": "@soumith for example\ngrid_size = torch.Size([number_of_box, 1, 7,7])\ngrid = F.affine_grid(theta, grid_size)           # the shape of theta is number_of_box * 2 * 3\ncropped_images = F.grid_sample(image, grid)      # the shape of image is 1xCxHxW or CxHxW\n\nThe results are number_of_box cropped images from the same image.\nI feel this would be very useful for object detection since each image has many region proposals.", "body": "@soumith for example\r\n```\r\ngrid_size = torch.Size([number_of_box, 1, 7,7])\r\ngrid = F.affine_grid(theta, grid_size)           # the shape of theta is number_of_box * 2 * 3\r\ncropped_images = F.grid_sample(image, grid)      # the shape of image is 1xCxHxW or CxHxW\r\n```\r\nThe results are `number_of_box` cropped images from the same image.\r\nI feel this would be very useful for object detection since each image has many region proposals."}