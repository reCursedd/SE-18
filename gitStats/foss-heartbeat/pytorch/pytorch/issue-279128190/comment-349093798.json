{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/349093798", "html_url": "https://github.com/pytorch/pytorch/issues/4010#issuecomment-349093798", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4010", "id": 349093798, "node_id": "MDEyOklzc3VlQ29tbWVudDM0OTA5Mzc5OA==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-04T20:24:24Z", "updated_at": "2017-12-04T20:35:44Z", "author_association": "NONE", "body_html": "<p>This would make sense if the tensor actually uses a contiguous segment of underlying storage without skips, like for the example above, but also has some zero-strides. I guess my case is just that we may perform the element-wise ops by first removing zero-strided dimensions, and then putting them back.</p>\n<p>Where would writing or reading to expanded tensor happen? I was thinking the op would perform and then would reshape/expand again:</p>\n<p>I was thinking of something like (when reshape gets <a href=\"https://github.com/pytorch/pytorch/issues/3919#issuecomment-347931970\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3919/hovercard\">added</a>):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">mul</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">c</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> need another condition, this one isn't good for 10x5x1x1 expanded to 10x5x15x15</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> and re-expanding will probably not work with just reshape</span>\n    <span class=\"pl-k\">return</span> (x.reshape(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>) <span class=\"pl-k\">*</span> c).reshape(x.size()) <span class=\"pl-k\">if</span> <span class=\"pl-c1\">sum</span>(x.stride()) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">else</span> x <span class=\"pl-k\">*</span> c</pre></div>", "body_text": "This would make sense if the tensor actually uses a contiguous segment of underlying storage without skips, like for the example above, but also has some zero-strides. I guess my case is just that we may perform the element-wise ops by first removing zero-strided dimensions, and then putting them back.\nWhere would writing or reading to expanded tensor happen? I was thinking the op would perform and then would reshape/expand again:\nI was thinking of something like (when reshape gets added):\ndef mul(x, c):\n    # need another condition, this one isn't good for 10x5x1x1 expanded to 10x5x15x15\n    # and re-expanding will probably not work with just reshape\n    return (x.reshape(-1) * c).reshape(x.size()) if sum(x.stride()) == 1 else x * c", "body": "This would make sense if the tensor actually uses a contiguous segment of underlying storage without skips, like for the example above, but also has some zero-strides. I guess my case is just that we may perform the element-wise ops by first removing zero-strided dimensions, and then putting them back.\r\n\r\nWhere would writing or reading to expanded tensor happen? I was thinking the op would perform and then would reshape/expand again:\r\n\r\nI was thinking of something like (when reshape gets [added](https://github.com/pytorch/pytorch/issues/3919#issuecomment-347931970)):\r\n```python\r\ndef mul(x, c):\r\n    # need another condition, this one isn't good for 10x5x1x1 expanded to 10x5x15x15\r\n    # and re-expanding will probably not work with just reshape\r\n    return (x.reshape(-1) * c).reshape(x.size()) if sum(x.stride()) == 1 else x * c\r\n```\r\n"}