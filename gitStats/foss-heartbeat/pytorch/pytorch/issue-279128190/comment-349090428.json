{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/349090428", "html_url": "https://github.com/pytorch/pytorch/issues/4010#issuecomment-349090428", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4010", "id": 349090428, "node_id": "MDEyOklzc3VlQ29tbWVudDM0OTA5MDQyOA==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-04T20:12:06Z", "updated_at": "2017-12-04T20:13:04Z", "author_association": "NONE", "body_html": "<p>Agreed, the benefits aren't obvious especially when we have good broadcasting.</p>\n<p>For perf regression, for actually contiguous chunks of memory this wouldn't be the case, right?<br>\nPreserving small storage size should save memory for big expands (compared to the existing behavior). But again, not sure how frequent this happens.</p>\n<p>Anyway, closing this issue.</p>", "body_text": "Agreed, the benefits aren't obvious especially when we have good broadcasting.\nFor perf regression, for actually contiguous chunks of memory this wouldn't be the case, right?\nPreserving small storage size should save memory for big expands (compared to the existing behavior). But again, not sure how frequent this happens.\nAnyway, closing this issue.", "body": "Agreed, the benefits aren't obvious especially when we have good broadcasting.\r\n\r\nFor perf regression, for actually contiguous chunks of memory this wouldn't be the case, right?\r\nPreserving small storage size should save memory for big expands (compared to the existing behavior). But again, not sure how frequent this happens.\r\n\r\nAnyway, closing this issue."}