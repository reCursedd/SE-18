{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4673", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4673/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4673/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4673/events", "html_url": "https://github.com/pytorch/pytorch/issues/4673", "id": 288600895, "node_id": "MDU6SXNzdWUyODg2MDA4OTU=", "number": 4673, "title": "GPU memory consumption with cudnn.enabled = False", "user": {"login": "tlkvstepan", "id": 11693251, "node_id": "MDQ6VXNlcjExNjkzMjUx", "avatar_url": "https://avatars2.githubusercontent.com/u/11693251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tlkvstepan", "html_url": "https://github.com/tlkvstepan", "followers_url": "https://api.github.com/users/tlkvstepan/followers", "following_url": "https://api.github.com/users/tlkvstepan/following{/other_user}", "gists_url": "https://api.github.com/users/tlkvstepan/gists{/gist_id}", "starred_url": "https://api.github.com/users/tlkvstepan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tlkvstepan/subscriptions", "organizations_url": "https://api.github.com/users/tlkvstepan/orgs", "repos_url": "https://api.github.com/users/tlkvstepan/repos", "events_url": "https://api.github.com/users/tlkvstepan/events{/privacy}", "received_events_url": "https://api.github.com/users/tlkvstepan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-15T13:51:38Z", "updated_at": "2018-01-19T09:46:50Z", "closed_at": "2018-01-15T20:32:35Z", "author_association": "NONE", "body_html": "<pre><code>import torch as th \nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport subprocess\nimport torch.backends.cudnn as cudnn\ncudnn.enabled = False\n\ndef get_gpu_memory_map():\n    \n    result = subprocess.check_output(\n        [\n            'nvidia-smi', '--query-gpu=memory.used',\n            '--format=csv,nounits,noheader'\n        ])\n\n    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n    \n    return gpu_memory_map\n\ndef conv2D_block(in_channels, out_channels, kernel_size=3, stride=1):\n    padding = kernel_size//2\n    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n                         nn.LeakyReLU(negative_slope=0.1, inplace=True),\n                         nn.BatchNorm2d(out_channels))\n\ndownsample0 = conv2D_block(in_channels=64, out_channels=64, kernel_size=5, stride=2)\ndownsample0.float().cuda()\ndownsample0.eval()\n\ninp = Variable(th.rand(1, 64, 3000/2, 3000/2).float().cuda(), volatile=True)\nprint 'before', get_gpu_memory_map()\nembed0 = downsample0(inp);  th.cuda.empty_cache() \nprint 'after downsample0', get_gpu_memory_map()   \n</code></pre>\n<p>According to this code, difference in used GPU memory  before and after convolution is  4809 MB - 1345 MB = 3.5 GB . This is too much since <em>inp</em> is just 536MB and <em>embed0</em> is 134 MB. From my experiments this issue is fixed if i delete nn.BatchNorm2d block.</p>\n<p>What can be the reason for this strange behavior?</p>\n<p>PS: I turned off CUDNN to avoid another bug with ConvTranspose3d  [<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"284361477\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4344\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4344/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4344\">#4344</a>]</p>\n<p>Pyton2.7, PyTorch 0.3 (pip),  CUDA 8, CUDNN 7</p>", "body_text": "import torch as th \nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport subprocess\nimport torch.backends.cudnn as cudnn\ncudnn.enabled = False\n\ndef get_gpu_memory_map():\n    \n    result = subprocess.check_output(\n        [\n            'nvidia-smi', '--query-gpu=memory.used',\n            '--format=csv,nounits,noheader'\n        ])\n\n    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n    \n    return gpu_memory_map\n\ndef conv2D_block(in_channels, out_channels, kernel_size=3, stride=1):\n    padding = kernel_size//2\n    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n                         nn.LeakyReLU(negative_slope=0.1, inplace=True),\n                         nn.BatchNorm2d(out_channels))\n\ndownsample0 = conv2D_block(in_channels=64, out_channels=64, kernel_size=5, stride=2)\ndownsample0.float().cuda()\ndownsample0.eval()\n\ninp = Variable(th.rand(1, 64, 3000/2, 3000/2).float().cuda(), volatile=True)\nprint 'before', get_gpu_memory_map()\nembed0 = downsample0(inp);  th.cuda.empty_cache() \nprint 'after downsample0', get_gpu_memory_map()   \n\nAccording to this code, difference in used GPU memory  before and after convolution is  4809 MB - 1345 MB = 3.5 GB . This is too much since inp is just 536MB and embed0 is 134 MB. From my experiments this issue is fixed if i delete nn.BatchNorm2d block.\nWhat can be the reason for this strange behavior?\nPS: I turned off CUDNN to avoid another bug with ConvTranspose3d  [#4344]\nPyton2.7, PyTorch 0.3 (pip),  CUDA 8, CUDNN 7", "body": "```\r\nimport torch as th \r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport subprocess\r\nimport torch.backends.cudnn as cudnn\r\ncudnn.enabled = False\r\n\r\ndef get_gpu_memory_map():\r\n    \r\n    result = subprocess.check_output(\r\n        [\r\n            'nvidia-smi', '--query-gpu=memory.used',\r\n            '--format=csv,nounits,noheader'\r\n        ])\r\n\r\n    gpu_memory = [int(x) for x in result.strip().split('\\n')]\r\n    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\r\n    \r\n    return gpu_memory_map\r\n\r\ndef conv2D_block(in_channels, out_channels, kernel_size=3, stride=1):\r\n    padding = kernel_size//2\r\n    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\r\n                         nn.LeakyReLU(negative_slope=0.1, inplace=True),\r\n                         nn.BatchNorm2d(out_channels))\r\n\r\ndownsample0 = conv2D_block(in_channels=64, out_channels=64, kernel_size=5, stride=2)\r\ndownsample0.float().cuda()\r\ndownsample0.eval()\r\n\r\ninp = Variable(th.rand(1, 64, 3000/2, 3000/2).float().cuda(), volatile=True)\r\nprint 'before', get_gpu_memory_map()\r\nembed0 = downsample0(inp);  th.cuda.empty_cache() \r\nprint 'after downsample0', get_gpu_memory_map()   \r\n```\r\nAccording to this code, difference in used GPU memory  before and after convolution is  4809 MB - 1345 MB = 3.5 GB . This is too much since *inp* is just 536MB and *embed0* is 134 MB. From my experiments this issue is fixed if i delete nn.BatchNorm2d block.\r\n\r\nWhat can be the reason for this strange behavior? \r\n\r\nPS: I turned off CUDNN to avoid another bug with ConvTranspose3d  [#4344]\r\n\r\nPyton2.7, PyTorch 0.3 (pip),  CUDA 8, CUDNN 7\r\n"}