{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1447", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1447/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1447/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1447/events", "html_url": "https://github.com/pytorch/pytorch/issues/1447", "id": 225818524, "node_id": "MDU6SXNzdWUyMjU4MTg1MjQ=", "number": 1447, "title": "sparse_mask on uncoalesced sparse tensors does not make sense", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-05-02T20:55:24Z", "updated_at": "2017-05-03T21:53:48Z", "closed_at": "2017-05-03T21:53:48Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2560662\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinraison\">@martinraison</a> and I talked about the intended semantics of sparse_mask when given a sparse tensor as an argument, and we came to the following conclusions:</p>\n<ol>\n<li>\n<p>sparse_mask with an uncoalesced sparse tensor does not make sense, full stop. Unlike values, where your update might be linear and work correctly on an uncoalesced sparse tensor, there isn't any good reason why you want to pluck out values from the dense tensor multiple times, it is basically always a bug.</p>\n</li>\n<li>\n<p>In the (eventual) documentation for sparse_mask, we will recommend calling coalesce before doing any operations involving sparse_mask (or nonlinear updates to indices/values).</p>\n</li>\n<li>\n<p>We should add a test to sparse_mask which checks if the <code>coalesced</code> flag of the input tensor is true, and raise an error if it is not. This is a cheap safety check which will prevent people from forgetting to call coalesce (as in (2)).</p>\n</li>\n</ol>\n<p>There is a performance consequence to calling coalesce every iteration of training. If the gradient is producing coalesced vectors, we can alleviate this problem by adding a preprocessing step to coalesce() which tests if the input is already coalesced, and bugs out in that case. However, I think this is out of scope for this particular ticket for now.</p>", "body_text": "@martinraison and I talked about the intended semantics of sparse_mask when given a sparse tensor as an argument, and we came to the following conclusions:\n\n\nsparse_mask with an uncoalesced sparse tensor does not make sense, full stop. Unlike values, where your update might be linear and work correctly on an uncoalesced sparse tensor, there isn't any good reason why you want to pluck out values from the dense tensor multiple times, it is basically always a bug.\n\n\nIn the (eventual) documentation for sparse_mask, we will recommend calling coalesce before doing any operations involving sparse_mask (or nonlinear updates to indices/values).\n\n\nWe should add a test to sparse_mask which checks if the coalesced flag of the input tensor is true, and raise an error if it is not. This is a cheap safety check which will prevent people from forgetting to call coalesce (as in (2)).\n\n\nThere is a performance consequence to calling coalesce every iteration of training. If the gradient is producing coalesced vectors, we can alleviate this problem by adding a preprocessing step to coalesce() which tests if the input is already coalesced, and bugs out in that case. However, I think this is out of scope for this particular ticket for now.", "body": "@martinraison and I talked about the intended semantics of sparse_mask when given a sparse tensor as an argument, and we came to the following conclusions:\r\n\r\n1. sparse_mask with an uncoalesced sparse tensor does not make sense, full stop. Unlike values, where your update might be linear and work correctly on an uncoalesced sparse tensor, there isn't any good reason why you want to pluck out values from the dense tensor multiple times, it is basically always a bug.\r\n\r\n2. In the (eventual) documentation for sparse_mask, we will recommend calling coalesce before doing any operations involving sparse_mask (or nonlinear updates to indices/values).\r\n\r\n3. We should add a test to sparse_mask which checks if the `coalesced` flag of the input tensor is true, and raise an error if it is not. This is a cheap safety check which will prevent people from forgetting to call coalesce (as in (2)).\r\n\r\nThere is a performance consequence to calling coalesce every iteration of training. If the gradient is producing coalesced vectors, we can alleviate this problem by adding a preprocessing step to coalesce() which tests if the input is already coalesced, and bugs out in that case. However, I think this is out of scope for this particular ticket for now."}