{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210943255", "pull_request_review_id": 147269095, "id": 210943255, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMDk0MzI1NQ==", "diff_hunk": "@@ -60,24 +60,37 @@ struct AnnotatedGraph {\n   std::vector<TensorDesc> output_desc;\n };\n \n-struct ConcatDesc {\n-  size_t nSubtensors; // == 1 for outputs that are not concats, otherwise it is the number tensors concatenated\n-  size_t dim; // dimension along which the concat occurs\n+// Descriptor for chunk-ing an input tensor into subtensors\n+// OR concat-ing an output tensor from subtensors\n+struct PartitionDesc {\n+  size_t nSubtensors; // == 1 for tensors that should not be operated on via chunk/cat\n+  size_t dim; // dimension along which the chunk/concat occurs\n   std::unique_ptr<TensorDesc> subtensorDesc; // descriptor for the subtensor, if it exists\n-  ConcatDesc()\n+  PartitionDesc()\n   : nSubtensors(1), dim(0) {}\n-  ConcatDesc(const TensorDesc & desc, size_t nSubtensors, size_t dim)\n+  // PartitionDesc is used as metadata for either fused chunk or FusedConcat ops.\n+  // Depending on which one it is used for, the contiguity calc is different.\n+  PartitionDesc(const TensorDesc & desc, size_t nSubtensors, size_t dim, bool is_chunk)\n   : nSubtensors(nSubtensors), dim(dim) {\n     JIT_ASSERT(nSubtensors > 1);\n     std::vector<bool> cont = desc.contiguity;\n-    if(dim > 0) {\n-      // when we narrow the concatenated output\n-      // we make the size[dim] smaller while keeping the stride[dim] the same,\n-      // meaning: stride[dim - 1] != stride[dim]*size[dim]\n-      // so dim - 1 is no longer contiguous\n-      cont[dim - 1] = false;\n+    if (is_chunk) {\n+      subtensorDesc.reset(new TensorDesc(desc.scalar_type, desc.contiguity));", "path": "torch/csrc/jit/fusion_compiler.h", "position": null, "original_position": 30, "commit_id": "b00a76e1588f34aa2c1d1a9e55fe76b1ad7cf71d", "original_commit_id": "60b58f153f0325eeb585d030da9af61f124b4aa7", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "Yes, `desc.contiguity` should already have the correct contiguity:\r\nhttps://github.com/pytorch/pytorch/blob/60b58f153f0325eeb585d030da9af61f124b4aa7/torch/csrc/jit/fusion_compiler.cpp#L470-L476 \r\nThat part of the code constructs `desc` with the correct sizes / strides of each of the output chunks, and then the TensorDesc constructor computes the correct contiguity. `desc` is then passed into the PartitionDesc ctor. \r\n\r\nThis behavior is different from what happens in a `cat` operation: for `aten::cat` PartitionDesc computes the correct contiguity, but for `aten::chunk` PartitionDesc is passed the correct contiguity. I'll add comments, a separate constructor, or move some code around as appropriate to make this distinction clearer.", "created_at": "2018-08-17T15:16:40Z", "updated_at": "2018-11-23T15:49:36Z", "html_url": "https://github.com/pytorch/pytorch/pull/10178#discussion_r210943255", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10178", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210943255"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10178#discussion_r210943255"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10178"}}, "body_html": "<p>Yes, <code>desc.contiguity</code> should already have the correct contiguity:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/60b58f153f0325eeb585d030da9af61f124b4aa7/torch/csrc/jit/fusion_compiler.cpp#L470-L476\">pytorch/torch/csrc/jit/fusion_compiler.cpp</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 470 to 476\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/60b58f153f0325eeb585d030da9af61f124b4aa7\">60b58f1</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L470\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"470\"></td>\n          <td id=\"LC470\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">auto</span> tensor_type = p-&gt;<span class=\"pl-c1\">type</span>()-&gt;<span class=\"pl-smi\">cast</span>&lt;TensorType&gt;(); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L471\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"471\"></td>\n          <td id=\"LC471\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> std::vector&lt;<span class=\"pl-c1\">int64_t</span>&gt; <span class=\"pl-c1\">sizes</span>(tensor_type-&gt;<span class=\"pl-c1\">sizes</span>().<span class=\"pl-c1\">begin</span>(), tensor_type-&gt;<span class=\"pl-c1\">sizes</span>().<span class=\"pl-c1\">end</span>()); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L472\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"472\"></td>\n          <td id=\"LC472\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-c1\">JIT_ASSERT</span>(sizes[dim] % chunks == <span class=\"pl-c1\">0</span>); <span class=\"pl-c\"><span class=\"pl-c\">//</span> Should have been checked in graph fuser</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L473\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"473\"></td>\n          <td id=\"LC473\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> sizes[dim] /= chunks; </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L474\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"474\"></td>\n          <td id=\"LC474\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> TensorDesc <span class=\"pl-smi\">desc</span>(tensor_type-&gt;<span class=\"pl-c1\">scalarType</span>(), sizes, tensor_type-&gt;<span class=\"pl-c1\">strides</span>()); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L475\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"475\"></td>\n          <td id=\"LC475\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L476\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"476\"></td>\n          <td id=\"LC476\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> chunk_desc.<span class=\"pl-c1\">emplace_back</span>(desc, chunks, dim, <span class=\"pl-c\"><span class=\"pl-c\">/*</span>is_chunk<span class=\"pl-c\">*/</span></span><span class=\"pl-c1\">true</span>); </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n<br>\nThat part of the code constructs <code>desc</code> with the correct sizes / strides of each of the output chunks, and then the TensorDesc constructor computes the correct contiguity. <code>desc</code> is then passed into the PartitionDesc ctor.</p>\n<p>This behavior is different from what happens in a <code>cat</code> operation: for <code>aten::cat</code> PartitionDesc computes the correct contiguity, but for <code>aten::chunk</code> PartitionDesc is passed the correct contiguity. I'll add comments, a separate constructor, or move some code around as appropriate to make this distinction clearer.</p>", "body_text": "Yes, desc.contiguity should already have the correct contiguity:\n\n  \n    \n      pytorch/torch/csrc/jit/fusion_compiler.cpp\n    \n    \n        Lines 470 to 476\n      in\n      60b58f1\n    \n    \n    \n    \n\n        \n          \n           auto tensor_type = p->type()->cast<TensorType>(); \n        \n\n        \n          \n           std::vector<int64_t> sizes(tensor_type->sizes().begin(), tensor_type->sizes().end()); \n        \n\n        \n          \n           JIT_ASSERT(sizes[dim] % chunks == 0); // Should have been checked in graph fuser \n        \n\n        \n          \n           sizes[dim] /= chunks; \n        \n\n        \n          \n           TensorDesc desc(tensor_type->scalarType(), sizes, tensor_type->strides()); \n        \n\n        \n          \n            \n        \n\n        \n          \n           chunk_desc.emplace_back(desc, chunks, dim, /*is_chunk*/true); \n        \n    \n  \n\n\nThat part of the code constructs desc with the correct sizes / strides of each of the output chunks, and then the TensorDesc constructor computes the correct contiguity. desc is then passed into the PartitionDesc ctor.\nThis behavior is different from what happens in a cat operation: for aten::cat PartitionDesc computes the correct contiguity, but for aten::chunk PartitionDesc is passed the correct contiguity. I'll add comments, a separate constructor, or move some code around as appropriate to make this distinction clearer.", "in_reply_to_id": 210725831}