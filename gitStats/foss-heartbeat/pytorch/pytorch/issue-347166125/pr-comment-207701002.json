{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/207701002", "pull_request_review_id": 143372876, "id": 207701002, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNzcwMTAwMg==", "diff_hunk": "@@ -60,6 +60,15 @@ struct AnnotatedGraph {\n   std::vector<TensorDesc> output_desc;\n };\n \n+struct ChunkDesc {", "path": "torch/csrc/jit/fusion_compiler.h", "position": null, "original_position": 4, "commit_id": "b00a76e1588f34aa2c1d1a9e55fe76b1ad7cf71d", "original_commit_id": "b7c32375b90410b074fd47b6daacd5d72bd25ae2", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "Now that I think about this more, I believe ChunkDesc and ConcatDesc are actually exactly the same thing. Each describes how to split up a bigger tensor into smaller components that become inputs into the kernel. The only difference is that for chunks it describes an input, and for cat, an output. However from the kernels perspective they are all just pointers to memory anyway. It should cleaner to actually have the code reflect this similarity, and because they are the same concept, they should also be able to share a lot of code. For instance I was suggesting adding a precomputed TensorDesc to Chunk -- well concat already has that and the handling for it.", "created_at": "2018-08-04T06:10:39Z", "updated_at": "2018-11-23T15:48:45Z", "html_url": "https://github.com/pytorch/pytorch/pull/10178#discussion_r207701002", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10178", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/207701002"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10178#discussion_r207701002"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10178"}}, "body_html": "<p>Now that I think about this more, I believe ChunkDesc and ConcatDesc are actually exactly the same thing. Each describes how to split up a bigger tensor into smaller components that become inputs into the kernel. The only difference is that for chunks it describes an input, and for cat, an output. However from the kernels perspective they are all just pointers to memory anyway. It should cleaner to actually have the code reflect this similarity, and because they are the same concept, they should also be able to share a lot of code. For instance I was suggesting adding a precomputed TensorDesc to Chunk -- well concat already has that and the handling for it.</p>", "body_text": "Now that I think about this more, I believe ChunkDesc and ConcatDesc are actually exactly the same thing. Each describes how to split up a bigger tensor into smaller components that become inputs into the kernel. The only difference is that for chunks it describes an input, and for cat, an output. However from the kernels perspective they are all just pointers to memory anyway. It should cleaner to actually have the code reflect this similarity, and because they are the same concept, they should also be able to share a lot of code. For instance I was suggesting adding a precomputed TensorDesc to Chunk -- well concat already has that and the handling for it."}