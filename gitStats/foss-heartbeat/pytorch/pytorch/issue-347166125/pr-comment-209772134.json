{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/209772134", "pull_request_review_id": 145771888, "id": 209772134, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwOTc3MjEzNA==", "diff_hunk": "@@ -624,41 +668,94 @@ void compressContiguous(\n \n } // anonymous namespace\n \n+// XXX: Assumes that after at::chunk, all inputs are the same size\n+static inline std::vector<int64_t> computeMapSize(\n+    const at::Tensor& tensor,\n+    const ConcatDesc& chunkDesc) {\n+  std::vector<int64_t> sizes(tensor.sizes().begin(), tensor.sizes().end());\n+  JIT_ASSERT(chunkDesc.nSubtensors > 1);\n+  JIT_ASSERT(sizes[chunkDesc.dim] % chunkDesc.nSubtensors == 0);\n+  sizes[chunkDesc.dim] /= chunkDesc.nSubtensors;\n+  return sizes;\n+}\n+\n+// XXX: this code assumes that inputs are 32-bit addressable\n+static inline uint32_t computeNumel(at::ArrayRef<int64_t> sizes) {\n+  uint32_t result = 1;\n+  if (sizes.size() == 0) {\n+    return 0;\n+  }\n+  for (int64_t size : sizes) {\n+    result *= size;\n+  }\n+  return result;\n+}\n+\n void CompiledFusionFunction::launch_with_tensors(at::ArrayRef<at::Tensor> inputs, at::ArrayRef<at::Tensor> outputs) {\n   at::DeviceGuard device_guard(inputs);\n   JIT_ASSERT(inputs.size() == input_desc.size());\n   JIT_ASSERT(outputs.size() == output_desc.size());\n+  size_t flat_inputs_size = 0;\n   size_t flat_outputs_size = 0;\n+  for(auto & c : chunk_desc)\n+    flat_inputs_size += c.nSubtensors;\n   for(auto & c : concat_desc)\n     flat_outputs_size += c.nSubtensors;\n   // XXX: this code assumes that inputs are 32-bit addressable\n   // XXX: this code assumes that all inputs are of the same size\n   JIT_ASSERT(inputs[0].numel() <= std::numeric_limits<uint32_t>::max());\n-  uint32_t numel = inputs[0].numel();\n-  at::IntList map_size = inputs[0].sizes();\n+\n+  // Compute map_size, numel from the first input\n+  at::IntList map_size;\n+  uint32_t numel;\n+  std::vector<int64_t> keep_alive_size;\n+  if (chunk_desc[0].nSubtensors == 1) {", "path": "torch/csrc/jit/fusion_compiler.cpp", "position": null, "original_position": 149, "commit_id": "b00a76e1588f34aa2c1d1a9e55fe76b1ad7cf71d", "original_commit_id": "afe7b9de639573fc47672209036fa7e2f1d16cb7", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Didn't you assert this never happens above?", "created_at": "2018-08-13T21:54:46Z", "updated_at": "2018-11-23T15:49:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/10178#discussion_r209772134", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10178", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/209772134"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10178#discussion_r209772134"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10178"}}, "body_html": "<p>Didn't you assert this never happens above?</p>", "body_text": "Didn't you assert this never happens above?"}