{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/392617809", "html_url": "https://github.com/pytorch/pytorch/issues/4884#issuecomment-392617809", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4884", "id": 392617809, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjYxNzgwOQ==", "user": {"login": "stes", "id": 727984, "node_id": "MDQ6VXNlcjcyNzk4NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/727984?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stes", "html_url": "https://github.com/stes", "followers_url": "https://api.github.com/users/stes/followers", "following_url": "https://api.github.com/users/stes/following{/other_user}", "gists_url": "https://api.github.com/users/stes/gists{/gist_id}", "starred_url": "https://api.github.com/users/stes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stes/subscriptions", "organizations_url": "https://api.github.com/users/stes/orgs", "repos_url": "https://api.github.com/users/stes/repos", "events_url": "https://api.github.com/users/stes/events{/privacy}", "received_events_url": "https://api.github.com/users/stes/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-28T23:42:59Z", "updated_at": "2018-05-28T23:44:48Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5948971\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/happsky\">@happsky</a> Try to run your network on the CPU to get a more meaningful error message (see my post above). Probably the size of the tensor you want to process becomes smaller than the kernel size at some point.</p>\n<p>Here's a minimal example highlighting the issue:</p>\n<div class=\"highlight highlight-source-python\"><pre>X    <span class=\"pl-k\">=</span> torch.Tensor(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">4</span>)\nconv <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">10</span>,<span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>)\n\nconv(X)</pre></div>\n<p>yields</p>\n<div class=\"highlight highlight-source-diff\"><pre><span class=\"pl-md\"><span class=\"pl-md\">-</span> RuntimeError: Calculated padded input size per channel: (4 x 4).</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span> Kernel size: (5 x 5). Kernel size can't greater than actual input size</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span> at [...]</span></pre></div>\n<p>while</p>\n<div class=\"highlight highlight-source-python\"><pre>X    <span class=\"pl-k\">=</span> torch.Tensor(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">4</span>)\nconv <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">10</span>,<span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">5</span>)\n\nX <span class=\"pl-k\">=</span> X.cuda()\nconv.cuda()\n\nconv(X)</pre></div>\n<p>yields the cryptic error message mentioned in this issue:</p>\n<div class=\"highlight highlight-source-diff\"><pre><span class=\"pl-md\"><span class=\"pl-md\">-</span> RuntimeError: Expected tensor for argument #1 'input' to have the</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span> same dimension as tensor for 'result'; but 4 does not equal 2 (while</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span> checking arguments for cudnn_convolution)</span></pre></div>\n<p>You might also consider to post a minimal example of your issue to <a href=\"https://discuss.pytorch.org\" rel=\"nofollow\">https://discuss.pytorch.org</a></p>", "body_text": "@happsky Try to run your network on the CPU to get a more meaningful error message (see my post above). Probably the size of the tensor you want to process becomes smaller than the kernel size at some point.\nHere's a minimal example highlighting the issue:\nX    = torch.Tensor(3,2,4,4)\nconv = torch.nn.Conv2d(2,10,kernel_size=5)\n\nconv(X)\nyields\n- RuntimeError: Calculated padded input size per channel: (4 x 4).\n- Kernel size: (5 x 5). Kernel size can't greater than actual input size\n- at [...]\nwhile\nX    = torch.Tensor(3,2,4,4)\nconv = torch.nn.Conv2d(2,10,kernel_size=5)\n\nX = X.cuda()\nconv.cuda()\n\nconv(X)\nyields the cryptic error message mentioned in this issue:\n- RuntimeError: Expected tensor for argument #1 'input' to have the\n- same dimension as tensor for 'result'; but 4 does not equal 2 (while\n- checking arguments for cudnn_convolution)\nYou might also consider to post a minimal example of your issue to https://discuss.pytorch.org", "body": "@happsky Try to run your network on the CPU to get a more meaningful error message (see my post above). Probably the size of the tensor you want to process becomes smaller than the kernel size at some point.\r\n\r\nHere's a minimal example highlighting the issue:\r\n\r\n``` python\r\nX    = torch.Tensor(3,2,4,4)\r\nconv = torch.nn.Conv2d(2,10,kernel_size=5)\r\n\r\nconv(X)\r\n```\r\nyields\r\n```diff\r\n- RuntimeError: Calculated padded input size per channel: (4 x 4).\r\n- Kernel size: (5 x 5). Kernel size can't greater than actual input size\r\n- at [...]\r\n```\r\n\r\nwhile\r\n\r\n``` python\r\nX    = torch.Tensor(3,2,4,4)\r\nconv = torch.nn.Conv2d(2,10,kernel_size=5)\r\n\r\nX = X.cuda()\r\nconv.cuda()\r\n\r\nconv(X)\r\n```\r\n\r\nyields the cryptic error message mentioned in this issue:\r\n\r\n```diff\r\n- RuntimeError: Expected tensor for argument #1 'input' to have the\r\n- same dimension as tensor for 'result'; but 4 does not equal 2 (while\r\n- checking arguments for cudnn_convolution)\r\n```\r\n\r\nYou might also consider to post a minimal example of your issue to https://discuss.pytorch.org"}