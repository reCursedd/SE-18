{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/357597215", "html_url": "https://github.com/pytorch/pytorch/issues/4017#issuecomment-357597215", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4017", "id": 357597215, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzU5NzIxNQ==", "user": {"login": "Zrachel", "id": 4532062, "node_id": "MDQ6VXNlcjQ1MzIwNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4532062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zrachel", "html_url": "https://github.com/Zrachel", "followers_url": "https://api.github.com/users/Zrachel/followers", "following_url": "https://api.github.com/users/Zrachel/following{/other_user}", "gists_url": "https://api.github.com/users/Zrachel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zrachel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zrachel/subscriptions", "organizations_url": "https://api.github.com/users/Zrachel/orgs", "repos_url": "https://api.github.com/users/Zrachel/repos", "events_url": "https://api.github.com/users/Zrachel/events{/privacy}", "received_events_url": "https://api.github.com/users/Zrachel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-15T06:56:48Z", "updated_at": "2018-01-15T06:56:48Z", "author_association": "NONE", "body_html": "<p>Same problem here.</p>\n<p>CUDA: v7.5<br>\nCUDNN: v6.0</p>\n<pre><code>running install\nrunning build_deps\n-- The C compiler identification is GNU 4.8.5\n-- The CXX compiler identification is GNU 4.8.5\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Checking if C linker supports --verbose\n-- Checking if C linker supports --verbose - yes\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Checking if CXX linker supports --verbose\n-- Checking if CXX linker supports --verbose - yes\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"7.0\") \n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl\n/usr/bin/make64 MAC=64 install\nScanning dependencies of target nccl\n[100%] Generating lib/libnccl.so\n/usr/bin/make64 MAC=64 -j 12\nGrabbing  src/nccl.h                          &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/include/nccl.h\nCompiling src/libwrap.cu                      &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/libwrap.o\nCompiling src/core.cu                         &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/core.o\nCompiling src/all_gather.cu                   &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_gather.o\nCompiling src/all_reduce.cu                   &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_reduce.o\nCompiling src/broadcast.cu                    &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/broadcast.o\nCompiling src/reduce.cu                       &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce.o\nCompiling src/reduce_scatter.cu               &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce_scatter.o\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nLinking   libnccl.so.1.3.5                    &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl.so.1.3.5\nArchiving libnccl_static.a                    &gt; /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl_static.a\n[100%] Built target nccl\nInstall the project...\n-- Install configuration: \"Release\"\n-- Installing: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/tmp_install/include/nccl.h\n-- The C compiler identification is GNU 4.8.5\n-- The CXX compiler identification is GNU 4.8.5\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Checking if C linker supports --verbose\n-- Checking if C linker supports --verbose - yes\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Checking if CXX linker supports --verbose\n-- Checking if CXX linker supports --verbose - yes\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"5.5\") \n-- Autodetected CUDA architecture(s): 3.5 3.5 3.5 3.5\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n-- Try OpenMP C flag = [-fopenmp]\n-- Performing Test OpenMP_FLAG_DETECTED\n-- Performing Test OpenMP_FLAG_DETECTED - Success\n-- Try OpenMP CXX flag = [-fopenmp]\n-- Performing Test OpenMP_FLAG_DETECTED\n-- Performing Test OpenMP_FLAG_DETECTED - Success\n-- Found OpenMP: -fopenmp  \n-- Compiling with OpenMP support\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\n-- Compiling with MAGMA support\n-- MAGMA INCLUDE DIRECTORIES: /home/zhangruiqing01/tools/anaconda3/include\n-- MAGMA LIBRARIES: /home/zhangruiqing01/tools/anaconda3/lib/libmagma.a\n-- MAGMA V2 check: 1\n-- Could not find hardware support for NEON on this machine.\n-- No OMAP3 processor on this machine.\n-- No OMAP4 processor on this machine.\n-- Looking for cpuid.h\n-- Looking for cpuid.h - found\n-- Performing Test HAVE_GCC_GET_CPUID\n-- Performing Test HAVE_GCC_GET_CPUID - Success\n-- Performing Test NO_GCC_EBX_FPIC_BUG\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\n-- Performing Test C_HAS_SSE1_1\n-- Performing Test C_HAS_SSE1_1 - Success\n-- Performing Test C_HAS_SSE2_1\n-- Performing Test C_HAS_SSE2_1 - Success\n-- Performing Test C_HAS_SSE3_1\n-- Performing Test C_HAS_SSE3_1 - Failed\n-- Performing Test C_HAS_SSE3_2\n-- Performing Test C_HAS_SSE3_2 - Success\n-- Performing Test C_HAS_SSE4_1_1\n-- Performing Test C_HAS_SSE4_1_1 - Failed\n-- Performing Test C_HAS_SSE4_1_2\n-- Performing Test C_HAS_SSE4_1_2 - Success\n-- Performing Test C_HAS_SSE4_2_1\n-- Performing Test C_HAS_SSE4_2_1 - Failed\n-- Performing Test C_HAS_SSE4_2_2\n-- Performing Test C_HAS_SSE4_2_2 - Success\n-- Performing Test C_HAS_AVX_1\n-- Performing Test C_HAS_AVX_1 - Failed\n-- Performing Test C_HAS_AVX_2\n-- Performing Test C_HAS_AVX_2 - Success\n-- Performing Test C_HAS_AVX2_1\n-- Performing Test C_HAS_AVX2_1 - Failed\n-- Performing Test C_HAS_AVX2_2\n-- Performing Test C_HAS_AVX2_2 - Failed\n-- Performing Test C_HAS_AVX2_3\n-- Performing Test C_HAS_AVX2_3 - Failed\n-- Performing Test CXX_HAS_SSE1_1\n-- Performing Test CXX_HAS_SSE1_1 - Success\n-- Performing Test CXX_HAS_SSE2_1\n-- Performing Test CXX_HAS_SSE2_1 - Success\n-- Performing Test CXX_HAS_SSE3_2 - Success\n-- Performing Test CXX_HAS_SSE4_1_1\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\n-- Performing Test CXX_HAS_SSE4_1_2\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\n-- Performing Test CXX_HAS_SSE4_2_1\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\n-- Performing Test CXX_HAS_SSE4_2_2\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\n-- Performing Test CXX_HAS_AVX_1\n-- Performing Test CXX_HAS_AVX_1 - Failed\n-- Performing Test CXX_HAS_AVX_2\n-- Performing Test CXX_HAS_AVX_2 - Success\n-- Performing Test CXX_HAS_AVX2_1\n-- Performing Test CXX_HAS_AVX2_1 - Failed\n-- Performing Test CXX_HAS_AVX2_2\n-- Performing Test CXX_HAS_AVX2_2 - Failed\n-- Performing Test CXX_HAS_AVX2_3\n-- Performing Test CXX_HAS_AVX2_3 - Failed\n-- SSE2 Found\n-- SSE3 Found\n-- AVX Found\n-- Performing Test HAS_C11_ATOMICS\n-- Performing Test HAS_C11_ATOMICS - Failed\n-- Performing Test HAS_MSC_ATOMICS\n-- Performing Test HAS_MSC_ATOMICS - Failed\n-- Performing Test HAS_GCC_ATOMICS\n-- Performing Test HAS_GCC_ATOMICS - Success\n-- Atomics: using GCC intrinsics\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_gnu_thread: not found\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\n--   Library gomp: -fopenmp\n--   Library pthread: /usr/lib64/libpthread.so\n--   Library m: /usr/lib64/libm.so\n--   Library dl: /usr/lib64/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - not found\n-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel: not found\n-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel: not found\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_gnu_thread: not found\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\n--   Library iomp5: /home/zhangruiqing01/tools/anaconda3/lib/libiomp5.so\n--   Library pthread: /usr/lib64/libpthread.so\n--   Library m: /usr/lib64/libm.so\n--   Library dl: /usr/lib64/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - found\n-- MKL library found\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\n-- Performing Test BLAS_F2C_FLOAT_WORKS\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\n-- Performing Test BLAS_USE_CBLAS_DOT\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\n-- Found a library with BLAS API (mkl).\n-- Found a library with LAPACK API. (mkl)\n-- Found CUDNN: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include  \n-- Found cuDNN: v6.0.21  (include: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include, library: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/lib64/libcudnn.so)\n-- Could NOT find NNPACK (missing:  NNPACK_INCLUDE_DIR NNPACK_LIBRARY CPUINFO_LIBRARY PTHREADPOOL_LIBRARY) \n-- NNPACK not found. Compiling without nNPACK support\n-- Using python found in /home/zhangruiqing01/tools/anaconda3/bin/python\n-- Looking for clock_gettime in rt\n-- Looking for clock_gettime in rt - found\n-- Looking for mmap\n-- Looking for mmap - found\n-- Looking for shm_open\n-- Looking for shm_open - found\n-- Looking for shm_unlink\n-- Looking for shm_unlink - found\n-- Looking for malloc_usable_size\n-- Looking for malloc_usable_size - found\n-- Performing Test C_HAS_THREAD\n-- Performing Test C_HAS_THREAD - Success\ndisable contrib because ATEN_NO_CONTRIB is set\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten\n/usr/bin/make64 MAC=64 install -j12\nScanning dependencies of target aten_files_are_generated\n[  0%] Generating ATen/CPUByteStorage.cpp, ATen/CPUByteStorage.h, ATen/CPUByteTensor.cpp, ATen/CPUByteTensor.h, ATen/CPUByteType.cpp, ATen/CPUByteType.h, ATen/CPUCharStorage.cpp, ATen/CPUCharStorage.h, ATen/CPUCharTensor.cpp, ATen/CPUCharTensor.h, ATen/CPUCharType.cpp, ATen/CPUCharType.h, ATen/CPUDoubleStorage.cpp, ATen/CPUDoubleStorage.h, ATen/CPUDoubleTensor.cpp, ATen/CPUDoubleTensor.h, ATen/CPUDoubleType.cpp, ATen/CPUDoubleType.h, ATen/CPUFloatStorage.cpp, ATen/CPUFloatStorage.h, ATen/CPUFloatTensor.cpp, ATen/CPUFloatTensor.h, ATen/CPUFloatType.cpp, ATen/CPUFloatType.h, ATen/CPUGenerator.h, ATen/CPUHalfStorage.cpp, ATen/CPUHalfStorage.h, ATen/CPUHalfTensor.cpp, ATen/CPUHalfTensor.h, ATen/CPUHalfType.cpp, ATen/CPUHalfType.h, ATen/CPUIntStorage.cpp, ATen/CPUIntStorage.h, ATen/CPUIntTensor.cpp, ATen/CPUIntTensor.h, ATen/CPUIntType.cpp, ATen/CPUIntType.h, ATen/CPULongStorage.cpp, ATen/CPULongStorage.h, ATen/CPULongTensor.cpp, ATen/CPULongTensor.h, ATen/CPULongType.cpp, ATen/CPULongType.h, ATen/CPUShortStorage.cpp, ATen/CPUShortStorage.h, ATen/CPUShortTensor.cpp, ATen/CPUShortTensor.h, ATen/CPUShortType.cpp, ATen/CPUShortType.h, ATen/CUDAByteStorage.cpp, ATen/CUDAByteStorage.h, ATen/CUDAByteTensor.cpp, ATen/CUDAByteTensor.h, ATen/CUDAByteType.cpp, ATen/CUDAByteType.h, ATen/CUDACharStorage.cpp, ATen/CUDACharStorage.h, ATen/CUDACharTensor.cpp, ATen/CUDACharTensor.h, ATen/CUDACharType.cpp, ATen/CUDACharType.h, ATen/CUDADoubleStorage.cpp, ATen/CUDADoubleStorage.h, ATen/CUDADoubleTensor.cpp, ATen/CUDADoubleTensor.h, ATen/CUDADoubleType.cpp, ATen/CUDADoubleType.h, ATen/CUDAFloatStorage.cpp, ATen/CUDAFloatStorage.h, ATen/CUDAFloatTensor.cpp, ATen/CUDAFloatTensor.h, ATen/CUDAFloatType.cpp, ATen/CUDAFloatType.h, ATen/CUDAGenerator.h, ATen/CUDAHalfStorage.cpp, ATen/CUDAHalfStorage.h, ATen/CUDAHalfTensor.cpp, ATen/CUDAHalfTensor.h, ATen/CUDAHalfType.cpp, ATen/CUDAHalfType.h, ATen/CUDAIntStorage.cpp, ATen/CUDAIntStorage.h, ATen/CUDAIntTensor.cpp, ATen/CUDAIntTensor.h, ATen/CUDAIntType.cpp, ATen/CUDAIntType.h, ATen/CUDALongStorage.cpp, ATen/CUDALongStorage.h, ATen/CUDALongTensor.cpp, ATen/CUDALongTensor.h, ATen/CUDALongType.cpp, ATen/CUDALongType.h, ATen/CUDAShortStorage.cpp, ATen/CUDAShortStorage.h, ATen/CUDAShortTensor.cpp, ATen/CUDAShortTensor.h, ATen/CUDAShortType.cpp, ATen/CUDAShortType.h, ATen/Copy.cpp, ATen/Declarations.yaml, ATen/Functions.h, ATen/NativeFunctions.h, ATen/SparseCPUByteTensor.cpp, ATen/SparseCPUByteTensor.h, ATen/SparseCPUByteType.cpp, ATen/SparseCPUByteType.h, ATen/SparseCPUCharTensor.cpp, ATen/SparseCPUCharTensor.h, ATen/SparseCPUCharType.cpp, ATen/SparseCPUCharType.h, ATen/SparseCPUDoubleTensor.cpp, ATen/SparseCPUDoubleTensor.h, ATen/SparseCPUDoubleType.cpp, ATen/SparseCPUDoubleType.h, ATen/SparseCPUFloatTensor.cpp, ATen/SparseCPUFloatTensor.h, ATen/SparseCPUFloatType.cpp, ATen/SparseCPUFloatType.h, ATen/SparseCPUIntTensor.cpp, ATen/SparseCPUIntTensor.h, ATen/SparseCPUIntType.cpp, ATen/SparseCPUIntType.h, ATen/SparseCPULongTensor.cpp, ATen/SparseCPULongTensor.h, ATen/SparseCPULongType.cpp, ATen/SparseCPULongType.h, ATen/SparseCPUShortTensor.cpp, ATen/SparseCPUShortTensor.h, ATen/SparseCPUShortType.cpp, ATen/SparseCPUShortType.h, ATen/SparseCUDAByteTensor.cpp, ATen/SparseCUDAByteTensor.h, ATen/SparseCUDAByteType.cpp, ATen/SparseCUDAByteType.h, ATen/SparseCUDACharTensor.cpp, ATen/SparseCUDACharTensor.h, ATen/SparseCUDACharType.cpp, ATen/SparseCUDACharType.h, ATen/SparseCUDADoubleTensor.cpp, ATen/SparseCUDADoubleTensor.h, ATen/SparseCUDADoubleType.cpp, ATen/SparseCUDADoubleType.h, ATen/SparseCUDAFloatTensor.cpp, ATen/SparseCUDAFloatTensor.h, ATen/SparseCUDAFloatType.cpp, ATen/SparseCUDAFloatType.h, ATen/SparseCUDAIntTensor.cpp, ATen/SparseCUDAIntTensor.h, ATen/SparseCUDAIntType.cpp, ATen/SparseCUDAIntType.h, ATen/SparseCUDALongTensor.cpp, ATen/SparseCUDALongTensor.h, ATen/SparseCUDALongType.cpp, ATen/SparseCUDALongType.h, ATen/SparseCUDAShortTensor.cpp, ATen/SparseCUDAShortTensor.h, ATen/SparseCUDAShortType.cpp, ATen/SparseCUDAShortType.h, ATen/Tensor.h, ATen/TensorMethods.h, ATen/Type.cpp, ATen/Type.h\n[  0%] Built target aten_files_are_generated\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCReduceApplyUtils.cu.o\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCSleep.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorage.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorageCopy.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensor.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorCopy.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMath.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathBlas.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathMagma.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathPairwise.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathReduce.cu.o\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"int\" to \"__half\"\n\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n2 errors detected in the compilation of \"/tmp/tmpxft_000027da_00000000-7_THCBlas.cpp1.ii\".\nCMake Error at ATen_generated_THCBlas.cu.o.cmake:267 (message):\n  Error generating file\n  /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten/src/ATen/CMakeFiles/ATen.dir/__/THC/./ATen_generated_THCBlas.cu.o\n\n\nmake64[2]: *** [src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o] Error 1\nmake64[2]: *** Waiting for unfinished jobs....\nmake64[1]: *** [src/ATen/CMakeFiles/ATen.dir/all] Error 2\nmake64: *** [all] Error 2\n[zhangruiqing01@yq01-idl-gpu-offline41.yq01.baidu.com:~/tools/py-torch-install/pytorch/pytorch]\n$ \n</code></pre>", "body_text": "Same problem here.\nCUDA: v7.5\nCUDNN: v6.0\nrunning install\nrunning build_deps\n-- The C compiler identification is GNU 4.8.5\n-- The CXX compiler identification is GNU 4.8.5\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Checking if C linker supports --verbose\n-- Checking if C linker supports --verbose - yes\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Checking if CXX linker supports --verbose\n-- Checking if CXX linker supports --verbose - yes\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"7.0\") \n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl\n/usr/bin/make64 MAC=64 install\nScanning dependencies of target nccl\n[100%] Generating lib/libnccl.so\n/usr/bin/make64 MAC=64 -j 12\nGrabbing  src/nccl.h                          > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/include/nccl.h\nCompiling src/libwrap.cu                      > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/libwrap.o\nCompiling src/core.cu                         > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/core.o\nCompiling src/all_gather.cu                   > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_gather.o\nCompiling src/all_reduce.cu                   > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_reduce.o\nCompiling src/broadcast.cu                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/broadcast.o\nCompiling src/reduce.cu                       > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce.o\nCompiling src/reduce_scatter.cu               > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce_scatter.o\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nLinking   libnccl.so.1.3.5                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl.so.1.3.5\nArchiving libnccl_static.a                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl_static.a\n[100%] Built target nccl\nInstall the project...\n-- Install configuration: \"Release\"\n-- Installing: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/tmp_install/include/nccl.h\n-- The C compiler identification is GNU 4.8.5\n-- The CXX compiler identification is GNU 4.8.5\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Checking if C linker supports --verbose\n-- Checking if C linker supports --verbose - yes\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Checking if CXX linker supports --verbose\n-- Checking if CXX linker supports --verbose - yes\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"5.5\") \n-- Autodetected CUDA architecture(s): 3.5 3.5 3.5 3.5\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n-- Try OpenMP C flag = [-fopenmp]\n-- Performing Test OpenMP_FLAG_DETECTED\n-- Performing Test OpenMP_FLAG_DETECTED - Success\n-- Try OpenMP CXX flag = [-fopenmp]\n-- Performing Test OpenMP_FLAG_DETECTED\n-- Performing Test OpenMP_FLAG_DETECTED - Success\n-- Found OpenMP: -fopenmp  \n-- Compiling with OpenMP support\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\n-- Compiling with MAGMA support\n-- MAGMA INCLUDE DIRECTORIES: /home/zhangruiqing01/tools/anaconda3/include\n-- MAGMA LIBRARIES: /home/zhangruiqing01/tools/anaconda3/lib/libmagma.a\n-- MAGMA V2 check: 1\n-- Could not find hardware support for NEON on this machine.\n-- No OMAP3 processor on this machine.\n-- No OMAP4 processor on this machine.\n-- Looking for cpuid.h\n-- Looking for cpuid.h - found\n-- Performing Test HAVE_GCC_GET_CPUID\n-- Performing Test HAVE_GCC_GET_CPUID - Success\n-- Performing Test NO_GCC_EBX_FPIC_BUG\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\n-- Performing Test C_HAS_SSE1_1\n-- Performing Test C_HAS_SSE1_1 - Success\n-- Performing Test C_HAS_SSE2_1\n-- Performing Test C_HAS_SSE2_1 - Success\n-- Performing Test C_HAS_SSE3_1\n-- Performing Test C_HAS_SSE3_1 - Failed\n-- Performing Test C_HAS_SSE3_2\n-- Performing Test C_HAS_SSE3_2 - Success\n-- Performing Test C_HAS_SSE4_1_1\n-- Performing Test C_HAS_SSE4_1_1 - Failed\n-- Performing Test C_HAS_SSE4_1_2\n-- Performing Test C_HAS_SSE4_1_2 - Success\n-- Performing Test C_HAS_SSE4_2_1\n-- Performing Test C_HAS_SSE4_2_1 - Failed\n-- Performing Test C_HAS_SSE4_2_2\n-- Performing Test C_HAS_SSE4_2_2 - Success\n-- Performing Test C_HAS_AVX_1\n-- Performing Test C_HAS_AVX_1 - Failed\n-- Performing Test C_HAS_AVX_2\n-- Performing Test C_HAS_AVX_2 - Success\n-- Performing Test C_HAS_AVX2_1\n-- Performing Test C_HAS_AVX2_1 - Failed\n-- Performing Test C_HAS_AVX2_2\n-- Performing Test C_HAS_AVX2_2 - Failed\n-- Performing Test C_HAS_AVX2_3\n-- Performing Test C_HAS_AVX2_3 - Failed\n-- Performing Test CXX_HAS_SSE1_1\n-- Performing Test CXX_HAS_SSE1_1 - Success\n-- Performing Test CXX_HAS_SSE2_1\n-- Performing Test CXX_HAS_SSE2_1 - Success\n-- Performing Test CXX_HAS_SSE3_2 - Success\n-- Performing Test CXX_HAS_SSE4_1_1\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\n-- Performing Test CXX_HAS_SSE4_1_2\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\n-- Performing Test CXX_HAS_SSE4_2_1\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\n-- Performing Test CXX_HAS_SSE4_2_2\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\n-- Performing Test CXX_HAS_AVX_1\n-- Performing Test CXX_HAS_AVX_1 - Failed\n-- Performing Test CXX_HAS_AVX_2\n-- Performing Test CXX_HAS_AVX_2 - Success\n-- Performing Test CXX_HAS_AVX2_1\n-- Performing Test CXX_HAS_AVX2_1 - Failed\n-- Performing Test CXX_HAS_AVX2_2\n-- Performing Test CXX_HAS_AVX2_2 - Failed\n-- Performing Test CXX_HAS_AVX2_3\n-- Performing Test CXX_HAS_AVX2_3 - Failed\n-- SSE2 Found\n-- SSE3 Found\n-- AVX Found\n-- Performing Test HAS_C11_ATOMICS\n-- Performing Test HAS_C11_ATOMICS - Failed\n-- Performing Test HAS_MSC_ATOMICS\n-- Performing Test HAS_MSC_ATOMICS - Failed\n-- Performing Test HAS_GCC_ATOMICS\n-- Performing Test HAS_GCC_ATOMICS - Success\n-- Atomics: using GCC intrinsics\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_gnu_thread: not found\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\n--   Library gomp: -fopenmp\n--   Library pthread: /usr/lib64/libpthread.so\n--   Library m: /usr/lib64/libm.so\n--   Library dl: /usr/lib64/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - not found\n-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel: not found\n-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_intel: not found\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf_lp64: not found\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_gf: not found\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_gnu_thread: not found\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\n--   Library iomp5: /home/zhangruiqing01/tools/anaconda3/lib/libiomp5.so\n--   Library pthread: /usr/lib64/libpthread.so\n--   Library m: /usr/lib64/libm.so\n--   Library dl: /usr/lib64/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - found\n-- MKL library found\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\n-- Performing Test BLAS_F2C_FLOAT_WORKS\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\n-- Performing Test BLAS_USE_CBLAS_DOT\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\n-- Found a library with BLAS API (mkl).\n-- Found a library with LAPACK API. (mkl)\n-- Found CUDNN: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include  \n-- Found cuDNN: v6.0.21  (include: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include, library: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/lib64/libcudnn.so)\n-- Could NOT find NNPACK (missing:  NNPACK_INCLUDE_DIR NNPACK_LIBRARY CPUINFO_LIBRARY PTHREADPOOL_LIBRARY) \n-- NNPACK not found. Compiling without nNPACK support\n-- Using python found in /home/zhangruiqing01/tools/anaconda3/bin/python\n-- Looking for clock_gettime in rt\n-- Looking for clock_gettime in rt - found\n-- Looking for mmap\n-- Looking for mmap - found\n-- Looking for shm_open\n-- Looking for shm_open - found\n-- Looking for shm_unlink\n-- Looking for shm_unlink - found\n-- Looking for malloc_usable_size\n-- Looking for malloc_usable_size - found\n-- Performing Test C_HAS_THREAD\n-- Performing Test C_HAS_THREAD - Success\ndisable contrib because ATEN_NO_CONTRIB is set\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten\n/usr/bin/make64 MAC=64 install -j12\nScanning dependencies of target aten_files_are_generated\n[  0%] Generating ATen/CPUByteStorage.cpp, ATen/CPUByteStorage.h, ATen/CPUByteTensor.cpp, ATen/CPUByteTensor.h, ATen/CPUByteType.cpp, ATen/CPUByteType.h, ATen/CPUCharStorage.cpp, ATen/CPUCharStorage.h, ATen/CPUCharTensor.cpp, ATen/CPUCharTensor.h, ATen/CPUCharType.cpp, ATen/CPUCharType.h, ATen/CPUDoubleStorage.cpp, ATen/CPUDoubleStorage.h, ATen/CPUDoubleTensor.cpp, ATen/CPUDoubleTensor.h, ATen/CPUDoubleType.cpp, ATen/CPUDoubleType.h, ATen/CPUFloatStorage.cpp, ATen/CPUFloatStorage.h, ATen/CPUFloatTensor.cpp, ATen/CPUFloatTensor.h, ATen/CPUFloatType.cpp, ATen/CPUFloatType.h, ATen/CPUGenerator.h, ATen/CPUHalfStorage.cpp, ATen/CPUHalfStorage.h, ATen/CPUHalfTensor.cpp, ATen/CPUHalfTensor.h, ATen/CPUHalfType.cpp, ATen/CPUHalfType.h, ATen/CPUIntStorage.cpp, ATen/CPUIntStorage.h, ATen/CPUIntTensor.cpp, ATen/CPUIntTensor.h, ATen/CPUIntType.cpp, ATen/CPUIntType.h, ATen/CPULongStorage.cpp, ATen/CPULongStorage.h, ATen/CPULongTensor.cpp, ATen/CPULongTensor.h, ATen/CPULongType.cpp, ATen/CPULongType.h, ATen/CPUShortStorage.cpp, ATen/CPUShortStorage.h, ATen/CPUShortTensor.cpp, ATen/CPUShortTensor.h, ATen/CPUShortType.cpp, ATen/CPUShortType.h, ATen/CUDAByteStorage.cpp, ATen/CUDAByteStorage.h, ATen/CUDAByteTensor.cpp, ATen/CUDAByteTensor.h, ATen/CUDAByteType.cpp, ATen/CUDAByteType.h, ATen/CUDACharStorage.cpp, ATen/CUDACharStorage.h, ATen/CUDACharTensor.cpp, ATen/CUDACharTensor.h, ATen/CUDACharType.cpp, ATen/CUDACharType.h, ATen/CUDADoubleStorage.cpp, ATen/CUDADoubleStorage.h, ATen/CUDADoubleTensor.cpp, ATen/CUDADoubleTensor.h, ATen/CUDADoubleType.cpp, ATen/CUDADoubleType.h, ATen/CUDAFloatStorage.cpp, ATen/CUDAFloatStorage.h, ATen/CUDAFloatTensor.cpp, ATen/CUDAFloatTensor.h, ATen/CUDAFloatType.cpp, ATen/CUDAFloatType.h, ATen/CUDAGenerator.h, ATen/CUDAHalfStorage.cpp, ATen/CUDAHalfStorage.h, ATen/CUDAHalfTensor.cpp, ATen/CUDAHalfTensor.h, ATen/CUDAHalfType.cpp, ATen/CUDAHalfType.h, ATen/CUDAIntStorage.cpp, ATen/CUDAIntStorage.h, ATen/CUDAIntTensor.cpp, ATen/CUDAIntTensor.h, ATen/CUDAIntType.cpp, ATen/CUDAIntType.h, ATen/CUDALongStorage.cpp, ATen/CUDALongStorage.h, ATen/CUDALongTensor.cpp, ATen/CUDALongTensor.h, ATen/CUDALongType.cpp, ATen/CUDALongType.h, ATen/CUDAShortStorage.cpp, ATen/CUDAShortStorage.h, ATen/CUDAShortTensor.cpp, ATen/CUDAShortTensor.h, ATen/CUDAShortType.cpp, ATen/CUDAShortType.h, ATen/Copy.cpp, ATen/Declarations.yaml, ATen/Functions.h, ATen/NativeFunctions.h, ATen/SparseCPUByteTensor.cpp, ATen/SparseCPUByteTensor.h, ATen/SparseCPUByteType.cpp, ATen/SparseCPUByteType.h, ATen/SparseCPUCharTensor.cpp, ATen/SparseCPUCharTensor.h, ATen/SparseCPUCharType.cpp, ATen/SparseCPUCharType.h, ATen/SparseCPUDoubleTensor.cpp, ATen/SparseCPUDoubleTensor.h, ATen/SparseCPUDoubleType.cpp, ATen/SparseCPUDoubleType.h, ATen/SparseCPUFloatTensor.cpp, ATen/SparseCPUFloatTensor.h, ATen/SparseCPUFloatType.cpp, ATen/SparseCPUFloatType.h, ATen/SparseCPUIntTensor.cpp, ATen/SparseCPUIntTensor.h, ATen/SparseCPUIntType.cpp, ATen/SparseCPUIntType.h, ATen/SparseCPULongTensor.cpp, ATen/SparseCPULongTensor.h, ATen/SparseCPULongType.cpp, ATen/SparseCPULongType.h, ATen/SparseCPUShortTensor.cpp, ATen/SparseCPUShortTensor.h, ATen/SparseCPUShortType.cpp, ATen/SparseCPUShortType.h, ATen/SparseCUDAByteTensor.cpp, ATen/SparseCUDAByteTensor.h, ATen/SparseCUDAByteType.cpp, ATen/SparseCUDAByteType.h, ATen/SparseCUDACharTensor.cpp, ATen/SparseCUDACharTensor.h, ATen/SparseCUDACharType.cpp, ATen/SparseCUDACharType.h, ATen/SparseCUDADoubleTensor.cpp, ATen/SparseCUDADoubleTensor.h, ATen/SparseCUDADoubleType.cpp, ATen/SparseCUDADoubleType.h, ATen/SparseCUDAFloatTensor.cpp, ATen/SparseCUDAFloatTensor.h, ATen/SparseCUDAFloatType.cpp, ATen/SparseCUDAFloatType.h, ATen/SparseCUDAIntTensor.cpp, ATen/SparseCUDAIntTensor.h, ATen/SparseCUDAIntType.cpp, ATen/SparseCUDAIntType.h, ATen/SparseCUDALongTensor.cpp, ATen/SparseCUDALongTensor.h, ATen/SparseCUDALongType.cpp, ATen/SparseCUDALongType.h, ATen/SparseCUDAShortTensor.cpp, ATen/SparseCUDAShortTensor.h, ATen/SparseCUDAShortType.cpp, ATen/SparseCUDAShortType.h, ATen/Tensor.h, ATen/TensorMethods.h, ATen/Type.cpp, ATen/Type.h\n[  0%] Built target aten_files_are_generated\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCReduceApplyUtils.cu.o\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCSleep.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorage.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorageCopy.cu.o\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensor.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorCopy.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMath.cu.o\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathBlas.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathMagma.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathPairwise.cu.o\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathReduce.cu.o\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"int\" to \"__half\"\n\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"float\" to \"__half\"\n\n2 errors detected in the compilation of \"/tmp/tmpxft_000027da_00000000-7_THCBlas.cpp1.ii\".\nCMake Error at ATen_generated_THCBlas.cu.o.cmake:267 (message):\n  Error generating file\n  /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten/src/ATen/CMakeFiles/ATen.dir/__/THC/./ATen_generated_THCBlas.cu.o\n\n\nmake64[2]: *** [src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o] Error 1\nmake64[2]: *** Waiting for unfinished jobs....\nmake64[1]: *** [src/ATen/CMakeFiles/ATen.dir/all] Error 2\nmake64: *** [all] Error 2\n[zhangruiqing01@yq01-idl-gpu-offline41.yq01.baidu.com:~/tools/py-torch-install/pytorch/pytorch]\n$", "body": "Same problem here. \r\n\r\nCUDA: v7.5\r\nCUDNN: v6.0\r\n\r\n```\r\nrunning install\r\nrunning build_deps\r\n-- The C compiler identification is GNU 4.8.5\r\n-- The CXX compiler identification is GNU 4.8.5\r\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\r\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Checking if C linker supports --verbose\r\n-- Checking if C linker supports --verbose - yes\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\r\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Checking if CXX linker supports --verbose\r\n-- Checking if CXX linker supports --verbose - yes\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"7.0\") \r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl\r\n/usr/bin/make64 MAC=64 install\r\nScanning dependencies of target nccl\r\n[100%] Generating lib/libnccl.so\r\n/usr/bin/make64 MAC=64 -j 12\r\nGrabbing  src/nccl.h                          > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/include/nccl.h\r\nCompiling src/libwrap.cu                      > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/libwrap.o\r\nCompiling src/core.cu                         > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/core.o\r\nCompiling src/all_gather.cu                   > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_gather.o\r\nCompiling src/all_reduce.cu                   > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/all_reduce.o\r\nCompiling src/broadcast.cu                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/broadcast.o\r\nCompiling src/reduce.cu                       > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce.o\r\nCompiling src/reduce_scatter.cu               > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/obj/reduce_scatter.o\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nLinking   libnccl.so.1.3.5                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl.so.1.3.5\r\nArchiving libnccl_static.a                    > /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/nccl/lib/libnccl_static.a\r\n[100%] Built target nccl\r\nInstall the project...\r\n-- Install configuration: \"Release\"\r\n-- Installing: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/tmp_install/include/nccl.h\r\n-- The C compiler identification is GNU 4.8.5\r\n-- The CXX compiler identification is GNU 4.8.5\r\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc\r\n-- Check for working C compiler: /home/zhangruiqing01/tools/anaconda3/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Checking if C linker supports --verbose\r\n-- Checking if C linker supports --verbose - yes\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++\r\n-- Check for working CXX compiler: /home/zhangruiqing01/tools/anaconda3/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Checking if CXX linker supports --verbose\r\n-- Checking if CXX linker supports --verbose - yes\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Found CUDA: /usr/local/cuda (found suitable version \"7.5\", minimum required is \"5.5\") \r\n-- Autodetected CUDA architecture(s): 3.5 3.5 3.5 3.5\r\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\r\n-- Removing -DNDEBUG from compile flags\r\n-- Try OpenMP C flag = [-fopenmp]\r\n-- Performing Test OpenMP_FLAG_DETECTED\r\n-- Performing Test OpenMP_FLAG_DETECTED - Success\r\n-- Try OpenMP CXX flag = [-fopenmp]\r\n-- Performing Test OpenMP_FLAG_DETECTED\r\n-- Performing Test OpenMP_FLAG_DETECTED - Success\r\n-- Found OpenMP: -fopenmp  \r\n-- Compiling with OpenMP support\r\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\r\n-- Compiling with MAGMA support\r\n-- MAGMA INCLUDE DIRECTORIES: /home/zhangruiqing01/tools/anaconda3/include\r\n-- MAGMA LIBRARIES: /home/zhangruiqing01/tools/anaconda3/lib/libmagma.a\r\n-- MAGMA V2 check: 1\r\n-- Could not find hardware support for NEON on this machine.\r\n-- No OMAP3 processor on this machine.\r\n-- No OMAP4 processor on this machine.\r\n-- Looking for cpuid.h\r\n-- Looking for cpuid.h - found\r\n-- Performing Test HAVE_GCC_GET_CPUID\r\n-- Performing Test HAVE_GCC_GET_CPUID - Success\r\n-- Performing Test NO_GCC_EBX_FPIC_BUG\r\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\r\n-- Performing Test C_HAS_SSE1_1\r\n-- Performing Test C_HAS_SSE1_1 - Success\r\n-- Performing Test C_HAS_SSE2_1\r\n-- Performing Test C_HAS_SSE2_1 - Success\r\n-- Performing Test C_HAS_SSE3_1\r\n-- Performing Test C_HAS_SSE3_1 - Failed\r\n-- Performing Test C_HAS_SSE3_2\r\n-- Performing Test C_HAS_SSE3_2 - Success\r\n-- Performing Test C_HAS_SSE4_1_1\r\n-- Performing Test C_HAS_SSE4_1_1 - Failed\r\n-- Performing Test C_HAS_SSE4_1_2\r\n-- Performing Test C_HAS_SSE4_1_2 - Success\r\n-- Performing Test C_HAS_SSE4_2_1\r\n-- Performing Test C_HAS_SSE4_2_1 - Failed\r\n-- Performing Test C_HAS_SSE4_2_2\r\n-- Performing Test C_HAS_SSE4_2_2 - Success\r\n-- Performing Test C_HAS_AVX_1\r\n-- Performing Test C_HAS_AVX_1 - Failed\r\n-- Performing Test C_HAS_AVX_2\r\n-- Performing Test C_HAS_AVX_2 - Success\r\n-- Performing Test C_HAS_AVX2_1\r\n-- Performing Test C_HAS_AVX2_1 - Failed\r\n-- Performing Test C_HAS_AVX2_2\r\n-- Performing Test C_HAS_AVX2_2 - Failed\r\n-- Performing Test C_HAS_AVX2_3\r\n-- Performing Test C_HAS_AVX2_3 - Failed\r\n-- Performing Test CXX_HAS_SSE1_1\r\n-- Performing Test CXX_HAS_SSE1_1 - Success\r\n-- Performing Test CXX_HAS_SSE2_1\r\n-- Performing Test CXX_HAS_SSE2_1 - Success\r\n-- Performing Test CXX_HAS_SSE3_2 - Success\r\n-- Performing Test CXX_HAS_SSE4_1_1\r\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\r\n-- Performing Test CXX_HAS_SSE4_1_2\r\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\r\n-- Performing Test CXX_HAS_SSE4_2_1\r\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\r\n-- Performing Test CXX_HAS_SSE4_2_2\r\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\r\n-- Performing Test CXX_HAS_AVX_1\r\n-- Performing Test CXX_HAS_AVX_1 - Failed\r\n-- Performing Test CXX_HAS_AVX_2\r\n-- Performing Test CXX_HAS_AVX_2 - Success\r\n-- Performing Test CXX_HAS_AVX2_1\r\n-- Performing Test CXX_HAS_AVX2_1 - Failed\r\n-- Performing Test CXX_HAS_AVX2_2\r\n-- Performing Test CXX_HAS_AVX2_2 - Failed\r\n-- Performing Test CXX_HAS_AVX2_3\r\n-- Performing Test CXX_HAS_AVX2_3 - Failed\r\n-- SSE2 Found\r\n-- SSE3 Found\r\n-- AVX Found\r\n-- Performing Test HAS_C11_ATOMICS\r\n-- Performing Test HAS_C11_ATOMICS - Failed\r\n-- Performing Test HAS_MSC_ATOMICS\r\n-- Performing Test HAS_MSC_ATOMICS - Failed\r\n-- Performing Test HAS_GCC_ATOMICS\r\n-- Performing Test HAS_GCC_ATOMICS - Success\r\n-- Atomics: using GCC intrinsics\r\n-- Looking for sys/types.h\r\n-- Looking for sys/types.h - found\r\n-- Looking for stdint.h\r\n-- Looking for stdint.h - found\r\n-- Looking for stddef.h\r\n-- Looking for stddef.h - found\r\n-- Check size of void*\r\n-- Check size of void* - done\r\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf_lp64: not found\r\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf_lp64: not found\r\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf: not found\r\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf: not found\r\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\r\n--   Library mkl_gnu_thread: not found\r\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\r\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\r\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\r\n--   Library gomp: -fopenmp\r\n--   Library pthread: /usr/lib64/libpthread.so\r\n--   Library m: /usr/lib64/libm.so\r\n--   Library dl: /usr/lib64/libdl.so\r\n-- Looking for cblas_sgemm\r\n-- Looking for cblas_sgemm - not found\r\n-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_intel: not found\r\n-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_intel: not found\r\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_gf_lp64: not found\r\n-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_gf_lp64: not found\r\n-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_gf: not found\r\n-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_gf: not found\r\n-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\r\n--   Library mkl_gnu_thread: not found\r\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]\r\n--   Library mkl_intel_lp64: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_lp64.so\r\n--   Library mkl_intel_thread: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_intel_thread.so\r\n--   Library mkl_core: /home/zhangruiqing01/tools/anaconda3/lib/libmkl_core.so\r\n--   Library iomp5: /home/zhangruiqing01/tools/anaconda3/lib/libiomp5.so\r\n--   Library pthread: /usr/lib64/libpthread.so\r\n--   Library m: /usr/lib64/libm.so\r\n--   Library dl: /usr/lib64/libdl.so\r\n-- Looking for cblas_sgemm\r\n-- Looking for cblas_sgemm - found\r\n-- MKL library found\r\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\r\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\r\n-- Performing Test BLAS_F2C_FLOAT_WORKS\r\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\r\n-- Performing Test BLAS_USE_CBLAS_DOT\r\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\r\n-- Found a library with BLAS API (mkl).\r\n-- Found a library with LAPACK API. (mkl)\r\n-- Found CUDNN: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include  \r\n-- Found cuDNN: v6.0.21  (include: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/include, library: /home/zhangruiqing01/tools/py-torch-install/cudnn6.0/lib64/libcudnn.so)\r\n-- Could NOT find NNPACK (missing:  NNPACK_INCLUDE_DIR NNPACK_LIBRARY CPUINFO_LIBRARY PTHREADPOOL_LIBRARY) \r\n-- NNPACK not found. Compiling without nNPACK support\r\n-- Using python found in /home/zhangruiqing01/tools/anaconda3/bin/python\r\n-- Looking for clock_gettime in rt\r\n-- Looking for clock_gettime in rt - found\r\n-- Looking for mmap\r\n-- Looking for mmap - found\r\n-- Looking for shm_open\r\n-- Looking for shm_open - found\r\n-- Looking for shm_unlink\r\n-- Looking for shm_unlink - found\r\n-- Looking for malloc_usable_size\r\n-- Looking for malloc_usable_size - found\r\n-- Performing Test C_HAS_THREAD\r\n-- Performing Test C_HAS_THREAD - Success\r\ndisable contrib because ATEN_NO_CONTRIB is set\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten\r\n/usr/bin/make64 MAC=64 install -j12\r\nScanning dependencies of target aten_files_are_generated\r\n[  0%] Generating ATen/CPUByteStorage.cpp, ATen/CPUByteStorage.h, ATen/CPUByteTensor.cpp, ATen/CPUByteTensor.h, ATen/CPUByteType.cpp, ATen/CPUByteType.h, ATen/CPUCharStorage.cpp, ATen/CPUCharStorage.h, ATen/CPUCharTensor.cpp, ATen/CPUCharTensor.h, ATen/CPUCharType.cpp, ATen/CPUCharType.h, ATen/CPUDoubleStorage.cpp, ATen/CPUDoubleStorage.h, ATen/CPUDoubleTensor.cpp, ATen/CPUDoubleTensor.h, ATen/CPUDoubleType.cpp, ATen/CPUDoubleType.h, ATen/CPUFloatStorage.cpp, ATen/CPUFloatStorage.h, ATen/CPUFloatTensor.cpp, ATen/CPUFloatTensor.h, ATen/CPUFloatType.cpp, ATen/CPUFloatType.h, ATen/CPUGenerator.h, ATen/CPUHalfStorage.cpp, ATen/CPUHalfStorage.h, ATen/CPUHalfTensor.cpp, ATen/CPUHalfTensor.h, ATen/CPUHalfType.cpp, ATen/CPUHalfType.h, ATen/CPUIntStorage.cpp, ATen/CPUIntStorage.h, ATen/CPUIntTensor.cpp, ATen/CPUIntTensor.h, ATen/CPUIntType.cpp, ATen/CPUIntType.h, ATen/CPULongStorage.cpp, ATen/CPULongStorage.h, ATen/CPULongTensor.cpp, ATen/CPULongTensor.h, ATen/CPULongType.cpp, ATen/CPULongType.h, ATen/CPUShortStorage.cpp, ATen/CPUShortStorage.h, ATen/CPUShortTensor.cpp, ATen/CPUShortTensor.h, ATen/CPUShortType.cpp, ATen/CPUShortType.h, ATen/CUDAByteStorage.cpp, ATen/CUDAByteStorage.h, ATen/CUDAByteTensor.cpp, ATen/CUDAByteTensor.h, ATen/CUDAByteType.cpp, ATen/CUDAByteType.h, ATen/CUDACharStorage.cpp, ATen/CUDACharStorage.h, ATen/CUDACharTensor.cpp, ATen/CUDACharTensor.h, ATen/CUDACharType.cpp, ATen/CUDACharType.h, ATen/CUDADoubleStorage.cpp, ATen/CUDADoubleStorage.h, ATen/CUDADoubleTensor.cpp, ATen/CUDADoubleTensor.h, ATen/CUDADoubleType.cpp, ATen/CUDADoubleType.h, ATen/CUDAFloatStorage.cpp, ATen/CUDAFloatStorage.h, ATen/CUDAFloatTensor.cpp, ATen/CUDAFloatTensor.h, ATen/CUDAFloatType.cpp, ATen/CUDAFloatType.h, ATen/CUDAGenerator.h, ATen/CUDAHalfStorage.cpp, ATen/CUDAHalfStorage.h, ATen/CUDAHalfTensor.cpp, ATen/CUDAHalfTensor.h, ATen/CUDAHalfType.cpp, ATen/CUDAHalfType.h, ATen/CUDAIntStorage.cpp, ATen/CUDAIntStorage.h, ATen/CUDAIntTensor.cpp, ATen/CUDAIntTensor.h, ATen/CUDAIntType.cpp, ATen/CUDAIntType.h, ATen/CUDALongStorage.cpp, ATen/CUDALongStorage.h, ATen/CUDALongTensor.cpp, ATen/CUDALongTensor.h, ATen/CUDALongType.cpp, ATen/CUDALongType.h, ATen/CUDAShortStorage.cpp, ATen/CUDAShortStorage.h, ATen/CUDAShortTensor.cpp, ATen/CUDAShortTensor.h, ATen/CUDAShortType.cpp, ATen/CUDAShortType.h, ATen/Copy.cpp, ATen/Declarations.yaml, ATen/Functions.h, ATen/NativeFunctions.h, ATen/SparseCPUByteTensor.cpp, ATen/SparseCPUByteTensor.h, ATen/SparseCPUByteType.cpp, ATen/SparseCPUByteType.h, ATen/SparseCPUCharTensor.cpp, ATen/SparseCPUCharTensor.h, ATen/SparseCPUCharType.cpp, ATen/SparseCPUCharType.h, ATen/SparseCPUDoubleTensor.cpp, ATen/SparseCPUDoubleTensor.h, ATen/SparseCPUDoubleType.cpp, ATen/SparseCPUDoubleType.h, ATen/SparseCPUFloatTensor.cpp, ATen/SparseCPUFloatTensor.h, ATen/SparseCPUFloatType.cpp, ATen/SparseCPUFloatType.h, ATen/SparseCPUIntTensor.cpp, ATen/SparseCPUIntTensor.h, ATen/SparseCPUIntType.cpp, ATen/SparseCPUIntType.h, ATen/SparseCPULongTensor.cpp, ATen/SparseCPULongTensor.h, ATen/SparseCPULongType.cpp, ATen/SparseCPULongType.h, ATen/SparseCPUShortTensor.cpp, ATen/SparseCPUShortTensor.h, ATen/SparseCPUShortType.cpp, ATen/SparseCPUShortType.h, ATen/SparseCUDAByteTensor.cpp, ATen/SparseCUDAByteTensor.h, ATen/SparseCUDAByteType.cpp, ATen/SparseCUDAByteType.h, ATen/SparseCUDACharTensor.cpp, ATen/SparseCUDACharTensor.h, ATen/SparseCUDACharType.cpp, ATen/SparseCUDACharType.h, ATen/SparseCUDADoubleTensor.cpp, ATen/SparseCUDADoubleTensor.h, ATen/SparseCUDADoubleType.cpp, ATen/SparseCUDADoubleType.h, ATen/SparseCUDAFloatTensor.cpp, ATen/SparseCUDAFloatTensor.h, ATen/SparseCUDAFloatType.cpp, ATen/SparseCUDAFloatType.h, ATen/SparseCUDAIntTensor.cpp, ATen/SparseCUDAIntTensor.h, ATen/SparseCUDAIntType.cpp, ATen/SparseCUDAIntType.h, ATen/SparseCUDALongTensor.cpp, ATen/SparseCUDALongTensor.h, ATen/SparseCUDALongType.cpp, ATen/SparseCUDALongType.h, ATen/SparseCUDAShortTensor.cpp, ATen/SparseCUDAShortTensor.h, ATen/SparseCUDAShortType.cpp, ATen/SparseCUDAShortType.h, ATen/Tensor.h, ATen/TensorMethods.h, ATen/Type.cpp, ATen/Type.h\r\n[  0%] Built target aten_files_are_generated\r\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCReduceApplyUtils.cu.o\r\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o\r\n[  0%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCSleep.cu.o\r\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorage.cu.o\r\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorageCopy.cu.o\r\n[  1%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensor.cu.o\r\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorCopy.cu.o\r\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMath.cu.o\r\n[  2%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathBlas.cu.o\r\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathMagma.cu.o\r\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathPairwise.cu.o\r\n[  3%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathReduce.cu.o\r\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"int\" to \"__half\"\r\n\r\n/home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/aten/src/THC/THCBlas.cu(77): error: no suitable constructor exists to convert from \"float\" to \"__half\"\r\n\r\n2 errors detected in the compilation of \"/tmp/tmpxft_000027da_00000000-7_THCBlas.cpp1.ii\".\r\nCMake Error at ATen_generated_THCBlas.cu.o.cmake:267 (message):\r\n  Error generating file\r\n  /home/zhangruiqing01/tools/py-torch-install/pytorch/pytorch/torch/lib/build/aten/src/ATen/CMakeFiles/ATen.dir/__/THC/./ATen_generated_THCBlas.cu.o\r\n\r\n\r\nmake64[2]: *** [src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o] Error 1\r\nmake64[2]: *** Waiting for unfinished jobs....\r\nmake64[1]: *** [src/ATen/CMakeFiles/ATen.dir/all] Error 2\r\nmake64: *** [all] Error 2\r\n[zhangruiqing01@yq01-idl-gpu-offline41.yq01.baidu.com:~/tools/py-torch-install/pytorch/pytorch]\r\n$ \r\n```\r\n"}