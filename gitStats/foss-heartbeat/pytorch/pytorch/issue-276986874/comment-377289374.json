{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377289374", "html_url": "https://github.com/pytorch/pytorch/issues/3898#issuecomment-377289374", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3898", "id": 377289374, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzI4OTM3NA==", "user": {"login": "floringogianu", "id": 1670348, "node_id": "MDQ6VXNlcjE2NzAzNDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1670348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/floringogianu", "html_url": "https://github.com/floringogianu", "followers_url": "https://api.github.com/users/floringogianu/followers", "following_url": "https://api.github.com/users/floringogianu/following{/other_user}", "gists_url": "https://api.github.com/users/floringogianu/gists{/gist_id}", "starred_url": "https://api.github.com/users/floringogianu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/floringogianu/subscriptions", "organizations_url": "https://api.github.com/users/floringogianu/orgs", "repos_url": "https://api.github.com/users/floringogianu/repos", "events_url": "https://api.github.com/users/floringogianu/events{/privacy}", "received_events_url": "https://api.github.com/users/floringogianu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-29T16:18:23Z", "updated_at": "2018-03-29T16:18:23Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1080217\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/latkins\">@latkins</a> I did exactly that, wrote a custom <code>collate_fn</code> for the DataLoader but I get the same error.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">sparse_graph_batch_collate</span>(<span class=\"pl-smi\">batch</span>):\n    sparse_batch <span class=\"pl-k\">=</span> [(torch.sparse.LongTensor(<span class=\"pl-k\">*</span>adj),\n                     torch.sparse.LongTensor(<span class=\"pl-k\">*</span>graph)) <span class=\"pl-k\">for</span> adj, graph <span class=\"pl-k\">in</span> batch]\n    <span class=\"pl-k\">return</span> sparse_batch</pre></div>\n<p>Or maybe you are constructing the SparseTensors outside the <code>collate_fn</code> too (when iterating through the batches)?</p>", "body_text": "@latkins I did exactly that, wrote a custom collate_fn for the DataLoader but I get the same error.\ndef sparse_graph_batch_collate(batch):\n    sparse_batch = [(torch.sparse.LongTensor(*adj),\n                     torch.sparse.LongTensor(*graph)) for adj, graph in batch]\n    return sparse_batch\nOr maybe you are constructing the SparseTensors outside the collate_fn too (when iterating through the batches)?", "body": "@latkins I did exactly that, wrote a custom `collate_fn` for the DataLoader but I get the same error.\r\n\r\n```python\r\ndef sparse_graph_batch_collate(batch):\r\n    sparse_batch = [(torch.sparse.LongTensor(*adj),\r\n                     torch.sparse.LongTensor(*graph)) for adj, graph in batch]\r\n    return sparse_batch\r\n```\r\nOr maybe you are constructing the SparseTensors outside the `collate_fn` too (when iterating through the batches)?"}