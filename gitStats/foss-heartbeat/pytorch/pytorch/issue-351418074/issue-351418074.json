{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10604", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10604/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10604/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10604/events", "html_url": "https://github.com/pytorch/pytorch/issues/10604", "id": 351418074, "node_id": "MDU6SXNzdWUzNTE0MTgwNzQ=", "number": 10604, "title": "Bilinear interpolation behavior inconsistent with TF, CoreML and Caffe", "user": {"login": "libfun", "id": 301147, "node_id": "MDQ6VXNlcjMwMTE0Nw==", "avatar_url": "https://avatars0.githubusercontent.com/u/301147?v=4", "gravatar_id": "", "url": "https://api.github.com/users/libfun", "html_url": "https://github.com/libfun", "followers_url": "https://api.github.com/users/libfun/followers", "following_url": "https://api.github.com/users/libfun/following{/other_user}", "gists_url": "https://api.github.com/users/libfun/gists{/gist_id}", "starred_url": "https://api.github.com/users/libfun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/libfun/subscriptions", "organizations_url": "https://api.github.com/users/libfun/orgs", "repos_url": "https://api.github.com/users/libfun/repos", "events_url": "https://api.github.com/users/libfun/events{/privacy}", "received_events_url": "https://api.github.com/users/libfun/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-17T00:45:34Z", "updated_at": "2018-08-17T21:31:39Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Trying to compare and transfer models between Caffe, TF and Pytorch found difference in output of bilinear interpolations between all. Caffe is using depthwise transposed convolutions instead of straightforward resize, so it's easy to reimplement both in TF and Pytorch.<br>\nHowever, there is difference between output for TF and Pytorch with <code>align_corners=False</code>, which is default for both.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre>img <span class=\"pl-k\">=</span> cv2.resize(cv2.imread(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>./lenna.png<span class=\"pl-pds\">'</span></span>)[:, :, ::<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], (<span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>))\nimg <span class=\"pl-k\">=</span> img.reshape(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">3</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nimg <span class=\"pl-k\">=</span> tf.convert_to_tensor(img)\noutput_size <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">512</span>]\noutput <span class=\"pl-k\">=</span> tf.image.resize_bilinear(img, output_size, <span class=\"pl-v\">align_corners</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        values <span class=\"pl-k\">=</span> sess.run([output])\nout_tf <span class=\"pl-k\">=</span> values[<span class=\"pl-c1\">0</span>].astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n\nimg <span class=\"pl-k\">=</span> img.reshape(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">3</span>).transpose(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nout_pt <span class=\"pl-k\">=</span> nn.functional.interpolate(torch.from_numpy(nimg), \n                                   <span class=\"pl-v\">scale_factor</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, \n                                   <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>bilinear<span class=\"pl-pds\">'</span></span>, \n                                   <span class=\"pl-v\">align_corners</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nout_pt <span class=\"pl-k\">=</span> out_pt.data.numpy().transpose(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>)[<span class=\"pl-c1\">0</span>]\n\n<span class=\"pl-c1\">print</span>(np.max(np.abs(out_pt <span class=\"pl-k\">-</span> out_tf)))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> output 5.6624413e-06</span></pre></div>\n<p>But</p>\n<div class=\"highlight highlight-source-python\"><pre>img <span class=\"pl-k\">=</span> cv2.resize(cv2.imread(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>./lenna.png<span class=\"pl-pds\">'</span></span>)[:, :, ::<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], (<span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>))\nimg <span class=\"pl-k\">=</span> img.reshape(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">3</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nimg <span class=\"pl-k\">=</span> tf.convert_to_tensor(img)\noutput_size <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">512</span>, <span class=\"pl-c1\">512</span>]\noutput <span class=\"pl-k\">=</span> tf.image.resize_bilinear(img, output_size, <span class=\"pl-v\">align_corners</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        values <span class=\"pl-k\">=</span> sess.run([output])\nout_tf <span class=\"pl-k\">=</span> values[<span class=\"pl-c1\">0</span>].astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-c1\">0</span>]\n\nimg <span class=\"pl-k\">=</span> img.reshape(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">3</span>).transpose(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>).astype(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>float32<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">255</span>.\nout_pt <span class=\"pl-k\">=</span> nn.functional.interpolate(torch.from_numpy(nimg), \n                                   <span class=\"pl-v\">scale_factor</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, \n                                   <span class=\"pl-v\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>bilinear<span class=\"pl-pds\">'</span></span>, \n                                   <span class=\"pl-v\">align_corners</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\nout_pt <span class=\"pl-k\">=</span> out_pt.data.numpy().transpose(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>)[<span class=\"pl-c1\">0</span>]\n\n<span class=\"pl-c1\">print</span>(np.max(np.abs(out_pt <span class=\"pl-k\">-</span> out_tf)))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> output 0.22745097</span></pre></div>\n<p>Output diff * 10:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/301147/44241919-c4d2d180-a17b-11e8-81eb-9e44c5741d42.png\"><img src=\"https://user-images.githubusercontent.com/301147/44241919-c4d2d180-a17b-11e8-81eb-9e44c5741d42.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>Output of CoreML is consistent with TF, so it seems that there is a bug with implementation of bilinear interpolation with <code>align_corners=False</code> in Pytorch.</p>\n<p>Diff is reproducible both on cpu and cuda with cudnn 7.1, cuda 9.1.</p>", "body_text": "Issue description\nTrying to compare and transfer models between Caffe, TF and Pytorch found difference in output of bilinear interpolations between all. Caffe is using depthwise transposed convolutions instead of straightforward resize, so it's easy to reimplement both in TF and Pytorch.\nHowever, there is difference between output for TF and Pytorch with align_corners=False, which is default for both.\nCode example\nimg = cv2.resize(cv2.imread('./lenna.png')[:, :, ::-1], (256, 256))\nimg = img.reshape(1, 256, 256, 3).astype('float32') / 255.\nimg = tf.convert_to_tensor(img)\noutput_size = [512, 512]\noutput = tf.image.resize_bilinear(img, output_size, align_corners=True)\nwith tf.Session() as sess:\n        values = sess.run([output])\nout_tf = values[0].astype('float32')[0]\n\nimg = img.reshape(1, 256, 256, 3).transpose(0, 3, 1, 2).astype('float32') / 255.\nout_pt = nn.functional.interpolate(torch.from_numpy(nimg), \n                                   scale_factor=2, \n                                   mode='bilinear', \n                                   align_corners=True)\nout_pt = out_pt.data.numpy().transpose(0, 2, 3, 1)[0]\n\nprint(np.max(np.abs(out_pt - out_tf)))\n# output 5.6624413e-06\nBut\nimg = cv2.resize(cv2.imread('./lenna.png')[:, :, ::-1], (256, 256))\nimg = img.reshape(1, 256, 256, 3).astype('float32') / 255.\nimg = tf.convert_to_tensor(img)\noutput_size = [512, 512]\noutput = tf.image.resize_bilinear(img, output_size, align_corners=False)\nwith tf.Session() as sess:\n        values = sess.run([output])\nout_tf = values[0].astype('float32')[0]\n\nimg = img.reshape(1, 256, 256, 3).transpose(0, 3, 1, 2).astype('float32') / 255.\nout_pt = nn.functional.interpolate(torch.from_numpy(nimg), \n                                   scale_factor=2, \n                                   mode='bilinear', \n                                   align_corners=False)\nout_pt = out_pt.data.numpy().transpose(0, 2, 3, 1)[0]\n\nprint(np.max(np.abs(out_pt - out_tf)))\n# output 0.22745097\nOutput diff * 10:\n\nOutput of CoreML is consistent with TF, so it seems that there is a bug with implementation of bilinear interpolation with align_corners=False in Pytorch.\nDiff is reproducible both on cpu and cuda with cudnn 7.1, cuda 9.1.", "body": "## Issue description\r\n\r\nTrying to compare and transfer models between Caffe, TF and Pytorch found difference in output of bilinear interpolations between all. Caffe is using depthwise transposed convolutions instead of straightforward resize, so it's easy to reimplement both in TF and Pytorch.\r\nHowever, there is difference between output for TF and Pytorch with `align_corners=False`, which is default for both.\r\n\r\n## Code example\r\n\r\n```Python\r\nimg = cv2.resize(cv2.imread('./lenna.png')[:, :, ::-1], (256, 256))\r\nimg = img.reshape(1, 256, 256, 3).astype('float32') / 255.\r\nimg = tf.convert_to_tensor(img)\r\noutput_size = [512, 512]\r\noutput = tf.image.resize_bilinear(img, output_size, align_corners=True)\r\nwith tf.Session() as sess:\r\n        values = sess.run([output])\r\nout_tf = values[0].astype('float32')[0]\r\n\r\nimg = img.reshape(1, 256, 256, 3).transpose(0, 3, 1, 2).astype('float32') / 255.\r\nout_pt = nn.functional.interpolate(torch.from_numpy(nimg), \r\n                                   scale_factor=2, \r\n                                   mode='bilinear', \r\n                                   align_corners=True)\r\nout_pt = out_pt.data.numpy().transpose(0, 2, 3, 1)[0]\r\n\r\nprint(np.max(np.abs(out_pt - out_tf)))\r\n# output 5.6624413e-06\r\n``` \r\nBut\r\n```Python\r\nimg = cv2.resize(cv2.imread('./lenna.png')[:, :, ::-1], (256, 256))\r\nimg = img.reshape(1, 256, 256, 3).astype('float32') / 255.\r\nimg = tf.convert_to_tensor(img)\r\noutput_size = [512, 512]\r\noutput = tf.image.resize_bilinear(img, output_size, align_corners=False)\r\nwith tf.Session() as sess:\r\n        values = sess.run([output])\r\nout_tf = values[0].astype('float32')[0]\r\n\r\nimg = img.reshape(1, 256, 256, 3).transpose(0, 3, 1, 2).astype('float32') / 255.\r\nout_pt = nn.functional.interpolate(torch.from_numpy(nimg), \r\n                                   scale_factor=2, \r\n                                   mode='bilinear', \r\n                                   align_corners=False)\r\nout_pt = out_pt.data.numpy().transpose(0, 2, 3, 1)[0]\r\n\r\nprint(np.max(np.abs(out_pt - out_tf)))\r\n# output 0.22745097\r\n``` \r\n\r\nOutput diff * 10:\r\n![image](https://user-images.githubusercontent.com/301147/44241919-c4d2d180-a17b-11e8-81eb-9e44c5741d42.png)\r\n\r\nOutput of CoreML is consistent with TF, so it seems that there is a bug with implementation of bilinear interpolation with `align_corners=False` in Pytorch.\r\n\r\nDiff is reproducible both on cpu and cuda with cudnn 7.1, cuda 9.1.\r\n"}