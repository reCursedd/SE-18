{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5303", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5303/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5303/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5303/events", "html_url": "https://github.com/pytorch/pytorch/issues/5303", "id": 298423826, "node_id": "MDU6SXNzdWUyOTg0MjM4MjY=", "number": 5303, "title": "Cuda runtime error 48 when running detect.py", "user": {"login": "raggot", "id": 28010246, "node_id": "MDQ6VXNlcjI4MDEwMjQ2", "avatar_url": "https://avatars2.githubusercontent.com/u/28010246?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raggot", "html_url": "https://github.com/raggot", "followers_url": "https://api.github.com/users/raggot/followers", "following_url": "https://api.github.com/users/raggot/following{/other_user}", "gists_url": "https://api.github.com/users/raggot/gists{/gist_id}", "starred_url": "https://api.github.com/users/raggot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raggot/subscriptions", "organizations_url": "https://api.github.com/users/raggot/orgs", "repos_url": "https://api.github.com/users/raggot/repos", "events_url": "https://api.github.com/users/raggot/events{/privacy}", "received_events_url": "https://api.github.com/users/raggot/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-19T23:04:15Z", "updated_at": "2018-02-20T17:22:14Z", "closed_at": "2018-02-20T17:22:14Z", "author_association": "NONE", "body_html": "<p>I am having an issue running Pytorch for the first time. This is my configuration:</p>\n<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: 0.3.1.post2</li>\n<li>How you installed PyTorch: conda install pytorch torchvision cuda91 -c pytorch</li>\n<li>Python version: 3.5</li>\n<li>CUDA/cuDNN version: 9.1</li>\n<li>GPU models and configuration: GTX 650 Ti</li>\n<li>GCC version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609</li>\n</ul>\n<p>If I run:<br>\n<code>python detect.py cfg/yolo.cfg yolo.weights data/dog.jpg</code></p>\n<p>This is the output:</p>\n<pre><code>y cfg/yolo.cfg yolo.weights data/dog.jpg\nlayer     filters    size              input                output\n    0 conv     32  3 x 3 / 1   416 x 416 x   3   -&gt;   416 x 416 x  32\n    1 max          2 x 2 / 2   416 x 416 x  32   -&gt;   208 x 208 x  32\n    2 conv     64  3 x 3 / 1   208 x 208 x  32   -&gt;   208 x 208 x  64\n    3 max          2 x 2 / 2   208 x 208 x  64   -&gt;   104 x 104 x  64\n    4 conv    128  3 x 3 / 1   104 x 104 x  64   -&gt;   104 x 104 x 128\n    5 conv     64  1 x 1 / 1   104 x 104 x 128   -&gt;   104 x 104 x  64\n    6 conv    128  3 x 3 / 1   104 x 104 x  64   -&gt;   104 x 104 x 128\n    7 max          2 x 2 / 2   104 x 104 x 128   -&gt;    52 x  52 x 128\n    8 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256\n    9 conv    128  1 x 1 / 1    52 x  52 x 256   -&gt;    52 x  52 x 128\n   10 conv    256  3 x 3 / 1    52 x  52 x 128   -&gt;    52 x  52 x 256\n   11 max          2 x 2 / 2    52 x  52 x 256   -&gt;    26 x  26 x 256\n   12 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512\n   13 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256\n   14 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512\n   15 conv    256  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x 256\n   16 conv    512  3 x 3 / 1    26 x  26 x 256   -&gt;    26 x  26 x 512\n   17 max          2 x 2 / 2    26 x  26 x 512   -&gt;    13 x  13 x 512\n   18 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024\n   19 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512\n   20 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024\n   21 conv    512  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 512\n   22 conv   1024  3 x 3 / 1    13 x  13 x 512   -&gt;    13 x  13 x1024\n   23 conv   1024  3 x 3 / 1    13 x  13 x1024   -&gt;    13 x  13 x1024\n   24 conv   1024  3 x 3 / 1    13 x  13 x1024   -&gt;    13 x  13 x1024\n   25 route  16\n   26 conv     64  1 x 1 / 1    26 x  26 x 512   -&gt;    26 x  26 x  64\n   27 reorg              / 2    26 x  26 x  64   -&gt;    13 x  13 x 256\n   28 route  27 24\n   29 conv   1024  3 x 3 / 1    13 x  13 x1280   -&gt;    13 x  13 x1024\n   30 conv    425  1 x 1 / 1    13 x  13 x1024   -&gt;    13 x  13 x 425\n   31 detection\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:175: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:157: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\nLoading weights from yolo.weights... Done!\n/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/cuda/__init__.py:97: UserWarning: \n    Found GPU0 GeForce GTX 650 Ti which is of cuda capability 3.0.\n    PyTorch no longer supports this GPU because it is too old.\n    \n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu line=29 error=48 : no kernel image is available for execution on the device\nTraceback (most recent call last):\n  File \"detect.py\", line 113, in &lt;module&gt;\n    detect(cfgfile, weightfile, imgfile)\n  File \"detect.py\", line 31, in detect\n    boxes = do_detect(m, sized, 0.5, 0.4, use_cuda)\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/utils.py\", line 336, in do_detect\n    output = model(img)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/darknet.py\", line 91, in forward\n    x = self.models[ind](x)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/container.py\", line 67, in forward\n    input = module(input)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/activation.py\", line 401, in forward\n    return F.leaky_relu(input, self.negative_slope, self.inplace)\nRuntimeError: cuda runtime error (48) : no kernel image is available for execution on the device at /opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu:29\n\n</code></pre>\n<p>Although I know my GTX 650 Ti is not supported, I don't think that is the problem. I read somewhere that probably it is incompatible with CUDA 9.1, which would mean I'd need to downgrade my CUDA installation.</p>\n<p>Before I start delicate (and annoying) operations, I'd like to know what precisely I would have to do/install to get my gear up and running with PyTorch. I may alternatively buy a GTX 1060 to make sure I get better compatibility and support for a longer time.</p>\n<p>Thanks for your time.</p>", "body_text": "I am having an issue running Pytorch for the first time. This is my configuration:\n\nOS: Ubuntu 16.04\nPyTorch version: 0.3.1.post2\nHow you installed PyTorch: conda install pytorch torchvision cuda91 -c pytorch\nPython version: 3.5\nCUDA/cuDNN version: 9.1\nGPU models and configuration: GTX 650 Ti\nGCC version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\n\nIf I run:\npython detect.py cfg/yolo.cfg yolo.weights data/dog.jpg\nThis is the output:\ny cfg/yolo.cfg yolo.weights data/dog.jpg\nlayer     filters    size              input                output\n    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32\n    1 max          2 x 2 / 2   416 x 416 x  32   ->   208 x 208 x  32\n    2 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64\n    3 max          2 x 2 / 2   208 x 208 x  64   ->   104 x 104 x  64\n    4 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n    5 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64\n    6 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\n    7 max          2 x 2 / 2   104 x 104 x 128   ->    52 x  52 x 128\n    8 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n    9 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\n   10 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\n   11 max          2 x 2 / 2    52 x  52 x 256   ->    26 x  26 x 256\n   12 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n   13 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n   14 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n   15 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\n   16 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\n   17 max          2 x 2 / 2    26 x  26 x 512   ->    13 x  13 x 512\n   18 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n   19 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n   20 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n   21 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\n   22 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\n   23 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\n   24 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\n   25 route  16\n   26 conv     64  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  64\n   27 reorg              / 2    26 x  26 x  64   ->    13 x  13 x 256\n   28 route  27 24\n   29 conv   1024  3 x 3 / 1    13 x  13 x1280   ->    13 x  13 x1024\n   30 conv    425  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 425\n   31 detection\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:175: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:157: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\nLoading weights from yolo.weights... Done!\n/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/cuda/__init__.py:97: UserWarning: \n    Found GPU0 GeForce GTX 650 Ti which is of cuda capability 3.0.\n    PyTorch no longer supports this GPU because it is too old.\n    \n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu line=29 error=48 : no kernel image is available for execution on the device\nTraceback (most recent call last):\n  File \"detect.py\", line 113, in <module>\n    detect(cfgfile, weightfile, imgfile)\n  File \"detect.py\", line 31, in detect\n    boxes = do_detect(m, sized, 0.5, 0.4, use_cuda)\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/utils.py\", line 336, in do_detect\n    output = model(img)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/darknet.py\", line 91, in forward\n    x = self.models[ind](x)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/container.py\", line 67, in forward\n    input = module(input)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/activation.py\", line 401, in forward\n    return F.leaky_relu(input, self.negative_slope, self.inplace)\nRuntimeError: cuda runtime error (48) : no kernel image is available for execution on the device at /opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu:29\n\n\nAlthough I know my GTX 650 Ti is not supported, I don't think that is the problem. I read somewhere that probably it is incompatible with CUDA 9.1, which would mean I'd need to downgrade my CUDA installation.\nBefore I start delicate (and annoying) operations, I'd like to know what precisely I would have to do/install to get my gear up and running with PyTorch. I may alternatively buy a GTX 1060 to make sure I get better compatibility and support for a longer time.\nThanks for your time.", "body": "I am having an issue running Pytorch for the first time. This is my configuration:\r\n- OS: Ubuntu 16.04\r\n- PyTorch version: 0.3.1.post2\r\n- How you installed PyTorch: conda install pytorch torchvision cuda91 -c pytorch\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 9.1\r\n- GPU models and configuration: GTX 650 Ti\r\n- GCC version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\r\n\r\nIf I run:\r\n`python detect.py cfg/yolo.cfg yolo.weights data/dog.jpg`\r\n\r\nThis is the output:\r\n```\r\ny cfg/yolo.cfg yolo.weights data/dog.jpg\r\nlayer     filters    size              input                output\r\n    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32\r\n    1 max          2 x 2 / 2   416 x 416 x  32   ->   208 x 208 x  32\r\n    2 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64\r\n    3 max          2 x 2 / 2   208 x 208 x  64   ->   104 x 104 x  64\r\n    4 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\r\n    5 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64\r\n    6 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128\r\n    7 max          2 x 2 / 2   104 x 104 x 128   ->    52 x  52 x 128\r\n    8 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\r\n    9 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128\r\n   10 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256\r\n   11 max          2 x 2 / 2    52 x  52 x 256   ->    26 x  26 x 256\r\n   12 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\r\n   13 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\r\n   14 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\r\n   15 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256\r\n   16 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512\r\n   17 max          2 x 2 / 2    26 x  26 x 512   ->    13 x  13 x 512\r\n   18 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\r\n   19 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\r\n   20 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\r\n   21 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512\r\n   22 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024\r\n   23 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\r\n   24 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024\r\n   25 route  16\r\n   26 conv     64  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  64\r\n   27 reorg              / 2    26 x  26 x  64   ->    13 x  13 x 256\r\n   28 route  27 24\r\n   29 conv   1024  3 x 3 / 1    13 x  13 x1280   ->    13 x  13 x1024\r\n   30 conv    425  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 425\r\n   31 detection\r\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:175: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\r\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\r\n/home/raggot/Projects/Github/pytorch-yolo2/cfg.py:157: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\r\n  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\r\nLoading weights from yolo.weights... Done!\r\n/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/cuda/__init__.py:97: UserWarning: \r\n    Found GPU0 GeForce GTX 650 Ti which is of cuda capability 3.0.\r\n    PyTorch no longer supports this GPU because it is too old.\r\n    \r\n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu line=29 error=48 : no kernel image is available for execution on the device\r\nTraceback (most recent call last):\r\n  File \"detect.py\", line 113, in <module>\r\n    detect(cfgfile, weightfile, imgfile)\r\n  File \"detect.py\", line 31, in detect\r\n    boxes = do_detect(m, sized, 0.5, 0.4, use_cuda)\r\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/utils.py\", line 336, in do_detect\r\n    output = model(img)\r\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/raggot/Projects/Github/pytorch-yolo2/darknet.py\", line 91, in forward\r\n    x = self.models[ind](x)\r\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/container.py\", line 67, in forward\r\n    input = module(input)\r\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 357, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/raggot/anaconda3/envs/fencing/lib/python3.5/site-packages/torch/nn/modules/activation.py\", line 401, in forward\r\n    return F.leaky_relu(input, self.negative_slope, self.inplace)\r\nRuntimeError: cuda runtime error (48) : no kernel image is available for execution on the device at /opt/conda/conda-bld/pytorch_1518241644131/work/torch/lib/THCUNN/generic/LeakyReLU.cu:29\r\n\r\n```\r\n\r\nAlthough I know my GTX 650 Ti is not supported, I don't think that is the problem. I read somewhere that probably it is incompatible with CUDA 9.1, which would mean I'd need to downgrade my CUDA installation. \r\n\r\nBefore I start delicate (and annoying) operations, I'd like to know what precisely I would have to do/install to get my gear up and running with PyTorch. I may alternatively buy a GTX 1060 to make sure I get better compatibility and support for a longer time.\r\n\r\nThanks for your time.\r\n"}