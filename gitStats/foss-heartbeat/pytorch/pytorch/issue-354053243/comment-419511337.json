{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/419511337", "html_url": "https://github.com/pytorch/pytorch/pull/10881#issuecomment-419511337", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10881", "id": 419511337, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTUxMTMzNw==", "user": {"login": "mcarilli", "id": 7799218, "node_id": "MDQ6VXNlcjc3OTkyMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7799218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarilli", "html_url": "https://github.com/mcarilli", "followers_url": "https://api.github.com/users/mcarilli/followers", "following_url": "https://api.github.com/users/mcarilli/following{/other_user}", "gists_url": "https://api.github.com/users/mcarilli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarilli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarilli/subscriptions", "organizations_url": "https://api.github.com/users/mcarilli/orgs", "repos_url": "https://api.github.com/users/mcarilli/repos", "events_url": "https://api.github.com/users/mcarilli/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarilli/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T17:31:24Z", "updated_at": "2018-09-10T16:33:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I've updated the PR to move all string processing so that it only occurs in the narrowest NVTX-specific case, with less verbose annotations (<code>seq=N</code> and <code>stashed seq=N</code> for VariableType::function and Function object operator() ranges respectively).  Again, I'm not sure if this is exactly what you wanted, but if not, please clarify so we can iterate on it.</p>\n<p>To restrict string processing to the NVTX-specific case, I had to expand the function signature of <code>profiler::pushRange</code> with some defaulted arguments, but those additional arguments may turn out to be useful for other cases in the future, so I don't think they do any harm.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> Now that the annotation changes have been restricted to NVTX only, the existing <code>test_profiler</code> in <code>test_autograd.py</code> passes, because it doesn't cover NVTX.  I'm not sure how to add an NVTX-specific test, short of running the entire test script through nvprof and loading and inspecting the resulting nvprof file.</p>\n<p>I've also updated the docstring of <code>emit_nvtx</code> in <code>torch/autograd/profiler.py</code> with a comprehensive and hopefully clear explanation of how the sequence numbers can be interpreted.</p>\n<p>Edit:  Oops, forgot to run flake8, so docstring doesn't pass.  Given that the rest of the PR is not yet approved, I'll ignore that for now, and fix it in future edits rather than clobber your CI again immediately for a trivial change.  Other failures appear unrelated.</p>", "body_text": "@apaszke I've updated the PR to move all string processing so that it only occurs in the narrowest NVTX-specific case, with less verbose annotations (seq=N and stashed seq=N for VariableType::function and Function object operator() ranges respectively).  Again, I'm not sure if this is exactly what you wanted, but if not, please clarify so we can iterate on it.\nTo restrict string processing to the NVTX-specific case, I had to expand the function signature of profiler::pushRange with some defaulted arguments, but those additional arguments may turn out to be useful for other cases in the future, so I don't think they do any harm.\n@ezyang Now that the annotation changes have been restricted to NVTX only, the existing test_profiler in test_autograd.py passes, because it doesn't cover NVTX.  I'm not sure how to add an NVTX-specific test, short of running the entire test script through nvprof and loading and inspecting the resulting nvprof file.\nI've also updated the docstring of emit_nvtx in torch/autograd/profiler.py with a comprehensive and hopefully clear explanation of how the sequence numbers can be interpreted.\nEdit:  Oops, forgot to run flake8, so docstring doesn't pass.  Given that the rest of the PR is not yet approved, I'll ignore that for now, and fix it in future edits rather than clobber your CI again immediately for a trivial change.  Other failures appear unrelated.", "body": "@apaszke I've updated the PR to move all string processing so that it only occurs in the narrowest NVTX-specific case, with less verbose annotations (`seq=N` and `stashed seq=N` for VariableType::function and Function object operator() ranges respectively).  Again, I'm not sure if this is exactly what you wanted, but if not, please clarify so we can iterate on it.\r\n\r\nTo restrict string processing to the NVTX-specific case, I had to expand the function signature of `profiler::pushRange` with some defaulted arguments, but those additional arguments may turn out to be useful for other cases in the future, so I don't think they do any harm. \r\n\r\n@ezyang Now that the annotation changes have been restricted to NVTX only, the existing `test_profiler` in `test_autograd.py` passes, because it doesn't cover NVTX.  I'm not sure how to add an NVTX-specific test, short of running the entire test script through nvprof and loading and inspecting the resulting nvprof file.\r\n\r\nI've also updated the docstring of `emit_nvtx` in `torch/autograd/profiler.py` with a comprehensive and hopefully clear explanation of how the sequence numbers can be interpreted.\r\n\r\nEdit:  Oops, forgot to run flake8, so docstring doesn't pass.  Given that the rest of the PR is not yet approved, I'll ignore that for now, and fix it in future edits rather than clobber your CI again immediately for a trivial change.  Other failures appear unrelated."}