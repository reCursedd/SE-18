{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1668", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1668/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1668/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1668/events", "html_url": "https://github.com/pytorch/pytorch/issues/1668", "id": 231819063, "node_id": "MDU6SXNzdWUyMzE4MTkwNjM=", "number": 1668, "title": "Easy way to switch between CPU and cuda ", "user": {"login": "chsasank", "id": 9305875, "node_id": "MDQ6VXNlcjkzMDU4NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/9305875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chsasank", "html_url": "https://github.com/chsasank", "followers_url": "https://api.github.com/users/chsasank/followers", "following_url": "https://api.github.com/users/chsasank/following{/other_user}", "gists_url": "https://api.github.com/users/chsasank/gists{/gist_id}", "starred_url": "https://api.github.com/users/chsasank/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chsasank/subscriptions", "organizations_url": "https://api.github.com/users/chsasank/orgs", "repos_url": "https://api.github.com/users/chsasank/repos", "events_url": "https://api.github.com/users/chsasank/events{/privacy}", "received_events_url": "https://api.github.com/users/chsasank/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2017-05-27T18:19:43Z", "updated_at": "2018-10-16T09:11:10Z", "closed_at": "2018-04-24T20:34:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Right now, as far as I know there is no one simple way to write code which runs seamlessly both on CPU and GPU. We need to resort to switches like</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> torch.zeros()\n<span class=\"pl-k\">if</span> torch.cuda.available():\n    x <span class=\"pl-k\">=</span> x.cuda()</pre></div>\n<p>One reason for this is functions which create tensors like <code>torch.ones</code> etc create on CPU.<br>\nIf there are functions like <code>torch.cuda.ones</code> etc available we can use code like this which runs seamlessly:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> torch.cuda.available():\n    <span class=\"pl-k\">import</span> torch.cuda <span class=\"pl-k\">as</span> t\n<span class=\"pl-k\">else</span>:\n    <span class=\"pl-k\">import</span> torch <span class=\"pl-k\">as</span> t\n\nx <span class=\"pl-k\">=</span> t.zeros()\ny <span class=\"pl-k\">=</span> Variable(x)</pre></div>\n<p>This is just one way to make the switch easy, there might be a better way to do the same.</p>", "body_text": "Right now, as far as I know there is no one simple way to write code which runs seamlessly both on CPU and GPU. We need to resort to switches like\nx = torch.zeros()\nif torch.cuda.available():\n    x = x.cuda()\nOne reason for this is functions which create tensors like torch.ones etc create on CPU.\nIf there are functions like torch.cuda.ones etc available we can use code like this which runs seamlessly:\nif torch.cuda.available():\n    import torch.cuda as t\nelse:\n    import torch as t\n\nx = t.zeros()\ny = Variable(x)\nThis is just one way to make the switch easy, there might be a better way to do the same.", "body": "Right now, as far as I know there is no one simple way to write code which runs seamlessly both on CPU and GPU. We need to resort to switches like \r\n\r\n```python\r\nx = torch.zeros()\r\nif torch.cuda.available():\r\n    x = x.cuda()\r\n```\r\n\r\nOne reason for this is functions which create tensors like `torch.ones` etc create on CPU. \r\nIf there are functions like `torch.cuda.ones` etc available we can use code like this which runs seamlessly:\r\n\r\n```python\r\nif torch.cuda.available():\r\n    import torch.cuda as t\r\nelse:\r\n    import torch as t\r\n\r\nx = t.zeros()\r\ny = Variable(x)\r\n```\r\n\r\nThis is just one way to make the switch easy, there might be a better way to do the same."}