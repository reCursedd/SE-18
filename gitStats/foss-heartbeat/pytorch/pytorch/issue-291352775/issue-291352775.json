{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4836", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4836/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4836/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4836/events", "html_url": "https://github.com/pytorch/pytorch/issues/4836", "id": 291352775, "node_id": "MDU6SXNzdWUyOTEzNTI3NzU=", "number": 4836, "title": "Inconsistency between advanced indexing of Tensors and Variables", "user": {"login": "dancsi", "id": 405156, "node_id": "MDQ6VXNlcjQwNTE1Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/405156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dancsi", "html_url": "https://github.com/dancsi", "followers_url": "https://api.github.com/users/dancsi/followers", "following_url": "https://api.github.com/users/dancsi/following{/other_user}", "gists_url": "https://api.github.com/users/dancsi/gists{/gist_id}", "starred_url": "https://api.github.com/users/dancsi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dancsi/subscriptions", "organizations_url": "https://api.github.com/users/dancsi/orgs", "repos_url": "https://api.github.com/users/dancsi/repos", "events_url": "https://api.github.com/users/dancsi/events{/privacy}", "received_events_url": "https://api.github.com/users/dancsi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-24T20:42:48Z", "updated_at": "2018-01-24T22:03:59Z", "closed_at": "2018-01-24T22:03:59Z", "author_association": "NONE", "body_html": "<p>I have noticed an inconsistency while trying to perform advanced indexing of <code>Tensor</code>s and <code>Variable</code>s. For some reason, <code>Variable</code>s seem to support more complicated indexing operations than <code>Tensor</code>s.<br>\nHere is an example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> t <span class=\"pl-k\">=</span> torch.arange(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">10</span>) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">10</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> i <span class=\"pl-k\">=</span> torch.arange(<span class=\"pl-c1\">6</span>).type(torch.LongTensor).view(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> i\n <span class=\"pl-c1\">0</span>  <span class=\"pl-c1\">1</span>  <span class=\"pl-c1\">2</span>\n <span class=\"pl-c1\">3</span>  <span class=\"pl-c1\">4</span>  <span class=\"pl-c1\">5</span>\n[torch.LongTensor of size <span class=\"pl-ii\">2x3</span>]\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> t[i]\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n<span class=\"pl-c1\">IndexError</span>: Indexing a Tensor <span class=\"pl-k\">with</span> a torch.LongTensor triggers index_select semantics, <span class=\"pl-k\">and</span> thus we expect an empty tensor <span class=\"pl-k\">or</span> a vector, but the indexing Tensor passed has <span class=\"pl-c1\">2</span> dimensions</pre></div>\n<p>However, when I wrap <code>t</code> in a <code>Variable</code>, I get the expected result:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.autograd.Variable(t)[i]\nVariable containing:\n <span class=\"pl-c1\">10</span>  <span class=\"pl-c1\">20</span>  <span class=\"pl-c1\">30</span>\n <span class=\"pl-c1\">40</span>  <span class=\"pl-c1\">50</span>  <span class=\"pl-c1\">60</span>\n[torch.FloatTensor of size (<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>)]</pre></div>\n<p>For reference, this is the result returned by numpy, as well:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> t.numpy()[i.numpy()]\narray([[<span class=\"pl-c1\">10</span>., <span class=\"pl-c1\">20</span>., <span class=\"pl-c1\">30</span>.],\n       [<span class=\"pl-c1\">40</span>., <span class=\"pl-c1\">50</span>., <span class=\"pl-c1\">60</span>.]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32)</pre></div>\n<p>I have tried this with source-built pytorch 0.4 from master (currently at <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/8400c57daaed4ebf870c7b08cfcb94fd4405aac8/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/8400c57daaed4ebf870c7b08cfcb94fd4405aac8\"><tt>8400c57</tt></a>), running on Linux on CPU. The bug can not be replicated on version 0.3.</p>", "body_text": "I have noticed an inconsistency while trying to perform advanced indexing of Tensors and Variables. For some reason, Variables seem to support more complicated indexing operations than Tensors.\nHere is an example:\n>>> t = torch.arange(1,10) * 10\n>>> i = torch.arange(6).type(torch.LongTensor).view(2, 3)\n>>> i\n 0  1  2\n 3  4  5\n[torch.LongTensor of size 2x3]\n>>> t[i]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: Indexing a Tensor with a torch.LongTensor triggers index_select semantics, and thus we expect an empty tensor or a vector, but the indexing Tensor passed has 2 dimensions\nHowever, when I wrap t in a Variable, I get the expected result:\n>>> torch.autograd.Variable(t)[i]\nVariable containing:\n 10  20  30\n 40  50  60\n[torch.FloatTensor of size (2,3)]\nFor reference, this is the result returned by numpy, as well:\n>>> t.numpy()[i.numpy()]\narray([[10., 20., 30.],\n       [40., 50., 60.]], dtype=float32)\nI have tried this with source-built pytorch 0.4 from master (currently at 8400c57), running on Linux on CPU. The bug can not be replicated on version 0.3.", "body": "I have noticed an inconsistency while trying to perform advanced indexing of `Tensor`s and `Variable`s. For some reason, `Variable`s seem to support more complicated indexing operations than `Tensor`s. \r\nHere is an example:\r\n```Python\r\n>>> t = torch.arange(1,10) * 10\r\n>>> i = torch.arange(6).type(torch.LongTensor).view(2, 3)\r\n>>> i\r\n 0  1  2\r\n 3  4  5\r\n[torch.LongTensor of size 2x3]\r\n>>> t[i]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nIndexError: Indexing a Tensor with a torch.LongTensor triggers index_select semantics, and thus we expect an empty tensor or a vector, but the indexing Tensor passed has 2 dimensions\r\n```\r\nHowever, when I wrap `t` in a `Variable`, I get the expected result:\r\n```Python\r\n>>> torch.autograd.Variable(t)[i]\r\nVariable containing:\r\n 10  20  30\r\n 40  50  60\r\n[torch.FloatTensor of size (2,3)]\r\n```\r\nFor reference, this is the result returned by numpy, as well:\r\n```Python\r\n>>> t.numpy()[i.numpy()]\r\narray([[10., 20., 30.],\r\n       [40., 50., 60.]], dtype=float32)\r\n```\r\nI have tried this with source-built pytorch 0.4 from master (currently at 8400c57daaed4ebf870c7b08cfcb94fd4405aac8), running on Linux on CPU. The bug can not be replicated on version 0.3."}