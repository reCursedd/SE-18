{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/438884095", "html_url": "https://github.com/pytorch/pytorch/issues/14000#issuecomment-438884095", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/14000", "id": 438884095, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODg4NDA5NQ==", "user": {"login": "Suhail", "id": 66225, "node_id": "MDQ6VXNlcjY2MjI1", "avatar_url": "https://avatars1.githubusercontent.com/u/66225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Suhail", "html_url": "https://github.com/Suhail", "followers_url": "https://api.github.com/users/Suhail/followers", "following_url": "https://api.github.com/users/Suhail/following{/other_user}", "gists_url": "https://api.github.com/users/Suhail/gists{/gist_id}", "starred_url": "https://api.github.com/users/Suhail/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Suhail/subscriptions", "organizations_url": "https://api.github.com/users/Suhail/orgs", "repos_url": "https://api.github.com/users/Suhail/repos", "events_url": "https://api.github.com/users/Suhail/events{/privacy}", "received_events_url": "https://api.github.com/users/Suhail/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-15T01:38:54Z", "updated_at": "2018-11-15T01:39:27Z", "author_association": "NONE", "body_html": "<p>Hmm, I get this error now:</p>\n<pre><code>./example-app ../mnist-traced.pt\nModel loaded.\nterminate called after throwing an instance of 'c10::Error'\n  what():  Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 1-dimensional input of size [2352] instead (check_input_shape_forward at /pytorch/aten/src/ATen/native/Convolution.cpp:170)\nframe #0: std::function&lt;std::string ()&gt;::operator()() const + 0x11 (0x7fa5ebdd50d1 in /home/paperspace/mnist-torch-script-test/libtorch/lib/libc10.so)\n</code></pre>\n<div class=\"highlight highlight-source-c++\"><pre>    <span class=\"pl-k\">auto</span> blob = j.get&lt;vector&lt;vector&lt;vector&lt;vector&lt;<span class=\"pl-k\">float</span>&gt;&gt;&gt;&gt;&gt;();\n    <span class=\"pl-k\">auto</span> tensor = torch::empty(<span class=\"pl-c1\">1</span> * <span class=\"pl-c1\">3</span> * <span class=\"pl-c1\">28</span> * <span class=\"pl-c1\">28</span>);\n    <span class=\"pl-k\">float</span>* data = tensor.data&lt;<span class=\"pl-k\">float</span>&gt;();\n\n    <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; i : blob) {\n        <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; j : i) {\n            <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; k : j) {\n                <span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; l : k) {\n                    *data++ = l;\n                }\n            }\n        }\n    }\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>cout &lt;&lt; data &lt;&lt; endl;</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">/*</span>at::TensorOptions options(at::ScalarType::Byte);</span>\n<span class=\"pl-c\"></span>\n<span class=\"pl-c\">    at::Tensor t = torch::from_blob(data, {1, 3, 28, 28});</span>\n<span class=\"pl-c\">    t = t.toType(at::kFloat);</span>\n<span class=\"pl-c\">    <span class=\"pl-c\">*/</span></span>\n\n    inputs.emplace_back(tensor);\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Run inference</span>\n    <span class=\"pl-k\">auto</span> output = module-&gt;<span class=\"pl-en\">forward</span>(inputs).toTensor();\n    cout &lt;&lt; output.slice(<span class=\"pl-c\"><span class=\"pl-c\">/*</span>dim=<span class=\"pl-c\">*/</span></span><span class=\"pl-c1\">1</span>, <span class=\"pl-c\"><span class=\"pl-c\">/*</span>start=<span class=\"pl-c\">*/</span></span><span class=\"pl-c1\">0</span>, <span class=\"pl-c\"><span class=\"pl-c\">/*</span>end=<span class=\"pl-c\">*/</span></span><span class=\"pl-c1\">5</span>) &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;</pre></div>", "body_text": "Hmm, I get this error now:\n./example-app ../mnist-traced.pt\nModel loaded.\nterminate called after throwing an instance of 'c10::Error'\n  what():  Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 1-dimensional input of size [2352] instead (check_input_shape_forward at /pytorch/aten/src/ATen/native/Convolution.cpp:170)\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fa5ebdd50d1 in /home/paperspace/mnist-torch-script-test/libtorch/lib/libc10.so)\n\n    auto blob = j.get<vector<vector<vector<vector<float>>>>>();\n    auto tensor = torch::empty(1 * 3 * 28 * 28);\n    float* data = tensor.data<float>();\n\n    for (const auto& i : blob) {\n        for (const auto& j : i) {\n            for (const auto& k : j) {\n                for (const auto& l : k) {\n                    *data++ = l;\n                }\n            }\n        }\n    }\n\n    //cout << data << endl;\n\n    /*at::TensorOptions options(at::ScalarType::Byte);\n\n    at::Tensor t = torch::from_blob(data, {1, 3, 28, 28});\n    t = t.toType(at::kFloat);\n    */\n\n    inputs.emplace_back(tensor);\n\n    // Run inference\n    auto output = module->forward(inputs).toTensor();\n    cout << output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) << '\\n';", "body": "Hmm, I get this error now:\r\n\r\n```\r\n./example-app ../mnist-traced.pt\r\nModel loaded.\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 1-dimensional input of size [2352] instead (check_input_shape_forward at /pytorch/aten/src/ATen/native/Convolution.cpp:170)\r\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fa5ebdd50d1 in /home/paperspace/mnist-torch-script-test/libtorch/lib/libc10.so)\r\n```\r\n\r\n```c++\r\n    auto blob = j.get<vector<vector<vector<vector<float>>>>>();\r\n    auto tensor = torch::empty(1 * 3 * 28 * 28);\r\n    float* data = tensor.data<float>();\r\n\r\n    for (const auto& i : blob) {\r\n        for (const auto& j : i) {\r\n            for (const auto& k : j) {\r\n                for (const auto& l : k) {\r\n                    *data++ = l;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    //cout << data << endl;\r\n\r\n    /*at::TensorOptions options(at::ScalarType::Byte);\r\n\r\n    at::Tensor t = torch::from_blob(data, {1, 3, 28, 28});\r\n    t = t.toType(at::kFloat);\r\n    */\r\n\r\n    inputs.emplace_back(tensor);\r\n\r\n    // Run inference\r\n    auto output = module->forward(inputs).toTensor();\r\n    cout << output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) << '\\n';\r\n```"}