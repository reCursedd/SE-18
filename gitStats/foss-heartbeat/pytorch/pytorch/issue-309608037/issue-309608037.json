{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6100", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6100/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6100/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6100/events", "html_url": "https://github.com/pytorch/pytorch/pull/6100", "id": 309608037, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc4MjE5NjY1", "number": 6100, "title": "Add batched linear solver to torch.gesv()", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-03-29T03:39:41Z", "updated_at": "2018-11-23T15:43:38Z", "closed_at": "2018-05-08T21:06:28Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/6100", "html_url": "https://github.com/pytorch/pytorch/pull/6100", "diff_url": "https://github.com/pytorch/pytorch/pull/6100.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/6100.patch"}, "body_html": "<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #3164.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"266628708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3164\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3164/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/3164\">#3164</a><br>\nPicks up from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"286423294\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4502\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4502/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4502\">#4502</a></p>\n<p>I moved <code>gesv</code> to ATen.<br>\nAdds bindings for MAGMA's <code>gesv_batched</code> function for CUDA.<br>\nFor CPU, runs <code>THLapack(gesv)</code> in a for loop.</p>\n<p>The new function supports arbitrary batch dimensions (and broadcasting<br>\nof those dimensions). For example, the 4-d tensor <code>A x B x M x M</code> should<br>\nbe treated as having batch-size <code>(A x B)</code>.</p>\n<p>The overhead of creating the magma_queue_t is: ~350000 microseconds<br>\nthe first time it's called and ~6 microseconds every time after that.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>", "body_text": "Fixes #3164\nPicks up from #4502\nI moved gesv to ATen.\nAdds bindings for MAGMA's gesv_batched function for CUDA.\nFor CPU, runs THLapack(gesv) in a for loop.\nThe new function supports arbitrary batch dimensions (and broadcasting\nof those dimensions). For example, the 4-d tensor A x B x M x M should\nbe treated as having batch-size (A x B).\nThe overhead of creating the magma_queue_t is: ~350000 microseconds\nthe first time it's called and ~6 microseconds every time after that.\ncc @colesbury @apaszke", "body": "Fixes #3164\r\nPicks up from #4502\r\n\r\nI moved `gesv` to ATen.\r\nAdds bindings for MAGMA's `gesv_batched` function for CUDA.\r\nFor CPU, runs `THLapack(gesv)` in a for loop.\r\n\r\nThe new function supports arbitrary batch dimensions (and broadcasting\r\nof those dimensions). For example, the 4-d tensor `A x B x M x M` should\r\nbe treated as having batch-size `(A x B)`.\r\n\r\nThe overhead of creating the magma_queue_t is: ~350000 microseconds\r\nthe first time it's called and ~6 microseconds every time after that.\r\n\r\ncc @colesbury @apaszke "}