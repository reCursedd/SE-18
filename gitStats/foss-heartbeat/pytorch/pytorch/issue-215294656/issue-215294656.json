{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1040", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1040/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1040/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1040/events", "html_url": "https://github.com/pytorch/pytorch/issues/1040", "id": 215294656, "node_id": "MDU6SXNzdWUyMTUyOTQ2NTY=", "number": 1040, "title": "\"no CUDA-capable device is detected,\" but shows up elsewhere", "user": {"login": "drscotthawley", "id": 13925685, "node_id": "MDQ6VXNlcjEzOTI1Njg1", "avatar_url": "https://avatars1.githubusercontent.com/u/13925685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drscotthawley", "html_url": "https://github.com/drscotthawley", "followers_url": "https://api.github.com/users/drscotthawley/followers", "following_url": "https://api.github.com/users/drscotthawley/following{/other_user}", "gists_url": "https://api.github.com/users/drscotthawley/gists{/gist_id}", "starred_url": "https://api.github.com/users/drscotthawley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drscotthawley/subscriptions", "organizations_url": "https://api.github.com/users/drscotthawley/orgs", "repos_url": "https://api.github.com/users/drscotthawley/repos", "events_url": "https://api.github.com/users/drscotthawley/events{/privacy}", "received_events_url": "https://api.github.com/users/drscotthawley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-19T21:03:13Z", "updated_at": "2017-03-19T21:15:37Z", "closed_at": "2017-03-19T21:15:37Z", "author_association": "NONE", "body_html": "<p>I'm running the examples/mnist/ code at <a href=\"https://github.com/pytorch/examples/tree/master/mnist\">https://github.com/pytorch/examples/tree/master/mnist</a>.</p>\n<p>When I follow the README's instructions I get (running from bash):</p>\n<pre><code>(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python main.py\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\nFiles already downloaded\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.297210\nTrain Epoch: 1 [640/60000 (1%)]\tLoss: 2.318286\nTrain Epoch: 1 [1280/60000 (2%)]\tLoss: 2.298914\nTrain Epoch: 1 [1920/60000 (3%)]\tLoss: 2.317417\nTrain Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295015\n^C\n</code></pre>\n<p>But my cards are enabled...</p>\n<pre><code>~/pytorch/examples/mnist$ nvidia-smi\nSun Mar 19 15:50:14 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:01:00.0      On |                  N/A |\n| 23%   27C    P8    10W / 250W |     63MiB / 12186MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\n| 23%   27C    P8     8W / 250W |      1MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1094    G   /usr/lib/xorg/Xorg                              60MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>...and I've been running other PyTorch code that correctly detects my devices, for example,</p>\n<pre><code>(py35) ~/pytorch/examples/mnist$ python\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; if torch.cuda.is_available():\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\n... \nUsing CUDA, number of devices =  2\n&gt;&gt;&gt; \n\n</code></pre>\n<p>Seems like the use of the flag CUDA_VISIBLE_DEVICES=2 actually <em>disables</em> CUDA, as shown...</p>\n<pre><code>(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; if torch.cuda.is_available():\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\n... else:\n...     print(\"Can't find CUDA\")\n... \nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\nCan't find CUDA\n</code></pre>\n<p>Perhaps the README for this example should have that env flag deleted, or....?</p>", "body_text": "I'm running the examples/mnist/ code at https://github.com/pytorch/examples/tree/master/mnist.\nWhen I follow the README's instructions I get (running from bash):\n(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python main.py\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\nFiles already downloaded\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.297210\nTrain Epoch: 1 [640/60000 (1%)]\tLoss: 2.318286\nTrain Epoch: 1 [1280/60000 (2%)]\tLoss: 2.298914\nTrain Epoch: 1 [1920/60000 (3%)]\tLoss: 2.317417\nTrain Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295015\n^C\n\nBut my cards are enabled...\n~/pytorch/examples/mnist$ nvidia-smi\nSun Mar 19 15:50:14 2017       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN X (Pascal)    Off  | 0000:01:00.0      On |                  N/A |\n| 23%   27C    P8    10W / 250W |     63MiB / 12186MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\n| 23%   27C    P8     8W / 250W |      1MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1094    G   /usr/lib/xorg/Xorg                              60MiB |\n+-----------------------------------------------------------------------------+\n\n...and I've been running other PyTorch code that correctly detects my devices, for example,\n(py35) ~/pytorch/examples/mnist$ python\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import torch\n>>> if torch.cuda.is_available():\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\n... \nUsing CUDA, number of devices =  2\n>>> \n\n\nSeems like the use of the flag CUDA_VISIBLE_DEVICES=2 actually disables CUDA, as shown...\n(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import torch\n>>> if torch.cuda.is_available():\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\n... else:\n...     print(\"Can't find CUDA\")\n... \nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\nCan't find CUDA\n\nPerhaps the README for this example should have that env flag deleted, or....?", "body": "I'm running the examples/mnist/ code at https://github.com/pytorch/examples/tree/master/mnist.\r\n\r\nWhen I follow the README's instructions I get (running from bash):\r\n\r\n```\r\n(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python main.py\r\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\r\nFiles already downloaded\r\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.297210\r\nTrain Epoch: 1 [640/60000 (1%)]\tLoss: 2.318286\r\nTrain Epoch: 1 [1280/60000 (2%)]\tLoss: 2.298914\r\nTrain Epoch: 1 [1920/60000 (3%)]\tLoss: 2.317417\r\nTrain Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295015\r\n^C\r\n``` \r\n\r\nBut my cards are enabled...\r\n```\r\n~/pytorch/examples/mnist$ nvidia-smi\r\nSun Mar 19 15:50:14 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 0000:01:00.0      On |                  N/A |\r\n| 23%   27C    P8    10W / 250W |     63MiB / 12186MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A |\r\n| 23%   27C    P8     8W / 250W |      1MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1094    G   /usr/lib/xorg/Xorg                              60MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n...and I've been running other PyTorch code that correctly detects my devices, for example,\r\n\r\n\r\n```\r\n(py35) ~/pytorch/examples/mnist$ python\r\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \r\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> if torch.cuda.is_available():\r\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\r\n... \r\nUsing CUDA, number of devices =  2\r\n>>> \r\n\r\n```\r\nSeems like the use of the flag CUDA_VISIBLE_DEVICES=2 actually *disables* CUDA, as shown...\r\n\r\n```\r\n(py35) ~/pytorch/examples/mnist$ CUDA_VISIBLE_DEVICES=2 python\r\nPython 3.5.2 |Anaconda 4.3.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \r\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> if torch.cuda.is_available():\r\n...     print(\"Using CUDA, number of devices = \",torch.cuda.device_count())\r\n... else:\r\n...     print(\"Can't find CUDA\")\r\n... \r\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=109 error=38 : no CUDA-capable device is detected\r\nCan't find CUDA\r\n```\r\n\r\n\r\nPerhaps the README for this example should have that env flag deleted, or....?\r\n"}