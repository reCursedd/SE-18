{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/375933192", "html_url": "https://github.com/pytorch/pytorch/pull/4594#issuecomment-375933192", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4594", "id": 375933192, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NTkzMzE5Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-24T23:43:37Z", "updated_at": "2018-03-24T23:43:37Z", "author_association": "MEMBER", "body_html": "<ol>\n<li>It's not like it's not used. It is pretty much necessary if you want to use higher order gradients or want to manually split backward into multiple steps.</li>\n<li>What kind of better data packing do you have in mind? To be honest I would be very worries if this diff would increase the speed of some networks, because that would suggest that there's a bug somewhere (it does more work than the naive thing!).</li>\n<li>Yep. Would be great if we could avoid that.</li>\n</ol>\n<p>I guess a good enough approximation for now would be to have a counter which says how many <code>.grad</code>s in are you currently, and raise an error in the checkpointed function if it's &gt; 0.</p>", "body_text": "It's not like it's not used. It is pretty much necessary if you want to use higher order gradients or want to manually split backward into multiple steps.\nWhat kind of better data packing do you have in mind? To be honest I would be very worries if this diff would increase the speed of some networks, because that would suggest that there's a bug somewhere (it does more work than the naive thing!).\nYep. Would be great if we could avoid that.\n\nI guess a good enough approximation for now would be to have a counter which says how many .grads in are you currently, and raise an error in the checkpointed function if it's > 0.", "body": "1. It's not like it's not used. It is pretty much necessary if you want to use higher order gradients or want to manually split backward into multiple steps.\r\n2. What kind of better data packing do you have in mind? To be honest I would be very worries if this diff would increase the speed of some networks, because that would suggest that there's a bug somewhere (it does more work than the naive thing!).\r\n3. Yep. Would be great if we could avoid that.\r\n\r\nI guess a good enough approximation for now would be to have a counter which says how many `.grad`s in are you currently, and raise an error in the checkpointed function if it's > 0."}