{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195346771", "pull_request_review_id": 128695675, "id": 195346771, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTM0Njc3MQ==", "diff_hunk": "@@ -3026,6 +3043,404 @@ def fn(x):\n         self.checkScript(fn, (torch.tensor(2),))\n \n \n+class TestEndToEndHybridFrontendModels(JitTestCase):\n+\n+    def test_dcgan_models(self):\n+        class DCGANGenerator(nn.Module):\n+            def __init__(self, nz, ngf, nc):\n+                super(DCGANGenerator, self).__init__()\n+                self.main = nn.Sequential(\n+                    # input is Z, going into a convolution\n+                    nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n+                    nn.BatchNorm2d(ngf * 8),\n+                    nn.ReLU(True),\n+                    # state size. (ngf*8) x 4 x 4\n+                    nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ngf * 4),\n+                    nn.ReLU(True),\n+                    # state size. (ngf*4) x 8 x 8\n+                    nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ngf * 2),\n+                    nn.ReLU(True),\n+                    # state size. (ngf*2) x 16 x 16\n+                    nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ngf),\n+                    nn.ReLU(True),\n+                    # state size. (ngf) x 32 x 32\n+                    nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n+                    nn.Tanh()\n+                    # state size. (nc) x 64 x 64\n+                )\n+\n+            def forward(self, input):\n+                return self.main(input)\n+\n+        class DCGANDiscriminator(nn.Module):\n+            def __init__(self, nc, ndf):\n+                super(DCGANDiscriminator, self).__init__()\n+                self.main = nn.Sequential(\n+                    # input is (nc) x 64 x 64\n+                    nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n+                    nn.LeakyReLU(0.2, inplace=True),\n+                    # state size. (ndf) x 32 x 32\n+                    nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ndf * 2),\n+                    nn.LeakyReLU(0.2, inplace=True),\n+                    # state size. (ndf*2) x 16 x 16\n+                    nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ndf * 4),\n+                    nn.LeakyReLU(0.2, inplace=True),\n+                    # state size. (ndf*4) x 8 x 8\n+                    nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n+                    nn.BatchNorm2d(ndf * 8),\n+                    nn.LeakyReLU(0.2, inplace=True),\n+                    # state size. (ndf*8) x 4 x 4\n+                    nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n+                    nn.Sigmoid()\n+                )\n+\n+            def forward(self, input):\n+                return self.main(input).view(-1, 1).squeeze(1)\n+\n+        bs, nz, ngf, nc, ndf = 5, 6, 9, 3, 10\n+        self.checkTrace(DCGANGenerator(nz, ngf, nc), (torch.rand(bs, nz, 1, 1),))\n+        example_input = DCGANGenerator(nz, ngf, nc)(torch.rand(bs, nz, 1, 1))\n+        self.checkTrace(DCGANDiscriminator(nc, ndf), (example_input,))\n+\n+    @unittest.skip('https://github.com/pytorch/pytorch/issues/8439 InstanceNormalization bug')\n+    def test_neural_style(self):\n+        class TransformerNet(torch.nn.Module):\n+            def __init__(self):\n+                super(TransformerNet, self).__init__()\n+                # Initial convolution layers\n+                self.conv1 = ConvLayer(3, 32, kernel_size=9, stride=1)\n+                self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n+                self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n+                self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n+                self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n+                self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n+                # Residual layers\n+                self.res1 = ResidualBlock(128)\n+                self.res2 = ResidualBlock(128)\n+                self.res3 = ResidualBlock(128)\n+                self.res4 = ResidualBlock(128)\n+                self.res5 = ResidualBlock(128)\n+                # Upsampling Layers\n+                self.deconv1 = UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2)\n+                self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n+                self.deconv2 = UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2)\n+                self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n+                self.deconv3 = ConvLayer(32, 3, kernel_size=9, stride=1)\n+                # Non-linearities\n+                self.relu = torch.nn.ReLU()\n+\n+            def forward(self, X):\n+                y = self.relu(self.in1(self.conv1(X)))\n+                y = self.relu(self.in2(self.conv2(y)))\n+                y = self.relu(self.in3(self.conv3(y)))\n+                y = self.res1(y)\n+                y = self.res2(y)\n+                y = self.res3(y)\n+                y = self.res4(y)\n+                y = self.res5(y)\n+                y = self.relu(self.in4(self.deconv1(y)))\n+                y = self.relu(self.in5(self.deconv2(y)))\n+                y = self.deconv3(y)\n+                return y\n+\n+        class ConvLayer(torch.nn.Module):\n+            def __init__(self, in_channels, out_channels, kernel_size, stride):\n+                super(ConvLayer, self).__init__()\n+                reflection_padding = kernel_size // 2\n+                self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n+                self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n+\n+            def forward(self, x):\n+                out = self.reflection_pad(x)\n+                out = self.conv2d(out)\n+                return out\n+\n+        class ResidualBlock(torch.nn.Module):\n+            \"\"\"ResidualBlock\n+            introduced in: https://arxiv.org/abs/1512.03385\n+            recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html\n+            \"\"\"\n+\n+            def __init__(self, channels):\n+                super(ResidualBlock, self).__init__()\n+                self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n+                self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n+                self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n+                self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n+                self.relu = torch.nn.ReLU()\n+\n+            def forward(self, x):\n+                residual = x\n+                out = self.relu(self.in1(self.conv1(x)))\n+                out = self.in2(self.conv2(out))\n+                out = out + residual\n+                return out\n+\n+        class UpsampleConvLayer(torch.nn.Module):\n+            \"\"\"UpsampleConvLayer\n+            Upsamples the input and then does a convolution. This method gives better results\n+            compared to ConvTranspose2d.\n+            ref: http://distill.pub/2016/deconv-checkerboard/\n+            \"\"\"\n+\n+            def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n+                super(UpsampleConvLayer, self).__init__()\n+                self.upsample = upsample\n+                if upsample:\n+                    self.upsample_layer = torch.nn.Upsample(mode='nearest', scale_factor=upsample)\n+                reflection_padding = kernel_size // 2\n+                self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n+                self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n+\n+            def forward(self, x):\n+                x_in = x\n+                if self.upsample:\n+                    x_in = self.upsample_layer(x_in)\n+                out = self.reflection_pad(x_in)\n+                out = self.conv2d(out)\n+                return out\n+\n+        self.checkTrace(TransformerNet(), (torch.rand(5, 3, 224, 224),))\n+\n+    def test_mnist(self):\n+        class Net(nn.Module):\n+            def __init__(self):\n+                super(Net, self).__init__()\n+                self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n+                self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n+                self.conv2_drop = nn.Dropout2d()\n+                self.fc1 = nn.Linear(320, 50)\n+                self.fc2 = nn.Linear(50, 10)\n+\n+            def forward(self, x):\n+                x = F.relu(F.max_pool2d(self.conv1(x), 2))\n+                x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n+                x = x.view(-1, 320)\n+                x = F.relu(self.fc1(x))\n+                x = F.dropout(x, training=self.training)\n+                x = self.fc2(x)\n+                return F.log_softmax(x, dim=1)\n+\n+        # FIXME: eval() is present because it works around the issue described\n+        # in https://github.com/pytorch/pytorch/issues/8448\n+        self.checkTrace(Net().eval(), (torch.rand(5, 1, 28, 28),))\n+\n+    def test_reinforcement_learning(self):\n+        class Policy(nn.Module):\n+            def __init__(self):\n+                super(Policy, self).__init__()\n+                self.affine1 = nn.Linear(4, 128)\n+                self.affine2 = nn.Linear(128, 2)\n+\n+                self.saved_log_probs = []\n+                self.rewards = []\n+\n+            def forward(self, x):\n+                x = F.relu(self.affine1(x))\n+                action_scores = self.affine2(x)\n+                return F.softmax(action_scores, dim=1)\n+\n+        self.checkTrace(Policy(), (torch.rand(1, 4),))\n+\n+    def test_snli(self):\n+        # TODO:\n+        #   1) nn.LSTM is called as a Python function https://github.com/pytorch/pytorch/issues/8449\n+        #   2) Dropout is called as a Python function https://github.com/pytorch/pytorch/issues/8450\n+        class Bottle(nn.Module):\n+\n+            def forward(self, input):\n+                if len(input.size()) <= 2:\n+                    return super(Bottle, self).forward(input)\n+                size = input.size()[:2]\n+                out = super(Bottle, self).forward(input.view(size[0] * size[1], -1))\n+                return out.view(size[0], size[1], -1)\n+\n+        class Linear(Bottle, nn.Linear):\n+            pass\n+\n+        class Encoder(nn.Module):\n+\n+            def __init__(self, config):\n+                super(Encoder, self).__init__()\n+                self.config = config\n+                input_size = config.d_proj if config.projection else config.d_embed\n+                dropout = 0 if config.n_layers == 1 else config.dp_ratio\n+                self.rnn = nn.LSTM(input_size=input_size, hidden_size=config.d_hidden,\n+                                   num_layers=config.n_layers, dropout=dropout,\n+                                   bidirectional=config.birnn)\n+\n+            def forward(self, inputs):\n+                batch_size = inputs.size()[1]\n+                state_shape = self.config.n_cells, batch_size, self.config.d_hidden\n+                h0 = c0 = inputs.new_zeros(state_shape)\n+                outputs, (ht, ct) = self.rnn(inputs, (h0, c0))\n+                return ht[-1] if not self.config.birnn else ht[-2:].transpose(0, 1).contiguous().view(batch_size, -1)\n+\n+        class SNLIClassifier(nn.Module):\n+\n+            def __init__(self, config):\n+                super(SNLIClassifier, self).__init__()\n+                self.config = config\n+                self.embed = nn.Embedding(config.n_embed, config.d_embed)\n+                self.projection = Linear(config.d_embed, config.d_proj)\n+                self.encoder = Encoder(config)\n+                self.dropout = nn.Dropout(p=config.dp_ratio)\n+                self.relu = nn.ReLU()\n+                seq_in_size = 2 * config.d_hidden\n+                if self.config.birnn:\n+                    seq_in_size *= 2\n+                lin_config = [seq_in_size] * 2\n+                self.out = nn.Sequential(\n+                    Linear(*lin_config),\n+                    self.relu,\n+                    self.dropout,\n+                    Linear(*lin_config),\n+                    self.relu,\n+                    self.dropout,\n+                    Linear(*lin_config),\n+                    self.relu,\n+                    self.dropout,\n+                    Linear(seq_in_size, config.d_out))\n+\n+            def forward(self, premise, hypothesis):\n+                prem_embed = self.embed(premise)\n+                hypo_embed = self.embed(hypothesis)\n+                if self.config.fix_emb:\n+                    prem_embed = prem_embed.detach()\n+                    hypo_embed = hypo_embed.detach()\n+                if self.config.projection:\n+                    prem_embed = self.relu(self.projection(prem_embed))\n+                    hypo_embed = self.relu(self.projection(hypo_embed))\n+                premise = self.encoder(prem_embed)\n+                hypothesis = self.encoder(hypo_embed)\n+                scores = self.out(torch.cat([premise, hypothesis], 1))\n+                return scores\n+\n+        class Config:\n+            n_embed = 100\n+            d_embed = 100\n+            d_proj = 300\n+            dp_ratio = 0.0  # For deterministic testing TODO: change by fixing seed in checkTrace?\n+            d_hidden = 300\n+            birnn = True\n+            d_out = 300\n+            fix_emb = True\n+            projection = True\n+            n_layers = 2\n+            n_cells = 4  # 2 * n_layers because birnn = True\n+\n+        premise = torch.LongTensor(48, 128).random_(0, 100)\n+        hypothesis = torch.LongTensor(24, 128).random_(0, 100)\n+\n+        self.checkTrace(SNLIClassifier(Config()), (premise, hypothesis), inputs_require_grads=False, verbose=True)\n+\n+    def test_super_resolution(self):\n+        import torch.nn.init as init\n+\n+        class Net(nn.Module):\n+\n+            def __init__(self, upscale_factor):\n+                super(Net, self).__init__()\n+\n+                self.relu = nn.ReLU()\n+                self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n+                self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n+                self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n+                self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n+                self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n+\n+                self._initialize_weights()\n+\n+            def forward(self, x):\n+                x = self.relu(self.conv1(x))\n+                x = self.relu(self.conv2(x))\n+                x = self.relu(self.conv3(x))\n+                x = self.pixel_shuffle(self.conv4(x))\n+                return x\n+\n+            def _initialize_weights(self):\n+                init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n+                init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n+                init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n+                init.orthogonal_(self.conv4.weight)\n+\n+        net = Net(upscale_factor=4)\n+        net._initialize_weights()", "path": "test/test_jit.py", "position": null, "original_position": 496, "commit_id": "5c5cca36d71dfe035f7d339541ad9994e757d6e5", "original_commit_id": "43719789fc2d69baf805e2cac16dffd0b46fab2c", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "This looks unnecessary. Can you remove `_initialize_weights` altogether? It doesn't even take part in tracing", "created_at": "2018-06-14T08:55:12Z", "updated_at": "2018-11-23T15:45:31Z", "html_url": "https://github.com/pytorch/pytorch/pull/8451#discussion_r195346771", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8451", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195346771"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8451#discussion_r195346771"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8451"}}, "body_html": "<p>This looks unnecessary. Can you remove <code>_initialize_weights</code> altogether? It doesn't even take part in tracing</p>", "body_text": "This looks unnecessary. Can you remove _initialize_weights altogether? It doesn't even take part in tracing"}