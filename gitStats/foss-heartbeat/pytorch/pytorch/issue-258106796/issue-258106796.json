{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2751", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2751/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2751/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2751/events", "html_url": "https://github.com/pytorch/pytorch/pull/2751", "id": 258106796, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQxMzU5NDc0", "number": 2751, "title": "Specifying the value used for padding", "user": {"login": "hassyGo", "id": 8895515, "node_id": "MDQ6VXNlcjg4OTU1MTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/8895515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hassyGo", "html_url": "https://github.com/hassyGo", "followers_url": "https://api.github.com/users/hassyGo/followers", "following_url": "https://api.github.com/users/hassyGo/following{/other_user}", "gists_url": "https://api.github.com/users/hassyGo/gists{/gist_id}", "starred_url": "https://api.github.com/users/hassyGo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hassyGo/subscriptions", "organizations_url": "https://api.github.com/users/hassyGo/orgs", "repos_url": "https://api.github.com/users/hassyGo/repos", "events_url": "https://api.github.com/users/hassyGo/events{/privacy}", "received_events_url": "https://api.github.com/users/hassyGo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-15T17:12:56Z", "updated_at": "2018-11-23T15:34:37Z", "closed_at": "2017-09-18T18:48:11Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/2751", "html_url": "https://github.com/pytorch/pytorch/pull/2751", "diff_url": "https://github.com/pytorch/pytorch/pull/2751.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/2751.patch"}, "body_html": "<p>The \"pad_packed_sequence\" function fills padded elements with zeros, but sometimes it is not useful. For example, some previous papers on NLP, including my recent paper [1], use a max-pooling technique for RNN-based sentence representations. More specifically, the max-pooling technique selects the maximum value from all time steps (i.e., hidden states) for each dimension. In such a case, we do not want the padded zeros to be selected. To overcome this situation, we can simply use a very small value instead of zero.</p>\n<p>An LSTM example is shown below:</p>\n<p>input = embedding(Variable(batchInput))<br>\npackedInput = torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first = True)<br>\nh, (hn, cn) = lstm(packedInput, (h0, c0))<br>\nh, _ = torch.nn.utils.rnn.pad_packed_sequence(h, -1024.0, batch_first = True)<br>\nsentenceRep, _ = torch.max(h, 1, keepdim = True)</p>\n<p>[1] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks. Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and Richard Socher. The 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017).<br>\n<a href=\"https://arxiv.org/abs/1611.01587\" rel=\"nofollow\">https://arxiv.org/abs/1611.01587</a> (Equation (4))</p>", "body_text": "The \"pad_packed_sequence\" function fills padded elements with zeros, but sometimes it is not useful. For example, some previous papers on NLP, including my recent paper [1], use a max-pooling technique for RNN-based sentence representations. More specifically, the max-pooling technique selects the maximum value from all time steps (i.e., hidden states) for each dimension. In such a case, we do not want the padded zeros to be selected. To overcome this situation, we can simply use a very small value instead of zero.\nAn LSTM example is shown below:\ninput = embedding(Variable(batchInput))\npackedInput = torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first = True)\nh, (hn, cn) = lstm(packedInput, (h0, c0))\nh, _ = torch.nn.utils.rnn.pad_packed_sequence(h, -1024.0, batch_first = True)\nsentenceRep, _ = torch.max(h, 1, keepdim = True)\n[1] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks. Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and Richard Socher. The 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017).\nhttps://arxiv.org/abs/1611.01587 (Equation (4))", "body": "The \"pad_packed_sequence\" function fills padded elements with zeros, but sometimes it is not useful. For example, some previous papers on NLP, including my recent paper [1], use a max-pooling technique for RNN-based sentence representations. More specifically, the max-pooling technique selects the maximum value from all time steps (i.e., hidden states) for each dimension. In such a case, we do not want the padded zeros to be selected. To overcome this situation, we can simply use a very small value instead of zero.\r\n\r\nAn LSTM example is shown below:\r\n\r\ninput = embedding(Variable(batchInput))\r\npackedInput = torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first = True)\r\nh, (hn, cn) = lstm(packedInput, (h0, c0))\r\nh, _ = torch.nn.utils.rnn.pad_packed_sequence(h, -1024.0, batch_first = True)\r\nsentenceRep, _ = torch.max(h, 1, keepdim = True)\r\n\r\n[1] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks. Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and Richard Socher. The 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017).\r\nhttps://arxiv.org/abs/1611.01587 (Equation (4))"}