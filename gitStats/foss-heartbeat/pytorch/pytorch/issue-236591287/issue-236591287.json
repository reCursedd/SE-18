{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1827", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1827/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1827/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1827/events", "html_url": "https://github.com/pytorch/pytorch/issues/1827", "id": 236591287, "node_id": "MDU6SXNzdWUyMzY1OTEyODc=", "number": 1827, "title": "th.distributed.all_reduce() memory leak", "user": {"login": "seba-1511", "id": 626253, "node_id": "MDQ6VXNlcjYyNjI1Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/626253?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seba-1511", "html_url": "https://github.com/seba-1511", "followers_url": "https://api.github.com/users/seba-1511/followers", "following_url": "https://api.github.com/users/seba-1511/following{/other_user}", "gists_url": "https://api.github.com/users/seba-1511/gists{/gist_id}", "starred_url": "https://api.github.com/users/seba-1511/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seba-1511/subscriptions", "organizations_url": "https://api.github.com/users/seba-1511/orgs", "repos_url": "https://api.github.com/users/seba-1511/repos", "events_url": "https://api.github.com/users/seba-1511/events{/privacy}", "received_events_url": "https://api.github.com/users/seba-1511/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2017-06-16T20:43:43Z", "updated_at": "2017-07-13T06:14:37Z", "closed_at": "2017-07-13T06:14:37Z", "author_association": "NONE", "body_html": "<p>The following snippet runs out of memory. Commenting the all_reduce solves the issue.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span>!/usr/bin/env python</span>\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> torch <span class=\"pl-k\">as</span> th\n<span class=\"pl-k\">import</span> torch.distributed <span class=\"pl-k\">as</span> dist\n<span class=\"pl-k\">from</span> torch.multiprocessing <span class=\"pl-k\">import</span> Process\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\">rank</span>, <span class=\"pl-smi\">size</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Distributed function to be implemented later. <span class=\"pl-pds\">\"\"\"</span></span>\n    t <span class=\"pl-k\">=</span> th.rand(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>)\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10000000</span>):\n        c <span class=\"pl-k\">=</span> t.clone()\n        dist.all_reduce(c, dist.reduce_op.<span class=\"pl-c1\">SUM</span>)\n        t.set_(c)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">init_processes</span>(<span class=\"pl-smi\">rank</span>, <span class=\"pl-smi\">size</span>, <span class=\"pl-smi\">fn</span>, <span class=\"pl-smi\">backend</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>tcp<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Initialize the distributed environment. <span class=\"pl-pds\">\"\"\"</span></span>\n    os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>MASTER_ADDR<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>127.0.0.1<span class=\"pl-pds\">'</span></span>\n    os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>MASTER_PORT<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>29500<span class=\"pl-pds\">'</span></span>\n    dist.init_process_group(backend, <span class=\"pl-v\">rank</span><span class=\"pl-k\">=</span>rank, <span class=\"pl-v\">world_size</span><span class=\"pl-k\">=</span>size)\n    fn(rank, size)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\n    processes <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> rank <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(size):\n        p <span class=\"pl-k\">=</span> Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>init_processes, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> processes:\n        p.join()</pre></div>\n<p><strong>Possible issue</strong>: the retain statements in <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/lib/THD/base/TensorDescriptor.cpp#L8\">https://github.com/pytorch/pytorch/blob/master/torch/lib/THD/base/TensorDescriptor.cpp#L8</a></p>", "body_text": "The following snippet runs out of memory. Commenting the all_reduce solves the issue.\n#!/usr/bin/env python\nimport os\nimport torch as th\nimport torch.distributed as dist\nfrom torch.multiprocessing import Process\n\ndef run(rank, size):\n    \"\"\" Distributed function to be implemented later. \"\"\"\n    t = th.rand(100, 100)\n    for _ in range(10000000):\n        c = t.clone()\n        dist.all_reduce(c, dist.reduce_op.SUM)\n        t.set_(c)\n\ndef init_processes(rank, size, fn, backend='tcp'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank, world_size=size)\n    fn(rank, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    for rank in range(size):\n        p = Process(target=init_processes, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\nPossible issue: the retain statements in https://github.com/pytorch/pytorch/blob/master/torch/lib/THD/base/TensorDescriptor.cpp#L8", "body": "The following snippet runs out of memory. Commenting the all_reduce solves the issue.\r\n\r\n```python\r\n#!/usr/bin/env python\r\nimport os\r\nimport torch as th\r\nimport torch.distributed as dist\r\nfrom torch.multiprocessing import Process\r\n\r\ndef run(rank, size):\r\n    \"\"\" Distributed function to be implemented later. \"\"\"\r\n    t = th.rand(100, 100)\r\n    for _ in range(10000000):\r\n        c = t.clone()\r\n        dist.all_reduce(c, dist.reduce_op.SUM)\r\n        t.set_(c)\r\n\r\ndef init_processes(rank, size, fn, backend='tcp'):\r\n    \"\"\" Initialize the distributed environment. \"\"\"\r\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\r\n    os.environ['MASTER_PORT'] = '29500'\r\n    dist.init_process_group(backend, rank=rank, world_size=size)\r\n    fn(rank, size)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    size = 4\r\n    processes = []\r\n    for rank in range(size):\r\n        p = Process(target=init_processes, args=(rank, size, run))\r\n        p.start()\r\n        processes.append(p)\r\n\r\n    for p in processes:\r\n        p.join()\r\n```\r\n\r\n**Possible issue**: the retain statements in https://github.com/pytorch/pytorch/blob/master/torch/lib/THD/base/TensorDescriptor.cpp#L8"}