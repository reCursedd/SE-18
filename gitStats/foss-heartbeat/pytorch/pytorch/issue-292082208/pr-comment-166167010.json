{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166167010", "pull_request_review_id": 94204023, "id": 166167010, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjE2NzAxMA==", "diff_hunk": "@@ -117,14 +122,34 @@ def __init__(self, module, device_ids=None, output_device=None, dim=0):\n         else:\n             self._module_copies = [self.module]\n \n+        # Split parameters into type buckets so that parameter sync (broadcast)\n+        # can operates on mixed parameter types. (e.g. mixed half and float)\n+        self.param_type_buckets = {}\n+        for device_idx, module in enumerate(self._module_copies):\n+            for p in module.parameters():\n+                tp = type(p.data)\n+                if tp == torch.cuda.HalfTensor and \\\n+                        dist._backend != dist.dist_backend.NCCL:\n+                    raise RuntimeError(\"DistributedDataParallel currently only \"\n+                                       \"supports half precision parameters \"\n+                                       \"with NCCL backend\")\n+                if tp not in self.param_type_buckets:\n+                    self.param_type_buckets[tp] = \\\n+                        [[] for _ in range(len(self.device_ids))]\n+                # Add the parameter into the type bucket\n+                self.param_type_buckets[tp][device_idx].append(p)\n+\n         # Split parameters into buckets that will coalesce reductions\n-        # TODO: different types need different buckets\n-        t = None\n-        for p in self.module.parameters():\n-            tp = type(p.data)\n-            if t is not None and t is not tp:\n-                raise ValueError(\"DistributedDataParallel requires all parameters' data to be of the same type\")\n-            t = tp\n+        #\n+        # Note that the NCCL backend currently only supports a single reduction\n+        # bucket, so instead of splitting different Tensor types (half, float,\n+        # double, etc) into separate buckets, which will form multipel buckets,\n+        # we will split the parameters into reduction buckets regardless of\n+        # the data types here.", "path": "torch/nn/parallel/distributed.py", "position": null, "original_position": 62, "commit_id": "0a6d068ab9c8084ebc38a0f08e84929c68374cd5", "original_commit_id": "c2c0cc2fd6a88940c16be4b6cc7c60746e10a7f6", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "This is mainly for the purpose of NCCL backend since it will only supports a single reduction thread. \r\nNow that NCCL is going to a separate path in https://github.com/pytorch/pytorch/pull/5064/files.  I guess we can directly bucketing the reduction bucket as you said. ", "created_at": "2018-02-06T01:45:37Z", "updated_at": "2018-11-23T15:39:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/4891#discussion_r166167010", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4891", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166167010"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4891#discussion_r166167010"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4891"}}, "body_html": "<p>This is mainly for the purpose of NCCL backend since it will only supports a single reduction thread.<br>\nNow that NCCL is going to a separate path in <a href=\"https://github.com/pytorch/pytorch/pull/5064/files\">https://github.com/pytorch/pytorch/pull/5064/files</a>.  I guess we can directly bucketing the reduction bucket as you said.</p>", "body_text": "This is mainly for the purpose of NCCL backend since it will only supports a single reduction thread.\nNow that NCCL is going to a separate path in https://github.com/pytorch/pytorch/pull/5064/files.  I guess we can directly bucketing the reduction bucket as you said.", "in_reply_to_id": 166139357}