{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/290174693", "html_url": "https://github.com/pytorch/pytorch/issues/1137#issuecomment-290174693", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1137", "id": 290174693, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MDE3NDY5Mw==", "user": {"login": "lanpa", "id": 2005323, "node_id": "MDQ6VXNlcjIwMDUzMjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2005323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lanpa", "html_url": "https://github.com/lanpa", "followers_url": "https://api.github.com/users/lanpa/followers", "following_url": "https://api.github.com/users/lanpa/following{/other_user}", "gists_url": "https://api.github.com/users/lanpa/gists{/gist_id}", "starred_url": "https://api.github.com/users/lanpa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lanpa/subscriptions", "organizations_url": "https://api.github.com/users/lanpa/orgs", "repos_url": "https://api.github.com/users/lanpa/repos", "events_url": "https://api.github.com/users/lanpa/events{/privacy}", "received_events_url": "https://api.github.com/users/lanpa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-29T18:07:54Z", "updated_at": "2017-03-29T18:07:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If the data is not growing during training phase, I would treat this as a data cleanup task before training.</p>\n<p>However, you can override the default <code>__gettiem__()</code> as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torchvision.datasets <span class=\"pl-k\">as</span> dset\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ImageFolderEX</span>(<span class=\"pl-e\">dset</span>.<span class=\"pl-e\">ImageFolder</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        path, label <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.imgs[index]\n        <span class=\"pl-k\">try</span>:\n            img <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.loader(os.path.join(<span class=\"pl-c1\">self</span>.root, path))\n        <span class=\"pl-k\">except</span>:\n            <span class=\"pl-k\">pass</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span>your handling code</span>\n        <span class=\"pl-k\">return</span> [img, label]</pre></div>", "body_text": "If the data is not growing during training phase, I would treat this as a data cleanup task before training.\nHowever, you can override the default __gettiem__() as follows:\nimport torchvision.datasets as dset\nclass ImageFolderEX(dset.ImageFolder):\n    def __getitem__(self, index):\n        path, label = self.imgs[index]\n        try:\n            img = self.loader(os.path.join(self.root, path))\n        except:\n            pass #your handling code\n        return [img, label]", "body": "If the data is not growing during training phase, I would treat this as a data cleanup task before training.\r\n\r\nHowever, you can override the default `__gettiem__()` as follows:\r\n\r\n```python\r\nimport torchvision.datasets as dset\r\nclass ImageFolderEX(dset.ImageFolder):\r\n    def __getitem__(self, index):\r\n        path, label = self.imgs[index]\r\n        try:\r\n            img = self.loader(os.path.join(self.root, path))\r\n        except:\r\n            pass #your handling code\r\n        return [img, label]\r\n```"}