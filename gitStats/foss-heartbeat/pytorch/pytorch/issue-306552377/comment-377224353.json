{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377224353", "html_url": "https://github.com/pytorch/pytorch/issues/5879#issuecomment-377224353", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5879", "id": 377224353, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzIyNDM1Mw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-29T12:48:33Z", "updated_at": "2018-03-29T12:48:33Z", "author_association": "MEMBER", "body_html": "<p>Yes I understand that, and it is not true that you need to go through disk to get your data in a new process. I explicitly suggested <code>fork</code>, because it creates a copy-on-write snapshot of the whole memory of your process, including all the data you have inside. Then, you only read the data structures and dump them to disk, which should cause very limited duplication of pages <em>in-memory</em> (so has still low overhead) because of e.g. adjusting the refcounts.</p>\n<p>I also don't think we can do anything about it, so I'm closing the issue. Hope my comments will be useful!</p>", "body_text": "Yes I understand that, and it is not true that you need to go through disk to get your data in a new process. I explicitly suggested fork, because it creates a copy-on-write snapshot of the whole memory of your process, including all the data you have inside. Then, you only read the data structures and dump them to disk, which should cause very limited duplication of pages in-memory (so has still low overhead) because of e.g. adjusting the refcounts.\nI also don't think we can do anything about it, so I'm closing the issue. Hope my comments will be useful!", "body": "Yes I understand that, and it is not true that you need to go through disk to get your data in a new process. I explicitly suggested `fork`, because it creates a copy-on-write snapshot of the whole memory of your process, including all the data you have inside. Then, you only read the data structures and dump them to disk, which should cause very limited duplication of pages *in-memory* (so has still low overhead) because of e.g. adjusting the refcounts.\r\n\r\nI also don't think we can do anything about it, so I'm closing the issue. Hope my comments will be useful!"}