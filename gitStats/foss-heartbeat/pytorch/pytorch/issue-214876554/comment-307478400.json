{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/307478400", "html_url": "https://github.com/pytorch/pytorch/issues/1020#issuecomment-307478400", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1020", "id": 307478400, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzQ3ODQwMA==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-09T19:25:49Z", "updated_at": "2017-06-09T19:27:51Z", "author_association": "MEMBER", "body_html": "<p>The current softmax behavior for choice of dimension doesn't make much sense. We should allow the user to specify the dimension, but we should also choose a smart default.</p>\n<p>I think we should choose a default dim that's consistent across the input shapes. That leaves dim 0 and dim -1 (and dim 0 isn't a good choice). dim -1 is nice because it treats all the left-most dimensions like a \"batch\". This is consistent with broadcasting behavior, where the left-most dimensions get expanded. For example:</p>\n<p><code>F.softmax((input @ weight) + bias)</code></p>\n<p>The <code>input @ weight</code> generalizes from 2d to 3d+ dimensions by treating all the left-most dimensions the same way (as part of a batch/stack). Softmax should do the same thing.</p>", "body_text": "The current softmax behavior for choice of dimension doesn't make much sense. We should allow the user to specify the dimension, but we should also choose a smart default.\nI think we should choose a default dim that's consistent across the input shapes. That leaves dim 0 and dim -1 (and dim 0 isn't a good choice). dim -1 is nice because it treats all the left-most dimensions like a \"batch\". This is consistent with broadcasting behavior, where the left-most dimensions get expanded. For example:\nF.softmax((input @ weight) + bias)\nThe input @ weight generalizes from 2d to 3d+ dimensions by treating all the left-most dimensions the same way (as part of a batch/stack). Softmax should do the same thing.", "body": "The current softmax behavior for choice of dimension doesn't make much sense. We should allow the user to specify the dimension, but we should also choose a smart default.\r\n\r\nI think we should choose a default dim that's consistent across the input shapes. That leaves dim 0 and dim -1 (and dim 0 isn't a good choice). dim -1 is nice because it treats all the left-most dimensions like a \"batch\". This is consistent with broadcasting behavior, where the left-most dimensions get expanded. For example:\r\n\r\n```F.softmax((input @ weight) + bias)```\r\n\r\nThe `input @ weight` generalizes from 2d to 3d+ dimensions by treating all the left-most dimensions the same way (as part of a batch/stack). Softmax should do the same thing."}