{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13292", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13292/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13292/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13292/events", "html_url": "https://github.com/pytorch/pytorch/issues/13292", "id": 375312525, "node_id": "MDU6SXNzdWUzNzUzMTI1MjU=", "number": 13292, "title": "torch.flip incorrect behavior", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-10-30T04:09:05Z", "updated_at": "2018-11-08T04:32:19Z", "closed_at": "2018-11-08T04:32:19Z", "author_association": "MEMBER", "body_html": "<p>As reported on slack:</p>\n<p>Can somebody explain the behavior of <code>flip</code> to me? I would expect that <code>t.flip([a, b])</code> is a shorthand for <code>t.flip(a).flip(b)</code>, but this is not the case (see below). Does the tuple variant flip along a diagonal or what?</p>\n<pre><code>In [12]: t = torch.arange(3*4*5).reshape(1, 3, 4, 5)\n\nIn [13]: t.flip([1, 3]).shape\nOut[13]: torch.Size([5, 4, 3, 1])\n\nIn [14]: t.flip(1).flip(3).shape\nOut[14]: torch.Size([1, 3, 4, 5])\n</code></pre>\n<p>ngimel says:</p>\n<p>Looks like a bug. FWIW, flip on cuda tensor is not changing shape. There's some logic about permuting in the flip on cpu, that I don't quite get, may be it is to blame.<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/TensorTransformations.cpp#L33-L54\">https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/TensorTransformations.cpp#L33-L54</a></p>", "body_text": "As reported on slack:\nCan somebody explain the behavior of flip to me? I would expect that t.flip([a, b]) is a shorthand for t.flip(a).flip(b), but this is not the case (see below). Does the tuple variant flip along a diagonal or what?\nIn [12]: t = torch.arange(3*4*5).reshape(1, 3, 4, 5)\n\nIn [13]: t.flip([1, 3]).shape\nOut[13]: torch.Size([5, 4, 3, 1])\n\nIn [14]: t.flip(1).flip(3).shape\nOut[14]: torch.Size([1, 3, 4, 5])\n\nngimel says:\nLooks like a bug. FWIW, flip on cuda tensor is not changing shape. There's some logic about permuting in the flip on cpu, that I don't quite get, may be it is to blame.\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/TensorTransformations.cpp#L33-L54", "body": "As reported on slack:\r\n\r\nCan somebody explain the behavior of `flip` to me? I would expect that `t.flip([a, b])` is a shorthand for `t.flip(a).flip(b)`, but this is not the case (see below). Does the tuple variant flip along a diagonal or what?\r\n\r\n```\r\nIn [12]: t = torch.arange(3*4*5).reshape(1, 3, 4, 5)\r\n\r\nIn [13]: t.flip([1, 3]).shape\r\nOut[13]: torch.Size([5, 4, 3, 1])\r\n\r\nIn [14]: t.flip(1).flip(3).shape\r\nOut[14]: torch.Size([1, 3, 4, 5])\r\n```\r\n\r\nngimel says:\r\n\r\nLooks like a bug. FWIW, flip on cuda tensor is not changing shape. There's some logic about permuting in the flip on cpu, that I don't quite get, may be it is to blame.\r\nhttps://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/TensorTransformations.cpp#L33-L54\r\n"}