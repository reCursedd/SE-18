{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162082092", "pull_request_review_id": 89477638, "id": 162082092, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MjA4MjA5Mg==", "diff_hunk": "@@ -64,25 +69,30 @@ def logits(self):\n     def probs(self):\r\n         return logits_to_probs(self.logits, is_binary=True)\r\n \r\n+    @property\r\n+    def param_shape(self):\r\n+        return self._param.size()\r\n+\r\n     def sample(self, sample_shape=torch.Size()):\r\n         shape = self._extended_shape(sample_shape) + (self.total_count,)\r\n         return torch.bernoulli(self.probs.unsqueeze(-1).expand(shape)).sum(dim=-1)\r\n \r\n     def log_prob(self, value):\r\n         self._validate_log_prob_arg(value)\r\n-        probs = clamp_probs(self.probs)\r\n         log_factorial_n = math.lgamma(self.total_count + 1)\r\n         log_factorial_k = torch.lgamma(value + 1)\r\n         log_factorial_nmk = torch.lgamma(self.total_count - value + 1)\r\n+        max_val = (-self.logits).clamp(min=0.0)\r\n         return (log_factorial_n - log_factorial_k - log_factorial_nmk +\r\n-                value * self.logits + self.total_count * torch.log1p(-probs))\r\n+                value * self.logits + self.total_count * max_val -\r", "path": "torch/distributions/binomial.py", "position": null, "original_position": 47, "commit_id": "e7b2bbb187b455c58029aa4ac87fd0b85f47989b", "original_commit_id": "56d79469b1054671f207b14b7707c1704fd5730d", "user": {"login": "alicanb", "id": 1093846, "node_id": "MDQ6VXNlcjEwOTM4NDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1093846?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alicanb", "html_url": "https://github.com/alicanb", "followers_url": "https://api.github.com/users/alicanb/followers", "following_url": "https://api.github.com/users/alicanb/following{/other_user}", "gists_url": "https://api.github.com/users/alicanb/gists{/gist_id}", "starred_url": "https://api.github.com/users/alicanb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alicanb/subscriptions", "organizations_url": "https://api.github.com/users/alicanb/orgs", "repos_url": "https://api.github.com/users/alicanb/repos", "events_url": "https://api.github.com/users/alicanb/events{/privacy}", "received_events_url": "https://api.github.com/users/alicanb/received_events", "type": "User", "site_admin": false}, "body": "Sure, we can get rid of `clamp_probs` then, I think this was the only place that it's used. You can also add a note there that  `max_val - torch.log1p((self.logits + 2 * max_val).exp())) =  torch.log1p(-self.probs))` . It may help the readers in the future.", "created_at": "2018-01-17T15:23:04Z", "updated_at": "2018-11-23T15:38:15Z", "html_url": "https://github.com/pytorch/pytorch/pull/4691#discussion_r162082092", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4691", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162082092"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4691#discussion_r162082092"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4691"}}, "body_html": "<p>Sure, we can get rid of <code>clamp_probs</code> then, I think this was the only place that it's used. You can also add a note there that  <code>max_val - torch.log1p((self.logits + 2 * max_val).exp())) =  torch.log1p(-self.probs))</code> . It may help the readers in the future.</p>", "body_text": "Sure, we can get rid of clamp_probs then, I think this was the only place that it's used. You can also add a note there that  max_val - torch.log1p((self.logits + 2 * max_val).exp())) =  torch.log1p(-self.probs)) . It may help the readers in the future.", "in_reply_to_id": 161942277}