{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143434240", "pull_request_review_id": 67941927, "id": 143434240, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MzQzNDI0MA==", "diff_hunk": "@@ -0,0 +1,212 @@\n+#include \"nccl.h\"\n+#include \"torch/csrc/THP.h\"\n+#include \"torch/csrc/Types.h\"\n+#include \"torch/csrc/cuda/THCP.h\"\n+\n+#include <nccl.h>\n+#include <sstream>\n+#include <unordered_map>\n+\n+#ifdef ncclGroupStart\n+#define NCCL_VERSION 2\n+#endif\n+\n+static inline void CHECK(ncclResult_t status)\n+{\n+  if (status != ncclSuccess) {\n+    std::stringstream err;\n+    err << \"NCCL Error \" << status << \": \" << ncclGetErrorString(status);\n+    throw std::runtime_error(err.str());\n+  }\n+}\n+\n+// TODO: make this thread_local + add mutexes\n+std::unordered_map<std::string, std::unordered_map<int, ncclComm_t> > _communicators;\n+std::vector<ncclComm_t *> _all_communicators;\n+\n+PyObject * THCPModule_nccl_destroy(PyObject *args) {\n+  for(auto comm: _all_communicators) {\n+    ncclCommDestroy(*comm);\n+  }\n+  Py_RETURN_NONE;\n+}\n+\n+static std::unordered_map<int, ncclComm_t> _get_communicator(const int *devs, int ndevices) {\n+  std::stringstream hash;\n+  for (int i = 0; i < ndevices; i++) {\n+    hash << devs[i] << \",\";\n+  }\n+  if (_communicators.find(hash.str()) == _communicators.end()) {\n+    ncclComm_t *comms = (ncclComm_t*) malloc(sizeof(ncclComm_t) * ndevices);\n+    assert(comms);\n+    CHECK(ncclCommInitAll(comms, ndevices, devs));\n+    _all_communicators.push_back(comms);\n+    for (int i = 0; i < ndevices; i++) {\n+      _communicators[hash.str()][devs[i]] = comms[i];\n+    }\n+  }\n+  return _communicators[hash.str()];\n+}\n+\n+static void _check_inputs(THPObjectPtr &inputs, THPObjectPtr &outputs, int size_multiplier) {\n+  if (!PySequence_Check(inputs.get()) || !PySequence_Check(outputs.get())) {\n+    throw std::runtime_error(\"inputs and outputs have to be sequences of Tensors\");\n+  }\n+\n+  // len(inputs) == len(outputs)\n+  Py_ssize_t len = PySequence_Fast_GET_SIZE(inputs.get());", "path": "torch/csrc/cuda/nccl.cpp", "position": null, "original_position": 57, "commit_id": "a531a9ae90ee16ad5784cff1d0faa7278c0c2be5", "original_commit_id": "5edfbff975aaa43b8a66d0fca8f2e694de25b99a", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "You can't call `Fast` functions unless the object is a result of `PySequence_Fast`", "created_at": "2017-10-09T10:42:33Z", "updated_at": "2018-11-23T15:35:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/3028#discussion_r143434240", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3028", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143434240"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3028#discussion_r143434240"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3028"}}, "body_html": "<p>You can't call <code>Fast</code> functions unless the object is a result of <code>PySequence_Fast</code></p>", "body_text": "You can't call Fast functions unless the object is a result of PySequence_Fast"}