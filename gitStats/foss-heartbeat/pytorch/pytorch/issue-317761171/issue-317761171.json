{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6962", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6962/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6962/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6962/events", "html_url": "https://github.com/pytorch/pytorch/issues/6962", "id": 317761171, "node_id": "MDU6SXNzdWUzMTc3NjExNzE=", "number": 6962, "title": "PyTorch cuBLAS bindings are not thread-safe when used with multiple streams", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-25T19:23:50Z", "updated_at": "2018-04-25T19:24:36Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>PyTorch's cuBLAS bindings are not thread-safe when used with multiple streams on the same device. The underlying cuBLAS API <strong>is</strong> thread-safe, even with the same handle. However, each call in <a href=\"https://github.com/pytorch/pytorch/blob/333e8c9b227057635d365af96430cc6f4a1bab86/aten/src/THC/THCBlas.cu#L18-L19\"><code>aten/src/THC/THCBlas.cu</code></a> first sets the stream on the cuBLAS handle before calling into cuBLAS. These changes to the handle are visible to other threads. The handle's stream may change in between the call to <code>cublasSetStream</code> and the subsequent cuBLAS call.</p>\n<p>The <a href=\"https://docs.nvidia.com/cuda/cublas/index.html#thread-safety2\" rel=\"nofollow\">cuBLAS API</a> recommends using one cuBLAS handle per thread. We may not want to do this because threads are relatively light-weight, but creating and destroying handles is expensive (destroying the handle causes synchronizations). DataParallel, for example, creates new threads for each forward pass.</p>\n<p>Alternatively, we could use a mutex around the <code>cublasSetStream</code> and subsequent API call. The mutex should be per-cuBLAS handle (and the handles are per-device).</p>\n<p>We can also delete the \"reserve BLAS handles\" functionality from THC, since it is not used in PyTorch.</p>\n<p>Version: PyTorch master (0.5)</p>", "body_text": "PyTorch's cuBLAS bindings are not thread-safe when used with multiple streams on the same device. The underlying cuBLAS API is thread-safe, even with the same handle. However, each call in aten/src/THC/THCBlas.cu first sets the stream on the cuBLAS handle before calling into cuBLAS. These changes to the handle are visible to other threads. The handle's stream may change in between the call to cublasSetStream and the subsequent cuBLAS call.\nThe cuBLAS API recommends using one cuBLAS handle per thread. We may not want to do this because threads are relatively light-weight, but creating and destroying handles is expensive (destroying the handle causes synchronizations). DataParallel, for example, creates new threads for each forward pass.\nAlternatively, we could use a mutex around the cublasSetStream and subsequent API call. The mutex should be per-cuBLAS handle (and the handles are per-device).\nWe can also delete the \"reserve BLAS handles\" functionality from THC, since it is not used in PyTorch.\nVersion: PyTorch master (0.5)", "body": "PyTorch's cuBLAS bindings are not thread-safe when used with multiple streams on the same device. The underlying cuBLAS API **is** thread-safe, even with the same handle. However, each call in [`aten/src/THC/THCBlas.cu`](https://github.com/pytorch/pytorch/blob/333e8c9b227057635d365af96430cc6f4a1bab86/aten/src/THC/THCBlas.cu#L18-L19) first sets the stream on the cuBLAS handle before calling into cuBLAS. These changes to the handle are visible to other threads. The handle's stream may change in between the call to `cublasSetStream` and the subsequent cuBLAS call.\r\n\r\nThe [cuBLAS API](https://docs.nvidia.com/cuda/cublas/index.html#thread-safety2) recommends using one cuBLAS handle per thread. We may not want to do this because threads are relatively light-weight, but creating and destroying handles is expensive (destroying the handle causes synchronizations). DataParallel, for example, creates new threads for each forward pass.\r\n\r\nAlternatively, we could use a mutex around the `cublasSetStream` and subsequent API call. The mutex should be per-cuBLAS handle (and the handles are per-device).\r\n\r\nWe can also delete the \"reserve BLAS handles\" functionality from THC, since it is not used in PyTorch. \r\n \r\nVersion: PyTorch master (0.5)\r\n"}