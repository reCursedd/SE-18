{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4795", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4795/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4795/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4795/events", "html_url": "https://github.com/pytorch/pytorch/pull/4795", "id": 290693631, "node_id": "MDExOlB1bGxSZXF1ZXN0MTY0NDcyNTc2", "number": 4795, "title": "Enabling Infiniband support for Gloo data channel with auto IB detection", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-23T03:08:37Z", "updated_at": "2018-11-23T15:38:32Z", "closed_at": "2018-01-24T22:18:25Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4795", "html_url": "https://github.com/pytorch/pytorch/pull/4795", "diff_url": "https://github.com/pytorch/pytorch/pull/4795.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4795.patch"}, "body_html": "<p>This PR enables the proper and easy use of Infiniband support for Gloo backend of distributed training.</p>\n<p>Now simply just building PyTorch with</p>\n<p><code>python ./setup.py install </code></p>\n<p>will take care of everything by automatically detecting IB devices on the system.</p>\n<p>this helper function of gloo ::gloo::transport::ibverbs::getDeviceNames was added earlier by me to automatically find all IB interfaces in the system.</p>\n<p>For the Gloo data channel and cache. We now use a vector to store all the devices (not used currently, but will be able to easily extend in the future to support multiple IB devices).</p>\n<p>Also fixed the format error of the bcast gpu direct checking.</p>\n<p>Tested for both TCP and IB, both works fine.</p>\n<p>Snippet of build logs:</p>\n<pre><code>-- Found NCCL: /public/apps/NCCL/2.1.2-1/include\n-- Determining NCCL version from the header file: /public/apps/NCCL/2.1.2-1/include/nccl.h\n-- NCCL_MAJOR_VERSION: 2\n-- Found NCCL (include: /public/apps/NCCL/2.1.2-1/include, library: /public/apps/NCCL/2.1.2-1/lib/libnccl.so)\n-- Found MPI_C: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found MPI_CXX: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found Gloo: TRUE\n-- Found CUDA: /public/apps/cuda/9.0 (found suitable version \"9.0\", minimum required is \"7.5\")\n-- MPI_LIBRARIES: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found Gloo, will compile with Gloo distributed backend\n-- Building the gloo backend with both TCP and infiniband support\n-- NCCL_LIBRARIES: /public/apps/NCCL/2.1.2-1/lib/libnccl.so\n-- NCCL Version 2 or higher found, will compile with NCCL distributed backend\n</code></pre>\n<p><strong>PLUS</strong></p>\n<p>Added a helper script to automatically detect IB devices in the system and enable IB build by default. The user can have the option to force IB build as well using</p>\n<p><code>USE_GLOO_IBVERBS python ./setup.py install </code></p>\n<p><strong>IB detected</strong></p>\n<pre><code>running install\nrunning build_deps\n-- IB_detect: 4 IB devices detected, compiling with IB support.\n-- Autodetected CUDA architecture(s): 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n</code></pre>\n<p><strong>No IB detected</strong></p>\n<pre><code>running install\nrunning build_deps\n-- IB_detect: no IB device detected, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS\n-- Autodetected CUDA architecture(s): 6.0 6.0\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n</code></pre>\n<p><strong>No IB tool found</strong></p>\n<pre><code>running install\nrunning build_deps\n-- IB_detect: unable to detect IB devices, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS\n</code></pre>", "body_text": "This PR enables the proper and easy use of Infiniband support for Gloo backend of distributed training.\nNow simply just building PyTorch with\npython ./setup.py install \nwill take care of everything by automatically detecting IB devices on the system.\nthis helper function of gloo ::gloo::transport::ibverbs::getDeviceNames was added earlier by me to automatically find all IB interfaces in the system.\nFor the Gloo data channel and cache. We now use a vector to store all the devices (not used currently, but will be able to easily extend in the future to support multiple IB devices).\nAlso fixed the format error of the bcast gpu direct checking.\nTested for both TCP and IB, both works fine.\nSnippet of build logs:\n-- Found NCCL: /public/apps/NCCL/2.1.2-1/include\n-- Determining NCCL version from the header file: /public/apps/NCCL/2.1.2-1/include/nccl.h\n-- NCCL_MAJOR_VERSION: 2\n-- Found NCCL (include: /public/apps/NCCL/2.1.2-1/include, library: /public/apps/NCCL/2.1.2-1/lib/libnccl.so)\n-- Found MPI_C: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found MPI_CXX: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found Gloo: TRUE\n-- Found CUDA: /public/apps/cuda/9.0 (found suitable version \"9.0\", minimum required is \"7.5\")\n-- MPI_LIBRARIES: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\n-- Found Gloo, will compile with Gloo distributed backend\n-- Building the gloo backend with both TCP and infiniband support\n-- NCCL_LIBRARIES: /public/apps/NCCL/2.1.2-1/lib/libnccl.so\n-- NCCL Version 2 or higher found, will compile with NCCL distributed backend\n\nPLUS\nAdded a helper script to automatically detect IB devices in the system and enable IB build by default. The user can have the option to force IB build as well using\nUSE_GLOO_IBVERBS python ./setup.py install \nIB detected\nrunning install\nrunning build_deps\n-- IB_detect: 4 IB devices detected, compiling with IB support.\n-- Autodetected CUDA architecture(s): 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n\nNo IB detected\nrunning install\nrunning build_deps\n-- IB_detect: no IB device detected, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS\n-- Autodetected CUDA architecture(s): 6.0 6.0\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n\nNo IB tool found\nrunning install\nrunning build_deps\n-- IB_detect: unable to detect IB devices, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS", "body": "This PR enables the proper and easy use of Infiniband support for Gloo backend of distributed training. \r\n\r\nNow simply just building PyTorch with\r\n\r\n`python ./setup.py install\r\n`\r\n\r\nwill take care of everything by automatically detecting IB devices on the system.  \r\n\r\nthis helper function of gloo ::gloo::transport::ibverbs::getDeviceNames was added earlier by me to automatically find all IB interfaces in the system.\r\n\r\nFor the Gloo data channel and cache. We now use a vector to store all the devices (not used currently, but will be able to easily extend in the future to support multiple IB devices).\r\n\r\nAlso fixed the format error of the bcast gpu direct checking.\r\n\r\nTested for both TCP and IB, both works fine.\r\n\r\nSnippet of build logs:\r\n\r\n```\r\n-- Found NCCL: /public/apps/NCCL/2.1.2-1/include\r\n-- Determining NCCL version from the header file: /public/apps/NCCL/2.1.2-1/include/nccl.h\r\n-- NCCL_MAJOR_VERSION: 2\r\n-- Found NCCL (include: /public/apps/NCCL/2.1.2-1/include, library: /public/apps/NCCL/2.1.2-1/lib/libnccl.so)\r\n-- Found MPI_C: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\r\n-- Found MPI_CXX: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\r\n-- Found Gloo: TRUE\r\n-- Found CUDA: /public/apps/cuda/9.0 (found suitable version \"9.0\", minimum required is \"7.5\")\r\n-- MPI_LIBRARIES: /public/apps/openmpi/2.1.1/gcc.4.8.4/lib/libmpi.so\r\n-- Found Gloo, will compile with Gloo distributed backend\r\n-- Building the gloo backend with both TCP and infiniband support\r\n-- NCCL_LIBRARIES: /public/apps/NCCL/2.1.2-1/lib/libnccl.so\r\n-- NCCL Version 2 or higher found, will compile with NCCL distributed backend\r\n```\r\n\r\n**PLUS**\r\n\r\nAdded a helper script to automatically detect IB devices in the system and enable IB build by default. The user can have the option to force IB build as well using \r\n\r\n`USE_GLOO_IBVERBS python ./setup.py install\r\n`\r\n\r\n**IB detected**\r\n```\r\nrunning install\r\nrunning build_deps\r\n-- IB_detect: 4 IB devices detected, compiling with IB support.\r\n-- Autodetected CUDA architecture(s): 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0\r\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\r\n-- Removing -DNDEBUG from compile flags\r\n```\r\n\r\n**No IB detected**\r\n```\r\nrunning install\r\nrunning build_deps\r\n-- IB_detect: no IB device detected, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS\r\n-- Autodetected CUDA architecture(s): 6.0 6.0\r\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\r\n-- Removing -DNDEBUG from compile flags\r\n```\r\n\r\n**No IB tool found**\r\n```\r\nrunning install\r\nrunning build_deps\r\n-- IB_detect: unable to detect IB devices, compiling with no IB support by default unless overridden by WITH_GLOO_IBVERBS\r\n```"}