{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163349938", "pull_request_review_id": 90949676, "id": 163349938, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MzM0OTkzOA==", "diff_hunk": "@@ -375,31 +391,32 @@ struct algorithm_spec<CollectiveType::BROADCAST, T> {\n #ifdef WITH_CUDA\n     } else if (device == DeviceType::CUDA) {\n       auto stream = THCState_getCurrentStream(THDGetCudaState());\n-      \n-      #if defined(GLOO_USE_IBVERBS) && GLOO_USE_IBVERBS\n-            // Only enable GPU direct if the device supports it\n-            if (context->getDevice()->hasGPUDirect()) {\n-              algo = std::make_shared<::gloo::CudaBroadcastOneToAll<T,\n-                                      ::gloo::CudaDeviceWorkspace<T>>>(\n-                context,\n-                std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},\n-                count,\n-                src_rank,\n-                0,\n-                std::vector<cudaStream_t>{stream});\n-            } else\n-      #endif\n-            {\n-              algo = std::make_shared<::gloo::CudaBroadcastOneToAll<T,\n-                                      ::gloo::CudaHostWorkspace<T>>>( \n-                context,\n-                std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},\n-                count,\n-                src_rank,\n-                0,\n-                std::vector<cudaStream_t>{stream});\n-            }\n+\n+#if defined(WITH_GLOO_IBVERBS) && WITH_GLOO_IBVERBS\n+      // Only enable GPU direct if the device supports it\n+      if (context->getDevice()->hasGPUDirect()) {\n+        algo = std::make_shared<::gloo::CudaBroadcastOneToAll<T,\n+                                ::gloo::CudaDeviceWorkspace<T>>>(\n+          context,\n+          std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},\n+          count,\n+          src_rank,\n+          0,\n+          std::vector<cudaStream_t>{stream});\n+      } else\n #endif\n+      {\n+        algo = std::make_shared<::gloo::CudaBroadcastOneToAll<T,\n+                                ::gloo::CudaHostWorkspace<T>>>(\n+          context,\n+          std::initializer_list<T*>{reinterpret_cast<T*>(input_buffer.get())},\n+          count,\n+          src_rank,\n+          0,\n+          std::vector<cudaStream_t>{stream});\n+      }\n+#endif", "path": "torch/lib/THD/base/data_channels/GlooCache.hpp", "position": 110, "original_position": 110, "commit_id": "b45de3a1281aef5cfa14013ecdbad556e0c98f4c", "original_commit_id": "8647463fa1f32ff86cc8db34df23612263466cd9", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "It matches with WITH_CUDA.", "created_at": "2018-01-23T19:24:14Z", "updated_at": "2018-11-23T15:38:27Z", "html_url": "https://github.com/pytorch/pytorch/pull/4795#discussion_r163349938", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4795", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163349938"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4795#discussion_r163349938"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4795"}}, "body_html": "<p>It matches with WITH_CUDA.</p>", "body_text": "It matches with WITH_CUDA.", "in_reply_to_id": 163193313}