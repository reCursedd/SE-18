{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10535", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10535/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10535/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10535/events", "html_url": "https://github.com/pytorch/pytorch/pull/10535", "id": 350731655, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA4NTA1MDI1", "number": 10535, "title": "parallel norm operation for ATen on CPU", "user": {"login": "xhzhao", "id": 17486215, "node_id": "MDQ6VXNlcjE3NDg2MjE1", "avatar_url": "https://avatars1.githubusercontent.com/u/17486215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xhzhao", "html_url": "https://github.com/xhzhao", "followers_url": "https://api.github.com/users/xhzhao/followers", "following_url": "https://api.github.com/users/xhzhao/following{/other_user}", "gists_url": "https://api.github.com/users/xhzhao/gists{/gist_id}", "starred_url": "https://api.github.com/users/xhzhao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xhzhao/subscriptions", "organizations_url": "https://api.github.com/users/xhzhao/orgs", "repos_url": "https://api.github.com/users/xhzhao/repos", "events_url": "https://api.github.com/users/xhzhao/events{/privacy}", "received_events_url": "https://api.github.com/users/xhzhao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 559719279, "node_id": "MDU6TGFiZWw1NTk3MTkyNzk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/ready%20for%20review", "name": "ready for review", "color": "b60205", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-08-15T08:44:17Z", "updated_at": "2018-11-23T15:50:19Z", "closed_at": "2018-09-14T06:46:09Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10535", "html_url": "https://github.com/pytorch/pytorch/pull/10535", "diff_url": "https://github.com/pytorch/pytorch/pull/10535.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10535.patch"}, "body_html": "<p>optimize norm operation for ATen CPU path.<br>\nnorm is a very heavy operation in RNN related workloads, see OpenNMT-py <a href=\"https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/utils/optimizers.py#L227\">example</a>.<br>\nOur profiling show that norm takes about 8% in OpenNMT-py training time, which is not acceptable.</p>\n<p>currently, the code path from TH module runs in sequential on CPU, see <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMoreMath.cpp#L1937\">link</a>.<br>\nThe norm performance data compare before and after our optimization:</p>\n<table>\n<thead>\n<tr>\n<th>norm size</th>\n<th>SKX6148 OOB</th>\n<th>SKX6148 OPT</th>\n<th>speedup</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>[35820, 500]</td>\n<td>19.9693</td>\n<td>0.6204</td>\n<td>32.19</td>\n</tr>\n<tr>\n<td>[24997,   500]</td>\n<td>13.8752</td>\n<td>0.4370</td>\n<td>31.75</td>\n</tr>\n<tr>\n<td>[2000, 1000]</td>\n<td>2.1803</td>\n<td>0.0926</td>\n<td>23.53</td>\n</tr>\n<tr>\n<td>[2000,   500]</td>\n<td>1.0949</td>\n<td>0.0508</td>\n<td>21.55</td>\n</tr>\n<tr>\n<td>[500, 1000]</td>\n<td>0.5483</td>\n<td>0.0494</td>\n<td>11.10</td>\n</tr>\n<tr>\n<td>[500,   500]</td>\n<td>0.2758</td>\n<td>0.0494</td>\n<td>5.58</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th>norm size</th>\n<th>i7 OOB</th>\n<th>i7 OPT</th>\n<th>speedup</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>[35820, 500]</td>\n<td>18.0185</td>\n<td>3.8186</td>\n<td>4.72</td>\n</tr>\n<tr>\n<td>[24997,   500]</td>\n<td>12.5457</td>\n<td>2.5238</td>\n<td>4.97</td>\n</tr>\n<tr>\n<td>[2000, 1000]</td>\n<td>1.8258</td>\n<td>0.4204</td>\n<td>4.34</td>\n</tr>\n<tr>\n<td>[2000,   500]</td>\n<td>0.9252</td>\n<td>0.2391</td>\n<td>3.87</td>\n</tr>\n<tr>\n<td>[500, 1000]</td>\n<td>0.4696</td>\n<td>0.1129</td>\n<td>4.16</td>\n</tr>\n<tr>\n<td>[500,   500]</td>\n<td>0.2380</td>\n<td>0.0650</td>\n<td>3.66</td>\n</tr>\n</tbody>\n</table>", "body_text": "optimize norm operation for ATen CPU path.\nnorm is a very heavy operation in RNN related workloads, see OpenNMT-py example.\nOur profiling show that norm takes about 8% in OpenNMT-py training time, which is not acceptable.\ncurrently, the code path from TH module runs in sequential on CPU, see link.\nThe norm performance data compare before and after our optimization:\n\n\n\nnorm size\nSKX6148 OOB\nSKX6148 OPT\nspeedup\n\n\n\n\n[35820, 500]\n19.9693\n0.6204\n32.19\n\n\n[24997,   500]\n13.8752\n0.4370\n31.75\n\n\n[2000, 1000]\n2.1803\n0.0926\n23.53\n\n\n[2000,   500]\n1.0949\n0.0508\n21.55\n\n\n[500, 1000]\n0.5483\n0.0494\n11.10\n\n\n[500,   500]\n0.2758\n0.0494\n5.58\n\n\n\n\n\n\nnorm size\ni7 OOB\ni7 OPT\nspeedup\n\n\n\n\n[35820, 500]\n18.0185\n3.8186\n4.72\n\n\n[24997,   500]\n12.5457\n2.5238\n4.97\n\n\n[2000, 1000]\n1.8258\n0.4204\n4.34\n\n\n[2000,   500]\n0.9252\n0.2391\n3.87\n\n\n[500, 1000]\n0.4696\n0.1129\n4.16\n\n\n[500,   500]\n0.2380\n0.0650\n3.66", "body": "optimize norm operation for ATen CPU path. \r\nnorm is a very heavy operation in RNN related workloads, see OpenNMT-py [example](https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/utils/optimizers.py#L227).\r\nOur profiling show that norm takes about 8% in OpenNMT-py training time, which is not acceptable.\r\n\r\ncurrently, the code path from TH module runs in sequential on CPU, see [link](https://github.com/pytorch/pytorch/blob/master/aten/src/TH/generic/THTensorMoreMath.cpp#L1937).\r\nThe norm performance data compare before and after our optimization:\r\n\r\n\r\nnorm size | SKX6148 OOB | SKX6148 OPT | speedup\r\n-- | -- | -- | --\r\n[35820, 500] | 19.9693 | 0.6204 | 32.19\r\n[24997,   500] | 13.8752 | 0.4370 | 31.75\r\n[2000, 1000] | 2.1803 | 0.0926 | 23.53\r\n[2000,   500] | 1.0949 | 0.0508 | 21.55\r\n[500, 1000] | 0.5483 | 0.0494 | 11.10\r\n[500,   500] | 0.2758 | 0.0494 | 5.58\r\n\r\n\r\n\r\nnorm size | i7 OOB | i7 OPT | speedup\r\n-- | -- | -- | --\r\n[35820, 500] | 18.0185 | 3.8186 | 4.72\r\n[24997,   500] | 12.5457 | 2.5238 | 4.97\r\n[2000, 1000] | 1.8258 | 0.4204 | 4.34\r\n[2000,   500] | 0.9252 | 0.2391 | 3.87\r\n[500, 1000] | 0.4696 | 0.1129 | 4.16\r\n[500,   500] | 0.2380 | 0.0650 | 3.66\r\n\r\n\r\n\r\n\r\n"}