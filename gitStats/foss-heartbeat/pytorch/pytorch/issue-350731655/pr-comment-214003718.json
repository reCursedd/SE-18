{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/214003718", "pull_request_review_id": 150960292, "id": 214003718, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNDAwMzcxOA==", "diff_hunk": "@@ -183,9 +183,104 @@ static void prod_kernel_impl(Tensor& result, const Tensor& self, at::optional<in\n   });\n }\n \n+template<typename scalar_t>\n+struct NormReduction {\n+  static void apply(Tensor& res, const Tensor& self, Scalar p, at::optional<int64_t> dim) {\n+    auto out_ = res.data<scalar_t>();\n+    auto data_ = self.data<scalar_t>();\n+    auto numel = self.numel();\n+    float pval = 0.0;\n+    if (p.isIntegral()){\n+      pval = p.to<int64_t>();\n+    } else if (p.isFloatingPoint()) {\n+      pval = p.to<float>();\n+    }\n+    if (!dim.has_value()) {\n+      *out_ = reduce_all(data_, numel,  pval);\n+      return;\n+    }\n+    int64_t n = self.size(*dim);\n+    int64_t stride = self.stride(*dim);\n+    // A contiguous tensor does not need to hold a meaningful stride\n+    // if the corresponding size is 1\n+    if (n == 1) {\n+      stride = 1;\n+      for (int64_t i = self.ndimension() - 1; i > *dim; i--) {\n+        stride *= self.size(i);\n+      }\n+    }\n+    int64_t batch = numel / n;\n+    parallel_for(0, batch, 1, [=](int64_t begin, int64_t end) {\n+      for (int64_t bi = begin; bi < end; bi++) {\n+        int64_t b = bi / stride;\n+        int64_t i = bi % stride;\n+        const scalar_t* data = &data_[b * n * stride + i];\n+        out_[bi] = norm_calc(data, n, stride, pval);\n+      }\n+    });\n+  }\n+\n+  static scalar_t reduce_all(const scalar_t* data_, int64_t size,  float pval) {\n+    scalar_t sum = parallel_reduce(\n+      0,\n+      size,\n+      internal::GRAIN_SIZE,\n+      (scalar_t)0,\n+      [=](int64_t begin, int64_t end, scalar_t init) {\n+        const scalar_t* data = &data_[begin];\n+        int64_t n = end - begin;\n+        scalar_t result = norm_calc(data, n, 1, pval);\n+        return result;\n+      },\n+      std::plus<scalar_t>());\n+    return sum;\n+  }\n+\n+  static scalar_t norm_calc(const scalar_t* data, int64_t n, int64_t stride, float pval) {\n+        scalar_t result = 0.0;", "path": "aten/src/ATen/native/cpu/ReduceOpsKernel.cpp", "position": null, "original_position": 58, "commit_id": "01620c5d75010435810c9b85584db9ff65cf5887", "original_commit_id": "062a70a3e9f6ccc9b3b14df2a865b9d80d01e7c1", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "My impression is that we don't actually need to add vectorization at this point, as this code will probably be updated once TensorIterator gets in, which will significantly simplify things.", "created_at": "2018-08-30T12:04:05Z", "updated_at": "2018-11-23T15:50:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/10535#discussion_r214003718", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10535", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/214003718"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10535#discussion_r214003718"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10535"}}, "body_html": "<p>My impression is that we don't actually need to add vectorization at this point, as this code will probably be updated once TensorIterator gets in, which will significantly simplify things.</p>", "body_text": "My impression is that we don't actually need to add vectorization at this point, as this code will probably be updated once TensorIterator gets in, which will significantly simplify things.", "in_reply_to_id": 213393190}