{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6896", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6896/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6896/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6896/events", "html_url": "https://github.com/pytorch/pytorch/pull/6896", "id": 317140074, "node_id": "MDExOlB1bGxSZXF1ZXN0MTgzNjcxMTY4", "number": 6896, "title": "[Caffe2] Support non peer access in muji and fix bug when reduced_affix is empty", "user": {"login": "daquexian", "id": 11607199, "node_id": "MDQ6VXNlcjExNjA3MTk5", "avatar_url": "https://avatars0.githubusercontent.com/u/11607199?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daquexian", "html_url": "https://github.com/daquexian", "followers_url": "https://api.github.com/users/daquexian/followers", "following_url": "https://api.github.com/users/daquexian/following{/other_user}", "gists_url": "https://api.github.com/users/daquexian/gists{/gist_id}", "starred_url": "https://api.github.com/users/daquexian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daquexian/subscriptions", "organizations_url": "https://api.github.com/users/daquexian/orgs", "repos_url": "https://api.github.com/users/daquexian/repos", "events_url": "https://api.github.com/users/daquexian/events{/privacy}", "received_events_url": "https://api.github.com/users/daquexian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2018-04-24T09:19:54Z", "updated_at": "2018-11-23T15:44:48Z", "closed_at": "2018-06-04T19:14:44Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/6896", "html_url": "https://github.com/pytorch/pytorch/pull/6896", "diff_url": "https://github.com/pytorch/pytorch/pull/6896.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/6896.patch"}, "body_html": "<p>reference: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"291478698\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/facebookresearch/Detectron/issues/32\" data-hovercard-type=\"issue\" data-hovercard-url=\"/facebookresearch/Detectron/issues/32/hovercard\" href=\"https://github.com/facebookresearch/Detectron/issues/32\">facebookresearch/Detectron#32</a></p>\n<p>Detectron users with gpus lacking peer access can't train models using multiple gpus. A workaround is using nccl but it may <a href=\"https://github.com/facebookresearch/Detectron/issues/32#issuecomment-361140510\" data-hovercard-type=\"issue\" data-hovercard-url=\"/facebookresearch/Detectron/issues/32/hovercard\">suffer from deadlock</a>.</p>\n<p>I updated the code in muji so that it will use the proper way of allreduce according to the peer access pattern. Since there are many users having four gpus where pear access are enabled between {0,1} and {2,3}(e.g. myself), I also added an <code>Allreduce4Group2</code> function for this case.</p>\n<p>I have verified it on <a href=\"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_4gpu_e2e_faster_rcnn_R-50-FPN.yaml\">configs/getting_started/tutorial_4gpu_e2e_faster_rcnn_R-50-FPN.yaml</a> of detectron</p>", "body_text": "reference: facebookresearch/Detectron#32\nDetectron users with gpus lacking peer access can't train models using multiple gpus. A workaround is using nccl but it may suffer from deadlock.\nI updated the code in muji so that it will use the proper way of allreduce according to the peer access pattern. Since there are many users having four gpus where pear access are enabled between {0,1} and {2,3}(e.g. myself), I also added an Allreduce4Group2 function for this case.\nI have verified it on configs/getting_started/tutorial_4gpu_e2e_faster_rcnn_R-50-FPN.yaml of detectron", "body": "reference: https://github.com/facebookresearch/Detectron/issues/32\r\n\r\nDetectron users with gpus lacking peer access can't train models using multiple gpus. A workaround is using nccl but it may [suffer from deadlock](https://github.com/facebookresearch/Detectron/issues/32#issuecomment-361140510).\r\n\r\nI updated the code in muji so that it will use the proper way of allreduce according to the peer access pattern. Since there are many users having four gpus where pear access are enabled between {0,1} and {2,3}(e.g. myself), I also added an `Allreduce4Group2` function for this case.\r\n\r\nI have verified it on [configs/getting_started/tutorial_4gpu_e2e_faster_rcnn_R-50-FPN.yaml](https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_4gpu_e2e_faster_rcnn_R-50-FPN.yaml) of detectron"}