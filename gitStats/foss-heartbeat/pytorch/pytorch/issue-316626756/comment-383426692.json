{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/383426692", "html_url": "https://github.com/pytorch/pytorch/issues/6850#issuecomment-383426692", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6850", "id": 383426692, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzQyNjY5Mg==", "user": {"login": "meder411", "id": 6818607, "node_id": "MDQ6VXNlcjY4MTg2MDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6818607?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meder411", "html_url": "https://github.com/meder411", "followers_url": "https://api.github.com/users/meder411/followers", "following_url": "https://api.github.com/users/meder411/following{/other_user}", "gists_url": "https://api.github.com/users/meder411/gists{/gist_id}", "starred_url": "https://api.github.com/users/meder411/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meder411/subscriptions", "organizations_url": "https://api.github.com/users/meder411/orgs", "repos_url": "https://api.github.com/users/meder411/repos", "events_url": "https://api.github.com/users/meder411/events{/privacy}", "received_events_url": "https://api.github.com/users/meder411/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-23T00:54:26Z", "updated_at": "2018-04-23T00:57:56Z", "author_association": "NONE", "body_html": "<p>Apologies for being vague. <code>index_mean_</code> would compute the mean from a data tensor given an index vector. I.e. the same general operation as the existing <a href=\"http://pytorch.org/docs/master/tensors.html?highlight=index_add_#torch.Tensor.index_add_\" rel=\"nofollow\"><code>index_add_</code> </a> but computing the mean per each index instead of the sum. Similarly, <code>index_max_()</code> would compute the max of the data per each index and <code>index_min_()</code> would compute the min of the data per each index. <code>index_lambda_()</code> would allow the developer to write a custom per index operation.</p>\n<p>Currently, <code>index_mean_</code> can be done by first computing frequencies through an <code>index_add_()</code> operation with a vector of ones as the accumulated data and subsequently dividing it from another <code>index_add_()</code> operation that accumulated over the data of interest. I suspect it is more efficient to compute these frequencies on the back end though. I haven't yet figured out a way to engineer <code>index_max_()</code> or <code>index_min_()</code> from the current API.</p>", "body_text": "Apologies for being vague. index_mean_ would compute the mean from a data tensor given an index vector. I.e. the same general operation as the existing index_add_  but computing the mean per each index instead of the sum. Similarly, index_max_() would compute the max of the data per each index and index_min_() would compute the min of the data per each index. index_lambda_() would allow the developer to write a custom per index operation.\nCurrently, index_mean_ can be done by first computing frequencies through an index_add_() operation with a vector of ones as the accumulated data and subsequently dividing it from another index_add_() operation that accumulated over the data of interest. I suspect it is more efficient to compute these frequencies on the back end though. I haven't yet figured out a way to engineer index_max_() or index_min_() from the current API.", "body": "Apologies for being vague. `index_mean_` would compute the mean from a data tensor given an index vector. I.e. the same general operation as the existing [`index_add_` ](http://pytorch.org/docs/master/tensors.html?highlight=index_add_#torch.Tensor.index_add_) but computing the mean per each index instead of the sum. Similarly, `index_max_()` would compute the max of the data per each index and `index_min_()` would compute the min of the data per each index. `index_lambda_()` would allow the developer to write a custom per index operation.\r\n\r\nCurrently, `index_mean_` can be done by first computing frequencies through an `index_add_()` operation with a vector of ones as the accumulated data and subsequently dividing it from another `index_add_()` operation that accumulated over the data of interest. I suspect it is more efficient to compute these frequencies on the back end though. I haven't yet figured out a way to engineer `index_max_()` or `index_min_()` from the current API."}