{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/384503259", "html_url": "https://github.com/pytorch/pytorch/issues/6950#issuecomment-384503259", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6950", "id": 384503259, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NDUwMzI1OQ==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-26T03:40:30Z", "updated_at": "2018-04-26T03:41:21Z", "author_association": "MEMBER", "body_html": "<p>So, this is historical to an accidental bug from about ~15 years or so that ended up empirically working better. That being said, in the age of very deep ResNets and ReLUs, I'm not sure if it's still empirically better anymore, someone has to do an ablation study. (resnets btw use Kaiming initialization, I just wanted to talk about modernization of the field)</p>\n<p>For full context see my comments in this Google+ thread: <a href=\"https://plus.google.com/+SoumithChintala/posts/RZfdrRQWL6u\" rel=\"nofollow\">https://plus.google.com/+SoumithChintala/posts/RZfdrRQWL6u</a></p>\n<p>The actual initialization comes from <a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\" rel=\"nofollow\">LeCun'98 Efficient Backprop</a>.</p>\n<p>From my conversation with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192030\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andresy\">@andresy</a> 4 years ago, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192030\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andresy\">@andresy</a> or <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=612213\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/leonbottou\">@leonbottou</a> or someone from that era briefly didn't multiply the stddev by <code>sqrt(3)</code> and noticed that this bug empirically works better in practice. And hence this bug has been kept (in Torch-5, Torch-7, PyTorch and probably previous libraries to Torch-5).</p>", "body_text": "So, this is historical to an accidental bug from about ~15 years or so that ended up empirically working better. That being said, in the age of very deep ResNets and ReLUs, I'm not sure if it's still empirically better anymore, someone has to do an ablation study. (resnets btw use Kaiming initialization, I just wanted to talk about modernization of the field)\nFor full context see my comments in this Google+ thread: https://plus.google.com/+SoumithChintala/posts/RZfdrRQWL6u\nThe actual initialization comes from LeCun'98 Efficient Backprop.\nFrom my conversation with @andresy 4 years ago, @andresy or @leonbottou or someone from that era briefly didn't multiply the stddev by sqrt(3) and noticed that this bug empirically works better in practice. And hence this bug has been kept (in Torch-5, Torch-7, PyTorch and probably previous libraries to Torch-5).", "body": "So, this is historical to an accidental bug from about ~15 years or so that ended up empirically working better. That being said, in the age of very deep ResNets and ReLUs, I'm not sure if it's still empirically better anymore, someone has to do an ablation study. (resnets btw use Kaiming initialization, I just wanted to talk about modernization of the field)\r\n\r\nFor full context see my comments in this Google+ thread: https://plus.google.com/+SoumithChintala/posts/RZfdrRQWL6u\r\n\r\nThe actual initialization comes from [LeCun'98 Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf).\r\n\r\nFrom my conversation with @andresy 4 years ago, @andresy or @leonbottou or someone from that era briefly didn't multiply the stddev by `sqrt(3)` and noticed that this bug empirically works better in practice. And hence this bug has been kept (in Torch-5, Torch-7, PyTorch and probably previous libraries to Torch-5)."}