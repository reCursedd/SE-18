{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10541", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10541/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10541/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10541/events", "html_url": "https://github.com/pytorch/pytorch/issues/10541", "id": 350862430, "node_id": "MDU6SXNzdWUzNTA4NjI0MzA=", "number": 10541, "title": "Serialization / Deserialization of Model Parameters Broken", "user": {"login": "rothn", "id": 4665783, "node_id": "MDQ6VXNlcjQ2NjU3ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4665783?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rothn", "html_url": "https://github.com/rothn", "followers_url": "https://api.github.com/users/rothn/followers", "following_url": "https://api.github.com/users/rothn/following{/other_user}", "gists_url": "https://api.github.com/users/rothn/gists{/gist_id}", "starred_url": "https://api.github.com/users/rothn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rothn/subscriptions", "organizations_url": "https://api.github.com/users/rothn/orgs", "repos_url": "https://api.github.com/users/rothn/repos", "events_url": "https://api.github.com/users/rothn/events{/privacy}", "received_events_url": "https://api.github.com/users/rothn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 545367190, "node_id": "MDU6TGFiZWw1NDUzNjcxOTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-15T15:48:32Z", "updated_at": "2018-09-07T00:21:21Z", "closed_at": "2018-09-07T00:21:21Z", "author_association": "NONE", "body_html": "<p>Torch version: 0.4.1<br>\nPython version: 3.7.0</p>\n<h2>Issue description</h2>\n<p>I serialize the state_dict of a Sequential fully-connected network model (1029 inputs, 2 hidden layers of 50 neurons each, and 2 output neurons (instead of just one since one day I might use the same code for a multiclass classifier) with sigmoid activations) to a file. Then I create the same model and load that file, and I get the error in \"code example\". <strong>Please note that I do check that both models are what I think they are with</strong> <code>print(list(ffnn)[0].weight.size())</code> both before attempting to load the model params and after creating the model in the file that generates it.</p>\n<h2>Code example</h2>\n<p>Save the model:</p>\n<pre lang=\"def\" data-meta=\"init_weights(m):\"><code>    if type(m) == nn.Linear:\n        #m.weight.data.fill_(0.01)\n        #m.bias.data.fill_(0.01)\n        m.weight.data.uniform_()\n        m.bias.data.uniform_()\n\n# Create a model with Sequential\ndef create_model(input_size, hidden_size, output_size):\n    to_ret = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.Sigmoid(),\n            #nn.Linear(hidden_size, hidden_size),\n            #nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.Sigmoid(),\n            nn.Linear(hidden_size, output_size)#,\n            #nn.LogSoftmax(dim=0)\n            )\n    to_ret.apply(init_weights)\n    return to_ret\n\nffnn = create_model(n_inputs, 50, 2)\n\n# Make sure this really is x50 wide (serialization error seems to say otherwise)\nprint(list(ffnn)[0].weight.size())\n\n#... &lt;training code goes here&gt; ...\n\ntorch.save(ffnn.state_dict(), 'trained_model')\n</code></pre>\n<p>Load the model:</p>\n<pre lang=\"def\" data-meta=\"init_weights(m):\"><code>    if type(m) == nn.Linear:\n        #m.weight.data.fill_(0.01)\n        #m.bias.data.fill_(0.01)\n        m.weight.data.uniform_()\n        m.bias.data.uniform_()\n\n# Create a model with Sequential\ndef create_model(input_size, hidden_size, output_size):\n    to_ret = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.Sigmoid(),\n            #nn.Linear(hidden_size, hidden_size),\n            #nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.Sigmoid(),\n            nn.Linear(hidden_size, output_size)#,\n            #nn.LogSoftmax(dim=0)\n            )\n    to_ret.apply(init_weights)\n    return to_ret\n\nffnn = create_model(n_inputs, 50, 2)\n\n# Make sure this really is x50 wide (deserialization error seems to say otherwise)\nprint(list(ffnn)[0].weight.size())\n\nffnn.load_state_dict(torch.load('trained_model'))\n</code></pre>\n<p>Output from both print statements (is the same):<br>\n<code>torch.Size([50, 1029])</code></p>\n<p>Another thing that tells me this isn't me is that when I load/save the entire model with <code>torch.save(ffnn, 'trained_model')</code> and <code>ffnn = torch.load('trained_model')</code> and print the sizes, the model loads correctly with appropriately-sized layers. However, I want to only save the model parameters to avoid the pitfalls of saving an entire model :-).</p>\n<p>Error:</p>\n<pre lang=\"Traceback\" data-meta=\"(most recent call last):\"><code>  File \"trained_classifier_run_on_training.py\", line 532, in &lt;module&gt;\n    ffnn.load_state_dict(torch.load('torch_model'))\n  File \"/Users/nicholasroth/ml_python/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 719, in load_state_dict\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\nRuntimeError: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param of torch.Size([200, 1029]) from checkpoint, where the shape is torch.Size([50, 1029]) in current model.\n\tsize mismatch for 0.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\n\tsize mismatch for 2.weight: copying a param of torch.Size([200, 200]) from checkpoint, where the shape is torch.Size([50, 50]) in current model.\n\tsize mismatch for 2.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\n\tsize mismatch for 4.weight: copying a param of torch.Size([2, 200]) from checkpoint, where the shape is torch.Size([2, 50]) in current model.\n</code></pre>\n<h2>System Info</h2>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): pip</li>\n<li>Build command you used (if compiling from source): --</li>\n<li>OS: macOS 10.13.6</li>\n<li>PyTorch version: 0.4.1</li>\n<li>Python version: 3.7.0</li>\n<li>CUDA/cuDNN version: --</li>\n<li>GPU models and configuration: --</li>\n<li>GCC version (if compiling from source): --</li>\n<li>CMake version: --</li>\n<li>Versions of any other relevant libraries: --</li>\n</ul>", "body_text": "Torch version: 0.4.1\nPython version: 3.7.0\nIssue description\nI serialize the state_dict of a Sequential fully-connected network model (1029 inputs, 2 hidden layers of 50 neurons each, and 2 output neurons (instead of just one since one day I might use the same code for a multiclass classifier) with sigmoid activations) to a file. Then I create the same model and load that file, and I get the error in \"code example\". Please note that I do check that both models are what I think they are with print(list(ffnn)[0].weight.size()) both before attempting to load the model params and after creating the model in the file that generates it.\nCode example\nSave the model:\n    if type(m) == nn.Linear:\n        #m.weight.data.fill_(0.01)\n        #m.bias.data.fill_(0.01)\n        m.weight.data.uniform_()\n        m.bias.data.uniform_()\n\n# Create a model with Sequential\ndef create_model(input_size, hidden_size, output_size):\n    to_ret = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.Sigmoid(),\n            #nn.Linear(hidden_size, hidden_size),\n            #nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.Sigmoid(),\n            nn.Linear(hidden_size, output_size)#,\n            #nn.LogSoftmax(dim=0)\n            )\n    to_ret.apply(init_weights)\n    return to_ret\n\nffnn = create_model(n_inputs, 50, 2)\n\n# Make sure this really is x50 wide (serialization error seems to say otherwise)\nprint(list(ffnn)[0].weight.size())\n\n#... <training code goes here> ...\n\ntorch.save(ffnn.state_dict(), 'trained_model')\n\nLoad the model:\n    if type(m) == nn.Linear:\n        #m.weight.data.fill_(0.01)\n        #m.bias.data.fill_(0.01)\n        m.weight.data.uniform_()\n        m.bias.data.uniform_()\n\n# Create a model with Sequential\ndef create_model(input_size, hidden_size, output_size):\n    to_ret = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.Sigmoid(),\n            #nn.Linear(hidden_size, hidden_size),\n            #nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.Sigmoid(),\n            nn.Linear(hidden_size, output_size)#,\n            #nn.LogSoftmax(dim=0)\n            )\n    to_ret.apply(init_weights)\n    return to_ret\n\nffnn = create_model(n_inputs, 50, 2)\n\n# Make sure this really is x50 wide (deserialization error seems to say otherwise)\nprint(list(ffnn)[0].weight.size())\n\nffnn.load_state_dict(torch.load('trained_model'))\n\nOutput from both print statements (is the same):\ntorch.Size([50, 1029])\nAnother thing that tells me this isn't me is that when I load/save the entire model with torch.save(ffnn, 'trained_model') and ffnn = torch.load('trained_model') and print the sizes, the model loads correctly with appropriately-sized layers. However, I want to only save the model parameters to avoid the pitfalls of saving an entire model :-).\nError:\n  File \"trained_classifier_run_on_training.py\", line 532, in <module>\n    ffnn.load_state_dict(torch.load('torch_model'))\n  File \"/Users/nicholasroth/ml_python/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 719, in load_state_dict\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\nRuntimeError: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param of torch.Size([200, 1029]) from checkpoint, where the shape is torch.Size([50, 1029]) in current model.\n\tsize mismatch for 0.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\n\tsize mismatch for 2.weight: copying a param of torch.Size([200, 200]) from checkpoint, where the shape is torch.Size([50, 50]) in current model.\n\tsize mismatch for 2.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\n\tsize mismatch for 4.weight: copying a param of torch.Size([2, 200]) from checkpoint, where the shape is torch.Size([2, 50]) in current model.\n\nSystem Info\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): pip\nBuild command you used (if compiling from source): --\nOS: macOS 10.13.6\nPyTorch version: 0.4.1\nPython version: 3.7.0\nCUDA/cuDNN version: --\nGPU models and configuration: --\nGCC version (if compiling from source): --\nCMake version: --\nVersions of any other relevant libraries: --", "body": "Torch version: 0.4.1\r\nPython version: 3.7.0\r\n\r\n## Issue description\r\n\r\nI serialize the state_dict of a Sequential fully-connected network model (1029 inputs, 2 hidden layers of 50 neurons each, and 2 output neurons (instead of just one since one day I might use the same code for a multiclass classifier) with sigmoid activations) to a file. Then I create the same model and load that file, and I get the error in \"code example\". **Please note that I do check that both models are what I think they are with** `print(list(ffnn)[0].weight.size())` both before attempting to load the model params and after creating the model in the file that generates it.\r\n\r\n## Code example\r\n\r\nSave the model:\r\n```def init_weights(m):\r\n    if type(m) == nn.Linear:\r\n        #m.weight.data.fill_(0.01)\r\n        #m.bias.data.fill_(0.01)\r\n        m.weight.data.uniform_()\r\n        m.bias.data.uniform_()\r\n\r\n# Create a model with Sequential\r\ndef create_model(input_size, hidden_size, output_size):\r\n    to_ret = nn.Sequential(\r\n            nn.Linear(input_size, hidden_size),\r\n            nn.Sigmoid(),\r\n            #nn.Linear(hidden_size, hidden_size),\r\n            #nn.ReLU(),\r\n            nn.Linear(hidden_size, hidden_size),\r\n            nn.Sigmoid(),\r\n            nn.Linear(hidden_size, output_size)#,\r\n            #nn.LogSoftmax(dim=0)\r\n            )\r\n    to_ret.apply(init_weights)\r\n    return to_ret\r\n\r\nffnn = create_model(n_inputs, 50, 2)\r\n\r\n# Make sure this really is x50 wide (serialization error seems to say otherwise)\r\nprint(list(ffnn)[0].weight.size())\r\n\r\n#... <training code goes here> ...\r\n\r\ntorch.save(ffnn.state_dict(), 'trained_model')\r\n```\r\n\r\nLoad the model:\r\n```def init_weights(m):\r\n    if type(m) == nn.Linear:\r\n        #m.weight.data.fill_(0.01)\r\n        #m.bias.data.fill_(0.01)\r\n        m.weight.data.uniform_()\r\n        m.bias.data.uniform_()\r\n\r\n# Create a model with Sequential\r\ndef create_model(input_size, hidden_size, output_size):\r\n    to_ret = nn.Sequential(\r\n            nn.Linear(input_size, hidden_size),\r\n            nn.Sigmoid(),\r\n            #nn.Linear(hidden_size, hidden_size),\r\n            #nn.ReLU(),\r\n            nn.Linear(hidden_size, hidden_size),\r\n            nn.Sigmoid(),\r\n            nn.Linear(hidden_size, output_size)#,\r\n            #nn.LogSoftmax(dim=0)\r\n            )\r\n    to_ret.apply(init_weights)\r\n    return to_ret\r\n\r\nffnn = create_model(n_inputs, 50, 2)\r\n\r\n# Make sure this really is x50 wide (deserialization error seems to say otherwise)\r\nprint(list(ffnn)[0].weight.size())\r\n\r\nffnn.load_state_dict(torch.load('trained_model'))\r\n```\r\n\r\nOutput from both print statements (is the same):\r\n`torch.Size([50, 1029])`\r\n\r\nAnother thing that tells me this isn't me is that when I load/save the entire model with `torch.save(ffnn, 'trained_model')` and `ffnn = torch.load('trained_model')` and print the sizes, the model loads correctly with appropriately-sized layers. However, I want to only save the model parameters to avoid the pitfalls of saving an entire model :-).\r\n\r\nError:\r\n```Traceback (most recent call last):\r\n  File \"trained_classifier_run_on_training.py\", line 532, in <module>\r\n    ffnn.load_state_dict(torch.load('torch_model'))\r\n  File \"/Users/nicholasroth/ml_python/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 719, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for Sequential:\r\n\tsize mismatch for 0.weight: copying a param of torch.Size([200, 1029]) from checkpoint, where the shape is torch.Size([50, 1029]) in current model.\r\n\tsize mismatch for 0.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\r\n\tsize mismatch for 2.weight: copying a param of torch.Size([200, 200]) from checkpoint, where the shape is torch.Size([50, 50]) in current model.\r\n\tsize mismatch for 2.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([50]) in current model.\r\n\tsize mismatch for 4.weight: copying a param of torch.Size([2, 200]) from checkpoint, where the shape is torch.Size([2, 50]) in current model.\r\n```\r\n\r\n## System Info\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): pip\r\n- Build command you used (if compiling from source): --\r\n- OS: macOS 10.13.6\r\n- PyTorch version: 0.4.1\r\n- Python version: 3.7.0\r\n- CUDA/cuDNN version: --\r\n- GPU models and configuration: --\r\n- GCC version (if compiling from source): --\r\n- CMake version: --\r\n- Versions of any other relevant libraries: --\r\n"}