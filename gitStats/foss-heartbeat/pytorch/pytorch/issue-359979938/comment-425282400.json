{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/425282400", "html_url": "https://github.com/pytorch/pytorch/issues/11647#issuecomment-425282400", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11647", "id": 425282400, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTI4MjQwMA==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-28T00:23:05Z", "updated_at": "2018-09-28T00:27:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10950530\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/blester125\">@blester125</a> After couple days endeavor on the <a href=\"https://github.com/blester125/baseline.git\">Baseline</a> project and timing <code>Modules</code> and different parts of the model using <code>torch.cuda.Event()</code>, finally it gets me closer to the answer... Most likely the perf regression during training is from advanced indexing. Specifically, during the <a href=\"https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/tagger/train.py#L109-L131\">training loop</a> at <code>tagger/train.py</code>, it calls into <a href=\"https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/tagger/model.py#L192-L216\">compute_loss</a> at <code>tagger/model.py</code>, which then calls into <a href=\"https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L731-L750\">neg_log_loss</a> at <code>torchy.py</code>, then it calls into <a href=\"https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L752-L781\">score_sentence</a> at the same file. Inside this function, the biggest difference in runtime between 0.4.0 and 0.4.1 during training is from this <a href=\"https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L769-L772\">line</a></p>\n<p>Time takes for 1 epoch of training on that line of code:</p>\n<pre><code>0.4.0: 5806.34 ms\n0.4.1: 17637.5 ms\n</code></pre>\n<p>Here is a separate test of runtime among different PyTorch versions:</p>\n<pre><code>import torch\nfrom random import *\n\n&gt;&gt;&gt; x = torch.randn(2, 5, 10).cuda()\n&gt;&gt;&gt; n = 10\n&gt;&gt;&gt; I1 = [randint(0, 1) for i in range(n)]\n&gt;&gt;&gt; I2 = [randint(0, 4) for i in range(n)]\n&gt;&gt;&gt; I3 = [randint(0, 9) for i in range(n)]\n\n&gt;&gt;&gt; %timeit -r 100 torch.cuda.synchronize(); x[I1, I2, I3]; torch.cuda.synchronize()\n\n========= 0.4.0 ========\n10000 loops, best of 100: 163 \u00b5s per loop\n\n========= 0.4.1 ========\n1000 loops, best of 100: 610 \u00b5s per loop\n\n========= master ========\n1000 loops, best of 100: 739 \u00b5s per loop\n</code></pre>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> is going to push a patch to improve performance of advanced indexing, and it should fix this issue.</p>", "body_text": "@blester125 After couple days endeavor on the Baseline project and timing Modules and different parts of the model using torch.cuda.Event(), finally it gets me closer to the answer... Most likely the perf regression during training is from advanced indexing. Specifically, during the training loop at tagger/train.py, it calls into compute_loss at tagger/model.py, which then calls into neg_log_loss at torchy.py, then it calls into score_sentence at the same file. Inside this function, the biggest difference in runtime between 0.4.0 and 0.4.1 during training is from this line\nTime takes for 1 epoch of training on that line of code:\n0.4.0: 5806.34 ms\n0.4.1: 17637.5 ms\n\nHere is a separate test of runtime among different PyTorch versions:\nimport torch\nfrom random import *\n\n>>> x = torch.randn(2, 5, 10).cuda()\n>>> n = 10\n>>> I1 = [randint(0, 1) for i in range(n)]\n>>> I2 = [randint(0, 4) for i in range(n)]\n>>> I3 = [randint(0, 9) for i in range(n)]\n\n>>> %timeit -r 100 torch.cuda.synchronize(); x[I1, I2, I3]; torch.cuda.synchronize()\n\n========= 0.4.0 ========\n10000 loops, best of 100: 163 \u00b5s per loop\n\n========= 0.4.1 ========\n1000 loops, best of 100: 610 \u00b5s per loop\n\n========= master ========\n1000 loops, best of 100: 739 \u00b5s per loop\n\n@colesbury is going to push a patch to improve performance of advanced indexing, and it should fix this issue.", "body": "@blester125 After couple days endeavor on the [Baseline](https://github.com/blester125/baseline.git) project and timing `Modules` and different parts of the model using `torch.cuda.Event()`, finally it gets me closer to the answer... Most likely the perf regression during training is from advanced indexing. Specifically, during the [training loop](https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/tagger/train.py#L109-L131) at `tagger/train.py`, it calls into [compute_loss](https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/tagger/model.py#L192-L216) at `tagger/model.py`, which then calls into [neg_log_loss](https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L731-L750) at `torchy.py`, then it calls into [score_sentence](https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L752-L781) at the same file. Inside this function, the biggest difference in runtime between 0.4.0 and 0.4.1 during training is from this [line](https://github.com/blester125/baseline/blob/4edc5dd05bb737dcba543b12c8943ffbae6c9c92/python/baseline/pytorch/torchy.py#L769-L772)\r\n\r\nTime takes for 1 epoch of training on that line of code:\r\n```\r\n0.4.0: 5806.34 ms\r\n0.4.1: 17637.5 ms\r\n```\r\n\r\nHere is a separate test of runtime among different PyTorch versions:\r\n```\r\nimport torch\r\nfrom random import *\r\n\r\n>>> x = torch.randn(2, 5, 10).cuda()\r\n>>> n = 10\r\n>>> I1 = [randint(0, 1) for i in range(n)]\r\n>>> I2 = [randint(0, 4) for i in range(n)]\r\n>>> I3 = [randint(0, 9) for i in range(n)]\r\n\r\n>>> %timeit -r 100 torch.cuda.synchronize(); x[I1, I2, I3]; torch.cuda.synchronize()\r\n\r\n========= 0.4.0 ========\r\n10000 loops, best of 100: 163 \u00b5s per loop\r\n\r\n========= 0.4.1 ========\r\n1000 loops, best of 100: 610 \u00b5s per loop\r\n\r\n========= master ========\r\n1000 loops, best of 100: 739 \u00b5s per loop\r\n```\r\n\r\n@colesbury is going to push a patch to improve performance of advanced indexing, and it should fix this issue."}