{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14307", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14307/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14307/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14307/events", "html_url": "https://github.com/pytorch/pytorch/issues/14307", "id": 383360286, "node_id": "MDU6SXNzdWUzODMzNjAyODY=", "number": 14307, "title": "Thread deadlock problem on Dataloader", "user": {"login": "LoganZhou", "id": 19534567, "node_id": "MDQ6VXNlcjE5NTM0NTY3", "avatar_url": "https://avatars3.githubusercontent.com/u/19534567?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LoganZhou", "html_url": "https://github.com/LoganZhou", "followers_url": "https://api.github.com/users/LoganZhou/followers", "following_url": "https://api.github.com/users/LoganZhou/following{/other_user}", "gists_url": "https://api.github.com/users/LoganZhou/gists{/gist_id}", "starred_url": "https://api.github.com/users/LoganZhou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LoganZhou/subscriptions", "organizations_url": "https://api.github.com/users/LoganZhou/orgs", "repos_url": "https://api.github.com/users/LoganZhou/repos", "events_url": "https://api.github.com/users/LoganZhou/events{/privacy}", "received_events_url": "https://api.github.com/users/LoganZhou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-22T02:42:51Z", "updated_at": "2018-11-22T10:48:21Z", "closed_at": "2018-11-22T10:48:21Z", "author_association": "NONE", "body_html": "<h2>Thread deadlock problem on Dataloader</h2>\n<p>Hey guys!</p>\n<p>Currently, I try to train distributed model, but the dataloader seems to have a thread deadlock problem on master process while other slave processes reading data well. <code>TripletPDRDataset</code> tries to return 3 images in the function <code>__getitem()__</code>, including an anchor, a positive sample and a negative sample. I found that it can work well if don't use distributed sampler.</p>\n<p>Best,</p>\n<p>Heng Zhou</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Run the following command on master node:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>python -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=0</pre></div>\n<ol start=\"2\">\n<li>Run the following command on slave node:</li>\n</ol>\n<div class=\"highlight highlight-source-shell\"><pre>python -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=1</pre></div>\n<h3>Code sample</h3>\n<p><strong>PDR_Dataset .py</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> torch.utils <span class=\"pl-k\">import</span> data\n<span class=\"pl-k\">from</span> torch.utils.data.sampler <span class=\"pl-k\">import</span> BatchSampler\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">PIL</span> <span class=\"pl-k\">import</span> Image\n<span class=\"pl-k\">import</span> torchvision.transforms <span class=\"pl-k\">as</span> transforms\n<span class=\"pl-k\">import</span> json\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">TripletPDRDataset</span>(<span class=\"pl-e\">data</span>.<span class=\"pl-e\">Dataset</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">images_dir</span>, <span class=\"pl-smi\">labels_path</span>, <span class=\"pl-smi\">transforms</span>, <span class=\"pl-smi\">train</span>):\n        <span class=\"pl-c1\">self</span>.train <span class=\"pl-k\">=</span> train\n        <span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(labels_path, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>r<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n            examples <span class=\"pl-k\">=</span> json.loads(f.read())\n        <span class=\"pl-c1\">self</span>.images_dir <span class=\"pl-k\">=</span> images_dir\n        <span class=\"pl-c1\">self</span>.transforms <span class=\"pl-k\">=</span> transforms\n        <span class=\"pl-c1\">self</span>.labels <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c1\">self</span>.image_ids <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> example <span class=\"pl-k\">in</span> examples:\n            <span class=\"pl-c1\">self</span>.image_ids.append(example[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image_id<span class=\"pl-pds\">\"</span></span>])\n            <span class=\"pl-c1\">self</span>.labels.append(example[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>disease_class<span class=\"pl-pds\">\"</span></span>])\n        <span class=\"pl-c1\">self</span>.labels_set <span class=\"pl-k\">=</span> <span class=\"pl-c1\">set</span>(<span class=\"pl-c1\">self</span>.labels)\n\n        <span class=\"pl-c1\">self</span>.label_to_indices <span class=\"pl-k\">=</span> {\n            label: np.where(np.array(<span class=\"pl-c1\">self</span>.labels) <span class=\"pl-k\">==</span> label)[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">for</span> label <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>.labels_set\n        }\n\n        <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">self</span>.train:\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> generate fixed triplets for testing</span>\n            random_state <span class=\"pl-k\">=</span> np.random.RandomState(<span class=\"pl-c1\">29</span>)\n\n            triplets <span class=\"pl-k\">=</span> [[i,\n                         random_state.choice(<span class=\"pl-c1\">self</span>.label_to_indices[<span class=\"pl-c1\">self</span>.labels[i]]),\n                         random_state.choice(<span class=\"pl-c1\">self</span>.label_to_indices[\n                                                 np.random.choice(\n                                                     <span class=\"pl-c1\">list</span>(<span class=\"pl-c1\">self</span>.labels_set <span class=\"pl-k\">-</span> {<span class=\"pl-c1\">self</span>.labels[i]})\n                                                 )\n                                             ])\n                         ]\n                        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.image_ids))]\n            <span class=\"pl-c1\">self</span>.test_triplets <span class=\"pl-k\">=</span> triplets\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.train:\n            img1_id, label1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[index], <span class=\"pl-c1\">self</span>.labels[index]\n            positive_index <span class=\"pl-k\">=</span> index\n            <span class=\"pl-k\">while</span> positive_index <span class=\"pl-k\">==</span> index:\n                positive_index <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">self</span>.label_to_indices[label1])\n            negative_label <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">list</span>(<span class=\"pl-c1\">self</span>.labels_set <span class=\"pl-k\">-</span> {label1}))\n            negative_index <span class=\"pl-k\">=</span> np.random.choice(<span class=\"pl-c1\">self</span>.label_to_indices[negative_label])\n            img2_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[positive_index]\n            img3_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[negative_index]\n        <span class=\"pl-k\">else</span>:\n            img1_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[<span class=\"pl-c1\">self</span>.test_triplets[index][<span class=\"pl-c1\">0</span>]]\n            img2_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[<span class=\"pl-c1\">self</span>.test_triplets[index][<span class=\"pl-c1\">1</span>]]\n            img3_id <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.image_ids[<span class=\"pl-c1\">self</span>.test_triplets[index][<span class=\"pl-c1\">2</span>]]\n\n        img1 <span class=\"pl-k\">=</span> Image.open(os.path.join(<span class=\"pl-c1\">self</span>.images_dir, img1_id))\n        img2 <span class=\"pl-k\">=</span> Image.open(os.path.join(<span class=\"pl-c1\">self</span>.images_dir, img2_id))\n        img3 <span class=\"pl-k\">=</span> Image.open(os.path.join(<span class=\"pl-c1\">self</span>.images_dir, img3_id))\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.transforms <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n            img1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.transforms(img1)\n            img2 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.transforms(img2)\n            img3 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.transforms(img3)\n        <span class=\"pl-k\">return</span> (img1, img2, img3), []\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__len__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">self</span>.image_ids)</pre></div>\n<p><strong>test_dataset.py</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> coding:utf-8</span>\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> torchvision.transforms <span class=\"pl-k\">as</span> transforms\n<span class=\"pl-k\">import</span> torch.utils.data.distributed\n<span class=\"pl-k\">import</span> torch.distributed <span class=\"pl-k\">as</span> dist\n<span class=\"pl-k\">import</span> torch.utils.data\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">PDR_Dataset</span> <span class=\"pl-k\">import</span> <span class=\"pl-k\">*</span>\n\nparser <span class=\"pl-k\">=</span> argparse.ArgumentParser(<span class=\"pl-v\">description</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>PyTorch DataLoader Test<span class=\"pl-pds\">'</span></span>)\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--world-size<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>number of distributed processes<span class=\"pl-pds\">'</span></span>)\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--dist-url<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>env://<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>url used to set up distributed training<span class=\"pl-pds\">'</span></span>)\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--global-rank<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>process rank of global process group<span class=\"pl-pds\">'</span></span>)\nparser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--dist-backend<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>nccl<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n                    <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>distributed backend<span class=\"pl-pds\">'</span></span>)\n\nargs <span class=\"pl-k\">=</span> parser.parse_args()\n\ndist.init_process_group(<span class=\"pl-v\">backend</span><span class=\"pl-k\">=</span>args.dist_backend, <span class=\"pl-v\">init_method</span><span class=\"pl-k\">=</span>args.dist_url,\n                        <span class=\"pl-v\">world_size</span><span class=\"pl-k\">=</span>args.world_size, <span class=\"pl-v\">rank</span><span class=\"pl-k\">=</span>args.global_rank)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>=&gt; Distributed: success (<span class=\"pl-c1\">%d</span>/<span class=\"pl-c1\">%d</span>)!<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> (dist.get_rank() <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, dist.get_world_size()))\n\n\ntraindir <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-sr\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">\"</span>/home/asc001/AI_Challenger/PDR2018/data/trainingset/images<span class=\"pl-pds\">\"</span></span>)\ntrainlabel <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-sr\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">\"</span>/home/asc001/AI_Challenger/PDR2018/data/trainingset/AgriculturalDisease_train_annotations<span class=\"pl-c1\">.</span>json<span class=\"pl-pds\">\"</span></span>)\n\n\ntrain_dataset <span class=\"pl-k\">=</span> TripletPDRDataset(\n        traindir, trainlabel, transforms.Compose([\n            transforms.RandomResizedCrop(<span class=\"pl-c1\">331</span>, <span class=\"pl-v\">scale</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">1.0</span>)),\n            transforms.RandomRotation(<span class=\"pl-v\">degrees</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">360</span>)),\n            transforms.ToTensor(),\n            transforms.Normalize(<span class=\"pl-v\">mean</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">0.485</span>, <span class=\"pl-c1\">0.456</span>, <span class=\"pl-c1\">0.406</span>],\n                                 <span class=\"pl-v\">std</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">0.229</span>, <span class=\"pl-c1\">0.224</span>, <span class=\"pl-c1\">0.225</span>]), ]), <span class=\"pl-v\">train</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\ntrain_sampler <span class=\"pl-k\">=</span> torch.utils.data.distributed.DistributedSampler(train_dataset)\n\ntriplet_train_loader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(\n        train_dataset, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span>(train_sampler <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>),\n        <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">pin_memory</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">sampler</span><span class=\"pl-k\">=</span>train_sampler)\n\n<span class=\"pl-k\">for</span> batch_idx, (data, target) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(triplet_train_loader):\n    message <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Train: [<span class=\"pl-c1\">{}</span>/<span class=\"pl-c1\">{}</span> (<span class=\"pl-c1\">{<span class=\"pl-k\">:.0f</span>}</span>%)]<span class=\"pl-pds\">'</span></span>.format(\n        batch_idx <span class=\"pl-k\">*</span> <span class=\"pl-c1\">len</span>(data[<span class=\"pl-c1\">0</span>]), <span class=\"pl-c1\">len</span>(triplet_train_loader),\n        <span class=\"pl-c1\">100</span>. <span class=\"pl-k\">*</span> batch_idx <span class=\"pl-k\">/</span> <span class=\"pl-c1\">len</span>(triplet_train_loader))\n    <span class=\"pl-c1\">print</span>(message)</pre></div>\n<h3>stack traces</h3>\n<div class=\"highlight highlight-source-shell\"><pre>Traceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test_dataset.py<span class=\"pl-pds\">\"</span></span>, line 49, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    <span class=\"pl-k\">for</span> <span class=\"pl-smi\">batch_idx, (data, target)</span> <span class=\"pl-k\">in</span> enumerate(triplet_train_loader):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py<span class=\"pl-pds\">\"</span></span>, line 631, <span class=\"pl-k\">in</span> __next__\n    idx, batch = <span class=\"pl-en\">self._get_batch</span>()\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py<span class=\"pl-pds\">\"</span></span>, line 601, <span class=\"pl-k\">in</span> _get_batch\n    <span class=\"pl-k\">return</span> self.data_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/asc001/anaconda3/envs/pytorch/lib/python3.6/queue.py<span class=\"pl-pds\">\"</span></span>, line 173, <span class=\"pl-k\">in</span> get\n    self.not_empty.wait(remaining)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/asc001/anaconda3/envs/pytorch/lib/python3.6/threading.py<span class=\"pl-pds\">\"</span></span>, line 299, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">wait</span>\n    gotit = waiter.acquire(True, timeout)\nKeyboardInterrupt</pre></div>\n<h2>Expected behavior</h2>\n<p>The progress of distributed process outputs may look like the same, but the master process stuck while running.</p>\n<pre><code>master\n...\nTrain: [1180/3965 (7%)]\nTrain: [1184/3965 (7%)]\nTrain: [1188/3965 (7%)]\nTrain: [1192/3965 (8%)]\nTrain: [1196/3965 (8%)]    &lt;== stuck here\n</code></pre>\n<pre><code>slave\n...\nTrain: [6248/3965 (39%)]\nTrain: [6252/3965 (39%)]\nTrain: [6256/3965 (39%)]\nTrain: [6260/3965 (39%)] \n</code></pre>\n<h2>Environment</h2>\n<p>PyTorch version: 1.0.0a0+86e1009<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.88</p>\n<p>OS: CentOS Linux release 7.3.1611 (Core)<br>\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)<br>\nCMake version: version 3.12.2</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration:<br>\nGPU 0: Tesla P100-PCIE-16GB<br>\nGPU 1: Tesla P100-PCIE-16GB</p>\n<p>Nvidia driver version: 396.26<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] torch                     1.0.0a0+86e1009           <br>\n[conda] torchfile                 0.1.0                     <br>\n[conda] torchvision               0.2.1                     </p>\n<h2>Additional context</h2>\n<p><a href=\"https://drive.google.com/file/d/1rzJ3Qt_y_VNSLWH5U8R6Et1OJ5_IEgUS/view?usp=sharing\" rel=\"nofollow\">Here is the validation dataset</a>, you can download it for testing.</p>", "body_text": "Thread deadlock problem on Dataloader\nHey guys!\nCurrently, I try to train distributed model, but the dataloader seems to have a thread deadlock problem on master process while other slave processes reading data well. TripletPDRDataset tries to return 3 images in the function __getitem()__, including an anchor, a positive sample and a negative sample. I found that it can work well if don't use distributed sampler.\nBest,\nHeng Zhou\nTo Reproduce\nSteps to reproduce the behavior:\n\nRun the following command on master node:\n\npython -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=0\n\nRun the following command on slave node:\n\npython -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=1\nCode sample\nPDR_Dataset .py\nimport os\nimport numpy as np\nfrom torch.utils import data\nfrom torch.utils.data.sampler import BatchSampler\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport json\n\nclass TripletPDRDataset(data.Dataset):\n    def __init__(self, images_dir, labels_path, transforms, train):\n        self.train = train\n        with open(labels_path, 'r') as f:\n            examples = json.loads(f.read())\n        self.images_dir = images_dir\n        self.transforms = transforms\n        self.labels = []\n        self.image_ids = []\n        for example in examples:\n            self.image_ids.append(example[\"image_id\"])\n            self.labels.append(example[\"disease_class\"])\n        self.labels_set = set(self.labels)\n\n        self.label_to_indices = {\n            label: np.where(np.array(self.labels) == label)[0] for label in self.labels_set\n        }\n\n        if not self.train:\n            # generate fixed triplets for testing\n            random_state = np.random.RandomState(29)\n\n            triplets = [[i,\n                         random_state.choice(self.label_to_indices[self.labels[i]]),\n                         random_state.choice(self.label_to_indices[\n                                                 np.random.choice(\n                                                     list(self.labels_set - {self.labels[i]})\n                                                 )\n                                             ])\n                         ]\n                        for i in range(len(self.image_ids))]\n            self.test_triplets = triplets\n\n    def __getitem__(self, index):\n        if self.train:\n            img1_id, label1 = self.image_ids[index], self.labels[index]\n            positive_index = index\n            while positive_index == index:\n                positive_index = np.random.choice(self.label_to_indices[label1])\n            negative_label = np.random.choice(list(self.labels_set - {label1}))\n            negative_index = np.random.choice(self.label_to_indices[negative_label])\n            img2_id = self.image_ids[positive_index]\n            img3_id = self.image_ids[negative_index]\n        else:\n            img1_id = self.image_ids[self.test_triplets[index][0]]\n            img2_id = self.image_ids[self.test_triplets[index][1]]\n            img3_id = self.image_ids[self.test_triplets[index][2]]\n\n        img1 = Image.open(os.path.join(self.images_dir, img1_id))\n        img2 = Image.open(os.path.join(self.images_dir, img2_id))\n        img3 = Image.open(os.path.join(self.images_dir, img3_id))\n        if self.transforms is not None:\n            img1 = self.transforms(img1)\n            img2 = self.transforms(img2)\n            img3 = self.transforms(img3)\n        return (img1, img2, img3), []\n\n    def __len__(self):\n        return len(self.image_ids)\ntest_dataset.py\n# coding:utf-8\nimport torch\nimport argparse\nimport torchvision.transforms as transforms\nimport torch.utils.data.distributed\nimport torch.distributed as dist\nimport torch.utils.data\nfrom PDR_Dataset import *\n\nparser = argparse.ArgumentParser(description='PyTorch DataLoader Test')\nparser.add_argument('--world-size', default=1, type=int,\n                    help='number of distributed processes')\nparser.add_argument('--dist-url', default='env://', type=str,\n                    help='url used to set up distributed training')\nparser.add_argument('--global-rank', default=0, type=int,\n                    help='process rank of global process group')\nparser.add_argument('--dist-backend', default='nccl', type=str,\n                    help='distributed backend')\n\nargs = parser.parse_args()\n\ndist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                        world_size=args.world_size, rank=args.global_rank)\nprint(\"=> Distributed: success (%d/%d)!\" % (dist.get_rank() + 1, dist.get_world_size()))\n\n\ntraindir = os.path.join(r\"/home/asc001/AI_Challenger/PDR2018/data/trainingset/images\")\ntrainlabel = os.path.join(r\"/home/asc001/AI_Challenger/PDR2018/data/trainingset/AgriculturalDisease_train_annotations.json\")\n\n\ntrain_dataset = TripletPDRDataset(\n        traindir, trainlabel, transforms.Compose([\n            transforms.RandomResizedCrop(331, scale=(0.5, 1.0)),\n            transforms.RandomRotation(degrees=(0, 360)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]), ]), train=True)\n\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n\ntriplet_train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=4, shuffle=(train_sampler is None),\n        num_workers=2, pin_memory=True, sampler=train_sampler)\n\nfor batch_idx, (data, target) in enumerate(triplet_train_loader):\n    message = 'Train: [{}/{} ({:.0f}%)]'.format(\n        batch_idx * len(data[0]), len(triplet_train_loader),\n        100. * batch_idx / len(triplet_train_loader))\n    print(message)\nstack traces\nTraceback (most recent call last):\n  File \"test_dataset.py\", line 49, in <module>\n    for batch_idx, (data, target) in enumerate(triplet_train_loader):\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n    idx, batch = self._get_batch()\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 601, in _get_batch\n    return self.data_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/queue.py\", line 173, in get\n    self.not_empty.wait(remaining)\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 299, in wait\n    gotit = waiter.acquire(True, timeout)\nKeyboardInterrupt\nExpected behavior\nThe progress of distributed process outputs may look like the same, but the master process stuck while running.\nmaster\n...\nTrain: [1180/3965 (7%)]\nTrain: [1184/3965 (7%)]\nTrain: [1188/3965 (7%)]\nTrain: [1192/3965 (8%)]\nTrain: [1196/3965 (8%)]    <== stuck here\n\nslave\n...\nTrain: [6248/3965 (39%)]\nTrain: [6252/3965 (39%)]\nTrain: [6256/3965 (39%)]\nTrain: [6260/3965 (39%)] \n\nEnvironment\nPyTorch version: 1.0.0a0+86e1009\nIs debug build: No\nCUDA used to build PyTorch: 9.2.88\nOS: CentOS Linux release 7.3.1611 (Core)\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)\nCMake version: version 3.12.2\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: Tesla P100-PCIE-16GB\nGPU 1: Tesla P100-PCIE-16GB\nNvidia driver version: 396.26\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     1.0.0a0+86e1009           \n[conda] torchfile                 0.1.0                     \n[conda] torchvision               0.2.1                     \nAdditional context\nHere is the validation dataset, you can download it for testing.", "body": "## Thread deadlock problem on Dataloader\r\n\r\nHey guys! \r\n\r\nCurrently, I try to train distributed model, but the dataloader seems to have a thread deadlock problem on master process while other slave processes reading data well. `TripletPDRDataset` tries to return 3 images in the function `__getitem()__`, including an anchor, a positive sample and a negative sample. I found that it can work well if don't use distributed sampler.\r\n\r\nBest, \r\n\r\nHeng Zhou\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the following command on master node:\r\n```shell\r\npython -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=0\r\n```\r\n2. Run the following command on slave node:\r\n```shell\r\npython -u test_dataset.py --world-size=2 --dist-url=tcp://10.10.10.1:23456 --dist-backend=nccl --global-rank=1\r\n```\r\n\r\n### Code sample\r\n**PDR_Dataset .py**\r\n\r\n```python\r\nimport os\r\nimport numpy as np\r\nfrom torch.utils import data\r\nfrom torch.utils.data.sampler import BatchSampler\r\nfrom PIL import Image\r\nimport torchvision.transforms as transforms\r\nimport json\r\n\r\nclass TripletPDRDataset(data.Dataset):\r\n    def __init__(self, images_dir, labels_path, transforms, train):\r\n        self.train = train\r\n        with open(labels_path, 'r') as f:\r\n            examples = json.loads(f.read())\r\n        self.images_dir = images_dir\r\n        self.transforms = transforms\r\n        self.labels = []\r\n        self.image_ids = []\r\n        for example in examples:\r\n            self.image_ids.append(example[\"image_id\"])\r\n            self.labels.append(example[\"disease_class\"])\r\n        self.labels_set = set(self.labels)\r\n\r\n        self.label_to_indices = {\r\n            label: np.where(np.array(self.labels) == label)[0] for label in self.labels_set\r\n        }\r\n\r\n        if not self.train:\r\n            # generate fixed triplets for testing\r\n            random_state = np.random.RandomState(29)\r\n\r\n            triplets = [[i,\r\n                         random_state.choice(self.label_to_indices[self.labels[i]]),\r\n                         random_state.choice(self.label_to_indices[\r\n                                                 np.random.choice(\r\n                                                     list(self.labels_set - {self.labels[i]})\r\n                                                 )\r\n                                             ])\r\n                         ]\r\n                        for i in range(len(self.image_ids))]\r\n            self.test_triplets = triplets\r\n\r\n    def __getitem__(self, index):\r\n        if self.train:\r\n            img1_id, label1 = self.image_ids[index], self.labels[index]\r\n            positive_index = index\r\n            while positive_index == index:\r\n                positive_index = np.random.choice(self.label_to_indices[label1])\r\n            negative_label = np.random.choice(list(self.labels_set - {label1}))\r\n            negative_index = np.random.choice(self.label_to_indices[negative_label])\r\n            img2_id = self.image_ids[positive_index]\r\n            img3_id = self.image_ids[negative_index]\r\n        else:\r\n            img1_id = self.image_ids[self.test_triplets[index][0]]\r\n            img2_id = self.image_ids[self.test_triplets[index][1]]\r\n            img3_id = self.image_ids[self.test_triplets[index][2]]\r\n\r\n        img1 = Image.open(os.path.join(self.images_dir, img1_id))\r\n        img2 = Image.open(os.path.join(self.images_dir, img2_id))\r\n        img3 = Image.open(os.path.join(self.images_dir, img3_id))\r\n        if self.transforms is not None:\r\n            img1 = self.transforms(img1)\r\n            img2 = self.transforms(img2)\r\n            img3 = self.transforms(img3)\r\n        return (img1, img2, img3), []\r\n\r\n    def __len__(self):\r\n        return len(self.image_ids)\r\n```\r\n\r\n**test_dataset.py**\r\n\r\n```python\r\n# coding:utf-8\r\nimport torch\r\nimport argparse\r\nimport torchvision.transforms as transforms\r\nimport torch.utils.data.distributed\r\nimport torch.distributed as dist\r\nimport torch.utils.data\r\nfrom PDR_Dataset import *\r\n\r\nparser = argparse.ArgumentParser(description='PyTorch DataLoader Test')\r\nparser.add_argument('--world-size', default=1, type=int,\r\n                    help='number of distributed processes')\r\nparser.add_argument('--dist-url', default='env://', type=str,\r\n                    help='url used to set up distributed training')\r\nparser.add_argument('--global-rank', default=0, type=int,\r\n                    help='process rank of global process group')\r\nparser.add_argument('--dist-backend', default='nccl', type=str,\r\n                    help='distributed backend')\r\n\r\nargs = parser.parse_args()\r\n\r\ndist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\r\n                        world_size=args.world_size, rank=args.global_rank)\r\nprint(\"=> Distributed: success (%d/%d)!\" % (dist.get_rank() + 1, dist.get_world_size()))\r\n\r\n\r\ntraindir = os.path.join(r\"/home/asc001/AI_Challenger/PDR2018/data/trainingset/images\")\r\ntrainlabel = os.path.join(r\"/home/asc001/AI_Challenger/PDR2018/data/trainingset/AgriculturalDisease_train_annotations.json\")\r\n\r\n\r\ntrain_dataset = TripletPDRDataset(\r\n        traindir, trainlabel, transforms.Compose([\r\n            transforms.RandomResizedCrop(331, scale=(0.5, 1.0)),\r\n            transforms.RandomRotation(degrees=(0, 360)),\r\n            transforms.ToTensor(),\r\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n                                 std=[0.229, 0.224, 0.225]), ]), train=True)\r\n\r\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\r\n\r\ntriplet_train_loader = torch.utils.data.DataLoader(\r\n        train_dataset, batch_size=4, shuffle=(train_sampler is None),\r\n        num_workers=2, pin_memory=True, sampler=train_sampler)\r\n\r\nfor batch_idx, (data, target) in enumerate(triplet_train_loader):\r\n    message = 'Train: [{}/{} ({:.0f}%)]'.format(\r\n        batch_idx * len(data[0]), len(triplet_train_loader),\r\n        100. * batch_idx / len(triplet_train_loader))\r\n    print(message)\r\n```\r\n\r\n### stack traces\r\n\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"test_dataset.py\", line 49, in <module>\r\n    for batch_idx, (data, target) in enumerate(triplet_train_loader):\r\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\r\n    idx, batch = self._get_batch()\r\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 601, in _get_batch\r\n    return self.data_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\r\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/queue.py\", line 173, in get\r\n    self.not_empty.wait(remaining)\r\n  File \"/home/asc001/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 299, in wait\r\n    gotit = waiter.acquire(True, timeout)\r\nKeyboardInterrupt\r\n```\r\n\r\n## Expected behavior\r\n\r\nThe progress of distributed process outputs may look like the same, but the master process stuck while running. \r\n\r\n```\r\nmaster\r\n...\r\nTrain: [1180/3965 (7%)]\r\nTrain: [1184/3965 (7%)]\r\nTrain: [1188/3965 (7%)]\r\nTrain: [1192/3965 (8%)]\r\nTrain: [1196/3965 (8%)]    <== stuck here\r\n```\r\n\r\n```\r\nslave\r\n...\r\nTrain: [6248/3965 (39%)]\r\nTrain: [6252/3965 (39%)]\r\nTrain: [6256/3965 (39%)]\r\nTrain: [6260/3965 (39%)] \r\n```\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.0.0a0+86e1009\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.88\r\n\r\nOS: CentOS Linux release 7.3.1611 (Core) \r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: Tesla P100-PCIE-16GB\r\nGPU 1: Tesla P100-PCIE-16GB\r\n\r\nNvidia driver version: 396.26\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] torch                     1.0.0a0+86e1009           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n\r\n## Additional context\r\n[Here is the validation dataset](https://drive.google.com/file/d/1rzJ3Qt_y_VNSLWH5U8R6Et1OJ5_IEgUS/view?usp=sharing), you can download it for testing."}