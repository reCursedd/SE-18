{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9673", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9673/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9673/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9673/events", "html_url": "https://github.com/pytorch/pytorch/issues/9673", "id": 343291998, "node_id": "MDU6SXNzdWUzNDMyOTE5OTg=", "number": 9673, "title": "\"arguments are located on different GPUs\"  at  backward pass", "user": {"login": "youkaichao", "id": 23236638, "node_id": "MDQ6VXNlcjIzMjM2NjM4", "avatar_url": "https://avatars0.githubusercontent.com/u/23236638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/youkaichao", "html_url": "https://github.com/youkaichao", "followers_url": "https://api.github.com/users/youkaichao/followers", "following_url": "https://api.github.com/users/youkaichao/following{/other_user}", "gists_url": "https://api.github.com/users/youkaichao/gists{/gist_id}", "starred_url": "https://api.github.com/users/youkaichao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/youkaichao/subscriptions", "organizations_url": "https://api.github.com/users/youkaichao/orgs", "repos_url": "https://api.github.com/users/youkaichao/repos", "events_url": "https://api.github.com/users/youkaichao/events{/privacy}", "received_events_url": "https://api.github.com/users/youkaichao/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-07-21T03:10:25Z", "updated_at": "2018-07-21T13:34:21Z", "closed_at": "2018-07-21T04:53:28Z", "author_association": "NONE", "body_html": "<p>I have seen other posts about this error, but theirs are different from mine.</p>\n<p>after spending a whole night debugging, I located the error, but I can't fit it (can't figure out why it's happening).</p>\n<p>here is the minimum code to reproduce it ::</p>\n<pre><code>from easydl import *\nsetGPU('0,1')\n\nfeature_extractor = nn.Linear(10, 10)\nclassifier = nn.Linear(10, 10)\nnet = nn.Sequential(feature_extractor, classifier)\nnet.cuda()\nnet = nn.DataParallel(net)\n\ndiscriminator = nn.Sequential(\n    # place 1\n    GradientReverseModule(lambda step: aToBSheduler(step, 0.0, 1.0, gamma=10, max_iter=10000)),\n    nn.Linear(10,1)\n)\ndiscriminator.cuda()\ndiscriminator = nn.DataParallel(discriminator)\n\nop = optim.SGD(net.parameters(),lr=1)\n\nfor _ in range(2):\n    with OptimizerManager(op):\n        im_source = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\n        im_target = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\n        outs_source = net.forward(im_source)\n        outs_target = net.forward(im_target)\n        d_source = discriminator(outs_source)\n        d_target = discriminator(outs_target)\n        if len(sys.argv) &gt; 1:\n            # place 2\n            loss = torch.sum(outs_source) + torch.sum(outs_target) + torch.sum(d_source) + torch.sum(d_source)\n        else:\n            # place 3\n            loss = torch.sum(outs_source) + torch.sum(outs_target)\n        loss = loss * loss.detach()\n        loss.backward()\n</code></pre>\n<p>error happens at this line <code>loss.backward()</code>.</p>\n<p>there are 3 places that I marked in the code above.</p>\n<p>I have made 2 observations:</p>\n<ol>\n<li>if code at <strong>place 1</strong> is removed, no error is reported</li>\n<li>else, if I use <strong>place 2</strong>, I get an error of \"arguments are located on different GPUs\". if I use <strong>place 3</strong>, no error is reported.</li>\n</ol>\n<p>code at <strong>place 1</strong> has documentation <a href=\"https://easydl.readthedocs.io/en/latest/modules/easydl.pytorch.html?highlight=GradientReverseModule#easydl.pytorch.pytorch.GradientReverseModule\" rel=\"nofollow\">here</a> . In short, It servers as identity mapping at forward pass and reverses the gradient at backward pass. the scheduler changes the coefficient of backward pass gradually. documentation about <code>aToBSheduler</code> is <a href=\"https://easydl.readthedocs.io/en/latest/modules/easydl.common.html?highlight=aToBSheduler#easydl.common.scheduler.aToBSheduler\" rel=\"nofollow\">here</a></p>\n<p>how can I fix it if I want to use code at <strong>place 1</strong>?</p>", "body_text": "I have seen other posts about this error, but theirs are different from mine.\nafter spending a whole night debugging, I located the error, but I can't fit it (can't figure out why it's happening).\nhere is the minimum code to reproduce it ::\nfrom easydl import *\nsetGPU('0,1')\n\nfeature_extractor = nn.Linear(10, 10)\nclassifier = nn.Linear(10, 10)\nnet = nn.Sequential(feature_extractor, classifier)\nnet.cuda()\nnet = nn.DataParallel(net)\n\ndiscriminator = nn.Sequential(\n    # place 1\n    GradientReverseModule(lambda step: aToBSheduler(step, 0.0, 1.0, gamma=10, max_iter=10000)),\n    nn.Linear(10,1)\n)\ndiscriminator.cuda()\ndiscriminator = nn.DataParallel(discriminator)\n\nop = optim.SGD(net.parameters(),lr=1)\n\nfor _ in range(2):\n    with OptimizerManager(op):\n        im_source = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\n        im_target = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\n        outs_source = net.forward(im_source)\n        outs_target = net.forward(im_target)\n        d_source = discriminator(outs_source)\n        d_target = discriminator(outs_target)\n        if len(sys.argv) > 1:\n            # place 2\n            loss = torch.sum(outs_source) + torch.sum(outs_target) + torch.sum(d_source) + torch.sum(d_source)\n        else:\n            # place 3\n            loss = torch.sum(outs_source) + torch.sum(outs_target)\n        loss = loss * loss.detach()\n        loss.backward()\n\nerror happens at this line loss.backward().\nthere are 3 places that I marked in the code above.\nI have made 2 observations:\n\nif code at place 1 is removed, no error is reported\nelse, if I use place 2, I get an error of \"arguments are located on different GPUs\". if I use place 3, no error is reported.\n\ncode at place 1 has documentation here . In short, It servers as identity mapping at forward pass and reverses the gradient at backward pass. the scheduler changes the coefficient of backward pass gradually. documentation about aToBSheduler is here\nhow can I fix it if I want to use code at place 1?", "body": "I have seen other posts about this error, but theirs are different from mine.\r\n\r\nafter spending a whole night debugging, I located the error, but I can't fit it (can't figure out why it's happening).\r\n\r\nhere is the minimum code to reproduce it ::\r\n        \r\n```\r\nfrom easydl import *\r\nsetGPU('0,1')\r\n\r\nfeature_extractor = nn.Linear(10, 10)\r\nclassifier = nn.Linear(10, 10)\r\nnet = nn.Sequential(feature_extractor, classifier)\r\nnet.cuda()\r\nnet = nn.DataParallel(net)\r\n\r\ndiscriminator = nn.Sequential(\r\n    # place 1\r\n    GradientReverseModule(lambda step: aToBSheduler(step, 0.0, 1.0, gamma=10, max_iter=10000)),\r\n    nn.Linear(10,1)\r\n)\r\ndiscriminator.cuda()\r\ndiscriminator = nn.DataParallel(discriminator)\r\n\r\nop = optim.SGD(net.parameters(),lr=1)\r\n\r\nfor _ in range(2):\r\n    with OptimizerManager(op):\r\n        im_source = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\r\n        im_target = Variable(torch.from_numpy(np.random.rand(36, 10).astype(np.float32))).cuda()\r\n        outs_source = net.forward(im_source)\r\n        outs_target = net.forward(im_target)\r\n        d_source = discriminator(outs_source)\r\n        d_target = discriminator(outs_target)\r\n        if len(sys.argv) > 1:\r\n            # place 2\r\n            loss = torch.sum(outs_source) + torch.sum(outs_target) + torch.sum(d_source) + torch.sum(d_source)\r\n        else:\r\n            # place 3\r\n            loss = torch.sum(outs_source) + torch.sum(outs_target)\r\n        loss = loss * loss.detach()\r\n        loss.backward()\r\n```\r\n\r\nerror happens at this line ``loss.backward()``.\r\n\r\nthere are 3 places that I marked in the code above.\r\n\r\nI have made 2 observations:\r\n\r\n1.  if code at **place 1** is removed, no error is reported\r\n2.  else, if I use **place 2**, I get an error of \"arguments are located on different GPUs\". if I use **place 3**, no error is reported. \r\n\r\ncode at **place 1** has documentation [here](https://easydl.readthedocs.io/en/latest/modules/easydl.pytorch.html?highlight=GradientReverseModule#easydl.pytorch.pytorch.GradientReverseModule) . In short, It servers as identity mapping at forward pass and reverses the gradient at backward pass. the scheduler changes the coefficient of backward pass gradually. documentation about ``aToBSheduler`` is [here](https://easydl.readthedocs.io/en/latest/modules/easydl.common.html?highlight=aToBSheduler#easydl.common.scheduler.aToBSheduler)\r\n\r\nhow can I fix it if I want to use code at **place 1**?"}