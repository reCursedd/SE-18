{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/389447728", "html_url": "https://github.com/pytorch/pytorch/issues/805#issuecomment-389447728", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/805", "id": 389447728, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTQ0NzcyOA==", "user": {"login": "lucasb-eyer", "id": 1476029, "node_id": "MDQ6VXNlcjE0NzYwMjk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1476029?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucasb-eyer", "html_url": "https://github.com/lucasb-eyer", "followers_url": "https://api.github.com/users/lucasb-eyer/followers", "following_url": "https://api.github.com/users/lucasb-eyer/following{/other_user}", "gists_url": "https://api.github.com/users/lucasb-eyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucasb-eyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucasb-eyer/subscriptions", "organizations_url": "https://api.github.com/users/lucasb-eyer/orgs", "repos_url": "https://api.github.com/users/lucasb-eyer/repos", "events_url": "https://api.github.com/users/lucasb-eyer/events{/privacy}", "received_events_url": "https://api.github.com/users/lucasb-eyer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-16T09:00:36Z", "updated_at": "2018-05-16T09:00:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>And here's a version that is a pure non-linearity applied on the last dimension, this way it can be used with more than just Linears: convs of any dimension, time-series, etc. But it's almost trivial, honestly, so I agree with not including it in the lib to avoid bloat.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Maxout</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">pool_size</span>):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>._pool_size <span class=\"pl-k\">=</span> pool_size\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">assert</span> x.shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">%</span> <span class=\"pl-c1\">self</span>._pool_size <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>, \\\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Wrong input last dim size (<span class=\"pl-c1\">{}</span>) for Maxout(<span class=\"pl-c1\">{}</span>)<span class=\"pl-pds\">'</span></span>.format(x.shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-c1\">self</span>._pool_size)\n        m, i <span class=\"pl-k\">=</span> x.view(<span class=\"pl-k\">*</span>x.shape[:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], x.shape[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>] <span class=\"pl-k\">//</span> <span class=\"pl-c1\">self</span>._pool_size, <span class=\"pl-c1\">self</span>._pool_size).max(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-k\">return</span> m</pre></div>\n<p>Example use:</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.arange(<span class=\"pl-c1\">3</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">6</span>).view(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">6</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>tensor([[  0,   1,   2,   3,   4,   5],</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>        [  6,   7,   8,   9,  10,  11],</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>        [ 12,  13,  14,  15,  16,  17]])</span>\n\nMaxout(<span class=\"pl-c1\">3</span>)(torch.arange(<span class=\"pl-c1\">3</span><span class=\"pl-k\">*</span><span class=\"pl-c1\">6</span>).view(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">6</span>))\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>tensor([[  2,   5],</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>        [  8,  11],</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>        [ 14,  17]])</span></pre></div>", "body_text": "And here's a version that is a pure non-linearity applied on the last dimension, this way it can be used with more than just Linears: convs of any dimension, time-series, etc. But it's almost trivial, honestly, so I agree with not including it in the lib to avoid bloat.\nclass Maxout(nn.Module):\n    def __init__(self, pool_size):\n        super().__init__()\n        self._pool_size = pool_size\n\n    def forward(self, x):\n        assert x.shape[-1] % self._pool_size == 0, \\\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[-1], self._pool_size)\n        m, i = x.view(*x.shape[:-1], x.shape[-1] // self._pool_size, self._pool_size).max(-1)\n        return m\nExample use:\ntorch.arange(3*6).view(3,6)\n#tensor([[  0,   1,   2,   3,   4,   5],\n#        [  6,   7,   8,   9,  10,  11],\n#        [ 12,  13,  14,  15,  16,  17]])\n\nMaxout(3)(torch.arange(3*6).view(3,6))\n#tensor([[  2,   5],\n#        [  8,  11],\n#        [ 14,  17]])", "body": "And here's a version that is a pure non-linearity applied on the last dimension, this way it can be used with more than just Linears: convs of any dimension, time-series, etc. But it's almost trivial, honestly, so I agree with not including it in the lib to avoid bloat.\r\n\r\n```python\r\nclass Maxout(nn.Module):\r\n    def __init__(self, pool_size):\r\n        super().__init__()\r\n        self._pool_size = pool_size\r\n\r\n    def forward(self, x):\r\n        assert x.shape[-1] % self._pool_size == 0, \\\r\n            'Wrong input last dim size ({}) for Maxout({})'.format(x.shape[-1], self._pool_size)\r\n        m, i = x.view(*x.shape[:-1], x.shape[-1] // self._pool_size, self._pool_size).max(-1)\r\n        return m\r\n```\r\n\r\nExample use:\r\n\r\n```python\r\ntorch.arange(3*6).view(3,6)\r\n#tensor([[  0,   1,   2,   3,   4,   5],\r\n#        [  6,   7,   8,   9,  10,  11],\r\n#        [ 12,  13,  14,  15,  16,  17]])\r\n\r\nMaxout(3)(torch.arange(3*6).view(3,6))\r\n#tensor([[  2,   5],\r\n#        [  8,  11],\r\n#        [ 14,  17]])"}