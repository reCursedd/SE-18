{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/155975488", "pull_request_review_id": 82379273, "id": 155975488, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NTk3NTQ4OA==", "diff_hunk": "@@ -355,6 +355,50 @@ def lookup_pred(pred, xs):\n         \"\"\"Return the index of the first element of xs matching pred.\"\"\"\n         return next((i, x) for i, x in enumerate(xs) if pred(x))\n \n+    def is_nn_fwd(defn_name, declarations_by_name):", "path": "tools/autograd/gen_variable_type.py", "position": null, "original_position": 13, "commit_id": "f806cacd7c92d2f8205a73bfdaad3ddfa93d79f4", "original_commit_id": "a017bdd9b28f6d350f16eab7c4f7a860c10b337c", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Yes, you are right.\r\n\r\nThinking about this more, buffers seem to introduce a staging problem:\r\n\r\n- In Tensor, we would like foo and foo_forward, because a user who only plans to do inference prefers not to have to create the buffers themselves.\r\n\r\n- In Variable, we'd also like foo and foo_forward, but we cannot directly forward foo to foo in ATen; instead, it must be forwarded to foo_forward, so that we have access to the buffers to save for backwards.\r\n\r\nSo, coincidentally, Tensor foo and Variable foo have the same arguments, but they must be implemented twice because the Variable version must dispatch to Tensor foo_forward, NOT Variable foo_forward, as the native mechanism would ordinarily do (there is NO reason why you would expose such a thing.)\r\n\r\nI'm satisfied with the current mechanism, and OK if we just document the \"buffer out of nowhere\" behavior.", "created_at": "2017-12-11T03:01:26Z", "updated_at": "2018-11-23T15:37:15Z", "html_url": "https://github.com/pytorch/pytorch/pull/4096#discussion_r155975488", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4096", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/155975488"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4096#discussion_r155975488"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4096"}}, "body_html": "<p>Yes, you are right.</p>\n<p>Thinking about this more, buffers seem to introduce a staging problem:</p>\n<ul>\n<li>\n<p>In Tensor, we would like foo and foo_forward, because a user who only plans to do inference prefers not to have to create the buffers themselves.</p>\n</li>\n<li>\n<p>In Variable, we'd also like foo and foo_forward, but we cannot directly forward foo to foo in ATen; instead, it must be forwarded to foo_forward, so that we have access to the buffers to save for backwards.</p>\n</li>\n</ul>\n<p>So, coincidentally, Tensor foo and Variable foo have the same arguments, but they must be implemented twice because the Variable version must dispatch to Tensor foo_forward, NOT Variable foo_forward, as the native mechanism would ordinarily do (there is NO reason why you would expose such a thing.)</p>\n<p>I'm satisfied with the current mechanism, and OK if we just document the \"buffer out of nowhere\" behavior.</p>", "body_text": "Yes, you are right.\nThinking about this more, buffers seem to introduce a staging problem:\n\n\nIn Tensor, we would like foo and foo_forward, because a user who only plans to do inference prefers not to have to create the buffers themselves.\n\n\nIn Variable, we'd also like foo and foo_forward, but we cannot directly forward foo to foo in ATen; instead, it must be forwarded to foo_forward, so that we have access to the buffers to save for backwards.\n\n\nSo, coincidentally, Tensor foo and Variable foo have the same arguments, but they must be implemented twice because the Variable version must dispatch to Tensor foo_forward, NOT Variable foo_forward, as the native mechanism would ordinarily do (there is NO reason why you would expose such a thing.)\nI'm satisfied with the current mechanism, and OK if we just document the \"buffer out of nowhere\" behavior.", "in_reply_to_id": 155932189}