{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/301460796", "html_url": "https://github.com/pytorch/pytorch/issues/1528#issuecomment-301460796", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1528", "id": 301460796, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTQ2MDc5Ng==", "user": {"login": "Stonesjtu", "id": 4556044, "node_id": "MDQ6VXNlcjQ1NTYwNDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4556044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stonesjtu", "html_url": "https://github.com/Stonesjtu", "followers_url": "https://api.github.com/users/Stonesjtu/followers", "following_url": "https://api.github.com/users/Stonesjtu/following{/other_user}", "gists_url": "https://api.github.com/users/Stonesjtu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stonesjtu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stonesjtu/subscriptions", "organizations_url": "https://api.github.com/users/Stonesjtu/orgs", "repos_url": "https://api.github.com/users/Stonesjtu/repos", "events_url": "https://api.github.com/users/Stonesjtu/events{/privacy}", "received_events_url": "https://api.github.com/users/Stonesjtu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-15T12:31:57Z", "updated_at": "2017-05-15T12:31:57Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Additionally, I have another example for this bug.</p>\n<div class=\"highlight highlight-source-python\"><pre>va <span class=\"pl-k\">=</span> Variable(torch.Tensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>]), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nidx <span class=\"pl-k\">=</span> torch.LongTensor([<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">0</span>])\nloss <span class=\"pl-k\">=</span> va[idx].sum()\nloss.backward()\n<span class=\"pl-c1\">print</span>(va.grad)</pre></div>\n<p>output:</p>\n<pre><code>Variable containing:\n 1  # supposed to be 3\n 0\n[torch.FloatTensor of size 2]\n</code></pre>\n<p>It costs me 2 weeks to locate this bug in my script.<br>\nPlz fix ASAP.</p>", "body_text": "Additionally, I have another example for this bug.\nva = Variable(torch.Tensor([1,1]), requires_grad=True)\nidx = torch.LongTensor([0,0,0])\nloss = va[idx].sum()\nloss.backward()\nprint(va.grad)\noutput:\nVariable containing:\n 1  # supposed to be 3\n 0\n[torch.FloatTensor of size 2]\n\nIt costs me 2 weeks to locate this bug in my script.\nPlz fix ASAP.", "body": "Additionally, I have another example for this bug.\r\n```python\r\nva = Variable(torch.Tensor([1,1]), requires_grad=True)\r\nidx = torch.LongTensor([0,0,0])\r\nloss = va[idx].sum()\r\nloss.backward()\r\nprint(va.grad)\r\n```\r\noutput:\r\n```\r\nVariable containing:\r\n 1  # supposed to be 3\r\n 0\r\n[torch.FloatTensor of size 2]\r\n```\r\nIt costs me 2 weeks to locate this bug in my script.\r\nPlz fix ASAP."}