{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7019", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7019/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7019/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7019/events", "html_url": "https://github.com/pytorch/pytorch/issues/7019", "id": 318234909, "node_id": "MDU6SXNzdWUzMTgyMzQ5MDk=", "number": 7019, "title": "PyTorch 0.4 hangs with nn.DataParallel but PyTorch 0.3.1 does not", "user": {"login": "klshrinidhi", "id": 1181669, "node_id": "MDQ6VXNlcjExODE2Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1181669?v=4", "gravatar_id": "", "url": "https://api.github.com/users/klshrinidhi", "html_url": "https://github.com/klshrinidhi", "followers_url": "https://api.github.com/users/klshrinidhi/followers", "following_url": "https://api.github.com/users/klshrinidhi/following{/other_user}", "gists_url": "https://api.github.com/users/klshrinidhi/gists{/gist_id}", "starred_url": "https://api.github.com/users/klshrinidhi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/klshrinidhi/subscriptions", "organizations_url": "https://api.github.com/users/klshrinidhi/orgs", "repos_url": "https://api.github.com/users/klshrinidhi/repos", "events_url": "https://api.github.com/users/klshrinidhi/events{/privacy}", "received_events_url": "https://api.github.com/users/klshrinidhi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 897288569, "node_id": "MDU6TGFiZWw4OTcyODg1Njk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/pytorch", "name": "pytorch", "color": "f05732", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-04-26T23:57:09Z", "updated_at": "2018-11-16T14:01:06Z", "closed_at": "2018-05-01T17:58:27Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>The snippet below hangs with PyTorch 0.4 but successfully finishes with PyTorch 0.3.1.<br>\nI found that removing <code>model = nn.DataParallel(model).cuda()</code> allows the snippet pass.</p>\n<h2>Code example</h2>\n<pre><code>import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass NET(nn.Module):\n    def __init__(self):\n        super(NET, self).__init__()\n        self.dense = nn.Linear(256, 512)\n\n    def forward(self, input):\n        return self.dense(input)\n\nif __name__ == '__main__':\n    model = NET()\n    model = nn.DataParallel(model).cuda()\n    x = Variable(torch.rand(128, 256))\n    y = model(x) ##### &lt;&lt;&lt;&lt;--- GETS STUCK HERE FOREVER\n</code></pre>\n<p>Running above inside a docker container produces the following output.</p>\n<pre><code>NCCL version 2.1.15+cuda8.0\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/tmp/k6WOhB/60:/tmp/k6WOhB/59:/tmp/k6WOhB/58:/tmp/k6WOhB/57:/tmp/k6WOhB/56:/tmp/k6WOhB/55:/tmp/k6WOhB/54:/tmp/k6WOhB/53:/tmp/k6WOhB/52:/tmp/k6WOhB/51:/tmp/k6WOhB/50:/tmp/k6WOhB/49:/tmp/k6WOhB/48:/tmp/k6WOhB/47:/tmp/k6WOhB/46:/tmp/k6WOhB/45:/tmp/k6WOhB/44:/tmp/k6WOhB/43:/tmp/k6WOhB/42:/tmp/k6WOhB/41:/tmp/k6WOhB/40:/tmp/k6WOhB/39:/tmp/k6WOhB/38:/tmp/k6WOhB/37:/tmp/k6WOhB/36:/tmp/k6WOhB/35:/tmp/k6WOhB/34:/tmp/k6WOhB/33:/tmp/k6WOhB/32:/tmp/k6WOhB/31:/tmp/k6WOhB/30:/tmp/k6'\nUnexpected end of /proc/mounts line `WOhB/29:/tmp/k6WOhB/28:/tmp/k6WOhB/27:/tmp/k6WOhB/26:/tmp/k6WOhB/25:/tmp/k6WOhB/24:/tmp/k6WOhB/23:/tmp/k6WOhB/22:/tmp/k6WOhB/21:/tmp/k6WOhB/20:/tmp/k6WOhB/19:/tmp/k6WOhB/18:/tmp/k6WOhB/17:/tmp/k6WOhB/16:/tmp/k6WOhB/15:/tmp/k6WOhB/14:/tmp/k6WOhB/13:/tmp/k6WOhB/12:/tmp/k6WOhB/11:/tmp/k6WOhB/10:/tmp/k6WOhB/9:/tmp/k6WOhB/8:/tmp/k6WOhB/7:/tmp/k6WOhB/6:/tmp/k6WOhB/5:/tmp/k6WOhB/4:/tmp/k6WOhB/3:/tmp/k6WOhB/2:/tmp/k6WOhB/1:/tmp/k6WOhB/0,upperdir=/mnt/01/mesos_work/provisioner/containers/4436f199-bf49-453f-9b95-e84'\n&lt;&lt;&lt;&lt; STUCK HERE&gt;&gt;&gt;\n</code></pre>\n<h2>System Info</h2>\n<ul>\n<li>Running inside a docker container.</li>\n<li>openmpi 3.0.0</li>\n<li>nccl 2.15</li>\n<li>nnpack (commit -- 04d045a2efe3785edcd7ccc72c2e81dc7a3377c3)</li>\n</ul>\n<pre><code>Collecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Debian GNU/Linux 8 (jessie)\nGCC version: (Debian 4.9.2-10) 4.9.2\nCMake version: version 3.0.2\n\nPython version: 2.7\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.25\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.2\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\n\nVersions of relevant libraries:\n[pip] numpy (1.14.2)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] magma-cuda80              2.3.0                         1    soumith\n[conda] pytorch                   0.4.0           py27_cuda8.0.61_cudnn7.1.2_1    pytorch\n[conda] torchvision               0.2.1                    py27_1    pytorch\n</code></pre>\n<p>Happy to provide any more information.</p>", "body_text": "Issue description\nThe snippet below hangs with PyTorch 0.4 but successfully finishes with PyTorch 0.3.1.\nI found that removing model = nn.DataParallel(model).cuda() allows the snippet pass.\nCode example\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass NET(nn.Module):\n    def __init__(self):\n        super(NET, self).__init__()\n        self.dense = nn.Linear(256, 512)\n\n    def forward(self, input):\n        return self.dense(input)\n\nif __name__ == '__main__':\n    model = NET()\n    model = nn.DataParallel(model).cuda()\n    x = Variable(torch.rand(128, 256))\n    y = model(x) ##### <<<<--- GETS STUCK HERE FOREVER\n\nRunning above inside a docker container produces the following output.\nNCCL version 2.1.15+cuda8.0\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/tmp/k6WOhB/60:/tmp/k6WOhB/59:/tmp/k6WOhB/58:/tmp/k6WOhB/57:/tmp/k6WOhB/56:/tmp/k6WOhB/55:/tmp/k6WOhB/54:/tmp/k6WOhB/53:/tmp/k6WOhB/52:/tmp/k6WOhB/51:/tmp/k6WOhB/50:/tmp/k6WOhB/49:/tmp/k6WOhB/48:/tmp/k6WOhB/47:/tmp/k6WOhB/46:/tmp/k6WOhB/45:/tmp/k6WOhB/44:/tmp/k6WOhB/43:/tmp/k6WOhB/42:/tmp/k6WOhB/41:/tmp/k6WOhB/40:/tmp/k6WOhB/39:/tmp/k6WOhB/38:/tmp/k6WOhB/37:/tmp/k6WOhB/36:/tmp/k6WOhB/35:/tmp/k6WOhB/34:/tmp/k6WOhB/33:/tmp/k6WOhB/32:/tmp/k6WOhB/31:/tmp/k6WOhB/30:/tmp/k6'\nUnexpected end of /proc/mounts line `WOhB/29:/tmp/k6WOhB/28:/tmp/k6WOhB/27:/tmp/k6WOhB/26:/tmp/k6WOhB/25:/tmp/k6WOhB/24:/tmp/k6WOhB/23:/tmp/k6WOhB/22:/tmp/k6WOhB/21:/tmp/k6WOhB/20:/tmp/k6WOhB/19:/tmp/k6WOhB/18:/tmp/k6WOhB/17:/tmp/k6WOhB/16:/tmp/k6WOhB/15:/tmp/k6WOhB/14:/tmp/k6WOhB/13:/tmp/k6WOhB/12:/tmp/k6WOhB/11:/tmp/k6WOhB/10:/tmp/k6WOhB/9:/tmp/k6WOhB/8:/tmp/k6WOhB/7:/tmp/k6WOhB/6:/tmp/k6WOhB/5:/tmp/k6WOhB/4:/tmp/k6WOhB/3:/tmp/k6WOhB/2:/tmp/k6WOhB/1:/tmp/k6WOhB/0,upperdir=/mnt/01/mesos_work/provisioner/containers/4436f199-bf49-453f-9b95-e84'\n<<<< STUCK HERE>>>\n\nSystem Info\n\nRunning inside a docker container.\nopenmpi 3.0.0\nnccl 2.15\nnnpack (commit -- 04d045a2efe3785edcd7ccc72c2e81dc7a3377c3)\n\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Debian GNU/Linux 8 (jessie)\nGCC version: (Debian 4.9.2-10) 4.9.2\nCMake version: version 3.0.2\n\nPython version: 2.7\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.25\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.2\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\n\nVersions of relevant libraries:\n[pip] numpy (1.14.2)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] magma-cuda80              2.3.0                         1    soumith\n[conda] pytorch                   0.4.0           py27_cuda8.0.61_cudnn7.1.2_1    pytorch\n[conda] torchvision               0.2.1                    py27_1    pytorch\n\nHappy to provide any more information.", "body": "## Issue description\r\nThe snippet below hangs with PyTorch 0.4 but successfully finishes with PyTorch 0.3.1.\r\nI found that removing `model = nn.DataParallel(model).cuda()` allows the snippet pass.\r\n\r\n## Code example\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nclass NET(nn.Module):\r\n    def __init__(self):\r\n        super(NET, self).__init__()\r\n        self.dense = nn.Linear(256, 512)\r\n\r\n    def forward(self, input):\r\n        return self.dense(input)\r\n\r\nif __name__ == '__main__':\r\n    model = NET()\r\n    model = nn.DataParallel(model).cuda()\r\n    x = Variable(torch.rand(128, 256))\r\n    y = model(x) ##### <<<<--- GETS STUCK HERE FOREVER\r\n```\r\nRunning above inside a docker container produces the following output.\r\n```\r\nNCCL version 2.1.15+cuda8.0\r\nUnexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/tmp/k6WOhB/60:/tmp/k6WOhB/59:/tmp/k6WOhB/58:/tmp/k6WOhB/57:/tmp/k6WOhB/56:/tmp/k6WOhB/55:/tmp/k6WOhB/54:/tmp/k6WOhB/53:/tmp/k6WOhB/52:/tmp/k6WOhB/51:/tmp/k6WOhB/50:/tmp/k6WOhB/49:/tmp/k6WOhB/48:/tmp/k6WOhB/47:/tmp/k6WOhB/46:/tmp/k6WOhB/45:/tmp/k6WOhB/44:/tmp/k6WOhB/43:/tmp/k6WOhB/42:/tmp/k6WOhB/41:/tmp/k6WOhB/40:/tmp/k6WOhB/39:/tmp/k6WOhB/38:/tmp/k6WOhB/37:/tmp/k6WOhB/36:/tmp/k6WOhB/35:/tmp/k6WOhB/34:/tmp/k6WOhB/33:/tmp/k6WOhB/32:/tmp/k6WOhB/31:/tmp/k6WOhB/30:/tmp/k6'\r\nUnexpected end of /proc/mounts line `WOhB/29:/tmp/k6WOhB/28:/tmp/k6WOhB/27:/tmp/k6WOhB/26:/tmp/k6WOhB/25:/tmp/k6WOhB/24:/tmp/k6WOhB/23:/tmp/k6WOhB/22:/tmp/k6WOhB/21:/tmp/k6WOhB/20:/tmp/k6WOhB/19:/tmp/k6WOhB/18:/tmp/k6WOhB/17:/tmp/k6WOhB/16:/tmp/k6WOhB/15:/tmp/k6WOhB/14:/tmp/k6WOhB/13:/tmp/k6WOhB/12:/tmp/k6WOhB/11:/tmp/k6WOhB/10:/tmp/k6WOhB/9:/tmp/k6WOhB/8:/tmp/k6WOhB/7:/tmp/k6WOhB/6:/tmp/k6WOhB/5:/tmp/k6WOhB/4:/tmp/k6WOhB/3:/tmp/k6WOhB/2:/tmp/k6WOhB/1:/tmp/k6WOhB/0,upperdir=/mnt/01/mesos_work/provisioner/containers/4436f199-bf49-453f-9b95-e84'\r\n<<<< STUCK HERE>>>\r\n```\r\n\r\n## System Info\r\n* Running inside a docker container.\r\n* openmpi 3.0.0\r\n* nccl 2.15\r\n* nnpack (commit -- 04d045a2efe3785edcd7ccc72c2e81dc7a3377c3)\r\n```\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Debian GNU/Linux 8 (jessie)\r\nGCC version: (Debian 4.9.2-10) 4.9.2\r\nCMake version: version 3.0.2\r\n\r\nPython version: 2.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 390.25\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.2\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.2)\r\n[pip] torch (0.4.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] magma-cuda80              2.3.0                         1    soumith\r\n[conda] pytorch                   0.4.0           py27_cuda8.0.61_cudnn7.1.2_1    pytorch\r\n[conda] torchvision               0.2.1                    py27_1    pytorch\r\n```\r\n\r\nHappy to provide any more information. "}