{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153259866", "pull_request_review_id": 79239917, "id": 153259866, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MzI1OTg2Ng==", "diff_hunk": "@@ -426,58 +434,55 @@ __global__ void THCTensor_kernel_varInnermostDim(Real *tgt, Real *src_, unsigned\n       }\n     }\n \n-    local_sum[threadIdx.y][threadIdx.x] =\n+    Accreal local_sum =\n         THCNumerics<Accreal>::mul(local_mean, ScalarConvert<int, Accreal>::to(count));\n     __syncthreads();\n \n-\n-    // Compute the true mean of each of the blockDim.x rows by reducing the sums\n-    for (unsigned s = 8; s > 1; s >>= 1) {\n-      if (row < num_rows && threadIdx.x < s) {\n-        local_sum[threadIdx.y][threadIdx.x] = THCNumerics<Accreal>::add(\n-            local_sum[threadIdx.y][threadIdx.x],\n-            local_sum[threadIdx.y][threadIdx.x + s]);\n-      }\n-      __syncthreads();\n+    /*\n+     * We are reducing across each row of 16 threads to find the true sum of the\n+     * entire input row.\n+     *\n+     * This is done in a warp shuffle: each warp has 2 rows of 16 threads for a\n+     * total of 32 threads. The warp will accumulate the sums of each row of \n+     * 16 threads in the first thread of the row (with threadIdx.x == 0)\n+     */\n+    for (unsigned s = 8; s >= 1; s >>= 1) {\n+      local_sum = THCNumerics<Accreal>::add(local_sum, \n+          WARP_SHFL_DOWN((row < num_rows) ? local_sum : acc_zero, s));\n     }\n-\n     if (row < num_rows && threadIdx.x == 0) {\n-      mean[threadIdx.y] = THCNumerics<Accreal>::div(\n-          THCNumerics<Accreal>::add(local_sum[threadIdx.y][0], local_sum[threadIdx.y][1]),\n-          ScalarConvert<int, Accreal>::to(row_size));\n+      // This is the true mean of the entire input row. There are 32 true means.\n+      mean[threadIdx.y] = THCNumerics<Accreal>::div(local_sum, ScalarConvert<int, Accreal>::to(row_size));", "path": "aten/src/THC/THCTensorMathReduce.cuh", "position": null, "original_position": 78, "commit_id": "3196e5ddaa826b9e19563999120c64aa6efb545e", "original_commit_id": "37bafd189fca4efae41f0a37000f5727ee9b02a3", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "Good point, that should work. I'll update this using __shfl_sync", "created_at": "2017-11-27T17:04:31Z", "updated_at": "2018-11-23T15:36:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/3846#discussion_r153259866", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3846", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/153259866"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3846#discussion_r153259866"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3846"}}, "body_html": "<p>Good point, that should work. I'll update this using __shfl_sync</p>", "body_text": "Good point, that should work. I'll update this using __shfl_sync", "in_reply_to_id": 152860085}