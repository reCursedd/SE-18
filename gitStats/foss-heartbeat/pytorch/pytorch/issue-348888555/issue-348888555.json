{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10357", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10357/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10357/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10357/events", "html_url": "https://github.com/pytorch/pytorch/issues/10357", "id": 348888555, "node_id": "MDU6SXNzdWUzNDg4ODg1NTU=", "number": 10357, "title": "torch.bernoulli inconsistent gpu/cpu results", "user": {"login": "davidmascharka", "id": 5611862, "node_id": "MDQ6VXNlcjU2MTE4NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5611862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmascharka", "html_url": "https://github.com/davidmascharka", "followers_url": "https://api.github.com/users/davidmascharka/followers", "following_url": "https://api.github.com/users/davidmascharka/following{/other_user}", "gists_url": "https://api.github.com/users/davidmascharka/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmascharka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmascharka/subscriptions", "organizations_url": "https://api.github.com/users/davidmascharka/orgs", "repos_url": "https://api.github.com/users/davidmascharka/repos", "events_url": "https://api.github.com/users/davidmascharka/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmascharka/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-08-08T20:55:27Z", "updated_at": "2018-09-19T23:51:36Z", "closed_at": "2018-09-19T23:51:36Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>The behavior of CUDA and CPU <code>sample</code> in the <code>distributions</code> module is inconsistent. On the CPU side, there appears to be an argument validity check, while on the GPU side, this does not appear to be implemented. <a href=\"https://github.com/pytorch/pytorch/issues/5248\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/5248/hovercard\">This issue</a> is somewhat related.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.distributions.Bernoulli(torch.FloatTensor([<span class=\"pl-c1\">1.5</span>])).sample()\n<span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">150</span><span class=\"pl-k\">-</span>d17a827b2cc3<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span> torch.distributions.Bernoulli(torch.FloatTensor([<span class=\"pl-c1\">1.5</span>])).sample()\n\npython3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>distributions<span class=\"pl-k\">/</span>bernoulli.py <span class=\"pl-k\">in</span> sample(<span class=\"pl-c1\">self</span>, sample_shape)\n     <span class=\"pl-c1\">72</span>         shape <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._extended_shape(sample_shape)\n     <span class=\"pl-c1\">73</span>         <span class=\"pl-k\">with</span> torch.no_grad():\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">74</span>             <span class=\"pl-k\">return</span> torch.bernoulli(<span class=\"pl-c1\">self</span>.probs.expand(shape))\n     <span class=\"pl-c1\">75</span> \n     <span class=\"pl-c1\">76</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">log_prob</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">value</span>):\n\n<span class=\"pl-c1\">RuntimeError</span>: invalid argument <span class=\"pl-c1\">1</span>: must be <span class=\"pl-k\">&gt;=</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">and</span> <span class=\"pl-k\">&lt;=</span> <span class=\"pl-c1\">1</span> at <span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>aten<span class=\"pl-k\">/</span>src<span class=\"pl-k\">/</span><span class=\"pl-c1\">TH</span><span class=\"pl-k\">/</span>THRandom.cpp:<span class=\"pl-c1\">314</span>\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.distributions.Bernoulli(torch.cuda.FloatTensor([<span class=\"pl-c1\">1.5</span>])).sample()\ntensor([<span class=\"pl-c1\">1</span>.], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.distributions.Bernoulli(torch.cuda.FloatTensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>])).sample()\ntensor([<span class=\"pl-c1\">0</span>.], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)</pre></div>\n<h2>System Info</h2>\n<pre><code>PyTorch version: 0.5.0a0+a24163a\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.9.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration: \nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.67\ncuDNN version: 7\n\nVersions of relevant libraries:\n[pip] numpy (1.13.3)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.5.0a0+a24163a)\n[pip] torchvision (0.1.9)\n</code></pre>", "body_text": "Issue description\nThe behavior of CUDA and CPU sample in the distributions module is inconsistent. On the CPU side, there appears to be an argument validity check, while on the GPU side, this does not appear to be implemented. This issue is somewhat related.\nCode example\n>>> torch.distributions.Bernoulli(torch.FloatTensor([1.5])).sample()\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-150-d17a827b2cc3> in <module>()\n----> 1 torch.distributions.Bernoulli(torch.FloatTensor([1.5])).sample()\n\npython3.6/site-packages/torch/distributions/bernoulli.py in sample(self, sample_shape)\n     72         shape = self._extended_shape(sample_shape)\n     73         with torch.no_grad():\n---> 74             return torch.bernoulli(self.probs.expand(shape))\n     75 \n     76     def log_prob(self, value):\n\nRuntimeError: invalid argument 1: must be >= 0 and <= 1 at /pytorch/aten/src/TH/THRandom.cpp:314\n\n>>> torch.distributions.Bernoulli(torch.cuda.FloatTensor([1.5])).sample()\ntensor([1.], device='cuda:0')\n\n>>> torch.distributions.Bernoulli(torch.cuda.FloatTensor([-2])).sample()\ntensor([0.], device='cuda:0')\nSystem Info\nPyTorch version: 0.5.0a0+a24163a\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.9.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration: \nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.67\ncuDNN version: 7\n\nVersions of relevant libraries:\n[pip] numpy (1.13.3)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.5.0a0+a24163a)\n[pip] torchvision (0.1.9)", "body": "## Issue description\r\n\r\nThe behavior of CUDA and CPU `sample` in the `distributions` module is inconsistent. On the CPU side, there appears to be an argument validity check, while on the GPU side, this does not appear to be implemented. [This issue](https://github.com/pytorch/pytorch/issues/5248) is somewhat related.\r\n\r\n## Code example\r\n\r\n```python\r\n>>> torch.distributions.Bernoulli(torch.FloatTensor([1.5])).sample()\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-150-d17a827b2cc3> in <module>()\r\n----> 1 torch.distributions.Bernoulli(torch.FloatTensor([1.5])).sample()\r\n\r\npython3.6/site-packages/torch/distributions/bernoulli.py in sample(self, sample_shape)\r\n     72         shape = self._extended_shape(sample_shape)\r\n     73         with torch.no_grad():\r\n---> 74             return torch.bernoulli(self.probs.expand(shape))\r\n     75 \r\n     76     def log_prob(self, value):\r\n\r\nRuntimeError: invalid argument 1: must be >= 0 and <= 1 at /pytorch/aten/src/TH/THRandom.cpp:314\r\n\r\n>>> torch.distributions.Bernoulli(torch.cuda.FloatTensor([1.5])).sample()\r\ntensor([1.], device='cuda:0')\r\n\r\n>>> torch.distributions.Bernoulli(torch.cuda.FloatTensor([-2])).sample()\r\ntensor([0.], device='cuda:0')\r\n```\r\n\r\n## System Info\r\n\r\n```\r\nPyTorch version: 0.5.0a0+a24163a\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.9.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 390.67\r\ncuDNN version: 7\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.13.3)\r\n[pip] numpydoc (0.7.0)\r\n[pip] torch (0.5.0a0+a24163a)\r\n[pip] torchvision (0.1.9)\r\n```"}