{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230486827", "pull_request_review_id": 171244568, "id": 230486827, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMDQ4NjgyNw==", "diff_hunk": "@@ -0,0 +1,334 @@\n+#include \"caffe2/proto/caffe2_pb.h\"\n+#include \"caffe2/proto/torch_pb.h\"\n+\n+#include \"caffe2/serialize/intermediate_model.h\"\n+\n+namespace at {\n+namespace serialize{\n+\n+void IntermediateTensor::update(caffe2::TensorProto* tensor_proto,\n+    std::unordered_map<uint64_t, std::shared_ptr<SharedData>>* id_data,\n+    DeserializeMode mode) {\n+  AT_ASSERTM(tensor_proto->has_data_type(), \"no data_type in TensorProto!\");\n+  dataType_ = tensor_proto->data_type();\n+  for (int i = 0; i < tensor_proto->dims_size(); ++i) {\n+    dims_.push_back(tensor_proto->dims(i));\n+  }\n+  if (tensor_proto->has_name()) {\n+    // TODO: TensorProto's name is not used, we just keep it here for now\n+    // later we will deprecate it.\n+    name_ = tensor_proto->name();\n+  }\n+  if (tensor_proto->has_device_detail()) {\n+    const auto& device_detail = tensor_proto->device_detail();\n+    deviceDetail_.deviceType = device_detail.device_type();\n+    if (device_detail.has_device_id()) {\n+      deviceDetail_.deviceId = device_detail.device_id();\n+    }\n+    if (device_detail.has_random_seed()) {\n+      AT_ERROR(\"DeviceOption contains random seed, not supported!\");\n+    }\n+    if (device_detail.has_node_name()) {\n+      AT_ERROR(\"DeviceOption contains node name, not supported!\");\n+    }\n+    if (device_detail.extra_info_size() > 0) {\n+      AT_ERROR(\"DeviceOption contains extra info, not supported!\");\n+    }\n+  }\n+  AT_ASSERTM(tensor_proto->has_storage_type(), \"no storage_type in TensorProto!\");\n+  int64_t storage_type = tensor_proto->storage_type();\n+  switch (storage_type) {\n+    case caffe2::TensorProto_StorageType_TYPED:\n+      // TODO\n+      AT_ERROR(\"Storing data in typed field is not suppored yet!\");\n+    case caffe2::TensorProto_StorageType_RAW:\n+      // TODO\n+      AT_ERROR(\"Storing data in raw field is not supported yet!\");\n+    case caffe2::TensorProto_StorageType_EXTERNAL:\n+      {\n+        AT_ASSERTM(tensor_proto->has_external_data(), \"storage type is EXTERNAL, \"\n+            \"but no external_data in TensorProto!\");\n+        auto& external_data = tensor_proto->external_data();\n+        offset_ = external_data.offset();\n+        for (int i = 0; i < external_data.strides_size(); ++i) {\n+          strides_.push_back(external_data.strides(i));\n+        }\n+        int64_t source_type = external_data.source_type();\n+        if (source_type == caffe2::ExternalDataProto_SourceType_INLINE_CONTAINER) {\n+          AT_ASSERTM(external_data.has_record_id(), \"no record_id in ExternalDataProto and source_type is INLINE_CONTAINER!\");\n+          // only load the data of the tensor in EAGER mode\n+          uint64_t record_id = caffe2::stoull(external_data.record_id());\n+          auto it = id_data->find(record_id);\n+          if (mode == DeserializeMode::EAGER) {\n+            // tensor data is only loaded in EAGER mode\n+            if (it == id_data->end()) {\n+              AT_ERROR(\"Tensor's data is missing in id_data, tensor name is \",\n+                  name_, \", and record_id is \", caffe2::to_string(record_id));\n+            }\n+            data_ = it->second;\n+            AT_ASSERT(data_->recordId.value() == record_id);\n+          } else {\n+            AT_ASSERTM(mode == DeserializeMode::LAZY, \"unkonw deserialize mode.\");\n+            if (it == id_data->end()) {\n+              data_ = std::make_shared<SharedData>(record_id);\n+              (*id_data)[record_id] = data_;\n+            } else {\n+              data_ = it->second;\n+            }\n+          }\n+        } else if (source_type == caffe2::ExternalDataProto_SourceType_SIMPLE_FILE) {\n+          // TODO\n+          AT_ERROR(\"Storing data in separate file is not supported yet!\");\n+        } else {\n+          // TODO\n+          AT_ERROR(\"Unknown source_type: \", caffe2::to_string(source_type));\n+        }\n+        break;\n+      }\n+    case caffe2::TensorProto_StorageType_NO_CONTENT:\n+      {\n+        noContent_ = true;\n+        break;\n+      }\n+    default:\n+      AT_ERROR(\"Uknown storage_type: \", caffe2::to_string(storage_type));\n+  }\n+\n+}\n+\n+void IntermediateTensor::dump(caffe2::TensorProto* tensor_proto) {\n+  for (auto dim : dims_) {\n+    tensor_proto->add_dims(dim);\n+  }\n+  tensor_proto->set_data_type(static_cast<caffe2::TensorProto_DataType>(dataType_));\n+  // NB: maybe later we support RAW\n+  tensor_proto->set_storage_type(caffe2::TensorProto_StorageType::TensorProto_StorageType_EXTERNAL);\n+  caffe2::ExternalDataProto* data_proto = tensor_proto->mutable_external_data();\n+  // NB: maybe later we support SIMPLE_FILE\n+  data_proto->set_source_type(caffe2::ExternalDataProto_SourceType_INLINE_CONTAINER);\n+  AT_ASSERTM(data_->recordId.has_value(), \"recordId is required for SharedData!\");\n+  data_proto->set_record_id(caffe2::to_string(data_->recordId.value()));\n+  data_proto->set_offset(offset_);\n+  for (auto stride : strides_) {\n+    data_proto->add_strides(stride);\n+  }\n+  caffe2::DeviceOption* device_detail = tensor_proto->mutable_device_detail();\n+  device_detail->set_device_type(deviceDetail_.deviceType);\n+  if (deviceDetail_.deviceId.has_value()) {\n+    device_detail->set_device_id(deviceDetail_.deviceId.value());\n+  }\n+}\n+\n+IntermediateParameter::IntermediateParameter(torch::ParameterDef* param_def,\n+    std::unordered_map<uint64_t, std::shared_ptr<SharedData>>* id_data,\n+    DeserializeMode mode) {\n+  AT_ASSERTM(param_def->has_name(), \"ParameterDef has no name! \",\n+      param_def->DebugString());\n+  name_ = param_def->name();\n+  isBuffer_ = param_def->is_buffer();\n+  requireGradient_ = param_def->require_gradient();\n+  if (param_def->has_tensor()) {\n+    tensor_.update(param_def->mutable_tensor(), id_data, mode);\n+  } else {\n+    // TODO\n+    AT_ERROR(\"A ParameterDef does not contain any tensor!\");\n+  }\n+}\n+\n+void IntermediateParameter::dump(torch::ParameterDef* param_def) {\n+  param_def->set_name(name_);\n+  param_def->set_is_buffer(isBuffer_);\n+  param_def->set_require_gradient(requireGradient_);\n+  caffe2::TensorProto* tensor_def = param_def->mutable_tensor();\n+  tensor_.dump(tensor_def);\n+}\n+\n+IntermediateMethod::IntermediateMethod(torch::MethodDef* method_def) {\n+  AT_ASSERTM(method_def->has_name(), \"name is required for MethodDef!\");\n+  name_ = method_def->name();\n+  if (method_def->has_torch_script()) {\n+    torchScript_ = method_def->torch_script();\n+  } else if (method_def->has_graph()) {\n+    graph_.reset(method_def->release_graph());\n+  } else {\n+    AT_ERROR(\"No method body is found!\");\n+  }\n+}\n+\n+IntermediateMethod::IntermediateMethod(const IntermediateMethod& method) {", "path": "caffe2/serialize/intermediate_model.cc", "position": null, "original_position": 158, "commit_id": "53180b449481169c2c2ff9e23ac18289412c62b3", "original_commit_id": "79a037e168a2f09bbc918c6801865b6e333c8a03", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "why do you ever need to have copy / assignment constructors for these?", "created_at": "2018-11-02T19:41:09Z", "updated_at": "2018-11-23T15:54:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/13020#discussion_r230486827", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13020", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230486827"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13020#discussion_r230486827"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13020"}}, "body_html": "<p>why do you ever need to have copy / assignment constructors for these?</p>", "body_text": "why do you ever need to have copy / assignment constructors for these?"}