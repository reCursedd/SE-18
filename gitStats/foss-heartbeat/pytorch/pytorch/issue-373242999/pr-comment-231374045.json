{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231374045", "pull_request_review_id": 172332477, "id": 231374045, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTM3NDA0NQ==", "diff_hunk": "@@ -0,0 +1,399 @@\n+#pragma once\n+\n+#include <unordered_map>\n+#include <stack>\n+#include <string>\n+\n+#include <ATen/core/Allocator.h>\n+#include <c10/util/Optional.h>\n+\n+#include \"caffe2/core/common.h\"\n+#include \"caffe2/serialize/inline_container.h\"\n+\n+namespace caffe2 {\n+  class TensorProto;\n+  class NetDef;\n+}\n+\n+namespace torch {\n+  class ParameterDef;\n+  class MethodDef;\n+  class ModuleDef;\n+  class ModelDef;\n+}\n+\n+namespace at {\n+namespace serialize {\n+\n+enum class DeserializeMode {\n+  // In LOADER_TENSOR_DATA mode, we load the file from the beginning, and eagarly load the content of tensors\n+  LOADER_TENSOR_DATA = 1,\n+  // In HEADER_ONLY mode, we only load the last record of the file, which is the model metadata\n+  // And the data of the tensor will be loaded later\n+  HEADER_ONLY = 2,\n+};\n+\n+// multiple tensor may share the same content\n+// SharedData contains:\n+//    1) record id (i.e., the offset in the inline container)\n+//    2) size, the size of the content\n+//    3) data, in serialize, IntermediateModel does NOT own the data,\n+//       in deserialize, the data pointer is returned by PyTorchFileReader,\n+//       and IntermediateModel owns the data. The ownership later will be\n+//       transferred to Tensor\n+struct SharedData {\n+  // constructor\n+  explicit SharedData(uint64_t record_id, uint64_t size)\n+    : recordId(record_id), size(size), dataPtr() {}\n+  explicit SharedData(uint64_t record_id, uint64_t size, at::DataPtr&& data_ptr)\n+    : recordId(record_id), size(size), dataPtr(std::move(data_ptr)) {}\n+\n+  c10::optional<uint64_t> recordId;\n+  uint64_t size = 0; // the size of the record\n+  at::DataPtr dataPtr;\n+};\n+\n+// IntermediateDeviceOption stores device related information\n+struct IntermediateDeviceOption {\n+  int32_t deviceType = 0;\n+  c10::optional<int32_t> deviceId;\n+};\n+\n+// IntermediateTensor contains\n+//   1) element type information\n+//   2) shape information\n+//   3) pointer to the data (including offset and strides)\n+class CAFFE2_API IntermediateTensor final {\n+ public:\n+  // constructor\n+  IntermediateTensor() = default;\n+\n+  explicit IntermediateTensor(int64_t dataType, const std::vector<int64_t>& dims,\n+      int64_t offset): dataType_(dataType), dims_(dims), offset_(offset) {}\n+\n+  // extract data from TensorProto, called in deserialize\n+  // assume record id to data mapping is complete\n+  void update(caffe2::TensorProto* tensor_proto,\n+      std::unordered_map<uint64_t, std::shared_ptr<SharedData>>* id_data,\n+      DeserializeMode mode);\n+\n+  // update the data pointer, invoked in serialize\n+  void updateData(std::shared_ptr<SharedData> data) {\n+    data_ = data;\n+  }\n+\n+  // dump data to TensorProto, called in serialize\n+  // assume the data is already saved\n+  void dump(caffe2::TensorProto* tensor_proto);\n+\n+  // getters/setters\n+  int64_t dataType() const {\n+    return dataType_;\n+  }\n+\n+  const std::vector<int64_t>& dims() const {\n+    return dims_;\n+  }\n+\n+  std::shared_ptr<SharedData> data() const {\n+    return data_;\n+  }\n+\n+  int64_t offset() const {\n+    return offset_;\n+  }\n+\n+  const IntermediateDeviceOption& deviceDetail() const {\n+    return deviceDetail_;\n+  }\n+\n+  const std::vector<int64_t>& strides() const {\n+    return strides_;\n+  }\n+\n+  bool noContent() const {\n+    return noContent_;\n+  }\n+\n+\n+  void setData(std::shared_ptr<SharedData> data) {\n+    AT_ASSERTM(!noContent_, \"noContent_ is true, but set content!\");\n+    data_ = data;\n+  }\n+\n+  void setStrides(const std::vector<int64_t>& strides) {\n+    strides_ = strides;\n+  }\n+\n+  void setDeviceDetail(const IntermediateDeviceOption& device_detail) {\n+    deviceDetail_ = device_detail;\n+  }\n+\n+ private:\n+  std::string name_;\n+  int64_t dataType_;\n+  std::vector<int64_t> dims_;\n+  int64_t offset_ = 0;\n+  std::vector<int64_t> strides_;\n+  // TODO: since we still have 2 different Tensor classes in Caffe2 and PyTorch\n+  // right now, let's just store the data pointer, and create Tensors\n+  // while converting IntermediateModel to the JitScriptModule/Predictor/etc.\n+  std::shared_ptr<SharedData> data_;\n+  IntermediateDeviceOption deviceDetail_;\n+  bool noContent_ = false;\n+};\n+\n+class CAFFE2_API IntermediateParameter final {\n+ public:\n+  // constructors\n+  IntermediateParameter() = default;\n+\n+  explicit IntermediateParameter(const std::string& name, bool is_buffer, bool require_gradient) :\n+    name_(name), isBuffer_(is_buffer), requireGradient_(require_gradient) {}\n+\n+  explicit IntermediateParameter(torch::ParameterDef* param_def,\n+      std::unordered_map<uint64_t, std::shared_ptr<SharedData>>* id_data,\n+      DeserializeMode mode);\n+\n+  // dump data to ParameterDef, invoked in serialize\n+  void dump(torch::ParameterDef* param_def);\n+\n+  // getters/setters\n+  const std::string& name() const {\n+    return name_;\n+  }\n+\n+  bool isBuffer() const {\n+    return isBuffer_;\n+  }\n+\n+  bool requireGradient() const {\n+    return requireGradient_;\n+  }\n+\n+  const IntermediateTensor& tensor() const {\n+    return tensor_;\n+  }\n+\n+  IntermediateTensor* mutableTensor() {\n+    return &tensor_;\n+  }\n+\n+  void setName(const std::string& name) {\n+    name_ = name;\n+  }\n+\n+  void setIsBuffer(bool is_buffer) {\n+    isBuffer_ = is_buffer;\n+  }\n+\n+  void setRequireGradient(bool require_gradient) {\n+    requireGradient_ = require_gradient;\n+  }\n+\n+ private:\n+  std::string name_;\n+  bool isBuffer_ = false;\n+  bool requireGradient_ = false;\n+  IntermediateTensor tensor_;\n+};\n+\n+class CAFFE2_API IntermediateMethod final {\n+ public:\n+  // constructors\n+  IntermediateMethod() {};\n+\n+  explicit IntermediateMethod(torch::MethodDef* method_def);\n+\n+  IntermediateMethod(const IntermediateMethod& method) = delete;\n+  IntermediateMethod& operator =(const IntermediateMethod& method) = delete;\n+\n+  IntermediateMethod(IntermediateMethod&& method) = default;\n+  IntermediateMethod& operator =(IntermediateMethod&& method) = default;\n+\n+  // dump data to MethodDef, called in serialize\n+  void dump(torch::MethodDef* method_def);\n+\n+  // getters\n+  const std::string& name() const {\n+    return name_;\n+  }\n+\n+  const std::string& torchScript() const {\n+    return torchScript_;\n+  }\n+\n+  // setters\n+  void setName(const std::string& name) {\n+    name_ = name;\n+  }\n+\n+  void setTorchScript(const std::string& torch_script) {\n+    torchScript_ = torch_script;\n+  }\n+\n+ private:\n+  std::string name_;\n+  //std::unique_ptr<caffe2::NetDef> graph_;", "path": "caffe2/serialize/intermediate_model.h", "position": null, "original_position": 237, "commit_id": "53180b449481169c2c2ff9e23ac18289412c62b3", "original_commit_id": "b8874b41223cb9d6aa361646d3b42dc5ecbdead2", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "why did you remove the NetDef? since it's forward declared it should be fine", "created_at": "2018-11-07T03:55:30Z", "updated_at": "2018-11-23T15:54:26Z", "html_url": "https://github.com/pytorch/pytorch/pull/13020#discussion_r231374045", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13020", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231374045"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13020#discussion_r231374045"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13020"}}, "body_html": "<p>why did you remove the NetDef? since it's forward declared it should be fine</p>", "body_text": "why did you remove the NetDef? since it's forward declared it should be fine"}