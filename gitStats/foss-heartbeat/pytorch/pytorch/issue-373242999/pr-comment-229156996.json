{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/229156996", "pull_request_review_id": 169588672, "id": 229156996, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyOTE1Njk5Ng==", "diff_hunk": "@@ -0,0 +1,600 @@\n+#pragma once\n+\n+#include <unordered_map>\n+#include <stack>\n+#include <string>\n+\n+#include <ATen/core/Allocator.h>\n+\n+#include \"caffe2/core/common.h\"\n+#include \"caffe2/proto/caffe2_pb.h\"\n+#include \"caffe2/proto/torch_pb.h\"\n+#include \"caffe2/serialize/inline_container.h\"\n+\n+namespace at {\n+namespace serialize {\n+\n+// multiple tensor may share the same content\n+// SharedData contains:\n+//    1) record id (i.e., the offset in the inline container)\n+//    2) size, the size of the content\n+//    3) data, in serialize, IntermediateModel does NOT own the data,\n+//       in deserialize, the data pointer is returned by PyTorchFileReader,\n+//       and IntermediateModel owns the data. The ownership later will be\n+//       transferred to Tensor\n+class SharedData {\n+ public:\n+  // constructor\n+  explicit SharedData(uint64_t record_id, at::DataPtr&& data_ptr, uint64_t size)\n+    : recordId_(record_id), dataPtr_(std::move(data_ptr)), size_(size){}\n+\n+  // getters\n+  void* rawData() {\n+    return dataPtr_.get();\n+  }\n+\n+  uint64_t recordId() const {\n+    return recordId_;\n+  }\n+\n+  uint64_t size() const {\n+    return size_;\n+  }\n+\n+  // setters\n+  void setDataPtr(at::DataPtr&& data_ptr) {\n+    dataPtr_ = std::move(data_ptr);\n+  }\n+\n+  void setRecordId(uint64_t record_id) {\n+    recordId_ = record_id;\n+  }\n+\n+  void setSize(uint64_t size) {\n+    size_ = size;\n+  }\n+\n+ private:\n+  uint64_t recordId_;\n+  at::DataPtr dataPtr_;\n+  uint64_t size_;\n+};\n+\n+// IntermediateDeviceOption stores device related information\n+struct IntermediateDeviceOption {\n+  int32_t deviceType = 0;\n+  int32_t deviceId;\n+  bool hasDeviceId = false;\n+};\n+\n+// IntermediateTensor contains\n+//   1) element type information\n+//   2) shape information\n+//   3) pointer to the data (including offset and strides)\n+class IntermediateTensor final {\n+ public:\n+  // constructor\n+  IntermediateTensor() = default;\n+\n+  // extract data from TensorProto, called in deserialize\n+  // assume record id to data mapping is complete\n+  void update(caffe2::TensorProto* tensor_proto,\n+      std::unordered_map<uint64_t, std::shared_ptr<SharedData>>* id_data) {\n+    AT_ASSERTM(tensor_proto->has_data_type(), \"no data_type in TensorProto!\");\n+    dataType_ = tensor_proto->data_type();\n+    for (int i = 0; i < tensor_proto->dims_size(); ++i) {\n+      dims_.push_back(tensor_proto->dims(i));\n+    }\n+    if (tensor_proto->has_name()) {\n+      // TODO: TensorProto's name is not used, we just keep it here for now\n+      // later we will deprecate it.\n+      name_ = tensor_proto->name();\n+    }\n+    if (tensor_proto->has_device_detail()) {\n+      const auto& device_detail = tensor_proto->device_detail();\n+      deviceDetail_.deviceType = device_detail.device_type();\n+      if (device_detail.has_device_id()) {\n+        deviceDetail_.hasDeviceId = true;\n+        deviceDetail_.deviceId = device_detail.device_id();\n+      }\n+      if (device_detail.has_random_seed()) {\n+        AT_ERROR(\"DeviceOption contains random seed, not supported!\");\n+      }\n+      if (device_detail.has_node_name()) {\n+        AT_ERROR(\"DeviceOption contains node name, not supported!\");\n+      }\n+      if (device_detail.extra_info_size() > 0) {\n+        AT_ERROR(\"DeviceOption contains extra info, not supported!\");\n+      }\n+    }\n+    AT_ASSERTM(tensor_proto->has_storage_type(), \"no storage_type in TensorProto!\");\n+    int64_t storage_type = tensor_proto->storage_type();\n+    switch (storage_type) {\n+      case caffe2::TensorProto_StorageType_TYPED:\n+        // TODO\n+        AT_ERROR(\"Storing data in typed field is not suppored yet!\");\n+      case caffe2::TensorProto_StorageType_RAW:\n+        // TODO\n+        AT_ERROR(\"Storing data in raw field is not supported yet!\");\n+      case caffe2::TensorProto_StorageType_EXTERNAL:\n+        {\n+          AT_ASSERTM(tensor_proto->has_external_data(), \"storage type is EXTERNAL, \"\n+              \"but no external_data in TensorProto!\");\n+          auto& external_data = tensor_proto->external_data();\n+          offset_ = external_data.offset();\n+          for (int i = 0; i < external_data.strides_size(); ++i) {\n+            strides_.push_back(external_data.strides(i));\n+          }\n+          int64_t source_type = external_data.source_type();\n+          if (source_type == caffe2::ExternalDataProto_SourceType_INLINE_CONTAINER) {\n+            AT_ASSERTM(external_data.has_record_id(), \"no record_id in ExternalDataProto and source_type is INLINE_CONTAINER!\");\n+            int64_t record_id = std::stoul(external_data.record_id());\n+            auto it = id_data->find(record_id);\n+            if (it == id_data->end()) {\n+              AT_ERROR(\"Tensor's data is missing in id_data, tensor name is %s, and record_id is %lld\", name_, record_id);\n+            }\n+            data_ = it->second;\n+          } else if (source_type == caffe2::ExternalDataProto_SourceType_SIMPLE_FILE) {\n+            // TODO\n+            AT_ERROR(\"Storing data in separate file is not supported yet!\");\n+          } else {\n+            // TODO\n+            AT_ERROR(\"Unknown source_type: %lld!\", source_type);\n+          }\n+          break;\n+        }\n+      case caffe2::TensorProto_StorageType_NO_CONTENT:\n+        {\n+          noContent_ = true;\n+          break;\n+        }\n+      default:\n+        AT_ERROR(\"Uknown storage_type %lld\", storage_type);", "path": "caffe2/serialize/intermediate_model.h", "position": null, "original_position": 152, "commit_id": "53180b449481169c2c2ff9e23ac18289412c62b3", "original_commit_id": "a01175f558ff676c429944fe0c885483a2a4265c", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "here and everywhere: AT_ERROR is like CAFFE_ENFORCE - it just concats arguments, not doing format strings", "created_at": "2018-10-30T02:17:38Z", "updated_at": "2018-11-23T15:53:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/13020#discussion_r229156996", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13020", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/229156996"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13020#discussion_r229156996"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13020"}}, "body_html": "<p>here and everywhere: AT_ERROR is like CAFFE_ENFORCE - it just concats arguments, not doing format strings</p>", "body_text": "here and everywhere: AT_ERROR is like CAFFE_ENFORCE - it just concats arguments, not doing format strings"}