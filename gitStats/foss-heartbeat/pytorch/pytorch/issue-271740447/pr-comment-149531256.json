{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149531256", "pull_request_review_id": 74940542, "id": 149531256, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0OTUzMTI1Ng==", "diff_hunk": "@@ -1,5 +1,46 @@\n # Defines derivative formulas and Python signatures of methods on Variable\n #\n+# Each entry consists of:\n+#   - A 'name', which specifies the ATen name of the function you\n+#     are defining derivatives for, and a C-style argument\n+#     specification.\n+#   - One or more gradients entries, mapping a differentiable input\n+#     names to a formula specifying how to compute its gradient.\n+#     Note that a single gradient entry can specify the gradient\n+#     formula for multiple input names, by specifying a key\n+#     \"input1, input2\" (see atan2 for an example).\n+#\n+# Gradient expressions are standard C++ expressions operating on ATen\n+# variables.  In a gradient expression, the following variables are in\n+# scope:\n+#   - 'grad' (aka 'grad_output'), the gradient of the output which\n+#     we are going to left-multiply.  When the forward returns multiple\n+#     outputs, 'grad' always refers to the first output\n+#     (TODO: reconsider this); you can refer to other outputs using", "path": "tools/autograd/derivatives.yaml", "position": null, "original_position": 19, "commit_id": "41319909d9558730b1fa8a1af043e14f1ac75acc", "original_commit_id": "e4316fe81b252a3c5ab917eebb77b82735a08759", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Yeah grads is fine. If you use `grad` we check that there is exactly one incoming gradient. (This is the common case). Otherwise, it's up to you to ensure that `grads` is the correct size.", "created_at": "2017-11-07T23:02:50Z", "updated_at": "2018-11-23T15:36:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/3526#discussion_r149531256", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3526", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149531256"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3526#discussion_r149531256"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3526"}}, "body_html": "<p>Yeah grads is fine. If you use <code>grad</code> we check that there is exactly one incoming gradient. (This is the common case). Otherwise, it's up to you to ensure that <code>grads</code> is the correct size.</p>", "body_text": "Yeah grads is fine. If you use grad we check that there is exactly one incoming gradient. (This is the common case). Otherwise, it's up to you to ensure that grads is the correct size."}