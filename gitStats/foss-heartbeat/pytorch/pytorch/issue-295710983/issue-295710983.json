{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5146", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5146/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5146/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5146/events", "html_url": "https://github.com/pytorch/pytorch/issues/5146", "id": 295710983, "node_id": "MDU6SXNzdWUyOTU3MTA5ODM=", "number": 5146, "title": "ONNX export of Pytorch models is buggy.", "user": {"login": "anirudhacharya", "id": 2778341, "node_id": "MDQ6VXNlcjI3NzgzNDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/2778341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anirudhacharya", "html_url": "https://github.com/anirudhacharya", "followers_url": "https://api.github.com/users/anirudhacharya/followers", "following_url": "https://api.github.com/users/anirudhacharya/following{/other_user}", "gists_url": "https://api.github.com/users/anirudhacharya/gists{/gist_id}", "starred_url": "https://api.github.com/users/anirudhacharya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anirudhacharya/subscriptions", "organizations_url": "https://api.github.com/users/anirudhacharya/orgs", "repos_url": "https://api.github.com/users/anirudhacharya/repos", "events_url": "https://api.github.com/users/anirudhacharya/events{/privacy}", "received_events_url": "https://api.github.com/users/anirudhacharya/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-09T00:11:06Z", "updated_at": "2018-10-30T06:46:11Z", "closed_at": "2018-02-09T04:18:36Z", "author_association": "NONE", "body_html": "<p>While exporting pytorch models to ONNX format using torch_onnx.export, sometimes it generates the wrong serialized file. The generated onnx file cannot be imported into any of the other frameworks like caffe2 or mxnet. When I try to import it, I get the following error message -</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \"alon.py\", line 33, in<br>\nprepared_backend = onnx_caffe2.backend.prepare(model)<br>\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx_caffe2/backend.py\", line 439, in prepare<br>\nsuper(Caffe2Backend, cls).prepare(model, device, **kwargs)<br>\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/backend/base.py\", line 53, in prepare<br>\nonnx.checker.check_model(model)<br>\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 154, in check_model<br>\ncheck_graph(model.graph)<br>\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 127, in check_graph<br>\ncheck_node(node)<br>\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 40, in check_node<br>\n'NodeProto of type {} did not pass defs schema check.'.format(str(node.op_type)))<br>\nValueError: NodeProto of type ReduceMean did not pass defs schema<br>\ncheck.</p>\n</blockquote>\n<p>Even when I try to run  the onnx model checker on the generated model, I get the following errors -</p>\n<div class=\"highlight highlight-source-shell\"><pre>import onnx\nmodel = onnx.load(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>toy_model.onnx<span class=\"pl-pds\">\"</span></span>)\nonnx.checker.check_model(model)\n\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line 1, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx-1.0.1-py2.7-macosx-10.9-x86_64.egg/onnx/checker.py<span class=\"pl-pds\">\"</span></span>, line 77, <span class=\"pl-k\">in</span> check_model\n    <span class=\"pl-en\">C.check_model(model.SerializeToString</span>())\nonnx.onnx_cpp2py_export.checker.ValidationError: Attribute <span class=\"pl-s\"><span class=\"pl-pds\">'</span>axes<span class=\"pl-pds\">'</span></span> is expected to have field <span class=\"pl-s\"><span class=\"pl-pds\">'</span>ints<span class=\"pl-pds\">'</span></span>\n\n==&gt; Context: Bad node spec: input: \"5\" output: \"6\" op_type: \"ReduceMean\" attribute { name: \"axes\" i: 2 type: INT } attribute { name: \"keepdims\" i: 0 type: INT } doc_string: \"alon.py(18): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(236): traced_inner\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(259): wrapper\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(241): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(217): trace\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(116): _export\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(75): export\\nalon.py(27): &lt;module&gt;\\n\"</pre></div>\n<p>Installation Details</p>\n<ul>\n<li>OS: MacOS Sierra</li>\n<li>PyTorch version:</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>conda list <span class=\"pl-k\">|</span> grep torch\npytorch                   0.3.0           py27_cuda0.0_cudnn0.0he480db7_4    pytorch\ntorchvision               0.2.0            py27hfc0307a_1    pytorch</pre></div>\n<ul>\n<li>How you installed PyTorch (conda, pip, source): conda</li>\n<li>Python version: 2.7</li>\n</ul>\n<p>Following is the code that creates the model</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">import</span> torch.nn.functional <span class=\"pl-k\">as</span> F\n<span class=\"pl-k\">import</span> torch.optim <span class=\"pl-k\">as</span> optim\n<span class=\"pl-k\">from</span> torchvision <span class=\"pl-k\">import</span> datasets, transforms\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch.onnx <span class=\"pl-k\">as</span> torch_onnx\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(Model, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.conv <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>), <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>):\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv(inputs)\n        x <span class=\"pl-k\">=</span> x.view(x.size()[<span class=\"pl-c1\">0</span>], x.size()[<span class=\"pl-c1\">1</span>], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-k\">return</span> torch.mean(x, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n\ninput_shape <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>)\nmodel_onnx_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>toy_model.onnx<span class=\"pl-pds\">\"</span></span>\nmodel <span class=\"pl-k\">=</span> Model()\nmodel.train(<span class=\"pl-c1\">False</span>)\n\ndummy_input <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">*</span>input_shape))\ntorch_onnx.export(model, \n                  dummy_input, \n                  model_onnx_path, \n                  <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>Code that tries to import it into mxnet/caffe -</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> onnx\n<span class=\"pl-k\">import</span> onnx_caffe2.backend\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Load the ONNX ModelProto object. model is a standard Python protobuf object</span>\nmodel <span class=\"pl-k\">=</span> onnx.load(model_onnx_path)\nprepared_backend <span class=\"pl-k\">=</span> onnx_caffe2.backend.prepare(model)</pre></div>\n<p>and</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> onnx_mxnet, mxnet\nsym, params <span class=\"pl-k\">=</span> onnx_mxnet.import_model(model_onnx_path)</pre></div>\n<p>I think this a bug with Pytorch's export to ONNX functionality, do acknowledge if you think the same.</p>", "body_text": "While exporting pytorch models to ONNX format using torch_onnx.export, sometimes it generates the wrong serialized file. The generated onnx file cannot be imported into any of the other frameworks like caffe2 or mxnet. When I try to import it, I get the following error message -\n\nTraceback (most recent call last):\nFile \"alon.py\", line 33, in\nprepared_backend = onnx_caffe2.backend.prepare(model)\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx_caffe2/backend.py\", line 439, in prepare\nsuper(Caffe2Backend, cls).prepare(model, device, **kwargs)\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/backend/base.py\", line 53, in prepare\nonnx.checker.check_model(model)\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 154, in check_model\ncheck_graph(model.graph)\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 127, in check_graph\ncheck_node(node)\nFile \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 40, in check_node\n'NodeProto of type {} did not pass defs schema check.'.format(str(node.op_type)))\nValueError: NodeProto of type ReduceMean did not pass defs schema\ncheck.\n\nEven when I try to run  the onnx model checker on the generated model, I get the following errors -\nimport onnx\nmodel = onnx.load(\"toy_model.onnx\")\nonnx.checker.check_model(model)\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx-1.0.1-py2.7-macosx-10.9-x86_64.egg/onnx/checker.py\", line 77, in check_model\n    C.check_model(model.SerializeToString())\nonnx.onnx_cpp2py_export.checker.ValidationError: Attribute 'axes' is expected to have field 'ints'\n\n==> Context: Bad node spec: input: \"5\" output: \"6\" op_type: \"ReduceMean\" attribute { name: \"axes\" i: 2 type: INT } attribute { name: \"keepdims\" i: 0 type: INT } doc_string: \"alon.py(18): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(236): traced_inner\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(259): wrapper\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(241): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(217): trace\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(116): _export\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(75): export\\nalon.py(27): <module>\\n\"\nInstallation Details\n\nOS: MacOS Sierra\nPyTorch version:\n\nconda list | grep torch\npytorch                   0.3.0           py27_cuda0.0_cudnn0.0he480db7_4    pytorch\ntorchvision               0.2.0            py27hfc0307a_1    pytorch\n\nHow you installed PyTorch (conda, pip, source): conda\nPython version: 2.7\n\nFollowing is the code that creates the model\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport torch.onnx as torch_onnx\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=1, padding=0, bias=False)\n\n    def forward(self, inputs):\n        x = self.conv(inputs)\n        x = x.view(x.size()[0], x.size()[1], -1)\n        return torch.mean(x, dim=2)\n\ninput_shape = (3, 100, 100)\nmodel_onnx_path = \"toy_model.onnx\"\nmodel = Model()\nmodel.train(False)\n\ndummy_input = Variable(torch.randn(1, *input_shape))\ntorch_onnx.export(model, \n                  dummy_input, \n                  model_onnx_path, \n                  verbose=True)\nCode that tries to import it into mxnet/caffe -\nimport onnx\nimport onnx_caffe2.backend\n# Load the ONNX ModelProto object. model is a standard Python protobuf object\nmodel = onnx.load(model_onnx_path)\nprepared_backend = onnx_caffe2.backend.prepare(model)\nand\nimport onnx_mxnet, mxnet\nsym, params = onnx_mxnet.import_model(model_onnx_path)\nI think this a bug with Pytorch's export to ONNX functionality, do acknowledge if you think the same.", "body": "While exporting pytorch models to ONNX format using torch_onnx.export, sometimes it generates the wrong serialized file. The generated onnx file cannot be imported into any of the other frameworks like caffe2 or mxnet. When I try to import it, I get the following error message -\r\n\r\n> Traceback (most recent call last):\r\n> File \"alon.py\", line 33, in \r\n> prepared_backend = onnx_caffe2.backend.prepare(model)\r\n> File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx_caffe2/backend.py\", line 439, in prepare\r\n> super(Caffe2Backend, cls).prepare(model, device, **kwargs)\r\n> File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/backend/base.py\", line 53, in prepare\r\n> onnx.checker.check_model(model)\r\n> File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 154, in check_model\r\n> check_graph(model.graph)\r\n> File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 127, in check_graph\r\n> check_node(node)\r\n> File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx/checker.py\", line 40, in check_node\r\n> 'NodeProto of type {} did not pass defs schema check.'.format(str(node.op_type)))\r\n> ValueError: NodeProto of type ReduceMean did not pass defs schema\r\n> check.\r\n\r\nEven when I try to run  the onnx model checker on the generated model, I get the following errors -\r\n```bash\r\nimport onnx\r\nmodel = onnx.load(\"toy_model.onnx\")\r\nonnx.checker.check_model(model)\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/onnx-1.0.1-py2.7-macosx-10.9-x86_64.egg/onnx/checker.py\", line 77, in check_model\r\n    C.check_model(model.SerializeToString())\r\nonnx.onnx_cpp2py_export.checker.ValidationError: Attribute 'axes' is expected to have field 'ints'\r\n\r\n==> Context: Bad node spec: input: \"5\" output: \"6\" op_type: \"ReduceMean\" attribute { name: \"axes\" i: 2 type: INT } attribute { name: \"keepdims\" i: 0 type: INT } doc_string: \"alon.py(18): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(236): traced_inner\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(259): wrapper\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(241): forward\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/nn/modules/module.py(325): __call__\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/jit/__init__.py(217): trace\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(116): _export\\n/Users/aanirud/anaconda2/envs/onnx/lib/python2.7/site-packages/torch/onnx/__init__.py(75): export\\nalon.py(27): <module>\\n\"\r\n```\r\nInstallation Details\r\n- OS: MacOS Sierra\r\n- PyTorch version: \r\n```bash\r\nconda list | grep torch\r\npytorch                   0.3.0           py27_cuda0.0_cudnn0.0he480db7_4    pytorch\r\ntorchvision               0.2.0            py27hfc0307a_1    pytorch\r\n```\r\n- How you installed PyTorch (conda, pip, source): conda\r\n- Python version: 2.7\r\n\r\nFollowing is the code that creates the model\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nfrom torchvision import datasets, transforms\r\nfrom torch.autograd import Variable\r\nimport torch.onnx as torch_onnx\r\n\r\nclass Model(nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=1, padding=0, bias=False)\r\n\r\n    def forward(self, inputs):\r\n        x = self.conv(inputs)\r\n        x = x.view(x.size()[0], x.size()[1], -1)\r\n        return torch.mean(x, dim=2)\r\n\r\ninput_shape = (3, 100, 100)\r\nmodel_onnx_path = \"toy_model.onnx\"\r\nmodel = Model()\r\nmodel.train(False)\r\n\r\ndummy_input = Variable(torch.randn(1, *input_shape))\r\ntorch_onnx.export(model, \r\n                  dummy_input, \r\n                  model_onnx_path, \r\n                  verbose=True)\r\n```\r\n\r\nCode that tries to import it into mxnet/caffe -\r\n```python\r\nimport onnx\r\nimport onnx_caffe2.backend\r\n# Load the ONNX ModelProto object. model is a standard Python protobuf object\r\nmodel = onnx.load(model_onnx_path)\r\nprepared_backend = onnx_caffe2.backend.prepare(model)\r\n```\r\nand\r\n```python\r\nimport onnx_mxnet, mxnet\r\nsym, params = onnx_mxnet.import_model(model_onnx_path)\r\n```\r\nI think this a bug with Pytorch's export to ONNX functionality, do acknowledge if you think the same."}