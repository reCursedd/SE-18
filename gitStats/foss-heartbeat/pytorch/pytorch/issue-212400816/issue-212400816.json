{"url": "https://api.github.com/repos/pytorch/pytorch/issues/950", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/950/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/950/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/950/events", "html_url": "https://github.com/pytorch/pytorch/issues/950", "id": 212400816, "node_id": "MDU6SXNzdWUyMTI0MDA4MTY=", "number": 950, "title": "In-place sub with shared memory, wrong result", "user": {"login": "bermanmaxim", "id": 5989894, "node_id": "MDQ6VXNlcjU5ODk4OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/5989894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bermanmaxim", "html_url": "https://github.com/bermanmaxim", "followers_url": "https://api.github.com/users/bermanmaxim/followers", "following_url": "https://api.github.com/users/bermanmaxim/following{/other_user}", "gists_url": "https://api.github.com/users/bermanmaxim/gists{/gist_id}", "starred_url": "https://api.github.com/users/bermanmaxim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bermanmaxim/subscriptions", "organizations_url": "https://api.github.com/users/bermanmaxim/orgs", "repos_url": "https://api.github.com/users/bermanmaxim/repos", "events_url": "https://api.github.com/users/bermanmaxim/events{/privacy}", "received_events_url": "https://api.github.com/users/bermanmaxim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-07T11:09:47Z", "updated_at": "2017-03-07T14:19:26Z", "closed_at": "2017-03-07T14:19:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi, I ran into this non-intuitive behavior:</p>\n<pre><code>test = torch.Tensor([1, 2, 3, 4, 5])\ntest[1:] -= test[:-1]\n</code></pre>\n<p>results in <code>test = [1, 1, 1, 1, 4]</code> for me, while the non in-place version <code>test[1:] = test[1:] - test[:-1]</code> returns the correct result <code>[1, 1, 1, 1, 1]</code>. If I put the tensor to cuda() first the output seems correct...<br>\n(pytorch compiled from master '0.1.9+aaf41c6')</p>", "body_text": "Hi, I ran into this non-intuitive behavior:\ntest = torch.Tensor([1, 2, 3, 4, 5])\ntest[1:] -= test[:-1]\n\nresults in test = [1, 1, 1, 1, 4] for me, while the non in-place version test[1:] = test[1:] - test[:-1] returns the correct result [1, 1, 1, 1, 1]. If I put the tensor to cuda() first the output seems correct...\n(pytorch compiled from master '0.1.9+aaf41c6')", "body": "Hi, I ran into this non-intuitive behavior:\r\n```\r\ntest = torch.Tensor([1, 2, 3, 4, 5])\r\ntest[1:] -= test[:-1]\r\n```\r\nresults in `test = [1, 1, 1, 1, 4]` for me, while the non in-place version `test[1:] = test[1:] - test[:-1]` returns the correct result `[1, 1, 1, 1, 1]`. If I put the tensor to cuda() first the output seems correct...\r\n(pytorch compiled from master '0.1.9+aaf41c6')\r\n"}