{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/419338551", "html_url": "https://github.com/pytorch/pytorch/issues/842#issuecomment-419338551", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/842", "id": 419338551, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTMzODU1MQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T06:38:24Z", "updated_at": "2018-09-07T06:38:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=38509346\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/weiyangfb\">@weiyangfb</a> You are comparing apples and oranges here. BCELoss should be compared with CrossEntropyLoss instead. Futhermore, if we change the behavior, we should relax the constraint, rather than tighten it. So I'm going to make this proposal here:</p>\n<ol>\n<li>Make BCELoss accept both floating point and int64 target. (What this issue asks about.)</li>\n<li>Also make CrossEntropyLoss accept floating point target, i.e., a soft distribution. This is very useful and people have been asking for it for a couple times.</li>\n</ol>\n<p>Neither should be hard though, given that now we have ATen native functions :)</p>", "body_text": "@weiyangfb You are comparing apples and oranges here. BCELoss should be compared with CrossEntropyLoss instead. Futhermore, if we change the behavior, we should relax the constraint, rather than tighten it. So I'm going to make this proposal here:\n\nMake BCELoss accept both floating point and int64 target. (What this issue asks about.)\nAlso make CrossEntropyLoss accept floating point target, i.e., a soft distribution. This is very useful and people have been asking for it for a couple times.\n\nNeither should be hard though, given that now we have ATen native functions :)", "body": "@weiyangfb You are comparing apples and oranges here. BCELoss should be compared with CrossEntropyLoss instead. Futhermore, if we change the behavior, we should relax the constraint, rather than tighten it. So I'm going to make this proposal here:\r\n1. Make BCELoss accept both floating point and int64 target. (What this issue asks about.)\r\n2. Also make CrossEntropyLoss accept floating point target, i.e., a soft distribution. This is very useful and people have been asking for it for a couple times.\r\n\r\nNeither should be hard though, given that now we have ATen native functions :) "}