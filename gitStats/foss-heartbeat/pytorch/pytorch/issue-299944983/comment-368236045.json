{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368236045", "html_url": "https://github.com/pytorch/pytorch/issues/5398#issuecomment-368236045", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5398", "id": 368236045, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODIzNjA0NQ==", "user": {"login": "sampathweb", "id": 1437573, "node_id": "MDQ6VXNlcjE0Mzc1NzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1437573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sampathweb", "html_url": "https://github.com/sampathweb", "followers_url": "https://api.github.com/users/sampathweb/followers", "following_url": "https://api.github.com/users/sampathweb/following{/other_user}", "gists_url": "https://api.github.com/users/sampathweb/gists{/gist_id}", "starred_url": "https://api.github.com/users/sampathweb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sampathweb/subscriptions", "organizations_url": "https://api.github.com/users/sampathweb/orgs", "repos_url": "https://api.github.com/users/sampathweb/repos", "events_url": "https://api.github.com/users/sampathweb/events{/privacy}", "received_events_url": "https://api.github.com/users/sampathweb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-24T15:29:37Z", "updated_at": "2018-02-24T15:30:35Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21106717\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/abhaikollara\">@abhaikollara</a> - Interesting.  Possibly because when you do <code>self.y[idx]</code>, you get a Scalar value (indexing on a 1-D Tensor) of type int and not an torch.cuda tensor you get for <code>self.x[idx]</code> being a 2-D Tensor.</p>\n<pre><code>&gt;&gt;&gt; print(type(self.y[idx]), type(self.x[idx]))`\n&lt;class 'int'&gt; &lt;class 'torch.cuda.FloatTensor'&gt;\n</code></pre>\n<p>Alternatively, during the training loop, you might want to put X and y in cuda while wrapping it in a variable like most pyTorch code examples.  Hope this is useful</p>", "body_text": "@abhaikollara - Interesting.  Possibly because when you do self.y[idx], you get a Scalar value (indexing on a 1-D Tensor) of type int and not an torch.cuda tensor you get for self.x[idx] being a 2-D Tensor.\n>>> print(type(self.y[idx]), type(self.x[idx]))`\n<class 'int'> <class 'torch.cuda.FloatTensor'>\n\nAlternatively, during the training loop, you might want to put X and y in cuda while wrapping it in a variable like most pyTorch code examples.  Hope this is useful", "body": "@abhaikollara - Interesting.  Possibly because when you do `self.y[idx]`, you get a Scalar value (indexing on a 1-D Tensor) of type int and not an torch.cuda tensor you get for `self.x[idx]` being a 2-D Tensor.\r\n```\r\n>>> print(type(self.y[idx]), type(self.x[idx]))`\r\n<class 'int'> <class 'torch.cuda.FloatTensor'>\r\n```\r\nAlternatively, during the training loop, you might want to put X and y in cuda while wrapping it in a variable like most pyTorch code examples.  Hope this is useful"}