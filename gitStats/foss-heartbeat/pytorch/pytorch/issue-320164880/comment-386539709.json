{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386539709", "html_url": "https://github.com/pytorch/pytorch/issues/7277#issuecomment-386539709", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7277", "id": 386539709, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjUzOTcwOQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-04T08:44:40Z", "updated_at": "2018-05-04T08:44:40Z", "author_association": "MEMBER", "body_html": "<p>I think if we specify the device explicitly, it should perform the move to the device. If no device is passed in the argument, then it should take the device of the tensor that was passed.</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">3</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> what should be the device here?</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> I'd say on the gpu</span>\nb <span class=\"pl-k\">=</span> torch.tensor(a)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> but this should be on the cpu</span>\nc <span class=\"pl-k\">=</span> torch.tensor(a, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cpu<span class=\"pl-pds\">'</span></span>)</pre></div>", "body_text": "I think if we specify the device explicitly, it should perform the move to the device. If no device is passed in the argument, then it should take the device of the tensor that was passed.\na = torch.rand(3, device='cuda')\n\n# what should be the device here?\n# I'd say on the gpu\nb = torch.tensor(a)\n\n# but this should be on the cpu\nc = torch.tensor(a, device='cpu')", "body": "I think if we specify the device explicitly, it should perform the move to the device. If no device is passed in the argument, then it should take the device of the tensor that was passed.\r\n\r\n```python\r\na = torch.rand(3, device='cuda')\r\n\r\n# what should be the device here?\r\n# I'd say on the gpu\r\nb = torch.tensor(a)\r\n\r\n# but this should be on the cpu\r\nc = torch.tensor(a, device='cpu')\r\n```"}