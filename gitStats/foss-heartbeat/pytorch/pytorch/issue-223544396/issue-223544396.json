{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1329", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1329/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1329/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1329/events", "html_url": "https://github.com/pytorch/pytorch/issues/1329", "id": 223544396, "node_id": "MDU6SXNzdWUyMjM1NDQzOTY=", "number": 1329, "title": "[proposed feature] Eve: Improving Stochastic Gradient Descent with Feedback", "user": {"login": "snowyday", "id": 1930625, "node_id": "MDQ6VXNlcjE5MzA2MjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1930625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/snowyday", "html_url": "https://github.com/snowyday", "followers_url": "https://api.github.com/users/snowyday/followers", "following_url": "https://api.github.com/users/snowyday/following{/other_user}", "gists_url": "https://api.github.com/users/snowyday/gists{/gist_id}", "starred_url": "https://api.github.com/users/snowyday/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/snowyday/subscriptions", "organizations_url": "https://api.github.com/users/snowyday/orgs", "repos_url": "https://api.github.com/users/snowyday/repos", "events_url": "https://api.github.com/users/snowyday/events{/privacy}", "received_events_url": "https://api.github.com/users/snowyday/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-22T06:32:24Z", "updated_at": "2017-04-30T05:04:23Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi all,</p>\n<p>I implemented a paper \"Improving Stochastic Gradient Descent with Feedback\" as called <a href=\"https://arxiv.org/abs/1611.01505\" rel=\"nofollow\">Eve</a>.<br>\nEve is a modified version of Adam, and outperforms other SGD algorithms on some benchmark tasks including image classification.<br>\nPlease, give me any advice and code review.</p>\n<p>The code is uploaded in this <a href=\"https://gist.github.com/snowyday/19b959b268d3af7785b2dd0e2f37f6bb\">gist</a>, and below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> math\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> from .optimizer import Optimizer</span>\n<span class=\"pl-k\">from</span> torch.optim <span class=\"pl-k\">import</span> Optimizer\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Eve</span>(<span class=\"pl-e\">Optimizer</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Implements Eve (Adam with feedback) algorithm.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    It has been proposed in `Improving Stochastic Gradient Descent with Feedback, `_.</span>\n<span class=\"pl-s\">    </span>\n<span class=\"pl-s\">    Arguments:</span>\n<span class=\"pl-s\">        params (iterable): iterable of parameters to optimize or dicts defining</span>\n<span class=\"pl-s\">            parameter groups</span>\n<span class=\"pl-s\">        lr (float, optional): learning rate (default: 1e-2)</span>\n<span class=\"pl-s\">        betas (Tuple[float, float, float], optional): coefficients used for computing</span>\n<span class=\"pl-s\">            running averages of gradient and its square (default: (0.9, 0.999, 0.999))</span>\n<span class=\"pl-s\">        thr ((Tuple[float, float], optional): lower and upper threshold for relative change </span>\n<span class=\"pl-s\">            (default: (0.1, 10))</span>\n<span class=\"pl-s\">        eps (float, optional): term added to the denominator to improve</span>\n<span class=\"pl-s\">            numerical stability (default: 1e-8)</span>\n<span class=\"pl-s\">        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">    .. _Eve\\: Improving Stochastic Gradient Descent with Feedback</span>\n<span class=\"pl-s\">        https://arxiv.org/abs/1611.01505</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">params</span>, <span class=\"pl-smi\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-2</span>, <span class=\"pl-smi\">betas</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">0.9</span>, <span class=\"pl-c1\">0.999</span>, <span class=\"pl-c1\">0.999</span>), <span class=\"pl-smi\">eps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1e-8</span>, <span class=\"pl-smi\">thr</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">0.1</span>, <span class=\"pl-c1\">10</span>), <span class=\"pl-smi\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>):\n        defaults <span class=\"pl-k\">=</span> <span class=\"pl-c1\">dict</span>(<span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span>lr, <span class=\"pl-v\">betas</span><span class=\"pl-k\">=</span>betas, <span class=\"pl-v\">eps</span><span class=\"pl-k\">=</span>eps, <span class=\"pl-v\">thr</span><span class=\"pl-k\">=</span>thr, <span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span>weight_decay)\n        <span class=\"pl-c1\">super</span>(Eve, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>(params, defaults)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">step</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">closure</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Performs a single optimization step.</span>\n<span class=\"pl-s\">        </span>\n<span class=\"pl-s\">        Arguments:</span>\n<span class=\"pl-s\">            closure (callable, optional): A closure that reevaluates the model</span>\n<span class=\"pl-s\">                and returns the loss.</span>\n<span class=\"pl-s\">        <span class=\"pl-pds\">\"\"\"</span></span>\n\n        <span class=\"pl-k\">if</span> closure <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n            loss <span class=\"pl-k\">=</span> closure()\n            loss_val <span class=\"pl-k\">=</span> loss.data[<span class=\"pl-c1\">0</span>]\n        <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Eve requires a value of the loss function.<span class=\"pl-pds\">\"</span></span>)\n\n        <span class=\"pl-k\">for</span> group <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>.param_groups:\n            <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>params<span class=\"pl-pds\">'</span></span>]:\n\n                grad <span class=\"pl-k\">=</span> p.grad.data\n                state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state[<span class=\"pl-c1\">id</span>(p)]\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> State initialization</span>\n                <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(state) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>step<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Exponential moving average of gradient values</span>\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>exp_avg<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> grad.new().resize_as_(grad).zero_()\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Exponential moving average of squared gradient values</span>\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>exp_avg_sq<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> grad.new().resize_as_(grad).zero_()\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Previous loss value</span>\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss_hat_prev<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> loss_val\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Feed-back from the loss function</span>\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay_rate<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n\n                exp_avg, exp_avg_sq <span class=\"pl-k\">=</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>exp_avg<span class=\"pl-pds\">'</span></span>], state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>exp_avg_sq<span class=\"pl-pds\">'</span></span>]\n                beta1, beta2, beta3 <span class=\"pl-k\">=</span> group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>betas<span class=\"pl-pds\">'</span></span>]\n                thl, thu <span class=\"pl-k\">=</span> group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>thr<span class=\"pl-pds\">'</span></span>]\n                loss_hat_prev <span class=\"pl-k\">=</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss_hat_prev<span class=\"pl-pds\">'</span></span>]\n\n                state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>step<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n\n                <span class=\"pl-k\">if</span> group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_decay<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">0</span>:\n                    grad <span class=\"pl-k\">=</span> grad.add(group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_decay<span class=\"pl-pds\">'</span></span>], p.data)\n\n                <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decay the first and second moment running average coefficient</span>\n                exp_avg.mul_(beta1).add_(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> beta2, grad, grad)\n\n                bias_correction1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> beta1 <span class=\"pl-k\">**</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>step<span class=\"pl-pds\">'</span></span>]\n                bias_correction2 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> beta2 <span class=\"pl-k\">**</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>step<span class=\"pl-pds\">'</span></span>]\n                step_size <span class=\"pl-k\">=</span> group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lr<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">*</span> math.sqrt(bias_correction2) <span class=\"pl-k\">/</span> bias_correction1\n\n                <span class=\"pl-k\">if</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>step<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span>:\n                    <span class=\"pl-k\">if</span> loss_val <span class=\"pl-k\">&gt;=</span> loss_hat_prev:\n                        lower_bound <span class=\"pl-k\">=</span> thl <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n                        upper_bound <span class=\"pl-k\">=</span> thu <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>\n                    <span class=\"pl-k\">else</span>:\n                        lower_bound <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">/</span> (thu <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)\n                        upper_bound <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">/</span> (thl <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)\n\n                    clip <span class=\"pl-k\">=</span> <span class=\"pl-c1\">min</span>(<span class=\"pl-c1\">max</span>(lower_bound, loss_val <span class=\"pl-k\">/</span> loss_hat_prev), upper_bound)\n                    loss_hat <span class=\"pl-k\">=</span> clip <span class=\"pl-k\">*</span> loss_hat_prev\n                    relative_change <span class=\"pl-k\">=</span> <span class=\"pl-c1\">abs</span>(loss_hat <span class=\"pl-k\">-</span> loss_hat_prev) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">min</span>(loss_hat, loss_hat_prev)\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay_rate<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> beta3 <span class=\"pl-k\">*</span> state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay_rate<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> beta3) <span class=\"pl-k\">*</span> relative_change\n                    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss_hat_prev<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> loss_hat\n\n                denom <span class=\"pl-k\">=</span> exp_avg_sq.sqrt().mul_(state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>decay_rate<span class=\"pl-pds\">'</span></span>]).add_(group[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>eps<span class=\"pl-pds\">'</span></span>])\n\n                p.data.addcdiv_(<span class=\"pl-k\">-</span>step_size, exp_avg, denom)\n\n        <span class=\"pl-k\">return</span> loss</pre></div>", "body_text": "Hi all,\nI implemented a paper \"Improving Stochastic Gradient Descent with Feedback\" as called Eve.\nEve is a modified version of Adam, and outperforms other SGD algorithms on some benchmark tasks including image classification.\nPlease, give me any advice and code review.\nThe code is uploaded in this gist, and below:\nimport math\n# from .optimizer import Optimizer\nfrom torch.optim import Optimizer\n\n\nclass Eve(Optimizer):\n    \"\"\"Implements Eve (Adam with feedback) algorithm.\n    \n    It has been proposed in `Improving Stochastic Gradient Descent with Feedback, `_.\n    \n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-2)\n        betas (Tuple[float, float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999, 0.999))\n        thr ((Tuple[float, float], optional): lower and upper threshold for relative change \n            (default: (0.1, 10))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        \n    .. _Eve\\: Improving Stochastic Gradient Descent with Feedback\n        https://arxiv.org/abs/1611.01505\n    \"\"\"\n\n    def __init__(self, params, lr=1e-2, betas=(0.9, 0.999, 0.999), eps=1e-8, thr=(0.1, 10), weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps, thr=thr, weight_decay=weight_decay)\n        super(Eve, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n        \n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n\n        if closure is not None:\n            loss = closure()\n            loss_val = loss.data[0]\n        else:\n            raise ValueError(\"Eve requires a value of the loss function.\")\n\n        for group in self.param_groups:\n            for p in group['params']:\n\n                grad = p.grad.data\n                state = self.state[id(p)]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = grad.new().resize_as_(grad).zero_()\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = grad.new().resize_as_(grad).zero_()\n                    # Previous loss value\n                    state['loss_hat_prev'] = loss_val\n                    # Feed-back from the loss function\n                    state['decay_rate'] = 1\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2, beta3 = group['betas']\n                thl, thu = group['thr']\n                loss_hat_prev = state['loss_hat_prev']\n\n                state['step'] += 1\n\n                if group['weight_decay'] != 0:\n                    grad = grad.add(group['weight_decay'], p.data)\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n\n                if state['step'] > 1:\n                    if loss_val >= loss_hat_prev:\n                        lower_bound = thl + 1\n                        upper_bound = thu + 1\n                    else:\n                        lower_bound = 1 / (thu + 1)\n                        upper_bound = 1 / (thl + 1)\n\n                    clip = min(max(lower_bound, loss_val / loss_hat_prev), upper_bound)\n                    loss_hat = clip * loss_hat_prev\n                    relative_change = abs(loss_hat - loss_hat_prev) / min(loss_hat, loss_hat_prev)\n                    state['decay_rate'] = beta3 * state['decay_rate'] + (1 - beta3) * relative_change\n                    state['loss_hat_prev'] = loss_hat\n\n                denom = exp_avg_sq.sqrt().mul_(state['decay_rate']).add_(group['eps'])\n\n                p.data.addcdiv_(-step_size, exp_avg, denom)\n\n        return loss", "body": "Hi all,\r\n\r\nI implemented a paper \"Improving Stochastic Gradient Descent with Feedback\" as called [Eve](https://arxiv.org/abs/1611.01505).\r\nEve is a modified version of Adam, and outperforms other SGD algorithms on some benchmark tasks including image classification.\r\nPlease, give me any advice and code review.\r\n\r\nThe code is uploaded in this [gist](https://gist.github.com/snowyday/19b959b268d3af7785b2dd0e2f37f6bb), and below:\r\n```python\r\nimport math\r\n# from .optimizer import Optimizer\r\nfrom torch.optim import Optimizer\r\n\r\n\r\nclass Eve(Optimizer):\r\n    \"\"\"Implements Eve (Adam with feedback) algorithm.\r\n    \r\n    It has been proposed in `Improving Stochastic Gradient Descent with Feedback, `_.\r\n    \r\n    Arguments:\r\n        params (iterable): iterable of parameters to optimize or dicts defining\r\n            parameter groups\r\n        lr (float, optional): learning rate (default: 1e-2)\r\n        betas (Tuple[float, float, float], optional): coefficients used for computing\r\n            running averages of gradient and its square (default: (0.9, 0.999, 0.999))\r\n        thr ((Tuple[float, float], optional): lower and upper threshold for relative change \r\n            (default: (0.1, 10))\r\n        eps (float, optional): term added to the denominator to improve\r\n            numerical stability (default: 1e-8)\r\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\r\n        \r\n    .. _Eve\\: Improving Stochastic Gradient Descent with Feedback\r\n        https://arxiv.org/abs/1611.01505\r\n    \"\"\"\r\n\r\n    def __init__(self, params, lr=1e-2, betas=(0.9, 0.999, 0.999), eps=1e-8, thr=(0.1, 10), weight_decay=0):\r\n        defaults = dict(lr=lr, betas=betas, eps=eps, thr=thr, weight_decay=weight_decay)\r\n        super(Eve, self).__init__(params, defaults)\r\n\r\n    def step(self, closure=None):\r\n        \"\"\"Performs a single optimization step.\r\n        \r\n        Arguments:\r\n            closure (callable, optional): A closure that reevaluates the model\r\n                and returns the loss.\r\n        \"\"\"\r\n\r\n        if closure is not None:\r\n            loss = closure()\r\n            loss_val = loss.data[0]\r\n        else:\r\n            raise ValueError(\"Eve requires a value of the loss function.\")\r\n\r\n        for group in self.param_groups:\r\n            for p in group['params']:\r\n\r\n                grad = p.grad.data\r\n                state = self.state[id(p)]\r\n\r\n                # State initialization\r\n                if len(state) == 0:\r\n                    state['step'] = 0\r\n                    # Exponential moving average of gradient values\r\n                    state['exp_avg'] = grad.new().resize_as_(grad).zero_()\r\n                    # Exponential moving average of squared gradient values\r\n                    state['exp_avg_sq'] = grad.new().resize_as_(grad).zero_()\r\n                    # Previous loss value\r\n                    state['loss_hat_prev'] = loss_val\r\n                    # Feed-back from the loss function\r\n                    state['decay_rate'] = 1\r\n\r\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\r\n                beta1, beta2, beta3 = group['betas']\r\n                thl, thu = group['thr']\r\n                loss_hat_prev = state['loss_hat_prev']\r\n\r\n                state['step'] += 1\r\n\r\n                if group['weight_decay'] != 0:\r\n                    grad = grad.add(group['weight_decay'], p.data)\r\n\r\n                # Decay the first and second moment running average coefficient\r\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\r\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\r\n\r\n                bias_correction1 = 1 - beta1 ** state['step']\r\n                bias_correction2 = 1 - beta2 ** state['step']\r\n                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\r\n\r\n                if state['step'] > 1:\r\n                    if loss_val >= loss_hat_prev:\r\n                        lower_bound = thl + 1\r\n                        upper_bound = thu + 1\r\n                    else:\r\n                        lower_bound = 1 / (thu + 1)\r\n                        upper_bound = 1 / (thl + 1)\r\n\r\n                    clip = min(max(lower_bound, loss_val / loss_hat_prev), upper_bound)\r\n                    loss_hat = clip * loss_hat_prev\r\n                    relative_change = abs(loss_hat - loss_hat_prev) / min(loss_hat, loss_hat_prev)\r\n                    state['decay_rate'] = beta3 * state['decay_rate'] + (1 - beta3) * relative_change\r\n                    state['loss_hat_prev'] = loss_hat\r\n\r\n                denom = exp_avg_sq.sqrt().mul_(state['decay_rate']).add_(group['eps'])\r\n\r\n                p.data.addcdiv_(-step_size, exp_avg, denom)\r\n\r\n        return loss\r\n```"}