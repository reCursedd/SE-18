{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/376391679", "html_url": "https://github.com/pytorch/pytorch/pull/6026#issuecomment-376391679", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6026", "id": 376391679, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NjM5MTY3OQ==", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-27T04:15:13Z", "updated_at": "2018-03-27T13:58:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Generally the dispatch code looks more compact, which is nice. But, I think we might to revisit it again in the future. Having the ability to pass a table or function for non-standard cases is definitely good, but we might need to add support for a wider range of objects, such as templated functions (I'm not sure this supports that).</p>\n<p>All calls to tbb will need to be prefaced by a call to the init_tbb_num_threads function as otherwise the scheduler will be initialized with the wrong number of threads. Maybe we should setup tbb so that this is required by making it unavailable anywhere outside of Parallel.h/.cpp and therefore force all devs to wrap the tbb calls into an ATen api call. Alternatively it would be great if this wasn't necessary to begin with, but I don't think this will happen any time soon. There are <a href=\"https://software.intel.com/en-us/node/589744\" rel=\"nofollow\">preview features</a> that appear to attempt to support this, but I didn't get them to work correctly for our case.</p>\n<p>Everything else looks good to me.</p>\n<p>EDIT: I'm wondering if we could delay merging the dispatch and vec256 changes until after the <a href=\"https://github.com/pytorch/pytorch/pull/6030\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/6030/hovercard\">Unary ops</a> have been merged?</p>", "body_text": "Generally the dispatch code looks more compact, which is nice. But, I think we might to revisit it again in the future. Having the ability to pass a table or function for non-standard cases is definitely good, but we might need to add support for a wider range of objects, such as templated functions (I'm not sure this supports that).\nAll calls to tbb will need to be prefaced by a call to the init_tbb_num_threads function as otherwise the scheduler will be initialized with the wrong number of threads. Maybe we should setup tbb so that this is required by making it unavailable anywhere outside of Parallel.h/.cpp and therefore force all devs to wrap the tbb calls into an ATen api call. Alternatively it would be great if this wasn't necessary to begin with, but I don't think this will happen any time soon. There are preview features that appear to attempt to support this, but I didn't get them to work correctly for our case.\nEverything else looks good to me.\nEDIT: I'm wondering if we could delay merging the dispatch and vec256 changes until after the Unary ops have been merged?", "body": "Generally the dispatch code looks more compact, which is nice. But, I think we might to revisit it again in the future. Having the ability to pass a table or function for non-standard cases is definitely good, but we might need to add support for a wider range of objects, such as templated functions (I'm not sure this supports that).\r\n\r\nAll calls to tbb will need to be prefaced by a call to the init_tbb_num_threads function as otherwise the scheduler will be initialized with the wrong number of threads. Maybe we should setup tbb so that this is required by making it unavailable anywhere outside of Parallel.h/.cpp and therefore force all devs to wrap the tbb calls into an ATen api call. Alternatively it would be great if this wasn't necessary to begin with, but I don't think this will happen any time soon. There are [preview features](https://software.intel.com/en-us/node/589744) that appear to attempt to support this, but I didn't get them to work correctly for our case.\r\n\r\nEverything else looks good to me.\r\n\r\nEDIT: I'm wondering if we could delay merging the dispatch and vec256 changes until after the [Unary ops](https://github.com/pytorch/pytorch/pull/6030) have been merged?"}