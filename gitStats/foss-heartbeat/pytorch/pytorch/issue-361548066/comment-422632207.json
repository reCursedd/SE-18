{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422632207", "html_url": "https://github.com/pytorch/pytorch/issues/11849#issuecomment-422632207", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11849", "id": 422632207, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjYzMjIwNw==", "user": {"login": "w-hc", "id": 17956191, "node_id": "MDQ6VXNlcjE3OTU2MTkx", "avatar_url": "https://avatars2.githubusercontent.com/u/17956191?v=4", "gravatar_id": "", "url": "https://api.github.com/users/w-hc", "html_url": "https://github.com/w-hc", "followers_url": "https://api.github.com/users/w-hc/followers", "following_url": "https://api.github.com/users/w-hc/following{/other_user}", "gists_url": "https://api.github.com/users/w-hc/gists{/gist_id}", "starred_url": "https://api.github.com/users/w-hc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/w-hc/subscriptions", "organizations_url": "https://api.github.com/users/w-hc/orgs", "repos_url": "https://api.github.com/users/w-hc/repos", "events_url": "https://api.github.com/users/w-hc/events{/privacy}", "received_events_url": "https://api.github.com/users/w-hc/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T02:57:45Z", "updated_at": "2018-09-19T02:57:45Z", "author_association": "NONE", "body_html": "<p>First, load your model before nn.dataparallel is applied.<br>\ndataparallel encapsulates the model and so the state dictionary may not match exactly.</p>\n<p>In addition, given that device mappings change all the time on cluster, and that there is occasional need to load model under CPU setting for minor tests, I always load with torch.load(map_location='cpu'), before doing load_state_dict. A little bit of extra loading and transfer time in exchange for safety might be a good trade-off.</p>", "body_text": "First, load your model before nn.dataparallel is applied.\ndataparallel encapsulates the model and so the state dictionary may not match exactly.\nIn addition, given that device mappings change all the time on cluster, and that there is occasional need to load model under CPU setting for minor tests, I always load with torch.load(map_location='cpu'), before doing load_state_dict. A little bit of extra loading and transfer time in exchange for safety might be a good trade-off.", "body": "First, load your model before nn.dataparallel is applied.\r\ndataparallel encapsulates the model and so the state dictionary may not match exactly. \r\n\r\nIn addition, given that device mappings change all the time on cluster, and that there is occasional need to load model under CPU setting for minor tests, I always load with torch.load(map_location='cpu'), before doing load_state_dict. A little bit of extra loading and transfer time in exchange for safety might be a good trade-off."}