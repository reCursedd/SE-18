{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7322", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7322/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7322/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7322/events", "html_url": "https://github.com/pytorch/pytorch/issues/7322", "id": 320549933, "node_id": "MDU6SXNzdWUzMjA1NDk5MzM=", "number": 7322, "title": "Possible bug with .ge gradient flow?", "user": {"login": "Abhishaike", "id": 19715304, "node_id": "MDQ6VXNlcjE5NzE1MzA0", "avatar_url": "https://avatars1.githubusercontent.com/u/19715304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Abhishaike", "html_url": "https://github.com/Abhishaike", "followers_url": "https://api.github.com/users/Abhishaike/followers", "following_url": "https://api.github.com/users/Abhishaike/following{/other_user}", "gists_url": "https://api.github.com/users/Abhishaike/gists{/gist_id}", "starred_url": "https://api.github.com/users/Abhishaike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Abhishaike/subscriptions", "organizations_url": "https://api.github.com/users/Abhishaike/orgs", "repos_url": "https://api.github.com/users/Abhishaike/repos", "events_url": "https://api.github.com/users/Abhishaike/events{/privacy}", "received_events_url": "https://api.github.com/users/Abhishaike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-05T23:44:24Z", "updated_at": "2018-05-06T00:54:41Z", "closed_at": "2018-05-06T00:54:41Z", "author_association": "NONE", "body_html": "<p>I may have a fundamental misunderstanding how how PyTorch works, but whenever I try to apply a torch.ge() function in the middle of the forward() definition, gradients do not flow to the layers prior to that function.</p>\n<p>Here is a reproducible code example:</p>\n<pre><code>import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as transforms\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1_0 = self.Conv_Module(3, 6, 1, 3, 1)\n        self.layer1_1 = self.Conv_Module(1, 6, 4, 3, 1)\n        self.Dense = self.Classification(384)\n\n    def Conv_Module(self, in_filters, out_filters, stride, kernel_size, padding):\n        return nn.Sequential(\n            nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=out_filters, out_channels=out_filters, kernel_size=kernel_size, stride=stride, padding=padding),\n            nn.ReLU())\n\n    def Classification(self, num_in):\n        return nn.Sequential(\n            nn.Linear(num_in, 10))\n\n    def forward(self, original_img):\n        first_conv = self.layer1_0(original_img)\n        attention_map = first_conv.mean(1).unsqueeze(dim = 1)\n        inverted_attention = -attention_map\n        output_mask = torch.ge(attention_map, inverted_attention).float()\n        second_conv = self.layer1_1(output_mask)\n        Classifier = self.Dense(second_conv.view(-1, 384))\n        return F.log_softmax(Classifier, dim=1)\n\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n                                           shuffle=True, num_workers=1)\n\nmodel = Net()\noptimizer = optim.Adam(model.parameters(), lr=1.5)\nmodel.train()\n\nfor batch_idx, (data, target) in enumerate(train_loader):\n    model.train()\n    data, target = Variable(data), Variable(target)\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    print(\"Weights before .ge:\" , torch.sum(model.layer1_0[0].weight))\n    print(\"Weights after .ge:\" ,torch.sum(model.layer1_1[0].weight))\n    print(\"*********\")\n</code></pre>\n<p>The print statements I have at the bottom show that the weights change for the layers after torch.ge(), but do not change before it. Here's what the output is:</p>\n<pre><code>Weights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(10.8658)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-24.6382)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-62.4911)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-93.4978)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-119.7056)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-142.2933)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-162.0192)\n</code></pre>\n<p>Please try to provide a minimal example to repro the bug.<br>\nError messages and stack traces are also helpful.</p>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Mac OSX 10.13.3<br>\nGCC version: Could not collect<br>\nCMake version: version 3.10.3</p>\n<p>Python version: 3.5<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.8.0rc1)<br>\n[conda] Could not collect</p>", "body_text": "I may have a fundamental misunderstanding how how PyTorch works, but whenever I try to apply a torch.ge() function in the middle of the forward() definition, gradients do not flow to the layers prior to that function.\nHere is a reproducible code example:\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as transforms\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1_0 = self.Conv_Module(3, 6, 1, 3, 1)\n        self.layer1_1 = self.Conv_Module(1, 6, 4, 3, 1)\n        self.Dense = self.Classification(384)\n\n    def Conv_Module(self, in_filters, out_filters, stride, kernel_size, padding):\n        return nn.Sequential(\n            nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=kernel_size, stride=1, padding=padding),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=out_filters, out_channels=out_filters, kernel_size=kernel_size, stride=stride, padding=padding),\n            nn.ReLU())\n\n    def Classification(self, num_in):\n        return nn.Sequential(\n            nn.Linear(num_in, 10))\n\n    def forward(self, original_img):\n        first_conv = self.layer1_0(original_img)\n        attention_map = first_conv.mean(1).unsqueeze(dim = 1)\n        inverted_attention = -attention_map\n        output_mask = torch.ge(attention_map, inverted_attention).float()\n        second_conv = self.layer1_1(output_mask)\n        Classifier = self.Dense(second_conv.view(-1, 384))\n        return F.log_softmax(Classifier, dim=1)\n\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n                                           shuffle=True, num_workers=1)\n\nmodel = Net()\noptimizer = optim.Adam(model.parameters(), lr=1.5)\nmodel.train()\n\nfor batch_idx, (data, target) in enumerate(train_loader):\n    model.train()\n    data, target = Variable(data), Variable(target)\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    print(\"Weights before .ge:\" , torch.sum(model.layer1_0[0].weight))\n    print(\"Weights after .ge:\" ,torch.sum(model.layer1_1[0].weight))\n    print(\"*********\")\n\nThe print statements I have at the bottom show that the weights change for the layers after torch.ge(), but do not change before it. Here's what the output is:\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(10.8658)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-24.6382)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-62.4911)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-93.4978)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-119.7056)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-142.2933)\n*********\nWeights before .ge: tensor(-1.2797)\nWeights after .ge: tensor(-162.0192)\n\nPlease try to provide a minimal example to repro the bug.\nError messages and stack traces are also helpful.\nSystem Info\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.10.3\nPython version: 3.5\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip] numpy (1.8.0rc1)\n[conda] Could not collect", "body": "I may have a fundamental misunderstanding how how PyTorch works, but whenever I try to apply a torch.ge() function in the middle of the forward() definition, gradients do not flow to the layers prior to that function. \r\n\r\nHere is a reproducible code example: \r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport torchvision\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nimport torchvision.transforms as transforms\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.layer1_0 = self.Conv_Module(3, 6, 1, 3, 1)\r\n        self.layer1_1 = self.Conv_Module(1, 6, 4, 3, 1)\r\n        self.Dense = self.Classification(384)\r\n\r\n    def Conv_Module(self, in_filters, out_filters, stride, kernel_size, padding):\r\n        return nn.Sequential(\r\n            nn.Conv2d(in_channels=in_filters, out_channels=out_filters, kernel_size=kernel_size, stride=1, padding=padding),\r\n            nn.ReLU(),\r\n            nn.Conv2d(in_channels=out_filters, out_channels=out_filters, kernel_size=kernel_size, stride=stride, padding=padding),\r\n            nn.ReLU())\r\n\r\n    def Classification(self, num_in):\r\n        return nn.Sequential(\r\n            nn.Linear(num_in, 10))\r\n\r\n    def forward(self, original_img):\r\n        first_conv = self.layer1_0(original_img)\r\n        attention_map = first_conv.mean(1).unsqueeze(dim = 1)\r\n        inverted_attention = -attention_map\r\n        output_mask = torch.ge(attention_map, inverted_attention).float()\r\n        second_conv = self.layer1_1(output_mask)\r\n        Classifier = self.Dense(second_conv.view(-1, 384))\r\n        return F.log_softmax(Classifier, dim=1)\r\n\r\n\r\ntransform = transforms.Compose([\r\n    transforms.ToTensor(),\r\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\r\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n                                        download=True, transform=transform)\r\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\r\n                                           shuffle=True, num_workers=1)\r\n\r\nmodel = Net()\r\noptimizer = optim.Adam(model.parameters(), lr=1.5)\r\nmodel.train()\r\n\r\nfor batch_idx, (data, target) in enumerate(train_loader):\r\n    model.train()\r\n    data, target = Variable(data), Variable(target)\r\n    optimizer.zero_grad()\r\n    output = model(data)\r\n    loss = F.nll_loss(output, target)\r\n    loss.backward()\r\n    optimizer.step()\r\n    print(\"Weights before .ge:\" , torch.sum(model.layer1_0[0].weight))\r\n    print(\"Weights after .ge:\" ,torch.sum(model.layer1_1[0].weight))\r\n    print(\"*********\")\r\n```\r\n\r\nThe print statements I have at the bottom show that the weights change for the layers after torch.ge(), but do not change before it. Here's what the output is:\r\n\r\n```\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(10.8658)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-24.6382)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-62.4911)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-93.4978)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-119.7056)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-142.2933)\r\n*********\r\nWeights before .ge: tensor(-1.2797)\r\nWeights after .ge: tensor(-162.0192)\r\n```\r\nPlease try to provide a minimal example to repro the bug.\r\nError messages and stack traces are also helpful.\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.10.3\r\n\r\nPython version: 3.5\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.8.0rc1)\r\n[conda] Could not collect"}