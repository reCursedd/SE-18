{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/436194649", "html_url": "https://github.com/pytorch/pytorch/issues/5315#issuecomment-436194649", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5315", "id": 436194649, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjE5NDY0OQ==", "user": {"login": "bpinaya", "id": 2473733, "node_id": "MDQ6VXNlcjI0NzM3MzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2473733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpinaya", "html_url": "https://github.com/bpinaya", "followers_url": "https://api.github.com/users/bpinaya/followers", "following_url": "https://api.github.com/users/bpinaya/following{/other_user}", "gists_url": "https://api.github.com/users/bpinaya/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpinaya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpinaya/subscriptions", "organizations_url": "https://api.github.com/users/bpinaya/orgs", "repos_url": "https://api.github.com/users/bpinaya/repos", "events_url": "https://api.github.com/users/bpinaya/events{/privacy}", "received_events_url": "https://api.github.com/users/bpinaya/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T09:54:24Z", "updated_at": "2018-11-06T09:54:24Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=527241\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/daniel-j-h\">@daniel-j-h</a> I think you are using cpu only? On Pytorch 1.0 RC I get:</p>\n<pre><code>Traceback (most recent call last):\n  File \"onnx_second_test.py\", line 22, in &lt;module&gt;\n    torch.onnx.export(model, dummy, 'resnet50.pb')\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\n    return utils.export(*args, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\n    operator_export_type=operator_export_type)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\n    example_outputs, propagate)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 223, in _model_to_graph\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 191, in _trace_and_get_graph_from_model\n    trace, torch_out = torch.jit.get_trace_graph(model, args)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 167, in get_trace_graph\n    return LegacyTracedModule(f)(*args, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 198, in forward\n    out = self.inner(*trace_inputs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 475, in __call__\n    result = self._slow_forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 465, in _slow_forward\n    result = self.forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 125, in forward\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 130, in replicate\n    return replicate(module, device_ids)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 13, in replicate\n    param_copies = Broadcast.apply(devices, *params)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 14, in forward\n    raise TypeError('Broadcast function not implemented for CPU tensors')\nTypeError: Broadcast function not implemented for CPU tensors\n</code></pre>\n<p>The following works for me:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch.onnx\n<span class=\"pl-k\">import</span> torchvision\n\ndevice <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda:0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> torch.cuda.is_available() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>)\n\ndummy <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>))\n\nmodel <span class=\"pl-k\">=</span> torchvision.models.resnet50(<span class=\"pl-v\">pretrained</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\nmodel.to(device)\n\ntorch.onnx.export(model, dummy, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>resnet50.pb<span class=\"pl-pds\">\"</span></span>)</pre></div>", "body_text": "@daniel-j-h I think you are using cpu only? On Pytorch 1.0 RC I get:\nTraceback (most recent call last):\n  File \"onnx_second_test.py\", line 22, in <module>\n    torch.onnx.export(model, dummy, 'resnet50.pb')\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\n    return utils.export(*args, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\n    operator_export_type=operator_export_type)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\n    example_outputs, propagate)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 223, in _model_to_graph\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 191, in _trace_and_get_graph_from_model\n    trace, torch_out = torch.jit.get_trace_graph(model, args)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 167, in get_trace_graph\n    return LegacyTracedModule(f)(*args, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 198, in forward\n    out = self.inner(*trace_inputs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 475, in __call__\n    result = self._slow_forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 465, in _slow_forward\n    result = self.forward(*input, **kwargs)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 125, in forward\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 130, in replicate\n    return replicate(module, device_ids)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 13, in replicate\n    param_copies = Broadcast.apply(devices, *params)\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 14, in forward\n    raise TypeError('Broadcast function not implemented for CPU tensors')\nTypeError: Broadcast function not implemented for CPU tensors\n\nThe following works for me:\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.onnx\nimport torchvision\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndummy = Variable(torch.randn(10, 3, 224, 224, device='cuda'))\n\nmodel = torchvision.models.resnet50(pretrained=True)\n\nmodel.to(device)\n\ntorch.onnx.export(model, dummy, \"resnet50.pb\")", "body": "@daniel-j-h I think you are using cpu only? On Pytorch 1.0 RC I get:\r\n```\r\nTraceback (most recent call last):\r\n  File \"onnx_second_test.py\", line 22, in <module>\r\n    torch.onnx.export(model, dummy, 'resnet50.pb')\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\r\n    return utils.export(*args, **kwargs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\r\n    operator_export_type=operator_export_type)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\r\n    example_outputs, propagate)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 223, in _model_to_graph\r\n    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/onnx/utils.py\", line 191, in _trace_and_get_graph_from_model\r\n    trace, torch_out = torch.jit.get_trace_graph(model, args)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 167, in get_trace_graph\r\n    return LegacyTracedModule(f)(*args, **kwargs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py\", line 198, in forward\r\n    out = self.inner(*trace_inputs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 475, in __call__\r\n    result = self._slow_forward(*input, **kwargs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 465, in _slow_forward\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 125, in forward\r\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 130, in replicate\r\n    return replicate(module, device_ids)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 13, in replicate\r\n    param_copies = Broadcast.apply(devices, *params)\r\n  File \"/home/bpinaya/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 14, in forward\r\n    raise TypeError('Broadcast function not implemented for CPU tensors')\r\nTypeError: Broadcast function not implemented for CPU tensors\r\n```\r\n\r\nThe following works for me:\r\n```python\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport torch.onnx\r\nimport torchvision\r\n\r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n\r\ndummy = Variable(torch.randn(10, 3, 224, 224, device='cuda'))\r\n\r\nmodel = torchvision.models.resnet50(pretrained=True)\r\n\r\nmodel.to(device)\r\n\r\ntorch.onnx.export(model, dummy, \"resnet50.pb\")\r\n```"}