{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230270990", "pull_request_review_id": 170971001, "id": 230270990, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMDI3MDk5MA==", "diff_hunk": "@@ -37,14 +41,35 @@ struct TensorGroup {\n   }\n };\n \n-std::vector<TensorGroup> take_tensors(at::TensorList tensors, size_t size_limit);\n-void reorder_tensors_like(std::vector<at::Tensor>& tensors, at::TensorList order);\n+// Helper function that take a list of tensor by the size limit, if the\n+// list of tensors are of different tensor types, each type will be taken by\n+// the size limit. In other words, the input tensor list will firstlbe bucketed\n+// by tensor types, and then each bucket will be further bucketed by size_limit\n+std::vector<TensorGroup> take_tensors(\n+    at::TensorList tensors,\n+    size_t size_limit);\n+\n+// Helper function that take a list of tensor by the size limit in a\n+// fine-grained manner. This helper will loop through the input tensor list and\n+// accumulate enough tensors (even though the tensors can be of different type)\n+// until size_limit is hit. Then for each accumulation, it will further bucket\n+// the accumulation by different types. In other words, for each size_limit's\n+// accumulation, multiple buckets are generated.", "path": "torch/csrc/utils/tensor_flatten.h", "position": null, "original_position": 57, "commit_id": "9f1e4eeab105cd57c121631d00a050d80afc0709", "original_commit_id": "a0d341aa3fd1a3b3a424fcf9af8ee75edd187c71", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "body": "Multiple buckets as in 1 per type (in the last sentence)? If I understand correctly this will output in chronological order (since you don't care about type when counting up to the size limit), compared to potential complete out of order for the other implementation. If this is the case, I would assume this more fine grained one has a much better shot overlapping indeed and we should consider just replacing it instead of having 2 functions with similar outcome.", "created_at": "2018-11-02T05:05:48Z", "updated_at": "2018-11-23T15:54:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/13496#discussion_r230270990", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13496", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230270990"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13496#discussion_r230270990"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13496"}}, "body_html": "<p>Multiple buckets as in 1 per type (in the last sentence)? If I understand correctly this will output in chronological order (since you don't care about type when counting up to the size limit), compared to potential complete out of order for the other implementation. If this is the case, I would assume this more fine grained one has a much better shot overlapping indeed and we should consider just replacing it instead of having 2 functions with similar outcome.</p>", "body_text": "Multiple buckets as in 1 per type (in the last sentence)? If I understand correctly this will output in chronological order (since you don't care about type when counting up to the size limit), compared to potential complete out of order for the other implementation. If this is the case, I would assume this more fine grained one has a much better shot overlapping indeed and we should consider just replacing it instead of having 2 functions with similar outcome."}