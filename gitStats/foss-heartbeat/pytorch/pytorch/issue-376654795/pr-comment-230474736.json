{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230474736", "pull_request_review_id": 171228797, "id": 230474736, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMDQ3NDczNg==", "diff_hunk": "@@ -1,44 +1,93 @@\n #include \"torch/csrc/utils/tensor_flatten.h\"\n \n+#include <map>\n #include <unordered_map>\n \n-namespace torch { namespace utils {\n+namespace torch {\n+namespace utils {\n \n using namespace at;\n \n std::vector<TensorGroup> take_tensors(TensorList tensors, size_t size_limit) {\n   std::vector<TensorGroup> results;\n-  results.reserve(tensors.size()); // an overapproximation, but at least we won't have to copy stuff around\n-  std::unordered_map<at::Type*, TensorGroup> groups;\n-  for (const auto & tensor : tensors) {\n-    auto & type = tensor.type();\n+  // an overapproximation, but at least we won't have to copy stuff around\n+  results.reserve(tensors.size());\n+  std::map<TypeID, TensorGroup> groups;\n+  for (const auto& tensor : tensors) {\n+    auto& type = tensor.type();\n     size_t tensor_size;\n     if (type.is_sparse()) {\n       const auto& indices = tensor._indices();\n       const auto& values = tensor._values();\n       tensor_size = indices.numel() * indices.type().elementSizeInBytes() +\n-                    values.numel() * indices.type().elementSizeInBytes();\n+          values.numel() * indices.type().elementSizeInBytes();\n     } else {\n       tensor_size = tensor.numel() * type.elementSizeInBytes();\n     }\n-    auto & type_group = groups[&type];\n+\n+    auto& type_group = groups[type.ID()];\n     type_group.tensors.push_back(tensor);\n     type_group.size += tensor_size;\n-    if (type_group.size + tensor_size >= size_limit) {\n+    if (type_group.size >= size_limit) {\n       results.emplace_back();\n       std::swap(results.back(), type_group);\n     }\n   }\n   // End case. Look for any remaining groups and return them.\n-  for (auto & entry : groups) {\n-    auto & group = entry.second;\n+  for (auto& entry : groups) {\n+    auto& group = entry.second;\n     if (group.size > 0) {\n       results.emplace_back(std::move(group));\n     }\n   }\n   return results;\n }\n \n+std::vector<TensorGroup> take_tensors_finegrained(\n+    TensorList tensors,", "path": "torch/csrc/utils/tensor_flatten.cpp", "position": null, "original_position": 57, "commit_id": "9f1e4eeab105cd57c121631d00a050d80afc0709", "original_commit_id": "a0d341aa3fd1a3b3a424fcf9af8ee75edd187c71", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "Eventually, I would like to use the function for BW bucketing strategy, the difference is explained in comments, I will rewrite the comments to make it more clear", "created_at": "2018-11-02T18:52:43Z", "updated_at": "2018-11-23T15:54:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/13496#discussion_r230474736", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13496", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230474736"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13496#discussion_r230474736"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13496"}}, "body_html": "<p>Eventually, I would like to use the function for BW bucketing strategy, the difference is explained in comments, I will rewrite the comments to make it more clear</p>", "body_text": "Eventually, I would like to use the function for BW bucketing strategy, the difference is explained in comments, I will rewrite the comments to make it more clear", "in_reply_to_id": 230448396}