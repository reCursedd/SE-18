{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/435607788", "html_url": "https://github.com/pytorch/pytorch/issues/9688#issuecomment-435607788", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9688", "id": 435607788, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTYwNzc4OA==", "user": {"login": "c-hofer", "id": 28672615, "node_id": "MDQ6VXNlcjI4NjcyNjE1", "avatar_url": "https://avatars2.githubusercontent.com/u/28672615?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c-hofer", "html_url": "https://github.com/c-hofer", "followers_url": "https://api.github.com/users/c-hofer/followers", "following_url": "https://api.github.com/users/c-hofer/following{/other_user}", "gists_url": "https://api.github.com/users/c-hofer/gists{/gist_id}", "starred_url": "https://api.github.com/users/c-hofer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c-hofer/subscriptions", "organizations_url": "https://api.github.com/users/c-hofer/orgs", "repos_url": "https://api.github.com/users/c-hofer/repos", "events_url": "https://api.github.com/users/c-hofer/events{/privacy}", "received_events_url": "https://api.github.com/users/c-hofer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-03T17:54:15Z", "updated_at": "2018-11-03T17:54:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6359743\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/albanD\">@albanD</a> Thanks for the verbose update :) It made things much clearer. So in conclusion, we can say that the mentioned behavior is a design choice when implementing a recursive differentiation framework.  It produces (from my point of view) un<em>intuitive</em> behavior regarding \"exclusion\" but I guess that's the price to pay for <em>intuitive</em> behavior in other cases, e.g., your example.</p>\n<h3>Some thoughts on your solution ....</h3>\n<p>With recursive differentiation in mind its clear that exchanging</p>\n<pre><code>x = x.sqrt()\nx = x[x &gt; 0]\n</code></pre>\n<p>by</p>\n<pre><code>x = x[x &gt; 0]\nx = x.sqrt()\n</code></pre>\n<p>solves the issue.<br>\nHowever, one could be in the situation that the latter is not an option as we have no access to<br>\n<code>x</code> before the <code>sqrt</code> operation. For example this could be a distance matrix which is given some functionality which then \"excludes\" unwanted \"coordinates\".<br>\nOr more general, you get an tensor <code>D</code> and some algorithm, <code>alg</code>,  uses <code>D</code> but can, based on <code>D</code>'s point-values, decide which parts have defined gradients. In the current framework you need to have detail information on <code>D</code> to be sure that autograd works, in terms of encapsulation this may be a disadvantage.<br>\n(This case is not hypothetical, I am currently  in a similar situation ;) )</p>\n<p>Would it be reasonable to propose an \"exclusion\" functionality where locally the multiplicative algebra is<br>\nchanged such that <code>nan * 0 = 0</code>?<br>\nIn this case <code>alg</code> could decide solely on the values of <code>D</code> which index selection should be applied.</p>\n<p>This is just a thought and may be not important, or a huge pain for maybe little gain.</p>\n<p>--cheers chris</p>", "body_text": "@albanD Thanks for the verbose update :) It made things much clearer. So in conclusion, we can say that the mentioned behavior is a design choice when implementing a recursive differentiation framework.  It produces (from my point of view) unintuitive behavior regarding \"exclusion\" but I guess that's the price to pay for intuitive behavior in other cases, e.g., your example.\nSome thoughts on your solution ....\nWith recursive differentiation in mind its clear that exchanging\nx = x.sqrt()\nx = x[x > 0]\n\nby\nx = x[x > 0]\nx = x.sqrt()\n\nsolves the issue.\nHowever, one could be in the situation that the latter is not an option as we have no access to\nx before the sqrt operation. For example this could be a distance matrix which is given some functionality which then \"excludes\" unwanted \"coordinates\".\nOr more general, you get an tensor D and some algorithm, alg,  uses D but can, based on D's point-values, decide which parts have defined gradients. In the current framework you need to have detail information on D to be sure that autograd works, in terms of encapsulation this may be a disadvantage.\n(This case is not hypothetical, I am currently  in a similar situation ;) )\nWould it be reasonable to propose an \"exclusion\" functionality where locally the multiplicative algebra is\nchanged such that nan * 0 = 0?\nIn this case alg could decide solely on the values of D which index selection should be applied.\nThis is just a thought and may be not important, or a huge pain for maybe little gain.\n--cheers chris", "body": "@albanD Thanks for the verbose update :) It made things much clearer. So in conclusion, we can say that the mentioned behavior is a design choice when implementing a recursive differentiation framework.  It produces (from my point of view) un*intuitive* behavior regarding \"exclusion\" but I guess that's the price to pay for *intuitive* behavior in other cases, e.g., your example. \r\n\r\n\r\n### Some thoughts on your solution .... \r\n\r\nWith recursive differentiation in mind its clear that exchanging\r\n```\r\nx = x.sqrt()\r\nx = x[x > 0]\r\n```\r\nby\r\n```\r\nx = x[x > 0]\r\nx = x.sqrt()\r\n```\r\nsolves the issue. \r\nHowever, one could be in the situation that the latter is not an option as we have no access to\r\n`x` before the `sqrt` operation. For example this could be a distance matrix which is given some functionality which then \"excludes\" unwanted \"coordinates\". \r\nOr more general, you get an tensor `D` and some algorithm, `alg`,  uses `D` but can, based on `D`'s point-values, decide which parts have defined gradients. In the current framework you need to have detail information on `D` to be sure that autograd works, in terms of encapsulation this may be a disadvantage. \r\n(This case is not hypothetical, I am currently  in a similar situation ;) ) \r\n\r\nWould it be reasonable to propose an \"exclusion\" functionality where locally the multiplicative algebra is \r\nchanged such that `nan * 0 = 0`? \r\nIn this case `alg` could decide solely on the values of `D` which index selection should be applied. \r\n\r\nThis is just a thought and may be not important, or a huge pain for maybe little gain. \r\n\r\n--cheers chris\r\n\r\n"}