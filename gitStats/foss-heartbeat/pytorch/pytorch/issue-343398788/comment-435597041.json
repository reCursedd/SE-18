{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/435597041", "html_url": "https://github.com/pytorch/pytorch/issues/9688#issuecomment-435597041", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9688", "id": 435597041, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTU5NzA0MQ==", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-03T15:37:53Z", "updated_at": "2018-11-03T15:43:00Z", "author_association": "COLLABORATOR", "body_html": "<p>Hey,<br>\nThis answer grew more than I expected. It contains the current behavior that we give to the autograd (slightly different from what you were thinking), my point of view on your conclusion, the detail of why you get nan in your case and a simple fix that give you the right gradients at no cost (actually faster than the version that gives nan).</p>\n<h4>The current specification is the following:</h4>\n<p>For every elementary Function that is implemented, what is returned as the gradient of the output wrt the input is defined as follow where each is checked in this order:</p>\n<ul>\n<li>If the forward function is not defined (<code>sqrt(-1)</code> or <code>log(-1)</code> for example) then this is undefined. Most function will return nan, but for performance reasons, some functions will return not-nan values (<code>log</code> for example).</li>\n<li>If a gradient exist at the current point, return it</li>\n<li>If the function is convex, return one of it's subgradients at the current point (absolute value at 0 for example)</li>\n<li>Define the gradient at the current point by continuity (note that inf is possible here), if two values are possible, pick one arbitrarily (for example clamp or sqrt)</li>\n<li>No other rule is needed as all of our functions are differentiable almost everywhere.</li>\n</ul>\n<p>When the user define a function that is a combination of these elementary Functions, the chain rule is used to get the full gradient. If you have <code>f(x) = g(h(x))</code>, the engine cannot consider the properties of <code>df/dx</code> as it does not know about it, it will only work with <code>dg/dx</code> and <code>dh/dx</code> where g and h are elementary functions.</p>\n<h4>Your conclusion</h4>\n<p>So actually the gradient that is used can only be nan if the forward function was giving nan as well.<br>\nIn your case, the chain rule make a nan appear because the gradient of the input is <code>0*inf</code> (see next point).<br>\nI don't think we want to give 0 for all undefined operations as:</p>\n<ul>\n<li>I think it makes sense to define the gradient by continuity if there is a single point where the function is not differentiable</li>\n<li>Forcing the gradient to be 0 does not make sense in all case even though it does in yours. Just looking at sqrt at 0, consider the sample below:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">x</span>):\n    x1 <span class=\"pl-k\">=</span> x.clone()\n    x1[x1<span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> x1 contains all the positive values</span>\n    x2 <span class=\"pl-k\">=</span> x.clone()\n    x2[x2<span class=\"pl-k\">&gt;</span><span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> x2 contains all the negative values</span>\n    <span class=\"pl-k\">return</span> (x1<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>).sqrt() <span class=\"pl-k\">-</span> (x2<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>).sqrt()\n\ninp <span class=\"pl-k\">=</span> torch.tensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>., <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nout <span class=\"pl-k\">=</span> f(inp)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>out<span class=\"pl-pds\">\"</span></span>, out) <span class=\"pl-c\"><span class=\"pl-c\">#</span> [-2., -1., 0, 1, 2]</span>\n\nres <span class=\"pl-k\">=</span> torch.autograd.grad(out.sum(), inp)[<span class=\"pl-c1\">0</span>]\n<span class=\"pl-c1\">print</span>(res)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> [1., 1., nan, 1., 1.]</span></pre></div>\n<p>It's a weird way to write an identity, but that's ok. At the moment, if you ask for the gradient at 0 of this function, you will get <code>nan</code>. Meaning that given the implementation and using the chain rule, we cannot compute the gradient at this point.<br>\nIf now we set the gradient of the square root at 0 to 0, then this function will have a gradient of 0 at 0. For an identity function you expect 1.<br>\nAt the moment in the worst case we return nan for something that could have had a proper gradient. But we always return correct gradients when it's not nan. With your proposition, the autograd engine could return a well formed gradient value that is wrong (in this example, 0 instead of 1).</p>\n<p>Basically the chain rule allows you to shoot yourself in the foot if you try hard enough and will make differentiable functions impossible to differentiate.<br>\nUnfortunately, I don't see a good way to reduce this problem while always returning valid gradients if we return one (not-nan).</p>\n<h4>What cause the nan in your case</h4>\n<p>In your example, the problem is that if you write: <code>y = x.sqrt()</code> and <code>out = y[y&gt;0]</code>. Then for the values of <code>x &lt;= 0</code>, <code>y</code> will be <code>0</code> or <code>nan</code>. And so the gradient of y (with respect to a given quantity that i will call <code>loss</code>) will be 0 for these entries. the chain rule for the gradient of <code>x</code> will then give you <code>dloss/dx = dloss/dy * dy/dx = </code>:</p>\n<ul>\n<li><code>0 * nan</code> if <code>x&lt;0</code></li>\n<li><code>0 * inf</code> if <code>x == 0</code></li>\n<li><code>1 / (2 * sqrt(x))</code> if <code>x &gt; 0</code></li>\n</ul>\n<h4>Your example is easy to fix</h4>\n<p>if you change:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> x.sqrt()\nx <span class=\"pl-k\">=</span> x[x <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>]</pre></div>\n<p>by</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> x[x <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>]\nx <span class=\"pl-k\">=</span> x.sqrt()</pre></div>\n<p>For your code sample, then you get the gradient you expect at no cost ! It will actually be <em>faster</em> because instead of doing the sqrt op on the whole tensor before discarding part of it, you will actually do it only on the part that you care about.</p>", "body_text": "Hey,\nThis answer grew more than I expected. It contains the current behavior that we give to the autograd (slightly different from what you were thinking), my point of view on your conclusion, the detail of why you get nan in your case and a simple fix that give you the right gradients at no cost (actually faster than the version that gives nan).\nThe current specification is the following:\nFor every elementary Function that is implemented, what is returned as the gradient of the output wrt the input is defined as follow where each is checked in this order:\n\nIf the forward function is not defined (sqrt(-1) or log(-1) for example) then this is undefined. Most function will return nan, but for performance reasons, some functions will return not-nan values (log for example).\nIf a gradient exist at the current point, return it\nIf the function is convex, return one of it's subgradients at the current point (absolute value at 0 for example)\nDefine the gradient at the current point by continuity (note that inf is possible here), if two values are possible, pick one arbitrarily (for example clamp or sqrt)\nNo other rule is needed as all of our functions are differentiable almost everywhere.\n\nWhen the user define a function that is a combination of these elementary Functions, the chain rule is used to get the full gradient. If you have f(x) = g(h(x)), the engine cannot consider the properties of df/dx as it does not know about it, it will only work with dg/dx and dh/dx where g and h are elementary functions.\nYour conclusion\nSo actually the gradient that is used can only be nan if the forward function was giving nan as well.\nIn your case, the chain rule make a nan appear because the gradient of the input is 0*inf (see next point).\nI don't think we want to give 0 for all undefined operations as:\n\nI think it makes sense to define the gradient by continuity if there is a single point where the function is not differentiable\nForcing the gradient to be 0 does not make sense in all case even though it does in yours. Just looking at sqrt at 0, consider the sample below:\n\nimport torch\ndef f(x):\n    x1 = x.clone()\n    x1[x1<0] = 0\n    # x1 contains all the positive values\n    x2 = x.clone()\n    x2[x2>0] = 0\n    # x2 contains all the negative values\n    return (x1**2).sqrt() - (x2**2).sqrt()\n\ninp = torch.tensor([-2., -1., 0, 1, 2], requires_grad=True)\nout = f(inp)\nprint(\"out\", out) # [-2., -1., 0, 1, 2]\n\nres = torch.autograd.grad(out.sum(), inp)[0]\nprint(res)  # [1., 1., nan, 1., 1.]\nIt's a weird way to write an identity, but that's ok. At the moment, if you ask for the gradient at 0 of this function, you will get nan. Meaning that given the implementation and using the chain rule, we cannot compute the gradient at this point.\nIf now we set the gradient of the square root at 0 to 0, then this function will have a gradient of 0 at 0. For an identity function you expect 1.\nAt the moment in the worst case we return nan for something that could have had a proper gradient. But we always return correct gradients when it's not nan. With your proposition, the autograd engine could return a well formed gradient value that is wrong (in this example, 0 instead of 1).\nBasically the chain rule allows you to shoot yourself in the foot if you try hard enough and will make differentiable functions impossible to differentiate.\nUnfortunately, I don't see a good way to reduce this problem while always returning valid gradients if we return one (not-nan).\nWhat cause the nan in your case\nIn your example, the problem is that if you write: y = x.sqrt() and out = y[y>0]. Then for the values of x <= 0, y will be 0 or nan. And so the gradient of y (with respect to a given quantity that i will call loss) will be 0 for these entries. the chain rule for the gradient of x will then give you dloss/dx = dloss/dy * dy/dx = :\n\n0 * nan if x<0\n0 * inf if x == 0\n1 / (2 * sqrt(x)) if x > 0\n\nYour example is easy to fix\nif you change:\nx = x.sqrt()\nx = x[x > 0]\nby\nx = x[x > 0]\nx = x.sqrt()\nFor your code sample, then you get the gradient you expect at no cost ! It will actually be faster because instead of doing the sqrt op on the whole tensor before discarding part of it, you will actually do it only on the part that you care about.", "body": "Hey,\r\nThis answer grew more than I expected. It contains the current behavior that we give to the autograd (slightly different from what you were thinking), my point of view on your conclusion, the detail of why you get nan in your case and a simple fix that give you the right gradients at no cost (actually faster than the version that gives nan).\r\n\r\n#### The current specification is the following:\r\nFor every elementary Function that is implemented, what is returned as the gradient of the output wrt the input is defined as follow where each is checked in this order:\r\n- If the forward function is not defined (`sqrt(-1)` or `log(-1)` for example) then this is undefined. Most function will return nan, but for performance reasons, some functions will return not-nan values (`log` for example).\r\n- If a gradient exist at the current point, return it\r\n- If the function is convex, return one of it's subgradients at the current point (absolute value at 0 for example)\r\n- Define the gradient at the current point by continuity (note that inf is possible here), if two values are possible, pick one arbitrarily (for example clamp or sqrt)\r\n- No other rule is needed as all of our functions are differentiable almost everywhere.\r\n\r\nWhen the user define a function that is a combination of these elementary Functions, the chain rule is used to get the full gradient. If you have `f(x) = g(h(x))`, the engine cannot consider the properties of `df/dx` as it does not know about it, it will only work with `dg/dx` and `dh/dx` where g and h are elementary functions.\r\n\r\n#### Your conclusion\r\nSo actually the gradient that is used can only be nan if the forward function was giving nan as well.\r\nIn your case, the chain rule make a nan appear because the gradient of the input is `0*inf` (see next point).\r\nI don't think we want to give 0 for all undefined operations as:\r\n- I think it makes sense to define the gradient by continuity if there is a single point where the function is not differentiable\r\n- Forcing the gradient to be 0 does not make sense in all case even though it does in yours. Just looking at sqrt at 0, consider the sample below:\r\n```python\r\nimport torch\r\ndef f(x):\r\n    x1 = x.clone()\r\n    x1[x1<0] = 0\r\n    # x1 contains all the positive values\r\n    x2 = x.clone()\r\n    x2[x2>0] = 0\r\n    # x2 contains all the negative values\r\n    return (x1**2).sqrt() - (x2**2).sqrt()\r\n\r\ninp = torch.tensor([-2., -1., 0, 1, 2], requires_grad=True)\r\nout = f(inp)\r\nprint(\"out\", out) # [-2., -1., 0, 1, 2]\r\n\r\nres = torch.autograd.grad(out.sum(), inp)[0]\r\nprint(res)  # [1., 1., nan, 1., 1.]\r\n```\r\nIt's a weird way to write an identity, but that's ok. At the moment, if you ask for the gradient at 0 of this function, you will get `nan`. Meaning that given the implementation and using the chain rule, we cannot compute the gradient at this point.\r\nIf now we set the gradient of the square root at 0 to 0, then this function will have a gradient of 0 at 0. For an identity function you expect 1.\r\nAt the moment in the worst case we return nan for something that could have had a proper gradient. But we always return correct gradients when it's not nan. With your proposition, the autograd engine could return a well formed gradient value that is wrong (in this example, 0 instead of 1).\r\n\r\nBasically the chain rule allows you to shoot yourself in the foot if you try hard enough and will make differentiable functions impossible to differentiate.\r\nUnfortunately, I don't see a good way to reduce this problem while always returning valid gradients if we return one (not-nan).\r\n\r\n#### What cause the nan in your case\r\nIn your example, the problem is that if you write: `y = x.sqrt()` and `out = y[y>0]`. Then for the values of `x <= 0`, `y` will be `0` or `nan`. And so the gradient of y (with respect to a given quantity that i will call `loss`) will be 0 for these entries. the chain rule for the gradient of `x` will then give you `dloss/dx = dloss/dy * dy/dx = `:\r\n- `0 * nan` if `x<0`\r\n- `0 * inf` if `x == 0`\r\n- `1 / (2 * sqrt(x))` if `x > 0`\r\n\r\n#### Your example is easy to fix\r\nif you change:\r\n```python\r\nx = x.sqrt()\r\nx = x[x > 0]\r\n```\r\nby\r\n```python\r\nx = x[x > 0]\r\nx = x.sqrt()\r\n```\r\nFor your code sample, then you get the gradient you expect at no cost ! It will actually be *faster* because instead of doing the sqrt op on the whole tensor before discarding part of it, you will actually do it only on the part that you care about."}