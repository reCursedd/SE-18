{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10058", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10058/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10058/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10058/events", "html_url": "https://github.com/pytorch/pytorch/pull/10058", "id": 346047212, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA1MDA0ODA3", "number": 10058, "title": "[c10d] Added Reduce,AllGather,Gather,Scatter Ops for NCCL and MPI process groups", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953883, "node_id": "MDU6TGFiZWw2Nzk5NTM4ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributed", "name": "distributed", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-07-31T06:06:47Z", "updated_at": "2018-11-23T15:49:15Z", "closed_at": "2018-08-14T20:11:28Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10058", "html_url": "https://github.com/pytorch/pytorch/pull/10058", "diff_url": "https://github.com/pytorch/pytorch/pull/10058.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10058.patch"}, "body_html": "<p>Added</p>\n<ul>\n<li>Reduce (both NCCL and MPI)</li>\n<li>AllGather (both NCCL and MPI)</li>\n<li>Gather (MPI)</li>\n<li>Scatter (MPI)</li>\n</ul>\n<p>for c10d process groups. This basically finalizes all supported ops for C10d to match THD.</p>\n<p>All ops are tested as well.</p>\n<pre><code>mpirun -np 8 ./ProcessGroupMPITest\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\n</code></pre>\n<pre><code>./ProcessGroupNCCLTest\nAllreduce test successful\nBroadcast test successful\nReduce test successful\nAllgather test successful\n</code></pre>", "body_text": "Added\n\nReduce (both NCCL and MPI)\nAllGather (both NCCL and MPI)\nGather (MPI)\nScatter (MPI)\n\nfor c10d process groups. This basically finalizes all supported ops for C10d to match THD.\nAll ops are tested as well.\nmpirun -np 8 ./ProcessGroupMPITest\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\nTest successful\n\n./ProcessGroupNCCLTest\nAllreduce test successful\nBroadcast test successful\nReduce test successful\nAllgather test successful", "body": "Added \r\n- Reduce (both NCCL and MPI)\r\n- AllGather (both NCCL and MPI)\r\n- Gather (MPI)\r\n- Scatter (MPI)\r\n\r\nfor c10d process groups. This basically finalizes all supported ops for C10d to match THD.\r\n\r\nAll ops are tested as well.\r\n\r\n```\r\nmpirun -np 8 ./ProcessGroupMPITest\r\nTest successful\r\nTest successful\r\nTest successful\r\nTest successful\r\nTest successful\r\nTest successful\r\nTest successful\r\nTest successful\r\n```\r\n\r\n```\r\n./ProcessGroupNCCLTest\r\nAllreduce test successful\r\nBroadcast test successful\r\nReduce test successful\r\nAllgather test successful\r\n```"}