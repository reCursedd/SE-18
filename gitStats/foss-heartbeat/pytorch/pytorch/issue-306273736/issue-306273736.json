{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5862", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5862/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5862/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5862/events", "html_url": "https://github.com/pytorch/pytorch/issues/5862", "id": 306273736, "node_id": "MDU6SXNzdWUzMDYyNzM3MzY=", "number": 5862, "title": "Bug: torchvision/transforms/functional/to_pil_image always converts 1-channel (gray) FloatTensor images to 8-bit unsigned int", "user": {"login": "mathski", "id": 3429621, "node_id": "MDQ6VXNlcjM0Mjk2MjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/3429621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mathski", "html_url": "https://github.com/mathski", "followers_url": "https://api.github.com/users/mathski/followers", "following_url": "https://api.github.com/users/mathski/following{/other_user}", "gists_url": "https://api.github.com/users/mathski/gists{/gist_id}", "starred_url": "https://api.github.com/users/mathski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mathski/subscriptions", "organizations_url": "https://api.github.com/users/mathski/orgs", "repos_url": "https://api.github.com/users/mathski/repos", "events_url": "https://api.github.com/users/mathski/events{/privacy}", "received_events_url": "https://api.github.com/users/mathski/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-18T19:32:12Z", "updated_at": "2018-03-19T14:16:36Z", "closed_at": "2018-03-19T14:16:35Z", "author_association": "NONE", "body_html": "<ul>\n<li>OS: Ubuntu 16.04.4 LTS x64</li>\n<li>PyTorch version: 0.3.0</li>\n<li>Torchvision version: 0.2.0</li>\n<li>How you installed PyTorch (conda, pip, source): conda</li>\n<li>Python version: 3</li>\n<li>CUDA/cuDNN version: 8.0</li>\n<li>GPU models and configuration: Titan X (Maxwell)</li>\n</ul>\n<p>ERROR:<br>\n<strong>ValueError: Incorrect mode (&lt;class 'float'&gt;) supplied for input type &lt;class 'numpy.dtype'&gt;. Should be L</strong></p>\n<p>The <em>torchvision</em> transform <strong>ToPILImage(mode=float)</strong> will always break for input of type <em>torch.FloatTensor</em><br>\n<strong>ToPILImage()</strong> uses the internal function <strong>to_pil_image</strong> found in <em>torchvision/transforms/functional.py</em></p>\n<p>In <em><a href=\"https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py\">https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py</a></em>:<br>\nLine 104 checks if the input is of type <em>torch.FloatTensor</em><br>\nIf so, line 105 scales the input by 255, but then converts it to <strong>byte</strong><br>\nLines 113-127 check if the user-specified mode is the expected mode, and throws an error if not.<br>\nThe expected mode is assigned by <strong>npimg.dtype</strong>, which return <strong>np.uint8</strong> if line 105 is executed</p>\n<p>I believe the bug can be fixed by changing line 105 from:<br>\n<strong>pic = pic.mul(255).byte()</strong><br>\n-to-<br>\n<strong>pic = pic.mul(255)</strong></p>\n<p><strong>Test script:</strong><br>\nimport torch<br>\nfrom torchvision import transforms<br>\na = torch.FloatTensor(1,64,64)<br>\ntform = transforms.Compose([transforms.ToPILImage(mode=float)])<br>\nb = tform(a)</p>\n<p>Please let me know if I am in error.<br>\nThank you.</p>", "body_text": "OS: Ubuntu 16.04.4 LTS x64\nPyTorch version: 0.3.0\nTorchvision version: 0.2.0\nHow you installed PyTorch (conda, pip, source): conda\nPython version: 3\nCUDA/cuDNN version: 8.0\nGPU models and configuration: Titan X (Maxwell)\n\nERROR:\nValueError: Incorrect mode (<class 'float'>) supplied for input type <class 'numpy.dtype'>. Should be L\nThe torchvision transform ToPILImage(mode=float) will always break for input of type torch.FloatTensor\nToPILImage() uses the internal function to_pil_image found in torchvision/transforms/functional.py\nIn https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py:\nLine 104 checks if the input is of type torch.FloatTensor\nIf so, line 105 scales the input by 255, but then converts it to byte\nLines 113-127 check if the user-specified mode is the expected mode, and throws an error if not.\nThe expected mode is assigned by npimg.dtype, which return np.uint8 if line 105 is executed\nI believe the bug can be fixed by changing line 105 from:\npic = pic.mul(255).byte()\n-to-\npic = pic.mul(255)\nTest script:\nimport torch\nfrom torchvision import transforms\na = torch.FloatTensor(1,64,64)\ntform = transforms.Compose([transforms.ToPILImage(mode=float)])\nb = tform(a)\nPlease let me know if I am in error.\nThank you.", "body": "- OS: Ubuntu 16.04.4 LTS x64\r\n- PyTorch version: 0.3.0\r\n- Torchvision version: 0.2.0\r\n- How you installed PyTorch (conda, pip, source): conda\r\n- Python version: 3\r\n- CUDA/cuDNN version: 8.0\r\n- GPU models and configuration: Titan X (Maxwell)\r\n\r\nERROR:\r\n**ValueError: Incorrect mode (<class 'float'>) supplied for input type <class 'numpy.dtype'>. Should be L**\r\n\r\nThe *torchvision* transform **ToPILImage(mode=float)** will always break for input of type *torch.FloatTensor*\r\n**ToPILImage()** uses the internal function **to_pil_image** found in *torchvision/transforms/functional.py*\r\n\r\nIn *https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py*:\r\nLine 104 checks if the input is of type *torch.FloatTensor*\r\nIf so, line 105 scales the input by 255, but then converts it to **byte**\r\nLines 113-127 check if the user-specified mode is the expected mode, and throws an error if not.\r\nThe expected mode is assigned by **npimg.dtype**, which return **np.uint8** if line 105 is executed \r\n\r\nI believe the bug can be fixed by changing line 105 from:\r\n**pic = pic.mul(255).byte()**\r\n-to-\r\n**pic = pic.mul(255)**\r\n\r\n**Test script:**\r\nimport torch\r\nfrom torchvision import transforms\r\na = torch.FloatTensor(1,64,64)\r\ntform = transforms.Compose([transforms.ToPILImage(mode=float)])\r\nb = tform(a)\r\n\r\nPlease let me know if I am in error. \r\nThank you.\r\n\r\n"}