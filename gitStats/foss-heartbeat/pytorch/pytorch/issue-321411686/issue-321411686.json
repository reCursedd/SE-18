{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7405", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7405/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7405/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7405/events", "html_url": "https://github.com/pytorch/pytorch/issues/7405", "id": 321411686, "node_id": "MDU6SXNzdWUzMjE0MTE2ODY=", "number": 7405, "title": "arguments are located on different GPUs ", "user": {"login": "lan2720", "id": 5330101, "node_id": "MDQ6VXNlcjUzMzAxMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5330101?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lan2720", "html_url": "https://github.com/lan2720", "followers_url": "https://api.github.com/users/lan2720/followers", "following_url": "https://api.github.com/users/lan2720/following{/other_user}", "gists_url": "https://api.github.com/users/lan2720/gists{/gist_id}", "starred_url": "https://api.github.com/users/lan2720/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lan2720/subscriptions", "organizations_url": "https://api.github.com/users/lan2720/orgs", "repos_url": "https://api.github.com/users/lan2720/repos", "events_url": "https://api.github.com/users/lan2720/events{/privacy}", "received_events_url": "https://api.github.com/users/lan2720/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-09T02:48:13Z", "updated_at": "2018-05-15T04:20:43Z", "closed_at": "2018-05-09T08:33:52Z", "author_association": "NONE", "body_html": "<p>Hi, I trained a model and when it was early stopping, the train part was finished and test part started.</p>\n<p>But here was a runtime error when I used the gpuid != 0 (when gpuid=0, it's ok).</p>\n<pre><code>epoch: 52 / dev_acc: 0.6304668304668305\nearly stopping by dev_acc!\nmax dev acc: 0.667027027027027\nA model is saved successfully as /home/saved_models/dev_acc_0.667027027027027.pkl!\n====================TRAINING FINISHED====================\n====================TESTING STARTED====================\nTraceback (most recent call last):\n  File \"difficulty.py\", line 460, in &lt;module&gt;\n    main()\n  File \"difficulty.py\", line 451, in main\n    test_acc = test(args, test_data, model, True)\n  File \"difficulty.py\", line 413, in test\n    batch_pred_cuda = model(paragraph, sentence, answer, paragraph_mask, sentence_mask, answer_mask, length, oov)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/data1/jiananwang/difficulty/model.py\", line 384, in forward\n    para = self.embedding(paragraph).view(-1, self.para_limit*self.sent_limit, self.word_dim) #[B, PL*SL, D]\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 108, in forward\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/functional.py\", line 1076, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: arguments are located on different GPUs at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generic/THCTensorIndex.cu:563\n</code></pre>\n<p>The nn.Embedding Layer is embedded in the overall model, but its initial weights are loaded from a numpy array.<br>\nCould anyone provide some clue to resolve it?</p>", "body_text": "Hi, I trained a model and when it was early stopping, the train part was finished and test part started.\nBut here was a runtime error when I used the gpuid != 0 (when gpuid=0, it's ok).\nepoch: 52 / dev_acc: 0.6304668304668305\nearly stopping by dev_acc!\nmax dev acc: 0.667027027027027\nA model is saved successfully as /home/saved_models/dev_acc_0.667027027027027.pkl!\n====================TRAINING FINISHED====================\n====================TESTING STARTED====================\nTraceback (most recent call last):\n  File \"difficulty.py\", line 460, in <module>\n    main()\n  File \"difficulty.py\", line 451, in main\n    test_acc = test(args, test_data, model, True)\n  File \"difficulty.py\", line 413, in test\n    batch_pred_cuda = model(paragraph, sentence, answer, paragraph_mask, sentence_mask, answer_mask, length, oov)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/data1/jiananwang/difficulty/model.py\", line 384, in forward\n    para = self.embedding(paragraph).view(-1, self.para_limit*self.sent_limit, self.word_dim) #[B, PL*SL, D]\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 108, in forward\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/functional.py\", line 1076, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: arguments are located on different GPUs at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generic/THCTensorIndex.cu:563\n\nThe nn.Embedding Layer is embedded in the overall model, but its initial weights are loaded from a numpy array.\nCould anyone provide some clue to resolve it?", "body": "Hi, I trained a model and when it was early stopping, the train part was finished and test part started.\r\n\r\nBut here was a runtime error when I used the gpuid != 0 (when gpuid=0, it's ok).\r\n```\r\nepoch: 52 / dev_acc: 0.6304668304668305\r\nearly stopping by dev_acc!\r\nmax dev acc: 0.667027027027027\r\nA model is saved successfully as /home/saved_models/dev_acc_0.667027027027027.pkl!\r\n====================TRAINING FINISHED====================\r\n====================TESTING STARTED====================\r\nTraceback (most recent call last):\r\n  File \"difficulty.py\", line 460, in <module>\r\n    main()\r\n  File \"difficulty.py\", line 451, in main\r\n    test_acc = test(args, test_data, model, True)\r\n  File \"difficulty.py\", line 413, in test\r\n    batch_pred_cuda = model(paragraph, sentence, answer, paragraph_mask, sentence_mask, answer_mask, length, oov)\r\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/data1/jiananwang/difficulty/model.py\", line 384, in forward\r\n    para = self.embedding(paragraph).view(-1, self.para_limit*self.sent_limit, self.word_dim) #[B, PL*SL, D]\r\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 108, in forward\r\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\r\n  File \"/home/jiananwang/anaconda2/envs/daqg/lib/python3.6/site-packages/torch/nn/functional.py\", line 1076, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: arguments are located on different GPUs at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/generic/THCTensorIndex.cu:563\r\n```\r\nThe nn.Embedding Layer is embedded in the overall model, but its initial weights are loaded from a numpy array. \r\nCould anyone provide some clue to resolve it?"}