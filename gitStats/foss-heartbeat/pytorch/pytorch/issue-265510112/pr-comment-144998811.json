{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144998811", "pull_request_review_id": 69734012, "id": 144998811, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDk5ODgxMQ==", "diff_hunk": "@@ -19,27 +19,72 @@ def __str__(self):\n     def table(self, sort_by=None):\n         return build_table(self, sort_by)\n \n+    def export_chrome_trace(self, path):\n+        \"\"\"Exports an EventList as a Chrome tracing tools file.\n+\n+        The checkpoint can be later loaded and inspected under ``chrome://tracing`` URL.\n+\n+        Arguments:\n+            path (str): Path where the trace will be written.\n+        \"\"\"\n+        import json\n+        with open(path, 'w') as f:\n+            chrome_events = []\n+            for evt in self:\n+                chrome_events.append(dict(\n+                    name=evt.name,\n+                    ph='X',\n+                    ts=evt.start / 1000,\n+                    dur=evt.cpu_time_total / 1000,\n+                    tid='Autograd functions',\n+                    pid='Autograd functions',\n+                    args={},\n+                ))\n+            json.dump(chrome_events, f)\n+\n+    def key_averages(self):\n+        \"\"\"Averages all function events over their keys.\n+\n+        Returns:\n+            An EventList containing FunctionEventAvg objects.\n+        \"\"\"\n+        stats = defaultdict(FunctionEventAvg)\n+        for evt in self:\n+            stats[evt.key] += evt\n+        return EventList(stats.values())\n+\n+    def total_average(self):\n+        \"\"\"Averages all events.\n+\n+        Returns:\n+            A FunctionEventAvg object.\n+        \"\"\"\n+        total_stat = FunctionEventAvg()\n+        for evt in self:\n+            total_stat += evt\n+            total_stat.key = None\n+        total_stat.key = 'Total'\n+        return total_stat\n+\n \n class profile(object):\n     \"\"\"Context manager that manages autograd profiler state and holds a summary of results.\n \n     Arguments:\n-        use_nvprof (bool, optional): If True, uses nvprof (might incur high overhead and\n-            assumes that the whole process is running inside nvprof), otherwise uses a custom\n-            CPU-only profiler (with negligible overhead). Default: False.\n-        trace_path (str, optional): A path of the CUDA checkpoint. If specified, it will be left\n-            unmodified after profiling finishes, so it can be opened and inspected in nvvp. Otherwise\n-            it will be created in a temporary directory and removed after reading the results.\n         enabled (bool, optional): Setting this to False makes this context manager a no-op.\n             Default: True.\n \n+    .. warning:\n+        This context managers should not be called recursively, i.e. at most one\n+        instance should be enabled at any given time.\n+\n     Example:\n         >>> x = Variable(torch.randn(1, 1), requires_grad=True)\n         >>> with torch.autograd.profiler.profile() as prof:\n         ...     y = x ** 2\n         ...     y.backward()\n         >>> # NOTE: some columns were removed for brevity\n-        ... print(prof.key_averages())\n+        ... print(prof)", "path": "torch/autograd/profiler.py", "position": 76, "original_position": 76, "commit_id": "39ad68ce8734cb966e3271441e148846aab325d4", "original_commit_id": "39ad68ce8734cb966e3271441e148846aab325d4", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Any particular reason this change was reverted?", "created_at": "2017-10-16T23:53:44Z", "updated_at": "2018-11-23T15:35:20Z", "html_url": "https://github.com/pytorch/pytorch/pull/3120#discussion_r144998811", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3120", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144998811"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3120#discussion_r144998811"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3120"}}, "body_html": "<p>Any particular reason this change was reverted?</p>", "body_text": "Any particular reason this change was reverted?"}