{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/338974690", "html_url": "https://github.com/pytorch/pytorch/issues/3185#issuecomment-338974690", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3185", "id": 338974690, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODk3NDY5MA==", "user": {"login": "jwvdm", "id": 1158561, "node_id": "MDQ6VXNlcjExNTg1NjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1158561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwvdm", "html_url": "https://github.com/jwvdm", "followers_url": "https://api.github.com/users/jwvdm/followers", "following_url": "https://api.github.com/users/jwvdm/following{/other_user}", "gists_url": "https://api.github.com/users/jwvdm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwvdm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwvdm/subscriptions", "organizations_url": "https://api.github.com/users/jwvdm/orgs", "repos_url": "https://api.github.com/users/jwvdm/repos", "events_url": "https://api.github.com/users/jwvdm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwvdm/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-24T12:34:33Z", "updated_at": "2017-10-24T12:34:33Z", "author_association": "NONE", "body_html": "<p>We've been working on a library for deep generative models that extends PyTorch. We have currently written implementations for the following distributions (and have been adding distributions almost daily)</p>\n<ul>\n<li>Normal</li>\n<li>Concrete (a.k.a. Gumbel-Softmax)</li>\n<li>Exponential</li>\n<li>Laplace</li>\n<li>Logistic</li>\n<li>Uniform</li>\n</ul>\n<p>Note that all of these distributions are \"reparameterized\" distributions for which sampled values are differentiable.</p>\n<p>We wrote our distribution API before <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a>'s changes last week. In particular, we implement a a sample method <code>Distribution.sample(self, *sizes)</code> that accepts an optional arguments to draw multiple samples.</p>\n<p>We'd be happy to prepare a pull request.</p>", "body_text": "We've been working on a library for deep generative models that extends PyTorch. We have currently written implementations for the following distributions (and have been adding distributions almost daily)\n\nNormal\nConcrete (a.k.a. Gumbel-Softmax)\nExponential\nLaplace\nLogistic\nUniform\n\nNote that all of these distributions are \"reparameterized\" distributions for which sampled values are differentiable.\nWe wrote our distribution API before @colesbury's changes last week. In particular, we implement a a sample method Distribution.sample(self, *sizes) that accepts an optional arguments to draw multiple samples.\nWe'd be happy to prepare a pull request.", "body": "We've been working on a library for deep generative models that extends PyTorch. We have currently written implementations for the following distributions (and have been adding distributions almost daily)\r\n\r\n- Normal \r\n- Concrete (a.k.a. Gumbel-Softmax)\r\n- Exponential\r\n- Laplace\r\n- Logistic\r\n- Uniform\r\n\r\nNote that all of these distributions are \"reparameterized\" distributions for which sampled values are differentiable. \r\n\r\nWe wrote our distribution API before @colesbury's changes last week. In particular, we implement a a sample method `Distribution.sample(self, *sizes)` that accepts an optional arguments to draw multiple samples. \r\n\r\nWe'd be happy to prepare a pull request. "}