{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/289124536", "html_url": "https://github.com/pytorch/pytorch/pull/857#issuecomment-289124536", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/857", "id": 289124536, "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTEyNDUzNg==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-24T19:40:24Z", "updated_at": "2017-03-24T19:40:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Depends on the sizes. Also, once extra overhead of a dozen getDevice/setDevice for every pointwise kernel is taken care of, addr_ can be better. But overall you are right, for medium to small sizes, expand_as is faster than addr_ (expand_as + add is a single pointwise apply kernel, addr is create tensor (for some reason there is memcopy there), fill (overhead of starting a pointwise kernel), call cublas). Even though cublas ger kernel is usually faster than torch's pointwiseApply, when all overheads are taken into account expand_as + add wins.</p>", "body_text": "Depends on the sizes. Also, once extra overhead of a dozen getDevice/setDevice for every pointwise kernel is taken care of, addr_ can be better. But overall you are right, for medium to small sizes, expand_as is faster than addr_ (expand_as + add is a single pointwise apply kernel, addr is create tensor (for some reason there is memcopy there), fill (overhead of starting a pointwise kernel), call cublas). Even though cublas ger kernel is usually faster than torch's pointwiseApply, when all overheads are taken into account expand_as + add wins.", "body": "Depends on the sizes. Also, once extra overhead of a dozen getDevice/setDevice for every pointwise kernel is taken care of, addr_ can be better. But overall you are right, for medium to small sizes, expand_as is faster than addr_ (expand_as + add is a single pointwise apply kernel, addr is create tensor (for some reason there is memcopy there), fill (overhead of starting a pointwise kernel), call cublas). Even though cublas ger kernel is usually faster than torch's pointwiseApply, when all overheads are taken into account expand_as + add wins. "}