{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/417423153", "html_url": "https://github.com/pytorch/pytorch/issues/8054#issuecomment-417423153", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8054", "id": 417423153, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNzQyMzE1Mw==", "user": {"login": "0wu", "id": 13663916, "node_id": "MDQ6VXNlcjEzNjYzOTE2", "avatar_url": "https://avatars2.githubusercontent.com/u/13663916?v=4", "gravatar_id": "", "url": "https://api.github.com/users/0wu", "html_url": "https://github.com/0wu", "followers_url": "https://api.github.com/users/0wu/followers", "following_url": "https://api.github.com/users/0wu/following{/other_user}", "gists_url": "https://api.github.com/users/0wu/gists{/gist_id}", "starred_url": "https://api.github.com/users/0wu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/0wu/subscriptions", "organizations_url": "https://api.github.com/users/0wu/orgs", "repos_url": "https://api.github.com/users/0wu/repos", "events_url": "https://api.github.com/users/0wu/events{/privacy}", "received_events_url": "https://api.github.com/users/0wu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-30T18:34:37Z", "updated_at": "2018-08-30T18:34:37Z", "author_association": "NONE", "body_html": "<p>There are two ways to implement this.<br>\n(1) Add an option in pytorch export routine to prefer static shape output.<br>\n(2) Add a post export ONNX optimization pass to infer shape from input+onnx model and generate a static-shaped model from there.</p>\n<p>(1) is probably easier to implement while (2) is more flexible and the same optimization code and apply to model exported from other frameworks.</p>\n<p>I used ONNX export to generate inference code running on edge hardware, while in most cases, a static-shaped model is preferred to dynamic one.</p>", "body_text": "There are two ways to implement this.\n(1) Add an option in pytorch export routine to prefer static shape output.\n(2) Add a post export ONNX optimization pass to infer shape from input+onnx model and generate a static-shaped model from there.\n(1) is probably easier to implement while (2) is more flexible and the same optimization code and apply to model exported from other frameworks.\nI used ONNX export to generate inference code running on edge hardware, while in most cases, a static-shaped model is preferred to dynamic one.", "body": "There are two ways to implement this.\r\n(1) Add an option in pytorch export routine to prefer static shape output.\r\n(2) Add a post export ONNX optimization pass to infer shape from input+onnx model and generate a static-shaped model from there. \r\n\r\n(1) is probably easier to implement while (2) is more flexible and the same optimization code and apply to model exported from other frameworks.\r\n\r\nI used ONNX export to generate inference code running on edge hardware, while in most cases, a static-shaped model is preferred to dynamic one."}