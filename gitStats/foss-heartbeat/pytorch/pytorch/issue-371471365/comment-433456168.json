{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/433456168", "html_url": "https://github.com/pytorch/pytorch/issues/12817#issuecomment-433456168", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12817", "id": 433456168, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzQ1NjE2OA==", "user": {"login": "jatentaki", "id": 22394841, "node_id": "MDQ6VXNlcjIyMzk0ODQx", "avatar_url": "https://avatars1.githubusercontent.com/u/22394841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jatentaki", "html_url": "https://github.com/jatentaki", "followers_url": "https://api.github.com/users/jatentaki/followers", "following_url": "https://api.github.com/users/jatentaki/following{/other_user}", "gists_url": "https://api.github.com/users/jatentaki/gists{/gist_id}", "starred_url": "https://api.github.com/users/jatentaki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jatentaki/subscriptions", "organizations_url": "https://api.github.com/users/jatentaki/orgs", "repos_url": "https://api.github.com/users/jatentaki/repos", "events_url": "https://api.github.com/users/jatentaki/events{/privacy}", "received_events_url": "https://api.github.com/users/jatentaki/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-26T15:55:47Z", "updated_at": "2018-10-26T15:56:39Z", "author_association": "NONE", "body_html": "<p>Sorry for taking so long. Here it is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(Model, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n\n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> torch.nn.Conv1d(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">4</span>)\n        <span class=\"pl-c1\">self</span>.conv2 <span class=\"pl-k\">=</span> torch.nn.Conv1d(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">3</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        y <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv1(x)\n        y <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv2(y)\n\n        <span class=\"pl-k\">return</span> y\n\nm <span class=\"pl-k\">=</span> Model().cuda()\ngood <span class=\"pl-k\">=</span> torch.randn((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">10</span>)).cuda()\nsmall <span class=\"pl-k\">=</span> torch.randn((<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>)).cuda()\n\ntraced <span class=\"pl-k\">=</span> torch.jit.trace(m, good)\n\ntraced(small)</pre></div>\n<p>in this case, it's just that the <code>small</code> input is too short for the 2nd convolution to work with (due to no padding).</p>", "body_text": "Sorry for taking so long. Here it is:\nimport torch\n\nclass Model(torch.nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        self.conv1 = torch.nn.Conv1d(5, 10, 4)\n        self.conv2 = torch.nn.Conv1d(10, 5, 3)\n\n    def forward(self, x):\n        y = self.conv1(x)\n        y = self.conv2(y)\n\n        return y\n\nm = Model().cuda()\ngood = torch.randn((1, 5, 10)).cuda()\nsmall = torch.randn((1, 5, 5)).cuda()\n\ntraced = torch.jit.trace(m, good)\n\ntraced(small)\nin this case, it's just that the small input is too short for the 2nd convolution to work with (due to no padding).", "body": "Sorry for taking so long. Here it is:\r\n\r\n```python\r\nimport torch\r\n\r\nclass Model(torch.nn.Module):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n\r\n        self.conv1 = torch.nn.Conv1d(5, 10, 4)\r\n        self.conv2 = torch.nn.Conv1d(10, 5, 3)\r\n\r\n    def forward(self, x):\r\n        y = self.conv1(x)\r\n        y = self.conv2(y)\r\n\r\n        return y\r\n\r\nm = Model().cuda()\r\ngood = torch.randn((1, 5, 10)).cuda()\r\nsmall = torch.randn((1, 5, 5)).cuda()\r\n\r\ntraced = torch.jit.trace(m, good)\r\n\r\ntraced(small)\r\n```\r\n\r\nin this case, it's just that the `small` input is too short for the 2nd convolution to work with (due to no padding)."}