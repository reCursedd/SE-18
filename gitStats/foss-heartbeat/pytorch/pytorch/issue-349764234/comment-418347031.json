{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/418347031", "html_url": "https://github.com/pytorch/pytorch/issues/10442#issuecomment-418347031", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10442", "id": 418347031, "node_id": "MDEyOklzc3VlQ29tbWVudDQxODM0NzAzMQ==", "user": {"login": "avmgithub", "id": 9083746, "node_id": "MDQ6VXNlcjkwODM3NDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9083746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avmgithub", "html_url": "https://github.com/avmgithub", "followers_url": "https://api.github.com/users/avmgithub/followers", "following_url": "https://api.github.com/users/avmgithub/following{/other_user}", "gists_url": "https://api.github.com/users/avmgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/avmgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avmgithub/subscriptions", "organizations_url": "https://api.github.com/users/avmgithub/orgs", "repos_url": "https://api.github.com/users/avmgithub/repos", "events_url": "https://api.github.com/users/avmgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/avmgithub/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-04T12:22:42Z", "updated_at": "2018-09-04T12:22:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I don't know if that is the problem either.</p>\n<p>In my experience , during compile , link time,  when a library is missing, you will specifically see in your logs that another library depending on it will complain of undefined symbols.  You can usually google those undefined symbols and results may point you to the missing library itself.  For example in your more detailed log the line: /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0: undefined reference to `_gfortran_etime@GFORTRAN_7'   seems to say you are missing a library that could be related to fortran library.   The libopenblas seems to be linked with a gfortran library and it cannot find it.   If you have that gfortran lib in your conda environment then you may want to add  /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/  to your LD_LIBRARY_PATH during build time and see if it makes the errors disappear.  You can also do an ldd /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0  to see if it finds all its library requirements.</p>\n<p>I have several CUDA versions in my systems also  (9.1 and 9.2)  and the pytorch scripts build with where the /usr/local/cuda directory is linked with.</p>\n<p>If you try and follow the reference script I pointed to regarding the library and package requirements ,  you should be able to at least get to a point where pytorch is building for you.   Then from there you can experiment with some other configuration (like libraries from conda or other versions etc).</p>\n<p>Another way would be to use a docker container if that is available in your environment.</p>", "body_text": "I don't know if that is the problem either.\nIn my experience , during compile , link time,  when a library is missing, you will specifically see in your logs that another library depending on it will complain of undefined symbols.  You can usually google those undefined symbols and results may point you to the missing library itself.  For example in your more detailed log the line: /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0: undefined reference to `_gfortran_etime@GFORTRAN_7'   seems to say you are missing a library that could be related to fortran library.   The libopenblas seems to be linked with a gfortran library and it cannot find it.   If you have that gfortran lib in your conda environment then you may want to add  /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/  to your LD_LIBRARY_PATH during build time and see if it makes the errors disappear.  You can also do an ldd /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0  to see if it finds all its library requirements.\nI have several CUDA versions in my systems also  (9.1 and 9.2)  and the pytorch scripts build with where the /usr/local/cuda directory is linked with.\nIf you try and follow the reference script I pointed to regarding the library and package requirements ,  you should be able to at least get to a point where pytorch is building for you.   Then from there you can experiment with some other configuration (like libraries from conda or other versions etc).\nAnother way would be to use a docker container if that is available in your environment.", "body": "I don't know if that is the problem either.\r\n\r\nIn my experience , during compile , link time,  when a library is missing, you will specifically see in your logs that another library depending on it will complain of undefined symbols.  You can usually google those undefined symbols and results may point you to the missing library itself.  For example in your more detailed log the line: /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0: undefined reference to `_gfortran_etime@GFORTRAN_7'   seems to say you are missing a library that could be related to fortran library.   The libopenblas seems to be linked with a gfortran library and it cannot find it.   If you have that gfortran lib in your conda environment then you may want to add  /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/  to your LD_LIBRARY_PATH during build time and see if it makes the errors disappear.  You can also do an ldd /autofs/nccs-svm1_home1/shubhankar/miniconda3/envs/pytorch/lib/libopenblas.so.0  to see if it finds all its library requirements.        \r\n\r\nI have several CUDA versions in my systems also  (9.1 and 9.2)  and the pytorch scripts build with where the /usr/local/cuda directory is linked with.   \r\n\r\nIf you try and follow the reference script I pointed to regarding the library and package requirements ,  you should be able to at least get to a point where pytorch is building for you.   Then from there you can experiment with some other configuration (like libraries from conda or other versions etc).\r\n\r\nAnother way would be to use a docker container if that is available in your environment."}