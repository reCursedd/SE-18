{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166431155", "pull_request_review_id": 94491362, "id": 166431155, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NjQzMTE1NQ==", "diff_hunk": "@@ -188,6 +197,34 @@ def train(self, mode=True):\n         for module in self._module_copies[1:]:\n             module.train(mode)\n \n+    def _dist_broadcast_coalesced(self, tensors, buffer_size):\n+        \"\"\"\n+        Broadcast a sequence of tensors to the default group from rank 0.\n+        Small tensors are first coalesced into a buffer to reduce the number of\n+        broadcasts.\n+\n+        tensors (sequence): tensors to broadcast. Each tensor needs to be on the\n+                            same GPU.\n+        buffer_size (int): maximum size of the buffer for coalescing\n+        \"\"\"\n+        tensors_bucket = []\n+        # To init the first bucket right away\n+        cur_bucket_size = buffer_size\n+        for tensor in tensors:\n+            if cur_bucket_size >= buffer_size:\n+                tensors_bucket.append([])\n+                cur_bucket_size = 0\n+            tensors_bucket[-1].append(tensor)\n+            cur_bucket_size += tensor.numel() * tensor.element_size()", "path": "torch/nn/parallel/distributed.py", "position": null, "original_position": 54, "commit_id": "93db5e9ef08374d7f28f0cf3e15422199ab752a1", "original_commit_id": "4cc16b4fbb2c29fb9231eb5ae102b4f378300cbc", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "There's `torch._utils._take_tensors` that will do most of these things for you, including handling different types, which is not handled here. Please use that. To see an example look at how `broadcast_coalesced` [used to be implemented](https://github.com/pytorch/pytorch/blob/fa5efab669d68f2931292176d3376e3519bdd0b4/torch/cuda/comm.py#L32-L70).", "created_at": "2018-02-06T20:21:44Z", "updated_at": "2018-11-23T15:39:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/4978#discussion_r166431155", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4978", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166431155"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4978#discussion_r166431155"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4978"}}, "body_html": "<p>There's <code>torch._utils._take_tensors</code> that will do most of these things for you, including handling different types, which is not handled here. Please use that. To see an example look at how <code>broadcast_coalesced</code> <a href=\"https://github.com/pytorch/pytorch/blob/fa5efab669d68f2931292176d3376e3519bdd0b4/torch/cuda/comm.py#L32-L70\">used to be implemented</a>.</p>", "body_text": "There's torch._utils._take_tensors that will do most of these things for you, including handling different types, which is not handled here. Please use that. To see an example look at how broadcast_coalesced used to be implemented."}