{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/404989053", "html_url": "https://github.com/pytorch/pytorch/issues/9413#issuecomment-404989053", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9413", "id": 404989053, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDk4OTA1Mw==", "user": {"login": "zasdfgbnm", "id": 1032377, "node_id": "MDQ6VXNlcjEwMzIzNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1032377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zasdfgbnm", "html_url": "https://github.com/zasdfgbnm", "followers_url": "https://api.github.com/users/zasdfgbnm/followers", "following_url": "https://api.github.com/users/zasdfgbnm/following{/other_user}", "gists_url": "https://api.github.com/users/zasdfgbnm/gists{/gist_id}", "starred_url": "https://api.github.com/users/zasdfgbnm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zasdfgbnm/subscriptions", "organizations_url": "https://api.github.com/users/zasdfgbnm/orgs", "repos_url": "https://api.github.com/users/zasdfgbnm/repos", "events_url": "https://api.github.com/users/zasdfgbnm/events{/privacy}", "received_events_url": "https://api.github.com/users/zasdfgbnm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-14T01:27:28Z", "updated_at": "2018-07-14T02:51:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a><br>\nThe special case where the first argument is a scalar might be most natural because it behaves just like <code>list.index</code>, and similar to <code>torch.nonzero</code>, that is:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.tensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>,<span class=\"pl-c1\">7</span>,<span class=\"pl-c1\">8</span>])\ntorch.find(<span class=\"pl-c1\">4</span>, a)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> is the same as</span>\n[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">5</span>,<span class=\"pl-c1\">6</span>,<span class=\"pl-c1\">7</span>,<span class=\"pl-c1\">8</span>].index(<span class=\"pl-c1\">4</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> is the same as</span>\n(a<span class=\"pl-k\">==</span><span class=\"pl-c1\">4</span>).nonzero()[<span class=\"pl-c1\">0</span>].squeeze()</pre></div>\n<p>If the first argument is not scalar, you can think of it as <code>list.index</code> \"in batch\"</p>\n<p>This can also be used to compute the reverse index in some case, such as<br>\n1D LongTensor --&gt;(sort, mask_select, index_select, expand, repeat, meshgrid,  #etc...)* --&gt; a new LongTensor<br>\nand I want to compute where each element in the new tensor comes from the original tensor.</p>\n<p>The original requirement comes from an application I'm developing. I have a <code>LongTensor</code> storing a list of all chemical symbols (carbon, oxygen, etc.) supported by my application, and another <code>LongTensor</code> storing all chemical symbols that exists in user's input. I want to get the index of one thing in the other. I used to be converting it to python lists and work on that, but now I want to <code>@script</code> my function, and these list operations starts to become trouble. So I'm seeking for a neat pytorch solution.</p>", "body_text": "@gchanan\nThe special case where the first argument is a scalar might be most natural because it behaves just like list.index, and similar to torch.nonzero, that is:\na = torch.tensor([1,2,3,4,5,6,7,8])\ntorch.find(4, a)\n# is the same as\n[1,2,3,4,5,6,7,8].index(4)\n# is the same as\n(a==4).nonzero()[0].squeeze()\nIf the first argument is not scalar, you can think of it as list.index \"in batch\"\nThis can also be used to compute the reverse index in some case, such as\n1D LongTensor -->(sort, mask_select, index_select, expand, repeat, meshgrid,  #etc...)* --> a new LongTensor\nand I want to compute where each element in the new tensor comes from the original tensor.\nThe original requirement comes from an application I'm developing. I have a LongTensor storing a list of all chemical symbols (carbon, oxygen, etc.) supported by my application, and another LongTensor storing all chemical symbols that exists in user's input. I want to get the index of one thing in the other. I used to be converting it to python lists and work on that, but now I want to @script my function, and these list operations starts to become trouble. So I'm seeking for a neat pytorch solution.", "body": "@gchanan \r\nThe special case where the first argument is a scalar might be most natural because it behaves just like `list.index`, and similar to `torch.nonzero`, that is:\r\n```python\r\na = torch.tensor([1,2,3,4,5,6,7,8])\r\ntorch.find(4, a)\r\n# is the same as\r\n[1,2,3,4,5,6,7,8].index(4)\r\n# is the same as\r\n(a==4).nonzero()[0].squeeze()\r\n```\r\nIf the first argument is not scalar, you can think of it as `list.index` \"in batch\"\r\n\r\nThis can also be used to compute the reverse index in some case, such as\r\n1D LongTensor -->(sort, mask_select, index_select, expand, repeat, meshgrid,  #etc...)* --> a new LongTensor\r\nand I want to compute where each element in the new tensor comes from the original tensor.\r\n\r\nThe original requirement comes from an application I'm developing. I have a `LongTensor` storing a list of all chemical symbols (carbon, oxygen, etc.) supported by my application, and another `LongTensor` storing all chemical symbols that exists in user's input. I want to get the index of one thing in the other. I used to be converting it to python lists and work on that, but now I want to `@script` my function, and these list operations starts to become trouble. So I'm seeking for a neat pytorch solution."}