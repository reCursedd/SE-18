{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/139431182", "pull_request_review_id": 63361364, "id": 139431182, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzOTQzMTE4Mg==", "diff_hunk": "@@ -226,43 +226,35 @@ def forward(ctx, input, p=2, dim=None, keepdim=None):\n         ctx.keepdim = False if keepdim is None else keepdim\n \n         if dim is None:\n-            ctx.norm = input.norm(p)\n-            ctx.save_for_backward(input)\n-            return input.new((ctx.norm,))\n+            norm = input.norm(p)\n+            output = input.new((norm,))\n         else:\n             if keepdim is not None:\n                 output = input.norm(p, dim, keepdim=keepdim)\n             else:\n                 output = input.norm(p, dim)\n-            ctx.save_for_backward(input, output)\n-            return output\n+        ctx.save_for_backward(input, output)\n+        return output\n \n     @staticmethod\n     def backward(ctx, grad_output):\n-        if ctx.dim is None:\n-            input, = ctx.saved_variables\n-            if ctx.p == 2:\n-                scale_v = (grad_output / ctx.norm).expand_as(input)\n-                return input.mul(scale_v), None, None, None\n-            else:\n-                pow = input.abs().pow(ctx.p - 2)\n-                scale_v = (grad_output / ctx.norm ** (ctx.p - 1)).expand_as(input)\n-                return input.mul(pow).mul(scale_v), None, None, None\n+        input, output = ctx.saved_variables\n+        if ctx.dim is not None and ctx.keepdim is False and input.dim() != 1:\n+            grad_output = grad_output.unsqueeze(ctx.dim)\n+            output = output.unsqueeze(ctx.dim)\n+\n+        if ctx.p == 2:\n+            grad_input = input.mul(grad_output).div(output)\n         else:\n-            input, output = ctx.saved_variables\n+            input_pow = input.abs().pow(ctx.p - 2)\n+            output_pow = output.pow(ctx.p - 1)\n+            grad_input = input.mul(input_pow).mul(grad_output).div(output_pow)\n \n-            if ctx.keepdim is False and input.dim() != 1:\n-                grad_output = grad_output.unsqueeze(ctx.dim)\n-                output = output.unsqueeze(ctx.dim)\n+        # Special case at 0 where we return a subgradient containing 0\n+        zero_mask = (output == 0).type_as(grad_input)\n+        grad_input.mul(1 - zero_mask)", "path": "torch/autograd/_functions/reduce.py", "position": null, "original_position": 48, "commit_id": "cf37ec0fce1c30260ff87a91b618951236452e1a", "original_commit_id": "d17b84f3a30b6af5f220ef8fc77fe20b9c083627", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "body": "Yes, my bad, the test was wrong... Thanks for spotting that.", "created_at": "2017-09-18T14:03:19Z", "updated_at": "2018-11-23T15:34:38Z", "html_url": "https://github.com/pytorch/pytorch/pull/2775#discussion_r139431182", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2775", "author_association": "COLLABORATOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/139431182"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2775#discussion_r139431182"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2775"}}, "body_html": "<p>Yes, my bad, the test was wrong... Thanks for spotting that.</p>", "body_text": "Yes, my bad, the test was wrong... Thanks for spotting that.", "in_reply_to_id": 139425497}