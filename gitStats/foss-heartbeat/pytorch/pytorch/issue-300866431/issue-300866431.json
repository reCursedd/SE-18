{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5449", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5449/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5449/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5449/events", "html_url": "https://github.com/pytorch/pytorch/pull/5449", "id": 300866431, "node_id": "MDExOlB1bGxSZXF1ZXN0MTcxODM5MzA1", "number": 5449, "title": "Add source information to IR nodes", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-02-28T02:22:10Z", "updated_at": "2018-11-23T15:40:10Z", "closed_at": "2018-03-01T01:06:19Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5449", "html_url": "https://github.com/pytorch/pytorch/pull/5449", "diff_url": "https://github.com/pytorch/pytorch/pull/5449.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5449.patch"}, "body_html": "<p>SourceRange information from the script is now propagated to IR nodes.<br>\nThis information is only used in two places now: the interpreter<br>\nwraps errors that occur when an instruction executes and shape<br>\npropagation now reports errors on the line where it fails:</p>\n<pre><code>Traceback (most recent call last):\n  File \"test/test_jit.py\", line 1655, in test_script_error\n    bar(Variable(torch.rand(10), requires_grad=True), Variable(torch.rand(9), requires_grad=True))\nRuntimeError:\nThe size of tensor a (10) must match the size of tensor b (9) at non-singleton dimension 0:\n@torch.jit.script\ndef bar(c, b):\n    return c / b\n           ~~~~~ &lt;--- HERE\n</code></pre>\n<p>In the future, shape propagation should really not report any size<br>\nerrors and instead just not propagate shapes and let the actual<br>\nexecution fail. However, this is hard to accomplish while we still<br>\ndepend on running the op to do shape propagation. While we still do this, reporting the error at the right source location is better than just letting the assertion fail.</p>", "body_text": "SourceRange information from the script is now propagated to IR nodes.\nThis information is only used in two places now: the interpreter\nwraps errors that occur when an instruction executes and shape\npropagation now reports errors on the line where it fails:\nTraceback (most recent call last):\n  File \"test/test_jit.py\", line 1655, in test_script_error\n    bar(Variable(torch.rand(10), requires_grad=True), Variable(torch.rand(9), requires_grad=True))\nRuntimeError:\nThe size of tensor a (10) must match the size of tensor b (9) at non-singleton dimension 0:\n@torch.jit.script\ndef bar(c, b):\n    return c / b\n           ~~~~~ <--- HERE\n\nIn the future, shape propagation should really not report any size\nerrors and instead just not propagate shapes and let the actual\nexecution fail. However, this is hard to accomplish while we still\ndepend on running the op to do shape propagation. While we still do this, reporting the error at the right source location is better than just letting the assertion fail.", "body": "SourceRange information from the script is now propagated to IR nodes.\r\nThis information is only used in two places now: the interpreter\r\nwraps errors that occur when an instruction executes and shape\r\npropagation now reports errors on the line where it fails:\r\n\r\n    Traceback (most recent call last):\r\n      File \"test/test_jit.py\", line 1655, in test_script_error\r\n        bar(Variable(torch.rand(10), requires_grad=True), Variable(torch.rand(9), requires_grad=True))\r\n    RuntimeError:\r\n    The size of tensor a (10) must match the size of tensor b (9) at non-singleton dimension 0:\r\n    @torch.jit.script\r\n    def bar(c, b):\r\n        return c / b\r\n               ~~~~~ <--- HERE\r\n\r\nIn the future, shape propagation should really not report any size\r\nerrors and instead just not propagate shapes and let the actual\r\nexecution fail. However, this is hard to accomplish while we still\r\ndepend on running the op to do shape propagation. While we still do this, reporting the error at the right source location is better than just letting the assertion fail."}