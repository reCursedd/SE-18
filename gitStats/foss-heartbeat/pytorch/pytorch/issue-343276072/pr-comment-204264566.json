{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204264566", "pull_request_review_id": 139311273, "id": 204264566, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDI2NDU2Ng==", "diff_hunk": "@@ -0,0 +1,159 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/AccumulateType.h\"\n+#include \"ATen/cuda/CUDAApplyUtils.cuh\"\n+#include \"detail/IndexUtils.cuh\"\n+#include \"detail/TensorInfo.cuh\"\n+#include \"curand_kernel.h\"\n+\n+#include <THC/THCGeneral.h>\n+#include <THC/THCTensorRandom.h>\n+#include <THC/THCGenerator.hpp>\n+\n+\n+THCGenerator* THCRandom_getGenerator(THCState* state);\n+\n+namespace at{\n+namespace native{\n+\n+namespace {\n+\n+//due to limitations of philox generator UNROLL has to be 4\n+const int UNROLL = 4;\n+\n+std::pair<uint64_t, uint64_t> next_philox_seed(at::Generator* gen, uint64_t increment) {\n+  auto gen_ = THCRandom_getGenerator(at::globalContext().getTHCState());\n+  uint64_t offset = gen_->state.philox_seed_offset.fetch_add(increment);\n+  return std::make_pair(gen_->state.initial_seed, offset);\n+}\n+\n+\n+template <\n+          typename scalar_t,\n+          typename accscalar_t,\n+          typename IndexType,\n+          int ADims>\n+#if __CUDA_ARCH__ >= 350\n+__launch_bounds__(256,8)\n+#endif\n+__global__ void\n+fused_dropout_kernel(cuda::detail::TensorInfo<scalar_t, IndexType> a,\n+                      cuda::detail::TensorInfo<scalar_t, IndexType> b,\n+                      cuda::detail::TensorInfo<uint8_t, IndexType> c,\n+                      IndexType totalElements, accscalar_t p, std::pair<uint64_t, uint64_t> seeds\n+                      ) {\n+\n+  accscalar_t pinv = accscalar_t(1)/p;\n+  IndexType idx = blockIdx.x * blockDim.x + threadIdx.x;\n+  curandStatePhilox4_32_10_t state;\n+    curand_init(\n+        seeds.first,\n+        idx,\n+        seeds.second,\n+        &state);\n+  IndexType rounded_size = ((totalElements - 1)/(blockDim.x*gridDim.x*UNROLL)+1)*blockDim.x*gridDim.x*UNROLL;\n+  for (IndexType linearIndex = idx;\n+       linearIndex < rounded_size;\n+       linearIndex += gridDim.x * blockDim.x*UNROLL) {\n+//curand_uniform_double was pure evil anyway, not doing what it promises, and there's nothing for halfs, so generate float for everything\n+       float4 rand = curand_uniform4(&state);\n+       scalar_t src[UNROLL];\n+       rand.x = rand.x < p;\n+       rand.y = rand.y < p;\n+       rand.z = rand.z < p;\n+       rand.w = rand.w < p;\n+       for (int ii = 0; ii < UNROLL; ii++) {\n+           IndexType li = linearIndex + blockDim.x * gridDim.x * ii;\n+           if (li < totalElements) {\n+    // Convert `linearIndex` into an offset of `a`\n+               const IndexType aOffset =\n+                   cuda::detail::IndexToOffset<scalar_t, IndexType, ADims>::get(li, a);\n+               src[ii] = a.data[aOffset];\n+           }\n+       }\n+       for (int ii = 0; ii < UNROLL; ii++) {\n+           IndexType li = linearIndex + blockDim.x * gridDim.x * ii;\n+           if (li < totalElements) {\n+    // Convert `linearIndex` into an offset of `b`\n+               const IndexType bOffset =\n+                   cuda::detail::IndexToOffset<scalar_t, IndexType, 1>::get(li, b);\n+               b.data[bOffset] = src[ii]*(&rand.x)[ii]*pinv;\n+               c.data[bOffset] = (uint8_t)(&rand.x)[ii];\n+           }\n+       }\n+       __syncthreads();\n+  }\n+}\n+\n+template<typename scalar_t, typename accscalar_t>\n+void masked_scale_kernel(at::Tensor& ret, const at::Tensor src, const at::Tensor mask, accscalar_t scale){\n+   at::cuda::CUDA_tensor_apply3<scalar_t, scalar_t, uint8_t>(ret, src, mask, [scale]__device__(scalar_t& ret_val, const scalar_t& src_val, const uint8_t mask_val){\n+       ret_val = mask_val * src_val * scale;\n+  });\n+}\n+} //anonymous namespace\n+\n+std::tuple<Tensor,Tensor>\n+fused_dropout_cuda(const Tensor& self, double p, Generator * gen){\n+  Tensor ret = at::empty_like(self);\n+  Tensor mask = self.type().toScalarType(kByte).tensor(self.sizes());\n+  const int64_t nelem = self.numel();\n+  int64_t block_size = 256;\n+  unsigned int blocks_per_sm = at::cuda::getCurrentDeviceProperties()->maxThreadsPerMultiProcessor/block_size;\n+  dim3 dim_block(block_size);\n+  dim3 grid((nelem + block_size -1)/block_size);\n+  grid.x = std::min((unsigned int)at::cuda::getCurrentDeviceProperties()->multiProcessorCount * blocks_per_sm, grid.x);\n+  int64_t nrep = ((nelem - 1)/(block_size*grid.x*UNROLL)+1)*UNROLL;", "path": "aten/src/ATen/native/cuda/Dropout.cu", "position": null, "original_position": 105, "commit_id": "dabffecde0fd4da60bf71575f7e4ccefc2f56d76", "original_commit_id": "54a7d06c9b135b4dc166bd19fd7594aac6c5d779", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "What's this? `nrep` is not super helpful", "created_at": "2018-07-23T01:28:07Z", "updated_at": "2018-11-23T15:47:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/9666#discussion_r204264566", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9666", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204264566"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9666#discussion_r204264566"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9666"}}, "body_html": "<p>What's this? <code>nrep</code> is not super helpful</p>", "body_text": "What's this? nrep is not super helpful"}