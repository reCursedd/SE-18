{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/315786404", "html_url": "https://github.com/pytorch/pytorch/issues/2124#issuecomment-315786404", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2124", "id": 315786404, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTc4NjQwNA==", "user": {"login": "awni", "id": 1542805, "node_id": "MDQ6VXNlcjE1NDI4MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1542805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awni", "html_url": "https://github.com/awni", "followers_url": "https://api.github.com/users/awni/followers", "following_url": "https://api.github.com/users/awni/following{/other_user}", "gists_url": "https://api.github.com/users/awni/gists{/gist_id}", "starred_url": "https://api.github.com/users/awni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awni/subscriptions", "organizations_url": "https://api.github.com/users/awni/orgs", "repos_url": "https://api.github.com/users/awni/repos", "events_url": "https://api.github.com/users/awni/events{/privacy}", "received_events_url": "https://api.github.com/users/awni/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-17T15:18:30Z", "updated_at": "2017-07-17T15:18:30Z", "author_association": "NONE", "body_html": "<p>I think it would be good to have <code>torch.sum</code> behave the same on a plain <code>ByteTensor</code> as it does on a <code>ByteTensor</code> which is wrapped in a <code>Variable</code>. Presumably for the plain <code>ByteTensor</code> the accumulation is done in higher precision whereas for the <code>Variable</code> it seems like it's overflowing.</p>\n<p>If you keep the <code>ByteTensor</code> reduce in higher precision then I think it's fine to have <code>==</code> return a <code>ByteTensor</code> (this also seems more inline with numpy semantics which returns a bool on <code>a==b</code>).</p>", "body_text": "I think it would be good to have torch.sum behave the same on a plain ByteTensor as it does on a ByteTensor which is wrapped in a Variable. Presumably for the plain ByteTensor the accumulation is done in higher precision whereas for the Variable it seems like it's overflowing.\nIf you keep the ByteTensor reduce in higher precision then I think it's fine to have == return a ByteTensor (this also seems more inline with numpy semantics which returns a bool on a==b).", "body": "I think it would be good to have `torch.sum` behave the same on a plain `ByteTensor` as it does on a `ByteTensor` which is wrapped in a `Variable`. Presumably for the plain `ByteTensor` the accumulation is done in higher precision whereas for the `Variable` it seems like it's overflowing.\r\n\r\nIf you keep the `ByteTensor` reduce in higher precision then I think it's fine to have `==` return a `ByteTensor` (this also seems more inline with numpy semantics which returns a bool on `a==b`). "}