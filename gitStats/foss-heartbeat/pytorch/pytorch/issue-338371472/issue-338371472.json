{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9170", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9170/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9170/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9170/events", "html_url": "https://github.com/pytorch/pytorch/issues/9170", "id": 338371472, "node_id": "MDU6SXNzdWUzMzgzNzE0NzI=", "number": 9170, "title": "Big drop in performance for larger batch size for otherwise same training script", "user": {"login": "erxnmedia", "id": 8052009, "node_id": "MDQ6VXNlcjgwNTIwMDk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8052009?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erxnmedia", "html_url": "https://github.com/erxnmedia", "followers_url": "https://api.github.com/users/erxnmedia/followers", "following_url": "https://api.github.com/users/erxnmedia/following{/other_user}", "gists_url": "https://api.github.com/users/erxnmedia/gists{/gist_id}", "starred_url": "https://api.github.com/users/erxnmedia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erxnmedia/subscriptions", "organizations_url": "https://api.github.com/users/erxnmedia/orgs", "repos_url": "https://api.github.com/users/erxnmedia/repos", "events_url": "https://api.github.com/users/erxnmedia/events{/privacy}", "received_events_url": "https://api.github.com/users/erxnmedia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-04T20:38:09Z", "updated_at": "2018-09-26T18:24:20Z", "closed_at": "2018-07-04T21:20:17Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I have a script with batch size 4 which gets 58% accuracy.  I change the batch size to 4096 and I get 19% accuracy.  I am not shuffling the inputs.  The accuracy results should be the same.  Is there a bug?  See also <a href=\"https://stackoverflow.com/questions/51180423/is-there-a-bug-with-pytorch-training-for-large-batch-sizes-or-with-this-script\" rel=\"nofollow\">https://stackoverflow.com/questions/51180423/is-there-a-bug-with-pytorch-training-for-large-batch-sizes-or-with-this-script</a></p>\n<h2>Code example</h2>\n<pre><code>BIGGER_BATCH=4  # At this setting, 58% accuracy.  Change to to 4096, get 19% accuracy.\n\nimport numpy as np\nimport torch # Tensor Package (for use on GPU)\nimport torch.nn as nn ## Neural Network package\nimport torch.optim as optim # Optimization package\nimport torchvision # for dealing with vision data\nimport torchvision.transforms as transforms # for modifying vision data to run it through models\nfrom torch.autograd import Variable # for computational graph\nimport torch.nn.functional as F # Non-linearities package\nimport matplotlib.pyplot as plt # for plotting\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\ntransform = transforms.Compose( # we're going to use this to transform our data to make each sample more uniform\n   [\n    transforms.ToTensor(), # converts each sample from a (0-255, 0-255, 0-255) PIL Image format to a (0-1, 0-1, 0-1) FloatTensor format\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # for each of the 3 channels of the image, subtract mean 0.5 and divide by stdev 0.5\n   ]) # the normalization makes each SGD iteration more stable and overall makes convergence easier\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform) # this is all we need to get/wrangle the dataset!\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BIGGER_BATCH,\n                                          shuffle=False)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BIGGER_BATCH,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # each image can have 1 of 10 labels\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 5) # Let's add more feature maps - that might help\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 5) # And another conv layer with even more feature maps\n        self.fc1 = nn.Linear(20 * 5 * 5, 120) # and finally, adjusting our first linear layer's input to our previous output\n        self.fc2 = nn.Linear(120, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x) # we're changing our nonlinearity / activation function from sigmoid to ReLU for a slight speedup\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.pool(x) # after this pooling layer, we're down to a torch.Size([4, 20, 5, 5]) tensor.\n        x = x.view(-1, 20 * 5 * 5) # so let's adjust our tensor again.\n        x = self.fc1(x)             \n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        return x\n\nnet = Net().cuda()\n\nNUMBER_OF_EPOCHS = 25\nLEARNING_RATE = 1e-2\nloss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n\nfor epoch in range(NUMBER_OF_EPOCHS):\n    train_loader_iter = iter(trainloader)\n    for batch_idx, (inputs, labels) in enumerate(train_loader_iter):\n        net.zero_grad()\n        inputs, labels = Variable(inputs.float().cuda()), Variable(labels.cuda())\n        output = net(inputs)\n        loss = loss_function(output, labels)\n        loss.backward()\n        optimizer.step()\n    if epoch % 5 is 0:\n        print(\"Iteration: \" + str(epoch + 1))\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\n\nimshow(torchvision.utils.make_grid(images[0:4]))\n\noutputs = net(Variable(images.cuda()))\n_, predicted = torch.max(outputs.data, 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n\ncorrect = 0\ntotal = 0\nfor data in testloader:\n    images, labels = data\n    labels = labels.cuda()\n    outputs = net(Variable(images.cuda()))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\n\n</code></pre>\n<h2>System Info</h2>\n<pre><code>[pip] numpy (1.14.3)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda90                    1.0                           0    pytorch\n[conda] pytorch                   0.4.0           py36_cuda90_cudnn7he774522_1  [cuda90]  pytorch\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "Issue description\nI have a script with batch size 4 which gets 58% accuracy.  I change the batch size to 4096 and I get 19% accuracy.  I am not shuffling the inputs.  The accuracy results should be the same.  Is there a bug?  See also https://stackoverflow.com/questions/51180423/is-there-a-bug-with-pytorch-training-for-large-batch-sizes-or-with-this-script\nCode example\nBIGGER_BATCH=4  # At this setting, 58% accuracy.  Change to to 4096, get 19% accuracy.\n\nimport numpy as np\nimport torch # Tensor Package (for use on GPU)\nimport torch.nn as nn ## Neural Network package\nimport torch.optim as optim # Optimization package\nimport torchvision # for dealing with vision data\nimport torchvision.transforms as transforms # for modifying vision data to run it through models\nfrom torch.autograd import Variable # for computational graph\nimport torch.nn.functional as F # Non-linearities package\nimport matplotlib.pyplot as plt # for plotting\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\ntransform = transforms.Compose( # we're going to use this to transform our data to make each sample more uniform\n   [\n    transforms.ToTensor(), # converts each sample from a (0-255, 0-255, 0-255) PIL Image format to a (0-1, 0-1, 0-1) FloatTensor format\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # for each of the 3 channels of the image, subtract mean 0.5 and divide by stdev 0.5\n   ]) # the normalization makes each SGD iteration more stable and overall makes convergence easier\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform) # this is all we need to get/wrangle the dataset!\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BIGGER_BATCH,\n                                          shuffle=False)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BIGGER_BATCH,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # each image can have 1 of 10 labels\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 5) # Let's add more feature maps - that might help\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 5) # And another conv layer with even more feature maps\n        self.fc1 = nn.Linear(20 * 5 * 5, 120) # and finally, adjusting our first linear layer's input to our previous output\n        self.fc2 = nn.Linear(120, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x) # we're changing our nonlinearity / activation function from sigmoid to ReLU for a slight speedup\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.pool(x) # after this pooling layer, we're down to a torch.Size([4, 20, 5, 5]) tensor.\n        x = x.view(-1, 20 * 5 * 5) # so let's adjust our tensor again.\n        x = self.fc1(x)             \n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        return x\n\nnet = Net().cuda()\n\nNUMBER_OF_EPOCHS = 25\nLEARNING_RATE = 1e-2\nloss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\n\nfor epoch in range(NUMBER_OF_EPOCHS):\n    train_loader_iter = iter(trainloader)\n    for batch_idx, (inputs, labels) in enumerate(train_loader_iter):\n        net.zero_grad()\n        inputs, labels = Variable(inputs.float().cuda()), Variable(labels.cuda())\n        output = net(inputs)\n        loss = loss_function(output, labels)\n        loss.backward()\n        optimizer.step()\n    if epoch % 5 is 0:\n        print(\"Iteration: \" + str(epoch + 1))\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\n\nimshow(torchvision.utils.make_grid(images[0:4]))\n\noutputs = net(Variable(images.cuda()))\n_, predicted = torch.max(outputs.data, 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n\ncorrect = 0\ntotal = 0\nfor data in testloader:\n    images, labels = data\n    labels = labels.cuda()\n    outputs = net(Variable(images.cuda()))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))\n\n\nSystem Info\n[pip] numpy (1.14.3)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda90                    1.0                           0    pytorch\n[conda] pytorch                   0.4.0           py36_cuda90_cudnn7he774522_1  [cuda90]  pytorch\n[conda] torchvision               0.2.1                     <pip>", "body": "## Issue description\r\n\r\nI have a script with batch size 4 which gets 58% accuracy.  I change the batch size to 4096 and I get 19% accuracy.  I am not shuffling the inputs.  The accuracy results should be the same.  Is there a bug?  See also https://stackoverflow.com/questions/51180423/is-there-a-bug-with-pytorch-training-for-large-batch-sizes-or-with-this-script\r\n\r\n## Code example\r\n\r\n```\r\nBIGGER_BATCH=4  # At this setting, 58% accuracy.  Change to to 4096, get 19% accuracy.\r\n\r\nimport numpy as np\r\nimport torch # Tensor Package (for use on GPU)\r\nimport torch.nn as nn ## Neural Network package\r\nimport torch.optim as optim # Optimization package\r\nimport torchvision # for dealing with vision data\r\nimport torchvision.transforms as transforms # for modifying vision data to run it through models\r\nfrom torch.autograd import Variable # for computational graph\r\nimport torch.nn.functional as F # Non-linearities package\r\nimport matplotlib.pyplot as plt # for plotting\r\n\r\ndef imshow(img):\r\n    img = img / 2 + 0.5     # unnormalize\r\n    npimg = img.numpy()\r\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n\r\ntransform = transforms.Compose( # we're going to use this to transform our data to make each sample more uniform\r\n   [\r\n    transforms.ToTensor(), # converts each sample from a (0-255, 0-255, 0-255) PIL Image format to a (0-1, 0-1, 0-1) FloatTensor format\r\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # for each of the 3 channels of the image, subtract mean 0.5 and divide by stdev 0.5\r\n   ]) # the normalization makes each SGD iteration more stable and overall makes convergence easier\r\n\r\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n                                        download=True, transform=transform) # this is all we need to get/wrangle the dataset!\r\n\r\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\r\n                                       download=True, transform=transform)\r\n\r\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BIGGER_BATCH,\r\n                                          shuffle=False)\r\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BIGGER_BATCH,\r\n                                         shuffle=False)\r\n\r\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # each image can have 1 of 10 labels\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv2d(3, 10, 5) # Let's add more feature maps - that might help\r\n        self.pool = nn.MaxPool2d(2, 2)\r\n        self.conv2 = nn.Conv2d(10, 20, 5) # And another conv layer with even more feature maps\r\n        self.fc1 = nn.Linear(20 * 5 * 5, 120) # and finally, adjusting our first linear layer's input to our previous output\r\n        self.fc2 = nn.Linear(120, 10)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = F.relu(x) # we're changing our nonlinearity / activation function from sigmoid to ReLU for a slight speedup\r\n        x = self.pool(x)\r\n        x = self.conv2(x)\r\n        x = F.relu(x)\r\n        x = self.pool(x) # after this pooling layer, we're down to a torch.Size([4, 20, 5, 5]) tensor.\r\n        x = x.view(-1, 20 * 5 * 5) # so let's adjust our tensor again.\r\n        x = self.fc1(x)             \r\n        x = F.relu(x)\r\n        x = self.fc2(x)\r\n        x = F.relu(x)\r\n        return x\r\n\r\nnet = Net().cuda()\r\n\r\nNUMBER_OF_EPOCHS = 25\r\nLEARNING_RATE = 1e-2\r\nloss_function = nn.CrossEntropyLoss()\r\noptimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE)\r\n\r\nfor epoch in range(NUMBER_OF_EPOCHS):\r\n    train_loader_iter = iter(trainloader)\r\n    for batch_idx, (inputs, labels) in enumerate(train_loader_iter):\r\n        net.zero_grad()\r\n        inputs, labels = Variable(inputs.float().cuda()), Variable(labels.cuda())\r\n        output = net(inputs)\r\n        loss = loss_function(output, labels)\r\n        loss.backward()\r\n        optimizer.step()\r\n    if epoch % 5 is 0:\r\n        print(\"Iteration: \" + str(epoch + 1))\r\n\r\ndataiter = iter(testloader)\r\nimages, labels = dataiter.next()\r\n\r\nimshow(torchvision.utils.make_grid(images[0:4]))\r\n\r\noutputs = net(Variable(images.cuda()))\r\n_, predicted = torch.max(outputs.data, 1)\r\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\r\n                              for j in range(4)))\r\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\r\n\r\ncorrect = 0\r\ntotal = 0\r\nfor data in testloader:\r\n    images, labels = data\r\n    labels = labels.cuda()\r\n    outputs = net(Variable(images.cuda()))\r\n    _, predicted = torch.max(outputs.data, 1)\r\n    total += labels.size(0)\r\n    correct += (predicted == labels).sum()\r\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\r\n    100 * correct / total))\r\n\r\n```\r\n## System Info\r\n\r\n```\r\n[pip] numpy (1.14.3)\r\n[pip] torch (0.4.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda90                    1.0                           0    pytorch\r\n[conda] pytorch                   0.4.0           py36_cuda90_cudnn7he774522_1  [cuda90]  pytorch\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n"}