{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/338160981", "html_url": "https://github.com/pytorch/pytorch/issues/3147#issuecomment-338160981", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3147", "id": 338160981, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODE2MDk4MQ==", "user": {"login": "cjsg", "id": 28411935, "node_id": "MDQ6VXNlcjI4NDExOTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/28411935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjsg", "html_url": "https://github.com/cjsg", "followers_url": "https://api.github.com/users/cjsg/followers", "following_url": "https://api.github.com/users/cjsg/following{/other_user}", "gists_url": "https://api.github.com/users/cjsg/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjsg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjsg/subscriptions", "organizations_url": "https://api.github.com/users/cjsg/orgs", "repos_url": "https://api.github.com/users/cjsg/repos", "events_url": "https://api.github.com/users/cjsg/events{/privacy}", "received_events_url": "https://api.github.com/users/cjsg/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-20T09:51:44Z", "updated_at": "2017-10-20T09:51:44Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks to all for your help and suggestions! Special thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a>, who gave the right hint!</p>\n<p>The reason it failed is because I was trying to build/install pytorch on the login node of a cluster. And while the cuda/cudnn binaries/libraries are accessible from there, the login node has no GPU card and thus no nvidia drivers. That is why the <code>ld</code> command would not recognize the <code>-lcuda</code> option.<br>\nSo to make the installation work, I simply logged into a node with GPU, and did the installation there.</p>\n<p>Two suggestions though:</p>\n<ul>\n<li>Maybe it would make sense to check at the beginning of the installation whether the nvidia drivers are in the ldconfig path. This would avoid spending 45 minutes to do the build just to notice around the end that the installation is bound to fail because of ld .</li>\n<li>even with 10GB of memory, the installation ran out of memory. I had to request 20GB to make it work. I think, it's because the installation assumes that it can use all the system's memory, whereas on clusters, users usually get allocated only a fraction of the total memory. Don't know how difficult it would be to tell the installation to use only that allocated memory (or a pre-specified maximal amount).</li>\n</ul>", "body_text": "Thanks to all for your help and suggestions! Special thanks to @soumith, who gave the right hint!\nThe reason it failed is because I was trying to build/install pytorch on the login node of a cluster. And while the cuda/cudnn binaries/libraries are accessible from there, the login node has no GPU card and thus no nvidia drivers. That is why the ld command would not recognize the -lcuda option.\nSo to make the installation work, I simply logged into a node with GPU, and did the installation there.\nTwo suggestions though:\n\nMaybe it would make sense to check at the beginning of the installation whether the nvidia drivers are in the ldconfig path. This would avoid spending 45 minutes to do the build just to notice around the end that the installation is bound to fail because of ld .\neven with 10GB of memory, the installation ran out of memory. I had to request 20GB to make it work. I think, it's because the installation assumes that it can use all the system's memory, whereas on clusters, users usually get allocated only a fraction of the total memory. Don't know how difficult it would be to tell the installation to use only that allocated memory (or a pre-specified maximal amount).", "body": "Thanks to all for your help and suggestions! Special thanks to @soumith, who gave the right hint!\r\n\r\nThe reason it failed is because I was trying to build/install pytorch on the login node of a cluster. And while the cuda/cudnn binaries/libraries are accessible from there, the login node has no GPU card and thus no nvidia drivers. That is why the `ld` command would not recognize the `-lcuda` option.\r\nSo to make the installation work, I simply logged into a node with GPU, and did the installation there.\r\n\r\nTwo suggestions though:\r\n- Maybe it would make sense to check at the beginning of the installation whether the nvidia drivers are in the ldconfig path. This would avoid spending 45 minutes to do the build just to notice around the end that the installation is bound to fail because of ld .\r\n- even with 10GB of memory, the installation ran out of memory. I had to request 20GB to make it work. I think, it's because the installation assumes that it can use all the system's memory, whereas on clusters, users usually get allocated only a fraction of the total memory. Don't know how difficult it would be to tell the installation to use only that allocated memory (or a pre-specified maximal amount)."}