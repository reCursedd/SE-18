{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/324406470", "html_url": "https://github.com/pytorch/pytorch/issues/2478#issuecomment-324406470", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2478", "id": 324406470, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDQwNjQ3MA==", "user": {"login": "Taha-Bahadori", "id": 31113375, "node_id": "MDQ6VXNlcjMxMTEzMzc1", "avatar_url": "https://avatars3.githubusercontent.com/u/31113375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Taha-Bahadori", "html_url": "https://github.com/Taha-Bahadori", "followers_url": "https://api.github.com/users/Taha-Bahadori/followers", "following_url": "https://api.github.com/users/Taha-Bahadori/following{/other_user}", "gists_url": "https://api.github.com/users/Taha-Bahadori/gists{/gist_id}", "starred_url": "https://api.github.com/users/Taha-Bahadori/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Taha-Bahadori/subscriptions", "organizations_url": "https://api.github.com/users/Taha-Bahadori/orgs", "repos_url": "https://api.github.com/users/Taha-Bahadori/repos", "events_url": "https://api.github.com/users/Taha-Bahadori/events{/privacy}", "received_events_url": "https://api.github.com/users/Taha-Bahadori/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-23T17:30:02Z", "updated_at": "2017-08-23T17:30:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a>: I created a subclass to do this as follows.  It works as I described above.</p>\n<pre><code>\nclass ReduceLROnPlateauBT(ReduceLROnPlateau):\n    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,\n                 verbose=False, threshold=1e-4, threshold_mode='rel',\n                 cooldown=0, min_lr=0, eps=1e-8, model=None):\n        super(ReduceLROnPlateauBT, self).__init__(optimizer, mode=mode,\n                                                  factor=factor, patience=patience,\n                                                  verbose=verbose, threshold=threshold, \n                                                  threshold_mode=threshold_mode,\n                                                  cooldown=cooldown, min_lr=min_lr, eps=eps)\n        self.model = model\n        self.model_state_dict = None if model is None else model.state_dict()\n\n    def step(self, metrics, epoch=None):\n        current = metrics\n        if epoch is None:\n            epoch = self.last_epoch = self.last_epoch + 1\n        self.last_epoch = epoch\n\n        if self.is_better(current, self.best):\n            self.best = current\n            self.num_bad_epochs = 0\n            if self.model is not None: # Saving good models\n                self.model_state_dict = self.model.state_dict()\n        else:\n            self.num_bad_epochs += 1\n\n        if self.in_cooldown:\n            self.cooldown_counter -= 1\n            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n\n        if self.num_bad_epochs &gt; self.patience:\n            self._reduce_lr(epoch)\n            self.cooldown_counter = self.cooldown\n            self.num_bad_epochs = 0\n            if self.model is not None: # Loading good models\n                self.model.load_state_dict(self.model_state_dict )\n</code></pre>", "body_text": "@soumith: I created a subclass to do this as follows.  It works as I described above.\n\nclass ReduceLROnPlateauBT(ReduceLROnPlateau):\n    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,\n                 verbose=False, threshold=1e-4, threshold_mode='rel',\n                 cooldown=0, min_lr=0, eps=1e-8, model=None):\n        super(ReduceLROnPlateauBT, self).__init__(optimizer, mode=mode,\n                                                  factor=factor, patience=patience,\n                                                  verbose=verbose, threshold=threshold, \n                                                  threshold_mode=threshold_mode,\n                                                  cooldown=cooldown, min_lr=min_lr, eps=eps)\n        self.model = model\n        self.model_state_dict = None if model is None else model.state_dict()\n\n    def step(self, metrics, epoch=None):\n        current = metrics\n        if epoch is None:\n            epoch = self.last_epoch = self.last_epoch + 1\n        self.last_epoch = epoch\n\n        if self.is_better(current, self.best):\n            self.best = current\n            self.num_bad_epochs = 0\n            if self.model is not None: # Saving good models\n                self.model_state_dict = self.model.state_dict()\n        else:\n            self.num_bad_epochs += 1\n\n        if self.in_cooldown:\n            self.cooldown_counter -= 1\n            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n\n        if self.num_bad_epochs > self.patience:\n            self._reduce_lr(epoch)\n            self.cooldown_counter = self.cooldown\n            self.num_bad_epochs = 0\n            if self.model is not None: # Loading good models\n                self.model.load_state_dict(self.model_state_dict )", "body": "@soumith: I created a subclass to do this as follows.  It works as I described above.\r\n\r\n<pre><code>\r\nclass ReduceLROnPlateauBT(ReduceLROnPlateau):\r\n    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,\r\n                 verbose=False, threshold=1e-4, threshold_mode='rel',\r\n                 cooldown=0, min_lr=0, eps=1e-8, model=None):\r\n        super(ReduceLROnPlateauBT, self).__init__(optimizer, mode=mode,\r\n                                                  factor=factor, patience=patience,\r\n                                                  verbose=verbose, threshold=threshold, \r\n                                                  threshold_mode=threshold_mode,\r\n                                                  cooldown=cooldown, min_lr=min_lr, eps=eps)\r\n        self.model = model\r\n        self.model_state_dict = None if model is None else model.state_dict()\r\n\r\n    def step(self, metrics, epoch=None):\r\n        current = metrics\r\n        if epoch is None:\r\n            epoch = self.last_epoch = self.last_epoch + 1\r\n        self.last_epoch = epoch\r\n\r\n        if self.is_better(current, self.best):\r\n            self.best = current\r\n            self.num_bad_epochs = 0\r\n            if self.model is not None: # Saving good models\r\n                self.model_state_dict = self.model.state_dict()\r\n        else:\r\n            self.num_bad_epochs += 1\r\n\r\n        if self.in_cooldown:\r\n            self.cooldown_counter -= 1\r\n            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\r\n\r\n        if self.num_bad_epochs > self.patience:\r\n            self._reduce_lr(epoch)\r\n            self.cooldown_counter = self.cooldown\r\n            self.num_bad_epochs = 0\r\n            if self.model is not None: # Loading good models\r\n                self.model.load_state_dict(self.model_state_dict )\r\n</code></pre>"}