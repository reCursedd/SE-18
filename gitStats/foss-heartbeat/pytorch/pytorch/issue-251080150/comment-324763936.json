{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/324763936", "html_url": "https://github.com/pytorch/pytorch/issues/2478#issuecomment-324763936", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2478", "id": 324763936, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDc2MzkzNg==", "user": {"login": "Taha-Bahadori", "id": 31113375, "node_id": "MDQ6VXNlcjMxMTEzMzc1", "avatar_url": "https://avatars3.githubusercontent.com/u/31113375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Taha-Bahadori", "html_url": "https://github.com/Taha-Bahadori", "followers_url": "https://api.github.com/users/Taha-Bahadori/followers", "following_url": "https://api.github.com/users/Taha-Bahadori/following{/other_user}", "gists_url": "https://api.github.com/users/Taha-Bahadori/gists{/gist_id}", "starred_url": "https://api.github.com/users/Taha-Bahadori/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Taha-Bahadori/subscriptions", "organizations_url": "https://api.github.com/users/Taha-Bahadori/orgs", "repos_url": "https://api.github.com/users/Taha-Bahadori/repos", "events_url": "https://api.github.com/users/Taha-Bahadori/events{/privacy}", "received_events_url": "https://api.github.com/users/Taha-Bahadori/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-24T21:34:17Z", "updated_at": "2017-08-24T21:34:17Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16099575\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Jiaming-Liu\">@Jiaming-Liu</a> I think there should be a mistake in your code snippet.  Here is an example that shows the above saving and loading <code>state_dict</code> should work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">M</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(M, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.mem <span class=\"pl-k\">=</span> nn.Parameter(torch.zeros(<span class=\"pl-c1\">1</span>))\n\nm <span class=\"pl-k\">=</span> M()\n<span class=\"pl-c1\">print</span> m\n<span class=\"pl-c1\">print</span> m.state_dict()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Saving the current state_dict</span>\nsd <span class=\"pl-k\">=</span> m.state_dict()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Changing the value of the parameter</span>\nm.mem.data <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">1</span>)\n<span class=\"pl-c1\">print</span> m.state_dict()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Now loading the original zero parameter back</span>\nm.load_state_dict(sd)\n<span class=\"pl-c1\">print</span> m.state_dict()\n</pre></div>", "body_text": "@Jiaming-Liu I think there should be a mistake in your code snippet.  Here is an example that shows the above saving and loading state_dict should work:\nimport torch\nimport torch.nn as nn\n\nclass M(nn.Module):\n    def __init__(self):\n        super(M, self).__init__()\n        self.mem = nn.Parameter(torch.zeros(1))\n\nm = M()\nprint m\nprint m.state_dict()\n\n# Saving the current state_dict\nsd = m.state_dict()\n\n# Changing the value of the parameter\nm.mem.data = torch.ones(1)\nprint m.state_dict()\n\n# Now loading the original zero parameter back\nm.load_state_dict(sd)\nprint m.state_dict()", "body": "@Jiaming-Liu I think there should be a mistake in your code snippet.  Here is an example that shows the above saving and loading `state_dict` should work:\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass M(nn.Module):\r\n    def __init__(self):\r\n        super(M, self).__init__()\r\n        self.mem = nn.Parameter(torch.zeros(1))\r\n\r\nm = M()\r\nprint m\r\nprint m.state_dict()\r\n\r\n# Saving the current state_dict\r\nsd = m.state_dict()\r\n\r\n# Changing the value of the parameter\r\nm.mem.data = torch.ones(1)\r\nprint m.state_dict()\r\n\r\n# Now loading the original zero parameter back\r\nm.load_state_dict(sd)\r\nprint m.state_dict()\r\n\r\n```\r\n"}