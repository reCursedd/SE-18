{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1122", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1122/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1122/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1122/events", "html_url": "https://github.com/pytorch/pytorch/pull/1122", "id": 217453060, "node_id": "MDExOlB1bGxSZXF1ZXN0MTEyODkzMjM5", "number": 1122, "title": "Implements Cumsum function for autograd", "user": {"login": "bunelr", "id": 3354626, "node_id": "MDQ6VXNlcjMzNTQ2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3354626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bunelr", "html_url": "https://github.com/bunelr", "followers_url": "https://api.github.com/users/bunelr/followers", "following_url": "https://api.github.com/users/bunelr/following{/other_user}", "gists_url": "https://api.github.com/users/bunelr/gists{/gist_id}", "starred_url": "https://api.github.com/users/bunelr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bunelr/subscriptions", "organizations_url": "https://api.github.com/users/bunelr/orgs", "repos_url": "https://api.github.com/users/bunelr/repos", "events_url": "https://api.github.com/users/bunelr/events{/privacy}", "received_events_url": "https://api.github.com/users/bunelr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-03-28T05:36:19Z", "updated_at": "2018-11-23T15:32:54Z", "closed_at": "2017-03-29T15:45:57Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1122", "html_url": "https://github.com/pytorch/pytorch/pull/1122", "diff_url": "https://github.com/pytorch/pytorch/pull/1122.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1122.patch"}, "body_html": "<p>The ideal implementation of a backward pass for the cumsum operation would be a<br>\ncumsum operation on the reversed tensor but there is to my knowledge no reverse<br>\noperation yet in pytorch.</p>\n<p>I needed this for one of my project so I implemented it, and I saw in issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"200504875\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/440\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/440/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/440\">#440</a> that this was a pending feature so I thought I would propose my implementation.</p>\n<p>Let me know if there is a better place where this should be implemented, if more tests should be added or if anything is missing.</p>\n<p>I might be able to take a look at some of the others later if no one is working on them.</p>", "body_text": "The ideal implementation of a backward pass for the cumsum operation would be a\ncumsum operation on the reversed tensor but there is to my knowledge no reverse\noperation yet in pytorch.\nI needed this for one of my project so I implemented it, and I saw in issue #440 that this was a pending feature so I thought I would propose my implementation.\nLet me know if there is a better place where this should be implemented, if more tests should be added or if anything is missing.\nI might be able to take a look at some of the others later if no one is working on them.", "body": "The ideal implementation of a backward pass for the cumsum operation would be a\r\ncumsum operation on the reversed tensor but there is to my knowledge no reverse\r\noperation yet in pytorch.\r\n\r\nI needed this for one of my project so I implemented it, and I saw in issue #440 that this was a pending feature so I thought I would propose my implementation.\r\n\r\nLet me know if there is a better place where this should be implemented, if more tests should be added or if anything is missing.\r\n\r\nI might be able to take a look at some of the others later if no one is working on them."}