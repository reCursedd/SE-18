{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1829", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1829/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1829/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1829/events", "html_url": "https://github.com/pytorch/pytorch/issues/1829", "id": 236614433, "node_id": "MDU6SXNzdWUyMzY2MTQ0MzM=", "number": 1829, "title": "cuda out of memory with size 1 tensor", "user": {"login": "fakufaku", "id": 1118133, "node_id": "MDQ6VXNlcjExMTgxMzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1118133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fakufaku", "html_url": "https://github.com/fakufaku", "followers_url": "https://api.github.com/users/fakufaku/followers", "following_url": "https://api.github.com/users/fakufaku/following{/other_user}", "gists_url": "https://api.github.com/users/fakufaku/gists{/gist_id}", "starred_url": "https://api.github.com/users/fakufaku/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fakufaku/subscriptions", "organizations_url": "https://api.github.com/users/fakufaku/orgs", "repos_url": "https://api.github.com/users/fakufaku/repos", "events_url": "https://api.github.com/users/fakufaku/events{/privacy}", "received_events_url": "https://api.github.com/users/fakufaku/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-06-16T22:35:48Z", "updated_at": "2018-10-16T08:38:21Z", "closed_at": "2017-06-17T08:33:50Z", "author_association": "NONE", "body_html": "<p>Hi, I have just built pytorch on OS X with CUDA support.</p>\n<p>I'm having some trouble using CUDA features as it seems to run out of memory even with a size 1 tensor.</p>\n<pre><code>ipython --pylab\nPython 3.5.3 |Continuum Analytics, Inc.| (default, Mar  6 2017, 12:15:08)\nType 'copyright', 'credits' or 'license' for more information\nIPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\nUsing matplotlib backend: MacOSX\n\nIn [1]: import torch\n\nIn [2]: torch.cuda.current_device()\nOut[2]: 0\n\nIn [3]: torch.cuda.device_count()\nOut[3]: 1\n\nIn [4]: torch.cuda.FloatTensor([1])\nTHCudaCheck FAIL file=/Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-4-8352503114b9&gt; in &lt;module&gt;()\n----&gt; 1 torch.cuda.FloatTensor([1])\n\n~/anaconda/envs/python3/lib/python3.5/site-packages/torch/cuda/__init__.py in _lazy_new(cls, *args, **kwargs)\n    267     # We need this method only for lazy init, so we can remove it\n    268     del _CudaBase.__new__\n--&gt; 269     return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\n    270\n    271\n\nRuntimeError: cuda runtime error (2) : out of memory at /Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu:66\n</code></pre>\n<p>My laptop is fairly old, with an NVIDIA GeForce GT 650M 1024 MB. CUDA version is 8.0. Torch version is <code>0.1.12+8d33603</code>. OS X is 10.12.4. I am using Python 3.5.3 with Anaconda.</p>", "body_text": "Hi, I have just built pytorch on OS X with CUDA support.\nI'm having some trouble using CUDA features as it seems to run out of memory even with a size 1 tensor.\nipython --pylab\nPython 3.5.3 |Continuum Analytics, Inc.| (default, Mar  6 2017, 12:15:08)\nType 'copyright', 'credits' or 'license' for more information\nIPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\nUsing matplotlib backend: MacOSX\n\nIn [1]: import torch\n\nIn [2]: torch.cuda.current_device()\nOut[2]: 0\n\nIn [3]: torch.cuda.device_count()\nOut[3]: 1\n\nIn [4]: torch.cuda.FloatTensor([1])\nTHCudaCheck FAIL file=/Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-4-8352503114b9> in <module>()\n----> 1 torch.cuda.FloatTensor([1])\n\n~/anaconda/envs/python3/lib/python3.5/site-packages/torch/cuda/__init__.py in _lazy_new(cls, *args, **kwargs)\n    267     # We need this method only for lazy init, so we can remove it\n    268     del _CudaBase.__new__\n--> 269     return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\n    270\n    271\n\nRuntimeError: cuda runtime error (2) : out of memory at /Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu:66\n\nMy laptop is fairly old, with an NVIDIA GeForce GT 650M 1024 MB. CUDA version is 8.0. Torch version is 0.1.12+8d33603. OS X is 10.12.4. I am using Python 3.5.3 with Anaconda.", "body": "Hi, I have just built pytorch on OS X with CUDA support.\r\n\r\nI'm having some trouble using CUDA features as it seems to run out of memory even with a size 1 tensor.\r\n```\r\nipython --pylab\r\nPython 3.5.3 |Continuum Analytics, Inc.| (default, Mar  6 2017, 12:15:08)\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\r\nUsing matplotlib backend: MacOSX\r\n\r\nIn [1]: import torch\r\n\r\nIn [2]: torch.cuda.current_device()\r\nOut[2]: 0\r\n\r\nIn [3]: torch.cuda.device_count()\r\nOut[3]: 1\r\n\r\nIn [4]: torch.cuda.FloatTensor([1])\r\nTHCudaCheck FAIL file=/Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-8352503114b9> in <module>()\r\n----> 1 torch.cuda.FloatTensor([1])\r\n\r\n~/anaconda/envs/python3/lib/python3.5/site-packages/torch/cuda/__init__.py in _lazy_new(cls, *args, **kwargs)\r\n    267     # We need this method only for lazy init, so we can remove it\r\n    268     del _CudaBase.__new__\r\n--> 269     return super(_CudaBase, cls).__new__(cls, *args, **kwargs)\r\n    270\r\n    271\r\n\r\nRuntimeError: cuda runtime error (2) : out of memory at /Users/scheibler/sandbox/pytorch/torch/lib/THC/generic/THCStorage.cu:66\r\n```\r\n\r\nMy laptop is fairly old, with an NVIDIA GeForce GT 650M 1024 MB. CUDA version is 8.0. Torch version is `0.1.12+8d33603`. OS X is 10.12.4. I am using Python 3.5.3 with Anaconda."}