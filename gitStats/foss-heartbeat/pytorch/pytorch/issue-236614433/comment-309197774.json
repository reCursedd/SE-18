{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/309197774", "html_url": "https://github.com/pytorch/pytorch/issues/1829#issuecomment-309197774", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1829", "id": 309197774, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTE5Nzc3NA==", "user": {"login": "fakufaku", "id": 1118133, "node_id": "MDQ6VXNlcjExMTgxMzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1118133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fakufaku", "html_url": "https://github.com/fakufaku", "followers_url": "https://api.github.com/users/fakufaku/followers", "following_url": "https://api.github.com/users/fakufaku/following{/other_user}", "gists_url": "https://api.github.com/users/fakufaku/gists{/gist_id}", "starred_url": "https://api.github.com/users/fakufaku/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fakufaku/subscriptions", "organizations_url": "https://api.github.com/users/fakufaku/orgs", "repos_url": "https://api.github.com/users/fakufaku/repos", "events_url": "https://api.github.com/users/fakufaku/events{/privacy}", "received_events_url": "https://api.github.com/users/fakufaku/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-17T06:50:33Z", "updated_at": "2017-06-17T06:50:33Z", "author_association": "NONE", "body_html": "<p>Thanks for the advice. I quickly wrote a small program to access cudaMemGetInfo</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;cuda_runtime_api.h&gt;\n\nint main(int argc, char **argv)\n{\n\n  size_t free, total;\n\n  cudaMemGetInfo(&amp;free, &amp;total);\n\n  printf(\"CUDA memory: free=%d, total=%d\\n\", (int)free, (int)total);\n\n  return 0;\n}\n</code></pre>\n<p>and compile it by running</p>\n<pre><code>&gt; nvcc cuda_mem.cpp -o cuda_mem\n</code></pre>\n<p>When I run it, I get the following</p>\n<pre><code>&gt; ./cuda_mem\nCUDA memory: free=1515520, total=1073414144\n</code></pre>\n<p>So it seems indeed, there is very little memory free. Since the graphics card is used for the OS, is it possible it is just using up everything available ? (this is not a particularly big graphics card I think.)</p>", "body_text": "Thanks for the advice. I quickly wrote a small program to access cudaMemGetInfo\n#include <stdio.h>\n#include <cuda_runtime_api.h>\n\nint main(int argc, char **argv)\n{\n\n  size_t free, total;\n\n  cudaMemGetInfo(&free, &total);\n\n  printf(\"CUDA memory: free=%d, total=%d\\n\", (int)free, (int)total);\n\n  return 0;\n}\n\nand compile it by running\n> nvcc cuda_mem.cpp -o cuda_mem\n\nWhen I run it, I get the following\n> ./cuda_mem\nCUDA memory: free=1515520, total=1073414144\n\nSo it seems indeed, there is very little memory free. Since the graphics card is used for the OS, is it possible it is just using up everything available ? (this is not a particularly big graphics card I think.)", "body": "Thanks for the advice. I quickly wrote a small program to access cudaMemGetInfo\r\n```\r\n#include <stdio.h>\r\n#include <cuda_runtime_api.h>\r\n\r\nint main(int argc, char **argv)\r\n{\r\n\r\n  size_t free, total;\r\n\r\n  cudaMemGetInfo(&free, &total);\r\n\r\n  printf(\"CUDA memory: free=%d, total=%d\\n\", (int)free, (int)total);\r\n\r\n  return 0;\r\n}\r\n```\r\nand compile it by running\r\n```\r\n> nvcc cuda_mem.cpp -o cuda_mem\r\n```\r\nWhen I run it, I get the following\r\n```\r\n> ./cuda_mem\r\nCUDA memory: free=1515520, total=1073414144\r\n```\r\nSo it seems indeed, there is very little memory free. Since the graphics card is used for the OS, is it possible it is just using up everything available ? (this is not a particularly big graphics card I think.)"}