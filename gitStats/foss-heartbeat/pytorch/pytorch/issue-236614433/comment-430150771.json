{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430150771", "html_url": "https://github.com/pytorch/pytorch/issues/1829#issuecomment-430150771", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1829", "id": 430150771, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDE1MDc3MQ==", "user": {"login": "jianchao-li", "id": 26521863, "node_id": "MDQ6VXNlcjI2NTIxODYz", "avatar_url": "https://avatars2.githubusercontent.com/u/26521863?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jianchao-li", "html_url": "https://github.com/jianchao-li", "followers_url": "https://api.github.com/users/jianchao-li/followers", "following_url": "https://api.github.com/users/jianchao-li/following{/other_user}", "gists_url": "https://api.github.com/users/jianchao-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/jianchao-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jianchao-li/subscriptions", "organizations_url": "https://api.github.com/users/jianchao-li/orgs", "repos_url": "https://api.github.com/users/jianchao-li/repos", "events_url": "https://api.github.com/users/jianchao-li/events{/privacy}", "received_events_url": "https://api.github.com/users/jianchao-li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-16T08:36:26Z", "updated_at": "2018-10-16T08:38:21Z", "author_association": "NONE", "body_html": "<p>Hello, I also came across this problem in an 8-GPU machine. I wrote two scripts to check the conditions of GPUs.</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda_runtime_api.h<span class=\"pl-pds\">\"</span></span>\n  \n<span class=\"pl-k\">using</span> <span class=\"pl-k\">namespace</span> <span class=\"pl-en\">std</span><span class=\"pl-k\">;</span>\n  \n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>( <span class=\"pl-k\">void</span> ) {\n    <span class=\"pl-k\">int</span> num_gpus;\n    <span class=\"pl-c1\">size_t</span> <span class=\"pl-c1\">free</span>, total;\n    <span class=\"pl-c1\">cudaGetDeviceCount</span>( &amp;num_gpus );\n    <span class=\"pl-k\">for</span> ( <span class=\"pl-k\">int</span> gpu_id = <span class=\"pl-c1\">0</span>; gpu_id &lt; num_gpus; gpu_id++ ) {\n        <span class=\"pl-c1\">cudaSetDevice</span>( gpu_id );\n        <span class=\"pl-k\">int</span> id;\n        <span class=\"pl-c1\">cudaGetDevice</span>( &amp;id );\n        <span class=\"pl-c1\">cudaMemGetInfo</span>( &amp;<span class=\"pl-c1\">free</span>, &amp;total );\n        cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>GPU <span class=\"pl-pds\">\"</span></span> &lt;&lt; id &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> memory: free=<span class=\"pl-pds\">\"</span></span> &lt;&lt; <span class=\"pl-c1\">free</span> &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>, total=<span class=\"pl-pds\">\"</span></span> &lt;&lt; total &lt;&lt; endl;\n    }\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<p>This one gives reasonable results since I have not run any program in the GPUs.</p>\n<div class=\"highlight highlight-source-shell\"><pre>GPU 0 memory: free=16488464384, total=16945512448\nGPU 1 memory: free=16488464384, total=16945512448\nGPU 2 memory: free=16488464384, total=16945512448\nGPU 3 memory: free=16488464384, total=16945512448\nGPU 4 memory: free=16488464384, total=16945512448\nGPU 5 memory: free=16488464384, total=16945512448\nGPU 6 memory: free=16488464384, total=16945512448\nGPU 7 memory: free=16488464384, total=16945512448</pre></div>\n<p>However, when I tried to create a <code>torch.cuda.FloatTensor</code> with only one element, one card (GPU 4) is out of memory...</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n \n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    x <span class=\"pl-k\">=</span> np.random.randn(<span class=\"pl-c1\">1</span>)\n    <span class=\"pl-k\">try</span>:\n        t <span class=\"pl-k\">=</span> torch.cuda.FloatTensor(x)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Success!<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">Exception</span> <span class=\"pl-k\">as</span> e:\n        <span class=\"pl-c1\">print</span>(e)</pre></div>\n<p>The execution results are as follows.</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ CUDA_VISIBLE_DEVICES=0 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=1 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=2 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=3 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=4 python3 check.py \nCUDA error: out of memory\n$ CUDA_VISIBLE_DEVICES=5 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=6 python3 check.py \nSuccess<span class=\"pl-k\">!</span>\n$ CUDA_VISIBLE_DEVICES=7 python3 check.py \nSuccess<span class=\"pl-k\">!</span></pre></div>", "body_text": "Hello, I also came across this problem in an 8-GPU machine. I wrote two scripts to check the conditions of GPUs.\n#include <iostream>\n#include \"cuda.h\"\n#include \"cuda_runtime_api.h\"\n  \nusing namespace std;\n  \nint main( void ) {\n    int num_gpus;\n    size_t free, total;\n    cudaGetDeviceCount( &num_gpus );\n    for ( int gpu_id = 0; gpu_id < num_gpus; gpu_id++ ) {\n        cudaSetDevice( gpu_id );\n        int id;\n        cudaGetDevice( &id );\n        cudaMemGetInfo( &free, &total );\n        cout << \"GPU \" << id << \" memory: free=\" << free << \", total=\" << total << endl;\n    }\n    return 0;\n}\nThis one gives reasonable results since I have not run any program in the GPUs.\nGPU 0 memory: free=16488464384, total=16945512448\nGPU 1 memory: free=16488464384, total=16945512448\nGPU 2 memory: free=16488464384, total=16945512448\nGPU 3 memory: free=16488464384, total=16945512448\nGPU 4 memory: free=16488464384, total=16945512448\nGPU 5 memory: free=16488464384, total=16945512448\nGPU 6 memory: free=16488464384, total=16945512448\nGPU 7 memory: free=16488464384, total=16945512448\nHowever, when I tried to create a torch.cuda.FloatTensor with only one element, one card (GPU 4) is out of memory...\nimport torch\nimport numpy as np\n \nif __name__ == '__main__':\n    x = np.random.randn(1)\n    try:\n        t = torch.cuda.FloatTensor(x)\n        print('Success!')\n    except Exception as e:\n        print(e)\nThe execution results are as follows.\n$ CUDA_VISIBLE_DEVICES=0 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=1 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=2 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=3 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=4 python3 check.py \nCUDA error: out of memory\n$ CUDA_VISIBLE_DEVICES=5 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=6 python3 check.py \nSuccess!\n$ CUDA_VISIBLE_DEVICES=7 python3 check.py \nSuccess!", "body": "Hello, I also came across this problem in an 8-GPU machine. I wrote two scripts to check the conditions of GPUs.\r\n\r\n```cpp\r\n#include <iostream>\r\n#include \"cuda.h\"\r\n#include \"cuda_runtime_api.h\"\r\n  \r\nusing namespace std;\r\n  \r\nint main( void ) {\r\n    int num_gpus;\r\n    size_t free, total;\r\n    cudaGetDeviceCount( &num_gpus );\r\n    for ( int gpu_id = 0; gpu_id < num_gpus; gpu_id++ ) {\r\n        cudaSetDevice( gpu_id );\r\n        int id;\r\n        cudaGetDevice( &id );\r\n        cudaMemGetInfo( &free, &total );\r\n        cout << \"GPU \" << id << \" memory: free=\" << free << \", total=\" << total << endl;\r\n    }\r\n    return 0;\r\n}\r\n```\r\n\r\nThis one gives reasonable results since I have not run any program in the GPUs. \r\n\r\n```bash\r\nGPU 0 memory: free=16488464384, total=16945512448\r\nGPU 1 memory: free=16488464384, total=16945512448\r\nGPU 2 memory: free=16488464384, total=16945512448\r\nGPU 3 memory: free=16488464384, total=16945512448\r\nGPU 4 memory: free=16488464384, total=16945512448\r\nGPU 5 memory: free=16488464384, total=16945512448\r\nGPU 6 memory: free=16488464384, total=16945512448\r\nGPU 7 memory: free=16488464384, total=16945512448\r\n```\r\n\r\nHowever, when I tried to create a `torch.cuda.FloatTensor` with only one element, one card (GPU 4) is out of memory...\r\n\r\n```python\r\nimport torch\r\nimport numpy as np\r\n \r\nif __name__ == '__main__':\r\n    x = np.random.randn(1)\r\n    try:\r\n        t = torch.cuda.FloatTensor(x)\r\n        print('Success!')\r\n    except Exception as e:\r\n        print(e)\r\n```\r\n\r\nThe execution results are as follows.\r\n\r\n```bash\r\n$ CUDA_VISIBLE_DEVICES=0 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=1 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=2 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=3 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=4 python3 check.py \r\nCUDA error: out of memory\r\n$ CUDA_VISIBLE_DEVICES=5 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=6 python3 check.py \r\nSuccess!\r\n$ CUDA_VISIBLE_DEVICES=7 python3 check.py \r\nSuccess!\r\n```"}