{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13751", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13751/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13751/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13751/events", "html_url": "https://github.com/pytorch/pytorch/pull/13751", "id": 378942365, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI5NTI4Mjc3", "number": 13751, "title": "Improve CUDA out-of-memory error message", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-08T22:23:10Z", "updated_at": "2018-11-23T15:54:36Z", "closed_at": "2018-11-09T22:34:56Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/13751", "html_url": "https://github.com/pytorch/pytorch/pull/13751", "diff_url": "https://github.com/pytorch/pytorch/pull/13751.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/13751.patch"}, "body_html": "<pre><code>The new error message now looks like (from Python):\n\n  RuntimeError: CUDA out of memory. Tried to allocate 16.00 GiB (GPU 0; 11.93 GiB total capacity; 4.00 GiB already allocated; 7.33 GiB free; 179.00 KiB cached)\n\nSummary of terms:\n\n  \"total capacity\": total global memory on GPU\n  \"already allocated\": memory allocated by the program using the\n                       caching allocator\n  \"free\": free memory as reported by the CUDA API\n  \"cached\": memory held by the allocator but not used by the program\n \n  The \"allocated\" amount  does not include memory allocated outside\n  of the caching allocator, such as memory allocated by other programs\n  or memory held by the driver.\n \n  The sum of \"allocated\" + \"free\" + \"cached\" may be less than the\n  total capacity due to memory held by the driver and usage by other\n  programs.\n\n  Note that at this point cuda_malloc_retry has already returned all\n  possible \"cached\" memory to the driver. The only remaining \"cached\"\n  memory is split from a larger block that is partially in-use.\n</code></pre>\n<p>This also fixes an issue where on out-of-memory could cause an unrelated subsequent CUDA kernel launch to fail because <code>cudaGetLastError()</code> was not cleared.</p>", "body_text": "The new error message now looks like (from Python):\n\n  RuntimeError: CUDA out of memory. Tried to allocate 16.00 GiB (GPU 0; 11.93 GiB total capacity; 4.00 GiB already allocated; 7.33 GiB free; 179.00 KiB cached)\n\nSummary of terms:\n\n  \"total capacity\": total global memory on GPU\n  \"already allocated\": memory allocated by the program using the\n                       caching allocator\n  \"free\": free memory as reported by the CUDA API\n  \"cached\": memory held by the allocator but not used by the program\n \n  The \"allocated\" amount  does not include memory allocated outside\n  of the caching allocator, such as memory allocated by other programs\n  or memory held by the driver.\n \n  The sum of \"allocated\" + \"free\" + \"cached\" may be less than the\n  total capacity due to memory held by the driver and usage by other\n  programs.\n\n  Note that at this point cuda_malloc_retry has already returned all\n  possible \"cached\" memory to the driver. The only remaining \"cached\"\n  memory is split from a larger block that is partially in-use.\n\nThis also fixes an issue where on out-of-memory could cause an unrelated subsequent CUDA kernel launch to fail because cudaGetLastError() was not cleared.", "body": "```\r\nThe new error message now looks like (from Python):\r\n\r\n  RuntimeError: CUDA out of memory. Tried to allocate 16.00 GiB (GPU 0; 11.93 GiB total capacity; 4.00 GiB already allocated; 7.33 GiB free; 179.00 KiB cached)\r\n\r\nSummary of terms:\r\n\r\n  \"total capacity\": total global memory on GPU\r\n  \"already allocated\": memory allocated by the program using the\r\n                       caching allocator\r\n  \"free\": free memory as reported by the CUDA API\r\n  \"cached\": memory held by the allocator but not used by the program\r\n \r\n  The \"allocated\" amount  does not include memory allocated outside\r\n  of the caching allocator, such as memory allocated by other programs\r\n  or memory held by the driver.\r\n \r\n  The sum of \"allocated\" + \"free\" + \"cached\" may be less than the\r\n  total capacity due to memory held by the driver and usage by other\r\n  programs.\r\n\r\n  Note that at this point cuda_malloc_retry has already returned all\r\n  possible \"cached\" memory to the driver. The only remaining \"cached\"\r\n  memory is split from a larger block that is partially in-use.\r\n```\r\n\r\nThis also fixes an issue where on out-of-memory could cause an unrelated subsequent CUDA kernel launch to fail because `cudaGetLastError()` was not cleared."}