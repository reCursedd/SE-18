{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197124740", "pull_request_review_id": 130805365, "id": 197124740, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzEyNDc0MA==", "diff_hunk": "@@ -214,9 +159,18 @@ SparseTensor new_with_tensor_and_size_sparse(const LongTensor& indices, const Te\n   AT_CHECK(sizes.size() == sparseDims + denseDims, \"number of dimensions must be sparseDims (\", sparseDims, \") + denseDims (\", denseDims, \"), but got \", sizes);\n \n   LongTensor max_indices = std::get</* values */ 0>(indices.max(/* dim */ 1, /* keepdim */ false));\n-  auto max_indices_accessor = max_indices.accessor<int64_t, 1>();\n+  LongTensor cpu_max_indices;\n+  if (max_indices.is_cuda()) {\n+    cpu_max_indices = at::CPU(kLong).tensor(max_indices.sizes());\n+    cpu_max_indices.copy_(max_indices);\n+  } else {\n+    cpu_max_indices = max_indices;\n+  }\n+  auto cpu_max_indices_accessor = cpu_max_indices.accessor<int64_t, 1>();\n   for (int64_t d = 0; d < sparseDims; d++) {\n-    int64_t max_index_in_dim = max_indices_accessor[d];\n+    // NB: This used to sync ndim times to access each entry; now we copy", "path": "aten/src/ATen/native/sparse/SparseTensor.cpp", "position": 90, "original_position": 91, "commit_id": "1a3c38e577f84307b7b6f7c8e49818fde11f343f", "original_commit_id": "c11ea30b5dc65385ffe2f12f9664f658d7ca4d97", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "I guess it's a matter of sync/async pref. If we do the error tests in kernel we won't find out about it until the async error code finally gets back to us. Do you really want it in a kernel?", "created_at": "2018-06-21T13:05:40Z", "updated_at": "2018-11-23T15:45:59Z", "html_url": "https://github.com/pytorch/pytorch/pull/8689#discussion_r197124740", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8689", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197124740"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8689#discussion_r197124740"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8689"}}, "body_html": "<p>I guess it's a matter of sync/async pref. If we do the error tests in kernel we won't find out about it until the async error code finally gets back to us. Do you really want it in a kernel?</p>", "body_text": "I guess it's a matter of sync/async pref. If we do the error tests in kernel we won't find out about it until the async error code finally gets back to us. Do you really want it in a kernel?", "in_reply_to_id": 196960682}