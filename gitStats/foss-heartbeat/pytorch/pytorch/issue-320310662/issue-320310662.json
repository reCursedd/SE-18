{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7284", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7284/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7284/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7284/events", "html_url": "https://github.com/pytorch/pytorch/issues/7284", "id": 320310662, "node_id": "MDU6SXNzdWUzMjAzMTA2NjI=", "number": 7284, "title": "[feature request] Bucketization", "user": {"login": "superbobry", "id": 185856, "node_id": "MDQ6VXNlcjE4NTg1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/185856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/superbobry", "html_url": "https://github.com/superbobry", "followers_url": "https://api.github.com/users/superbobry/followers", "following_url": "https://api.github.com/users/superbobry/following{/other_user}", "gists_url": "https://api.github.com/users/superbobry/gists{/gist_id}", "starred_url": "https://api.github.com/users/superbobry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/superbobry/subscriptions", "organizations_url": "https://api.github.com/users/superbobry/orgs", "repos_url": "https://api.github.com/users/superbobry/repos", "events_url": "https://api.github.com/users/superbobry/events{/privacy}", "received_events_url": "https://api.github.com/users/superbobry/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-04T15:05:58Z", "updated_at": "2018-08-29T05:10:14Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>Both the 0.4.0 version and the <code>master</code> version are missing a bucketization operation, i.e. an operation which given a 1-D tensor of values, and another 1-D tensor of bucket boundaries, return a new tensor where each value is substituted for the index of the corresponding bucket.</p>\n<p>The operation seems to be <a href=\"https://github.com/pytorch/pytorch/blob/master/caffe2/operators/one_hot_ops.cc#L90\">available</a> in Caffe2, but I'm not sure if the code can be reused in PyTorch.</p>\n<p>Alternatively, PyTorch could provide a variant of <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.searchsorted.html\" rel=\"nofollow\"><code>searchsorted</code></a> so that the users can easily write O(log n) bucketization.</p>\n<h2>Code example</h2>\n<p>A trivial implementation might be something like:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">bucketize</span>(<span class=\"pl-smi\">tensor</span>, <span class=\"pl-smi\">bucket_boundaries</span>):\n    result <span class=\"pl-k\">=</span> torch.zeros_like(tensor, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.int32)\n    <span class=\"pl-k\">for</span> boundary <span class=\"pl-k\">in</span> bucket_boundaries:\n        result <span class=\"pl-k\">+=</span> (tensor <span class=\"pl-k\">&gt;</span> boundary).int()\n    <span class=\"pl-k\">return</span> result</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> bucketize(torch.tensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>]), <span class=\"pl-v\">bucket_boundaries</span><span class=\"pl-k\">=</span>torch.tensor([<span class=\"pl-c1\">2</span>]))\ntensor([ <span class=\"pl-c1\">0</span>,  <span class=\"pl-c1\">0</span>,  <span class=\"pl-c1\">0</span>,  <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.int32)</pre></div>\n<p>N.B. the handling of bucket endpoints could be implemented differently.</p>\n<h2>System Info</h2>\n<pre><code>PyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.8.2\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.2)\n[pip3] torch (0.4.0)\n[pip3] torchvision (0.2.1)\n[conda] torch                     0.4.0                     &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "Issue description\nBoth the 0.4.0 version and the master version are missing a bucketization operation, i.e. an operation which given a 1-D tensor of values, and another 1-D tensor of bucket boundaries, return a new tensor where each value is substituted for the index of the corresponding bucket.\nThe operation seems to be available in Caffe2, but I'm not sure if the code can be reused in PyTorch.\nAlternatively, PyTorch could provide a variant of searchsorted so that the users can easily write O(log n) bucketization.\nCode example\nA trivial implementation might be something like:\ndef bucketize(tensor, bucket_boundaries):\n    result = torch.zeros_like(tensor, dtype=torch.int32)\n    for boundary in bucket_boundaries:\n        result += (tensor > boundary).int()\n    return result\n>>> bucketize(torch.tensor([-3, 1, 2, 4]), bucket_boundaries=torch.tensor([2]))\ntensor([ 0,  0,  0,  1], dtype=torch.int32)\nN.B. the handling of bucket endpoints could be implemented differently.\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.8.2\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip3] numpy (1.14.2)\n[pip3] torch (0.4.0)\n[pip3] torchvision (0.2.1)\n[conda] torch                     0.4.0                     <pip>\n[conda] torchvision               0.2.1                     <pip>", "body": "## Issue description\r\n\r\nBoth the 0.4.0 version and the `master` version are missing a bucketization operation, i.e. an operation which given a 1-D tensor of values, and another 1-D tensor of bucket boundaries, return a new tensor where each value is substituted for the index of the corresponding bucket.\r\n\r\nThe operation seems to be [available](https://github.com/pytorch/pytorch/blob/master/caffe2/operators/one_hot_ops.cc#L90) in Caffe2, but I'm not sure if the code can be reused in PyTorch.\r\n\r\nAlternatively, PyTorch could provide a variant of [`searchsorted`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.searchsorted.html) so that the users can easily write O(log n) bucketization.\r\n\r\n## Code example\r\n\r\nA trivial implementation might be something like:\r\n\r\n```python\r\ndef bucketize(tensor, bucket_boundaries):\r\n    result = torch.zeros_like(tensor, dtype=torch.int32)\r\n    for boundary in bucket_boundaries:\r\n        result += (tensor > boundary).int()\r\n    return result\r\n```\r\n\r\n```python\r\n>>> bucketize(torch.tensor([-3, 1, 2, 4]), bucket_boundaries=torch.tensor([2]))\r\ntensor([ 0,  0,  0,  1], dtype=torch.int32)\r\n```\r\n\r\nN.B. the handling of bucket endpoints could be implemented differently.\r\n\r\n## System Info\r\n\r\n```\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.8.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.2)\r\n[pip3] torch (0.4.0)\r\n[pip3] torchvision (0.2.1)\r\n[conda] torch                     0.4.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n"}