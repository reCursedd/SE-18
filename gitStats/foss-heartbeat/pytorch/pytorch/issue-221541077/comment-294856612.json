{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/294856612", "html_url": "https://github.com/pytorch/pytorch/issues/1253#issuecomment-294856612", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1253", "id": 294856612, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDg1NjYxMg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-18T14:10:07Z", "updated_at": "2017-04-18T14:10:07Z", "author_association": "MEMBER", "body_html": "<p>I looked into it and it seems all good to me. Your new gist uses 651MB in the first version and 642MB in the second. The increased memory usage comes from the the way Python uses scopes -- all iterations run in the global one, so when you compute the second one <code>loss</code>, <code>out</code>, etc. are still alive until they're overwritten, thus increasing the peak memory usage. If you add <code>del out, loss, train_in, labels_in</code> after <code>loss.backward()</code> the memory usage will go down to 642MB. In the second case, the variables go out of scope once the function returns, so the memory is freed before the second iteration starts.</p>", "body_text": "I looked into it and it seems all good to me. Your new gist uses 651MB in the first version and 642MB in the second. The increased memory usage comes from the the way Python uses scopes -- all iterations run in the global one, so when you compute the second one loss, out, etc. are still alive until they're overwritten, thus increasing the peak memory usage. If you add del out, loss, train_in, labels_in after loss.backward() the memory usage will go down to 642MB. In the second case, the variables go out of scope once the function returns, so the memory is freed before the second iteration starts.", "body": "I looked into it and it seems all good to me. Your new gist uses 651MB in the first version and 642MB in the second. The increased memory usage comes from the the way Python uses scopes -- all iterations run in the global one, so when you compute the second one `loss`, `out`, etc. are still alive until they're overwritten, thus increasing the peak memory usage. If you add `del out, loss, train_in, labels_in` after `loss.backward()` the memory usage will go down to 642MB. In the second case, the variables go out of scope once the function returns, so the memory is freed before the second iteration starts."}