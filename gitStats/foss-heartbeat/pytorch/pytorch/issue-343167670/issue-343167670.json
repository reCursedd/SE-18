{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9634", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9634/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9634/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9634/events", "html_url": "https://github.com/pytorch/pytorch/issues/9634", "id": 343167670, "node_id": "MDU6SXNzdWUzNDMxNjc2NzA=", "number": 9634, "title": "Model only has gradients when \"x = x + bias\" and not when \"x += bias\"", "user": {"login": "mxbi", "id": 6796648, "node_id": "MDQ6VXNlcjY3OTY2NDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6796648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mxbi", "html_url": "https://github.com/mxbi", "followers_url": "https://api.github.com/users/mxbi/followers", "following_url": "https://api.github.com/users/mxbi/following{/other_user}", "gists_url": "https://api.github.com/users/mxbi/gists{/gist_id}", "starred_url": "https://api.github.com/users/mxbi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mxbi/subscriptions", "organizations_url": "https://api.github.com/users/mxbi/orgs", "repos_url": "https://api.github.com/users/mxbi/repos", "events_url": "https://api.github.com/users/mxbi/events{/privacy}", "received_events_url": "https://api.github.com/users/mxbi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-20T16:17:25Z", "updated_at": "2018-07-20T17:33:17Z", "closed_at": "2018-07-20T17:33:16Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I've built a simple model with a single bias layer (adding a set of constants to the inputs) as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Bias</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">dim</span>):\n        <span class=\"pl-c1\">super</span>(Bias, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">=</span> nn.Parameter(torch.zeros(dim))\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">self</span>.bias\n        <span class=\"pl-k\">return</span> x</pre></div>\n<p>However, when I try training with this with an Adam optimizer, the weights of the bias layer do not change at all. Checking <code>list(model.parameters())</code> shows that it is indeed in the optimizer, and checking <code>list(model.parameters()[0].grad)</code> after running <code>loss.backward()</code> returns a vector of all zeros.</p>\n<p>As soon as I change the <code>x += self.bias</code> to <code>x = x + self.bias</code> in the forward() function, the model trains perfectly. The same issue also occurs with other operators such as <code>*=</code>. This model works:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Bias</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">dim</span>):\n        <span class=\"pl-c1\">super</span>(Bias, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">=</span> nn.Parameter(torch.zeros(dim))\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> x <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.bias\n        <span class=\"pl-k\">return</span> x</pre></div>\n<p>It seems there is some difference with how the gradients of these are calculated which means that the gradients are all-zero when += is used and so training the model does not work. Is this intended behaviour?</p>\n<h2>System Info</h2>\n<pre><code>PyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Ubuntu 16.04.2 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: TITAN X (Pascal)\n\nNvidia driver version: 384.81\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.14.5)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.4.0)\n[pip] torchfile (0.1.0)\n[pip] torchsummary (1.3)\n[pip] torchvision (0.2.1)\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch\n[conda] torchfile                 0.1.0                     &lt;pip&gt;\n[conda] torchsummary              1.3                       &lt;pip&gt;\n[conda] torchvision               0.2.1                    py36_1    pytorch\n</code></pre>", "body_text": "Issue description\nI've built a simple model with a single bias layer (adding a set of constants to the inputs) as follows:\nclass Bias(nn.Module):\n    def __init__(self, dim):\n        super(Bias, self).__init__()\n        self.bias = nn.Parameter(torch.zeros(dim))\n\n    def forward(self, x):\n        x += self.bias\n        return x\nHowever, when I try training with this with an Adam optimizer, the weights of the bias layer do not change at all. Checking list(model.parameters()) shows that it is indeed in the optimizer, and checking list(model.parameters()[0].grad) after running loss.backward() returns a vector of all zeros.\nAs soon as I change the x += self.bias to x = x + self.bias in the forward() function, the model trains perfectly. The same issue also occurs with other operators such as *=. This model works:\nclass Bias(nn.Module):\n    def __init__(self, dim):\n        super(Bias, self).__init__()\n        self.bias = nn.Parameter(torch.zeros(dim))\n\n    def forward(self, x):\n        x = x + self.bias\n        return x\nIt seems there is some difference with how the gradients of these are calculated which means that the gradients are all-zero when += is used and so training the model does not work. Is this intended behaviour?\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\n\nOS: Ubuntu 16.04.2 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCMake version: version 3.5.1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration: \nGPU 0: TITAN X (Pascal)\n\nNvidia driver version: 384.81\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.14.5)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.4.0)\n[pip] torchfile (0.1.0)\n[pip] torchsummary (1.3)\n[pip] torchvision (0.2.1)\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch\n[conda] torchfile                 0.1.0                     <pip>\n[conda] torchsummary              1.3                       <pip>\n[conda] torchvision               0.2.1                    py36_1    pytorch", "body": "## Issue description\r\n\r\nI've built a simple model with a single bias layer (adding a set of constants to the inputs) as follows:\r\n\r\n```python\r\nclass Bias(nn.Module):\r\n    def __init__(self, dim):\r\n        super(Bias, self).__init__()\r\n        self.bias = nn.Parameter(torch.zeros(dim))\r\n\r\n    def forward(self, x):\r\n        x += self.bias\r\n        return x\r\n```\r\nHowever, when I try training with this with an Adam optimizer, the weights of the bias layer do not change at all. Checking `list(model.parameters())` shows that it is indeed in the optimizer, and checking `list(model.parameters()[0].grad)` after running `loss.backward()` returns a vector of all zeros.\r\n\r\nAs soon as I change the `x += self.bias` to `x = x + self.bias` in the forward() function, the model trains perfectly. The same issue also occurs with other operators such as `*=`. This model works:\r\n\r\n```python\r\nclass Bias(nn.Module):\r\n    def __init__(self, dim):\r\n        super(Bias, self).__init__()\r\n        self.bias = nn.Parameter(torch.zeros(dim))\r\n\r\n    def forward(self, x):\r\n        x = x + self.bias\r\n        return x\r\n```\r\nIt seems there is some difference with how the gradients of these are calculated which means that the gradients are all-zero when += is used and so training the model does not work. Is this intended behaviour?\r\n\r\n## System Info\r\n```\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 16.04.2 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: \r\nGPU 0: TITAN X (Pascal)\r\n\r\nNvidia driver version: 384.81\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.5)\r\n[pip] numpydoc (0.8.0)\r\n[pip] torch (0.4.0)\r\n[pip] torchfile (0.1.0)\r\n[pip] torchsummary (1.3)\r\n[pip] torchvision (0.2.1)\r\n[conda] pytorch                   0.4.0           py36_cuda8.0.61_cudnn7.1.2_1    pytorch\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchsummary              1.3                       <pip>\r\n[conda] torchvision               0.2.1                    py36_1    pytorch\r\n```"}