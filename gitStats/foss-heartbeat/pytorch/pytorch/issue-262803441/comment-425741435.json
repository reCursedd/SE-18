{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/425741435", "html_url": "https://github.com/pytorch/pytorch/issues/2971#issuecomment-425741435", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2971", "id": 425741435, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTc0MTQzNQ==", "user": {"login": "Erotemic", "id": 3186211, "node_id": "MDQ6VXNlcjMxODYyMTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3186211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Erotemic", "html_url": "https://github.com/Erotemic", "followers_url": "https://api.github.com/users/Erotemic/followers", "following_url": "https://api.github.com/users/Erotemic/following{/other_user}", "gists_url": "https://api.github.com/users/Erotemic/gists{/gist_id}", "starred_url": "https://api.github.com/users/Erotemic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Erotemic/subscriptions", "organizations_url": "https://api.github.com/users/Erotemic/orgs", "repos_url": "https://api.github.com/users/Erotemic/repos", "events_url": "https://api.github.com/users/Erotemic/events{/privacy}", "received_events_url": "https://api.github.com/users/Erotemic/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-30T18:35:09Z", "updated_at": "2018-09-30T18:35:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm also seeing this error in 0.4.1</p>\n<p>I think I can work around this, so I'm not investing effort in coming up with a MWE, but I can at least post some information about what I think is happening which may help others.</p>\n<p>The relevant part of the traceback I get is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">RuntimeError</span>: Traceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">106</span>, <span class=\"pl-k\">in</span> _worker_loop\n    samples <span class=\"pl-k\">=</span> collate_fn([dataset[i] <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> batch_indices])\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">106</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>listcomp<span class=\"pl-k\">&gt;</span>\n    samples <span class=\"pl-k\">=</span> collate_fn([dataset[i] <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> batch_indices])\n\n<span class=\"pl-c1\">...</span>\n\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/joncrall/code/netharn/netharn/util/nms/nms_core.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">123</span>, <span class=\"pl-k\">in</span> non_max_supression\n    device <span class=\"pl-k\">=</span> torch.cuda.current_device()\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">332</span>, <span class=\"pl-k\">in</span> current_device\n    _lazy_init()\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">159</span>, <span class=\"pl-k\">in</span> _lazy_init\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Cannot re-initialize CUDA in forked subprocess. <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> msg)\n<span class=\"pl-c1\">RuntimeError</span>: Cannot re<span class=\"pl-k\">-</span>initialize <span class=\"pl-c1\">CUDA</span> <span class=\"pl-k\">in</span> forked subprocess. To use <span class=\"pl-c1\">CUDA</span> <span class=\"pl-k\">with</span> multiprocessing, you must use the <span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span> start method</pre></div>\n<p>I think this is happening because I'm using a GPU implementation of nonmax-suppression in my data loader. So perhaps calling <code>torch.cuda.current_device()</code> in a background process is not ok?</p>\n<p>I can work around this by changing my NMS implementation to use a CPU instead. Unfortunately this doesn't fix whatever the underlying issue is.</p>", "body_text": "I'm also seeing this error in 0.4.1\nI think I can work around this, so I'm not investing effort in coming up with a MWE, but I can at least post some information about what I think is happening which may help others.\nThe relevant part of the traceback I get is:\nRuntimeError: Traceback (most recent call last):\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n\n...\n\n  File \"/home/joncrall/code/netharn/netharn/util/nms/nms_core.py\", line 123, in non_max_supression\n    device = torch.cuda.current_device()\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 332, in current_device\n    _lazy_init()\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 159, in _lazy_init\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\nI think this is happening because I'm using a GPU implementation of nonmax-suppression in my data loader. So perhaps calling torch.cuda.current_device() in a background process is not ok?\nI can work around this by changing my NMS implementation to use a CPU instead. Unfortunately this doesn't fix whatever the underlying issue is.", "body": "I'm also seeing this error in 0.4.1\r\n\r\nI think I can work around this, so I'm not investing effort in coming up with a MWE, but I can at least post some information about what I think is happening which may help others. \r\n\r\nThe relevant part of the traceback I get is: \r\n\r\n```python\r\nRuntimeError: Traceback (most recent call last):\r\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n\r\n...\r\n\r\n  File \"/home/joncrall/code/netharn/netharn/util/nms/nms_core.py\", line 123, in non_max_supression\r\n    device = torch.cuda.current_device()\r\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 332, in current_device\r\n    _lazy_init()\r\n  File \"/home/joncrall/.local/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 159, in _lazy_init\r\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\r\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\r\n```\r\n\r\nI think this is happening because I'm using a GPU implementation of nonmax-suppression in my data loader. So perhaps calling `torch.cuda.current_device()` in a background process is not ok? \r\n\r\nI can work around this by changing my NMS implementation to use a CPU instead. Unfortunately this doesn't fix whatever the underlying issue is. "}