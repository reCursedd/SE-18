{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2971", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2971/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2971/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2971/events", "html_url": "https://github.com/pytorch/pytorch/issues/2971", "id": 262803441, "node_id": "MDU6SXNzdWUyNjI4MDM0NDE=", "number": 2971, "title": "RuntimeError: Cannot re-initialize CUDA in forked subprocess", "user": {"login": "GuillaumeLeclerc", "id": 2017051, "node_id": "MDQ6VXNlcjIwMTcwNTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2017051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuillaumeLeclerc", "html_url": "https://github.com/GuillaumeLeclerc", "followers_url": "https://api.github.com/users/GuillaumeLeclerc/followers", "following_url": "https://api.github.com/users/GuillaumeLeclerc/following{/other_user}", "gists_url": "https://api.github.com/users/GuillaumeLeclerc/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuillaumeLeclerc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuillaumeLeclerc/subscriptions", "organizations_url": "https://api.github.com/users/GuillaumeLeclerc/orgs", "repos_url": "https://api.github.com/users/GuillaumeLeclerc/repos", "events_url": "https://api.github.com/users/GuillaumeLeclerc/events{/privacy}", "received_events_url": "https://api.github.com/users/GuillaumeLeclerc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-10-04T14:14:43Z", "updated_at": "2018-09-30T18:35:09Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>Today I ran into this error:</p>\n<p><code>RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method</code></p>\n<p>I saw <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"226741248\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1494\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1494/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1494\">#1494</a> and it seems pretty similar except in my case it only happens after a while and is solved by  a reboot.</p>\n<p>I run Ubuntu 16.04, the latest version of pytorch from conda.</p>\n<p>The code is super simple. I have a function that takes a numpy array and process it with pytorch and return a numpy array. I have multiple inputs so I use <code>torch.threading.Pool</code> and map all the inputs with the function. Therefore there is no sharing of tensors between processes.</p>\n<p>Does anyone know what might be happening ? Since this is in a process the stack trace is useless.</p>\n<p>Thank you</p>", "body_text": "Hello,\nToday I ran into this error:\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\nI saw #1494 and it seems pretty similar except in my case it only happens after a while and is solved by  a reboot.\nI run Ubuntu 16.04, the latest version of pytorch from conda.\nThe code is super simple. I have a function that takes a numpy array and process it with pytorch and return a numpy array. I have multiple inputs so I use torch.threading.Pool and map all the inputs with the function. Therefore there is no sharing of tensors between processes.\nDoes anyone know what might be happening ? Since this is in a process the stack trace is useless.\nThank you", "body": "Hello,\r\n\r\nToday I ran into this error:\r\n\r\n```RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method```\r\n\r\nI saw #1494 and it seems pretty similar except in my case it only happens after a while and is solved by  a reboot.\r\n\r\nI run Ubuntu 16.04, the latest version of pytorch from conda.\r\n\r\nThe code is super simple. I have a function that takes a numpy array and process it with pytorch and return a numpy array. I have multiple inputs so I use `torch.threading.Pool` and map all the inputs with the function. Therefore there is no sharing of tensors between processes.\r\n\r\nDoes anyone know what might be happening ? Since this is in a process the stack trace is useless.\r\n\r\nThank you\r\n"}