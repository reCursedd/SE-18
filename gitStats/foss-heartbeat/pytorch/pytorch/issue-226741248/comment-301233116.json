{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/301233116", "html_url": "https://github.com/pytorch/pytorch/issues/1494#issuecomment-301233116", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1494", "id": 301233116, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTIzMzExNg==", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-13T08:08:52Z", "updated_at": "2017-05-13T08:10:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> Seems to be more complex than I thought. Need to be .cuda on two different GPUs.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> from multiprocessing import set_start_method</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> try:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>     set_start_method('spawn')</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> except RuntimeError:</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>     pass</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Above are NOT executed</span>\n\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.multiprocessing <span class=\"pl-k\">import</span> Process\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">boom</span>():\n    b <span class=\"pl-k\">=</span> torch.FloatTensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>])\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> b = b.cuda(0) # Normal error msg.</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> b = b.cuda(1) # Normal error msg.</span>\n    b <span class=\"pl-k\">=</span> torch.autograd.Variable(b)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> b = b.cuda(1) # Normal error msg.</span>\n    b <span class=\"pl-k\">=</span> b.cuda(<span class=\"pl-c1\">0</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55</span>\n\na <span class=\"pl-k\">=</span> torch.FloatTensor([<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>])\na <span class=\"pl-k\">=</span> a.cuda(<span class=\"pl-c1\">1</span>)\na <span class=\"pl-k\">=</span> torch.autograd.Variable(a)\np <span class=\"pl-k\">=</span> Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>boom,<span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>())\np.daemon <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\np.start()\np.join()\n</pre></div>\n<p>Error:</p>\n<pre><code>THCudaCheck FAIL file=/b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c line=55 error=3 : initialization error\nProcess Process-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/------/test_boom.py\", line 15, in boom\n    b = b.cuda(0) #\n  File \"/------/torch/autograd/variable.py\", line 240, in cuda\n    return CudaTransfer(device_id, async)(self)\n  File \"/------/torch/autograd/_functions/tensor.py\", line 160, in forward\n    return i.cuda(async=self.async)\n  File \"/------/torch/_utils.py\", line 65, in _cuda\n    return new_type(self.size()).copy_(self, async)\nRuntimeError: cuda runtime error (3) : initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55\n</code></pre>", "body_text": "@apaszke Seems to be more complex than I thought. Need to be .cuda on two different GPUs.\n# from multiprocessing import set_start_method\n# try:\n#     set_start_method('spawn')\n# except RuntimeError:\n#     pass\n\n# Above are NOT executed\n\nimport torch\nfrom torch.multiprocessing import Process\n\ndef boom():\n    b = torch.FloatTensor([1,2,3])\n    # b = b.cuda(0) # Normal error msg.\n    # b = b.cuda(1) # Normal error msg.\n    b = torch.autograd.Variable(b)\n    # b = b.cuda(1) # Normal error msg.\n    b = b.cuda(0) # initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55\n\na = torch.FloatTensor([2,2,3])\na = a.cuda(1)\na = torch.autograd.Variable(a)\np = Process(target=boom,args=())\np.daemon = True\np.start()\np.join()\n\nError:\nTHCudaCheck FAIL file=/b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c line=55 error=3 : initialization error\nProcess Process-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/------/test_boom.py\", line 15, in boom\n    b = b.cuda(0) #\n  File \"/------/torch/autograd/variable.py\", line 240, in cuda\n    return CudaTransfer(device_id, async)(self)\n  File \"/------/torch/autograd/_functions/tensor.py\", line 160, in forward\n    return i.cuda(async=self.async)\n  File \"/------/torch/_utils.py\", line 65, in _cuda\n    return new_type(self.size()).copy_(self, async)\nRuntimeError: cuda runtime error (3) : initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55", "body": "@apaszke Seems to be more complex than I thought. Need to be .cuda on two different GPUs.\r\n\r\n``` python\r\n# from multiprocessing import set_start_method\r\n# try:\r\n#     set_start_method('spawn')\r\n# except RuntimeError:\r\n#     pass\r\n\r\n# Above are NOT executed\r\n\r\nimport torch\r\nfrom torch.multiprocessing import Process\r\n\r\ndef boom():\r\n    b = torch.FloatTensor([1,2,3])\r\n    # b = b.cuda(0) # Normal error msg.\r\n    # b = b.cuda(1) # Normal error msg.\r\n    b = torch.autograd.Variable(b)\r\n    # b = b.cuda(1) # Normal error msg.\r\n    b = b.cuda(0) # initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55\r\n\r\na = torch.FloatTensor([2,2,3])\r\na = a.cuda(1)\r\na = torch.autograd.Variable(a)\r\np = Process(target=boom,args=())\r\np.daemon = True\r\np.start()\r\np.join()\r\n\r\n```\r\n\r\nError:\r\n```\r\nTHCudaCheck FAIL file=/b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c line=55 error=3 : initialization error\r\nProcess Process-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/------/test_boom.py\", line 15, in boom\r\n    b = b.cuda(0) #\r\n  File \"/------/torch/autograd/variable.py\", line 240, in cuda\r\n    return CudaTransfer(device_id, async)(self)\r\n  File \"/------/torch/autograd/_functions/tensor.py\", line 160, in forward\r\n    return i.cuda(async=self.async)\r\n  File \"/------/torch/_utils.py\", line 65, in _cuda\r\n    return new_type(self.size()).copy_(self, async)\r\nRuntimeError: cuda runtime error (3) : initialization error at /b/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.c:55\r\n```"}