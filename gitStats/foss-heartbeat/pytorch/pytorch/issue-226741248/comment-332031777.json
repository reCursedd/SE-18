{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/332031777", "html_url": "https://github.com/pytorch/pytorch/issues/1494#issuecomment-332031777", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1494", "id": 332031777, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjAzMTc3Nw==", "user": {"login": "braingineer", "id": 1455742, "node_id": "MDQ6VXNlcjE0NTU3NDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1455742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/braingineer", "html_url": "https://github.com/braingineer", "followers_url": "https://api.github.com/users/braingineer/followers", "following_url": "https://api.github.com/users/braingineer/following{/other_user}", "gists_url": "https://api.github.com/users/braingineer/gists{/gist_id}", "starred_url": "https://api.github.com/users/braingineer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/braingineer/subscriptions", "organizations_url": "https://api.github.com/users/braingineer/orgs", "repos_url": "https://api.github.com/users/braingineer/repos", "events_url": "https://api.github.com/users/braingineer/events{/privacy}", "received_events_url": "https://api.github.com/users/braingineer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-25T22:26:35Z", "updated_at": "2017-09-25T22:26:35Z", "author_association": "NONE", "body_html": "<p>maybe related, not sure if it should be another issue:</p>\n<pre><code>import argparse\nimport torch\nfrom multiprocessing import Process\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--gpu-id\", default=0, type=int,\n                        choices=list(range(torch.cuda.device_count())))\n\n    return parser.parse_args()\n\n\ndef run_in_process():\n    print(torch.cuda.device_count())\n\ndef main():\n    args = parse_args()\n    p = Process(target=run_in_process)\n    p.start()\n    p.join()\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p>gives</p>\n<pre><code>Process Process-1:\nTraceback (most recent call last):\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"maybe_pytorch_bug.py\", line 15, in run_in_process\n    print(torch.cuda.device_count())\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 190, in device_count\n    _lazy_init()\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 83, in _lazy_init\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n</code></pre>\n<p>if the <code>torch.cuda.device_count</code> is taken out of the argument parser, then there is no error.  Not a huge deal to work around, just wanted to flag it.</p>", "body_text": "maybe related, not sure if it should be another issue:\nimport argparse\nimport torch\nfrom multiprocessing import Process\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--gpu-id\", default=0, type=int,\n                        choices=list(range(torch.cuda.device_count())))\n\n    return parser.parse_args()\n\n\ndef run_in_process():\n    print(torch.cuda.device_count())\n\ndef main():\n    args = parse_args()\n    p = Process(target=run_in_process)\n    p.start()\n    p.join()\n\nif __name__ == '__main__':\n    main()\n\ngives\nProcess Process-1:\nTraceback (most recent call last):\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n    self.run()\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"maybe_pytorch_bug.py\", line 15, in run_in_process\n    print(torch.cuda.device_count())\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 190, in device_count\n    _lazy_init()\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 83, in _lazy_init\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n\nif the torch.cuda.device_count is taken out of the argument parser, then there is no error.  Not a huge deal to work around, just wanted to flag it.", "body": "maybe related, not sure if it should be another issue:\r\n\r\n```\r\nimport argparse\r\nimport torch\r\nfrom multiprocessing import Process\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser()\r\n\r\n    parser.add_argument(\"--gpu-id\", default=0, type=int,\r\n                        choices=list(range(torch.cuda.device_count())))\r\n\r\n    return parser.parse_args()\r\n\r\n\r\ndef run_in_process():\r\n    print(torch.cuda.device_count())\r\n\r\ndef main():\r\n    args = parse_args()\r\n    p = Process(target=run_in_process)\r\n    p.start()\r\n    p.join()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\ngives\r\n\r\n```\r\nProcess Process-1:\r\nTraceback (most recent call last):\r\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\r\n    self.run()\r\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"maybe_pytorch_bug.py\", line 15, in run_in_process\r\n    print(torch.cuda.device_count())\r\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 190, in device_count\r\n    _lazy_init()\r\n  File \"/home/brian/anaconda3/envs/t3/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 83, in _lazy_init\r\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\r\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\r\n```\r\n\r\nif the `torch.cuda.device_count` is taken out of the argument parser, then there is no error.  Not a huge deal to work around, just wanted to flag it. "}