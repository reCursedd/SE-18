{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162795817", "pull_request_review_id": 90316793, "id": 162795817, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Mjc5NTgxNw==", "diff_hunk": "@@ -6,10 +6,36 @@\n class Stream(torch._C._CudaStreamBase):\n     \"\"\"Wrapper around a CUDA stream.\n \n+    A `CUDA stream`_ is an independent sequence of execution that belongs to a\n+    specific device.  If you do not create a stream explicitly, each device uses\n+    its own \"default\" stream.\n+\n+    Operations inside each stream is serialized in the order they are created,\n+    but operations from different streams can execute concurrently in any\n+    relative order, unless explicit synchronization instructions (such as\n+    :meth:`~synchronize` or :meth:`~wait_stream`) are used.  For example, the\n+    following code is incorrect:\n+\n+        >>> s = torch.cuda.stream()  # Create a new stream.\n+        >>> A = torch.cuda.FloatTensor(100, 100).normal_(0.0, 1.0)\n+        >>> with torch.cuda.stream(s):\n+        >>>     # sum() may start execution before normal_() finishes!\n+        >>>     B = torch.sum(A)\n+\n+    As convenience, when the \"current stream\" is the default stream, PyTorch\n+    automatically performs necessary synchronization when copying data between\n+    CPU and GPU or between two GPUs.  Hence, as long as you do not explicitly\n+    create a (non-default) stream (or explicitly request asynchronous operation\n+    in, e.g., :meth:`~torch.Tensor.copy_`), your code will run as if every\n+    operation was executed synchronously.  However, when using non-default\n+    streams, it is the user's responsibility to ensure proper synchronization.", "path": "torch/cuda/streams.py", "position": null, "original_position": 26, "commit_id": "e4f79a17bcfe8311abb188241587c79583cb47af", "original_commit_id": "b6398f86ba0de4b00df288e00f999fbf767d80ec", "user": {"login": "yongjik", "id": 31876421, "node_id": "MDQ6VXNlcjMxODc2NDIx", "avatar_url": "https://avatars2.githubusercontent.com/u/31876421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongjik", "html_url": "https://github.com/yongjik", "followers_url": "https://api.github.com/users/yongjik/followers", "following_url": "https://api.github.com/users/yongjik/following{/other_user}", "gists_url": "https://api.github.com/users/yongjik/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongjik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongjik/subscriptions", "organizations_url": "https://api.github.com/users/yongjik/orgs", "repos_url": "https://api.github.com/users/yongjik/repos", "events_url": "https://api.github.com/users/yongjik/events{/privacy}", "received_events_url": "https://api.github.com/users/yongjik/received_events", "type": "User", "site_admin": false}, "body": "Done.  (Also added a paragraph about how asynchronous computation works.)", "created_at": "2018-01-20T22:46:42Z", "updated_at": "2018-11-23T15:38:21Z", "html_url": "https://github.com/pytorch/pytorch/pull/4756#discussion_r162795817", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4756", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162795817"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4756#discussion_r162795817"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4756"}}, "body_html": "<p>Done.  (Also added a paragraph about how asynchronous computation works.)</p>", "body_text": "Done.  (Also added a paragraph about how asynchronous computation works.)", "in_reply_to_id": 162793510}