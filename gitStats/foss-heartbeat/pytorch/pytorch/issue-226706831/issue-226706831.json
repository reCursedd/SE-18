{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1492", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1492/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1492/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1492/events", "html_url": "https://github.com/pytorch/pytorch/pull/1492", "id": 226706831, "node_id": "MDExOlB1bGxSZXF1ZXN0MTE5MjY5MDY3", "number": 1492, "title": "Add a keepdim parameter for reduction functions over a single dimension.", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-05-05T22:23:31Z", "updated_at": "2017-07-19T22:53:53Z", "closed_at": "2017-05-09T23:30:30Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1492", "html_url": "https://github.com/pytorch/pytorch/pull/1492", "diff_url": "https://github.com/pytorch/pytorch/pull/1492.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1492.patch"}, "body_html": "<p>By default, this parameter is False -- a backwards incompatible change, but<br>\none that follows numpy semantics, e.g. numpy.sum (numpy names the parameter<br>\n\"keepdims\" since you can pass multiple dims to reduction functions).</p>\n<p>The old behavior seems desired mainly for normalization type operations<br>\nwhere the tensor will immediately be expanded out again, e.g.:<br>\nprobs.sum(1).expand_as(probs)<br>\nwhich no longer works as written because the dimension to expand is missing.<br>\nThis can be fixed by simply passing True as \"keepdim\" argument<br>\nto the reduction operation, e.g:<br>\nprobs.sum(1, keepdim=True).expand_as(probs)</p>", "body_text": "By default, this parameter is False -- a backwards incompatible change, but\none that follows numpy semantics, e.g. numpy.sum (numpy names the parameter\n\"keepdims\" since you can pass multiple dims to reduction functions).\nThe old behavior seems desired mainly for normalization type operations\nwhere the tensor will immediately be expanded out again, e.g.:\nprobs.sum(1).expand_as(probs)\nwhich no longer works as written because the dimension to expand is missing.\nThis can be fixed by simply passing True as \"keepdim\" argument\nto the reduction operation, e.g:\nprobs.sum(1, keepdim=True).expand_as(probs)", "body": "By default, this parameter is False -- a backwards incompatible change, but\r\none that follows numpy semantics, e.g. numpy.sum (numpy names the parameter\r\n\"keepdims\" since you can pass multiple dims to reduction functions).\r\n\r\nThe old behavior seems desired mainly for normalization type operations\r\nwhere the tensor will immediately be expanded out again, e.g.:\r\nprobs.sum(1).expand_as(probs)\r\nwhich no longer works as written because the dimension to expand is missing.\r\nThis can be fixed by simply passing True as \"keepdim\" argument\r\nto the reduction operation, e.g:\r\nprobs.sum(1, keepdim=True).expand_as(probs)"}