{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/214438065", "pull_request_review_id": 151503352, "id": 214438065, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNDQzODA2NQ==", "diff_hunk": "@@ -798,7 +804,7 @@ void FusedKernel::launch_with_tensors(at::ArrayRef<at::Tensor> inputs, at::Array\n   arguments.reserve(3 + flat_inputs_size + flat_outputs_size);\n   auto addTensorInfoRaw = [&](TensorDesc & desc, void* data_ptr, at::IntList sizes, at::IntList strides) {\n     size_t nDim = desc.nDim(); // NOTE: this is the compressed dim", "path": "torch/csrc/jit/fusion_compiler.cpp", "position": null, "original_position": 43, "commit_id": "78651c25b6947546afef2b02286da0e039c5a285", "original_commit_id": "72f91b16e5b8bb52fb871ea589685394a935db37", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "`desc.nDim()` does return 0 now as a result of the `lastIsContiguous() ` returning False for scalar tensors. \r\n\r\nI can also only patch `desc.nDim()` to return 0 and have `lastIsContiguous()` return True for scalar tensors instead.", "created_at": "2018-08-31T18:22:10Z", "updated_at": "2018-11-23T15:50:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/10952#discussion_r214438065", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10952", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/214438065"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10952#discussion_r214438065"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10952"}}, "body_html": "<p><code>desc.nDim()</code> does return 0 now as a result of the <code>lastIsContiguous() </code> returning False for scalar tensors.</p>\n<p>I can also only patch <code>desc.nDim()</code> to return 0 and have <code>lastIsContiguous()</code> return True for scalar tensors instead.</p>", "body_text": "desc.nDim() does return 0 now as a result of the lastIsContiguous()  returning False for scalar tensors.\nI can also only patch desc.nDim() to return 0 and have lastIsContiguous() return True for scalar tensors instead.", "in_reply_to_id": 214435460}