{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/416757555", "html_url": "https://github.com/pytorch/pytorch/pull/10952#issuecomment-416757555", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10952", "id": 416757555, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjc1NzU1NQ==", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-28T22:10:45Z", "updated_at": "2018-08-28T22:11:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks! I think that this fixes the scalar issue, and the Hamiltonian Monte Carlo examples pass with this change. The VAE example is now throwing a different error, but I think that might be a separate issue. I'll either create a new one or update <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"352355590\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10715\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10715/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10715\">#10715</a>.</p>\n<details><summary> Stack Trace </summary>\n<pre><code>  $ python examples/vae/vae.py --jit\nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\nTraceback (most recent call last):\n  File \"examples/vae/vae.py\", line 212, in &lt;module&gt;\n    model = main(args)\n  File \"examples/vae/vae.py\", line 154, in main\n    epoch_loss += svi.step(x)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\n    ret = self.compiled[argc](*params_and_args)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\n    return self._get_method('forward')(*args, **kwargs)\nRuntimeError:\nThe size of tensor a (256) must match the size of tensor b (96) at non-singleton dimension 0 (infer_size at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/aten/src/ATen/ExpandUtils.cpp:22)\nframe #0: at::TensorIterator::compute_shape() + 381 (0x1142a1a7d in libcaffe2.dylib)\nframe #1: at::TensorIterator::Builder::build() + 159 (0x1142a11bf in libcaffe2.dylib)\nframe #2: at::TensorIterator::binary_op(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 126 (0x1142a0fee in libcaffe2.dylib)\nframe #3: at::native::mul_out(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 319 (0x114163d3f in libcaffe2.dylib)\nframe #4: at::native::mul(at::Tensor const&amp;, at::Tensor const&amp;) + 60 (0x11416439c in libcaffe2.dylib)\nframe #5: at::Type::mul(at::Tensor const&amp;, at::Tensor const&amp;) const + 64 (0x11456a190 in libcaffe2.dylib)\nframe #6: torch::autograd::VariableType::mul(at::Tensor const&amp;, at::Tensor const&amp;) const + 1861 (0x116674315 in libtorch.dylib)\nframe #7: at::mul(at::Tensor const&amp;, at::Tensor const&amp;) + 86 (0x116b4e0b6 in libtorch.dylib)\nframe #8: torch::jit::(anonymous namespace)::$_445::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 162 (0x116b4df92 in libtorch.dylib)\nframe #9: int std::__1::__invoke_void_return_wrapper&lt;int&gt;::__call&lt;torch::jit::(anonymous namespace)::$_445&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&gt;(torch::jit::(anonymous namespace)::$_445&amp;&amp;&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&amp;&amp;) + 77 (0x116b4dedd in libtorch.dylib)\nframe #10: std::__1::__function::__func&lt;torch::jit::(anonymous namespace)::$_445, std::__1::allocator&lt;torch::jit::(anonymous namespace)::$_445&gt;, int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 68 (0x116b4ddd4 in libtorch.dylib)\nframe #11: std::__1::function&lt;int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #12: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #13: torch::jit::InterpreterState::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #14: torch::jit::FusedKernelCache::runFallback(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 50 (0x1168b0de2 in libtorch.dylib)\nframe #15: torch::jit::FusedKernelCache::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 271 (0x1168ae3af in libtorch.dylib)\nframe #16: torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 78 (0x116e8325e in libtorch.dylib)\nframe #17: int std::__1::__invoke_void_return_wrapper&lt;int&gt;::__call&lt;torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&gt;(torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&amp;&amp;&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&amp;&amp;) + 77 (0x116e831fd in libtorch.dylib)\nframe #18: std::__1::__function::__func&lt;torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;), std::__1::allocator&lt;torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;, int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 57 (0x116e82f19 in libtorch.dylib)\nframe #19: std::__1::function&lt;int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #20: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #21: torch::jit::InterpreterState::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #22: torch::jit::(anonymous namespace)::ExecutionPlan::runWithGrad(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 1224 (0x116cbf9d8 in libtorch.dylib)\nframe #23: torch::jit::(anonymous namespace)::ExecutionPlan::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 62 (0x116caff9e in libtorch.dylib)\nframe #24: torch::jit::GraphExecutorImpl::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 2195 (0x116caa533 in libtorch.dylib)\nframe #25: torch::jit::GraphExecutor::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 40 (0x116ca9c98 in libtorch.dylib)\nframe #26: torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 78 (0x116d804be in libtorch.dylib)\nframe #27: int std::__1::__invoke_void_return_wrapper&lt;int&gt;::__call&lt;torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&gt;(torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&amp;&amp;&amp;, std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;&amp;&amp;) + 77 (0x116d8045d in libtorch.dylib)\nframe #28: std::__1::__function::__func&lt;torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;), std::__1::allocator&lt;torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;, int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 57 (0x116d80179 in libtorch.dylib)\nframe #29: std::__1::function&lt;int (std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;)&gt;::operator()(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #30: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #31: torch::jit::InterpreterState::runOneStage(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #32: torch::jit::GraphExecutorImpl::runFallback(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 62 (0x116cae51e in libtorch.dylib)\nframe #33: torch::jit::GraphExecutorImpl::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 2110 (0x116caa4de in libtorch.dylib)\nframe #34: torch::jit::GraphExecutor::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 40 (0x116ca9c98 in libtorch.dylib)\nframe #35: torch::jit::script::Method::run(std::__1::vector&lt;torch::jit::IValue, std::__1::allocator&lt;torch::jit::IValue&gt; &gt;&amp;) + 1144 (0x113399198 in _C.cpython-36m-darwin.so)\nframe #36: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs) + 175 (0x11337b9df in _C.cpython-36m-darwin.so)\nframe #37: pybind11::object pybind11::detail::argument_loader&lt;torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs&gt;::call_impl&lt;pybind11::object, pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), 0ul, 1ul, 2ul, pybind11::detail::void_type&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::detail::index_sequence&lt;0ul, 1ul, 2ul&gt;, pybind11::detail::void_type&amp;&amp;) + 276 (0x1133e5624 in _C.cpython-36m-darwin.so)\nframe #38: std::__1::enable_if&lt;!(std::is_void&lt;pybind11::object&gt;::value), pybind11::object&gt;::type pybind11::detail::argument_loader&lt;torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs&gt;::call&lt;pybind11::object, pybind11::detail::void_type, pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs)&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs)) + 56 (0x1133e4e68 in _C.cpython-36m-darwin.so)\nframe #39: void pybind11::cpp_function::initialize&lt;pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(pybind11::detail::function_call&amp;)::operator()(pybind11::detail::function_call&amp;) const + 225 (0x1133e4d21 in _C.cpython-36m-darwin.so)\nframe #40: void pybind11::cpp_function::initialize&lt;pybind11::object (*&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::object (*&amp;&amp;&amp;)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&amp;, pybind11::args, pybind11::kwargs), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(pybind11::detail::function_call&amp;)::__invoke(pybind11::detail::function_call&amp;) + 24 (0x1133e4c28 in _C.cpython-36m-darwin.so)\nframe #41: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 6919 (0x112c432b7 in _C.cpython-36m-darwin.so)\n&lt;omitting python frames&gt;\n:\noperation failed in interpreter:\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/normal.py(59): rsample\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/independent.py(75): rsample\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/distributions/torch_distribution.py(42): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(119): default_process_message\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(181): apply_stack\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/primitives.py(84): sample\nexamples/vae/vae.py(105): guide\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(176): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(192): get_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/enum.py(40): get_importance_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(52): _get_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/elbo.py(111): _get_traces\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(168): loss_and_surrogate_loss\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(49): compiled\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py(290): wrapper\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(39): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(202): loss_and_grads\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py(96): step\nexamples/vae/vae.py(154): main\nexamples/vae/vae.py(212): &lt;module&gt;\n</code></pre>\n</details>", "body_text": "Thanks! I think that this fixes the scalar issue, and the Hamiltonian Monte Carlo examples pass with this change. The VAE example is now throwing a different error, but I think that might be a separate issue. I'll either create a new one or update #10715.\n Stack Trace \n  $ python examples/vae/vae.py --jit\nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\nTraceback (most recent call last):\n  File \"examples/vae/vae.py\", line 212, in <module>\n    model = main(args)\n  File \"examples/vae/vae.py\", line 154, in main\n    epoch_loss += svi.step(x)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\n    ret = self.compiled[argc](*params_and_args)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\n    return self._get_method('forward')(*args, **kwargs)\nRuntimeError:\nThe size of tensor a (256) must match the size of tensor b (96) at non-singleton dimension 0 (infer_size at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/aten/src/ATen/ExpandUtils.cpp:22)\nframe #0: at::TensorIterator::compute_shape() + 381 (0x1142a1a7d in libcaffe2.dylib)\nframe #1: at::TensorIterator::Builder::build() + 159 (0x1142a11bf in libcaffe2.dylib)\nframe #2: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&) + 126 (0x1142a0fee in libcaffe2.dylib)\nframe #3: at::native::mul_out(at::Tensor&, at::Tensor const&, at::Tensor const&) + 319 (0x114163d3f in libcaffe2.dylib)\nframe #4: at::native::mul(at::Tensor const&, at::Tensor const&) + 60 (0x11416439c in libcaffe2.dylib)\nframe #5: at::Type::mul(at::Tensor const&, at::Tensor const&) const + 64 (0x11456a190 in libcaffe2.dylib)\nframe #6: torch::autograd::VariableType::mul(at::Tensor const&, at::Tensor const&) const + 1861 (0x116674315 in libtorch.dylib)\nframe #7: at::mul(at::Tensor const&, at::Tensor const&) + 86 (0x116b4e0b6 in libtorch.dylib)\nframe #8: torch::jit::(anonymous namespace)::$_445::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 162 (0x116b4df92 in libtorch.dylib)\nframe #9: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::(anonymous namespace)::$_445&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::(anonymous namespace)::$_445&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116b4dedd in libtorch.dylib)\nframe #10: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_445, std::__1::allocator<torch::jit::(anonymous namespace)::$_445>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 68 (0x116b4ddd4 in libtorch.dylib)\nframe #11: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #12: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #13: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #14: torch::jit::FusedKernelCache::runFallback(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 50 (0x1168b0de2 in libtorch.dylib)\nframe #15: torch::jit::FusedKernelCache::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 271 (0x1168ae3af in libtorch.dylib)\nframe #16: torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 78 (0x116e8325e in libtorch.dylib)\nframe #17: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116e831fd in libtorch.dylib)\nframe #18: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 57 (0x116e82f19 in libtorch.dylib)\nframe #19: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #20: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #21: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #22: torch::jit::(anonymous namespace)::ExecutionPlan::runWithGrad(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 1224 (0x116cbf9d8 in libtorch.dylib)\nframe #23: torch::jit::(anonymous namespace)::ExecutionPlan::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 62 (0x116caff9e in libtorch.dylib)\nframe #24: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 2195 (0x116caa533 in libtorch.dylib)\nframe #25: torch::jit::GraphExecutor::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116ca9c98 in libtorch.dylib)\nframe #26: torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 78 (0x116d804be in libtorch.dylib)\nframe #27: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116d8045d in libtorch.dylib)\nframe #28: std::__1::__function::__func<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 57 (0x116d80179 in libtorch.dylib)\nframe #29: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\nframe #30: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\nframe #31: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\nframe #32: torch::jit::GraphExecutorImpl::runFallback(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 62 (0x116cae51e in libtorch.dylib)\nframe #33: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 2110 (0x116caa4de in libtorch.dylib)\nframe #34: torch::jit::GraphExecutor::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116ca9c98 in libtorch.dylib)\nframe #35: torch::jit::script::Method::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 1144 (0x113399198 in _C.cpython-36m-darwin.so)\nframe #36: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&, pybind11::args, pybind11::kwargs) + 175 (0x11337b9df in _C.cpython-36m-darwin.so)\nframe #37: pybind11::object pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args, pybind11::kwargs>::call_impl<pybind11::object, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), 0ul, 1ul, 2ul, pybind11::detail::void_type>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::detail::index_sequence<0ul, 1ul, 2ul>, pybind11::detail::void_type&&) + 276 (0x1133e5624 in _C.cpython-36m-darwin.so)\nframe #38: std::__1::enable_if<!(std::is_void<pybind11::object>::value), pybind11::object>::type pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args, pybind11::kwargs>::call<pybind11::object, pybind11::detail::void_type, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs)>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs)) + 56 (0x1133e4e68 in _C.cpython-36m-darwin.so)\nframe #39: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 225 (0x1133e4d21 in _C.cpython-36m-darwin.so)\nframe #40: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 24 (0x1133e4c28 in _C.cpython-36m-darwin.so)\nframe #41: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 6919 (0x112c432b7 in _C.cpython-36m-darwin.so)\n<omitting python frames>\n:\noperation failed in interpreter:\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/normal.py(59): rsample\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/independent.py(75): rsample\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/distributions/torch_distribution.py(42): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(119): default_process_message\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(181): apply_stack\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/primitives.py(84): sample\nexamples/vae/vae.py(105): guide\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(176): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(192): get_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/enum.py(40): get_importance_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(52): _get_trace\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/elbo.py(111): _get_traces\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(168): loss_and_surrogate_loss\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(49): compiled\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py(290): wrapper\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(39): __call__\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(202): loss_and_grads\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py(96): step\nexamples/vae/vae.py(154): main\nexamples/vae/vae.py(212): <module>", "body": "Thanks! I think that this fixes the scalar issue, and the Hamiltonian Monte Carlo examples pass with this change. The VAE example is now throwing a different error, but I think that might be a separate issue. I'll either create a new one or update #10715. \r\n\r\n<details><Summary> Stack Trace </Summary>\r\n\r\n```\r\n  $ python examples/vae/vae.py --jit\r\nclang: error: unsupported option '-fopenmp'\r\nclang: error: unsupported option '-fopenmp'\r\nwarning: pytorch jit fuser failed to compile with openmp, trying without it...\r\nTraceback (most recent call last):\r\n  File \"examples/vae/vae.py\", line 212, in <module>\r\n    model = main(args)\r\n  File \"examples/vae/vae.py\", line 154, in main\r\n    epoch_loss += svi.step(x)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py\", line 96, in step\r\n    loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py\", line 202, in loss_and_grads\r\n    loss, surrogate_loss = self._loss_and_surrogate_loss(*args)\r\n  File \"/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py\", line 59, in __call__\r\n    ret = self.compiled[argc](*params_and_args)\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 736, in forward\r\n    return self._get_method('forward')(*args, **kwargs)\r\nRuntimeError:\r\nThe size of tensor a (256) must match the size of tensor b (96) at non-singleton dimension 0 (infer_size at /Users/npradhan/workspace/pyro_dev/pytorch/pytorch/aten/src/ATen/ExpandUtils.cpp:22)\r\nframe #0: at::TensorIterator::compute_shape() + 381 (0x1142a1a7d in libcaffe2.dylib)\r\nframe #1: at::TensorIterator::Builder::build() + 159 (0x1142a11bf in libcaffe2.dylib)\r\nframe #2: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&) + 126 (0x1142a0fee in libcaffe2.dylib)\r\nframe #3: at::native::mul_out(at::Tensor&, at::Tensor const&, at::Tensor const&) + 319 (0x114163d3f in libcaffe2.dylib)\r\nframe #4: at::native::mul(at::Tensor const&, at::Tensor const&) + 60 (0x11416439c in libcaffe2.dylib)\r\nframe #5: at::Type::mul(at::Tensor const&, at::Tensor const&) const + 64 (0x11456a190 in libcaffe2.dylib)\r\nframe #6: torch::autograd::VariableType::mul(at::Tensor const&, at::Tensor const&) const + 1861 (0x116674315 in libtorch.dylib)\r\nframe #7: at::mul(at::Tensor const&, at::Tensor const&) + 86 (0x116b4e0b6 in libtorch.dylib)\r\nframe #8: torch::jit::(anonymous namespace)::$_445::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 162 (0x116b4df92 in libtorch.dylib)\r\nframe #9: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::(anonymous namespace)::$_445&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::(anonymous namespace)::$_445&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116b4dedd in libtorch.dylib)\r\nframe #10: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_445, std::__1::allocator<torch::jit::(anonymous namespace)::$_445>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 68 (0x116b4ddd4 in libtorch.dylib)\r\nframe #11: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\r\nframe #12: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\r\nframe #13: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\r\nframe #14: torch::jit::FusedKernelCache::runFallback(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 50 (0x1168b0de2 in libtorch.dylib)\r\nframe #15: torch::jit::FusedKernelCache::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 271 (0x1168ae3af in libtorch.dylib)\r\nframe #16: torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 78 (0x116e8325e in libtorch.dylib)\r\nframe #17: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116e831fd in libtorch.dylib)\r\nframe #18: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::(anonymous namespace)::$_0::operator()(torch::jit::Node*) const::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 57 (0x116e82f19 in libtorch.dylib)\r\nframe #19: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\r\nframe #20: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\r\nframe #21: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\r\nframe #22: torch::jit::(anonymous namespace)::ExecutionPlan::runWithGrad(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 1224 (0x116cbf9d8 in libtorch.dylib)\r\nframe #23: torch::jit::(anonymous namespace)::ExecutionPlan::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 62 (0x116caff9e in libtorch.dylib)\r\nframe #24: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 2195 (0x116caa533 in libtorch.dylib)\r\nframe #25: torch::jit::GraphExecutor::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116ca9c98 in libtorch.dylib)\r\nframe #26: torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 78 (0x116d804be in libtorch.dylib)\r\nframe #27: int std::__1::__invoke_void_return_wrapper<int>::__call<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&>(torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)&&&, std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&&&) + 77 (0x116d8045d in libtorch.dylib)\r\nframe #28: std::__1::__function::__func<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&), std::__1::allocator<torch::jit::CodeImpl::getInterpreterOperation(torch::jit::Node*)::'lambda'(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>, int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 57 (0x116d80179 in libtorch.dylib)\r\nframe #29: std::__1::function<int (std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&)>::operator()(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) const + 142 (0x113256c4e in _C.cpython-36m-darwin.so)\r\nframe #30: torch::jit::InterpreterStateImpl::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 315 (0x116d5a5eb in libtorch.dylib)\r\nframe #31: torch::jit::InterpreterState::runOneStage(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116d5a4a8 in libtorch.dylib)\r\nframe #32: torch::jit::GraphExecutorImpl::runFallback(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 62 (0x116cae51e in libtorch.dylib)\r\nframe #33: torch::jit::GraphExecutorImpl::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 2110 (0x116caa4de in libtorch.dylib)\r\nframe #34: torch::jit::GraphExecutor::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 40 (0x116ca9c98 in libtorch.dylib)\r\nframe #35: torch::jit::script::Method::run(std::__1::vector<torch::jit::IValue, std::__1::allocator<torch::jit::IValue> >&) + 1144 (0x113399198 in _C.cpython-36m-darwin.so)\r\nframe #36: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&, pybind11::args, pybind11::kwargs) + 175 (0x11337b9df in _C.cpython-36m-darwin.so)\r\nframe #37: pybind11::object pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args, pybind11::kwargs>::call_impl<pybind11::object, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), 0ul, 1ul, 2ul, pybind11::detail::void_type>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::detail::index_sequence<0ul, 1ul, 2ul>, pybind11::detail::void_type&&) + 276 (0x1133e5624 in _C.cpython-36m-darwin.so)\r\nframe #38: std::__1::enable_if<!(std::is_void<pybind11::object>::value), pybind11::object>::type pybind11::detail::argument_loader<torch::jit::script::Method&, pybind11::args, pybind11::kwargs>::call<pybind11::object, pybind11::detail::void_type, pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs)>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs)) + 56 (0x1133e4e68 in _C.cpython-36m-darwin.so)\r\nframe #39: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::operator()(pybind11::detail::function_call&) const + 225 (0x1133e4d21 in _C.cpython-36m-darwin.so)\r\nframe #40: void pybind11::cpp_function::initialize<pybind11::object (*&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object, torch::jit::script::Method&, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11::object (*&&&)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::object (*)(torch::jit::script::Method&, pybind11::args, pybind11::kwargs), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 24 (0x1133e4c28 in _C.cpython-36m-darwin.so)\r\nframe #41: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 6919 (0x112c432b7 in _C.cpython-36m-darwin.so)\r\n<omitting python frames>\r\n:\r\noperation failed in interpreter:\r\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/normal.py(59): rsample\r\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/distributions/independent.py(75): rsample\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/distributions/torch_distribution.py(42): __call__\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(119): default_process_message\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/runtime.py(181): apply_stack\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/primitives.py(84): sample\r\nexamples/vae/vae.py(105): guide\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(176): __call__\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/trace_messenger.py(192): get_trace\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/enum.py(40): get_importance_trace\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(52): _get_trace\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/elbo.py(111): _get_traces\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(168): loss_and_surrogate_loss\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/poutine/messenger.py(27): _wraps\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(49): compiled\r\n/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py(290): wrapper\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/ops/jit.py(39): __call__\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/trace_elbo.py(202): loss_and_grads\r\n/Users/npradhan/workspace/pyro_dev/pyro/pyro/infer/svi.py(96): step\r\nexamples/vae/vae.py(154): main\r\nexamples/vae/vae.py(212): <module>\r\n```\r\n\r\n</details>"}