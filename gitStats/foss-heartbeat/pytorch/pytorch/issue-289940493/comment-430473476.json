{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430473476", "html_url": "https://github.com/pytorch/pytorch/issues/4741#issuecomment-430473476", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4741", "id": 430473476, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDQ3MzQ3Ng==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T03:06:15Z", "updated_at": "2018-10-17T03:06:15Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>pytorch applies bessel's correction by default</p>\n</blockquote>\n<p>Yes, that's what the BN paper proposes.</p>\n<blockquote>\n<p>inputs are not normalized by their own batch statistics, but rather the updated version of the running mean/var</p>\n</blockquote>\n<p>You will get wrong gradient this will though. So no.</p>\n<blockquote>\n<p>single batch of data</p>\n</blockquote>\n<p>how many samples do you have in there?</p>", "body_text": "pytorch applies bessel's correction by default\n\nYes, that's what the BN paper proposes.\n\ninputs are not normalized by their own batch statistics, but rather the updated version of the running mean/var\n\nYou will get wrong gradient this will though. So no.\n\nsingle batch of data\n\nhow many samples do you have in there?", "body": "> pytorch applies bessel's correction by default\r\n\r\nYes, that's what the BN paper proposes.\r\n\r\n> inputs are not normalized by their own batch statistics, but rather the updated version of the running mean/var\r\n\r\nYou will get wrong gradient this will though. So no.\r\n\r\n> single batch of data\r\n\r\nhow many samples do you have in there?"}