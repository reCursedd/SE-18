{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430475146", "html_url": "https://github.com/pytorch/pytorch/issues/4741#issuecomment-430475146", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4741", "id": 430475146, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDQ3NTE0Ng==", "user": {"login": "penguinshin", "id": 10840426, "node_id": "MDQ6VXNlcjEwODQwNDI2", "avatar_url": "https://avatars3.githubusercontent.com/u/10840426?v=4", "gravatar_id": "", "url": "https://api.github.com/users/penguinshin", "html_url": "https://github.com/penguinshin", "followers_url": "https://api.github.com/users/penguinshin/followers", "following_url": "https://api.github.com/users/penguinshin/following{/other_user}", "gists_url": "https://api.github.com/users/penguinshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/penguinshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/penguinshin/subscriptions", "organizations_url": "https://api.github.com/users/penguinshin/orgs", "repos_url": "https://api.github.com/users/penguinshin/repos", "events_url": "https://api.github.com/users/penguinshin/events{/privacy}", "received_events_url": "https://api.github.com/users/penguinshin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T03:16:25Z", "updated_at": "2018-10-17T03:19:20Z", "author_association": "NONE", "body_html": "<p>Sorry for the trouble...</p>\n<p>Its the same dimensions as the example above, so I feed a 180x1x180 ultimately. However, I think there is something special I'm doing that might be throwing off the batchnorm, maybe you can tell me if this would negatively impact -</p>\n<p>I originally have a 128 x 1 x 360 window. I loop through each of the 128 windows and create 180 windows of width 180, so for example, the first 360 window would be converted into 180 sliding windows of length 180. I run each 180x1x180 window  (of the 128) through the net and sum the losses over all 128, before calling a backward pass and running optimizer.step(). Presumably, using train mode would mean that each of those windows (of the 128) would be batch normalized appropriately within one backward pass.</p>\n<p>My guess is that each window's high autocorrelation (since the 180 batches are all from one continuous 360 window) produces a sharp batch statistics, and maybe that is responsible for the issue, but I don't know for sure. I am going to try setting a lower momentum.</p>", "body_text": "Sorry for the trouble...\nIts the same dimensions as the example above, so I feed a 180x1x180 ultimately. However, I think there is something special I'm doing that might be throwing off the batchnorm, maybe you can tell me if this would negatively impact -\nI originally have a 128 x 1 x 360 window. I loop through each of the 128 windows and create 180 windows of width 180, so for example, the first 360 window would be converted into 180 sliding windows of length 180. I run each 180x1x180 window  (of the 128) through the net and sum the losses over all 128, before calling a backward pass and running optimizer.step(). Presumably, using train mode would mean that each of those windows (of the 128) would be batch normalized appropriately within one backward pass.\nMy guess is that each window's high autocorrelation (since the 180 batches are all from one continuous 360 window) produces a sharp batch statistics, and maybe that is responsible for the issue, but I don't know for sure. I am going to try setting a lower momentum.", "body": "Sorry for the trouble...\r\n\r\nIts the same dimensions as the example above, so I feed a 180x1x180 ultimately. However, I think there is something special I'm doing that might be throwing off the batchnorm, maybe you can tell me if this would negatively impact - \r\n\r\nI originally have a 128 x 1 x 360 window. I loop through each of the 128 windows and create 180 windows of width 180, so for example, the first 360 window would be converted into 180 sliding windows of length 180. I run each 180x1x180 window  (of the 128) through the net and sum the losses over all 128, before calling a backward pass and running optimizer.step(). Presumably, using train mode would mean that each of those windows (of the 128) would be batch normalized appropriately within one backward pass. \r\n\r\nMy guess is that each window's high autocorrelation (since the 180 batches are all from one continuous 360 window) produces a sharp batch statistics, and maybe that is responsible for the issue, but I don't know for sure. I am going to try setting a lower momentum."}