{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184891827", "pull_request_review_id": 116175319, "id": 184891827, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDg5MTgyNw==", "diff_hunk": "@@ -281,5 +250,143 @@ Tensor embedding_bag_backward_cuda(const Tensor &grad_, const Tensor &indices,\n   THCudaCheck(cudaGetLastError());\n   return grad_weight;\n }\n+\n+template <typename scalar_t>\n+__global__ void EmbeddingBag_accGradParametersKernel_max(\n+    int64_t *max_indices, scalar_t *gradOutput,\n+    scalar_t *gradWeight, int64_t stride, int64_t numBags) {\n+\n+  using accscalar_t = cuda::acc_type<scalar_t>;\n+\n+  int64_t chunksPerBag = THCCeilDiv(stride, (int64_t)blockDim.x);\n+  int64_t numChunks = numBags * chunksPerBag;\n+  int64_t chunkOffset = blockIdx.x * blockDim.y + threadIdx.y;\n+  int64_t chunkStride = gridDim.x * blockDim.y;\n+\n+  for (int64_t chunk = chunkOffset; chunk < numChunks; chunk += chunkStride) {\n+    int64_t featureDim = (chunk % chunksPerBag) * blockDim.x + threadIdx.x;\n+    if (featureDim < stride) {\n+      int64_t bag = chunk / chunksPerBag;\n+\n+      int64_t word_idx = max_indices[bag * stride + featureDim];\n+      \n+      atomicAdd(&(gradWeight[word_idx * stride + featureDim]), gradOutput[bag * stride + featureDim]);", "path": "aten/src/ATen/native/cuda/EmbeddingBag.cu", "position": 200, "original_position": 200, "commit_id": "64b3f40534d8b4fe1f99680940a98d410c1d045f", "original_commit_id": "9deb22c6b995b54164078e219e7ca1dce93f85a6", "user": {"login": "Lalaland", "id": 342233, "node_id": "MDQ6VXNlcjM0MjIzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/342233?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lalaland", "html_url": "https://github.com/Lalaland", "followers_url": "https://api.github.com/users/Lalaland/followers", "following_url": "https://api.github.com/users/Lalaland/following{/other_user}", "gists_url": "https://api.github.com/users/Lalaland/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lalaland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lalaland/subscriptions", "organizations_url": "https://api.github.com/users/Lalaland/orgs", "repos_url": "https://api.github.com/users/Lalaland/repos", "events_url": "https://api.github.com/users/Lalaland/events{/privacy}", "received_events_url": "https://api.github.com/users/Lalaland/received_events", "type": "User", "site_admin": false}, "body": "I'll look into this and create a separate PR for that once this PR lands. I was mainly just copying the overall logic of SpatialAdaptiveMaxPooling.cu (which uses atomicAdd) for this initial PR. In theory it should be rather straightforward, just sort by the target location just like how the rest of the embedding bag code works.", "created_at": "2018-04-29T19:04:13Z", "updated_at": "2018-11-23T15:43:24Z", "html_url": "https://github.com/pytorch/pytorch/pull/5725#discussion_r184891827", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5725", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184891827"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5725#discussion_r184891827"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5725"}}, "body_html": "<p>I'll look into this and create a separate PR for that once this PR lands. I was mainly just copying the overall logic of SpatialAdaptiveMaxPooling.cu (which uses atomicAdd) for this initial PR. In theory it should be rather straightforward, just sort by the target location just like how the rest of the embedding bag code works.</p>", "body_text": "I'll look into this and create a separate PR for that once this PR lands. I was mainly just copying the overall logic of SpatialAdaptiveMaxPooling.cu (which uses atomicAdd) for this initial PR. In theory it should be rather straightforward, just sort by the target location just like how the rest of the embedding bag code works.", "in_reply_to_id": 184890207}