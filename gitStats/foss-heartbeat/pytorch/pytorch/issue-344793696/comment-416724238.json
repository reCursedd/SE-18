{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/416724238", "html_url": "https://github.com/pytorch/pytorch/issues/9873#issuecomment-416724238", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9873", "id": 416724238, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjcyNDIzOA==", "user": {"login": "simonm3", "id": 1199593, "node_id": "MDQ6VXNlcjExOTk1OTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1199593?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonm3", "html_url": "https://github.com/simonm3", "followers_url": "https://api.github.com/users/simonm3/followers", "following_url": "https://api.github.com/users/simonm3/following{/other_user}", "gists_url": "https://api.github.com/users/simonm3/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonm3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonm3/subscriptions", "organizations_url": "https://api.github.com/users/simonm3/orgs", "repos_url": "https://api.github.com/users/simonm3/repos", "events_url": "https://api.github.com/users/simonm3/events{/privacy}", "received_events_url": "https://api.github.com/users/simonm3/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-28T20:12:08Z", "updated_at": "2018-08-28T20:12:08Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31172908\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/berkinmalkoc\">@berkinmalkoc</a>  if I uninstall intel-openmp then it uninstalls a long list of packages that depend on it such as numpy and mkldnn. I guess you have two openmp versions installed so need to uninstall one to avoid clashes; whereas I have just the one.</p>\n<p>I tried setting OMP_NUM_THREADS/MKL_NUM_THREADS but whatever setting I tried seemed to make no difference to the timings on either 8 or 72 vcpus.</p>\n<p>I increased my batch size from 5 to 100 which made pytorch faster but not keras. Now pytorch is 191 minutes on 8 vcpus and 48 minutes on 72 so a multiple of 4. Meanwhile keras is 463 minutes on 8 vcpus and 63 minutes on 72 so a multiple of 7 which still seems significantly different,</p>\n<p>I did struggle a bit getting consistent benchmarks as it is hard to clear all caches and get a stable starting point so all numbers are approximate. Also there may be different optimisation methods between keras and pytorch; and indeed my models are not identical.  So perhaps this kind of difference is to be expected.</p>", "body_text": "@berkinmalkoc  if I uninstall intel-openmp then it uninstalls a long list of packages that depend on it such as numpy and mkldnn. I guess you have two openmp versions installed so need to uninstall one to avoid clashes; whereas I have just the one.\nI tried setting OMP_NUM_THREADS/MKL_NUM_THREADS but whatever setting I tried seemed to make no difference to the timings on either 8 or 72 vcpus.\nI increased my batch size from 5 to 100 which made pytorch faster but not keras. Now pytorch is 191 minutes on 8 vcpus and 48 minutes on 72 so a multiple of 4. Meanwhile keras is 463 minutes on 8 vcpus and 63 minutes on 72 so a multiple of 7 which still seems significantly different,\nI did struggle a bit getting consistent benchmarks as it is hard to clear all caches and get a stable starting point so all numbers are approximate. Also there may be different optimisation methods between keras and pytorch; and indeed my models are not identical.  So perhaps this kind of difference is to be expected.", "body": "@berkinmalkoc  if I uninstall intel-openmp then it uninstalls a long list of packages that depend on it such as numpy and mkldnn. I guess you have two openmp versions installed so need to uninstall one to avoid clashes; whereas I have just the one.\r\n\r\nI tried setting OMP_NUM_THREADS/MKL_NUM_THREADS but whatever setting I tried seemed to make no difference to the timings on either 8 or 72 vcpus.\r\n\r\nI increased my batch size from 5 to 100 which made pytorch faster but not keras. Now pytorch is 191 minutes on 8 vcpus and 48 minutes on 72 so a multiple of 4. Meanwhile keras is 463 minutes on 8 vcpus and 63 minutes on 72 so a multiple of 7 which still seems significantly different,\r\n\r\nI did struggle a bit getting consistent benchmarks as it is hard to clear all caches and get a stable starting point so all numbers are approximate. Also there may be different optimisation methods between keras and pytorch; and indeed my models are not identical.  So perhaps this kind of difference is to be expected."}