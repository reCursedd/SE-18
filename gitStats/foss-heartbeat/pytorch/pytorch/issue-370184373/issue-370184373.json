{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12651", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12651/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12651/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12651/events", "html_url": "https://github.com/pytorch/pytorch/issues/12651", "id": 370184373, "node_id": "MDU6SXNzdWUzNzAxODQzNzM=", "number": 12651, "title": "With extremely large input 1D convolution manages memory unexpectedly", "user": {"login": "olyaromanyuk", "id": 15520877, "node_id": "MDQ6VXNlcjE1NTIwODc3", "avatar_url": "https://avatars0.githubusercontent.com/u/15520877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/olyaromanyuk", "html_url": "https://github.com/olyaromanyuk", "followers_url": "https://api.github.com/users/olyaromanyuk/followers", "following_url": "https://api.github.com/users/olyaromanyuk/following{/other_user}", "gists_url": "https://api.github.com/users/olyaromanyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/olyaromanyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/olyaromanyuk/subscriptions", "organizations_url": "https://api.github.com/users/olyaromanyuk/orgs", "repos_url": "https://api.github.com/users/olyaromanyuk/repos", "events_url": "https://api.github.com/users/olyaromanyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/olyaromanyuk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-15T14:15:23Z", "updated_at": "2018-10-15T17:45:40Z", "closed_at": "2018-10-15T17:45:40Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>For extremely large inputs ( approximately 5*100,000,000) the training process behaves very differently for different but very close input sizes. For size 5*97,825,587 and smaller training runs ok for more than 10 epochs, for the size 5*97,825,588 and larger training fails during the second epoch with RuntimeError: CUDA error: out of memory</p>\n<h2>To Reproduce</h2>\n<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.cuda.set_device(1)\n\nsequence_length = 97825587\nprint(sequence_length)\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=5, out_channels=1, kernel_size=sequence_length, stride=10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = torch.sigmoid(x)\n        return x\n\nmodel = Net().cuda()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.BCELoss()\n\ndata = torch.normal(torch.zeros(1, 5, sequence_length), torch.ones(1, 5, sequence_length))\ndata = data.cuda()\nlabel = torch.ones(1, 1, 1)\nlabel = label.cuda()\n\nfor epoch in range(10):\n    output = model(data)\n    print(output.shape)\n\n    loss = criterion(output, label)\n\n    optimizer.zero_grad()\n    loss.backward()\n\n    optimizer.step()\n\n\n    event = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, 1 * len(data),\n                                                                     1,\n                                                                     100. * 1 / 1,\n                                                                     float(loss) / 1)\n    print(event)\n\n</code></pre>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Run the code with <code>sequence_length = 97825587</code> and <code>sequence_length = 97825588</code></li>\n</ol>\n<h2>Expected behavior</h2>\n<p>Fail during the second epoch doesn't look right, if the input is too large the training should fail during the first epoch.<br>\nI was monitoring the memory usage, the training with smaller input used 12199Mb, with a bit larger input first epoch was finished with 11640Mb used and during backpropagation in the second epoch, the error was encountered.<br>\nI think some small memory leak is unlikely if it was the case the training with a bit smaller input would run out of memory during one of the epochs.<br>\nI assume that the cause is likely somewhere in the implementation of convolution. The convolution I use in the code is equivalent to a linear layer, it calculates the same output and has the same number of parameters, but I could not find the same behaviour with linear layer</p>\n<h2>Environment</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0<br>\nCMake version: Could not collect</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.1.85<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX TITAN X<br>\nGPU 1: GeForce GTX TITAN X<br>\nGPU 2: GeForce GTX TITAN X<br>\nGPU 3: GeForce GTX TITAN X</p>\n<p>Nvidia driver version: 390.87<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] Could not collect</p>\n<p>The issue is not unique for version 0.4, I've tested it with 2018/10/15 nightly build, the exact input size where behavior changes moved, but the issue is still there.</p>\n<h2>Additional context</h2>\n<p>I've designed the code above to understand the memory usage of convolutional layers, here are links to my questions at Pytorch Forums and StackOverflow, maybe you will find something useful there</p>\n<ul>\n<li><a href=\"https://discuss.pytorch.org/t/with-extremely-large-input-1d-convolution-uses-memory-inefficiently/27066\" rel=\"nofollow\">https://discuss.pytorch.org/t/with-extremely-large-input-1d-convolution-uses-memory-inefficiently/27066</a></li>\n<li><a href=\"https://stackoverflow.com/questions/52762173/pytorch-convolutional-network-memory-usage-details\" rel=\"nofollow\">https://stackoverflow.com/questions/52762173/pytorch-convolutional-network-memory-usage-details</a></li>\n</ul>\n<p>I think, that this issue is related to what is described here</p>\n<ul>\n<li><a href=\"https://discuss.pytorch.org/t/how-to-free-gpu-memory-and-delete-memory-allocated-variables/20856\" rel=\"nofollow\">https://discuss.pytorch.org/t/how-to-free-gpu-memory-and-delete-memory-allocated-variables/20856</a></li>\n</ul>", "body_text": "\ud83d\udc1b Bug\nFor extremely large inputs ( approximately 5*100,000,000) the training process behaves very differently for different but very close input sizes. For size 5*97,825,587 and smaller training runs ok for more than 10 epochs, for the size 5*97,825,588 and larger training fails during the second epoch with RuntimeError: CUDA error: out of memory\nTo Reproduce\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.cuda.set_device(1)\n\nsequence_length = 97825587\nprint(sequence_length)\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=5, out_channels=1, kernel_size=sequence_length, stride=10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = torch.sigmoid(x)\n        return x\n\nmodel = Net().cuda()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.BCELoss()\n\ndata = torch.normal(torch.zeros(1, 5, sequence_length), torch.ones(1, 5, sequence_length))\ndata = data.cuda()\nlabel = torch.ones(1, 1, 1)\nlabel = label.cuda()\n\nfor epoch in range(10):\n    output = model(data)\n    print(output.shape)\n\n    loss = criterion(output, label)\n\n    optimizer.zero_grad()\n    loss.backward()\n\n    optimizer.step()\n\n\n    event = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, 1 * len(data),\n                                                                     1,\n                                                                     100. * 1 / 1,\n                                                                     float(loss) / 1)\n    print(event)\n\n\nSteps to reproduce the behavior:\n\nRun the code with sequence_length = 97825587 and sequence_length = 97825588\n\nExpected behavior\nFail during the second epoch doesn't look right, if the input is too large the training should fail during the first epoch.\nI was monitoring the memory usage, the training with smaller input used 12199Mb, with a bit larger input first epoch was finished with 11640Mb used and during backpropagation in the second epoch, the error was encountered.\nI think some small memory leak is unlikely if it was the case the training with a bit smaller input would run out of memory during one of the epochs.\nI assume that the cause is likely somewhere in the implementation of convolution. The convolution I use in the code is equivalent to a linear layer, it calculates the same output and has the same number of parameters, but I could not find the same behaviour with linear layer\nEnvironment\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\nCMake version: Could not collect\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.1.85\nGPU models and configuration:\nGPU 0: GeForce GTX TITAN X\nGPU 1: GeForce GTX TITAN X\nGPU 2: GeForce GTX TITAN X\nGPU 3: GeForce GTX TITAN X\nNvidia driver version: 390.87\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] Could not collect\nThe issue is not unique for version 0.4, I've tested it with 2018/10/15 nightly build, the exact input size where behavior changes moved, but the issue is still there.\nAdditional context\nI've designed the code above to understand the memory usage of convolutional layers, here are links to my questions at Pytorch Forums and StackOverflow, maybe you will find something useful there\n\nhttps://discuss.pytorch.org/t/with-extremely-large-input-1d-convolution-uses-memory-inefficiently/27066\nhttps://stackoverflow.com/questions/52762173/pytorch-convolutional-network-memory-usage-details\n\nI think, that this issue is related to what is described here\n\nhttps://discuss.pytorch.org/t/how-to-free-gpu-memory-and-delete-memory-allocated-variables/20856", "body": "## \ud83d\udc1b Bug\r\n\r\nFor extremely large inputs ( approximately 5\\*100,000,000) the training process behaves very differently for different but very close input sizes. For size 5\\*97,825,587 and smaller training runs ok for more than 10 epochs, for the size 5\\*97,825,588 and larger training fails during the second epoch with RuntimeError: CUDA error: out of memory\r\n\r\n## To Reproduce\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\n\r\ntorch.cuda.set_device(1)\r\n\r\nsequence_length = 97825587\r\nprint(sequence_length)\r\n\r\nclass Net(nn.Module):\r\n\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv1d(in_channels=5, out_channels=1, kernel_size=sequence_length, stride=10)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = torch.sigmoid(x)\r\n        return x\r\n\r\nmodel = Net().cuda()\r\n\r\noptimizer = optim.Adam(model.parameters(), lr=0.001)\r\ncriterion = torch.nn.BCELoss()\r\n\r\ndata = torch.normal(torch.zeros(1, 5, sequence_length), torch.ones(1, 5, sequence_length))\r\ndata = data.cuda()\r\nlabel = torch.ones(1, 1, 1)\r\nlabel = label.cuda()\r\n\r\nfor epoch in range(10):\r\n    output = model(data)\r\n    print(output.shape)\r\n\r\n    loss = criterion(output, label)\r\n\r\n    optimizer.zero_grad()\r\n    loss.backward()\r\n\r\n    optimizer.step()\r\n\r\n\r\n    event = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, 1 * len(data),\r\n                                                                     1,\r\n                                                                     100. * 1 / 1,\r\n                                                                     float(loss) / 1)\r\n    print(event)\r\n\r\n```\r\n\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the code with `sequence_length = 97825587` and `sequence_length = 97825588`\r\n\r\n## Expected behavior\r\n\r\nFail during the second epoch doesn't look right, if the input is too large the training should fail during the first epoch. \r\nI was monitoring the memory usage, the training with smaller input used 12199Mb, with a bit larger input first epoch was finished with 11640Mb used and during backpropagation in the second epoch, the error was encountered.\r\nI think some small memory leak is unlikely if it was the case the training with a bit smaller input would run out of memory during one of the epochs.\r\nI assume that the cause is likely somewhere in the implementation of convolution. The convolution I use in the code is equivalent to a linear layer, it calculates the same output and has the same number of parameters, but I could not find the same behaviour with linear layer\r\n\r\n## Environment\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.1.85\r\nGPU models and configuration:\r\nGPU 0: GeForce GTX TITAN X\r\nGPU 1: GeForce GTX TITAN X\r\nGPU 2: GeForce GTX TITAN X\r\nGPU 3: GeForce GTX TITAN X\r\n\r\nNvidia driver version: 390.87\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] Could not collect\r\n\r\nThe issue is not unique for version 0.4, I've tested it with 2018/10/15 nightly build, the exact input size where behavior changes moved, but the issue is still there. \r\n\r\n## Additional context\r\n\r\nI've designed the code above to understand the memory usage of convolutional layers, here are links to my questions at Pytorch Forums and StackOverflow, maybe you will find something useful there\r\n- https://discuss.pytorch.org/t/with-extremely-large-input-1d-convolution-uses-memory-inefficiently/27066\r\n- https://stackoverflow.com/questions/52762173/pytorch-convolutional-network-memory-usage-details\r\n\r\nI think, that this issue is related to what is described here\r\n- https://discuss.pytorch.org/t/how-to-free-gpu-memory-and-delete-memory-allocated-variables/20856\r\n"}