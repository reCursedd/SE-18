{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/318274253", "html_url": "https://github.com/pytorch/pytorch/issues/2220#issuecomment-318274253", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2220", "id": 318274253, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODI3NDI1Mw==", "user": {"login": "haoransh", "id": 12680986, "node_id": "MDQ6VXNlcjEyNjgwOTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12680986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haoransh", "html_url": "https://github.com/haoransh", "followers_url": "https://api.github.com/users/haoransh/followers", "following_url": "https://api.github.com/users/haoransh/following{/other_user}", "gists_url": "https://api.github.com/users/haoransh/gists{/gist_id}", "starred_url": "https://api.github.com/users/haoransh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haoransh/subscriptions", "organizations_url": "https://api.github.com/users/haoransh/orgs", "repos_url": "https://api.github.com/users/haoransh/repos", "events_url": "https://api.github.com/users/haoransh/events{/privacy}", "received_events_url": "https://api.github.com/users/haoransh/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-27T06:46:39Z", "updated_at": "2017-07-27T06:46:39Z", "author_association": "NONE", "body_html": "<p>I met similar problem. Let's look at the source code of function binary_cross_entropy_with_logits here: <a href=\"http://pytorch.org/docs/master/_modules/torch/nn/functional.html#binary_cross_entropy_with_logits\" rel=\"nofollow\">http://pytorch.org/docs/master/_modules/torch/nn/functional.html#binary_cross_entropy_with_logits</a></p>\n<p>The <code>input</code> should be a Torch.FloatTensor, whose element should be a real number between 0 and 1, but the <code>target</code> should be a Torch.LongTensor, whose element is either 0 or 1. The FloatTensor and LongTensor is not compatible so the first size check cannot pass, neither the following multilication operation. So I think this could be a bug. Is there a version which fix this problem?</p>\n<p>Thanks very much if anyone can help!</p>", "body_text": "I met similar problem. Let's look at the source code of function binary_cross_entropy_with_logits here: http://pytorch.org/docs/master/_modules/torch/nn/functional.html#binary_cross_entropy_with_logits\nThe input should be a Torch.FloatTensor, whose element should be a real number between 0 and 1, but the target should be a Torch.LongTensor, whose element is either 0 or 1. The FloatTensor and LongTensor is not compatible so the first size check cannot pass, neither the following multilication operation. So I think this could be a bug. Is there a version which fix this problem?\nThanks very much if anyone can help!", "body": "I met similar problem. Let's look at the source code of function binary_cross_entropy_with_logits here: http://pytorch.org/docs/master/_modules/torch/nn/functional.html#binary_cross_entropy_with_logits\r\n\r\nThe ``input`` should be a Torch.FloatTensor, whose element should be a real number between 0 and 1, but the ``target`` should be a Torch.LongTensor, whose element is either 0 or 1. The FloatTensor and LongTensor is not compatible so the first size check cannot pass, neither the following multilication operation. So I think this could be a bug. Is there a version which fix this problem?\r\n\r\nThanks very much if anyone can help!"}