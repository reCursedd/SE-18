{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9822", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9822/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9822/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9822/events", "html_url": "https://github.com/pytorch/pytorch/issues/9822", "id": 344505530, "node_id": "MDU6SXNzdWUzNDQ1MDU1MzA=", "number": 9822, "title": "[bug/feature request] Slice export not propagating negative indexes", "user": {"login": "cbecker", "id": 26833, "node_id": "MDQ6VXNlcjI2ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/26833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cbecker", "html_url": "https://github.com/cbecker", "followers_url": "https://api.github.com/users/cbecker/followers", "following_url": "https://api.github.com/users/cbecker/following{/other_user}", "gists_url": "https://api.github.com/users/cbecker/gists{/gist_id}", "starred_url": "https://api.github.com/users/cbecker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cbecker/subscriptions", "organizations_url": "https://api.github.com/users/cbecker/orgs", "repos_url": "https://api.github.com/users/cbecker/repos", "events_url": "https://api.github.com/users/cbecker/events{/privacy}", "received_events_url": "https://api.github.com/users/cbecker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-25T15:56:25Z", "updated_at": "2018-07-27T04:10:13Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>When exporting a pytorch model to ONNX that contains a slice operation with negative indexes, i.e.</p>\n<pre><code>class MyModel(nn.Module):\n    def forward(self, x):\n        return x[:, :, :, 1:-1]\n</code></pre>\n<p>Then the ONNX slice operation does not contain the negative indexes, but are instead replaced by positive indexes depending on the input's size at the time of the trace/export.</p>\n<p>This can be very limiting because in the case of FCNNs that use a crop or other slicing operation it means that one is bound to a single patch size, as the slicing won't adapt correctly to inputs with different sizes.</p>\n<p>I went through the python code and the tracer, and so far it looks like the issue is within the torch C/C++ code. I would be glad to contribute if someone can point me to where to look, and also if this is an issue we want to tackle or a desired behavior.</p>\n<h2>Code example</h2>\n<p>Running</p>\n<pre><code>import torch\nimport torch.onnx as tonnx\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass MyModel(nn.Module):\n    def forward(self, x):\n        return x[:, :, :, 1:-1]\n\ndummy_input = Variable(torch.randn(1, 3, 224, 224))\nmodel = MyModel()\n\ntonnx.export(model, dummy_input, \"/tmp/model.onnx\", verbose=True)\n</code></pre>\n<p>yields:</p>\n<pre><code>graph(%0 : Float(1, 3, 224, 224)) {\n  %1 : Float(1, 3, 224!, 222) = onnx::Slice[axes=[3], ends=[223], starts=[1]](%0), scope: MyModel\n  return (%1);\n}\n</code></pre>\n<p>I would expect <code>ends</code> to be <code>[-1]</code> instead of <code>[223]</code>.</p>\n<p>This is on the latest install with pip.</p>", "body_text": "Issue description\nWhen exporting a pytorch model to ONNX that contains a slice operation with negative indexes, i.e.\nclass MyModel(nn.Module):\n    def forward(self, x):\n        return x[:, :, :, 1:-1]\n\nThen the ONNX slice operation does not contain the negative indexes, but are instead replaced by positive indexes depending on the input's size at the time of the trace/export.\nThis can be very limiting because in the case of FCNNs that use a crop or other slicing operation it means that one is bound to a single patch size, as the slicing won't adapt correctly to inputs with different sizes.\nI went through the python code and the tracer, and so far it looks like the issue is within the torch C/C++ code. I would be glad to contribute if someone can point me to where to look, and also if this is an issue we want to tackle or a desired behavior.\nCode example\nRunning\nimport torch\nimport torch.onnx as tonnx\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass MyModel(nn.Module):\n    def forward(self, x):\n        return x[:, :, :, 1:-1]\n\ndummy_input = Variable(torch.randn(1, 3, 224, 224))\nmodel = MyModel()\n\ntonnx.export(model, dummy_input, \"/tmp/model.onnx\", verbose=True)\n\nyields:\ngraph(%0 : Float(1, 3, 224, 224)) {\n  %1 : Float(1, 3, 224!, 222) = onnx::Slice[axes=[3], ends=[223], starts=[1]](%0), scope: MyModel\n  return (%1);\n}\n\nI would expect ends to be [-1] instead of [223].\nThis is on the latest install with pip.", "body": "## Issue description\r\nWhen exporting a pytorch model to ONNX that contains a slice operation with negative indexes, i.e.\r\n```\r\nclass MyModel(nn.Module):\r\n    def forward(self, x):\r\n        return x[:, :, :, 1:-1]\r\n```\r\n\r\nThen the ONNX slice operation does not contain the negative indexes, but are instead replaced by positive indexes depending on the input's size at the time of the trace/export.\r\n\r\nThis can be very limiting because in the case of FCNNs that use a crop or other slicing operation it means that one is bound to a single patch size, as the slicing won't adapt correctly to inputs with different sizes.\r\n\r\nI went through the python code and the tracer, and so far it looks like the issue is within the torch C/C++ code. I would be glad to contribute if someone can point me to where to look, and also if this is an issue we want to tackle or a desired behavior.\r\n\r\n## Code example\r\nRunning\r\n```\r\nimport torch\r\nimport torch.onnx as tonnx\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nclass MyModel(nn.Module):\r\n    def forward(self, x):\r\n        return x[:, :, :, 1:-1]\r\n\r\ndummy_input = Variable(torch.randn(1, 3, 224, 224))\r\nmodel = MyModel()\r\n\r\ntonnx.export(model, dummy_input, \"/tmp/model.onnx\", verbose=True)\r\n```\r\n\r\nyields:\r\n```\r\ngraph(%0 : Float(1, 3, 224, 224)) {\r\n  %1 : Float(1, 3, 224!, 222) = onnx::Slice[axes=[3], ends=[223], starts=[1]](%0), scope: MyModel\r\n  return (%1);\r\n}\r\n```\r\n\r\nI would expect `ends` to be `[-1]` instead of `[223]`.\r\n\r\nThis is on the latest install with pip.\r\n"}