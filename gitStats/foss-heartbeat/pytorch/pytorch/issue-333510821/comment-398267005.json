{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/398267005", "html_url": "https://github.com/pytorch/pytorch/issues/8637#issuecomment-398267005", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8637", "id": 398267005, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODI2NzAwNQ==", "user": {"login": "BestSonny", "id": 6027713, "node_id": "MDQ6VXNlcjYwMjc3MTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6027713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BestSonny", "html_url": "https://github.com/BestSonny", "followers_url": "https://api.github.com/users/BestSonny/followers", "following_url": "https://api.github.com/users/BestSonny/following{/other_user}", "gists_url": "https://api.github.com/users/BestSonny/gists{/gist_id}", "starred_url": "https://api.github.com/users/BestSonny/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BestSonny/subscriptions", "organizations_url": "https://api.github.com/users/BestSonny/orgs", "repos_url": "https://api.github.com/users/BestSonny/repos", "events_url": "https://api.github.com/users/BestSonny/events{/privacy}", "received_events_url": "https://api.github.com/users/BestSonny/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-19T03:57:54Z", "updated_at": "2018-06-19T03:59:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>A demo code is provided to reproduce the errors. testModude2 works fine while testModude is not good.</p>\n<pre><code>import torch\nfrom torch import nn\n\nclass testModule(nn.Module):\n    def __init__(self):\n        super(testModule, self).__init__()\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\n                         kernel_size=1, stride=1, padding=0)\n        self.operation_function = self._realOperation\n\n    def forward(self, x):\n        output = self.operation_function(x)\n        return output\n\n    def _realOperation(self, x):\n        x = self.g(x)\n        return x\n\nclass testModule2(nn.Module):\n    def __init__(self):\n        super(testModule2, self).__init__()\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\n                         kernel_size=1, stride=1, padding=0)\n    def forward(self, x):\n        x = self.g(x)\n        return x\n\nif __name__ == '__main__':\n        input = torch.rand(4, 1, 1, 1).cuda()\n        net = testModule()\n        net2 = testModule2()\n        gpu_num = torch.cuda.device_count()\n        print('GPU NUM: {:2d}'.format(gpu_num))\n        if gpu_num &gt; 1:\n            net = torch.nn.DataParallel(net, list(range(gpu_num))).cuda()\n            net2 = torch.nn.DataParallel(net2, list(range(gpu_num))).cuda()\n        out2 = net2(input)\n        print(out2.size())\n        out = net(input)\n        print(out.size())\n</code></pre>", "body_text": "A demo code is provided to reproduce the errors. testModude2 works fine while testModude is not good.\nimport torch\nfrom torch import nn\n\nclass testModule(nn.Module):\n    def __init__(self):\n        super(testModule, self).__init__()\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\n                         kernel_size=1, stride=1, padding=0)\n        self.operation_function = self._realOperation\n\n    def forward(self, x):\n        output = self.operation_function(x)\n        return output\n\n    def _realOperation(self, x):\n        x = self.g(x)\n        return x\n\nclass testModule2(nn.Module):\n    def __init__(self):\n        super(testModule2, self).__init__()\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\n                         kernel_size=1, stride=1, padding=0)\n    def forward(self, x):\n        x = self.g(x)\n        return x\n\nif __name__ == '__main__':\n        input = torch.rand(4, 1, 1, 1).cuda()\n        net = testModule()\n        net2 = testModule2()\n        gpu_num = torch.cuda.device_count()\n        print('GPU NUM: {:2d}'.format(gpu_num))\n        if gpu_num > 1:\n            net = torch.nn.DataParallel(net, list(range(gpu_num))).cuda()\n            net2 = torch.nn.DataParallel(net2, list(range(gpu_num))).cuda()\n        out2 = net2(input)\n        print(out2.size())\n        out = net(input)\n        print(out.size())", "body": "A demo code is provided to reproduce the errors. testModude2 works fine while testModude is not good.\r\n\r\n```\r\nimport torch\r\nfrom torch import nn\r\n\r\nclass testModule(nn.Module):\r\n    def __init__(self):\r\n        super(testModule, self).__init__()\r\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\r\n                         kernel_size=1, stride=1, padding=0)\r\n        self.operation_function = self._realOperation\r\n\r\n    def forward(self, x):\r\n        output = self.operation_function(x)\r\n        return output\r\n\r\n    def _realOperation(self, x):\r\n        x = self.g(x)\r\n        return x\r\n\r\nclass testModule2(nn.Module):\r\n    def __init__(self):\r\n        super(testModule2, self).__init__()\r\n        self.g = nn.Conv2d(in_channels=1, out_channels=1,\r\n                         kernel_size=1, stride=1, padding=0)\r\n    def forward(self, x):\r\n        x = self.g(x)\r\n        return x\r\n\r\nif __name__ == '__main__':\r\n        input = torch.rand(4, 1, 1, 1).cuda()\r\n        net = testModule()\r\n        net2 = testModule2()\r\n        gpu_num = torch.cuda.device_count()\r\n        print('GPU NUM: {:2d}'.format(gpu_num))\r\n        if gpu_num > 1:\r\n            net = torch.nn.DataParallel(net, list(range(gpu_num))).cuda()\r\n            net2 = torch.nn.DataParallel(net2, list(range(gpu_num))).cuda()\r\n        out2 = net2(input)\r\n        print(out2.size())\r\n        out = net(input)\r\n        print(out.size())\r\n```"}