{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/313735757", "html_url": "https://github.com/pytorch/pytorch/issues/2001#issuecomment-313735757", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2001", "id": 313735757, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzczNTc1Nw==", "user": {"login": "ncullen93", "id": 13004360, "node_id": "MDQ6VXNlcjEzMDA0MzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/13004360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ncullen93", "html_url": "https://github.com/ncullen93", "followers_url": "https://api.github.com/users/ncullen93/followers", "following_url": "https://api.github.com/users/ncullen93/following{/other_user}", "gists_url": "https://api.github.com/users/ncullen93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ncullen93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ncullen93/subscriptions", "organizations_url": "https://api.github.com/users/ncullen93/orgs", "repos_url": "https://api.github.com/users/ncullen93/repos", "events_url": "https://api.github.com/users/ncullen93/events{/privacy}", "received_events_url": "https://api.github.com/users/ncullen93/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-07T16:53:39Z", "updated_at": "2017-07-07T16:58:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Sure you can! Here's something to get you started. (Adapted from other code, so it's not tested in the wild). Note that you HAVE to know the input size, and you HAVE to make a forward pass through the network. Those are the only reqs I think.</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">summary</span>(<span class=\"pl-smi\">input_size</span>, <span class=\"pl-smi\">model</span>):\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">register_hook</span>(<span class=\"pl-smi\">module</span>):\n            <span class=\"pl-k\">def</span> <span class=\"pl-en\">hook</span>(<span class=\"pl-smi\">module</span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">output</span>):\n                class_name <span class=\"pl-k\">=</span> <span class=\"pl-c1\">str</span>(module.<span class=\"pl-c1\">__class__</span>).split(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>)[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>].split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>'<span class=\"pl-pds\">\"</span></span>)[<span class=\"pl-c1\">0</span>]\n                module_idx <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(summary)\n\n                m_key <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span>-<span class=\"pl-c1\">%i</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (class_name, module_idx<span class=\"pl-k\">+</span><span class=\"pl-c1\">1</span>)\n                summary[m_key] <span class=\"pl-k\">=</span> OrderedDict()\n                summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input_shape<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(<span class=\"pl-c1\">input</span>[<span class=\"pl-c1\">0</span>].size())\n                summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>input_shape<span class=\"pl-pds\">'</span></span>][<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>\n                summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output_shape<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(output.size())\n                summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>output_shape<span class=\"pl-pds\">'</span></span>][<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>\n\n                params <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n                <span class=\"pl-k\">if</span> <span class=\"pl-c1\">hasattr</span>(module, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight<span class=\"pl-pds\">'</span></span>):\n                    params <span class=\"pl-k\">+=</span> th.prod(th.LongTensor(<span class=\"pl-c1\">list</span>(module.weight.size())))\n                    <span class=\"pl-k\">if</span> module.weight.requires_grad:\n                        summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>trainable<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n                    <span class=\"pl-k\">else</span>:\n                        summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>trainable<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\n                <span class=\"pl-k\">if</span> <span class=\"pl-c1\">hasattr</span>(module, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>bias<span class=\"pl-pds\">'</span></span>):\n                    params <span class=\"pl-k\">+=</span>  th.prod(th.LongTensor(<span class=\"pl-c1\">list</span>(module.bias.size())))\n                summary[m_key][<span class=\"pl-s\"><span class=\"pl-pds\">'</span>nb_params<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">=</span> params\n                \n            <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(module, nn.Sequential) <span class=\"pl-k\">and</span> \\\n               <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(module, nn.ModuleList) <span class=\"pl-k\">and</span> \\\n               <span class=\"pl-k\">not</span> (module <span class=\"pl-k\">==</span> model):\n                hooks.append(module.register_forward_hook(hook))\n        \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> check if there are multiple inputs to the network</span>\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(input_size[<span class=\"pl-c1\">0</span>], (<span class=\"pl-c1\">list</span>, <span class=\"pl-c1\">tuple</span>)):\n            x <span class=\"pl-k\">=</span> [Variable(th.rand(<span class=\"pl-c1\">1</span>,<span class=\"pl-k\">*</span>in_size)) <span class=\"pl-k\">for</span> in_size <span class=\"pl-k\">in</span> input_size]\n        <span class=\"pl-k\">else</span>:\n            x <span class=\"pl-k\">=</span> Variable(th.rand(<span class=\"pl-c1\">1</span>,<span class=\"pl-k\">*</span>input_size))\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> create properties</span>\n        summary <span class=\"pl-k\">=</span> OrderedDict()\n        hooks <span class=\"pl-k\">=</span> []\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> register hook</span>\n        model.apply(register_hook)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> make a forward pass</span>\n        model(x)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> remove these hooks</span>\n        <span class=\"pl-k\">for</span> h <span class=\"pl-k\">in</span> hooks:\n            h.remove()\n\n        <span class=\"pl-k\">return</span> summary</pre></div>\n<p>Here's an example of Keras summary, FYI:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/13004360/27968068-89234e14-6313-11e7-92dc-92c31b8e28b9.png\"><img width=\"562\" alt=\"screen shot 2017-07-07 at 12 55 01 pm\" src=\"https://user-images.githubusercontent.com/13004360/27968068-89234e14-6313-11e7-92dc-92c31b8e28b9.png\" style=\"max-width:100%;\"></a></p>", "body_text": "Sure you can! Here's something to get you started. (Adapted from other code, so it's not tested in the wild). Note that you HAVE to know the input size, and you HAVE to make a forward pass through the network. Those are the only reqs I think.\n    def summary(input_size, model):\n        def register_hook(module):\n            def hook(module, input, output):\n                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n                module_idx = len(summary)\n\n                m_key = '%s-%i' % (class_name, module_idx+1)\n                summary[m_key] = OrderedDict()\n                summary[m_key]['input_shape'] = list(input[0].size())\n                summary[m_key]['input_shape'][0] = -1\n                summary[m_key]['output_shape'] = list(output.size())\n                summary[m_key]['output_shape'][0] = -1\n\n                params = 0\n                if hasattr(module, 'weight'):\n                    params += th.prod(th.LongTensor(list(module.weight.size())))\n                    if module.weight.requires_grad:\n                        summary[m_key]['trainable'] = True\n                    else:\n                        summary[m_key]['trainable'] = False\n                if hasattr(module, 'bias'):\n                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n                summary[m_key]['nb_params'] = params\n                \n            if not isinstance(module, nn.Sequential) and \\\n               not isinstance(module, nn.ModuleList) and \\\n               not (module == model):\n                hooks.append(module.register_forward_hook(hook))\n        \n        # check if there are multiple inputs to the network\n        if isinstance(input_size[0], (list, tuple)):\n            x = [Variable(th.rand(1,*in_size)) for in_size in input_size]\n        else:\n            x = Variable(th.rand(1,*input_size))\n\n        # create properties\n        summary = OrderedDict()\n        hooks = []\n        # register hook\n        model.apply(register_hook)\n        # make a forward pass\n        model(x)\n        # remove these hooks\n        for h in hooks:\n            h.remove()\n\n        return summary\nHere's an example of Keras summary, FYI:", "body": "Sure you can! Here's something to get you started. (Adapted from other code, so it's not tested in the wild). Note that you HAVE to know the input size, and you HAVE to make a forward pass through the network. Those are the only reqs I think.\r\n\r\n```python\r\n    def summary(input_size, model):\r\n        def register_hook(module):\r\n            def hook(module, input, output):\r\n                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\r\n                module_idx = len(summary)\r\n\r\n                m_key = '%s-%i' % (class_name, module_idx+1)\r\n                summary[m_key] = OrderedDict()\r\n                summary[m_key]['input_shape'] = list(input[0].size())\r\n                summary[m_key]['input_shape'][0] = -1\r\n                summary[m_key]['output_shape'] = list(output.size())\r\n                summary[m_key]['output_shape'][0] = -1\r\n\r\n                params = 0\r\n                if hasattr(module, 'weight'):\r\n                    params += th.prod(th.LongTensor(list(module.weight.size())))\r\n                    if module.weight.requires_grad:\r\n                        summary[m_key]['trainable'] = True\r\n                    else:\r\n                        summary[m_key]['trainable'] = False\r\n                if hasattr(module, 'bias'):\r\n                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\r\n                summary[m_key]['nb_params'] = params\r\n                \r\n            if not isinstance(module, nn.Sequential) and \\\r\n               not isinstance(module, nn.ModuleList) and \\\r\n               not (module == model):\r\n                hooks.append(module.register_forward_hook(hook))\r\n        \r\n        # check if there are multiple inputs to the network\r\n        if isinstance(input_size[0], (list, tuple)):\r\n            x = [Variable(th.rand(1,*in_size)) for in_size in input_size]\r\n        else:\r\n            x = Variable(th.rand(1,*input_size))\r\n\r\n        # create properties\r\n        summary = OrderedDict()\r\n        hooks = []\r\n        # register hook\r\n        model.apply(register_hook)\r\n        # make a forward pass\r\n        model(x)\r\n        # remove these hooks\r\n        for h in hooks:\r\n            h.remove()\r\n\r\n        return summary\r\n```\r\nHere's an example of Keras summary, FYI:\r\n\r\n<img width=\"562\" alt=\"screen shot 2017-07-07 at 12 55 01 pm\" src=\"https://user-images.githubusercontent.com/13004360/27968068-89234e14-6313-11e7-92dc-92c31b8e28b9.png\">\r\n"}