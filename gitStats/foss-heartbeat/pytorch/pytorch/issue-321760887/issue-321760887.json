{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7445", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7445/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7445/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7445/events", "html_url": "https://github.com/pytorch/pytorch/issues/7445", "id": 321760887, "node_id": "MDU6SXNzdWUzMjE3NjA4ODc=", "number": 7445, "title": "CUDA out of memory problem in Pytorch 0.4", "user": {"login": "yqy", "id": 1547409, "node_id": "MDQ6VXNlcjE1NDc0MDk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1547409?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yqy", "html_url": "https://github.com/yqy", "followers_url": "https://api.github.com/users/yqy/followers", "following_url": "https://api.github.com/users/yqy/following{/other_user}", "gists_url": "https://api.github.com/users/yqy/gists{/gist_id}", "starred_url": "https://api.github.com/users/yqy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yqy/subscriptions", "organizations_url": "https://api.github.com/users/yqy/orgs", "repos_url": "https://api.github.com/users/yqy/repos", "events_url": "https://api.github.com/users/yqy/events{/privacy}", "received_events_url": "https://api.github.com/users/yqy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-09T23:34:54Z", "updated_at": "2018-05-10T02:25:45Z", "closed_at": "2018-05-10T02:25:45Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I have implemented a tensorflow project by pytorch. However, I meet a problem of \"CUDA out of memory\" when calculating the gradient.</p>\n<ul>\n<li>Does pytorch requires more GPU memory than tensorflow?</li>\n<li>Or is there any suggestions for saving memory?</li>\n</ul>\n<p>Thanks a lot!</p>", "body_text": "Issue description\nI have implemented a tensorflow project by pytorch. However, I meet a problem of \"CUDA out of memory\" when calculating the gradient.\n\nDoes pytorch requires more GPU memory than tensorflow?\nOr is there any suggestions for saving memory?\n\nThanks a lot!", "body": "## Issue description\r\nI have implemented a tensorflow project by pytorch. However, I meet a problem of \"CUDA out of memory\" when calculating the gradient.\r\n\r\n - Does pytorch requires more GPU memory than tensorflow?\r\n - Or is there any suggestions for saving memory?\r\n\r\nThanks a lot!"}