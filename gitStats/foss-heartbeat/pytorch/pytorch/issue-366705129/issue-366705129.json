{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12319", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12319/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12319/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12319/events", "html_url": "https://github.com/pytorch/pytorch/issues/12319", "id": 366705129, "node_id": "MDU6SXNzdWUzNjY3MDUxMjk=", "number": 12319, "title": "torch.jit.load cannot load saved scripted model", "user": {"login": "outcastofmusic", "id": 237281, "node_id": "MDQ6VXNlcjIzNzI4MQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/237281?v=4", "gravatar_id": "", "url": "https://api.github.com/users/outcastofmusic", "html_url": "https://github.com/outcastofmusic", "followers_url": "https://api.github.com/users/outcastofmusic/followers", "following_url": "https://api.github.com/users/outcastofmusic/following{/other_user}", "gists_url": "https://api.github.com/users/outcastofmusic/gists{/gist_id}", "starred_url": "https://api.github.com/users/outcastofmusic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/outcastofmusic/subscriptions", "organizations_url": "https://api.github.com/users/outcastofmusic/orgs", "repos_url": "https://api.github.com/users/outcastofmusic/repos", "events_url": "https://api.github.com/users/outcastofmusic/events{/privacy}", "received_events_url": "https://api.github.com/users/outcastofmusic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1076922764, "node_id": "MDU6TGFiZWwxMDc2OTIyNzY0", "url": "https://api.github.com/repos/pytorch/pytorch/labels/nn", "name": "nn", "color": "e2de53", "default": false}, {"id": 1076921751, "node_id": "MDU6TGFiZWwxMDc2OTIxNzUx", "url": "https://api.github.com/repos/pytorch/pytorch/labels/torch", "name": "torch", "color": "4fdddd", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "li-roy", "id": 8813817, "node_id": "MDQ6VXNlcjg4MTM4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8813817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/li-roy", "html_url": "https://github.com/li-roy", "followers_url": "https://api.github.com/users/li-roy/followers", "following_url": "https://api.github.com/users/li-roy/following{/other_user}", "gists_url": "https://api.github.com/users/li-roy/gists{/gist_id}", "starred_url": "https://api.github.com/users/li-roy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/li-roy/subscriptions", "organizations_url": "https://api.github.com/users/li-roy/orgs", "repos_url": "https://api.github.com/users/li-roy/repos", "events_url": "https://api.github.com/users/li-roy/events{/privacy}", "received_events_url": "https://api.github.com/users/li-roy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-10-04T09:42:10Z", "updated_at": "2018-10-09T05:26:45Z", "closed_at": "2018-10-09T05:26:45Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Trying to load a simple saved scripted_model produces an error:</p>\n<pre lang=\"Traceback\" data-meta=\"(most recent call last):\"><code>  File \"example_save_torch_script.py\", line 62, in &lt;module&gt;\n    new_scripted_model = torch.jit.load(\"script_model.pt\")\n  File \"/home/agis/anaconda3/envs/fastai-v1/lib/python3.6/site-packages/torch/jit/__init__.py\", line 98, in load\n    torch._C.import_ir_module(module_lookup, f)\nRuntimeError: it != value_type_map_.end() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281, please report a bug to PyTorch. (buildIntermediateValue at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281)\n</code></pre>\n<h2>To Reproduce</h2>\n<p>Providing the following code to reproduce the error:</p>\n<pre><code>import torch\n\nclass MyModuleS(torch.jit.ScriptModule):\n    def __init__(self, N, M):\n        super(MyModuleS, self).__init__()\n        self.weight = torch.nn.Parameter(torch.rand(N, M))\n\n    @torch.jit.script_method\n    def forward(self, input: torch.Tensor):\n        if bool(input.sum() &gt; 0):\n            output = self.weight.mv(input)\n        else:\n            output = self.weight + input\n        return output\n\n\nmy_script_module = MyModuleS(200, 200)\n\ntest_input = torch.rand(200)\n\noutput = my_script_module(test_input)\nprint(my_script_module.graph)\nprint(\"scripted model: \", output.size())\n\nmy_script_module.save(\"script_model.pt\")\n\n\nnew_scripted_model = torch.jit.load(\"script_model.pt\")  # crash happens here\noutput = new_scripted_model(test_input)\nprint(output)\n</code></pre>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>run script</li>\n</ol>\n<h2>Expected behavior</h2>\n<p>The scripted module should be loaded and  the code should be run</p>\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<p>Collecting environment information...<br>\nPyTorch version: 1.0.0.dev20181002<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148<br>\nOS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.12.2<br>\nPython version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti<br>\nNvidia driver version: 396.37<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.2.1<br>\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a<br>\nVersions of relevant libraries:<br>\n[pip] msgpack-numpy (0.4.3.2)<br>\n[pip] numpy (1.15.2)<br>\n[pip] torch (1.0.0.dev20181002)<br>\n[pip] torchvision (0.2.1)<br>\n[conda] cuda92                    1.0                           0    pytorch<br>\n[conda] pytorch-nightly           1.0.0.dev20181002 py3.6_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch<br>\n[conda] torchvision               0.2.1                      py_0    fastai</p>", "body_text": "\ud83d\udc1b Bug\nTrying to load a simple saved scripted_model produces an error:\n  File \"example_save_torch_script.py\", line 62, in <module>\n    new_scripted_model = torch.jit.load(\"script_model.pt\")\n  File \"/home/agis/anaconda3/envs/fastai-v1/lib/python3.6/site-packages/torch/jit/__init__.py\", line 98, in load\n    torch._C.import_ir_module(module_lookup, f)\nRuntimeError: it != value_type_map_.end() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281, please report a bug to PyTorch. (buildIntermediateValue at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281)\n\nTo Reproduce\nProviding the following code to reproduce the error:\nimport torch\n\nclass MyModuleS(torch.jit.ScriptModule):\n    def __init__(self, N, M):\n        super(MyModuleS, self).__init__()\n        self.weight = torch.nn.Parameter(torch.rand(N, M))\n\n    @torch.jit.script_method\n    def forward(self, input: torch.Tensor):\n        if bool(input.sum() > 0):\n            output = self.weight.mv(input)\n        else:\n            output = self.weight + input\n        return output\n\n\nmy_script_module = MyModuleS(200, 200)\n\ntest_input = torch.rand(200)\n\noutput = my_script_module(test_input)\nprint(my_script_module.graph)\nprint(\"scripted model: \", output.size())\n\nmy_script_module.save(\"script_model.pt\")\n\n\nnew_scripted_model = torch.jit.load(\"script_model.pt\")  # crash happens here\noutput = new_scripted_model(test_input)\nprint(output)\n\nSteps to reproduce the behavior:\n\nrun script\n\nExpected behavior\nThe scripted module should be loaded and  the code should be run\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\nCollecting environment information...\nPyTorch version: 1.0.0.dev20181002\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti\nNvidia driver version: 396.37\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.2.1\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a\nVersions of relevant libraries:\n[pip] msgpack-numpy (0.4.3.2)\n[pip] numpy (1.15.2)\n[pip] torch (1.0.0.dev20181002)\n[pip] torchvision (0.2.1)\n[conda] cuda92                    1.0                           0    pytorch\n[conda] pytorch-nightly           1.0.0.dev20181002 py3.6_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch\n[conda] torchvision               0.2.1                      py_0    fastai", "body": "## \ud83d\udc1b Bug\r\nTrying to load a simple saved scripted_model produces an error:\r\n```Traceback (most recent call last):\r\n  File \"example_save_torch_script.py\", line 62, in <module>\r\n    new_scripted_model = torch.jit.load(\"script_model.pt\")\r\n  File \"/home/agis/anaconda3/envs/fastai-v1/lib/python3.6/site-packages/torch/jit/__init__.py\", line 98, in load\r\n    torch._C.import_ir_module(module_lookup, f)\r\nRuntimeError: it != value_type_map_.end() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281, please report a bug to PyTorch. (buildIntermediateValue at /opt/conda/conda-bld/pytorch-nightly_1538471633750/work/torch/csrc/jit/import.cpp:281)\r\n```\r\n\r\n## To Reproduce\r\nProviding the following code to reproduce the error: \r\n```\r\nimport torch\r\n\r\nclass MyModuleS(torch.jit.ScriptModule):\r\n    def __init__(self, N, M):\r\n        super(MyModuleS, self).__init__()\r\n        self.weight = torch.nn.Parameter(torch.rand(N, M))\r\n\r\n    @torch.jit.script_method\r\n    def forward(self, input: torch.Tensor):\r\n        if bool(input.sum() > 0):\r\n            output = self.weight.mv(input)\r\n        else:\r\n            output = self.weight + input\r\n        return output\r\n\r\n\r\nmy_script_module = MyModuleS(200, 200)\r\n\r\ntest_input = torch.rand(200)\r\n\r\noutput = my_script_module(test_input)\r\nprint(my_script_module.graph)\r\nprint(\"scripted model: \", output.size())\r\n\r\nmy_script_module.save(\"script_model.pt\")\r\n\r\n\r\nnew_scripted_model = torch.jit.load(\"script_model.pt\")  # crash happens here\r\noutput = new_scripted_model(test_input)\r\nprint(output)\r\n```\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. run script\r\n\r\n## Expected behavior\r\nThe scripted module should be loaded and  the code should be run\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.0.0.dev20181002\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.12.2\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti\r\nNvidia driver version: 396.37\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn.so.7.2.1\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudnn_static.a\r\nVersions of relevant libraries:\r\n[pip] msgpack-numpy (0.4.3.2)\r\n[pip] numpy (1.15.2)\r\n[pip] torch (1.0.0.dev20181002)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda92                    1.0                           0    pytorch\r\n[conda] pytorch-nightly           1.0.0.dev20181002 py3.6_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch\r\n[conda] torchvision               0.2.1                      py_0    fastai"}