{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9875", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9875/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9875/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9875/events", "html_url": "https://github.com/pytorch/pytorch/issues/9875", "id": 344816824, "node_id": "MDU6SXNzdWUzNDQ4MTY4MjQ=", "number": 9875, "title": "onnx to caffe2 err", "user": {"login": "lizhen2017", "id": 41407473, "node_id": "MDQ6VXNlcjQxNDA3NDcz", "avatar_url": "https://avatars3.githubusercontent.com/u/41407473?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lizhen2017", "html_url": "https://github.com/lizhen2017", "followers_url": "https://api.github.com/users/lizhen2017/followers", "following_url": "https://api.github.com/users/lizhen2017/following{/other_user}", "gists_url": "https://api.github.com/users/lizhen2017/gists{/gist_id}", "starred_url": "https://api.github.com/users/lizhen2017/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lizhen2017/subscriptions", "organizations_url": "https://api.github.com/users/lizhen2017/orgs", "repos_url": "https://api.github.com/users/lizhen2017/repos", "events_url": "https://api.github.com/users/lizhen2017/events{/privacy}", "received_events_url": "https://api.github.com/users/lizhen2017/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-07-26T12:08:54Z", "updated_at": "2018-07-27T03:51:12Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Provide a short description.<br>\nfrom pytorch model to onnx, and from onnx to caffe2, err ocurr, help me please, thanks all.</p>\n<h2>Code example</h2>\n<p>from torch.autograd import Variable<br>\nimport torch.onnx<br>\nimport torchvision</p>\n<p>dummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda()<br>\nmodel = torchvision.models.alexnet(pretrained=False).cuda()<br>\ntorch.onnx._export(model, dummy_input, \"alexnet.proto\", verbose=True)<br>\nimport onnx<br>\nimport caffe2.python.onnx.backend as backend</p>\n<h1>load onnx object</h1>\n<p>model = onnx.load(\"alexnet.proto\")<br>\nprint(type(model))<br>\nprepared_backend = backend.prepare(model)<br>\nfrom caffe2.python.onnx.backend import Caffe2Backend as c2<br>\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)<br>\nwith open(\"squeeze_init_net.pb\", \"wb\") as f:<br>\nf.write(init_net.SerializeToString())<br>\nwith open(\"squeeze_predict_net.pb\", \"wb\") as f:<br>\nf.write(predict_net.SerializeToString())</p>\n<h2>System Info</h2>\n<h2>&lt;class 'onnx.onnx_pb2.ModelProto'&gt;</h2>\n<p>ValueError                                Traceback (most recent call last)<br>\n in ()<br>\n4 model = onnx.load(\"alexnet.proto\")<br>\n5 print(type(model))<br>\n----&gt; 6 prepared_backend = backend.prepare(model)<br>\n7 from caffe2.python.onnx.backend import Caffe2Backend as c2<br>\n8 init_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)</p>\n<p>/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in prepare(cls, model, device, **kwargs)<br>\n745         # Check whether we have RNN related ops<br>\n746         pred_model = ModelProto()<br>\n--&gt; 747         pred_model.ParseFromString(cls.optimize_onnx(model.SerializeToString(), predict=True))<br>\n748         rnn_nodes = []<br>\n749         for node in pred_model.graph.node:</p>\n<p>/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in optimize_onnx(input, init, predict)<br>\n701         if predict:<br>\n702             passes.append('split_predict')<br>\n--&gt; 703         out = onnx.optimizer.optimize(input, passes)<br>\n704         return out<br>\n705</p>\n<p>/home/fiona/anaconda2/lib/python2.7/site-packages/onnx-1.2.1-py2.7-linux-x86_64.egg/onnx/optimizer.pyc in optimize(model, passes)<br>\n43                   'fuse_transpose_into_gemm']<br>\n44     if not isinstance(model, ModelProto):<br>\n---&gt; 45         raise ValueError('Optimizer only accepts ModelProto, incorrect type: {}'.format(type(model)))<br>\n46<br>\n47     model_str = model.SerializeToString()</p>\n<p>ValueError: Optimizer only accepts ModelProto, incorrect type: &lt;type 'str'&gt;</p>\n<ul>\n<li>PyTorch and Caffe2:</li>\n<li>How you installed PyTorch (pip):</li>\n<li>OS:Ubuntu16.04</li>\n<li>PyTorch version:0.4.0</li>\n<li>Python version:anaconda  python2 2.7.1</li>\n<li>CUDA/cuDNN version:8.0/6.0.5</li>\n<li>GPU models and configuration: GeForce GTX 1080 Ti/PCIe/SSE2</li>\n<li>GCC version (if compiling from source):5.4.0</li>\n<li>CMake version:3.11.1</li>\n<li>Versions of any other relevant libraries:<br>\neigen:3.3.4, opencv 3.4.1</li>\n</ul>", "body_text": "Issue description\nProvide a short description.\nfrom pytorch model to onnx, and from onnx to caffe2, err ocurr, help me please, thanks all.\nCode example\nfrom torch.autograd import Variable\nimport torch.onnx\nimport torchvision\ndummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda()\nmodel = torchvision.models.alexnet(pretrained=False).cuda()\ntorch.onnx._export(model, dummy_input, \"alexnet.proto\", verbose=True)\nimport onnx\nimport caffe2.python.onnx.backend as backend\nload onnx object\nmodel = onnx.load(\"alexnet.proto\")\nprint(type(model))\nprepared_backend = backend.prepare(model)\nfrom caffe2.python.onnx.backend import Caffe2Backend as c2\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\nwith open(\"squeeze_init_net.pb\", \"wb\") as f:\nf.write(init_net.SerializeToString())\nwith open(\"squeeze_predict_net.pb\", \"wb\") as f:\nf.write(predict_net.SerializeToString())\nSystem Info\n<class 'onnx.onnx_pb2.ModelProto'>\nValueError                                Traceback (most recent call last)\n in ()\n4 model = onnx.load(\"alexnet.proto\")\n5 print(type(model))\n----> 6 prepared_backend = backend.prepare(model)\n7 from caffe2.python.onnx.backend import Caffe2Backend as c2\n8 init_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\n/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in prepare(cls, model, device, **kwargs)\n745         # Check whether we have RNN related ops\n746         pred_model = ModelProto()\n--> 747         pred_model.ParseFromString(cls.optimize_onnx(model.SerializeToString(), predict=True))\n748         rnn_nodes = []\n749         for node in pred_model.graph.node:\n/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in optimize_onnx(input, init, predict)\n701         if predict:\n702             passes.append('split_predict')\n--> 703         out = onnx.optimizer.optimize(input, passes)\n704         return out\n705\n/home/fiona/anaconda2/lib/python2.7/site-packages/onnx-1.2.1-py2.7-linux-x86_64.egg/onnx/optimizer.pyc in optimize(model, passes)\n43                   'fuse_transpose_into_gemm']\n44     if not isinstance(model, ModelProto):\n---> 45         raise ValueError('Optimizer only accepts ModelProto, incorrect type: {}'.format(type(model)))\n46\n47     model_str = model.SerializeToString()\nValueError: Optimizer only accepts ModelProto, incorrect type: <type 'str'>\n\nPyTorch and Caffe2:\nHow you installed PyTorch (pip):\nOS:Ubuntu16.04\nPyTorch version:0.4.0\nPython version:anaconda  python2 2.7.1\nCUDA/cuDNN version:8.0/6.0.5\nGPU models and configuration: GeForce GTX 1080 Ti/PCIe/SSE2\nGCC version (if compiling from source):5.4.0\nCMake version:3.11.1\nVersions of any other relevant libraries:\neigen:3.3.4, opencv 3.4.1", "body": "## Issue description\r\n\r\nProvide a short description.\r\nfrom pytorch model to onnx, and from onnx to caffe2, err ocurr, help me please, thanks all. \r\n## Code example\r\nfrom torch.autograd import Variable\r\nimport torch.onnx\r\nimport torchvision\r\n\r\ndummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda()\r\nmodel = torchvision.models.alexnet(pretrained=False).cuda()\r\ntorch.onnx._export(model, dummy_input, \"alexnet.proto\", verbose=True)\r\nimport onnx\r\nimport caffe2.python.onnx.backend as backend\r\n# load onnx object\r\nmodel = onnx.load(\"alexnet.proto\")\r\nprint(type(model))\r\nprepared_backend = backend.prepare(model)\r\nfrom caffe2.python.onnx.backend import Caffe2Backend as c2\r\ninit_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\r\nwith open(\"squeeze_init_net.pb\", \"wb\") as f:\r\n    f.write(init_net.SerializeToString())\r\nwith open(\"squeeze_predict_net.pb\", \"wb\") as f:\r\n    f.write(predict_net.SerializeToString())\r\n## System Info\r\n<class 'onnx.onnx_pb2.ModelProto'>\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-16-4691dd3e26ec> in <module>()\r\n      4 model = onnx.load(\"alexnet.proto\")\r\n      5 print(type(model))\r\n----> 6 prepared_backend = backend.prepare(model)\r\n      7 from caffe2.python.onnx.backend import Caffe2Backend as c2\r\n      8 init_net, predict_net = c2.onnx_graph_to_caffe2_net(model.graph)\r\n\r\n/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in prepare(cls, model, device, **kwargs)\r\n    745         # Check whether we have RNN related ops\r\n    746         pred_model = ModelProto()\r\n--> 747         pred_model.ParseFromString(cls.optimize_onnx(model.SerializeToString(), predict=True))\r\n    748         rnn_nodes = []\r\n    749         for node in pred_model.graph.node:\r\n\r\n/home/fiona/lizhen/caffe2/build/caffe2/python/onnx/backend.pyc in optimize_onnx(input, init, predict)\r\n    701         if predict:\r\n    702             passes.append('split_predict')\r\n--> 703         out = onnx.optimizer.optimize(input, passes)\r\n    704         return out\r\n    705 \r\n\r\n/home/fiona/anaconda2/lib/python2.7/site-packages/onnx-1.2.1-py2.7-linux-x86_64.egg/onnx/optimizer.pyc in optimize(model, passes)\r\n     43                   'fuse_transpose_into_gemm']\r\n     44     if not isinstance(model, ModelProto):\r\n---> 45         raise ValueError('Optimizer only accepts ModelProto, incorrect type: {}'.format(type(model)))\r\n     46 \r\n     47     model_str = model.SerializeToString()\r\n\r\nValueError: Optimizer only accepts ModelProto, incorrect type: <type 'str'>\r\n- PyTorch and Caffe2:\r\n- How you installed PyTorch (pip):\r\n- OS:Ubuntu16.04\r\n- PyTorch version:0.4.0\r\n- Python version:anaconda  python2 2.7.1\r\n- CUDA/cuDNN version:8.0/6.0.5\r\n- GPU models and configuration: GeForce GTX 1080 Ti/PCIe/SSE2\r\n- GCC version (if compiling from source):5.4.0\r\n- CMake version:3.11.1\r\n- Versions of any other relevant libraries:\r\neigen:3.3.4, opencv 3.4.1\r\n"}