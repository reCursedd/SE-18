{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6374", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6374/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6374/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6374/events", "html_url": "https://github.com/pytorch/pytorch/issues/6374", "id": 312155488, "node_id": "MDU6SXNzdWUzMTIxNTU0ODg=", "number": 6374, "title": "type(any_tensor) is always Variable", "user": {"login": "davidbau", "id": 3458792, "node_id": "MDQ6VXNlcjM0NTg3OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3458792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidbau", "html_url": "https://github.com/davidbau", "followers_url": "https://api.github.com/users/davidbau/followers", "following_url": "https://api.github.com/users/davidbau/following{/other_user}", "gists_url": "https://api.github.com/users/davidbau/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidbau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidbau/subscriptions", "organizations_url": "https://api.github.com/users/davidbau/orgs", "repos_url": "https://api.github.com/users/davidbau/repos", "events_url": "https://api.github.com/users/davidbau/events{/privacy}", "received_events_url": "https://api.github.com/users/davidbau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-07T00:35:02Z", "updated_at": "2018-04-07T05:04:18Z", "closed_at": "2018-04-07T05:04:18Z", "author_association": "NONE", "body_html": "<p>On current builds of pytorch, <code>type(t)</code> for any tensor <code>t</code> seems to always be <code>autograd.Variable</code> now.<br>\nIs there any way to get the actual tensor type back out, e.g., for coercing one tensor to the same data type of another tensor?</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; type(torch.zeros(2))\n&lt;class 'torch.autograd.variable.Variable'&gt;\n</code></pre>", "body_text": "On current builds of pytorch, type(t) for any tensor t seems to always be autograd.Variable now.\nIs there any way to get the actual tensor type back out, e.g., for coercing one tensor to the same data type of another tensor?\n>>> import torch\n>>> type(torch.zeros(2))\n<class 'torch.autograd.variable.Variable'>", "body": "On current builds of pytorch, `type(t)` for any tensor `t` seems to always be `autograd.Variable` now. \r\nIs there any way to get the actual tensor type back out, e.g., for coercing one tensor to the same data type of another tensor?\r\n\r\n```\r\n>>> import torch\r\n>>> type(torch.zeros(2))\r\n<class 'torch.autograd.variable.Variable'>\r\n```\r\n"}