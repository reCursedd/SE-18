{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/431427239", "html_url": "https://github.com/pytorch/pytorch/issues/12876#issuecomment-431427239", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12876", "id": 431427239, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMTQyNzIzOQ==", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-19T16:50:34Z", "updated_at": "2018-10-19T16:50:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Output of that particular test:</p>\n<pre><code>Oct 19 12:27:22 test_reduce_multigpu (__main__.TestDistBackend) ... Process process 0:\nOct 19 12:27:22 Traceback (most recent call last):\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\nOct 19 12:27:22     self.run()\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\nOct 19 12:27:22     self._target(*self._args, **self._kwargs)\nOct 19 12:27:22   File \"test_distributed.py\", line 1330, in _run\nOct 19 12:27:22     rank=self.rank\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 280, in init_process_group\nOct 19 12:27:22     store, rank, world_size = next(rendezvous(init_method))\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/rendezvous.py\", line 131, in _env_rendezvous_handler\nOct 19 12:27:22     store = TCPStore(master_addr, master_port, start_daemon)\nOct 19 12:27:22 RuntimeError: Address already in use\nOct 19 12:37:22 FAIL\n</code></pre>\n<p>The failure can happen on any test that uses the TCP store though, so removing all uses will fix the problem.</p>", "body_text": "Output of that particular test:\nOct 19 12:27:22 test_reduce_multigpu (__main__.TestDistBackend) ... Process process 0:\nOct 19 12:27:22 Traceback (most recent call last):\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\nOct 19 12:27:22     self.run()\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\nOct 19 12:27:22     self._target(*self._args, **self._kwargs)\nOct 19 12:27:22   File \"test_distributed.py\", line 1330, in _run\nOct 19 12:27:22     rank=self.rank\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 280, in init_process_group\nOct 19 12:27:22     store, rank, world_size = next(rendezvous(init_method))\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/rendezvous.py\", line 131, in _env_rendezvous_handler\nOct 19 12:27:22     store = TCPStore(master_addr, master_port, start_daemon)\nOct 19 12:27:22 RuntimeError: Address already in use\nOct 19 12:37:22 FAIL\n\nThe failure can happen on any test that uses the TCP store though, so removing all uses will fix the problem.", "body": "Output of that particular test:\r\n\r\n```\r\nOct 19 12:27:22 test_reduce_multigpu (__main__.TestDistBackend) ... Process process 0:\r\nOct 19 12:27:22 Traceback (most recent call last):\r\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\r\nOct 19 12:27:22     self.run()\r\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\r\nOct 19 12:27:22     self._target(*self._args, **self._kwargs)\r\nOct 19 12:27:22   File \"test_distributed.py\", line 1330, in _run\r\nOct 19 12:27:22     rank=self.rank\r\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 280, in init_process_group\r\nOct 19 12:27:22     store, rank, world_size = next(rendezvous(init_method))\r\nOct 19 12:27:22   File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/rendezvous.py\", line 131, in _env_rendezvous_handler\r\nOct 19 12:27:22     store = TCPStore(master_addr, master_port, start_daemon)\r\nOct 19 12:27:22 RuntimeError: Address already in use\r\nOct 19 12:37:22 FAIL\r\n```\r\n\r\nThe failure can happen on any test that uses the TCP store though, so removing all uses will fix the problem."}