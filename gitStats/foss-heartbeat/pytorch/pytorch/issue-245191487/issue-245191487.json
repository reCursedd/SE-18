{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2195", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2195/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2195/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2195/events", "html_url": "https://github.com/pytorch/pytorch/pull/2195", "id": 245191487, "node_id": "MDExOlB1bGxSZXF1ZXN0MTMyMTMxODI5", "number": 2195, "title": "reformulate bce_with_logits to not use abs", "user": {"login": "alykhantejani", "id": 687194, "node_id": "MDQ6VXNlcjY4NzE5NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/687194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alykhantejani", "html_url": "https://github.com/alykhantejani", "followers_url": "https://api.github.com/users/alykhantejani/followers", "following_url": "https://api.github.com/users/alykhantejani/following{/other_user}", "gists_url": "https://api.github.com/users/alykhantejani/gists{/gist_id}", "starred_url": "https://api.github.com/users/alykhantejani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alykhantejani/subscriptions", "organizations_url": "https://api.github.com/users/alykhantejani/orgs", "repos_url": "https://api.github.com/users/alykhantejani/repos", "events_url": "https://api.github.com/users/alykhantejani/events{/privacy}", "received_events_url": "https://api.github.com/users/alykhantejani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-07-24T19:58:04Z", "updated_at": "2017-07-24T22:16:31Z", "closed_at": "2017-07-24T22:16:28Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/2195", "html_url": "https://github.com/pytorch/pytorch/pull/2195", "diff_url": "https://github.com/pytorch/pytorch/pull/2195.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/2195.patch"}, "body_html": "<p>This is a fix for the bug reported <a href=\"https://github.com/pytorch/pytorch/pull/1792#issuecomment-317289657\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/1792/hovercard\">here</a> in which <code>binary_cross_entropy_with_logits</code> gives the wrong gradient with <code>input</code> and <code>target</code> are <code>0</code>.</p>\n<p>After some investigation, this is because the gradient of <code>abs</code> at <code>0</code> is <code>0</code> (see <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/autograd/_functions/pointwise.py#L139\">here</a>)</p>\n<p>In this PR I have reformulated the numerically stable <code>binary_cross_entropy_with_logits</code> to not use <code>abs</code> (originally I used what <a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\" rel=\"nofollow\">tensorflow does</a>, which is use abs).</p>\n<p>I guess in general we should think about whether we want the grad of <code>abs(0)</code> to be <code>0</code>?</p>", "body_text": "This is a fix for the bug reported here in which binary_cross_entropy_with_logits gives the wrong gradient with input and target are 0.\nAfter some investigation, this is because the gradient of abs at 0 is 0 (see here)\nIn this PR I have reformulated the numerically stable binary_cross_entropy_with_logits to not use abs (originally I used what tensorflow does, which is use abs).\nI guess in general we should think about whether we want the grad of abs(0) to be 0?", "body": "This is a fix for the bug reported [here](https://github.com/pytorch/pytorch/pull/1792#issuecomment-317289657) in which `binary_cross_entropy_with_logits` gives the wrong gradient with `input` and `target` are `0`. \r\n\r\nAfter some investigation, this is because the gradient of `abs` at `0` is `0` (see [here](https://github.com/pytorch/pytorch/blob/master/torch/autograd/_functions/pointwise.py#L139))\r\n\r\nIn this PR I have reformulated the numerically stable `binary_cross_entropy_with_logits` to not use `abs` (originally I used what [tensorflow does](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits), which is use abs).\r\n\r\nI guess in general we should think about whether we want the grad of `abs(0)` to be `0`?"}