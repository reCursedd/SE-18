{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234755331", "pull_request_review_id": 176465033, "id": 234755331, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDc1NTMzMQ==", "diff_hunk": "@@ -3,23 +3,113 @@\n \n namespace c10 {\n \n-ThreadPool::ThreadPool() { /* intended to leave empty */ }\n+TaskThreadPoolBase::~TaskThreadPoolBase() { /* intended to leave empty */ }\n \n-ThreadPool::~ThreadPool() { /* intended to leave empty */ }\n+ThreadPool::ThreadPool(std::size_t pool_size, int numa_node_id)\n+    : threads_(pool_size),\n+      running_(true),\n+      complete_(true),\n+      available_(pool_size),\n+      total_(pool_size),\n+      numa_node_id_(numa_node_id) {\n+  for (std::size_t i = 0; i < pool_size; ++i) {\n+    threads_[i] = std::thread(std::bind(&ThreadPool::main_loop, this, i));\n+  }\n+}\n+\n+ThreadPool::~ThreadPool() {\n+  // Set running flag to false then notify all threads.\n+  {\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    running_ = false;\n+    condition_.notify_all();\n+  }\n+\n+  try {\n+    for (auto& t : threads_) {\n+      t.join();\n+    }\n+  } catch (const std::exception&) {\n+  }\n+}\n+\n+size_t ThreadPool::size() const {\n+  return threads_.size();\n+}\n+\n+size_t ThreadPool::numAvailable() const {\n+  return available_;\n+}\n \n-void ThreadPool::schedule(std::function<void(void)> task) {\n-  tasks.push(task);\n+void ThreadPool::run(const std::function<void()>& func) {\n+  runTask(func);\n }\n \n-void ThreadPool::workOnTasksUntilCompleted(\n-    c10::intrusive_ptr<ivalue::Future> future) {\n-  while (!future->completed()) {\n-    auto task = tasks.front();\n-    tasks.pop();\n-    task();\n+void ThreadPool::waitWorkComplete() {\n+  std::unique_lock<std::mutex> lock(mutex_);\n+  while (!complete_) {\n+    completed_.wait(lock);\n   }\n }\n \n-ThreadPool global_work_queue;\n+void ThreadPool::waitWorkComplete(c10::intrusive_ptr<ivalue::Future> future) {\n+  // TODO: wait on future\n+  waitWorkComplete();", "path": "aten/src/ATen/core/thread_pool.cpp", "position": null, "original_position": 66, "commit_id": "d2668b7fb104dd83ba5bd248841ececa24bac6e7", "original_commit_id": "ba000cbb93152f16f9984778d19376f3dde95bfd", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "A couple nits:\r\n\r\n1. Why change the name of `workOnTasksUntilCompleted`? Even though that is not what the method does now, it reflects the design as we want it to work. We can easily forget the places where it is valid to have the thread join the worker pool if we rename it to something else and forget to name it back. It is better to leave it as is, with a note for how it should work in the future.\r\n\r\n2. This implementation will livelock when there is a continual stream of work coming into the threadpool. If the thread is going to sleep then it should arrange for it to be woken up when Future is completed.", "created_at": "2018-11-19T19:40:29Z", "updated_at": "2018-11-23T15:55:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/14114#discussion_r234755331", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/14114", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234755331"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/14114#discussion_r234755331"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/14114"}}, "body_html": "<p>A couple nits:</p>\n<ol>\n<li>\n<p>Why change the name of <code>workOnTasksUntilCompleted</code>? Even though that is not what the method does now, it reflects the design as we want it to work. We can easily forget the places where it is valid to have the thread join the worker pool if we rename it to something else and forget to name it back. It is better to leave it as is, with a note for how it should work in the future.</p>\n</li>\n<li>\n<p>This implementation will livelock when there is a continual stream of work coming into the threadpool. If the thread is going to sleep then it should arrange for it to be woken up when Future is completed.</p>\n</li>\n</ol>", "body_text": "A couple nits:\n\n\nWhy change the name of workOnTasksUntilCompleted? Even though that is not what the method does now, it reflects the design as we want it to work. We can easily forget the places where it is valid to have the thread join the worker pool if we rename it to something else and forget to name it back. It is better to leave it as is, with a note for how it should work in the future.\n\n\nThis implementation will livelock when there is a continual stream of work coming into the threadpool. If the thread is going to sleep then it should arrange for it to be woken up when Future is completed."}