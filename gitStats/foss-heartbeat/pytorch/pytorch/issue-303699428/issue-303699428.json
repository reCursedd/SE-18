{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5656", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5656/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5656/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5656/events", "html_url": "https://github.com/pytorch/pytorch/issues/5656", "id": 303699428, "node_id": "MDU6SXNzdWUzMDM2OTk0Mjg=", "number": 5656, "title": "cannot inference on multi GPU?", "user": {"login": "pzz2011", "id": 5304200, "node_id": "MDQ6VXNlcjUzMDQyMDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5304200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzz2011", "html_url": "https://github.com/pzz2011", "followers_url": "https://api.github.com/users/pzz2011/followers", "following_url": "https://api.github.com/users/pzz2011/following{/other_user}", "gists_url": "https://api.github.com/users/pzz2011/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzz2011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzz2011/subscriptions", "organizations_url": "https://api.github.com/users/pzz2011/orgs", "repos_url": "https://api.github.com/users/pzz2011/repos", "events_url": "https://api.github.com/users/pzz2011/events{/privacy}", "received_events_url": "https://api.github.com/users/pzz2011/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-09T02:10:42Z", "updated_at": "2018-03-09T02:58:11Z", "closed_at": "2018-03-09T02:58:11Z", "author_association": "NONE", "body_html": "<p>pytorch version 0.3.1<br>\nOS CenOS<br>\nCUDA Version 9.0.176<br>\nCUDNN 7<br>\nGPU:8  V100 16GB</p>\n<p>THCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory<br>\n*** Error in `python': free(): invalid pointer: 0x00007f161ccfe780 ***</p>\n<p>I wonder that why I cannot inference on multi-GPU....</p>\n<p>opt = parser.parse_args()<br>\ncuda = opt.cuda</p>\n<p>if cuda and not torch.cuda.is_available():<br>\nraise Exception(\"No GPU found, please run without --cuda\")</p>\n<p>model = torch.load(opt.model)[\"model\"].module</p>", "body_text": "pytorch version 0.3.1\nOS CenOS\nCUDA Version 9.0.176\nCUDNN 7\nGPU:8  V100 16GB\nTHCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory\n*** Error in `python': free(): invalid pointer: 0x00007f161ccfe780 ***\nI wonder that why I cannot inference on multi-GPU....\nopt = parser.parse_args()\ncuda = opt.cuda\nif cuda and not torch.cuda.is_available():\nraise Exception(\"No GPU found, please run without --cuda\")\nmodel = torch.load(opt.model)[\"model\"].module", "body": "pytorch version 0.3.1\r\nOS CenOS\r\nCUDA Version 9.0.176\r\nCUDNN 7\r\nGPU:8  V100 16GB\r\n\r\n\r\nTHCudaCheck FAIL file=/pytorch/torch/lib/THC/generic/THCStorage.cu line=58 error=2 : out of memory\r\n*** Error in `python': free(): invalid pointer: 0x00007f161ccfe780 ***\r\n\r\nI wonder that why I cannot inference on multi-GPU....\r\n\r\n\r\nopt = parser.parse_args()\r\ncuda = opt.cuda\r\n\r\nif cuda and not torch.cuda.is_available():\r\n    raise Exception(\"No GPU found, please run without --cuda\")\r\n\r\nmodel = torch.load(opt.model)[\"model\"].module\r\n\r\n\r\n\r\n"}