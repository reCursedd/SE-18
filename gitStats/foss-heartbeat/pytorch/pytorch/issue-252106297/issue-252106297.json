{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2515", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2515/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2515/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2515/events", "html_url": "https://github.com/pytorch/pytorch/issues/2515", "id": 252106297, "node_id": "MDU6SXNzdWUyNTIxMDYyOTc=", "number": 2515, "title": "weight_norm assertion error when using bias=False and using cuda", "user": {"login": "jramapuram", "id": 8204807, "node_id": "MDQ6VXNlcjgyMDQ4MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/8204807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jramapuram", "html_url": "https://github.com/jramapuram", "followers_url": "https://api.github.com/users/jramapuram/followers", "following_url": "https://api.github.com/users/jramapuram/following{/other_user}", "gists_url": "https://api.github.com/users/jramapuram/gists{/gist_id}", "starred_url": "https://api.github.com/users/jramapuram/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jramapuram/subscriptions", "organizations_url": "https://api.github.com/users/jramapuram/orgs", "repos_url": "https://api.github.com/users/jramapuram/repos", "events_url": "https://api.github.com/users/jramapuram/events{/privacy}", "received_events_url": "https://api.github.com/users/jramapuram/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-08-22T22:20:57Z", "updated_at": "2018-09-07T20:44:52Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Running python3.6 w/ pytorch0.2:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\n\ng <span class=\"pl-k\">=</span> nn.GRU(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">20</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>).cuda()\ng <span class=\"pl-k\">=</span> nn.utils.weight_norm(g, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_hh_l0<span class=\"pl-pds\">'</span></span>)\ng <span class=\"pl-k\">=</span> nn.utils.weight_norm(g, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_ih_l0<span class=\"pl-pds\">'</span></span>)\ng.flatten_parameters()\nzero_state <span class=\"pl-k\">=</span> Variable(torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">20</span>).cuda())\n\nx <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">20</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>).cuda())\noutput, state <span class=\"pl-k\">=</span> g(x, zero_state)</pre></div>\n<div class=\"highlight highlight-source-shell\"><pre>---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython-input-15-bacede2d81b<span class=\"pl-k\">6&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">&lt;module&gt;</span>()\n     11 \n     12 x = Variable(torch.randn(20, 32, <span class=\"pl-en\">100).cuda</span>())\n---<span class=\"pl-k\">&gt;</span> 13 output, state = g(x, zero_state)\n\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py <span class=\"pl-k\">in</span> __call__(self, <span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    222         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_pre_hooks.values</span>():\n    223             hook(self, input)\n--<span class=\"pl-k\">&gt;</span> 224         result = self.forward(<span class=\"pl-k\">*</span>input, <span class=\"pl-k\">**</span>kwargs)\n    225         <span class=\"pl-k\">for</span> <span class=\"pl-smi\">hook</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">self._forward_hooks.values</span>():\n    226             hook_result = hook(self, input, result)\n\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py <span class=\"pl-k\">in</span> forward(self, input, hx)\n    143         <span class=\"pl-k\">if</span> has_flat_weights:\n    144             first_data = <span class=\"pl-en\">next(self.parameters</span>()).data\n--<span class=\"pl-k\">&gt;</span> 145             assert <span class=\"pl-en\">first_data.storage().size</span>() == self._param_buf_size\n    146             flat_weight = <span class=\"pl-en\">first_data.new().set_(first_data.storage</span>(), 0, torch.Size([self._param_buf_size]))\n    147         else:\n\nAssertionError: </pre></div>\n<p><strong>Note</strong>: This works fine when not using cuda, i.e:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\n\ng <span class=\"pl-k\">=</span> nn.GRU(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">20</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\ng <span class=\"pl-k\">=</span> nn.utils.weight_norm(g, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_hh_l0<span class=\"pl-pds\">'</span></span>)\ng <span class=\"pl-k\">=</span> nn.utils.weight_norm(g, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>weight_ih_l0<span class=\"pl-pds\">'</span></span>)\ng.flatten_parameters()\nzero_state <span class=\"pl-k\">=</span> Variable(torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">20</span>))\n\nx <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">20</span>, <span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">100</span>))\noutput, state <span class=\"pl-k\">=</span> g(x, zero_state)</pre></div>", "body_text": "Running python3.6 w/ pytorch0.2:\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ng = nn.GRU(100, 20, bias=False).cuda()\ng = nn.utils.weight_norm(g, name='weight_hh_l0')\ng = nn.utils.weight_norm(g, name='weight_ih_l0')\ng.flatten_parameters()\nzero_state = Variable(torch.zeros(1, 32, 20).cuda())\n\nx = Variable(torch.randn(20, 32, 100).cuda())\noutput, state = g(x, zero_state)\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n<ipython-input-15-bacede2d81b6> in <module>()\n     11 \n     12 x = Variable(torch.randn(20, 32, 100).cuda())\n---> 13 output, state = g(x, zero_state)\n\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\n    143         if has_flat_weights:\n    144             first_data = next(self.parameters()).data\n--> 145             assert first_data.storage().size() == self._param_buf_size\n    146             flat_weight = first_data.new().set_(first_data.storage(), 0, torch.Size([self._param_buf_size]))\n    147         else:\n\nAssertionError: \nNote: This works fine when not using cuda, i.e:\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ng = nn.GRU(100, 20, bias=False)\ng = nn.utils.weight_norm(g, name='weight_hh_l0')\ng = nn.utils.weight_norm(g, name='weight_ih_l0')\ng.flatten_parameters()\nzero_state = Variable(torch.zeros(1, 32, 20))\n\nx = Variable(torch.randn(20, 32, 100))\noutput, state = g(x, zero_state)", "body": "Running python3.6 w/ pytorch0.2:\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\n\r\ng = nn.GRU(100, 20, bias=False).cuda()\r\ng = nn.utils.weight_norm(g, name='weight_hh_l0')\r\ng = nn.utils.weight_norm(g, name='weight_ih_l0')\r\ng.flatten_parameters()\r\nzero_state = Variable(torch.zeros(1, 32, 20).cuda())\r\n\r\nx = Variable(torch.randn(20, 32, 100).cuda())\r\noutput, state = g(x, zero_state)\r\n```\r\n\r\n```bash\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-15-bacede2d81b6> in <module>()\r\n     11 \r\n     12 x = Variable(torch.randn(20, 32, 100).cuda())\r\n---> 13 output, state = g(x, zero_state)\r\n\r\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n/home/jason/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py in forward(self, input, hx)\r\n    143         if has_flat_weights:\r\n    144             first_data = next(self.parameters()).data\r\n--> 145             assert first_data.storage().size() == self._param_buf_size\r\n    146             flat_weight = first_data.new().set_(first_data.storage(), 0, torch.Size([self._param_buf_size]))\r\n    147         else:\r\n\r\nAssertionError: \r\n```\r\n\r\n**Note**: This works fine when not using cuda, i.e:\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\n\r\ng = nn.GRU(100, 20, bias=False)\r\ng = nn.utils.weight_norm(g, name='weight_hh_l0')\r\ng = nn.utils.weight_norm(g, name='weight_ih_l0')\r\ng.flatten_parameters()\r\nzero_state = Variable(torch.zeros(1, 32, 20))\r\n\r\nx = Variable(torch.randn(20, 32, 100))\r\noutput, state = g(x, zero_state)\r\n```"}