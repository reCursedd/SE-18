{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/358894180", "html_url": "https://github.com/pytorch/pytorch/issues/4715#issuecomment-358894180", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4715", "id": 358894180, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODg5NDE4MA==", "user": {"login": "lizeyan", "id": 12494243, "node_id": "MDQ6VXNlcjEyNDk0MjQz", "avatar_url": "https://avatars2.githubusercontent.com/u/12494243?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lizeyan", "html_url": "https://github.com/lizeyan", "followers_url": "https://api.github.com/users/lizeyan/followers", "following_url": "https://api.github.com/users/lizeyan/following{/other_user}", "gists_url": "https://api.github.com/users/lizeyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/lizeyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lizeyan/subscriptions", "organizations_url": "https://api.github.com/users/lizeyan/orgs", "repos_url": "https://api.github.com/users/lizeyan/repos", "events_url": "https://api.github.com/users/lizeyan/events{/privacy}", "received_events_url": "https://api.github.com/users/lizeyan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T08:05:45Z", "updated_at": "2018-01-19T08:05:45Z", "author_association": "NONE", "body_html": "<p>I have the same issue.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">model_sample</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> sample the handwriting style from the constant prior distribution</span>\n        prior_mu <span class=\"pl-k\">=</span> Variable(torch.zeros([batch_size, <span class=\"pl-c1\">self</span>.z_dim]))\n        prior_sigma <span class=\"pl-k\">=</span> Variable(torch.ones([batch_size, <span class=\"pl-c1\">self</span>.z_dim]))\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.use_cuda:\n            prior_mu <span class=\"pl-k\">=</span> prior_mu.cuda()\n            prior_sigma <span class=\"pl-k\">=</span> prior_sigma.cuda()\n        zs <span class=\"pl-k\">=</span> pyro.sample(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>z<span class=\"pl-pds\">\"</span></span>, dist.normal, prior_mu, prior_sigma)\n        mu <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.decoder.forward(zs)\n        xs <span class=\"pl-k\">=</span> pyro.sample(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>sample<span class=\"pl-pds\">\"</span></span>, dist.bernoulli, mu)\n        <span class=\"pl-k\">return</span> xs, mu</pre></div>\n<p>Then get the exception:</p>\n<pre><code>&lt;ipython-input-22-4e8c50fd6e8a&gt; in model_sample(self, batch_size)\n     60         zs = pyro.sample(\"z\", dist.normal, prior_mu, prior_sigma)\n     61         mu = self.decoder.forward(zs)\n---&gt; 62         xs = pyro.sample(\"sample\", dist.bernoulli, mu)\n     63         return xs, mu\n\n/exp/pyro/pyro/__init__.py in sample(name, fn, *args, **kwargs)\n     61                           RuntimeWarning)\n     62             return obs\n---&gt; 63         return fn(*args, **kwargs)\n     64     # if stack not empty, apply everything in the stack?\n     65     else:\n\n/exp/pyro/pyro/distributions/random_primitive.py in sample(self, *args, **kwargs)\n     35 \n     36     def sample(self, *args, **kwargs):\n---&gt; 37         return self.dist_class(*args, **kwargs).sample()\n     38 \n     39     __call__ = sample\n\n/exp/pyro/pyro/distributions/torch_wrapper.py in sample(self)\n     36             return self.torch_dist.rsample(self._sample_shape)\n     37         else:\n---&gt; 38             return self.torch_dist.sample(self._sample_shape)\n     39 \n     40     def batch_log_pdf(self, x):\n\n/miniconda/lib/python3.6/site-packages/torch/distributions/bernoulli.py in sample(self, sample_shape)\n     55     def sample(self, sample_shape=torch.Size()):\n     56         shape = self._extended_shape(sample_shape)\n---&gt; 57         return torch.bernoulli(self.probs.expand(shape))\n     58 \n     59     def log_prob(self, value):\n\nRuntimeError: bernoulli is not implemented for type torch.cuda.FloatTensor\n</code></pre>", "body_text": "I have the same issue.\ndef model_sample(self, batch_size=1):\n        # sample the handwriting style from the constant prior distribution\n        prior_mu = Variable(torch.zeros([batch_size, self.z_dim]))\n        prior_sigma = Variable(torch.ones([batch_size, self.z_dim]))\n        if self.use_cuda:\n            prior_mu = prior_mu.cuda()\n            prior_sigma = prior_sigma.cuda()\n        zs = pyro.sample(\"z\", dist.normal, prior_mu, prior_sigma)\n        mu = self.decoder.forward(zs)\n        xs = pyro.sample(\"sample\", dist.bernoulli, mu)\n        return xs, mu\nThen get the exception:\n<ipython-input-22-4e8c50fd6e8a> in model_sample(self, batch_size)\n     60         zs = pyro.sample(\"z\", dist.normal, prior_mu, prior_sigma)\n     61         mu = self.decoder.forward(zs)\n---> 62         xs = pyro.sample(\"sample\", dist.bernoulli, mu)\n     63         return xs, mu\n\n/exp/pyro/pyro/__init__.py in sample(name, fn, *args, **kwargs)\n     61                           RuntimeWarning)\n     62             return obs\n---> 63         return fn(*args, **kwargs)\n     64     # if stack not empty, apply everything in the stack?\n     65     else:\n\n/exp/pyro/pyro/distributions/random_primitive.py in sample(self, *args, **kwargs)\n     35 \n     36     def sample(self, *args, **kwargs):\n---> 37         return self.dist_class(*args, **kwargs).sample()\n     38 \n     39     __call__ = sample\n\n/exp/pyro/pyro/distributions/torch_wrapper.py in sample(self)\n     36             return self.torch_dist.rsample(self._sample_shape)\n     37         else:\n---> 38             return self.torch_dist.sample(self._sample_shape)\n     39 \n     40     def batch_log_pdf(self, x):\n\n/miniconda/lib/python3.6/site-packages/torch/distributions/bernoulli.py in sample(self, sample_shape)\n     55     def sample(self, sample_shape=torch.Size()):\n     56         shape = self._extended_shape(sample_shape)\n---> 57         return torch.bernoulli(self.probs.expand(shape))\n     58 \n     59     def log_prob(self, value):\n\nRuntimeError: bernoulli is not implemented for type torch.cuda.FloatTensor", "body": "I have the same issue.\r\n``` python\r\ndef model_sample(self, batch_size=1):\r\n        # sample the handwriting style from the constant prior distribution\r\n        prior_mu = Variable(torch.zeros([batch_size, self.z_dim]))\r\n        prior_sigma = Variable(torch.ones([batch_size, self.z_dim]))\r\n        if self.use_cuda:\r\n            prior_mu = prior_mu.cuda()\r\n            prior_sigma = prior_sigma.cuda()\r\n        zs = pyro.sample(\"z\", dist.normal, prior_mu, prior_sigma)\r\n        mu = self.decoder.forward(zs)\r\n        xs = pyro.sample(\"sample\", dist.bernoulli, mu)\r\n        return xs, mu\r\n```\r\n\r\nThen get the exception:\r\n```\r\n<ipython-input-22-4e8c50fd6e8a> in model_sample(self, batch_size)\r\n     60         zs = pyro.sample(\"z\", dist.normal, prior_mu, prior_sigma)\r\n     61         mu = self.decoder.forward(zs)\r\n---> 62         xs = pyro.sample(\"sample\", dist.bernoulli, mu)\r\n     63         return xs, mu\r\n\r\n/exp/pyro/pyro/__init__.py in sample(name, fn, *args, **kwargs)\r\n     61                           RuntimeWarning)\r\n     62             return obs\r\n---> 63         return fn(*args, **kwargs)\r\n     64     # if stack not empty, apply everything in the stack?\r\n     65     else:\r\n\r\n/exp/pyro/pyro/distributions/random_primitive.py in sample(self, *args, **kwargs)\r\n     35 \r\n     36     def sample(self, *args, **kwargs):\r\n---> 37         return self.dist_class(*args, **kwargs).sample()\r\n     38 \r\n     39     __call__ = sample\r\n\r\n/exp/pyro/pyro/distributions/torch_wrapper.py in sample(self)\r\n     36             return self.torch_dist.rsample(self._sample_shape)\r\n     37         else:\r\n---> 38             return self.torch_dist.sample(self._sample_shape)\r\n     39 \r\n     40     def batch_log_pdf(self, x):\r\n\r\n/miniconda/lib/python3.6/site-packages/torch/distributions/bernoulli.py in sample(self, sample_shape)\r\n     55     def sample(self, sample_shape=torch.Size()):\r\n     56         shape = self._extended_shape(sample_shape)\r\n---> 57         return torch.bernoulli(self.probs.expand(shape))\r\n     58 \r\n     59     def log_prob(self, value):\r\n\r\nRuntimeError: bernoulli is not implemented for type torch.cuda.FloatTensor\r\n```"}