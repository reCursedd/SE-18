{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/364504782", "html_url": "https://github.com/pytorch/pytorch/issues/4186#issuecomment-364504782", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4186", "id": 364504782, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDUwNDc4Mg==", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-09T17:41:02Z", "updated_at": "2018-02-09T17:41:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20233731\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mingfeima\">@mingfeima</a>,</p>\n<p>There is one workload (<a href=\"https://github.com/yf225/examples/tree/benchmark_test/word_language_model\">Word Language Model</a>) we've been working on recently where a) an efficient CPU implementation <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/FusedRNNKernel.c\">does not exist</a> b) it represents a <a href=\"https://gist.githubusercontent.com/yf225/40c0adb8bfb2a7b774fa266fb4bc409e/raw/20c67ebadbd75f41c6c9fd2e00b4b2562b60700a/mini_sequence_labeler.py\" rel=\"nofollow\">good proxy for other applications</a> and c) pytorch has recently invested work in <a href=\"https://github.com/pytorch/pytorch/commit/7bd2db997e95bf69e67bee3be5b0ef73ef39a516#diff-63ea4b4ea36b3763ca8ed2806100426a\">optimizing</a> the <a href=\"https://github.com/pytorch/pytorch/commit/7bd2db997e95bf69e67bee3be5b0ef73ef39a516\">GPU version</a>. This is a good starting point and fused RNN kernels can significantly speed up the code here. Let me know if this works for you.</p>\n<p>Thanks,<br>\nChristian</p>", "body_text": "Hello @mingfeima,\nThere is one workload (Word Language Model) we've been working on recently where a) an efficient CPU implementation does not exist b) it represents a good proxy for other applications and c) pytorch has recently invested work in optimizing the GPU version. This is a good starting point and fused RNN kernels can significantly speed up the code here. Let me know if this works for you.\nThanks,\nChristian", "body": "Hello @mingfeima,\r\n\r\nThere is one workload ([Word Language Model](https://github.com/yf225/examples/tree/benchmark_test/word_language_model)) we've been working on recently where a) an efficient CPU implementation [does not exist](https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/FusedRNNKernel.c) b) it represents a [good proxy for other applications](https://gist.githubusercontent.com/yf225/40c0adb8bfb2a7b774fa266fb4bc409e/raw/20c67ebadbd75f41c6c9fd2e00b4b2562b60700a/mini_sequence_labeler.py) and c) pytorch has recently invested work in [optimizing](https://github.com/pytorch/pytorch/commit/7bd2db997e95bf69e67bee3be5b0ef73ef39a516#diff-63ea4b4ea36b3763ca8ed2806100426a) the [GPU version](https://github.com/pytorch/pytorch/commit/7bd2db997e95bf69e67bee3be5b0ef73ef39a516). This is a good starting point and fused RNN kernels can significantly speed up the code here. Let me know if this works for you.\r\n\r\nThanks,\r\nChristian"}