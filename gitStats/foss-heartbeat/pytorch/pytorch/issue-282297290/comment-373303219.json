{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/373303219", "html_url": "https://github.com/pytorch/pytorch/issues/4186#issuecomment-373303219", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4186", "id": 373303219, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MzMwMzIxOQ==", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-15T08:50:21Z", "updated_at": "2018-03-15T08:50:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4063635\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yf225\">@yf225</a> we have been looking into <a href=\"https://github.com/yf225/examples/tree/benchmark_test/word_language_model\">word_language_model</a> lately.<br>\nThe low CPU performance is caused by several reasons, missing FusedRNNKernel is one of them but not the major one. After implementing forward and backward path of GRU and LSTM at aten/src/THNN/generic/FusedRNNKernel.c, the CPU performance gets only 10% performance boost on our Xeon Skylake 8180 server (2 sockets, 28 core per socket), which is quite abnormal.</p>\n<ol>\n<li>the biggest issue we found is that the forward path and backward path are using two sets of OpenMP threads separately at runtime. The usual BKM when running a server CPU is to set OMP_NUM_THREADS = number of physical cores. And we observed from vtune that forward path is using a set of 56 OpenMP threads and backward path is using another 56. Once set OMP_NUM_THREADS to be 28, i got much better performance even losing 50% of the total computing power, since fwd/bwd path threads are executing peacefully. :(<br>\nThe issue slows down not only RNN but also Convolution, and almost every CPU operator that depends on OpenMP for parallelization.</li>\n<li>Besides GRU/LSTM layers, some other operators also contribute a lot to the total runtime, for instance:</li>\n</ol>\n<ul>\n<li>logsoftmax</li>\n<li>dropout</li>\n<li>norm<br>\nWe will have these problems solved in an appropriate manner, step by step.<br>\nThe analysis of mini sequence labeler just began, i will have you updated later.</li>\n</ul>", "body_text": "@soumith @cpuhrsch @yf225 we have been looking into word_language_model lately.\nThe low CPU performance is caused by several reasons, missing FusedRNNKernel is one of them but not the major one. After implementing forward and backward path of GRU and LSTM at aten/src/THNN/generic/FusedRNNKernel.c, the CPU performance gets only 10% performance boost on our Xeon Skylake 8180 server (2 sockets, 28 core per socket), which is quite abnormal.\n\nthe biggest issue we found is that the forward path and backward path are using two sets of OpenMP threads separately at runtime. The usual BKM when running a server CPU is to set OMP_NUM_THREADS = number of physical cores. And we observed from vtune that forward path is using a set of 56 OpenMP threads and backward path is using another 56. Once set OMP_NUM_THREADS to be 28, i got much better performance even losing 50% of the total computing power, since fwd/bwd path threads are executing peacefully. :(\nThe issue slows down not only RNN but also Convolution, and almost every CPU operator that depends on OpenMP for parallelization.\nBesides GRU/LSTM layers, some other operators also contribute a lot to the total runtime, for instance:\n\n\nlogsoftmax\ndropout\nnorm\nWe will have these problems solved in an appropriate manner, step by step.\nThe analysis of mini sequence labeler just began, i will have you updated later.", "body": "@soumith @cpuhrsch @yf225 we have been looking into [word_language_model](https://github.com/yf225/examples/tree/benchmark_test/word_language_model) lately.\r\nThe low CPU performance is caused by several reasons, missing FusedRNNKernel is one of them but not the major one. After implementing forward and backward path of GRU and LSTM at aten/src/THNN/generic/FusedRNNKernel.c, the CPU performance gets only 10% performance boost on our Xeon Skylake 8180 server (2 sockets, 28 core per socket), which is quite abnormal.\r\n\r\n1. the biggest issue we found is that the forward path and backward path are using two sets of OpenMP threads separately at runtime. The usual BKM when running a server CPU is to set OMP_NUM_THREADS = number of physical cores. And we observed from vtune that forward path is using a set of 56 OpenMP threads and backward path is using another 56. Once set OMP_NUM_THREADS to be 28, i got much better performance even losing 50% of the total computing power, since fwd/bwd path threads are executing peacefully. :(\r\nThe issue slows down not only RNN but also Convolution, and almost every CPU operator that depends on OpenMP for parallelization.\r\n2. Besides GRU/LSTM layers, some other operators also contribute a lot to the total runtime, for instance:\r\n- logsoftmax\r\n- dropout\r\n- norm\r\nWe will have these problems solved in an appropriate manner, step by step.\r\nThe analysis of mini sequence labeler just began, i will have you updated later."}