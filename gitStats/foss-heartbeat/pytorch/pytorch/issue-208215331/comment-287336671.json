{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/287336671", "html_url": "https://github.com/pytorch/pytorch/issues/763#issuecomment-287336671", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/763", "id": 287336671, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NzMzNjY3MQ==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-17T12:00:48Z", "updated_at": "2017-03-17T12:00:48Z", "author_association": "MEMBER", "body_html": "<p>Adding context to the task for community members to pick it up. ( cc: <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19649871\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/uridah\">@uridah</a> )</p>\n<p>nn.Bilinear refers to <a href=\"https://github.com/torch/nn/blob/master/doc/simple.md#nn.Bilinear\">this Lua-Torch layer</a></p>\n<p>It computes a Bilinear transformation <code>\\forall k: y_k = x_1 A_k x_2 + b</code>.</p>\n<p>To contrast this, a Linear transformation is <code>\\forall k: y_k = A_k x_1 + b</code>.</p>\n<p>The source code for it is <a href=\"https://github.com/torch/nn/blob/master/Bilinear.lua\">here</a> and has been transpiled to <code>legacy.nn</code> of PyTorch <a href=\"https://github.com/pytorch/pytorch/blob/79f5bf84e54d57a4c81912aeedb0b8a27f97c27e/torch/legacy/nn/Bilinear.py\">here</a></p>\n<p>This task is to implement <code>nn.Bilinear</code> under the <code>nn</code> package (not <code>legacy.nn</code>) which uses autograd.</p>\n<p>Doing the basic PyTorch tutorials might give you enough familiarity with autograd / neural networks.</p>\n<p>Now coming to the task. Take a look at how <code>nn.Linear</code> is implemented in PyTorch here:</p>\n<ol>\n<li>core implementation in nn._functions<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/2b23712dc34ad281a1d9c7d5a829a83168503f93/torch/nn/_functions/linear.py#L5-L31\">pytorch/torch/nn/_functions/linear.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 5 to 31\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/2b23712dc34ad281a1d9c7d5a829a83168503f93\">2b23712</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L5\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"5\"></td>\n          <td id=\"LC5\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">class</span> <span class=\"pl-en\">Linear</span>(<span class=\"pl-e\">Function</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L6\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"6\"></td>\n          <td id=\"LC6\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L7\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"7\"></td>\n          <td id=\"LC7\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">weight</span>, <span class=\"pl-smi\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L8\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"8\"></td>\n          <td id=\"LC8\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.save_for_backward(<span class=\"pl-c1\">input</span>, weight, bias) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L9\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"9\"></td>\n          <td id=\"LC9\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.new(<span class=\"pl-c1\">input</span>.size(<span class=\"pl-c1\">0</span>), weight.size(<span class=\"pl-c1\">0</span>)) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L10\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"10\"></td>\n          <td id=\"LC10\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         output.addmm_(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">input</span>, weight.t()) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L11\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"11\"></td>\n          <td id=\"LC11\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L12\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"12\"></td>\n          <td id=\"LC12\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c\"><span class=\"pl-c\">#</span> cuBLAS doesn't support 0 strides in sger, so we can't use expand</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L13\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"13\"></td>\n          <td id=\"LC13\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c1\">self</span>.add_buffer <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.new(<span class=\"pl-c1\">1</span>).resize_(<span class=\"pl-c1\">input</span>.size(<span class=\"pl-c1\">0</span>)).fill_(<span class=\"pl-c1\">1</span>) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L14\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"14\"></td>\n          <td id=\"LC14\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             output.addr_(<span class=\"pl-c1\">self</span>.add_buffer, bias) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L15\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"15\"></td>\n          <td id=\"LC15\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">return</span> output </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L16\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"16\"></td>\n          <td id=\"LC16\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L17\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"17\"></td>\n          <td id=\"LC17\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-en\">backward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">grad_output</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L18\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"18\"></td>\n          <td id=\"LC18\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">input</span>, weight, bias <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.saved_tensors </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L19\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"19\"></td>\n          <td id=\"LC19\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L20\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"20\"></td>\n          <td id=\"LC20\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         grad_input <span class=\"pl-k\">=</span> grad_weight <span class=\"pl-k\">=</span> grad_bias <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L21\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"21\"></td>\n          <td id=\"LC21\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.needs_input_grad[<span class=\"pl-c1\">0</span>]: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L22\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"22\"></td>\n          <td id=\"LC22\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             grad_input <span class=\"pl-k\">=</span> torch.mm(grad_output, weight) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L23\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"23\"></td>\n          <td id=\"LC23\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.needs_input_grad[<span class=\"pl-c1\">1</span>]: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L24\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"24\"></td>\n          <td id=\"LC24\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             grad_weight <span class=\"pl-k\">=</span> torch.mm(grad_output.t(), <span class=\"pl-c1\">input</span>) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L25\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"25\"></td>\n          <td id=\"LC25\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span> <span class=\"pl-k\">and</span> <span class=\"pl-c1\">self</span>.needs_input_grad[<span class=\"pl-c1\">2</span>]: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L26\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"26\"></td>\n          <td id=\"LC26\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             grad_bias <span class=\"pl-k\">=</span> torch.mv(grad_output.t(), <span class=\"pl-c1\">self</span>.add_buffer) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L27\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"27\"></td>\n          <td id=\"LC27\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L28\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"28\"></td>\n          <td id=\"LC28\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L29\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"29\"></td>\n          <td id=\"LC29\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">return</span> grad_input, grad_weight, grad_bias </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L30\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"30\"></td>\n          <td id=\"LC30\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">else</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L31\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"31\"></td>\n          <td id=\"LC31\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">return</span> grad_input, grad_weight </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</li>\n<li>then, called in nn via creating an <code>nn.Linear</code> which is a subclass of <code>nn.Module</code>:<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/2b23712dc34ad281a1d9c7d5a829a83168503f93/torch/nn/modules/linear.py#L9-L60\">pytorch/torch/nn/modules/linear.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 9 to 60\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/2b23712dc34ad281a1d9c7d5a829a83168503f93\">2b23712</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L9\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"9\"></td>\n          <td id=\"LC9\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">class</span> <span class=\"pl-en\">Linear</span>(<span class=\"pl-e\">Module</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L10\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"10\"></td>\n          <td id=\"LC10\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-s\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">\"\"\"</span>Applies a linear transformation to the incoming data: :math:`y = Ax + b`</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L11\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"11\"></td>\n          <td id=\"LC11\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\"></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L12\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"12\"></td>\n          <td id=\"LC12\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">    Args:</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L13\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"13\"></td>\n          <td id=\"LC13\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        in_features: size of each input sample</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L14\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"14\"></td>\n          <td id=\"LC14\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        out_features: size of each output sample</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L15\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"15\"></td>\n          <td id=\"LC15\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        bias: If set to False, the layer will not learn an additive bias. Default: True</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L16\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"16\"></td>\n          <td id=\"LC16\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\"></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L17\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"17\"></td>\n          <td id=\"LC17\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">    Shape:</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L18\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"18\"></td>\n          <td id=\"LC18\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        - Input: :math:`(N, in\\_features)`</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L19\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"19\"></td>\n          <td id=\"LC19\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        - Output: :math:`(N, out\\_features)`</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L20\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"20\"></td>\n          <td id=\"LC20\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\"></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L21\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"21\"></td>\n          <td id=\"LC21\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">    Attributes:</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L22\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"22\"></td>\n          <td id=\"LC22\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        weight: the learnable weights of the module of shape (out_features x in_features)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L23\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"23\"></td>\n          <td id=\"LC23\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        bias:   the learnable bias of the module of shape (out_features)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L24\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"24\"></td>\n          <td id=\"LC24\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\"></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L25\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"25\"></td>\n          <td id=\"LC25\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">    Examples::</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L26\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"26\"></td>\n          <td id=\"LC26\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\"></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L27\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"27\"></td>\n          <td id=\"LC27\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>m = nn.Linear(20, 30)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L28\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"28\"></td>\n          <td id=\"LC28\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(128, 20))</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L29\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"29\"></td>\n          <td id=\"LC29\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>output = m(input)</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L30\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"30\"></td>\n          <td id=\"LC30\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">        <span class=\"pl-k\">&gt;&gt;&gt; </span>print(output.size())</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L31\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"31\"></td>\n          <td id=\"LC31\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L32\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"32\"></td>\n          <td id=\"LC32\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L33\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"33\"></td>\n          <td id=\"LC33\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">in_features</span>, <span class=\"pl-smi\">out_features</span>, <span class=\"pl-smi\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L34\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"34\"></td>\n          <td id=\"LC34\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">super</span>(Linear, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>() </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L35\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"35\"></td>\n          <td id=\"LC35\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.in_features <span class=\"pl-k\">=</span> in_features </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L36\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"36\"></td>\n          <td id=\"LC36\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.out_features <span class=\"pl-k\">=</span> out_features </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L37\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"37\"></td>\n          <td id=\"LC37\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.weight <span class=\"pl-k\">=</span> Parameter(torch.Tensor(out_features, in_features)) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L38\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"38\"></td>\n          <td id=\"LC38\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> bias: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L39\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"39\"></td>\n          <td id=\"LC39\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">=</span> Parameter(torch.Tensor(out_features)) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L40\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"40\"></td>\n          <td id=\"LC40\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">else</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L41\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"41\"></td>\n          <td id=\"LC41\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c1\">self</span>.register_parameter(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>bias<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">None</span>) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L42\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"42\"></td>\n          <td id=\"LC42\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.reset_parameters() </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L43\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"43\"></td>\n          <td id=\"LC43\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L44\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"44\"></td>\n          <td id=\"LC44\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-en\">reset_parameters</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L45\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"45\"></td>\n          <td id=\"LC45\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         stdv <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> math.sqrt(<span class=\"pl-c1\">self</span>.weight.size(<span class=\"pl-c1\">1</span>)) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L46\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"46\"></td>\n          <td id=\"LC46\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-c1\">self</span>.weight.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L47\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"47\"></td>\n          <td id=\"LC47\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L48\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"48\"></td>\n          <td id=\"LC48\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c1\">self</span>.bias.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L49\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"49\"></td>\n          <td id=\"LC49\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L50\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"50\"></td>\n          <td id=\"LC50\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L51\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"51\"></td>\n          <td id=\"LC51\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L52\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"52\"></td>\n          <td id=\"LC52\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._backend.Linear()(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L53\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"53\"></td>\n          <td id=\"LC53\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">else</span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L54\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"54\"></td>\n          <td id=\"LC54\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._backend.Linear()(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight, <span class=\"pl-c1\">self</span>.bias) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L55\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"55\"></td>\n          <td id=\"LC55\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L56\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"56\"></td>\n          <td id=\"LC56\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__repr__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L57\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"57\"></td>\n          <td id=\"LC57\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.<span class=\"pl-c1\">__class__</span>.<span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span> (<span class=\"pl-pds\">'</span></span> \\ </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L58\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"58\"></td>\n          <td id=\"LC58\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">+</span> <span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.in_features) <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span> -&gt; <span class=\"pl-pds\">'</span></span> \\ </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L59\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"59\"></td>\n          <td id=\"LC59\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">+</span> <span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.out_features) <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>)<span class=\"pl-pds\">'</span></span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L60\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"60\"></td>\n          <td id=\"LC60\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</li>\n</ol>\n<p>Read the notes <a href=\"http://pytorch.org/docs/notes/extending.html\" rel=\"nofollow\">Extending Autograd</a> which would be helpful to understand the need for various functions such as <code>save_for_backward</code>.</p>\n<p>To test your implementation, you need to write unit tests such as here:<br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/test/test_nn.py#L2256-L2261\">https://github.com/pytorch/pytorch/blob/master/test/test_nn.py#L2256-L2261</a></p>\n<p>Initially, you probably want to just test it via the interpreter, comparing the output to the reference implementation in <code>torch.legacy.nn.BIlinear</code>.</p>\n<p>You will have more questions, and we shall resolve them via comments here or on slack.</p>\n<p>Lastly, look at the <a href=\"https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md#developing-locally-with-pytorch\">CONTRIBUTING</a> document for tips on locally developing pytorch.</p>", "body_text": "Adding context to the task for community members to pick it up. ( cc: @uridah )\nnn.Bilinear refers to this Lua-Torch layer\nIt computes a Bilinear transformation \\forall k: y_k = x_1 A_k x_2 + b.\nTo contrast this, a Linear transformation is \\forall k: y_k = A_k x_1 + b.\nThe source code for it is here and has been transpiled to legacy.nn of PyTorch here\nThis task is to implement nn.Bilinear under the nn package (not legacy.nn) which uses autograd.\nDoing the basic PyTorch tutorials might give you enough familiarity with autograd / neural networks.\nNow coming to the task. Take a look at how nn.Linear is implemented in PyTorch here:\n\ncore implementation in nn._functions\n\n  \n    \n      pytorch/torch/nn/_functions/linear.py\n    \n    \n        Lines 5 to 31\n      in\n      2b23712\n    \n    \n    \n    \n\n        \n          \n           class Linear(Function): \n        \n\n        \n          \n            \n        \n\n        \n          \n               def forward(self, input, weight, bias=None): \n        \n\n        \n          \n                   self.save_for_backward(input, weight, bias) \n        \n\n        \n          \n                   output = input.new(input.size(0), weight.size(0)) \n        \n\n        \n          \n                   output.addmm_(0, 1, input, weight.t()) \n        \n\n        \n          \n                   if bias is not None: \n        \n\n        \n          \n                       # cuBLAS doesn't support 0 strides in sger, so we can't use expand \n        \n\n        \n          \n                       self.add_buffer = input.new(1).resize_(input.size(0)).fill_(1) \n        \n\n        \n          \n                       output.addr_(self.add_buffer, bias) \n        \n\n        \n          \n                   return output \n        \n\n        \n          \n            \n        \n\n        \n          \n               def backward(self, grad_output): \n        \n\n        \n          \n                   input, weight, bias = self.saved_tensors \n        \n\n        \n          \n            \n        \n\n        \n          \n                   grad_input = grad_weight = grad_bias = None \n        \n\n        \n          \n                   if self.needs_input_grad[0]: \n        \n\n        \n          \n                       grad_input = torch.mm(grad_output, weight) \n        \n\n        \n          \n                   if self.needs_input_grad[1]: \n        \n\n        \n          \n                       grad_weight = torch.mm(grad_output.t(), input) \n        \n\n        \n          \n                   if bias is not None and self.needs_input_grad[2]: \n        \n\n        \n          \n                       grad_bias = torch.mv(grad_output.t(), self.add_buffer) \n        \n\n        \n          \n            \n        \n\n        \n          \n                   if bias is not None: \n        \n\n        \n          \n                       return grad_input, grad_weight, grad_bias \n        \n\n        \n          \n                   else: \n        \n\n        \n          \n                       return grad_input, grad_weight \n        \n    \n  \n\n\nthen, called in nn via creating an nn.Linear which is a subclass of nn.Module:\n\n  \n    \n      pytorch/torch/nn/modules/linear.py\n    \n    \n        Lines 9 to 60\n      in\n      2b23712\n    \n    \n    \n    \n\n        \n          \n           class Linear(Module): \n        \n\n        \n          \n               r\"\"\"Applies a linear transformation to the incoming data: :math:`y = Ax + b` \n        \n\n        \n          \n            \n        \n\n        \n          \n               Args: \n        \n\n        \n          \n                   in_features: size of each input sample \n        \n\n        \n          \n                   out_features: size of each output sample \n        \n\n        \n          \n                   bias: If set to False, the layer will not learn an additive bias. Default: True \n        \n\n        \n          \n            \n        \n\n        \n          \n               Shape: \n        \n\n        \n          \n                   - Input: :math:`(N, in\\_features)` \n        \n\n        \n          \n                   - Output: :math:`(N, out\\_features)` \n        \n\n        \n          \n            \n        \n\n        \n          \n               Attributes: \n        \n\n        \n          \n                   weight: the learnable weights of the module of shape (out_features x in_features) \n        \n\n        \n          \n                   bias:   the learnable bias of the module of shape (out_features) \n        \n\n        \n          \n            \n        \n\n        \n          \n               Examples:: \n        \n\n        \n          \n            \n        \n\n        \n          \n                   >>> m = nn.Linear(20, 30) \n        \n\n        \n          \n                   >>> input = autograd.Variable(torch.randn(128, 20)) \n        \n\n        \n          \n                   >>> output = m(input) \n        \n\n        \n          \n                   >>> print(output.size()) \n        \n\n        \n          \n               \"\"\" \n        \n\n        \n          \n            \n        \n\n        \n          \n               def __init__(self, in_features, out_features, bias=True): \n        \n\n        \n          \n                   super(Linear, self).__init__() \n        \n\n        \n          \n                   self.in_features = in_features \n        \n\n        \n          \n                   self.out_features = out_features \n        \n\n        \n          \n                   self.weight = Parameter(torch.Tensor(out_features, in_features)) \n        \n\n        \n          \n                   if bias: \n        \n\n        \n          \n                       self.bias = Parameter(torch.Tensor(out_features)) \n        \n\n        \n          \n                   else: \n        \n\n        \n          \n                       self.register_parameter('bias', None) \n        \n\n        \n          \n                   self.reset_parameters() \n        \n\n        \n          \n            \n        \n\n        \n          \n               def reset_parameters(self): \n        \n\n        \n          \n                   stdv = 1. / math.sqrt(self.weight.size(1)) \n        \n\n        \n          \n                   self.weight.data.uniform_(-stdv, stdv) \n        \n\n        \n          \n                   if self.bias is not None: \n        \n\n        \n          \n                       self.bias.data.uniform_(-stdv, stdv) \n        \n\n        \n          \n            \n        \n\n        \n          \n               def forward(self, input): \n        \n\n        \n          \n                   if self.bias is None: \n        \n\n        \n          \n                       return self._backend.Linear()(input, self.weight) \n        \n\n        \n          \n                   else: \n        \n\n        \n          \n                       return self._backend.Linear()(input, self.weight, self.bias) \n        \n\n        \n          \n            \n        \n\n        \n          \n               def __repr__(self): \n        \n\n        \n          \n                   return self.__class__.__name__ + ' (' \\ \n        \n\n        \n          \n                       + str(self.in_features) + ' -> ' \\ \n        \n\n        \n          \n                       + str(self.out_features) + ')' \n        \n\n        \n          \n            \n        \n    \n  \n\n\n\nRead the notes Extending Autograd which would be helpful to understand the need for various functions such as save_for_backward.\nTo test your implementation, you need to write unit tests such as here:\nhttps://github.com/pytorch/pytorch/blob/master/test/test_nn.py#L2256-L2261\nInitially, you probably want to just test it via the interpreter, comparing the output to the reference implementation in torch.legacy.nn.BIlinear.\nYou will have more questions, and we shall resolve them via comments here or on slack.\nLastly, look at the CONTRIBUTING document for tips on locally developing pytorch.", "body": "Adding context to the task for community members to pick it up. ( cc: @uridah )\r\n\r\nnn.Bilinear refers to [this Lua-Torch layer](https://github.com/torch/nn/blob/master/doc/simple.md#nn.Bilinear)\r\n\r\nIt computes a Bilinear transformation `\\forall k: y_k = x_1 A_k x_2 + b`.\r\n\r\nTo contrast this, a Linear transformation is `\\forall k: y_k = A_k x_1 + b`.\r\n\r\nThe source code for it is [here](https://github.com/torch/nn/blob/master/Bilinear.lua) and has been transpiled to `legacy.nn` of PyTorch [here](https://github.com/pytorch/pytorch/blob/79f5bf84e54d57a4c81912aeedb0b8a27f97c27e/torch/legacy/nn/Bilinear.py)\r\n\r\nThis task is to implement `nn.Bilinear` under the `nn` package (not `legacy.nn`) which uses autograd.\r\n\r\nDoing the basic PyTorch tutorials might give you enough familiarity with autograd / neural networks.\r\n\r\nNow coming to the task. Take a look at how `nn.Linear` is implemented in PyTorch here:\r\n\r\n1. core implementation in nn._functions\r\nhttps://github.com/pytorch/pytorch/blob/2b23712dc34ad281a1d9c7d5a829a83168503f93/torch/nn/_functions/linear.py#L5-L31\r\n2. then, called in nn via creating an `nn.Linear` which is a subclass of `nn.Module`:\r\nhttps://github.com/pytorch/pytorch/blob/2b23712dc34ad281a1d9c7d5a829a83168503f93/torch/nn/modules/linear.py#L9-L60\r\n\r\nRead the notes [Extending Autograd](http://pytorch.org/docs/notes/extending.html) which would be helpful to understand the need for various functions such as `save_for_backward`.\r\n\r\nTo test your implementation, you need to write unit tests such as here:\r\nhttps://github.com/pytorch/pytorch/blob/master/test/test_nn.py#L2256-L2261 \r\n\r\nInitially, you probably want to just test it via the interpreter, comparing the output to the reference implementation in `torch.legacy.nn.BIlinear`.\r\n\r\nYou will have more questions, and we shall resolve them via comments here or on slack.\r\n\r\nLastly, look at the [CONTRIBUTING](https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md#developing-locally-with-pytorch) document for tips on locally developing pytorch."}