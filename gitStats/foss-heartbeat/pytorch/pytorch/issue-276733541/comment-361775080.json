{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/361775080", "html_url": "https://github.com/pytorch/pytorch/issues/3867#issuecomment-361775080", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3867", "id": 361775080, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTc3NTA4MA==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T23:53:03Z", "updated_at": "2018-01-30T23:53:03Z", "author_association": "MEMBER", "body_html": "<p>So, a basic padding calculation strategy (which does <strong>not</strong> gives the same results as TensorFlow, but the shapes are similar) is to have</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">_get_padding</span>(<span class=\"pl-smi\">padding_type</span>, <span class=\"pl-smi\">kernel_size</span>):\n    <span class=\"pl-k\">assert</span> padding_type <span class=\"pl-k\">in</span> [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>VALID<span class=\"pl-pds\">'</span></span>]\n    <span class=\"pl-k\">if</span> padding_type <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>:\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">tuple</span>((k <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">//</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> kernel_size))\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">tuple</span>(<span class=\"pl-c1\">0</span> <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> kernel_size)</pre></div>\n<p>Is that what you have in mind @im9uri ?</p>", "body_text": "So, a basic padding calculation strategy (which does not gives the same results as TensorFlow, but the shapes are similar) is to have\ndef _get_padding(padding_type, kernel_size):\n    assert padding_type in ['SAME', 'VALID']\n    if padding_type == 'SAME':\n        return tuple((k - 1) // 2 for k in kernel_size))\n    return tuple(0 for _ in kernel_size)\nIs that what you have in mind @im9uri ?", "body": "So, a basic padding calculation strategy (which does **not** gives the same results as TensorFlow, but the shapes are similar) is to have\r\n```python\r\ndef _get_padding(padding_type, kernel_size):\r\n    assert padding_type in ['SAME', 'VALID']\r\n    if padding_type == 'SAME':\r\n        return tuple((k - 1) // 2 for k in kernel_size))\r\n    return tuple(0 for _ in kernel_size)\r\n```\r\n\r\nIs that what you have in mind @im9uri ?"}