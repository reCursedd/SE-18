{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407663012", "html_url": "https://github.com/pytorch/pytorch/issues/3867#issuecomment-407663012", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3867", "id": 407663012, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzY2MzAxMg==", "user": {"login": "kylemcdonald", "id": 157106, "node_id": "MDQ6VXNlcjE1NzEwNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/157106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kylemcdonald", "html_url": "https://github.com/kylemcdonald", "followers_url": "https://api.github.com/users/kylemcdonald/followers", "following_url": "https://api.github.com/users/kylemcdonald/following{/other_user}", "gists_url": "https://api.github.com/users/kylemcdonald/gists{/gist_id}", "starred_url": "https://api.github.com/users/kylemcdonald/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kylemcdonald/subscriptions", "organizations_url": "https://api.github.com/users/kylemcdonald/orgs", "repos_url": "https://api.github.com/users/kylemcdonald/repos", "events_url": "https://api.github.com/users/kylemcdonald/events{/privacy}", "received_events_url": "https://api.github.com/users/kylemcdonald/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-25T07:36:53Z", "updated_at": "2018-07-25T07:38:09Z", "author_association": "NONE", "body_html": "<p>Here is a very simple Conv2d layer with <code>same</code> padding for reference. It only support square kernels and stride=1, dilation=1, groups=1.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Conv2dSame</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">in_channels</span>, <span class=\"pl-smi\">out_channels</span>, <span class=\"pl-smi\">kernel_size</span>, <span class=\"pl-smi\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-smi\">padding_layer</span><span class=\"pl-k\">=</span>torch.nn.ReflectionPad2d):\n        <span class=\"pl-c1\">super</span>().<span class=\"pl-c1\">__init__</span>()\n        ka <span class=\"pl-k\">=</span> kernel_size <span class=\"pl-k\">//</span> <span class=\"pl-c1\">2</span>\n        kb <span class=\"pl-k\">=</span> ka <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span> <span class=\"pl-k\">if</span> kernel_size <span class=\"pl-k\">%</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">else</span> ka\n        <span class=\"pl-c1\">self</span>.net <span class=\"pl-k\">=</span> torch.nn.Sequential(\n            padding_layer((ka,kb,ka,kb)),\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span>bias)\n        )\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.net(x)\n    \nc <span class=\"pl-k\">=</span> Conv2dSame(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">5</span>)\n<span class=\"pl-c1\">print</span>(c(torch.rand((<span class=\"pl-c1\">16</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">10</span>))).shape)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> torch.Size([16, 3, 10, 10])</span></pre></div>", "body_text": "Here is a very simple Conv2d layer with same padding for reference. It only support square kernels and stride=1, dilation=1, groups=1.\nclass Conv2dSame(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias=True, padding_layer=torch.nn.ReflectionPad2d):\n        super().__init__()\n        ka = kernel_size // 2\n        kb = ka - 1 if kernel_size % 2 == 0 else ka\n        self.net = torch.nn.Sequential(\n            padding_layer((ka,kb,ka,kb)),\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias)\n        )\n    def forward(self, x):\n        return self.net(x)\n    \nc = Conv2dSame(1,3,5)\nprint(c(torch.rand((16,1,10,10))).shape)\n\n# torch.Size([16, 3, 10, 10])", "body": "Here is a very simple Conv2d layer with `same` padding for reference. It only support square kernels and stride=1, dilation=1, groups=1.\r\n\r\n```python\r\nclass Conv2dSame(torch.nn.Module):\r\n    def __init__(self, in_channels, out_channels, kernel_size, bias=True, padding_layer=torch.nn.ReflectionPad2d):\r\n        super().__init__()\r\n        ka = kernel_size // 2\r\n        kb = ka - 1 if kernel_size % 2 == 0 else ka\r\n        self.net = torch.nn.Sequential(\r\n            padding_layer((ka,kb,ka,kb)),\r\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias)\r\n        )\r\n    def forward(self, x):\r\n        return self.net(x)\r\n    \r\nc = Conv2dSame(1,3,5)\r\nprint(c(torch.rand((16,1,10,10))).shape)\r\n\r\n# torch.Size([16, 3, 10, 10])\r\n```\r\n"}