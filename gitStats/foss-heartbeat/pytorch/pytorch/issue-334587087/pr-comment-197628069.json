{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197628069", "pull_request_review_id": 131411388, "id": 197628069, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzYyODA2OQ==", "diff_hunk": "@@ -0,0 +1,154 @@\n+#pragma once\n+\n+#include <unordered_map>\n+\n+#include \"onnx/onnx_pb.h\"\n+#include \"onnx/onnxifi.h\"\n+\n+#include \"caffe2/core/context.h\"\n+#include \"caffe2/core/logging.h\"\n+#include \"caffe2/core/operator.h\"\n+#include \"caffe2/onnx/onnxifi_manager.h\"\n+\n+namespace caffe2 {\n+\n+template <typename T, typename Context>\n+class OnnxifiOp final : public Operator<Context> {\n+ public:\n+  USE_OPERATOR_CONTEXT_FUNCTIONS;\n+  OnnxifiOp(const OperatorDef& operator_def, Workspace* ws)\n+      : Operator<Context>(operator_def, ws) {\n+    onnxifi_backend_ =\n+        OperatorBase::GetSingleArgument<std::string>(\"onnxifi_backend\", \"\");\n+    location_ = OperatorBase::GetSingleArgument<std::string>(\n+        \"onnxifi_backend_path\", \"\");\n+    backend_idx_ =\n+        OperatorBase::GetSingleArgument<int>(\"onnxifi_backend_idx\", 0);\n+    auto suffix = OperatorBase::GetSingleArgument<std::string>(\n+        \"onnxifi_backend_suffix\", \"\");\n+    CAFFE_ENFORCE(!onnxifi_backend_.empty(), \"Unspecified onnxifi_backend\");\n+    CAFFE_ENFORCE(!location_.empty(), \"Unspecified onnxifi_backend_path\");\n+    auto* onnxifi_manager = onnx::OnnxifiManager::get_onnxifi_manager();\n+    lib_ = onnxifi_manager->AddOnnxifiLibrary(onnxifi_backend_, location_, suffix);\n+    auto onnx_model_str =\n+        OperatorBase::GetSingleArgument<std::string>(\"onnx_model\", \"\");\n+    CAFFE_ENFORCE(!onnx_model_str.empty(), \"onnx_model cannot be empty\");\n+\n+    // Setup input/output descriptor templates\n+    for (const auto& input : operator_def.input()) {\n+      input_desc_.push_back(onnxTensorDescriptor());\n+      input_desc_.back().name = input.c_str();\n+    }\n+    int output_idx = 0;\n+    for (const auto& output : operator_def.output()) {\n+      output_desc_.push_back(onnxTensorDescriptor());\n+      output_desc_.back().name = output.c_str();\n+\n+      // For output, we try to get its output size hint\n+      const std::string key = MakeString(\"output_size_hint_\", output_idx);\n+      auto output_size_hint = OperatorBase::GetRepeatedArgument<int>(key);\n+      if (!output_size_hint.empty()) {\n+        std::vector<TIndex> dims;\n+        for (const auto v : output_size_hint) {\n+          dims.push_back(v);\n+        }\n+        output_size_hints_.emplace(output_idx, std::move(dims));\n+      }\n+      ++output_idx;\n+    }\n+\n+    // TODO: Encode the rest of the arguments to backend\n+\n+    // Pull the weights from workspace and assembly it back to the onnx model,\n+    // notice that since we may have rewritten the net, we need to map the\n+    // weight names\n+    // TODO: this step can be avoided by initGraphIO\n+    auto initializers =\n+        OperatorBase::GetRepeatedArgument<std::string>(\"initializers\");\n+    CAFFE_ENFORCE_EQ(\n+        initializers.size() % 2, 0, \"initializers should come in pairs\");\n+    std::unordered_set<std::string> initializer_set;\n+    std::unordered_map<std::string, std::string> input_mapping;\n+    for (auto it = initializers.begin(); it != initializers.end(); ++it) {\n+      auto key = *it++;\n+      input_mapping.emplace(key, *it);\n+      initializer_set.emplace(key);\n+    }\n+    Workspace mapped_ws(ws, input_mapping);\n+    ::ONNX_NAMESPACE::ModelProto onnx_model;\n+    ParseProtoFromLargeString(onnx_model_str, &onnx_model);\n+    BuildInitializationList(\n+        &mapped_ws, onnx_model.mutable_graph(), &initializer_set);\n+    onnx_model_str.clear();\n+    onnx_model.SerializeToString(&onnx_model_str);\n+\n+    // Build the Onnxifi engine\n+    CAFFE_ENFORCE_EQ(\n+        lib_->onnxGetBackendIDs(&backend_id_, &num_backends_),\n+        ONNXIFI_STATUS_SUCCESS);\n+    CAFFE_ENFORCE_GT(num_backends_, backend_idx_);\n+    // TODO: feed encoded parameter list to backend\n+    CAFFE_ENFORCE_EQ(\n+        lib_->onnxInitBackend(backend_id_, NULL, &backend_),\n+        ONNXIFI_STATUS_SUCCESS);\n+    CAFFE_ENFORCE_EQ(\n+        lib_->onnxInitGraph(\n+            backend_,\n+            onnx_model_str.size(),\n+            (void*)(onnx_model_str.c_str()),\n+            0,\n+            NULL,\n+            &graph_),\n+        ONNXIFI_STATUS_SUCCESS);\n+  }\n+\n+  ~OnnxifiOp() {\n+    if (backend_id_ && !num_backends_) {\n+      CAFFE_ENFORCE_EQ(\n+          lib_->onnxReleaseBackendID(backend_id_), ONNXIFI_STATUS_SUCCESS);\n+    }\n+    if (graph_) {\n+      CAFFE_ENFORCE_EQ(lib_->onnxReleaseGraph(graph_), ONNXIFI_STATUS_SUCCESS);", "path": "caffe2/operators/onnxifi_op.h", "position": null, "original_position": 111, "commit_id": "d441bb622ebb16bcc309e6ffb07b51ed43f161ce", "original_commit_id": "3a10fd562ca087dd3e1f61cff4439eb5ef7a61a0", "user": {"login": "Maratyszcza", "id": 1093985, "node_id": "MDQ6VXNlcjEwOTM5ODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1093985?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Maratyszcza", "html_url": "https://github.com/Maratyszcza", "followers_url": "https://api.github.com/users/Maratyszcza/followers", "following_url": "https://api.github.com/users/Maratyszcza/following{/other_user}", "gists_url": "https://api.github.com/users/Maratyszcza/gists{/gist_id}", "starred_url": "https://api.github.com/users/Maratyszcza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Maratyszcza/subscriptions", "organizations_url": "https://api.github.com/users/Maratyszcza/orgs", "repos_url": "https://api.github.com/users/Maratyszcza/repos", "events_url": "https://api.github.com/users/Maratyszcza/events{/privacy}", "received_events_url": "https://api.github.com/users/Maratyszcza/received_events", "type": "User", "site_admin": false}, "body": "Would be good to set `graph_ = nullptr` after releasing it, just for safety. Same with `backend_` & `backend_id_`", "created_at": "2018-06-24T04:26:17Z", "updated_at": "2018-11-23T15:46:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/8749#discussion_r197628069", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8749", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197628069"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8749#discussion_r197628069"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8749"}}, "body_html": "<p>Would be good to set <code>graph_ = nullptr</code> after releasing it, just for safety. Same with <code>backend_</code> &amp; <code>backend_id_</code></p>", "body_text": "Would be good to set graph_ = nullptr after releasing it, just for safety. Same with backend_ & backend_id_"}