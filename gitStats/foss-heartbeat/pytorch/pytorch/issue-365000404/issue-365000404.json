{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12175", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12175/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12175/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12175/events", "html_url": "https://github.com/pytorch/pytorch/pull/12175", "id": 365000404, "node_id": "MDExOlB1bGxSZXF1ZXN0MjE5MDU0NDU2", "number": 12175, "title": "Smarter differentiable subgraph slicing", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-28T18:46:56Z", "updated_at": "2018-11-23T15:52:53Z", "closed_at": "2018-10-11T23:22:09Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/12175", "html_url": "https://github.com/pytorch/pytorch/pull/12175", "diff_url": "https://github.com/pytorch/pytorch/pull/12175.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/12175.patch"}, "body_html": "<h3>Motivation</h3>\n<p>If any inputs require_grad then the graph executor does differential subgraph slicing. The existing algorithm combines adjacent differentiable Node*.</p>\n<p>There are two major motivations. The first is improving fusion opportunities: the graph fusion pass runs after differential subgraph slicing. This means that only nodes that are a part of the same differential subgraph may be considered for fusion. If something like the following happens,</p>\n<pre><code>y = f(x)\nk = not_differentiable_op(m)\nz = g(y)\n</code></pre>\n<p>and f and g are both fusible and differentiable operations, then they will be inserted into different differential subgraphs and not fused together.</p>\n<p>The second is to enable JIT optimizations on backward passes for things like an (automatically) unrolled LSTM. Right now, in an unrolled LSTM, we see something like the following:</p>\n<pre><code>lstm_cell()\nnon_differentiable_list_op()\nlstm_cell()\nnon_differentiable_list_op()\nlstm_cell()\nnon_differentiable_list_op()\n</code></pre>\n<p>Each lstm_cell itself is differentiable and gets put into a separate differential subgraph. During the backwards pass, each prim::DifferentiableSubgraph has its own graph executor: these graph executors cannot talk to each other. It is better if we combined all of the lstm_cells (where applicable) into one differential subgraph so their backward passes are combined into one graph executor that can perform better optimizations than several separate graph executors.</p>\n<h3>Problem Statement</h3>\n<p>Think about the computation graph as a DAG where edges are data dependencies and vertices are operations (the nodes). Each vertex is either black or red; a vertex is colored black if it is differentiable and red otherwise. The goal is to contract edges (merge nodes) to have the fewest black vertices remaining such that the graph is still a DAG.</p>\n<h3>Implementation</h3>\n<p>The algorithm is the following:</p>\n<ul>\n<li>Take the Graph&amp; and create a shadow \"DynamicDAG\" object to wrap Node* and edges. Each Vertex holds multiple Node* (but starts out holding one Node*) and each edge is a data dependency.</li>\n<li>Greedily contract vertices in the DynamicDAG if they are \"differentiable\". This operation is unrelated to the Graph&amp;.\n<ul>\n<li>A Vertex is \"differentiable\" if all the nodes it holds is differentiable.</li>\n<li>When contracting vertices, combine their Node* contents.</li>\n<li>The DynamicDAG keeps its vertices in topological order and complains if the contraction is invalid so everything is good.</li>\n</ul>\n</li>\n<li>Take the DynamicDAG: reorder the nodes in the Graph&amp; to match the topological order in the DynamicDAG.</li>\n<li>Finally, go through each Vertex in the DynamicDAG: if it contains multiple Node* then merge all of them into a prim::DifferentiableGraph.</li>\n</ul>\n<p>The DynamicDAG is based off of the dynamic top sort algorithm in <a href=\"https://www.doc.ic.ac.uk/~phjk/Publications/DynamicTopoSortAlg-JEA-07.pdf\" rel=\"nofollow\">this paper</a> by Pearce and Kelly.</p>\n<h3>Analysis</h3>\n<p>Each contractEdge(producer, consumer) call is <code>O(|AR| log |AR| * min(|out_edges(producer)|, |in_edges(consumer)|)</code> where <code>AR</code> is the \"affected region\" (defined as the set of nodes that, in topological order, are between producer and consumer). By only considering contractions such that <code>|ord(producer) - ord(consumer)| &lt; threshold1</code> and <code>|out_edges(producer)| &lt; threshold2</code> we can make each contractEdge(producer, consumer) call take constant time. The resulting algorithm is linear in the number of nodes.</p>\n<h3>Test Plan</h3>\n<p>Added a lot of small test cases.</p>\n<p>Looking for suggestions on the following:</p>\n<ul>\n<li>what big computation graphs should I run this on to test how fast or slow it is?</li>\n<li>what things other than correctness should I be thinking about when I test this?</li>\n</ul>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a></p>", "body_text": "Motivation\nIf any inputs require_grad then the graph executor does differential subgraph slicing. The existing algorithm combines adjacent differentiable Node*.\nThere are two major motivations. The first is improving fusion opportunities: the graph fusion pass runs after differential subgraph slicing. This means that only nodes that are a part of the same differential subgraph may be considered for fusion. If something like the following happens,\ny = f(x)\nk = not_differentiable_op(m)\nz = g(y)\n\nand f and g are both fusible and differentiable operations, then they will be inserted into different differential subgraphs and not fused together.\nThe second is to enable JIT optimizations on backward passes for things like an (automatically) unrolled LSTM. Right now, in an unrolled LSTM, we see something like the following:\nlstm_cell()\nnon_differentiable_list_op()\nlstm_cell()\nnon_differentiable_list_op()\nlstm_cell()\nnon_differentiable_list_op()\n\nEach lstm_cell itself is differentiable and gets put into a separate differential subgraph. During the backwards pass, each prim::DifferentiableSubgraph has its own graph executor: these graph executors cannot talk to each other. It is better if we combined all of the lstm_cells (where applicable) into one differential subgraph so their backward passes are combined into one graph executor that can perform better optimizations than several separate graph executors.\nProblem Statement\nThink about the computation graph as a DAG where edges are data dependencies and vertices are operations (the nodes). Each vertex is either black or red; a vertex is colored black if it is differentiable and red otherwise. The goal is to contract edges (merge nodes) to have the fewest black vertices remaining such that the graph is still a DAG.\nImplementation\nThe algorithm is the following:\n\nTake the Graph& and create a shadow \"DynamicDAG\" object to wrap Node* and edges. Each Vertex holds multiple Node* (but starts out holding one Node*) and each edge is a data dependency.\nGreedily contract vertices in the DynamicDAG if they are \"differentiable\". This operation is unrelated to the Graph&.\n\nA Vertex is \"differentiable\" if all the nodes it holds is differentiable.\nWhen contracting vertices, combine their Node* contents.\nThe DynamicDAG keeps its vertices in topological order and complains if the contraction is invalid so everything is good.\n\n\nTake the DynamicDAG: reorder the nodes in the Graph& to match the topological order in the DynamicDAG.\nFinally, go through each Vertex in the DynamicDAG: if it contains multiple Node* then merge all of them into a prim::DifferentiableGraph.\n\nThe DynamicDAG is based off of the dynamic top sort algorithm in this paper by Pearce and Kelly.\nAnalysis\nEach contractEdge(producer, consumer) call is O(|AR| log |AR| * min(|out_edges(producer)|, |in_edges(consumer)|) where AR is the \"affected region\" (defined as the set of nodes that, in topological order, are between producer and consumer). By only considering contractions such that |ord(producer) - ord(consumer)| < threshold1 and |out_edges(producer)| < threshold2 we can make each contractEdge(producer, consumer) call take constant time. The resulting algorithm is linear in the number of nodes.\nTest Plan\nAdded a lot of small test cases.\nLooking for suggestions on the following:\n\nwhat big computation graphs should I run this on to test how fast or slow it is?\nwhat things other than correctness should I be thinking about when I test this?\n\ncc @apaszke @zdevito", "body": "### Motivation\r\n\r\nIf any inputs require_grad then the graph executor does differential subgraph slicing. The existing algorithm combines adjacent differentiable Node*.\r\n\r\nThere are two major motivations. The first is improving fusion opportunities: the graph fusion pass runs after differential subgraph slicing. This means that only nodes that are a part of the same differential subgraph may be considered for fusion. If something like the following happens,\r\n```\r\ny = f(x)\r\nk = not_differentiable_op(m)\r\nz = g(y)\r\n```\r\nand f and g are both fusible and differentiable operations, then they will be inserted into different differential subgraphs and not fused together.\r\n\r\nThe second is to enable JIT optimizations on backward passes for things like an (automatically) unrolled LSTM. Right now, in an unrolled LSTM, we see something like the following:\r\n```\r\nlstm_cell()\r\nnon_differentiable_list_op()\r\nlstm_cell()\r\nnon_differentiable_list_op()\r\nlstm_cell()\r\nnon_differentiable_list_op()\r\n```\r\nEach lstm_cell itself is differentiable and gets put into a separate differential subgraph. During the backwards pass, each prim::DifferentiableSubgraph has its own graph executor: these graph executors cannot talk to each other. It is better if we combined all of the lstm_cells (where applicable) into one differential subgraph so their backward passes are combined into one graph executor that can perform better optimizations than several separate graph executors.\r\n\r\n### Problem Statement\r\nThink about the computation graph as a DAG where edges are data dependencies and vertices are operations (the nodes). Each vertex is either black or red; a vertex is colored black if it is differentiable and red otherwise. The goal is to contract edges (merge nodes) to have the fewest black vertices remaining such that the graph is still a DAG.\r\n\r\n### Implementation\r\nThe algorithm is the following:\r\n- Take the Graph& and create a shadow \"DynamicDAG\" object to wrap Node* and edges. Each Vertex holds multiple Node* (but starts out holding one Node*) and each edge is a data dependency.\r\n- Greedily contract vertices in the DynamicDAG if they are \"differentiable\". This operation is unrelated to the Graph&.\r\n  - A Vertex is \"differentiable\" if all the nodes it holds is differentiable.\r\n  - When contracting vertices, combine their Node* contents.\r\n  - The DynamicDAG keeps its vertices in topological order and complains if the contraction is invalid so everything is good.\r\n- Take the DynamicDAG: reorder the nodes in the Graph& to match the topological order in the DynamicDAG.\r\n- Finally, go through each Vertex in the DynamicDAG: if it contains multiple Node* then merge all of them into a prim::DifferentiableGraph.\r\n\r\nThe DynamicDAG is based off of the dynamic top sort algorithm in [this paper](https://www.doc.ic.ac.uk/~phjk/Publications/DynamicTopoSortAlg-JEA-07.pdf) by Pearce and Kelly.\r\n\r\n### Analysis\r\nEach contractEdge(producer, consumer) call is `O(|AR| log |AR| * min(|out_edges(producer)|, |in_edges(consumer)|)` where `AR` is the \"affected region\" (defined as the set of nodes that, in topological order, are between producer and consumer). By only considering contractions such that `|ord(producer) - ord(consumer)| < threshold1` and `|out_edges(producer)| < threshold2` we can make each contractEdge(producer, consumer) call take constant time. The resulting algorithm is linear in the number of nodes.\r\n\r\n### Test Plan\r\nAdded a lot of small test cases.\r\n\r\nLooking for suggestions on the following:\r\n- what big computation graphs should I run this on to test how fast or slow it is?\r\n- what things other than correctness should I be thinking about when I test this?\r\n\r\ncc @apaszke @zdevito \r\n"}