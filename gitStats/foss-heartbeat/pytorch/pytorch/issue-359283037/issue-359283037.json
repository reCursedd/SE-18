{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11559", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11559/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11559/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11559/events", "html_url": "https://github.com/pytorch/pytorch/issues/11559", "id": 359283037, "node_id": "MDU6SXNzdWUzNTkyODMwMzc=", "number": 11559, "title": "TensorOptions should not read default options at construction/factory time (the ones_like()/to() problem)", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-12T01:37:30Z", "updated_at": "2018-09-12T03:11:57Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>Consider the following PyTorch code:</p>\n<pre><code>y = torch.ones_like(x, dtype=torch.float64)\n</code></pre>\n<p>If x is a CUDA float tensor, what do you expect y to be? I'd expect a CUDA double tensor.</p>\n<p>OK, how about this C++?</p>\n<pre><code>auto y = at::ones_like(x, at::dtype(at::kDouble));\n</code></pre>\n<p>Seems like a nearly line-by-line translation, right? WRONG. By default, the C++ code produces a <strong>CPU</strong> double tensor. This is because <code>at::dtype()</code> constructs a default <code>TensorOptions</code> using the nullary constructor, which consults the TensorOptions TLS to determine what the default, e.g., device should be. Which is CPU by default. So you the above C++ code is effectively equivalent to:</p>\n<pre><code>auto y = at::ones_like(x, at::device(at::kCPU).dtype(at::kDouble));\n</code></pre>\n<p>which obviously gives you a CPU tensor.</p>\n<p>Here's how we should fix it:</p>\n<ol>\n<li>Make all fields of <code>TensorOptions</code> optional.</li>\n<li>The default constructor of <code>TensorOptions</code> leaves all fields <code>nullopt</code>.</li>\n<li>A getter for a field in <code>TensorOptions</code> for a nullopt field consults the default TLS to determine what value to provide. We also add opt accessors which return, e.g., <code>at::optional&lt;Device&gt;</code>. (Alternate plan: introduce another type, <code>TensorType</code>, which is what <code>TensorOptions</code> is today; e.g., all fields are non-optional). (Variation on the plan: the TLS accessors live out-of-line of TensorOptions, since TLS is not supported in the mobile build.)</li>\n<li>Replace the three overloads of <code>to(ScalarType)</code> and <code>to(Backend, ScalarType)</code> with <code>to(TensorOptions)</code></li>\n<li>Methods for which reasonable defaults exists (e.g., <code>ones_like</code> and <code>to</code>) don't use TLS ever; instead, they default to the local default that makes sense (e.g., the tensor to make ones \"like\", or the tensor you're converting from).</li>\n</ol>", "body_text": "Consider the following PyTorch code:\ny = torch.ones_like(x, dtype=torch.float64)\n\nIf x is a CUDA float tensor, what do you expect y to be? I'd expect a CUDA double tensor.\nOK, how about this C++?\nauto y = at::ones_like(x, at::dtype(at::kDouble));\n\nSeems like a nearly line-by-line translation, right? WRONG. By default, the C++ code produces a CPU double tensor. This is because at::dtype() constructs a default TensorOptions using the nullary constructor, which consults the TensorOptions TLS to determine what the default, e.g., device should be. Which is CPU by default. So you the above C++ code is effectively equivalent to:\nauto y = at::ones_like(x, at::device(at::kCPU).dtype(at::kDouble));\n\nwhich obviously gives you a CPU tensor.\nHere's how we should fix it:\n\nMake all fields of TensorOptions optional.\nThe default constructor of TensorOptions leaves all fields nullopt.\nA getter for a field in TensorOptions for a nullopt field consults the default TLS to determine what value to provide. We also add opt accessors which return, e.g., at::optional<Device>. (Alternate plan: introduce another type, TensorType, which is what TensorOptions is today; e.g., all fields are non-optional). (Variation on the plan: the TLS accessors live out-of-line of TensorOptions, since TLS is not supported in the mobile build.)\nReplace the three overloads of to(ScalarType) and to(Backend, ScalarType) with to(TensorOptions)\nMethods for which reasonable defaults exists (e.g., ones_like and to) don't use TLS ever; instead, they default to the local default that makes sense (e.g., the tensor to make ones \"like\", or the tensor you're converting from).", "body": "Consider the following PyTorch code:\r\n\r\n```\r\ny = torch.ones_like(x, dtype=torch.float64)\r\n```\r\n\r\nIf x is a CUDA float tensor, what do you expect y to be? I'd expect a CUDA double tensor.\r\n\r\nOK, how about this C++?\r\n\r\n```\r\nauto y = at::ones_like(x, at::dtype(at::kDouble));\r\n```\r\n\r\nSeems like a nearly line-by-line translation, right? WRONG. By default, the C++ code produces a **CPU** double tensor. This is because `at::dtype()` constructs a default `TensorOptions` using the nullary constructor, which consults the TensorOptions TLS to determine what the default, e.g., device should be. Which is CPU by default. So you the above C++ code is effectively equivalent to:\r\n\r\n```\r\nauto y = at::ones_like(x, at::device(at::kCPU).dtype(at::kDouble));\r\n```\r\n\r\nwhich obviously gives you a CPU tensor.\r\n\r\nHere's how we should fix it:\r\n\r\n1. Make all fields of `TensorOptions` optional.\r\n2. The default constructor of `TensorOptions` leaves all fields `nullopt`.\r\n3. A getter for a field in `TensorOptions` for a nullopt field consults the default TLS to determine what value to provide. We also add opt accessors which return, e.g., `at::optional<Device>`. (Alternate plan: introduce another type, `TensorType`, which is what `TensorOptions` is today; e.g., all fields are non-optional). (Variation on the plan: the TLS accessors live out-of-line of TensorOptions, since TLS is not supported in the mobile build.)\r\n4. Replace the three overloads of `to(ScalarType)` and `to(Backend, ScalarType)` with `to(TensorOptions)`\r\n5. Methods for which reasonable defaults exists (e.g., `ones_like` and `to`) don't use TLS ever; instead, they default to the local default that makes sense (e.g., the tensor to make ones \"like\", or the tensor you're converting from)."}