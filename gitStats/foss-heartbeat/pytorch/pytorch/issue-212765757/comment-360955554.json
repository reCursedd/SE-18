{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/360955554", "html_url": "https://github.com/pytorch/pytorch/issues/958#issuecomment-360955554", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/958", "id": 360955554, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDk1NTU1NA==", "user": {"login": "TommeyChang", "id": 15918318, "node_id": "MDQ6VXNlcjE1OTE4MzE4", "avatar_url": "https://avatars0.githubusercontent.com/u/15918318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TommeyChang", "html_url": "https://github.com/TommeyChang", "followers_url": "https://api.github.com/users/TommeyChang/followers", "following_url": "https://api.github.com/users/TommeyChang/following{/other_user}", "gists_url": "https://api.github.com/users/TommeyChang/gists{/gist_id}", "starred_url": "https://api.github.com/users/TommeyChang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TommeyChang/subscriptions", "organizations_url": "https://api.github.com/users/TommeyChang/orgs", "repos_url": "https://api.github.com/users/TommeyChang/repos", "events_url": "https://api.github.com/users/TommeyChang/events{/privacy}", "received_events_url": "https://api.github.com/users/TommeyChang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-27T03:11:49Z", "updated_at": "2018-01-27T06:12:45Z", "author_association": "NONE", "body_html": "<p>In the example, two models will be generated for training and validation respectively. With this setting, there will be another model run in the GPU when validation, and the GPU will be out of memory even you wrap the validation data with volatile parameter.<br>\nI solve this problem by just set only one model, and wrap the validation data with volatile parameter to reduce the calculation. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12710772\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tabibusairam\">@tabibusairam</a></p>", "body_text": "In the example, two models will be generated for training and validation respectively. With this setting, there will be another model run in the GPU when validation, and the GPU will be out of memory even you wrap the validation data with volatile parameter.\nI solve this problem by just set only one model, and wrap the validation data with volatile parameter to reduce the calculation. @tabibusairam", "body": "In the example, two models will be generated for training and validation respectively. With this setting, there will be another model run in the GPU when validation, and the GPU will be out of memory even you wrap the validation data with volatile parameter.\r\nI solve this problem by just set only one model, and wrap the validation data with volatile parameter to reduce the calculation. @tabibusairam "}