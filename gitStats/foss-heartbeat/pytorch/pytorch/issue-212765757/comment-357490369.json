{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/357490369", "html_url": "https://github.com/pytorch/pytorch/issues/958#issuecomment-357490369", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/958", "id": 357490369, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzQ5MDM2OQ==", "user": {"login": "zcrwind", "id": 25099380, "node_id": "MDQ6VXNlcjI1MDk5Mzgw", "avatar_url": "https://avatars1.githubusercontent.com/u/25099380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zcrwind", "html_url": "https://github.com/zcrwind", "followers_url": "https://api.github.com/users/zcrwind/followers", "following_url": "https://api.github.com/users/zcrwind/following{/other_user}", "gists_url": "https://api.github.com/users/zcrwind/gists{/gist_id}", "starred_url": "https://api.github.com/users/zcrwind/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zcrwind/subscriptions", "organizations_url": "https://api.github.com/users/zcrwind/orgs", "repos_url": "https://api.github.com/users/zcrwind/repos", "events_url": "https://api.github.com/users/zcrwind/events{/privacy}", "received_events_url": "https://api.github.com/users/zcrwind/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-14T05:47:14Z", "updated_at": "2018-01-14T05:49:13Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12710772\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tabibusairam\">@tabibusairam</a> I also encountered the same issue: the training process worked fine (with 6G cuda memory and my GPU has 12G memory) but the evaluating process which goes through the same network got a error information as follows:</p>\n<pre><code>THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\nTraceback (most recent call last):\n  File \"evaluate.py\", line 132, in &lt;module&gt;\n    evaluate(pnet, args)\n  File \"evaluate.py\", line 94, in evaluate\n    predictions = pnet(X_test, initial_states)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 224, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 497, in forward\n    output, hidden_states = self.step(A0, hidden_states)\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 377, in step\n    forget_gate = hard_sigmoid(self.conv_layers['f'][lay](inputs))\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 28, in hard_sigmoid\n    x = F.threshold(-x, 0, 0)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/functional.py\", line 459, in threshold\n    return _functions.thnn.Threshold.apply(input, threshold, value, inplace)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 174, in forward\n    getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu:66\n</code></pre>\n<p>Have you worked out? Thanks.</p>", "body_text": "@tabibusairam I also encountered the same issue: the training process worked fine (with 6G cuda memory and my GPU has 12G memory) but the evaluating process which goes through the same network got a error information as follows:\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\nTraceback (most recent call last):\n  File \"evaluate.py\", line 132, in <module>\n    evaluate(pnet, args)\n  File \"evaluate.py\", line 94, in evaluate\n    predictions = pnet(X_test, initial_states)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 224, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 497, in forward\n    output, hidden_states = self.step(A0, hidden_states)\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 377, in step\n    forget_gate = hard_sigmoid(self.conv_layers['f'][lay](inputs))\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 28, in hard_sigmoid\n    x = F.threshold(-x, 0, 0)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/functional.py\", line 459, in threshold\n    return _functions.thnn.Threshold.apply(input, threshold, value, inplace)\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 174, in forward\n    getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu:66\n\nHave you worked out? Thanks.", "body": "@tabibusairam I also encountered the same issue: the training process worked fine (with 6G cuda memory and my GPU has 12G memory) but the evaluating process which goes through the same network got a error information as follows:\r\n```\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\r\nTraceback (most recent call last):\r\n  File \"evaluate.py\", line 132, in <module>\r\n    evaluate(pnet, args)\r\n  File \"evaluate.py\", line 94, in evaluate\r\n    predictions = pnet(X_test, initial_states)\r\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 224, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 497, in forward\r\n    output, hidden_states = self.step(A0, hidden_states)\r\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 377, in step\r\n    forget_gate = hard_sigmoid(self.conv_layers['f'][lay](inputs))\r\n  File \"/home/zcrwind/workspace/pro/predict/zcr/pnet.py\", line 28, in hard_sigmoid\r\n    x = F.threshold(-x, 0, 0)\r\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/functional.py\", line 459, in threshold\r\n    return _functions.thnn.Threshold.apply(input, threshold, value, inplace)\r\n  File \"/home/zcrwind/.conda/envs/condapython3.6/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 174, in forward\r\n    getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, output, *args)\r\nRuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THC/generic/THCStorage.cu:66\r\n```\r\nHave you worked out? Thanks."}