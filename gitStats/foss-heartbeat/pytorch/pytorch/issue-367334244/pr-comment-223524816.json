{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223524816", "pull_request_review_id": 162671382, "id": 223524816, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMzUyNDgxNg==", "diff_hunk": "@@ -4,547 +4,85 @@ import \"caffe2/proto/caffe2.proto\";\n \n package torch;\n \n-// Overview\n-//\n-// ONNX is an open specification that is comprised of the following components:\n-//\n-// 1)  A definition of an extensible computation graph model.\n-// 2)  Definitions of standard data types.\n-// 3)  Definitions of built-in operators.\n-//\n-// This document describes the syntax of models and their computation graphs,\n-// as well as the standard data types. Together, they are referred to as the ONNX\n-// Intermediate Representation, or 'IR' for short.\n-//\n-// The normative semantic specification of the ONNX IR is found in docs/IR.md.\n-// Definitions of the built-in neural network operators may be found in docs/Operators.md.\n-\n-// Notes\n-//\n-// Release\n-//\n-// We are still in the very early stage of defining ONNX. The current\n-// version of ONNX is a starting point. While we are actively working\n-// towards a complete spec, we would like to get the community involved\n-// by sharing our working version of ONNX.\n-//\n-// Protobuf compatibility\n-//\n-// To simplify framework compatibility, ONNX is defined using the subset of\n-// protobuf that is compatible with both protobuf v2 and v3. This means that we\n-// do not use any protobuf features that are only available in one of the two\n-// versions.\n-//\n-// Here are the most notable contortions we have to carry out to work around\n-// these limitations:\n-//\n-//   - No 'map' (added protobuf 3.0). We instead represent mappings as lists\n-//     of key-value pairs, where order does not matter and duplicates\n-//     are not allowed.\n-\n-// Versioning\n-//\n-// ONNX versioning is specified in docs/IR.md and elaborated on in docs/Versioning.md\n-//\n-// To be compatible with both proto2 and proto3, we will use a version number\n-// that is not defined by the default value but an explicit enum number.\n-enum Version {\n-  // proto3 requires the first enum value to be zero.\n-  // We add this just to appease the compiler.\n+enum ProtoVersion {\n   _START_VERSION = 0;\n-  // The version field is always serialized and we will use it to store the\n-  // version that the  graph is generated from. This helps us set up version\n-  // control.\n-  // For the IR, we are using simple numbers starting with with 0x00000001,\n-  // which was the version we published on Oct 10, 2017.\n-  IR_VERSION_2017_10_10 = 0x0000000000000001;\n-\n-  // IR_VERSION 2 published on Oct 30, 2017\n-  // - Added type discriminator to AttributeProto to support proto3 users\n-  IR_VERSION_2017_10_30 = 0x0000000000000002;\n-\n-  // IR VERSION 3 published on Nov 3, 2017\n-  // - For operator versioning:\n-  //    - Added new message OperatorSetIdProto\n-  //    - Added opset_import in ModelProto\n-  // - For vendor extensions, added domain in NodeProto\n-  IR_VERSION_NEWEST_ONNX = 0x0000000000000003;\n-\n-  // PYTORCH IR VERSION\n-  IR_VERSION_NEWEST = 0x0000000000000103;\n+  IR_VERSION_NEWEST = 0x0000000000000101;\n }\n \n-// Attributes\n-//\n-// A named attribute containing either singular float, integer, string, graph,\n-// and tensor values, or repeated float, integer, string, graph, and tensor values.\n-// An AttributeProto MUST contain the name field, and *only one* of the\n-// following content fields, effectively enforcing a C/C++ union equivalent.\n-message AttributeProto {\n-\n-  // Note: this enum is structurally identical to the OpSchema::AttrType\n-  // enum defined in schema.h.  If you rev one, you likely need to rev the other.\n-  enum AttributeType {\n-    UNDEFINED = 0;\n-    FLOAT = 1;\n-    INT = 2;\n-    STRING = 3;\n-    TENSOR = 4;\n-    GRAPH = 5;\n-\n-    FLOATS = 6;\n-    INTS = 7;\n-    STRINGS = 8;\n-    TENSORS = 9;\n-    GRAPHS = 10;\n+message MethodDef {\n+  // method name\n+  optional string name = 1; // method name\n+\n+  // static graph\n+  optional caffe2.NetDef graph = 2;\n+  // method is represented as torch script\n+  optional string torch_script = 3;\n+\n+  // the names of inputs and outputs\n+  repeated string inputs = 4;\n+  repeated string outputs = 5;\n+\n+  // method type, can be one of the following:\n+  //   1) MAIN, the main method, by default is `forward` method\n+  //   2) INIT, only run once for initialization\n+  //   3) REGULAR, may run multiple times at runtime\n+  enum MethodType {\n+    MAIN = 1;\n+    INIT = 2;\n+    REGULAR = 3;\n   }\n \n-  // The name field MUST be present for this version of the IR.\n-  optional string name = 1;           // namespace Attribute\n-\n-  // if ref_attr_name is not empty, ref_attr_name is the attribute name in parent function.\n-  // In this case, this AttributeProto does not contain data, and it's a reference of attribute\n-  // in parent scope.\n-  // NOTE: This should ONLY be used in function (sub-graph). It's invalid to be used in main graph.\n-  optional string ref_attr_name = 21;\n-\n-  // A human-readable documentation for this attribute. Markdown is allowed.\n-  optional string doc_string = 13;\n+  optional MethodType method_type = 6;\n \n-  // The type field MUST be present for this version of the IR.\n-  // For 0.0.1 versions of the IR, this field was not defined, and\n-  // implementations needed to use has_field hueristics to determine\n-  // which value field was in use.  For IR_VERSION 0.0.2 or later, this\n-  // field MUST be set and match the f|i|s|t|... field in use.  This\n-  // change was made to accomodate proto3 implementations.\n-  optional AttributeType type = 20;   // discriminator that indicates which field below is in use\n+  optional string debug_info = 7;\n \n-  // Exactly ONE of the following fields must be present for this version of the IR\n-  optional float f = 2;               // float\n-  optional int64 i = 3;               // int\n-  optional bytes s = 4;               // UTF-8 string\n-  optional TensorProto t = 5;         // tensor value\n-  optional GraphProto g = 6;          // graph\n-  // Do not use field below, it's deprecated.\n-  // optional ValueProto v = 12;         // value - subsumes everything but graph\n-\n-  repeated float floats = 7;          // list of floats\n-  repeated int64 ints = 8;            // list of ints\n-  repeated bytes strings = 9;         // list of UTF-8 strings\n-  repeated TensorProto tensors = 10;  // list of tensors\n-  repeated GraphProto graphs = 11;    // list of graph\n-}\n-\n-// Defines information on value, including the name, the type, and\n-// the shape of the value.\n-message ValueInfoProto {\n-  // This field MUST be present in this version of the IR.\n-  optional string name = 1;     // namespace Value\n-  // This field MUST be present in this version of the IR.\n-  optional TypeProto type = 2;\n-  // A human-readable documentation for this value. Markdown is allowed.\n-  optional string doc_string = 3;\n+  repeated caffe2.Argument annotations = 8;\n }\n \n-// Nodes\n-//\n-// Computation graphs are made up of a DAG of nodes, which represent what is\n-// commonly called a \"layer\" or \"pipeline stage\" in machine learning frameworks.\n-//\n-// For example, it can be a node of type \"Conv\" that takes in an image, a filter\n-// tensor and a bias tensor, and produces the convolved output.\n-message NodeProto {\n-  repeated string input = 1;    // namespace Value\n-  repeated string output = 2;   // namespace Value\n \n-  // An optional identifier for this node in a graph.\n-  // This field MAY be absent in ths version of the IR.\n-  optional string name = 3;     // namespace Node\n+message ModuleDef {\n+  repeated ModuleDef submodules = 1;\n \n-  // The symbolic identifier of the Operator to execute.\n-  optional string op_type = 4;  // namespace Operator\n-  // The domain of the OperatorSet that specifies the operator named by op_type.\n-  optional string domain = 7;   // namespace Domain\n+  // We suppose to store the modules in one of the following format:\n+  //   - methods (static graph or torch script)\n+  //   - pickle\n+  //   - cpp_arena\n+  repeated MethodDef methods = 2;\n+  // because the old pickle modules may not be supported by torch_script,\n+  // have to stored as pickle_arena at this moment.\n+  optional bytes pickle_arena = 3;\n+  // should be exposed by the Class Archive, so user can save\n+  // module specific data which cannot be store in the graph or torch_script\n+  optional bytes cpp_arena = 4;\n \n-  // Additional named attributes.\n-  repeated AttributeProto attribute = 5;\n+  // the names of inputs and outputs of the module are inferred\n+  // from the main method.\n \n-  // A human-readable documentation for this node. Markdown is allowed.\n-  // Equivalent to string debug_info\n-  optional string doc_string = 6;\n+  optional string debug_info = 5;\n \n-  // Additional annotations, attributes are defined in Schema\n-  // To be added as annotations:\n-  //    string engine\n-  //    string list control_input\n-  //    int64 is_gradient_op\n-  repeated AttributeProto annotations = 8;\n-\n-  // Besides the node type, PyTorhc also serialize ATen function signature\n-  optional caffe2.DeviceOption device_option = 51;\n-  optional string aten_function = 52;\n+  repeated caffe2.Argument annotations = 6;\n }\n \n-// Models\n-//\n-// ModelProto is a top-level file/container format for bundling a ML model and\n-// associating its computation graph with metadata.\n-//\n-// The semantics of the model are described by the associated GraphProto.\n-//\n-// Model ==> Caffe2 MetaNetDef\n-//       ==> PyTorch Module\n-message ModelProto {\n-  // The version of the IR this model targets. See Version enum above.\n-  // This field MUST be present.\n+message ModelDef {\n   optional int64 ir_version = 1;\n \n-  // The OperatorSets this model relies on.\n-  // All ModelProtos MUST have at least one entry that\n-  // specifies which version of the ONNX OperatorSet is\n-  // being imported.\n-  //\n-  // All nodes in the ModelProto's graph will bind against the operator\n-  // with the same-domain/same-op_type operator with the HIGHEST version\n-  // in the referenced operator sets.\n-  repeated OperatorSetIdProto opset_import = 8;\n-\n-  // The name of the framework or tool used to generate this model.\n-  // This field SHOULD be present to indicate which implementation/tool/framework\n-  // emitted the model.\n-  optional string producer_name = 2;\n-\n-  // The version of the framework or tool used to generate this model.\n-  // This field SHOULD be present to indicate which implementation/tool/framework\n-  // emitted the model.\n-  optional string producer_version = 3;\n-\n-  // Domain name of the model.\n-  // We use reverse domain names as name space indicators. For example:\n-  // `com.facebook.fair` or `com.microsoft.cognitiveservices`\n-  //\n-  // Together with `model_version` and GraphProto.name, this forms the unique identity of\n-  // the graph.\n-  optional string domain = 4;\n-\n-  // The version of the graph encoded. See Version enum below.\n-  optional int64 model_version = 5;\n-\n-  // A human-readable documentation for this model. Markdown is allowed.\n-  optional string doc_string = 6;\n-\n-  // The parameterized graph that is evaluated to execute the model.\n-  // The main graph, in single graph case, it is ONNX compatible.\n-  optional GraphProto graph = 7;\n-\n-  // The remaining nets in MetaNetDef.\n-  // Submodules and methods in PyTorch.\n-  repeated GraphProto methods = 15;\n-\n-  // Named metadata values; keys should be distinct.\n-  // Many meta data in MetaNetDef and preditor are piggy backed here.\n-  // 1) project\n-  // 2) model_class\n-  // 3) internal_version\n-  // 4) predictor_type\n-  // 5) predictor_id\n-  // 6) execute_plan\n-  // 7) applicationSpecificInfo (another string map, need to verify it has no duplicate.)\n-  // 8) engine\n-  // 9) publish time\n-  repeated StringStringEntryProto metadata_props = 14;\n-\n-  // Model name\n-  optional string name = 16;\n-\n-  // Model name\n-  repeated AttributeProto annotations = 17;\n-\n-  // Mapping from list name to blob name list, must be string list type.\n-  // Equivalent to blobs in MetaNetDef.\n-  repeated AttributeProto blob_lists = 51;\n-\n-  // Mapping from plan name to serialized plan, must be string list type.\n-  // Equivalent to plans in MetaNetDef.\n-  repeated AttributeProto plans = 52;\n-};\n-\n-// StringStringEntryProto follows the pattern for cross-proto-version maps.\n-// See https://developers.google.com/protocol-buffers/docs/proto3#maps\n-message StringStringEntryProto {\n-  optional string key = 1;\n-  optional string value= 2;\n-};\n-\n-// Graphs\n-//\n-// A graph defines the computational logic of a model and is comprised of a parameterized\n-// list of nodes that form a directed acyclic graph based on their inputs and outputs.\n-// This is the equivalent of the \"network\" or \"graph\" in many deep learning\n-// frameworks.\n-// Graph ==> NetDef in Caffe2\n-//       ==> Submodule/Method in PyTorch\n-message GraphProto {\n-  // The nodes in the graph, sorted topologically.\n-  repeated NodeProto node = 1;\n-\n-  // The name of the graph.\n-  optional string name = 2;   // namespace Graph\n-\n-  // A list of named tensor values, used to specify constant inputs of the graph.\n-  // Each TensorProto entry must have a distinct name (within the list) that\n-  // also appears in the input list.\n-  repeated TensorProto initializer = 5;\n-\n-  // A human-readable documentation for this graph. Markdown is allowed.\n-  optional string doc_string = 10;\n-\n-  // The inputs and outputs of the graph.\n-  repeated ValueInfoProto input = 11;\n-  repeated ValueInfoProto output = 12;\n-\n-  // Information for the values in the graph. The ValueInfoProto.name's\n-  // must be distinct. It is optional for a value to appear in value_info list.\n-  repeated ValueInfoProto value_info = 13;\n-\n-  // Additional annotations.\n-  repeated AttributeProto annotations = 14;\n-\n-  // DO NOT USE the following fields, they were deprecated from earlier versions.\n-  // repeated string input = 3;\n-  // repeated string output = 4;\n-  // optional int64 ir_version = 6;\n-  // optional int64 producer_version = 7;\n-  // optional string producer_tag = 8;\n-  // optional string domain = 9;\n-}\n-\n-// Tensors\n-//\n-// A serialized tensor value.\n-message TensorProto {\n-  enum DataType {\n-    UNDEFINED = 0;\n-    // Basic types.\n-    FLOAT = 1;   // float\n-    UINT8 = 2;   // uint8_t\n-    INT8 = 3;    // int8_t\n-    UINT16 = 4;  // uint16_t\n-    INT16 = 5;   // int16_t\n-    INT32 = 6;   // int32_t\n-    INT64 = 7;   // int64_t\n-    STRING = 8;  // string\n-    BOOL = 9;    // bool\n-\n-    // Advanced types\n-    FLOAT16 = 10;\n-    DOUBLE = 11;\n-    UINT32 = 12;\n-    UINT64 = 13;\n-    COMPLEX64 = 14;     // complex with float32 real and imaginary components\n-    COMPLEX128 = 15;    // complex with float64 real and imaginary components\n-    // Future extensions go here.\n-\n-    // Special data type, real type information is stored in ValueInfoProto.\n-    // If data_type is SPECIAL, raw_data should be used.\n-    SPECIAL = 51;\n-  }\n-\n-  // The shape of the tensor.\n-  repeated int64 dims = 1;\n-  repeated int64 strides = 14;\n-\n-  // The data type of the tensor.\n-  optional DataType data_type = 2;\n-\n-  // For very large tensors, we may want to store them in chunks, in which\n-  // case the following fields will specify the segment that is stored in\n-  // the current TensorProto.\n-  message Segment {\n-    optional int64 begin = 1;\n-    optional int64 end = 2;\n-    optional int64 chuck_num = 51;\n-    optional int64 chuck_id = 52;\n-  }\n-  // Used as offset in the external shared data.\n-  optional Segment segment = 3;\n-\n-  // Tensor content must be organized in row-major order.\n-  //\n-  // Depending on the data_type field, exactly one of the fields below with\n-  // name ending in _data is used to store the elements of the tensor.\n-\n-  // For float and complex64 values\n-  // Complex64 tensors are encoded as a single array of floats,\n-  // with the real components appearing in odd numbered positions,\n-  // and the corresponding imaginary component apparing in the\n-  // subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]\n-  // is encoded as [1.0, 2.0 ,3.0 ,4.0]\n-  // When this field is present, the data_type field MUST be FLOAT or COMPLEX64.\n-  repeated float float_data = 4 [packed = true];\n-\n-  // For int32, uint8, int8, uint16, int16, bool, and Half values\n-  // float16 values must be bit-wise converted to an uint16_t prior\n-  // to writing to the buffer.\n-  // When this field is present, the data_type field MUST be\n-  // INT32, INT16, INT8, UINT16, INT8, BOOL, or FLOAT16\n-  repeated int32 int32_data = 5 [packed = true];\n-\n-  // For strings.\n-  // Each element of string_data is a UTF-8 encoded Unicode\n-  // string. No trailing null, no leading BOM. The protobuf \"string\"\n-  // scalar type is not used to match ML community conventions.\n-  // When this field is present, the data_type field MUST be STRING\n-  repeated bytes string_data = 6;\n-\n-  // For int64.\n-  // When this field is present, the data_type field MUST be INT64\n-  repeated int64 int64_data = 7 [packed = true];\n-\n-  // Optionally, a name for the tensor.\n-  optional string name = 8; // namespace Value\n-\n-  // A human-readable documentation for this tensor. Markdown is allowed.\n-  optional string doc_string = 12;\n-\n-  // Serializations can either use one of the fields above, or use this\n-  // raw bytes field. The only exception is the string case, where one is\n-  // required to store the content in the repeated bytes string_data field.\n-  //\n-  // When this raw_data field is used to store tensor value, elements MUST\n-  // be stored in as fixed-width, little-endian order.\n-  // Floating-point data types MUST be stored in IEEE 754 format.\n-  // Complex64 elements must be written as two consecutive FLOAT values, real component first.\n-  // Complex128 elements must be written as two consecutive DOUBLE values, real component first.\n-  // Boolean type MUST be written one byte per tensor element (00000001 for true, 00000000 for false).\n-  //\n-  // Note: the advantage of specific field rather than the raw_data field is\n-  // that in some cases (e.g. int data), protobuf does a better packing via\n-  // variable length storage, and may lead to smaller binary footprint.\n-  // When this field is present, the data_type field MUST NOT be STRING or UNDEFINED\n-  optional bytes raw_data = 9;\n-\n-  // For double\n-  // Complex64 tensors are encoded as a single array of doubles,\n-  // with the real components appearing in odd numbered positions,\n-  // and the corresponding imaginary component apparing in the\n-  // subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]\n-  // is encoded as [1.0, 2.0 ,3.0 ,4.0]\n-  // When this field is present, the data_type field MUST be DOUBLE or COMPLEX128\n-  repeated double double_data = 10 [packed = true];\n-\n-  // For uint64 and uint32 values\n-  // When this field is present, the data_type field MUST be\n-  // UINT32 or UINT64\n-  repeated uint64 uint64_data = 11 [packed = true];\n+  // main module of the model\n+  optional ModuleDef main_module = 2;\n \n-  // External data by file name\n-  optional string external_data = 13;\n+  repeated caffe2.TensorProto parameters = 3;\n+  repeated caffe2.TensorProto value_infos = 4;", "path": "caffe2/proto/torch.proto", "position": null, "original_position": 487, "commit_id": "af60ce1589b2921a069f7c301ab6bec2886fba79", "original_commit_id": "838babc6328000dfa8cfdbcecf65cbb9062886e7", "user": {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}, "body": "These are the type information values inside the models. For PyTorch model, right now, this field is probably not useful. But later, when IR is stable enough, and we decide to export static graph, we probably want to use this field to store the type and shape information about the non-input/output values.", "created_at": "2018-10-08T23:32:24Z", "updated_at": "2018-11-23T15:52:38Z", "html_url": "https://github.com/pytorch/pytorch/pull/12384#discussion_r223524816", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12384", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/223524816"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12384#discussion_r223524816"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12384"}}, "body_html": "<p>These are the type information values inside the models. For PyTorch model, right now, this field is probably not useful. But later, when IR is stable enough, and we decide to export static graph, we probably want to use this field to store the type and shape information about the non-input/output values.</p>", "body_text": "These are the type information values inside the models. For PyTorch model, right now, this field is probably not useful. But later, when IR is stable enough, and we decide to export static graph, we probably want to use this field to store the type and shape information about the non-input/output values.", "in_reply_to_id": 223516929}