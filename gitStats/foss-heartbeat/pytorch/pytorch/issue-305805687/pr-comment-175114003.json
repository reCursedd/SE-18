{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175114003", "pull_request_review_id": 104595315, "id": 175114003, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTExNDAwMw==", "diff_hunk": "@@ -790,37 +801,34 @@ def forward(self, x):\n         model_DDP = copy.deepcopy(model)\n         model_DDP.cuda(gpu_subset[0])\n         model_DDP = nn.parallel.DistributedDataParallel(model_DDP, device_ids=gpu_subset)\n-        optimizer = optim.SGD(model_DDP.parameters(), lr=1e-2)\n-        optimizer.zero_grad()\n \n         # batch_size for DDP should be divisible by #GPU per node.\n         batch_size = len(gpu_subset) * int(WORLD_SIZE)\n         input_cpu = torch.randn(batch_size, 2)\n         target = torch.randn(batch_size, 4)\n         loss = nn.MSELoss()\n \n-        # single gpu training\n-        self._test_DDP_helper(model_gpu,\n-                              input_cpu.cuda(gpu_subset[0]),\n-                              target.cuda(gpu_subset[0]),\n-                              loss)\n-\n-        # DDP training, DDP scatters subsets of input_cpu to nodes/GPUs\n-        self._test_DDP_helper(model_DDP,\n-                              input_cpu[rank * len(gpu_subset):(rank + 1) * len(gpu_subset)],\n-                              target[rank * len(gpu_subset):(rank + 1) * len(gpu_subset)].cuda(gpu_subset[0]),\n-                              loss)\n-\n-        for layer_gpu, layer_DDP in zip(model_gpu.modules(), model_DDP.module.modules()):\n-            if isinstance(layer_gpu, nn.Linear):\n-                self.assertEqual(layer_gpu.weight.grad, layer_DDP.weight.grad)\n-\n-        # Run SGD and second iteration to shake out errors\n-        optimizer.step()\n-        self._test_DDP_helper(model_DDP,\n-                              input_cpu,\n-                              target.cuda(gpu_subset[0]),\n-                              loss)\n+        for i in range(2):\n+            # single gpu training\n+            self._test_DDP_helper(model_gpu,\n+                                  input_cpu.cuda(gpu_subset[0]),\n+                                  target.cuda(gpu_subset[0]),\n+                                  loss)\n+\n+            # DDP training, DDP scatters subsets of input_cpu to nodes/GPUs\n+            self._test_DDP_helper(model_DDP,\n+                                  input_cpu[rank * len(gpu_subset):(rank + 1) * len(gpu_subset)],\n+                                  target[rank * len(gpu_subset):(rank + 1) * len(gpu_subset)].cuda(gpu_subset[0]),\n+                                  loss)\n+\n+            # Update weights and run a second iteration to shake out errors\n+            model_step(model_gpu)\n+            model_step(model_DDP.module)", "path": "test/test_distributed.py", "position": null, "original_position": 68, "commit_id": "ab3832af65779a69071fde292d2360179da83f86", "original_commit_id": "ba1bb1f94813633d9da894d540f49c83ef853a8e", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "The change above would also just let you pass `model_DDP` here without taking `.module`", "created_at": "2018-03-16T14:50:43Z", "updated_at": "2018-11-23T15:40:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/5830#discussion_r175114003", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5830", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175114003"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5830#discussion_r175114003"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5830"}}, "body_html": "<p>The change above would also just let you pass <code>model_DDP</code> here without taking <code>.module</code></p>", "body_text": "The change above would also just let you pass model_DDP here without taking .module"}