{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5301", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5301/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5301/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5301/events", "html_url": "https://github.com/pytorch/pytorch/issues/5301", "id": 298364258, "node_id": "MDU6SXNzdWUyOTgzNjQyNTg=", "number": 5301, "title": "Runtime Error with DataLoader: exited unexpectedly", "user": {"login": "mxlei01", "id": 7399324, "node_id": "MDQ6VXNlcjczOTkzMjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/7399324?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mxlei01", "html_url": "https://github.com/mxlei01", "followers_url": "https://api.github.com/users/mxlei01/followers", "following_url": "https://api.github.com/users/mxlei01/following{/other_user}", "gists_url": "https://api.github.com/users/mxlei01/gists{/gist_id}", "starred_url": "https://api.github.com/users/mxlei01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mxlei01/subscriptions", "organizations_url": "https://api.github.com/users/mxlei01/orgs", "repos_url": "https://api.github.com/users/mxlei01/repos", "events_url": "https://api.github.com/users/mxlei01/events{/privacy}", "received_events_url": "https://api.github.com/users/mxlei01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-02-19T18:15:25Z", "updated_at": "2018-11-14T11:58:53Z", "closed_at": "2018-02-21T23:04:27Z", "author_association": "NONE", "body_html": "<p>Hi All,</p>\n<p>I have a DataLoader that loads a line from a file with Numpy, then convert it to a torch Tensor, and whenever I run this with more than 1 workers, it gives me an error:</p>\n<p><code>RuntimeError: DataLoader worker (pid 30141) exited unexpectedly with exit code 1.</code></p>\n<p>However, whenever I run it with 0 workers, it works.</p>\n<p>Is there some sort of logs that shows why the worker exited unexpectedly?</p>\n<p>Still have around 10gb of gpu memory, and gpu utilization of 0% when this happens.</p>\n<p>But If I use CPU only, then this I can have multiple workers successfully.</p>\n<p>Here's what I do:</p>\n<pre><code>def get_line(filename, index):\n    with open(filename, \"rb\") as f:\n        for count, line in enumerate(f):\n            if count == index:\n                return line\n    \ndef count_line(filename):\n    with open(filename, \"rb\") as f:\n        size = 0\n        for count, _ in enumerate(f):\n            size = count\n        return size\n\nclass LineDatasetDnn(Dataset):\n    def __init__(self, features_filename, labels_filename):\n        self.features_filename = features_filename\n        self.labels_filename = labels_filename\n        self.lines = count_line(self.features_filename)\n    \n    def __getitem__(self, idx):\n        feature_line = get_line(self.features_filename, idx)\n        feature = torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).cuda().float() if torch.cuda.is_available() else torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).float()\n        \n        label_line = get_line(self.labels_filename, idx)\n        label = torch.Tensor(np.fromstring(label_line, dtype=float, sep=' ')) if torch.cuda.is_available() else torch.FloatTensor(np.fromstring(label_line, dtype=float, sep=' '))\n\n        return feature, label\n        \n    def __len__(self):\n        return self.lines\n\ndef get_concat_dataset_dnn(data_type):\n    files = sorted(os.listdir(f\"./ds_data/txt/dnn/{data_type}/input\"))\n    datasets = [LineDatasetDnn(f\"./ds_data/txt/dnn/{data_type}/input/{file}\",\n                               f\"./ds_data/txt/dnn/{data_type}/output/{file}\")\n                for file in files]\n    return data.ConcatDataset(datasets)\n\nfor feature, label in data.DataLoader(get_concat_dataset_dnn(\"train\"),\n                                              batch_size=dnn_minibatch_size, shuffle=True, collate_fn=transform_variable_dnn,\n                                              num_workers=2, pin_memory=pin_memory):\n</code></pre>", "body_text": "Hi All,\nI have a DataLoader that loads a line from a file with Numpy, then convert it to a torch Tensor, and whenever I run this with more than 1 workers, it gives me an error:\nRuntimeError: DataLoader worker (pid 30141) exited unexpectedly with exit code 1.\nHowever, whenever I run it with 0 workers, it works.\nIs there some sort of logs that shows why the worker exited unexpectedly?\nStill have around 10gb of gpu memory, and gpu utilization of 0% when this happens.\nBut If I use CPU only, then this I can have multiple workers successfully.\nHere's what I do:\ndef get_line(filename, index):\n    with open(filename, \"rb\") as f:\n        for count, line in enumerate(f):\n            if count == index:\n                return line\n    \ndef count_line(filename):\n    with open(filename, \"rb\") as f:\n        size = 0\n        for count, _ in enumerate(f):\n            size = count\n        return size\n\nclass LineDatasetDnn(Dataset):\n    def __init__(self, features_filename, labels_filename):\n        self.features_filename = features_filename\n        self.labels_filename = labels_filename\n        self.lines = count_line(self.features_filename)\n    \n    def __getitem__(self, idx):\n        feature_line = get_line(self.features_filename, idx)\n        feature = torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).cuda().float() if torch.cuda.is_available() else torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).float()\n        \n        label_line = get_line(self.labels_filename, idx)\n        label = torch.Tensor(np.fromstring(label_line, dtype=float, sep=' ')) if torch.cuda.is_available() else torch.FloatTensor(np.fromstring(label_line, dtype=float, sep=' '))\n\n        return feature, label\n        \n    def __len__(self):\n        return self.lines\n\ndef get_concat_dataset_dnn(data_type):\n    files = sorted(os.listdir(f\"./ds_data/txt/dnn/{data_type}/input\"))\n    datasets = [LineDatasetDnn(f\"./ds_data/txt/dnn/{data_type}/input/{file}\",\n                               f\"./ds_data/txt/dnn/{data_type}/output/{file}\")\n                for file in files]\n    return data.ConcatDataset(datasets)\n\nfor feature, label in data.DataLoader(get_concat_dataset_dnn(\"train\"),\n                                              batch_size=dnn_minibatch_size, shuffle=True, collate_fn=transform_variable_dnn,\n                                              num_workers=2, pin_memory=pin_memory):", "body": "Hi All,\r\n\r\nI have a DataLoader that loads a line from a file with Numpy, then convert it to a torch Tensor, and whenever I run this with more than 1 workers, it gives me an error:\r\n\r\n`RuntimeError: DataLoader worker (pid 30141) exited unexpectedly with exit code 1.`\r\n\r\nHowever, whenever I run it with 0 workers, it works.\r\n\r\nIs there some sort of logs that shows why the worker exited unexpectedly?\r\n\r\nStill have around 10gb of gpu memory, and gpu utilization of 0% when this happens.\r\n\r\nBut If I use CPU only, then this I can have multiple workers successfully.\r\n\r\nHere's what I do:\r\n\r\n```\r\ndef get_line(filename, index):\r\n    with open(filename, \"rb\") as f:\r\n        for count, line in enumerate(f):\r\n            if count == index:\r\n                return line\r\n    \r\ndef count_line(filename):\r\n    with open(filename, \"rb\") as f:\r\n        size = 0\r\n        for count, _ in enumerate(f):\r\n            size = count\r\n        return size\r\n\r\nclass LineDatasetDnn(Dataset):\r\n    def __init__(self, features_filename, labels_filename):\r\n        self.features_filename = features_filename\r\n        self.labels_filename = labels_filename\r\n        self.lines = count_line(self.features_filename)\r\n    \r\n    def __getitem__(self, idx):\r\n        feature_line = get_line(self.features_filename, idx)\r\n        feature = torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).cuda().float() if torch.cuda.is_available() else torch.from_numpy(np.fromstring(feature_line, dtype=float, sep=' ')).float()\r\n        \r\n        label_line = get_line(self.labels_filename, idx)\r\n        label = torch.Tensor(np.fromstring(label_line, dtype=float, sep=' ')) if torch.cuda.is_available() else torch.FloatTensor(np.fromstring(label_line, dtype=float, sep=' '))\r\n\r\n        return feature, label\r\n        \r\n    def __len__(self):\r\n        return self.lines\r\n\r\ndef get_concat_dataset_dnn(data_type):\r\n    files = sorted(os.listdir(f\"./ds_data/txt/dnn/{data_type}/input\"))\r\n    datasets = [LineDatasetDnn(f\"./ds_data/txt/dnn/{data_type}/input/{file}\",\r\n                               f\"./ds_data/txt/dnn/{data_type}/output/{file}\")\r\n                for file in files]\r\n    return data.ConcatDataset(datasets)\r\n\r\nfor feature, label in data.DataLoader(get_concat_dataset_dnn(\"train\"),\r\n                                              batch_size=dnn_minibatch_size, shuffle=True, collate_fn=transform_variable_dnn,\r\n                                              num_workers=2, pin_memory=pin_memory):\r\n```\r\n"}