{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2718", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2718/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2718/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2718/events", "html_url": "https://github.com/pytorch/pytorch/issues/2718", "id": 257353078, "node_id": "MDU6SXNzdWUyNTczNTMwNzg=", "number": 2718, "title": "Python crash during backward", "user": {"login": "EtienneDesticourt", "id": 8978248, "node_id": "MDQ6VXNlcjg5NzgyNDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/8978248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EtienneDesticourt", "html_url": "https://github.com/EtienneDesticourt", "followers_url": "https://api.github.com/users/EtienneDesticourt/followers", "following_url": "https://api.github.com/users/EtienneDesticourt/following{/other_user}", "gists_url": "https://api.github.com/users/EtienneDesticourt/gists{/gist_id}", "starred_url": "https://api.github.com/users/EtienneDesticourt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EtienneDesticourt/subscriptions", "organizations_url": "https://api.github.com/users/EtienneDesticourt/orgs", "repos_url": "https://api.github.com/users/EtienneDesticourt/repos", "events_url": "https://api.github.com/users/EtienneDesticourt/events{/privacy}", "received_events_url": "https://api.github.com/users/EtienneDesticourt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-09-13T11:53:44Z", "updated_at": "2017-10-25T06:27:39Z", "closed_at": "2017-09-17T14:37:21Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I'm running the windows version (torch==0.2.1 +a4fc05a) so if you're not interested in its issues, and if it has no bearing on the other versions, feel free to disregard this issue.</p>\n<p>I was trying to build an adversarial autoencoder with multiple discriminators and python crashes in the middle of writing a Traceback when I call backward with this architecture. It also starts consuming huge amounts of memory and the cpu goes full throttle. I think it might have to do with the way I slice some variables.</p>\n<p>It might be related to issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"223308953\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1318\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1318/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1318\">#1318</a>, I don't know enough about the backend to be sure so I'm opening this new issue.</p>\n<p>Here's a minimal example to reproduce the issue:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c1\">NUM_CLASSES</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">4</span>\n<span class=\"pl-c1\">BATCH_SIZE</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">256</span>\n<span class=\"pl-c1\">ENCODER_INPUT_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">200</span>\n<span class=\"pl-c1\">LATENT_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n<span class=\"pl-c1\">OUTPUT_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n<span class=\"pl-c1\">HIDDEN_DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">512</span>\n<span class=\"pl-c1\">EPSILON</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1e-8</span>\n\nencoder <span class=\"pl-k\">=</span> nn.Sequential(\n    nn.Linear(<span class=\"pl-c1\">ENCODER_INPUT_DIM</span>, <span class=\"pl-c1\">HIDDEN_DIM</span>),\n    nn.Linear(<span class=\"pl-c1\">HIDDEN_DIM</span>, <span class=\"pl-c1\">HIDDEN_DIM</span>),\n    nn.Linear(<span class=\"pl-c1\">HIDDEN_DIM</span>, <span class=\"pl-c1\">LATENT_DIM</span>)).cuda()\n\nenc_loss <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: <span class=\"pl-k\">-</span>torch.mean(torch.log(x <span class=\"pl-k\">+</span> <span class=\"pl-c1\">EPSILON</span>))\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> We create one discriminator per label</span>\ndiscriminators <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">NUM_CLASSES</span>):\n    discriminator <span class=\"pl-k\">=</span> nn.Sequential(\n        nn.Linear(<span class=\"pl-c1\">LATENT_DIM</span>, <span class=\"pl-c1\">HIDDEN_DIM</span>),\n        nn.Linear(<span class=\"pl-c1\">HIDDEN_DIM</span>, <span class=\"pl-c1\">HIDDEN_DIM</span>),\n        nn.Linear(<span class=\"pl-c1\">HIDDEN_DIM</span>, <span class=\"pl-c1\">OUTPUT_DIM</span>)).cuda()\n    discriminators.append(discriminator)\n\ndisc_loss <span class=\"pl-k\">=</span> <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">real</span>, <span class=\"pl-smi\">fake</span>: <span class=\"pl-k\">-</span>torch.mean(torch.log(real <span class=\"pl-k\">+</span> <span class=\"pl-c1\">EPSILON</span>) <span class=\"pl-k\">+</span> torch.log(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> fake <span class=\"pl-k\">+</span> <span class=\"pl-c1\">EPSILON</span>))\n\nbatch_x <span class=\"pl-k\">=</span> Variable(torch.randn((<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">ENCODER_INPUT_DIM</span>))).cuda()\nbatch_y <span class=\"pl-k\">=</span> Variable(torch.from_numpy(np.random.randint(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">NUM_CLASSES</span>, (<span class=\"pl-c1\">BATCH_SIZE</span>,)))).cuda()\n\ngenerated_latent <span class=\"pl-k\">=</span> encoder(batch_x)\nprior_latent <span class=\"pl-k\">=</span> Variable(torch.randn((<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">LATENT_DIM</span>))).cuda()\n<span class=\"pl-k\">for</span> i, disc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(discriminators):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> For each discriminator we get the batch data that matches the discriminator's label</span>\n    indices <span class=\"pl-k\">=</span> (batch_y<span class=\"pl-k\">==</span>i).data.nonzero()[:, <span class=\"pl-c1\">0</span>].cuda()\n    generated <span class=\"pl-k\">=</span> generated_latent[indices, :]\n    prior <span class=\"pl-k\">=</span> prior_latent[indices, :]\n    \n    fake <span class=\"pl-k\">=</span> disc(generated)\n    real <span class=\"pl-k\">=</span> disc(prior)\n    loss <span class=\"pl-k\">=</span> disc_loss(real, fake)\n    loss.backward() <span class=\"pl-c\"><span class=\"pl-c\">#</span> CRASHES HERE ON SECOND ITERATION</span>\n    <span class=\"pl-c1\">print</span>(i)\n</pre></div>\n<p>If we replace:<br>\n<code>generated_latent = encoder(batch_x)</code><br>\nwith<br>\n<code>generated_latent = Variable(encoder(batch_x).data)</code><br>\nThe problem no longer appears, so I'm thinking it has trouble backpropagating the sliced variables through the encoder.</p>", "body_text": "Hi,\nI'm running the windows version (torch==0.2.1 +a4fc05a) so if you're not interested in its issues, and if it has no bearing on the other versions, feel free to disregard this issue.\nI was trying to build an adversarial autoencoder with multiple discriminators and python crashes in the middle of writing a Traceback when I call backward with this architecture. It also starts consuming huge amounts of memory and the cpu goes full throttle. I think it might have to do with the way I slice some variables.\nIt might be related to issue #1318, I don't know enough about the backend to be sure so I'm opening this new issue.\nHere's a minimal example to reproduce the issue:\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\n\nNUM_CLASSES = 4\nBATCH_SIZE = 256\nENCODER_INPUT_DIM = 200\nLATENT_DIM = 2\nOUTPUT_DIM = 1\nHIDDEN_DIM = 512\nEPSILON = 1e-8\n\nencoder = nn.Sequential(\n    nn.Linear(ENCODER_INPUT_DIM, HIDDEN_DIM),\n    nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n    nn.Linear(HIDDEN_DIM, LATENT_DIM)).cuda()\n\nenc_loss = lambda x: -torch.mean(torch.log(x + EPSILON))\n\n# We create one discriminator per label\ndiscriminators = []\nfor i in range(NUM_CLASSES):\n    discriminator = nn.Sequential(\n        nn.Linear(LATENT_DIM, HIDDEN_DIM),\n        nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n        nn.Linear(HIDDEN_DIM, OUTPUT_DIM)).cuda()\n    discriminators.append(discriminator)\n\ndisc_loss = lambda real, fake: -torch.mean(torch.log(real + EPSILON) + torch.log(1 - fake + EPSILON))\n\nbatch_x = Variable(torch.randn((BATCH_SIZE, ENCODER_INPUT_DIM))).cuda()\nbatch_y = Variable(torch.from_numpy(np.random.randint(0, NUM_CLASSES, (BATCH_SIZE,)))).cuda()\n\ngenerated_latent = encoder(batch_x)\nprior_latent = Variable(torch.randn((BATCH_SIZE, LATENT_DIM))).cuda()\nfor i, disc in enumerate(discriminators):\n    # For each discriminator we get the batch data that matches the discriminator's label\n    indices = (batch_y==i).data.nonzero()[:, 0].cuda()\n    generated = generated_latent[indices, :]\n    prior = prior_latent[indices, :]\n    \n    fake = disc(generated)\n    real = disc(prior)\n    loss = disc_loss(real, fake)\n    loss.backward() # CRASHES HERE ON SECOND ITERATION\n    print(i)\n\nIf we replace:\ngenerated_latent = encoder(batch_x)\nwith\ngenerated_latent = Variable(encoder(batch_x).data)\nThe problem no longer appears, so I'm thinking it has trouble backpropagating the sliced variables through the encoder.", "body": "Hi,\r\n\r\nI'm running the windows version (torch==0.2.1 +a4fc05a) so if you're not interested in its issues, and if it has no bearing on the other versions, feel free to disregard this issue.\r\n\r\nI was trying to build an adversarial autoencoder with multiple discriminators and python crashes in the middle of writing a Traceback when I call backward with this architecture. It also starts consuming huge amounts of memory and the cpu goes full throttle. I think it might have to do with the way I slice some variables.\r\n\r\nIt might be related to issue #1318, I don't know enough about the backend to be sure so I'm opening this new issue.\r\n\r\nHere's a minimal example to reproduce the issue:\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport numpy as np\r\n\r\nNUM_CLASSES = 4\r\nBATCH_SIZE = 256\r\nENCODER_INPUT_DIM = 200\r\nLATENT_DIM = 2\r\nOUTPUT_DIM = 1\r\nHIDDEN_DIM = 512\r\nEPSILON = 1e-8\r\n\r\nencoder = nn.Sequential(\r\n    nn.Linear(ENCODER_INPUT_DIM, HIDDEN_DIM),\r\n    nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\r\n    nn.Linear(HIDDEN_DIM, LATENT_DIM)).cuda()\r\n\r\nenc_loss = lambda x: -torch.mean(torch.log(x + EPSILON))\r\n\r\n# We create one discriminator per label\r\ndiscriminators = []\r\nfor i in range(NUM_CLASSES):\r\n    discriminator = nn.Sequential(\r\n        nn.Linear(LATENT_DIM, HIDDEN_DIM),\r\n        nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\r\n        nn.Linear(HIDDEN_DIM, OUTPUT_DIM)).cuda()\r\n    discriminators.append(discriminator)\r\n\r\ndisc_loss = lambda real, fake: -torch.mean(torch.log(real + EPSILON) + torch.log(1 - fake + EPSILON))\r\n\r\nbatch_x = Variable(torch.randn((BATCH_SIZE, ENCODER_INPUT_DIM))).cuda()\r\nbatch_y = Variable(torch.from_numpy(np.random.randint(0, NUM_CLASSES, (BATCH_SIZE,)))).cuda()\r\n\r\ngenerated_latent = encoder(batch_x)\r\nprior_latent = Variable(torch.randn((BATCH_SIZE, LATENT_DIM))).cuda()\r\nfor i, disc in enumerate(discriminators):\r\n    # For each discriminator we get the batch data that matches the discriminator's label\r\n    indices = (batch_y==i).data.nonzero()[:, 0].cuda()\r\n    generated = generated_latent[indices, :]\r\n    prior = prior_latent[indices, :]\r\n    \r\n    fake = disc(generated)\r\n    real = disc(prior)\r\n    loss = disc_loss(real, fake)\r\n    loss.backward() # CRASHES HERE ON SECOND ITERATION\r\n    print(i)\r\n\r\n```\r\n\r\nIf we replace:\r\n`generated_latent = encoder(batch_x)`\r\nwith\r\n`generated_latent = Variable(encoder(batch_x).data)`\r\nThe problem no longer appears, so I'm thinking it has trouble backpropagating the sliced variables through the encoder.\r\n\r\n"}