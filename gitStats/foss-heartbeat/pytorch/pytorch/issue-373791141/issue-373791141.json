{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13112", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13112/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13112/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13112/events", "html_url": "https://github.com/pytorch/pytorch/issues/13112", "id": 373791141, "node_id": "MDU6SXNzdWUzNzM3OTExNDE=", "number": 13112, "title": "why grad is disappear when put data to cuda?", "user": {"login": "ericyan71", "id": 22901866, "node_id": "MDQ6VXNlcjIyOTAxODY2", "avatar_url": "https://avatars0.githubusercontent.com/u/22901866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericyan71", "html_url": "https://github.com/ericyan71", "followers_url": "https://api.github.com/users/ericyan71/followers", "following_url": "https://api.github.com/users/ericyan71/following{/other_user}", "gists_url": "https://api.github.com/users/ericyan71/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericyan71/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericyan71/subscriptions", "organizations_url": "https://api.github.com/users/ericyan71/orgs", "repos_url": "https://api.github.com/users/ericyan71/repos", "events_url": "https://api.github.com/users/ericyan71/events{/privacy}", "received_events_url": "https://api.github.com/users/ericyan71/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-25T06:23:06Z", "updated_at": "2018-10-25T09:12:40Z", "closed_at": "2018-10-25T09:12:40Z", "author_association": "NONE", "body_html": "<p>hello, I write a simple small test to test grad, I found a strange behavor, in test1, I use Tensor in cpu, then I can get grad, but if I put them to gpu, the grad is gone, here is my test code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\ndevice <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">test1</span>():\n    a <span class=\"pl-k\">=</span> torch.tensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    b <span class=\"pl-k\">=</span> a<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>\n    c <span class=\"pl-k\">=</span> torch.mean(b)\n    c.backward()\n    <span class=\"pl-c1\">print</span>(a.grad)</pre></div>\n<p><code>the result is: tensor([0.6667, 1.3333, 2.0000])</code></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">test2</span>():\n    a <span class=\"pl-k\">=</span> torch.tensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>).to(device)\n    b <span class=\"pl-k\">=</span> a<span class=\"pl-k\">**</span><span class=\"pl-c1\">2</span>\n    c <span class=\"pl-k\">=</span> torch.mean(b)\n    c.backward()\n    <span class=\"pl-c1\">print</span>(a.grad)</pre></div>\n<p><code>the result is : None</code></p>\n<p>I don't understand why they are different, thanks.</p>", "body_text": "hello, I write a simple small test to test grad, I found a strange behavor, in test1, I use Tensor in cpu, then I can get grad, but if I put them to gpu, the grad is gone, here is my test code:\nimport torch\ndevice = torch.device('cuda')\n    \ndef test1():\n    a = torch.tensor([1,2,3], dtype=torch.float32, requires_grad=True)\n    b = a**2\n    c = torch.mean(b)\n    c.backward()\n    print(a.grad)\nthe result is: tensor([0.6667, 1.3333, 2.0000])\ndef test2():\n    a = torch.tensor([1,2,3], dtype=torch.float32, requires_grad=True).to(device)\n    b = a**2\n    c = torch.mean(b)\n    c.backward()\n    print(a.grad)\nthe result is : None\nI don't understand why they are different, thanks.", "body": "hello, I write a simple small test to test grad, I found a strange behavor, in test1, I use Tensor in cpu, then I can get grad, but if I put them to gpu, the grad is gone, here is my test code:\r\n\r\n```python\r\nimport torch\r\ndevice = torch.device('cuda')\r\n    \r\ndef test1():\r\n    a = torch.tensor([1,2,3], dtype=torch.float32, requires_grad=True)\r\n    b = a**2\r\n    c = torch.mean(b)\r\n    c.backward()\r\n    print(a.grad)\r\n```\r\n`the result is: tensor([0.6667, 1.3333, 2.0000])`\r\n\r\n```python    \r\ndef test2():\r\n    a = torch.tensor([1,2,3], dtype=torch.float32, requires_grad=True).to(device)\r\n    b = a**2\r\n    c = torch.mean(b)\r\n    c.backward()\r\n    print(a.grad)\r\n```\r\n`the result is : None`\r\n\r\nI don't understand why they are different, thanks."}