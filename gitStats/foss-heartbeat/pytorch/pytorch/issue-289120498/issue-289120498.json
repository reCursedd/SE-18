{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4698", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4698/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4698/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4698/events", "html_url": "https://github.com/pytorch/pytorch/issues/4698", "id": 289120498, "node_id": "MDU6SXNzdWUyODkxMjA0OTg=", "number": 4698, "title": "Failed to load model", "user": {"login": "Fangyh09", "id": 9389269, "node_id": "MDQ6VXNlcjkzODkyNjk=", "avatar_url": "https://avatars3.githubusercontent.com/u/9389269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Fangyh09", "html_url": "https://github.com/Fangyh09", "followers_url": "https://api.github.com/users/Fangyh09/followers", "following_url": "https://api.github.com/users/Fangyh09/following{/other_user}", "gists_url": "https://api.github.com/users/Fangyh09/gists{/gist_id}", "starred_url": "https://api.github.com/users/Fangyh09/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Fangyh09/subscriptions", "organizations_url": "https://api.github.com/users/Fangyh09/orgs", "repos_url": "https://api.github.com/users/Fangyh09/repos", "events_url": "https://api.github.com/users/Fangyh09/events{/privacy}", "received_events_url": "https://api.github.com/users/Fangyh09/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-17T02:16:13Z", "updated_at": "2018-02-22T15:04:59Z", "closed_at": "2018-01-22T03:15:29Z", "author_association": "NONE", "body_html": "<p>I cannot load model, the error message is</p>\n<div class=\"highlight highlight-source-shell\"><pre>TypeError: <span class=\"pl-k\">&lt;</span>module <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">&gt;</span> is a built-in class</pre></div>\n<p>I used this to load model.</p>\n<div class=\"highlight highlight-source-python\"><pre>net_path <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/home/foo/checkpoint80.t7<span class=\"pl-pds\">'</span></span>\nnet <span class=\"pl-k\">=</span> torch.load(net_path).cuda(<span class=\"pl-v\">device_id</span><span class=\"pl-k\">=</span>gpus[<span class=\"pl-c1\">0</span>])</pre></div>\n<p>And this to save model.</p>\n<div class=\"highlight highlight-source-python\"><pre>checkpoint_file <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>checkpoint<span class=\"pl-c1\">{}</span>.t7<span class=\"pl-pds\">'</span></span>.format(epoch)\ntorch.save(net, checkpoint_file)</pre></div>\n<p><em><strong>ps, It's okay to run the code in jupyter notebook. However, if I just convert the jupyter file into corresponding python file, it will encounter the above problem.</strong></em></p>\n<p>The whole error messages are:</p>\n<div class=\"highlight highlight-source-shell\"><pre>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython-input-28-276f7c472cc<span class=\"pl-k\">0&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-en\">&lt;module&gt;</span>()\n      8     net_path = <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/home/foo/checkpoint80.t7<span class=\"pl-pds\">'</span></span>\n      9     print(net_path)\n---<span class=\"pl-k\">&gt;</span> 10     net = torch.load(net_path).cuda(device_id=gpus[0])\n     11     images = sample_batched[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>image<span class=\"pl-pds\">'</span></span>].cuda(device=gpus[0])\n     12     poses = sample_batched[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>pose<span class=\"pl-pds\">'</span></span>].cuda(device=gpus[0])\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py <span class=\"pl-k\">in</span> load(f, map_location, pickle_module)\n    229         f = open(f, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>)\n    230     try:\n--<span class=\"pl-k\">&gt;</span> 231         <span class=\"pl-k\">return</span> _load(f, map_location, pickle_module)\n    232     finally:\n    233         <span class=\"pl-k\">if</span> new_fd:\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py <span class=\"pl-k\">in</span> _load(f, map_location, pickle_module)\n    377     unpickler = pickle_module.Unpickler(f)\n    378     unpickler.persistent_load = persistent_load\n--<span class=\"pl-k\">&gt;</span> 379     result = <span class=\"pl-en\">unpickler.load</span>()\n    380 \n    381     deserialized_storage_keys = pickle_module.load(f)\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py <span class=\"pl-k\">in</span> persistent_load(saved_id)\n    342             <span class=\"pl-c\"><span class=\"pl-c\">#</span> Ignore containers that don't have any sources saved</span>\n    343             <span class=\"pl-k\">if</span> all(data[1:]):\n--<span class=\"pl-k\">&gt;</span> 344                 _check_container_source(<span class=\"pl-k\">*</span>data)\n    345             <span class=\"pl-k\">return</span> data[0]\n    346         <span class=\"pl-k\">elif</span> typename == <span class=\"pl-s\"><span class=\"pl-pds\">'</span>storage<span class=\"pl-pds\">'</span></span>:\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py <span class=\"pl-k\">in</span> _check_container_source(container_type, source_file, original_source)\n    252 \n    253     def _check_container_source(container_type, source_file, original_source):\n--<span class=\"pl-k\">&gt;</span> 254         current_source = inspect.getsource(container_type)\n    255         <span class=\"pl-k\">if</span> original_source <span class=\"pl-k\">!</span>= current_source:\n    256             <span class=\"pl-k\">if</span> container_type.dump_patches:\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/lib/python3.6/inspect.py <span class=\"pl-k\">in</span> getsource(object)\n    963     or code object.  The <span class=\"pl-c1\">source</span> code is returned as a single string.  An\n    964     OSError is raised <span class=\"pl-k\">if</span> the <span class=\"pl-c1\">source</span> code cannot be retrieved.<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\">--&gt; 965     lines, lnum = getsourcelines(object)</span>\n<span class=\"pl-s\">    966     return ''.join(lines)</span>\n<span class=\"pl-s\">    967 </span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcelines(object)</span>\n<span class=\"pl-s\">    950     raised if the source code cannot be retrieved.<span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\n    951     object = unwrap(object)\n--<span class=\"pl-k\">&gt;</span> 952     lines, lnum = findsource(object)\n    953 \n    954     <span class=\"pl-k\">if</span> ismodule(object):\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/lib/python3.6/inspect.py <span class=\"pl-k\">in</span> findsource(object)\n    763     is raised <span class=\"pl-k\">if</span> the <span class=\"pl-c1\">source</span> code cannot be retrieved.<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\n<span class=\"pl-s\">    764 </span>\n<span class=\"pl-s\">--&gt; 765     file = getsourcefile(object)</span>\n<span class=\"pl-s\">    766     if file:</span>\n<span class=\"pl-s\">    767         # Invalidate cache if needed.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcefile(object)</span>\n<span class=\"pl-s\">    679     Return None if no way can be identified to get the source.</span>\n<span class=\"pl-s\">    680     <span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>\n--<span class=\"pl-k\">&gt;</span> 681     filename = getfile(object)\n    682     all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\n    683     all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n\n<span class=\"pl-k\">~</span>/.pyenv/versions/3.6.2/lib/python3.6/inspect.py <span class=\"pl-k\">in</span> getfile(object)\n    649             <span class=\"pl-k\">if</span> hasattr(object, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__file__<span class=\"pl-pds\">'</span></span>):\n    650                 <span class=\"pl-k\">return</span> object.__file__\n--<span class=\"pl-k\">&gt;</span> 651         raise TypeError(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>{!r} is a built-in class<span class=\"pl-pds\">'</span></span>.format(object))\n    652     <span class=\"pl-k\">if</span> ismethod(object):\n    653         object = object.__func__</pre></div>", "body_text": "I cannot load model, the error message is\nTypeError: <module '__main__'> is a built-in class\nI used this to load model.\nnet_path = '/home/foo/checkpoint80.t7'\nnet = torch.load(net_path).cuda(device_id=gpus[0])\nAnd this to save model.\ncheckpoint_file = 'checkpoint{}.t7'.format(epoch)\ntorch.save(net, checkpoint_file)\nps, It's okay to run the code in jupyter notebook. However, if I just convert the jupyter file into corresponding python file, it will encounter the above problem.\nThe whole error messages are:\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-28-276f7c472cc0> in <module>()\n      8     net_path = '/home/foo/checkpoint80.t7'\n      9     print(net_path)\n---> 10     net = torch.load(net_path).cuda(device_id=gpus[0])\n     11     images = sample_batched['image'].cuda(device=gpus[0])\n     12     poses = sample_batched['pose'].cuda(device=gpus[0])\n\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in load(f, map_location, pickle_module)\n    229         f = open(f, 'rb')\n    230     try:\n--> 231         return _load(f, map_location, pickle_module)\n    232     finally:\n    233         if new_fd:\n\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in _load(f, map_location, pickle_module)\n    377     unpickler = pickle_module.Unpickler(f)\n    378     unpickler.persistent_load = persistent_load\n--> 379     result = unpickler.load()\n    380 \n    381     deserialized_storage_keys = pickle_module.load(f)\n\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in persistent_load(saved_id)\n    342             # Ignore containers that don't have any sources saved\n    343             if all(data[1:]):\n--> 344                 _check_container_source(*data)\n    345             return data[0]\n    346         elif typename == 'storage':\n\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in _check_container_source(container_type, source_file, original_source)\n    252 \n    253     def _check_container_source(container_type, source_file, original_source):\n--> 254         current_source = inspect.getsource(container_type)\n    255         if original_source != current_source:\n    256             if container_type.dump_patches:\n\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsource(object)\n    963     or code object.  The source code is returned as a single string.  An\n    964     OSError is raised if the source code cannot be retrieved.\"\"\"\n--> 965     lines, lnum = getsourcelines(object)\n    966     return ''.join(lines)\n    967 \n\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcelines(object)\n    950     raised if the source code cannot be retrieved.\"\"\"\n    951     object = unwrap(object)\n--> 952     lines, lnum = findsource(object)\n    953 \n    954     if ismodule(object):\n\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in findsource(object)\n    763     is raised if the source code cannot be retrieved.\"\"\"\n    764 \n--> 765     file = getsourcefile(object)\n    766     if file:\n    767         # Invalidate cache if needed.\n\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcefile(object)\n    679     Return None if no way can be identified to get the source.\n    680     \"\"\"\n--> 681     filename = getfile(object)\n    682     all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\n    683     all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getfile(object)\n    649             if hasattr(object, '__file__'):\n    650                 return object.__file__\n--> 651         raise TypeError('{!r} is a built-in class'.format(object))\n    652     if ismethod(object):\n    653         object = object.__func__", "body": "I cannot load model, the error message is \r\n```bash\r\nTypeError: <module '__main__'> is a built-in class\r\n```\r\nI used this to load model.\r\n```python\r\nnet_path = '/home/foo/checkpoint80.t7'\r\nnet = torch.load(net_path).cuda(device_id=gpus[0])\r\n```\r\nAnd this to save model.\r\n```python\r\ncheckpoint_file = 'checkpoint{}.t7'.format(epoch)\r\ntorch.save(net, checkpoint_file)\r\n```\r\n***ps, It's okay to run the code in jupyter notebook. However, if I just convert the jupyter file into corresponding python file, it will encounter the above problem.***\r\n\r\nThe whole error messages are:\r\n```bash\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-28-276f7c472cc0> in <module>()\r\n      8     net_path = '/home/foo/checkpoint80.t7'\r\n      9     print(net_path)\r\n---> 10     net = torch.load(net_path).cuda(device_id=gpus[0])\r\n     11     images = sample_batched['image'].cuda(device=gpus[0])\r\n     12     poses = sample_batched['pose'].cuda(device=gpus[0])\r\n\r\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in load(f, map_location, pickle_module)\r\n    229         f = open(f, 'rb')\r\n    230     try:\r\n--> 231         return _load(f, map_location, pickle_module)\r\n    232     finally:\r\n    233         if new_fd:\r\n\r\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in _load(f, map_location, pickle_module)\r\n    377     unpickler = pickle_module.Unpickler(f)\r\n    378     unpickler.persistent_load = persistent_load\r\n--> 379     result = unpickler.load()\r\n    380 \r\n    381     deserialized_storage_keys = pickle_module.load(f)\r\n\r\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in persistent_load(saved_id)\r\n    342             # Ignore containers that don't have any sources saved\r\n    343             if all(data[1:]):\r\n--> 344                 _check_container_source(*data)\r\n    345             return data[0]\r\n    346         elif typename == 'storage':\r\n\r\n~/.pyenv/versions/3.6.2/envs/env3.6/lib/python3.6/site-packages/torch/serialization.py in _check_container_source(container_type, source_file, original_source)\r\n    252 \r\n    253     def _check_container_source(container_type, source_file, original_source):\r\n--> 254         current_source = inspect.getsource(container_type)\r\n    255         if original_source != current_source:\r\n    256             if container_type.dump_patches:\r\n\r\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsource(object)\r\n    963     or code object.  The source code is returned as a single string.  An\r\n    964     OSError is raised if the source code cannot be retrieved.\"\"\"\r\n--> 965     lines, lnum = getsourcelines(object)\r\n    966     return ''.join(lines)\r\n    967 \r\n\r\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcelines(object)\r\n    950     raised if the source code cannot be retrieved.\"\"\"\r\n    951     object = unwrap(object)\r\n--> 952     lines, lnum = findsource(object)\r\n    953 \r\n    954     if ismodule(object):\r\n\r\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in findsource(object)\r\n    763     is raised if the source code cannot be retrieved.\"\"\"\r\n    764 \r\n--> 765     file = getsourcefile(object)\r\n    766     if file:\r\n    767         # Invalidate cache if needed.\r\n\r\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getsourcefile(object)\r\n    679     Return None if no way can be identified to get the source.\r\n    680     \"\"\"\r\n--> 681     filename = getfile(object)\r\n    682     all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\r\n    683     all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\r\n\r\n~/.pyenv/versions/3.6.2/lib/python3.6/inspect.py in getfile(object)\r\n    649             if hasattr(object, '__file__'):\r\n    650                 return object.__file__\r\n--> 651         raise TypeError('{!r} is a built-in class'.format(object))\r\n    652     if ismethod(object):\r\n    653         object = object.__func__\r\n```"}