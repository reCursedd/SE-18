{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/342480496", "html_url": "https://github.com/pytorch/pytorch/issues/3531#issuecomment-342480496", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3531", "id": 342480496, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjQ4MDQ5Ng==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-07T13:23:13Z", "updated_at": "2017-11-07T13:23:13Z", "author_association": "MEMBER", "body_html": "<p>All of this is expected and as far as I know is exactly the same in NumPy and Lua Torch. Basically, there are two kinds of indexing - simple and advanced. Simple are things like adding dimensions, slicing and selecting along dimensions. Advanced indexing is masking and selecting a number of indices. Simple indexing always returns a view, and advanced indexing always returns a tensor that doesn't share memory with the original one.</p>\n<p>Now, if you did the indexing in one go (e.g. <code>a[idxes, 1]</code> instead of <code>a[:, 1][idxes]</code>), then all these examples would work, because <code>__setitem__</code> gets called only once and we will sort everything out for you. However, in Python semantics <code>a[idxes][:, 1] = 1</code> is no different than this:</p>\n<div class=\"highlight highlight-source-python\"><pre>__tmp <span class=\"pl-k\">=</span> a[idxes] <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>: __tmp doesn't share memory with a!</span>\n__tmp[:, <span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span></pre></div>\n<p>We, as a library, only see a single call to <code>__getitem__</code> and single call to <code>__setitem__</code> and there's no way for us to determine if you did this in a single line, and the result is a temporary, or if it was performed in multiple lines and it's clear what happens.</p>", "body_text": "All of this is expected and as far as I know is exactly the same in NumPy and Lua Torch. Basically, there are two kinds of indexing - simple and advanced. Simple are things like adding dimensions, slicing and selecting along dimensions. Advanced indexing is masking and selecting a number of indices. Simple indexing always returns a view, and advanced indexing always returns a tensor that doesn't share memory with the original one.\nNow, if you did the indexing in one go (e.g. a[idxes, 1] instead of a[:, 1][idxes]), then all these examples would work, because __setitem__ gets called only once and we will sort everything out for you. However, in Python semantics a[idxes][:, 1] = 1 is no different than this:\n__tmp = a[idxes] # NOTE: __tmp doesn't share memory with a!\n__tmp[:, 1] = 1\nWe, as a library, only see a single call to __getitem__ and single call to __setitem__ and there's no way for us to determine if you did this in a single line, and the result is a temporary, or if it was performed in multiple lines and it's clear what happens.", "body": "All of this is expected and as far as I know is exactly the same in NumPy and Lua Torch. Basically, there are two kinds of indexing - simple and advanced. Simple are things like adding dimensions, slicing and selecting along dimensions. Advanced indexing is masking and selecting a number of indices. Simple indexing always returns a view, and advanced indexing always returns a tensor that doesn't share memory with the original one.\r\n\r\nNow, if you did the indexing in one go (e.g. `a[idxes, 1]` instead of `a[:, 1][idxes]`), then all these examples would work, because `__setitem__` gets called only once and we will sort everything out for you. However, in Python semantics `a[idxes][:, 1] = 1` is no different than this:\r\n```python\r\n__tmp = a[idxes] # NOTE: __tmp doesn't share memory with a!\r\n__tmp[:, 1] = 1\r\n```\r\nWe, as a library, only see a single call to `__getitem__` and single call to `__setitem__` and there's no way for us to determine if you did this in a single line, and the result is a temporary, or if it was performed in multiple lines and it's clear what happens."}