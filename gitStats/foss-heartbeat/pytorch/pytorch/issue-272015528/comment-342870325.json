{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/342870325", "html_url": "https://github.com/pytorch/pytorch/pull/3555#issuecomment-342870325", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3555", "id": 342870325, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Mjg3MDMyNQ==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-08T16:22:08Z", "updated_at": "2017-11-08T16:22:08Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">Let\u2019s just add a section about migration to the docs. I don\u2019t really like\nlinking to a GitHub PR.\n\nWe can also include a snippet in the error message itself.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Wed, Nov 8, 2017 at 10:26 AM Adam Paszke ***@***.***&gt; wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In torch/autograd/variable.py\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"272015528\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3555\" href=\"https://github.com/pytorch/pytorch/pull/3555#discussion_r149701494\">#3555 (comment)</a>&gt;:\n\n &gt; -\n -        Differentiating stochastic nodes requires providing them with reward\n -        value. If your graph contains any stochastic operations, you should\n -        call this function on their outputs. Otherwise an error will be raised.\n -\n -        Parameters:\n -            reward(Tensor): Tensor with per-element rewards. It has to match\n -                the device location and shape of Variable's data.\n -        \"\"\"\n -        if not isinstance(self.grad_fn, StochasticFunction):\n -            raise RuntimeError(\"reinforce() can be only called on outputs \"\n -                               \"of stochastic functions\")\n -        self.grad_fn._reinforce(reward)\n +        raise RuntimeError(\n +            \"reinforce() was removed. Use torch.distributions instead.\\n\"\n +            \"See <a href=\"http://pytorch.org/docs/master/distributions.html\">http://pytorch.org/docs/master/distributions.html</a>\")\n\n I'm fine with anything that will point people *directly* to the snippet\n that lets them fix their code, but this diff is quite large so it might be\n hard to parse. Let's say \"see , where in the header you can find an example\n showing how to implement policy gradient\".\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"272015528\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3555\" href=\"https://github.com/pytorch/pytorch/pull/3555#discussion_r149701494\">#3555 (comment)</a>&gt;, or mute\n the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAoB-rvE4eB2v3RgivyLmuJ29XgtWL7xks5s0cg9gaJpZM4QVllJ\">https://github.com/notifications/unsubscribe-auth/AAoB-rvE4eB2v3RgivyLmuJ29XgtWL7xks5s0cg9gaJpZM4QVllJ</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Let\u2019s just add a section about migration to the docs. I don\u2019t really like\nlinking to a GitHub PR.\n\nWe can also include a snippet in the error message itself.\n\u2026\nOn Wed, Nov 8, 2017 at 10:26 AM Adam Paszke ***@***.***> wrote:\n ***@***.**** commented on this pull request.\n ------------------------------\n\n In torch/autograd/variable.py\n <#3555 (comment)>:\n\n > -\n -        Differentiating stochastic nodes requires providing them with reward\n -        value. If your graph contains any stochastic operations, you should\n -        call this function on their outputs. Otherwise an error will be raised.\n -\n -        Parameters:\n -            reward(Tensor): Tensor with per-element rewards. It has to match\n -                the device location and shape of Variable's data.\n -        \"\"\"\n -        if not isinstance(self.grad_fn, StochasticFunction):\n -            raise RuntimeError(\"reinforce() can be only called on outputs \"\n -                               \"of stochastic functions\")\n -        self.grad_fn._reinforce(reward)\n +        raise RuntimeError(\n +            \"reinforce() was removed. Use torch.distributions instead.\\n\"\n +            \"See http://pytorch.org/docs/master/distributions.html\")\n\n I'm fine with anything that will point people *directly* to the snippet\n that lets them fix their code, but this diff is quite large so it might be\n hard to parse. Let's say \"see , where in the header you can find an example\n showing how to implement policy gradient\".\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#3555 (comment)>, or mute\n the thread\n <https://github.com/notifications/unsubscribe-auth/AAoB-rvE4eB2v3RgivyLmuJ29XgtWL7xks5s0cg9gaJpZM4QVllJ>\n .", "body": "Let\u2019s just add a section about migration to the docs. I don\u2019t really like\nlinking to a GitHub PR.\n\nWe can also include a snippet in the error message itself.\n\nOn Wed, Nov 8, 2017 at 10:26 AM Adam Paszke <notifications@github.com>\nwrote:\n\n> *@apaszke* commented on this pull request.\n> ------------------------------\n>\n> In torch/autograd/variable.py\n> <https://github.com/pytorch/pytorch/pull/3555#discussion_r149701494>:\n>\n> > -\n> -        Differentiating stochastic nodes requires providing them with reward\n> -        value. If your graph contains any stochastic operations, you should\n> -        call this function on their outputs. Otherwise an error will be raised.\n> -\n> -        Parameters:\n> -            reward(Tensor): Tensor with per-element rewards. It has to match\n> -                the device location and shape of Variable's data.\n> -        \"\"\"\n> -        if not isinstance(self.grad_fn, StochasticFunction):\n> -            raise RuntimeError(\"reinforce() can be only called on outputs \"\n> -                               \"of stochastic functions\")\n> -        self.grad_fn._reinforce(reward)\n> +        raise RuntimeError(\n> +            \"reinforce() was removed. Use torch.distributions instead.\\n\"\n> +            \"See http://pytorch.org/docs/master/distributions.html\")\n>\n> I'm fine with anything that will point people *directly* to the snippet\n> that lets them fix their code, but this diff is quite large so it might be\n> hard to parse. Let's say \"see , where in the header you can find an example\n> showing how to implement policy gradient\".\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pytorch/pytorch/pull/3555#discussion_r149701494>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AAoB-rvE4eB2v3RgivyLmuJ29XgtWL7xks5s0cg9gaJpZM4QVllJ>\n> .\n>\n"}