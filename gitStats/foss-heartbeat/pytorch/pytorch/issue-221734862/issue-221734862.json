{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1258", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1258/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1258/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1258/events", "html_url": "https://github.com/pytorch/pytorch/issues/1258", "id": 221734862, "node_id": "MDU6SXNzdWUyMjE3MzQ4NjI=", "number": 1258, "title": "about torch.nn.CrossEntropyLoss", "user": {"login": "dablyo", "id": 7297653, "node_id": "MDQ6VXNlcjcyOTc2NTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/7297653?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dablyo", "html_url": "https://github.com/dablyo", "followers_url": "https://api.github.com/users/dablyo/followers", "following_url": "https://api.github.com/users/dablyo/following{/other_user}", "gists_url": "https://api.github.com/users/dablyo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dablyo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dablyo/subscriptions", "organizations_url": "https://api.github.com/users/dablyo/orgs", "repos_url": "https://api.github.com/users/dablyo/repos", "events_url": "https://api.github.com/users/dablyo/events{/privacy}", "received_events_url": "https://api.github.com/users/dablyo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-14T03:38:25Z", "updated_at": "2017-12-04T07:32:25Z", "closed_at": "2017-04-14T14:49:24Z", "author_association": "NONE", "body_html": "<p>about torch.nn.CrossEntropyLoss,<br>\ni'm learning pytorch, and taking the anpr project<br>\n(<a href=\"https://github.com/matthewearl/deep-anpr\">https://github.com/matthewearl/deep-anpr</a>,<br>\n<a href=\"http://matthewearl.github.io/2016/05/06/cnn-anpr/\" rel=\"nofollow\">http://matthewearl.github.io/2016/05/06/cnn-anpr/</a>)<br>\nas a exercise, transplant it to pytorch platform.</p>\n<p>there is a problem,i'm using nn.CrossEntropyLoss() as loss function:<br>\ncriterion=nn.CrossEntropyLoss()</p>\n<p>the output.data of model is:<br>\n1.00000e-02 *<br>\n-2.5552  2.7582  2.5368  ...   5.6184  1.2288 -0.0076<br>\n-0.7033  1.3167 -1.0966  ...   4.7249  1.3217  1.8367<br>\n-0.7592  1.4777  1.8095  ...   0.8733  1.2417  1.1521<br>\n-0.1040 -0.7054 -3.4862  ...   4.7703  2.9595  1.4263<br>\n[torch.FloatTensor of size 4x253]</p>\n<p>and targets.data is:<br>\n1     0     0  ...      0     0     0<br>\n1     0     0  ...      0     0     0<br>\n1     0     0  ...      0     0     0<br>\n1     0     0  ...      0     0     0<br>\n[torch.DoubleTensor of size 4x253]</p>\n<p>when i call:<br>\nloss=criterion(output,targets)<br>\nerror occured,information is:<br>\nTypeError: FloatClassNLLCriterion_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, torch.DoubleTensor, torch.FloatTensor, bool, NoneType, torch.FloatTensor), but expected (int state, torch.FloatTensor input, torch.LongTensor target, torch.FloatTensor output, bool sizeAverage, [torch.FloatTensor weights or None], torch.FloatTensor total_weight)</p>\n<p>'expected torch.LongTensor','got torch.DoubleTensor',but if i convert the targets into LongTensor:<br>\ntorch.LongTensor(numpy.array(targets.data.numpy(),numpy.long))<br>\ncall loss=criterion(output,targets), the error is:<br>\nRuntimeError: multi-target not supported at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.10_1488752595704/work/torch/lib/THNN/generic/ClassNLLCriterion.c:20</p>\n<p>my last exercise is mnist, a example from pytorch,i made a bit modification,batch_size is 4,the loss function:<br>\nloss =  F.nll_loss(outputs, labels)<br>\noutputs.data:<br>\n-2.3220 -2.1229 -2.3395 -2.3391 -2.5270 -2.3269 -2.1055 -2.2321 -2.4943 -2.2996<br>\n-2.3653 -2.2034 -2.4437 -2.2708 -2.5114 -2.3286 -2.1921 -2.1771 -2.3343 -2.2533<br>\n-2.2809 -2.2119 -2.3872 -2.2190 -2.4610 -2.2946 -2.2053 -2.3192 -2.3674 -2.3100<br>\n-2.3715 -2.1455 -2.4199 -2.4177 -2.4565 -2.2812 -2.2467 -2.1144 -2.3321 -2.3009<br>\n[torch.FloatTensor of size 4x10]</p>\n<p>labels.data:<br>\n8<br>\n6<br>\n0<br>\n1<br>\n[torch.LongTensor of size 4]</p>\n<p>the labels, for a input image,must be a single element, in upper example, there is 253 numbers, and in 'mnist',there is only one number, the shape of outputs is difference from labels.</p>\n<p>i review the tensorflow manual, tf.nn.softmax_cross_entropy_with_logits,<br>\n'Logits and labels must have the sameshape [batch_size, num_classes] and the same dtype (either float32 or float64).'</p>\n<p>so,can i using pytorch in this case, or how can i do?<br>\nmany thks</p>", "body_text": "about torch.nn.CrossEntropyLoss,\ni'm learning pytorch, and taking the anpr project\n(https://github.com/matthewearl/deep-anpr,\nhttp://matthewearl.github.io/2016/05/06/cnn-anpr/)\nas a exercise, transplant it to pytorch platform.\nthere is a problem,i'm using nn.CrossEntropyLoss() as loss function:\ncriterion=nn.CrossEntropyLoss()\nthe output.data of model is:\n1.00000e-02 *\n-2.5552  2.7582  2.5368  ...   5.6184  1.2288 -0.0076\n-0.7033  1.3167 -1.0966  ...   4.7249  1.3217  1.8367\n-0.7592  1.4777  1.8095  ...   0.8733  1.2417  1.1521\n-0.1040 -0.7054 -3.4862  ...   4.7703  2.9595  1.4263\n[torch.FloatTensor of size 4x253]\nand targets.data is:\n1     0     0  ...      0     0     0\n1     0     0  ...      0     0     0\n1     0     0  ...      0     0     0\n1     0     0  ...      0     0     0\n[torch.DoubleTensor of size 4x253]\nwhen i call:\nloss=criterion(output,targets)\nerror occured,information is:\nTypeError: FloatClassNLLCriterion_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, torch.DoubleTensor, torch.FloatTensor, bool, NoneType, torch.FloatTensor), but expected (int state, torch.FloatTensor input, torch.LongTensor target, torch.FloatTensor output, bool sizeAverage, [torch.FloatTensor weights or None], torch.FloatTensor total_weight)\n'expected torch.LongTensor','got torch.DoubleTensor',but if i convert the targets into LongTensor:\ntorch.LongTensor(numpy.array(targets.data.numpy(),numpy.long))\ncall loss=criterion(output,targets), the error is:\nRuntimeError: multi-target not supported at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.10_1488752595704/work/torch/lib/THNN/generic/ClassNLLCriterion.c:20\nmy last exercise is mnist, a example from pytorch,i made a bit modification,batch_size is 4,the loss function:\nloss =  F.nll_loss(outputs, labels)\noutputs.data:\n-2.3220 -2.1229 -2.3395 -2.3391 -2.5270 -2.3269 -2.1055 -2.2321 -2.4943 -2.2996\n-2.3653 -2.2034 -2.4437 -2.2708 -2.5114 -2.3286 -2.1921 -2.1771 -2.3343 -2.2533\n-2.2809 -2.2119 -2.3872 -2.2190 -2.4610 -2.2946 -2.2053 -2.3192 -2.3674 -2.3100\n-2.3715 -2.1455 -2.4199 -2.4177 -2.4565 -2.2812 -2.2467 -2.1144 -2.3321 -2.3009\n[torch.FloatTensor of size 4x10]\nlabels.data:\n8\n6\n0\n1\n[torch.LongTensor of size 4]\nthe labels, for a input image,must be a single element, in upper example, there is 253 numbers, and in 'mnist',there is only one number, the shape of outputs is difference from labels.\ni review the tensorflow manual, tf.nn.softmax_cross_entropy_with_logits,\n'Logits and labels must have the sameshape [batch_size, num_classes] and the same dtype (either float32 or float64).'\nso,can i using pytorch in this case, or how can i do?\nmany thks", "body": "about torch.nn.CrossEntropyLoss,\r\ni'm learning pytorch, and taking the anpr project \r\n(https://github.com/matthewearl/deep-anpr,\r\nhttp://matthewearl.github.io/2016/05/06/cnn-anpr/) \r\nas a exercise, transplant it to pytorch platform.\r\n\r\nthere is a problem,i'm using nn.CrossEntropyLoss() as loss function:\r\ncriterion=nn.CrossEntropyLoss()\r\n\r\nthe output.data of model is:\r\n1.00000e-02 *\r\n-2.5552  2.7582  2.5368  ...   5.6184  1.2288 -0.0076\r\n-0.7033  1.3167 -1.0966  ...   4.7249  1.3217  1.8367\r\n-0.7592  1.4777  1.8095  ...   0.8733  1.2417  1.1521\r\n-0.1040 -0.7054 -3.4862  ...   4.7703  2.9595  1.4263\r\n[torch.FloatTensor of size 4x253]\r\n\r\nand targets.data is:\r\n    1     0     0  ...      0     0     0\r\n    1     0     0  ...      0     0     0\r\n    1     0     0  ...      0     0     0\r\n    1     0     0  ...      0     0     0\r\n[torch.DoubleTensor of size 4x253]\r\n\r\nwhen i call:\r\nloss=criterion(output,targets)\r\nerror occured,information is:\r\nTypeError: FloatClassNLLCriterion_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, torch.DoubleTensor, torch.FloatTensor, bool, NoneType, torch.FloatTensor), but expected (int state, torch.FloatTensor input, torch.LongTensor target, torch.FloatTensor output, bool sizeAverage, [torch.FloatTensor weights or None], torch.FloatTensor total_weight)\r\n\r\n'expected torch.LongTensor','got torch.DoubleTensor',but if i convert the targets into LongTensor:\r\ntorch.LongTensor(numpy.array(targets.data.numpy(),numpy.long))\r\ncall loss=criterion(output,targets), the error is:\r\nRuntimeError: multi-target not supported at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.10_1488752595704/work/torch/lib/THNN/generic/ClassNLLCriterion.c:20\r\n\r\nmy last exercise is mnist, a example from pytorch,i made a bit modification,batch_size is 4,the loss function:\r\nloss =  F.nll_loss(outputs, labels)\r\noutputs.data: \r\n-2.3220 -2.1229 -2.3395 -2.3391 -2.5270 -2.3269 -2.1055 -2.2321 -2.4943 -2.2996\r\n-2.3653 -2.2034 -2.4437 -2.2708 -2.5114 -2.3286 -2.1921 -2.1771 -2.3343 -2.2533\r\n-2.2809 -2.2119 -2.3872 -2.2190 -2.4610 -2.2946 -2.2053 -2.3192 -2.3674 -2.3100\r\n-2.3715 -2.1455 -2.4199 -2.4177 -2.4565 -2.2812 -2.2467 -2.1144 -2.3321 -2.3009\r\n[torch.FloatTensor of size 4x10]\r\n\r\nlabels.data:\r\n 8\r\n 6\r\n 0\r\n 1\r\n[torch.LongTensor of size 4]\r\n\r\nthe labels, for a input image,must be a single element, in upper example, there is 253 numbers, and in 'mnist',there is only one number, the shape of outputs is difference from labels.\r\n\r\ni review the tensorflow manual, tf.nn.softmax_cross_entropy_with_logits,\r\n'Logits and labels must have the sameshape [batch_size, num_classes] and the same dtype (either float32 or float64).'\r\n\r\nso,can i using pytorch in this case, or how can i do?\r\nmany thks\r\n"}