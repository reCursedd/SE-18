{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12358", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12358/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12358/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12358/events", "html_url": "https://github.com/pytorch/pytorch/issues/12358", "id": 367042707, "node_id": "MDU6SXNzdWUzNjcwNDI3MDc=", "number": 12358, "title": "BrokenPipeError on \"DataLoading and PreProcessing\" tutorial", "user": {"login": "david2588e", "id": 19882172, "node_id": "MDQ6VXNlcjE5ODgyMTcy", "avatar_url": "https://avatars3.githubusercontent.com/u/19882172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david2588e", "html_url": "https://github.com/david2588e", "followers_url": "https://api.github.com/users/david2588e/followers", "following_url": "https://api.github.com/users/david2588e/following{/other_user}", "gists_url": "https://api.github.com/users/david2588e/gists{/gist_id}", "starred_url": "https://api.github.com/users/david2588e/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david2588e/subscriptions", "organizations_url": "https://api.github.com/users/david2588e/orgs", "repos_url": "https://api.github.com/users/david2588e/repos", "events_url": "https://api.github.com/users/david2588e/events{/privacy}", "received_events_url": "https://api.github.com/users/david2588e/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-10-05T03:00:36Z", "updated_at": "2018-10-09T07:48:07Z", "closed_at": "2018-10-09T07:48:07Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>BrokenPipeError: [Errno 32] Broken pipe</li>\n<li></li>\n<li></li>\n</ol>\n\n<h2>Expected behavior</h2>\n\n<p>File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\process.py\", line 112, in start<br>\nself._popen = self._Popen(self)</p>\n<p>File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 223, in _Popen<br>\nreturn _default_context.get_context().Process._Popen(process_obj)</p>\n<p>File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 322, in _Popen<br>\nreturn Popen(process_obj)</p>\n<p>File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in <strong>init</strong><br>\nreduction.dump(process_obj, to_child)</p>\n<p>File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\reduction.py\", line 60, in dump<br>\nForkingPickler(file, protocol).dump(obj)</p>\n<p>BrokenPipeError: [Errno 32] Broken pipe</p>\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<p><strong>Collecting environment information...<br>\nTraceback (most recent call last):<br>\nFile \"collect_env.py\", line 348, in <br>\nmain()<br>\nFile \"collect_env.py\", line 343, in main<br>\noutput = get_pretty_env_info()<br>\nFile \"collect_env.py\", line 338, in get_pretty_env_info<br>\nreturn pretty_str(get_env_info())<br>\nFile \"collect_env.py\", line 232, in get_env_info<br>\ncudnn_version=get_cudnn_version(run_lambda),<br>\nFile \"collect_env.py\", line 112, in get_cudnn_version<br>\nrc, out, _ = run_lambda(cudnn_cmd)<br>\nFile \"collect_env.py\", line 43, in run<br>\nerr = err.decode(\"ascii\")<br>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 0: ordinal not in range(128)</strong></p>\n<ul>\n<li>\n<p>PyTorch Version (e.g., 1.0):</p>\n</li>\n<li>\n<p>OS (e.g., Linux):</p>\n</li>\n<li>\n<p>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source):<br>\nconda install pytorch -c pytorch<br>\npip3 install torchvision</p>\n</li>\n<li>\n<p>Build command you used (if compiling from source):</p>\n</li>\n<li>\n<p>Python version: Python 3.7</p>\n</li>\n<li>\n<p>CUDA/cuDNN version:<br>\nCUDA Version 9.1.85</p>\n</li>\n</ul>\n<p>CUDA Patch Version 9.1.85.3</p>\n<ul>\n<li>GPU models and configuration:  GTX 1060</li>\n<li>Any other relevant information:</li>\n</ul>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nBrokenPipeError: [Errno 32] Broken pipe\n\n\n\n\nExpected behavior\n\nFile \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\process.py\", line 112, in start\nself._popen = self._Popen(self)\nFile \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\nreturn _default_context.get_context().Process._Popen(process_obj)\nFile \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\nreturn Popen(process_obj)\nFile \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in init\nreduction.dump(process_obj, to_child)\nFile \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\nForkingPickler(file, protocol).dump(obj)\nBrokenPipeError: [Errno 32] Broken pipe\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\nCollecting environment information...\nTraceback (most recent call last):\nFile \"collect_env.py\", line 348, in \nmain()\nFile \"collect_env.py\", line 343, in main\noutput = get_pretty_env_info()\nFile \"collect_env.py\", line 338, in get_pretty_env_info\nreturn pretty_str(get_env_info())\nFile \"collect_env.py\", line 232, in get_env_info\ncudnn_version=get_cudnn_version(run_lambda),\nFile \"collect_env.py\", line 112, in get_cudnn_version\nrc, out, _ = run_lambda(cudnn_cmd)\nFile \"collect_env.py\", line 43, in run\nerr = err.decode(\"ascii\")\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 0: ordinal not in range(128)\n\n\nPyTorch Version (e.g., 1.0):\n\n\nOS (e.g., Linux):\n\n\nHow you installed PyTorch (conda, pip, source):\nconda install pytorch -c pytorch\npip3 install torchvision\n\n\nBuild command you used (if compiling from source):\n\n\nPython version: Python 3.7\n\n\nCUDA/cuDNN version:\nCUDA Version 9.1.85\n\n\nCUDA Patch Version 9.1.85.3\n\nGPU models and configuration:  GTX 1060\nAny other relevant information:\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. BrokenPipeError: [Errno 32] Broken pipe \r\n1.\r\n1.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n\r\n  File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n\r\n  File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n\r\n  File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n\r\n  File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n\r\n  File \"C:\\Users\\Liu\\Anaconda2\\envs\\py3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n**Collecting environment information...\r\nTraceback (most recent call last):\r\n  File \"collect_env.py\", line 348, in <module>\r\n    main()\r\n  File \"collect_env.py\", line 343, in main\r\n    output = get_pretty_env_info()\r\n  File \"collect_env.py\", line 338, in get_pretty_env_info\r\n    return pretty_str(get_env_info())\r\n  File \"collect_env.py\", line 232, in get_env_info\r\n    cudnn_version=get_cudnn_version(run_lambda),\r\n  File \"collect_env.py\", line 112, in get_cudnn_version\r\n    rc, out, _ = run_lambda(cudnn_cmd)\r\n  File \"collect_env.py\", line 43, in run\r\n    err = err.decode(\"ascii\")\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 0: ordinal not in range(128)**\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):  \r\nconda install pytorch -c pytorch\r\npip3 install torchvision\r\n\r\n - Build command you used (if compiling from source):\r\n - Python version: Python 3.7\r\n - CUDA/cuDNN version: \r\nCUDA Version 9.1.85\r\n\r\nCUDA Patch Version 9.1.85.3\r\n\r\n - GPU models and configuration:  GTX 1060 \r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}