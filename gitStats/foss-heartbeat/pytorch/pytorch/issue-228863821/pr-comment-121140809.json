{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121140809", "pull_request_review_id": 43170402, "id": 121140809, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTE0MDgwOQ==", "diff_hunk": "@@ -300,7 +302,24 @@ def __matmul__(self, other):\n             return self.unsqueeze(0).mm(other).squeeze(0)\n         elif dim_self == 2 and dim_other == 2:\n             return self.mm(other)\n-        raise ValueError(\"both arguments to __matmul__ need to be 1D or 2D, \"\n+        elif dim_self >= 2 and dim_other >= 2:\n+            # ensure each tensor is at least 3-dimensional\n+            self_exp_size = torch.Size((1,) * max(3 - self.dim(), 0) + self.size())\n+            other_exp_size = torch.Size((1,) * max(3 - other.dim(), 0) + other.size())\n+\n+            # expand the batch portion (i.e. cut off matrix dimensions and expand rest)\n+            expand_batch_portion = torch._C._infer_size(self_exp_size[:-2], other_exp_size[:-2])\n+\n+            # flatten expanded batches\n+            self_expanded = self.expand(*(expand_batch_portion + self_exp_size[-2:])) \\\n+                .contiguous().view(reduce(mul, expand_batch_portion), *self_exp_size[-2:])\n+            other_expanded = other.expand(*(expand_batch_portion + other_exp_size[-2:])) \\\n+                .contiguous().view(reduce(mul, expand_batch_portion), *other_exp_size[-2:])\n+\n+            # reshape batches back into result\n+            total_expansion = expand_batch_portion + (self_exp_size[-2], other_exp_size[-1])\n+            return self_expanded.bmm(other_expanded).view(*(total_expansion))", "path": "torch/tensor.py", "position": 30, "original_position": 30, "commit_id": "ca546930a8c9f31eab0a6fb79154ad4e985882e3", "original_commit_id": "0fb1f36420a17612e870b8c5c1851e7e85912ba3", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "We probably need to fix the `Variable` case for `__matmul__` to reflect the behavior of the new `__matmul__` as well.", "created_at": "2017-06-09T14:32:15Z", "updated_at": "2018-11-23T15:33:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/1563#discussion_r121140809", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1563", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121140809"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1563#discussion_r121140809"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1563"}}, "body_html": "<p>We probably need to fix the <code>Variable</code> case for <code>__matmul__</code> to reflect the behavior of the new <code>__matmul__</code> as well.</p>", "body_text": "We probably need to fix the Variable case for __matmul__ to reflect the behavior of the new __matmul__ as well.", "in_reply_to_id": 119902826}