{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14175", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14175/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14175/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14175/events", "html_url": "https://github.com/pytorch/pytorch/issues/14175", "id": 382042590, "node_id": "MDU6SXNzdWUzODIwNDI1OTA=", "number": 14175, "title": "Batched SVD using cuSolver", "user": {"login": "jjbouza", "id": 13842088, "node_id": "MDQ6VXNlcjEzODQyMDg4", "avatar_url": "https://avatars3.githubusercontent.com/u/13842088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jjbouza", "html_url": "https://github.com/jjbouza", "followers_url": "https://api.github.com/users/jjbouza/followers", "following_url": "https://api.github.com/users/jjbouza/following{/other_user}", "gists_url": "https://api.github.com/users/jjbouza/gists{/gist_id}", "starred_url": "https://api.github.com/users/jjbouza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jjbouza/subscriptions", "organizations_url": "https://api.github.com/users/jjbouza/orgs", "repos_url": "https://api.github.com/users/jjbouza/repos", "events_url": "https://api.github.com/users/jjbouza/events{/privacy}", "received_events_url": "https://api.github.com/users/jjbouza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-11-19T03:22:00Z", "updated_at": "2018-11-22T23:16:26Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>It seems there are several people working on batch mode linear algebra routines, i.e. <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"361307365\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/11796\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/11796/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/11796\">#11796</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"381428121\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/14071\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/14071/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/14071\">#14071</a> are active.</p>\n<p>Any plans for adding a batch mode SVD? This would be useful for certain implementations of group equivariant networks.</p>\n<p>I'm not completely familiar with the PyTorch codebase, but if I'm not mistaken the usual backend used for linear algebra computations on the GPU is MAGMA. I don't think MAGMA implements a batch SVD operation, but <a href=\"https://docs.nvidia.com/cuda/cusolver/index.html\" rel=\"nofollow\">cuSolver</a> does for small matrices (max 32x32). For larger matrices we can just fall back to the current approach.</p>\n<p>If no one else is planning on working on this I can take a look at it. The correct way to do this would be to model something like <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"345343185\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9949\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9949/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9949\">#9949</a>, right?</p>\n<p>I realize several others have made similar suggestions: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"347127890\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10172\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10172/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10172\">#10172</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"289037625\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4689\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4689/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4689\">#4689</a>. Those issues don't seem active however.</p>", "body_text": "It seems there are several people working on batch mode linear algebra routines, i.e. #11796 and #14071 are active.\nAny plans for adding a batch mode SVD? This would be useful for certain implementations of group equivariant networks.\nI'm not completely familiar with the PyTorch codebase, but if I'm not mistaken the usual backend used for linear algebra computations on the GPU is MAGMA. I don't think MAGMA implements a batch SVD operation, but cuSolver does for small matrices (max 32x32). For larger matrices we can just fall back to the current approach.\nIf no one else is planning on working on this I can take a look at it. The correct way to do this would be to model something like #9949, right?\nI realize several others have made similar suggestions: #10172, #4689. Those issues don't seem active however.", "body": "It seems there are several people working on batch mode linear algebra routines, i.e. #11796 and #14071 are active. \r\n\r\nAny plans for adding a batch mode SVD? This would be useful for certain implementations of group equivariant networks. \r\n\r\nI'm not completely familiar with the PyTorch codebase, but if I'm not mistaken the usual backend used for linear algebra computations on the GPU is MAGMA. I don't think MAGMA implements a batch SVD operation, but [cuSolver](https://docs.nvidia.com/cuda/cusolver/index.html) does for small matrices (max 32x32). For larger matrices we can just fall back to the current approach. \r\n\r\nIf no one else is planning on working on this I can take a look at it. The correct way to do this would be to model something like #9949, right? \r\n\r\nI realize several others have made similar suggestions: #10172, #4689. Those issues don't seem active however. "}