{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/440122286", "html_url": "https://github.com/pytorch/pytorch/issues/14175#issuecomment-440122286", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/14175", "id": 440122286, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDEyMjI4Ng==", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-20T03:13:16Z", "updated_at": "2018-11-20T03:21:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think it wouldn't be wise to paralyze users by asking them to use CPU for matrices larger than 32x32, and I am instead advocating for a uniform API use across CPU and GPU.</p>\n<p>Your idea utilizing <code>cuSolver</code> is a good one. On a related note, I think we can use MAGMA for SVD for batches with matrices larger than 32x32. The code would be very similar to LAPACK code for batching in a loop, which you should be able to find in <code>aten/src/ATen/native/BatchLinearAlgebra.cpp</code>. As far as the code base goes, I don't think <code>cuSolver</code> has been extensively used.</p>", "body_text": "I think it wouldn't be wise to paralyze users by asking them to use CPU for matrices larger than 32x32, and I am instead advocating for a uniform API use across CPU and GPU.\nYour idea utilizing cuSolver is a good one. On a related note, I think we can use MAGMA for SVD for batches with matrices larger than 32x32. The code would be very similar to LAPACK code for batching in a loop, which you should be able to find in aten/src/ATen/native/BatchLinearAlgebra.cpp. As far as the code base goes, I don't think cuSolver has been extensively used.", "body": "I think it wouldn't be wise to paralyze users by asking them to use CPU for matrices larger than 32x32, and I am instead advocating for a uniform API use across CPU and GPU.\r\n\r\nYour idea utilizing `cuSolver` is a good one. On a related note, I think we can use MAGMA for SVD for batches with matrices larger than 32x32. The code would be very similar to LAPACK code for batching in a loop, which you should be able to find in `aten/src/ATen/native/BatchLinearAlgebra.cpp`. As far as the code base goes, I don't think `cuSolver` has been extensively used."}