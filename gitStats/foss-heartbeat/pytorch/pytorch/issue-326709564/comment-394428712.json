{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/394428712", "html_url": "https://github.com/pytorch/pytorch/pull/7873#issuecomment-394428712", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7873", "id": 394428712, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDQyODcxMg==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-04T17:08:09Z", "updated_at": "2018-06-04T17:08:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For flipping, save for some alignment issues (which can be avoided for sure by e.g. using 1024x1024 tensor), you accesses are still contiguous (elements that are adjacent in original tensor would still be adjacent in the flipped one, even if they are in the different order), so comparing with a regular pointwise op is better. You might want to run your comparison against some real 2d tensor that cannot be collapsed to 1d (you can create it by e.g. running torch.chunk on the 1st dim), to add some index math that you necessarily have for flipping.</p>", "body_text": "For flipping, save for some alignment issues (which can be avoided for sure by e.g. using 1024x1024 tensor), you accesses are still contiguous (elements that are adjacent in original tensor would still be adjacent in the flipped one, even if they are in the different order), so comparing with a regular pointwise op is better. You might want to run your comparison against some real 2d tensor that cannot be collapsed to 1d (you can create it by e.g. running torch.chunk on the 1st dim), to add some index math that you necessarily have for flipping.", "body": "For flipping, save for some alignment issues (which can be avoided for sure by e.g. using 1024x1024 tensor), you accesses are still contiguous (elements that are adjacent in original tensor would still be adjacent in the flipped one, even if they are in the different order), so comparing with a regular pointwise op is better. You might want to run your comparison against some real 2d tensor that cannot be collapsed to 1d (you can create it by e.g. running torch.chunk on the 1st dim), to add some index math that you necessarily have for flipping. "}