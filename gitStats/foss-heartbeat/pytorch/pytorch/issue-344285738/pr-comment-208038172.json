{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208038172", "pull_request_review_id": 143770920, "id": 208038172, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwODAzODE3Mg==", "diff_hunk": "@@ -509,10 +515,103 @@ def test_gloo_backend(self):\n     @skip_if_not_multigpu\n     @skip_if_not_nccl\n     def test_nccl_backend(self):\n-        store = c10d.TCPStore('localhost', self.port, self.rank == 0)\n+        store = c10d.TCPStore('localhost', self.port, self.is_master)\n         process_group = c10d.ProcessGroupNCCL(store, self.rank, self.world_size)\n         self._test_ddp_with_process_group(process_group)\n \n+    @skip_if_not_multigpu\n+    def test_dist_broadcast_coalesced(self):\n+        # Set up process group.\n+        store = c10d.TCPStore('localhost', self.port, self.is_master)\n+        options = c10d.ProcessGroupGloo.Options()\n+        options.devices = [c10d.ProcessGroupGloo.create_tcp_device(interface=\"lo\")]\n+        process_group = c10d.ProcessGroupGloo(store, self.rank, self.world_size, options)\n+\n+        device = torch.device('cuda')\n+\n+        target = torch.arange(10, dtype=torch.float64, device=device).chunk(2)\n+\n+        if self.is_master:\n+            # All processes should have these tensors in the end.\n+            tensors = target\n+        else:\n+            # Non-master processes start with empty tensors and should be\n+            # filled with the tensors from the master.\n+            tensors = torch.zeros(10, device=device).chunk(2)\n+\n+        c10d._dist_broadcast_coalesced(\n+            tensors,\n+            buffer_size=25 * MB,\n+            process_group=process_group)\n+\n+        if not self.is_master:\n+            self.assertEqual(tensors, target)\n+\n+    @skip_if_not_multigpu\n+    def test_sync_params_no_buffers(self):\n+        # Set up process group.\n+        store = c10d.TCPStore('localhost', self.port, self.is_master)\n+        options = c10d.ProcessGroupGloo.Options()\n+        options.devices = [c10d.ProcessGroupGloo.create_tcp_device(interface=\"lo\")]\n+        process_group = c10d.ProcessGroupGloo(store, self.rank, self.world_size, options)\n+\n+        # Use all available devices on every process here (data is small, so should be fine).\n+        devices = list(range(torch.cuda.device_count()))\n+        target = torch.arange(10, dtype=torch.float64, device='cuda:0').chunk(2)\n+        parameter_data = [target]\n+        parameter_data += [torch.zeros(10, device=torch.device('cuda', d)).chunk(2) for d in devices[1:]]\n+        buffer_data = [[]] * len(parameter_data)\n+\n+        c10d._sync_params(\n+            process_group,\n+            parameter_data=parameter_data,\n+            buffer_data=buffer_data,\n+            devices=devices,\n+            broadcast_bucket_size=25 * MB,\n+            broadcast_buffers=False)\n+\n+        for device_data in parameter_data:\n+            for i, parameter in enumerate(device_data):\n+                self.assertEqual(parameter, target[i])\n+\n+    @skip_if_not_multigpu\n+    def test_sync_params_with_buffers(self):\n+        # Set up process group.\n+        store = c10d.TCPStore('localhost', self.port, self.is_master)\n+        options = c10d.ProcessGroupGloo.Options()\n+        options.devices = [c10d.ProcessGroupGloo.create_tcp_device(interface=\"lo\")]\n+        process_group = c10d.ProcessGroupGloo(store, self.rank, self.world_size, options)\n+\n+        devices = list(range(torch.cuda.device_count()))\n+        target = torch.arange(10, dtype=torch.float64, device='cuda:0').chunk(2)\n+        parameter_data = [target]\n+        parameter_data += [torch.zeros(10, device=torch.device('cuda', d)).chunk(2) for d in devices[1:]]\n+\n+        # sync_params should do a dist_broadcast for buffers, so we only populate the master buffers and\n+        # then check that other processes' tensors end up matching.\n+\n+        if self.is_master:\n+            buffer_data = [target]\n+            buffer_data += [torch.zeros(10, device=torch.device('cuda', d)).chunk(2) for d in devices[1:]]\n+        else:\n+            buffer_data = [torch.zeros(10, device=torch.device('cuda', d)).chunk(2) for d in devices]\n+\n+        c10d._sync_params(\n+            process_group,\n+            parameter_data=parameter_data,\n+            buffer_data=buffer_data,\n+            devices=devices,\n+            broadcast_bucket_size=25 * MB,", "path": "test/test_c10d.py", "position": null, "original_position": 120, "commit_id": "ec7d38172ea9e1ed54bc0fb1774f54d51fe5e035", "original_commit_id": "e115f43682408e7f3e7354f0807df4fa77690bcc", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "Good point", "created_at": "2018-08-06T21:41:02Z", "updated_at": "2018-11-23T15:48:50Z", "html_url": "https://github.com/pytorch/pytorch/pull/9805#discussion_r208038172", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9805", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208038172"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9805#discussion_r208038172"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9805"}}, "body_html": "<p>Good point</p>", "body_text": "Good point", "in_reply_to_id": 208035109}