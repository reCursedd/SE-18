{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13176", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13176/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13176/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13176/events", "html_url": "https://github.com/pytorch/pytorch/issues/13176", "id": 374529711, "node_id": "MDU6SXNzdWUzNzQ1Mjk3MTE=", "number": 13176, "title": "Edits to torch/lib/c10d/ProcessGroupGloo.cpp (and possibly other files) do not successfully recompile", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "anderspapitto", "id": 1388690, "node_id": "MDQ6VXNlcjEzODg2OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1388690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anderspapitto", "html_url": "https://github.com/anderspapitto", "followers_url": "https://api.github.com/users/anderspapitto/followers", "following_url": "https://api.github.com/users/anderspapitto/following{/other_user}", "gists_url": "https://api.github.com/users/anderspapitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/anderspapitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anderspapitto/subscriptions", "organizations_url": "https://api.github.com/users/anderspapitto/orgs", "repos_url": "https://api.github.com/users/anderspapitto/repos", "events_url": "https://api.github.com/users/anderspapitto/events{/privacy}", "received_events_url": "https://api.github.com/users/anderspapitto/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "anderspapitto", "id": 1388690, "node_id": "MDQ6VXNlcjEzODg2OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1388690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anderspapitto", "html_url": "https://github.com/anderspapitto", "followers_url": "https://api.github.com/users/anderspapitto/followers", "following_url": "https://api.github.com/users/anderspapitto/following{/other_user}", "gists_url": "https://api.github.com/users/anderspapitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/anderspapitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anderspapitto/subscriptions", "organizations_url": "https://api.github.com/users/anderspapitto/orgs", "repos_url": "https://api.github.com/users/anderspapitto/repos", "events_url": "https://api.github.com/users/anderspapitto/events{/privacy}", "received_events_url": "https://api.github.com/users/anderspapitto/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-10-26T20:06:53Z", "updated_at": "2018-10-26T20:30:05Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Fresh checkout of PyTorch on <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/c95fa4b9046085aefa91e76845f20918bd1054ef/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/c95fa4b9046085aefa91e76845f20918bd1054ef\"><tt>c95fa4b</tt></a></li>\n<li>Do a build <code>python setup.py build_deps develop</code></li>\n<li>Apply this patch:</li>\n</ol>\n<pre><code>diff --git a/torch/lib/c10d/ProcessGroupGloo.cpp b/torch/lib/c10d/ProcessGroupGloo.cpp\nindex 513cc0c7b..ed633da19 100644\n--- a/torch/lib/c10d/ProcessGroupGloo.cpp\n+++ b/torch/lib/c10d/ProcessGroupGloo.cpp\n@@ -499,6 +499,7 @@ void ProcessGroupGloo::createBroadcast(AlgorithmEntry&amp; entry) {\n // failure must be signaled through the Work future.\n //\n EntryType ProcessGroupGloo::construct(const AlgorithmKey&amp; key) {\n+  AT_ERROR(\"arglebargle\");\n   at::DeviceGuard deviceGuard;\n   auto entry = std::unique_ptr&lt;AlgorithmEntry&gt;(new AlgorithmEntry);\n   entry-&gt;key = key;\n</code></pre>\n<ol start=\"4\">\n<li>Do a build <code>python setup.py build_deps develop</code></li>\n<li>Run <code>python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced</code></li>\n</ol>\n<p>Test doesn't fail.</p>\n<p>You can induce a correct recompilation by deleting the <code>so</code> file in build:</p>\n<pre><code>$ rm build/lib.*/torch/_C*\n$ python setup.py build_deps develop\n$ python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced\nProcess process 1:\nProcess process 0:\nTraceback (most recent call last):\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"test/test_c10d.py\", line 354, in _run\n    getattr(self, self.id().split(\".\")[2])()\n  File \"test/test_c10d.py\", line 319, in wrapper\n    fn(self)\n  File \"test/test_c10d.py\", line 45, in wrapper\n    return func(*args, **kwargs)\n  File \"test/test_c10d.py\", line 763, in test_dist_broadcast_coalesced\n    buffer_size=10)\nRuntimeError: arglebargle (construct at ../torch/lib/c10d/ProcessGroupGloo.cpp:502)\n</code></pre>\n<h2>Expected behavior</h2>\n<p>Test fails with arglebargle.</p>\n<h2>Environment</h2>\n<p>On a devgpu005.ash6</p>\n<pre><code>(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake --version\ncmake version 3.12.2\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake3 --version\ncmake version 3.7.2\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] ninja --version\n1.8.2.git.kitware.dyndep-1.jobserver-1\n</code></pre>", "body_text": "\ud83d\udc1b Bug\nTo Reproduce\nSteps to reproduce the behavior:\n\nFresh checkout of PyTorch on c95fa4b\nDo a build python setup.py build_deps develop\nApply this patch:\n\ndiff --git a/torch/lib/c10d/ProcessGroupGloo.cpp b/torch/lib/c10d/ProcessGroupGloo.cpp\nindex 513cc0c7b..ed633da19 100644\n--- a/torch/lib/c10d/ProcessGroupGloo.cpp\n+++ b/torch/lib/c10d/ProcessGroupGloo.cpp\n@@ -499,6 +499,7 @@ void ProcessGroupGloo::createBroadcast(AlgorithmEntry& entry) {\n // failure must be signaled through the Work future.\n //\n EntryType ProcessGroupGloo::construct(const AlgorithmKey& key) {\n+  AT_ERROR(\"arglebargle\");\n   at::DeviceGuard deviceGuard;\n   auto entry = std::unique_ptr<AlgorithmEntry>(new AlgorithmEntry);\n   entry->key = key;\n\n\nDo a build python setup.py build_deps develop\nRun python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced\n\nTest doesn't fail.\nYou can induce a correct recompilation by deleting the so file in build:\n$ rm build/lib.*/torch/_C*\n$ python setup.py build_deps develop\n$ python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced\nProcess process 1:\nProcess process 0:\nTraceback (most recent call last):\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"test/test_c10d.py\", line 354, in _run\n    getattr(self, self.id().split(\".\")[2])()\n  File \"test/test_c10d.py\", line 319, in wrapper\n    fn(self)\n  File \"test/test_c10d.py\", line 45, in wrapper\n    return func(*args, **kwargs)\n  File \"test/test_c10d.py\", line 763, in test_dist_broadcast_coalesced\n    buffer_size=10)\nRuntimeError: arglebargle (construct at ../torch/lib/c10d/ProcessGroupGloo.cpp:502)\n\nExpected behavior\nTest fails with arglebargle.\nEnvironment\nOn a devgpu005.ash6\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake --version\ncmake version 3.12.2\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake3 --version\ncmake version 3.7.2\n\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] ninja --version\n1.8.2.git.kitware.dyndep-1.jobserver-1", "body": "## \ud83d\udc1b Bug\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Fresh checkout of PyTorch on c95fa4b9046085aefa91e76845f20918bd1054ef\r\n2. Do a build `python setup.py build_deps develop`\r\n3. Apply this patch:\r\n\r\n```\r\ndiff --git a/torch/lib/c10d/ProcessGroupGloo.cpp b/torch/lib/c10d/ProcessGroupGloo.cpp\r\nindex 513cc0c7b..ed633da19 100644\r\n--- a/torch/lib/c10d/ProcessGroupGloo.cpp\r\n+++ b/torch/lib/c10d/ProcessGroupGloo.cpp\r\n@@ -499,6 +499,7 @@ void ProcessGroupGloo::createBroadcast(AlgorithmEntry& entry) {\r\n // failure must be signaled through the Work future.\r\n //\r\n EntryType ProcessGroupGloo::construct(const AlgorithmKey& key) {\r\n+  AT_ERROR(\"arglebargle\");\r\n   at::DeviceGuard deviceGuard;\r\n   auto entry = std::unique_ptr<AlgorithmEntry>(new AlgorithmEntry);\r\n   entry->key = key;\r\n```\r\n\r\n4. Do a build `python setup.py build_deps develop`\r\n5. Run `python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced`\r\n\r\nTest doesn't fail.\r\n\r\nYou can induce a correct recompilation by deleting the `so` file in build:\r\n\r\n```\r\n$ rm build/lib.*/torch/_C*\r\n$ python setup.py build_deps develop\r\n$ python test/test_c10d.py DistributedDataParallelTest.test_dist_broadcast_coalesced\r\nProcess process 1:\r\nProcess process 0:\r\nTraceback (most recent call last):\r\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\r\n    self.run()\r\n  File \"/home/ezyang/Dev/pytorch-repro-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"test/test_c10d.py\", line 354, in _run\r\n    getattr(self, self.id().split(\".\")[2])()\r\n  File \"test/test_c10d.py\", line 319, in wrapper\r\n    fn(self)\r\n  File \"test/test_c10d.py\", line 45, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"test/test_c10d.py\", line 763, in test_dist_broadcast_coalesced\r\n    buffer_size=10)\r\nRuntimeError: arglebargle (construct at ../torch/lib/c10d/ProcessGroupGloo.cpp:502)\r\n```\r\n\r\n## Expected behavior\r\n\r\nTest fails with arglebargle.\r\n\r\n## Environment\r\n\r\nOn a devgpu005.ash6\r\n\r\n```\r\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake --version\r\ncmake version 3.12.2\r\n\r\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\r\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] cmake3 --version\r\ncmake version 3.7.2\r\n\r\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\r\n(/home/ezyang/Dev/pytorch-repro-env) [ezyang@devgpu005.ash6 ~/Dev/pytorch-repro] ninja --version\r\n1.8.2.git.kitware.dyndep-1.jobserver-1\r\n```\r\n\r\n"}