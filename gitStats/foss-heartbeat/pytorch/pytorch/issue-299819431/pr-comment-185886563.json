{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185886563", "pull_request_review_id": 117365791, "id": 185886563, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTg4NjU2Mw==", "diff_hunk": "@@ -1,239 +1,394 @@\n import math\n+import types\n import random\n+import warnings\n \n import torch\n \n+##########################\n+# base initializer\n+##########################\n \n-def calculate_gain(nonlinearity, param=None):\n-    \"\"\"Return the recommended gain value for the given nonlinearity function.\n-    The values are as follows:\n \n-    ============ ==========================================\n-    nonlinearity gain\n-    ============ ==========================================\n-    linear       :math:`1`\n-    conv{1,2,3}d :math:`1`\n-    sigmoid      :math:`1`\n-    tanh         :math:`5 / 3`\n-    relu         :math:`\\sqrt{2}`\n-    leaky_relu   :math:`\\sqrt{2 / (1 + negative\\_slope^2)}`\n-    ============ ==========================================\n+class Initializer(object):\n+    \"\"\"\n+    Base class for all initializations.\n+    \"\"\"\n+    def __new__(cls, *non_tensor_args, **non_tensor_kwargs):\n+        first = None\n+        if len(non_tensor_args) > 0:\n+            first = non_tensor_args[0]\n+        if first is None:\n+            return object.__new__(cls)\n+        if isinstance(first, (torch.Tensor, torch.autograd.Variable)):\n+            return cls(*non_tensor_args[1:], **non_tensor_kwargs)(first)\n+        else:\n+            return object.__new__(cls)\n+\n+##########################\n+# initializers\n+##########################\n+\n+\n+class Ones(Initializer):\n+    r\"\"\"Fills the input Tensor with ones.\n \n     Args:\n-        nonlinearity: the nonlinear function (`nn.functional` name)\n-        param: optional parameter for the nonlinear function\n+        tensor: an n-dimensional `torch.Tensor`\n \n     Examples:\n-        >>> gain = nn.init.calculate_gain('leaky_relu')\n+        >>> w = torch.Tensor(3, 5)\n+        >>> nn.init.ones_(w)\n+        >>> ones_init = nn.init.ones_()\n+        >>> ones_init(w)\n     \"\"\"\n-    linear_fns = ['linear', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d', 'conv_transpose2d', 'conv_transpose3d']\n-    if nonlinearity in linear_fns or nonlinearity == 'sigmoid':\n-        return 1\n-    elif nonlinearity == 'tanh':\n-        return 5.0 / 3\n-    elif nonlinearity == 'relu':\n-        return math.sqrt(2.0)\n-    elif nonlinearity == 'leaky_relu':\n-        if param is None:\n-            negative_slope = 0.01\n-        elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float):\n-            # True/False are instances of int, hence check above\n-            negative_slope = param\n-        else:\n-            raise ValueError(\"negative_slope {} not a valid number\".format(param))\n-        return math.sqrt(2.0 / (1 + negative_slope ** 2))\n-    else:\n-        raise ValueError(\"Unsupported nonlinearity {}\".format(nonlinearity))\n+    def __call__(self, tensor):\n+        with torch.no_grad():\n+            return tensor.fill_(1)\n \n \n-def uniform(tensor, a=0, b=1):\n-    \"\"\"Fills the input Tensor or Variable with values drawn from the uniform\n-    distribution :math:`U(a, b)`.\n+class Zeros(Initializer):", "path": "torch/nn/init.py", "position": 87, "original_position": 87, "commit_id": "1b8eecd6b4922b1b50e970563bc446ac4b997e9f", "original_commit_id": "1b8eecd6b4922b1b50e970563bc446ac4b997e9f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Can you please reorder those in the same way as they appeared in the original file? Right now it's hard to review them, because the diffs are really messed up", "created_at": "2018-05-03T17:54:54Z", "updated_at": "2018-11-23T15:43:35Z", "html_url": "https://github.com/pytorch/pytorch/pull/5382#discussion_r185886563", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5382", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185886563"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5382#discussion_r185886563"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5382"}}, "body_html": "<p>Can you please reorder those in the same way as they appeared in the original file? Right now it's hard to review them, because the diffs are really messed up</p>", "body_text": "Can you please reorder those in the same way as they appeared in the original file? Right now it's hard to review them, because the diffs are really messed up"}