{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1347", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1347/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1347/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1347/events", "html_url": "https://github.com/pytorch/pytorch/issues/1347", "id": 223937281, "node_id": "MDU6SXNzdWUyMjM5MzcyODE=", "number": 1347, "title": "tensor.new() can have nan's, and some pytorch code is thus unsafe", "user": {"login": "ankitkv", "id": 3175634, "node_id": "MDQ6VXNlcjMxNzU2MzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3175634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankitkv", "html_url": "https://github.com/ankitkv", "followers_url": "https://api.github.com/users/ankitkv/followers", "following_url": "https://api.github.com/users/ankitkv/following{/other_user}", "gists_url": "https://api.github.com/users/ankitkv/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankitkv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankitkv/subscriptions", "organizations_url": "https://api.github.com/users/ankitkv/orgs", "repos_url": "https://api.github.com/users/ankitkv/repos", "events_url": "https://api.github.com/users/ankitkv/events{/privacy}", "received_events_url": "https://api.github.com/users/ankitkv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-04-24T20:12:59Z", "updated_at": "2017-04-25T19:44:14Z", "closed_at": "2017-04-25T19:44:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>tensor.new()</code> does not initialize memory, so it could end up containing <code>nan</code>'s. This could be unsafe in some cases.</p>\n<p>For example, in <code>torch/autograd/variable.py</code>:</p>\n<pre><code>def mm(self, matrix):\n    output = Variable(self.data.new(self.data.size(0), matrix.data.size(1)))\n    return self._static_blas(Addmm, (output, 0, 1, self, matrix), False)\n\ndef bmm(self, batch):\n    output = Variable(self.data.new(self.data.size(0), self.data.size(1),\n                                    batch.data.size(2)))\n    return self._static_blas(Baddbmm, (output, 0, 1, self, batch), False)\n\ndef mv(self, vector):\n    output = Variable(self.data.new(self.data.size(0)))\n    return self._static_blas(Addmv, (output, 0, 1, self, vector), False)\n\ndef ger(self, vector):\n    output = Variable(self.data.new(self.data.size(0), vector.data.size(0)))\n    return self._static_blas(Addr, (output, 0, 1, self, vector), False)\n</code></pre>\n<p>is dangerous because <code>output</code> could contain a <code>nan</code>, and even though <code>alpha</code> is being set to <code>0</code>, <code>nan * 0 = nan</code> and the result could contain a <code>nan</code> (I had an optim test failing because of a <code>nan</code> originating this way).</p>\n<p>I haven't done an exhaustive search, so there may be other places in the code that could have this issue.</p>", "body_text": "tensor.new() does not initialize memory, so it could end up containing nan's. This could be unsafe in some cases.\nFor example, in torch/autograd/variable.py:\ndef mm(self, matrix):\n    output = Variable(self.data.new(self.data.size(0), matrix.data.size(1)))\n    return self._static_blas(Addmm, (output, 0, 1, self, matrix), False)\n\ndef bmm(self, batch):\n    output = Variable(self.data.new(self.data.size(0), self.data.size(1),\n                                    batch.data.size(2)))\n    return self._static_blas(Baddbmm, (output, 0, 1, self, batch), False)\n\ndef mv(self, vector):\n    output = Variable(self.data.new(self.data.size(0)))\n    return self._static_blas(Addmv, (output, 0, 1, self, vector), False)\n\ndef ger(self, vector):\n    output = Variable(self.data.new(self.data.size(0), vector.data.size(0)))\n    return self._static_blas(Addr, (output, 0, 1, self, vector), False)\n\nis dangerous because output could contain a nan, and even though alpha is being set to 0, nan * 0 = nan and the result could contain a nan (I had an optim test failing because of a nan originating this way).\nI haven't done an exhaustive search, so there may be other places in the code that could have this issue.", "body": "`tensor.new()` does not initialize memory, so it could end up containing `nan`'s. This could be unsafe in some cases.\r\n\r\nFor example, in `torch/autograd/variable.py`:\r\n```\r\ndef mm(self, matrix):\r\n    output = Variable(self.data.new(self.data.size(0), matrix.data.size(1)))\r\n    return self._static_blas(Addmm, (output, 0, 1, self, matrix), False)\r\n\r\ndef bmm(self, batch):\r\n    output = Variable(self.data.new(self.data.size(0), self.data.size(1),\r\n                                    batch.data.size(2)))\r\n    return self._static_blas(Baddbmm, (output, 0, 1, self, batch), False)\r\n\r\ndef mv(self, vector):\r\n    output = Variable(self.data.new(self.data.size(0)))\r\n    return self._static_blas(Addmv, (output, 0, 1, self, vector), False)\r\n\r\ndef ger(self, vector):\r\n    output = Variable(self.data.new(self.data.size(0), vector.data.size(0)))\r\n    return self._static_blas(Addr, (output, 0, 1, self, vector), False)\r\n```\r\nis dangerous because `output` could contain a `nan`, and even though `alpha` is being set to `0`, `nan * 0 = nan` and the result could contain a `nan` (I had an optim test failing because of a `nan` originating this way).\r\n\r\nI haven't done an exhaustive search, so there may be other places in the code that could have this issue."}