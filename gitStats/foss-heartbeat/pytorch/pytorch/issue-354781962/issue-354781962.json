{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10948", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10948/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10948/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10948/events", "html_url": "https://github.com/pytorch/pytorch/issues/10948", "id": 354781962, "node_id": "MDU6SXNzdWUzNTQ3ODE5NjI=", "number": 10948, "title": "Poisson sample() broken for certain sample shapes on CPU", "user": {"login": "connorhargus", "id": 3538879, "node_id": "MDQ6VXNlcjM1Mzg4Nzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/3538879?v=4", "gravatar_id": "", "url": "https://api.github.com/users/connorhargus", "html_url": "https://github.com/connorhargus", "followers_url": "https://api.github.com/users/connorhargus/followers", "following_url": "https://api.github.com/users/connorhargus/following{/other_user}", "gists_url": "https://api.github.com/users/connorhargus/gists{/gist_id}", "starred_url": "https://api.github.com/users/connorhargus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/connorhargus/subscriptions", "organizations_url": "https://api.github.com/users/connorhargus/orgs", "repos_url": "https://api.github.com/users/connorhargus/repos", "events_url": "https://api.github.com/users/connorhargus/events{/privacy}", "received_events_url": "https://api.github.com/users/connorhargus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-08-28T15:23:19Z", "updated_at": "2018-08-31T20:21:07Z", "closed_at": "2018-08-31T20:21:07Z", "author_association": "NONE", "body_html": "<p>Using a sample_shape with 1 for the final value (i.e. t.size([2, 1]), but not t.size([1, 2]) is giving me garbage outputs when I call sample() on the CPU (not when I move rates in the example below to the GPU):</p>\n<h2>Code example</h2>\n<pre><code>import torch as t\nfrom torch.distributions import Poisson, Bernoulli\nimport random\nimport numpy as np\n\nrandom.seed(0)\nt.manual_seed(0)\nt.cuda.manual_seed(0)\nnp.random.seed(0)\n\nrates = t.tensor(60 * [0.5000], requires_grad=True)\n\ndist = Poisson(rate=rates)\n\ns = dist.sample(t.Size([2, 1]))\nprint(rates.shape)\nprint(s.shape)\nprint(s)\n</code></pre>\n<p>Output:</p>\n<pre><code>torch.Size([60])\ntorch.Size([2, 1, 60])\ntensor([[[                   2.,                    1.,                    1.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    1.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    1.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    1.,                    0.,\n                             0.,                    1.,                    0.,\n                             0.,                    1.,                    3.,\n                             0.,                    2.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    0.,                    1.,\n                             2.,                    0.,                    1.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.]],\n\n        [[                   0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n          -9223372036854775808.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.]]])\n</code></pre>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: NVS 510<br>\nGPU 1: GeForce GTX TITAN X<br>\nGPU 2: GeForce GTX TITAN X</p>\n<p>Nvidia driver version: 390.30<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1<br>\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.14.0)<br>\n[pip] numpydoc (0.7.0)<br>\n[pip] torch (0.4.1)<br>\n[pip] torchvision (0.2.1)<br>\n[conda] cuda90                    1.0                  h6433d27_0    pytorch<br>\n[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch<br>\n[conda] torchvision               0.2.1                    py36_1    pytorch</p>", "body_text": "Using a sample_shape with 1 for the final value (i.e. t.size([2, 1]), but not t.size([1, 2]) is giving me garbage outputs when I call sample() on the CPU (not when I move rates in the example below to the GPU):\nCode example\nimport torch as t\nfrom torch.distributions import Poisson, Bernoulli\nimport random\nimport numpy as np\n\nrandom.seed(0)\nt.manual_seed(0)\nt.cuda.manual_seed(0)\nnp.random.seed(0)\n\nrates = t.tensor(60 * [0.5000], requires_grad=True)\n\ndist = Poisson(rate=rates)\n\ns = dist.sample(t.Size([2, 1]))\nprint(rates.shape)\nprint(s.shape)\nprint(s)\n\nOutput:\ntorch.Size([60])\ntorch.Size([2, 1, 60])\ntensor([[[                   2.,                    1.,                    1.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    1.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    1.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    1.,                    0.,\n                             0.,                    1.,                    0.,\n                             0.,                    1.,                    3.,\n                             0.,                    2.,                    0.,\n                             1.,                    0.,                    0.,\n                             0.,                    0.,                    1.,\n                             0.,                    0.,                    1.,\n                             2.,                    0.,                    1.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.]],\n\n        [[                   0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0., -9223372036854775808.,\n          -9223372036854775808.,                    0.,                    0.,\n                             0.,                    0.,                    0.,\n                             0.,                    0.,                    0.]]])\n\nSystem Info\nCollecting environment information...\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: NVS 510\nGPU 1: GeForce GTX TITAN X\nGPU 2: GeForce GTX TITAN X\nNvidia driver version: 390.30\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\nVersions of relevant libraries:\n[pip] numpy (1.14.0)\n[pip] numpydoc (0.7.0)\n[pip] torch (0.4.1)\n[pip] torchvision (0.2.1)\n[conda] cuda90                    1.0                  h6433d27_0    pytorch\n[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch", "body": "Using a sample_shape with 1 for the final value (i.e. t.size([2, 1]), but not t.size([1, 2]) is giving me garbage outputs when I call sample() on the CPU (not when I move rates in the example below to the GPU):\r\n\r\n## Code example\r\n\r\n```\r\nimport torch as t\r\nfrom torch.distributions import Poisson, Bernoulli\r\nimport random\r\nimport numpy as np\r\n\r\nrandom.seed(0)\r\nt.manual_seed(0)\r\nt.cuda.manual_seed(0)\r\nnp.random.seed(0)\r\n\r\nrates = t.tensor(60 * [0.5000], requires_grad=True)\r\n\r\ndist = Poisson(rate=rates)\r\n\r\ns = dist.sample(t.Size([2, 1]))\r\nprint(rates.shape)\r\nprint(s.shape)\r\nprint(s)\r\n```\r\n\r\nOutput:\r\n```\r\ntorch.Size([60])\r\ntorch.Size([2, 1, 60])\r\ntensor([[[                   2.,                    1.,                    1.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             1.,                    0.,                    0.,\r\n                             0.,                    1.,                    0.,\r\n                             1.,                    0.,                    0.,\r\n                             0.,                    0.,                    1.,\r\n                             0.,                    1.,                    0.,\r\n                             0.,                    0.,                    1.,\r\n                             0.,                    1.,                    0.,\r\n                             0.,                    1.,                    0.,\r\n                             0.,                    1.,                    3.,\r\n                             0.,                    2.,                    0.,\r\n                             1.,                    0.,                    0.,\r\n                             0.,                    0.,                    1.,\r\n                             0.,                    0.,                    1.,\r\n                             2.,                    0.,                    1.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.]],\r\n\r\n        [[                   0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0., -9223372036854775808.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0., -9223372036854775808.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0., -9223372036854775808.,\r\n          -9223372036854775808.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.,\r\n                             0.,                    0.,                    0.]]])\r\n```\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration:\r\nGPU 0: NVS 510\r\nGPU 1: GeForce GTX TITAN X\r\nGPU 2: GeForce GTX TITAN X\r\n\r\nNvidia driver version: 390.30\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.2.1\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.0)\r\n[pip] numpydoc (0.7.0)\r\n[pip] torch (0.4.1)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda90                    1.0                  h6433d27_0    pytorch\r\n[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch\r\n[conda] torchvision               0.2.1                    py36_1    pytorch"}