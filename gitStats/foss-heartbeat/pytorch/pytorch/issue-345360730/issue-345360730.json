{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9951", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9951/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9951/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9951/events", "html_url": "https://github.com/pytorch/pytorch/issues/9951", "id": 345360730, "node_id": "MDU6SXNzdWUzNDUzNjA3MzA=", "number": 9951, "title": "ONNX -> Caffe2 lstm issue", "user": {"login": "Kandarp2516", "id": 6077129, "node_id": "MDQ6VXNlcjYwNzcxMjk=", "avatar_url": "https://avatars2.githubusercontent.com/u/6077129?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kandarp2516", "html_url": "https://github.com/Kandarp2516", "followers_url": "https://api.github.com/users/Kandarp2516/followers", "following_url": "https://api.github.com/users/Kandarp2516/following{/other_user}", "gists_url": "https://api.github.com/users/Kandarp2516/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kandarp2516/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kandarp2516/subscriptions", "organizations_url": "https://api.github.com/users/Kandarp2516/orgs", "repos_url": "https://api.github.com/users/Kandarp2516/repos", "events_url": "https://api.github.com/users/Kandarp2516/events{/privacy}", "received_events_url": "https://api.github.com/users/Kandarp2516/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}, {"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-27T20:43:57Z", "updated_at": "2018-08-01T01:12:20Z", "closed_at": "2018-08-01T01:12:20Z", "author_association": "NONE", "body_html": "<p>I am trying to convert ONNX model to caffe2. While trying to run:</p>\n<pre><code>import onnx\nimport caffe2.python.onnx.backend as backend\nfrom caffe2.python.onnx.backend import Caffe2Backend\n\ndef main():\n    model_onnx = onnx.load(\"lstm.onnx\")\n    onnx.checker.check_model(model_onnx)\n    try:\n        input_size_net, predict_net = Caffe2Backend.onnx_graph_to_caffe2_net(model_onnx)\n        with open('init_net.pb', \"wb\") as f:\n            f.write(init_net.SerializeToString())\n            \n        with open('predict_net.pb', \"wb\") as f:\n            f.write(predict_net.SerializeToString())\n            \n    except (Exception, RuntimeError) as e:\n        print(e)\n        print(' ===== Unsuccessfull Caffe2 save run, exiting ===== ')\n        return\n        \n    finally:\n        print(' ===== Step 3 finished')\n\n</code></pre>\n<p>I get error:</p>\n<blockquote>\n<p>ONNX FATAL: list index out of range<br>\nTraceback (most recent call last):<br>\nFile \"check_pytorch.py\", line 13, in <br>\nprepared_backend = backend.prepare(model)<br>\nFile \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 788, in prepare<br>\ninit_net, predict_net = cls._onnx_model_to_caffe2_net(model, device, opset_version, False)<br>\nFile \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 976, in _onnx_model_to_caffe2_net<br>\nraise RuntimeError('ONNX conversion failed')<br>\nRuntimeError: ONNX conversion failed</p>\n</blockquote>\n<p>I found similar issue here: <a href=\"url\">https://discuss.pytorch.org/t/onnx-caffe2-for-recurrent-models-issue/21826</a></p>\n<p>It seems like a bug. Is there any easy work around for this?</p>\n<p>I am using anaconda and have installed caffe2 from caffe2 channel and onnx from exyang channel.</p>", "body_text": "I am trying to convert ONNX model to caffe2. While trying to run:\nimport onnx\nimport caffe2.python.onnx.backend as backend\nfrom caffe2.python.onnx.backend import Caffe2Backend\n\ndef main():\n    model_onnx = onnx.load(\"lstm.onnx\")\n    onnx.checker.check_model(model_onnx)\n    try:\n        input_size_net, predict_net = Caffe2Backend.onnx_graph_to_caffe2_net(model_onnx)\n        with open('init_net.pb', \"wb\") as f:\n            f.write(init_net.SerializeToString())\n            \n        with open('predict_net.pb', \"wb\") as f:\n            f.write(predict_net.SerializeToString())\n            \n    except (Exception, RuntimeError) as e:\n        print(e)\n        print(' ===== Unsuccessfull Caffe2 save run, exiting ===== ')\n        return\n        \n    finally:\n        print(' ===== Step 3 finished')\n\n\nI get error:\n\nONNX FATAL: list index out of range\nTraceback (most recent call last):\nFile \"check_pytorch.py\", line 13, in \nprepared_backend = backend.prepare(model)\nFile \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 788, in prepare\ninit_net, predict_net = cls._onnx_model_to_caffe2_net(model, device, opset_version, False)\nFile \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 976, in _onnx_model_to_caffe2_net\nraise RuntimeError('ONNX conversion failed')\nRuntimeError: ONNX conversion failed\n\nI found similar issue here: https://discuss.pytorch.org/t/onnx-caffe2-for-recurrent-models-issue/21826\nIt seems like a bug. Is there any easy work around for this?\nI am using anaconda and have installed caffe2 from caffe2 channel and onnx from exyang channel.", "body": "I am trying to convert ONNX model to caffe2. While trying to run:\r\n\r\n```\r\nimport onnx\r\nimport caffe2.python.onnx.backend as backend\r\nfrom caffe2.python.onnx.backend import Caffe2Backend\r\n\r\ndef main():\r\n    model_onnx = onnx.load(\"lstm.onnx\")\r\n    onnx.checker.check_model(model_onnx)\r\n    try:\r\n        input_size_net, predict_net = Caffe2Backend.onnx_graph_to_caffe2_net(model_onnx)\r\n        with open('init_net.pb', \"wb\") as f:\r\n            f.write(init_net.SerializeToString())\r\n            \r\n        with open('predict_net.pb', \"wb\") as f:\r\n            f.write(predict_net.SerializeToString())\r\n            \r\n    except (Exception, RuntimeError) as e:\r\n        print(e)\r\n        print(' ===== Unsuccessfull Caffe2 save run, exiting ===== ')\r\n        return\r\n        \r\n    finally:\r\n        print(' ===== Step 3 finished')\r\n\r\n```\r\nI get error:\r\n\r\n> ONNX FATAL: list index out of range\r\n> Traceback (most recent call last):\r\n>   File \"check_pytorch.py\", line 13, in <module>\r\n>     prepared_backend = backend.prepare(model)\r\n>   File \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 788, in prepare\r\n>     init_net, predict_net = cls._onnx_model_to_caffe2_net(model, device, opset_version, False)\r\n>   File \"/anaconda2/envs/py36_caffe2_onnx/lib/python3.6/site-packages/caffe2/python/onnx/backend.py\", line 976, in _onnx_model_to_caffe2_net\r\n>     raise RuntimeError('ONNX conversion failed')\r\n> RuntimeError: ONNX conversion failed\r\n\r\nI found similar issue here: [https://discuss.pytorch.org/t/onnx-caffe2-for-recurrent-models-issue/21826](url)\r\n\r\nIt seems like a bug. Is there any easy work around for this?\r\n\r\nI am using anaconda and have installed caffe2 from caffe2 channel and onnx from exyang channel.\r\n\r\n"}