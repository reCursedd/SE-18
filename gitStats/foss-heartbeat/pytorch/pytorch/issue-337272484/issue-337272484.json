{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9076", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9076/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9076/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9076/events", "html_url": "https://github.com/pytorch/pytorch/issues/9076", "id": 337272484, "node_id": "MDU6SXNzdWUzMzcyNzI0ODQ=", "number": 9076, "title": "RuntimeError: running_mean should contain 256 elements not 128", "user": {"login": "mabdullahrafique", "id": 32646935, "node_id": "MDQ6VXNlcjMyNjQ2OTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/32646935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mabdullahrafique", "html_url": "https://github.com/mabdullahrafique", "followers_url": "https://api.github.com/users/mabdullahrafique/followers", "following_url": "https://api.github.com/users/mabdullahrafique/following{/other_user}", "gists_url": "https://api.github.com/users/mabdullahrafique/gists{/gist_id}", "starred_url": "https://api.github.com/users/mabdullahrafique/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mabdullahrafique/subscriptions", "organizations_url": "https://api.github.com/users/mabdullahrafique/orgs", "repos_url": "https://api.github.com/users/mabdullahrafique/repos", "events_url": "https://api.github.com/users/mabdullahrafique/events{/privacy}", "received_events_url": "https://api.github.com/users/mabdullahrafique/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-01T08:00:53Z", "updated_at": "2018-07-01T13:36:32Z", "closed_at": "2018-07-01T13:36:21Z", "author_association": "NONE", "body_html": "<p>I am implementing dcgan with pytorch to generate mnist digits, but I am getting the following error:</p>\n<pre><code>`   Training Begins\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-14-d9dc58f7d539&gt; in &lt;module&gt;()\n     19         #First with real data\n     20         discriminator.zero_grad()\n---&gt; 21         output = discriminator(input)\n     22         d_loss = criterion(output, one)\n     23         d_loss.backward()\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--&gt; 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py in forward(self, input)\n     89     def forward(self, input):\n     90         for module in self._modules.values():\n---&gt; 91             input = module(input)\n     92         return input\n     93 \n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--&gt; 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py in forward(self, input)\n     47         return F.batch_norm(\n     48             input, self.running_mean, self.running_var, self.weight, self.bias,\n---&gt; 49             self.training or not self.track_running_stats, self.momentum, self.eps)\n     50 \n     51     def extra_repr(self):\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n   1192     return torch.batch_norm(\n   1193         input, weight, bias, running_mean, running_var,\n-&gt; 1194         training, momentum, eps, torch.backends.cudnn.enabled\n   1195     )\n   1196 \n\nRuntimeError: running_mean should contain 256 elements not 128\n\n`\n\n</code></pre>\n<blockquote>\n<p>here is  generator and discriminator architecture</p>\n</blockquote>\n<pre><code>`\n    #here noise_dim = 100 and gen_c = 64\n    generator = nn.Sequential(\n    nn.ConvTranspose2d(opt.noise_dim,opt.gen_c*8,4,1,0,bias = False),\n    nn.BatchNorm2d(opt.gen_c*8),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*8,opt.gen_c*4,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*4),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*4,opt.gen_c*2,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*2,opt.gen_c,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c,opt.img_c,4,2,1,bias = False),\n    nn.Tanh()\n    )\n\n    discriminator = nn.Sequential(\n    nn.Conv2d(opt.img_c,opt.disc_c,4,2,1,bias = False),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c,opt.disc_c*2,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*2,opt.disc_c*4,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*4,opt.disc_c*8,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*8,1,4,2,1,bias = False)\n    )\n\n    def weight_init(m):\n          class_name=m.__class__.__name__\n          if class_name.find('Conv')!=-1:\n                  m.weight.data.normal_(0,0.02)\n           elif class_name.find('Norm')!=-1:\n                  m.weight.data.normal_(1.0,0.02)\n\n\n      generator.apply(weight_init)\n      discriminator.apply(weight_init)`\n\n</code></pre>\n<blockquote>\n<p>I am importing dataset using</p>\n</blockquote>\n<pre><code>`transform = transforms.Compose([transforms.Resize(opt.img_size)\n                                ,transforms.ToTensor(),\n                                transforms.Normalize([0.5]*3,[0.5]*3)])\ndatasets= data.MNIST(root='mnist/',transform = transform , download = True)\ndataloader = to.utils.data.DataLoader(datasets,opt.batch_size,shuffle = True, num_workers = opt.workers)`\n</code></pre>\n<blockquote>\n<p>Here is configuration class for model</p>\n</blockquote>\n<pre><code>class Configuration:\n    learning_rate = 0.0002\n    noise_dim = 64 #Input Noise dimension\n    img_size = 64\n    img_c = 1 #Input Image channels\n    gen_c = 64 #generator channels\n    disc_c = 64 #Discriminator channels\n    beta = .5\n    batch_size = 32\n    number_epochs = 100\n    workers = 8 # Number of processors to be used by program\n    gpu = True\n    \nopt = Configuration()\n</code></pre>\n<ul>\n<li>PyTorch</li>\n<li>Installed pytorch using conda</li>\n<li>Jupyter notebook</li>\n<li>Ubuntu 16.04</li>\n<li>PyTorch version: 0.4.0</li>\n<li>8.0.61/6.0.21 version:</li>\n<li>Nvidia Gtx-1060</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>", "body_text": "I am implementing dcgan with pytorch to generate mnist digits, but I am getting the following error:\n`   Training Begins\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-14-d9dc58f7d539> in <module>()\n     19         #First with real data\n     20         discriminator.zero_grad()\n---> 21         output = discriminator(input)\n     22         d_loss = criterion(output, one)\n     23         d_loss.backward()\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--> 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py in forward(self, input)\n     89     def forward(self, input):\n     90         for module in self._modules.values():\n---> 91             input = module(input)\n     92         return input\n     93 \n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--> 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py in forward(self, input)\n     47         return F.batch_norm(\n     48             input, self.running_mean, self.running_var, self.weight, self.bias,\n---> 49             self.training or not self.track_running_stats, self.momentum, self.eps)\n     50 \n     51     def extra_repr(self):\n\n~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n   1192     return torch.batch_norm(\n   1193         input, weight, bias, running_mean, running_var,\n-> 1194         training, momentum, eps, torch.backends.cudnn.enabled\n   1195     )\n   1196 \n\nRuntimeError: running_mean should contain 256 elements not 128\n\n`\n\n\n\nhere is  generator and discriminator architecture\n\n`\n    #here noise_dim = 100 and gen_c = 64\n    generator = nn.Sequential(\n    nn.ConvTranspose2d(opt.noise_dim,opt.gen_c*8,4,1,0,bias = False),\n    nn.BatchNorm2d(opt.gen_c*8),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*8,opt.gen_c*4,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*4),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*4,opt.gen_c*2,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c*2,opt.gen_c,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(opt.gen_c,opt.img_c,4,2,1,bias = False),\n    nn.Tanh()\n    )\n\n    discriminator = nn.Sequential(\n    nn.Conv2d(opt.img_c,opt.disc_c,4,2,1,bias = False),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c,opt.disc_c*2,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*2,opt.disc_c*4,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*4,opt.disc_c*8,4,2,1,bias = False),\n    nn.BatchNorm2d(opt.gen_c*2),\n    nn.LeakyReLU(0.2,inplace = True),\n    \n    nn.Conv2d(opt.disc_c*8,1,4,2,1,bias = False)\n    )\n\n    def weight_init(m):\n          class_name=m.__class__.__name__\n          if class_name.find('Conv')!=-1:\n                  m.weight.data.normal_(0,0.02)\n           elif class_name.find('Norm')!=-1:\n                  m.weight.data.normal_(1.0,0.02)\n\n\n      generator.apply(weight_init)\n      discriminator.apply(weight_init)`\n\n\n\nI am importing dataset using\n\n`transform = transforms.Compose([transforms.Resize(opt.img_size)\n                                ,transforms.ToTensor(),\n                                transforms.Normalize([0.5]*3,[0.5]*3)])\ndatasets= data.MNIST(root='mnist/',transform = transform , download = True)\ndataloader = to.utils.data.DataLoader(datasets,opt.batch_size,shuffle = True, num_workers = opt.workers)`\n\n\nHere is configuration class for model\n\nclass Configuration:\n    learning_rate = 0.0002\n    noise_dim = 64 #Input Noise dimension\n    img_size = 64\n    img_c = 1 #Input Image channels\n    gen_c = 64 #generator channels\n    disc_c = 64 #Discriminator channels\n    beta = .5\n    batch_size = 32\n    number_epochs = 100\n    workers = 8 # Number of processors to be used by program\n    gpu = True\n    \nopt = Configuration()\n\n\nPyTorch\nInstalled pytorch using conda\nJupyter notebook\nUbuntu 16.04\nPyTorch version: 0.4.0\n8.0.61/6.0.21 version:\nNvidia Gtx-1060\nGCC version (if compiling from source):\nCMake version:\nVersions of any other relevant libraries:", "body": "I am implementing dcgan with pytorch to generate mnist digits, but I am getting the following error:\r\n```\r\n`   Training Begins\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-14-d9dc58f7d539> in <module>()\r\n     19         #First with real data\r\n     20         discriminator.zero_grad()\r\n---> 21         output = discriminator(input)\r\n     22         d_loss = criterion(output, one)\r\n     23         d_loss.backward()\r\n\r\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    489             result = self._slow_forward(*input, **kwargs)\r\n    490         else:\r\n--> 491             result = self.forward(*input, **kwargs)\r\n    492         for hook in self._forward_hooks.values():\r\n    493             hook_result = hook(self, input, result)\r\n\r\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py in forward(self, input)\r\n     89     def forward(self, input):\r\n     90         for module in self._modules.values():\r\n---> 91             input = module(input)\r\n     92         return input\r\n     93 \r\n\r\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    489             result = self._slow_forward(*input, **kwargs)\r\n    490         else:\r\n--> 491             result = self.forward(*input, **kwargs)\r\n    492         for hook in self._forward_hooks.values():\r\n    493             hook_result = hook(self, input, result)\r\n\r\n~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py in forward(self, input)\r\n     47         return F.batch_norm(\r\n     48             input, self.running_mean, self.running_var, self.weight, self.bias,\r\n---> 49             self.training or not self.track_running_stats, self.momentum, self.eps)\r\n     50 \r\n     51     def extra_repr(self):\r\n\r\n~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\r\n   1192     return torch.batch_norm(\r\n   1193         input, weight, bias, running_mean, running_var,\r\n-> 1194         training, momentum, eps, torch.backends.cudnn.enabled\r\n   1195     )\r\n   1196 \r\n\r\nRuntimeError: running_mean should contain 256 elements not 128\r\n\r\n`\r\n\r\n```\r\n> here is  generator and discriminator architecture \r\n\r\n```\r\n`\r\n    #here noise_dim = 100 and gen_c = 64\r\n    generator = nn.Sequential(\r\n    nn.ConvTranspose2d(opt.noise_dim,opt.gen_c*8,4,1,0,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*8),\r\n    nn.ReLU(True),\r\n    \r\n    nn.ConvTranspose2d(opt.gen_c*8,opt.gen_c*4,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*4),\r\n    nn.ReLU(True),\r\n    \r\n    nn.ConvTranspose2d(opt.gen_c*4,opt.gen_c*2,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*2),\r\n    nn.ReLU(True),\r\n    \r\n    nn.ConvTranspose2d(opt.gen_c*2,opt.gen_c,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c),\r\n    nn.ReLU(True),\r\n    \r\n    nn.ConvTranspose2d(opt.gen_c,opt.img_c,4,2,1,bias = False),\r\n    nn.Tanh()\r\n    )\r\n\r\n    discriminator = nn.Sequential(\r\n    nn.Conv2d(opt.img_c,opt.disc_c,4,2,1,bias = False),\r\n    nn.LeakyReLU(0.2,inplace = True),\r\n    \r\n    nn.Conv2d(opt.disc_c,opt.disc_c*2,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*2),\r\n    nn.LeakyReLU(0.2,inplace = True),\r\n    \r\n    nn.Conv2d(opt.disc_c*2,opt.disc_c*4,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*2),\r\n    nn.LeakyReLU(0.2,inplace = True),\r\n    \r\n    nn.Conv2d(opt.disc_c*4,opt.disc_c*8,4,2,1,bias = False),\r\n    nn.BatchNorm2d(opt.gen_c*2),\r\n    nn.LeakyReLU(0.2,inplace = True),\r\n    \r\n    nn.Conv2d(opt.disc_c*8,1,4,2,1,bias = False)\r\n    )\r\n\r\n    def weight_init(m):\r\n          class_name=m.__class__.__name__\r\n          if class_name.find('Conv')!=-1:\r\n                  m.weight.data.normal_(0,0.02)\r\n           elif class_name.find('Norm')!=-1:\r\n                  m.weight.data.normal_(1.0,0.02)\r\n\r\n\r\n      generator.apply(weight_init)\r\n      discriminator.apply(weight_init)`\r\n\r\n```\r\n> I am importing dataset using \r\n\r\n```\r\n`transform = transforms.Compose([transforms.Resize(opt.img_size)\r\n                                ,transforms.ToTensor(),\r\n                                transforms.Normalize([0.5]*3,[0.5]*3)])\r\ndatasets= data.MNIST(root='mnist/',transform = transform , download = True)\r\ndataloader = to.utils.data.DataLoader(datasets,opt.batch_size,shuffle = True, num_workers = opt.workers)`\r\n```\r\n\r\n> Here is configuration class for model\r\n```\r\nclass Configuration:\r\n    learning_rate = 0.0002\r\n    noise_dim = 64 #Input Noise dimension\r\n    img_size = 64\r\n    img_c = 1 #Input Image channels\r\n    gen_c = 64 #generator channels\r\n    disc_c = 64 #Discriminator channels\r\n    beta = .5\r\n    batch_size = 32\r\n    number_epochs = 100\r\n    workers = 8 # Number of processors to be used by program\r\n    gpu = True\r\n    \r\nopt = Configuration()\r\n```\r\n    \r\n\r\n- PyTorch \r\n- Installed pytorch using conda\r\n- Jupyter notebook\r\n- Ubuntu 16.04\r\n- PyTorch version: 0.4.0\r\n- 8.0.61/6.0.21 version:\r\n- Nvidia Gtx-1060\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Versions of any other relevant libraries:\r\n"}