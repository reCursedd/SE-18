{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355468615", "html_url": "https://github.com/pytorch/pytorch/pull/4493#issuecomment-355468615", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4493", "id": 355468615, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTQ2ODYxNQ==", "user": {"login": "yongjik", "id": 31876421, "node_id": "MDQ6VXNlcjMxODc2NDIx", "avatar_url": "https://avatars2.githubusercontent.com/u/31876421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongjik", "html_url": "https://github.com/yongjik", "followers_url": "https://api.github.com/users/yongjik/followers", "following_url": "https://api.github.com/users/yongjik/following{/other_user}", "gists_url": "https://api.github.com/users/yongjik/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongjik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongjik/subscriptions", "organizations_url": "https://api.github.com/users/yongjik/orgs", "repos_url": "https://api.github.com/users/yongjik/repos", "events_url": "https://api.github.com/users/yongjik/events{/privacy}", "received_events_url": "https://api.github.com/users/yongjik/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-05T04:10:01Z", "updated_at": "2018-01-05T04:10:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have measured execution times for various configurations, and found that the performance sometimes improves a lot, while it almost never worsens.</p>\n<p>A somewhat realistic example of big improvement is:</p>\n<pre><code>B = torch.cuda.FloatTensor(2000, 2000)\nA = torch.cuda.FloatTensor(2000, 500)\n\nidxs = (np.arange(500) * 7) % 500\nidxs = torch.cuda.LongTensor(idxs)\n\nB.index_add_(1, idxs, A)\n# On GTX 1080, execution time decreases 88% (1.195 ms -&gt; 0.138 ms).\n</code></pre>\n<p>One (arguably pathological) case where performance degrades is:</p>\n<pre><code>B = torch.cuda.FloatTensor(2000, 4)\nidxs = torch.cuda.LongTensor(np.zeros(40))\nB.index_fill_(1, idxs, 1.0)\n# On GTX 1080, execution time increases 22% (13.45 us -&gt; 16.41 us).\n</code></pre>", "body_text": "I have measured execution times for various configurations, and found that the performance sometimes improves a lot, while it almost never worsens.\nA somewhat realistic example of big improvement is:\nB = torch.cuda.FloatTensor(2000, 2000)\nA = torch.cuda.FloatTensor(2000, 500)\n\nidxs = (np.arange(500) * 7) % 500\nidxs = torch.cuda.LongTensor(idxs)\n\nB.index_add_(1, idxs, A)\n# On GTX 1080, execution time decreases 88% (1.195 ms -> 0.138 ms).\n\nOne (arguably pathological) case where performance degrades is:\nB = torch.cuda.FloatTensor(2000, 4)\nidxs = torch.cuda.LongTensor(np.zeros(40))\nB.index_fill_(1, idxs, 1.0)\n# On GTX 1080, execution time increases 22% (13.45 us -> 16.41 us).", "body": "I have measured execution times for various configurations, and found that the performance sometimes improves a lot, while it almost never worsens.\r\n\r\nA somewhat realistic example of big improvement is:\r\n\r\n    B = torch.cuda.FloatTensor(2000, 2000)\r\n    A = torch.cuda.FloatTensor(2000, 500)\r\n\r\n    idxs = (np.arange(500) * 7) % 500\r\n    idxs = torch.cuda.LongTensor(idxs)\r\n\r\n    B.index_add_(1, idxs, A)\r\n    # On GTX 1080, execution time decreases 88% (1.195 ms -> 0.138 ms).\r\n\r\nOne (arguably pathological) case where performance degrades is:\r\n\r\n    B = torch.cuda.FloatTensor(2000, 4)\r\n    idxs = torch.cuda.LongTensor(np.zeros(40))\r\n    B.index_fill_(1, idxs, 1.0)\r\n    # On GTX 1080, execution time increases 22% (13.45 us -> 16.41 us)."}