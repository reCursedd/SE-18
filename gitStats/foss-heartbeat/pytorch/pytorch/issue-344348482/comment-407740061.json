{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407740061", "html_url": "https://github.com/pytorch/pytorch/issues/9811#issuecomment-407740061", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9811", "id": 407740061, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzc0MDA2MQ==", "user": {"login": "0phoff", "id": 11853089, "node_id": "MDQ6VXNlcjExODUzMDg5", "avatar_url": "https://avatars3.githubusercontent.com/u/11853089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/0phoff", "html_url": "https://github.com/0phoff", "followers_url": "https://api.github.com/users/0phoff/followers", "following_url": "https://api.github.com/users/0phoff/following{/other_user}", "gists_url": "https://api.github.com/users/0phoff/gists{/gist_id}", "starred_url": "https://api.github.com/users/0phoff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/0phoff/subscriptions", "organizations_url": "https://api.github.com/users/0phoff/orgs", "repos_url": "https://api.github.com/users/0phoff/repos", "events_url": "https://api.github.com/users/0phoff/events{/privacy}", "received_events_url": "https://api.github.com/users/0phoff/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-25T12:38:37Z", "updated_at": "2018-07-25T12:40:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yeah but then the loss computations are not split over the different GPUs, thus increasing the training time.</p>\n<p>This problem is also bigger than computing losses in the forward pass of a module. Any network that outputs only one number will have this problem with the <code>DataParallel</code> class.</p>\n<p>Your point about the output being dependent on the number of GPUs is valid though. Not sure how to tackle this in a clean way...<br>\nMaybe the <code>DataParallel</code> class should have <code>reduce</code> and <code>size_average</code> parameters like the different loss functions for aggregating the output.</p>\n<p>Setting <code>reduce</code> to <strong>False</strong> would result in the current behaviour.<br>\nSetting it to <strong>True</strong> would mean we take the sum/average of the different output tensors (depending on <code>size_average</code>).<br>\nWe could even allow the creation of a new dimension if <code>reduce</code> is <strong>False</strong>  and the outputs are scalar tensors. I know this means the output is dependent on the number of GPUs but that would mean the user would want that behaviour in that case?</p>", "body_text": "Yeah but then the loss computations are not split over the different GPUs, thus increasing the training time.\nThis problem is also bigger than computing losses in the forward pass of a module. Any network that outputs only one number will have this problem with the DataParallel class.\nYour point about the output being dependent on the number of GPUs is valid though. Not sure how to tackle this in a clean way...\nMaybe the DataParallel class should have reduce and size_average parameters like the different loss functions for aggregating the output.\nSetting reduce to False would result in the current behaviour.\nSetting it to True would mean we take the sum/average of the different output tensors (depending on size_average).\nWe could even allow the creation of a new dimension if reduce is False  and the outputs are scalar tensors. I know this means the output is dependent on the number of GPUs but that would mean the user would want that behaviour in that case?", "body": "Yeah but then the loss computations are not split over the different GPUs, thus increasing the training time.\r\n\r\nThis problem is also bigger than computing losses in the forward pass of a module. Any network that outputs only one number will have this problem with the `DataParallel` class.\r\n\r\nYour point about the output being dependent on the number of GPUs is valid though. Not sure how to tackle this in a clean way...\r\nMaybe the `DataParallel` class should have `reduce` and `size_average` parameters like the different loss functions for aggregating the output. \r\n\r\nSetting `reduce` to __False__ would result in the current behaviour.  \r\nSetting it to __True__ would mean we take the sum/average of the different output tensors (depending on `size_average`).  \r\nWe could even allow the creation of a new dimension if `reduce` is __False__  and the outputs are scalar tensors. I know this means the output is dependent on the number of GPUs but that would mean the user would want that behaviour in that case?"}