{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/408019345", "html_url": "https://github.com/pytorch/pytorch/issues/9811#issuecomment-408019345", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9811", "id": 408019345, "node_id": "MDEyOklzc3VlQ29tbWVudDQwODAxOTM0NQ==", "user": {"login": "0phoff", "id": 11853089, "node_id": "MDQ6VXNlcjExODUzMDg5", "avatar_url": "https://avatars3.githubusercontent.com/u/11853089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/0phoff", "html_url": "https://github.com/0phoff", "followers_url": "https://api.github.com/users/0phoff/followers", "following_url": "https://api.github.com/users/0phoff/following{/other_user}", "gists_url": "https://api.github.com/users/0phoff/gists{/gist_id}", "starred_url": "https://api.github.com/users/0phoff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/0phoff/subscriptions", "organizations_url": "https://api.github.com/users/0phoff/orgs", "repos_url": "https://api.github.com/users/0phoff/repos", "events_url": "https://api.github.com/users/0phoff/events{/privacy}", "received_events_url": "https://api.github.com/users/0phoff/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-26T08:27:42Z", "updated_at": "2018-07-26T08:27:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7761488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sharpsy\">@sharpsy</a>, I did not think that one through...<br>\nI agree that this behaviour is not what we want. Setting <code>reduce=False</code> in the loss function works and fixes my issue in quite a clean way (you just have to compute the mean outside of the <code>DataParallel</code> class). I will continue to work like that (or compute the loss on one GPU outside of <code>DataParallel</code>).</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a>, I think making a vector from the scalar tensors might indeed not be the best idea...<br>\nMaybe leave it like it used to be?</p>\n<p>Sorry to have caused this misunderstanding and thanks for your help explaining why my proposed fix is a bad idea! <g-emoji class=\"g-emoji\" alias=\"sweat_smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f605.png\">\ud83d\ude05</g-emoji></p>", "body_text": "@sharpsy, I did not think that one through...\nI agree that this behaviour is not what we want. Setting reduce=False in the loss function works and fixes my issue in quite a clean way (you just have to compute the mean outside of the DataParallel class). I will continue to work like that (or compute the loss on one GPU outside of DataParallel).\n@SsnL, I think making a vector from the scalar tensors might indeed not be the best idea...\nMaybe leave it like it used to be?\nSorry to have caused this misunderstanding and thanks for your help explaining why my proposed fix is a bad idea! \ud83d\ude05", "body": "@sharpsy, I did not think that one through...  \r\nI agree that this behaviour is not what we want. Setting ``reduce=False`` in the loss function works and fixes my issue in quite a clean way (you just have to compute the mean outside of the ``DataParallel`` class). I will continue to work like that (or compute the loss on one GPU outside of ``DataParallel``).\r\n\r\n@SsnL, I think making a vector from the scalar tensors might indeed not be the best idea...  \r\nMaybe leave it like it used to be?\r\n\r\nSorry to have caused this misunderstanding and thanks for your help explaining why my proposed fix is a bad idea! :sweat_smile: "}