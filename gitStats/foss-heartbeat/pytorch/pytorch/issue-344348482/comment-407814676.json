{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407814676", "html_url": "https://github.com/pytorch/pytorch/issues/9811#issuecomment-407814676", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9811", "id": 407814676, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzgxNDY3Ng==", "user": {"login": "sharpsy", "id": 7761488, "node_id": "MDQ6VXNlcjc3NjE0ODg=", "avatar_url": "https://avatars2.githubusercontent.com/u/7761488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharpsy", "html_url": "https://github.com/sharpsy", "followers_url": "https://api.github.com/users/sharpsy/followers", "following_url": "https://api.github.com/users/sharpsy/following{/other_user}", "gists_url": "https://api.github.com/users/sharpsy/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharpsy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharpsy/subscriptions", "organizations_url": "https://api.github.com/users/sharpsy/orgs", "repos_url": "https://api.github.com/users/sharpsy/repos", "events_url": "https://api.github.com/users/sharpsy/events{/privacy}", "received_events_url": "https://api.github.com/users/sharpsy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-25T16:26:13Z", "updated_at": "2018-07-25T16:26:44Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a>, if I understand correctly - this means that using <code>DataParallel</code> can now have unexpected consequences. One cannot guarantee the shape of the result anymore and the shape might change based on the configuration of the environment and machine hardware on which it is run. Code that works on the local machine with the 'cpu' device might break in the cloud that uses 'cuda' device. This doesn't sound nice.</p>\n<p>Sometimes we reuse modules made from other researchers and wrapping them in <code>DataParallel</code> would now silently pass and raise an error due to wrong shape further in the pipeline, possibly not even in the same process/machine. Previous behavior would have raised an exception immediately when gathering those results.</p>\n<p>There is even more dangerous effect, where the model appears that it works - but training it on a different number of GPUs would influence the result in subtle way. For example - the use case that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11853089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/0phoff\">@0phoff</a> has! The module returns an average of all losses in the batch. New behavior would return a vector of 4 averages if it is run on 4 GPUs. Than he takes the average of this vector. But this will not be the same number if run on 3 GPUs or a single GPU due to a difference in number of batches processed by each GPU!</p>\n<p>Let me explain with a short example:<br>\nA batch of 3 would be calculated on a single GPU and results would be <code>[0.3, 0.2, 0.8]</code> and model that returns the loss would return <code>0.43</code>.<br>\nIf cast to <code>DataParallel</code>, and calculated on 2 GPUs, [GPU1 - batch 0,1], [GPU2 - batch 2] - return values would be <code>[0.25, 0.8]</code> (0.25 is average between 0.2 and 0.3)- taking the average loss of <code>[0.25, 0.8]</code> is now <code>0.525</code>!<br>\nCalculating on 3 GPUs, one gets <code>[0.3, 0.2, 0.8]</code> as results and average is back to <code>0.43</code>!</p>\n<p>Is there a way to hear the opinion in favor of this change and try to influence it?</p>", "body_text": "@SsnL, if I understand correctly - this means that using DataParallel can now have unexpected consequences. One cannot guarantee the shape of the result anymore and the shape might change based on the configuration of the environment and machine hardware on which it is run. Code that works on the local machine with the 'cpu' device might break in the cloud that uses 'cuda' device. This doesn't sound nice.\nSometimes we reuse modules made from other researchers and wrapping them in DataParallel would now silently pass and raise an error due to wrong shape further in the pipeline, possibly not even in the same process/machine. Previous behavior would have raised an exception immediately when gathering those results.\nThere is even more dangerous effect, where the model appears that it works - but training it on a different number of GPUs would influence the result in subtle way. For example - the use case that @0phoff has! The module returns an average of all losses in the batch. New behavior would return a vector of 4 averages if it is run on 4 GPUs. Than he takes the average of this vector. But this will not be the same number if run on 3 GPUs or a single GPU due to a difference in number of batches processed by each GPU!\nLet me explain with a short example:\nA batch of 3 would be calculated on a single GPU and results would be [0.3, 0.2, 0.8] and model that returns the loss would return 0.43.\nIf cast to DataParallel, and calculated on 2 GPUs, [GPU1 - batch 0,1], [GPU2 - batch 2] - return values would be [0.25, 0.8] (0.25 is average between 0.2 and 0.3)- taking the average loss of [0.25, 0.8] is now 0.525!\nCalculating on 3 GPUs, one gets [0.3, 0.2, 0.8] as results and average is back to 0.43!\nIs there a way to hear the opinion in favor of this change and try to influence it?", "body": "@SsnL, if I understand correctly - this means that using `DataParallel` can now have unexpected consequences. One cannot guarantee the shape of the result anymore and the shape might change based on the configuration of the environment and machine hardware on which it is run. Code that works on the local machine with the 'cpu' device might break in the cloud that uses 'cuda' device. This doesn't sound nice.\r\n\r\nSometimes we reuse modules made from other researchers and wrapping them in `DataParallel` would now silently pass and raise an error due to wrong shape further in the pipeline, possibly not even in the same process/machine. Previous behavior would have raised an exception immediately when gathering those results.\r\n\r\nThere is even more dangerous effect, where the model appears that it works - but training it on a different number of GPUs would influence the result in subtle way. For example - the use case that @0phoff has! The module returns an average of all losses in the batch. New behavior would return a vector of 4 averages if it is run on 4 GPUs. Than he takes the average of this vector. But this will not be the same number if run on 3 GPUs or a single GPU due to a difference in number of batches processed by each GPU!\r\n\r\nLet me explain with a short example:\r\nA batch of 3 would be calculated on a single GPU and results would be `[0.3, 0.2, 0.8]` and model that returns the loss would return `0.43`.\r\nIf cast to `DataParallel`, and calculated on 2 GPUs, [GPU1 - batch 0,1], [GPU2 - batch 2] - return values would be `[0.25, 0.8]` (0.25 is average between 0.2 and 0.3)- taking the average loss of `[0.25, 0.8]` is now `0.525`!\r\nCalculating on 3 GPUs, one gets `[0.3, 0.2, 0.8]` as results and average is back to `0.43`!\r\n\r\nIs there a way to hear the opinion in favor of this change and try to influence it?"}