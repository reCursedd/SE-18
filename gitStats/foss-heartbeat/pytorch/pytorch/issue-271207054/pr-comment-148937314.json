{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148937314", "pull_request_review_id": 74261785, "id": 148937314, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0ODkzNzMxNA==", "diff_hunk": "@@ -224,13 +232,38 @@ def _run_symbolic_function(g, n, inputs):\n             op_name = n.kind()[:-1]\n         else:\n             op_name = n.kind()\n-        if not hasattr(torch.onnx.symbolic, op_name):\n-            warnings.warn(\"ONNX export failed on {} because torch.onnx.symbolic.{} does not exist\"\n-                          .format(op_name, op_name))\n-            return None\n-        fn = getattr(torch.onnx.symbolic, op_name)\n-        attrs = {k: n[k] for k in n.attributeNames()}\n-        return fn(g, *inputs, **attrs)\n+        if globals()['aten']:\n+            attrs = {}\n+            def type_suffix(var):\n+                if isinstance(var, numbers.Integral):\n+                    return \"i\"\n+                elif isinstance(var, float):\n+                    return \"f\"\n+                elif isinstance(var, string_classes):\n+                    return \"s\"\n+                elif torch.is_tensor(var):\n+                    return \"t\"\n+                else:\n+                    raise ValueError(\"Unknown attribute type when exporting ATen ops:\".format(type(var)))\n+            for k in n.attributeNames():\n+                val = n[k]\n+                if not isinstance(val, string_classes) and not torch.is_tensor(val) and isinstance(val, collections.Iterable):\n+                    attrs[k + \"_\" + type_suffix(val[0])] = val\n+                else:\n+                    attrs[k + \"_\" + type_suffix(val)] = val\n+            node = _graph_at(g, op_name, *inputs, **attrs)\n+            # Only max_pool2d return two values\n+            if op_name == \"max_pool2d\":", "path": "torch/onnx/__init__.py", "position": null, "original_position": 68, "commit_id": "4c123c3774d8ae68b413ff99fe3cb15c7984f408", "original_commit_id": "715e58a6934fa8c8d7f121cef4ad510ceda539ad", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "This is a good point. Actually, this is a good opportunity to extend the `run_symbolic_function` so that other multiple return ATen functions get handled properly. Basically, what we should do is pass the number of expected outputs based on the trace to the function here, so we can consequently return the correct number of outputs.\r\n\r\nSuppose that there are two expected outputs. IIUC, the ATen op in Caffe2 will actually return two outputs. So really, we should create a multi-return ATen op, not a single return one with None in the second parameter. Though, I could be wrong (having not tested this case.) Do you know?", "created_at": "2017-11-04T18:06:47Z", "updated_at": "2018-11-23T15:36:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/3489#discussion_r148937314", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3489", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148937314"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3489#discussion_r148937314"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3489"}}, "body_html": "<p>This is a good point. Actually, this is a good opportunity to extend the <code>run_symbolic_function</code> so that other multiple return ATen functions get handled properly. Basically, what we should do is pass the number of expected outputs based on the trace to the function here, so we can consequently return the correct number of outputs.</p>\n<p>Suppose that there are two expected outputs. IIUC, the ATen op in Caffe2 will actually return two outputs. So really, we should create a multi-return ATen op, not a single return one with None in the second parameter. Though, I could be wrong (having not tested this case.) Do you know?</p>", "body_text": "This is a good point. Actually, this is a good opportunity to extend the run_symbolic_function so that other multiple return ATen functions get handled properly. Basically, what we should do is pass the number of expected outputs based on the trace to the function here, so we can consequently return the correct number of outputs.\nSuppose that there are two expected outputs. IIUC, the ATen op in Caffe2 will actually return two outputs. So really, we should create a multi-return ATen op, not a single return one with None in the second parameter. Though, I could be wrong (having not tested this case.) Do you know?"}