{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/369892859", "html_url": "https://github.com/pytorch/pytorch/issues/2575#issuecomment-369892859", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2575", "id": 369892859, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTg5Mjg1OQ==", "user": {"login": "lautjy", "id": 9349212, "node_id": "MDQ6VXNlcjkzNDkyMTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/9349212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lautjy", "html_url": "https://github.com/lautjy", "followers_url": "https://api.github.com/users/lautjy/followers", "following_url": "https://api.github.com/users/lautjy/following{/other_user}", "gists_url": "https://api.github.com/users/lautjy/gists{/gist_id}", "starred_url": "https://api.github.com/users/lautjy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lautjy/subscriptions", "organizations_url": "https://api.github.com/users/lautjy/orgs", "repos_url": "https://api.github.com/users/lautjy/repos", "events_url": "https://api.github.com/users/lautjy/events{/privacy}", "received_events_url": "https://api.github.com/users/lautjy/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-02T11:07:02Z", "updated_at": "2018-03-02T11:07:43Z", "author_association": "NONE", "body_html": "<p>This is more like an infrastructure issue. It depends on the system where you are building &amp; running things. For me, starting with Amazon's DeepLearning AMI, installing Python libs via conda leads to this TLS problem. But Fast.ai's community AMI does not have this TLS problem, even though I have the same libs there (due to being built with different glibc switch, having different glibc build, etc.).</p>\n<p>Libraries that your OS loads when you <code>import something</code> have been built with a specific version(s) of glibc. That determines how many \"static TLS\" objects (from .so files) your system can load before getting stuck with this issue. You would not run into this problem if you didn't have libs on your system that use \"initial-exec\" model. That happens if things were build without <code>-gPIC</code> flag. Even single \"initial-exec\" using lib changes the whole loading model, and bombs you TLS count. Hence this problem.<br>\n(proper info in this SO: <a href=\"https://stackoverflow.com/questions/14892101/cannot-load-any-more-object-with-static-tls\" rel=\"nofollow\">https://stackoverflow.com/questions/14892101/cannot-load-any-more-object-with-static-tls</a> )</p>\n<p>You can check through your libraries who are the <code>__thread</code> users: <code>readelf -l /path/to/foo.so | grep TLS</code><br>\nAnd this to see if they use initial-exec: <code>readelf --dynamic /path/to/foo.so</code></p>\n<p>Solutions?</p>\n<ol start=\"0\">\n<li>Above there are hacks that might work: change the order of  <code>import</code>s in your Python code. That changes the order in which libraries are loaded, and <em>may</em> be a way to avoid this TLS issue. For me it did not work.</li>\n</ol>\n<p>Google-fu reveals other solutions:</p>\n<ol>\n<li>\n<p>Rebuild glibc with more default static TLS storage. e.g. Increase DTV_SURPLUS until it works. (Ubuntu doubled this system wide at some version, but one may need to increase even more.)</p>\n</li>\n<li>\n<p>Rebuild your dependent libraries so that they don't use \"initial-exec\" TLS model. Aka <strong>everything</strong> should be built with <code>-fPIC</code> flag. Because even if just one library linked in the import chain is without that, it will force everything into \"bad TLS mode\" and causes this problem (see SO link above for actual explanation).</p>\n</li>\n</ol>\n<p>(edit: And this is not Python specific. It is more fundamental.)</p>", "body_text": "This is more like an infrastructure issue. It depends on the system where you are building & running things. For me, starting with Amazon's DeepLearning AMI, installing Python libs via conda leads to this TLS problem. But Fast.ai's community AMI does not have this TLS problem, even though I have the same libs there (due to being built with different glibc switch, having different glibc build, etc.).\nLibraries that your OS loads when you import something have been built with a specific version(s) of glibc. That determines how many \"static TLS\" objects (from .so files) your system can load before getting stuck with this issue. You would not run into this problem if you didn't have libs on your system that use \"initial-exec\" model. That happens if things were build without -gPIC flag. Even single \"initial-exec\" using lib changes the whole loading model, and bombs you TLS count. Hence this problem.\n(proper info in this SO: https://stackoverflow.com/questions/14892101/cannot-load-any-more-object-with-static-tls )\nYou can check through your libraries who are the __thread users: readelf -l /path/to/foo.so | grep TLS\nAnd this to see if they use initial-exec: readelf --dynamic /path/to/foo.so\nSolutions?\n\nAbove there are hacks that might work: change the order of  imports in your Python code. That changes the order in which libraries are loaded, and may be a way to avoid this TLS issue. For me it did not work.\n\nGoogle-fu reveals other solutions:\n\n\nRebuild glibc with more default static TLS storage. e.g. Increase DTV_SURPLUS until it works. (Ubuntu doubled this system wide at some version, but one may need to increase even more.)\n\n\nRebuild your dependent libraries so that they don't use \"initial-exec\" TLS model. Aka everything should be built with -fPIC flag. Because even if just one library linked in the import chain is without that, it will force everything into \"bad TLS mode\" and causes this problem (see SO link above for actual explanation).\n\n\n(edit: And this is not Python specific. It is more fundamental.)", "body": "This is more like an infrastructure issue. It depends on the system where you are building & running things. For me, starting with Amazon's DeepLearning AMI, installing Python libs via conda leads to this TLS problem. But Fast.ai's community AMI does not have this TLS problem, even though I have the same libs there (due to being built with different glibc switch, having different glibc build, etc.).\r\n\r\nLibraries that your OS loads when you `import something` have been built with a specific version(s) of glibc. That determines how many \"static TLS\" objects (from .so files) your system can load before getting stuck with this issue. You would not run into this problem if you didn't have libs on your system that use \"initial-exec\" model. That happens if things were build without `-gPIC` flag. Even single \"initial-exec\" using lib changes the whole loading model, and bombs you TLS count. Hence this problem.\r\n(proper info in this SO: https://stackoverflow.com/questions/14892101/cannot-load-any-more-object-with-static-tls )\r\n\r\nYou can check through your libraries who are the `__thread` users: `readelf -l /path/to/foo.so | grep TLS`\r\nAnd this to see if they use initial-exec: `readelf --dynamic /path/to/foo.so`\r\n\r\nSolutions?\r\n\r\n0) Above there are hacks that might work: change the order of  `import`s in your Python code. That changes the order in which libraries are loaded, and *may* be a way to avoid this TLS issue. For me it did not work.\r\n\r\nGoogle-fu reveals other solutions:\r\n1) Rebuild glibc with more default static TLS storage. e.g. Increase DTV_SURPLUS until it works. (Ubuntu doubled this system wide at some version, but one may need to increase even more.)\r\n\r\n2) Rebuild your dependent libraries so that they don't use \"initial-exec\" TLS model. Aka **everything** should be built with `-fPIC` flag. Because even if just one library linked in the import chain is without that, it will force everything into \"bad TLS mode\" and causes this problem (see SO link above for actual explanation).\r\n\r\n(edit: And this is not Python specific. It is more fundamental.)"}