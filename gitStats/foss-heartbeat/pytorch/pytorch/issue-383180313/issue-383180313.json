{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14278", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14278/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14278/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14278/events", "html_url": "https://github.com/pytorch/pytorch/pull/14278", "id": 383180313, "node_id": "MDExOlB1bGxSZXF1ZXN0MjMyNzEyMjE5", "number": 14278, "title": "Make checkpoint_sequential work with multiple arguments", "user": {"login": "andersenchen", "id": 2110833, "node_id": "MDQ6VXNlcjIxMTA4MzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2110833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andersenchen", "html_url": "https://github.com/andersenchen", "followers_url": "https://api.github.com/users/andersenchen/followers", "following_url": "https://api.github.com/users/andersenchen/following{/other_user}", "gists_url": "https://api.github.com/users/andersenchen/gists{/gist_id}", "starred_url": "https://api.github.com/users/andersenchen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andersenchen/subscriptions", "organizations_url": "https://api.github.com/users/andersenchen/orgs", "repos_url": "https://api.github.com/users/andersenchen/repos", "events_url": "https://api.github.com/users/andersenchen/events{/privacy}", "received_events_url": "https://api.github.com/users/andersenchen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-21T15:49:03Z", "updated_at": "2018-11-23T21:37:52Z", "closed_at": null, "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/14278", "html_url": "https://github.com/pytorch/pytorch/pull/14278", "diff_url": "https://github.com/pytorch/pytorch/pull/14278.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/14278.patch"}, "body_html": "<p>Summary:<br>\nIn this commit, we make checkpoint_sequential work for models with multiple tensor inputs. Previously, it only processed the first tensor and ignored the rest.</p>\n<p>We introduce a new test in test/test_utils.py that replicates the issue referenced in this <a href=\"https://github.com/pytorch/pytorch/issues/11093\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/11093/hovercard\">GitHub issue</a>, and we make sure that the test passes by changing the behavior of checkpoint_sequential to process all input tensors.</p>\n<p>Differential Revision: D13144672</p>", "body_text": "Summary:\nIn this commit, we make checkpoint_sequential work for models with multiple tensor inputs. Previously, it only processed the first tensor and ignored the rest.\nWe introduce a new test in test/test_utils.py that replicates the issue referenced in this GitHub issue, and we make sure that the test passes by changing the behavior of checkpoint_sequential to process all input tensors.\nDifferential Revision: D13144672", "body": "Summary:\r\nIn this commit, we make checkpoint_sequential work for models with multiple tensor inputs. Previously, it only processed the first tensor and ignored the rest.\r\n\r\nWe introduce a new test in test/test_utils.py that replicates the issue referenced in this [GitHub issue](https://github.com/pytorch/pytorch/issues/11093), and we make sure that the test passes by changing the behavior of checkpoint_sequential to process all input tensors.\r\n\r\nDifferential Revision: D13144672\r\n"}