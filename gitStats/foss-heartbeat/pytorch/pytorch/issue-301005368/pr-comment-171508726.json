{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171508726", "pull_request_review_id": 100370118, "id": 171508726, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTUwODcyNg==", "diff_hunk": "@@ -32,7 +34,7 @@ class Threshold(Module):\n         >>> print(m(input))\n     \"\"\"\n \n-    def __init__(self, threshold, value, inplace=False):\n+    def __init__(self, threshold=0.0, value=0.0, inplace=False):", "path": "torch/nn/modules/activation.py", "position": null, "original_position": 14, "commit_id": "2f0f0e3ca3fd541c8f799feb805f28db88ea27fa", "original_commit_id": "db62804b96e6e6c0989174ae260106a6a0e06f54", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I agree with @SsnL. Threshold is really a family of functions, and you need to choose the one you want explicitly. If you want the defaults (which are indeed commonly used), we picked it already for you under the name of `nn.ReLU`. In the hyperparameter optimization case, if you want to limit yourself to parameter-less nonlinearities, you should just exclude Threshold in favor of ReLU.", "created_at": "2018-03-01T09:54:34Z", "updated_at": "2018-11-23T15:40:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/5457#discussion_r171508726", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5457", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171508726"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5457#discussion_r171508726"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5457"}}, "body_html": "<p>I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a>. Threshold is really a family of functions, and you need to choose the one you want explicitly. If you want the defaults (which are indeed commonly used), we picked it already for you under the name of <code>nn.ReLU</code>. In the hyperparameter optimization case, if you want to limit yourself to parameter-less nonlinearities, you should just exclude Threshold in favor of ReLU.</p>", "body_text": "I agree with @SsnL. Threshold is really a family of functions, and you need to choose the one you want explicitly. If you want the defaults (which are indeed commonly used), we picked it already for you under the name of nn.ReLU. In the hyperparameter optimization case, if you want to limit yourself to parameter-less nonlinearities, you should just exclude Threshold in favor of ReLU.", "in_reply_to_id": 171328160}