{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171333262", "pull_request_review_id": 100167551, "id": 171333262, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTMzMzI2Mg==", "diff_hunk": "@@ -32,7 +34,7 @@ class Threshold(Module):\n         >>> print(m(input))\n     \"\"\"\n \n-    def __init__(self, threshold, value, inplace=False):\n+    def __init__(self, threshold=0.0, value=0.0, inplace=False):", "path": "torch/nn/modules/activation.py", "position": null, "original_position": 14, "commit_id": "2f0f0e3ca3fd541c8f799feb805f28db88ea27fa", "original_commit_id": "db62804b96e6e6c0989174ae260106a6a0e06f54", "user": {"login": "pmitros", "id": 1427775, "node_id": "MDQ6VXNlcjE0Mjc3NzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1427775?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmitros", "html_url": "https://github.com/pmitros", "followers_url": "https://api.github.com/users/pmitros/followers", "following_url": "https://api.github.com/users/pmitros/following{/other_user}", "gists_url": "https://api.github.com/users/pmitros/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmitros/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmitros/subscriptions", "organizations_url": "https://api.github.com/users/pmitros/orgs", "repos_url": "https://api.github.com/users/pmitros/repos", "events_url": "https://api.github.com/users/pmitros/events{/privacy}", "received_events_url": "https://api.github.com/users/pmitros/received_events", "type": "User", "site_admin": false}, "body": "This one, I'll push back on a little bit harder. It's important to be consistent on function signatures, especially in a language with duck typing, and especially in a field where one might want to introspect code to e.g. optimize hyperparameters or visualize what's going on.\r\n\r\nBefore this change, the nonlinear activation functions had different function signatures. In particular, it was impossible for a program to call `Threshold` without human intervention since there was no reasonable set of default values provided.\r\n\r\nUse cases:\r\n\r\n* The script which generated the images is oblivious to anything about the functions other that they are a nonlinear functions with one input and one output\r\n* Optimizing hyperparameters, for example picking choice of nonlinearity through something like simulated annealing or genetic algorithms (and further optimizing parameter choices on those nonlinearities from a reasonable starting-point if desired).\r\n* For learning purposes, having tools where students might have a visualization of these functions, and tweak parameters.\r\n\r\nThe next step would be to register these in some way (e.g. Python entry points).", "created_at": "2018-02-28T18:05:28Z", "updated_at": "2018-11-23T15:40:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/5457#discussion_r171333262", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5457", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171333262"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5457#discussion_r171333262"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5457"}}, "body_html": "<p>This one, I'll push back on a little bit harder. It's important to be consistent on function signatures, especially in a language with duck typing, and especially in a field where one might want to introspect code to e.g. optimize hyperparameters or visualize what's going on.</p>\n<p>Before this change, the nonlinear activation functions had different function signatures. In particular, it was impossible for a program to call <code>Threshold</code> without human intervention since there was no reasonable set of default values provided.</p>\n<p>Use cases:</p>\n<ul>\n<li>The script which generated the images is oblivious to anything about the functions other that they are a nonlinear functions with one input and one output</li>\n<li>Optimizing hyperparameters, for example picking choice of nonlinearity through something like simulated annealing or genetic algorithms (and further optimizing parameter choices on those nonlinearities from a reasonable starting-point if desired).</li>\n<li>For learning purposes, having tools where students might have a visualization of these functions, and tweak parameters.</li>\n</ul>\n<p>The next step would be to register these in some way (e.g. Python entry points).</p>", "body_text": "This one, I'll push back on a little bit harder. It's important to be consistent on function signatures, especially in a language with duck typing, and especially in a field where one might want to introspect code to e.g. optimize hyperparameters or visualize what's going on.\nBefore this change, the nonlinear activation functions had different function signatures. In particular, it was impossible for a program to call Threshold without human intervention since there was no reasonable set of default values provided.\nUse cases:\n\nThe script which generated the images is oblivious to anything about the functions other that they are a nonlinear functions with one input and one output\nOptimizing hyperparameters, for example picking choice of nonlinearity through something like simulated annealing or genetic algorithms (and further optimizing parameter choices on those nonlinearities from a reasonable starting-point if desired).\nFor learning purposes, having tools where students might have a visualization of these functions, and tweak parameters.\n\nThe next step would be to register these in some way (e.g. Python entry points).", "in_reply_to_id": 171328160}