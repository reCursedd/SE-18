{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11230", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11230/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11230/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11230/events", "html_url": "https://github.com/pytorch/pytorch/pull/11230", "id": 356914015, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEzMDU1ODQx", "number": 11230, "title": "Add AVX optimizations for pdist", "user": {"login": "erikbrinkman", "id": 858926, "node_id": "MDQ6VXNlcjg1ODkyNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/858926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erikbrinkman", "html_url": "https://github.com/erikbrinkman", "followers_url": "https://api.github.com/users/erikbrinkman/followers", "following_url": "https://api.github.com/users/erikbrinkman/following{/other_user}", "gists_url": "https://api.github.com/users/erikbrinkman/gists{/gist_id}", "starred_url": "https://api.github.com/users/erikbrinkman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erikbrinkman/subscriptions", "organizations_url": "https://api.github.com/users/erikbrinkman/orgs", "repos_url": "https://api.github.com/users/erikbrinkman/repos", "events_url": "https://api.github.com/users/erikbrinkman/events{/privacy}", "received_events_url": "https://api.github.com/users/erikbrinkman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-09-04T17:53:17Z", "updated_at": "2018-11-23T15:50:37Z", "closed_at": "2018-09-09T05:56:24Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11230", "html_url": "https://github.com/pytorch/pytorch/pull/11230", "diff_url": "https://github.com/pytorch/pytorch/pull/11230.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11230.patch"}, "body_html": "<p>Added AVX optimizations for pdist using Vec256. This brings single threaded performance up to speed with scipy, but the current implementation greatly hurts performance without AVX enabled. Is there a way to special case out AVX on dispatch and call the non Vec256 code? Or is the way I used Vec256 completely wrong?</p>\n<h1>Single threaded comparison to scipy</h1>\n<p>This is the time to compute the pdist of a 2048 x 2048 float matrix with only one thread for various values of p between torch and scipy. p = 3 is the code path for arbitrary p, and so is much slower than the other values.</p>\n<table>\n<thead>\n<tr>\n<th>p</th>\n<th>torch</th>\n<th>scipy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>6.27 s \u00b1 393 ms</td>\n<td>7.23 s \u00b1 498 ms</td>\n</tr>\n<tr>\n<td>1</td>\n<td>5.49 s \u00b1 201 ms</td>\n<td>43.4 s \u00b1 1.09 s</td>\n</tr>\n<tr>\n<td>2</td>\n<td>5.74 s \u00b1 474 ms</td>\n<td>53.8 s \u00b1 3.52 s</td>\n</tr>\n<tr>\n<td>\u221e</td>\n<td>5.59 s \u00b1 292 ms</td>\n<td>47.4 s \u00b1 2.03 s</td>\n</tr>\n<tr>\n<td>3</td>\n<td>really slow</td>\n<td>gave up</td>\n</tr>\n</tbody>\n</table>\n<h1>Result by AVX support</h1>\n<p>This is the time to compute the distance and gradient of a 2048 x 2048 float matrix with all threads by AVX support. <code>before</code> is the old code, <code>default</code> is no AVX support, etc. Interestingly the AVX optimizations provided a great benefit over the old unoptimized code, but drastically hurt performance when compiled without AVX optimizations. p = 3 is the code path for arbitrary p, and so is much slower than the other values.</p>\n<h2>Results for p = 0</h2>\n<table>\n<thead>\n<tr>\n<th>avx</th>\n<th>dist</th>\n<th>grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>before</td>\n<td>514 ms \u00b1 87.5 ms</td>\n<td>191 \u00b5s \u00b1 35 \u00b5s</td>\n</tr>\n<tr>\n<td>default</td>\n<td>3.47 s \u00b1 183 ms</td>\n<td>201 \u00b5s \u00b1 24.6 \u00b5s</td>\n</tr>\n<tr>\n<td>avx</td>\n<td>123 ms \u00b1 18.2 ms</td>\n<td>281 \u00b5s \u00b1 130 \u00b5s</td>\n</tr>\n<tr>\n<td>avx2</td>\n<td>103 ms \u00b1 11.4 ms</td>\n<td>216 \u00b5s \u00b1 74.4 \u00b5s</td>\n</tr>\n</tbody>\n</table>\n<h2>Results for p = 1</h2>\n<table>\n<thead>\n<tr>\n<th>avx</th>\n<th>dist</th>\n<th>grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>before</td>\n<td>426 ms \u00b1 35 ms</td>\n<td>6.21 s \u00b1 187 ms</td>\n</tr>\n<tr>\n<td>default</td>\n<td>2.6 s \u00b1 123 ms</td>\n<td>5.62 s \u00b1 273 ms</td>\n</tr>\n<tr>\n<td>avx</td>\n<td>104 ms \u00b1 6.37 ms</td>\n<td>833 ms \u00b1 44.3 ms</td>\n</tr>\n<tr>\n<td>avx2</td>\n<td>106 ms \u00b1 3.59 ms</td>\n<td>924 ms \u00b1 86.2 ms</td>\n</tr>\n</tbody>\n</table>\n<h2>Results for p = 2</h2>\n<table>\n<thead>\n<tr>\n<th>avx</th>\n<th>dist</th>\n<th>grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>before</td>\n<td>425 ms \u00b1 45.4 ms</td>\n<td>6.31 s \u00b1 125 ms</td>\n</tr>\n<tr>\n<td>default</td>\n<td>3.04 s \u00b1 187 ms</td>\n<td>3.55 s \u00b1 242 ms</td>\n</tr>\n<tr>\n<td>avx</td>\n<td>110 ms \u00b1 3.66 ms</td>\n<td>896 ms \u00b1 21.8 ms</td>\n</tr>\n<tr>\n<td>avx2</td>\n<td>113 ms \u00b1 4.68 ms</td>\n<td>934 ms \u00b1 25.2 ms</td>\n</tr>\n</tbody>\n</table>\n<h2>Results for p = \u221e</h2>\n<table>\n<thead>\n<tr>\n<th>avx</th>\n<th>dist</th>\n<th>grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>before</td>\n<td>501 ms \u00b1 39.5 ms</td>\n<td>6.64 s \u00b1 321 ms</td>\n</tr>\n<tr>\n<td>default</td>\n<td>2.15 s \u00b1 92.9 ms</td>\n<td>8.43 s \u00b1 355 ms</td>\n</tr>\n<tr>\n<td>avx</td>\n<td>104 ms \u00b1 5.52 ms</td>\n<td>835 ms \u00b1 36.7 ms</td>\n</tr>\n<tr>\n<td>avx2</td>\n<td>100 ms \u00b1 3.41 ms</td>\n<td>864 ms \u00b1 67 ms</td>\n</tr>\n</tbody>\n</table>\n<h2>Results for p = 3</h2>\n<table>\n<thead>\n<tr>\n<th>avx</th>\n<th>dist</th>\n<th>grad</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>before</td>\n<td>22.6 s \u00b1 413 ms</td>\n<td>11.1 s \u00b1 242 ms</td>\n</tr>\n<tr>\n<td>default</td>\n<td>24.9 s \u00b1 1 s</td>\n<td>11.2 s \u00b1 293 ms</td>\n</tr>\n<tr>\n<td>avx</td>\n<td>2.69 s \u00b1 148 ms</td>\n<td>5.63 s \u00b1 88.4 ms</td>\n</tr>\n<tr>\n<td>avx2</td>\n<td>2.48 s \u00b1 31.8 ms</td>\n<td>5.61 s \u00b1 114 ms</td>\n</tr>\n</tbody>\n</table>", "body_text": "Added AVX optimizations for pdist using Vec256. This brings single threaded performance up to speed with scipy, but the current implementation greatly hurts performance without AVX enabled. Is there a way to special case out AVX on dispatch and call the non Vec256 code? Or is the way I used Vec256 completely wrong?\nSingle threaded comparison to scipy\nThis is the time to compute the pdist of a 2048 x 2048 float matrix with only one thread for various values of p between torch and scipy. p = 3 is the code path for arbitrary p, and so is much slower than the other values.\n\n\n\np\ntorch\nscipy\n\n\n\n\n0\n6.27 s \u00b1 393 ms\n7.23 s \u00b1 498 ms\n\n\n1\n5.49 s \u00b1 201 ms\n43.4 s \u00b1 1.09 s\n\n\n2\n5.74 s \u00b1 474 ms\n53.8 s \u00b1 3.52 s\n\n\n\u221e\n5.59 s \u00b1 292 ms\n47.4 s \u00b1 2.03 s\n\n\n3\nreally slow\ngave up\n\n\n\nResult by AVX support\nThis is the time to compute the distance and gradient of a 2048 x 2048 float matrix with all threads by AVX support. before is the old code, default is no AVX support, etc. Interestingly the AVX optimizations provided a great benefit over the old unoptimized code, but drastically hurt performance when compiled without AVX optimizations. p = 3 is the code path for arbitrary p, and so is much slower than the other values.\nResults for p = 0\n\n\n\navx\ndist\ngrad\n\n\n\n\nbefore\n514 ms \u00b1 87.5 ms\n191 \u00b5s \u00b1 35 \u00b5s\n\n\ndefault\n3.47 s \u00b1 183 ms\n201 \u00b5s \u00b1 24.6 \u00b5s\n\n\navx\n123 ms \u00b1 18.2 ms\n281 \u00b5s \u00b1 130 \u00b5s\n\n\navx2\n103 ms \u00b1 11.4 ms\n216 \u00b5s \u00b1 74.4 \u00b5s\n\n\n\nResults for p = 1\n\n\n\navx\ndist\ngrad\n\n\n\n\nbefore\n426 ms \u00b1 35 ms\n6.21 s \u00b1 187 ms\n\n\ndefault\n2.6 s \u00b1 123 ms\n5.62 s \u00b1 273 ms\n\n\navx\n104 ms \u00b1 6.37 ms\n833 ms \u00b1 44.3 ms\n\n\navx2\n106 ms \u00b1 3.59 ms\n924 ms \u00b1 86.2 ms\n\n\n\nResults for p = 2\n\n\n\navx\ndist\ngrad\n\n\n\n\nbefore\n425 ms \u00b1 45.4 ms\n6.31 s \u00b1 125 ms\n\n\ndefault\n3.04 s \u00b1 187 ms\n3.55 s \u00b1 242 ms\n\n\navx\n110 ms \u00b1 3.66 ms\n896 ms \u00b1 21.8 ms\n\n\navx2\n113 ms \u00b1 4.68 ms\n934 ms \u00b1 25.2 ms\n\n\n\nResults for p = \u221e\n\n\n\navx\ndist\ngrad\n\n\n\n\nbefore\n501 ms \u00b1 39.5 ms\n6.64 s \u00b1 321 ms\n\n\ndefault\n2.15 s \u00b1 92.9 ms\n8.43 s \u00b1 355 ms\n\n\navx\n104 ms \u00b1 5.52 ms\n835 ms \u00b1 36.7 ms\n\n\navx2\n100 ms \u00b1 3.41 ms\n864 ms \u00b1 67 ms\n\n\n\nResults for p = 3\n\n\n\navx\ndist\ngrad\n\n\n\n\nbefore\n22.6 s \u00b1 413 ms\n11.1 s \u00b1 242 ms\n\n\ndefault\n24.9 s \u00b1 1 s\n11.2 s \u00b1 293 ms\n\n\navx\n2.69 s \u00b1 148 ms\n5.63 s \u00b1 88.4 ms\n\n\navx2\n2.48 s \u00b1 31.8 ms\n5.61 s \u00b1 114 ms", "body": "Added AVX optimizations for pdist using Vec256. This brings single threaded performance up to speed with scipy, but the current implementation greatly hurts performance without AVX enabled. Is there a way to special case out AVX on dispatch and call the non Vec256 code? Or is the way I used Vec256 completely wrong?\r\n\r\nSingle threaded comparison to scipy\r\n============================\r\n\r\nThis is the time to compute the pdist of a 2048 x 2048 float matrix with only one thread for various values of p between torch and scipy. p = 3 is the code path for arbitrary p, and so is much slower than the other values.\r\n\r\np | torch | scipy\r\n-----|-----------|------\r\n0 | 6.27 s \u00b1 393 ms | 7.23 s \u00b1 498 ms\r\n1 | 5.49 s \u00b1 201 ms | 43.4 s \u00b1 1.09 s\r\n2 | 5.74 s \u00b1 474 ms | 53.8 s \u00b1 3.52 s\r\n\u221e | 5.59 s \u00b1 292 ms | 47.4 s \u00b1 2.03 s\r\n3 | really slow | gave up\r\n\r\nResult by AVX support\r\n================\r\n\r\nThis is the time to compute the distance and gradient of a 2048 x 2048 float matrix with all threads by AVX support. `before` is the old code, `default` is no AVX support, etc. Interestingly the AVX optimizations provided a great benefit over the old unoptimized code, but drastically hurt performance when compiled without AVX optimizations. p = 3 is the code path for arbitrary p, and so is much slower than the other values.\r\n\r\nResults for p = 0\r\n----------------\r\n\r\navx | dist | grad\r\n----|------|-----\r\nbefore | 514 ms \u00b1 87.5 ms | 191 \u00b5s \u00b1 35 \u00b5s\r\ndefault | 3.47 s \u00b1 183 ms | 201 \u00b5s \u00b1 24.6 \u00b5s\r\navx | 123 ms \u00b1 18.2 ms | 281 \u00b5s \u00b1 130 \u00b5s\r\navx2 | 103 ms \u00b1 11.4 ms | 216 \u00b5s \u00b1 74.4 \u00b5s\r\n\r\nResults for p = 1\r\n----------------\r\n\r\navx | dist | grad\r\n----|------|-----\r\nbefore | 426 ms \u00b1 35 ms | 6.21 s \u00b1 187 ms\r\ndefault | 2.6 s \u00b1 123 ms | 5.62 s \u00b1 273 ms\r\navx | 104 ms \u00b1 6.37 ms | 833 ms \u00b1 44.3 ms\r\navx2 | 106 ms \u00b1 3.59 ms | 924 ms \u00b1 86.2 ms\r\n\r\nResults for p = 2\r\n-----------------\r\n\r\navx | dist | grad\r\n----|------|-----\r\nbefore | 425 ms \u00b1 45.4 ms | 6.31 s \u00b1 125 ms\r\ndefault | 3.04 s \u00b1 187 ms | 3.55 s \u00b1 242 ms\r\navx | 110 ms \u00b1 3.66 ms | 896 ms \u00b1 21.8 ms\r\navx2 | 113 ms \u00b1 4.68 ms | 934 ms \u00b1 25.2 ms\r\n\r\nResults for p = \u221e\r\n------------------\r\n\r\navx | dist | grad\r\n----|------|-----\r\nbefore | 501 ms \u00b1 39.5 ms | 6.64 s \u00b1 321 ms\r\ndefault | 2.15 s \u00b1 92.9 ms | 8.43 s \u00b1 355 ms\r\navx | 104 ms \u00b1 5.52 ms | 835 ms \u00b1 36.7 ms\r\navx2 | 100 ms \u00b1 3.41 ms | 864 ms \u00b1 67 ms\r\n\r\nResults for p = 3\r\n-----------------\r\n\r\navx | dist | grad\r\n----|------|-----\r\nbefore | 22.6 s \u00b1 413 ms | 11.1 s \u00b1 242 ms\r\ndefault | 24.9 s \u00b1 1 s | 11.2 s \u00b1 293 ms\r\navx | 2.69 s \u00b1 148 ms | 5.63 s \u00b1 88.4 ms\r\navx2 | 2.48 s \u00b1 31.8 ms | 5.61 s \u00b1 114 ms"}