{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7028", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7028/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7028/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7028/events", "html_url": "https://github.com/pytorch/pytorch/issues/7028", "id": 318286465, "node_id": "MDU6SXNzdWUzMTgyODY0NjU=", "number": 7028, "title": "Batchnorm's running_var is wrong(I test it use momentum = 1)", "user": {"login": "zhujianing", "id": 19886982, "node_id": "MDQ6VXNlcjE5ODg2OTgy", "avatar_url": "https://avatars3.githubusercontent.com/u/19886982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhujianing", "html_url": "https://github.com/zhujianing", "followers_url": "https://api.github.com/users/zhujianing/followers", "following_url": "https://api.github.com/users/zhujianing/following{/other_user}", "gists_url": "https://api.github.com/users/zhujianing/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhujianing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhujianing/subscriptions", "organizations_url": "https://api.github.com/users/zhujianing/orgs", "repos_url": "https://api.github.com/users/zhujianing/repos", "events_url": "https://api.github.com/users/zhujianing/events{/privacy}", "received_events_url": "https://api.github.com/users/zhujianing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-04-27T05:56:48Z", "updated_at": "2018-04-27T06:51:45Z", "closed_at": "2018-04-27T06:51:45Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I test BN1d use momentum = 1, but i found  running_var is not equal to <code>numpy.std(input.data.numpy()</code>'s output , but runing_mean is right , it is equal to <code>numpy.mean(input.data.numpy()</code></p>\n<h2>there is my testing code</h2>\n<pre><code>import torch\nfrom torch import nn\nimport numpy\nfrom torch.autograd import Variable\n\nbn = nn.BatchNorm1d(4,momentum=1)\ninput = Variable(torch.Tensor([ [2,15,2,1] ,[2,17,2,1] ,[-4,-2,-2,-1] ]))\nbn.weight.data = torch.ones(4)\nbn.bias.data = torch.zeros(4)\nbn.training = True\nprint(bn.train)\noutput = bn(input)\nprint(bn._buffers)\nprint(numpy.mean(input.data.numpy(), axis=0))\nprint(numpy.std(input.data.numpy(), axis=0))\n</code></pre>\n<h2>there are results</h2>\n<pre><code>&lt;bound method BatchNorm1d.train of BatchNorm1d(4, eps=1e-05, momentum=1, affine=True, track_running_stats=True)&gt;\nOrderedDict([('running_mean', tensor([  0.0000,  10.0000,   0.6667,   0.3333])), ('running_var', tensor([  12.0000,  109.0000,5.3333,    1.3333]))])\n[ 0.         10.          0.6666667   0.33333334]\n[2.828427   8.524474   1.8856181  0.94280905]\n</code></pre>", "body_text": "Issue description\nI test BN1d use momentum = 1, but i found  running_var is not equal to numpy.std(input.data.numpy()'s output , but runing_mean is right , it is equal to numpy.mean(input.data.numpy()\nthere is my testing code\nimport torch\nfrom torch import nn\nimport numpy\nfrom torch.autograd import Variable\n\nbn = nn.BatchNorm1d(4,momentum=1)\ninput = Variable(torch.Tensor([ [2,15,2,1] ,[2,17,2,1] ,[-4,-2,-2,-1] ]))\nbn.weight.data = torch.ones(4)\nbn.bias.data = torch.zeros(4)\nbn.training = True\nprint(bn.train)\noutput = bn(input)\nprint(bn._buffers)\nprint(numpy.mean(input.data.numpy(), axis=0))\nprint(numpy.std(input.data.numpy(), axis=0))\n\nthere are results\n<bound method BatchNorm1d.train of BatchNorm1d(4, eps=1e-05, momentum=1, affine=True, track_running_stats=True)>\nOrderedDict([('running_mean', tensor([  0.0000,  10.0000,   0.6667,   0.3333])), ('running_var', tensor([  12.0000,  109.0000,5.3333,    1.3333]))])\n[ 0.         10.          0.6666667   0.33333334]\n[2.828427   8.524474   1.8856181  0.94280905]", "body": "## Issue description\r\n\r\nI test BN1d use momentum = 1, but i found  running_var is not equal to `numpy.std(input.data.numpy()`'s output , but runing_mean is right , it is equal to `numpy.mean(input.data.numpy()` \r\n## there is my testing code\r\n```\r\nimport torch\r\nfrom torch import nn\r\nimport numpy\r\nfrom torch.autograd import Variable\r\n\r\nbn = nn.BatchNorm1d(4,momentum=1)\r\ninput = Variable(torch.Tensor([ [2,15,2,1] ,[2,17,2,1] ,[-4,-2,-2,-1] ]))\r\nbn.weight.data = torch.ones(4)\r\nbn.bias.data = torch.zeros(4)\r\nbn.training = True\r\nprint(bn.train)\r\noutput = bn(input)\r\nprint(bn._buffers)\r\nprint(numpy.mean(input.data.numpy(), axis=0))\r\nprint(numpy.std(input.data.numpy(), axis=0))\r\n```\r\n## there are results\r\n```\r\n<bound method BatchNorm1d.train of BatchNorm1d(4, eps=1e-05, momentum=1, affine=True, track_running_stats=True)>\r\nOrderedDict([('running_mean', tensor([  0.0000,  10.0000,   0.6667,   0.3333])), ('running_var', tensor([  12.0000,  109.0000,5.3333,    1.3333]))])\r\n[ 0.         10.          0.6666667   0.33333334]\r\n[2.828427   8.524474   1.8856181  0.94280905]\r\n```"}