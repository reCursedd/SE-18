{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6258", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6258/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6258/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6258/events", "html_url": "https://github.com/pytorch/pytorch/issues/6258", "id": 311054348, "node_id": "MDU6SXNzdWUzMTEwNTQzNDg=", "number": 6258, "title": "[feature request] use mkl_vml.h for exp, log vectorization on CPU", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-04-04T01:32:50Z", "updated_at": "2018-04-09T16:49:01Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1716488\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cpuhrsch\">@cpuhrsch</a> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"310551545\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6192\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/6192/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/6192\">#6192</a> disables imprecise vectorized function from avx_mathfunc.h<br>\n<a href=\"https://software.intel.com/en-us/mkl-developer-reference-c-vm-mathematical-functions\" rel=\"nofollow\">vml</a> is a vector math library from MKL, both performance and precision is promised. As long as <code>mkl</code> and <code>mkl-include</code> is installed in conda, vml can be used in ATen.<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20226293\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MlWoo\">@MlWoo</a> was preparing the code previously, the job got interrupted since he is in hospital lately :(<br>\nBelow is the performance comparison of avx_mathfunc and vml in exp. Though the performance improvement is not so much, the precision is guaranteed.<br>\nif this looks ok to you, we will continue the job, after <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20226293\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MlWoo\">@MlWoo</a> finish his therapy anyway.</p>\n<pre><code>avx_mathfunc.h\nexp:            size: 10^2      elapsed avg: 0.00018437 variance: 0.00002326    type: torch.FloatTensor\nexp:            size: 10^3      elapsed avg: 0.00051801 variance: 0.00012947    type: torch.FloatTensor\nexp:            size: 10^4      elapsed avg: 0.00399129 variance: 0.00030216    type: torch.FloatTensor\nexp:            size: 10^5      elapsed avg: 0.05558920 variance: 0.00430511    type: torch.FloatTensor\n\nvml\nexp:            size: 10^2      elapsed avg: 0.00004063 variance: 0.00001652    type: torch.FloatTensor\nexp:            size: 10^3      elapsed avg: 0.00048499 variance: 0.00003081    type: torch.FloatTensor\nexp:            size: 10^4      elapsed avg: 0.00325508 variance: 0.00007704    type: torch.FloatTensor\nexp:            size: 10^5      elapsed avg: 0.04254997 variance: 0.00301427    type: torch.FloatTensor\n\n</code></pre>", "body_text": "@cpuhrsch #6192 disables imprecise vectorized function from avx_mathfunc.h\nvml is a vector math library from MKL, both performance and precision is promised. As long as mkl and mkl-include is installed in conda, vml can be used in ATen.\n@MlWoo was preparing the code previously, the job got interrupted since he is in hospital lately :(\nBelow is the performance comparison of avx_mathfunc and vml in exp. Though the performance improvement is not so much, the precision is guaranteed.\nif this looks ok to you, we will continue the job, after @MlWoo finish his therapy anyway.\navx_mathfunc.h\nexp:            size: 10^2      elapsed avg: 0.00018437 variance: 0.00002326    type: torch.FloatTensor\nexp:            size: 10^3      elapsed avg: 0.00051801 variance: 0.00012947    type: torch.FloatTensor\nexp:            size: 10^4      elapsed avg: 0.00399129 variance: 0.00030216    type: torch.FloatTensor\nexp:            size: 10^5      elapsed avg: 0.05558920 variance: 0.00430511    type: torch.FloatTensor\n\nvml\nexp:            size: 10^2      elapsed avg: 0.00004063 variance: 0.00001652    type: torch.FloatTensor\nexp:            size: 10^3      elapsed avg: 0.00048499 variance: 0.00003081    type: torch.FloatTensor\nexp:            size: 10^4      elapsed avg: 0.00325508 variance: 0.00007704    type: torch.FloatTensor\nexp:            size: 10^5      elapsed avg: 0.04254997 variance: 0.00301427    type: torch.FloatTensor", "body": "@cpuhrsch #6192 disables imprecise vectorized function from avx_mathfunc.h\r\n[vml](https://software.intel.com/en-us/mkl-developer-reference-c-vm-mathematical-functions) is a vector math library from MKL, both performance and precision is promised. As long as `mkl` and `mkl-include` is installed in conda, vml can be used in ATen.\r\n@MlWoo was preparing the code previously, the job got interrupted since he is in hospital lately :(\r\nBelow is the performance comparison of avx_mathfunc and vml in exp. Though the performance improvement is not so much, the precision is guaranteed.\r\nif this looks ok to you, we will continue the job, after @MlWoo finish his therapy anyway.\r\n```\r\navx_mathfunc.h\r\nexp:            size: 10^2      elapsed avg: 0.00018437 variance: 0.00002326    type: torch.FloatTensor\r\nexp:            size: 10^3      elapsed avg: 0.00051801 variance: 0.00012947    type: torch.FloatTensor\r\nexp:            size: 10^4      elapsed avg: 0.00399129 variance: 0.00030216    type: torch.FloatTensor\r\nexp:            size: 10^5      elapsed avg: 0.05558920 variance: 0.00430511    type: torch.FloatTensor\r\n\r\nvml\r\nexp:            size: 10^2      elapsed avg: 0.00004063 variance: 0.00001652    type: torch.FloatTensor\r\nexp:            size: 10^3      elapsed avg: 0.00048499 variance: 0.00003081    type: torch.FloatTensor\r\nexp:            size: 10^4      elapsed avg: 0.00325508 variance: 0.00007704    type: torch.FloatTensor\r\nexp:            size: 10^5      elapsed avg: 0.04254997 variance: 0.00301427    type: torch.FloatTensor\r\n\r\n```"}