{"url": "https://api.github.com/repos/pytorch/pytorch/issues/599", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/599/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/599/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/599/events", "html_url": "https://github.com/pytorch/pytorch/issues/599", "id": 203469897, "node_id": "MDU6SXNzdWUyMDM0Njk4OTc=", "number": 599, "title": "Problem with GPU mem usage with RNN cuDNN backend", "user": {"login": "csarofeen", "id": 22205833, "node_id": "MDQ6VXNlcjIyMjA1ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/22205833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csarofeen", "html_url": "https://github.com/csarofeen", "followers_url": "https://api.github.com/users/csarofeen/followers", "following_url": "https://api.github.com/users/csarofeen/following{/other_user}", "gists_url": "https://api.github.com/users/csarofeen/gists{/gist_id}", "starred_url": "https://api.github.com/users/csarofeen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csarofeen/subscriptions", "organizations_url": "https://api.github.com/users/csarofeen/orgs", "repos_url": "https://api.github.com/users/csarofeen/repos", "events_url": "https://api.github.com/users/csarofeen/events{/privacy}", "received_events_url": "https://api.github.com/users/csarofeen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2017-01-26T19:46:19Z", "updated_at": "2017-01-28T22:30:08Z", "closed_at": "2017-01-28T22:30:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>cuDNN backend for RNN stabilizes at large mem usage. The following code stabilizes for me at 14+GiB reported by nvidia-smi. The same RNN without cuDNN uses &lt;2.5GiB.</p>\n<pre><code>import torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport time\nfrom torch.autograd import Variable\n\ntorch.backends.cudnn.enabled=False\n\ninput_size = 512\nhidden_size = 256\nbatch_size = 512\ntime_steps = 300\nlr   = 4e-2\n\nmodel = nn.RNNBase('LSTM', input_size, hidden_size, 1).cuda()\n\noptimizer = optim.SGD(model.parameters(),\n                      lr = lr,\n                      momentum=0.9,\n                      dampening = 0.0,\n                      weight_decay = 0.0\n                     )\n\ncriterion = nn.MSELoss().cuda()\n\ntrain_data = torch.randn(time_steps, batch_size, input_size).cuda()\n\nhidden = (Variable(torch.zeros(1, batch_size, hidden_size).cuda()),\n          Variable(torch.zeros(1, batch_size, hidden_size).cuda()))\ntarget = Variable(torch.randn(time_steps-1, input_size, hidden_size).cuda())\ninput = Variable(train_data[0:time_steps-1])\n\nfor epoch in range(5000):\n\n    start = time.time()\n    loss = 0\n    model.zero_grad()\n    hidden[0].data.fill_(0.0)\n    hidden[1].data.fill_(0.0)\n\n    output, loss = model(input, hidden)\n\n    loss = criterion(output.view(-1, input_size), target.view(-1, input_size))\n    loss.backward()\n\n    optimizer.step()\n    print(\"Epoch \" + str(epoch+1) + \" ran in \"+str( time.time() - start) + \" seconds\")\n</code></pre>", "body_text": "cuDNN backend for RNN stabilizes at large mem usage. The following code stabilizes for me at 14+GiB reported by nvidia-smi. The same RNN without cuDNN uses <2.5GiB.\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport time\nfrom torch.autograd import Variable\n\ntorch.backends.cudnn.enabled=False\n\ninput_size = 512\nhidden_size = 256\nbatch_size = 512\ntime_steps = 300\nlr   = 4e-2\n\nmodel = nn.RNNBase('LSTM', input_size, hidden_size, 1).cuda()\n\noptimizer = optim.SGD(model.parameters(),\n                      lr = lr,\n                      momentum=0.9,\n                      dampening = 0.0,\n                      weight_decay = 0.0\n                     )\n\ncriterion = nn.MSELoss().cuda()\n\ntrain_data = torch.randn(time_steps, batch_size, input_size).cuda()\n\nhidden = (Variable(torch.zeros(1, batch_size, hidden_size).cuda()),\n          Variable(torch.zeros(1, batch_size, hidden_size).cuda()))\ntarget = Variable(torch.randn(time_steps-1, input_size, hidden_size).cuda())\ninput = Variable(train_data[0:time_steps-1])\n\nfor epoch in range(5000):\n\n    start = time.time()\n    loss = 0\n    model.zero_grad()\n    hidden[0].data.fill_(0.0)\n    hidden[1].data.fill_(0.0)\n\n    output, loss = model(input, hidden)\n\n    loss = criterion(output.view(-1, input_size), target.view(-1, input_size))\n    loss.backward()\n\n    optimizer.step()\n    print(\"Epoch \" + str(epoch+1) + \" ran in \"+str( time.time() - start) + \" seconds\")", "body": "cuDNN backend for RNN stabilizes at large mem usage. The following code stabilizes for me at 14+GiB reported by nvidia-smi. The same RNN without cuDNN uses <2.5GiB.\r\n```\r\nimport torch\r\nimport torch.optim as optim\r\nimport torch.nn as nn\r\nimport time\r\nfrom torch.autograd import Variable\r\n\r\ntorch.backends.cudnn.enabled=False\r\n\r\ninput_size = 512\r\nhidden_size = 256\r\nbatch_size = 512\r\ntime_steps = 300\r\nlr   = 4e-2\r\n\r\nmodel = nn.RNNBase('LSTM', input_size, hidden_size, 1).cuda()\r\n\r\noptimizer = optim.SGD(model.parameters(),\r\n                      lr = lr,\r\n                      momentum=0.9,\r\n                      dampening = 0.0,\r\n                      weight_decay = 0.0\r\n                     )\r\n\r\ncriterion = nn.MSELoss().cuda()\r\n\r\ntrain_data = torch.randn(time_steps, batch_size, input_size).cuda()\r\n\r\nhidden = (Variable(torch.zeros(1, batch_size, hidden_size).cuda()),\r\n          Variable(torch.zeros(1, batch_size, hidden_size).cuda()))\r\ntarget = Variable(torch.randn(time_steps-1, input_size, hidden_size).cuda())\r\ninput = Variable(train_data[0:time_steps-1])\r\n\r\nfor epoch in range(5000):\r\n\r\n    start = time.time()\r\n    loss = 0\r\n    model.zero_grad()\r\n    hidden[0].data.fill_(0.0)\r\n    hidden[1].data.fill_(0.0)\r\n\r\n    output, loss = model(input, hidden)\r\n\r\n    loss = criterion(output.view(-1, input_size), target.view(-1, input_size))\r\n    loss.backward()\r\n\r\n    optimizer.step()\r\n    print(\"Epoch \" + str(epoch+1) + \" ran in \"+str( time.time() - start) + \" seconds\")\r\n```"}