{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/156883265", "pull_request_review_id": 83430728, "id": 156883265, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1Njg4MzI2NQ==", "diff_hunk": "@@ -146,31 +144,30 @@ def backward(ctx, grad):\n \n     def test_accumulate_grad(self):\n         grad_output = Variable(torch.ones(5, 5))\n-        for start_volatile, end_volatile in product((True, False), repeat=2):\n-            go1 = grad_output.data if start_volatile else grad_output\n-            go2 = grad_output.data if end_volatile else grad_output\n \n+        def compute_grad(create_graph):\n             x = Variable(torch.randn(5, 5), requires_grad=True)\n             y = x + 2\n-            y.backward(go1, retain_graph=True)\n+            y.backward(grad_output, retain_graph=True)\n             x_grad = x.grad\n-            x_grad_clone = x.grad.data.clone()\n-            y.backward(go2)\n+            x_grad_clone = x.grad.clone()\n+            y.backward(grad_output, create_graph=create_graph)\n+            return x_grad, x_grad_clone\n \n-            # That's the only case when we can accumulate in-place\n-            # TODO: reconsider this logic (see accumulate_grad.cpp)\n-            if start_volatile:\n-                expected_grad = x_grad_clone * 2\n-            else:\n-                expected_grad = x_grad_clone\n-            self.assertEqual(x_grad.data, expected_grad)\n+        # Accumulate in-place when create_graph is False\n+        x_grad, x_grad_clone = compute_grad(create_graph=False)\n+        self.assertEqual(x_grad, x_grad_clone * 2)\n+\n+        # Accumulate out-of-place when create_graph is False\n+        x_grad, x_grad_clone = compute_grad(create_graph=True)\n+        self.assertEqual(x_grad, x_grad_clone)\n \n     def test_hessian_vector(self):\n         x = Variable(torch.randn(2, 2), requires_grad=True)\n         y = Variable(torch.randn(2, 2), requires_grad=True)\n \n         z = x ** 2 + y * x + y ** 2\n-        z.backward(Variable(torch.ones(2, 2), requires_grad=True), retain_graph=True)\n+        z.backward(torch.ones(2, 2), create_graph=True)", "path": "test/test_autograd.py", "position": 90, "original_position": 90, "commit_id": "5aa6a4195c92aa7a2c416cbdff72ae50e94d4e03", "original_commit_id": "d5fa2c1e8af3471fbcd9ccb8d4a125036cd31707", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Is it now the case that passing a Variable that requires grad is not sufficient to trigger creation of the graph? If yes, we should at least print a warning", "created_at": "2017-12-14T08:52:39Z", "updated_at": "2018-11-23T15:37:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/3970#discussion_r156883265", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3970", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/156883265"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3970#discussion_r156883265"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3970"}}, "body_html": "<p>Is it now the case that passing a Variable that requires grad is not sufficient to trigger creation of the graph? If yes, we should at least print a warning</p>", "body_text": "Is it now the case that passing a Variable that requires grad is not sufficient to trigger creation of the graph? If yes, we should at least print a warning"}