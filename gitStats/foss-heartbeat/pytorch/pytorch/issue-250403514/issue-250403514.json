{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2428", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2428/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2428/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2428/events", "html_url": "https://github.com/pytorch/pytorch/issues/2428", "id": 250403514, "node_id": "MDU6SXNzdWUyNTA0MDM1MTQ=", "number": 2428, "title": "DistributedDataParallel fails if model buffers are empty", "user": {"login": "Scitator", "id": 7606451, "node_id": "MDQ6VXNlcjc2MDY0NTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7606451?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Scitator", "html_url": "https://github.com/Scitator", "followers_url": "https://api.github.com/users/Scitator/followers", "following_url": "https://api.github.com/users/Scitator/following{/other_user}", "gists_url": "https://api.github.com/users/Scitator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Scitator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Scitator/subscriptions", "organizations_url": "https://api.github.com/users/Scitator/orgs", "repos_url": "https://api.github.com/users/Scitator/repos", "events_url": "https://api.github.com/users/Scitator/events{/privacy}", "received_events_url": "https://api.github.com/users/Scitator/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-15T18:51:19Z", "updated_at": "2017-10-06T13:20:24Z", "closed_at": "2017-10-06T13:20:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>During running following <a href=\"https://github.com/pytorch/examples/blob/master/imagenet/main.py\">example</a>, I always have <code>IndexError</code> during model sync.</p>\n<p>After some experiments, I found, that I use model, without any <code>buffers</code> (it would be great if u can explain me what are they). By this way, during <a href=\"github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py#L181\">sync</a>:</p>\n<pre><code>    def _sync_params(self):\n        params = [p.data for p in self.module.parameters()]\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, param in zip(tensors, module.parameters()):\n                param.data.set_(tensor)\n\n        # cross-node buffer sync\n        buffers = list(self.module._all_buffers())\n        flat_buffers = _flatten_tensors(buffers)\n        dist.broadcast(flat_buffers, 0)\n        for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\n            buf.copy_(synced)\n\n        # intra-node buffer sync\n        result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, buf in zip(tensors, module._all_buffers()):\n                buf.set_(tensor)\n</code></pre>\n<p>There was an error with flattening empty list.</p>\n<p>My simple solution for this problem (and it works!):</p>\n<pre><code>    def _sync_params(self):\n        params = [p.data for p in self.module.parameters()]\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, param in zip(tensors, module.parameters()):\n                param.data.set_(tensor)\n        \n        buffers = list(self.module._all_buffers())\n        if len(buffers) &gt; 0:\n            # cross-node buffer sync\n            flat_buffers = _flatten_tensors(buffers)\n            dist.broadcast(flat_buffers, 0)\n            for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\n                buf.copy_(synced)\n\n            # intra-node buffer sync\n            result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\n            for tensors, module in zip(result[1:], self._module_copies[1:]):\n                for tensor, buf in zip(tensors, module._all_buffers()):\n                    buf.set_(tensor)\n</code></pre>\n<p>By this way, some questions:</p>\n<ol>\n<li>It it correct solution? Can it cause any side effects?</li>\n<li>Does model have any other optional sync params?</li>\n<li>Pull request?</li>\n</ol>", "body_text": "During running following example, I always have IndexError during model sync.\nAfter some experiments, I found, that I use model, without any buffers (it would be great if u can explain me what are they). By this way, during sync:\n    def _sync_params(self):\n        params = [p.data for p in self.module.parameters()]\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, param in zip(tensors, module.parameters()):\n                param.data.set_(tensor)\n\n        # cross-node buffer sync\n        buffers = list(self.module._all_buffers())\n        flat_buffers = _flatten_tensors(buffers)\n        dist.broadcast(flat_buffers, 0)\n        for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\n            buf.copy_(synced)\n\n        # intra-node buffer sync\n        result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, buf in zip(tensors, module._all_buffers()):\n                buf.set_(tensor)\n\nThere was an error with flattening empty list.\nMy simple solution for this problem (and it works!):\n    def _sync_params(self):\n        params = [p.data for p in self.module.parameters()]\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\n            for tensor, param in zip(tensors, module.parameters()):\n                param.data.set_(tensor)\n        \n        buffers = list(self.module._all_buffers())\n        if len(buffers) > 0:\n            # cross-node buffer sync\n            flat_buffers = _flatten_tensors(buffers)\n            dist.broadcast(flat_buffers, 0)\n            for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\n                buf.copy_(synced)\n\n            # intra-node buffer sync\n            result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\n            for tensors, module in zip(result[1:], self._module_copies[1:]):\n                for tensor, buf in zip(tensors, module._all_buffers()):\n                    buf.set_(tensor)\n\nBy this way, some questions:\n\nIt it correct solution? Can it cause any side effects?\nDoes model have any other optional sync params?\nPull request?", "body": "During running following [example](https://github.com/pytorch/examples/blob/master/imagenet/main.py), I always have `IndexError` during model sync.\r\n\r\nAfter some experiments, I found, that I use model, without any `buffers` (it would be great if u can explain me what are they). By this way, during [sync](github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py#L181):\r\n```\r\n    def _sync_params(self):\r\n        params = [p.data for p in self.module.parameters()]\r\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\r\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\r\n            for tensor, param in zip(tensors, module.parameters()):\r\n                param.data.set_(tensor)\r\n\r\n        # cross-node buffer sync\r\n        buffers = list(self.module._all_buffers())\r\n        flat_buffers = _flatten_tensors(buffers)\r\n        dist.broadcast(flat_buffers, 0)\r\n        for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\r\n            buf.copy_(synced)\r\n\r\n        # intra-node buffer sync\r\n        result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\r\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\r\n            for tensor, buf in zip(tensors, module._all_buffers()):\r\n                buf.set_(tensor)\r\n```\r\nThere was an error with flattening empty list.\r\n\r\nMy simple solution for this problem (and it works!):\r\n```\r\n    def _sync_params(self):\r\n        params = [p.data for p in self.module.parameters()]\r\n        result = broadcast_coalesced(params, self.device_ids, self.broadcast_bucket_size)\r\n        for tensors, module in zip(result[1:], self._module_copies[1:]):\r\n            for tensor, param in zip(tensors, module.parameters()):\r\n                param.data.set_(tensor)\r\n        \r\n        buffers = list(self.module._all_buffers())\r\n        if len(buffers) > 0:\r\n            # cross-node buffer sync\r\n            flat_buffers = _flatten_tensors(buffers)\r\n            dist.broadcast(flat_buffers, 0)\r\n            for buf, synced in zip(buffers, _unflatten_tensors(flat_buffers, buffers)):\r\n                buf.copy_(synced)\r\n\r\n            # intra-node buffer sync\r\n            result = broadcast_coalesced(buffers, self.device_ids, self.broadcast_bucket_size)\r\n            for tensors, module in zip(result[1:], self._module_copies[1:]):\r\n                for tensor, buf in zip(tensors, module._all_buffers()):\r\n                    buf.set_(tensor)\r\n```\r\n\r\nBy this way, some questions:\r\n1. It it correct solution? Can it cause any side effects?\r\n2. Does model have any other optional sync params?\r\n3. Pull request?"}