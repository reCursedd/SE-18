{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10260", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10260/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10260/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10260/events", "html_url": "https://github.com/pytorch/pytorch/pull/10260", "id": 347992054, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA2NDUwOTgy", "number": 10260, "title": "speed-up dataloader iteration in case the dataset is a TensorDataset \u2026", "user": {"login": "richardalligier", "id": 24826685, "node_id": "MDQ6VXNlcjI0ODI2Njg1", "avatar_url": "https://avatars3.githubusercontent.com/u/24826685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/richardalligier", "html_url": "https://github.com/richardalligier", "followers_url": "https://api.github.com/users/richardalligier/followers", "following_url": "https://api.github.com/users/richardalligier/following{/other_user}", "gists_url": "https://api.github.com/users/richardalligier/gists{/gist_id}", "starred_url": "https://api.github.com/users/richardalligier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/richardalligier/subscriptions", "organizations_url": "https://api.github.com/users/richardalligier/orgs", "repos_url": "https://api.github.com/users/richardalligier/repos", "events_url": "https://api.github.com/users/richardalligier/events{/privacy}", "received_events_url": "https://api.github.com/users/richardalligier/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-08-06T16:22:46Z", "updated_at": "2018-11-23T15:48:52Z", "closed_at": "2018-08-07T15:17:55Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10260", "html_url": "https://github.com/pytorch/pytorch/pull/10260", "diff_url": "https://github.com/pytorch/pytorch/pull/10260.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10260.patch"}, "body_html": "<p>The iteration of a Dataloader object can be speed-up when the dataset is a TensorDataset object and default_collate is used. In such a case, I have replaced <code>collate_fn([dataset[i] for i in indices])</code> by <code>[tensor.index_select(0, torch_indices) for tensor in dataset.tensors]</code>.</p>\n<p>I used the code below to test it</p>\n<pre><code>N=10000\nxs = torch.randn(N,5)\nys = torch.randn(N)\nds = torch.utils.data.TensorDataset(xs,ys)\ntrain_loader = DataLoader(ds, batch_size=256, shuffle=True, num_workers=NUM_WORKER)\nstart = time.time()\nfor _ in range(10):\n    for _ in train_loader:\n        pass\nprint(time.time() - start)\n</code></pre>\n<p>On my old 2-cores laptop (without GPU), I have compared before and after my modification:</p>\n<table>\n<thead>\n<tr>\n<th>NUM_WORKER</th>\n<th align=\"center\">Before [s]</th>\n<th align=\"right\">After [s]</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td align=\"center\">1.39</td>\n<td align=\"right\">0.09</td>\n</tr>\n<tr>\n<td>1</td>\n<td align=\"center\">6.01</td>\n<td align=\"right\">4.07</td>\n</tr>\n<tr>\n<td>2</td>\n<td align=\"center\">4.71</td>\n<td align=\"right\">3.49</td>\n</tr>\n</tbody>\n</table>", "body_text": "The iteration of a Dataloader object can be speed-up when the dataset is a TensorDataset object and default_collate is used. In such a case, I have replaced collate_fn([dataset[i] for i in indices]) by [tensor.index_select(0, torch_indices) for tensor in dataset.tensors].\nI used the code below to test it\nN=10000\nxs = torch.randn(N,5)\nys = torch.randn(N)\nds = torch.utils.data.TensorDataset(xs,ys)\ntrain_loader = DataLoader(ds, batch_size=256, shuffle=True, num_workers=NUM_WORKER)\nstart = time.time()\nfor _ in range(10):\n    for _ in train_loader:\n        pass\nprint(time.time() - start)\n\nOn my old 2-cores laptop (without GPU), I have compared before and after my modification:\n\n\n\nNUM_WORKER\nBefore [s]\nAfter [s]\n\n\n\n\n0\n1.39\n0.09\n\n\n1\n6.01\n4.07\n\n\n2\n4.71\n3.49", "body": "The iteration of a Dataloader object can be speed-up when the dataset is a TensorDataset object and default_collate is used. In such a case, I have replaced `collate_fn([dataset[i] for i in indices])` by `[tensor.index_select(0, torch_indices) for tensor in dataset.tensors]`.\r\n\r\nI used the code below to test it\r\n```\r\nN=10000\r\nxs = torch.randn(N,5)\r\nys = torch.randn(N)\r\nds = torch.utils.data.TensorDataset(xs,ys)\r\ntrain_loader = DataLoader(ds, batch_size=256, shuffle=True, num_workers=NUM_WORKER)\r\nstart = time.time()\r\nfor _ in range(10):\r\n    for _ in train_loader:\r\n        pass\r\nprint(time.time() - start)\r\n```\r\nOn my old 2-cores laptop (without GPU), I have compared before and after my modification:\r\n\r\n| NUM_WORKER        | Before [s]           | After [s]  |\r\n| ------------- |:-------------:| -----:|\r\n| 0      | 1.39 | 0.09 |\r\n| 1      | 6.01      |   4.07 |\r\n| 2 | 4.71      |    3.49 |\r\n\r\n"}