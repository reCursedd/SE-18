{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/411015824", "html_url": "https://github.com/pytorch/pytorch/pull/10260#issuecomment-411015824", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10260", "id": 411015824, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTAxNTgyNA==", "user": {"login": "richardalligier", "id": 24826685, "node_id": "MDQ6VXNlcjI0ODI2Njg1", "avatar_url": "https://avatars3.githubusercontent.com/u/24826685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/richardalligier", "html_url": "https://github.com/richardalligier", "followers_url": "https://api.github.com/users/richardalligier/followers", "following_url": "https://api.github.com/users/richardalligier/following{/other_user}", "gists_url": "https://api.github.com/users/richardalligier/gists{/gist_id}", "starred_url": "https://api.github.com/users/richardalligier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/richardalligier/subscriptions", "organizations_url": "https://api.github.com/users/richardalligier/orgs", "repos_url": "https://api.github.com/users/richardalligier/repos", "events_url": "https://api.github.com/users/richardalligier/events{/privacy}", "received_events_url": "https://api.github.com/users/richardalligier/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-07T10:48:56Z", "updated_at": "2018-08-07T10:50:18Z", "author_association": "NONE", "body_html": "<p>Thanks for your help, I think I have understood, is it something like that ?</p>\n<pre><code>class MyTensorDataset(TensorDataset):\n    def __getitem__(self,index):\n        if isinstance(index, int):\n            return super(MyTensorDataset,self).__getitem__(index)\n        else:\n            batch_index=torch.LongTensor(index)\n            return tuple(tensor.index_select(0, batch_index) for tensor in self.tensors)\n\ndef removefirstdim(iterator):\n    for tensors in iterator:\n        yield tuple(tensor[0] for tensor in tensors)\n\nN=10000\nxs = torch.randn(N,5)\nys = torch.randn(N)\nds = MyTensorDataset(xs,ys)\nbatch_sampler = BatchSampler(sampler=RandomSampler(range(N)), batch_size=256, drop_last=False)\ntrain_loader = removefirstdim(DataLoader(ds,sampler=batch_sampler, num_workers=NUM))\nstart=time.time()\nfor _ in range(10):\n    for x,y in train_loader:\n        pass\nprint(time.time()-start)\n</code></pre>\n<p>With this solution I have a speed similar to the one obtained with my modification. I used the <code>removefirstdim</code> function to remove the dimension added by the DataLoader. It might not be necessary depending on what is done inside the training loop.</p>", "body_text": "Thanks for your help, I think I have understood, is it something like that ?\nclass MyTensorDataset(TensorDataset):\n    def __getitem__(self,index):\n        if isinstance(index, int):\n            return super(MyTensorDataset,self).__getitem__(index)\n        else:\n            batch_index=torch.LongTensor(index)\n            return tuple(tensor.index_select(0, batch_index) for tensor in self.tensors)\n\ndef removefirstdim(iterator):\n    for tensors in iterator:\n        yield tuple(tensor[0] for tensor in tensors)\n\nN=10000\nxs = torch.randn(N,5)\nys = torch.randn(N)\nds = MyTensorDataset(xs,ys)\nbatch_sampler = BatchSampler(sampler=RandomSampler(range(N)), batch_size=256, drop_last=False)\ntrain_loader = removefirstdim(DataLoader(ds,sampler=batch_sampler, num_workers=NUM))\nstart=time.time()\nfor _ in range(10):\n    for x,y in train_loader:\n        pass\nprint(time.time()-start)\n\nWith this solution I have a speed similar to the one obtained with my modification. I used the removefirstdim function to remove the dimension added by the DataLoader. It might not be necessary depending on what is done inside the training loop.", "body": "Thanks for your help, I think I have understood, is it something like that ?\r\n```\r\nclass MyTensorDataset(TensorDataset):\r\n    def __getitem__(self,index):\r\n        if isinstance(index, int):\r\n            return super(MyTensorDataset,self).__getitem__(index)\r\n        else:\r\n            batch_index=torch.LongTensor(index)\r\n            return tuple(tensor.index_select(0, batch_index) for tensor in self.tensors)\r\n\r\ndef removefirstdim(iterator):\r\n    for tensors in iterator:\r\n        yield tuple(tensor[0] for tensor in tensors)\r\n\r\nN=10000\r\nxs = torch.randn(N,5)\r\nys = torch.randn(N)\r\nds = MyTensorDataset(xs,ys)\r\nbatch_sampler = BatchSampler(sampler=RandomSampler(range(N)), batch_size=256, drop_last=False)\r\ntrain_loader = removefirstdim(DataLoader(ds,sampler=batch_sampler, num_workers=NUM))\r\nstart=time.time()\r\nfor _ in range(10):\r\n    for x,y in train_loader:\r\n        pass\r\nprint(time.time()-start)\r\n```\r\nWith this solution I have a speed similar to the one obtained with my modification. I used the `removefirstdim` function to remove the dimension added by the DataLoader. It might not be necessary depending on what is done inside the training loop. "}