{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159293765", "pull_request_review_id": 86218601, "id": 159293765, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTI5Mzc2NQ==", "diff_hunk": "@@ -3492,119 +3492,133 @@ void THTensor_(bhistc)(THTensor *hist, THTensor *tensor, int64_t nbins, real min\n }\n \n // Approximate reparameterized gradient of Beta(x,alpha,beta) wrt alpha.\n-// Assumes x is close to zero.\n+// Assumes x is close to zero and uses a Taylor expansion.\n static inline real THTensor_(beta_grad_alpha_small)(real x, real alpha, real beta) {\n-  const real b1 = beta - 1;\n-  const real b2 = beta - 2;\n-  const real b3 = beta - 3;\n-  const real b4 = beta - 4;\n-  const real a0 = 1 / alpha;\n-  const real a1 = 1 / (alpha + 1);\n-  const real a2 = 1 / (alpha + 2);\n-  const real a3 = 1 / (alpha + 3);\n-  const real a4 = 1 / (alpha + 4);\n-  // Let pdf = pow(x,alpha-1) * pow(1-x,beta-1) / Beta(alpha,beta).\n-  // Let const = Beta(alpha,beta) / pow(x, alpha). Then\n-  const real one_over_const_pdf = x / TH_MATH_NAME(pow)(1 - x, beta - 1);\n-  const real const_cdf = +a0 + b1 * x * (\n-                         -a1 + b2 * x / 2 * (\n-                         +a2 + b3 * x / 3 * (\n-                         -a3 + b4 * x / 4 * (\n-                         +a4))));\n-  const real const_cdf_alpha = (log(x) + TH_MATH_NAME(TH_digamma)(alpha + beta) -\n-                                TH_MATH_NAME(TH_digamma)(alpha)) * const_cdf\n-                             + -a0 * a0 + b1 * x * (\n-                               +a1 * a1 + b2 * x / 2 * (\n-                               -a2 * a2 + b3 * x / 3 * (\n-                               +a2 * a3 + b4 * x / 4 * (\n-                               -a4))));\n-  const real result = -const_cdf_alpha * one_over_const_pdf;\n+  const real factor = TH_digamma(alpha) - TH_digamma(alpha + beta) - TH_MATH_NAME(log)(x);\n+  real numer = 1;\n+  real series = numer / alpha * (factor + 1 / alpha);\n+  for (int i = 1; i <= 10; ++i) {\n+    numer *= (i - beta) * x / i;\n+    const real denom = alpha + i;\n+    series += numer / denom * (factor + 1 / denom);\n+  }\n+  const real result = x * TH_MATH_NAME(pow)(1 - x, 1 - beta) * series;\n   return isnan(result) ? 0.0 : result;\n }\n \n // Approximate reparameterized gradient of Beta(x,alpha,beta) wrt beta.\n-// Assumes x is close to zero.\n+// Assumes x is close to zero and uses a Taylor expansion.\n static inline real THTensor_(beta_grad_beta_small)(real x, real alpha, real beta) {\n-  const real a0 = 1 / alpha;\n-  const real a1 = 1 / (alpha + 1);\n-  const real a2 = 1 / (alpha + 2);\n-  const real a3 = 1 / (alpha + 3);\n-  // Let pdf = pow(x,alpha-1) * pow(1-x,beta-1) / Beta(alpha,beta).\n-  // Let const = Beta(alpha,beta) / pow(x, alpha). Then\n-  const real one_over_const_pdf = x / TH_MATH_NAME(pow)(1 - x, beta - 1);\n-  const real const_cdf = +a0 + (beta - 1) * x * (\n-                         -a1 + (beta - 2) * x / 2 * (\n-                         +a2 + (beta - 3) * x / 3 * (\n-                         -a3)));\n-  const real const_cdf_beta = (TH_MATH_NAME(TH_digamma)(alpha + beta) -\n-                               TH_MATH_NAME(TH_digamma)(beta)) * const_cdf\n-                            + 0 + x * (\n-                            -a1 + x / 2 * (\n-                            +a2 * (2 * beta - 3) + x / 3 * (\n-                            -a3 * (3 * beta * beta - 12 * beta + 11))));\n-  const real result = -const_cdf_beta * one_over_const_pdf;\n+  const real factor = TH_digamma(alpha+beta) - TH_digamma(beta);\n+  real numer = 1;\n+  real betas = 1;\n+  real dbetas = 0;\n+  real series = factor / alpha;\n+  for (int i = 1; i <= 8; ++i) {\n+    numer *= -x / i;\n+    dbetas = dbetas * (beta - i) + betas;\n+    betas = betas * (beta - i);\n+    series += numer / (alpha + i) * (dbetas + factor * betas);\n+  }\n+  const real result = -x * TH_MATH_NAME(pow)(1 - x, 1 - beta) * series;\n   return isnan(result) ? 0.0 : result;\n }\n \n+// Approximate reparameterized gradient of Beta(x,alpha,beta) wrt alpha.\n+// Assumes alpha and beta are both large and uses a Rice saddle point expansion.\n+// To ensure numerical stability, this computation is performed at higher precision.\n+static inline real THTensor_(beta_grad_alpha_mid)(double x, double alpha, double beta) {\n+  const double total = alpha + beta;\n+  const double mean = alpha / total;\n+  const double std = sqrt(alpha * beta / (total + 1)) / total;\n+  if (mean - 0.1 * std <= x && x <= mean + 0.1 * std) {\n+    // Avoid the singularity at x = mean.\n+    const double poly = 47 * x * (beta*beta)*(beta*beta) + alpha * (\n+                      (43 + 20 * (16 + 27 * beta) * x) * (beta*beta)*beta + alpha * (\n+                      3 * (59 + 180 * beta - 90 * x) * (beta*beta) + alpha * (\n+                      (453 + 1620 * beta * (1 - x) - 455 * x) * beta + alpha * (\n+                      8 * (1 - x) * (135 * beta - 11)))));\n+    const double prefactor_num = (1 + 12 * alpha) * (1 + 12 * beta) / (total * total);\n+    const double prefactor_den = 12960 * alpha * alpha * alpha * beta * beta * (1 + 12 * total);\n+    return prefactor_num * poly / prefactor_den;\n+  }\n+  const double prefactor = x * (x-1) / sqrt(2 * alpha * beta / total);\n+  const double stirling = (1 + 1 / (12 * alpha) + 1 / (288 * alpha*alpha))\n+                        * (1 + 1 / (12 * beta) + 1 / (288 * beta*beta))\n+                        / (1 + 1 / (12 * total) + 1 / (288 * total*total));\n+  const double term1_num = 2 * (alpha*alpha) * (x - 1) + alpha * beta * (x - 1) - x * (beta*beta);\n+  const double axbx = alpha * (x-1) + beta * x;\n+  const double term1_den = sqrt(2 * alpha / beta) * pow(total, 1.5f) * axbx*axbx;\n+  const double term1 = term1_num / term1_den;\n+  const double term2 = 0.5f * log(alpha / (total * x));\n+  const double term3_num = sqrt(8 * alpha * beta / total);\n+  const double term3_den = beta * x + alpha * (x - 1);\n+  const double term3 = term3_num / term3_den;\n+  const double term4_base = beta * log(beta / (total * (1 - x))) +\n+                          alpha * log(alpha / (total * x));\n+  const double term4 = pow(term4_base, -1.5f);\n+  const double term1234 = term1 + term2 * (term3 + (x < mean ? term4 : -term4));\n+  return stirling * prefactor * term1234;", "path": "aten/src/TH/generic/THTensorMath.c", "position": 115, "original_position": 115, "commit_id": "fd940a8ed82d34d6537cacb650297f1b9c18b645", "original_commit_id": "fd940a8ed82d34d6537cacb650297f1b9c18b645", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Are you using `double` here and `real` everywhere else on purpose? I think it's ok to do all of this math in double", "created_at": "2018-01-02T19:09:35Z", "updated_at": "2018-11-23T15:37:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/4421#discussion_r159293765", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4421", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159293765"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4421#discussion_r159293765"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4421"}}, "body_html": "<p>Are you using <code>double</code> here and <code>real</code> everywhere else on purpose? I think it's ok to do all of this math in double</p>", "body_text": "Are you using double here and real everywhere else on purpose? I think it's ok to do all of this math in double"}