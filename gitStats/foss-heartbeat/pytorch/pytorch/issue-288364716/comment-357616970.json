{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/357616970", "html_url": "https://github.com/pytorch/pytorch/pull/4658#issuecomment-357616970", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4658", "id": 357616970, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzYxNjk3MA==", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-15T08:45:45Z", "updated_at": "2018-01-15T08:45:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Regarding the naming, I think <code>logits</code> is general enough to describe a mapping of values from [0, 1] to [-inf, inf]. For the multi-class case, this mapping is the log of unnormalized probability values (as such, even <code>logprobs</code> is more precise than what the mapping actually is). For Bernoulli, we could use the same mapping as the multi-class case, if we were using two parameters, and the naming wouldn't be an issue. But since we use just one parameter, we have to use log odds to map from [0, 1] to [-inf, inf]. It will be nice to keep it consistent with TensorFlow's nomenclature, but if we decide to change it, an alternate naming scheme could be <code>logits</code> for Bernoulli and <code>multinomial_logits</code> (or, <code>multinom_logits</code>) for the multi-class case, so as to cause the least amount of surprise to users used to TensorFlow's API.</p>", "body_text": "Regarding the naming, I think logits is general enough to describe a mapping of values from [0, 1] to [-inf, inf]. For the multi-class case, this mapping is the log of unnormalized probability values (as such, even logprobs is more precise than what the mapping actually is). For Bernoulli, we could use the same mapping as the multi-class case, if we were using two parameters, and the naming wouldn't be an issue. But since we use just one parameter, we have to use log odds to map from [0, 1] to [-inf, inf]. It will be nice to keep it consistent with TensorFlow's nomenclature, but if we decide to change it, an alternate naming scheme could be logits for Bernoulli and multinomial_logits (or, multinom_logits) for the multi-class case, so as to cause the least amount of surprise to users used to TensorFlow's API.", "body": "Regarding the naming, I think `logits` is general enough to describe a mapping of values from [0, 1] to [-inf, inf]. For the multi-class case, this mapping is the log of unnormalized probability values (as such, even `logprobs` is more precise than what the mapping actually is). For Bernoulli, we could use the same mapping as the multi-class case, if we were using two parameters, and the naming wouldn't be an issue. But since we use just one parameter, we have to use log odds to map from [0, 1] to [-inf, inf]. It will be nice to keep it consistent with TensorFlow's nomenclature, but if we decide to change it, an alternate naming scheme could be `logits` for Bernoulli and `multinomial_logits` (or, `multinom_logits`) for the multi-class case, so as to cause the least amount of surprise to users used to TensorFlow's API."}