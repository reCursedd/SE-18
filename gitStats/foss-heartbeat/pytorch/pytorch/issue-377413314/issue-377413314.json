{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13569", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13569/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13569/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13569/events", "html_url": "https://github.com/pytorch/pytorch/issues/13569", "id": 377413314, "node_id": "MDU6SXNzdWUzNzc0MTMzMTQ=", "number": 13569, "title": "Assertion fails when using DataParallel with nn.Embedding and max_norm != None", "user": {"login": "adefossez", "id": 1990078, "node_id": "MDQ6VXNlcjE5OTAwNzg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1990078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adefossez", "html_url": "https://github.com/adefossez", "followers_url": "https://api.github.com/users/adefossez/followers", "following_url": "https://api.github.com/users/adefossez/following{/other_user}", "gists_url": "https://api.github.com/users/adefossez/gists{/gist_id}", "starred_url": "https://api.github.com/users/adefossez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adefossez/subscriptions", "organizations_url": "https://api.github.com/users/adefossez/orgs", "repos_url": "https://api.github.com/users/adefossez/repos", "events_url": "https://api.github.com/users/adefossez/events{/privacy}", "received_events_url": "https://api.github.com/users/adefossez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "nairbv", "id": 582713, "node_id": "MDQ6VXNlcjU4MjcxMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/582713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairbv", "html_url": "https://github.com/nairbv", "followers_url": "https://api.github.com/users/nairbv/followers", "following_url": "https://api.github.com/users/nairbv/following{/other_user}", "gists_url": "https://api.github.com/users/nairbv/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairbv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairbv/subscriptions", "organizations_url": "https://api.github.com/users/nairbv/orgs", "repos_url": "https://api.github.com/users/nairbv/repos", "events_url": "https://api.github.com/users/nairbv/events{/privacy}", "received_events_url": "https://api.github.com/users/nairbv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nairbv", "id": 582713, "node_id": "MDQ6VXNlcjU4MjcxMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/582713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nairbv", "html_url": "https://github.com/nairbv", "followers_url": "https://api.github.com/users/nairbv/followers", "following_url": "https://api.github.com/users/nairbv/following{/other_user}", "gists_url": "https://api.github.com/users/nairbv/gists{/gist_id}", "starred_url": "https://api.github.com/users/nairbv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nairbv/subscriptions", "organizations_url": "https://api.github.com/users/nairbv/orgs", "repos_url": "https://api.github.com/users/nairbv/repos", "events_url": "https://api.github.com/users/nairbv/events{/privacy}", "received_events_url": "https://api.github.com/users/nairbv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-11-05T14:02:00Z", "updated_at": "2018-11-16T14:53:28Z", "closed_at": "2018-11-16T14:53:28Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>When using <code>DataParallel</code> with <code>nn.Embedding</code> with <code>max_norm</code> set to a non <code>None</code> value, the following assertion is triggered:</p>\n<p><code>RuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.</code></p>\n<h2>To Reproduce</h2>\n<p>To reproduce, use the following script:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> nn\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    device <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda<span class=\"pl-pds\">\"</span></span>\n    embedding <span class=\"pl-k\">=</span> nn.Embedding(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">16</span>, <span class=\"pl-v\">max_norm</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>).to(device)\n    batch <span class=\"pl-k\">=</span> torch.randint(<span class=\"pl-c1\">128</span>, (<span class=\"pl-c1\">32</span>, ), <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>device)\n\n    embedding.forward(batch)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>OK<span class=\"pl-pds\">\"</span></span>)\n\n    parallel <span class=\"pl-k\">=</span> nn.DataParallel(embedding)\n    parallel.forward(batch)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    main()</pre></div>\n<p>This will output the following:</p>\n<pre><code>OK\nTraceback (most recent call last):\nFile \".../lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\nFile \".../lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\nFile \".../minimal.py\", line 20, in &lt;module&gt;\n    main()\nFile \".../minimal.py\", line 16, in main\n    parallel.forward(batch)\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 143, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 153, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in parallel_apply\n    raise output\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in _worker\n    output = module(*input, **kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/modules/sparse.py\", line 113, in forward\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\nFile \".../lib/python3.7/site-packages/torch/nn/functional.py\", line 1233, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.a\n</code></pre>\n<h2>Expected behavior</h2>\n<p>I expect the <code>forward</code> call to work the same whether I use <code>DataParallel</code> or not.</p>\n<h2>Environment</h2>\n<p>PyTorch version: 1.0.0.dev20181105<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.12.2</p>\n<p>Python version: 3.7<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration:<br>\nGPU 0: Quadro GP100<br>\nGPU 1: Quadro GP100</p>\n<p>Nvidia driver version: 396.51<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.15.2)<br>\n[pip] torch (1.0.0.dev20181105)<br>\n[pip] torchvision (0.2.1)<br>\n[conda] cuda92                    1.0                           0    pytorch<br>\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch<br>\n[conda] pytorch-nightly           1.0.0.dev20181105 py3.7_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch<br>\n[conda] torchvision               0.2.1                    py37_1    pytorch</p>", "body_text": "\ud83d\udc1b Bug\nWhen using DataParallel with nn.Embedding with max_norm set to a non None value, the following assertion is triggered:\nRuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.\nTo Reproduce\nTo reproduce, use the following script:\nimport torch\nfrom torch import nn\n\n\ndef main():\n    device = \"cuda\"\n    embedding = nn.Embedding(128, 16, max_norm=1).to(device)\n    batch = torch.randint(128, (32, ), device=device)\n\n    embedding.forward(batch)\n    print(\"OK\")\n\n    parallel = nn.DataParallel(embedding)\n    parallel.forward(batch)\n\n\nif __name__ == \"__main__\":\n    main()\nThis will output the following:\nOK\nTraceback (most recent call last):\nFile \".../lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\nFile \".../lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\nFile \".../minimal.py\", line 20, in <module>\n    main()\nFile \".../minimal.py\", line 16, in main\n    parallel.forward(batch)\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 143, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 153, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in parallel_apply\n    raise output\nFile \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in _worker\n    output = module(*input, **kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nFile \".../lib/python3.7/site-packages/torch/nn/modules/sparse.py\", line 113, in forward\n    self.norm_type, self.scale_grad_by_freq, self.sparse)\nFile \".../lib/python3.7/site-packages/torch/nn/functional.py\", line 1233, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\nRuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.a\n\nExpected behavior\nI expect the forward call to work the same whether I use DataParallel or not.\nEnvironment\nPyTorch version: 1.0.0.dev20181105\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: Quadro GP100\nGPU 1: Quadro GP100\nNvidia driver version: 396.51\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] numpy (1.15.2)\n[pip] torch (1.0.0.dev20181105)\n[pip] torchvision (0.2.1)\n[conda] cuda92                    1.0                           0    pytorch\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\n[conda] pytorch-nightly           1.0.0.dev20181105 py3.7_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch\n[conda] torchvision               0.2.1                    py37_1    pytorch", "body": "## \ud83d\udc1b Bug\r\n\r\nWhen using `DataParallel` with `nn.Embedding` with `max_norm` set to a non `None` value, the following assertion is triggered:\r\n\r\n`RuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.`\r\n\r\n## To Reproduce\r\n\r\nTo reproduce, use the following script:\r\n\r\n```python\r\nimport torch\r\nfrom torch import nn\r\n\r\n\r\ndef main():\r\n    device = \"cuda\"\r\n    embedding = nn.Embedding(128, 16, max_norm=1).to(device)\r\n    batch = torch.randint(128, (32, ), device=device)\r\n\r\n    embedding.forward(batch)\r\n    print(\"OK\")\r\n\r\n    parallel = nn.DataParallel(embedding)\r\n    parallel.forward(batch)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThis will output the following:\r\n\r\n    OK\r\n    Traceback (most recent call last):\r\n    File \".../lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n        \"__main__\", mod_spec)\r\n    File \".../lib/python3.7/runpy.py\", line 85, in _run_code\r\n        exec(code, run_globals)\r\n    File \".../minimal.py\", line 20, in <module>\r\n        main()\r\n    File \".../minimal.py\", line 16, in main\r\n        parallel.forward(batch)\r\n    File \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 143, in forward\r\n        outputs = self.parallel_apply(replicas, inputs, kwargs)\r\n    File \".../lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 153, in parallel_apply\r\n        return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\r\n    File \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in parallel_apply\r\n        raise output\r\n    File \".../lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in _worker\r\n        output = module(*input, **kwargs)\r\n    File \".../lib/python3.7/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n        result = self.forward(*input, **kwargs)\r\n    File \".../lib/python3.7/site-packages/torch/nn/modules/sparse.py\", line 113, in forward\r\n        self.norm_type, self.scale_grad_by_freq, self.sparse)\r\n    File \".../lib/python3.7/site-packages/torch/nn/functional.py\", line 1233, in embedding\r\n        return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\n    RuntimeError: output_nr_ == 0 ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1541411195070/work/torch/csrc/autograd/variable.cpp:196, please report a bug to PyTorch.a\r\n\r\n## Expected behavior\r\n\r\nI expect the `forward` call to work the same whether I use `DataParallel` or not.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.0.0.dev20181105\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration:\r\nGPU 0: Quadro GP100\r\nGPU 1: Quadro GP100\r\n\r\nNvidia driver version: 396.51\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.2)\r\n[pip] torch (1.0.0.dev20181105)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda92                    1.0                           0    pytorch\r\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\r\n[conda] pytorch-nightly           1.0.0.dev20181105 py3.7_cuda9.2.148_cudnn7.1.4_0  [cuda92]  pytorch\r\n[conda] torchvision               0.2.1                    py37_1    pytorch\r\n\r\n"}