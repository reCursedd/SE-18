{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/119988236", "pull_request_review_id": 41921728, "id": 119988236, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExOTk4ODIzNg==", "diff_hunk": "@@ -1,71 +1,74 @@\n import torch\n \n from ..function import Function\n+from ..variable import Variable\n \n \n class Diag(Function):\n \n-    def __init__(self, diagonal_idx=0):\n-        super(Diag, self).__init__()\n-        self.diagonal_idx = diagonal_idx\n+    @staticmethod\n+    def forward(ctx, input, diagonal_idx=0):\n+        ctx.diagonal_idx = diagonal_idx\n+        return input.diag(ctx.diagonal_idx)\n \n-    def forward(self, input):\n-        return input.diag(self.diagonal_idx)\n-\n-    def backward(self, grad_output):\n-        return grad_output.diag(self.diagonal_idx)\n+    @staticmethod\n+    def backward(ctx, grad_output):\n+        return grad_output.diag(ctx.diagonal_idx), None\n \n \n class Tril(Function):\n \n-    def __init__(self, diagonal_idx=0):\n-        super(Tril, self).__init__()\n-        self.diagonal_idx = diagonal_idx\n-\n-    def forward(self, input):\n-        return input.tril(self.diagonal_idx)\n+    @staticmethod\n+    def forward(ctx, input, diagonal_idx=0):\n+        ctx.diagonal_idx = diagonal_idx\n+        return input.tril(ctx.diagonal_idx)\n \n-    def backward(self, grad_output):\n-        return grad_output.tril(self.diagonal_idx)\n+    @staticmethod\n+    def backward(ctx, grad_output):\n+        return grad_output.tril(ctx.diagonal_idx), None\n \n \n class Triu(Function):\n \n-    def __init__(self, diagonal_idx=0):\n-        super(Triu, self).__init__()\n-        self.diagonal_idx = diagonal_idx\n-\n-    def forward(self, input):\n-        return input.triu(self.diagonal_idx)\n+    @staticmethod\n+    def forward(ctx, input, diagnoal_idx=0):\n+        ctx.diagonal_idx = diagnoal_idx\n+        return input.triu(ctx.diagonal_idx)\n \n-    def backward(self, grad_output):\n-        return grad_output.triu(self.diagonal_idx)\n+    @staticmethod\n+    def backward(ctx, grad_output):\n+        return grad_output.triu(ctx.diagonal_idx), None\n \n \n class Trace(Function):\n \n-    def forward(self, input):\n-        self.isize = input.size()\n-        return input.new((input.trace(),))\n-\n-    def backward(self, grad_output):\n-        isize = self.isize\n-        grad_input = grad_output.new(isize).zero_()\n-        grad_input.view(-1)[::(isize[1] + 1)] = grad_output[0]\n+    @staticmethod\n+    def forward(ctx, input):\n+        ctx.isize = input.size()\n+        return input.new((input.trace(), ))\n+\n+    @staticmethod\n+    def backward(ctx, grad_output):\n+        isize = ctx.isize\n+        mask = grad_output.data.new(isize).zero_()\n+        mask.view(-1)[::(isize[1] + 1)] = 1\n+        mask = Variable(mask)\n+        grad_output_expand = grad_output.view(1, 1).expand(isize)\n+        grad_input = mask * grad_output_expand", "path": "torch/autograd/_functions/linalg.py", "position": null, "original_position": 89, "commit_id": "2546d592aee0f10cb73960e820cde532167e35c2", "original_commit_id": "ee4786630655578b251f7bb32a508d0a87df88f4", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "You're right. But this will work:\r\n```python\r\nclass Trace(Function):\r\n\r\n    @staticmethod\r\n    def forward(ctx, input):\r\n        ctx.isize = input.size()\r\n        return input.new((input.trace(), ))\r\n\r\n    @staticmethod\r\n    def backward(ctx, grad_output):\r\n        isize = ctx.isize\r\n        min_size = min(isize)\r\n        grad_input = Variable(grad_output.data.new(isize).zero_()).view(-1)\r\n        grad_input[::(isize[1] + 1)] = grad_output.expand(min_size)\r\n        return grad_input.view(isize)\r\n```", "created_at": "2017-06-03T15:06:53Z", "updated_at": "2018-11-23T15:33:38Z", "html_url": "https://github.com/pytorch/pytorch/pull/1638#discussion_r119988236", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1638", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/119988236"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1638#discussion_r119988236"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1638"}}, "body_html": "<p>You're right. But this will work:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Trace</span>(<span class=\"pl-e\">Function</span>):\n\n    <span class=\"pl-en\">@</span><span class=\"pl-c1\">staticmethod</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\">ctx</span>, <span class=\"pl-smi\">input</span>):\n        ctx.isize <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.size()\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">input</span>.new((<span class=\"pl-c1\">input</span>.trace(), ))\n\n    <span class=\"pl-en\">@</span><span class=\"pl-c1\">staticmethod</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">backward</span>(<span class=\"pl-smi\">ctx</span>, <span class=\"pl-smi\">grad_output</span>):\n        isize <span class=\"pl-k\">=</span> ctx.isize\n        min_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">min</span>(isize)\n        grad_input <span class=\"pl-k\">=</span> Variable(grad_output.data.new(isize).zero_()).view(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        grad_input[::(isize[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>)] <span class=\"pl-k\">=</span> grad_output.expand(min_size)\n        <span class=\"pl-k\">return</span> grad_input.view(isize)</pre></div>", "body_text": "You're right. But this will work:\nclass Trace(Function):\n\n    @staticmethod\n    def forward(ctx, input):\n        ctx.isize = input.size()\n        return input.new((input.trace(), ))\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        isize = ctx.isize\n        min_size = min(isize)\n        grad_input = Variable(grad_output.data.new(isize).zero_()).view(-1)\n        grad_input[::(isize[1] + 1)] = grad_output.expand(min_size)\n        return grad_input.view(isize)", "in_reply_to_id": 118332961}