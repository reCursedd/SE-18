{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3022", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3022/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3022/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3022/events", "html_url": "https://github.com/pytorch/pytorch/issues/3022", "id": 263698513, "node_id": "MDU6SXNzdWUyNjM2OTg1MTM=", "number": 3022, "title": "Reliably repeating pytorch system crash/reboot when using imagenet examples", "user": {"login": "castleguarders", "id": 25285331, "node_id": "MDQ6VXNlcjI1Mjg1MzMx", "avatar_url": "https://avatars3.githubusercontent.com/u/25285331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/castleguarders", "html_url": "https://github.com/castleguarders", "followers_url": "https://api.github.com/users/castleguarders/followers", "following_url": "https://api.github.com/users/castleguarders/following{/other_user}", "gists_url": "https://api.github.com/users/castleguarders/gists{/gist_id}", "starred_url": "https://api.github.com/users/castleguarders/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/castleguarders/subscriptions", "organizations_url": "https://api.github.com/users/castleguarders/orgs", "repos_url": "https://api.github.com/users/castleguarders/repos", "events_url": "https://api.github.com/users/castleguarders/events{/privacy}", "received_events_url": "https://api.github.com/users/castleguarders/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 26, "created_at": "2017-10-08T07:06:33Z", "updated_at": "2018-11-12T16:16:04Z", "closed_at": "2017-10-10T13:49:03Z", "author_association": "NONE", "body_html": "<p>So I have a 100% repeatable system crash (reboot) when trying to run the imagenet example (2012 dataset). resnet18 defaults. The crash seems to happen at Variable.py at torch.autograd.backward(..) (line 158).</p>\n<p>I am able to run the basic mnist example successfully.</p>\n<p>Setup: Ubuntu 16.04, 4.10.0-35-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177669684\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/39\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/39/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/39\">#39</a>~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>python --version Python 3.6.2 :: Anaconda, Inc.</p>\n<p>/usr/local/cuda/bin/nvcc --version<br>\nnvcc: NVIDIA (R) Cuda compiler driver<br>\nCopyright (c) 2005-2017 NVIDIA Corporation<br>\nBuilt on Fri_Sep__1_21:08:03_CDT_2017<br>\nCuda compilation tools, release 9.0, V9.0.176</p>\n<p>nvidia-smi output.<br>\nSat Oct  7 23:51:53 2017<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |<br>\n| 14%   51C    P8    18W / 250W |    650MiB / 11170MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1335      G   /usr/lib/xorg/Xorg                           499MiB |<br>\n|    0      2231      G   cinnamon                                      55MiB |<br>\n|    0      3390      G   ...-token=C6DE372B6D9D4FCD6453869AF4C6B4E5    93MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>torch/vision was built locally on the machine from master. No issues at compile or install time, other than the normal compile time warnings...</p>\n<p>Happy to help get further information..</p>", "body_text": "So I have a 100% repeatable system crash (reboot) when trying to run the imagenet example (2012 dataset). resnet18 defaults. The crash seems to happen at Variable.py at torch.autograd.backward(..) (line 158).\nI am able to run the basic mnist example successfully.\nSetup: Ubuntu 16.04, 4.10.0-35-generic #39~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\npython --version Python 3.6.2 :: Anaconda, Inc.\n/usr/local/cuda/bin/nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2017 NVIDIA Corporation\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\nCuda compilation tools, release 9.0, V9.0.176\nnvidia-smi output.\nSat Oct  7 23:51:53 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |\n| 14%   51C    P8    18W / 250W |    650MiB / 11170MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1335      G   /usr/lib/xorg/Xorg                           499MiB |\n|    0      2231      G   cinnamon                                      55MiB |\n|    0      3390      G   ...-token=C6DE372B6D9D4FCD6453869AF4C6B4E5    93MiB |\n+-----------------------------------------------------------------------------+\ntorch/vision was built locally on the machine from master. No issues at compile or install time, other than the normal compile time warnings...\nHappy to help get further information..", "body": "So I have a 100% repeatable system crash (reboot) when trying to run the imagenet example (2012 dataset). resnet18 defaults. The crash seems to happen at Variable.py at torch.autograd.backward(..) (line 158).\r\n\r\nI am able to run the basic mnist example successfully. \r\n\r\n Setup: Ubuntu 16.04, 4.10.0-35-generic #39~16.04.1-Ubuntu SMP Wed Sep 13 09:02:42 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\npython --version Python 3.6.2 :: Anaconda, Inc.\r\n\r\n/usr/local/cuda/bin/nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n\r\nnvidia-smi output.\r\nSat Oct  7 23:51:53 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |\r\n| 14%   51C    P8    18W / 250W |    650MiB / 11170MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1335      G   /usr/lib/xorg/Xorg                           499MiB |\r\n|    0      2231      G   cinnamon                                      55MiB |\r\n|    0      3390      G   ...-token=C6DE372B6D9D4FCD6453869AF4C6B4E5    93MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\ntorch/vision was built locally on the machine from master. No issues at compile or install time, other than the normal compile time warnings...\r\n\r\nHappy to help get further information..\r\n"}