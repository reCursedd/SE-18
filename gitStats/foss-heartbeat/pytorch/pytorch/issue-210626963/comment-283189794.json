{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/283189794", "html_url": "https://github.com/pytorch/pytorch/issues/871#issuecomment-283189794", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/871", "id": 283189794, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MzE4OTc5NA==", "user": {"login": "ankitkv", "id": 3175634, "node_id": "MDQ6VXNlcjMxNzU2MzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3175634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankitkv", "html_url": "https://github.com/ankitkv", "followers_url": "https://api.github.com/users/ankitkv/followers", "following_url": "https://api.github.com/users/ankitkv/following{/other_user}", "gists_url": "https://api.github.com/users/ankitkv/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankitkv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankitkv/subscriptions", "organizations_url": "https://api.github.com/users/ankitkv/orgs", "repos_url": "https://api.github.com/users/ankitkv/repos", "events_url": "https://api.github.com/users/ankitkv/events{/privacy}", "received_events_url": "https://api.github.com/users/ankitkv/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-28T23:02:05Z", "updated_at": "2017-02-28T23:02:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4529377\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/killeent\">@killeent</a> I was able to reproduce the second issue a bunch of times, and I tried dumping the probability matrix whenever that happens. unfortunately, just loading it and calling <code>multinomial</code> on it doesn't seem to reproduce it immediately. based on my outputs in the bug report, this code usually runs into the problem at some point (longest I've seen is 30M iters):</p>\n<pre><code>from __future__ import print_function\n\nimport torch\n\nprob = torch.cuda.FloatTensor(\n    [[0.0017,  0.8274,  0.1657,  0.0004,  0.0017,  0.0031],\n     [0.0123,  0.0157,  0.0001,  0.0020,  0.0015,  0.9683],\n     [0.0067,  0.1369,  0.8092,  0.0422,  0.0030,  0.0021],\n     [0.1306,  0.0887,  0.7521,  0.0024,  0.0005,  0.0258],\n     [0.0425,  0.5981,  0.0140,  0.0565,  0.1005,  0.1885],\n     [0.0006,  0.0017,  0.9819,  0.0114,  0.0038,  0.0007]])\n\ni = 0\nwhile True:\n    nprob = prob + torch.randn(prob.size()).cuda()*1e-3\n    sampled = torch.multinomial(nprob, 1)\n    if ((sampled &gt; 5).sum()):\n        print('\\niter', i)\n        print('\\nprob:', nprob)\n        print('sampled:', sampled)\n        break\n    if i % 10000 == 0:\n        print('iter', i)\n    i += 1\n</code></pre>", "body_text": "@killeent I was able to reproduce the second issue a bunch of times, and I tried dumping the probability matrix whenever that happens. unfortunately, just loading it and calling multinomial on it doesn't seem to reproduce it immediately. based on my outputs in the bug report, this code usually runs into the problem at some point (longest I've seen is 30M iters):\nfrom __future__ import print_function\n\nimport torch\n\nprob = torch.cuda.FloatTensor(\n    [[0.0017,  0.8274,  0.1657,  0.0004,  0.0017,  0.0031],\n     [0.0123,  0.0157,  0.0001,  0.0020,  0.0015,  0.9683],\n     [0.0067,  0.1369,  0.8092,  0.0422,  0.0030,  0.0021],\n     [0.1306,  0.0887,  0.7521,  0.0024,  0.0005,  0.0258],\n     [0.0425,  0.5981,  0.0140,  0.0565,  0.1005,  0.1885],\n     [0.0006,  0.0017,  0.9819,  0.0114,  0.0038,  0.0007]])\n\ni = 0\nwhile True:\n    nprob = prob + torch.randn(prob.size()).cuda()*1e-3\n    sampled = torch.multinomial(nprob, 1)\n    if ((sampled > 5).sum()):\n        print('\\niter', i)\n        print('\\nprob:', nprob)\n        print('sampled:', sampled)\n        break\n    if i % 10000 == 0:\n        print('iter', i)\n    i += 1", "body": "@killeent I was able to reproduce the second issue a bunch of times, and I tried dumping the probability matrix whenever that happens. unfortunately, just loading it and calling `multinomial` on it doesn't seem to reproduce it immediately. based on my outputs in the bug report, this code usually runs into the problem at some point (longest I've seen is 30M iters):\r\n\r\n```\r\nfrom __future__ import print_function\r\n\r\nimport torch\r\n\r\nprob = torch.cuda.FloatTensor(\r\n    [[0.0017,  0.8274,  0.1657,  0.0004,  0.0017,  0.0031],\r\n     [0.0123,  0.0157,  0.0001,  0.0020,  0.0015,  0.9683],\r\n     [0.0067,  0.1369,  0.8092,  0.0422,  0.0030,  0.0021],\r\n     [0.1306,  0.0887,  0.7521,  0.0024,  0.0005,  0.0258],\r\n     [0.0425,  0.5981,  0.0140,  0.0565,  0.1005,  0.1885],\r\n     [0.0006,  0.0017,  0.9819,  0.0114,  0.0038,  0.0007]])\r\n\r\ni = 0\r\nwhile True:\r\n    nprob = prob + torch.randn(prob.size()).cuda()*1e-3\r\n    sampled = torch.multinomial(nprob, 1)\r\n    if ((sampled > 5).sum()):\r\n        print('\\niter', i)\r\n        print('\\nprob:', nprob)\r\n        print('sampled:', sampled)\r\n        break\r\n    if i % 10000 == 0:\r\n        print('iter', i)\r\n    i += 1\r\n```"}