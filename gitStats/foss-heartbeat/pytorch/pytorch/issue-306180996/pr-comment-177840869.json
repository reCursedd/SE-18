{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/177840869", "pull_request_review_id": 107789557, "id": 177840869, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3Nzg0MDg2OQ==", "diff_hunk": "@@ -0,0 +1,317 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/Config.h\"\n+#include \"ATen/Dispatch.h\"\n+#include \"ATen/NativeFunctions.h\"\n+#include \"ATen/native/SpectralOpsUtils.h\"\n+#include \"ATen/native/cuda/CuFFTUtils.h\"\n+\n+#include \"ATen/cuda/AccumulateType.cuh\"\n+#include \"ATen/cuda/CUDATensorMethods.cuh\"\n+#include \"ATen/cuda/CUDATypeConversion.cuh\"\n+\n+#include <THC/THCDeviceUtils.cuh>\n+#include <THC/THCNumerics.cuh>\n+#include <THC/THCTensorMathReduce.cuh>\n+#include <THC/THCTensorSort.cuh>\n+#include <THC/THCThrustAllocator.cuh>\n+#include <THCUNN/THCHalfAutoNumerics.cuh>\n+\n+#include <thrust/execution_policy.h>\n+#include <thrust/unique.h>\n+#include <cufft.h>\n+#include <cufftXt.h>\n+#include <cmath>\n+#include <numeric>\n+#include <iostream>\n+\n+namespace at { namespace native {\n+\n+__forceinline__\n+static bool is_pow_of_two(long long int  x) {\n+  return (x & (x - 1)) == 0;\n+}\n+\n+// In real-to-complex transform, cuFFT only fills half of the values due to\n+// conjugate symmetry. See native/SpectralUtils.h for more details.\n+// The following structs are used to fill in the other half with symmetry in\n+// case of real-to-complex transform with onesided=False flag.\n+\n+// counting_iterator => index to fill\n+struct cnt_to_dst_idx_functor : public thrust::unary_function<int64_t, int64_t>\n+{\n+  const int64_t last_dim_size;\n+  const int64_t last_dim_start_slice;\n+  const int64_t last_dim_to_fill_size;\n+\n+  cnt_to_dst_idx_functor(int64_t last_dim_size, int64_t last_dim_start_slice) :\n+    last_dim_size(last_dim_size), last_dim_start_slice(last_dim_start_slice),\n+    last_dim_to_fill_size(last_dim_size - last_dim_start_slice) {}\n+\n+  __host__ __device__ __forceinline__\n+  int64_t operator()(const int64_t& i) const\n+  {\n+    int64_t imag = i % 2;\n+    int64_t idx = i / 2;\n+    int64_t num_dim = idx / last_dim_to_fill_size;\n+    int64_t slice_idx = idx % last_dim_to_fill_size;\n+    return (num_dim * last_dim_size + last_dim_start_slice + slice_idx) * 2 + imag;\n+  }\n+};\n+\n+// index to fill => index to read from\n+template <typename scalar_t>\n+struct dst_idx_to_src_functor : public thrust::unary_function<int64_t, scalar_t>\n+{\n+  // output can have at most dim 5 (batch + 3 signal dim + real/imag)\n+  int64_t sizes[5], strides[5];\n+  const int64_t signal_ndim;\n+  scalar_t *data;  // device ptr\n+\n+  dst_idx_to_src_functor(const Tensor& batched_complex_signal)\n+    : signal_ndim(batched_complex_signal.dim() - 1),\n+      data(batched_complex_signal.data<scalar_t>()) {\n+    for (int64_t i = 0; i < signal_ndim; i++) {\n+      sizes[i] = batched_complex_signal.size(i);\n+      strides[i] = batched_complex_signal.stride(i);\n+    }\n+  }\n+\n+  __device__ __forceinline__\n+  scalar_t operator()(const int64_t& write_idx_with_imag) const\n+  {\n+    int64_t imag = write_idx_with_imag % 2;\n+    // all but first (batch) and last (real/imag) dims need to be reflected\n+    int64_t read_idx = 0;\n+    int64_t remainder = write_idx_with_imag - imag;\n+    int64_t dim_idx, dim_stride;\n+    for (int64_t i = 0; i < signal_ndim; i++) {\n+      dim_stride = strides[i];\n+      dim_idx = remainder / dim_stride;\n+      if (i == 0) {\n+        read_idx += dim_idx * dim_stride;\n+      } else if (dim_idx != 0) {\n+        read_idx += (sizes[i] - dim_idx) * dim_stride;\n+      }\n+      remainder = remainder % dim_stride;\n+    }\n+    if (imag) {\n+      return -data[read_idx + 1];\n+    } else {\n+      return data[read_idx];\n+    }\n+  }\n+};\n+\n+// input should be a contiguous batched tensor of same size as full (twosided)\n+// signals, but only contains half (onesided) of the values.\n+// This function modifies inplace.\n+__forceinline__\n+static void _fft_fill_with_conjugate_symmetry_(Tensor& input,", "path": "aten/src/ATen/native/cuda/SpectralOps.cu", "position": 109, "original_position": 109, "commit_id": "0f0d59ae356362438b95c5bccb195be5e283c849", "original_commit_id": "0f0d59ae356362438b95c5bccb195be5e283c849", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "This thrust CUDA implementation looks suspiciously low level. Do we really not have something that already does this for us? This is just reflecting half of a tensor buffer, is that right?", "created_at": "2018-03-28T18:07:11Z", "updated_at": "2018-11-23T15:41:14Z", "html_url": "https://github.com/pytorch/pytorch/pull/5856#discussion_r177840869", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5856", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/177840869"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5856#discussion_r177840869"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5856"}}, "body_html": "<p>This thrust CUDA implementation looks suspiciously low level. Do we really not have something that already does this for us? This is just reflecting half of a tensor buffer, is that right?</p>", "body_text": "This thrust CUDA implementation looks suspiciously low level. Do we really not have something that already does this for us? This is just reflecting half of a tensor buffer, is that right?"}