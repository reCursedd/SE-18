{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176785783", "pull_request_review_id": 106556086, "id": 176785783, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3Njc4NTc4Mw==", "diff_hunk": "@@ -5,33 +5,152 @@\n #endif\n \n #include \"ATen/ATen.h\"\n+#include \"ATen/Config.h\"\n #include \"ATen/NativeFunctions.h\"\n-#include \"ATen/WrapDimUtils.h\"\n-#include \"ATen/ExpandUtils.h\"\n+#include \"ATen/native/SpectralOpsUtils.h\"\n \n #include <algorithm>\n-#include <functional>\n-#include <numeric>\n #include <vector>\n-\n+#include <cmath>\n \n namespace at { namespace native {\n \n-// Since real-to-complex satisfy the Hermitian symmetry, i.e.,\n-// X[m, \\omega] = X[m, N - \\omega]*. We return only the first floor(N / 2) + 1\n-// values by default. This is also the assumption in libraries including cuFFT.\n-static inline int64_t infer_ft_complex_length(int64_t real_length) {\n-  return (real_length >> 1) + 1;\n+static inline Tensor _fft(const Tensor &self, const int64_t signal_ndim,\n+           const bool complex_input, const bool complex_output,\n+           const bool inverse, IntList signal_sizes, const bool normalized,\n+           const bool onesided) {\n+\n+  if (signal_ndim < 1 || signal_ndim > 3) {\n+    std::ostringstream ss;\n+    ss << \"Expected signal_ndim to be 1, 2, or 3, but got signal_ndim=\"\n+       << signal_ndim;\n+    throw std::runtime_error(ss.str());\n+  }\n+  if (!at::isFloatingType(self.type().scalarType())) {\n+    std::ostringstream ss;\n+    ss << \"Expected an input tensor of floating types, but got input \"\n+       << self.type() << self.sizes();\n+    throw std::runtime_error(ss.str());\n+  }\n+\n+  auto signal_tensor_ndim = signal_ndim + (int) complex_input;  // add complex dim\n+  if (self.dim() != signal_tensor_ndim && self.dim() != signal_tensor_ndim + 1) {\n+    std::ostringstream ss;\n+    ss << \"Given signal_ndim=\" << signal_ndim << \", expected an input tensor \"\n+       << \"of \" << signal_tensor_ndim << \"D or \" << signal_tensor_ndim + 1\n+       << \"D (batch mode)\";\n+    if (complex_input) {\n+      ss << \" (complex input adds an extra dimension)\";\n+    }\n+    ss << \", but got input \" << self.type() << self.sizes();\n+    throw std::runtime_error(ss.str());\n+  }\n+  bool is_batched = self.dim() == signal_tensor_ndim + 1;\n+\n+  Tensor input = self;\n+\n+  if (!is_batched) {\n+    input = input.unsqueeze(0);\n+  }\n+\n+  if (complex_input) {\n+    if (input.size(signal_ndim + 1) != 2) {\n+      std::ostringstream ss;\n+      ss << \"Expected an input tensor with a last dimension of size 2 \"\n+         << \"representing real + imaginary components, but got input \"\n+         << self.type() << self.sizes();\n+      throw std::runtime_error(ss.str());\n+    }\n+  }\n+\n+  // build signal_sizes and output_size\n+  if (signal_sizes.size() > 0 && (int64_t) signal_sizes.size() != signal_ndim) {\n+    std::ostringstream ss;\n+    ss << \"Expected signal_sizes to be empty (default) or of signal_ndim=\"\n+       << signal_ndim << \"D, but got signal_sizes=\" << signal_sizes;\n+    throw std::runtime_error(ss.str());\n+  }\n+  std::vector<int64_t> output_sizes(signal_ndim + 1 + (int) complex_output);\n+  output_sizes[0] = input.size(0);\n+  std::vector<int64_t> checked_signal_sizes(signal_ndim);\n+  int64_t input_size;\n+  for (int64_t i = 0; i < signal_ndim; i++) {\n+    input_size = input.size(i + 1);\n+    if (i == signal_ndim - 1 && onesided && complex_input && !complex_output) {\n+      // if last dim and complex-to-real onesided, input is only half of\n+      // signal, and we need to infer basing on signal_sizes, if given", "path": "aten/src/ATen/native/SpectralOps.cpp", "position": null, "original_position": 87, "commit_id": "0f0d59ae356362438b95c5bccb195be5e283c849", "original_commit_id": "1e3e1fdf253de18864657ebecdf9065ce2f465e1", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "I'm... guessing there is a doc somewhere which describes this? Can we have a link to it? :)", "created_at": "2018-03-23T16:10:35Z", "updated_at": "2018-11-23T15:41:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/5856#discussion_r176785783", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5856", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176785783"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5856#discussion_r176785783"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5856"}}, "body_html": "<p>I'm... guessing there is a doc somewhere which describes this? Can we have a link to it? :)</p>", "body_text": "I'm... guessing there is a doc somewhere which describes this? Can we have a link to it? :)"}