{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4660", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4660/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4660/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4660/events", "html_url": "https://github.com/pytorch/pytorch/issues/4660", "id": 288376719, "node_id": "MDU6SXNzdWUyODgzNzY3MTk=", "number": 4660, "title": "[Feature proposal] Add MC-derived optimizers", "user": {"login": "ssequeira", "id": 10168627, "node_id": "MDQ6VXNlcjEwMTY4NjI3", "avatar_url": "https://avatars3.githubusercontent.com/u/10168627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ssequeira", "html_url": "https://github.com/ssequeira", "followers_url": "https://api.github.com/users/ssequeira/followers", "following_url": "https://api.github.com/users/ssequeira/following{/other_user}", "gists_url": "https://api.github.com/users/ssequeira/gists{/gist_id}", "starred_url": "https://api.github.com/users/ssequeira/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ssequeira/subscriptions", "organizations_url": "https://api.github.com/users/ssequeira/orgs", "repos_url": "https://api.github.com/users/ssequeira/repos", "events_url": "https://api.github.com/users/ssequeira/events{/privacy}", "received_events_url": "https://api.github.com/users/ssequeira/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-01-14T02:26:56Z", "updated_at": "2018-01-14T02:33:54Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Recent papers have proposed SGD variants based on stochastic gradient MCMC algorithms that can complete with SOTA optimizers like Adam. Would anyone be interested in an implementation of Santa (<a href=\"http://people.ee.duke.edu/~lcarin/Santa_aistats16.pdf\" rel=\"nofollow\">Chen et al. 2016</a>) and relativistic stochastic gradient descent (<a href=\"http://proceedings.mlr.press/v54/lu17b/lu17b.pdf\" rel=\"nofollow\">Lu, Perrone et al. 2017</a>)?</p>", "body_text": "Recent papers have proposed SGD variants based on stochastic gradient MCMC algorithms that can complete with SOTA optimizers like Adam. Would anyone be interested in an implementation of Santa (Chen et al. 2016) and relativistic stochastic gradient descent (Lu, Perrone et al. 2017)?", "body": "Recent papers have proposed SGD variants based on stochastic gradient MCMC algorithms that can complete with SOTA optimizers like Adam. Would anyone be interested in an implementation of Santa ([Chen et al. 2016](http://people.ee.duke.edu/~lcarin/Santa_aistats16.pdf)) and relativistic stochastic gradient descent ([Lu, Perrone et al. 2017](http://proceedings.mlr.press/v54/lu17b/lu17b.pdf))?"}