{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144852147", "pull_request_review_id": 69566552, "id": 144852147, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDg1MjE0Nw==", "diff_hunk": "@@ -0,0 +1,191 @@\n+// updateOutput, updateGradInput Kernels ported from Sergey Zagoruyko's pyinn, which itself was a\n+// port from Caffe\n+\n+#include \"THCUNN.h\"\n+#include \"THCDeviceTensor.cuh\"\n+#include \"THCDeviceTensorUtils.cuh\"\n+#include \"THCNumerics.cuh\"\n+#include \"THCReduceApplyUtils.cuh\"\n+#include \"THCSortUtils.cuh\"\n+#include \"THCTensorMathReduce.cuh\"\n+#include \"SharedMem.cuh\"\n+#include \"common.h\"\n+\n+template <typename T, typename IndexType>\n+__global__ void spatialDepthwiseConvolutionUpdateOutput(\n+    const THCDeviceTensor<T, 4> input,\n+    THCDeviceTensor<T, 4> output,\n+    const THCDeviceTensor<T, 4> weight,\n+    const THCDeviceTensor<T, 1> bias,\n+    bool biasEnabled,\n+    IndexType totalElements,\n+    const int outputChannels,\n+    const int depthwiseMultiplier,\n+    const int inputWidth, const int inputHeight,\n+    const int outputWidth, const int outputHeight,\n+    const int kernelWidth, const int kernelHeight,\n+    const int strideWidth, const int strideHeight,\n+    const int padWidth, const int padHeight,\n+    const int dilationWidth, const int dilationHeight)\n+{\n+  for (IndexType linearIndex = blockIdx.x * blockDim.x + threadIdx.x;\n+       linearIndex < totalElements;\n+       linearIndex += gridDim.x * blockDim.x) {\n+\n+    const int n = linearIndex / outputChannels / outputHeight / outputWidth;\n+    const int c = (linearIndex / outputHeight / outputWidth) % outputChannels;\n+    const int h = (linearIndex / outputWidth) % outputHeight;\n+    const int w = linearIndex % outputWidth;", "path": "torch/lib/THCUNN/SpatialDepthwiseConvolution.cu", "position": null, "original_position": 38, "commit_id": "65cc6f18f7ad5eb23a300b5b7715dc6ea2282b5d", "original_commit_id": "b832c53242f272f5cc86fb1e25385985a02ef098", "user": {"login": "killeent", "id": 4529377, "node_id": "MDQ6VXNlcjQ1MjkzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4529377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/killeent", "html_url": "https://github.com/killeent", "followers_url": "https://api.github.com/users/killeent/followers", "following_url": "https://api.github.com/users/killeent/following{/other_user}", "gists_url": "https://api.github.com/users/killeent/gists{/gist_id}", "starred_url": "https://api.github.com/users/killeent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/killeent/subscriptions", "organizations_url": "https://api.github.com/users/killeent/orgs", "repos_url": "https://api.github.com/users/killeent/repos", "events_url": "https://api.github.com/users/killeent/events{/privacy}", "received_events_url": "https://api.github.com/users/killeent/received_events", "type": "User", "site_admin": false}, "body": "Also addressed by @ngimel above. I find that these kernels are pretty ugly no matter what.", "created_at": "2017-10-16T13:51:26Z", "updated_at": "2018-11-23T15:35:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144852147", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3057", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144852147"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144852147"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3057"}}, "body_html": "<p>Also addressed by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> above. I find that these kernels are pretty ugly no matter what.</p>", "body_text": "Also addressed by @ngimel above. I find that these kernels are pretty ugly no matter what.", "in_reply_to_id": 144693370}