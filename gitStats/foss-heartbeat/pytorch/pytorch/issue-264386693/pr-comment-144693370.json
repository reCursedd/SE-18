{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144693370", "pull_request_review_id": 69391176, "id": 144693370, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDY5MzM3MA==", "diff_hunk": "@@ -0,0 +1,191 @@\n+// updateOutput, updateGradInput Kernels ported from Sergey Zagoruyko's pyinn, which itself was a\n+// port from Caffe\n+\n+#include \"THCUNN.h\"\n+#include \"THCDeviceTensor.cuh\"\n+#include \"THCDeviceTensorUtils.cuh\"\n+#include \"THCNumerics.cuh\"\n+#include \"THCReduceApplyUtils.cuh\"\n+#include \"THCSortUtils.cuh\"\n+#include \"THCTensorMathReduce.cuh\"\n+#include \"SharedMem.cuh\"\n+#include \"common.h\"\n+\n+template <typename T, typename IndexType>\n+__global__ void spatialDepthwiseConvolutionUpdateOutput(\n+    const THCDeviceTensor<T, 4> input,\n+    THCDeviceTensor<T, 4> output,\n+    const THCDeviceTensor<T, 4> weight,\n+    const THCDeviceTensor<T, 1> bias,\n+    bool biasEnabled,\n+    IndexType totalElements,\n+    const int outputChannels,\n+    const int depthwiseMultiplier,\n+    const int inputWidth, const int inputHeight,\n+    const int outputWidth, const int outputHeight,\n+    const int kernelWidth, const int kernelHeight,\n+    const int strideWidth, const int strideHeight,\n+    const int padWidth, const int padHeight,\n+    const int dilationWidth, const int dilationHeight)\n+{\n+  for (IndexType linearIndex = blockIdx.x * blockDim.x + threadIdx.x;\n+       linearIndex < totalElements;\n+       linearIndex += gridDim.x * blockDim.x) {\n+\n+    const int n = linearIndex / outputChannels / outputHeight / outputWidth;\n+    const int c = (linearIndex / outputHeight / outputWidth) % outputChannels;\n+    const int h = (linearIndex / outputWidth) % outputHeight;\n+    const int w = linearIndex % outputWidth;", "path": "torch/lib/THCUNN/SpatialDepthwiseConvolution.cu", "position": null, "original_position": 38, "commit_id": "65cc6f18f7ad5eb23a300b5b7715dc6ea2282b5d", "original_commit_id": "b832c53242f272f5cc86fb1e25385985a02ef098", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I've seen integer divison and modulo being ridiculously expensive in CUDA, so it's best to avoid it. You can take a look at my Softmax PR to see how I used a 2d grid to tile the blocks, which let me avoid this indexing at all and made the kernel a few times faster.\r\n\r\n---\r\n\r\nAlso a suggestion: I usually find the kernels much easier to read when you pre-compute all the strides outside as `const int` and rewrite the indexing to look more like this:\r\n```cpp\r\n// outside of the loop\r\nconst int widthSize = outputWidth;\r\nconst int heightStride = widthSize;\r\nconst int heightSize = outputHeight;\r\nconst int channelStride = heightSize * heightStride;\r\nconst int channelSize = outputChannels;\r\nconst int batchStride = channelSize * channelStride;\r\n// inside the loop\r\nconst int w = linearIndex % widthSize;\r\nconst int h = (linearIndex / heightStride) % heightSize;\r\nconst int c = (linearIndex / channelStride) % channelSize;\r\nconst int n = linearIndex / batchStride;\r\n```", "created_at": "2017-10-14T12:36:45Z", "updated_at": "2018-11-23T15:35:17Z", "html_url": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144693370", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3057", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144693370"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144693370"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3057"}}, "body_html": "<p>I've seen integer divison and modulo being ridiculously expensive in CUDA, so it's best to avoid it. You can take a look at my Softmax PR to see how I used a 2d grid to tile the blocks, which let me avoid this indexing at all and made the kernel a few times faster.</p>\n<hr>\n<p>Also a suggestion: I usually find the kernels much easier to read when you pre-compute all the strides outside as <code>const int</code> and rewrite the indexing to look more like this:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\">//</span> outside of the loop</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> widthSize = outputWidth;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> heightStride = widthSize;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> heightSize = outputHeight;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> channelStride = heightSize * heightStride;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> channelSize = outputChannels;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> batchStride = channelSize * channelStride;\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> inside the loop</span>\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> w = linearIndex % widthSize;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> h = (linearIndex / heightStride) % heightSize;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> c = (linearIndex / channelStride) % channelSize;\n<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> n = linearIndex / batchStride;</pre></div>", "body_text": "I've seen integer divison and modulo being ridiculously expensive in CUDA, so it's best to avoid it. You can take a look at my Softmax PR to see how I used a 2d grid to tile the blocks, which let me avoid this indexing at all and made the kernel a few times faster.\n\nAlso a suggestion: I usually find the kernels much easier to read when you pre-compute all the strides outside as const int and rewrite the indexing to look more like this:\n// outside of the loop\nconst int widthSize = outputWidth;\nconst int heightStride = widthSize;\nconst int heightSize = outputHeight;\nconst int channelStride = heightSize * heightStride;\nconst int channelSize = outputChannels;\nconst int batchStride = channelSize * channelStride;\n// inside the loop\nconst int w = linearIndex % widthSize;\nconst int h = (linearIndex / heightStride) % heightSize;\nconst int c = (linearIndex / channelStride) % channelSize;\nconst int n = linearIndex / batchStride;"}