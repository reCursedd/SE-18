{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/336519873", "html_url": "https://github.com/pytorch/pytorch/pull/3057#issuecomment-336519873", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3057", "id": 336519873, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjUxOTg3Mw==", "user": {"login": "killeent", "id": 4529377, "node_id": "MDQ6VXNlcjQ1MjkzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4529377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/killeent", "html_url": "https://github.com/killeent", "followers_url": "https://api.github.com/users/killeent/followers", "following_url": "https://api.github.com/users/killeent/following{/other_user}", "gists_url": "https://api.github.com/users/killeent/gists{/gist_id}", "starred_url": "https://api.github.com/users/killeent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/killeent/subscriptions", "organizations_url": "https://api.github.com/users/killeent/orgs", "repos_url": "https://api.github.com/users/killeent/repos", "events_url": "https://api.github.com/users/killeent/events{/privacy}", "received_events_url": "https://api.github.com/users/killeent/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-13T17:39:27Z", "updated_at": "2017-10-13T17:39:27Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Some preliminary results (the parameters for the layers and inputs are taken from MobileNet). All times are for running 50 iterations of Forward/Backward. The trends:</p>\n<ul>\n<li>As the number of channels (and thus groups) increases, the new code becomes faster and faster, because we are replacing a bigger and bigger loop with a single call</li>\n<li>As the batch size increases, these performance gains are dampened, but still non-trivial</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Batch Size</th>\n<th>Input Channels</th>\n<th>Height</th>\n<th>Width</th>\n<th>kH</th>\n<th>kW</th>\n<th>Stride</th>\n<th>time (new)</th>\n<th>time (old)</th>\n<th>Speedup</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>32</td>\n<td>112</td>\n<td>112</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>0.2129</td>\n<td>0.0076</td>\n<td>28x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>64</td>\n<td>112</td>\n<td>112</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>0.1937</td>\n<td>0.0143</td>\n<td>13.5x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>0.4229</td>\n<td>0.0241</td>\n<td>17.5x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>0.3264</td>\n<td>0.0112</td>\n<td>29x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>0.7379</td>\n<td>0.0207</td>\n<td>35.5x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>0.7522</td>\n<td>0.0059</td>\n<td>127x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>1.406</td>\n<td>0.0097</td>\n<td>145x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.494</td>\n<td>0.0052</td>\n<td>287x</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1024</td>\n<td>7</td>\n<td>7</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>2.919</td>\n<td>0.0053</td>\n<td>550x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>32</td>\n<td>112</td>\n<td>112</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>3.603</td>\n<td>0.3102</td>\n<td>11.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>64</td>\n<td>112</td>\n<td>112</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>2.261</td>\n<td>0.5031</td>\n<td>4.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>4.343</td>\n<td>0.9285</td>\n<td>4.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.445</td>\n<td>0.2310</td>\n<td>6x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>3.586</td>\n<td>0.4187</td>\n<td>8.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.043</td>\n<td>0.1168</td>\n<td>9x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>2.489</td>\n<td>0.1957</td>\n<td>12.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.283</td>\n<td>0.0676</td>\n<td>18.5x</td>\n</tr>\n<tr>\n<td>64</td>\n<td>1024</td>\n<td>7</td>\n<td>7</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>2.238</td>\n<td>0.0686</td>\n<td>32.5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>32</td>\n<td>112</td>\n<td>112</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>7.008</td>\n<td>0.5918</td>\n<td>11.5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>64</td>\n<td>112</td>\n<td>112</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>3.825</td>\n<td>0.9979</td>\n<td>3.5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>8.922</td>\n<td>1.844</td>\n<td>4.5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128</td>\n<td>56</td>\n<td>56</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>2.419</td>\n<td>0.4574</td>\n<td>5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>9.471</td>\n<td>0.8292</td>\n<td>11x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>256</td>\n<td>28</td>\n<td>28</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.352</td>\n<td>0.2224</td>\n<td>6x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>1</td>\n<td>7.997</td>\n<td>0.3735</td>\n<td>21.5x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>512</td>\n<td>14</td>\n<td>14</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>1.371</td>\n<td>0.1128</td>\n<td>12x</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1024</td>\n<td>7</td>\n<td>7</td>\n<td>3</td>\n<td>3</td>\n<td>2</td>\n<td>2.383</td>\n<td>0.0998</td>\n<td>24x</td>\n</tr>\n</tbody>\n</table>", "body_text": "Some preliminary results (the parameters for the layers and inputs are taken from MobileNet). All times are for running 50 iterations of Forward/Backward. The trends:\n\nAs the number of channels (and thus groups) increases, the new code becomes faster and faster, because we are replacing a bigger and bigger loop with a single call\nAs the batch size increases, these performance gains are dampened, but still non-trivial\n\n\n\n\nBatch Size\nInput Channels\nHeight\nWidth\nkH\nkW\nStride\ntime (new)\ntime (old)\nSpeedup\n\n\n\n\n1\n32\n112\n112\n1\n1\n1\n0.2129\n0.0076\n28x\n\n\n1\n64\n112\n112\n3\n3\n2\n0.1937\n0.0143\n13.5x\n\n\n1\n128\n56\n56\n3\n3\n1\n0.4229\n0.0241\n17.5x\n\n\n1\n128\n56\n56\n3\n3\n2\n0.3264\n0.0112\n29x\n\n\n1\n256\n28\n28\n3\n3\n1\n0.7379\n0.0207\n35.5x\n\n\n1\n256\n28\n28\n3\n3\n2\n0.7522\n0.0059\n127x\n\n\n1\n512\n14\n14\n3\n3\n1\n1.406\n0.0097\n145x\n\n\n1\n512\n14\n14\n3\n3\n2\n1.494\n0.0052\n287x\n\n\n1\n1024\n7\n7\n3\n3\n2\n2.919\n0.0053\n550x\n\n\n64\n32\n112\n112\n1\n1\n1\n3.603\n0.3102\n11.5x\n\n\n64\n64\n112\n112\n3\n3\n2\n2.261\n0.5031\n4.5x\n\n\n64\n128\n56\n56\n3\n3\n1\n4.343\n0.9285\n4.5x\n\n\n64\n128\n56\n56\n3\n3\n2\n1.445\n0.2310\n6x\n\n\n64\n256\n28\n28\n3\n3\n1\n3.586\n0.4187\n8.5x\n\n\n64\n256\n28\n28\n3\n3\n2\n1.043\n0.1168\n9x\n\n\n64\n512\n14\n14\n3\n3\n1\n2.489\n0.1957\n12.5x\n\n\n64\n512\n14\n14\n3\n3\n2\n1.283\n0.0676\n18.5x\n\n\n64\n1024\n7\n7\n3\n3\n2\n2.238\n0.0686\n32.5x\n\n\n128\n32\n112\n112\n1\n1\n1\n7.008\n0.5918\n11.5x\n\n\n128\n64\n112\n112\n3\n3\n2\n3.825\n0.9979\n3.5x\n\n\n128\n128\n56\n56\n3\n3\n1\n8.922\n1.844\n4.5x\n\n\n128\n128\n56\n56\n3\n3\n2\n2.419\n0.4574\n5x\n\n\n128\n256\n28\n28\n3\n3\n1\n9.471\n0.8292\n11x\n\n\n128\n256\n28\n28\n3\n3\n2\n1.352\n0.2224\n6x\n\n\n128\n512\n14\n14\n3\n3\n1\n7.997\n0.3735\n21.5x\n\n\n128\n512\n14\n14\n3\n3\n2\n1.371\n0.1128\n12x\n\n\n128\n1024\n7\n7\n3\n3\n2\n2.383\n0.0998\n24x", "body": "Some preliminary results (the parameters for the layers and inputs are taken from MobileNet). All times are for running 50 iterations of Forward/Backward. The trends:\r\n\r\n- As the number of channels (and thus groups) increases, the new code becomes faster and faster, because we are replacing a bigger and bigger loop with a single call\r\n- As the batch size increases, these performance gains are dampened, but still non-trivial\r\n\r\nBatch Size | Input Channels | Height | Width | kH | kW | Stride | time (new) | time (old) | Speedup\r\n|---|---|---|---|---|---|---|---|---|---|\r\n1 | 32 | 112 | 112 | 1 | 1 | 1 | 0.2129 | 0.0076 | 28x\r\n1 | 64 | 112 | 112| 3 | 3 | 2 | 0.1937 | 0.0143 | 13.5x\r\n1 | 128 | 56 | 56 | 3 | 3 | 1 | 0.4229 | 0.0241 | 17.5x\r\n1 | 128 | 56 | 56 | 3 | 3 | 2 | 0.3264 | 0.0112 | 29x\r\n1 | 256 | 28 | 28 | 3  | 3 | 1 | 0.7379 | 0.0207 | 35.5x\r\n1 | 256 | 28 | 28 | 3  | 3 | 2 | 0.7522 | 0.0059 | 127x\r\n1 | 512 | 14 | 14 | 3 | 3 | 1 | 1.406 | 0.0097 | 145x\r\n1 | 512 | 14 | 14 | 3 | 3 | 2 | 1.494 | 0.0052 | 287x\r\n1 | 1024 | 7 | 7 | 3 | 3 | 2 | 2.919 | 0.0053 | 550x\r\n64 | 32 | 112 | 112 | 1 | 1 | 1 | 3.603 | 0.3102 | 11.5x\r\n64 | 64 | 112 | 112| 3 | 3 | 2 | 2.261 | 0.5031 | 4.5x\r\n64 | 128 | 56 | 56 | 3 | 3 | 1 | 4.343 | 0.9285 | 4.5x\r\n64 | 128 | 56 | 56 | 3 | 3 | 2 | 1.445 | 0.2310 | 6x\r\n64 | 256 | 28 | 28 | 3  | 3 | 1 | 3.586 | 0.4187 | 8.5x\r\n64 | 256 | 28 | 28 | 3  | 3 | 2 | 1.043 | 0.1168 | 9x\r\n64 | 512 | 14 | 14 | 3 | 3 | 1 | 2.489 | 0.1957 | 12.5x\r\n64 | 512 | 14 | 14 | 3 | 3 | 2 | 1.283 | 0.0676 | 18.5x\r\n64 | 1024 | 7 | 7 | 3 | 3 | 2 | 2.238 | 0.0686 | 32.5x\r\n128 | 32 | 112 | 112 | 1 | 1 | 1 | 7.008 | 0.5918 | 11.5x\r\n128 | 64 | 112 | 112| 3 | 3 | 2 | 3.825 | 0.9979 | 3.5x\r\n128 | 128 | 56 | 56 | 3 | 3 | 1 | 8.922 | 1.844 | 4.5x\r\n128 | 128 | 56 | 56 | 3 | 3 | 2 | 2.419 | 0.4574 | 5x\r\n128 | 256 | 28 | 28 | 3  | 3 | 1 | 9.471 | 0.8292 | 11x\r\n128 | 256 | 28 | 28 | 3  | 3 | 2 | 1.352 | 0.2224 | 6x\r\n128 | 512 | 14 | 14 | 3 | 3 | 1 | 7.997 | 0.3735 | 21.5x\r\n128 | 512 | 14 | 14 | 3 | 3 | 2 | 1.371 | 0.1128 | 12x\r\n128 | 1024 | 7 | 7 | 3 | 3 | 2 | 2.383 | 0.0998 | 24x\r\n\r\n\r\n\r\n\r\n"}