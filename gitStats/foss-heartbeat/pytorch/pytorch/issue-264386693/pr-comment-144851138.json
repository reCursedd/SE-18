{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144851138", "pull_request_review_id": 69565426, "id": 144851138, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDg1MTEzOA==", "diff_hunk": "@@ -0,0 +1,201 @@\n+#ifndef THC_GENERIC_FILE\n+#define THC_GENERIC_FILE \"generic/SpatialDepthwiseConvolution.cu\"\n+#else\n+\n+void THNN_(SpatialDepthwiseConvolution_updateOutput)(\n+                  THCState *state,\n+                  THCTensor *input,\n+                  THCTensor *output,\n+                  THCTensor *weight,\n+                  THCTensor *bias,\n+                  int kW, int kH,\n+                  int dW, int dH,\n+                  int padW, int padH,\n+                  int dilationW, int dilationH)\n+{\n+  THCUNN_assertSameGPU(state, 3, input, output, weight);\n+\n+  // Only handle 4D Input Tensors for now\n+  assert(THCTensor_(nDimension)(state, input) == 4);\n+  assert(THCTensor_(nDimension)(state, weight) == 4);\n+\n+  // We assume that the input and weight Tensors are shaped properly by\n+  // the caller, so we verify that here to some extent\n+\n+  // Weight Tensor is shape (output_channels, 1, kH, kW)\n+  assert(weight->size[1] == 1);\n+\n+  // Input Tensor is shape (N, input_channels, H, W)\n+  // We verify that the # of output_channels is a multiple of input_channels\n+  assert(weight->size[0] % input->size[1] == 0);\n+\n+  // Bias has same # of channels as output\n+  if (bias) {\n+    assert(bias->size[0] == weight->size[0]);\n+  }\n+\n+  // Following the behvaior of other THCUNN functions, we shape the output\n+  // Tensor ourselves\n+\n+  int batchSize = input->size[0];\n+  int height = input->size[2];\n+  int width = input->size[3];\n+  int outputHeight = (height + 2 * padH - (dilationH * (kH - 1) + 1)) / dH + 1;\n+  int outputWidth = (width + 2 * padW - (dilationW * (kW - 1) + 1)) / dW + 1;\n+  int outputChannels = weight->size[0];\n+\n+  THCTensor_(resize4d)(state, output, batchSize, outputChannels, outputHeight, outputWidth);\n+\n+  THCDeviceTensor<real, 4> dInput = toDeviceTensor<real, 4>(state, input);\n+  THCDeviceTensor<real, 4> dWeight = toDeviceTensor<real, 4>(state, weight);\n+  THCDeviceTensor<real, 4> dOutput = toDeviceTensor<real, 4>(state, output);\n+  THCDeviceTensor<real, 1> dBias;\n+  if (bias) {\n+    dBias = toDeviceTensor<real, 1>(state, bias);\n+  }\n+\n+  // Kernel currently relies upon all the Tensors to be contiguous\n+  assert(dInput.isContiguous());\n+  assert(dWeight.isContiguous());\n+  assert(dOutput.isContiguous());\n+\n+  int inputChannels = input->size[1];\n+  int depthwiseMultiplier = outputChannels / inputChannels;\n+\n+  // One thread per output value\n+  int n = THCTensor_(nElement)(state, output);\n+  int blocks = GET_BLOCKS(n);\n+  dim3 grid(blocks);\n+  dim3 block(CUDA_NUM_THREADS);\n+\n+  spatialDepthwiseConvolutionUpdateOutput<<<grid, block, 0, THCState_getCurrentStream(state)>>>(\n+    dInput, dOutput, dWeight, dBias, bias != NULL, n, outputChannels, depthwiseMultiplier,\n+    width, height, outputWidth, outputHeight,\n+    kW, kH, dW, dH, padW, padH, dilationW, dilationH);\n+\n+  THCudaCheck(cudaGetLastError());\n+}\n+\n+void THNN_(SpatialDepthwiseConvolution_updateGradInput)(\n+                  THCState *state,\n+                  THCTensor *input,\n+                  THCTensor *gradOutput,\n+                  THCTensor *gradInput,\n+                  THCTensor *weight,\n+                  int kW, int kH,\n+                  int dW, int dH,\n+                  int padW, int padH,\n+                  int dilationW, int dilationH)\n+{\n+  THCUNN_assertSameGPU(state, 4, input, gradOutput, gradInput, weight);", "path": "torch/lib/THCUNN/generic/SpatialDepthwiseConvolution.cu", "position": null, "original_position": 90, "commit_id": "65cc6f18f7ad5eb23a300b5b7715dc6ea2282b5d", "original_commit_id": "e322bc9f0ca6241150ff49ab4141a67b98530b15", "user": {"login": "killeent", "id": 4529377, "node_id": "MDQ6VXNlcjQ1MjkzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4529377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/killeent", "html_url": "https://github.com/killeent", "followers_url": "https://api.github.com/users/killeent/followers", "following_url": "https://api.github.com/users/killeent/following{/other_user}", "gists_url": "https://api.github.com/users/killeent/gists{/gist_id}", "starred_url": "https://api.github.com/users/killeent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/killeent/subscriptions", "organizations_url": "https://api.github.com/users/killeent/orgs", "repos_url": "https://api.github.com/users/killeent/repos", "events_url": "https://api.github.com/users/killeent/events{/privacy}", "received_events_url": "https://api.github.com/users/killeent/received_events", "type": "User", "site_admin": false}, "body": "Good catch. I was playing around with the input during development. However, I'm not a fan of mimic-ing the existing THNN functions which have these shared shape-checks, where you have to scroll back and forth to see what parameter maps to what name in the shape check. My hope is that shape-checking is largely starting to occur at the Python (or ATen) level with more sane error messages. When you get a `THNN` assertion failure, its essentially useless to the end user unless they look into the code themselves.", "created_at": "2017-10-16T13:47:52Z", "updated_at": "2018-11-23T15:35:18Z", "html_url": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144851138", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3057", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144851138"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144851138"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3057"}}, "body_html": "<p>Good catch. I was playing around with the input during development. However, I'm not a fan of mimic-ing the existing THNN functions which have these shared shape-checks, where you have to scroll back and forth to see what parameter maps to what name in the shape check. My hope is that shape-checking is largely starting to occur at the Python (or ATen) level with more sane error messages. When you get a <code>THNN</code> assertion failure, its essentially useless to the end user unless they look into the code themselves.</p>", "body_text": "Good catch. I was playing around with the input during development. However, I'm not a fan of mimic-ing the existing THNN functions which have these shared shape-checks, where you have to scroll back and forth to see what parameter maps to what name in the shape check. My hope is that shape-checking is largely starting to occur at the Python (or ATen) level with more sane error messages. When you get a THNN assertion failure, its essentially useless to the end user unless they look into the code themselves.", "in_reply_to_id": 144651684}