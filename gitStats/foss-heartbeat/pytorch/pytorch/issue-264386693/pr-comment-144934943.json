{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144934943", "pull_request_review_id": 69659088, "id": 144934943, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NDkzNDk0Mw==", "diff_hunk": "@@ -366,7 +413,25 @@ auto ConvBackward::apply(const variable_list& grad_outputs) -> variable_list {\n     should_compute_output(2) && bias.defined(),\n   };\n \n-  if (use_cudnn) {\n+  if (use_depthwise) {\n+    if (output_mask[0] || output_mask[1]) {\n+      auto kernel_size = weight.sizes().slice(2);\n+      auto stride = vecToInt64(this->stride);\n+      auto padding = vecToInt64(this->padding);\n+      auto dilation = vecToInt64(this->dilation);\n+\n+      std::tie(grad_input, grad_weight) = at::conv_depthwise2d_backward(\n+          grad_output, input, weight, kernel_size, stride, padding, dilation,\n+          {output_mask[0], output_mask[1]});\n+      }\n+\n+      // THCUNN implementation does not handle bias, so we do it ourselves\n+      if (output_mask[2]) {\n+        grad_bias = bias.type().tensor();\n+        grad_bias.resize_as_(bias).zero_();\n+        update_grad_bias(grad_output, grad_bias);", "path": "torch/csrc/autograd/functions/convolution.cpp", "position": null, "original_position": 121, "commit_id": "65cc6f18f7ad5eb23a300b5b7715dc6ea2282b5d", "original_commit_id": "0feeca82bb9289ed9d05183b6f3b079a3e210469", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Instead of creating a zeroed tensor and accumulating into it, just compute the grad_bias from `grad_output` i.e.\r\n\r\n```\r\ngrad_bias = compute_grad_bias(grad_output);\r\n```", "created_at": "2017-10-16T18:49:57Z", "updated_at": "2018-11-23T15:35:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144934943", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3057", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/144934943"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3057#discussion_r144934943"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3057"}}, "body_html": "<p>Instead of creating a zeroed tensor and accumulating into it, just compute the grad_bias from <code>grad_output</code> i.e.</p>\n<pre><code>grad_bias = compute_grad_bias(grad_output);\n</code></pre>", "body_text": "Instead of creating a zeroed tensor and accumulating into it, just compute the grad_bias from grad_output i.e.\ngrad_bias = compute_grad_bias(grad_output);"}