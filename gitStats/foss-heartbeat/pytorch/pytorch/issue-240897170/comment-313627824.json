{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/313627824", "html_url": "https://github.com/pytorch/pytorch/issues/1990#issuecomment-313627824", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1990", "id": 313627824, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzYyNzgyNA==", "user": {"login": "karandwivedi42", "id": 9624554, "node_id": "MDQ6VXNlcjk2MjQ1NTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/9624554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karandwivedi42", "html_url": "https://github.com/karandwivedi42", "followers_url": "https://api.github.com/users/karandwivedi42/followers", "following_url": "https://api.github.com/users/karandwivedi42/following{/other_user}", "gists_url": "https://api.github.com/users/karandwivedi42/gists{/gist_id}", "starred_url": "https://api.github.com/users/karandwivedi42/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karandwivedi42/subscriptions", "organizations_url": "https://api.github.com/users/karandwivedi42/orgs", "repos_url": "https://api.github.com/users/karandwivedi42/repos", "events_url": "https://api.github.com/users/karandwivedi42/events{/privacy}", "received_events_url": "https://api.github.com/users/karandwivedi42/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-07T09:00:49Z", "updated_at": "2017-08-05T11:11:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For fine-tuning the workaround becomes:</p>\n<div class=\"highlight highlight-source-python\"><pre>updated_params <span class=\"pl-k\">=</span> torch.load(pretrained)\nupdated_params.pop(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc.weight<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">None</span>)\nupdated_params.pop(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc.bias<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">None</span>)\nnew_params <span class=\"pl-k\">=</span> model.state_dict()\nnew_params.update(updated_params)\nmodel.load_state_dict(new_params)</pre></div>\n<p><code>ignored_keys</code> can just ignore the given keys from both loaded <code>state_dict</code> and <code>own_state</code> like:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">load_state_dict</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">state_dict</span>, <span class=\"pl-smi\">ignored_keys</span><span class=\"pl-k\">=</span>[]):\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Copies parameters and buffers from :attr:`state_dict` into</span>\n<span class=\"pl-s\">        this module and its descendants. The keys of :attr:`state_dict` must</span>\n<span class=\"pl-s\">        exactly match the keys returned by this module's :func:`state_dict()`</span>\n<span class=\"pl-s\">        function.</span>\n<span class=\"pl-s\">        Arguments:</span>\n<span class=\"pl-s\">            state_dict (dict): A dict containing parameters and</span>\n<span class=\"pl-s\">                persistent buffers.</span>\n<span class=\"pl-s\">        <span class=\"pl-pds\">\"\"\"</span></span>\n        own_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state_dict()\n        <span class=\"pl-k\">for</span> name, param <span class=\"pl-k\">in</span> state_dict.items():\n            <span class=\"pl-k\">if</span> name <span class=\"pl-k\">not</span> <span class=\"pl-k\">in</span> ignored_keys:       <span class=\"pl-c\"><span class=\"pl-c\">#</span> changed here</span>\n                <span class=\"pl-k\">if</span> name <span class=\"pl-k\">not</span> <span class=\"pl-k\">in</span> own_state:\n                    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">KeyError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>unexpected key \"<span class=\"pl-c1\">{}</span>\" in state_dict<span class=\"pl-pds\">'</span></span>\n                                   .format(name))\n                <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(param, Parameter):\n                    <span class=\"pl-c\"><span class=\"pl-c\">#</span> backwards compatibility for serialized parameters</span>\n                    param <span class=\"pl-k\">=</span> param.data\n                own_state[name].copy_(param)\n         <span class=\"pl-c\"><span class=\"pl-c\">#</span>  changed here</span>\n        missing <span class=\"pl-k\">=</span> <span class=\"pl-c1\">set</span>(own_state.keys()) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">set</span>(state_dict.keys()) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">set</span>(ignored_keys)\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(missing) <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>:\n            <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">KeyError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>missing keys in state_dict: \"<span class=\"pl-c1\">{}</span>\"<span class=\"pl-pds\">'</span></span>.format(missing))</pre></div>", "body_text": "For fine-tuning the workaround becomes:\nupdated_params = torch.load(pretrained)\nupdated_params.pop('fc.weight', None)\nupdated_params.pop('fc.bias', None)\nnew_params = model.state_dict()\nnew_params.update(updated_params)\nmodel.load_state_dict(new_params)\nignored_keys can just ignore the given keys from both loaded state_dict and own_state like:\n    def load_state_dict(self, state_dict, ignored_keys=[]):\n        \"\"\"Copies parameters and buffers from :attr:`state_dict` into\n        this module and its descendants. The keys of :attr:`state_dict` must\n        exactly match the keys returned by this module's :func:`state_dict()`\n        function.\n        Arguments:\n            state_dict (dict): A dict containing parameters and\n                persistent buffers.\n        \"\"\"\n        own_state = self.state_dict()\n        for name, param in state_dict.items():\n            if name not in ignored_keys:       # changed here\n                if name not in own_state:\n                    raise KeyError('unexpected key \"{}\" in state_dict'\n                                   .format(name))\n                if isinstance(param, Parameter):\n                    # backwards compatibility for serialized parameters\n                    param = param.data\n                own_state[name].copy_(param)\n         #  changed here\n        missing = set(own_state.keys()) - set(state_dict.keys()) - set(ignored_keys)\n        if len(missing) > 0:\n            raise KeyError('missing keys in state_dict: \"{}\"'.format(missing))", "body": "For fine-tuning the workaround becomes:\r\n```python\r\nupdated_params = torch.load(pretrained)\r\nupdated_params.pop('fc.weight', None)\r\nupdated_params.pop('fc.bias', None)\r\nnew_params = model.state_dict()\r\nnew_params.update(updated_params)\r\nmodel.load_state_dict(new_params)\r\n```\r\n\r\n`ignored_keys` can just ignore the given keys from both loaded `state_dict` and `own_state` like:\r\n\r\n```python\r\n    def load_state_dict(self, state_dict, ignored_keys=[]):\r\n        \"\"\"Copies parameters and buffers from :attr:`state_dict` into\r\n        this module and its descendants. The keys of :attr:`state_dict` must\r\n        exactly match the keys returned by this module's :func:`state_dict()`\r\n        function.\r\n        Arguments:\r\n            state_dict (dict): A dict containing parameters and\r\n                persistent buffers.\r\n        \"\"\"\r\n        own_state = self.state_dict()\r\n        for name, param in state_dict.items():\r\n            if name not in ignored_keys:       # changed here\r\n                if name not in own_state:\r\n                    raise KeyError('unexpected key \"{}\" in state_dict'\r\n                                   .format(name))\r\n                if isinstance(param, Parameter):\r\n                    # backwards compatibility for serialized parameters\r\n                    param = param.data\r\n                own_state[name].copy_(param)\r\n         #  changed here\r\n        missing = set(own_state.keys()) - set(state_dict.keys()) - set(ignored_keys)\r\n        if len(missing) > 0:\r\n            raise KeyError('missing keys in state_dict: \"{}\"'.format(missing))\r\n```"}