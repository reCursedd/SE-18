{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/279536709", "html_url": "https://github.com/pytorch/pytorch/issues/711#issuecomment-279536709", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/711", "id": 279536709, "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTUzNjcwOQ==", "user": {"login": "jekbradbury", "id": 11729078, "node_id": "MDQ6VXNlcjExNzI5MDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11729078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jekbradbury", "html_url": "https://github.com/jekbradbury", "followers_url": "https://api.github.com/users/jekbradbury/followers", "following_url": "https://api.github.com/users/jekbradbury/following{/other_user}", "gists_url": "https://api.github.com/users/jekbradbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/jekbradbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jekbradbury/subscriptions", "organizations_url": "https://api.github.com/users/jekbradbury/orgs", "repos_url": "https://api.github.com/users/jekbradbury/repos", "events_url": "https://api.github.com/users/jekbradbury/events{/privacy}", "received_events_url": "https://api.github.com/users/jekbradbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-13T22:00:09Z", "updated_at": "2017-02-13T22:00:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It would be fairly difficult to make something like that work for the main <code>LSTM</code> and <code>RNN</code> classes while retaining full CUDNN compatibility. But the <code>LSTMCell</code> and <code>RNNCell</code> classes probably don't benefit performance-wise from using CUDNN, and could be made more transparent and easy to subclass (perhaps along the lines of Chainer, where the LSTM cell class is an ordinary module with two <code>Linear</code> submodules representing the \"x to h\" and \"h to h\" transformations). Then using the cell classes to build RNNs is not too difficult.</p>", "body_text": "It would be fairly difficult to make something like that work for the main LSTM and RNN classes while retaining full CUDNN compatibility. But the LSTMCell and RNNCell classes probably don't benefit performance-wise from using CUDNN, and could be made more transparent and easy to subclass (perhaps along the lines of Chainer, where the LSTM cell class is an ordinary module with two Linear submodules representing the \"x to h\" and \"h to h\" transformations). Then using the cell classes to build RNNs is not too difficult.", "body": "It would be fairly difficult to make something like that work for the main `LSTM` and `RNN` classes while retaining full CUDNN compatibility. But the `LSTMCell` and `RNNCell` classes probably don't benefit performance-wise from using CUDNN, and could be made more transparent and easy to subclass (perhaps along the lines of Chainer, where the LSTM cell class is an ordinary module with two `Linear` submodules representing the \"x to h\" and \"h to h\" transformations). Then using the cell classes to build RNNs is not too difficult."}