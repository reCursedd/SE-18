{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/429300914", "html_url": "https://github.com/pytorch/pytorch/issues/711#issuecomment-429300914", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/711", "id": 429300914, "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTMwMDkxNA==", "user": {"login": "matthew-z", "id": 5741303, "node_id": "MDQ6VXNlcjU3NDEzMDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5741303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthew-z", "html_url": "https://github.com/matthew-z", "followers_url": "https://api.github.com/users/matthew-z/followers", "following_url": "https://api.github.com/users/matthew-z/following{/other_user}", "gists_url": "https://api.github.com/users/matthew-z/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthew-z/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthew-z/subscriptions", "organizations_url": "https://api.github.com/users/matthew-z/orgs", "repos_url": "https://api.github.com/users/matthew-z/repos", "events_url": "https://api.github.com/users/matthew-z/events{/privacy}", "received_events_url": "https://api.github.com/users/matthew-z/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-12T11:55:14Z", "updated_at": "2018-10-12T11:55:14Z", "author_association": "NONE", "body_html": "<p>I was wondering why JIT could make looping cells as efficient as CUDNN implementations.</p>\n<p>If my understanding is correct, Pytorch JIT can reduce the python overhead in looping, and it is helpful only when the calculation in each iteration is very simple. I guess the overhead is quite small for some complex RNN structures (e.g., with attention mechanism).</p>\n<p>Also, even Tensorflow dynamic_rnn, which has no python overhead in graph mode, is much slower than CUDNN RNN implementation as the latter is fused over the time dimension.</p>", "body_text": "I was wondering why JIT could make looping cells as efficient as CUDNN implementations.\nIf my understanding is correct, Pytorch JIT can reduce the python overhead in looping, and it is helpful only when the calculation in each iteration is very simple. I guess the overhead is quite small for some complex RNN structures (e.g., with attention mechanism).\nAlso, even Tensorflow dynamic_rnn, which has no python overhead in graph mode, is much slower than CUDNN RNN implementation as the latter is fused over the time dimension.", "body": "I was wondering why JIT could make looping cells as efficient as CUDNN implementations. \r\n\r\nIf my understanding is correct, Pytorch JIT can reduce the python overhead in looping, and it is helpful only when the calculation in each iteration is very simple. I guess the overhead is quite small for some complex RNN structures (e.g., with attention mechanism). \r\n\r\nAlso, even Tensorflow dynamic_rnn, which has no python overhead in graph mode, is much slower than CUDNN RNN implementation as the latter is fused over the time dimension."}