{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/299798665", "html_url": "https://github.com/pytorch/pytorch/pull/1016#issuecomment-299798665", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1016", "id": 299798665, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTc5ODY2NQ==", "user": {"login": "HiiYL", "id": 7908951, "node_id": "MDQ6VXNlcjc5MDg5NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/7908951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HiiYL", "html_url": "https://github.com/HiiYL", "followers_url": "https://api.github.com/users/HiiYL/followers", "following_url": "https://api.github.com/users/HiiYL/following{/other_user}", "gists_url": "https://api.github.com/users/HiiYL/gists{/gist_id}", "starred_url": "https://api.github.com/users/HiiYL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HiiYL/subscriptions", "organizations_url": "https://api.github.com/users/HiiYL/orgs", "repos_url": "https://api.github.com/users/HiiYL/repos", "events_url": "https://api.github.com/users/HiiYL/events{/privacy}", "received_events_url": "https://api.github.com/users/HiiYL/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-08T07:57:02Z", "updated_at": "2017-05-08T07:58:12Z", "author_association": "NONE", "body_html": "<p>Im trying to implement WGAN-GP using the <code>create_graph</code> argument of <code>torch.autograd.backward</code>, however it throws the following error when <code>backward()</code> is called on the gradients:<br>\n<code>RuntimeError: ConvBackward is not differentiable</code></p>\n<p>My code is here:<br>\n<a href=\"https://github.com/HiiYL/WGAN-GP-PyTorch/blob/master/main.py#L224\">https://github.com/HiiYL/WGAN-GP-PyTorch/blob/master/main.py#L224</a></p>", "body_text": "Im trying to implement WGAN-GP using the create_graph argument of torch.autograd.backward, however it throws the following error when backward() is called on the gradients:\nRuntimeError: ConvBackward is not differentiable\nMy code is here:\nhttps://github.com/HiiYL/WGAN-GP-PyTorch/blob/master/main.py#L224", "body": "Im trying to implement WGAN-GP using the `create_graph` argument of `torch.autograd.backward`, however it throws the following error when `backward()` is called on the gradients:\r\n``` RuntimeError: ConvBackward is not differentiable ```\r\n\r\nMy code is here:\r\nhttps://github.com/HiiYL/WGAN-GP-PyTorch/blob/master/main.py#L224"}