{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355304449", "html_url": "https://github.com/pytorch/pytorch/pull/1016#issuecomment-355304449", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1016", "id": 355304449, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTMwNDQ0OQ==", "user": {"login": "lucasb-eyer", "id": 1476029, "node_id": "MDQ6VXNlcjE0NzYwMjk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1476029?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucasb-eyer", "html_url": "https://github.com/lucasb-eyer", "followers_url": "https://api.github.com/users/lucasb-eyer/followers", "following_url": "https://api.github.com/users/lucasb-eyer/following{/other_user}", "gists_url": "https://api.github.com/users/lucasb-eyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucasb-eyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucasb-eyer/subscriptions", "organizations_url": "https://api.github.com/users/lucasb-eyer/orgs", "repos_url": "https://api.github.com/users/lucasb-eyer/repos", "events_url": "https://api.github.com/users/lucasb-eyer/events{/privacy}", "received_events_url": "https://api.github.com/users/lucasb-eyer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T15:01:53Z", "updated_at": "2018-01-04T15:01:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi all, the following code can be used to compute the full Hessian in a loop, as mentioned by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a>. I'm wondering if anyone knows of a trick to compute the diagonal of the Hessian in a single pass? I wasn't able to come up with anything myself.</p>\n<p>Code:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> Variable(torch.FloatTensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>]), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\ny <span class=\"pl-k\">=</span> x[<span class=\"pl-c1\">0</span>].pow(<span class=\"pl-c1\">2</span>) <span class=\"pl-k\">*</span> x[<span class=\"pl-c1\">1</span>]\n\ndx, <span class=\"pl-k\">=</span> grad(y, x, <span class=\"pl-v\">create_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-c1\">print</span>(dx)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> (4,1)'</span>\n\ndx_dx1, <span class=\"pl-k\">=</span> grad(dx, x, <span class=\"pl-v\">grad_outputs</span><span class=\"pl-k\">=</span>torch.FloatTensor([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">0</span>]), <span class=\"pl-v\">retain_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\ndx_dx2, <span class=\"pl-k\">=</span> grad(dx, x, <span class=\"pl-v\">grad_outputs</span><span class=\"pl-k\">=</span>torch.FloatTensor([<span class=\"pl-c1\">0</span>,<span class=\"pl-c1\">1</span>]))\n\n<span class=\"pl-c1\">print</span>(dx_dx1)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> (4,2)'</span>\n<span class=\"pl-c1\">print</span>(dx_dx2)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> (2,0)'</span></pre></div>", "body_text": "Hi all, the following code can be used to compute the full Hessian in a loop, as mentioned by @soumith. I'm wondering if anyone knows of a trick to compute the diagonal of the Hessian in a single pass? I wasn't able to come up with anything myself.\nCode:\nx = Variable(torch.FloatTensor([1,2]), requires_grad=True)\ny = x[0].pow(2) * x[1]\n\ndx, = grad(y, x, create_graph=True)\nprint(dx)  # (4,1)'\n\ndx_dx1, = grad(dx, x, grad_outputs=torch.FloatTensor([1,0]), retain_graph=True)\ndx_dx2, = grad(dx, x, grad_outputs=torch.FloatTensor([0,1]))\n\nprint(dx_dx1)  # (4,2)'\nprint(dx_dx2)  # (2,0)'", "body": "Hi all, the following code can be used to compute the full Hessian in a loop, as mentioned by @soumith. I'm wondering if anyone knows of a trick to compute the diagonal of the Hessian in a single pass? I wasn't able to come up with anything myself.\r\n\r\nCode:\r\n\r\n```python\r\nx = Variable(torch.FloatTensor([1,2]), requires_grad=True)\r\ny = x[0].pow(2) * x[1]\r\n\r\ndx, = grad(y, x, create_graph=True)\r\nprint(dx)  # (4,1)'\r\n\r\ndx_dx1, = grad(dx, x, grad_outputs=torch.FloatTensor([1,0]), retain_graph=True)\r\ndx_dx2, = grad(dx, x, grad_outputs=torch.FloatTensor([0,1]))\r\n\r\nprint(dx_dx1)  # (4,2)'\r\nprint(dx_dx2)  # (2,0)'\r\n```"}