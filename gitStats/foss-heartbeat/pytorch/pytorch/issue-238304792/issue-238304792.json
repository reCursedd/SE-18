{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1897", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1897/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1897/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1897/events", "html_url": "https://github.com/pytorch/pytorch/issues/1897", "id": 238304792, "node_id": "MDU6SXNzdWUyMzgzMDQ3OTI=", "number": 1897, "title": "Errors when num_workers is set to be value bigger than 0 in torch.utils.data.DataLoader", "user": {"login": "eriche2016", "id": 11784910, "node_id": "MDQ6VXNlcjExNzg0OTEw", "avatar_url": "https://avatars2.githubusercontent.com/u/11784910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eriche2016", "html_url": "https://github.com/eriche2016", "followers_url": "https://api.github.com/users/eriche2016/followers", "following_url": "https://api.github.com/users/eriche2016/following{/other_user}", "gists_url": "https://api.github.com/users/eriche2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/eriche2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eriche2016/subscriptions", "organizations_url": "https://api.github.com/users/eriche2016/orgs", "repos_url": "https://api.github.com/users/eriche2016/repos", "events_url": "https://api.github.com/users/eriche2016/events{/privacy}", "received_events_url": "https://api.github.com/users/eriche2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-24T08:37:53Z", "updated_at": "2017-06-27T08:07:32Z", "closed_at": "2017-06-26T02:01:33Z", "author_association": "NONE", "body_html": "<p>I have a dataset whose labels are from 0 to 9. And i wrap it using torch.utils.data.DataLoader, if i set num_workers to be 0, everything works fine, However if it is set to be 2, then the labels batch (a 1-D <em><strong>byte tensor</strong></em>)it loads at some epoch always seems to be bigger than 9, which seems to be 255. what causes this problem? any help? ( p.s., my dataset is .h5 file).</p>", "body_text": "I have a dataset whose labels are from 0 to 9. And i wrap it using torch.utils.data.DataLoader, if i set num_workers to be 0, everything works fine, However if it is set to be 2, then the labels batch (a 1-D byte tensor)it loads at some epoch always seems to be bigger than 9, which seems to be 255. what causes this problem? any help? ( p.s., my dataset is .h5 file).", "body": "I have a dataset whose labels are from 0 to 9. And i wrap it using torch.utils.data.DataLoader, if i set num_workers to be 0, everything works fine, However if it is set to be 2, then the labels batch (a 1-D ***byte tensor***)it loads at some epoch always seems to be bigger than 9, which seems to be 255. what causes this problem? any help? ( p.s., my dataset is .h5 file). \r\n\r\n"}