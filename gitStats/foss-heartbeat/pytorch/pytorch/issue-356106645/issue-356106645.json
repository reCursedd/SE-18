{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11156", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11156/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11156/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11156/events", "html_url": "https://github.com/pytorch/pytorch/pull/11156", "id": 356106645, "node_id": "MDExOlB1bGxSZXF1ZXN0MjEyNDgwOTAy", "number": 11156, "title": "Dont optimize slicing dispatch when we are tracing", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-08-31T19:57:47Z", "updated_at": "2018-09-02T00:14:06Z", "closed_at": "2018-09-02T00:14:06Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/11156", "html_url": "https://github.com/pytorch/pytorch/pull/11156", "diff_url": "https://github.com/pytorch/pytorch/pull/11156.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/11156.patch"}, "body_html": "<p>Previously when we had a slicing expression like <code>x[0:5, 0]</code>, where the sliced tensor was of size <code>5</code> in dimension 0, we would skip dispatching the actual slice call as an optimization.</p>\n<p>This caused incorrect behavior under tracing, as we would not record the slice op and thus if we encountered an input with a different shape while running the trace, we would get incorrect results.</p>", "body_text": "Previously when we had a slicing expression like x[0:5, 0], where the sliced tensor was of size 5 in dimension 0, we would skip dispatching the actual slice call as an optimization.\nThis caused incorrect behavior under tracing, as we would not record the slice op and thus if we encountered an input with a different shape while running the trace, we would get incorrect results.", "body": "Previously when we had a slicing expression like `x[0:5, 0]`, where the sliced tensor was of size `5` in dimension 0, we would skip dispatching the actual slice call as an optimization.\r\n\r\nThis caused incorrect behavior under tracing, as we would not record the slice op and thus if we encountered an input with a different shape while running the trace, we would get incorrect results."}