{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/288926490", "html_url": "https://github.com/pytorch/pytorch/issues/1082#issuecomment-288926490", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1082", "id": 288926490, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODkyNjQ5MA==", "user": {"login": "keskarnitish", "id": 5945552, "node_id": "MDQ6VXNlcjU5NDU1NTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/5945552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keskarnitish", "html_url": "https://github.com/keskarnitish", "followers_url": "https://api.github.com/users/keskarnitish/followers", "following_url": "https://api.github.com/users/keskarnitish/following{/other_user}", "gists_url": "https://api.github.com/users/keskarnitish/gists{/gist_id}", "starred_url": "https://api.github.com/users/keskarnitish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keskarnitish/subscriptions", "organizations_url": "https://api.github.com/users/keskarnitish/orgs", "repos_url": "https://api.github.com/users/keskarnitish/repos", "events_url": "https://api.github.com/users/keskarnitish/events{/privacy}", "received_events_url": "https://api.github.com/users/keskarnitish/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-24T03:49:55Z", "updated_at": "2017-03-24T03:49:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I had the same issue. It seems that the difference lies in the fact that, by default, NumPy does not employ the <a href=\"https://en.wikipedia.org/wiki/Bessel%27s_correction\" rel=\"nofollow\">Bessel correction</a> when computing the standard deviation but PyTorch does. The only difference is in the scaling which you can force via <code>ddof=1</code> in Numpy and via a <code>sqrt( (n-1) / n)</code> for PyTorch. The function signature for PyTorch's <code>std</code> doesn't seem to allow for this extra parameter.</p>\n<p>For your specific example, here's my comment in action:</p>\n<pre><code>In [14]: avg_price_array = [ 2249.,  2311.,  2337.,  2350.,  2380.,  2428.,  2422.,  2472.,\n        2472.,  2462.,  2467.,  2546.,  2546.,  2529.,  2547.,  2585.,\n        2610.,  2631.,  2645.,  2721.,  2794.,  2858.,  2937.,  3021.,\n        3050.,  3048.,  2940.,  2798.,  2796.,  2794.,  2743.,  2833.,\n        2928.,  2978.,  3088.,  3231.,  3200.,  3019.,  3077.,  3124.,\n        3142.,  3212.,  3329.,  3355.,  3319.,  3429.,  3462.,  3408.,\n        3365.,  3360.,  3250.,  3155.,  3156.,  3108.,  3011.,  2926.,\n        2930.,  3013.,  2948.,  2910.]\n\nIn [15]: avg_price_tensor = torch.from_numpy(np.array(avg_price_array))\n\nIn [16]: np.std(avg_price_array) # With n in the denominator; no Bessel Correction\nOut[16]: 329.16336496234408\n\nIn [17]: np.std(avg_price_array, ddof=1) # This is with the Bessel Correction\nOut[17]: 331.94116412502677\n\nIn [18]: avg_price_tensor.std() # This is with the Bessel Correction\nOut[18]: 331.9411641250268\n\nIn [21]: avg_price_tensor.std() * np.sqrt( (len(avg_price_array) - 1.)/(len(avg_price_array) ))\nOut[21]: 329.16336496234408\n</code></pre>\n<p>Hope this helps.</p>", "body_text": "I had the same issue. It seems that the difference lies in the fact that, by default, NumPy does not employ the Bessel correction when computing the standard deviation but PyTorch does. The only difference is in the scaling which you can force via ddof=1 in Numpy and via a sqrt( (n-1) / n) for PyTorch. The function signature for PyTorch's std doesn't seem to allow for this extra parameter.\nFor your specific example, here's my comment in action:\nIn [14]: avg_price_array = [ 2249.,  2311.,  2337.,  2350.,  2380.,  2428.,  2422.,  2472.,\n        2472.,  2462.,  2467.,  2546.,  2546.,  2529.,  2547.,  2585.,\n        2610.,  2631.,  2645.,  2721.,  2794.,  2858.,  2937.,  3021.,\n        3050.,  3048.,  2940.,  2798.,  2796.,  2794.,  2743.,  2833.,\n        2928.,  2978.,  3088.,  3231.,  3200.,  3019.,  3077.,  3124.,\n        3142.,  3212.,  3329.,  3355.,  3319.,  3429.,  3462.,  3408.,\n        3365.,  3360.,  3250.,  3155.,  3156.,  3108.,  3011.,  2926.,\n        2930.,  3013.,  2948.,  2910.]\n\nIn [15]: avg_price_tensor = torch.from_numpy(np.array(avg_price_array))\n\nIn [16]: np.std(avg_price_array) # With n in the denominator; no Bessel Correction\nOut[16]: 329.16336496234408\n\nIn [17]: np.std(avg_price_array, ddof=1) # This is with the Bessel Correction\nOut[17]: 331.94116412502677\n\nIn [18]: avg_price_tensor.std() # This is with the Bessel Correction\nOut[18]: 331.9411641250268\n\nIn [21]: avg_price_tensor.std() * np.sqrt( (len(avg_price_array) - 1.)/(len(avg_price_array) ))\nOut[21]: 329.16336496234408\n\nHope this helps.", "body": "I had the same issue. It seems that the difference lies in the fact that, by default, NumPy does not employ the [Bessel correction](https://en.wikipedia.org/wiki/Bessel%27s_correction) when computing the standard deviation but PyTorch does. The only difference is in the scaling which you can force via `ddof=1` in Numpy and via a `sqrt( (n-1) / n)` for PyTorch. The function signature for PyTorch's `std` doesn't seem to allow for this extra parameter. \r\n\r\nFor your specific example, here's my comment in action:\r\n\r\n```\r\nIn [14]: avg_price_array = [ 2249.,  2311.,  2337.,  2350.,  2380.,  2428.,  2422.,  2472.,\r\n        2472.,  2462.,  2467.,  2546.,  2546.,  2529.,  2547.,  2585.,\r\n        2610.,  2631.,  2645.,  2721.,  2794.,  2858.,  2937.,  3021.,\r\n        3050.,  3048.,  2940.,  2798.,  2796.,  2794.,  2743.,  2833.,\r\n        2928.,  2978.,  3088.,  3231.,  3200.,  3019.,  3077.,  3124.,\r\n        3142.,  3212.,  3329.,  3355.,  3319.,  3429.,  3462.,  3408.,\r\n        3365.,  3360.,  3250.,  3155.,  3156.,  3108.,  3011.,  2926.,\r\n        2930.,  3013.,  2948.,  2910.]\r\n\r\nIn [15]: avg_price_tensor = torch.from_numpy(np.array(avg_price_array))\r\n\r\nIn [16]: np.std(avg_price_array) # With n in the denominator; no Bessel Correction\r\nOut[16]: 329.16336496234408\r\n\r\nIn [17]: np.std(avg_price_array, ddof=1) # This is with the Bessel Correction\r\nOut[17]: 331.94116412502677\r\n\r\nIn [18]: avg_price_tensor.std() # This is with the Bessel Correction\r\nOut[18]: 331.9411641250268\r\n\r\nIn [21]: avg_price_tensor.std() * np.sqrt( (len(avg_price_array) - 1.)/(len(avg_price_array) ))\r\nOut[21]: 329.16336496234408\r\n```\r\n\r\nHope this helps. "}