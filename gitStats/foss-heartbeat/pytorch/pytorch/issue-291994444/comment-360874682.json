{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/360874682", "html_url": "https://github.com/pytorch/pytorch/issues/4877#issuecomment-360874682", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4877", "id": 360874682, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDg3NDY4Mg==", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-26T19:03:40Z", "updated_at": "2018-01-26T19:03:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yeah, I think adding dtype argument (or allowing torch.LongTensor().arange(...) ) , plus giving the \"correct\" behavior for float (not saturating at 2^24) would be the right solution if you don't want to return a dynamic type.</p>\n<p>It's unfortunate that this diverges from numpy and gives very unexpected behavior in the \"common\" case (step=1), when max &gt; 2^24 (which is not even that large). I remember we used to run into this landmine all the time back in torch7 when nn.LookupTable used to take FloatTensor.</p>", "body_text": "Yeah, I think adding dtype argument (or allowing torch.LongTensor().arange(...) ) , plus giving the \"correct\" behavior for float (not saturating at 2^24) would be the right solution if you don't want to return a dynamic type.\nIt's unfortunate that this diverges from numpy and gives very unexpected behavior in the \"common\" case (step=1), when max > 2^24 (which is not even that large). I remember we used to run into this landmine all the time back in torch7 when nn.LookupTable used to take FloatTensor.", "body": "Yeah, I think adding dtype argument (or allowing torch.LongTensor().arange(...) ) , plus giving the \"correct\" behavior for float (not saturating at 2^24) would be the right solution if you don't want to return a dynamic type.\r\n\r\nIt's unfortunate that this diverges from numpy and gives very unexpected behavior in the \"common\" case (step=1), when max > 2^24 (which is not even that large). I remember we used to run into this landmine all the time back in torch7 when nn.LookupTable used to take FloatTensor."}