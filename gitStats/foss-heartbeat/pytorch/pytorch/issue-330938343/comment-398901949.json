{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/398901949", "html_url": "https://github.com/pytorch/pytorch/pull/8313#issuecomment-398901949", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8313", "id": 398901949, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODkwMTk0OQ==", "user": {"login": "bstriner", "id": 12462956, "node_id": "MDQ6VXNlcjEyNDYyOTU2", "avatar_url": "https://avatars3.githubusercontent.com/u/12462956?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bstriner", "html_url": "https://github.com/bstriner", "followers_url": "https://api.github.com/users/bstriner/followers", "following_url": "https://api.github.com/users/bstriner/following{/other_user}", "gists_url": "https://api.github.com/users/bstriner/gists{/gist_id}", "starred_url": "https://api.github.com/users/bstriner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bstriner/subscriptions", "organizations_url": "https://api.github.com/users/bstriner/orgs", "repos_url": "https://api.github.com/users/bstriner/repos", "events_url": "https://api.github.com/users/bstriner/events{/privacy}", "received_events_url": "https://api.github.com/users/bstriner/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-20T21:23:58Z", "updated_at": "2018-06-20T21:23:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If it is same location as cuda, then it isn't a problem. Some people have multiple cudnn installs in separate directories, which is a complete pain.</p>\n<p>One possibility is to pull the paths found by cmake and use them as extra include and library paths if they exist. That would mean cudnn would work if it is in cuda_home or if it is in the same place as when built. whatever libraries you built with would be used for extensions.</p>\n<p>Should cover most situations. Not sure if there would be a situation where you would want to compile with one cudnn in one directory and build extensions with a different one in a different directory.</p>\n<p><a href=\"https://github.com/pytorch/pytorch/blob/master/cmake/Modules/FindCuDNN.cmake\">https://github.com/pytorch/pytorch/blob/master/cmake/Modules/FindCuDNN.cmake</a></p>", "body_text": "If it is same location as cuda, then it isn't a problem. Some people have multiple cudnn installs in separate directories, which is a complete pain.\nOne possibility is to pull the paths found by cmake and use them as extra include and library paths if they exist. That would mean cudnn would work if it is in cuda_home or if it is in the same place as when built. whatever libraries you built with would be used for extensions.\nShould cover most situations. Not sure if there would be a situation where you would want to compile with one cudnn in one directory and build extensions with a different one in a different directory.\nhttps://github.com/pytorch/pytorch/blob/master/cmake/Modules/FindCuDNN.cmake", "body": "If it is same location as cuda, then it isn't a problem. Some people have multiple cudnn installs in separate directories, which is a complete pain.\r\n\r\nOne possibility is to pull the paths found by cmake and use them as extra include and library paths if they exist. That would mean cudnn would work if it is in cuda_home or if it is in the same place as when built. whatever libraries you built with would be used for extensions.\r\n\r\nShould cover most situations. Not sure if there would be a situation where you would want to compile with one cudnn in one directory and build extensions with a different one in a different directory.\r\n\r\nhttps://github.com/pytorch/pytorch/blob/master/cmake/Modules/FindCuDNN.cmake"}