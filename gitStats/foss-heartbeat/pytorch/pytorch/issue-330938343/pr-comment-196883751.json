{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196883751", "pull_request_review_id": 130517965, "id": 196883751, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5Njg4Mzc1MQ==", "diff_hunk": "@@ -538,6 +543,8 @@ def load_inline(name,\n         functions: A list of function names for which to generate function\n             bindings. If a dictionary is given, it should map function names to\n             docstrings (which are otherwise just the function names).\n+        with_cuda: If ``cuda_sources`` is provided, CUDA will always be\n+            enabled. Use this flag for pure CPP extensions that require CUDA.", "path": "torch/utils/cpp_extension.py", "position": null, "original_position": 44, "commit_id": "a81a2b57870ae6fb255b386cb05439a522839499", "original_commit_id": "33464117ad10b41f9ea5d8fed83ff084b0527c63", "user": {"login": "bstriner", "id": 12462956, "node_id": "MDQ6VXNlcjEyNDYyOTU2", "avatar_url": "https://avatars3.githubusercontent.com/u/12462956?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bstriner", "html_url": "https://github.com/bstriner", "followers_url": "https://api.github.com/users/bstriner/followers", "following_url": "https://api.github.com/users/bstriner/following{/other_user}", "gists_url": "https://api.github.com/users/bstriner/gists{/gist_id}", "starred_url": "https://api.github.com/users/bstriner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bstriner/subscriptions", "organizations_url": "https://api.github.com/users/bstriner/orgs", "repos_url": "https://api.github.com/users/bstriner/repos", "events_url": "https://api.github.com/users/bstriner/events{/privacy}", "received_events_url": "https://api.github.com/users/bstriner/received_events", "type": "User", "site_admin": false}, "body": "@ezyang The thing that is tricky to describe is that with_cuda=False will still give you cuda if there are cuda_souces. Maybe the option would make more sense if it was something like `force_cuda` instead? Let me know if you like the below.\r\n\r\n\"Whether or not to enable CUDA. If `cuda_sources` is provided, this option is ignored and CUDA is always enabled. You might explicitly set this to True if your extension requires CUDA but doesn't actually have any CUDA source files.\"", "created_at": "2018-06-20T17:46:57Z", "updated_at": "2018-11-23T15:45:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/8313#discussion_r196883751", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8313", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196883751"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8313#discussion_r196883751"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8313"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> The thing that is tricky to describe is that with_cuda=False will still give you cuda if there are cuda_souces. Maybe the option would make more sense if it was something like <code>force_cuda</code> instead? Let me know if you like the below.</p>\n<p>\"Whether or not to enable CUDA. If <code>cuda_sources</code> is provided, this option is ignored and CUDA is always enabled. You might explicitly set this to True if your extension requires CUDA but doesn't actually have any CUDA source files.\"</p>", "body_text": "@ezyang The thing that is tricky to describe is that with_cuda=False will still give you cuda if there are cuda_souces. Maybe the option would make more sense if it was something like force_cuda instead? Let me know if you like the below.\n\"Whether or not to enable CUDA. If cuda_sources is provided, this option is ignored and CUDA is always enabled. You might explicitly set this to True if your extension requires CUDA but doesn't actually have any CUDA source files.\"", "in_reply_to_id": 196767142}