{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7634", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7634/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7634/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7634/events", "html_url": "https://github.com/pytorch/pytorch/issues/7634", "id": 323839494, "node_id": "MDU6SXNzdWUzMjM4Mzk0OTQ=", "number": 7634, "title": "cuda out of memory err:   when my gpu memory still has 4G left ", "user": {"login": "abbyQu", "id": 13145580, "node_id": "MDQ6VXNlcjEzMTQ1NTgw", "avatar_url": "https://avatars2.githubusercontent.com/u/13145580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abbyQu", "html_url": "https://github.com/abbyQu", "followers_url": "https://api.github.com/users/abbyQu/followers", "following_url": "https://api.github.com/users/abbyQu/following{/other_user}", "gists_url": "https://api.github.com/users/abbyQu/gists{/gist_id}", "starred_url": "https://api.github.com/users/abbyQu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abbyQu/subscriptions", "organizations_url": "https://api.github.com/users/abbyQu/orgs", "repos_url": "https://api.github.com/users/abbyQu/repos", "events_url": "https://api.github.com/users/abbyQu/events{/privacy}", "received_events_url": "https://api.github.com/users/abbyQu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-17T01:16:36Z", "updated_at": "2018-05-17T16:56:09Z", "closed_at": "2018-05-17T16:56:09Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>i was running a trained model  from github ,i watched the gpu memory, found that the script exited when the memory usage got 2G.<br>\nmy gpu is 1060 with 6G memory ,how did that come?</p>\n<p>PS: torch might has the 2G limit,but i haven't install that</p>\n<h2>System Info</h2>\n<p>RuntimeError: cuda runtime err(2): out of memory at /opt/conda/conda-bld/pytorch_1501953625411/work/pytorch-0.1.12/torch/libTHC/THCstorage.cu:66</p>\n<ul>\n<li>PyTorch or Caffe2:</li>\n<li>How you installed PyTorch (conda, pip, source):</li>\n<li>Build command you used (if compiling from source):</li>\n<li>OS: Ubuntu 14.04</li>\n<li>PyTorch version: pytorch 0.1.10</li>\n<li>Python version:  2.7</li>\n<li>CUDA/cuDNN version: 8.0/5.1</li>\n<li>GCC version (if compiling from source): 4.9</li>\n</ul>", "body_text": "Issue description\ni was running a trained model  from github ,i watched the gpu memory, found that the script exited when the memory usage got 2G.\nmy gpu is 1060 with 6G memory ,how did that come?\nPS: torch might has the 2G limit,but i haven't install that\nSystem Info\nRuntimeError: cuda runtime err(2): out of memory at /opt/conda/conda-bld/pytorch_1501953625411/work/pytorch-0.1.12/torch/libTHC/THCstorage.cu:66\n\nPyTorch or Caffe2:\nHow you installed PyTorch (conda, pip, source):\nBuild command you used (if compiling from source):\nOS: Ubuntu 14.04\nPyTorch version: pytorch 0.1.10\nPython version:  2.7\nCUDA/cuDNN version: 8.0/5.1\nGCC version (if compiling from source): 4.9", "body": " \r\n\r\n## Issue description\r\n\r\ni was running a trained model  from github ,i watched the gpu memory, found that the script exited when the memory usage got 2G.\r\nmy gpu is 1060 with 6G memory ,how did that come?\r\n\r\n\r\nPS: torch might has the 2G limit,but i haven't install that \r\n\r\n\r\n \r\n\r\n## System Info\r\nRuntimeError: cuda runtime err(2): out of memory at /opt/conda/conda-bld/pytorch_1501953625411/work/pytorch-0.1.12/torch/libTHC/THCstorage.cu:66\r\n\r\n \r\n\r\n- PyTorch or Caffe2:\r\n- How you installed PyTorch (conda, pip, source):\r\n- Build command you used (if compiling from source):\r\n- OS: Ubuntu 14.04\r\n- PyTorch version: pytorch 0.1.10\r\n- Python version:  2.7\r\n- CUDA/cuDNN version: 8.0/5.1 \r\n- GCC version (if compiling from source): 4.9\r\n \r\n \r\n"}