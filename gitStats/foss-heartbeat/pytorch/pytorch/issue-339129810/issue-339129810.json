{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9236", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9236/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9236/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9236/events", "html_url": "https://github.com/pytorch/pytorch/issues/9236", "id": 339129810, "node_id": "MDU6SXNzdWUzMzkxMjk4MTA=", "number": 9236, "title": "[feature request] Implementing a sampler for oversampling/undersampling", "user": {"login": "huntzhan", "id": 5213906, "node_id": "MDQ6VXNlcjUyMTM5MDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5213906?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huntzhan", "html_url": "https://github.com/huntzhan", "followers_url": "https://api.github.com/users/huntzhan/followers", "following_url": "https://api.github.com/users/huntzhan/following{/other_user}", "gists_url": "https://api.github.com/users/huntzhan/gists{/gist_id}", "starred_url": "https://api.github.com/users/huntzhan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huntzhan/subscriptions", "organizations_url": "https://api.github.com/users/huntzhan/orgs", "repos_url": "https://api.github.com/users/huntzhan/repos", "events_url": "https://api.github.com/users/huntzhan/events{/privacy}", "received_events_url": "https://api.github.com/users/huntzhan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-07T08:49:48Z", "updated_at": "2018-07-09T17:30:19Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>TL;DR:</strong> I've implemented a customized sampler with the control of the label distribution in each batch.<br>\nIs this something worth adding to PyTorch?</p>\n<p>The signature of <code>DistributionSampler</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">DistributionSampler</span>(<span class=\"pl-e\">Sampler</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">'''</span></span>\n<span class=\"pl-s\">    Control the label distribution.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Arguments:</span>\n<span class=\"pl-s\">        dataset (Dataset):</span>\n<span class=\"pl-s\">            dataset to sample from.</span>\n<span class=\"pl-s\">        label_accessor_fn (callable):</span>\n<span class=\"pl-s\">            to get the label of each sample.</span>\n<span class=\"pl-s\">        label_distribution (Dict[Any, float], optional):</span>\n<span class=\"pl-s\">            define the distribution of labels during for sampling.</span>\n<span class=\"pl-s\">        epoch_size (int, optional):</span>\n<span class=\"pl-s\">            control the size of the epoch.</span>\n<span class=\"pl-s\">            If not provided, len(self.dataset) will be used.</span>\n<span class=\"pl-s\">        strict_mode (bool, optional):</span>\n<span class=\"pl-s\">            check if label_distribution, if provided, match the set of</span>\n<span class=\"pl-s\">            labels extracted from dataset.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">'''</span></span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(\n        <span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">dataset</span>, <span class=\"pl-smi\">label_accessor_fn</span>,\n        <span class=\"pl-smi\">label_distribution</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">epoch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n        <span class=\"pl-smi\">strict_mode</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n    ):\n        <span class=\"pl-c1\">...</span></pre></div>\n<p>Usage:</p>\n<pre><code>    sampler = DistributionSampler(\n        dataset, lambda x: x['label'],\n        label_distribution={0: 0.3, 1: 0.7},\n    )\n</code></pre>", "body_text": "TL;DR: I've implemented a customized sampler with the control of the label distribution in each batch.\nIs this something worth adding to PyTorch?\nThe signature of DistributionSampler:\nclass DistributionSampler(Sampler):\n    '''\n    Control the label distribution.\n\n    Arguments:\n        dataset (Dataset):\n            dataset to sample from.\n        label_accessor_fn (callable):\n            to get the label of each sample.\n        label_distribution (Dict[Any, float], optional):\n            define the distribution of labels during for sampling.\n        epoch_size (int, optional):\n            control the size of the epoch.\n            If not provided, len(self.dataset) will be used.\n        strict_mode (bool, optional):\n            check if label_distribution, if provided, match the set of\n            labels extracted from dataset.\n    '''\n\n    def __init__(\n        self, dataset, label_accessor_fn,\n        label_distribution=None, epoch_size=None,\n        strict_mode=True,\n    ):\n        ...\nUsage:\n    sampler = DistributionSampler(\n        dataset, lambda x: x['label'],\n        label_distribution={0: 0.3, 1: 0.7},\n    )", "body": "**TL;DR:** I've implemented a customized sampler with the control of the label distribution in each batch.\r\nIs this something worth adding to PyTorch?\r\n\r\nThe signature of `DistributionSampler`:\r\n\r\n```python\r\nclass DistributionSampler(Sampler):\r\n    '''\r\n    Control the label distribution.\r\n\r\n    Arguments:\r\n        dataset (Dataset):\r\n            dataset to sample from.\r\n        label_accessor_fn (callable):\r\n            to get the label of each sample.\r\n        label_distribution (Dict[Any, float], optional):\r\n            define the distribution of labels during for sampling.\r\n        epoch_size (int, optional):\r\n            control the size of the epoch.\r\n            If not provided, len(self.dataset) will be used.\r\n        strict_mode (bool, optional):\r\n            check if label_distribution, if provided, match the set of\r\n            labels extracted from dataset.\r\n    '''\r\n\r\n    def __init__(\r\n        self, dataset, label_accessor_fn,\r\n        label_distribution=None, epoch_size=None,\r\n        strict_mode=True,\r\n    ):\r\n        ...\r\n```\r\n\r\nUsage:\r\n\r\n```\r\n    sampler = DistributionSampler(\r\n        dataset, lambda x: x['label'],\r\n        label_distribution={0: 0.3, 1: 0.7},\r\n    )\r\n```\r\n"}