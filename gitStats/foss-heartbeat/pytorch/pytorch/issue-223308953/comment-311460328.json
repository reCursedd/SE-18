{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/311460328", "html_url": "https://github.com/pytorch/pytorch/issues/1318#issuecomment-311460328", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1318", "id": 311460328, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTQ2MDMyOA==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-27T19:28:28Z", "updated_at": "2017-06-27T19:28:28Z", "author_association": "MEMBER", "body_html": "<p>Nice work tracking this down. A few comments:</p>\n<ol>\n<li>\n<p><a href=\"https://github.com/pytorch/pytorch/compare/master...albanD:fix_visit_bug#diff-e7525582ab432c30821289d64cc52bc3R1311\">This line</a> isn't necessary to trigger the crash.</p>\n</li>\n<li>\n<p>The second solution is significantly simpler, but I think it will fail to collect some cycles that include variables that are the result of functions which return multiple outputs. i.e. if <code>f(x) -&gt; (a, b)</code> then <code>a</code> and <code>b</code> may share a <code>grad_fn</code> so <code>var.grad_fn.use_count &gt; 1</code> might be true.</p>\n</li>\n</ol>", "body_text": "Nice work tracking this down. A few comments:\n\n\nThis line isn't necessary to trigger the crash.\n\n\nThe second solution is significantly simpler, but I think it will fail to collect some cycles that include variables that are the result of functions which return multiple outputs. i.e. if f(x) -> (a, b) then a and b may share a grad_fn so var.grad_fn.use_count > 1 might be true.", "body": "Nice work tracking this down. A few comments:\r\n\r\n1. [This line](https://github.com/pytorch/pytorch/compare/master...albanD:fix_visit_bug#diff-e7525582ab432c30821289d64cc52bc3R1311) isn't necessary to trigger the crash.\r\n\r\n2. The second solution is significantly simpler, but I think it will fail to collect some cycles that include variables that are the result of functions which return multiple outputs. i.e. if `f(x) -> (a, b)` then `a` and `b` may share a `grad_fn` so `var.grad_fn.use_count > 1` might be true."}