{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/398593258", "html_url": "https://github.com/pytorch/pytorch/pull/8635#issuecomment-398593258", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8635", "id": 398593258, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODU5MzI1OA==", "user": {"login": "fehiepsi", "id": 4736342, "node_id": "MDQ6VXNlcjQ3MzYzNDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/4736342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fehiepsi", "html_url": "https://github.com/fehiepsi", "followers_url": "https://api.github.com/users/fehiepsi/followers", "following_url": "https://api.github.com/users/fehiepsi/following{/other_user}", "gists_url": "https://api.github.com/users/fehiepsi/gists{/gist_id}", "starred_url": "https://api.github.com/users/fehiepsi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fehiepsi/subscriptions", "organizations_url": "https://api.github.com/users/fehiepsi/orgs", "repos_url": "https://api.github.com/users/fehiepsi/repos", "events_url": "https://api.github.com/users/fehiepsi/events{/privacy}", "received_events_url": "https://api.github.com/users/fehiepsi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-20T01:14:41Z", "updated_at": "2018-06-20T01:14:41Z", "author_association": "CONTRIBUTOR", "body_html": "<p>About the gradcheck which is 5x off, it seems that we have caught the issue at <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"333616066\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/8649\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/8649/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/8649\">#8649</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> will take a look for it.</p>\n<p>I am wondering about two other issues. The first is if <code>scale_factor</code> and <code>scale_diag</code> are good names. In <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/MultivariateNormalDiagPlusLowRank\" rel=\"nofollow\">tensorflow</a>, they used <code>scale_perturb_factor</code> and <code>scale_diag</code>. <code>factor</code> term comes from \"factor loading matrix\" in factor analysis. It is also called <code>components</code> in PCA. To me, <code>scale_factor</code> is a good name but I am open to other choices.</p>\n<p>Another issue is when to do \"broadcasting\". Different from other distributions, it seems that it is better to avoid using <code>.expand</code> in the first place. For example, computing <code>scale_tril</code> from <code>expanded_covariance_matrix</code> is less efficient than computing <code>scale_tril</code> from <code>covariance_matrix</code> then expand. So I think that depending on \"whatever\" scale input (cov, tril, precision) is, we will calculate <code>_scale_tril_unexpand</code> in the init method. Other properties will be expanded from the corresponding calculation with this <code>_scale_tril_unexpand</code>. This saves both memory/computation and makes properties of MVN consistency with other distributions.</p>\n<p>Regarding \"broadcasting\", to solve Linv_y, I broadcast L to match the batch shape of y, then use <code>trtrs</code> to solve. This might be inefficient when L and y have different batch shape. Assume that batch_shape of the distribution is 9, y has shape 10 x 9 x 8, and L has shape 3 x 8 x 8, then it is better to convert L to 9 x 8 x 8,  y to 9 x 80, and then apply batch_trtrs with L and y, then reshape the result. I am planning to implement that way after the <code>gradcheck</code> issue is fixed but wondering if there is a better workaround. FYI, we don't face this issue if we take the inverse of L first and then multiply because <code>.matmul</code> will automatically do \"broadcasting\".</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a> I think that you will have better ideas than me on these issues. Could you please give some thoughts on them?</p>", "body_text": "About the gradcheck which is 5x off, it seems that we have caught the issue at #8649 and @SsnL will take a look for it.\nI am wondering about two other issues. The first is if scale_factor and scale_diag are good names. In tensorflow, they used scale_perturb_factor and scale_diag. factor term comes from \"factor loading matrix\" in factor analysis. It is also called components in PCA. To me, scale_factor is a good name but I am open to other choices.\nAnother issue is when to do \"broadcasting\". Different from other distributions, it seems that it is better to avoid using .expand in the first place. For example, computing scale_tril from expanded_covariance_matrix is less efficient than computing scale_tril from covariance_matrix then expand. So I think that depending on \"whatever\" scale input (cov, tril, precision) is, we will calculate _scale_tril_unexpand in the init method. Other properties will be expanded from the corresponding calculation with this _scale_tril_unexpand. This saves both memory/computation and makes properties of MVN consistency with other distributions.\nRegarding \"broadcasting\", to solve Linv_y, I broadcast L to match the batch shape of y, then use trtrs to solve. This might be inefficient when L and y have different batch shape. Assume that batch_shape of the distribution is 9, y has shape 10 x 9 x 8, and L has shape 3 x 8 x 8, then it is better to convert L to 9 x 8 x 8,  y to 9 x 80, and then apply batch_trtrs with L and y, then reshape the result. I am planning to implement that way after the gradcheck issue is fixed but wondering if there is a better workaround. FYI, we don't face this issue if we take the inverse of L first and then multiply because .matmul will automatically do \"broadcasting\".\n@fritzo I think that you will have better ideas than me on these issues. Could you please give some thoughts on them?", "body": "About the gradcheck which is 5x off, it seems that we have caught the issue at https://github.com/pytorch/pytorch/issues/8649 and @SsnL will take a look for it.\r\n\r\nI am wondering about two other issues. The first is if `scale_factor` and `scale_diag` are good names. In [tensorflow](https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/MultivariateNormalDiagPlusLowRank), they used `scale_perturb_factor` and `scale_diag`. `factor` term comes from \"factor loading matrix\" in factor analysis. It is also called `components` in PCA. To me, `scale_factor` is a good name but I am open to other choices.\r\n\r\nAnother issue is when to do \"broadcasting\". Different from other distributions, it seems that it is better to avoid using `.expand` in the first place. For example, computing `scale_tril` from `expanded_covariance_matrix` is less efficient than computing `scale_tril` from `covariance_matrix` then expand. So I think that depending on \"whatever\" scale input (cov, tril, precision) is, we will calculate `_scale_tril_unexpand` in the init method. Other properties will be expanded from the corresponding calculation with this `_scale_tril_unexpand`. This saves both memory/computation and makes properties of MVN consistency with other distributions.\r\n\r\nRegarding \"broadcasting\", to solve Linv_y, I broadcast L to match the batch shape of y, then use `trtrs` to solve. This might be inefficient when L and y have different batch shape. Assume that batch_shape of the distribution is 9, y has shape 10 x 9 x 8, and L has shape 3 x 8 x 8, then it is better to convert L to 9 x 8 x 8,  y to 9 x 80, and then apply batch_trtrs with L and y, then reshape the result. I am planning to implement that way after the `gradcheck` issue is fixed but wondering if there is a better workaround. FYI, we don't face this issue if we take the inverse of L first and then multiply because `.matmul` will automatically do \"broadcasting\".\r\n\r\n@fritzo I think that you will have better ideas than me on these issues. Could you please give some thoughts on them?"}