{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/404134968", "html_url": "https://github.com/pytorch/pytorch/pull/8635#issuecomment-404134968", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8635", "id": 404134968, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDEzNDk2OA==", "user": {"login": "fehiepsi", "id": 4736342, "node_id": "MDQ6VXNlcjQ3MzYzNDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/4736342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fehiepsi", "html_url": "https://github.com/fehiepsi", "followers_url": "https://api.github.com/users/fehiepsi/followers", "following_url": "https://api.github.com/users/fehiepsi/following{/other_user}", "gists_url": "https://api.github.com/users/fehiepsi/gists{/gist_id}", "starred_url": "https://api.github.com/users/fehiepsi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fehiepsi/subscriptions", "organizations_url": "https://api.github.com/users/fehiepsi/orgs", "repos_url": "https://api.github.com/users/fehiepsi/repos", "events_url": "https://api.github.com/users/fehiepsi/events{/privacy}", "received_events_url": "https://api.github.com/users/fehiepsi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-11T11:21:27Z", "updated_at": "2018-07-11T11:23:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a> Currently, the implementation for <code>.log_prob</code> is fast (O(NM^2)), but the implementation for <code>.sample</code> is slow (O(N^3)) because I just compute scale_tril of <code>W @ W.t() + D</code>, which is a matrix of size <code>N x N</code>. This has been in my mind for a while and I have thought that there is no solution for it.</p>\n<p>Today, I checked again the slack's distributions room and found that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6617696\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/stepelu\">@stepelu</a> has suggested a very nice idea to reparameterize: take two random variables eps1, eps2 and compute W.eps1 + D^(1/2).eps2. It is a \"whoa\" moment for me. Sampling this way is pretty much fast! I will make changes corresponding to that.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>  In addition, I checked again tensorflow's <a href=\"https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/MultivariateNormalDiagPlusLowRank\" rel=\"nofollow\">MultivariateNormalDiagPlusLowRank</a>. It is different from us: their low rank version is for <code>scale</code>, not <code>covariance_matrix</code> (which is scale @ scale.t()). So I wonder if we stick with the names: <code>scale_factor</code> and <code>scale_diag</code> or change it to something like <code>components</code> and <code>diagonal</code>. If we keep <code>scale_factor</code> and <code>scale_diag</code>, then people might be confused with the ones in tensorflow.</p>", "body_text": "@fritzo Currently, the implementation for .log_prob is fast (O(NM^2)), but the implementation for .sample is slow (O(N^3)) because I just compute scale_tril of W @ W.t() + D, which is a matrix of size N x N. This has been in my mind for a while and I have thought that there is no solution for it.\nToday, I checked again the slack's distributions room and found that @stepelu has suggested a very nice idea to reparameterize: take two random variables eps1, eps2 and compute W.eps1 + D^(1/2).eps2. It is a \"whoa\" moment for me. Sampling this way is pretty much fast! I will make changes corresponding to that.\n@fritzo @apaszke  In addition, I checked again tensorflow's MultivariateNormalDiagPlusLowRank. It is different from us: their low rank version is for scale, not covariance_matrix (which is scale @ scale.t()). So I wonder if we stick with the names: scale_factor and scale_diag or change it to something like components and diagonal. If we keep scale_factor and scale_diag, then people might be confused with the ones in tensorflow.", "body": "@fritzo Currently, the implementation for `.log_prob` is fast (O(NM^2)), but the implementation for `.sample` is slow (O(N^3)) because I just compute scale_tril of `W @ W.t() + D`, which is a matrix of size `N x N`. This has been in my mind for a while and I have thought that there is no solution for it.\r\n\r\nToday, I checked again the slack's distributions room and found that @stepelu has suggested a very nice idea to reparameterize: take two random variables eps1, eps2 and compute W.eps1 + D^(1/2).eps2. It is a \"whoa\" moment for me. Sampling this way is pretty much fast! I will make changes corresponding to that.\r\n\r\n@fritzo @apaszke  In addition, I checked again tensorflow's [MultivariateNormalDiagPlusLowRank](https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/MultivariateNormalDiagPlusLowRank). It is different from us: their low rank version is for `scale`, not `covariance_matrix` (which is scale @ scale.t()). So I wonder if we stick with the names: `scale_factor` and `scale_diag` or change it to something like `components` and `diagonal`. If we keep `scale_factor` and `scale_diag`, then people might be confused with the ones in tensorflow."}