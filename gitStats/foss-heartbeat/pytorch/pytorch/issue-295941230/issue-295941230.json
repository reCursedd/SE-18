{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5159", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5159/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5159/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5159/events", "html_url": "https://github.com/pytorch/pytorch/issues/5159", "id": 295941230, "node_id": "MDU6SXNzdWUyOTU5NDEyMzA=", "number": 5159, "title": "TakeBackward taking a significant portion of backward time", "user": {"login": "rachtsingh", "id": 1606892, "node_id": "MDQ6VXNlcjE2MDY4OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1606892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rachtsingh", "html_url": "https://github.com/rachtsingh", "followers_url": "https://api.github.com/users/rachtsingh/followers", "following_url": "https://api.github.com/users/rachtsingh/following{/other_user}", "gists_url": "https://api.github.com/users/rachtsingh/gists{/gist_id}", "starred_url": "https://api.github.com/users/rachtsingh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rachtsingh/subscriptions", "organizations_url": "https://api.github.com/users/rachtsingh/orgs", "repos_url": "https://api.github.com/users/rachtsingh/repos", "events_url": "https://api.github.com/users/rachtsingh/events{/privacy}", "received_events_url": "https://api.github.com/users/rachtsingh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-02-09T17:03:48Z", "updated_at": "2018-05-28T15:14:00Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>I'm trying to write some code that requires reindexing the hidden states of an LSTM at each step (because of particle filtering). Is there a more efficient way to do this? It's pretty slow right now, and I wonder if another approach (<code>scatter_</code>?) might be better.</p>\n<p>If there's an internal issue with PyTorch, I'm happy to tackle it and make a PR; I just don't know where to look.</p>\n<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: <code>0.4.0a0+e3e3874</code></li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: 2.7.12</li>\n<li>CUDA/cuDNN version: 8.0</li>\n<li>GPU models and configuration: Tesla K80</li>\n<li>GCC version (if compiling from source): 5.4.0</li>\n</ul>\n<pre><code>import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nINPUT_SIZE = 1024\nHIDDEN_SIZE = 512\n\n\nclass IndexingIssues(nn.Module):\n    def __init__(self):\n        super(IndexingIssues, self).__init__()\n        self.enc = nn.LSTMCell(INPUT_SIZE, HIDDEN_SIZE)\n\n    def forward(self, input):\n        seq_len, batch_sz, _ = input.size()\n        h = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\n        c = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\n        for i in range(seq_len):\n            h, c = self.enc(input[i], (h, c))\n            idx = torch.arange(batch_sz).long().cuda().view(-1)  # just identity for now\n            h = h[idx]\n            c = c[idx]\n        return h.sum()\n\n\ndef main():\n    data = Variable(torch.randn(15, 80, INPUT_SIZE).cuda())\n    model = IndexingIssues().cuda()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n    with torch.autograd.profiler.profile() as prof:\n        for i in range(5):\n            optimizer.zero_grad()\n            loss = model(data)\n            loss.backward()\n            optimizer.step()\n    prof.export_chrome_trace(\"repro.prof\")\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p>Here's the chrome_trace it outputs <a href=\"https://github.com/pytorch/pytorch/files/1711786/repro.txt\">repro.txt</a><br>\n(this isn't a text file, just needed to rename so Github would accept it)</p>", "body_text": "I'm trying to write some code that requires reindexing the hidden states of an LSTM at each step (because of particle filtering). Is there a more efficient way to do this? It's pretty slow right now, and I wonder if another approach (scatter_?) might be better.\nIf there's an internal issue with PyTorch, I'm happy to tackle it and make a PR; I just don't know where to look.\n\nOS: Ubuntu 16.04\nPyTorch version: 0.4.0a0+e3e3874\nHow you installed PyTorch (conda, pip, source): source\nPython version: 2.7.12\nCUDA/cuDNN version: 8.0\nGPU models and configuration: Tesla K80\nGCC version (if compiling from source): 5.4.0\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nINPUT_SIZE = 1024\nHIDDEN_SIZE = 512\n\n\nclass IndexingIssues(nn.Module):\n    def __init__(self):\n        super(IndexingIssues, self).__init__()\n        self.enc = nn.LSTMCell(INPUT_SIZE, HIDDEN_SIZE)\n\n    def forward(self, input):\n        seq_len, batch_sz, _ = input.size()\n        h = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\n        c = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\n        for i in range(seq_len):\n            h, c = self.enc(input[i], (h, c))\n            idx = torch.arange(batch_sz).long().cuda().view(-1)  # just identity for now\n            h = h[idx]\n            c = c[idx]\n        return h.sum()\n\n\ndef main():\n    data = Variable(torch.randn(15, 80, INPUT_SIZE).cuda())\n    model = IndexingIssues().cuda()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n    with torch.autograd.profiler.profile() as prof:\n        for i in range(5):\n            optimizer.zero_grad()\n            loss = model(data)\n            loss.backward()\n            optimizer.step()\n    prof.export_chrome_trace(\"repro.prof\")\n\n\nif __name__ == '__main__':\n    main()\n\nHere's the chrome_trace it outputs repro.txt\n(this isn't a text file, just needed to rename so Github would accept it)", "body": "I'm trying to write some code that requires reindexing the hidden states of an LSTM at each step (because of particle filtering). Is there a more efficient way to do this? It's pretty slow right now, and I wonder if another approach (`scatter_`?) might be better.\r\n\r\nIf there's an internal issue with PyTorch, I'm happy to tackle it and make a PR; I just don't know where to look.\r\n\r\n- OS: Ubuntu 16.04\r\n- PyTorch version: `0.4.0a0+e3e3874`\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: 2.7.12\r\n- CUDA/cuDNN version: 8.0\r\n- GPU models and configuration: Tesla K80\r\n- GCC version (if compiling from source): 5.4.0\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nINPUT_SIZE = 1024\r\nHIDDEN_SIZE = 512\r\n\r\n\r\nclass IndexingIssues(nn.Module):\r\n    def __init__(self):\r\n        super(IndexingIssues, self).__init__()\r\n        self.enc = nn.LSTMCell(INPUT_SIZE, HIDDEN_SIZE)\r\n\r\n    def forward(self, input):\r\n        seq_len, batch_sz, _ = input.size()\r\n        h = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\r\n        c = Variable(input.data.new(batch_sz, HIDDEN_SIZE).zero_())\r\n        for i in range(seq_len):\r\n            h, c = self.enc(input[i], (h, c))\r\n            idx = torch.arange(batch_sz).long().cuda().view(-1)  # just identity for now\r\n            h = h[idx]\r\n            c = c[idx]\r\n        return h.sum()\r\n\r\n\r\ndef main():\r\n    data = Variable(torch.randn(15, 80, INPUT_SIZE).cuda())\r\n    model = IndexingIssues().cuda()\r\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\r\n    with torch.autograd.profiler.profile() as prof:\r\n        for i in range(5):\r\n            optimizer.zero_grad()\r\n            loss = model(data)\r\n            loss.backward()\r\n            optimizer.step()\r\n    prof.export_chrome_trace(\"repro.prof\")\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nHere's the chrome_trace it outputs [repro.txt](https://github.com/pytorch/pytorch/files/1711786/repro.txt)\r\n(this isn't a text file, just needed to rename so Github would accept it)"}