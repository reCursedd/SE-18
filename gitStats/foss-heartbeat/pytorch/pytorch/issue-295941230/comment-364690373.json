{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/364690373", "html_url": "https://github.com/pytorch/pytorch/issues/5159#issuecomment-364690373", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5159", "id": 364690373, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDY5MDM3Mw==", "user": {"login": "rachtsingh", "id": 1606892, "node_id": "MDQ6VXNlcjE2MDY4OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1606892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rachtsingh", "html_url": "https://github.com/rachtsingh", "followers_url": "https://api.github.com/users/rachtsingh/followers", "following_url": "https://api.github.com/users/rachtsingh/following{/other_user}", "gists_url": "https://api.github.com/users/rachtsingh/gists{/gist_id}", "starred_url": "https://api.github.com/users/rachtsingh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rachtsingh/subscriptions", "organizations_url": "https://api.github.com/users/rachtsingh/orgs", "repos_url": "https://api.github.com/users/rachtsingh/repos", "events_url": "https://api.github.com/users/rachtsingh/events{/privacy}", "received_events_url": "https://api.github.com/users/rachtsingh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-10T20:40:37Z", "updated_at": "2018-02-10T20:40:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes, you were completely right - it's 5-10x faster on backward compared to direct indexing on some benchmarks I just ran. This is really helpful, thank you very much.</p>\n<h3>indexing operator</h3>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Wall Duration</th>\n<th>Self time</th>\n<th>Average Duration</th>\n<th>Occurrences</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>SumBackward0</td>\n<td>0.014 ms</td>\n<td>0.004 ms</td>\n<td>0.014 ms</td>\n<td>1</td>\n</tr>\n<tr>\n<td>TakeBackward</td>\n<td>7.619 ms</td>\n<td>0.378 ms</td>\n<td>0.263 ms</td>\n<td>29</td>\n</tr>\n<tr>\n<td>LSTMFusedBackward</td>\n<td>3.276 ms</td>\n<td>2.191 ms</td>\n<td>0.218 ms</td>\n<td>15</td>\n</tr>\n<tr>\n<td>MmBackward</td>\n<td>3.155 ms</td>\n<td>0.710 ms</td>\n<td>0.105 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>TBackward</td>\n<td>0.265 ms</td>\n<td>0.152 ms</td>\n<td>0.009 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>add</td>\n<td>1.705 ms</td>\n<td>1.705 ms</td>\n<td>0.030 ms</td>\n<td>56</td>\n</tr>\n<tr>\n<td>N5torch8autograd14AccumulateGradE</td>\n<td>0.107 ms</td>\n<td>0.107 ms</td>\n<td>0.027 ms</td>\n<td>4</td>\n</tr>\n<tr>\n<td>expand</td>\n<td>0.010 ms</td>\n<td>0.010 ms</td>\n<td>0.010 ms</td>\n<td>1</td>\n</tr>\n<tr>\n<td>zeros</td>\n<td>0.488 ms</td>\n<td>0.488 ms</td>\n<td>0.016 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>put_</td>\n<td>6.767 ms</td>\n<td>6.767 ms</td>\n<td>0.233 ms</td>\n<td>29</td>\n</tr>\n<tr>\n<td>tensor</td>\n<td>0.202 ms</td>\n<td>0.202 ms</td>\n<td>0.007 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>sum</td>\n<td>0.869 ms</td>\n<td>0.869 ms</td>\n<td>0.029 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>t</td>\n<td>0.557 ms</td>\n<td>0.557 ms</td>\n<td>0.005 ms</td>\n<td>104</td>\n</tr>\n<tr>\n<td>mm</td>\n<td>2.002 ms</td>\n<td>2.002 ms</td>\n<td>0.045 ms</td>\n<td>44</td>\n</tr>\n<tr>\n<td>Totals</td>\n<td>27.036 ms</td>\n<td>16.142 ms</td>\n<td>0.062 ms</td>\n<td>433</td>\n</tr>\n</tbody>\n</table>\n<h3><code>index_select</code></h3>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Wall Duration</th>\n<th>Self time</th>\n<th>Average Duration</th>\n<th>Occurrences</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>N5torch8autograd9GraphRootE</td>\n<td>0.002 ms</td>\n<td>0.002 ms</td>\n<td>0.002 ms</td>\n<td>1</td>\n</tr>\n<tr>\n<td>SumBackward0</td>\n<td>0.013 ms</td>\n<td>0.004 ms</td>\n<td>0.013 ms</td>\n<td>1</td>\n</tr>\n<tr>\n<td>IndexSelectBackward</td>\n<td>1.164 ms</td>\n<td>0.226 ms</td>\n<td>0.040 ms</td>\n<td>29</td>\n</tr>\n<tr>\n<td>LSTMFusedBackward</td>\n<td>2.568 ms</td>\n<td>1.817 ms</td>\n<td>0.171 ms</td>\n<td>15</td>\n</tr>\n<tr>\n<td>MmBackward</td>\n<td>2.140 ms</td>\n<td>0.325 ms</td>\n<td>0.071 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>TBackward</td>\n<td>0.330 ms</td>\n<td>0.215 ms</td>\n<td>0.011 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>add</td>\n<td>1.095 ms</td>\n<td>1.095 ms</td>\n<td>0.020 ms</td>\n<td>56</td>\n</tr>\n<tr>\n<td>N5torch8autograd14AccumulateGradE</td>\n<td>0.042 ms</td>\n<td>0.042 ms</td>\n<td>0.010 ms</td>\n<td>4</td>\n</tr>\n<tr>\n<td>expand</td>\n<td>0.009 ms</td>\n<td>0.009 ms</td>\n<td>0.009 ms</td>\n<td>1</td>\n</tr>\n<tr>\n<td>zeros</td>\n<td>0.509 ms</td>\n<td>0.509 ms</td>\n<td>0.017 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>index_add_</td>\n<td>0.443 ms</td>\n<td>0.443 ms</td>\n<td>0.015 ms</td>\n<td>29</td>\n</tr>\n<tr>\n<td>tensor</td>\n<td>0.209 ms</td>\n<td>0.209 ms</td>\n<td>0.007 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>sum</td>\n<td>0.528 ms</td>\n<td>0.528 ms</td>\n<td>0.018 ms</td>\n<td>30</td>\n</tr>\n<tr>\n<td>t</td>\n<td>0.564 ms</td>\n<td>0.564 ms</td>\n<td>0.005 ms</td>\n<td>104</td>\n</tr>\n<tr>\n<td>mm</td>\n<td>1.366 ms</td>\n<td>1.366 ms</td>\n<td>0.031 ms</td>\n<td>44</td>\n</tr>\n<tr>\n<td>Totals</td>\n<td>10.982 ms</td>\n<td>7.353 ms</td>\n<td>0.025 ms</td>\n<td>434</td>\n</tr>\n</tbody>\n</table>\n<p>I'm not sure how accurate these profiling dumps are (since I'm not sure whether they measure kernel execution time correctly), but at least in terms of wall clock time it's definitely worthwhile.</p>", "body_text": "Yes, you were completely right - it's 5-10x faster on backward compared to direct indexing on some benchmarks I just ran. This is really helpful, thank you very much.\nindexing operator\n\n\n\nName\nWall Duration\nSelf time\nAverage Duration\nOccurrences\n\n\n\n\nSumBackward0\n0.014 ms\n0.004 ms\n0.014 ms\n1\n\n\nTakeBackward\n7.619 ms\n0.378 ms\n0.263 ms\n29\n\n\nLSTMFusedBackward\n3.276 ms\n2.191 ms\n0.218 ms\n15\n\n\nMmBackward\n3.155 ms\n0.710 ms\n0.105 ms\n30\n\n\nTBackward\n0.265 ms\n0.152 ms\n0.009 ms\n30\n\n\nadd\n1.705 ms\n1.705 ms\n0.030 ms\n56\n\n\nN5torch8autograd14AccumulateGradE\n0.107 ms\n0.107 ms\n0.027 ms\n4\n\n\nexpand\n0.010 ms\n0.010 ms\n0.010 ms\n1\n\n\nzeros\n0.488 ms\n0.488 ms\n0.016 ms\n30\n\n\nput_\n6.767 ms\n6.767 ms\n0.233 ms\n29\n\n\ntensor\n0.202 ms\n0.202 ms\n0.007 ms\n30\n\n\nsum\n0.869 ms\n0.869 ms\n0.029 ms\n30\n\n\nt\n0.557 ms\n0.557 ms\n0.005 ms\n104\n\n\nmm\n2.002 ms\n2.002 ms\n0.045 ms\n44\n\n\nTotals\n27.036 ms\n16.142 ms\n0.062 ms\n433\n\n\n\nindex_select\n\n\n\nName\nWall Duration\nSelf time\nAverage Duration\nOccurrences\n\n\n\n\nN5torch8autograd9GraphRootE\n0.002 ms\n0.002 ms\n0.002 ms\n1\n\n\nSumBackward0\n0.013 ms\n0.004 ms\n0.013 ms\n1\n\n\nIndexSelectBackward\n1.164 ms\n0.226 ms\n0.040 ms\n29\n\n\nLSTMFusedBackward\n2.568 ms\n1.817 ms\n0.171 ms\n15\n\n\nMmBackward\n2.140 ms\n0.325 ms\n0.071 ms\n30\n\n\nTBackward\n0.330 ms\n0.215 ms\n0.011 ms\n30\n\n\nadd\n1.095 ms\n1.095 ms\n0.020 ms\n56\n\n\nN5torch8autograd14AccumulateGradE\n0.042 ms\n0.042 ms\n0.010 ms\n4\n\n\nexpand\n0.009 ms\n0.009 ms\n0.009 ms\n1\n\n\nzeros\n0.509 ms\n0.509 ms\n0.017 ms\n30\n\n\nindex_add_\n0.443 ms\n0.443 ms\n0.015 ms\n29\n\n\ntensor\n0.209 ms\n0.209 ms\n0.007 ms\n30\n\n\nsum\n0.528 ms\n0.528 ms\n0.018 ms\n30\n\n\nt\n0.564 ms\n0.564 ms\n0.005 ms\n104\n\n\nmm\n1.366 ms\n1.366 ms\n0.031 ms\n44\n\n\nTotals\n10.982 ms\n7.353 ms\n0.025 ms\n434\n\n\n\nI'm not sure how accurate these profiling dumps are (since I'm not sure whether they measure kernel execution time correctly), but at least in terms of wall clock time it's definitely worthwhile.", "body": "Yes, you were completely right - it's 5-10x faster on backward compared to direct indexing on some benchmarks I just ran. This is really helpful, thank you very much.\r\n\r\n### indexing operator\r\n\r\nName | Wall Duration | Self time | Average Duration | Occurrences\r\n-- | -- | -- | -- | --\r\nSumBackward0 | 0.014 ms | 0.004 ms | 0.014 ms | 1\r\nTakeBackward | 7.619 ms | 0.378 ms | 0.263 ms | 29\r\nLSTMFusedBackward | 3.276 ms | 2.191 ms | 0.218 ms | 15\r\nMmBackward | 3.155 ms | 0.710 ms | 0.105 ms | 30\r\nTBackward | 0.265 ms | 0.152 ms | 0.009 ms | 30\r\nadd | 1.705 ms | 1.705 ms | 0.030 ms | 56\r\nN5torch8autograd14AccumulateGradE | 0.107 ms | 0.107 ms | 0.027 ms | 4\r\nexpand | 0.010 ms | 0.010 ms | 0.010 ms | 1\r\nzeros | 0.488 ms | 0.488 ms | 0.016 ms | 30\r\nput_ | 6.767 ms | 6.767 ms | 0.233 ms | 29\r\ntensor | 0.202 ms | 0.202 ms | 0.007 ms | 30\r\nsum | 0.869 ms | 0.869 ms | 0.029 ms | 30\r\nt | 0.557 ms | 0.557 ms | 0.005 ms | 104\r\nmm | 2.002 ms | 2.002 ms | 0.045 ms | 44\r\nTotals | 27.036 ms | 16.142 ms | 0.062 ms | 433\r\n\r\n\r\n\r\n### `index_select`\r\n\r\nName | Wall Duration | Self time | Average Duration | Occurrences\r\n-- | -- | -- | -- | --\r\nN5torch8autograd9GraphRootE | 0.002 ms | 0.002 ms | 0.002 ms | 1\r\nSumBackward0 | 0.013 ms | 0.004 ms | 0.013 ms | 1\r\nIndexSelectBackward | 1.164 ms | 0.226 ms | 0.040 ms | 29\r\nLSTMFusedBackward | 2.568 ms | 1.817 ms | 0.171 ms | 15\r\nMmBackward | 2.140 ms | 0.325 ms | 0.071 ms | 30\r\nTBackward | 0.330 ms | 0.215 ms | 0.011 ms | 30\r\nadd | 1.095 ms | 1.095 ms | 0.020 ms | 56\r\nN5torch8autograd14AccumulateGradE | 0.042 ms | 0.042 ms | 0.010 ms | 4\r\nexpand | 0.009 ms | 0.009 ms | 0.009 ms | 1\r\nzeros | 0.509 ms | 0.509 ms | 0.017 ms | 30\r\nindex_add_ | 0.443 ms | 0.443 ms | 0.015 ms | 29\r\ntensor | 0.209 ms | 0.209 ms | 0.007 ms | 30\r\nsum | 0.528 ms | 0.528 ms | 0.018 ms | 30\r\nt | 0.564 ms | 0.564 ms | 0.005 ms | 104\r\nmm | 1.366 ms | 1.366 ms | 0.031 ms | 44\r\nTotals | 10.982 ms | 7.353 ms | 0.025 ms | 434\r\n\r\nI'm not sure how accurate these profiling dumps are (since I'm not sure whether they measure kernel execution time correctly), but at least in terms of wall clock time it's definitely worthwhile. "}