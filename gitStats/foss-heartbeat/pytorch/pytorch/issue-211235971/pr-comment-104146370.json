{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104146370", "pull_request_review_id": 24965484, "id": 104146370, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNDE0NjM3MA==", "diff_hunk": "@@ -1332,50 +1333,58 @@ def compare_cpu_gpu(outputs_cpu, outputs_gpu):\n             # check grad weights separately, as nested dict\n             for cpu_layer_weight, gpu_layer_weight in zip(outputs_cpu['weights'], outputs_gpu['weights']):\n                 for (cpu_weight, gpu_weight) in zip(cpu_layer_weight, gpu_layer_weight):\n-                    self.assertEqual(cpu_weight.grad.data, gpu_weight.grad.data, prec=5e-5)\n+                    if cpu_weight is not None and gpu_weight is not None:\n+                        self.assertEqual(cpu_weight.grad.data, gpu_weight.grad.data, prec=5e-5)\n+                    else:\n+                        self.assertTrue(cpu_weight is None)\n+                        self.assertTrue(gpu_weight is None)\n \n         for module in (nn.RNN, nn.LSTM, nn.GRU):\n-            for bias, bidirectional, batch_first, contig, variable_len in product((True, False), repeat=5):\n+            for bias, bidirectional, batch_first, contig, skip_input, variable_len in product((True, False), repeat=6):\n                 num_directions = 2 if bidirectional else 1\n-                if batch_first:\n-                    input_val = torch.randn(batch, seq_length, input_size)\n-                    grad_output = torch.randn(batch, seq_length, hidden_size * num_directions)\n+                grad_output = torch.randn(seq_length, batch, hidden_size * num_directions)\n+                if skip_input:\n+                    input_val = torch.randn(seq_length, batch, hidden_size)", "path": "test/test_nn.py", "position": 31, "original_position": 30, "commit_id": "3cffe76bd63300da5ed3489df7135fad390d36ff", "original_commit_id": "cccdab6e069c194d3c69e239862a4e6445e49383", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Wouldn't it be simpler to add that at the top? It would simplify the code.\r\n```python\r\nif skip_input:\r\n    input_size = hidden_size\r\n```", "created_at": "2017-03-03T12:46:42Z", "updated_at": "2018-11-23T15:32:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/894#discussion_r104146370", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/894", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104146370"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/894#discussion_r104146370"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/894"}}, "body_html": "<p>Wouldn't it be simpler to add that at the top? It would simplify the code.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">if</span> skip_input:\n    input_size <span class=\"pl-k\">=</span> hidden_size</pre></div>", "body_text": "Wouldn't it be simpler to add that at the top? It would simplify the code.\nif skip_input:\n    input_size = hidden_size"}