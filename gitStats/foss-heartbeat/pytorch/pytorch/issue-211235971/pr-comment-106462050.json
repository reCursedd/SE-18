{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/106462050", "pull_request_review_id": 27385246, "id": 106462050, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNjQ2MjA1MA==", "diff_hunk": "@@ -8,19 +8,22 @@\n \n \n def RNNReLUCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n-    hy = F.relu(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))\n+    x_h = input if w_ih is None else F.linear(input, w_ih, b_ih)\n+    hy = F.relu(x_h + F.linear(hidden, w_hh, b_hh))\n     return hy\n \n \n def RNNTanhCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n-    hy = F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))\n+    x_h = input if w_ih is None else F.linear(input, w_ih, b_ih)\n+    hy = F.tanh(x_h + F.linear(hidden, w_hh, b_hh))\n     return hy\n \n \n def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None):\n     hx, cx = hidden\n-    gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)\n-    ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n+    x_h = input.unsqueeze(1).expand(input.size(0), 4, input.size(1)) if w_ih is None else F.linear(input, w_ih, b_ih)", "path": "torch/nn/_functions/rnn.py", "position": null, "original_position": 21, "commit_id": "3cffe76bd63300da5ed3489df7135fad390d36ff", "original_commit_id": "cccdab6e069c194d3c69e239862a4e6445e49383", "user": {"login": "justinchiu", "id": 2389353, "node_id": "MDQ6VXNlcjIzODkzNTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2389353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justinchiu", "html_url": "https://github.com/justinchiu", "followers_url": "https://api.github.com/users/justinchiu/followers", "following_url": "https://api.github.com/users/justinchiu/following{/other_user}", "gists_url": "https://api.github.com/users/justinchiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/justinchiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justinchiu/subscriptions", "organizations_url": "https://api.github.com/users/justinchiu/orgs", "repos_url": "https://api.github.com/users/justinchiu/repos", "events_url": "https://api.github.com/users/justinchiu/events{/privacy}", "received_events_url": "https://api.github.com/users/justinchiu/received_events", "type": "User", "site_admin": false}, "body": "the modern definition of lstm does indeed use different parameters for each linear projection in each gate. see section 4.6.1 of alex graves' [thesis](https://www.cs.toronto.edu/~graves/preprint.pdf), but that one's the extended lstm includes [peephole connections](ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf). although an older version did not have connections from the input vector to the gates at all (see figures [here](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709)), although i don't know of any modern code that uses gers' formulation as is. and fwiw the original formulation didn't have a [forget gate](http://www.bioinf.jku.at/publications/older/2604.pdf)...anyway this makes much more of a difference for the pytorch version than the cudnn API since the user will be *stacking* the cells and stacking will magnify this difference. i'm not sure how much of a difference there would be with a single layer cell, but that can be easily observed experimentally if someone is curious", "created_at": "2017-03-16T16:14:36Z", "updated_at": "2018-11-23T15:32:48Z", "html_url": "https://github.com/pytorch/pytorch/pull/894#discussion_r106462050", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/894", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/106462050"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/894#discussion_r106462050"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/894"}}, "body_html": "<p>the modern definition of lstm does indeed use different parameters for each linear projection in each gate. see section 4.6.1 of alex graves' <a href=\"https://www.cs.toronto.edu/~graves/preprint.pdf\" rel=\"nofollow\">thesis</a>, but that one's the extended lstm includes peephole connections. although an older version did not have connections from the input vector to the gates at all (see figures <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709\" rel=\"nofollow\">here</a>), although i don't know of any modern code that uses gers' formulation as is. and fwiw the original formulation didn't have a <a href=\"http://www.bioinf.jku.at/publications/older/2604.pdf\" rel=\"nofollow\">forget gate</a>...anyway this makes much more of a difference for the pytorch version than the cudnn API since the user will be <em>stacking</em> the cells and stacking will magnify this difference. i'm not sure how much of a difference there would be with a single layer cell, but that can be easily observed experimentally if someone is curious</p>", "body_text": "the modern definition of lstm does indeed use different parameters for each linear projection in each gate. see section 4.6.1 of alex graves' thesis, but that one's the extended lstm includes peephole connections. although an older version did not have connections from the input vector to the gates at all (see figures here), although i don't know of any modern code that uses gers' formulation as is. and fwiw the original formulation didn't have a forget gate...anyway this makes much more of a difference for the pytorch version than the cudnn API since the user will be stacking the cells and stacking will magnify this difference. i'm not sure how much of a difference there would be with a single layer cell, but that can be easily observed experimentally if someone is curious", "in_reply_to_id": 106094959}