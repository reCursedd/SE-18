{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1825", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1825/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1825/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1825/events", "html_url": "https://github.com/pytorch/pytorch/issues/1825", "id": 236496316, "node_id": "MDU6SXNzdWUyMzY0OTYzMTY=", "number": 1825, "title": "More general padding", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 424131850, "node_id": "MDU6TGFiZWw0MjQxMzE4NTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-06-16T14:17:25Z", "updated_at": "2017-09-18T18:49:34Z", "closed_at": "2017-09-18T18:49:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>It would be useful to have a padding function like numpy's pad. I think for PyTorch, what makes sense would be a <code>functional.constant_pad(value, [(dim_0_before, dim_0_after), (dim_1_before, dim_1_after), ...])</code>, where each tuple can also be a single element for before and after. Or, something like <code>F.constant_pad(value, (before, after), dim=x)</code>. I suggest we have separate functions for each type of padding (e.g. F.edge_pad, F.reflection_pad) instead of numpy's monolithic <a href=\"https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.pad.html\" rel=\"nofollow\">pad</a> function.</p>", "body_text": "It would be useful to have a padding function like numpy's pad. I think for PyTorch, what makes sense would be a functional.constant_pad(value, [(dim_0_before, dim_0_after), (dim_1_before, dim_1_after), ...]), where each tuple can also be a single element for before and after. Or, something like F.constant_pad(value, (before, after), dim=x). I suggest we have separate functions for each type of padding (e.g. F.edge_pad, F.reflection_pad) instead of numpy's monolithic pad function.", "body": "It would be useful to have a padding function like numpy's pad. I think for PyTorch, what makes sense would be a `functional.constant_pad(value, [(dim_0_before, dim_0_after), (dim_1_before, dim_1_after), ...])`, where each tuple can also be a single element for before and after. Or, something like `F.constant_pad(value, (before, after), dim=x)`. I suggest we have separate functions for each type of padding (e.g. F.edge_pad, F.reflection_pad) instead of numpy's monolithic [pad](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.pad.html) function."}