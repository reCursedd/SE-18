{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7620", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7620/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7620/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7620/events", "html_url": "https://github.com/pytorch/pytorch/issues/7620", "id": 323732172, "node_id": "MDU6SXNzdWUzMjM3MzIxNzI=", "number": 7620, "title": "[feature request] Update module parameters after __init__()", "user": {"login": "emilmelnikov", "id": 1649961, "node_id": "MDQ6VXNlcjE2NDk5NjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1649961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emilmelnikov", "html_url": "https://github.com/emilmelnikov", "followers_url": "https://api.github.com/users/emilmelnikov/followers", "following_url": "https://api.github.com/users/emilmelnikov/following{/other_user}", "gists_url": "https://api.github.com/users/emilmelnikov/gists{/gist_id}", "starred_url": "https://api.github.com/users/emilmelnikov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emilmelnikov/subscriptions", "organizations_url": "https://api.github.com/users/emilmelnikov/orgs", "repos_url": "https://api.github.com/users/emilmelnikov/repos", "events_url": "https://api.github.com/users/emilmelnikov/events{/privacy}", "received_events_url": "https://api.github.com/users/emilmelnikov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2018-05-16T18:17:49Z", "updated_at": "2018-05-25T21:12:49Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Currently, modules assign their parameters within constructors (see <a href=\"https://github.com/pytorch/pytorch/blob/c425d0350b9d4a4891eeb47c06ace1efb53da508/torch/nn/modules/linear.py#L41\">Linear</a> and <a href=\"https://github.com/pytorch/pytorch/blob/c425d0350b9d4a4891eeb47c06ace1efb53da508/torch/nn/modules/conv.py#L29\">_ConvNd</a> <code>__init__()</code> source). This makes <em>ad-hoc</em> patching of already created models not as flexible as it could be.</p>\n<p>As a motivating use case, one may want to adapt pre-packaged ResNet-18 for MNIST-like data. An intuitive solution would be the following:</p>\n<div class=\"highlight highlight-source-python\"><pre>model <span class=\"pl-k\">=</span> resnet18()\nmodel.conv1.in_channels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\nmodel.fc.out_features <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> New API: recreate contents of _parameters and _buffers</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> based on the modules' arguments supplied in __init__().</span>\nmodel.refresh_parameters()</pre></div>\n<p>It seems that the current solution is <a href=\"https://discuss.pytorch.org/t/how-to-modify-the-final-fc-layer-based-on-the-torch-model/766/3\" rel=\"nofollow\">to assign a fresh instance of the same module to it's parent</a>. However, one needs to pass all other module arguments. This gets especially tedious with convs (stride, kernel size, paddings etc.).</p>\n<p>Another solution is to add a <code>copy(arg1=foo, arg2=bar)</code> method to all modules that clones the module with the updated arguments <code>arg1</code> and <code>arg2</code>, set to <code>foo</code> and <code>bar</code>. This way, the example above would look like this:</p>\n<div class=\"highlight highlight-source-python\"><pre>model <span class=\"pl-k\">=</span> resnet18()\nmodel.conv1 <span class=\"pl-k\">=</span> model.conv1.copy(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\nmodel.fc.out_features <span class=\"pl-k\">=</span> model.fc.copy(<span class=\"pl-v\">out_features</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)</pre></div>", "body_text": "Currently, modules assign their parameters within constructors (see Linear and _ConvNd __init__() source). This makes ad-hoc patching of already created models not as flexible as it could be.\nAs a motivating use case, one may want to adapt pre-packaged ResNet-18 for MNIST-like data. An intuitive solution would be the following:\nmodel = resnet18()\nmodel.conv1.in_channels = 1\nmodel.fc.out_features = 10\n# New API: recreate contents of _parameters and _buffers\n# based on the modules' arguments supplied in __init__().\nmodel.refresh_parameters()\nIt seems that the current solution is to assign a fresh instance of the same module to it's parent. However, one needs to pass all other module arguments. This gets especially tedious with convs (stride, kernel size, paddings etc.).\nAnother solution is to add a copy(arg1=foo, arg2=bar) method to all modules that clones the module with the updated arguments arg1 and arg2, set to foo and bar. This way, the example above would look like this:\nmodel = resnet18()\nmodel.conv1 = model.conv1.copy(in_channels=1)\nmodel.fc.out_features = model.fc.copy(out_features=10)", "body": "Currently, modules assign their parameters within constructors (see [Linear](https://github.com/pytorch/pytorch/blob/c425d0350b9d4a4891eeb47c06ace1efb53da508/torch/nn/modules/linear.py#L41) and [_ConvNd](https://github.com/pytorch/pytorch/blob/c425d0350b9d4a4891eeb47c06ace1efb53da508/torch/nn/modules/conv.py#L29) `__init__()` source). This makes _ad-hoc_ patching of already created models not as flexible as it could be.\r\n\r\nAs a motivating use case, one may want to adapt pre-packaged ResNet-18 for MNIST-like data. An intuitive solution would be the following:\r\n```python\r\nmodel = resnet18()\r\nmodel.conv1.in_channels = 1\r\nmodel.fc.out_features = 10\r\n# New API: recreate contents of _parameters and _buffers\r\n# based on the modules' arguments supplied in __init__().\r\nmodel.refresh_parameters()\r\n```\r\n\r\nIt seems that the current solution is [to assign a fresh instance of the same module to it's parent](https://discuss.pytorch.org/t/how-to-modify-the-final-fc-layer-based-on-the-torch-model/766/3). However, one needs to pass all other module arguments. This gets especially tedious with convs (stride, kernel size, paddings etc.).\r\n\r\nAnother solution is to add a `copy(arg1=foo, arg2=bar)` method to all modules that clones the module with the updated arguments `arg1` and `arg2`, set to `foo` and `bar`. This way, the example above would look like this:\r\n```python\r\nmodel = resnet18()\r\nmodel.conv1 = model.conv1.copy(in_channels=1)\r\nmodel.fc.out_features = model.fc.copy(out_features=10)\r\n```"}