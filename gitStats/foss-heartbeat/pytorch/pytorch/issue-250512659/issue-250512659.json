{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2456", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2456/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2456/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2456/events", "html_url": "https://github.com/pytorch/pytorch/issues/2456", "id": 250512659, "node_id": "MDU6SXNzdWUyNTA1MTI2NTk=", "number": 2456, "title": "Adding Pixel Unshuffle", "user": {"login": "hinthornw", "id": 13333726, "node_id": "MDQ6VXNlcjEzMzMzNzI2", "avatar_url": "https://avatars2.githubusercontent.com/u/13333726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hinthornw", "html_url": "https://github.com/hinthornw", "followers_url": "https://api.github.com/users/hinthornw/followers", "following_url": "https://api.github.com/users/hinthornw/following{/other_user}", "gists_url": "https://api.github.com/users/hinthornw/gists{/gist_id}", "starred_url": "https://api.github.com/users/hinthornw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hinthornw/subscriptions", "organizations_url": "https://api.github.com/users/hinthornw/orgs", "repos_url": "https://api.github.com/users/hinthornw/repos", "events_url": "https://api.github.com/users/hinthornw/events{/privacy}", "received_events_url": "https://api.github.com/users/hinthornw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-08-16T05:09:55Z", "updated_at": "2017-08-31T17:07:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I would like to propose the addition of an inverse operation for the current PixelShuffle function. We have been researching temporally connected feature cascades and have had a lot of success in hierarchically mixing residual information through this function.</p>\n<p>The core operation is essentially the following:<br>\nFor feature map <em>fm</em> with  batchsize <em>b</em>, channels <em>c</em>, downsize ratio of <em>r</em>, and original height and width of <em>h,w</em>, do:</p>\n<pre><code>out_channel = c*(r**2)\nout_h = h//r\nout_w = w//r\nfm_view = fm.contiguous().view(b, c, out_h, r, out_w, r)\nfm_prime = fm_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\n</code></pre>", "body_text": "I would like to propose the addition of an inverse operation for the current PixelShuffle function. We have been researching temporally connected feature cascades and have had a lot of success in hierarchically mixing residual information through this function.\nThe core operation is essentially the following:\nFor feature map fm with  batchsize b, channels c, downsize ratio of r, and original height and width of h,w, do:\nout_channel = c*(r**2)\nout_h = h//r\nout_w = w//r\nfm_view = fm.contiguous().view(b, c, out_h, r, out_w, r)\nfm_prime = fm_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)", "body": "I would like to propose the addition of an inverse operation for the current PixelShuffle function. We have been researching temporally connected feature cascades and have had a lot of success in hierarchically mixing residual information through this function. \r\n\r\nThe core operation is essentially the following:\r\nFor feature map _fm_ with  batchsize _b_, channels _c_, downsize ratio of _r_, and original height and width of _h,w_, do:\r\n\r\n```\r\nout_channel = c*(r**2)\r\nout_h = h//r\r\nout_w = w//r\r\nfm_view = fm.contiguous().view(b, c, out_h, r, out_w, r)\r\nfm_prime = fm_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\r\n```\r\n\r\n"}