{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/310709975", "html_url": "https://github.com/pytorch/pytorch/pull/1884#issuecomment-310709975", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1884", "id": 310709975, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDcwOTk3NQ==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-23T16:20:38Z", "updated_at": "2017-06-23T16:20:38Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The problem with indexCopy is the output and gradient are undefined in the presence of repeated indices.  The docs are incorrect, they say that indices is \"index (LongTensor) \u2013 Indices to select from tensor\", but it's actually indices to copy to the underlying tensor, so with repeated indices its undefined who \"wins\".</p>\n<p>Here's an example with cuda:</p>\n<pre><code>&gt;&gt;&gt; torch.zeros(1000,1000).cuda().index_copy_(0, torch.zeros(1000).long().cuda(), torch.arange(1,1001).expand(1000,1000).t().cuda())\n\n  987   987   987  ...    984   984   984\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n       ...          \u22f1          ...\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n[torch.cuda.FloatTensor of size 1000x1000 (GPU 0)]\n</code></pre>", "body_text": "The problem with indexCopy is the output and gradient are undefined in the presence of repeated indices.  The docs are incorrect, they say that indices is \"index (LongTensor) \u2013 Indices to select from tensor\", but it's actually indices to copy to the underlying tensor, so with repeated indices its undefined who \"wins\".\nHere's an example with cuda:\n>>> torch.zeros(1000,1000).cuda().index_copy_(0, torch.zeros(1000).long().cuda(), torch.arange(1,1001).expand(1000,1000).t().cuda())\n\n  987   987   987  ...    984   984   984\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n       ...          \u22f1          ...\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n[torch.cuda.FloatTensor of size 1000x1000 (GPU 0)]", "body": "The problem with indexCopy is the output and gradient are undefined in the presence of repeated indices.  The docs are incorrect, they say that indices is \"index (LongTensor) \u2013 Indices to select from tensor\", but it's actually indices to copy to the underlying tensor, so with repeated indices its undefined who \"wins\".\r\n\r\nHere's an example with cuda:\r\n```\r\n>>> torch.zeros(1000,1000).cuda().index_copy_(0, torch.zeros(1000).long().cuda(), torch.arange(1,1001).expand(1000,1000).t().cuda())\r\n\r\n  987   987   987  ...    984   984   984\r\n    0     0     0  ...      0     0     0\r\n    0     0     0  ...      0     0     0\r\n       ...          \u22f1          ...\r\n    0     0     0  ...      0     0     0\r\n    0     0     0  ...      0     0     0\r\n    0     0     0  ...      0     0     0\r\n[torch.cuda.FloatTensor of size 1000x1000 (GPU 0)]\r\n```"}