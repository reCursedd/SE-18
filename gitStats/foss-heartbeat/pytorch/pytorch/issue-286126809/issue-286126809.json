{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4485", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4485/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4485/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4485/events", "html_url": "https://github.com/pytorch/pytorch/issues/4485", "id": 286126809, "node_id": "MDU6SXNzdWUyODYxMjY4MDk=", "number": 4485, "title": "DataParallel multi-gpu results do not match", "user": {"login": "taoari", "id": 3815006, "node_id": "MDQ6VXNlcjM4MTUwMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3815006?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taoari", "html_url": "https://github.com/taoari", "followers_url": "https://api.github.com/users/taoari/followers", "following_url": "https://api.github.com/users/taoari/following{/other_user}", "gists_url": "https://api.github.com/users/taoari/gists{/gist_id}", "starred_url": "https://api.github.com/users/taoari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taoari/subscriptions", "organizations_url": "https://api.github.com/users/taoari/orgs", "repos_url": "https://api.github.com/users/taoari/repos", "events_url": "https://api.github.com/users/taoari/events{/privacy}", "received_events_url": "https://api.github.com/users/taoari/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-04T22:02:36Z", "updated_at": "2018-01-04T22:07:16Z", "closed_at": "2018-01-04T22:07:16Z", "author_association": "NONE", "body_html": "<p>I am using the following scripts for multi-gpu computation using DataParallel:</p>\n<pre><code>def test():\n    \n    import torch\n    from torchvision import models\n    \n    batch = torch.autograd.Variable(torch.randn(6,3,224,224))\n    \n    model = models.resnet18(pretrained=True)\n    o1 = model(batch)\n\n    model = model.cuda()\n    o2 = model(batch.cuda())\n\n    import os\n    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n    model = torch.nn.DataParallel(model).cuda()\n    o3 = model(batch)\n    \n    import pdb; pdb.set_trace()\n    \nif __name__ == '__main__':\n    test()\n</code></pre>\n<p>The following is the output:</p>\n<pre><code>(Pdb) torch.__version__\n'0.3.0.post4'\n(Pdb) o1\nVariable containing:\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\n-2.6826 -0.6701 -0.5888  ...  -3.9985  1.1498  3.6315\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\n[torch.FloatTensor of size 6x1000]\n\n(Pdb) o2\nVariable containing:\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\n-2.6826 -0.6701 -0.5888  ...  -3.9986  1.1498  3.6315\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\n\n(Pdb) o3\nVariable containing:\n-1.3811 -0.7372  0.4853  ...  -0.5347  1.1808  1.8929\n 0.3251 -0.0499 -1.6649  ...  -0.3541  1.3475  0.0513\n 1.5659 -0.3755 -0.8420  ...   1.0978  2.3086 -0.6993\n-2.5921 -0.5145 -0.2801  ...  -2.1578  0.1405  2.5621\n-2.2629 -3.0985 -2.3914  ...  -1.6628  0.5047  0.1904\n 1.0781  2.1415  1.3389  ...   0.6119  2.1085  1.6552\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\n\n</code></pre>\n<p>The CPU (o1) computation matches the GPU (o2) computation. But why they do not match with multi-GPU (o3) computation?</p>", "body_text": "I am using the following scripts for multi-gpu computation using DataParallel:\ndef test():\n    \n    import torch\n    from torchvision import models\n    \n    batch = torch.autograd.Variable(torch.randn(6,3,224,224))\n    \n    model = models.resnet18(pretrained=True)\n    o1 = model(batch)\n\n    model = model.cuda()\n    o2 = model(batch.cuda())\n\n    import os\n    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n    model = torch.nn.DataParallel(model).cuda()\n    o3 = model(batch)\n    \n    import pdb; pdb.set_trace()\n    \nif __name__ == '__main__':\n    test()\n\nThe following is the output:\n(Pdb) torch.__version__\n'0.3.0.post4'\n(Pdb) o1\nVariable containing:\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\n-2.6826 -0.6701 -0.5888  ...  -3.9985  1.1498  3.6315\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\n[torch.FloatTensor of size 6x1000]\n\n(Pdb) o2\nVariable containing:\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\n-2.6826 -0.6701 -0.5888  ...  -3.9986  1.1498  3.6315\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\n\n(Pdb) o3\nVariable containing:\n-1.3811 -0.7372  0.4853  ...  -0.5347  1.1808  1.8929\n 0.3251 -0.0499 -1.6649  ...  -0.3541  1.3475  0.0513\n 1.5659 -0.3755 -0.8420  ...   1.0978  2.3086 -0.6993\n-2.5921 -0.5145 -0.2801  ...  -2.1578  0.1405  2.5621\n-2.2629 -3.0985 -2.3914  ...  -1.6628  0.5047  0.1904\n 1.0781  2.1415  1.3389  ...   0.6119  2.1085  1.6552\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\n\n\nThe CPU (o1) computation matches the GPU (o2) computation. But why they do not match with multi-GPU (o3) computation?", "body": "I am using the following scripts for multi-gpu computation using DataParallel:\r\n\r\n```\r\ndef test():\r\n    \r\n    import torch\r\n    from torchvision import models\r\n    \r\n    batch = torch.autograd.Variable(torch.randn(6,3,224,224))\r\n    \r\n    model = models.resnet18(pretrained=True)\r\n    o1 = model(batch)\r\n\r\n    model = model.cuda()\r\n    o2 = model(batch.cuda())\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\r\n    model = torch.nn.DataParallel(model).cuda()\r\n    o3 = model(batch)\r\n    \r\n    import pdb; pdb.set_trace()\r\n    \r\nif __name__ == '__main__':\r\n    test()\r\n```\r\n\r\nThe following is the output:\r\n\r\n```\r\n(Pdb) torch.__version__\r\n'0.3.0.post4'\r\n(Pdb) o1\r\nVariable containing:\r\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\r\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\r\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\r\n-2.6826 -0.6701 -0.5888  ...  -3.9985  1.1498  3.6315\r\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\r\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\r\n[torch.FloatTensor of size 6x1000]\r\n\r\n(Pdb) o2\r\nVariable containing:\r\n-2.7182 -1.4132 -0.1689  ...  -1.1170  0.9581  2.5264\r\n-0.2388 -1.9526 -1.3678  ...  -1.6317  2.4153  0.3164\r\n 0.4897 -0.4494 -1.2956  ...   1.2032  2.2951 -0.2223\r\n-2.6826 -0.6701 -0.5888  ...  -3.9986  1.1498  3.6315\r\n-0.9542 -1.9719 -1.5599  ...   0.7898 -0.4098 -1.1841\r\n 2.4871  3.4515  1.5563  ...   1.9212  1.0710  0.1708\r\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\r\n\r\n(Pdb) o3\r\nVariable containing:\r\n-1.3811 -0.7372  0.4853  ...  -0.5347  1.1808  1.8929\r\n 0.3251 -0.0499 -1.6649  ...  -0.3541  1.3475  0.0513\r\n 1.5659 -0.3755 -0.8420  ...   1.0978  2.3086 -0.6993\r\n-2.5921 -0.5145 -0.2801  ...  -2.1578  0.1405  2.5621\r\n-2.2629 -3.0985 -2.3914  ...  -1.6628  0.5047  0.1904\r\n 1.0781  2.1415  1.3389  ...   0.6119  2.1085  1.6552\r\n[torch.cuda.FloatTensor of size 6x1000 (GPU 0)]\r\n\r\n```\r\n\r\nThe CPU (o1) computation matches the GPU (o2) computation. But why they do not match with multi-GPU (o3) computation?"}