{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/345875409", "html_url": "https://github.com/pytorch/pytorch/issues/229#issuecomment-345875409", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/229", "id": 345875409, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTg3NTQwOQ==", "user": {"login": "wassname", "id": 1103714, "node_id": "MDQ6VXNlcjExMDM3MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1103714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wassname", "html_url": "https://github.com/wassname", "followers_url": "https://api.github.com/users/wassname/followers", "following_url": "https://api.github.com/users/wassname/following{/other_user}", "gists_url": "https://api.github.com/users/wassname/gists{/gist_id}", "starred_url": "https://api.github.com/users/wassname/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wassname/subscriptions", "organizations_url": "https://api.github.com/users/wassname/orgs", "repos_url": "https://api.github.com/users/wassname/repos", "events_url": "https://api.github.com/users/wassname/events{/privacy}", "received_events_url": "https://api.github.com/users/wassname/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-21T00:22:10Z", "updated_at": "2017-11-21T00:22:10Z", "author_association": "NONE", "body_html": "<p>Here's <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7605917\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dmarnerides\">@dmarnerides</a> code but with cuda support</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> https://github.com/pytorch/pytorch/issues/229</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">flip</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">dim</span>):\n    dim <span class=\"pl-k\">=</span> x.dim() <span class=\"pl-k\">+</span> dim <span class=\"pl-k\">if</span> dim <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">0</span> <span class=\"pl-k\">else</span> dim\n    inds <span class=\"pl-k\">=</span> <span class=\"pl-c1\">tuple</span>(<span class=\"pl-c1\">slice</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">None</span>) <span class=\"pl-k\">if</span> i <span class=\"pl-k\">!=</span> dim\n             <span class=\"pl-k\">else</span> x.new(torch.arange(x.size(i)<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>).tolist()).long()\n             <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(x.dim()))\n    <span class=\"pl-k\">return</span> x[inds]\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Code to test it with cpu</span>\na <span class=\"pl-k\">=</span> torch.Tensor([<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">25</span>)]).view(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>)\n<span class=\"pl-c1\">print</span>(a)\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">0</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -4</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">1</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -3</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">2</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -2</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">3</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -1</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Code to test it with cuda</span>\na <span class=\"pl-k\">=</span> torch.Tensor([<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">25</span>)]).view(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>).cuda()\n<span class=\"pl-c1\">print</span>(a)\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">0</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -4</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">1</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -3</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">2</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -2</span>\n<span class=\"pl-c1\">print</span>(flip(a, <span class=\"pl-c1\">3</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Or -1</span></pre></div>", "body_text": "Here's @dmarnerides code but with cuda support\n# https://github.com/pytorch/pytorch/issues/229\ndef flip(x, dim):\n    dim = x.dim() + dim if dim < 0 else dim\n    inds = tuple(slice(None, None) if i != dim\n             else x.new(torch.arange(x.size(i)-1, -1, -1).tolist()).long()\n             for i in range(x.dim()))\n    return x[inds]\n\n# Code to test it with cpu\na = torch.Tensor([range(1, 25)]).view(1, 2, 3, 4)\nprint(a)\nprint(flip(a, 0)) # Or -4\nprint(flip(a, 1)) # Or -3\nprint(flip(a, 2)) # Or -2\nprint(flip(a, 3)) # Or -1\n\n# Code to test it with cuda\na = torch.Tensor([range(1, 25)]).view(1, 2, 3, 4).cuda()\nprint(a)\nprint(flip(a, 0)) # Or -4\nprint(flip(a, 1)) # Or -3\nprint(flip(a, 2)) # Or -2\nprint(flip(a, 3)) # Or -1", "body": "Here's @dmarnerides code but with cuda support\r\n\r\n```py\r\n# https://github.com/pytorch/pytorch/issues/229\r\ndef flip(x, dim):\r\n    dim = x.dim() + dim if dim < 0 else dim\r\n    inds = tuple(slice(None, None) if i != dim\r\n             else x.new(torch.arange(x.size(i)-1, -1, -1).tolist()).long()\r\n             for i in range(x.dim()))\r\n    return x[inds]\r\n\r\n# Code to test it with cpu\r\na = torch.Tensor([range(1, 25)]).view(1, 2, 3, 4)\r\nprint(a)\r\nprint(flip(a, 0)) # Or -4\r\nprint(flip(a, 1)) # Or -3\r\nprint(flip(a, 2)) # Or -2\r\nprint(flip(a, 3)) # Or -1\r\n\r\n# Code to test it with cuda\r\na = torch.Tensor([range(1, 25)]).view(1, 2, 3, 4).cuda()\r\nprint(a)\r\nprint(flip(a, 0)) # Or -4\r\nprint(flip(a, 1)) # Or -3\r\nprint(flip(a, 2)) # Or -2\r\nprint(flip(a, 3)) # Or -1\r\n```"}