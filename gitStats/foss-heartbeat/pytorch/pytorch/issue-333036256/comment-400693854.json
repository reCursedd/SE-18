{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/400693854", "html_url": "https://github.com/pytorch/pytorch/pull/8586#issuecomment-400693854", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8586", "id": 400693854, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDY5Mzg1NA==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-27T14:31:26Z", "updated_at": "2018-06-27T14:31:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20787943\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/t-vi\">@t-vi</a> . Let's just fail when <code>eigenvector = false</code> now.</p>\n<p>One can work around this by make <code>symeig</code> always compute <code>eigenvector</code> and expose a wrapper function to Python. But that is inefficient when users don't want gradients.</p>\n<p>We should have a way to specify grad mode on vs. off forward. I'll post an issue on that. But for this PR, let's just make it an error.</p>", "body_text": "I agree with @t-vi . Let's just fail when eigenvector = false now.\nOne can work around this by make symeig always compute eigenvector and expose a wrapper function to Python. But that is inefficient when users don't want gradients.\nWe should have a way to specify grad mode on vs. off forward. I'll post an issue on that. But for this PR, let's just make it an error.", "body": "I agree with @t-vi . Let's just fail when `eigenvector = false` now. \r\n\r\nOne can work around this by make `symeig` always compute `eigenvector` and expose a wrapper function to Python. But that is inefficient when users don't want gradients.\r\n\r\nWe should have a way to specify grad mode on vs. off forward. I'll post an issue on that. But for this PR, let's just make it an error. "}