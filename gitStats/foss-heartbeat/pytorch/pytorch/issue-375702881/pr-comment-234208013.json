{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234208013", "pull_request_review_id": 175806296, "id": 234208013, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDIwODAxMw==", "diff_hunk": "@@ -1003,72 +1003,53 @@ def softmax(input, dim=None, _stacklevel=3, dtype=None):\n         return input.softmax(dim, dtype=dtype)\n \n \n-def _sample_gumbel(shape, eps=1e-10, out=None):\n-    \"\"\"\n-    Sample from Gumbel(0, 1)\n-\n-    based on\n-    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n-    (MIT license)\n-    \"\"\"\n-    U = out.resize_(shape).uniform_() if out is not None else torch.rand(shape)\n-    return - torch.log(eps - torch.log(U + eps))\n-\n-\n-def _gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n-    \"\"\"\n-    Draw a sample from the Gumbel-Softmax distribution\n-\n-    based on\n-    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n-    (MIT license)\n-    \"\"\"\n-    dims = logits.dim()\n-    gumbel_noise = _sample_gumbel(logits.size(), eps=eps, out=logits.data.new())\n-    y = logits + gumbel_noise\n-    return softmax(y / tau, dims - 1)\n-\n-\n-def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n+def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n     r\"\"\"\n-    Sample from the Gumbel-Softmax distribution and optionally discretize.\n+    Samples from the `Gumbel-Softmax distribution`_ and optionally discretizes.\n \n     Args:\n-      logits: `[batch_size, num_features]` unnormalized log probabilities\n+      logits: `[..., num_features]` unnormalized log probabilities\n       tau: non-negative scalar temperature\n       hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n             but will be differentiated as if it is the soft sample in autograd\n+      eps: Deprecated parameter to avoid log(0). Now handled elsewhere.\n+      dim (int): A dimension along which softmax will be computed.", "path": "torch/nn/functional.py", "position": null, "original_position": 43, "commit_id": "87d85b5147da20e0fc72d7442b4b2e62b1b647aa", "original_commit_id": "96a29e1b9c41d9b0387e339af11e4b9f29e7192e", "user": {"login": "ragulpr", "id": 10998266, "node_id": "MDQ6VXNlcjEwOTk4MjY2", "avatar_url": "https://avatars3.githubusercontent.com/u/10998266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ragulpr", "html_url": "https://github.com/ragulpr", "followers_url": "https://api.github.com/users/ragulpr/followers", "following_url": "https://api.github.com/users/ragulpr/following{/other_user}", "gists_url": "https://api.github.com/users/ragulpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/ragulpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ragulpr/subscriptions", "organizations_url": "https://api.github.com/users/ragulpr/orgs", "repos_url": "https://api.github.com/users/ragulpr/repos", "events_url": "https://api.github.com/users/ragulpr/events{/privacy}", "received_events_url": "https://api.github.com/users/ragulpr/received_events", "type": "User", "site_admin": false}, "body": "Fixed with a02c8b9 ", "created_at": "2018-11-16T13:46:59Z", "updated_at": "2018-11-23T15:55:00Z", "html_url": "https://github.com/pytorch/pytorch/pull/13339#discussion_r234208013", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13339", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234208013"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13339#discussion_r234208013"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13339"}}, "body_html": "<p>Fixed with <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/a02c8b9d1bf6cfff39146fa7c52c0ef892ab9a15/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/a02c8b9d1bf6cfff39146fa7c52c0ef892ab9a15\"><tt>a02c8b9</tt></a></p>", "body_text": "Fixed with a02c8b9", "in_reply_to_id": 234054526}