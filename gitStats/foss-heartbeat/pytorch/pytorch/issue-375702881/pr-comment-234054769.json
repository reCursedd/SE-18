{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234054769", "pull_request_review_id": 175614892, "id": 234054769, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDA1NDc2OQ==", "diff_hunk": "@@ -1003,72 +1003,53 @@ def softmax(input, dim=None, _stacklevel=3, dtype=None):\n         return input.softmax(dim, dtype=dtype)\n \n \n-def _sample_gumbel(shape, eps=1e-10, out=None):\n-    \"\"\"\n-    Sample from Gumbel(0, 1)\n-\n-    based on\n-    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n-    (MIT license)\n-    \"\"\"\n-    U = out.resize_(shape).uniform_() if out is not None else torch.rand(shape)\n-    return - torch.log(eps - torch.log(U + eps))\n-\n-\n-def _gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n-    \"\"\"\n-    Draw a sample from the Gumbel-Softmax distribution\n-\n-    based on\n-    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n-    (MIT license)\n-    \"\"\"\n-    dims = logits.dim()\n-    gumbel_noise = _sample_gumbel(logits.size(), eps=eps, out=logits.data.new())\n-    y = logits + gumbel_noise\n-    return softmax(y / tau, dims - 1)\n-\n-\n-def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n+def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n     r\"\"\"\n-    Sample from the Gumbel-Softmax distribution and optionally discretize.\n+    Samples from the `Gumbel-Softmax distribution`_ and optionally discretizes.\n \n     Args:\n-      logits: `[batch_size, num_features]` unnormalized log probabilities\n+      logits: `[..., num_features]` unnormalized log probabilities\n       tau: non-negative scalar temperature\n       hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n             but will be differentiated as if it is the soft sample in autograd\n+      eps: Deprecated parameter to avoid log(0). Now handled elsewhere.\n+      dim (int): A dimension along which softmax will be computed.\n \n     Returns:\n-      Sampled tensor of shape ``batch_size x num_features`` from the Gumbel-Softmax distribution.\n+      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n       If ``hard=True``, the returned samples will be one-hot, otherwise they will\n-      be probability distributions that sum to 1 across features\n+      be probability distributions that sum to 1 across `dim`.\n \n-    Constraints:\n+    .. note::\n+      This function is here for legacy reasons, may be removed from nn.Functional in the future.\n \n-    - Currently only work on 2D input :attr:`logits` tensor of shape ``batch_size x num_features``\n+    Examples::\n+        >>> logits = torch.randn(20, 32)\n+        >>> # Sample soft categorical using reparametrization trick:\n+        >>> F.gumbel_softmax(logits, tau=1, hard=False)\n+        >>> # Sample hard categorical using \"Straight-through\" trick:\n+        >>> F.gumbel_softmax(logits, tau=1, hard=True)\n \n-    Based on\n-    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n-    (MIT license)\n+    .. _Gumbel-Softmax distribution:\n+        https://arxiv.org/abs/1611.00712\n+        https://arxiv.org/abs/1611.01144\n     \"\"\"\n-    shape = logits.size()\n-    assert len(shape) == 2\n-    y_soft = _gumbel_softmax_sample(logits, tau=tau, eps=eps)\n+\n+    if eps != 1e-10:\n+        warnings.warn(\"`eps` parameter is deprecated.\", DeprecationWarning)\n+\n+    y_soft = logits.new(logits.shape)\n+    y_soft = (logits - y_soft.exponential_().log()) / tau  # Gumbel noise\n+    y_soft = y_soft.softmax(dim)  # Gumbel softmax noise\n+\n     if hard:\n-        _, k = y_soft.max(-1)\n-        # this bit is based on\n-        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n-        y_hard = logits.new_zeros(*shape).scatter_(-1, k.view(-1, 1), 1.0)\n-        # this cool bit of code achieves two things:\n-        # - makes the output value exactly one-hot (since we add then\n-        #   subtract y_soft value)\n-        # - makes the gradient equal to y_soft gradient (since we strip\n-        #   all other gradients)\n-        y = y_hard - y_soft.detach() + y_soft\n+        # Straight through.\n+        index = y_soft.max(dim, keepdim=True)[1]\n+        y_hard = logits.new_zeros(logits.shape).scatter_(dim, index, 1.0)\n+        return y_hard - y_soft.detach() + y_soft", "path": "torch/nn/functional.py", "position": 113, "original_position": 96, "commit_id": "87d85b5147da20e0fc72d7442b4b2e62b1b647aa", "original_commit_id": "96a29e1b9c41d9b0387e339af11e4b9f29e7192e", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Aw, I liked the old comment ;)", "created_at": "2018-11-16T00:18:40Z", "updated_at": "2018-11-23T15:54:58Z", "html_url": "https://github.com/pytorch/pytorch/pull/13339#discussion_r234054769", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13339", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234054769"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13339#discussion_r234054769"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13339"}}, "body_html": "<p>Aw, I liked the old comment ;)</p>", "body_text": "Aw, I liked the old comment ;)"}