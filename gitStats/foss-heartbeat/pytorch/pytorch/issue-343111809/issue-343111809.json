{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9624", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9624/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9624/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9624/events", "html_url": "https://github.com/pytorch/pytorch/issues/9624", "id": 343111809, "node_id": "MDU6SXNzdWUzNDMxMTE4MDk=", "number": 9624, "title": "Pycuda interoperability", "user": {"login": "themightyoarfish", "id": 11613312, "node_id": "MDQ6VXNlcjExNjEzMzEy", "avatar_url": "https://avatars0.githubusercontent.com/u/11613312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/themightyoarfish", "html_url": "https://github.com/themightyoarfish", "followers_url": "https://api.github.com/users/themightyoarfish/followers", "following_url": "https://api.github.com/users/themightyoarfish/following{/other_user}", "gists_url": "https://api.github.com/users/themightyoarfish/gists{/gist_id}", "starred_url": "https://api.github.com/users/themightyoarfish/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/themightyoarfish/subscriptions", "organizations_url": "https://api.github.com/users/themightyoarfish/orgs", "repos_url": "https://api.github.com/users/themightyoarfish/repos", "events_url": "https://api.github.com/users/themightyoarfish/events{/privacy}", "received_events_url": "https://api.github.com/users/themightyoarfish/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-20T13:40:42Z", "updated_at": "2018-09-06T16:14:53Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>For doing computations on tensors with <code>pycuda</code>, I can do this<br>\nfor going from <code>Tensor</code> to <code>pycuda.gpuarray.GPUArray</code>:</p>\n<pre><code>def tensor_to_gpuarray(tensor):\n    if not tensor.is_cuda:\n         raise ValueError('Cannot convert CPU tensor to GPUArray (call `cuda()` on it)')\n     else:\n         return GPUArray(tensor.shape, dtype=torch_dtype_to_numpy(tensor.dtype), gpudata=tensor.data_ptr())\n</code></pre>\n<p>however, I'm stumped on how to convert back to a Tensor without copying the data. How can this be done?</p>", "body_text": "For doing computations on tensors with pycuda, I can do this\nfor going from Tensor to pycuda.gpuarray.GPUArray:\ndef tensor_to_gpuarray(tensor):\n    if not tensor.is_cuda:\n         raise ValueError('Cannot convert CPU tensor to GPUArray (call `cuda()` on it)')\n     else:\n         return GPUArray(tensor.shape, dtype=torch_dtype_to_numpy(tensor.dtype), gpudata=tensor.data_ptr())\n\nhowever, I'm stumped on how to convert back to a Tensor without copying the data. How can this be done?", "body": "For doing computations on tensors with `pycuda`, I can do this\r\nfor going from `Tensor` to `pycuda.gpuarray.GPUArray`:\r\n```\r\ndef tensor_to_gpuarray(tensor):\r\n    if not tensor.is_cuda:\r\n         raise ValueError('Cannot convert CPU tensor to GPUArray (call `cuda()` on it)')\r\n     else:\r\n         return GPUArray(tensor.shape, dtype=torch_dtype_to_numpy(tensor.dtype), gpudata=tensor.data_ptr())\r\n```\r\nhowever, I'm stumped on how to convert back to a Tensor without copying the data. How can this be done?"}