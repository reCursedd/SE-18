{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/307622399", "html_url": "https://github.com/pytorch/pytorch/issues/1773#issuecomment-307622399", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1773", "id": 307622399, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYyMjM5OQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-11T11:07:12Z", "updated_at": "2017-06-11T11:07:12Z", "author_association": "MEMBER", "body_html": "<p>Could you provide a minimum reproducible code example?<br>\nThe only way I see that this could happen is if your target (or second) tensor is 1D, so when you index it (in the dataset, <code>C[0]</code>) it returns a python <code>float</code> (which is double), and thus the <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L103\">created tensor is a double</a>.</p>\n<p>I see no way of fixing it in pytorch except if we introduce scalar types, and indexing returns a scalar instead of a python number.</p>\n<p>For your problem, an easy solution is to return numpy arrays instead of torch tensors. This will be less efficient on multi-threaded setups (and can lead to errors for very large arrays), but should fix your case.</p>", "body_text": "Could you provide a minimum reproducible code example?\nThe only way I see that this could happen is if your target (or second) tensor is 1D, so when you index it (in the dataset, C[0]) it returns a python float (which is double), and thus the created tensor is a double.\nI see no way of fixing it in pytorch except if we introduce scalar types, and indexing returns a scalar instead of a python number.\nFor your problem, an easy solution is to return numpy arrays instead of torch tensors. This will be less efficient on multi-threaded setups (and can lead to errors for very large arrays), but should fix your case.", "body": "Could you provide a minimum reproducible code example?\r\nThe only way I see that this could happen is if your target (or second) tensor is 1D, so when you index it (in the dataset, `C[0]`) it returns a python `float` (which is double), and thus the [created tensor is a double](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L103).\r\n\r\nI see no way of fixing it in pytorch except if we introduce scalar types, and indexing returns a scalar instead of a python number.\r\n\r\nFor your problem, an easy solution is to return numpy arrays instead of torch tensors. This will be less efficient on multi-threaded setups (and can lead to errors for very large arrays), but should fix your case."}