{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2752", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2752/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2752/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2752/events", "html_url": "https://github.com/pytorch/pytorch/issues/2752", "id": 258165665, "node_id": "MDU6SXNzdWUyNTgxNjU2NjU=", "number": 2752, "title": "ONNX Padding Issue", "user": {"login": "colincsl", "id": 498232, "node_id": "MDQ6VXNlcjQ5ODIzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/498232?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colincsl", "html_url": "https://github.com/colincsl", "followers_url": "https://api.github.com/users/colincsl/followers", "following_url": "https://api.github.com/users/colincsl/following{/other_user}", "gists_url": "https://api.github.com/users/colincsl/gists{/gist_id}", "starred_url": "https://api.github.com/users/colincsl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colincsl/subscriptions", "organizations_url": "https://api.github.com/users/colincsl/orgs", "repos_url": "https://api.github.com/users/colincsl/repos", "events_url": "https://api.github.com/users/colincsl/events{/privacy}", "received_events_url": "https://api.github.com/users/colincsl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-15T21:10:43Z", "updated_at": "2017-10-11T18:10:23Z", "closed_at": "2017-10-11T18:10:23Z", "author_association": "NONE", "body_html": "<p>It looks like there is an issue converting pyTorch models with Reflection (or Replication) padding. If you try using torch.onnx.export with ReflectionPad2d you get an error like the one below.</p>\n<p>I think the issue is similar to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"257858911\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2742\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2742/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2742\">#2742</a>. In that case there was an issue because pooling parameters could be specified as scalars or tuples and thus they weren't being converted correctly. The same thing applies for padding. I'm not sure which file to look through to fix this.</p>\n<pre><code>Error occured while handling:\n%81 : Float(3, 32, 1026, 1), %82 : Handle = ^ReflectionPad2d(0, 0, 1, 1)(%79), uses = [[%83.i0], []];\n\nExported graph so far:\ngraph(%1 : Float(44, 128, 1, 1)\n      %2 : Float(44)\n      %3 : Float(128, 32, 3, 1)\n      %4 : Float(128)\n      %5 : Float(128, 32, 5, 1)\n      %6 : Float(128)\n\n....\n\n      %79 : Float(3, 32, 1024, 1)) {\n  return ();\n}\n\nTraceback (most recent call last):\n  File \"convert_to_caffe2.py\", line 66, in &lt;module&gt;\n    torch_out = torch.onnx.export(torch_model, x, \"test.onnx\", verbose=True)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 37, in export\n    _export(model, args, f, export_params, kwargs, verbose)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 51, in _export\n    proto = trace.export(list(model.state_dict().values()), verbose)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 133, in symbolic\n    return symbolic_fn(*args, **kwargs)\nTypeError: 'NoneType' object is not callable\n\n</code></pre>", "body_text": "It looks like there is an issue converting pyTorch models with Reflection (or Replication) padding. If you try using torch.onnx.export with ReflectionPad2d you get an error like the one below.\nI think the issue is similar to #2742. In that case there was an issue because pooling parameters could be specified as scalars or tuples and thus they weren't being converted correctly. The same thing applies for padding. I'm not sure which file to look through to fix this.\nError occured while handling:\n%81 : Float(3, 32, 1026, 1), %82 : Handle = ^ReflectionPad2d(0, 0, 1, 1)(%79), uses = [[%83.i0], []];\n\nExported graph so far:\ngraph(%1 : Float(44, 128, 1, 1)\n      %2 : Float(44)\n      %3 : Float(128, 32, 3, 1)\n      %4 : Float(128)\n      %5 : Float(128, 32, 5, 1)\n      %6 : Float(128)\n\n....\n\n      %79 : Float(3, 32, 1024, 1)) {\n  return ();\n}\n\nTraceback (most recent call last):\n  File \"convert_to_caffe2.py\", line 66, in <module>\n    torch_out = torch.onnx.export(torch_model, x, \"test.onnx\", verbose=True)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 37, in export\n    _export(model, args, f, export_params, kwargs, verbose)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 51, in _export\n    proto = trace.export(list(model.state_dict().values()), verbose)\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 133, in symbolic\n    return symbolic_fn(*args, **kwargs)\nTypeError: 'NoneType' object is not callable", "body": "It looks like there is an issue converting pyTorch models with Reflection (or Replication) padding. If you try using torch.onnx.export with ReflectionPad2d you get an error like the one below.\r\n\r\nI think the issue is similar to https://github.com/pytorch/pytorch/pull/2742. In that case there was an issue because pooling parameters could be specified as scalars or tuples and thus they weren't being converted correctly. The same thing applies for padding. I'm not sure which file to look through to fix this. \r\n\r\n```\r\nError occured while handling:\r\n%81 : Float(3, 32, 1026, 1), %82 : Handle = ^ReflectionPad2d(0, 0, 1, 1)(%79), uses = [[%83.i0], []];\r\n\r\nExported graph so far:\r\ngraph(%1 : Float(44, 128, 1, 1)\r\n      %2 : Float(44)\r\n      %3 : Float(128, 32, 3, 1)\r\n      %4 : Float(128)\r\n      %5 : Float(128, 32, 5, 1)\r\n      %6 : Float(128)\r\n\r\n....\r\n\r\n      %79 : Float(3, 32, 1024, 1)) {\r\n  return ();\r\n}\r\n\r\nTraceback (most recent call last):\r\n  File \"convert_to_caffe2.py\", line 66, in <module>\r\n    torch_out = torch.onnx.export(torch_model, x, \"test.onnx\", verbose=True)\r\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 37, in export\r\n    _export(model, args, f, export_params, kwargs, verbose)\r\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/onnx.py\", line 51, in _export\r\n    proto = trace.export(list(model.state_dict().values()), verbose)\r\n  File \"/home/clea/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 133, in symbolic\r\n    return symbolic_fn(*args, **kwargs)\r\nTypeError: 'NoneType' object is not callable\r\n\r\n```\r\n\r\n"}