{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12321", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12321/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12321/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12321/events", "html_url": "https://github.com/pytorch/pytorch/issues/12321", "id": 366738789, "node_id": "MDU6SXNzdWUzNjY3Mzg3ODk=", "number": 12321, "title": "torch.einsum inconsistent output", "user": {"login": "L-sky", "id": 10452832, "node_id": "MDQ6VXNlcjEwNDUyODMy", "avatar_url": "https://avatars2.githubusercontent.com/u/10452832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/L-sky", "html_url": "https://github.com/L-sky", "followers_url": "https://api.github.com/users/L-sky/followers", "following_url": "https://api.github.com/users/L-sky/following{/other_user}", "gists_url": "https://api.github.com/users/L-sky/gists{/gist_id}", "starred_url": "https://api.github.com/users/L-sky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/L-sky/subscriptions", "organizations_url": "https://api.github.com/users/L-sky/orgs", "repos_url": "https://api.github.com/users/L-sky/repos", "events_url": "https://api.github.com/users/L-sky/events{/privacy}", "received_events_url": "https://api.github.com/users/L-sky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1076919997, "node_id": "MDU6TGFiZWwxMDc2OTE5OTk3", "url": "https://api.github.com/repos/pytorch/pytorch/labels/correctness", "name": "correctness", "color": "2ef49b", "default": false}, {"id": 1076921751, "node_id": "MDU6TGFiZWwxMDc2OTIxNzUx", "url": "https://api.github.com/repos/pytorch/pytorch/labels/torch", "name": "torch", "color": "4fdddd", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-04T11:12:11Z", "updated_at": "2018-10-04T18:47:52Z", "closed_at": "2018-10-04T18:47:52Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>torch.einsum produce different result with/without expansion using iteration over repeated axis.</p>\n<h2>Minimal example</h2>\n<pre><code>import torch\na = torch.randn(2, 24, 10)\nb = torch.randn(5, 10)\n#a = a.cuda()\n#b = b.cuda()\nc1 = torch.einsum('ijk,bk-&gt;bij', [a,b])\nc2 = torch.einsum('bijk,bk-&gt;bij', [a.expand(b.size(0), 2, 24, 10),b])\nc3 = torch.zeros(5, 2, 24)\n\nfor i in range(5):\n    c3[i] = torch.einsum('ijk,k-&gt;ij', [a, b[i]])\n\nprint((c1-c2).abs().max())\nprint((c1-c3).abs().max())\nprint((c2-c3).abs().max())\n</code></pre>\n<p>Returns:</p>\n<pre><code>tensor(9.5367e-07)\ntensor(9.5367e-07)\ntensor(0.)\n</code></pre>\n<p>On cuda all three prints give non-zero output.</p>\n<h2>Expected behavior</h2>\n<p>Expected exactly the same result for all three expressions. In other words zeros for all three prints.</p>\n<h2>Environment</h2>\n<p>PyTorch version: 0.4.1<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010</p>\n<p>Python version: 3.6<br>\nCUDA runtime version: 9.1.85<br>\nGPU models and configuration: GPU 0: GeForce GTX 1070<br>\nNvidia driver version: 390.87</p>\n<p>[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch</p>", "body_text": "\ud83d\udc1b Bug\ntorch.einsum produce different result with/without expansion using iteration over repeated axis.\nMinimal example\nimport torch\na = torch.randn(2, 24, 10)\nb = torch.randn(5, 10)\n#a = a.cuda()\n#b = b.cuda()\nc1 = torch.einsum('ijk,bk->bij', [a,b])\nc2 = torch.einsum('bijk,bk->bij', [a.expand(b.size(0), 2, 24, 10),b])\nc3 = torch.zeros(5, 2, 24)\n\nfor i in range(5):\n    c3[i] = torch.einsum('ijk,k->ij', [a, b[i]])\n\nprint((c1-c2).abs().max())\nprint((c1-c3).abs().max())\nprint((c2-c3).abs().max())\n\nReturns:\ntensor(9.5367e-07)\ntensor(9.5367e-07)\ntensor(0.)\n\nOn cuda all three prints give non-zero output.\nExpected behavior\nExpected exactly the same result for all three expressions. In other words zeros for all three prints.\nEnvironment\nPyTorch version: 0.4.1\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\nPython version: 3.6\nCUDA runtime version: 9.1.85\nGPU models and configuration: GPU 0: GeForce GTX 1070\nNvidia driver version: 390.87\n[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch", "body": "## \ud83d\udc1b Bug\r\ntorch.einsum produce different result with/without expansion using iteration over repeated axis.\r\n\r\n## Minimal example\r\n```\r\nimport torch\r\na = torch.randn(2, 24, 10)\r\nb = torch.randn(5, 10)\r\n#a = a.cuda()\r\n#b = b.cuda()\r\nc1 = torch.einsum('ijk,bk->bij', [a,b])\r\nc2 = torch.einsum('bijk,bk->bij', [a.expand(b.size(0), 2, 24, 10),b])\r\nc3 = torch.zeros(5, 2, 24)\r\n\r\nfor i in range(5):\r\n    c3[i] = torch.einsum('ijk,k->ij', [a, b[i]])\r\n\r\nprint((c1-c2).abs().max())\r\nprint((c1-c3).abs().max())\r\nprint((c2-c3).abs().max())\r\n```\r\n\r\nReturns:\r\n```\r\ntensor(9.5367e-07)\r\ntensor(9.5367e-07)\r\ntensor(0.)\r\n```\r\n\r\nOn cuda all three prints give non-zero output. \r\n\r\n## Expected behavior\r\nExpected exactly the same result for all three expressions. In other words zeros for all three prints.\r\n\r\n## Environment\r\nPyTorch version: 0.4.1\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\r\n\r\nPython version: 3.6\r\nCUDA runtime version: 9.1.85\r\nGPU models and configuration: GPU 0: GeForce GTX 1070\r\nNvidia driver version: 390.87\r\n\r\n[conda] pytorch                   0.4.1           py36_cuda9.0.176_cudnn7.1.2_1    pytorch"}