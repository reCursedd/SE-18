{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/288475393", "html_url": "https://github.com/pytorch/pytorch/issues/1051#issuecomment-288475393", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1051", "id": 288475393, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODQ3NTM5Mw==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T17:25:32Z", "updated_at": "2017-03-22T17:25:32Z", "author_association": "MEMBER", "body_html": "<ol>\n<li>\n<p>It's probably simpler to disallow specifying the same device multiple times in DataParallel. I'm not sure there are sufficient use cases to warrant supporting it.</p>\n</li>\n<li>\n<p>It would be better to accumulate running_mean/var, but this requires autograd to support \"backward\" ops on things that aren't optimized by SGD.</p>\n</li>\n</ol>", "body_text": "It's probably simpler to disallow specifying the same device multiple times in DataParallel. I'm not sure there are sufficient use cases to warrant supporting it.\n\n\nIt would be better to accumulate running_mean/var, but this requires autograd to support \"backward\" ops on things that aren't optimized by SGD.", "body": "1. It's probably simpler to disallow specifying the same device multiple times in DataParallel. I'm not sure there are sufficient use cases to warrant supporting it.\r\n\r\n2. It would be better to accumulate running_mean/var, but this requires autograd to support \"backward\" ops on things that aren't optimized by SGD."}