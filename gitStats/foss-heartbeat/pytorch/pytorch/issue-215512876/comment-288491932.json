{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/288491932", "html_url": "https://github.com/pytorch/pytorch/issues/1051#issuecomment-288491932", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1051", "id": 288491932, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODQ5MTkzMg==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T18:17:51Z", "updated_at": "2017-03-22T18:36:45Z", "author_association": "CONTRIBUTOR", "body_html": "<ol start=\"2\">\n<li>I agree that accumulating running_mean/var across GPUs is not trivial in the current autograd model. But even if we decide not to accumulate them (arguably, over many epochs even the master GPU will see enough different samples to come up with good running estimates), current implementation broadcasting them to all the GPUs only to immediately discard whatever updates other GPUs made to them makes no sense. May be they should be not buffers, but some members of module <code>__dict__</code>, like, e.g. random states in rnns.<br>\nAlso, I think module replication in DataParallel should be better documented. Random states in rnn work now only because <code>__dict__</code> is shallow copied in replicate, it would break if <code>__dict__</code> were deep copied. But what if some module expects <code>__dict__</code> to be deep copied to work properly? There's nothing in the docs to say that it wouldn't work.</li>\n</ol>", "body_text": "I agree that accumulating running_mean/var across GPUs is not trivial in the current autograd model. But even if we decide not to accumulate them (arguably, over many epochs even the master GPU will see enough different samples to come up with good running estimates), current implementation broadcasting them to all the GPUs only to immediately discard whatever updates other GPUs made to them makes no sense. May be they should be not buffers, but some members of module __dict__, like, e.g. random states in rnns.\nAlso, I think module replication in DataParallel should be better documented. Random states in rnn work now only because __dict__ is shallow copied in replicate, it would break if __dict__ were deep copied. But what if some module expects __dict__ to be deep copied to work properly? There's nothing in the docs to say that it wouldn't work.", "body": "2. I agree that accumulating running_mean/var across GPUs is not trivial in the current autograd model. But even if we decide not to accumulate them (arguably, over many epochs even the master GPU will see enough different samples to come up with good running estimates), current implementation broadcasting them to all the GPUs only to immediately discard whatever updates other GPUs made to them makes no sense. May be they should be not buffers, but some members of module ```__dict__```, like, e.g. random states in rnns. \r\nAlso, I think module replication in DataParallel should be better documented. Random states in rnn work now only because ```__dict__``` is shallow copied in replicate, it would break if ```__dict__``` were deep copied. But what if some module expects ```__dict__``` to be deep copied to work properly? There's nothing in the docs to say that it wouldn't work.  "}