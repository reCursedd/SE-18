{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/362635394", "html_url": "https://github.com/pytorch/pytorch/issues/5004#issuecomment-362635394", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5004", "id": 362635394, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjYzNTM5NA==", "user": {"login": "Rhuax", "id": 9083577, "node_id": "MDQ6VXNlcjkwODM1Nzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/9083577?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rhuax", "html_url": "https://github.com/Rhuax", "followers_url": "https://api.github.com/users/Rhuax/followers", "following_url": "https://api.github.com/users/Rhuax/following{/other_user}", "gists_url": "https://api.github.com/users/Rhuax/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rhuax/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rhuax/subscriptions", "organizations_url": "https://api.github.com/users/Rhuax/orgs", "repos_url": "https://api.github.com/users/Rhuax/repos", "events_url": "https://api.github.com/users/Rhuax/events{/privacy}", "received_events_url": "https://api.github.com/users/Rhuax/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-02T16:32:19Z", "updated_at": "2018-02-02T16:32:39Z", "author_association": "NONE", "body_html": "<p>I managed to understand where the DoubleTensor was produced (instead of the FloatTensor). This was really hard to debug since I had practically no information ... By the way, now I have this error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 201, in &lt;module&gt;\n    trainIters(encoder1, attn_decoder1, 7, print_every=100)\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 170, in trainIters\n    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 94, in train\n    loss.backward()\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/variable.py\", line 167, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n    variables, grad_variables, retain_graph)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 335, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 343, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\", line 335, in backward_extended\n    grad_weight)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 468, in backward_weight\n    grad_params = get_parameters(fn, handle, dw)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 171, in get_parameters\n    assert cur_offset == offset\nAssertionError\n</code></pre>\n<p>The error message is again not very useful</p>", "body_text": "I managed to understand where the DoubleTensor was produced (instead of the FloatTensor). This was really hard to debug since I had practically no information ... By the way, now I have this error:\nTraceback (most recent call last):\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 201, in <module>\n    trainIters(encoder1, attn_decoder1, 7, print_every=100)\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 170, in trainIters\n    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 94, in train\n    loss.backward()\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/variable.py\", line 167, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n    variables, grad_variables, retain_graph)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 335, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 343, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\", line 335, in backward_extended\n    grad_weight)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 468, in backward_weight\n    grad_params = get_parameters(fn, handle, dw)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 171, in get_parameters\n    assert cur_offset == offset\nAssertionError\n\nThe error message is again not very useful", "body": "I managed to understand where the DoubleTensor was produced (instead of the FloatTensor). This was really hard to debug since I had practically no information ... By the way, now I have this error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 201, in <module>\r\n    trainIters(encoder1, attn_decoder1, 7, print_every=100)\r\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 170, in trainIters\r\n    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n  File \"/home/crow/PycharmProjects/text-summarization/train.py\", line 94, in train\r\n    loss.backward()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/variable.py\", line 167, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\r\n    variables, grad_variables, retain_graph)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 335, in _do_backward\r\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/function.py\", line 343, in backward\r\n    result = self.backward_extended(*nested_gradients)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\", line 335, in backward_extended\r\n    grad_weight)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 468, in backward_weight\r\n    grad_params = get_parameters(fn, handle, dw)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/backends/cudnn/rnn.py\", line 171, in get_parameters\r\n    assert cur_offset == offset\r\nAssertionError\r\n```\r\n\r\nThe error message is again not very useful"}