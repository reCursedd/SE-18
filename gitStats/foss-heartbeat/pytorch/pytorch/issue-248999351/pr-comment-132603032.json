{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/132603032", "pull_request_review_id": 55702335, "id": 132603032, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzMjYwMzAzMg==", "diff_hunk": "@@ -71,7 +71,10 @@ def safe_zeros_backward(inp, dim):\n             exclusive_normal = exclusive_normal_nocp.cumprod(dim)\n \n             def reverse_dim(var, dim):\n-                return var.index_select(dim, Variable(torch.arange(var.size(dim) - 1, -1, -1)).long())\n+                index = Variable(torch.arange(var.size(dim) - 1, -1, -1)).long()\n+                if var.is_cuda:\n+                    index = index.cuda()", "path": "torch/autograd/_functions/reduce.py", "position": null, "original_position": 7, "commit_id": "47fee489814fe5cc79e7dc22d4b92b06a3b04a1d", "original_commit_id": "2e8062825820eb9e353067b1dcf5d1ee5aa1d9a9", "user": {"login": "Stonesjtu", "id": 4556044, "node_id": "MDQ6VXNlcjQ1NTYwNDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4556044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stonesjtu", "html_url": "https://github.com/Stonesjtu", "followers_url": "https://api.github.com/users/Stonesjtu/followers", "following_url": "https://api.github.com/users/Stonesjtu/following{/other_user}", "gists_url": "https://api.github.com/users/Stonesjtu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stonesjtu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stonesjtu/subscriptions", "organizations_url": "https://api.github.com/users/Stonesjtu/orgs", "repos_url": "https://api.github.com/users/Stonesjtu/repos", "events_url": "https://api.github.com/users/Stonesjtu/events{/privacy}", "received_events_url": "https://api.github.com/users/Stonesjtu/received_events", "type": "User", "site_admin": false}, "body": "Yes, it does create a tensor on the same device as `var`. But the `arange` operation fails when the output tensor is not on the current cuda device.\r\nAnyway, the CUDA device id should not be a concern at such a low level in my opinion, these basic operations are performed on the same GPU card.", "created_at": "2017-08-11T00:59:17Z", "updated_at": "2018-11-23T15:34:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/2353#discussion_r132603032", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2353", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/132603032"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2353#discussion_r132603032"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2353"}}, "body_html": "<p>Yes, it does create a tensor on the same device as <code>var</code>. But the <code>arange</code> operation fails when the output tensor is not on the current cuda device.<br>\nAnyway, the CUDA device id should not be a concern at such a low level in my opinion, these basic operations are performed on the same GPU card.</p>", "body_text": "Yes, it does create a tensor on the same device as var. But the arange operation fails when the output tensor is not on the current cuda device.\nAnyway, the CUDA device id should not be a concern at such a low level in my opinion, these basic operations are performed on the same GPU card.", "in_reply_to_id": 132419500}