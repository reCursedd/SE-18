{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/132457334", "pull_request_review_id": 55539398, "id": 132457334, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzMjQ1NzMzNA==", "diff_hunk": "@@ -71,7 +71,10 @@ def safe_zeros_backward(inp, dim):\n             exclusive_normal = exclusive_normal_nocp.cumprod(dim)\n \n             def reverse_dim(var, dim):\n-                return var.index_select(dim, Variable(torch.arange(var.size(dim) - 1, -1, -1)).long())\n+                index = Variable(torch.arange(var.size(dim) - 1, -1, -1)).long()\n+                if var.is_cuda:\n+                    index = index.cuda()", "path": "torch/autograd/_functions/reduce.py", "position": null, "original_position": 7, "commit_id": "47fee489814fe5cc79e7dc22d4b92b06a3b04a1d", "original_commit_id": "2e8062825820eb9e353067b1dcf5d1ee5aa1d9a9", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "I believe that when you do `tensor.new()`, you have a new tensor created of the same type and device as `tensor`, so it should work just fine I think. Another (more verbose) option would be to use `with torch.cuda.device_of(tensor):`.\r\n\r\nPS: there is a typo in your example, as `var` is a Tensor and the snippet doesn't work.", "created_at": "2017-08-10T13:48:53Z", "updated_at": "2018-11-23T15:34:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/2353#discussion_r132457334", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2353", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/132457334"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2353#discussion_r132457334"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2353"}}, "body_html": "<p>I believe that when you do <code>tensor.new()</code>, you have a new tensor created of the same type and device as <code>tensor</code>, so it should work just fine I think. Another (more verbose) option would be to use <code>with torch.cuda.device_of(tensor):</code>.</p>\n<p>PS: there is a typo in your example, as <code>var</code> is a Tensor and the snippet doesn't work.</p>", "body_text": "I believe that when you do tensor.new(), you have a new tensor created of the same type and device as tensor, so it should work just fine I think. Another (more verbose) option would be to use with torch.cuda.device_of(tensor):.\nPS: there is a typo in your example, as var is a Tensor and the snippet doesn't work.", "in_reply_to_id": 132419500}