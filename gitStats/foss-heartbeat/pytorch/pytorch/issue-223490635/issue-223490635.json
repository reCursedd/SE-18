{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1324", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1324/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1324/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1324/events", "html_url": "https://github.com/pytorch/pytorch/issues/1324", "id": 223490635, "node_id": "MDU6SXNzdWUyMjM0OTA2MzU=", "number": 1324, "title": "Add ZeroPadding module", "user": {"login": "andrewgiessel", "id": 1160997, "node_id": "MDQ6VXNlcjExNjA5OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1160997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewgiessel", "html_url": "https://github.com/andrewgiessel", "followers_url": "https://api.github.com/users/andrewgiessel/followers", "following_url": "https://api.github.com/users/andrewgiessel/following{/other_user}", "gists_url": "https://api.github.com/users/andrewgiessel/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewgiessel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewgiessel/subscriptions", "organizations_url": "https://api.github.com/users/andrewgiessel/orgs", "repos_url": "https://api.github.com/users/andrewgiessel/repos", "events_url": "https://api.github.com/users/andrewgiessel/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewgiessel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-21T20:39:26Z", "updated_at": "2017-09-11T01:10:04Z", "closed_at": "2017-09-11T01:10:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello- currently pytorch has ReflectionPadding and ReplicationPadding but not ZeroPadding, and I'd like to help add it.</p>\n<p>(Bear with me, as I'm new to the codebase)</p>\n<p>After reading a bit, it seems like the <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/padding.py\">currently implemented padding modules</a> call backend functions which are themselves automatically imported/created by scanning through the the function definitions in THNN.h, and wrapping compiled code based on that.</p>\n<p>However, the <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/legacy/nn/Padding.py\">legacy padding module</a> seems a bit simpler, and is in pure python.  I hoping there is some standard and straight-foreward way to re-write <code>updateOutput()</code> and <code>updateGradInput()</code> into <code>forward()</code> and <code>backward()</code>, respectively.  In support of this notion, I wasn't able to find any THNN code for padding.</p>\n<p>Any guidance?</p>", "body_text": "Hello- currently pytorch has ReflectionPadding and ReplicationPadding but not ZeroPadding, and I'd like to help add it.\n(Bear with me, as I'm new to the codebase)\nAfter reading a bit, it seems like the currently implemented padding modules call backend functions which are themselves automatically imported/created by scanning through the the function definitions in THNN.h, and wrapping compiled code based on that.\nHowever, the legacy padding module seems a bit simpler, and is in pure python.  I hoping there is some standard and straight-foreward way to re-write updateOutput() and updateGradInput() into forward() and backward(), respectively.  In support of this notion, I wasn't able to find any THNN code for padding.\nAny guidance?", "body": "Hello- currently pytorch has ReflectionPadding and ReplicationPadding but not ZeroPadding, and I'd like to help add it.\r\n\r\n(Bear with me, as I'm new to the codebase)\r\n\r\nAfter reading a bit, it seems like the [currently implemented padding modules](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/padding.py) call backend functions which are themselves automatically imported/created by scanning through the the function definitions in THNN.h, and wrapping compiled code based on that. \r\n\r\nHowever, the [legacy padding module](https://github.com/pytorch/pytorch/blob/master/torch/legacy/nn/Padding.py) seems a bit simpler, and is in pure python.  I hoping there is some standard and straight-foreward way to re-write `updateOutput()` and `updateGradInput()` into `forward()` and `backward()`, respectively.  In support of this notion, I wasn't able to find any THNN code for padding.\r\n\r\nAny guidance?\r\n\r\n"}