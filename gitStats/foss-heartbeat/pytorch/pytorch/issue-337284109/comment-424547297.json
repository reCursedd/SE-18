{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/424547297", "html_url": "https://github.com/pytorch/pytorch/pull/9078#issuecomment-424547297", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9078", "id": 424547297, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDU0NzI5Nw==", "user": {"login": "pooryapzm", "id": 28755567, "node_id": "MDQ6VXNlcjI4NzU1NTY3", "avatar_url": "https://avatars2.githubusercontent.com/u/28755567?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pooryapzm", "html_url": "https://github.com/pooryapzm", "followers_url": "https://api.github.com/users/pooryapzm/followers", "following_url": "https://api.github.com/users/pooryapzm/following{/other_user}", "gists_url": "https://api.github.com/users/pooryapzm/gists{/gist_id}", "starred_url": "https://api.github.com/users/pooryapzm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pooryapzm/subscriptions", "organizations_url": "https://api.github.com/users/pooryapzm/orgs", "repos_url": "https://api.github.com/users/pooryapzm/repos", "events_url": "https://api.github.com/users/pooryapzm/events{/privacy}", "received_events_url": "https://api.github.com/users/pooryapzm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-26T00:42:14Z", "updated_at": "2018-09-26T00:42:14Z", "author_association": "NONE", "body_html": "<blockquote>\n<blockquote>\n<p>I installed pytorch from two source codes:</p>\n<pre><code>Commit 6dcaa47 from your repo (kshitij12345/pytorch:master)\nCommit ae1a972 from original pytorch:master (Which is the last commit your repo has from the pytorch:master)\nSo, there shouldn't be any problem with the single backward call for both. But I get the mentioned error from the former one while the latter one was fine.\n</code></pre>\n<p>It seems that your commit causes this error (btw, I'm not sure). I'll double check and will have a look and let you know if I found anything.</p>\n</blockquote>\n<p>In that case can you please share a minimal code snippet that produces the given error, so even I can check.<br>\nThank You.</p>\n</blockquote>\n<p>I am trying to write a minimal code to reproduce the given error.<br>\nMeanwhile, you can simply reproduce the error by training a simple model with OpenNMT. If you train the very example in their README, you will get the same error (there is no need for double gradients there).<br>\nAs far as I understand, the issue is with the (single) backward of the embedding table in both encoder and decoder.<br>\n<a href=\"https://github.com/OpenNMT/OpenNMT-py\">https://github.com/OpenNMT/OpenNMT-py</a></p>", "body_text": "I installed pytorch from two source codes:\nCommit 6dcaa47 from your repo (kshitij12345/pytorch:master)\nCommit ae1a972 from original pytorch:master (Which is the last commit your repo has from the pytorch:master)\nSo, there shouldn't be any problem with the single backward call for both. But I get the mentioned error from the former one while the latter one was fine.\n\nIt seems that your commit causes this error (btw, I'm not sure). I'll double check and will have a look and let you know if I found anything.\n\nIn that case can you please share a minimal code snippet that produces the given error, so even I can check.\nThank You.\n\nI am trying to write a minimal code to reproduce the given error.\nMeanwhile, you can simply reproduce the error by training a simple model with OpenNMT. If you train the very example in their README, you will get the same error (there is no need for double gradients there).\nAs far as I understand, the issue is with the (single) backward of the embedding table in both encoder and decoder.\nhttps://github.com/OpenNMT/OpenNMT-py", "body": "> > I installed pytorch from two source codes:\r\n> > ```\r\n> > Commit 6dcaa47 from your repo (kshitij12345/pytorch:master)\r\n> > Commit ae1a972 from original pytorch:master (Which is the last commit your repo has from the pytorch:master)\r\n> > So, there shouldn't be any problem with the single backward call for both. But I get the mentioned error from the former one while the latter one was fine.\r\n> > ```\r\n> > It seems that your commit causes this error (btw, I'm not sure). I'll double check and will have a look and let you know if I found anything.\r\n> \r\n> In that case can you please share a minimal code snippet that produces the given error, so even I can check.\r\n> Thank You.\r\n\r\nI am trying to write a minimal code to reproduce the given error.\r\nMeanwhile, you can simply reproduce the error by training a simple model with OpenNMT. If you train the very example in their README, you will get the same error (there is no need for double gradients there).\r\nAs far as I understand, the issue is with the (single) backward of the embedding table in both encoder and decoder.\r\nhttps://github.com/OpenNMT/OpenNMT-py\r\n"}