{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/192103855", "pull_request_review_id": 124811125, "id": 192103855, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MjEwMzg1NQ==", "diff_hunk": "@@ -51,10 +55,113 @@ void THTensor_(geometric)(THTensor *self, THGenerator *_generator, double p)\n   TH_TENSOR_APPLY(real, self, *self_data = (real)THRandom_geometric(_generator, p););\n }\n \n+#ifdef TH_BLAS_MKL\n+#define BERNOULLI_OMP 800\n+#define TH_OMP_OVERHEAD_THRESHOLD_COPY 20000\n+\n+void iBernoulli_generate_copy(THTensor *self, THGenerator *_generator, const double p)\n+{\n+  int64_t seed = THRandom_random(_generator);\n+  int64_t n = THTensor_(nElement)(self);\n+  int contig = THTensor_(isContiguous)(self);\n+  int *tmp = NULL;\n+  THIntTensor* intTensor = NULL;\n+\n+  if (contig) {\n+#ifdef TH_REAL_IS_INT\n+    tmp = THIntTensor_data(self);\n+#else\n+    tmp = (int*)THAlloc(n*sizeof(int));\n+#endif\n+  } else {\n+    intTensor = THIntTensor_new();\n+    THIntTensor_resizeNd(intTensor, self->nDimension, self->size, NULL);\n+    tmp = THIntTensor_data(intTensor);\n+  }\n+\n+#ifdef _OPENMP\n+  size_t nthr = !omp_in_parallel() && n >= BERNOULLI_OMP ? omp_get_num_threads() : 1;\n+#pragma omp parallel num_threads(nthr) firstprivate(nthr)\n+  {\n+    size_t tid = omp_get_thread_num();\n+    int64_t seg_len_tmp = n / nthr;\n+    int64_t line_index_offset = tid * seg_len_tmp;\n+    int64_t line_seg_len = (tid == nthr - 1)? (n-line_index_offset) : seg_len_tmp;\n+#else\n+  {\n+    int64_t line_index_offset = 0;\n+    int64_t line_seg_len = n;\n+#endif\n+\n+    if (line_seg_len > 0) {\n+      VSLStreamStatePtr stream;\n+      vslNewStream(&stream, VSL_BRNG_MCG31, seed);\n+      vslSkipAheadStream(stream, line_index_offset);\n+      viRngBernoulli(VSL_RNG_METHOD_BERNOULLI_ICDF, stream, line_seg_len,\n+        tmp + line_index_offset, p);\n+      vslDeleteStream(&stream);\n+\n+#ifndef TH_REAL_IS_INT\n+      if (contig) {\n+        real* self_seg = THTensor_(data)(self) + line_index_offset;\n+        int* tmp_seg = tmp + line_index_offset;\n+        THVector_(cvtFromInt)(self_seg, tmp_seg, line_seg_len);\n+      }\n+#endif\n+    }\n+  }\n+\n+  if(contig) {\n+#ifndef TH_REAL_IS_INT\n+    THFree(tmp);\n+#endif\n+  } else {\n+#ifdef _OPENMP\n+    TH_TENSOR_APPLY2_OMP(n, 1, 0, int, intTensor, real, self, *self_data = *intTensor_data;, TH_OMP_OVERHEAD_THRESHOLD_COPY)\n+#else\n+    TH_TENSOR_APPLY2(int, intTensor, real, self, *self_data = *intTensor_data;)\n+#endif\n+    THIntTensor_free(intTensor);\n+  }\n+\n+}\n+\n+#endif\n+\n void THTensor_(bernoulli)(THTensor *self, THGenerator *_generator, double p)\n {\n+#ifdef TH_BLAS_MKL\n+  uint32_t eax, ebx, ecx, edx;\n+  eax = 0x0;\n+  ecx = 0x0;\n+  cpuid(&eax, &ebx, &ecx, &edx);\n+  /*EAX=0: Get vendor ID as a twelve-character ASCII string stored in EBX, EDX, ECX (in that order)\n+    ASCII\n+    0x47: G\n+    0x65: e\n+    0x6e: n\n+    0x75: u\n+    0x69: i\n+    0x6e: n\n+    0x65: e\n+    0x49: I\n+    0x6e: n\n+    0x74: t\n+    0x65: e\n+    0x6c: l\n+    \"GenuineIntel\" \u2013 Intel\n+  */\n+  if((0x6c65746e == ecx) && (0x49656e69 == edx) && (0x756e6547 == ebx )) { /*Intel Vendor*/", "path": "aten/src/TH/generic/THTensorRandom.cpp", "position": null, "original_position": 111, "commit_id": "747e8775670233b943305a0f5bbed0a910052908", "original_commit_id": "1b42958f05ee50620883ff245c4407d57560370b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Can we isolate this into a separate function? It will probably be useful in more places.", "created_at": "2018-05-31T13:45:32Z", "updated_at": "2018-11-23T15:44:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/7171#discussion_r192103855", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7171", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/192103855"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7171#discussion_r192103855"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7171"}}, "body_html": "<p>Can we isolate this into a separate function? It will probably be useful in more places.</p>", "body_text": "Can we isolate this into a separate function? It will probably be useful in more places."}