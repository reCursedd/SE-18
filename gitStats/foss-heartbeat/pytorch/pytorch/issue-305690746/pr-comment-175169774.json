{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175169774", "pull_request_review_id": 104663212, "id": 175169774, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTE2OTc3NA==", "diff_hunk": "@@ -294,10 +294,10 @@ def saved_variables(formula, args):\n             'suffix': '_numel',\n             'type': 'int64_t',\n         }),\n-        # replace to_arg_sizes(self, 2) with self_argsizes_2\n-        (r'to_arg_sizes\\({}, (\\w+)\\)', {\n-            'suffix': lambda m: '_sizes_{}'.format(*m.groups()),\n-            'type': 'IntList',\n+        # replace to_args_sizes(self) with self_args_sizes\n+        (r'to_args_sizes\\({}\\)', {\n+            'suffix': '_args_sizes',\n+            'type': 'std::vector<std::vector<int64_t>>',", "path": "tools/autograd/load_derivatives.py", "position": 11, "original_position": 11, "commit_id": "fee486bd3bd78309203926f4af5734d6bbfc1839", "original_commit_id": "9ed3ebafdd29902b54193635a644c09e3a358bd5", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "here? https://github.com/pytorch/pytorch/blob/acc409396bda54e25dd0cccbd526821c52645662/tools/autograd/gen_autograd_functions.py#L139-L140.  Looks like you can just add another case here.", "created_at": "2018-03-16T17:55:49Z", "updated_at": "2018-11-23T15:40:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/5819#discussion_r175169774", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5819", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175169774"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5819#discussion_r175169774"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5819"}}, "body_html": "<p>here? <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/acc409396bda54e25dd0cccbd526821c52645662/tools/autograd/gen_autograd_functions.py#L139-L140\">pytorch/tools/autograd/gen_autograd_functions.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 139 to 140\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/acc409396bda54e25dd0cccbd526821c52645662\">acc4093</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L139\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"139\"></td>\n          <td id=\"LC139\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">elif</span> arg[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>type<span class=\"pl-pds\">'</span></span>] <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>IntList<span class=\"pl-pds\">'</span></span>: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L140\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"140\"></td>\n          <td id=\"LC140\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     saved_variables.append(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>std::vector&lt;int64_t&gt; <span class=\"pl-c1\">{}</span>;<span class=\"pl-pds\">'</span></span>.format(name)) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n.  Looks like you can just add another case here.</p>", "body_text": "here? \n  \n    \n      pytorch/tools/autograd/gen_autograd_functions.py\n    \n    \n        Lines 139 to 140\n      in\n      acc4093\n    \n    \n    \n    \n\n        \n          \n           elif arg['type'] == 'IntList': \n        \n\n        \n          \n               saved_variables.append('std::vector<int64_t> {};'.format(name)) \n        \n    \n  \n\n.  Looks like you can just add another case here.", "in_reply_to_id": 175151897}