{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3772", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3772/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3772/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3772/events", "html_url": "https://github.com/pytorch/pytorch/issues/3772", "id": 275084919, "node_id": "MDU6SXNzdWUyNzUwODQ5MTk=", "number": 3772, "title": "dispatch_hash: build error with GCC 6/7", "user": {"login": "stefan-it", "id": 20651387, "node_id": "MDQ6VXNlcjIwNjUxMzg3", "avatar_url": "https://avatars1.githubusercontent.com/u/20651387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stefan-it", "html_url": "https://github.com/stefan-it", "followers_url": "https://api.github.com/users/stefan-it/followers", "following_url": "https://api.github.com/users/stefan-it/following{/other_user}", "gists_url": "https://api.github.com/users/stefan-it/gists{/gist_id}", "starred_url": "https://api.github.com/users/stefan-it/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stefan-it/subscriptions", "organizations_url": "https://api.github.com/users/stefan-it/orgs", "repos_url": "https://api.github.com/users/stefan-it/repos", "events_url": "https://api.github.com/users/stefan-it/events{/privacy}", "received_events_url": "https://api.github.com/users/stefan-it/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-11-18T14:59:33Z", "updated_at": "2017-11-20T00:40:42Z", "closed_at": "2017-11-20T00:40:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi,</p>\n<p>I ran into the following compilation error using GCC in version 6.3 and 7.2 (using the latest <code>pytorch</code> version <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/0fd968230510944117ad0c480e893256a9874c2a/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/0fd968230510944117ad0c480e893256a9874c2a\"><tt>0fd9682</tt></a>):</p>\n<div class=\"highlight highlight-source-shell\"><pre>/mnt/Repositories/pytorch/torch/csrc/jit/python_arg_flatten.h:28:80:   required from here\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:75:39: error: call of overloaded <span class=\"pl-s\"><span class=\"pl-pds\">'</span>dispatch_hash(const at::ScalarType&amp;)<span class=\"pl-pds\">'</span></span> is ambiguous\n     <span class=\"pl-k\">return</span> _hash_detail::dispatch_hash(o)<span class=\"pl-k\">;</span>\n            <span class=\"pl-k\">~</span>~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:52:6: note: candidate: decltype <span class=\"pl-s\"><span class=\"pl-pds\">((</span>std<span class=\"pl-k\">::</span>hash<span class=\"pl-k\">&lt;</span>_Tp<span class=\"pl-k\">&gt;</span>()(o)<span class=\"pl-k\">,</span> std<span class=\"pl-k\">::</span>size_t(<span class=\"pl-pds\">))</span></span>) torch::_hash_detail::dispatch_hash(const T<span class=\"pl-k\">&amp;</span>) [with T <span class=\"pl-k\">=</span> at::ScalarType<span class=\"pl-k\">;</span> decltype <span class=\"pl-s\"><span class=\"pl-pds\">((</span>std<span class=\"pl-k\">::</span>hash<span class=\"pl-k\">&lt;</span>_Tp<span class=\"pl-k\">&gt;</span>()(o)<span class=\"pl-k\">,</span> std<span class=\"pl-k\">::</span>size_t(<span class=\"pl-pds\">))</span></span>) <span class=\"pl-k\">=</span> long unsigned int<span class=\"pl-k\">;</span> std::size_t <span class=\"pl-k\">=</span> long unsigned int]\n auto dispatch_hash(const T<span class=\"pl-k\">&amp;</span> o) -<span class=\"pl-k\">&gt;</span> <span class=\"pl-en\">decltype(std::hash&lt;T&gt;</span>()(o), <span class=\"pl-en\">std::size_t</span>()) {\n      ^~~~~~~~~~~~~\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:59:68: note: candidate: typename std::enable_if<span class=\"pl-k\">&lt;</span>std::is_enum<span class=\"pl-k\">&lt;</span>_Tp<span class=\"pl-k\">&gt;</span>::value, long unsigned int<span class=\"pl-k\">&gt;</span>::type torch::_hash_detail::dispatch_hash(const T<span class=\"pl-k\">&amp;</span>) [with T <span class=\"pl-k\">=</span> at::ScalarType<span class=\"pl-k\">;</span> typename std::enable_if<span class=\"pl-k\">&lt;</span>std::is_enum<span class=\"pl-k\">&lt;</span>_Tp<span class=\"pl-k\">&gt;</span>::value, long unsigned int<span class=\"pl-k\">&gt;</span>::type <span class=\"pl-k\">=</span> long unsigned int]\n typename std::enable_if<span class=\"pl-k\">&lt;</span>std::is_enum<span class=\"pl-k\">&lt;</span>T<span class=\"pl-k\">&gt;</span>::value, std::size_t<span class=\"pl-k\">&gt;</span>::type dispatch_hash(const T<span class=\"pl-k\">&amp;</span> o) {\n                                                                    ^~~~~~~~~~~~~</pre></div>\n<p>But I found a quick workaround for that (<code>torch/csrc/utils/hash.h</code>):</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">ifndef</span> _MSC_VER\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> MSVC has this one defined already</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>template&lt;typename T&gt;</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>typename std::enable_if&lt;std::is_enum&lt;T&gt;::value, std::size_t&gt;::type dispatch_hash(const T&amp; o) {</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">//</span>return std::hash&lt;int&gt;()(static_cast&lt;int&gt;(o));</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>}</span>\n#<span class=\"pl-k\">endif</span></pre></div>\n<p>Maybe we can add something like (\"pseudo-code\") around the dispatcher?</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">ifndef</span> _MSC_VER &amp;&amp; _GCC_VER &lt; 7</pre></div>\n<p>So I guess we can discuss a solution here. I can reproduce this on Arch Linux (both x64 and ARM64) + can give of course further feedback (testing patches and so on) :)</p>", "body_text": "Hi,\nI ran into the following compilation error using GCC in version 6.3 and 7.2 (using the latest pytorch version 0fd9682):\n/mnt/Repositories/pytorch/torch/csrc/jit/python_arg_flatten.h:28:80:   required from here\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:75:39: error: call of overloaded 'dispatch_hash(const at::ScalarType&)' is ambiguous\n     return _hash_detail::dispatch_hash(o);\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:52:6: note: candidate: decltype ((std::hash<_Tp>()(o), std::size_t())) torch::_hash_detail::dispatch_hash(const T&) [with T = at::ScalarType; decltype ((std::hash<_Tp>()(o), std::size_t())) = long unsigned int; std::size_t = long unsigned int]\n auto dispatch_hash(const T& o) -> decltype(std::hash<T>()(o), std::size_t()) {\n      ^~~~~~~~~~~~~\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:59:68: note: candidate: typename std::enable_if<std::is_enum<_Tp>::value, long unsigned int>::type torch::_hash_detail::dispatch_hash(const T&) [with T = at::ScalarType; typename std::enable_if<std::is_enum<_Tp>::value, long unsigned int>::type = long unsigned int]\n typename std::enable_if<std::is_enum<T>::value, std::size_t>::type dispatch_hash(const T& o) {\n                                                                    ^~~~~~~~~~~~~\nBut I found a quick workaround for that (torch/csrc/utils/hash.h):\n#ifndef _MSC_VER\n// MSVC has this one defined already\n//template<typename T>\n//typename std::enable_if<std::is_enum<T>::value, std::size_t>::type dispatch_hash(const T& o) {\n  //return std::hash<int>()(static_cast<int>(o));\n//}\n#endif\nMaybe we can add something like (\"pseudo-code\") around the dispatcher?\n#ifndef _MSC_VER && _GCC_VER < 7\nSo I guess we can discuss a solution here. I can reproduce this on Arch Linux (both x64 and ARM64) + can give of course further feedback (testing patches and so on) :)", "body": "Hi,\r\n\r\nI ran into the following compilation error using GCC in version 6.3 and 7.2 (using the latest `pytorch` version 0fd968230510944117ad0c480e893256a9874c2a):\r\n\r\n```bash\r\n/mnt/Repositories/pytorch/torch/csrc/jit/python_arg_flatten.h:28:80:   required from here\r\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:75:39: error: call of overloaded 'dispatch_hash(const at::ScalarType&)' is ambiguous\r\n     return _hash_detail::dispatch_hash(o);\r\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\r\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:52:6: note: candidate: decltype ((std::hash<_Tp>()(o), std::size_t())) torch::_hash_detail::dispatch_hash(const T&) [with T = at::ScalarType; decltype ((std::hash<_Tp>()(o), std::size_t())) = long unsigned int; std::size_t = long unsigned int]\r\n auto dispatch_hash(const T& o) -> decltype(std::hash<T>()(o), std::size_t()) {\r\n      ^~~~~~~~~~~~~\r\n/mnt/Repositories/pytorch/torch/csrc/utils/hash.h:59:68: note: candidate: typename std::enable_if<std::is_enum<_Tp>::value, long unsigned int>::type torch::_hash_detail::dispatch_hash(const T&) [with T = at::ScalarType; typename std::enable_if<std::is_enum<_Tp>::value, long unsigned int>::type = long unsigned int]\r\n typename std::enable_if<std::is_enum<T>::value, std::size_t>::type dispatch_hash(const T& o) {\r\n                                                                    ^~~~~~~~~~~~~\r\n```\r\n\r\nBut I found a quick workaround for that (`torch/csrc/utils/hash.h`):\r\n\r\n```cpp\r\n#ifndef _MSC_VER\r\n// MSVC has this one defined already\r\n//template<typename T>\r\n//typename std::enable_if<std::is_enum<T>::value, std::size_t>::type dispatch_hash(const T& o) {\r\n  //return std::hash<int>()(static_cast<int>(o));\r\n//}\r\n#endif\r\n```\r\n\r\nMaybe we can add something like (\"pseudo-code\") around the dispatcher?\r\n\r\n```cpp\r\n#ifndef _MSC_VER && _GCC_VER < 7\r\n```\r\n\r\nSo I guess we can discuss a solution here. I can reproduce this on Arch Linux (both x64 and ARM64) + can give of course further feedback (testing patches and so on) :)"}