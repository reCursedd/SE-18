{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13892", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13892/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13892/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13892/events", "html_url": "https://github.com/pytorch/pytorch/issues/13892", "id": 380153539, "node_id": "MDU6SXNzdWUzODAxNTM1Mzk=", "number": 13892, "title": "In-place matrix multiplication gives erroneous results.", "user": {"login": "rhaps0dy", "id": 4928242, "node_id": "MDQ6VXNlcjQ5MjgyNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4928242?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rhaps0dy", "html_url": "https://github.com/rhaps0dy", "followers_url": "https://api.github.com/users/rhaps0dy/followers", "following_url": "https://api.github.com/users/rhaps0dy/following{/other_user}", "gists_url": "https://api.github.com/users/rhaps0dy/gists{/gist_id}", "starred_url": "https://api.github.com/users/rhaps0dy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rhaps0dy/subscriptions", "organizations_url": "https://api.github.com/users/rhaps0dy/orgs", "repos_url": "https://api.github.com/users/rhaps0dy/repos", "events_url": "https://api.github.com/users/rhaps0dy/events{/privacy}", "received_events_url": "https://api.github.com/users/rhaps0dy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131853, "node_id": "MDU6TGFiZWw0MjQxMzE4NTM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/wontfix", "name": "wontfix", "color": "ffffff", "default": true}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-13T10:20:48Z", "updated_at": "2018-11-19T18:57:50Z", "closed_at": "2018-11-19T18:57:43Z", "author_association": "NONE", "body_html": "<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<p>Run the following snippet.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\ntorch.random.manual_seed(<span class=\"pl-c1\">1</span>)\nN<span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>\nb <span class=\"pl-k\">=</span> torch.randn([N, N], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cpu<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(b <span class=\"pl-k\">@</span> b.t())\ntorch.mm(b, b.t(), <span class=\"pl-v\">out</span><span class=\"pl-k\">=</span>b)\n<span class=\"pl-c1\">print</span>(b)</pre></div>\n<p>Output:</p>\n<pre><code>tensor([[ 5.9084,  3.8404,  1.7716, -1.8287],\n        [ 3.8404,  3.9303,  1.0525, -1.9818],\n        [ 1.7716,  1.0525,  1.2668,  0.3756],\n        [-1.8287, -1.9818,  0.3756,  3.1666]])\ntensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\n</code></pre>\n<p>CUDA seems to work well in this case, maybe because the matrix is small, but you can make it fail too:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\ntorch.random.manual_seed(<span class=\"pl-c1\">1</span>)\nN<span class=\"pl-k\">=</span><span class=\"pl-c1\">5000</span>\nb <span class=\"pl-k\">=</span> torch.randn([N, N], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(torch.any(torch.isnan(b <span class=\"pl-k\">@</span> b.t())))\ntorch.mm(b, b.t(), <span class=\"pl-v\">out</span><span class=\"pl-k\">=</span>b)\n<span class=\"pl-c1\">print</span>(torch.any(torch.isnan(b)))</pre></div>\n<p>Output:</p>\n<pre><code>tensor(0, device='cuda:0', dtype=torch.uint8)\ntensor(1, device='cuda:0', dtype=torch.uint8)\n\n</code></pre>\n<h2>Expected behavior</h2>\n<p>We would expect the two matrices to have the same result. In the second one, we would not expect a NaN to appear after a Matrix multiplication.</p>\n<p>Probably storing the result to the same place where you're reading it from is unrealistic, in this case, an exception or warning should be raised if the user does this. Or it should be written in the documentation (maybe it is? I haven't read <em>all</em> of it).</p>\n<h2>Environment</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>PyTorch was installed using pip.</p>\n<p>OS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration: GPU 0: GeForce GTX 1080<br>\nNvidia driver version: 396.44<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3<br>\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a</p>", "body_text": "To Reproduce\nSteps to reproduce the behavior:\nRun the following snippet.\nimport torch\ntorch.random.manual_seed(1)\nN=4\nb = torch.randn([N, N], device='cpu')\nprint(b @ b.t())\ntorch.mm(b, b.t(), out=b)\nprint(b)\nOutput:\ntensor([[ 5.9084,  3.8404,  1.7716, -1.8287],\n        [ 3.8404,  3.9303,  1.0525, -1.9818],\n        [ 1.7716,  1.0525,  1.2668,  0.3756],\n        [-1.8287, -1.9818,  0.3756,  3.1666]])\ntensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\n\nCUDA seems to work well in this case, maybe because the matrix is small, but you can make it fail too:\nimport torch\ntorch.random.manual_seed(1)\nN=5000\nb = torch.randn([N, N], device='cuda')\nprint(torch.any(torch.isnan(b @ b.t())))\ntorch.mm(b, b.t(), out=b)\nprint(torch.any(torch.isnan(b)))\nOutput:\ntensor(0, device='cuda:0', dtype=torch.uint8)\ntensor(1, device='cuda:0', dtype=torch.uint8)\n\n\nExpected behavior\nWe would expect the two matrices to have the same result. In the second one, we would not expect a NaN to appear after a Matrix multiplication.\nProbably storing the result to the same place where you're reading it from is unrealistic, in this case, an exception or warning should be raised if the user does this. Or it should be written in the documentation (maybe it is? I haven't read all of it).\nEnvironment\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nPyTorch was installed using pip.\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration: GPU 0: GeForce GTX 1080\nNvidia driver version: 396.44\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a", "body": "## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nRun the following snippet.\r\n\r\n```python\r\nimport torch\r\ntorch.random.manual_seed(1)\r\nN=4\r\nb = torch.randn([N, N], device='cpu')\r\nprint(b @ b.t())\r\ntorch.mm(b, b.t(), out=b)\r\nprint(b)\r\n```\r\n\r\nOutput:\r\n```\r\ntensor([[ 5.9084,  3.8404,  1.7716, -1.8287],\r\n        [ 3.8404,  3.9303,  1.0525, -1.9818],\r\n        [ 1.7716,  1.0525,  1.2668,  0.3756],\r\n        [-1.8287, -1.9818,  0.3756,  3.1666]])\r\ntensor([[0., 0., 0., 0.],\r\n        [0., 0., 0., 0.],\r\n        [0., 0., 0., 0.],\r\n        [0., 0., 0., 0.]])\r\n```\r\n\r\nCUDA seems to work well in this case, maybe because the matrix is small, but you can make it fail too:\r\n\r\n```python\r\nimport torch\r\ntorch.random.manual_seed(1)\r\nN=5000\r\nb = torch.randn([N, N], device='cuda')\r\nprint(torch.any(torch.isnan(b @ b.t())))\r\ntorch.mm(b, b.t(), out=b)\r\nprint(torch.any(torch.isnan(b)))\r\n```\r\n\r\nOutput:\r\n```\r\ntensor(0, device='cuda:0', dtype=torch.uint8)\r\ntensor(1, device='cuda:0', dtype=torch.uint8)\r\n\r\n```\r\n\r\n## Expected behavior\r\n\r\nWe would expect the two matrices to have the same result. In the second one, we would not expect a NaN to appear after a Matrix multiplication.\r\n\r\nProbably storing the result to the same place where you're reading it from is unrealistic, in this case, an exception or warning should be raised if the user does this. Or it should be written in the documentation (maybe it is? I haven't read _all_ of it).\r\n\r\n## Environment\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nPyTorch was installed using pip.\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: GPU 0: GeForce GTX 1080\r\nNvidia driver version: 396.44\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\r\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a"}