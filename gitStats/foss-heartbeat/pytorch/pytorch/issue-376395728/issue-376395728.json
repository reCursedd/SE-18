{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13448", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13448/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13448/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13448/events", "html_url": "https://github.com/pytorch/pytorch/issues/13448", "id": 376395728, "node_id": "MDU6SXNzdWUzNzYzOTU3Mjg=", "number": 13448, "title": "torch.sigmoid behaves inconsistently for 32- and 64-bit NaN inputs", "user": {"login": "grey-area", "id": 5156669, "node_id": "MDQ6VXNlcjUxNTY2Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5156669?v=4", "gravatar_id": "", "url": "https://api.github.com/users/grey-area", "html_url": "https://github.com/grey-area", "followers_url": "https://api.github.com/users/grey-area/followers", "following_url": "https://api.github.com/users/grey-area/following{/other_user}", "gists_url": "https://api.github.com/users/grey-area/gists{/gist_id}", "starred_url": "https://api.github.com/users/grey-area/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/grey-area/subscriptions", "organizations_url": "https://api.github.com/users/grey-area/orgs", "repos_url": "https://api.github.com/users/grey-area/repos", "events_url": "https://api.github.com/users/grey-area/events{/privacy}", "received_events_url": "https://api.github.com/users/grey-area/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-11-01T13:38:01Z", "updated_at": "2018-11-05T18:31:00Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>When applying torch.sigmoid to a DoubleTensor containing NaNs, the result will contain only NaNs.</p>\n<p>When applying torch.sigmoid to a FloatTensor containing NaNs, some values in the resulting tensor will be NaN, and some values will be a small number (4.156e-39). The proportion of each seems to depend deterministically on the size of the input tensor, but for a given input size, the proportion of each will vary from one machine to another.  The NaNs and small valued numbers appear in a periodic pattern in the output tensor.</p>\n<p>The bug doesn't manifest if everything is done on GPU.</p>\n<h2>Code example</h2>\n<h3>Code</h3>\n<pre><code>Ns = [10, 100, 1000, 10000]\n\nfor N in Ns:\n\n    nans_32_bit = (torch.zeros(N) / 0)\n    nans_64_bit = (nans_32_bit.type(torch.DoubleTensor))\n\n    print('Input: tensor of size N={} containing only NaN'.format(N))\n\n    post_sigmoid_32_bit = torch.sigmoid(nans_32_bit)\n    post_sigmoid_64_bit = torch.sigmoid(nans_64_bit)\n\n    proportion_nan_32_bit = torch.mean(torch.isnan(post_sigmoid_32_bit).type(torch.FloatTensor))\n    proportion_nan_64_bit = torch.mean(torch.isnan(post_sigmoid_64_bit).type(torch.FloatTensor))\n\n    print('After sigmoid:')\n    print('Proportion NaN in result with 32 bit input: {:.3f}'.format(proportion_nan_32_bit))\n    print('Proportion NaN in result with 64 bit input: {:.3f}\\n'.format(proportion_nan_64_bit))\n</code></pre>\n<h3>Code output</h3>\n<p>Input: tensor of size N=10 containing only NaN<br>\nAfter sigmoid:<br>\nProportion NaN in result with 32 bit input: 1.000<br>\nProportion NaN in result with 64 bit input: 1.000</p>\n<p>Input: tensor of size N=100 containing only NaN<br>\nAfter sigmoid:<br>\nProportion NaN in result with 32 bit input: 0.360<br>\nProportion NaN in result with 64 bit input: 1.000</p>\n<p>Input: tensor of size N=1000 containing only NaN<br>\nAfter sigmoid:<br>\nProportion NaN in result with 32 bit input: 0.040<br>\nProportion NaN in result with 64 bit input: 1.000</p>\n<p>Input: tensor of size N=10000 containing only NaN<br>\nAfter sigmoid:<br>\nProportion NaN in result with 32 bit input: 0.002<br>\nProportion NaN in result with 64 bit input: 1.000</p>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0<br>\nCMake version: version 3.10.2</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.1.85<br>\nGPU models and configuration: GPU 0: GeForce GTX 1050<br>\nNvidia driver version: 390.59<br>\ncuDNN version: 7102</p>\n<p>Versions of relevant libraries:<br>\n[pip] 18.1<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nWhen applying torch.sigmoid to a DoubleTensor containing NaNs, the result will contain only NaNs.\nWhen applying torch.sigmoid to a FloatTensor containing NaNs, some values in the resulting tensor will be NaN, and some values will be a small number (4.156e-39). The proportion of each seems to depend deterministically on the size of the input tensor, but for a given input size, the proportion of each will vary from one machine to another.  The NaNs and small valued numbers appear in a periodic pattern in the output tensor.\nThe bug doesn't manifest if everything is done on GPU.\nCode example\nCode\nNs = [10, 100, 1000, 10000]\n\nfor N in Ns:\n\n    nans_32_bit = (torch.zeros(N) / 0)\n    nans_64_bit = (nans_32_bit.type(torch.DoubleTensor))\n\n    print('Input: tensor of size N={} containing only NaN'.format(N))\n\n    post_sigmoid_32_bit = torch.sigmoid(nans_32_bit)\n    post_sigmoid_64_bit = torch.sigmoid(nans_64_bit)\n\n    proportion_nan_32_bit = torch.mean(torch.isnan(post_sigmoid_32_bit).type(torch.FloatTensor))\n    proportion_nan_64_bit = torch.mean(torch.isnan(post_sigmoid_64_bit).type(torch.FloatTensor))\n\n    print('After sigmoid:')\n    print('Proportion NaN in result with 32 bit input: {:.3f}'.format(proportion_nan_32_bit))\n    print('Proportion NaN in result with 64 bit input: {:.3f}\\n'.format(proportion_nan_64_bit))\n\nCode output\nInput: tensor of size N=10 containing only NaN\nAfter sigmoid:\nProportion NaN in result with 32 bit input: 1.000\nProportion NaN in result with 64 bit input: 1.000\nInput: tensor of size N=100 containing only NaN\nAfter sigmoid:\nProportion NaN in result with 32 bit input: 0.360\nProportion NaN in result with 64 bit input: 1.000\nInput: tensor of size N=1000 containing only NaN\nAfter sigmoid:\nProportion NaN in result with 32 bit input: 0.040\nProportion NaN in result with 64 bit input: 1.000\nInput: tensor of size N=10000 containing only NaN\nAfter sigmoid:\nProportion NaN in result with 32 bit input: 0.002\nProportion NaN in result with 64 bit input: 1.000\nSystem Info\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\nCMake version: version 3.10.2\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.1.85\nGPU models and configuration: GPU 0: GeForce GTX 1050\nNvidia driver version: 390.59\ncuDNN version: 7102\nVersions of relevant libraries:\n[pip] 18.1\n[conda] Could not collect", "body": "## Issue description\r\n\r\nWhen applying torch.sigmoid to a DoubleTensor containing NaNs, the result will contain only NaNs. \r\n\r\nWhen applying torch.sigmoid to a FloatTensor containing NaNs, some values in the resulting tensor will be NaN, and some values will be a small number (4.156e-39). The proportion of each seems to depend deterministically on the size of the input tensor, but for a given input size, the proportion of each will vary from one machine to another.  The NaNs and small valued numbers appear in a periodic pattern in the output tensor.\r\n\r\nThe bug doesn't manifest if everything is done on GPU.\r\n\r\n## Code example\r\n\r\n### Code\r\n\r\n```\r\nNs = [10, 100, 1000, 10000]\r\n\r\nfor N in Ns:\r\n\r\n    nans_32_bit = (torch.zeros(N) / 0)\r\n    nans_64_bit = (nans_32_bit.type(torch.DoubleTensor))\r\n\r\n    print('Input: tensor of size N={} containing only NaN'.format(N))\r\n\r\n    post_sigmoid_32_bit = torch.sigmoid(nans_32_bit)\r\n    post_sigmoid_64_bit = torch.sigmoid(nans_64_bit)\r\n\r\n    proportion_nan_32_bit = torch.mean(torch.isnan(post_sigmoid_32_bit).type(torch.FloatTensor))\r\n    proportion_nan_64_bit = torch.mean(torch.isnan(post_sigmoid_64_bit).type(torch.FloatTensor))\r\n\r\n    print('After sigmoid:')\r\n    print('Proportion NaN in result with 32 bit input: {:.3f}'.format(proportion_nan_32_bit))\r\n    print('Proportion NaN in result with 64 bit input: {:.3f}\\n'.format(proportion_nan_64_bit))\r\n```\r\n\r\n### Code output\r\n\r\nInput: tensor of size N=10 containing only NaN\r\nAfter sigmoid:\r\nProportion NaN in result with 32 bit input: 1.000\r\nProportion NaN in result with 64 bit input: 1.000\r\n\r\nInput: tensor of size N=100 containing only NaN\r\nAfter sigmoid:\r\nProportion NaN in result with 32 bit input: 0.360\r\nProportion NaN in result with 64 bit input: 1.000\r\n\r\nInput: tensor of size N=1000 containing only NaN\r\nAfter sigmoid:\r\nProportion NaN in result with 32 bit input: 0.040\r\nProportion NaN in result with 64 bit input: 1.000\r\n\r\nInput: tensor of size N=10000 containing only NaN\r\nAfter sigmoid:\r\nProportion NaN in result with 32 bit input: 0.002\r\nProportion NaN in result with 64 bit input: 1.000\r\n\r\n\r\n## System Info\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.1.85\r\nGPU models and configuration: GPU 0: GeForce GTX 1050\r\nNvidia driver version: 390.59\r\ncuDNN version: 7102\r\n\r\nVersions of relevant libraries:\r\n[pip] 18.1\r\n[conda] Could not collect\r\n"}