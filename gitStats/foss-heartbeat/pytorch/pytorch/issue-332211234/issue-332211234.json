{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8465", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8465/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8465/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8465/events", "html_url": "https://github.com/pytorch/pytorch/issues/8465", "id": 332211234, "node_id": "MDU6SXNzdWUzMzIyMTEyMzQ=", "number": 8465, "title": "model with weight_norm crashed when using nn.DataParallel", "user": {"login": "YuJiang01", "id": 7904758, "node_id": "MDQ6VXNlcjc5MDQ3NTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7904758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YuJiang01", "html_url": "https://github.com/YuJiang01", "followers_url": "https://api.github.com/users/YuJiang01/followers", "following_url": "https://api.github.com/users/YuJiang01/following{/other_user}", "gists_url": "https://api.github.com/users/YuJiang01/gists{/gist_id}", "starred_url": "https://api.github.com/users/YuJiang01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YuJiang01/subscriptions", "organizations_url": "https://api.github.com/users/YuJiang01/orgs", "repos_url": "https://api.github.com/users/YuJiang01/repos", "events_url": "https://api.github.com/users/YuJiang01/events{/privacy}", "received_events_url": "https://api.github.com/users/YuJiang01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-14T00:33:52Z", "updated_at": "2018-08-06T21:48:44Z", "closed_at": "2018-06-14T01:03:24Z", "author_association": "NONE", "body_html": "<pre><code>import torch\nimport torch.nn as nn\nfrom torch.nn.utils.weight_norm import weight_norm\n\nclass LinearWn(nn.Module):\n    def __init__(self):\n        super(LinearWn, self).__init__()\n        layers = [weight_norm(nn.Linear(100, 10), dim=None), nn.ReLU()]\n\n        self.main = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.main(x)\n\n\ntorch.manual_seed(1)\nmodel = LinearWn()\nmodel = model.cuda()\nmodel = nn.DataParallel(model)\n\ndata = torch.rand(2000, 100).cuda()\n\nres = model(data)\n\nres.sum().backward()\n</code></pre>\n<p>error message:<br>\nTraceback (most recent call last):<br>\nFile \"/private/home/tinayujiang/VQA/vqa_suite/toy_weight_norm.py\", line 24, in <br>\nres = model(data)<br>\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in <strong>call</strong><br>\nresult = self.forward(*input, **kwargs)<br>\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward<br>\nreplicas = self.replicate(self.module, self.device_ids[:len(inputs)])<br>\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate<br>\nreturn replicate(module, device_ids)<br>\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate<br>\nparam_copies = Broadcast.apply(devices, *params)<br>\nRuntimeError: slice() cannot be applied to a 0-dim tensor.</p>", "body_text": "import torch\nimport torch.nn as nn\nfrom torch.nn.utils.weight_norm import weight_norm\n\nclass LinearWn(nn.Module):\n    def __init__(self):\n        super(LinearWn, self).__init__()\n        layers = [weight_norm(nn.Linear(100, 10), dim=None), nn.ReLU()]\n\n        self.main = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.main(x)\n\n\ntorch.manual_seed(1)\nmodel = LinearWn()\nmodel = model.cuda()\nmodel = nn.DataParallel(model)\n\ndata = torch.rand(2000, 100).cuda()\n\nres = model(data)\n\nres.sum().backward()\n\nerror message:\nTraceback (most recent call last):\nFile \"/private/home/tinayujiang/VQA/vqa_suite/toy_weight_norm.py\", line 24, in \nres = model(data)\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in call\nresult = self.forward(*input, **kwargs)\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward\nreplicas = self.replicate(self.module, self.device_ids[:len(inputs)])\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate\nreturn replicate(module, device_ids)\nFile \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\nparam_copies = Broadcast.apply(devices, *params)\nRuntimeError: slice() cannot be applied to a 0-dim tensor.", "body": "```\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.nn.utils.weight_norm import weight_norm\r\n\r\nclass LinearWn(nn.Module):\r\n    def __init__(self):\r\n        super(LinearWn, self).__init__()\r\n        layers = [weight_norm(nn.Linear(100, 10), dim=None), nn.ReLU()]\r\n\r\n        self.main = nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        return self.main(x)\r\n\r\n\r\ntorch.manual_seed(1)\r\nmodel = LinearWn()\r\nmodel = model.cuda()\r\nmodel = nn.DataParallel(model)\r\n\r\ndata = torch.rand(2000, 100).cuda()\r\n\r\nres = model(data)\r\n\r\nres.sum().backward()\r\n```\r\n\r\nerror message:\r\nTraceback (most recent call last):\r\n  File \"/private/home/tinayujiang/VQA/vqa_suite/toy_weight_norm.py\", line 24, in <module>\r\n    res = model(data)\r\n  File \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward\r\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n  File \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate\r\n    return replicate(module, device_ids)\r\n  File \"/private/home/tinayujiang/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\r\n    param_copies = Broadcast.apply(devices, *params)\r\nRuntimeError: slice() cannot be applied to a 0-dim tensor.\r\n\r\n\r\n"}