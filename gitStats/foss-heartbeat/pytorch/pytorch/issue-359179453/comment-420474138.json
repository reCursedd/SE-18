{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/420474138", "html_url": "https://github.com/pytorch/pytorch/pull/11534#issuecomment-420474138", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11534", "id": 420474138, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMDQ3NDEzOA==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-12T00:49:40Z", "updated_at": "2018-09-12T00:50:02Z", "author_association": "MEMBER", "body_html": "<blockquote>\n<p>Speed is of no value if it crashes.</p>\n</blockquote>\n<p>Lack of (deterministically stack-overflow triggered) crashes in 0.01% of use cases is of no value if your library is 2x slower than other libraries in most other cases <g-emoji class=\"g-emoji\" alias=\"wink\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f609.png\">\ud83d\ude09</g-emoji></p>\n<blockquote>\n<p>And plenty of JITs block program execution on compilation.</p>\n</blockquote>\n<p>Fine, but this also happen once (or a few times), no matter how long does your program runs. This destruction happens <em>at every training step, over the whole duration of the program</em>.</p>\n<hr>\n<p>I didn't notice you change the dequeue for a vector. That sounds like a good idea, and would be a good improvement even for the older code, so it might be worth re-benchmarking against master + vector. Also, can you please post the same benchmark, but with a graph of low depth (to check how does the stack strategy perform compared to always using the heap).</p>", "body_text": "Speed is of no value if it crashes.\n\nLack of (deterministically stack-overflow triggered) crashes in 0.01% of use cases is of no value if your library is 2x slower than other libraries in most other cases \ud83d\ude09\n\nAnd plenty of JITs block program execution on compilation.\n\nFine, but this also happen once (or a few times), no matter how long does your program runs. This destruction happens at every training step, over the whole duration of the program.\n\nI didn't notice you change the dequeue for a vector. That sounds like a good idea, and would be a good improvement even for the older code, so it might be worth re-benchmarking against master + vector. Also, can you please post the same benchmark, but with a graph of low depth (to check how does the stack strategy perform compared to always using the heap).", "body": "> Speed is of no value if it crashes.\r\n\r\nLack of (deterministically stack-overflow triggered) crashes in 0.01% of use cases is of no value if your library is 2x slower than other libraries in most other cases \ud83d\ude09\r\n\r\n> And plenty of JITs block program execution on compilation.\r\n\r\nFine, but this also happen once (or a few times), no matter how long does your program runs. This destruction happens *at every training step, over the whole duration of the program*.\r\n\r\n---\r\n\r\nI didn't notice you change the dequeue for a vector. That sounds like a good idea, and would be a good improvement even for the older code, so it might be worth re-benchmarking against master + vector. Also, can you please post the same benchmark, but with a graph of low depth (to check how does the stack strategy perform compared to always using the heap)."}