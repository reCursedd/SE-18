{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/399131067", "html_url": "https://github.com/pytorch/pytorch/issues/8741#issuecomment-399131067", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8741", "id": 399131067, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTEzMTA2Nw==", "user": {"login": "0phoff", "id": 11853089, "node_id": "MDQ6VXNlcjExODUzMDg5", "avatar_url": "https://avatars3.githubusercontent.com/u/11853089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/0phoff", "html_url": "https://github.com/0phoff", "followers_url": "https://api.github.com/users/0phoff/followers", "following_url": "https://api.github.com/users/0phoff/following{/other_user}", "gists_url": "https://api.github.com/users/0phoff/gists{/gist_id}", "starred_url": "https://api.github.com/users/0phoff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/0phoff/subscriptions", "organizations_url": "https://api.github.com/users/0phoff/orgs", "repos_url": "https://api.github.com/users/0phoff/repos", "events_url": "https://api.github.com/users/0phoff/events{/privacy}", "received_events_url": "https://api.github.com/users/0phoff/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-21T14:50:02Z", "updated_at": "2018-06-21T14:50:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>But the point is I want to be able to continue training exactly where I left off, so this also means reloading the exact parameters of the optimizers/schedulers.</p>\n<p>Reinstantiating would mean I lose those params right?<br>\nImplementing a <code>to()</code> method would allow more freedom in saving and loading these weights. (eg. starting the training on one devices, and at a later stage continuing on a different one)</p>", "body_text": "But the point is I want to be able to continue training exactly where I left off, so this also means reloading the exact parameters of the optimizers/schedulers.\nReinstantiating would mean I lose those params right?\nImplementing a to() method would allow more freedom in saving and loading these weights. (eg. starting the training on one devices, and at a later stage continuing on a different one)", "body": "But the point is I want to be able to continue training exactly where I left off, so this also means reloading the exact parameters of the optimizers/schedulers.\r\n\r\nReinstantiating would mean I lose those params right?\r\nImplementing a `to()` method would allow more freedom in saving and loading these weights. (eg. starting the training on one devices, and at a later stage continuing on a different one)"}