{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/420498207", "html_url": "https://github.com/pytorch/pytorch/pull/11342#issuecomment-420498207", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11342", "id": 420498207, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMDQ5ODIwNw==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-12T03:15:50Z", "updated_at": "2018-09-12T03:15:50Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Yes, I think I agree that writing a storage sharing narrow seems difficult. It might be possible for coalesced tensors, if you only narrow a trailing dimension, but that seems like a limited enough case that we shouldn't bother.</p>\n<blockquote>\n<p>If there is an easy way to do Tensor newValues = self._values().masked_select(mask);<br>\nwhile preserving shared storage, let me know. Otherwise I think I'd have to rely on/enforce that the values tensor is contiguous, meaning indices must be sorted by the dimension being narrowed on.</p>\n</blockquote>\n<p>I don't see how your second sentence follows from the first.  There's no way to do a <code>masked_select</code> that preserves shared storage. But if you select the correct values for the indices in the narrow range, I don't see why they have to be <em>sorted</em>. You've already committed to doing an <code>O(n)</code> operation...</p>", "body_text": "Yes, I think I agree that writing a storage sharing narrow seems difficult. It might be possible for coalesced tensors, if you only narrow a trailing dimension, but that seems like a limited enough case that we shouldn't bother.\n\nIf there is an easy way to do Tensor newValues = self._values().masked_select(mask);\nwhile preserving shared storage, let me know. Otherwise I think I'd have to rely on/enforce that the values tensor is contiguous, meaning indices must be sorted by the dimension being narrowed on.\n\nI don't see how your second sentence follows from the first.  There's no way to do a masked_select that preserves shared storage. But if you select the correct values for the indices in the narrow range, I don't see why they have to be sorted. You've already committed to doing an O(n) operation...", "body": "Yes, I think I agree that writing a storage sharing narrow seems difficult. It might be possible for coalesced tensors, if you only narrow a trailing dimension, but that seems like a limited enough case that we shouldn't bother.\r\n\r\n> If there is an easy way to do Tensor newValues = self._values().masked_select(mask);\r\nwhile preserving shared storage, let me know. Otherwise I think I'd have to rely on/enforce that the values tensor is contiguous, meaning indices must be sorted by the dimension being narrowed on.\r\n\r\nI don't see how your second sentence follows from the first.  There's no way to do a `masked_select` that preserves shared storage. But if you select the correct values for the indices in the narrow range, I don't see why they have to be *sorted*. You've already committed to doing an `O(n)` operation..."}