{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/155932450", "pull_request_review_id": 82300167, "id": 155932450, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NTkzMjQ1MA==", "diff_hunk": "@@ -0,0 +1,89 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/NativeFunctions.h\"\n+#include \"ATen/WrapDimUtils.h\"\n+#include \"ATen/ExpandUtils.h\"\n+\n+#include <algorithm>\n+#include <functional>\n+#include <numeric>\n+#include <vector>\n+\n+namespace at { namespace native {\n+\n+std::tuple<Tensor, Tensor> stft(const Tensor& self, const int64_t frame_length,\n+                                const int64_t hop, const Tensor& window,\n+                                const int64_t pad_end) {\n+  #define REPR(SS) SS << \"stft(\" << self.type() << \"{\" << self.sizes() \\\n+                      << \"}, frame_length=\" << frame_length << \", hop=\" << hop \\\n+                      << \", window=\" << window.type() << \"{\" << window.sizes() \\\n+                      << \"}, pad_end=\" << pad_end << \")\"\n+  if (!at::isFloatingType(self.type().scalarType()) || self.dim() > 2) {\n+    std::ostringstream ss;\n+    REPR(ss) << \": expected a 1D or 2D tensor of floating types\";\n+    throw std::runtime_error(ss.str());\n+  }\n+  Tensor input = self;\n+  if (self.dim() == 1) {\n+    input = input.unsqueeze(0);\n+  }\n+  int64_t batch = input.size(0);\n+  int64_t len = input.size(1);\n+  if (frame_length <= 0 || frame_length > len) {\n+    std::ostringstream ss;\n+    REPR(ss) << \": expected 0 < frame_length < \" << len\n+             << \", but get frame_length=\" << frame_length;\n+    throw std::runtime_error(ss.str());\n+  }\n+  if (hop <= 0) {\n+    std::ostringstream ss;\n+    REPR(ss) << \" expected hop > 0, but get hop=\" << hop;\n+    throw std::runtime_error(ss.str());\n+  }\n+  if (window.defined() && (window.dim() != 1 || window.size(0) != frame_length)) {\n+    std::ostringstream ss;\n+    REPR(ss) << \": expected a 1D window tensor of size equal to \"\n+             << \"frame_length=\" << frame_length\n+             << \", but get window with size {\" << window.sizes() << \"}\";\n+    throw std::runtime_error(ss.str());\n+  }\n+  if (pad_end < 0) {\n+    std::ostringstream ss;\n+    REPR(ss) << \": expected pad_end >= 0, but get pad_end=\" << pad_end;\n+    throw std::runtime_error(ss.str());\n+  }\n+  #undef REPR\n+  // pad zeros\n+  if (pad_end != 0) {\n+    Tensor padded_input = self.type().zeros({batch, len + pad_end});\n+    padded_input.narrow(1, 0, len).copy_(input);\n+    input = padded_input;\n+    len += pad_end;\n+  }\n+  // build ft kernel\n+  // k[omega, t] = cos (2 pi omega t / N) - j sin (2 pi omega t / N)\n+  double N = static_cast<double>(frame_length);\n+  auto arange = self.type().arange(0, frame_length).unsqueeze_(1);\n+  auto arange_2d = arange.mm(arange.t()).mul_(M_PI * 2. / N);", "path": "aten/src/ATen/native/spectral_ops.cpp", "position": null, "original_position": 66, "commit_id": "87bdc6fb3644200d8c662f3dbc3b22e50ae6e4ca", "original_commit_id": "134730d085e028bbb23a94b7113b491a74224172", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "You can also use [`at::ger`](http://pytorch.org/docs/0.3.0/torch.html#torch.ger) to compute outer products.\r\n\r\nI'm a little confused by the scaling. `arange_2d` ends up being proportional to `N` because the multiplication by `1 / N` happens after the outer product. Is that correct?", "created_at": "2017-12-09T21:13:22Z", "updated_at": "2018-11-23T15:37:14Z", "html_url": "https://github.com/pytorch/pytorch/pull/4095#discussion_r155932450", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4095", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/155932450"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4095#discussion_r155932450"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4095"}}, "body_html": "<p>You can also use <a href=\"http://pytorch.org/docs/0.3.0/torch.html#torch.ger\" rel=\"nofollow\"><code>at::ger</code></a> to compute outer products.</p>\n<p>I'm a little confused by the scaling. <code>arange_2d</code> ends up being proportional to <code>N</code> because the multiplication by <code>1 / N</code> happens after the outer product. Is that correct?</p>", "body_text": "You can also use at::ger to compute outer products.\nI'm a little confused by the scaling. arange_2d ends up being proportional to N because the multiplication by 1 / N happens after the outer product. Is that correct?"}