{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2633", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2633/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2633/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2633/events", "html_url": "https://github.com/pytorch/pytorch/issues/2633", "id": 255371480, "node_id": "MDU6SXNzdWUyNTUzNzE0ODA=", "number": 2633, "title": "Combine Variable and Tensor APIs (Perform autograd directly on torch.Tensor)", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-09-05T18:44:26Z", "updated_at": "2018-04-12T03:25:15Z", "closed_at": "2018-02-28T00:40:50Z", "author_association": "MEMBER", "body_html": "<p>There are previous issues addressing this, but I want to write this up with a plan in a new issue.</p>\n<p>We should make <code>torch.Tensor</code> differentiable instead of having a wrapper <code>Variable</code> class. The Variable class adds conceptual overhead without sufficient benefit. It makes it harder for new users to adopt PyTorch by adding a second API which is similar but not exactly the same as Tensor.</p>\n<p>There are few prerequisites:</p>\n<ol>\n<li>Operations on <code>Variable</code>s need to be at least as fast as operations on <code>Tensor</code> (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"255359536\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2630\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2630/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2630\">#2630</a>)</li>\n<li>We need scalar support at the Python level (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"225700604\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1433\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1433/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1433\">#1433</a>)</li>\n</ol>\n<p>The <code>Variable</code> constructor will be deprecated and become a no-op.<br>\nThe <code>Variable.data</code> accessor will be deprecated and return a view that has requires_grad=False.<br>\nThe <code>torch.Tensor</code> constructors will take an optional keyword argument <code>requires_grad</code></p>\n<p>There will be a number of internal changes, but we shouldn't break most existing code:</p>\n<ol>\n<li>For performance reasons, we will no longer build up the graph of operations by default when <code>requires_grad=False</code> unless the operation uses stochastic variables. We'll use a context manager or global variable to enable graph creation.</li>\n<li>The new differentiable Tensor will need support all the operations currently on Tensor, including in-place and <code>out=</code> operations.</li>\n<li>In-place operations on leaf Variables which require_grad are not currently supported. In the new API, the tensor's value will be updated and it will remain a leaf node. (This is important for optimizers, which update leaf Variables in-place).</li>\n</ol>\n<p>There are probably a few other subtle differences between Tensor and Variable APIs. I'll update this issue as we address them.</p>\n<p>See also:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"224886304\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1384\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1384/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1384\">#1384</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"192655150\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/274\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/274/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/274\">#274</a></p>\n<h2>Failing Tests</h2>\n<ul>\n<li>test/test_autograd.py 23/738 # Greg will be fixing the tests, Tensor vs. Variable requires_grad</li>\n<li>test/test_cuda.py 2/1837  # Just test_broadcast from TestTorch</li>\n<li>test/test_dataloader.py OK</li>\n<li>test/test_distributed.py OK # error at top level</li>\n<li>test/test_distributions.py OK</li>\n<li>test/test_indexing.py OK</li>\n<li>test/test_jit.py OK</li>\n<li>test/test_legacy_nn.py OK</li>\n<li>test/test_multiprocessing.py OK</li>\n<li>test/test_nccl.py OK</li>\n<li>test/test_nn.py OK</li>\n<li>test/test_optim.py OK</li>\n<li>test/test_sparse.py 10/120 # missing sspaddmm, dsmm/mm, addmm</li>\n<li>test/test_torch.py 1/257 TestTorch.test_broadcast</li>\n<li>test/test_utils.py 2OK</li>\n</ul>", "body_text": "There are previous issues addressing this, but I want to write this up with a plan in a new issue.\nWe should make torch.Tensor differentiable instead of having a wrapper Variable class. The Variable class adds conceptual overhead without sufficient benefit. It makes it harder for new users to adopt PyTorch by adding a second API which is similar but not exactly the same as Tensor.\nThere are few prerequisites:\n\nOperations on Variables need to be at least as fast as operations on Tensor (#2630)\nWe need scalar support at the Python level (#1433)\n\nThe Variable constructor will be deprecated and become a no-op.\nThe Variable.data accessor will be deprecated and return a view that has requires_grad=False.\nThe torch.Tensor constructors will take an optional keyword argument requires_grad\nThere will be a number of internal changes, but we shouldn't break most existing code:\n\nFor performance reasons, we will no longer build up the graph of operations by default when requires_grad=False unless the operation uses stochastic variables. We'll use a context manager or global variable to enable graph creation.\nThe new differentiable Tensor will need support all the operations currently on Tensor, including in-place and out= operations.\nIn-place operations on leaf Variables which require_grad are not currently supported. In the new API, the tensor's value will be updated and it will remain a leaf node. (This is important for optimizers, which update leaf Variables in-place).\n\nThere are probably a few other subtle differences between Tensor and Variable APIs. I'll update this issue as we address them.\nSee also:\n#1384\n#274\nFailing Tests\n\ntest/test_autograd.py 23/738 # Greg will be fixing the tests, Tensor vs. Variable requires_grad\ntest/test_cuda.py 2/1837  # Just test_broadcast from TestTorch\ntest/test_dataloader.py OK\ntest/test_distributed.py OK # error at top level\ntest/test_distributions.py OK\ntest/test_indexing.py OK\ntest/test_jit.py OK\ntest/test_legacy_nn.py OK\ntest/test_multiprocessing.py OK\ntest/test_nccl.py OK\ntest/test_nn.py OK\ntest/test_optim.py OK\ntest/test_sparse.py 10/120 # missing sspaddmm, dsmm/mm, addmm\ntest/test_torch.py 1/257 TestTorch.test_broadcast\ntest/test_utils.py 2OK", "body": "There are previous issues addressing this, but I want to write this up with a plan in a new issue.\r\n\r\nWe should make `torch.Tensor` differentiable instead of having a wrapper `Variable` class. The Variable class adds conceptual overhead without sufficient benefit. It makes it harder for new users to adopt PyTorch by adding a second API which is similar but not exactly the same as Tensor.\r\n\r\nThere are few prerequisites:\r\n\r\n1. Operations on `Variable`s need to be at least as fast as operations on `Tensor` (https://github.com/pytorch/pytorch/issues/2630)\r\n2. We need scalar support at the Python level (https://github.com/pytorch/pytorch/issues/1433)\r\n\r\nThe `Variable` constructor will be deprecated and become a no-op.\r\nThe `Variable.data` accessor will be deprecated and return a view that has requires_grad=False.\r\nThe `torch.Tensor` constructors will take an optional keyword argument `requires_grad`\r\n\r\nThere will be a number of internal changes, but we shouldn't break most existing code:\r\n\r\n1. For performance reasons, we will no longer build up the graph of operations by default when `requires_grad=False` unless the operation uses stochastic variables. We'll use a context manager or global variable to enable graph creation.\r\n2. The new differentiable Tensor will need support all the operations currently on Tensor, including in-place and `out=` operations.\r\n3. In-place operations on leaf Variables which require_grad are not currently supported. In the new API, the tensor's value will be updated and it will remain a leaf node. (This is important for optimizers, which update leaf Variables in-place).\r\n\r\nThere are probably a few other subtle differences between Tensor and Variable APIs. I'll update this issue as we address them.\r\n\r\nSee also:\r\nhttps://github.com/pytorch/pytorch/issues/1384\r\nhttps://github.com/pytorch/pytorch/issues/274\r\n\r\n## Failing Tests\r\n\r\n- test/test_autograd.py 23/738 # Greg will be fixing the tests, Tensor vs. Variable requires_grad\r\n- test/test_cuda.py 2/1837  # Just test_broadcast from TestTorch\r\n- test/test_dataloader.py OK\r\n- test/test_distributed.py OK # error at top level\r\n- test/test_distributions.py OK\r\n- test/test_indexing.py OK\r\n- test/test_jit.py OK\r\n- test/test_legacy_nn.py OK\r\n- test/test_multiprocessing.py OK\r\n- test/test_nccl.py OK\r\n- test/test_nn.py OK\r\n- test/test_optim.py OK\r\n- test/test_sparse.py 10/120 # missing sspaddmm, dsmm/mm, addmm\r\n- test/test_torch.py 1/257 TestTorch.test_broadcast\r\n- test/test_utils.py 2OK \r\n"}