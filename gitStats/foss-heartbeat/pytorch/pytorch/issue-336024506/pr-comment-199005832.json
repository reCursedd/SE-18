{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199005832", "pull_request_review_id": 133044201, "id": 199005832, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5OTAwNTgzMg==", "diff_hunk": "@@ -0,0 +1,76 @@\n+#include \"BatchTensor.h\"\n+\n+namespace torch { namespace jit {\n+\n+BatchTensor::BatchTensor(at::Tensor data, at::Tensor mask, at::Tensor dims){\n+  if(data.dim() != mask.dim() || mask.dim() != dims.size(0) + 1){\n+    throw std::runtime_error(\"malformed MaskedBatch with data.dim(): \"\n+      + std::to_string(data.dim()) + \", mask.dim(): \" + std::to_string(mask.dim())\n+      + \", dims.size(0): \" + std::to_string(dims.size(0)));\n+  }\n+  this->data = data;\n+  this->mask = mask;\n+  this->dims = dims;\n+}\n+\n+BatchTensor::BatchTensor(const std::vector<at::Tensor> datalist, at::Tensor dims) {\n+  auto bs = datalist.size();\n+  std::vector<int64_t> sizes(dims.size(0) + 1, 0), mask_sizes(dims.size(0) + 1, 0);\n+  sizes[0] = bs;\n+  mask_sizes[0] = bs;\n+  for(int64_t i = 1; i < dims.size(0) + 1; i++){\n+    for(auto x : datalist){\n+      sizes[i] = std::max(sizes[i], x.size(i));\n+    }\n+    mask_sizes[i] = *dims[i - 1].toByteData() ? sizes[i] : 1;\n+  }\n+  data = datalist[0].type().zeros(sizes);\n+  mask = datalist[0].type().toScalarType(at::kByte).zeros(mask_sizes);\n+  for(std::size_t i = 0; i < datalist.size(); i++){\n+    auto data_item = data.narrow(0, i, 1);\n+    auto mask_item = mask.narrow(0, i, 1);\n+    for(int64_t j = 0; j < dims.size(0); j++){\n+      if(*dims[j].toByteData()){\n+        data_item = data_item.narrow(j + 1, 0, datalist[i].size(j + 1));\n+        mask_item = mask_item.narrow(j + 1, 0, datalist[i].size(j + 1));\n+      }\n+    }\n+    data_item += datalist[i];\n+    mask_item.fill_(1);\n+  }\n+  this->dims = dims;\n+}\n+\n+std::vector<at::Tensor> BatchTensor::examples() {\n+  std::vector<at::Tensor> result;\n+  // calculate number of valid entries in dth dimension of data\n+  auto mask_sum = [](at::Tensor data, int d) -> int64_t{\n+    data = data.sum(d, /*keepdim=*/true);\n+    while(data.dim() >= 1)\n+      data = data[0];\n+    return *data.toLongData();\n+  };\n+  for(int64_t i = 0; i < data.size(0); i++){\n+    auto data_tmp = data.narrow(0, i, 1);\n+    for(int64_t d = 0; d < dims.size(0); d++){\n+      if(*dims[d].toByteData()){\n+        data_tmp = data_tmp.narrow(d + 1, 0, mask_sum(mask[i], d));\n+      }\n+    }\n+    result.push_back(data_tmp);\n+  }\n+  return result;\n+}\n+\n+void initBatchTensorBindings(PyObject* module) {\n+  auto m = py::handle(module).cast<py::module>();\n+  py::class_<BatchTensor>(m, \"BatchTensor\")\n+      .def(py::init<at::Tensor, at::Tensor, at::Tensor>())\n+      .def(py::init<std::vector<at::Tensor>, at::Tensor>())\n+      .def(\"examples\", &BatchTensor::examples)\n+      .def(\"get_data\", &BatchTensor::getData)", "path": "torch/csrc/jit/batched/BatchTensor.cpp", "position": null, "original_position": 71, "commit_id": "d2fe9e89e99dd664c9c00d706cc551a0a741e5cc", "original_commit_id": "3fb9455f6c832d5bbbb710c0f033b53b43e22c10", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "style nit: in PyTorch we name C++ functions the way they appear in python. So we would have `BatchTensor::get_data`. This violates C++ style, but it is more important to be consistent across C++/Python than it is to follow C++ style.", "created_at": "2018-06-28T22:27:25Z", "updated_at": "2018-11-23T15:46:32Z", "html_url": "https://github.com/pytorch/pytorch/pull/8922#discussion_r199005832", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8922", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199005832"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8922#discussion_r199005832"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8922"}}, "body_html": "<p>style nit: in PyTorch we name C++ functions the way they appear in python. So we would have <code>BatchTensor::get_data</code>. This violates C++ style, but it is more important to be consistent across C++/Python than it is to follow C++ style.</p>", "body_text": "style nit: in PyTorch we name C++ functions the way they appear in python. So we would have BatchTensor::get_data. This violates C++ style, but it is more important to be consistent across C++/Python than it is to follow C++ style."}