{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7251", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7251/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7251/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7251/events", "html_url": "https://github.com/pytorch/pytorch/issues/7251", "id": 320023788, "node_id": "MDU6SXNzdWUzMjAwMjM3ODg=", "number": 7251, "title": "Inconsistency with .numpy()", "user": {"login": "markroxor", "id": 11366315, "node_id": "MDQ6VXNlcjExMzY2MzE1", "avatar_url": "https://avatars1.githubusercontent.com/u/11366315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markroxor", "html_url": "https://github.com/markroxor", "followers_url": "https://api.github.com/users/markroxor/followers", "following_url": "https://api.github.com/users/markroxor/following{/other_user}", "gists_url": "https://api.github.com/users/markroxor/gists{/gist_id}", "starred_url": "https://api.github.com/users/markroxor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markroxor/subscriptions", "organizations_url": "https://api.github.com/users/markroxor/orgs", "repos_url": "https://api.github.com/users/markroxor/repos", "events_url": "https://api.github.com/users/markroxor/events{/privacy}", "received_events_url": "https://api.github.com/users/markroxor/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-05-03T18:06:52Z", "updated_at": "2018-05-03T19:17:06Z", "closed_at": "2018-05-03T19:04:57Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>In the below code everything is same for both <code>Xtrain</code> and <code>X</code> except that <code>X</code> was initialized as a <code>ch.zeros</code> tensor and was later converted to numpy ndarray by using <code>X.numpy</code>. The principal components are different in both the scenarios provided that rest everything remains same.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch <span class=\"pl-k\">as</span> ch\n<span class=\"pl-k\">from</span> sklearn.decomposition <span class=\"pl-k\">import</span> <span class=\"pl-c1\">PCA</span>\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\nn <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\nn_dim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\n\nX <span class=\"pl-k\">=</span> ch.zeros(n, n_dim)\nm <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\nc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\nd <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n):\n    X[i,<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> i\n    X[i,<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> m<span class=\"pl-k\">*</span>i <span class=\"pl-k\">+</span> c\n    X[i,<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">=</span> (d <span class=\"pl-k\">-</span> <span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span>X[i,<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">-</span> <span class=\"pl-c1\">3</span><span class=\"pl-k\">*</span>X[i,<span class=\"pl-c1\">1</span>])<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span>\n\nX <span class=\"pl-k\">=</span> X.numpy()\n\n\nXtrain <span class=\"pl-k\">=</span> np.zeros([n, n_dim])\nm <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\nc <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\nd <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(n):\n    Xtrain[i,<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> i\n    Xtrain[i,<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">=</span> m<span class=\"pl-k\">*</span>i <span class=\"pl-k\">+</span> c\n    Xtrain[i,<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">=</span> (d <span class=\"pl-k\">-</span> <span class=\"pl-c1\">2</span><span class=\"pl-k\">*</span>Xtrain[i,<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">-</span> <span class=\"pl-c1\">3</span><span class=\"pl-k\">*</span>Xtrain[i,<span class=\"pl-c1\">1</span>])<span class=\"pl-k\">/</span><span class=\"pl-c1\">2</span>\n\n<span class=\"pl-c1\">print</span>(X, <span class=\"pl-c1\">type</span>(X))\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> (array([[  <span class=\"pl-c1\">0</span>. ,   <span class=\"pl-c1\">2</span>. ,  <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.5</span>],\n       [  <span class=\"pl-c1\">1</span>. ,   <span class=\"pl-c1\">7</span>. ,  <span class=\"pl-k\">-</span><span class=\"pl-c1\">9</span>. ],\n       [  <span class=\"pl-c1\">2</span>. ,  <span class=\"pl-c1\">12</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">17.5</span>],\n       [  <span class=\"pl-c1\">3</span>. ,  <span class=\"pl-c1\">17</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">26</span>. ],\n       [  <span class=\"pl-c1\">4</span>. ,  <span class=\"pl-c1\">22</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">34.5</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>float32), <span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">type</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>numpy.ndarray<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">&gt;</span>)\n<span class=\"pl-c1\">print</span>(Xtrain, <span class=\"pl-c1\">type</span>(Xtrain))\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> (array([[  <span class=\"pl-c1\">0</span>. ,   <span class=\"pl-c1\">2</span>. ,  <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.5</span>],\n       [  <span class=\"pl-c1\">1</span>. ,   <span class=\"pl-c1\">7</span>. ,  <span class=\"pl-k\">-</span><span class=\"pl-c1\">9</span>. ],\n       [  <span class=\"pl-c1\">2</span>. ,  <span class=\"pl-c1\">12</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">17.5</span>],\n       [  <span class=\"pl-c1\">3</span>. ,  <span class=\"pl-c1\">17</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">26</span>. ],\n       [  <span class=\"pl-c1\">4</span>. ,  <span class=\"pl-c1\">22</span>. , <span class=\"pl-k\">-</span><span class=\"pl-c1\">34.5</span>]]), <span class=\"pl-k\">&lt;</span><span class=\"pl-c1\">type</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>numpy.ndarray<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">&gt;</span>)\n<span class=\"pl-c1\">print</span>(np.allclose(Xtrain, X))\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">True</span>\npca_x <span class=\"pl-k\">=</span> PCA(<span class=\"pl-v\">n_components</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\npca_x.fit(X)\n\npca_xtrain <span class=\"pl-k\">=</span> PCA(<span class=\"pl-v\">n_components</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\npca_xtrain.fit(Xtrain)\n\n<span class=\"pl-c1\">print</span>(pca_x.components_)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> [[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0088666e-01</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0443327e-01</span>  <span class=\"pl-c1\">8.5753661e-01</span>]\n [<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.8938619e-02</span>  <span class=\"pl-c1\">8.6345071e-01</span>  <span class=\"pl-c1\">5.0097811e-01</span>]\n [<span class=\"pl-k\">-</span><span class=\"pl-c1\">9.9315059e-01</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">7.4505806e-09</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.1684125e-01</span>]]\n<span class=\"pl-c1\">print</span>(pca_xtrain.components_)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> [[<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.10088665</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.50443327</span>  <span class=\"pl-c1\">0.85753656</span>]\n [<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.82430398</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.44025326</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.35594945</span>]\n [<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.55708601</span>  <span class=\"pl-c1\">0.74278135</span>  <span class=\"pl-c1\">0.37139068</span>]]</pre></div>\n<h2>System Info</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.3.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: Could not collect</p>\n<p>OS: Ubuntu 18.04 LTS<br>\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0<br>\nCMake version: version 3.9.1</p>\n<p>Python version: 2.7<br>\nIs CUDA available: No<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration: GPU 0: GeForce GTX 1060 3GB<br>\nNvidia driver version: 390.48<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.5<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a<br>\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-3f9a723f.so.6.0.21</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.14.3)<br>\n[pip] torch (0.3.1)<br>\n[pip] torchvision (0.2.0)<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nIn the below code everything is same for both Xtrain and X except that X was initialized as a ch.zeros tensor and was later converted to numpy ndarray by using X.numpy. The principal components are different in both the scenarios provided that rest everything remains same.\nCode example\nimport torch as ch\nfrom sklearn.decomposition import PCA\nimport numpy as np\nn = 5\nn_dim = 3\n\nX = ch.zeros(n, n_dim)\nm = 5\nc = 2\nd = 5\nfor i in range(n):\n    X[i,0] = i\n    X[i,1] = m*i + c\n    X[i,2] = (d - 2*X[i,0] - 3*X[i,1])/2\n\nX = X.numpy()\n\n\nXtrain = np.zeros([n, n_dim])\nm = 5\nc = 2\nd = 5\nfor i in range(n):\n    Xtrain[i,0] = i\n    Xtrain[i,1] = m*i + c\n    Xtrain[i,2] = (d - 2*Xtrain[i,0] - 3*Xtrain[i,1])/2\n\nprint(X, type(X))\n>>> (array([[  0. ,   2. ,  -0.5],\n       [  1. ,   7. ,  -9. ],\n       [  2. ,  12. , -17.5],\n       [  3. ,  17. , -26. ],\n       [  4. ,  22. , -34.5]], dtype=float32), <type 'numpy.ndarray'>)\nprint(Xtrain, type(Xtrain))\n>>> (array([[  0. ,   2. ,  -0.5],\n       [  1. ,   7. ,  -9. ],\n       [  2. ,  12. , -17.5],\n       [  3. ,  17. , -26. ],\n       [  4. ,  22. , -34.5]]), <type 'numpy.ndarray'>)\nprint(np.allclose(Xtrain, X))\n>>> True\npca_x = PCA(n_components=3)\npca_x.fit(X)\n\npca_xtrain = PCA(n_components=3)\npca_xtrain.fit(Xtrain)\n\nprint(pca_x.components_)\n>>> [[-1.0088666e-01 -5.0443327e-01  8.5753661e-01]\n [-5.8938619e-02  8.6345071e-01  5.0097811e-01]\n [-9.9315059e-01 -7.4505806e-09 -1.1684125e-01]]\nprint(pca_xtrain.components_)\n>>> [[-0.10088665 -0.50443327  0.85753656]\n [-0.82430398 -0.44025326 -0.35594945]\n [-0.55708601  0.74278135  0.37139068]]\nSystem Info\nCollecting environment information...\nPyTorch version: 0.3.1\nIs debug build: No\nCUDA used to build PyTorch: Could not collect\nOS: Ubuntu 18.04 LTS\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\nCMake version: version 3.9.1\nPython version: 2.7\nIs CUDA available: No\nCUDA runtime version: Could not collect\nGPU models and configuration: GPU 0: GeForce GTX 1060 3GB\nNvidia driver version: 390.48\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.5\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-3f9a723f.so.6.0.21\nVersions of relevant libraries:\n[pip] numpy (1.14.3)\n[pip] torch (0.3.1)\n[pip] torchvision (0.2.0)\n[conda] Could not collect", "body": "## Issue description\r\nIn the below code everything is same for both `Xtrain` and `X` except that `X` was initialized as a `ch.zeros` tensor and was later converted to numpy ndarray by using `X.numpy`. The principal components are different in both the scenarios provided that rest everything remains same.\r\n\r\n## Code example\r\n\r\n```python\r\nimport torch as ch\r\nfrom sklearn.decomposition import PCA\r\nimport numpy as np\r\nn = 5\r\nn_dim = 3\r\n\r\nX = ch.zeros(n, n_dim)\r\nm = 5\r\nc = 2\r\nd = 5\r\nfor i in range(n):\r\n    X[i,0] = i\r\n    X[i,1] = m*i + c\r\n    X[i,2] = (d - 2*X[i,0] - 3*X[i,1])/2\r\n\r\nX = X.numpy()\r\n\r\n\r\nXtrain = np.zeros([n, n_dim])\r\nm = 5\r\nc = 2\r\nd = 5\r\nfor i in range(n):\r\n    Xtrain[i,0] = i\r\n    Xtrain[i,1] = m*i + c\r\n    Xtrain[i,2] = (d - 2*Xtrain[i,0] - 3*Xtrain[i,1])/2\r\n\r\nprint(X, type(X))\r\n>>> (array([[  0. ,   2. ,  -0.5],\r\n       [  1. ,   7. ,  -9. ],\r\n       [  2. ,  12. , -17.5],\r\n       [  3. ,  17. , -26. ],\r\n       [  4. ,  22. , -34.5]], dtype=float32), <type 'numpy.ndarray'>)\r\nprint(Xtrain, type(Xtrain))\r\n>>> (array([[  0. ,   2. ,  -0.5],\r\n       [  1. ,   7. ,  -9. ],\r\n       [  2. ,  12. , -17.5],\r\n       [  3. ,  17. , -26. ],\r\n       [  4. ,  22. , -34.5]]), <type 'numpy.ndarray'>)\r\nprint(np.allclose(Xtrain, X))\r\n>>> True\r\npca_x = PCA(n_components=3)\r\npca_x.fit(X)\r\n\r\npca_xtrain = PCA(n_components=3)\r\npca_xtrain.fit(Xtrain)\r\n\r\nprint(pca_x.components_)\r\n>>> [[-1.0088666e-01 -5.0443327e-01  8.5753661e-01]\r\n [-5.8938619e-02  8.6345071e-01  5.0097811e-01]\r\n [-9.9315059e-01 -7.4505806e-09 -1.1684125e-01]]\r\nprint(pca_xtrain.components_)\r\n>>> [[-0.10088665 -0.50443327  0.85753656]\r\n [-0.82430398 -0.44025326 -0.35594945]\r\n [-0.55708601  0.74278135  0.37139068]]\r\n```\r\n\r\n## System Info\r\nCollecting environment information...\r\nPyTorch version: 0.3.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: Could not collect\r\n\r\nOS: Ubuntu 18.04 LTS\r\nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\nCMake version: version 3.9.1\r\n\r\nPython version: 2.7\r\nIs CUDA available: No\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1060 3GB\r\nNvidia driver version: 390.48\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.6.0.21\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.5\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\r\n/usr/local/lib/python2.7/dist-packages/torch/lib/libcudnn-3f9a723f.so.6.0.21\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.14.3)\r\n[pip] torch (0.3.1)\r\n[pip] torchvision (0.2.0)\r\n[conda] Could not collect\r\n"}