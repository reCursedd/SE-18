{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/413105962", "html_url": "https://github.com/pytorch/pytorch/pull/8371#issuecomment-413105962", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8371", "id": 413105962, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzEwNTk2Mg==", "user": {"login": "bombs-kim", "id": 11001573, "node_id": "MDQ6VXNlcjExMDAxNTcz", "avatar_url": "https://avatars2.githubusercontent.com/u/11001573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bombs-kim", "html_url": "https://github.com/bombs-kim", "followers_url": "https://api.github.com/users/bombs-kim/followers", "following_url": "https://api.github.com/users/bombs-kim/following{/other_user}", "gists_url": "https://api.github.com/users/bombs-kim/gists{/gist_id}", "starred_url": "https://api.github.com/users/bombs-kim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bombs-kim/subscriptions", "organizations_url": "https://api.github.com/users/bombs-kim/orgs", "repos_url": "https://api.github.com/users/bombs-kim/repos", "events_url": "https://api.github.com/users/bombs-kim/events{/privacy}", "received_events_url": "https://api.github.com/users/bombs-kim/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-15T06:27:22Z", "updated_at": "2018-08-17T00:03:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> I see. <strong>Replicating a dataset by making each epoch much longer</strong> sounds promising. Although this doesn't reduce time to first batch, the cost will be amortized effectively by following batches. Thanks for your advice(I hope <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3028543\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Randl\">@Randl</a> agrees on it, too).</p>\n<p>I also agrees that there are many challenges to having the work granularity be samples instead of mini-batches, and that's why I came up with the second approach.</p>\n<p>Regarding \"breaking determinism\" thing, however, I think you have a wrong assumption. I think <code>DataSet</code> should be the one which is responsible for reproducibility, not <code>DataLoader</code> or <code>DataLoaderIter</code>. I pointed it out at this <a href=\"https://github.com/pytorch/pytorch/pull/4640\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4640/hovercard\">PR</a>. Actually only my first approach was related to this issue, and the second approach can be implemented either way and it's a bit off-topic at this point. If you like, we can continue the discussion at that PR.</p>\n<p>I think this PR is not needed anymore and I am happy to have this PR closed.</p>", "body_text": "@colesbury I see. Replicating a dataset by making each epoch much longer sounds promising. Although this doesn't reduce time to first batch, the cost will be amortized effectively by following batches. Thanks for your advice(I hope @Randl agrees on it, too).\nI also agrees that there are many challenges to having the work granularity be samples instead of mini-batches, and that's why I came up with the second approach.\nRegarding \"breaking determinism\" thing, however, I think you have a wrong assumption. I think DataSet should be the one which is responsible for reproducibility, not DataLoader or DataLoaderIter. I pointed it out at this PR. Actually only my first approach was related to this issue, and the second approach can be implemented either way and it's a bit off-topic at this point. If you like, we can continue the discussion at that PR.\nI think this PR is not needed anymore and I am happy to have this PR closed.", "body": "@colesbury I see. **Replicating a dataset by making each epoch much longer** sounds promising. Although this doesn't reduce time to first batch, the cost will be amortized effectively by following batches. Thanks for your advice(I hope @Randl agrees on it, too).\r\n\r\nI also agrees that there are many challenges to having the work granularity be samples instead of mini-batches, and that's why I came up with the second approach.\r\n\r\nRegarding \"breaking determinism\" thing, however, I think you have a wrong assumption. I think `DataSet` should be the one which is responsible for reproducibility, not `DataLoader` or `DataLoaderIter`. I pointed it out at this [PR](https://github.com/pytorch/pytorch/pull/4640). Actually only my first approach was related to this issue, and the second approach can be implemented either way and it's a bit off-topic at this point. If you like, we can continue the discussion at that PR.\r\n\r\nI think this PR is not needed anymore and I am happy to have this PR closed.\r\n\r\n"}