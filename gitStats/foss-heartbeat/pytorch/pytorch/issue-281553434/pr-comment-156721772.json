{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/156721772", "pull_request_review_id": 83246462, "id": 156721772, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NjcyMTc3Mg==", "diff_hunk": "@@ -74,4 +74,15 @@ cudaStream_t Context::getCurrentCUDAStream() const {\n }\n #endif\n \n+int64_t Context::current_device() const {\n+#if AT_CUDA_ENABLED()\n+  int device;\n+  cudaError_t err = cudaGetDevice(&device);\n+  if (err == cudaSuccess) {", "path": "aten/src/ATen/Context.cpp", "position": 8, "original_position": 8, "commit_id": "ddae27e99e428d3a90a94f9f4c170412bc2e0089", "original_commit_id": "9d37eb7f448cf29ec288c8f8ffa9b3fec223b733", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "I want the behavior for no GPUs to match the behavior for compiling without CUDA support. So that means both cases should return the same value or both cases should throw. In general, having these functions be safe to call in a context without CUDA is more useful than throwing exceptions.", "created_at": "2017-12-13T17:08:27Z", "updated_at": "2018-11-23T15:37:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/4139#discussion_r156721772", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4139", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/156721772"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4139#discussion_r156721772"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4139"}}, "body_html": "<p>I want the behavior for no GPUs to match the behavior for compiling without CUDA support. So that means both cases should return the same value or both cases should throw. In general, having these functions be safe to call in a context without CUDA is more useful than throwing exceptions.</p>", "body_text": "I want the behavior for no GPUs to match the behavior for compiling without CUDA support. So that means both cases should return the same value or both cases should throw. In general, having these functions be safe to call in a context without CUDA is more useful than throwing exceptions.", "in_reply_to_id": 156718243}