{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148474510", "pull_request_review_id": 73704858, "id": 148474510, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0ODQ3NDUxMA==", "diff_hunk": "@@ -0,0 +1,173 @@\n+#pragma once\n+\n+#include \"../DataChannel.hpp\"\n+#include \"DataChannelUtils.hpp\"\n+\n+#include <nccl.h>\n+\n+#include <utility>\n+#include <memory>\n+#include <string>\n+#include <unordered_map>\n+#include <vector>\n+\n+\n+#define NCCL_CHECK(cmd) do {                                  \\\n+  ncclResult_t error = cmd;                                   \\\n+  if (error != ncclSuccess) {                                 \\\n+    std::string err = \"NCCL error in: \" +                     \\\n+                      std::string(__FILE__) + \":\" +           \\\n+                      std::to_string(__LINE__) + \", \" +       \\\n+                      std::string(ncclGetErrorString(error)); \\\n+    throw std::runtime_error(err);                            \\\n+  }                                                           \\\n+} while (0)\n+\n+\n+namespace thd {\n+\n+struct DataChannelNccl : DataChannel {\n+  struct RequestNccl : DataChannel::Request {\n+\n+    RequestNccl(QueueWorker::Request&& request);\n+    virtual ~RequestNccl();\n+\n+    virtual bool isCompleted() override;\n+    virtual void wait() override;\n+\n+  private:\n+    QueueWorker::Request _request;\n+  };\n+\n+  DataChannelNccl(InitMethod::Config config, int timeout = -1);\n+  virtual ~DataChannelNccl();\n+\n+  bool init() override;\n+  void destroy() override;\n+\n+  rank_type getRank() override;\n+  rank_type getNumProcesses() override;\n+\n+  void allReduce(std::vector<at::Tensor>& input,\n+                 std::vector<at::Tensor>& output,\n+                 THDReduceOp operation,\n+                 THDGroup = THDGroupWORLD) override;\n+\n+  void allReduce(at::Tensor& data,\n+                 THDReduceOp operation,\n+                 THDGroup groupId = THDGroupWORLD) override;\n+\n+  void allGather(std::vector<at::Tensor>& input,\n+                 std::vector<at::Tensor>& output,\n+                 THDGroup groupId = THDGroupWORLD) override;\n+\n+  void allGather(std::vector<at::Tensor>& output,\n+                 at::Tensor& input,\n+                 THDGroup groupId = THDGroupWORLD) override;\n+\n+  void reduce(std::vector<at::Tensor>& input,\n+              THDReduceOp operation,\n+              rank_type dstRank,\n+              THDGroup groupId = THDGroupWORLD) override;\n+\n+  void reduce(at::Tensor& data,\n+              THDReduceOp operation,\n+              rank_type dstRank,\n+              THDGroup groupId = THDGroupWORLD) override;\n+\n+  void broadcast(std::vector<at::Tensor>& data,\n+                 rank_type srcRank,\n+                 THDGroup groupId = THDGroupWORLD) override;\n+\n+  void broadcast(at::Tensor& data,\n+                 rank_type srcRank,\n+                 THDGroup groupId = THDGroupWORLD) override;\n+\n+  void barrier(THDGroup groupId = THDGroupWORLD) override;\n+\n+  THDGroup newGroup(const std::vector<rank_type>& ranks) override;\n+\n+  void destroyGroup(THDGroup groupId = THDGroupWORLD) override;\n+\n+  // Not supported functions\n+  void gather(std::vector<at::Tensor>& output,\n+              at::Tensor& input,\n+              rank_type dstRank,\n+              THDGroup groupId = THDGroupWORLD) override;\n+\n+  void scatter(std::vector<at::Tensor>& input,\n+               at::Tensor& output,\n+               rank_type srcRank,\n+               THDGroup groupId = THDGroupWORLD) override;\n+\n+  void send(Scalar& data, rank_type dstRank) override;\n+\n+  void send(at::Tensor& data, rank_type dstRank) override;\n+\n+  void receive(Scalar& data, rank_type srcRank) override;\n+\n+  rank_type receive(at::Tensor& data) override;\n+\n+  void receive(at::Tensor& data, rank_type srcRank) override;\n+\n+  RequestNccl* isend(at::Tensor& data, rank_type dstRank) override;\n+\n+  RequestNccl* ireceive(at::Tensor& data, rank_type srcRank) override;\n+\n+private:\n+\n+  // Current process' rank\n+  rank_type _rank;\n+  // Number of processes in network\n+  rank_type _numProcesses;\n+  // Accept waiting timeout in milliseconds, optional\n+  int _timeout;\n+  // Master's address\n+  std::string _masterAddr;\n+  // Master's port\n+  port_type _masterPort;\n+  // Socket on which the master is listening\n+  int _masterListeningSocket;\n+  // Number of GPUs on each node\n+  int _numGPUs;\n+  // Mutex for Nccl Data Channel\n+  std::mutex _mutex;\n+\n+  /**\n+   * GPU device ID list for each group, each group should only have one device\n+   * list be associated with\n+   */\n+  std::unordered_map<THDGroup, std::string> _groupDevices;", "path": "torch/lib/THD/base/data_channels/DataChannelNccl.hpp", "position": null, "original_position": 140, "commit_id": "9400fd54da0d3b3a27b93cc4af8bb4c7a29b47d2", "original_commit_id": "029262b0414ad5b6bfa9af5c92e03b3160822708", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "1. Why use `std::string` for this? Using `std::vector` would let you avoid having to do the string parsing, which is likely slow.\r\n2. The comment is quite confusing. Why do you store a list if each group should have only one device?", "created_at": "2017-11-02T09:12:41Z", "updated_at": "2018-11-23T15:35:53Z", "html_url": "https://github.com/pytorch/pytorch/pull/3435#discussion_r148474510", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3435", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148474510"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3435#discussion_r148474510"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3435"}}, "body_html": "<ol>\n<li>Why use <code>std::string</code> for this? Using <code>std::vector</code> would let you avoid having to do the string parsing, which is likely slow.</li>\n<li>The comment is quite confusing. Why do you store a list if each group should have only one device?</li>\n</ol>", "body_text": "Why use std::string for this? Using std::vector would let you avoid having to do the string parsing, which is likely slow.\nThe comment is quite confusing. Why do you store a list if each group should have only one device?"}