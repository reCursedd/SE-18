{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150222740", "pull_request_review_id": 75742291, "id": 150222740, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDIyMjc0MA==", "diff_hunk": "@@ -320,3 +395,47 @@ def _process_batch():\n         with torch.cuda.device(device_ids[0]):\n             while True:\n                 _process_batch()  # just to have a clear scope\n+\n+    @staticmethod\n+    def _reduction_thread_fn_nccl(queue, group_id, device_ids, default_streams):\n+        \"\"\"\n+        Reduction thread function specifically for NCCL, the reduction will use\n+        default CUDA streams\n+        \"\"\"\n+        def _process_batch():\n+            dev_grad_batch, dev_events, job_event = queue.get()\n+            dev_coalesced = []\n+            # Coalesce the tensors on all devices and start a local reduction\n+            for dev_id, grad_batch, event, default_stream in \\\n+                    zip(device_ids,\n+                        dev_grad_batch,\n+                        dev_events,\n+                        default_streams):\n+                with torch.cuda.device(dev_id), \\\n+                        torch.cuda.stream(default_stream):\n+                    default_stream.wait_event(event)\n+                    coalesced = _flatten_dense_tensors(grad_batch)\n+                    dev_coalesced.append(coalesced)\n+\n+            # TODO: remove nccl.reduce with\n+            #       dist.all_reduce_multigpus\n+            nccl.reduce(dev_coalesced, root=0, streams=default_streams)", "path": "torch/nn/parallel/distributed.py", "position": null, "original_position": 205, "commit_id": "9400fd54da0d3b3a27b93cc4af8bb4c7a29b47d2", "original_commit_id": "18f92006e8b7b6efff22489a775eb1941e0091e9", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "that doesn't seem right - the parameters are broadcasted to all GPUs in `_sync_params`, which is why it's enough to use a single optimizer.\r\n\r\nI'm worried about adding these new functions in these PR. They have no tests and are not used in here either. There's no way for us to figure out if they're correct.", "created_at": "2017-11-10T12:25:16Z", "updated_at": "2018-11-23T15:36:20Z", "html_url": "https://github.com/pytorch/pytorch/pull/3435#discussion_r150222740", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3435", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150222740"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3435#discussion_r150222740"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3435"}}, "body_html": "<p>that doesn't seem right - the parameters are broadcasted to all GPUs in <code>_sync_params</code>, which is why it's enough to use a single optimizer.</p>\n<p>I'm worried about adding these new functions in these PR. They have no tests and are not used in here either. There's no way for us to figure out if they're correct.</p>", "body_text": "that doesn't seem right - the parameters are broadcasted to all GPUs in _sync_params, which is why it's enough to use a single optimizer.\nI'm worried about adding these new functions in these PR. They have no tests and are not used in here either. There's no way for us to figure out if they're correct.", "in_reply_to_id": 150059235}