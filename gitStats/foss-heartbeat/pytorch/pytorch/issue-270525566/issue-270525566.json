{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3435", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3435/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3435/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3435/events", "html_url": "https://github.com/pytorch/pytorch/pull/3435", "id": 270525566, "node_id": "MDExOlB1bGxSZXF1ZXN0MTUwMTk5NjAz", "number": 3435, "title": "Implemented NCCL Distributed Backend for PyTorch with new dist APIs", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2017-11-02T04:00:04Z", "updated_at": "2018-11-23T15:36:57Z", "closed_at": "2017-11-29T20:57:03Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3435", "html_url": "https://github.com/pytorch/pytorch/pull/3435", "diff_url": "https://github.com/pytorch/pytorch/pull/3435.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3435.patch"}, "body_html": "<p>This PR added a new PyTorch distributed backend called NcclDataChannel that uses NVIDIA NCCL2.0+ for collective operations across different GPUs on different nodes.  The Nccl backend uses TCP socket as the rendevous for the initial broadcast of the unique NCCL ID.</p>\n<p>The following new PyTorch APIs are added to perform collective operations on multiple GPU tensors, each of which resides on a different GPU.</p>\n<pre><code>    torch.distributed.all_reduce_multigpu(tensor_list, op=reduce_op.SUM, group=group.WORLD)\n    torch.distributed.reduce_multigpu(tensor_list, dst, op=reduce_op.SUM, group=group.WORLD)\n    torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=group.WORLD)\n    torch.distributed.broadcast_multigpu(tensor_list, src, group=group.WORLD)\n    torch.distributed.destroy_process_group()\n</code></pre>\n<p><strong>How to use?</strong></p>\n<pre><code>torch.distributed.init_process_group(\"nccl\")\n# Optional\ngrp = torch.distributed.new_group()\ntorch.distributed.all_reduce_multigpu(tensor_list, group=grp)\n# Clean shutdown to release all GPU resources\ntorch.distributed.destroy_process_group()\n</code></pre>\n<p>The exiting pytorch API such as torch.distributed.all_reduce works with \"NCCL\" backend as well.<br>\nAdded some tiny new code paths for distributed data parallel model to use NCCL backend.</p>\n<p><strong>Testing:</strong></p>\n<p>All new functions are tested using my own test scripts.</p>\n<p>On DGX1, 8 nodes with 4 Infinibands. I am able to run ResNet50 (that uses the modified distributed parallel model) for 140+ epochs without any issues.</p>\n<p><strong>TODO</strong> will be writing unit-test for the entire backend.  Current marked as experimental only</p>", "body_text": "This PR added a new PyTorch distributed backend called NcclDataChannel that uses NVIDIA NCCL2.0+ for collective operations across different GPUs on different nodes.  The Nccl backend uses TCP socket as the rendevous for the initial broadcast of the unique NCCL ID.\nThe following new PyTorch APIs are added to perform collective operations on multiple GPU tensors, each of which resides on a different GPU.\n    torch.distributed.all_reduce_multigpu(tensor_list, op=reduce_op.SUM, group=group.WORLD)\n    torch.distributed.reduce_multigpu(tensor_list, dst, op=reduce_op.SUM, group=group.WORLD)\n    torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=group.WORLD)\n    torch.distributed.broadcast_multigpu(tensor_list, src, group=group.WORLD)\n    torch.distributed.destroy_process_group()\n\nHow to use?\ntorch.distributed.init_process_group(\"nccl\")\n# Optional\ngrp = torch.distributed.new_group()\ntorch.distributed.all_reduce_multigpu(tensor_list, group=grp)\n# Clean shutdown to release all GPU resources\ntorch.distributed.destroy_process_group()\n\nThe exiting pytorch API such as torch.distributed.all_reduce works with \"NCCL\" backend as well.\nAdded some tiny new code paths for distributed data parallel model to use NCCL backend.\nTesting:\nAll new functions are tested using my own test scripts.\nOn DGX1, 8 nodes with 4 Infinibands. I am able to run ResNet50 (that uses the modified distributed parallel model) for 140+ epochs without any issues.\nTODO will be writing unit-test for the entire backend.  Current marked as experimental only", "body": "This PR added a new PyTorch distributed backend called NcclDataChannel that uses NVIDIA NCCL2.0+ for collective operations across different GPUs on different nodes.  The Nccl backend uses TCP socket as the rendevous for the initial broadcast of the unique NCCL ID.\r\n\r\nThe following new PyTorch APIs are added to perform collective operations on multiple GPU tensors, each of which resides on a different GPU.\r\n\r\n```\r\n    torch.distributed.all_reduce_multigpu(tensor_list, op=reduce_op.SUM, group=group.WORLD)\r\n    torch.distributed.reduce_multigpu(tensor_list, dst, op=reduce_op.SUM, group=group.WORLD)\r\n    torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=group.WORLD)\r\n    torch.distributed.broadcast_multigpu(tensor_list, src, group=group.WORLD)\r\n    torch.distributed.destroy_process_group()\r\n```\r\n\r\n**How to use?**\r\n\r\n```\r\ntorch.distributed.init_process_group(\"nccl\")\r\n# Optional\r\ngrp = torch.distributed.new_group()\r\ntorch.distributed.all_reduce_multigpu(tensor_list, group=grp)\r\n# Clean shutdown to release all GPU resources\r\ntorch.distributed.destroy_process_group()\r\n```\r\n\r\nThe exiting pytorch API such as torch.distributed.all_reduce works with \"NCCL\" backend as well.\r\nAdded some tiny new code paths for distributed data parallel model to use NCCL backend.\r\n\r\n**Testing:**\r\n\r\nAll new functions are tested using my own test scripts. \r\n\r\nOn DGX1, 8 nodes with 4 Infinibands. I am able to run ResNet50 (that uses the modified distributed parallel model) for 140+ epochs without any issues.\r\n\r\n**TODO** will be writing unit-test for the entire backend.  Current marked as experimental only"}