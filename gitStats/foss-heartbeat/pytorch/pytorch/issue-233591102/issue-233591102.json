{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1725", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1725/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1725/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1725/events", "html_url": "https://github.com/pytorch/pytorch/issues/1725", "id": 233591102, "node_id": "MDU6SXNzdWUyMzM1OTExMDI=", "number": 1725, "title": "Batchnorm does not normalize during test time", "user": {"login": "mmderakhshani", "id": 16706043, "node_id": "MDQ6VXNlcjE2NzA2MDQz", "avatar_url": "https://avatars0.githubusercontent.com/u/16706043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmderakhshani", "html_url": "https://github.com/mmderakhshani", "followers_url": "https://api.github.com/users/mmderakhshani/followers", "following_url": "https://api.github.com/users/mmderakhshani/following{/other_user}", "gists_url": "https://api.github.com/users/mmderakhshani/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmderakhshani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmderakhshani/subscriptions", "organizations_url": "https://api.github.com/users/mmderakhshani/orgs", "repos_url": "https://api.github.com/users/mmderakhshani/repos", "events_url": "https://api.github.com/users/mmderakhshani/events{/privacy}", "received_events_url": "https://api.github.com/users/mmderakhshani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": true, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-05T13:40:44Z", "updated_at": "2017-06-05T13:47:48Z", "closed_at": "2017-06-05T13:47:40Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI have transfered a keras based model to pytorch. Here is the code to transfer keras weights to pytorch:</p>\n<pre><code>def loadWeights(self):\n        model = load_model(self.modelUrl)        \n        j = json.loads(model.to_json())\n\n\n        for i, layer in enumerate(j['config']['layers']):\n            ln = layer['name']\n            l = model.get_layer(name=layer['name'])\n            if layer['class_name'] != 'Concatenate':\n                self.lid[ln] = l.input_shape[3]\n            else:\n                self.lid[ln] = l.input_shape[0][3]\n            self.lod[ln] = l.output_shape[3]\n            w = l.get_weights()\n            if layer['class_name'] == 'Conv2D':\n                filter_size = layer['config']['kernel_size'][0]\n                if filter_size == 3:\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \n                        filter_size,padding=1,stride=1,bias=False)\n                elif filter_size == 1:\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \n                        filter_size,padding=0,stride=1,bias=False)\n\n                self.layers[ln].weight.data = torch.from_numpy(w[0].transpose((3,2,0,1)))\n\n            elif layer['class_name'] == 'BatchNormalization':\n                self.layers[ln] = nn.BatchNorm2d(self.lid[ln])\n                self.layers[ln].weight.data = torch.from_numpy(w[0])\n                self.layers[ln].bias.data = torch.from_numpy(w[1])\n                self.layers[ln].running_mean.data = torch.from_numpy(w[2])\n                self.layers[ln].running_var.data = torch.from_numpy(w[3])\n\n            elif layer['class_name'] == 'LeakyReLU':\n                self.layers[ln] = nn.LeakyReLU(.1)\n            elif layer['class_name'] == 'MaxPooling2D':\n                self.layers[ln] = nn.MaxPool2d(2, 2)\n            elif layer['class_name'] == 'Lambda':\n                self.layers[ln] = space_to_depth(2)\n</code></pre>\n<p>By the way here is the network definition of mine:</p>\n<pre><code>YoloV2 (\n  (path1): ModuleList (\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (6): LeakyReLU (0.1)\n    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (10): LeakyReLU (0.1)\n    (11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (13): LeakyReLU (0.1)\n    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (16): LeakyReLU (0.1)\n    (17): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (20): LeakyReLU (0.1)\n    (21): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (23): LeakyReLU (0.1)\n    (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (26): LeakyReLU (0.1)\n    (27): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (28): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (30): LeakyReLU (0.1)\n    (31): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (33): LeakyReLU (0.1)\n    (34): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (36): LeakyReLU (0.1)\n    (37): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (39): LeakyReLU (0.1)\n    (40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (42): LeakyReLU (0.1)\n  )\n  (parallel1): ModuleList (\n    (0): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (3): LeakyReLU (0.1)\n    (4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (6): LeakyReLU (0.1)\n    (7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (9): LeakyReLU (0.1)\n    (10): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (12): LeakyReLU (0.1)\n    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (15): LeakyReLU (0.1)\n    (16): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (17): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (18): LeakyReLU (0.1)\n    (19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (20): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (21): LeakyReLU (0.1)\n  )\n  (parallel2): ModuleList (\n    (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): space_to_depth (\n    )\n  )\n  (path2): ModuleList (\n    (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): Conv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  )\n)\n</code></pre>\n<p>I wrote a class to forward an input image to the network. I have got two strategies:</p>\n<ol>\n<li>Without Calling <code>model.eval()</code></li>\n<li>With <code>model.eval()</code> call</li>\n</ol>\n<p>In first strategies, there are no warnings or errors and network prints some outputs(True or Fasle it does  not matter at the moment) and other thing which is so valuable to say is that the layers output's mean and std does not change very much (between -2 to 2):</p>\n<pre><code>input mean and std are -0.04494736304771177 and 0.556064745758631, respectively\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5099109076960409 and 3.483493296231317, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27291830491650276 and 1.036471545235261, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.4305392422732526 and 1.202917821877896, respectively\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.9899187664354396 and 4.050347281426372, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.0015420447168388517 and 2.409852554132013, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.7251764499188588 and 1.246702658686969, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 1.110645569343398 and 1.4124529129467818, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -2.1355855926564744 and 4.853101539204546, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.2206667769486426 and 1.8318006859506701, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.46897992809393835 and 0.859482247760845, respectively\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.9078326040506374 and 1.9656916315557942, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.43688638428484516 and 2.3344875729978045, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.0761453882177805 and 1.4362898618833972, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -3.0177889785774092 and 3.927335223735611, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.8723490468562499 and 2.2295311715708306, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.3222875415256367 and 1.0188470847637079, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.8346413859021834 and 1.2618543286784667, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.46426937940990426 and 3.565332046490428, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5789789276697301 and 1.5952710537735455, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27188616654222475 and 0.7431071560896871, respectively\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.7219821519924938 and 1.5646377234769224, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.05859121954425537 and 2.009835006552993, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.682884921279361 and 1.1638968358008939, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -4.1710328423149114 and 3.1222952569255313, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.6019020716905836 and 1.8825793546655925, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.011203291708299108 and 0.6490820490387453, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.34213214185854474 and 0.8960747742980884, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.8102769773375691 and 2.242571128761576, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.9936008172643053 and 1.3162715171971935, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.036753491923940534 and 0.4651764921831018, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.06986793111736317 and 0.756228160496226, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5786286138502325 and 1.631962011338411, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27703594028077 and 0.7727139464406952, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.6555578332189848 and 1.9442816225071249, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5118525658441543 and 1.1801905692229984, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.16570582170742787 and 0.5261316042109162, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.7035690433871121 and 1.003513400096224, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.586702496895472 and 1.4674813286924224, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.23500260385863672 and 0.7026550011530345, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.5039784600555615 and 1.6485516000922598, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.6886020402674757 and 1.4858046764156354, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.08872732962311336 and 0.4132245937714489, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.1220283306368888 and 0.5988100526443035, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.4159007540387892 and 1.2440949325163686, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.0476089786178813 and 1.1236696802684645, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.02763950308381415 and 0.3197062403557132, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 0.14509135742389725 and 0.4978156354745875, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.037194425551949 and 1.4406428829980131, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.05517879329770451 and 0.54638575096754, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.5650907167075608 and 1.0960796705504932, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.0179631560765796 and 1.1401937838658363, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.016447979783596935 and 0.3461334809904434, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.1031509910077126 and 0.7195396168567219, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5263724097257554 and 1.7285212223824609, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.10367102351043893 and 0.3346534859823307, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.27020657553412425 and 0.5317017422685887, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -3.585445386485042 and 5.086899781717164, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.16911862420653084 and 2.0421958251365386, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.7517265916328315 and 3.700349110068167, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.23258340700060495 and 0.9747704390933579, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.2080935812370515 and 0.5363052982473416, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.813569535448889 and 1.2314617636216465, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.2322173955099545 and 0.9918465251493507, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.21712208753555917 and 0.5636511219268967, respectively\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.01775318011710118 and 0.6055431501553021, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.17816445186751895 and 0.7195889862901408, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.3429062488257823 and 0.5177002127026878, respectively\nspace_to_depth (\n)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nFound 9 boxes for COCO_val2014_000000000042.jpg\nfrisbee 0.30 (209, 206) (347, 283)\nfrisbee 0.36 (235, 236) (338, 287)\nsuitcase 0.36 (59, 281) (281, 478)\nperson 0.44 (606, 26) (640, 163)\nperson 0.46 (119, 127) (334, 325)\ntie 0.50 (240, 272) (407, 478)\nchair 0.53 (103, 207) (226, 317)\nboat 0.56 (87, 124) (539, 478)\nsofa 0.63 (28, 209) (121, 308)\n</code></pre>\n<p>But in second strategy, story is different. layer output's mean and variance changes exponentially.</p>\n<pre><code> input mean and std are -0.04494736304771177 and 0.556064745758631, respectively\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5004743806591334 and 3.2451938932618813, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.2289622166064922 and 0.94894875285721, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.32535080570928987 and 1.0525597431701654, respectively\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.6401130915600954 and 3.6706229590068427, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -4.004212087424514 and 8.002498040262742, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.448057248625097 and 2.794619607363287, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.9234630808877886 and 3.2363604087774926, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -4.593692073735354 and 9.355192001463557, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -8.955928904613664 and 16.237733986265535, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.5552958584324834 and 4.914919534329322, respectively\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -3.6201700877935115 and 9.092207210834086, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -7.465137243465318 and 18.64723750334634, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.9573747554615017 and 7.066993566681194, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -20.035878502119925 and 20.422580826733082, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -39.12127531060829 and 36.298141999658235, respectively\nLeakyReLU (0.1)\noutput mean and std are -2.1507654894266146 and 11.323441465564994, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.010148529357874046 and 13.114547738885705, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -9.868222889836685 and 27.716066798854122, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -14.35351110881925 and 37.60034736743473, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.472574348168612 and 15.794030097242851, respectively\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -16.093271579544957 and 34.53466149540508, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -29.558075474104847 and 64.61764430170822, respectively\nLeakyReLU (0.1)\noutput mean and std are 5.308158185495806 and 27.480531382302487, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -95.00516871844684 and 77.68958602298824, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -157.96310839256662 and 126.04836081913527, respectively\nLeakyReLU (0.1)\noutput mean and std are -13.972440409863973 and 21.656575329214437, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are -8.588741508121828 and 24.97878772348646, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -25.218914712954923 and 60.589984363282774, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -30.572578246550986 and 71.3270147314146, respectively\nLeakyReLU (0.1)\noutput mean and std are 7.629328541304477 and 27.966696786011354, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -40.20503733121212 and 56.78530897900072, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -60.19630822914735 and 81.01215279636307, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.1732579516573692 and 26.961190438883264, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -44.354159634521224 and 69.45068405822532, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -44.6108416233467 and 70.53709134826606, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.164688049209314 and 30.629382577256333, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -60.09455703793958 and 59.26151418169549, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -84.05918085481835 and 80.93821288301436, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.998677666104009 and 25.06710075807031, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -84.47013122371641 and 59.395586825404195, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -113.0038979866816 and 78.01497584970957, respectively\nLeakyReLU (0.1)\noutput mean and std are -9.691565806949647 and 14.904434897315438, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are -7.084727277721027 and 16.89144822524408, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -18.469181988303056 and 40.46809047250108, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -19.27066238363107 and 39.965249248395295, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.1443751448719475 and 16.399852587199877, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -42.951979090906704 and 33.676679379162735, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -58.03006266055498 and 44.712284224554054, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.7120864047955426 and 16.85305115325033, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -62.05761384237711 and 50.43448540320261, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -63.72124559143942 and 57.778983122658374, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.7247640703501252 and 16.86207690244709, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -43.48458678305966 and 24.395471092021698, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -69.73365663384541 and 36.62449711934278, respectively\nLeakyReLU (0.1)\noutput mean and std are -6.300476440951662 and 9.787425046621092, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -30.729011372441875 and 25.218441033876672, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -159.4286791014364 and 129.8030214190841, respectively\nLeakyReLU (0.1)\noutput mean and std are -10.918062238962928 and 38.13093127356943, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -81.52529573452821 and 115.91647362884571, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -80.18162078336991 and 121.56326021420584, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.061222725045524166 and 47.10359980112523, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -137.05153923487129 and 163.5505120763411, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -136.5606036657814 and 175.08413844637286, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.0197972168610865 and 80.78677697044031, respectively\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -9.423463147412228 and 19.125065627582146, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -6.56899910951772 and 13.515443707070217, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.550776536112185 and 6.055068815026945, respectively\nspace_to_depth (\n)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:152: RuntimeWarning: overflow encountered in exp\n  return 1./(1 + np.exp(-1*inp))\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:143: RuntimeWarning: overflow encountered in exp\n  box_wh = np.exp(feature[..., 2:4])\nFound 0 boxes for COCO_val2014_000000000042.jpg\nFinish\n</code></pre>\n<p>Could you please tell me, what is wrong? what is the cause of this error?<br>\nbest.</p>", "body_text": "Hi,\nI have transfered a keras based model to pytorch. Here is the code to transfer keras weights to pytorch:\ndef loadWeights(self):\n        model = load_model(self.modelUrl)        \n        j = json.loads(model.to_json())\n\n\n        for i, layer in enumerate(j['config']['layers']):\n            ln = layer['name']\n            l = model.get_layer(name=layer['name'])\n            if layer['class_name'] != 'Concatenate':\n                self.lid[ln] = l.input_shape[3]\n            else:\n                self.lid[ln] = l.input_shape[0][3]\n            self.lod[ln] = l.output_shape[3]\n            w = l.get_weights()\n            if layer['class_name'] == 'Conv2D':\n                filter_size = layer['config']['kernel_size'][0]\n                if filter_size == 3:\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \n                        filter_size,padding=1,stride=1,bias=False)\n                elif filter_size == 1:\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \n                        filter_size,padding=0,stride=1,bias=False)\n\n                self.layers[ln].weight.data = torch.from_numpy(w[0].transpose((3,2,0,1)))\n\n            elif layer['class_name'] == 'BatchNormalization':\n                self.layers[ln] = nn.BatchNorm2d(self.lid[ln])\n                self.layers[ln].weight.data = torch.from_numpy(w[0])\n                self.layers[ln].bias.data = torch.from_numpy(w[1])\n                self.layers[ln].running_mean.data = torch.from_numpy(w[2])\n                self.layers[ln].running_var.data = torch.from_numpy(w[3])\n\n            elif layer['class_name'] == 'LeakyReLU':\n                self.layers[ln] = nn.LeakyReLU(.1)\n            elif layer['class_name'] == 'MaxPooling2D':\n                self.layers[ln] = nn.MaxPool2d(2, 2)\n            elif layer['class_name'] == 'Lambda':\n                self.layers[ln] = space_to_depth(2)\n\nBy the way here is the network definition of mine:\nYoloV2 (\n  (path1): ModuleList (\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (6): LeakyReLU (0.1)\n    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (10): LeakyReLU (0.1)\n    (11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (13): LeakyReLU (0.1)\n    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (16): LeakyReLU (0.1)\n    (17): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (20): LeakyReLU (0.1)\n    (21): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n    (23): LeakyReLU (0.1)\n    (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (26): LeakyReLU (0.1)\n    (27): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (28): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (30): LeakyReLU (0.1)\n    (31): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (33): LeakyReLU (0.1)\n    (34): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (36): LeakyReLU (0.1)\n    (37): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n    (39): LeakyReLU (0.1)\n    (40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (42): LeakyReLU (0.1)\n  )\n  (parallel1): ModuleList (\n    (0): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n    (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (3): LeakyReLU (0.1)\n    (4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (6): LeakyReLU (0.1)\n    (7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (9): LeakyReLU (0.1)\n    (10): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n    (12): LeakyReLU (0.1)\n    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (15): LeakyReLU (0.1)\n    (16): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (17): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (18): LeakyReLU (0.1)\n    (19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (20): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (21): LeakyReLU (0.1)\n  )\n  (parallel2): ModuleList (\n    (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): space_to_depth (\n    )\n  )\n  (path2): ModuleList (\n    (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n    (2): LeakyReLU (0.1)\n    (3): Conv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  )\n)\n\nI wrote a class to forward an input image to the network. I have got two strategies:\n\nWithout Calling model.eval()\nWith model.eval() call\n\nIn first strategies, there are no warnings or errors and network prints some outputs(True or Fasle it does  not matter at the moment) and other thing which is so valuable to say is that the layers output's mean and std does not change very much (between -2 to 2):\ninput mean and std are -0.04494736304771177 and 0.556064745758631, respectively\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5099109076960409 and 3.483493296231317, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27291830491650276 and 1.036471545235261, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.4305392422732526 and 1.202917821877896, respectively\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.9899187664354396 and 4.050347281426372, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.0015420447168388517 and 2.409852554132013, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.7251764499188588 and 1.246702658686969, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 1.110645569343398 and 1.4124529129467818, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -2.1355855926564744 and 4.853101539204546, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.2206667769486426 and 1.8318006859506701, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.46897992809393835 and 0.859482247760845, respectively\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.9078326040506374 and 1.9656916315557942, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.43688638428484516 and 2.3344875729978045, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.0761453882177805 and 1.4362898618833972, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -3.0177889785774092 and 3.927335223735611, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.8723490468562499 and 2.2295311715708306, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.3222875415256367 and 1.0188470847637079, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.8346413859021834 and 1.2618543286784667, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.46426937940990426 and 3.565332046490428, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5789789276697301 and 1.5952710537735455, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27188616654222475 and 0.7431071560896871, respectively\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.7219821519924938 and 1.5646377234769224, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.05859121954425537 and 2.009835006552993, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.682884921279361 and 1.1638968358008939, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -4.1710328423149114 and 3.1222952569255313, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.6019020716905836 and 1.8825793546655925, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.011203291708299108 and 0.6490820490387453, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.34213214185854474 and 0.8960747742980884, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.8102769773375691 and 2.242571128761576, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.9936008172643053 and 1.3162715171971935, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.036753491923940534 and 0.4651764921831018, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.06986793111736317 and 0.756228160496226, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5786286138502325 and 1.631962011338411, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.27703594028077 and 0.7727139464406952, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.6555578332189848 and 1.9442816225071249, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.5118525658441543 and 1.1801905692229984, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.16570582170742787 and 0.5261316042109162, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.7035690433871121 and 1.003513400096224, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.586702496895472 and 1.4674813286924224, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.23500260385863672 and 0.7026550011530345, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.5039784600555615 and 1.6485516000922598, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.6886020402674757 and 1.4858046764156354, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.08872732962311336 and 0.4132245937714489, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.1220283306368888 and 0.5988100526443035, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.4159007540387892 and 1.2440949325163686, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.0476089786178813 and 1.1236696802684645, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.02763950308381415 and 0.3197062403557132, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 0.14509135742389725 and 0.4978156354745875, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.037194425551949 and 1.4406428829980131, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.05517879329770451 and 0.54638575096754, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.5650907167075608 and 1.0960796705504932, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.0179631560765796 and 1.1401937838658363, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.016447979783596935 and 0.3461334809904434, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.1031509910077126 and 0.7195396168567219, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5263724097257554 and 1.7285212223824609, respectively\nLeakyReLU (0.1)\noutput mean and std are -0.10367102351043893 and 0.3346534859823307, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.27020657553412425 and 0.5317017422685887, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -3.585445386485042 and 5.086899781717164, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.16911862420653084 and 2.0421958251365386, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.7517265916328315 and 3.700349110068167, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.23258340700060495 and 0.9747704390933579, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.2080935812370515 and 0.5363052982473416, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -0.813569535448889 and 1.2314617636216465, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -0.2322173955099545 and 0.9918465251493507, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.21712208753555917 and 0.5636511219268967, respectively\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -0.01775318011710118 and 0.6055431501553021, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.17816445186751895 and 0.7195889862901408, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.3429062488257823 and 0.5177002127026878, respectively\nspace_to_depth (\n)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\nFound 9 boxes for COCO_val2014_000000000042.jpg\nfrisbee 0.30 (209, 206) (347, 283)\nfrisbee 0.36 (235, 236) (338, 287)\nsuitcase 0.36 (59, 281) (281, 478)\nperson 0.44 (606, 26) (640, 163)\nperson 0.46 (119, 127) (334, 325)\ntie 0.50 (240, 272) (407, 478)\nchair 0.53 (103, 207) (226, 317)\nboat 0.56 (87, 124) (539, 478)\nsofa 0.63 (28, 209) (121, 308)\n\nBut in second strategy, story is different. layer output's mean and variance changes exponentially.\n input mean and std are -0.04494736304771177 and 0.556064745758631, respectively\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -1.5004743806591334 and 3.2451938932618813, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.2289622166064922 and 0.94894875285721, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.32535080570928987 and 1.0525597431701654, respectively\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -1.6401130915600954 and 3.6706229590068427, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -4.004212087424514 and 8.002498040262742, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.448057248625097 and 2.794619607363287, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.9234630808877886 and 3.2363604087774926, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -4.593692073735354 and 9.355192001463557, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -8.955928904613664 and 16.237733986265535, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.5552958584324834 and 4.914919534329322, respectively\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -3.6201700877935115 and 9.092207210834086, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -7.465137243465318 and 18.64723750334634, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.9573747554615017 and 7.066993566681194, respectively\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -20.035878502119925 and 20.422580826733082, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -39.12127531060829 and 36.298141999658235, respectively\nLeakyReLU (0.1)\noutput mean and std are -2.1507654894266146 and 11.323441465564994, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are 0.010148529357874046 and 13.114547738885705, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -9.868222889836685 and 27.716066798854122, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -14.35351110881925 and 37.60034736743473, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.472574348168612 and 15.794030097242851, respectively\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -16.093271579544957 and 34.53466149540508, respectively\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -29.558075474104847 and 64.61764430170822, respectively\nLeakyReLU (0.1)\noutput mean and std are 5.308158185495806 and 27.480531382302487, respectively\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -95.00516871844684 and 77.68958602298824, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -157.96310839256662 and 126.04836081913527, respectively\nLeakyReLU (0.1)\noutput mean and std are -13.972440409863973 and 21.656575329214437, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are -8.588741508121828 and 24.97878772348646, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -25.218914712954923 and 60.589984363282774, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -30.572578246550986 and 71.3270147314146, respectively\nLeakyReLU (0.1)\noutput mean and std are 7.629328541304477 and 27.966696786011354, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -40.20503733121212 and 56.78530897900072, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -60.19630822914735 and 81.01215279636307, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.1732579516573692 and 26.961190438883264, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -44.354159634521224 and 69.45068405822532, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -44.6108416233467 and 70.53709134826606, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.164688049209314 and 30.629382577256333, respectively\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -60.09455703793958 and 59.26151418169549, respectively\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -84.05918085481835 and 80.93821288301436, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.998677666104009 and 25.06710075807031, respectively\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -84.47013122371641 and 59.395586825404195, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -113.0038979866816 and 78.01497584970957, respectively\nLeakyReLU (0.1)\noutput mean and std are -9.691565806949647 and 14.904434897315438, respectively\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\noutput mean and std are -7.084727277721027 and 16.89144822524408, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -18.469181988303056 and 40.46809047250108, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -19.27066238363107 and 39.965249248395295, respectively\nLeakyReLU (0.1)\noutput mean and std are 4.1443751448719475 and 16.399852587199877, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -42.951979090906704 and 33.676679379162735, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -58.03006266055498 and 44.712284224554054, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.7120864047955426 and 16.85305115325033, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -62.05761384237711 and 50.43448540320261, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -63.72124559143942 and 57.778983122658374, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.7247640703501252 and 16.86207690244709, respectively\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -43.48458678305966 and 24.395471092021698, respectively\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -69.73365663384541 and 36.62449711934278, respectively\nLeakyReLU (0.1)\noutput mean and std are -6.300476440951662 and 9.787425046621092, respectively\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -30.729011372441875 and 25.218441033876672, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -159.4286791014364 and 129.8030214190841, respectively\nLeakyReLU (0.1)\noutput mean and std are -10.918062238962928 and 38.13093127356943, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -81.52529573452821 and 115.91647362884571, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -80.18162078336991 and 121.56326021420584, respectively\nLeakyReLU (0.1)\noutput mean and std are 0.061222725045524166 and 47.10359980112523, respectively\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are -137.05153923487129 and 163.5505120763411, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -136.5606036657814 and 175.08413844637286, respectively\nLeakyReLU (0.1)\noutput mean and std are -3.0197972168610865 and 80.78677697044031, respectively\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are -9.423463147412228 and 19.125065627582146, respectively\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are -6.56899910951772 and 13.515443707070217, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.550776536112185 and 6.055068815026945, respectively\nspace_to_depth (\n)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nLeakyReLU (0.1)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:152: RuntimeWarning: overflow encountered in exp\n  return 1./(1 + np.exp(-1*inp))\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:143: RuntimeWarning: overflow encountered in exp\n  box_wh = np.exp(feature[..., 2:4])\nFound 0 boxes for COCO_val2014_000000000042.jpg\nFinish\n\nCould you please tell me, what is wrong? what is the cause of this error?\nbest.", "body": "Hi,\r\nI have transfered a keras based model to pytorch. Here is the code to transfer keras weights to pytorch:\r\n```\r\ndef loadWeights(self):\r\n        model = load_model(self.modelUrl)        \r\n        j = json.loads(model.to_json())\r\n\r\n\r\n        for i, layer in enumerate(j['config']['layers']):\r\n            ln = layer['name']\r\n            l = model.get_layer(name=layer['name'])\r\n            if layer['class_name'] != 'Concatenate':\r\n                self.lid[ln] = l.input_shape[3]\r\n            else:\r\n                self.lid[ln] = l.input_shape[0][3]\r\n            self.lod[ln] = l.output_shape[3]\r\n            w = l.get_weights()\r\n            if layer['class_name'] == 'Conv2D':\r\n                filter_size = layer['config']['kernel_size'][0]\r\n                if filter_size == 3:\r\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \r\n                        filter_size,padding=1,stride=1,bias=False)\r\n                elif filter_size == 1:\r\n                    self.layers[ln] = nn.Conv2d(self.lid[ln],self.lod[ln], \r\n                        filter_size,padding=0,stride=1,bias=False)\r\n\r\n                self.layers[ln].weight.data = torch.from_numpy(w[0].transpose((3,2,0,1)))\r\n\r\n            elif layer['class_name'] == 'BatchNormalization':\r\n                self.layers[ln] = nn.BatchNorm2d(self.lid[ln])\r\n                self.layers[ln].weight.data = torch.from_numpy(w[0])\r\n                self.layers[ln].bias.data = torch.from_numpy(w[1])\r\n                self.layers[ln].running_mean.data = torch.from_numpy(w[2])\r\n                self.layers[ln].running_var.data = torch.from_numpy(w[3])\r\n\r\n            elif layer['class_name'] == 'LeakyReLU':\r\n                self.layers[ln] = nn.LeakyReLU(.1)\r\n            elif layer['class_name'] == 'MaxPooling2D':\r\n                self.layers[ln] = nn.MaxPool2d(2, 2)\r\n            elif layer['class_name'] == 'Lambda':\r\n                self.layers[ln] = space_to_depth(2)\r\n```\r\nBy the way here is the network definition of mine:\r\n```\r\nYoloV2 (\r\n  (path1): ModuleList (\r\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\r\n    (2): LeakyReLU (0.1)\r\n    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\n    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\n    (6): LeakyReLU (0.1)\r\n    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\n    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\n    (10): LeakyReLU (0.1)\r\n    (11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\n    (13): LeakyReLU (0.1)\r\n    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\n    (16): LeakyReLU (0.1)\r\n    (17): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\n    (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\n    (20): LeakyReLU (0.1)\r\n    (21): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\n    (23): LeakyReLU (0.1)\r\n    (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\n    (26): LeakyReLU (0.1)\r\n    (27): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\n    (28): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\n    (30): LeakyReLU (0.1)\r\n    (31): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\n    (33): LeakyReLU (0.1)\r\n    (34): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\n    (36): LeakyReLU (0.1)\r\n    (37): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\n    (39): LeakyReLU (0.1)\r\n    (40): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\n    (42): LeakyReLU (0.1)\r\n  )\r\n  (parallel1): ModuleList (\r\n    (0): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\n    (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (3): LeakyReLU (0.1)\r\n    (4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\n    (6): LeakyReLU (0.1)\r\n    (7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (9): LeakyReLU (0.1)\r\n    (10): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\n    (12): LeakyReLU (0.1)\r\n    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (15): LeakyReLU (0.1)\r\n    (16): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (17): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (18): LeakyReLU (0.1)\r\n    (19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (20): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (21): LeakyReLU (0.1)\r\n  )\r\n  (parallel2): ModuleList (\r\n    (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\n    (2): LeakyReLU (0.1)\r\n    (3): space_to_depth (\r\n    )\r\n  )\r\n  (path2): ModuleList (\r\n    (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\n    (2): LeakyReLU (0.1)\r\n    (3): Conv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n  )\r\n)\r\n```\r\nI wrote a class to forward an input image to the network. I have got two strategies:\r\n1. Without Calling `model.eval()`\r\n2. With `model.eval()` call\r\n\r\nIn first strategies, there are no warnings or errors and network prints some outputs(True or Fasle it does  not matter at the moment) and other thing which is so valuable to say is that the layers output's mean and std does not change very much (between -2 to 2):\r\n```\r\ninput mean and std are -0.04494736304771177 and 0.556064745758631, respectively\r\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\r\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.5099109076960409 and 3.483493296231317, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.27291830491650276 and 1.036471545235261, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.4305392422732526 and 1.202917821877896, respectively\r\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -1.9899187664354396 and 4.050347281426372, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are 0.0015420447168388517 and 2.409852554132013, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.7251764499188588 and 1.246702658686969, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 1.110645569343398 and 1.4124529129467818, respectively\r\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -2.1355855926564744 and 4.853101539204546, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.2206667769486426 and 1.8318006859506701, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.46897992809393835 and 0.859482247760845, respectively\r\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.9078326040506374 and 1.9656916315557942, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are 0.43688638428484516 and 2.3344875729978045, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 1.0761453882177805 and 1.4362898618833972, respectively\r\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -3.0177889785774092 and 3.927335223735611, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.8723490468562499 and 2.2295311715708306, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.3222875415256367 and 1.0188470847637079, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.8346413859021834 and 1.2618543286784667, respectively\r\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.46426937940990426 and 3.565332046490428, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.5789789276697301 and 1.5952710537735455, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.27188616654222475 and 0.7431071560896871, respectively\r\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.7219821519924938 and 1.5646377234769224, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.05859121954425537 and 2.009835006552993, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.682884921279361 and 1.1638968358008939, respectively\r\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -4.1710328423149114 and 3.1222952569255313, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.6019020716905836 and 1.8825793546655925, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.011203291708299108 and 0.6490820490387453, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.34213214185854474 and 0.8960747742980884, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.8102769773375691 and 2.242571128761576, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.9936008172643053 and 1.3162715171971935, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.036753491923940534 and 0.4651764921831018, respectively\r\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.06986793111736317 and 0.756228160496226, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.5786286138502325 and 1.631962011338411, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.27703594028077 and 0.7727139464406952, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.6555578332189848 and 1.9442816225071249, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.5118525658441543 and 1.1801905692229984, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.16570582170742787 and 0.5261316042109162, respectively\r\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.7035690433871121 and 1.003513400096224, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.586702496895472 and 1.4674813286924224, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.23500260385863672 and 0.7026550011530345, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -1.5039784600555615 and 1.6485516000922598, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.6886020402674757 and 1.4858046764156354, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -0.08872732962311336 and 0.4132245937714489, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.1220283306368888 and 0.5988100526443035, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.4159007540387892 and 1.2440949325163686, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.0476089786178813 and 1.1236696802684645, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -0.02763950308381415 and 0.3197062403557132, respectively\r\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are 0.14509135742389725 and 0.4978156354745875, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.037194425551949 and 1.4406428829980131, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.05517879329770451 and 0.54638575096754, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.5650907167075608 and 1.0960796705504932, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.0179631560765796 and 1.1401937838658363, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -0.016447979783596935 and 0.3461334809904434, respectively\r\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.1031509910077126 and 0.7195396168567219, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.5263724097257554 and 1.7285212223824609, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -0.10367102351043893 and 0.3346534859823307, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.27020657553412425 and 0.5317017422685887, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -3.585445386485042 and 5.086899781717164, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.16911862420653084 and 2.0421958251365386, respectively\r\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.7517265916328315 and 3.700349110068167, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.23258340700060495 and 0.9747704390933579, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.2080935812370515 and 0.5363052982473416, respectively\r\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -0.813569535448889 and 1.2314617636216465, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -0.2322173955099545 and 0.9918465251493507, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.21712208753555917 and 0.5636511219268967, respectively\r\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -0.01775318011710118 and 0.6055431501553021, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are 0.17816445186751895 and 0.7195889862901408, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.3429062488257823 and 0.5177002127026878, respectively\r\nspace_to_depth (\r\n)\r\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\r\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\r\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are 0.34290624882578224 and 0.5177002127026903, respectively\r\nFound 9 boxes for COCO_val2014_000000000042.jpg\r\nfrisbee 0.30 (209, 206) (347, 283)\r\nfrisbee 0.36 (235, 236) (338, 287)\r\nsuitcase 0.36 (59, 281) (281, 478)\r\nperson 0.44 (606, 26) (640, 163)\r\nperson 0.46 (119, 127) (334, 325)\r\ntie 0.50 (240, 272) (407, 478)\r\nchair 0.53 (103, 207) (226, 317)\r\nboat 0.56 (87, 124) (539, 478)\r\nsofa 0.63 (28, 209) (121, 308)\r\n```\r\nBut in second strategy, story is different. layer output's mean and variance changes exponentially. \r\n```\r\n input mean and std are -0.04494736304771177 and 0.556064745758631, respectively\r\nConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are 0.010662011339761012 and 0.7021324724353769, respectively\r\nBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -1.5004743806591334 and 3.2451938932618813, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.2289622166064922 and 0.94894875285721, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.32535080570928987 and 1.0525597431701654, respectively\r\nConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -1.6401130915600954 and 3.6706229590068427, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -4.004212087424514 and 8.002498040262742, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.448057248625097 and 2.794619607363287, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.9234630808877886 and 3.2363604087774926, respectively\r\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -4.593692073735354 and 9.355192001463557, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -8.955928904613664 and 16.237733986265535, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.5552958584324834 and 4.914919534329322, respectively\r\nConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -3.6201700877935115 and 9.092207210834086, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -7.465137243465318 and 18.64723750334634, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 1.9573747554615017 and 7.066993566681194, respectively\r\nConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -20.035878502119925 and 20.422580826733082, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -39.12127531060829 and 36.298141999658235, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -2.1507654894266146 and 11.323441465564994, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are 0.010148529357874046 and 13.114547738885705, respectively\r\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -9.868222889836685 and 27.716066798854122, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -14.35351110881925 and 37.60034736743473, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 4.472574348168612 and 15.794030097242851, respectively\r\nConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -16.093271579544957 and 34.53466149540508, respectively\r\nBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -29.558075474104847 and 64.61764430170822, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 5.308158185495806 and 27.480531382302487, respectively\r\nConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -95.00516871844684 and 77.68958602298824, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -157.96310839256662 and 126.04836081913527, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -13.972440409863973 and 21.656575329214437, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are -8.588741508121828 and 24.97878772348646, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -25.218914712954923 and 60.589984363282774, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -30.572578246550986 and 71.3270147314146, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 7.629328541304477 and 27.966696786011354, respectively\r\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -40.20503733121212 and 56.78530897900072, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -60.19630822914735 and 81.01215279636307, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.1732579516573692 and 26.961190438883264, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -44.354159634521224 and 69.45068405822532, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -44.6108416233467 and 70.53709134826606, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 4.164688049209314 and 30.629382577256333, respectively\r\nConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -60.09455703793958 and 59.26151418169549, respectively\r\nBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -84.05918085481835 and 80.93821288301436, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -3.998677666104009 and 25.06710075807031, respectively\r\nConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -84.47013122371641 and 59.395586825404195, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -113.0038979866816 and 78.01497584970957, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -9.691565806949647 and 14.904434897315438, respectively\r\nMaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\r\noutput mean and std are -7.084727277721027 and 16.89144822524408, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -18.469181988303056 and 40.46809047250108, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -19.27066238363107 and 39.965249248395295, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 4.1443751448719475 and 16.399852587199877, respectively\r\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -42.951979090906704 and 33.676679379162735, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -58.03006266055498 and 44.712284224554054, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -3.7120864047955426 and 16.85305115325033, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -62.05761384237711 and 50.43448540320261, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -63.72124559143942 and 57.778983122658374, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -3.7247640703501252 and 16.86207690244709, respectively\r\nConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -43.48458678305966 and 24.395471092021698, respectively\r\nBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -69.73365663384541 and 36.62449711934278, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -6.300476440951662 and 9.787425046621092, respectively\r\nConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -30.729011372441875 and 25.218441033876672, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -159.4286791014364 and 129.8030214190841, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -10.918062238962928 and 38.13093127356943, respectively\r\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -81.52529573452821 and 115.91647362884571, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -80.18162078336991 and 121.56326021420584, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 0.061222725045524166 and 47.10359980112523, respectively\r\nConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are -137.05153923487129 and 163.5505120763411, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -136.5606036657814 and 175.08413844637286, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are -3.0197972168610865 and 80.78677697044031, respectively\r\nConv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are -9.423463147412228 and 19.125065627582146, respectively\r\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are -6.56899910951772 and 13.515443707070217, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 1.550776536112185 and 6.055068815026945, respectively\r\nspace_to_depth (\r\n)\r\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\r\nConv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\r\nBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\r\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\r\nLeakyReLU (0.1)\r\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\r\nConv2d(1024, 425, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\noutput mean and std are 1.550776536112185 and 6.055068815026951, respectively\r\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:152: RuntimeWarning: overflow encountered in exp\r\n  return 1./(1 + np.exp(-1*inp))\r\n/home/mohammad/Project/YAD2K-master/pytorch_model/yoloUtil.py:143: RuntimeWarning: overflow encountered in exp\r\n  box_wh = np.exp(feature[..., 2:4])\r\nFound 0 boxes for COCO_val2014_000000000042.jpg\r\nFinish\r\n```\r\nCould you please tell me, what is wrong? what is the cause of this error?\r\nbest."}