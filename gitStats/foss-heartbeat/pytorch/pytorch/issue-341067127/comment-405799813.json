{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/405799813", "html_url": "https://github.com/pytorch/pytorch/pull/9422#issuecomment-405799813", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9422", "id": 405799813, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTc5OTgxMw==", "user": {"login": "zasdfgbnm", "id": 1032377, "node_id": "MDQ6VXNlcjEwMzIzNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1032377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zasdfgbnm", "html_url": "https://github.com/zasdfgbnm", "followers_url": "https://api.github.com/users/zasdfgbnm/followers", "following_url": "https://api.github.com/users/zasdfgbnm/following{/other_user}", "gists_url": "https://api.github.com/users/zasdfgbnm/gists{/gist_id}", "starred_url": "https://api.github.com/users/zasdfgbnm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zasdfgbnm/subscriptions", "organizations_url": "https://api.github.com/users/zasdfgbnm/orgs", "repos_url": "https://api.github.com/users/zasdfgbnm/repos", "events_url": "https://api.github.com/users/zasdfgbnm/events{/privacy}", "received_events_url": "https://api.github.com/users/zasdfgbnm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-18T03:45:30Z", "updated_at": "2018-07-18T04:13:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> I have added the unit tests. One problem found was, for program like:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> math\n\na <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.double)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">x</span>):\n    <span class=\"pl-k\">return</span> math.pi <span class=\"pl-k\">*</span> x\n\ng <span class=\"pl-k\">=</span> torch.jit.script(f)\n\n<span class=\"pl-c1\">print</span>(f(a))\n<span class=\"pl-c1\">print</span>(g(a))</pre></div>\n<p>gives</p>\n<pre><code>tensor(3.1416, dtype=torch.float64)\nTraceback (most recent call last):\n  File \"test_.py\", line 12, in &lt;module&gt;\n    print(g(a))\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nRuntimeError: \nExpected object of type CPUFloatType but found type CPUDoubleType for argument #2 'other' (checked_cast_tensor at ../aten/src/ATen/Utils.h:42)\n</code></pre>\n<p>This is because in <code>ConstantPythonValue::create</code>, all floating python values are converted to <code>at::CPU(at::kFloat).scalarTensor</code>.</p>\n<p>This seems to be not easy to fix. I'm having similar problem for literals:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> math\n\na <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.double)\nb <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1.0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">f</span>(<span class=\"pl-smi\">x</span>):\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">3.14</span> <span class=\"pl-k\">*</span> x\n\ng <span class=\"pl-k\">=</span> torch.jit.script(f)\n\n<span class=\"pl-c1\">print</span>(f(a))\n<span class=\"pl-c1\">print</span>(g(a))\n<span class=\"pl-c1\">print</span>(f(b))\n<span class=\"pl-c1\">print</span>(g(b))</pre></div>\n<p>gives</p>\n<pre><code>tensor(3.1400, dtype=torch.float64)\ntensor(3.1400, dtype=torch.float64)\ntensor(3.1400)\nTraceback (most recent call last):\n  File \"test.py\", line 15, in &lt;module&gt;\n    print(g(b))\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nRuntimeError: torch/csrc/jit/fusion_compiler.cpp:526: operator(): Assertion `nDim &lt;= uncompressedDim` failed.\n</code></pre>\n<p>Is it OK to leave this problem as is? Or is there a good solution for that?</p>", "body_text": "@ezyang I have added the unit tests. One problem found was, for program like:\nimport torch\nimport math\n\na = torch.tensor(1.0, dtype=torch.double)\n\ndef f(x):\n    return math.pi * x\n\ng = torch.jit.script(f)\n\nprint(f(a))\nprint(g(a))\ngives\ntensor(3.1416, dtype=torch.float64)\nTraceback (most recent call last):\n  File \"test_.py\", line 12, in <module>\n    print(g(a))\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nRuntimeError: \nExpected object of type CPUFloatType but found type CPUDoubleType for argument #2 'other' (checked_cast_tensor at ../aten/src/ATen/Utils.h:42)\n\nThis is because in ConstantPythonValue::create, all floating python values are converted to at::CPU(at::kFloat).scalarTensor.\nThis seems to be not easy to fix. I'm having similar problem for literals:\nimport torch\nimport math\n\na = torch.tensor(1.0, dtype=torch.double)\nb = torch.tensor(1.0, dtype=torch.float)\n\ndef f(x):\n    return 3.14 * x\n\ng = torch.jit.script(f)\n\nprint(f(a))\nprint(g(a))\nprint(f(b))\nprint(g(b))\ngives\ntensor(3.1400, dtype=torch.float64)\ntensor(3.1400, dtype=torch.float64)\ntensor(3.1400)\nTraceback (most recent call last):\n  File \"test.py\", line 15, in <module>\n    print(g(b))\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n    result = self.forward(*input, **kwargs)\nRuntimeError: torch/csrc/jit/fusion_compiler.cpp:526: operator(): Assertion `nDim <= uncompressedDim` failed.\n\nIs it OK to leave this problem as is? Or is there a good solution for that?", "body": "@ezyang I have added the unit tests. One problem found was, for program like:\r\n```python\r\nimport torch\r\nimport math\r\n\r\na = torch.tensor(1.0, dtype=torch.double)\r\n\r\ndef f(x):\r\n    return math.pi * x\r\n\r\ng = torch.jit.script(f)\r\n\r\nprint(f(a))\r\nprint(g(a))\r\n```\r\ngives\r\n```\r\ntensor(3.1416, dtype=torch.float64)\r\nTraceback (most recent call last):\r\n  File \"test_.py\", line 12, in <module>\r\n    print(g(a))\r\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\nRuntimeError: \r\nExpected object of type CPUFloatType but found type CPUDoubleType for argument #2 'other' (checked_cast_tensor at ../aten/src/ATen/Utils.h:42)\r\n```\r\nThis is because in `ConstantPythonValue::create`, all floating python values are converted to `at::CPU(at::kFloat).scalarTensor`.\r\n\r\nThis seems to be not easy to fix. I'm having similar problem for literals:\r\n\r\n```python\r\nimport torch\r\nimport math\r\n\r\na = torch.tensor(1.0, dtype=torch.double)\r\nb = torch.tensor(1.0, dtype=torch.float)\r\n\r\ndef f(x):\r\n    return 3.14 * x\r\n\r\ng = torch.jit.script(f)\r\n\r\nprint(f(a))\r\nprint(g(a))\r\nprint(f(b))\r\nprint(g(b))\r\n```\r\ngives\r\n```\r\ntensor(3.1400, dtype=torch.float64)\r\ntensor(3.1400, dtype=torch.float64)\r\ntensor(3.1400)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 15, in <module>\r\n    print(g(b))\r\n  File \"/home/gaoxiang/pytorch-dev/pytorchdev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\r\n    result = self.forward(*input, **kwargs)\r\nRuntimeError: torch/csrc/jit/fusion_compiler.cpp:526: operator(): Assertion `nDim <= uncompressedDim` failed.\r\n```\r\n\r\nIs it OK to leave this problem as is? Or is there a good solution for that?"}