{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/284081837", "html_url": "https://github.com/pytorch/pytorch/issues/914#issuecomment-284081837", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/914", "id": 284081837, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NDA4MTgzNw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-03T21:59:56Z", "updated_at": "2017-03-03T21:59:56Z", "author_association": "MEMBER", "body_html": "<p>One simple fix was to make the workspace local to the function call. Right now it has been cached in the function object and it reserved at least 250MB per each time step even when a very small batch size was used. Before the change I could only fit in memory a batch of 8 sequences of length 20, but after a batch size of 64 with 35 time steps can be used. But there must be something else too.</p>", "body_text": "One simple fix was to make the workspace local to the function call. Right now it has been cached in the function object and it reserved at least 250MB per each time step even when a very small batch size was used. Before the change I could only fit in memory a batch of 8 sequences of length 20, but after a batch size of 64 with 35 time steps can be used. But there must be something else too.", "body": "One simple fix was to make the workspace local to the function call. Right now it has been cached in the function object and it reserved at least 250MB per each time step even when a very small batch size was used. Before the change I could only fit in memory a batch of 8 sequences of length 20, but after a batch size of 64 with 35 time steps can be used. But there must be something else too."}