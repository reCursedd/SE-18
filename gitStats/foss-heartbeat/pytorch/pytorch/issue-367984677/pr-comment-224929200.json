{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/224929200", "pull_request_review_id": 164426682, "id": 224929200, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNDkyOTIwMA==", "diff_hunk": "@@ -0,0 +1,284 @@\n+#include \"torch/csrc/TypeInfo.h\"\n+\n+#include \"torch/csrc/Exceptions.h\"\n+#include \"torch/csrc/utils/object_ptr.h\"\n+#include \"torch/csrc/utils/pybind.h\"\n+#include \"torch/csrc/utils/python_arg_parser.h\"\n+#include \"torch/csrc/utils/python_numbers.h\"\n+#include \"torch/csrc/utils/python_strings.h\"\n+\n+#include <ATen/core/Error.h>\n+\n+#include <structmember.h>\n+#include <cstring>\n+#include <limits>\n+#include <sstream>\n+\n+PyObject* THPFInfo_New(const at::ScalarType& type) {\n+  auto finfo = (PyTypeObject*)&THPFInfoType;\n+  auto self = THPObjectPtr{finfo->tp_alloc(finfo, 0)};\n+  if (!self)\n+    throw python_error();\n+  auto self_ = reinterpret_cast<THPDTypeInfo*>(self.get());\n+  self_->type = type;\n+  return self.release();\n+}\n+\n+PyObject* THPIInfo_New(const at::ScalarType& type) {\n+  auto iinfo = (PyTypeObject*)&THPIInfoType;\n+  auto self = THPObjectPtr{iinfo->tp_alloc(iinfo, 0)};\n+  if (!self)\n+    throw python_error();\n+  auto self_ = reinterpret_cast<THPDTypeInfo*>(self.get());\n+  self_->type = type;\n+  return self.release();\n+}\n+\n+PyObject* THPDTypeInfo_repr(THPDTypeInfo* self) {\n+  std::ostringstream oss;\n+  oss << \"type_info(type=\" << self->type << \")\";\n+  return THPUtils_packString(oss.str().c_str());\n+}\n+\n+PyObject* THPDTypeInfo_str(THPDTypeInfo* self) {\n+  std::ostringstream oss;\n+  oss << \"type_info(type=\" << self->type << \")\";\n+  return THPUtils_packString(oss.str().c_str());\n+}\n+\n+PyObject* THPFInfo_pynew(PyTypeObject* type, PyObject* args, PyObject* kwargs) {\n+  HANDLE_TH_ERRORS\n+  static torch::PythonArgParser parser({\n+      \"ScalarType(ScalarType type)\",\n+  });\n+  torch::ParsedArgs<1> parsed_args;\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+  AT_CHECK(r.idx == 0, \"Not a type\");\n+  at::ScalarType scalar_type = r.scalartype(0);\n+  if (!at::isFloatingType(scalar_type)) {\n+    return PyErr_Format(\n+        PyExc_TypeError,\n+        \"torch.finfo() requires a floating point input type. Use torch.iinfo to handle '%s'\",\n+        type->tp_name);\n+  }\n+  return THPFInfo_New(scalar_type);\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+PyObject* THPIInfo_pynew(PyTypeObject* type, PyObject* args, PyObject* kwargs) {\n+  HANDLE_TH_ERRORS\n+  static torch::PythonArgParser parser({\n+      \"ScalarType(ScalarType type)\",\n+  });\n+  torch::ParsedArgs<1> parsed_args;\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+  AT_CHECK(r.idx == 0, \"Not a type\");\n+\n+  at::ScalarType scalar_type = r.scalartype(0);\n+  if (at::isFloatingType(scalar_type)) {\n+    return PyErr_Format(\n+        PyExc_TypeError,\n+        \"torch.iinfo() requires an integer input type. Use torch.finfo to handle '%s'\",\n+        type->tp_name);\n+  }\n+  return THPIInfo_New(scalar_type);\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static PyObject* THPDTypeInfo_bits(THPDTypeInfo* self, void*) {\n+  int bits = elementSize(self->type) * 8;\n+  return PyLong_FromLong(bits);\n+}\n+\n+static PyObject* THPFInfo_eps(THPFInfo* self, void*) {\n+  switch (self->type) {\n+    case at::ScalarType::Float:\n+      return PyFloat_FromDouble(std::numeric_limits<float>::epsilon());\n+    case at::ScalarType::Double:\n+      return PyFloat_FromDouble(std::numeric_limits<double>::epsilon());\n+    case at::ScalarType::Half:\n+      return PyFloat_FromDouble(std::numeric_limits<at::Half>::epsilon());\n+    case at::ScalarType::ComplexFloat:\n+      return PyFloat_FromDouble(std::numeric_limits<float>::epsilon());\n+    case at::ScalarType::ComplexDouble:\n+      return PyFloat_FromDouble(std::numeric_limits<double>::epsilon());\n+    case at::ScalarType::ComplexHalf:\n+      return PyFloat_FromDouble(std::numeric_limits<at::Half>::epsilon());\n+    default:\n+      return Py_NotImplemented;", "path": "torch/csrc/TypeInfo.cpp", "position": null, "original_position": 108, "commit_id": "40738747edcecfbd4b6e95be2f07b9faea7c9b69", "original_commit_id": "2f98db9b7add8cd6d9382c267e1b525d68c157c9", "user": {"login": "benoitsteiner", "id": 6969686, "node_id": "MDQ6VXNlcjY5Njk2ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6969686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benoitsteiner", "html_url": "https://github.com/benoitsteiner", "followers_url": "https://api.github.com/users/benoitsteiner/followers", "following_url": "https://api.github.com/users/benoitsteiner/following{/other_user}", "gists_url": "https://api.github.com/users/benoitsteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/benoitsteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benoitsteiner/subscriptions", "organizations_url": "https://api.github.com/users/benoitsteiner/orgs", "repos_url": "https://api.github.com/users/benoitsteiner/repos", "events_url": "https://api.github.com/users/benoitsteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/benoitsteiner/received_events", "type": "User", "site_admin": false}, "body": "Indeed, thanks for catching this", "created_at": "2018-10-12T22:20:32Z", "updated_at": "2018-11-23T15:52:57Z", "html_url": "https://github.com/pytorch/pytorch/pull/12472#discussion_r224929200", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12472", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/224929200"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12472#discussion_r224929200"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12472"}}, "body_html": "<p>Indeed, thanks for catching this</p>", "body_text": "Indeed, thanks for catching this", "in_reply_to_id": 223530655}