{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347838407", "html_url": "https://github.com/pytorch/pytorch/issues/3930#issuecomment-347838407", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3930", "id": 347838407, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzgzODQwNw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T11:54:45Z", "updated_at": "2017-11-29T11:55:21Z", "author_association": "MEMBER", "body_html": "<p>Some preliminary results from caching the replicas. Unless the cache doesn't need to be refreshed the times look like this:</p>\n<ol>\n<li>Broadcasting parameters - 34.05 ms</li>\n<li>Broadcasting buffers - 16.02 ms</li>\n<li>Result assignment - 15.74 ms</li>\n</ol>\n<p><strong>TOTAL: 65.81 ms</strong></p>\n<p>The times for broadcasts are shorter mostly because I also cache flat parameter lists, so we don't need to iterate over the module DAG every time. BTW This change doesn't move anything to C++, so that is still an option to get better perf.</p>", "body_text": "Some preliminary results from caching the replicas. Unless the cache doesn't need to be refreshed the times look like this:\n\nBroadcasting parameters - 34.05 ms\nBroadcasting buffers - 16.02 ms\nResult assignment - 15.74 ms\n\nTOTAL: 65.81 ms\nThe times for broadcasts are shorter mostly because I also cache flat parameter lists, so we don't need to iterate over the module DAG every time. BTW This change doesn't move anything to C++, so that is still an option to get better perf.", "body": "Some preliminary results from caching the replicas. Unless the cache doesn't need to be refreshed the times look like this:\r\n\r\n1. Broadcasting parameters - 34.05 ms \r\n2. Broadcasting buffers - 16.02 ms \r\n3. Result assignment - 15.74 ms\r\n\r\n**TOTAL: 65.81 ms**\r\n\r\nThe times for broadcasts are shorter mostly because I also cache flat parameter lists, so we don't need to iterate over the module DAG every time. BTW This change doesn't move anything to C++, so that is still an option to get better perf."}