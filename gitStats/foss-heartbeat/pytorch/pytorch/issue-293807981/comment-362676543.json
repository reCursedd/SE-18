{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/362676543", "html_url": "https://github.com/pytorch/pytorch/issues/5008#issuecomment-362676543", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5008", "id": 362676543, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjY3NjU0Mw==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-02T19:07:08Z", "updated_at": "2018-02-02T19:07:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=39722092\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/a367\">@a367</a> The tensor variable inconsistency will be fixed when they become the same class. But giving the incorrect results is definitely problematic. Thanks for reporting this.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4556044\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Stonesjtu\">@Stonesjtu</a> This will also be fixed when the two classes merge. But at the moment, actually outputs of your code is somewhat expected. Reduction ops on tensors gives numeric values. But on variables they give a numel=1 Variable (so that they can keep track of history and do autograd). <code>a.sum()</code> gives you python int 3, and then <code>3 * 0.3 = 0.9</code>. <code>b.sum()</code> gives you <code>Variable(LongTensor([3]))</code>, so multiplying by 0.3 gives you what you see.</p>", "body_text": "@a367 The tensor variable inconsistency will be fixed when they become the same class. But giving the incorrect results is definitely problematic. Thanks for reporting this.\n@Stonesjtu This will also be fixed when the two classes merge. But at the moment, actually outputs of your code is somewhat expected. Reduction ops on tensors gives numeric values. But on variables they give a numel=1 Variable (so that they can keep track of history and do autograd). a.sum() gives you python int 3, and then 3 * 0.3 = 0.9. b.sum() gives you Variable(LongTensor([3])), so multiplying by 0.3 gives you what you see.", "body": "@a367 The tensor variable inconsistency will be fixed when they become the same class. But giving the incorrect results is definitely problematic. Thanks for reporting this.\r\n\r\n@Stonesjtu This will also be fixed when the two classes merge. But at the moment, actually outputs of your code is somewhat expected. Reduction ops on tensors gives numeric values. But on variables they give a numel=1 Variable (so that they can keep track of history and do autograd). `a.sum()` gives you python int 3, and then `3 * 0.3 = 0.9`. `b.sum()` gives you `Variable(LongTensor([3]))`, so multiplying by 0.3 gives you what you see."}