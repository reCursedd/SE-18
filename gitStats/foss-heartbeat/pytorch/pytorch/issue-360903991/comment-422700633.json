{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422700633", "html_url": "https://github.com/pytorch/pytorch/issues/11756#issuecomment-422700633", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11756", "id": 422700633, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjcwMDYzMw==", "user": {"login": "chenwc07", "id": 40051091, "node_id": "MDQ6VXNlcjQwMDUxMDkx", "avatar_url": "https://avatars2.githubusercontent.com/u/40051091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenwc07", "html_url": "https://github.com/chenwc07", "followers_url": "https://api.github.com/users/chenwc07/followers", "following_url": "https://api.github.com/users/chenwc07/following{/other_user}", "gists_url": "https://api.github.com/users/chenwc07/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenwc07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenwc07/subscriptions", "organizations_url": "https://api.github.com/users/chenwc07/orgs", "repos_url": "https://api.github.com/users/chenwc07/repos", "events_url": "https://api.github.com/users/chenwc07/events{/privacy}", "received_events_url": "https://api.github.com/users/chenwc07/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T08:05:42Z", "updated_at": "2018-09-19T08:05:42Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9845\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pietern\">@pietern</a> I tried the code on the machine with 4 Titan X, and it works well. Then I just copy the entire conda environment to the Titan xp machine and clone an exactly same environment. When running the same code I get:<br>\nTraceback (most recent call last):<br>\nFile \"test_cuda.py\", line 26, in <br>\nout = model(testdata)<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 491, in <strong>call</strong><br>\nresult = self.forward(*input, **kwargs)<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward<br>\nreplicas = self.replicate(self.module, self.device_ids[:len(inputs)])<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate<br>\nreturn replicate(module, device_ids)<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate<br>\nparam_copies = Broadcast.apply(devices, *params)<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 17, in forward<br>\noutputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)<br>\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/cuda/comm.py\", line 40, in broadcast_coalesced<br>\nreturn torch._C._broadcast_coalesced(tensors, devices, buffer_size)<br>\nRuntimeError: NCCL Error 1: unhandled cuda error<br>\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c line=184 error=77 : an illegal memory access was encountered<br>\nterminate called after throwing an instance of 'std::runtime_error'<br>\nwhat():  cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c:184<br>\nAborted (core dumped)</p>\n<p>The Nvidia driver version and cuda/cudnn version are the same.</p>", "body_text": "@pietern I tried the code on the machine with 4 Titan X, and it works well. Then I just copy the entire conda environment to the Titan xp machine and clone an exactly same environment. When running the same code I get:\nTraceback (most recent call last):\nFile \"test_cuda.py\", line 26, in \nout = model(testdata)\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 491, in call\nresult = self.forward(*input, **kwargs)\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward\nreplicas = self.replicate(self.module, self.device_ids[:len(inputs)])\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate\nreturn replicate(module, device_ids)\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\nparam_copies = Broadcast.apply(devices, *params)\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 17, in forward\noutputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)\nFile \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/cuda/comm.py\", line 40, in broadcast_coalesced\nreturn torch._C._broadcast_coalesced(tensors, devices, buffer_size)\nRuntimeError: NCCL Error 1: unhandled cuda error\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c line=184 error=77 : an illegal memory access was encountered\nterminate called after throwing an instance of 'std::runtime_error'\nwhat():  cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c:184\nAborted (core dumped)\nThe Nvidia driver version and cuda/cudnn version are the same.", "body": "@pietern I tried the code on the machine with 4 Titan X, and it works well. Then I just copy the entire conda environment to the Titan xp machine and clone an exactly same environment. When running the same code I get:\r\nTraceback (most recent call last):\r\n  File \"test_cuda.py\", line 26, in <module>\r\n    out = model(testdata)\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 491, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward\r\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate\r\n    return replicate(module, device_ids)\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/replicate.py\", line 12, in replicate\r\n    param_copies = Broadcast.apply(devices, *params)\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 17, in forward\r\n    outputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)\r\n  File \"/home/zhangd/anaconda3/envs/pytorch-clone/lib/python3.5/site-packages/torch/cuda/comm.py\", line 40, in broadcast_coalesced\r\n    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)\r\nRuntimeError: NCCL Error 1: unhandled cuda error\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c line=184 error=77 : an illegal memory access was encountered\r\nterminate called after throwing an instance of 'std::runtime_error'\r\n  what():  cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCStorage.c:184\r\nAborted (core dumped)\r\n\r\nThe Nvidia driver version and cuda/cudnn version are the same."}