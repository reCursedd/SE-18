{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422813464", "html_url": "https://github.com/pytorch/pytorch/issues/11756#issuecomment-422813464", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11756", "id": 422813464, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjgxMzQ2NA==", "user": {"login": "chenwc07", "id": 40051091, "node_id": "MDQ6VXNlcjQwMDUxMDkx", "avatar_url": "https://avatars2.githubusercontent.com/u/40051091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenwc07", "html_url": "https://github.com/chenwc07", "followers_url": "https://api.github.com/users/chenwc07/followers", "following_url": "https://api.github.com/users/chenwc07/following{/other_user}", "gists_url": "https://api.github.com/users/chenwc07/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenwc07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenwc07/subscriptions", "organizations_url": "https://api.github.com/users/chenwc07/orgs", "repos_url": "https://api.github.com/users/chenwc07/repos", "events_url": "https://api.github.com/users/chenwc07/events{/privacy}", "received_events_url": "https://api.github.com/users/chenwc07/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T13:56:06Z", "updated_at": "2018-09-19T13:56:06Z", "author_association": "NONE", "body_html": "<p>I found everything is going well when device_ids=[0,2,3] today! So I doubt there may be something wrong with the GPU1. Then I test the GPU one by one using another simple code like:<br>\n<code>os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'</code><br>\n<code>model.cuda(0)</code><br>\n<code>data = data.cuda(0)</code><br>\n<code>output = model(data)</code></p>\n<p>then I get the error message:</p>\n<p>RuntimeError                              Traceback (most recent call last)<br>\n in ()<br>\n6         labels = labels.cuda(0)<br>\n7<br>\n----&gt; 8         outputs = model(images)<br>\n9         loss = criterion(outputs, labels)<br>\n10</p>\n<p>/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in <strong>call</strong>(self, *input, **kwargs)<br>\n475             result = self._slow_forward(*input, **kwargs)<br>\n476         else:<br>\n--&gt; 477             result = self.forward(*input, **kwargs)<br>\n478         for hook in self._forward_hooks.values():<br>\n479             hook_result = hook(self, input, result)</p>\n<p> in forward(self, x)<br>\n34         out = self.avgpool(out)<br>\n35         out = out.view(out.size(0), -1)<br>\n---&gt; 36         out = self.fc(out)<br>\n37         return out</p>\n<p>/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in <strong>call</strong>(self, *input, **kwargs)<br>\n475             result = self._slow_forward(*input, **kwargs)<br>\n476         else:<br>\n--&gt; 477             result = self.forward(*input, **kwargs)<br>\n478         for hook in self._forward_hooks.values():<br>\n479             hook_result = hook(self, input, result)</p>\n<p>/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/linear.py in forward(self, input)<br>\n53<br>\n54     def forward(self, input):<br>\n---&gt; 55         return F.linear(input, self.weight, self.bias)<br>\n56<br>\n57     def extra_repr(self):</p>\n<p>/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/functional.py in linear(input, weight, bias)<br>\n1022     if input.dim() == 2 and bias is not None:<br>\n1023         # fused op is marginally faster<br>\n-&gt; 1024         return torch.addmm(bias, input, weight.t())<br>\n1025<br>\n1026     output = input.matmul(weight.t())</p>\n<p>RuntimeError: cublas runtime error : resource allocation failed at /opt/conda/conda-bld/pytorch_1532576128691/work/aten/src/THC/THCGeneral.cpp:333</p>\n<p>So there maybe something wrong with my GPU1 or there maybe a bug from pytorch?</p>", "body_text": "I found everything is going well when device_ids=[0,2,3] today! So I doubt there may be something wrong with the GPU1. Then I test the GPU one by one using another simple code like:\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\nmodel.cuda(0)\ndata = data.cuda(0)\noutput = model(data)\nthen I get the error message:\nRuntimeError                              Traceback (most recent call last)\n in ()\n6         labels = labels.cuda(0)\n7\n----> 8         outputs = model(images)\n9         loss = criterion(outputs, labels)\n10\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)\n475             result = self._slow_forward(*input, **kwargs)\n476         else:\n--> 477             result = self.forward(*input, **kwargs)\n478         for hook in self._forward_hooks.values():\n479             hook_result = hook(self, input, result)\n in forward(self, x)\n34         out = self.avgpool(out)\n35         out = out.view(out.size(0), -1)\n---> 36         out = self.fc(out)\n37         return out\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in call(self, *input, **kwargs)\n475             result = self._slow_forward(*input, **kwargs)\n476         else:\n--> 477             result = self.forward(*input, **kwargs)\n478         for hook in self._forward_hooks.values():\n479             hook_result = hook(self, input, result)\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/linear.py in forward(self, input)\n53\n54     def forward(self, input):\n---> 55         return F.linear(input, self.weight, self.bias)\n56\n57     def extra_repr(self):\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/functional.py in linear(input, weight, bias)\n1022     if input.dim() == 2 and bias is not None:\n1023         # fused op is marginally faster\n-> 1024         return torch.addmm(bias, input, weight.t())\n1025\n1026     output = input.matmul(weight.t())\nRuntimeError: cublas runtime error : resource allocation failed at /opt/conda/conda-bld/pytorch_1532576128691/work/aten/src/THC/THCGeneral.cpp:333\nSo there maybe something wrong with my GPU1 or there maybe a bug from pytorch?", "body": "I found everything is going well when device_ids=[0,2,3] today! So I doubt there may be something wrong with the GPU1. Then I test the GPU one by one using another simple code like:\r\n`os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'`\r\n`model.cuda(0)`\r\n`data = data.cuda(0)`\r\n`output = model(data)`\r\n\r\nthen I get the error message:\r\n\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-11-5a67f555efe4> in <module>()\r\n      6         labels = labels.cuda(0)\r\n      7 \r\n----> 8         outputs = model(images)\r\n      9         loss = criterion(outputs, labels)\r\n     10 \r\n\r\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n--> 477             result = self.forward(*input, **kwargs)\r\n    478         for hook in self._forward_hooks.values():\r\n    479             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-7-f744eb62f792> in forward(self, x)\r\n     34         out = self.avgpool(out)\r\n     35         out = out.view(out.size(0), -1)\r\n---> 36         out = self.fc(out)\r\n     37         return out\r\n\r\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    475             result = self._slow_forward(*input, **kwargs)\r\n    476         else:\r\n--> 477             result = self.forward(*input, **kwargs)\r\n    478         for hook in self._forward_hooks.values():\r\n    479             hook_result = hook(self, input, result)\r\n\r\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/linear.py in forward(self, input)\r\n     53 \r\n     54     def forward(self, input):\r\n---> 55         return F.linear(input, self.weight, self.bias)\r\n     56 \r\n     57     def extra_repr(self):\r\n\r\n/home/zhangd/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/functional.py in linear(input, weight, bias)\r\n   1022     if input.dim() == 2 and bias is not None:\r\n   1023         # fused op is marginally faster\r\n-> 1024         return torch.addmm(bias, input, weight.t())\r\n   1025 \r\n   1026     output = input.matmul(weight.t())\r\n\r\nRuntimeError: cublas runtime error : resource allocation failed at /opt/conda/conda-bld/pytorch_1532576128691/work/aten/src/THC/THCGeneral.cpp:333\r\n\r\nSo there maybe something wrong with my GPU1 or there maybe a bug from pytorch?\r\n"}