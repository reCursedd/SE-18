{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1272", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1272/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1272/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1272/events", "html_url": "https://github.com/pytorch/pytorch/issues/1272", "id": 222114184, "node_id": "MDU6SXNzdWUyMjIxMTQxODQ=", "number": 1272, "title": "memory leak(cpu, not gpu) in convolution layer", "user": {"login": "nido4010", "id": 23404351, "node_id": "MDQ6VXNlcjIzNDA0MzUx", "avatar_url": "https://avatars0.githubusercontent.com/u/23404351?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nido4010", "html_url": "https://github.com/nido4010", "followers_url": "https://api.github.com/users/nido4010/followers", "following_url": "https://api.github.com/users/nido4010/following{/other_user}", "gists_url": "https://api.github.com/users/nido4010/gists{/gist_id}", "starred_url": "https://api.github.com/users/nido4010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nido4010/subscriptions", "organizations_url": "https://api.github.com/users/nido4010/orgs", "repos_url": "https://api.github.com/users/nido4010/repos", "events_url": "https://api.github.com/users/nido4010/events{/privacy}", "received_events_url": "https://api.github.com/users/nido4010/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 491934870, "node_id": "MDU6TGFiZWw0OTE5MzQ4NzA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/dependency%20bug", "name": "dependency bug", "color": "b60205", "default": false}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2017-04-17T11:18:09Z", "updated_at": "2017-10-12T13:29:30Z", "closed_at": "2017-09-13T13:04:12Z", "author_association": "NONE", "body_html": "<p>Hello<br>\nI have a problem related to memory leak(cpu, not gpu) in ubuntu os.</p>\n<p>when I run below code with cudnn 5.1 and 6.0, memory usage increases every epoch.<br>\n(memory leak doesn't occur with cudnn 5.0, but cudnn 5.0 is 2x slower than cudnn 5.1 and 6.0)<br>\n<a href=\"https://gist.github.com/nido4010/6f533f1e55ae1fd38a017533f72dd3e8\">https://gist.github.com/nido4010/6f533f1e55ae1fd38a017533f72dd3e8</a></p>\n<p>To manually select convolution algorithm, I revise the code, pytorch-master/torch/csrc/cudnn/Conv.cpp<br>\nthe revised code is below<br>\n<a href=\"https://gist.github.com/nido4010/5686db92b1bbf1f252154b42b1cca95c\">https://gist.github.com/nido4010/5686db92b1bbf1f252154b42b1cca95c</a><br>\nrevision list</p>\n<ol>\n<li>comment out \"findAlgorithm(state, handle, conv, benchmark, algo);\" ( line 240)</li>\n<li>cudnnConvolutionFwdAlgo_t fwdAlg =<br>\nCUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED;( line 320)</li>\n<li>cudnnConvolutionBwdDataAlgo_t bwdDataAlg =<br>\nCUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED;( line 367)</li>\n<li>cudnnConvolutionBwdFilterAlgo_t bwdFilterAlg =<br>\nCUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED;(line 395)</li>\n</ol>\n<p>I check memory leak, while I change the forward, backward data, backward filter algorithm.<br>\nAlgorithm list is provided in cudnn user guide.</p>\n<p>when I select CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED for forward convolution, which is newly added in cudnn 5.1, memory usage increases by about 90MB every epoch.</p>\n<p>when I select CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED for backward data convolution, which is newly added in cudnn 5.1, memory usage increases by about 120MB every epoch.</p>\n<p>when I select CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED for backward filter convolution, which is newly added in cudnn 5.1, memory usage increases by about 130MB every epoch.</p>\n<p>About the other algorithms, memory leak doesn't occur.<br>\nI have not yet test the above experiment with cudnn 6.0, but memory leak occur when I compile pytorch with cudnn 6.0.</p>\n<p>Is there anybody who experiences memory leak like above??</p>\n<p>Experiment setup</p>\n<ol>\n<li>OS : linux mint 18.1(ubuntu 16.04.1)</li>\n<li>cuda : 8.0</li>\n<li>cudnn : 5.1</li>\n<li>python : 2.7</li>\n</ol>", "body_text": "Hello\nI have a problem related to memory leak(cpu, not gpu) in ubuntu os.\nwhen I run below code with cudnn 5.1 and 6.0, memory usage increases every epoch.\n(memory leak doesn't occur with cudnn 5.0, but cudnn 5.0 is 2x slower than cudnn 5.1 and 6.0)\nhttps://gist.github.com/nido4010/6f533f1e55ae1fd38a017533f72dd3e8\nTo manually select convolution algorithm, I revise the code, pytorch-master/torch/csrc/cudnn/Conv.cpp\nthe revised code is below\nhttps://gist.github.com/nido4010/5686db92b1bbf1f252154b42b1cca95c\nrevision list\n\ncomment out \"findAlgorithm(state, handle, conv, benchmark, algo);\" ( line 240)\ncudnnConvolutionFwdAlgo_t fwdAlg =\nCUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED;( line 320)\ncudnnConvolutionBwdDataAlgo_t bwdDataAlg =\nCUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED;( line 367)\ncudnnConvolutionBwdFilterAlgo_t bwdFilterAlg =\nCUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED;(line 395)\n\nI check memory leak, while I change the forward, backward data, backward filter algorithm.\nAlgorithm list is provided in cudnn user guide.\nwhen I select CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED for forward convolution, which is newly added in cudnn 5.1, memory usage increases by about 90MB every epoch.\nwhen I select CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED for backward data convolution, which is newly added in cudnn 5.1, memory usage increases by about 120MB every epoch.\nwhen I select CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED for backward filter convolution, which is newly added in cudnn 5.1, memory usage increases by about 130MB every epoch.\nAbout the other algorithms, memory leak doesn't occur.\nI have not yet test the above experiment with cudnn 6.0, but memory leak occur when I compile pytorch with cudnn 6.0.\nIs there anybody who experiences memory leak like above??\nExperiment setup\n\nOS : linux mint 18.1(ubuntu 16.04.1)\ncuda : 8.0\ncudnn : 5.1\npython : 2.7", "body": "Hello\r\nI have a problem related to memory leak(cpu, not gpu) in ubuntu os.\r\n\r\nwhen I run below code with cudnn 5.1 and 6.0, memory usage increases every epoch.\r\n(memory leak doesn't occur with cudnn 5.0, but cudnn 5.0 is 2x slower than cudnn 5.1 and 6.0)\r\nhttps://gist.github.com/nido4010/6f533f1e55ae1fd38a017533f72dd3e8\r\n\r\nTo manually select convolution algorithm, I revise the code, pytorch-master/torch/csrc/cudnn/Conv.cpp\r\nthe revised code is below\r\nhttps://gist.github.com/nido4010/5686db92b1bbf1f252154b42b1cca95c\r\nrevision list \r\n1. comment out \"findAlgorithm(state, handle, conv, benchmark, algo);\" ( line 240)\r\n2. cudnnConvolutionFwdAlgo_t fwdAlg =\r\nCUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED;( line 320)\r\n3. cudnnConvolutionBwdDataAlgo_t bwdDataAlg =\r\nCUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED;( line 367)\r\n4. cudnnConvolutionBwdFilterAlgo_t bwdFilterAlg =\r\nCUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED;(line 395)\r\n\r\nI check memory leak, while I change the forward, backward data, backward filter algorithm.\r\nAlgorithm list is provided in cudnn user guide.\r\n\r\nwhen I select CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED for forward convolution, which is newly added in cudnn 5.1, memory usage increases by about 90MB every epoch.\r\n\r\nwhen I select CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED for backward data convolution, which is newly added in cudnn 5.1, memory usage increases by about 120MB every epoch.\r\n\r\nwhen I select CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED for backward filter convolution, which is newly added in cudnn 5.1, memory usage increases by about 130MB every epoch.\r\n\r\nAbout the other algorithms, memory leak doesn't occur.\r\nI have not yet test the above experiment with cudnn 6.0, but memory leak occur when I compile pytorch with cudnn 6.0.\r\n\r\nIs there anybody who experiences memory leak like above??\r\n\r\nExperiment setup\r\n1. OS : linux mint 18.1(ubuntu 16.04.1)\r\n2. cuda : 8.0\r\n3. cudnn : 5.1\r\n4. python : 2.7\r\n\r\n\r\n\r\n\r\n\r\n\r\n \r\n"}