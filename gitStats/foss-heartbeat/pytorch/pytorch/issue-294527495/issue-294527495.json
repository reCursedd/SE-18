{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5059", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5059/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5059/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5059/events", "html_url": "https://github.com/pytorch/pytorch/issues/5059", "id": 294527495, "node_id": "MDU6SXNzdWUyOTQ1Mjc0OTU=", "number": 5059, "title": "np.random generates the same random numbers for each data batch", "user": {"login": "taoari", "id": 3815006, "node_id": "MDQ6VXNlcjM4MTUwMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/3815006?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taoari", "html_url": "https://github.com/taoari", "followers_url": "https://api.github.com/users/taoari/followers", "following_url": "https://api.github.com/users/taoari/following{/other_user}", "gists_url": "https://api.github.com/users/taoari/gists{/gist_id}", "starred_url": "https://api.github.com/users/taoari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taoari/subscriptions", "organizations_url": "https://api.github.com/users/taoari/orgs", "repos_url": "https://api.github.com/users/taoari/repos", "events_url": "https://api.github.com/users/taoari/events{/privacy}", "received_events_url": "https://api.github.com/users/taoari/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-02-05T20:14:45Z", "updated_at": "2018-08-15T12:04:38Z", "closed_at": "2018-02-05T20:50:53Z", "author_association": "NONE", "body_html": "<p>For example, the following script</p>\n<pre><code>from __future__ import print_function\n\nimport numpy as np\nimport random\n\n# np.random.seed(0)\n\nclass Transform(object):\n    def __init__(self):\n        pass\n\n    def __call__(self, item = None):\n        return [np.random.randint(10000, 20000), random.randint(20000,30000)]\n\nclass RandomDataset(object):\n\n    def __init__(self):\n        pass\n\n    def __getitem__(self, ind):\n        item = [ind, np.random.randint(1, 10000), random.randint(10000, 20000), 0]\n        tsfm =Transform()(item)\n        return np.array(item + tsfm)\n    def __len__(self):\n        return 20\n\n\nfrom torch.utils.data import DataLoader\n\nds = RandomDataset()\nds = DataLoader(ds, 10, shuffle=False, num_workers=4)\n\nfor batch in ds:\n    print(batch)\n</code></pre>\n<p>gives</p>\n<pre><code>#     0   2208  10983      0  15930  26264\n#     1   2798  14403      0  17685  29545\n#     2    528  16195      0  12927  28761\n#     3   8541  13614      0  15240  24058\n#     4   7144  14373      0  18374  28081\n#     5   2329  17456      0  15192  26903\n#     6    423  12168      0  18504  24193\n#     7   9476  12027      0  19924  22325\n#     8   3427  17570      0  12895  29773\n#     9   6526  13327      0  15768  24566\n#[torch.LongTensor of size 10x6]\n#\n#\n#    10   2208  15203      0  15930  26024\n#    11   2798  13264      0  17685  22011\n#    12    528  11714      0  12927  24688\n#    13   8541  11773      0  15240  29607\n#    14   7144  14655      0  18374  24573\n#    15   2329  12544      0  15192  27908\n#    16    423  15892      0  18504  23111\n#    17   9476  17389      0  19924  23799\n#    18   3427  12458      0  12895  23201\n#    19   6526  14935      0  15768  20789\n#[torch.LongTensor of size 10x6]\n</code></pre>\n<p>The second and fifth columns are np.random generated random numbers in Dataset and Transform. However, they are always that the same for different batches. This will make random data augmentation actually \"not random\".</p>", "body_text": "For example, the following script\nfrom __future__ import print_function\n\nimport numpy as np\nimport random\n\n# np.random.seed(0)\n\nclass Transform(object):\n    def __init__(self):\n        pass\n\n    def __call__(self, item = None):\n        return [np.random.randint(10000, 20000), random.randint(20000,30000)]\n\nclass RandomDataset(object):\n\n    def __init__(self):\n        pass\n\n    def __getitem__(self, ind):\n        item = [ind, np.random.randint(1, 10000), random.randint(10000, 20000), 0]\n        tsfm =Transform()(item)\n        return np.array(item + tsfm)\n    def __len__(self):\n        return 20\n\n\nfrom torch.utils.data import DataLoader\n\nds = RandomDataset()\nds = DataLoader(ds, 10, shuffle=False, num_workers=4)\n\nfor batch in ds:\n    print(batch)\n\ngives\n#     0   2208  10983      0  15930  26264\n#     1   2798  14403      0  17685  29545\n#     2    528  16195      0  12927  28761\n#     3   8541  13614      0  15240  24058\n#     4   7144  14373      0  18374  28081\n#     5   2329  17456      0  15192  26903\n#     6    423  12168      0  18504  24193\n#     7   9476  12027      0  19924  22325\n#     8   3427  17570      0  12895  29773\n#     9   6526  13327      0  15768  24566\n#[torch.LongTensor of size 10x6]\n#\n#\n#    10   2208  15203      0  15930  26024\n#    11   2798  13264      0  17685  22011\n#    12    528  11714      0  12927  24688\n#    13   8541  11773      0  15240  29607\n#    14   7144  14655      0  18374  24573\n#    15   2329  12544      0  15192  27908\n#    16    423  15892      0  18504  23111\n#    17   9476  17389      0  19924  23799\n#    18   3427  12458      0  12895  23201\n#    19   6526  14935      0  15768  20789\n#[torch.LongTensor of size 10x6]\n\nThe second and fifth columns are np.random generated random numbers in Dataset and Transform. However, they are always that the same for different batches. This will make random data augmentation actually \"not random\".", "body": "For example, the following script \r\n\r\n```\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\nimport random\r\n\r\n# np.random.seed(0)\r\n\r\nclass Transform(object):\r\n    def __init__(self):\r\n        pass\r\n\r\n    def __call__(self, item = None):\r\n        return [np.random.randint(10000, 20000), random.randint(20000,30000)]\r\n\r\nclass RandomDataset(object):\r\n\r\n    def __init__(self):\r\n        pass\r\n\r\n    def __getitem__(self, ind):\r\n        item = [ind, np.random.randint(1, 10000), random.randint(10000, 20000), 0]\r\n        tsfm =Transform()(item)\r\n        return np.array(item + tsfm)\r\n    def __len__(self):\r\n        return 20\r\n\r\n\r\nfrom torch.utils.data import DataLoader\r\n\r\nds = RandomDataset()\r\nds = DataLoader(ds, 10, shuffle=False, num_workers=4)\r\n\r\nfor batch in ds:\r\n    print(batch)\r\n```\r\n\r\ngives \r\n\r\n```\r\n#     0   2208  10983      0  15930  26264\r\n#     1   2798  14403      0  17685  29545\r\n#     2    528  16195      0  12927  28761\r\n#     3   8541  13614      0  15240  24058\r\n#     4   7144  14373      0  18374  28081\r\n#     5   2329  17456      0  15192  26903\r\n#     6    423  12168      0  18504  24193\r\n#     7   9476  12027      0  19924  22325\r\n#     8   3427  17570      0  12895  29773\r\n#     9   6526  13327      0  15768  24566\r\n#[torch.LongTensor of size 10x6]\r\n#\r\n#\r\n#    10   2208  15203      0  15930  26024\r\n#    11   2798  13264      0  17685  22011\r\n#    12    528  11714      0  12927  24688\r\n#    13   8541  11773      0  15240  29607\r\n#    14   7144  14655      0  18374  24573\r\n#    15   2329  12544      0  15192  27908\r\n#    16    423  15892      0  18504  23111\r\n#    17   9476  17389      0  19924  23799\r\n#    18   3427  12458      0  12895  23201\r\n#    19   6526  14935      0  15768  20789\r\n#[torch.LongTensor of size 10x6]\r\n```\r\n\r\nThe second and fifth columns are np.random generated random numbers in Dataset and Transform. However, they are always that the same for different batches. This will make random data augmentation actually \"not random\"."}