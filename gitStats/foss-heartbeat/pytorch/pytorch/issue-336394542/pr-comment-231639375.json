{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231639375", "pull_request_review_id": 172652516, "id": 231639375, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTYzOTM3NQ==", "diff_hunk": "@@ -1238,88 +1243,176 @@ static inline int64_t _min_storage_size(IntList sizes, IntList strides, int64_t\n }\n \n // See NOTE [ as_strided Backward ] for explanation\n+// NB: If you optimize this, test_autograd.test_as_strided_fast_path might need\n+//     to be updated. The test asserts that combinations of (un)squeeze,\n+//     permute, and transpose execute the \"fast\" path, which just returns a view\n+//     of grad (after reducing on input/output expanded dims) without allocating\n+//     an underlying storage-like tensor. It also asserts that some other ops\n+//     (currently just unfold) take the slower path.\n Tensor as_strided_backward(Tensor grad, TensorGeometry input_geometry, IntList sizes, IntList strides, int64_t storage_offset) {\n+  // This method implements the algorithm in NOTE [ as_strided Backward ], which\n+  // we refer to as Alg_bwd.\n+  // Moreover, it heavily uses the algorithm in NOTE [ Detecting Memory Overlap Within A Strided Tensor ]\n+  // to detect memory overlap, which we refer to as Alg_overlap. It is run on\n+  // both input and output geometries. To differentiate, we refer to them as\n+  // Alg_overlap_inp and Alg_overlap_out.\n+\n   // For output geometry,\n-  //   check for size 0 dimensions,\n-  //   skip size 1 dimensions,\n-  //   reduce grad on expanded dims (stride=0, size>1)\n-  // Step (0)     for the algorithm in NOTE [ as_strided Backward ]\n-  // Step (0)~(1) for the algorithm in NOTE [ Detecting Memory Overlap Within A Strided Tensor ]\n-  //              on output geometry\n-  auto odim = grad.dim();\n-  std::vector<int64_t> out_sizes_, out_strides_;\n-  out_sizes_.reserve(odim);\n-  out_strides_.reserve(odim);\n-  for (int64_t i = odim - 1; i >= 0; i--) {\n+  //   check for size 0 dimensions,                     (Alg_overlap_out step 0)\n+  //   skip size 1 dimensions,                          (Alg_overlap_out step 1)\n+  //   reduce grad on expanded dims (stride=0, size>1)  (Alg_bwd step 0.a)\n+  auto out_dim = grad.dim();\n+  auto& ty = grad.type();\n+  std::vector<int64_t> out_sizes_, out_strides_, out_expanded_dims;\n+  out_sizes_.reserve(out_dim);\n+  out_strides_.reserve(out_dim);\n+  for (int64_t i = out_dim - 1; i >= 0; i--) {\n     auto size_i = sizes[i];\n     auto stride_i = strides[i];\n     if (size_i == 0) {\n-      return at::zeros(input_geometry.sizes(), grad.type());\n-    } else if (size_i == 1) {\n-      grad = grad.squeeze(i);\n+      return at::zeros(input_geometry.sizes(), ty);\n     } else if (stride_i == 0) {\n-      grad = grad.sum(i, false);\n-    } else {\n+      out_expanded_dims.emplace_back(i);\n+    } else if (size_i != 1) {\n       out_sizes_.insert(out_sizes_.begin(), size_i);\n       out_strides_.insert(out_strides_.begin(), stride_i);\n     }\n   }\n-  // Step (2)~(4) for the algorithm in NOTE [ Detecting Memory Overlap Within A Strided Tensor ]\n-  //              on output geometry\n-  auto out_maybe_overlap = _maybe_overlapping_memory(out_sizes_, out_strides_);\n+  if (!out_expanded_dims.empty()) {\n+    grad = grad.sum(out_expanded_dims, false);\n+  }\n+  grad = grad.squeeze();\n \n   // For input geometry,\n-  //   check for size 0 dimensions,\n-  //   skip size 1 dimensions,\n-  // Step (0)~(1) for the algorithm in NOTE [ Detecting Memory Overlap Within A Strided Tensor ]\n-  //              on input geometry\n-  auto idim = input_geometry.dim();\n+  //   check for size 0 dimensions,                     (Alg_overlap_inp step 0)\n+  //   skip size 1 dimensions,                          (Alg_overlap_inp step 1)\n+  //   div grad by \\prod size_of_expanded_dims          (Alg_bwd step 0.b)\n+  auto inp_dim = input_geometry.dim();\n   IntList inp_sizes = input_geometry.sizes(), inp_strides = input_geometry.strides();\n-  std::vector<int64_t> inp_sizes_, inp_strides_;\n-  inp_sizes_.reserve(idim);\n-  inp_strides_.reserve(idim);\n-  for (int64_t i = idim - 1; i >= 0; i--) {\n+  int64_t inp_multiplicity = 1;\n+  std::vector<int64_t> inp_sizes_, inp_strides_, inp_sizes_w_expanded_dims;\n+  inp_sizes_.reserve(inp_dim);\n+  inp_strides_.reserve(inp_dim);\n+  inp_sizes_w_expanded_dims.reserve(out_dim);\n+  for (int64_t i = inp_dim - 1; i >= 0; i--) {\n     auto size_i = inp_sizes[i];\n     auto stride_i = inp_strides[i];\n     if (size_i == 0) {\n-      return at::zeros(input_geometry.sizes(), grad.type());\n-    } else if (size_i != 1) {\n-      inp_sizes_.insert(inp_sizes_.begin(), size_i);\n-      inp_strides_.insert(inp_strides_.begin(), stride_i);\n+      return at::zeros(input_geometry.sizes(), ty);\n+    } else if (stride_i == 0) {\n+      // Calculate multiplicity given by expanded dims.  (Alg_bwd step 0.b)\n+      inp_multiplicity *= size_i;\n+      // Moreover, we maintain a size where expanded dims are changed to size 1\n+      // dims so we can easily .view(...).expand(...) on the returned grad, if\n+      // neede, for Alg_bwd step 0.c.\n+      inp_sizes_w_expanded_dims.insert(inp_sizes_w_expanded_dims.begin(), 1);\n+    } else  {\n+      if (size_i != 1) {\n+        inp_sizes_.insert(inp_sizes_.begin(), size_i);\n+        inp_strides_.insert(inp_strides_.begin(), stride_i);\n+      }\n+      inp_sizes_w_expanded_dims.insert(inp_sizes_w_expanded_dims.begin(), size_i);\n     }\n   }\n-  // Step (1)~(4) for the algorithm in NOTE [ Detecting Memory Overlap Within A Strided Tensor ]\n-  //              on input geometry\n-  auto inp_maybe_overlap = _maybe_overlapping_memory(inp_sizes_, inp_strides_);\n+  // Divide grad by multiplicity given by expanded dims.  (Alg_bwd step 0.b)\n+  if (inp_multiplicity > 1) {\n+    grad = grad.div(inp_multiplicity);\n+  }\n+\n+  // Check output strides & sizes.  (Alg_overlap_out steps 2 ~ 4)", "path": "tools/autograd/templates/Functions.cpp", "position": 235, "original_position": 213, "commit_id": "8a4e5819aaa4daadfea6fa88f2e611e03e36ee33", "original_commit_id": "dbe5bfde5013d74a445f1f2282d22d4764575040", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Yes :) Because I end up doing extra things in the original loop in `_maybe_overlapping_memory`. And these extra things are different for input & output.", "created_at": "2018-11-07T19:11:22Z", "updated_at": "2018-11-23T15:54:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/8965#discussion_r231639375", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8965", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231639375"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8965#discussion_r231639375"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8965"}}, "body_html": "<p>Yes :) Because I end up doing extra things in the original loop in <code>_maybe_overlapping_memory</code>. And these extra things are different for input &amp; output.</p>", "body_text": "Yes :) Because I end up doing extra things in the original loop in _maybe_overlapping_memory. And these extra things are different for input & output.", "in_reply_to_id": 230839095}