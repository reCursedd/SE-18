{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/416849513", "html_url": "https://github.com/pytorch/pytorch/issues/10988#issuecomment-416849513", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10988", "id": 416849513, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjg0OTUxMw==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-29T07:12:29Z", "updated_at": "2018-08-29T07:12:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Currently, <code>einsum</code> reduces to <code>bmm</code> and will do the permutation for you. So while you won't get a computational advantage from using <code>einsum</code>, it probably is the right level of expressiveness (and there isn't much advantage in having arbitrary constructs for permuted axes in terms of expressiveness).<br>\nI'm currently investigating the inefficiency pointed out in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"351855556\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10661\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10661/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10661\">#10661</a> - currently it is in both bmm and einsum, and I have a tentative CPU fix, but need to get the GPU dispatching right.</p>", "body_text": "Currently, einsum reduces to bmm and will do the permutation for you. So while you won't get a computational advantage from using einsum, it probably is the right level of expressiveness (and there isn't much advantage in having arbitrary constructs for permuted axes in terms of expressiveness).\nI'm currently investigating the inefficiency pointed out in #10661 - currently it is in both bmm and einsum, and I have a tentative CPU fix, but need to get the GPU dispatching right.", "body": "Currently, `einsum` reduces to `bmm` and will do the permutation for you. So while you won't get a computational advantage from using `einsum`, it probably is the right level of expressiveness (and there isn't much advantage in having arbitrary constructs for permuted axes in terms of expressiveness).\r\nI'm currently investigating the inefficiency pointed out in #10661 - currently it is in both bmm and einsum, and I have a tentative CPU fix, but need to get the GPU dispatching right.\r\n"}