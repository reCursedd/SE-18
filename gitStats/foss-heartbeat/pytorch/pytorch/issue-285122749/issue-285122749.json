{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4408", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4408/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4408/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4408/events", "html_url": "https://github.com/pytorch/pytorch/issues/4408", "id": 285122749, "node_id": "MDU6SXNzdWUyODUxMjI3NDk=", "number": 4408, "title": "torch.onnx.export fails on Linear when bias=False, torch.onnx.symbolic.matmul does not exist", "user": {"login": "Erotemic", "id": 3186211, "node_id": "MDQ6VXNlcjMxODYyMTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3186211?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Erotemic", "html_url": "https://github.com/Erotemic", "followers_url": "https://api.github.com/users/Erotemic/followers", "following_url": "https://api.github.com/users/Erotemic/following{/other_user}", "gists_url": "https://api.github.com/users/Erotemic/gists{/gist_id}", "starred_url": "https://api.github.com/users/Erotemic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Erotemic/subscriptions", "organizations_url": "https://api.github.com/users/Erotemic/orgs", "repos_url": "https://api.github.com/users/Erotemic/repos", "events_url": "https://api.github.com/users/Erotemic/events{/privacy}", "received_events_url": "https://api.github.com/users/Erotemic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-12-29T16:49:13Z", "updated_at": "2018-01-03T15:24:11Z", "closed_at": "2018-01-03T15:24:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Using <code>torch.onnx.export</code> on a model that contains a linear layer with no bias, I receive an error:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>venv3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>onnx<span class=\"pl-k\">/</span><span class=\"pl-c1\">__init__</span>.py:<span class=\"pl-c1\">312</span>: <span class=\"pl-c1\">UserWarning</span>: <span class=\"pl-c1\">ONNX</span> export failed on matmul because torch.onnx.symbolic.matmul does <span class=\"pl-k\">not</span> exist\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>~/venv3/lib/python3.5/site-packages/torch/onnx/__init__.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">151</span>, <span class=\"pl-k\">in</span> _export\n    proto <span class=\"pl-k\">=</span> trace.export([], _onnx_opset_version)\n<span class=\"pl-c1\">RuntimeError</span>: <span class=\"pl-c1\">ONNX</span> export failed: Couldn<span class=\"pl-s\"><span class=\"pl-pds\">'</span>t export operator matmul<span class=\"pl-ii\"></span></span>\n\nGraph we tried to export:\ngraph(<span class=\"pl-k\">%</span><span class=\"pl-c1\">0</span> : Float(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">128</span>)\n      <span class=\"pl-k\">%</span><span class=\"pl-c1\">1</span> : Float(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">128</span>)) {\n  <span class=\"pl-k\">%</span><span class=\"pl-c1\">2</span> : Float(<span class=\"pl-c1\">128</span>!, <span class=\"pl-c1\">2</span>!) = Transpose[perm=[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>]](<span class=\"pl-k\">%</span><span class=\"pl-c1\">1</span>), scope: Linear\n  <span class=\"pl-k\">%</span><span class=\"pl-c1\">3</span> : Float(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>) = matmul(<span class=\"pl-k\">%</span><span class=\"pl-c1\">0</span>, <span class=\"pl-k\">%</span><span class=\"pl-c1\">2</span>), scope: Linear\n  <span class=\"pl-k\">return</span> (<span class=\"pl-k\">%</span><span class=\"pl-c1\">3</span>);\n}</pre></div>\n<p>I've constructed a minimal working example that reproduces this</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">mwe_bias</span>():\n    linear <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    args <span class=\"pl-k\">=</span> <span class=\"pl-c1\">tuple</span>([torch.autograd.Variable(torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">128</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)])\n    torch.onnx.export(linear, args, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>foo.onnx<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">export_params</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">mwe_nobias</span>():\n    linear <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">128</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n    args <span class=\"pl-k\">=</span> <span class=\"pl-c1\">tuple</span>([torch.autograd.Variable(torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">128</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)])\n    torch.onnx.export(linear, args, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>foo.onnx<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">export_params</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> does not cause an error</span>\nmwe_bias()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Causes an error</span>\nmwe_nobias()</pre></div>\n<p>Environment Info:</p>\n<div class=\"highlight highlight-source-python\"><pre>sys.platform <span class=\"pl-k\">=</span> linux\nsys.version <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3.5</span>.2 (default, Nov <span class=\"pl-c1\">17</span> <span class=\"pl-c1\">2016</span>, <span class=\"pl-c1\">17</span>:<span class=\"pl-c1\">0<span class=\"pl-ii\">5</span></span>:<span class=\"pl-c1\">23</span>) \\<span class=\"pl-ii\">n[GCC 5.4.0 20160609]</span>\ntorch.version.<span class=\"pl-c1\">__version__</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>0.4.0a0+af3bffb<span class=\"pl-pds\">'</span></span>\ntorch.version.cuda <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8.0</span>.61</pre></div>", "body_text": "Using torch.onnx.export on a model that contains a linear layer with no bias, I receive an error:\n~/venv3/lib/python3.5/site-packages/torch/onnx/__init__.py:312: UserWarning: ONNX export failed on matmul because torch.onnx.symbolic.matmul does not exist\n  File \"~/venv3/lib/python3.5/site-packages/torch/onnx/__init__.py\", line 151, in _export\n    proto = trace.export([], _onnx_opset_version)\nRuntimeError: ONNX export failed: Couldn't export operator matmul\n\nGraph we tried to export:\ngraph(%0 : Float(1, 128)\n      %1 : Float(2, 128)) {\n  %2 : Float(128!, 2!) = Transpose[perm=[1, 0]](%1), scope: Linear\n  %3 : Float(1, 2) = matmul(%0, %2), scope: Linear\n  return (%3);\n}\nI've constructed a minimal working example that reproduces this\ndef mwe_bias():\n    linear = torch.nn.Linear(128, 2, bias=1)\n    args = tuple([torch.autograd.Variable(torch.randn(1, 128), requires_grad=True)])\n    torch.onnx.export(linear, args, 'foo.onnx', export_params=False)\n\n\ndef mwe_nobias():\n    linear = torch.nn.Linear(128, 2, bias=0)\n    args = tuple([torch.autograd.Variable(torch.randn(1, 128), requires_grad=True)])\n    torch.onnx.export(linear, args, 'foo.onnx', export_params=False)\n\n# does not cause an error\nmwe_bias()\n# Causes an error\nmwe_nobias()\nEnvironment Info:\nsys.platform = linux\nsys.version = 3.5.2 (default, Nov 17 2016, 17:05:23) \\n[GCC 5.4.0 20160609]\ntorch.version.__version__ = '0.4.0a0+af3bffb'\ntorch.version.cuda = 8.0.61", "body": "Using `torch.onnx.export` on a model that contains a linear layer with no bias, I receive an error: \r\n\r\n```python\r\n~/venv3/lib/python3.5/site-packages/torch/onnx/__init__.py:312: UserWarning: ONNX export failed on matmul because torch.onnx.symbolic.matmul does not exist\r\n  File \"~/venv3/lib/python3.5/site-packages/torch/onnx/__init__.py\", line 151, in _export\r\n    proto = trace.export([], _onnx_opset_version)\r\nRuntimeError: ONNX export failed: Couldn't export operator matmul\r\n\r\nGraph we tried to export:\r\ngraph(%0 : Float(1, 128)\r\n      %1 : Float(2, 128)) {\r\n  %2 : Float(128!, 2!) = Transpose[perm=[1, 0]](%1), scope: Linear\r\n  %3 : Float(1, 2) = matmul(%0, %2), scope: Linear\r\n  return (%3);\r\n}\r\n```\r\n\r\nI've constructed a minimal working example that reproduces this\r\n```python\r\ndef mwe_bias():\r\n    linear = torch.nn.Linear(128, 2, bias=1)\r\n    args = tuple([torch.autograd.Variable(torch.randn(1, 128), requires_grad=True)])\r\n    torch.onnx.export(linear, args, 'foo.onnx', export_params=False)\r\n\r\n\r\ndef mwe_nobias():\r\n    linear = torch.nn.Linear(128, 2, bias=0)\r\n    args = tuple([torch.autograd.Variable(torch.randn(1, 128), requires_grad=True)])\r\n    torch.onnx.export(linear, args, 'foo.onnx', export_params=False)\r\n\r\n# does not cause an error\r\nmwe_bias()\r\n# Causes an error\r\nmwe_nobias()\r\n```\r\n\r\nEnvironment Info:\r\n```python\r\nsys.platform = linux\r\nsys.version = 3.5.2 (default, Nov 17 2016, 17:05:23) \\n[GCC 5.4.0 20160609]\r\ntorch.version.__version__ = '0.4.0a0+af3bffb'\r\ntorch.version.cuda = 8.0.61\r\n```"}