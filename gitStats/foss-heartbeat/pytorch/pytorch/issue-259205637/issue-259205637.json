{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2803", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2803/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2803/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2803/events", "html_url": "https://github.com/pytorch/pytorch/pull/2803", "id": 259205637, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQyMTMwODEz", "number": 2803, "title": "Parallelize CUDA LookupTable_renorm", "user": {"login": "squidgetx", "id": 6618711, "node_id": "MDQ6VXNlcjY2MTg3MTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6618711?v=4", "gravatar_id": "", "url": "https://api.github.com/users/squidgetx", "html_url": "https://github.com/squidgetx", "followers_url": "https://api.github.com/users/squidgetx/followers", "following_url": "https://api.github.com/users/squidgetx/following{/other_user}", "gists_url": "https://api.github.com/users/squidgetx/gists{/gist_id}", "starred_url": "https://api.github.com/users/squidgetx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/squidgetx/subscriptions", "organizations_url": "https://api.github.com/users/squidgetx/orgs", "repos_url": "https://api.github.com/users/squidgetx/repos", "events_url": "https://api.github.com/users/squidgetx/events{/privacy}", "received_events_url": "https://api.github.com/users/squidgetx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-09-20T15:27:40Z", "updated_at": "2018-11-23T15:34:42Z", "closed_at": "2017-09-25T18:04:08Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/2803", "html_url": "https://github.com/pytorch/pytorch/pull/2803", "diff_url": "https://github.com/pytorch/pytorch/pull/2803.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/2803.patch"}, "body_html": "<p>Investigating <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"222439796\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1278\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1278/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1278\">#1278</a> I found that while the CUDA algorithm for the renorming was using parallel algorithms to calculate norms and the renormalize, each slice was being processed sequentially. This PR attempts to fix that by nesting the original renorming logic in a thrust functor that can be applied over the embedding weights in parallel.</p>\n<p>My profiling using nvprof shows approximately a 33x speedup using embedding dimensions of 100k x 128 and a batch size of 1024 (~20ms vs 600us). I don't have a lot of experience with GPU programming so here's hoping I've interpreted the profiling results correctly!</p>\n<p>Original benchmark - you can see we are launching kernels and calling cudaMalloc, memcpy, and other API calls (some even twice) for every idx in the batch:</p>\n<pre><code> pow_v&lt;real, accreal&gt; unary_pow(normType);\n  thrust::plus&lt;accreal&gt; binary_plus;\n  // numel &lt;&lt; stride, since idx usually contains sparse row indices\n  cudaProfilerStart();\n  for (THCIndex_t i = 0; i &lt; numel; i++)\n  {\n    THCIndex_t k = idx_ptr[i] - TH_INDEX_BASE;\n    thrust::device_ptr&lt;real&gt; row_ptr = weight_ptr + k * stride;\n    accreal norm = thrust::transform_reduce(row_ptr, row_ptr + stride,\n      unary_pow, (accreal)0, binary_plus);\n    norm = std::pow(norm, (accreal) (1.0 / normType));\n    if (norm &gt; ScalarConvert&lt;real, accreal&gt;::to(maxNorm))\n    {\n      multiply_s&lt;real&gt; unary_mul(ScalarConvert&lt;accreal, real&gt;::to(maxNorm / (norm + 1e-7)));\n      thrust::transform(row_ptr, row_ptr + stride, row_ptr, unary_mul);\n    }\n  }\n  cudaDeviceSynchronize();\n  cudaProfilerStop();\n\n**** Test results ****\n\n$ nvprof --profile-from-start off test/test0.py\n\n  3 ==188596== Profiling result:\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\n  5  52.71%  11.001ms      1024  10.742us  10.496us  13.120us  _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj128ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm7EEELm128EEELm0EEENS4_7closureINS2_13reduce_detail17reduce_partitionsENS_5tuple    INS4_6cursorILj1EEENS_18transform_iteratorI5pow_vIffENS_10device_ptrIfEEfNS_11use_defaultEEENS2_21aligned_decompositionIlEENS_6detail15normal_iteratorINS_7pointerIfNS2_3tagESO_SO_EEEEfNS_4plusIfEENS_9null_typeES10_S10_S10_EEEEEEEEvT0_\n  6  31.65%  6.6055ms      2048  3.2250us  2.7200us  16.352us  [CUDA memcpy DtoH]\n  7  15.64%  3.2644ms      1024  3.1870us  3.1360us  3.3600us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value&lt;unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task&lt;thrust::system::cuda::detail::bulk_::parallel_group&lt;thrust::system::cuda::detail    ::bulk_::concurrent_group&lt;thrust::system::cuda::detail::bulk_::agent&lt;unsigned long=1&gt;, unsigned long=0&gt;, unsigned long=0&gt;, thrust::system::cuda::detail::bulk_::detail::closure&lt;thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple&lt;thrust::system::cuda    ::detail::bulk_::detail::cursor&lt;unsigned int=0&gt;, thrust::zip_iterator&lt;thrust::tuple&lt;thrust::device_ptr&lt;float&gt;, thrust::device_ptr&lt;float&gt;, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrus    t::null_type&gt;&gt;, thrust::detail::wrapped_function&lt;thrust::detail::unary_transform_functor&lt;multiply_s&lt;float&gt;&gt;, void&gt;, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;&gt;&gt;&gt;(unsigned long=1)\n  8\n  9 ==188596== API calls:\n 10 Time(%)      Time     Calls       Avg       Min       Max  Name\n 11  54.54%  1.32840s      2048  648.63us  13.739us  1.29628s  cudaLaunch\n 12  28.54%  695.05ms      1024  678.76us  505.18us  22.304ms  cudaMalloc\n 13  12.88%  313.75ms      1024  306.39us  176.28us  23.175ms  cudaFree\n 14   1.86%  45.341ms      2048  22.139us  18.996us  317.06us  cudaMemcpyAsync\n 15   0.73%  17.893ms      1024  17.473us  4.0190us  48.252us  cudaEventSynchronize\n 16   0.60%  14.723ms      6144  2.3960us  1.8940us  16.599us  cudaFuncGetAttributes\n 17   0.28%  6.7438ms      2048  3.2920us  2.8040us  16.990us  cudaStreamSynchronize\n 18   0.14%  3.4725ms      6144     565ns     287ns  14.442us  cudaGetDevice\n 19   0.14%  3.3119ms      2048  1.6170us  1.2890us  25.005us  cudaEventCreateWithFlags\n 20   0.10%  2.4582ms      2048  1.2000us  1.0140us  15.245us  cudaEventRecord\n 21   0.09%  2.2588ms      2048  1.1020us     759ns  296.39us  cudaEventDestroy\n 22   0.05%  1.2316ms      2048     601ns     353ns  385.44us  cudaConfigureCall\n 23   0.03%  811.96us      2048     396ns     331ns  12.707us  cudaSetupArgument\n 24   0.00%  12.811us         1  12.811us  12.811us  12.811us  cudaDeviceSynchronize\n</code></pre>\n<p>Newly parallelized version only calls cudaLaunch a single time :</p>\n<pre><code>180   cudaProfilerStart();\n181   pow_v&lt;real, accreal&gt; unary_pow(normType);\n182   thrust::plus&lt;accreal&gt; binary_plus;\n183\n184   thrust::for_each(idx_ptr, end_ptr,\n185       renorm_functor&lt;real, accreal&gt;(weight_ptr, stride, maxNorm, normType, binary_plus, unary_pow));\n186\n187   cudaDeviceSynchronize();\n188   cudaProfilerStop();\n\n**** Test results ****\n\n$ nvprof --profile-from-start off test/test0.py\n\n   1 ==244630== NVPROF is profiling process 244630, command: python test/test0.py\n  2 ==244630== Profiling application: python test/test0.py\n  3 ==244630== Profiling result:\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\n  5 100.00%  602.12us         1  602.12us  602.12us  602.12us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value&lt;unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task&lt;thrust::system::cuda::detail::bulk_::parallel_group&lt;thrust::system::cuda::detail    ::bulk_::concurrent_group&lt;thrust::system::cuda::detail::bulk_::agent&lt;unsigned long=1&gt;, unsigned long=0&gt;, unsigned long=0&gt;, thrust::system::cuda::detail::bulk_::detail::closure&lt;thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple&lt;thrust::system::cuda    ::detail::bulk_::detail::cursor&lt;unsigned int=0&gt;, thrust::device_ptr&lt;long&gt;, thrust::detail::wrapped_function&lt;renorm_functor&lt;float, float&gt;, void&gt;, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;&gt;&gt;&gt;(    unsigned long=1)\n  6\n  7 ==244630== API calls:\n  8 Time(%)      Time     Calls       Avg       Min       Max  Name\n  9  99.95%  1.32124s         1  1.32124s  1.32124s  1.32124s  cudaLaunch\n 10   0.04%  576.35us         1  576.35us  576.35us  576.35us  cudaDeviceSynchronize\n 11   0.00%  17.015us         4  4.2530us  3.4190us  5.7650us  cudaFuncGetAttributes\n 12   0.00%  9.6330us         1  9.6330us  9.6330us  9.6330us  cudaEventCreateWithFlags\n 13   0.00%  4.2920us         3  1.4300us     526ns  3.2190us  cudaGetDevice\n 14   0.00%  3.4740us         1  3.4740us  3.4740us  3.4740us  cudaEventRecord\n 15   0.00%  2.0270us         1  2.0270us  2.0270us  2.0270us  cudaEventDestroy\n 16   0.00%     541ns         1     541ns     541ns     541ns  cudaConfigureCall\n 17   0.00%     420ns         1     420ns     420ns     420ns  cudaSetupArgument\n</code></pre>\n<p>Simple test harness:</p>\n<pre><code>  2 import torch\n  3\n  4 size = 128\n  5 num_relations = 100000\n  6\n  7 embeds = torch.nn.Embedding(num_relations, size, max_norm=0.5).cuda()\n  8 input = torch.autograd.Variable(torch.randperm(1024).cuda())\n  9 embeds(input)\n</code></pre>", "body_text": "Investigating #1278 I found that while the CUDA algorithm for the renorming was using parallel algorithms to calculate norms and the renormalize, each slice was being processed sequentially. This PR attempts to fix that by nesting the original renorming logic in a thrust functor that can be applied over the embedding weights in parallel.\nMy profiling using nvprof shows approximately a 33x speedup using embedding dimensions of 100k x 128 and a batch size of 1024 (~20ms vs 600us). I don't have a lot of experience with GPU programming so here's hoping I've interpreted the profiling results correctly!\nOriginal benchmark - you can see we are launching kernels and calling cudaMalloc, memcpy, and other API calls (some even twice) for every idx in the batch:\n pow_v<real, accreal> unary_pow(normType);\n  thrust::plus<accreal> binary_plus;\n  // numel << stride, since idx usually contains sparse row indices\n  cudaProfilerStart();\n  for (THCIndex_t i = 0; i < numel; i++)\n  {\n    THCIndex_t k = idx_ptr[i] - TH_INDEX_BASE;\n    thrust::device_ptr<real> row_ptr = weight_ptr + k * stride;\n    accreal norm = thrust::transform_reduce(row_ptr, row_ptr + stride,\n      unary_pow, (accreal)0, binary_plus);\n    norm = std::pow(norm, (accreal) (1.0 / normType));\n    if (norm > ScalarConvert<real, accreal>::to(maxNorm))\n    {\n      multiply_s<real> unary_mul(ScalarConvert<accreal, real>::to(maxNorm / (norm + 1e-7)));\n      thrust::transform(row_ptr, row_ptr + stride, row_ptr, unary_mul);\n    }\n  }\n  cudaDeviceSynchronize();\n  cudaProfilerStop();\n\n**** Test results ****\n\n$ nvprof --profile-from-start off test/test0.py\n\n  3 ==188596== Profiling result:\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\n  5  52.71%  11.001ms      1024  10.742us  10.496us  13.120us  _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj128ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm7EEELm128EEELm0EEENS4_7closureINS2_13reduce_detail17reduce_partitionsENS_5tuple    INS4_6cursorILj1EEENS_18transform_iteratorI5pow_vIffENS_10device_ptrIfEEfNS_11use_defaultEEENS2_21aligned_decompositionIlEENS_6detail15normal_iteratorINS_7pointerIfNS2_3tagESO_SO_EEEEfNS_4plusIfEENS_9null_typeES10_S10_S10_EEEEEEEEvT0_\n  6  31.65%  6.6055ms      2048  3.2250us  2.7200us  16.352us  [CUDA memcpy DtoH]\n  7  15.64%  3.2644ms      1024  3.1870us  3.1360us  3.3600us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value<unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task<thrust::system::cuda::detail::bulk_::parallel_group<thrust::system::cuda::detail    ::bulk_::concurrent_group<thrust::system::cuda::detail::bulk_::agent<unsigned long=1>, unsigned long=0>, unsigned long=0>, thrust::system::cuda::detail::bulk_::detail::closure<thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple<thrust::system::cuda    ::detail::bulk_::detail::cursor<unsigned int=0>, thrust::zip_iterator<thrust::tuple<thrust::device_ptr<float>, thrust::device_ptr<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrus    t::null_type>>, thrust::detail::wrapped_function<thrust::detail::unary_transform_functor<multiply_s<float>>, void>, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>>>(unsigned long=1)\n  8\n  9 ==188596== API calls:\n 10 Time(%)      Time     Calls       Avg       Min       Max  Name\n 11  54.54%  1.32840s      2048  648.63us  13.739us  1.29628s  cudaLaunch\n 12  28.54%  695.05ms      1024  678.76us  505.18us  22.304ms  cudaMalloc\n 13  12.88%  313.75ms      1024  306.39us  176.28us  23.175ms  cudaFree\n 14   1.86%  45.341ms      2048  22.139us  18.996us  317.06us  cudaMemcpyAsync\n 15   0.73%  17.893ms      1024  17.473us  4.0190us  48.252us  cudaEventSynchronize\n 16   0.60%  14.723ms      6144  2.3960us  1.8940us  16.599us  cudaFuncGetAttributes\n 17   0.28%  6.7438ms      2048  3.2920us  2.8040us  16.990us  cudaStreamSynchronize\n 18   0.14%  3.4725ms      6144     565ns     287ns  14.442us  cudaGetDevice\n 19   0.14%  3.3119ms      2048  1.6170us  1.2890us  25.005us  cudaEventCreateWithFlags\n 20   0.10%  2.4582ms      2048  1.2000us  1.0140us  15.245us  cudaEventRecord\n 21   0.09%  2.2588ms      2048  1.1020us     759ns  296.39us  cudaEventDestroy\n 22   0.05%  1.2316ms      2048     601ns     353ns  385.44us  cudaConfigureCall\n 23   0.03%  811.96us      2048     396ns     331ns  12.707us  cudaSetupArgument\n 24   0.00%  12.811us         1  12.811us  12.811us  12.811us  cudaDeviceSynchronize\n\nNewly parallelized version only calls cudaLaunch a single time :\n180   cudaProfilerStart();\n181   pow_v<real, accreal> unary_pow(normType);\n182   thrust::plus<accreal> binary_plus;\n183\n184   thrust::for_each(idx_ptr, end_ptr,\n185       renorm_functor<real, accreal>(weight_ptr, stride, maxNorm, normType, binary_plus, unary_pow));\n186\n187   cudaDeviceSynchronize();\n188   cudaProfilerStop();\n\n**** Test results ****\n\n$ nvprof --profile-from-start off test/test0.py\n\n   1 ==244630== NVPROF is profiling process 244630, command: python test/test0.py\n  2 ==244630== Profiling application: python test/test0.py\n  3 ==244630== Profiling result:\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\n  5 100.00%  602.12us         1  602.12us  602.12us  602.12us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value<unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task<thrust::system::cuda::detail::bulk_::parallel_group<thrust::system::cuda::detail    ::bulk_::concurrent_group<thrust::system::cuda::detail::bulk_::agent<unsigned long=1>, unsigned long=0>, unsigned long=0>, thrust::system::cuda::detail::bulk_::detail::closure<thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple<thrust::system::cuda    ::detail::bulk_::detail::cursor<unsigned int=0>, thrust::device_ptr<long>, thrust::detail::wrapped_function<renorm_functor<float, float>, void>, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>>>(    unsigned long=1)\n  6\n  7 ==244630== API calls:\n  8 Time(%)      Time     Calls       Avg       Min       Max  Name\n  9  99.95%  1.32124s         1  1.32124s  1.32124s  1.32124s  cudaLaunch\n 10   0.04%  576.35us         1  576.35us  576.35us  576.35us  cudaDeviceSynchronize\n 11   0.00%  17.015us         4  4.2530us  3.4190us  5.7650us  cudaFuncGetAttributes\n 12   0.00%  9.6330us         1  9.6330us  9.6330us  9.6330us  cudaEventCreateWithFlags\n 13   0.00%  4.2920us         3  1.4300us     526ns  3.2190us  cudaGetDevice\n 14   0.00%  3.4740us         1  3.4740us  3.4740us  3.4740us  cudaEventRecord\n 15   0.00%  2.0270us         1  2.0270us  2.0270us  2.0270us  cudaEventDestroy\n 16   0.00%     541ns         1     541ns     541ns     541ns  cudaConfigureCall\n 17   0.00%     420ns         1     420ns     420ns     420ns  cudaSetupArgument\n\nSimple test harness:\n  2 import torch\n  3\n  4 size = 128\n  5 num_relations = 100000\n  6\n  7 embeds = torch.nn.Embedding(num_relations, size, max_norm=0.5).cuda()\n  8 input = torch.autograd.Variable(torch.randperm(1024).cuda())\n  9 embeds(input)", "body": "Investigating https://github.com/pytorch/pytorch/issues/1278 I found that while the CUDA algorithm for the renorming was using parallel algorithms to calculate norms and the renormalize, each slice was being processed sequentially. This PR attempts to fix that by nesting the original renorming logic in a thrust functor that can be applied over the embedding weights in parallel. \r\n\r\nMy profiling using nvprof shows approximately a 33x speedup using embedding dimensions of 100k x 128 and a batch size of 1024 (~20ms vs 600us). I don't have a lot of experience with GPU programming so here's hoping I've interpreted the profiling results correctly!\r\n\r\nOriginal benchmark - you can see we are launching kernels and calling cudaMalloc, memcpy, and other API calls (some even twice) for every idx in the batch:\r\n```\r\n pow_v<real, accreal> unary_pow(normType);\r\n  thrust::plus<accreal> binary_plus;\r\n  // numel << stride, since idx usually contains sparse row indices\r\n  cudaProfilerStart();\r\n  for (THCIndex_t i = 0; i < numel; i++)\r\n  {\r\n    THCIndex_t k = idx_ptr[i] - TH_INDEX_BASE;\r\n    thrust::device_ptr<real> row_ptr = weight_ptr + k * stride;\r\n    accreal norm = thrust::transform_reduce(row_ptr, row_ptr + stride,\r\n      unary_pow, (accreal)0, binary_plus);\r\n    norm = std::pow(norm, (accreal) (1.0 / normType));\r\n    if (norm > ScalarConvert<real, accreal>::to(maxNorm))\r\n    {\r\n      multiply_s<real> unary_mul(ScalarConvert<accreal, real>::to(maxNorm / (norm + 1e-7)));\r\n      thrust::transform(row_ptr, row_ptr + stride, row_ptr, unary_mul);\r\n    }\r\n  }\r\n  cudaDeviceSynchronize();\r\n  cudaProfilerStop();\r\n\r\n**** Test results ****\r\n\r\n$ nvprof --profile-from-start off test/test0.py\r\n\r\n  3 ==188596== Profiling result:\r\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\r\n  5  52.71%  11.001ms      1024  10.742us  10.496us  13.120us  _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj128ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm7EEELm128EEELm0EEENS4_7closureINS2_13reduce_detail17reduce_partitionsENS_5tuple    INS4_6cursorILj1EEENS_18transform_iteratorI5pow_vIffENS_10device_ptrIfEEfNS_11use_defaultEEENS2_21aligned_decompositionIlEENS_6detail15normal_iteratorINS_7pointerIfNS2_3tagESO_SO_EEEEfNS_4plusIfEENS_9null_typeES10_S10_S10_EEEEEEEEvT0_\r\n  6  31.65%  6.6055ms      2048  3.2250us  2.7200us  16.352us  [CUDA memcpy DtoH]\r\n  7  15.64%  3.2644ms      1024  3.1870us  3.1360us  3.3600us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value<unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task<thrust::system::cuda::detail::bulk_::parallel_group<thrust::system::cuda::detail    ::bulk_::concurrent_group<thrust::system::cuda::detail::bulk_::agent<unsigned long=1>, unsigned long=0>, unsigned long=0>, thrust::system::cuda::detail::bulk_::detail::closure<thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple<thrust::system::cuda    ::detail::bulk_::detail::cursor<unsigned int=0>, thrust::zip_iterator<thrust::tuple<thrust::device_ptr<float>, thrust::device_ptr<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrus    t::null_type>>, thrust::detail::wrapped_function<thrust::detail::unary_transform_functor<multiply_s<float>>, void>, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>>>(unsigned long=1)\r\n  8\r\n  9 ==188596== API calls:\r\n 10 Time(%)      Time     Calls       Avg       Min       Max  Name\r\n 11  54.54%  1.32840s      2048  648.63us  13.739us  1.29628s  cudaLaunch\r\n 12  28.54%  695.05ms      1024  678.76us  505.18us  22.304ms  cudaMalloc\r\n 13  12.88%  313.75ms      1024  306.39us  176.28us  23.175ms  cudaFree\r\n 14   1.86%  45.341ms      2048  22.139us  18.996us  317.06us  cudaMemcpyAsync\r\n 15   0.73%  17.893ms      1024  17.473us  4.0190us  48.252us  cudaEventSynchronize\r\n 16   0.60%  14.723ms      6144  2.3960us  1.8940us  16.599us  cudaFuncGetAttributes\r\n 17   0.28%  6.7438ms      2048  3.2920us  2.8040us  16.990us  cudaStreamSynchronize\r\n 18   0.14%  3.4725ms      6144     565ns     287ns  14.442us  cudaGetDevice\r\n 19   0.14%  3.3119ms      2048  1.6170us  1.2890us  25.005us  cudaEventCreateWithFlags\r\n 20   0.10%  2.4582ms      2048  1.2000us  1.0140us  15.245us  cudaEventRecord\r\n 21   0.09%  2.2588ms      2048  1.1020us     759ns  296.39us  cudaEventDestroy\r\n 22   0.05%  1.2316ms      2048     601ns     353ns  385.44us  cudaConfigureCall\r\n 23   0.03%  811.96us      2048     396ns     331ns  12.707us  cudaSetupArgument\r\n 24   0.00%  12.811us         1  12.811us  12.811us  12.811us  cudaDeviceSynchronize\r\n```\r\n\r\nNewly parallelized version only calls cudaLaunch a single time :\r\n\r\n```\r\n180   cudaProfilerStart();\r\n181   pow_v<real, accreal> unary_pow(normType);\r\n182   thrust::plus<accreal> binary_plus;\r\n183\r\n184   thrust::for_each(idx_ptr, end_ptr,\r\n185       renorm_functor<real, accreal>(weight_ptr, stride, maxNorm, normType, binary_plus, unary_pow));\r\n186\r\n187   cudaDeviceSynchronize();\r\n188   cudaProfilerStop();\r\n\r\n**** Test results ****\r\n\r\n$ nvprof --profile-from-start off test/test0.py\r\n\r\n   1 ==244630== NVPROF is profiling process 244630, command: python test/test0.py\r\n  2 ==244630== Profiling application: python test/test0.py\r\n  3 ==244630== Profiling result:\r\n  4 Time(%)      Time     Calls       Avg       Min       Max  Name\r\n  5 100.00%  602.12us         1  602.12us  602.12us  602.12us  void thrust::system::cuda::detail::bulk_::detail::launch_by_value<unsigned int=0, thrust::system::cuda::detail::bulk_::detail::cuda_task<thrust::system::cuda::detail::bulk_::parallel_group<thrust::system::cuda::detail    ::bulk_::concurrent_group<thrust::system::cuda::detail::bulk_::agent<unsigned long=1>, unsigned long=0>, unsigned long=0>, thrust::system::cuda::detail::bulk_::detail::closure<thrust::system::cuda::detail::for_each_n_detail::for_each_kernel, thrust::tuple<thrust::system::cuda    ::detail::bulk_::detail::cursor<unsigned int=0>, thrust::device_ptr<long>, thrust::detail::wrapped_function<renorm_functor<float, float>, void>, unsigned int, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>>>>(    unsigned long=1)\r\n  6\r\n  7 ==244630== API calls:\r\n  8 Time(%)      Time     Calls       Avg       Min       Max  Name\r\n  9  99.95%  1.32124s         1  1.32124s  1.32124s  1.32124s  cudaLaunch\r\n 10   0.04%  576.35us         1  576.35us  576.35us  576.35us  cudaDeviceSynchronize\r\n 11   0.00%  17.015us         4  4.2530us  3.4190us  5.7650us  cudaFuncGetAttributes\r\n 12   0.00%  9.6330us         1  9.6330us  9.6330us  9.6330us  cudaEventCreateWithFlags\r\n 13   0.00%  4.2920us         3  1.4300us     526ns  3.2190us  cudaGetDevice\r\n 14   0.00%  3.4740us         1  3.4740us  3.4740us  3.4740us  cudaEventRecord\r\n 15   0.00%  2.0270us         1  2.0270us  2.0270us  2.0270us  cudaEventDestroy\r\n 16   0.00%     541ns         1     541ns     541ns     541ns  cudaConfigureCall\r\n 17   0.00%     420ns         1     420ns     420ns     420ns  cudaSetupArgument\r\n```\r\n\r\nSimple test harness:\r\n```\r\n  2 import torch\r\n  3\r\n  4 size = 128\r\n  5 num_relations = 100000\r\n  6\r\n  7 embeds = torch.nn.Embedding(num_relations, size, max_norm=0.5).cuda()\r\n  8 input = torch.autograd.Variable(torch.randperm(1024).cuda())\r\n  9 embeds(input)\r\n```"}