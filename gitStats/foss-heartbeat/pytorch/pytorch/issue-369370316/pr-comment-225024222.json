{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/225024222", "pull_request_review_id": 164532842, "id": 225024222, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNTAyNDIyMg==", "diff_hunk": "@@ -30,10 +30,10 @@ void THTensor_(zero)(THTensor *r_)\n void THTensor_(maskedFill)(THTensor *tensor, THByteTensor *mask, scalar_t value)\n {\n #ifdef _OPENMP\n-  if (!omp_in_parallel()) {\n-    int64_t tensor_size = THTensor_(nElement)(tensor);\n-    int tensor_contig = THTensor_(isContiguous)(tensor);\n-    int mask_contig = THTensor_(isContiguous)(mask);\n+  int64_t tensor_size = THTensor_(nElement)(tensor);\n+  int tensor_contig = THTensor_(isContiguous)(tensor);\n+  int mask_contig = THTensor_(isContiguous)(mask);\n+  if (!omp_in_parallel() && tensor_contig && mask_contig) {", "path": "aten/src/TH/generic/THTensorEvenMoreMath.cpp", "position": 11, "original_position": 11, "commit_id": "50861c95701f213cd5813932f6fa7ed86934e7b0", "original_commit_id": "ed4d86e2b2b00bb9ac1535eeb4608f9fdbaec38d", "user": {"login": "mingfeima", "id": 20233731, "node_id": "MDQ6VXNlcjIwMjMzNzMx", "avatar_url": "https://avatars0.githubusercontent.com/u/20233731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeima", "html_url": "https://github.com/mingfeima", "followers_url": "https://api.github.com/users/mingfeima/followers", "following_url": "https://api.github.com/users/mingfeima/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeima/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeima/subscriptions", "organizations_url": "https://api.github.com/users/mingfeima/orgs", "repos_url": "https://api.github.com/users/mingfeima/repos", "events_url": "https://api.github.com/users/mingfeima/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeima/received_events", "type": "User", "site_admin": false}, "body": "Yes, you are right. `TH_TENSOR_APPLY2_OMP` does support non-contiguous tensor at the first place. So to solve it from root requires to refine `TH_TENSOR_APPLY2_OMP` logic. However the guy who wrote this quit Intel this summer and i am bombarded with other requests at the moment :(.\r\nSo i think we can suspend non-contiguous tensor optimization at present. Perhaps you can put a `improvement` label on this. I will get back to this once I have my hands free. Is this OK for you?", "created_at": "2018-10-15T02:21:11Z", "updated_at": "2018-11-23T15:53:00Z", "html_url": "https://github.com/pytorch/pytorch/pull/12594#discussion_r225024222", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12594", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/225024222"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12594#discussion_r225024222"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12594"}}, "body_html": "<p>Yes, you are right. <code>TH_TENSOR_APPLY2_OMP</code> does support non-contiguous tensor at the first place. So to solve it from root requires to refine <code>TH_TENSOR_APPLY2_OMP</code> logic. However the guy who wrote this quit Intel this summer and i am bombarded with other requests at the moment :(.<br>\nSo i think we can suspend non-contiguous tensor optimization at present. Perhaps you can put a <code>improvement</code> label on this. I will get back to this once I have my hands free. Is this OK for you?</p>", "body_text": "Yes, you are right. TH_TENSOR_APPLY2_OMP does support non-contiguous tensor at the first place. So to solve it from root requires to refine TH_TENSOR_APPLY2_OMP logic. However the guy who wrote this quit Intel this summer and i am bombarded with other requests at the moment :(.\nSo i think we can suspend non-contiguous tensor optimization at present. Perhaps you can put a improvement label on this. I will get back to this once I have my hands free. Is this OK for you?", "in_reply_to_id": 224926464}