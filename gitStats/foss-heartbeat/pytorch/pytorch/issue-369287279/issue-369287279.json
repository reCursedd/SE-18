{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12578", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12578/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12578/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12578/events", "html_url": "https://github.com/pytorch/pytorch/issues/12578", "id": 369287279, "node_id": "MDU6SXNzdWUzNjkyODcyNzk=", "number": 12578, "title": "Printing: mismatch result with numpy in pytorch 0.4", "user": {"login": "mravanelli", "id": 16886998, "node_id": "MDQ6VXNlcjE2ODg2OTk4", "avatar_url": "https://avatars1.githubusercontent.com/u/16886998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mravanelli", "html_url": "https://github.com/mravanelli", "followers_url": "https://api.github.com/users/mravanelli/followers", "following_url": "https://api.github.com/users/mravanelli/following{/other_user}", "gists_url": "https://api.github.com/users/mravanelli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mravanelli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mravanelli/subscriptions", "organizations_url": "https://api.github.com/users/mravanelli/orgs", "repos_url": "https://api.github.com/users/mravanelli/repos", "events_url": "https://api.github.com/users/mravanelli/events{/privacy}", "received_events_url": "https://api.github.com/users/mravanelli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-10-11T20:14:41Z", "updated_at": "2018-10-25T01:14:13Z", "closed_at": "2018-10-25T01:14:13Z", "author_association": "NONE", "body_html": "<p>I noticed a weird behavior when using torch.linspace.  Please take a look into the following code, where I compare the output of pytorch and numpy for different number of steps:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> sys\n\nmult_factor<span class=\"pl-k\">=</span><span class=\"pl-c1\">0.00002</span>\n\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Torch</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>11 steps<span class=\"pl-pds\">'</span></span>)\nn_ <span class=\"pl-k\">=</span> torch.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">11</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n\nn_ <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-c1\">11</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.....<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>12 steps<span class=\"pl-pds\">'</span></span>)\nn_ <span class=\"pl-k\">=</span> torch.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">12</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n\nn_ <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-c1\">12</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.....<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>13 steps<span class=\"pl-pds\">'</span></span>)\nn_ <span class=\"pl-k\">=</span> torch.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">13</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n\nn_ <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-c1\">13</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.....<span class=\"pl-pds\">'</span></span>)\n\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>14 steps<span class=\"pl-pds\">'</span></span>)\nn_ <span class=\"pl-k\">=</span> torch.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-v\">steps</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">14</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)\n\nn_ <span class=\"pl-k\">=</span> np.linspace(<span class=\"pl-k\">-</span><span class=\"pl-c1\">5.0</span>, <span class=\"pl-c1\">5.0</span>,<span class=\"pl-c1\">14</span>)<span class=\"pl-k\">*</span> mult_factor\n<span class=\"pl-c1\">print</span>(n_)</pre></div>\n<p>If I run the code above I have the following output:</p>\n<pre><code>11 steps\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n         0.0001,  0.0001,  0.0001])\n[-1.e-04 -8.e-05 -6.e-05 -4.e-05 -2.e-05  0.e+00  2.e-05  4.e-05  6.e-05\n  8.e-05  1.e-04]\n.....\n12 steps\ntensor([-1.0000e-04, -8.1818e-05, -6.3636e-05, -4.5455e-05, -2.7273e-05,\n        -9.0909e-06,  9.0909e-06,  2.7273e-05,  4.5455e-05,  6.3636e-05,\n         8.1818e-05,  1.0000e-04])\n[-1.00000000e-04 -8.18181818e-05 -6.36363636e-05 -4.54545455e-05\n -2.72727273e-05 -9.09090909e-06  9.09090909e-06  2.72727273e-05\n  4.54545455e-05  6.36363636e-05  8.18181818e-05  1.00000000e-04]\n.....\n13 steps\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0001,  0.0001,  0.0001])\n[-1.00000000e-04 -8.33333333e-05 -6.66666667e-05 -5.00000000e-05\n -3.33333333e-05 -1.66666667e-05  0.00000000e+00  1.66666667e-05\n  3.33333333e-05  5.00000000e-05  6.66666667e-05  8.33333333e-05\n  1.00000000e-04]\n.....\n14 steps\ntensor([-1.0000e-04, -8.4615e-05, -6.9231e-05, -5.3846e-05, -3.8462e-05,\n        -2.3077e-05, -7.6923e-06,  7.6923e-06,  2.3077e-05,  3.8462e-05,\n         5.3846e-05,  6.9231e-05,  8.4615e-05,  1.0000e-04])\n[-1.00000000e-04 -8.46153846e-05 -6.92307692e-05 -5.38461538e-05\n -3.84615385e-05 -2.30769231e-05 -7.69230769e-06  7.69230769e-06\n  2.30769231e-05  3.84615385e-05  5.38461538e-05  6.92307692e-05\n  8.46153846e-05  1.00000000e-04]\n</code></pre>\n<p>Curiously, when I set an even \"step\" everything seems to work, if I set an odd number of step it seems there is a lack of resolution.  Note that this doesn't happen in numpy. Moreover, I tried with pytorch 0.3 and the issue doesn't arise.  I  noticed the same behavior with torch.range and torch.arange.</p>\n<p>What could be the problem?</p>", "body_text": "I noticed a weird behavior when using torch.linspace.  Please take a look into the following code, where I compare the output of pytorch and numpy for different number of steps:\nimport torch\nimport numpy as np\nimport sys\n\nmult_factor=0.00002\n\n\n# Torch\nprint('11 steps')\nn_ = torch.linspace(-5.0, 5.0,steps=11)* mult_factor\nprint(n_)\n\nn_ = np.linspace(-5.0, 5.0,11)* mult_factor\nprint(n_)\nprint('.....')\n\nprint('12 steps')\nn_ = torch.linspace(-5.0, 5.0,steps=12)* mult_factor\nprint(n_)\n\nn_ = np.linspace(-5.0, 5.0,12)* mult_factor\nprint(n_)\nprint('.....')\n\nprint('13 steps')\nn_ = torch.linspace(-5.0, 5.0,steps=13)* mult_factor\nprint(n_)\n\nn_ = np.linspace(-5.0, 5.0,13)* mult_factor\nprint(n_)\nprint('.....')\n\n\nprint('14 steps')\nn_ = torch.linspace(-5.0, 5.0,steps=14)* mult_factor\nprint(n_)\n\nn_ = np.linspace(-5.0, 5.0,14)* mult_factor\nprint(n_)\nIf I run the code above I have the following output:\n11 steps\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n         0.0001,  0.0001,  0.0001])\n[-1.e-04 -8.e-05 -6.e-05 -4.e-05 -2.e-05  0.e+00  2.e-05  4.e-05  6.e-05\n  8.e-05  1.e-04]\n.....\n12 steps\ntensor([-1.0000e-04, -8.1818e-05, -6.3636e-05, -4.5455e-05, -2.7273e-05,\n        -9.0909e-06,  9.0909e-06,  2.7273e-05,  4.5455e-05,  6.3636e-05,\n         8.1818e-05,  1.0000e-04])\n[-1.00000000e-04 -8.18181818e-05 -6.36363636e-05 -4.54545455e-05\n -2.72727273e-05 -9.09090909e-06  9.09090909e-06  2.72727273e-05\n  4.54545455e-05  6.36363636e-05  8.18181818e-05  1.00000000e-04]\n.....\n13 steps\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0001,  0.0001,  0.0001])\n[-1.00000000e-04 -8.33333333e-05 -6.66666667e-05 -5.00000000e-05\n -3.33333333e-05 -1.66666667e-05  0.00000000e+00  1.66666667e-05\n  3.33333333e-05  5.00000000e-05  6.66666667e-05  8.33333333e-05\n  1.00000000e-04]\n.....\n14 steps\ntensor([-1.0000e-04, -8.4615e-05, -6.9231e-05, -5.3846e-05, -3.8462e-05,\n        -2.3077e-05, -7.6923e-06,  7.6923e-06,  2.3077e-05,  3.8462e-05,\n         5.3846e-05,  6.9231e-05,  8.4615e-05,  1.0000e-04])\n[-1.00000000e-04 -8.46153846e-05 -6.92307692e-05 -5.38461538e-05\n -3.84615385e-05 -2.30769231e-05 -7.69230769e-06  7.69230769e-06\n  2.30769231e-05  3.84615385e-05  5.38461538e-05  6.92307692e-05\n  8.46153846e-05  1.00000000e-04]\n\nCuriously, when I set an even \"step\" everything seems to work, if I set an odd number of step it seems there is a lack of resolution.  Note that this doesn't happen in numpy. Moreover, I tried with pytorch 0.3 and the issue doesn't arise.  I  noticed the same behavior with torch.range and torch.arange.\nWhat could be the problem?", "body": "I noticed a weird behavior when using torch.linspace.  Please take a look into the following code, where I compare the output of pytorch and numpy for different number of steps:\r\n\r\n```python\r\nimport torch\r\nimport numpy as np\r\nimport sys\r\n\r\nmult_factor=0.00002\r\n\r\n\r\n# Torch\r\nprint('11 steps')\r\nn_ = torch.linspace(-5.0, 5.0,steps=11)* mult_factor\r\nprint(n_)\r\n\r\nn_ = np.linspace(-5.0, 5.0,11)* mult_factor\r\nprint(n_)\r\nprint('.....')\r\n\r\nprint('12 steps')\r\nn_ = torch.linspace(-5.0, 5.0,steps=12)* mult_factor\r\nprint(n_)\r\n\r\nn_ = np.linspace(-5.0, 5.0,12)* mult_factor\r\nprint(n_)\r\nprint('.....')\r\n\r\nprint('13 steps')\r\nn_ = torch.linspace(-5.0, 5.0,steps=13)* mult_factor\r\nprint(n_)\r\n\r\nn_ = np.linspace(-5.0, 5.0,13)* mult_factor\r\nprint(n_)\r\nprint('.....')\r\n\r\n\r\nprint('14 steps')\r\nn_ = torch.linspace(-5.0, 5.0,steps=14)* mult_factor\r\nprint(n_)\r\n\r\nn_ = np.linspace(-5.0, 5.0,14)* mult_factor\r\nprint(n_)\r\n```\r\nIf I run the code above I have the following output:\r\n```\r\n11 steps\r\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\r\n         0.0001,  0.0001,  0.0001])\r\n[-1.e-04 -8.e-05 -6.e-05 -4.e-05 -2.e-05  0.e+00  2.e-05  4.e-05  6.e-05\r\n  8.e-05  1.e-04]\r\n.....\r\n12 steps\r\ntensor([-1.0000e-04, -8.1818e-05, -6.3636e-05, -4.5455e-05, -2.7273e-05,\r\n        -9.0909e-06,  9.0909e-06,  2.7273e-05,  4.5455e-05,  6.3636e-05,\r\n         8.1818e-05,  1.0000e-04])\r\n[-1.00000000e-04 -8.18181818e-05 -6.36363636e-05 -4.54545455e-05\r\n -2.72727273e-05 -9.09090909e-06  9.09090909e-06  2.72727273e-05\r\n  4.54545455e-05  6.36363636e-05  8.18181818e-05  1.00000000e-04]\r\n.....\r\n13 steps\r\ntensor([-0.0001, -0.0001, -0.0001, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\r\n         0.0000,  0.0000,  0.0001,  0.0001,  0.0001])\r\n[-1.00000000e-04 -8.33333333e-05 -6.66666667e-05 -5.00000000e-05\r\n -3.33333333e-05 -1.66666667e-05  0.00000000e+00  1.66666667e-05\r\n  3.33333333e-05  5.00000000e-05  6.66666667e-05  8.33333333e-05\r\n  1.00000000e-04]\r\n.....\r\n14 steps\r\ntensor([-1.0000e-04, -8.4615e-05, -6.9231e-05, -5.3846e-05, -3.8462e-05,\r\n        -2.3077e-05, -7.6923e-06,  7.6923e-06,  2.3077e-05,  3.8462e-05,\r\n         5.3846e-05,  6.9231e-05,  8.4615e-05,  1.0000e-04])\r\n[-1.00000000e-04 -8.46153846e-05 -6.92307692e-05 -5.38461538e-05\r\n -3.84615385e-05 -2.30769231e-05 -7.69230769e-06  7.69230769e-06\r\n  2.30769231e-05  3.84615385e-05  5.38461538e-05  6.92307692e-05\r\n  8.46153846e-05  1.00000000e-04]\r\n```\r\nCuriously, when I set an even \"step\" everything seems to work, if I set an odd number of step it seems there is a lack of resolution.  Note that this doesn't happen in numpy. Moreover, I tried with pytorch 0.3 and the issue doesn't arise.  I  noticed the same behavior with torch.range and torch.arange. \r\n\r\nWhat could be the problem? "}