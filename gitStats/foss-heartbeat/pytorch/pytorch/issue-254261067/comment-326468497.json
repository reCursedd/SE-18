{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/326468497", "html_url": "https://github.com/pytorch/pytorch/issues/2584#issuecomment-326468497", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2584", "id": 326468497, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjQ2ODQ5Nw==", "user": {"login": "ycszen", "id": 6136494, "node_id": "MDQ6VXNlcjYxMzY0OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6136494?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ycszen", "html_url": "https://github.com/ycszen", "followers_url": "https://api.github.com/users/ycszen/followers", "following_url": "https://api.github.com/users/ycszen/following{/other_user}", "gists_url": "https://api.github.com/users/ycszen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ycszen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ycszen/subscriptions", "organizations_url": "https://api.github.com/users/ycszen/orgs", "repos_url": "https://api.github.com/users/ycszen/repos", "events_url": "https://api.github.com/users/ycszen/events{/privacy}", "received_events_url": "https://api.github.com/users/ycszen/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-01T02:07:59Z", "updated_at": "2017-09-01T02:07:59Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> My opinion is that in the forward we can gather the multi-GPU batchnorm's input, then synchronize them to compute the statistics while in the backward we synchronize the gradient. This can enlarge the batchnorm's batchsize, so it can compute more precise statistics. This is why it can improve performance in some tasks which have small batch size. How about your opinion?</p>", "body_text": "@fmassa My opinion is that in the forward we can gather the multi-GPU batchnorm's input, then synchronize them to compute the statistics while in the backward we synchronize the gradient. This can enlarge the batchnorm's batchsize, so it can compute more precise statistics. This is why it can improve performance in some tasks which have small batch size. How about your opinion?", "body": "@fmassa My opinion is that in the forward we can gather the multi-GPU batchnorm's input, then synchronize them to compute the statistics while in the backward we synchronize the gradient. This can enlarge the batchnorm's batchsize, so it can compute more precise statistics. This is why it can improve performance in some tasks which have small batch size. How about your opinion?"}