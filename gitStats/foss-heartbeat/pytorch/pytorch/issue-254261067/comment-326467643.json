{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/326467643", "html_url": "https://github.com/pytorch/pytorch/issues/2584#issuecomment-326467643", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2584", "id": 326467643, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjQ2NzY0Mw==", "user": {"login": "ycszen", "id": 6136494, "node_id": "MDQ6VXNlcjYxMzY0OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6136494?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ycszen", "html_url": "https://github.com/ycszen", "followers_url": "https://api.github.com/users/ycszen/followers", "following_url": "https://api.github.com/users/ycszen/following{/other_user}", "gists_url": "https://api.github.com/users/ycszen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ycszen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ycszen/subscriptions", "organizations_url": "https://api.github.com/users/ycszen/orgs", "repos_url": "https://api.github.com/users/ycszen/repos", "events_url": "https://api.github.com/users/ycszen/events{/privacy}", "received_events_url": "https://api.github.com/users/ycszen/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-01T02:02:02Z", "updated_at": "2017-09-01T02:02:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> Yes. It is optional. In recognition task, the batch size per gpu is large, so this is not necessary. However, in semantic segmentation or detection, the batch size per gpu is so small, even one image per gpu, so the multi-GPU batch norm is crucial. Even in some case, we cannot reproduce the performance in the paper without multi-GPU, for example PSPNet or Deeplab v3.<br>\nPersonally, we can offer a parameter to control using multi-GPU or not.</p>", "body_text": "@ngimel Yes. It is optional. In recognition task, the batch size per gpu is large, so this is not necessary. However, in semantic segmentation or detection, the batch size per gpu is so small, even one image per gpu, so the multi-GPU batch norm is crucial. Even in some case, we cannot reproduce the performance in the paper without multi-GPU, for example PSPNet or Deeplab v3.\nPersonally, we can offer a parameter to control using multi-GPU or not.", "body": "@ngimel Yes. It is optional. In recognition task, the batch size per gpu is large, so this is not necessary. However, in semantic segmentation or detection, the batch size per gpu is so small, even one image per gpu, so the multi-GPU batch norm is crucial. Even in some case, we cannot reproduce the performance in the paper without multi-GPU, for example PSPNet or Deeplab v3.\r\nPersonally, we can offer a parameter to control using multi-GPU or not."}