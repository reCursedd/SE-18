{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7731", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7731/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7731/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7731/events", "html_url": "https://github.com/pytorch/pytorch/issues/7731", "id": 324959963, "node_id": "MDU6SXNzdWUzMjQ5NTk5NjM=", "number": 7731, "title": "in-place Arithmetic assignment operators gives wrong answers", "user": {"login": "calebh", "id": 542102, "node_id": "MDQ6VXNlcjU0MjEwMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/542102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calebh", "html_url": "https://github.com/calebh", "followers_url": "https://api.github.com/users/calebh/followers", "following_url": "https://api.github.com/users/calebh/following{/other_user}", "gists_url": "https://api.github.com/users/calebh/gists{/gist_id}", "starred_url": "https://api.github.com/users/calebh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calebh/subscriptions", "organizations_url": "https://api.github.com/users/calebh/orgs", "repos_url": "https://api.github.com/users/calebh/repos", "events_url": "https://api.github.com/users/calebh/events{/privacy}", "received_events_url": "https://api.github.com/users/calebh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-05-21T15:32:19Z", "updated_at": "2018-05-22T21:16:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Using the +=, -=, *=, /= operators gives the wrong answer in some cases without any warning. The matrix multiply assignment operator @= seems to work fine. I have tested in both PyTorch 0.3.0.post4 and PyTorch 0.4.0 (the latest version at the time of this issue creation) on the CPU. I have not tested whether this bug happens with CUDA.</p>\n<h2>Code example</h2>\n<p>I was able to produce a minimal case of this bug:</p>\n<pre><code>import torch\n\n## Addition\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 += t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 + t2)\n\n## Subtraction\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 -= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 - t2)\n\n## Multiplication\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 *= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 * t2)\n\n## Division\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 /= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 / t2)\n</code></pre>\n<h2>Output</h2>\n<pre><code>Incorrect answer\ntensor([[  7.,   7.,   7.],\n        [ 21.,  21.,  21.],\n        [ 62.,  62.,  62.]])\nCorrect answer\ntensor([[ 2.,  3.,  4.],\n        [ 3.,  4.,  5.],\n        [ 4.,  5.,  6.]])\nIncorrect answer\ntensor([[-5., -5., -5.],\n        [-3., -3., -3.],\n        [ 0.,  0.,  0.]])\nCorrect answer\ntensor([[ 0., -1., -2.],\n        [ 1.,  0., -1.],\n        [ 2.,  1.,  0.]])\nIncorrect answer\ntensor([[ 6.0000e+00,  6.0000e+00,  6.0000e+00],\n        [ 4.3200e+02,  4.3200e+02,  4.3200e+02],\n        [ 6.0466e+07,  6.0466e+07,  6.0466e+07]])\nCorrect answer\ntensor([[ 1.,  2.,  3.],\n        [ 2.,  4.,  6.],\n        [ 3.,  6.,  9.]])\nIncorrect answer\ntensor([[ 0.1667,  0.1667,  0.1667],\n        [ 0.3333,  0.3333,  0.3333],\n        [ 1.0000,  1.0000,  1.0000]])\nCorrect answer\ntensor([[ 1.0000,  0.5000,  0.3333],\n        [ 2.0000,  1.0000,  0.6667],\n        [ 3.0000,  1.5000,  1.0000]])\n</code></pre>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 17.10<br>\nGCC version: (Ubuntu 7.2.0-8ubuntu3.2) 7.2.0<br>\nCMake version: version 3.9.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.14.3)<br>\n[pip3] torch (0.4.0)<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nUsing the +=, -=, *=, /= operators gives the wrong answer in some cases without any warning. The matrix multiply assignment operator @= seems to work fine. I have tested in both PyTorch 0.3.0.post4 and PyTorch 0.4.0 (the latest version at the time of this issue creation) on the CPU. I have not tested whether this bug happens with CUDA.\nCode example\nI was able to produce a minimal case of this bug:\nimport torch\n\n## Addition\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 += t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 + t2)\n\n## Subtraction\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 -= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 - t2)\n\n## Multiplication\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 *= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 * t2)\n\n## Division\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nt1 /= t2\nprint(\"Incorrect answer\")\nprint(t1)\n\nx = torch.Tensor([[1],[2],[3]])\nt1 = x.expand(3, 3)\nt2 = x.t().expand(3, 3)\n\nprint(\"Correct answer\")\nprint(t1 / t2)\n\nOutput\nIncorrect answer\ntensor([[  7.,   7.,   7.],\n        [ 21.,  21.,  21.],\n        [ 62.,  62.,  62.]])\nCorrect answer\ntensor([[ 2.,  3.,  4.],\n        [ 3.,  4.,  5.],\n        [ 4.,  5.,  6.]])\nIncorrect answer\ntensor([[-5., -5., -5.],\n        [-3., -3., -3.],\n        [ 0.,  0.,  0.]])\nCorrect answer\ntensor([[ 0., -1., -2.],\n        [ 1.,  0., -1.],\n        [ 2.,  1.,  0.]])\nIncorrect answer\ntensor([[ 6.0000e+00,  6.0000e+00,  6.0000e+00],\n        [ 4.3200e+02,  4.3200e+02,  4.3200e+02],\n        [ 6.0466e+07,  6.0466e+07,  6.0466e+07]])\nCorrect answer\ntensor([[ 1.,  2.,  3.],\n        [ 2.,  4.,  6.],\n        [ 3.,  6.,  9.]])\nIncorrect answer\ntensor([[ 0.1667,  0.1667,  0.1667],\n        [ 0.3333,  0.3333,  0.3333],\n        [ 1.0000,  1.0000,  1.0000]])\nCorrect answer\ntensor([[ 1.0000,  0.5000,  0.3333],\n        [ 2.0000,  1.0000,  0.6667],\n        [ 3.0000,  1.5000,  1.0000]])\n\nSystem Info\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 17.10\nGCC version: (Ubuntu 7.2.0-8ubuntu3.2) 7.2.0\nCMake version: version 3.9.1\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] torch (0.4.0)\n[conda] Could not collect", "body": "## Issue description\r\n\r\nUsing the +=, -=, *=, /= operators gives the wrong answer in some cases without any warning. The matrix multiply assignment operator @= seems to work fine. I have tested in both PyTorch 0.3.0.post4 and PyTorch 0.4.0 (the latest version at the time of this issue creation) on the CPU. I have not tested whether this bug happens with CUDA.\r\n\r\n## Code example\r\n\r\nI was able to produce a minimal case of this bug:\r\n\r\n```\r\nimport torch\r\n\r\n## Addition\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nt1 += t2\r\nprint(\"Incorrect answer\")\r\nprint(t1)\r\n\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nprint(\"Correct answer\")\r\nprint(t1 + t2)\r\n\r\n## Subtraction\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nt1 -= t2\r\nprint(\"Incorrect answer\")\r\nprint(t1)\r\n\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nprint(\"Correct answer\")\r\nprint(t1 - t2)\r\n\r\n## Multiplication\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nt1 *= t2\r\nprint(\"Incorrect answer\")\r\nprint(t1)\r\n\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nprint(\"Correct answer\")\r\nprint(t1 * t2)\r\n\r\n## Division\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nt1 /= t2\r\nprint(\"Incorrect answer\")\r\nprint(t1)\r\n\r\nx = torch.Tensor([[1],[2],[3]])\r\nt1 = x.expand(3, 3)\r\nt2 = x.t().expand(3, 3)\r\n\r\nprint(\"Correct answer\")\r\nprint(t1 / t2)\r\n```\r\n\r\n## Output\r\n```\r\nIncorrect answer\r\ntensor([[  7.,   7.,   7.],\r\n        [ 21.,  21.,  21.],\r\n        [ 62.,  62.,  62.]])\r\nCorrect answer\r\ntensor([[ 2.,  3.,  4.],\r\n        [ 3.,  4.,  5.],\r\n        [ 4.,  5.,  6.]])\r\nIncorrect answer\r\ntensor([[-5., -5., -5.],\r\n        [-3., -3., -3.],\r\n        [ 0.,  0.,  0.]])\r\nCorrect answer\r\ntensor([[ 0., -1., -2.],\r\n        [ 1.,  0., -1.],\r\n        [ 2.,  1.,  0.]])\r\nIncorrect answer\r\ntensor([[ 6.0000e+00,  6.0000e+00,  6.0000e+00],\r\n        [ 4.3200e+02,  4.3200e+02,  4.3200e+02],\r\n        [ 6.0466e+07,  6.0466e+07,  6.0466e+07]])\r\nCorrect answer\r\ntensor([[ 1.,  2.,  3.],\r\n        [ 2.,  4.,  6.],\r\n        [ 3.,  6.,  9.]])\r\nIncorrect answer\r\ntensor([[ 0.1667,  0.1667,  0.1667],\r\n        [ 0.3333,  0.3333,  0.3333],\r\n        [ 1.0000,  1.0000,  1.0000]])\r\nCorrect answer\r\ntensor([[ 1.0000,  0.5000,  0.3333],\r\n        [ 2.0000,  1.0000,  0.6667],\r\n        [ 3.0000,  1.5000,  1.0000]])\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 17.10\r\nGCC version: (Ubuntu 7.2.0-8ubuntu3.2) 7.2.0\r\nCMake version: version 3.9.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.3)\r\n[pip3] torch (0.4.0)\r\n[conda] Could not collect"}