{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/398496484", "html_url": "https://github.com/pytorch/pytorch/issues/1875#issuecomment-398496484", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1875", "id": 398496484, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODQ5NjQ4NA==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-19T18:19:47Z", "updated_at": "2018-06-19T18:19:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Sounds like most Numpy-like ops have already been implemented, except for the <code>torch.mean()</code> for ByteTensors. Any reason why it is not supported?</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">get_mean</span>(<span class=\"pl-smi\">dtype</span>):\n    <span class=\"pl-k\">try</span>:\n        data <span class=\"pl-k\">=</span> np.random.randint(<span class=\"pl-c1\">10</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\n        x <span class=\"pl-k\">=</span> torch.tensor(data, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype)\n        <span class=\"pl-c1\">print</span>(x.dtype, x.mean())\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">Exception</span> <span class=\"pl-k\">as</span> e:\n        <span class=\"pl-c1\">print</span>(e)\n    \ndtypes <span class=\"pl-k\">=</span> [torch.float16, torch.float32, torch.float64, torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64]\n<span class=\"pl-k\">for</span> d <span class=\"pl-k\">in</span> dtypes:\n    get_mean(d)</pre></div>\n<p>mean is not implemented for type torch.HalfTensor<br>\n(torch.float32, tensor(5.5000))<br>\n(torch.float64, tensor(5.5000, dtype=torch.float64))<br>\nmean is not implemented for type torch.ByteTensor<br>\nmean is not implemented for type torch.CharTensor<br>\nmean is not implemented for type torch.ShortTensor<br>\nmean is not implemented for type torch.IntTensor<br>\nmean is not implemented for type torch.LongTensor</p>", "body_text": "Sounds like most Numpy-like ops have already been implemented, except for the torch.mean() for ByteTensors. Any reason why it is not supported?\ndef get_mean(dtype):\n    try:\n        data = np.random.randint(10, size=10)\n        x = torch.tensor(data, dtype=dtype)\n        print(x.dtype, x.mean())\n    except Exception as e:\n        print(e)\n    \ndtypes = [torch.float16, torch.float32, torch.float64, torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64]\nfor d in dtypes:\n    get_mean(d)\nmean is not implemented for type torch.HalfTensor\n(torch.float32, tensor(5.5000))\n(torch.float64, tensor(5.5000, dtype=torch.float64))\nmean is not implemented for type torch.ByteTensor\nmean is not implemented for type torch.CharTensor\nmean is not implemented for type torch.ShortTensor\nmean is not implemented for type torch.IntTensor\nmean is not implemented for type torch.LongTensor", "body": "Sounds like most Numpy-like ops have already been implemented, except for the `torch.mean()` for ByteTensors. Any reason why it is not supported?\r\n\r\n```python\r\ndef get_mean(dtype):\r\n    try:\r\n        data = np.random.randint(10, size=10)\r\n        x = torch.tensor(data, dtype=dtype)\r\n        print(x.dtype, x.mean())\r\n    except Exception as e:\r\n        print(e)\r\n    \r\ndtypes = [torch.float16, torch.float32, torch.float64, torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64]\r\nfor d in dtypes:\r\n    get_mean(d)\r\n```\r\nmean is not implemented for type torch.HalfTensor\r\n(torch.float32, tensor(5.5000))\r\n(torch.float64, tensor(5.5000, dtype=torch.float64))\r\nmean is not implemented for type torch.ByteTensor\r\nmean is not implemented for type torch.CharTensor\r\nmean is not implemented for type torch.ShortTensor\r\nmean is not implemented for type torch.IntTensor\r\nmean is not implemented for type torch.LongTensor"}