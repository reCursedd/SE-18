{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184414940", "pull_request_review_id": 115606721, "id": 184414940, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDQxNDk0MA==", "diff_hunk": "@@ -93,7 +93,7 @@\n \"\"\")\n \n ASSIGN_GRAD_FN = CodeTemplate(\"\"\"\\\n-grad_fn = std::make_shared<${op}>(${op_ctor});\n+grad_fn = std::shared_ptr<${op}>(new ${op}(${op_ctor}), deleteFunction);", "path": "tools/autograd/gen_variable_type.py", "position": 5, "original_position": 5, "commit_id": "92adc80cb73a1748ab2cb0cbe4eb50df38b7b051", "original_commit_id": "3cc9eca89964c3270eb141e94648d1f34d59c182", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "When one has a deep computation graph of only Python-created autograd functions, the code doesn't stack overflow because Python queues the THPFunction objects that own PyFunctions.  Even if the deallocation of the graph is triggered from the C++ side, to free the PyFunctions in the computation graph, the THPFunction python objects must be freed first.\r\n\r\nThere's this other case though, where the computation graph is a mix of PyFunctions and C++ Functions. Because Python has a low limit (`#define PyTrash_UNWIND_LEVEL 50`), it's not completely necessary to add the custom deleter for PyFunction: after ~50 THPFunction get deleted, the other THPFunctions get queued, stopping the deletion of the rest of the computation graph until those THPFunction get deleted.", "created_at": "2018-04-26T14:42:24Z", "updated_at": "2018-11-23T15:43:15Z", "html_url": "https://github.com/pytorch/pytorch/pull/6873#discussion_r184414940", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6873", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184414940"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6873#discussion_r184414940"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6873"}}, "body_html": "<p>When one has a deep computation graph of only Python-created autograd functions, the code doesn't stack overflow because Python queues the THPFunction objects that own PyFunctions.  Even if the deallocation of the graph is triggered from the C++ side, to free the PyFunctions in the computation graph, the THPFunction python objects must be freed first.</p>\n<p>There's this other case though, where the computation graph is a mix of PyFunctions and C++ Functions. Because Python has a low limit (<code>#define PyTrash_UNWIND_LEVEL 50</code>), it's not completely necessary to add the custom deleter for PyFunction: after ~50 THPFunction get deleted, the other THPFunctions get queued, stopping the deletion of the rest of the computation graph until those THPFunction get deleted.</p>", "body_text": "When one has a deep computation graph of only Python-created autograd functions, the code doesn't stack overflow because Python queues the THPFunction objects that own PyFunctions.  Even if the deallocation of the graph is triggered from the C++ side, to free the PyFunctions in the computation graph, the THPFunction python objects must be freed first.\nThere's this other case though, where the computation graph is a mix of PyFunctions and C++ Functions. Because Python has a low limit (#define PyTrash_UNWIND_LEVEL 50), it's not completely necessary to add the custom deleter for PyFunction: after ~50 THPFunction get deleted, the other THPFunctions get queued, stopping the deletion of the rest of the computation graph until those THPFunction get deleted.", "in_reply_to_id": 183663945}