{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184180558", "pull_request_review_id": 115323224, "id": 184180558, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDE4MDU1OA==", "diff_hunk": "@@ -106,4 +107,65 @@ void Function::set_up_context_edge(\n     backward_eval->forward_ctx_select = ctx_select;\n }\n \n+/*\n+ * Fix for #5534: prevent stack overflow on deletion of deep computation graph\n+ *\n+ * Sometimes one can end up with a very big computation graph of Functions\n+ * and Edges. Each std::shared_ptr<Function> contains a list of Edge, and\n+ * each Edge contains a std::shared_ptr<Function>. Deleting a\n+ * std::shared_ptr<Function> can trigger the recursive deletion of other\n+ * std::shared_ptr<Function>'s: this can stack overflow if the graph\n+ * is deep enough. Here is an example of such a graph:\n+ *\n+ * shared_ptr<Function> -> Edge -> shared_ptr<Function> -> Edge -> ... -> shared_ptr<Function>\n+ *\n+ * The solution here is to use a custom deleter with each\n+ * std::shared_ptr<Function>. The custom deleter keeps track of how many\n+ * nested deleters it is in. When this number exceeds the maximum allowed\n+ * depth, the Function* to be deleted are accumulated in a per-thread\n+ * delete queue and handled by one of the deleters.\n+ */\n+thread_local std::deque<Function*> kDeleteFunctionQueue;\n+\n+constexpr size_t kDeleteFunctionMaxRecursionDepth = 10000;", "path": "torch/csrc/autograd/function.cpp", "position": null, "original_position": 32, "commit_id": "92adc80cb73a1748ab2cb0cbe4eb50df38b7b051", "original_commit_id": "420314aa25d1527efa284b4647685619a359f8fb", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "It also makes me nervous....\r\n\r\nIf I set the number too high, a deep computation graph will still segfault. Right now my procedure is:\r\n- find the smallest `kDeleteFunctionMaxRecursionDepth` needed for a deep computation graph to segfault\r\n- Do this for different machines, and take the minimum of all of the resulting numbers.\r\n\r\nI tested on two machines: `kDeleteFunctionMaxRecursionDepth` of 15000 stackoverflows one machine and 60000 stackoverflows another.\r\n\r\nA better way to do this might be to determine if we're about to stack overflow (and if we are, then start using the delete queue) but I'm still looking into how feasible this is", "created_at": "2018-04-25T19:31:45Z", "updated_at": "2018-11-23T15:43:11Z", "html_url": "https://github.com/pytorch/pytorch/pull/6873#discussion_r184180558", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6873", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184180558"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6873#discussion_r184180558"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6873"}}, "body_html": "<p>It also makes me nervous....</p>\n<p>If I set the number too high, a deep computation graph will still segfault. Right now my procedure is:</p>\n<ul>\n<li>find the smallest <code>kDeleteFunctionMaxRecursionDepth</code> needed for a deep computation graph to segfault</li>\n<li>Do this for different machines, and take the minimum of all of the resulting numbers.</li>\n</ul>\n<p>I tested on two machines: <code>kDeleteFunctionMaxRecursionDepth</code> of 15000 stackoverflows one machine and 60000 stackoverflows another.</p>\n<p>A better way to do this might be to determine if we're about to stack overflow (and if we are, then start using the delete queue) but I'm still looking into how feasible this is</p>", "body_text": "It also makes me nervous....\nIf I set the number too high, a deep computation graph will still segfault. Right now my procedure is:\n\nfind the smallest kDeleteFunctionMaxRecursionDepth needed for a deep computation graph to segfault\nDo this for different machines, and take the minimum of all of the resulting numbers.\n\nI tested on two machines: kDeleteFunctionMaxRecursionDepth of 15000 stackoverflows one machine and 60000 stackoverflows another.\nA better way to do this might be to determine if we're about to stack overflow (and if we are, then start using the delete queue) but I'm still looking into how feasible this is", "in_reply_to_id": 184179172}