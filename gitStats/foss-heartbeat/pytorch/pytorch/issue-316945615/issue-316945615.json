{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6873", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6873/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6873/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6873/events", "html_url": "https://github.com/pytorch/pytorch/pull/6873", "id": 316945615, "node_id": "MDExOlB1bGxSZXF1ZXN0MTgzNTI5NTM5", "number": 6873, "title": "Prevent stack overflow on deletion of deep graph", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-23T19:10:56Z", "updated_at": "2018-11-23T15:43:20Z", "closed_at": "2018-04-27T19:49:59Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/6873", "html_url": "https://github.com/pytorch/pytorch/pull/6873", "diff_url": "https://github.com/pytorch/pytorch/pull/6873.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/6873.patch"}, "body_html": "<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #5534.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"301907292\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5534\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/5534/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/5534\">#5534</a>.</p>\n<p>Sometimes one can end up with a very big computation graph of Functions<br>\nand Edges. Each std::shared_ptr contains a list of Edge, and<br>\neach Edge contains a std::shared_ptr. Deleting a<br>\nstd::shared_ptr can trigger the recursive deletion of other<br>\nstd::shared_ptr's: this can stack overflow if the graph<br>\nis deep enough. Here is an example of such a graph:</p>\n<pre><code>shared_ptr&lt;Function&gt; -&gt; Edge -&gt; shared_ptr&lt;Function&gt; -&gt; Edge -&gt; ... -&gt; shared_ptr&lt;Function&gt;\n</code></pre>\n<p>The solution here is to use a custom deleter with each<br>\nstd::shared_ptr. The custom deleter keeps track of how many<br>\nnested deleters it is in. When this number exceeds the maximum allowed<br>\ndepth, the Function* to be deleted are accumulated in a per-thread<br>\ndelete queue and handled by one of the deleters.</p>\n<p>Example code that could trigger the overflow (set <code>depth</code> to something &gt;<br>\n100000) is below. I also benchmarked the below code before/after the<br>\nchanges to see if there are any significant performance differences.</p>\n<pre><code>import torch\ndef scope():\n    depth = 80000\n    x = torch.randn(9, requires_grad=True)\n    y = x.clone()\n\n    # build deeply nested computation graph\n    for i in range(depth):\n        y = y + y * 0.000001\n\n%timeit -n 100 scope()\n\n376 ms \u00b1 3.94 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nWithout changes:\n352 ms \u00b1 6.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code></pre>\n<p>With the change, the above code is 6.8% slower.</p>\n<p>Thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> for brainstorming solutions with me and coming up with this idea.</p>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>\n<p>EDIT: I did some more benchmarking. It looks like it takes 25% more time to free the computation graph in the case of the straight chain graph: <a href=\"https://gist.github.com/zou3519/93cf84d96ae431356ae7f7c1923ef51a\">https://gist.github.com/zou3519/93cf84d96ae431356ae7f7c1923ef51a</a></p>", "body_text": "Fixes #5534.\nSometimes one can end up with a very big computation graph of Functions\nand Edges. Each std::shared_ptr contains a list of Edge, and\neach Edge contains a std::shared_ptr. Deleting a\nstd::shared_ptr can trigger the recursive deletion of other\nstd::shared_ptr's: this can stack overflow if the graph\nis deep enough. Here is an example of such a graph:\nshared_ptr<Function> -> Edge -> shared_ptr<Function> -> Edge -> ... -> shared_ptr<Function>\n\nThe solution here is to use a custom deleter with each\nstd::shared_ptr. The custom deleter keeps track of how many\nnested deleters it is in. When this number exceeds the maximum allowed\ndepth, the Function* to be deleted are accumulated in a per-thread\ndelete queue and handled by one of the deleters.\nExample code that could trigger the overflow (set depth to something >\n100000) is below. I also benchmarked the below code before/after the\nchanges to see if there are any significant performance differences.\nimport torch\ndef scope():\n    depth = 80000\n    x = torch.randn(9, requires_grad=True)\n    y = x.clone()\n\n    # build deeply nested computation graph\n    for i in range(depth):\n        y = y + y * 0.000001\n\n%timeit -n 100 scope()\n\n376 ms \u00b1 3.94 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nWithout changes:\n352 ms \u00b1 6.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nWith the change, the above code is 6.8% slower.\nThanks to @ezyang and @SsnL for brainstorming solutions with me and coming up with this idea.\ncc @ezyang @SsnL @apaszke\nEDIT: I did some more benchmarking. It looks like it takes 25% more time to free the computation graph in the case of the straight chain graph: https://gist.github.com/zou3519/93cf84d96ae431356ae7f7c1923ef51a", "body": "Fixes #5534.\r\n\r\nSometimes one can end up with a very big computation graph of Functions\r\nand Edges. Each std::shared_ptr<Function> contains a list of Edge, and\r\neach Edge contains a std::shared_ptr<Function>. Deleting a\r\nstd::shared_ptr<Function> can trigger the recursive deletion of other\r\nstd::shared_ptr<Function>'s: this can stack overflow if the graph\r\nis deep enough. Here is an example of such a graph:\r\n\r\n    shared_ptr<Function> -> Edge -> shared_ptr<Function> -> Edge -> ... -> shared_ptr<Function>\r\n\r\nThe solution here is to use a custom deleter with each\r\nstd::shared_ptr<Function>. The custom deleter keeps track of how many\r\nnested deleters it is in. When this number exceeds the maximum allowed\r\ndepth, the Function* to be deleted are accumulated in a per-thread\r\ndelete queue and handled by one of the deleters.\r\n\r\nExample code that could trigger the overflow (set ``depth`` to something >\r\n100000) is below. I also benchmarked the below code before/after the\r\nchanges to see if there are any significant performance differences.\r\n\r\n```\r\nimport torch\r\ndef scope():\r\n    depth = 80000\r\n    x = torch.randn(9, requires_grad=True)\r\n    y = x.clone()\r\n\r\n    # build deeply nested computation graph\r\n    for i in range(depth):\r\n        y = y + y * 0.000001\r\n\r\n%timeit -n 100 scope()\r\n\r\n376 ms \u00b1 3.94 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n\r\nWithout changes:\r\n352 ms \u00b1 6.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\r\n```\r\n\r\nWith the change, the above code is 6.8% slower.\r\n\r\nThanks to @ezyang and @SsnL for brainstorming solutions with me and coming up with this idea.\r\n\r\ncc @ezyang @SsnL @apaszke \r\n\r\nEDIT: I did some more benchmarking. It looks like it takes 25% more time to free the computation graph in the case of the straight chain graph: https://gist.github.com/zou3519/93cf84d96ae431356ae7f7c1923ef51a\r\n"}