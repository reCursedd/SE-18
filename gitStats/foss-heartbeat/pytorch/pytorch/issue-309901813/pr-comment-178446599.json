{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178446599", "pull_request_review_id": 108507574, "id": 178446599, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODQ0NjU5OQ==", "diff_hunk": "@@ -185,21 +185,32 @@ Tensor _fft_cufft(const Tensor& self, int64_t signal_ndim,\n   std::vector<long long int> inembed(signal_ndim);\n \n   // check the input sizes and strides to see if we need to make it contiguous\n-  bool need_contiguous = input.stride(signal_ndim) == 0;\n+  // cuFFT doesn't support batch dim with stride 0\n+  bool need_contiguous = input.stride(0) == 0;\n+\n   if (complex_input) {\n-    // Real/imag dimension must be like complex type. Need to make the input\n-    // tensor contiguous if this dimension is not contiguous.\n+    // Real/imag dimension must be like complex type.\n     need_contiguous |= input.stride(-1) != 1;\n+    // Strides of other dimensions needs to be aligned when viewed as of\n+    // complex type, i.e., multiples of 2. We check the batch dim here. The\n+    // other signal dims are checked in a for-loop afterwards.\n+    need_contiguous |= input.stride(0) % 2 != 0;\n   } else if (is_half) {\n     // For half, base strides on the real part of real-to-complex and\n     // complex-to-real transforms are not supported. Since our output is always\n     // contiguous, only need to check real-to-complex case.\n     need_contiguous |= input.stride(signal_ndim) != 1;\n   }\n-  // store last tensor stride to infer inembed array\n-  // complex input's last dim is size 2 and contiguous\n+\n+  // Store last dimension stride to infer inembed array\n+  // This is used when `need_contiguous=False`, so we can assume that the last\n+  // dimension is indeed aligned. Complex input's last signal dim can be viewed\n+  // as having stride=2, where the unit is sizeof(real_type).\n   long long int ilast_stride = complex_input ? 2 : 1;\n-   // for each signal dim from innermost to outermost\n+  // For each signal dim from innermost to outermost, compute inembed values if\n+  // possible. If not, then we need to make input contiguous. Notice that if we\n+  // can compute inembed values, it means that the dimensions conform to the\n+  // data type alignment, e.g., strides are multiples of 2 when complex_input.\n   for (int64_t i = signal_ndim - 1; i >= 0; i--) {", "path": "aten/src/ATen/native/cuda/SpectralOps.cu", "position": null, "original_position": 36, "commit_id": "878b8fb7f17d4786a16263f3788f3290bcfe3347", "original_commit_id": "8f9d002ff38a78bdec0d4bb2b76803d1a32e86ac", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Aha! I see it!\r\n\r\nNow that I think I actually understand what this code is doing (as opposed to just doing \"spot checks\" on it), I have some comments about how it can be made clearer (unless, @colesbury, you think this code is perfectly clear as it stands? :o)\r\n\r\n1. Let's actually inline an explanation of what `inembeds` and `onembeds` are. At the moment, in this file, it seems the most explanation it gets is that they are \"the sizes of enclosing tensor.\" The Advanced Data Layout section of the cufft has a very poorly written section http://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout but the equations (e.g., `input[b * idist + (x * inembed[1] + y) * istride]`) convey the important information from which you can work out the rest. (Actually, that's not true; the docs add \"Note that the size of each dimension of the transform should be less than or equal to the inembed and onembed values for the corresponding dimension, that is n[i] \u2264 inembed[i], n[i] \u2264 onembed[i]\"; which means you can't pass broadcasted tensors (stride == 0) to cufft; judging that the mkl variant doesn't do this test, I'm guessing it doesn't have a similar restriction?\r\n\r\n2. Once this explanation exists, there will be multiple places where a code reader might see `inembed` or `onembeds` and wonder what it is. If you make the explanation in (1) a Note and reference it from each relevant call site, you can make it more likely that someone will actually write the comment you lovingly crafted in (1).\r\n\r\n3. In fact, it would be nice to have a general discussion about weird stride modes, and possibly factor out some of the logic in this function. Not for this PR, I've filed an issue for it. https://github.com/pytorch/pytorch/issues/6165\r\n\r\n4. What you might consider for this PR, from above, is refactoring the inembed calculation into its own function. The signature looks like `at::optional<std::vector<int64_t>> is_embedded_strides(std::vector<int64_t> stride)`. This returns `std::nullopt` when strides are not embedded (as per the cufft definition, I suppose, which means you ought to test for broadcasting too) and returning the multiplicative relationship between the strides when they are embedded.\r\n\r\nThanks for reading! Let me know if you disagree with any of this.", "created_at": "2018-04-01T02:35:51Z", "updated_at": "2018-11-23T15:41:27Z", "html_url": "https://github.com/pytorch/pytorch/pull/6118#discussion_r178446599", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6118", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178446599"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6118#discussion_r178446599"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6118"}}, "body_html": "<p>Aha! I see it!</p>\n<p>Now that I think I actually understand what this code is doing (as opposed to just doing \"spot checks\" on it), I have some comments about how it can be made clearer (unless, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a>, you think this code is perfectly clear as it stands? :o)</p>\n<ol>\n<li>\n<p>Let's actually inline an explanation of what <code>inembeds</code> and <code>onembeds</code> are. At the moment, in this file, it seems the most explanation it gets is that they are \"the sizes of enclosing tensor.\" The Advanced Data Layout section of the cufft has a very poorly written section <a href=\"http://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout\" rel=\"nofollow\">http://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout</a> but the equations (e.g., <code>input[b * idist + (x * inembed[1] + y) * istride]</code>) convey the important information from which you can work out the rest. (Actually, that's not true; the docs add \"Note that the size of each dimension of the transform should be less than or equal to the inembed and onembed values for the corresponding dimension, that is n[i] \u2264 inembed[i], n[i] \u2264 onembed[i]\"; which means you can't pass broadcasted tensors (stride == 0) to cufft; judging that the mkl variant doesn't do this test, I'm guessing it doesn't have a similar restriction?</p>\n</li>\n<li>\n<p>Once this explanation exists, there will be multiple places where a code reader might see <code>inembed</code> or <code>onembeds</code> and wonder what it is. If you make the explanation in (1) a Note and reference it from each relevant call site, you can make it more likely that someone will actually write the comment you lovingly crafted in (1).</p>\n</li>\n<li>\n<p>In fact, it would be nice to have a general discussion about weird stride modes, and possibly factor out some of the logic in this function. Not for this PR, I've filed an issue for it. <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"310287775\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6165\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6165/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6165\">#6165</a></p>\n</li>\n<li>\n<p>What you might consider for this PR, from above, is refactoring the inembed calculation into its own function. The signature looks like <code>at::optional&lt;std::vector&lt;int64_t&gt;&gt; is_embedded_strides(std::vector&lt;int64_t&gt; stride)</code>. This returns <code>std::nullopt</code> when strides are not embedded (as per the cufft definition, I suppose, which means you ought to test for broadcasting too) and returning the multiplicative relationship between the strides when they are embedded.</p>\n</li>\n</ol>\n<p>Thanks for reading! Let me know if you disagree with any of this.</p>", "body_text": "Aha! I see it!\nNow that I think I actually understand what this code is doing (as opposed to just doing \"spot checks\" on it), I have some comments about how it can be made clearer (unless, @colesbury, you think this code is perfectly clear as it stands? :o)\n\n\nLet's actually inline an explanation of what inembeds and onembeds are. At the moment, in this file, it seems the most explanation it gets is that they are \"the sizes of enclosing tensor.\" The Advanced Data Layout section of the cufft has a very poorly written section http://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout but the equations (e.g., input[b * idist + (x * inembed[1] + y) * istride]) convey the important information from which you can work out the rest. (Actually, that's not true; the docs add \"Note that the size of each dimension of the transform should be less than or equal to the inembed and onembed values for the corresponding dimension, that is n[i] \u2264 inembed[i], n[i] \u2264 onembed[i]\"; which means you can't pass broadcasted tensors (stride == 0) to cufft; judging that the mkl variant doesn't do this test, I'm guessing it doesn't have a similar restriction?\n\n\nOnce this explanation exists, there will be multiple places where a code reader might see inembed or onembeds and wonder what it is. If you make the explanation in (1) a Note and reference it from each relevant call site, you can make it more likely that someone will actually write the comment you lovingly crafted in (1).\n\n\nIn fact, it would be nice to have a general discussion about weird stride modes, and possibly factor out some of the logic in this function. Not for this PR, I've filed an issue for it. #6165\n\n\nWhat you might consider for this PR, from above, is refactoring the inembed calculation into its own function. The signature looks like at::optional<std::vector<int64_t>> is_embedded_strides(std::vector<int64_t> stride). This returns std::nullopt when strides are not embedded (as per the cufft definition, I suppose, which means you ought to test for broadcasting too) and returning the multiplicative relationship between the strides when they are embedded.\n\n\nThanks for reading! Let me know if you disagree with any of this.", "in_reply_to_id": 178445840}