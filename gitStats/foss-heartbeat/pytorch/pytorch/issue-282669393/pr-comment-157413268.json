{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157413268", "pull_request_review_id": 84049357, "id": 157413268, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NzQxMzI2OA==", "diff_hunk": "@@ -96,7 +96,15 @@ def _validate_log_prob_arg(self, value):\n         \"\"\"\n         if not (torch.is_tensor(value) or isinstance(value, Variable)):\n             raise ValueError('The value argument to log_prob must be a Tensor or Variable instance.')\n-        batch_dim_start = len(value.size()) - len(self._batch_shape) - len(self._event_shape)\n-        if value.size()[batch_dim_start:] != self._batch_shape + self._event_shape:\n-            raise ValueError('The right-most size of value must match: {}.'.\n-                             format(self._batch_shape + self._event_shape))\n+\n+        event_dim_start = len(value.size()) - len(self._event_shape)\n+        if value.size()[event_dim_start:] != self._event_shape:\n+            raise ValueError('The right-most size of value must match event_shape: {} vs {}.'.\n+                             format(value.size(), self._event_shape))\n+\n+        actual_shape = value.size()\n+        expected_shape = self._batch_shape + self._event_shape\n+        for i, j in zip(reversed(actual_shape), reversed(expected_shape)):", "path": "torch/distributions/distribution.py", "position": 16, "original_position": 16, "commit_id": "cf9466a97e1a40bc5ad6bf99c91ee98f4baaf907", "original_commit_id": "cf9466a97e1a40bc5ad6bf99c91ee98f4baaf907", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "body": "It may be cheaper to do\r\n```\r\n    if self._batch_shape and value.size()[:event_dim_start]:\r\n        try:\r\n            torch._C._infer_size(value.size()[:event_dim_start], self._batch_shape)\r\n        except RuntimeError:\r\n            raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\r\n                             format(actual_shape, expected_shape))\r\n```\r\n\r\nJust to make sure, this broadcasting will allow both upcasting of distribution parameters as well as upcasting of values:\r\n\r\ne.g.\r\n```\r\n        p = Normal(Variable(torch.Tensor([[0.0], [1.0]])),\r\n                   Variable(torch.Tensor([[1.0], [1.0]])))    # size (2, 1)\r\n        x = Variable(torch.Tensor([0.0, 1.0]))    # size (2,)\r\n        pdf = torch.exp(p.log_prob(x))     # size (2, 2)\r\n```", "created_at": "2017-12-18T07:20:45Z", "updated_at": "2018-11-23T15:37:30Z", "html_url": "https://github.com/pytorch/pytorch/pull/4210#discussion_r157413268", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4210", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157413268"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4210#discussion_r157413268"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4210"}}, "body_html": "<p>It may be cheaper to do</p>\n<pre><code>    if self._batch_shape and value.size()[:event_dim_start]:\n        try:\n            torch._C._infer_size(value.size()[:event_dim_start], self._batch_shape)\n        except RuntimeError:\n            raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n                             format(actual_shape, expected_shape))\n</code></pre>\n<p>Just to make sure, this broadcasting will allow both upcasting of distribution parameters as well as upcasting of values:</p>\n<p>e.g.</p>\n<pre><code>        p = Normal(Variable(torch.Tensor([[0.0], [1.0]])),\n                   Variable(torch.Tensor([[1.0], [1.0]])))    # size (2, 1)\n        x = Variable(torch.Tensor([0.0, 1.0]))    # size (2,)\n        pdf = torch.exp(p.log_prob(x))     # size (2, 2)\n</code></pre>", "body_text": "It may be cheaper to do\n    if self._batch_shape and value.size()[:event_dim_start]:\n        try:\n            torch._C._infer_size(value.size()[:event_dim_start], self._batch_shape)\n        except RuntimeError:\n            raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n                             format(actual_shape, expected_shape))\n\nJust to make sure, this broadcasting will allow both upcasting of distribution parameters as well as upcasting of values:\ne.g.\n        p = Normal(Variable(torch.Tensor([[0.0], [1.0]])),\n                   Variable(torch.Tensor([[1.0], [1.0]])))    # size (2, 1)\n        x = Variable(torch.Tensor([0.0, 1.0]))    # size (2,)\n        pdf = torch.exp(p.log_prob(x))     # size (2, 2)"}