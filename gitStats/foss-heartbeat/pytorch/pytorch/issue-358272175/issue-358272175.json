{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11422", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11422/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11422/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11422/events", "html_url": "https://github.com/pytorch/pytorch/issues/11422", "id": 358272175, "node_id": "MDU6SXNzdWUzNTgyNzIxNzU=", "number": 11422, "title": "Error on cuda.LongTensor which is sent via multiprocessing.Queue", "user": {"login": "kintaat", "id": 6628575, "node_id": "MDQ6VXNlcjY2Mjg1NzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6628575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kintaat", "html_url": "https://github.com/kintaat", "followers_url": "https://api.github.com/users/kintaat/followers", "following_url": "https://api.github.com/users/kintaat/following{/other_user}", "gists_url": "https://api.github.com/users/kintaat/gists{/gist_id}", "starred_url": "https://api.github.com/users/kintaat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kintaat/subscriptions", "organizations_url": "https://api.github.com/users/kintaat/orgs", "repos_url": "https://api.github.com/users/kintaat/repos", "events_url": "https://api.github.com/users/kintaat/events{/privacy}", "received_events_url": "https://api.github.com/users/kintaat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-08T07:19:35Z", "updated_at": "2018-11-16T16:04:59Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I was trying to send multiple tensors in tuple via <code>multiprocessing.Queue</code> to anther process. However when I access to a cuda LongTensor, I get this error</p>\n<pre><code>RuntimeError: Attempt to access Storage having data type Float as data type Long\n</code></pre>\n<h2>Code example</h2>\n<pre><code>import torch\nimport torch.multiprocessing as mp\nimport time\n\ndef producer(queue):\n    while True:\n        a = torch.ones(2,2).float().cuda()\n        idx = torch.LongTensor([[0, 0], [0, 1]]).cuda()\n        queue.put((a, idx))\n\ndef consumer(queue):\n    while True:\n        a, idx = queue.get()\n        print(idx.type())\n        print(idx)\n\nif __name__ == '__main__':\n    mp.set_start_method('spawn')\n\n    queue = mp.Queue()\n\n    p = mp.Process(target=producer, args=(queue,))\n    c = mp.Process(target=consumer, args=(queue,))\n    p.start()\n    c.start()\n    \n    time.sleep(10)\n\n    p.join()\n    c.join()\n</code></pre>\n<p>Output:</p>\n<pre><code>torch.cuda.LongTensor\nProcess Process-2:\nTraceback (most recent call last):\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n    self.run()\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"queue_test.py\", line 15, in consumer\n    print(idx)\n  File \"***/lib/python3.5/site-packages/torch/tensor.py\", line 57, in __repr__\n    return torch._tensor_str._str(self)\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 256, in _str\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 76, in __init__\n    copy = torch.empty(tensor.size(), dtype=torch.long).copy_(tensor).view(tensor.nelement())\nRuntimeError: Attempt to access Storage having data type Float as data type Long\n</code></pre>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 14.04.5 LTS<br>\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4<br>\nCMake version: version 3.11.0</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 8.0.61<br>\nGPU models and configuration:<br>\nGPU 0: Tesla P100-PCIE-16GB<br>\nGPU 1: Tesla P100-PCIE-16GB</p>\n<p>Nvidia driver version: 375.66<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.10<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.13.3)<br>\n[pip] torch (0.4.1)<br>\n[pip] torchvision (0.2.1)<br>\n[conda] torch                     0.4.1                     <br>\n[conda] torchvision               0.2.1                     </p>", "body_text": "I was trying to send multiple tensors in tuple via multiprocessing.Queue to anther process. However when I access to a cuda LongTensor, I get this error\nRuntimeError: Attempt to access Storage having data type Float as data type Long\n\nCode example\nimport torch\nimport torch.multiprocessing as mp\nimport time\n\ndef producer(queue):\n    while True:\n        a = torch.ones(2,2).float().cuda()\n        idx = torch.LongTensor([[0, 0], [0, 1]]).cuda()\n        queue.put((a, idx))\n\ndef consumer(queue):\n    while True:\n        a, idx = queue.get()\n        print(idx.type())\n        print(idx)\n\nif __name__ == '__main__':\n    mp.set_start_method('spawn')\n\n    queue = mp.Queue()\n\n    p = mp.Process(target=producer, args=(queue,))\n    c = mp.Process(target=consumer, args=(queue,))\n    p.start()\n    c.start()\n    \n    time.sleep(10)\n\n    p.join()\n    c.join()\n\nOutput:\ntorch.cuda.LongTensor\nProcess Process-2:\nTraceback (most recent call last):\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n    self.run()\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"queue_test.py\", line 15, in consumer\n    print(idx)\n  File \"***/lib/python3.5/site-packages/torch/tensor.py\", line 57, in __repr__\n    return torch._tensor_str._str(self)\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 256, in _str\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 76, in __init__\n    copy = torch.empty(tensor.size(), dtype=torch.long).copy_(tensor).view(tensor.nelement())\nRuntimeError: Attempt to access Storage having data type Float as data type Long\n\nSystem Info\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 14.04.5 LTS\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4\nCMake version: version 3.11.0\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 8.0.61\nGPU models and configuration:\nGPU 0: Tesla P100-PCIE-16GB\nGPU 1: Tesla P100-PCIE-16GB\nNvidia driver version: 375.66\ncuDNN version: Probably one of the following:\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.10\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\nVersions of relevant libraries:\n[pip] numpy (1.13.3)\n[pip] torch (0.4.1)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.4.1                     \n[conda] torchvision               0.2.1", "body": "I was trying to send multiple tensors in tuple via `multiprocessing.Queue` to anther process. However when I access to a cuda LongTensor, I get this error\r\n```\r\nRuntimeError: Attempt to access Storage having data type Float as data type Long\r\n```\r\n## Code example\r\n```\r\nimport torch\r\nimport torch.multiprocessing as mp\r\nimport time\r\n\r\ndef producer(queue):\r\n    while True:\r\n        a = torch.ones(2,2).float().cuda()\r\n        idx = torch.LongTensor([[0, 0], [0, 1]]).cuda()\r\n        queue.put((a, idx))\r\n\r\ndef consumer(queue):\r\n    while True:\r\n        a, idx = queue.get()\r\n        print(idx.type())\r\n        print(idx)\r\n\r\nif __name__ == '__main__':\r\n    mp.set_start_method('spawn')\r\n\r\n    queue = mp.Queue()\r\n\r\n    p = mp.Process(target=producer, args=(queue,))\r\n    c = mp.Process(target=consumer, args=(queue,))\r\n    p.start()\r\n    c.start()\r\n    \r\n    time.sleep(10)\r\n\r\n    p.join()\r\n    c.join()\r\n```\r\nOutput:\r\n```\r\ntorch.cuda.LongTensor\r\nProcess Process-2:\r\nTraceback (most recent call last):\r\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\r\n    self.run()\r\n  File \"***/lib/python3.5/multiprocessing/process.py\", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"queue_test.py\", line 15, in consumer\r\n    print(idx)\r\n  File \"***/lib/python3.5/site-packages/torch/tensor.py\", line 57, in __repr__\r\n    return torch._tensor_str._str(self)\r\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 256, in _str\r\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\r\n  File \"***/lib/python3.5/site-packages/torch/_tensor_str.py\", line 76, in __init__\r\n    copy = torch.empty(tensor.size(), dtype=torch.long).copy_(tensor).view(tensor.nelement())\r\nRuntimeError: Attempt to access Storage having data type Float as data type Long\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 14.04.5 LTS\r\nGCC version: (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4\r\nCMake version: version 3.11.0\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 8.0.61\r\nGPU models and configuration: \r\nGPU 0: Tesla P100-PCIE-16GB\r\nGPU 1: Tesla P100-PCIE-16GB\r\n\r\nNvidia driver version: 375.66\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.10\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6.0.21\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn_static.a\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.13.3)\r\n[pip] torch (0.4.1)\r\n[pip] torchvision (0.2.1)\r\n[conda] torch                     0.4.1                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n"}