{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/440783768", "html_url": "https://github.com/pytorch/pytorch/pull/12476#issuecomment-440783768", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12476", "id": 440783768, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDc4Mzc2OA==", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-21T19:30:04Z", "updated_at": "2018-11-21T19:30:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This PR depends on the algorithm caching so it's incompatible with nuking it :-)</p>\n<p>The reason for nuking the algorithm caching is that is has degenerate cases where memory usage will explode, as well as the additional tensor copy for every operation. It was a good first step to get things going but with the recent changes to Gloo around the unbound buffers and algorithms that use them, the algorithm caching is no longer needed and we can get rid of the runtime memory risk. Then after we figure out what's up with IB support we can put back the device selection code, and we'll get support for all algorithms automatically.</p>", "body_text": "This PR depends on the algorithm caching so it's incompatible with nuking it :-)\nThe reason for nuking the algorithm caching is that is has degenerate cases where memory usage will explode, as well as the additional tensor copy for every operation. It was a good first step to get things going but with the recent changes to Gloo around the unbound buffers and algorithms that use them, the algorithm caching is no longer needed and we can get rid of the runtime memory risk. Then after we figure out what's up with IB support we can put back the device selection code, and we'll get support for all algorithms automatically.", "body": "This PR depends on the algorithm caching so it's incompatible with nuking it :-)\r\n\r\nThe reason for nuking the algorithm caching is that is has degenerate cases where memory usage will explode, as well as the additional tensor copy for every operation. It was a good first step to get things going but with the recent changes to Gloo around the unbound buffers and algorithms that use them, the algorithm caching is no longer needed and we can get rid of the runtime memory risk. Then after we figure out what's up with IB support we can put back the device selection code, and we'll get support for all algorithms automatically."}