{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12622", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12622/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12622/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12622/events", "html_url": "https://github.com/pytorch/pytorch/issues/12622", "id": 369737389, "node_id": "MDU6SXNzdWUzNjk3MzczODk=", "number": 12622, "title": "Using nn.Parameter as args to torch.distributions.Normal", "user": {"login": "tuananhle7", "id": 15041137, "node_id": "MDQ6VXNlcjE1MDQxMTM3", "avatar_url": "https://avatars1.githubusercontent.com/u/15041137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tuananhle7", "html_url": "https://github.com/tuananhle7", "followers_url": "https://api.github.com/users/tuananhle7/followers", "following_url": "https://api.github.com/users/tuananhle7/following{/other_user}", "gists_url": "https://api.github.com/users/tuananhle7/gists{/gist_id}", "starred_url": "https://api.github.com/users/tuananhle7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tuananhle7/subscriptions", "organizations_url": "https://api.github.com/users/tuananhle7/orgs", "repos_url": "https://api.github.com/users/tuananhle7/repos", "events_url": "https://api.github.com/users/tuananhle7/events{/privacy}", "received_events_url": "https://api.github.com/users/tuananhle7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-12T23:04:50Z", "updated_at": "2018-10-12T23:22:30Z", "closed_at": "2018-10-12T23:22:30Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>It seems like it's not possible to pass <code>nn.Parameter</code> as arguments to <code>torch.distributions.Normal</code>.</p>\n<h2>To Reproduce</h2>\n<p>The following code</p>\n<pre><code>import torch\nimport torch.nn as nn\n\nclass VariationalPosterior(nn.Module):\n    def __init__(self):\n        super(VariationalPosterior, self).__init__()\n        self.loc = nn.Parameter(torch.zeros(()))\n        self.logscale = nn.Parameter(torch.zeros(()))\n    \n    def get_dist(self):\n        return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\n\nvariational_posterior = VariationalPosterior()\nprint(torch.__version__)\nprint(variational_posterior.get_dist())\n</code></pre>\n<p>prints</p>\n<pre><code>0.4.1\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-15-6d1be9715576&gt; in &lt;module&gt;()\n     13 variational_posterior = VariationalPosterior()\n     14 print(torch.__version__)\n---&gt; 15 print(variational_posterior.get_dist())\n\n&lt;ipython-input-15-6d1be9715576&gt; in get_dist(self)\n      9 \n     10     def get_dist(self):\n---&gt; 11         return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\n     12 \n     13 variational_posterior = VariationalPosterior()\n\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/normal.py in __init__(self, loc, scale, validate_args)\n     42 \n     43     def __init__(self, loc, scale, validate_args=None):\n---&gt; 44         self.loc, self.scale = broadcast_all(loc, scale)\n     45         if isinstance(loc, Number) and isinstance(scale, Number):\n     46             batch_shape = torch.Size()\n\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/utils.py in broadcast_all(*values)\n     69     tensor_idxs = [i for i in range(len(values)) if values[i].__class__.__name__ == 'Tensor']\n     70     if len(scalar_idxs) + len(tensor_idxs) != len(values):\n---&gt; 71         raise ValueError('Input arguments must all be instances of numbers.Number or torch.tensor.')\n     72     if tensor_idxs:\n     73         broadcast_shape = _broadcast_shape([values[i].size() for i in tensor_idxs])\n\nValueError: Input arguments must all be instances of numbers.Number or torch.tensor.\n</code></pre>\n<h2>Expected behavior</h2>\n<p>Expected to produce an <code>torch.distributions.Normal</code> object.</p>\n<h2>Environment</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: None</p>\n<p>OS: Mac OSX 10.11.6<br>\nGCC version: Could not collect<br>\nCMake version: version 3.7.1</p>\n<p>Python version: 3.5<br>\nIs CUDA available: No<br>\nCUDA runtime version: No CUDA<br>\nGPU models and configuration: No CUDA<br>\nNvidia driver version: No CUDA<br>\ncuDNN version: No CUDA</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.14.2)<br>\n[pip3] torch (0.4.1)<br>\n[pip3] torchvision (0.2.1)<br>\n[conda] pytorch                   0.4.1           py35_cuda0.0_cudnn0.0_1    pytorch<br>\n[conda] torch                     0.4.0a0+65a8ac0           <br>\n[conda] torchvision               0.2.1                    py35_1    pytorch</p>", "body_text": "\ud83d\udc1b Bug\nIt seems like it's not possible to pass nn.Parameter as arguments to torch.distributions.Normal.\nTo Reproduce\nThe following code\nimport torch\nimport torch.nn as nn\n\nclass VariationalPosterior(nn.Module):\n    def __init__(self):\n        super(VariationalPosterior, self).__init__()\n        self.loc = nn.Parameter(torch.zeros(()))\n        self.logscale = nn.Parameter(torch.zeros(()))\n    \n    def get_dist(self):\n        return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\n\nvariational_posterior = VariationalPosterior()\nprint(torch.__version__)\nprint(variational_posterior.get_dist())\n\nprints\n0.4.1\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-15-6d1be9715576> in <module>()\n     13 variational_posterior = VariationalPosterior()\n     14 print(torch.__version__)\n---> 15 print(variational_posterior.get_dist())\n\n<ipython-input-15-6d1be9715576> in get_dist(self)\n      9 \n     10     def get_dist(self):\n---> 11         return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\n     12 \n     13 variational_posterior = VariationalPosterior()\n\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/normal.py in __init__(self, loc, scale, validate_args)\n     42 \n     43     def __init__(self, loc, scale, validate_args=None):\n---> 44         self.loc, self.scale = broadcast_all(loc, scale)\n     45         if isinstance(loc, Number) and isinstance(scale, Number):\n     46             batch_shape = torch.Size()\n\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/utils.py in broadcast_all(*values)\n     69     tensor_idxs = [i for i in range(len(values)) if values[i].__class__.__name__ == 'Tensor']\n     70     if len(scalar_idxs) + len(tensor_idxs) != len(values):\n---> 71         raise ValueError('Input arguments must all be instances of numbers.Number or torch.tensor.')\n     72     if tensor_idxs:\n     73         broadcast_shape = _broadcast_shape([values[i].size() for i in tensor_idxs])\n\nValueError: Input arguments must all be instances of numbers.Number or torch.tensor.\n\nExpected behavior\nExpected to produce an torch.distributions.Normal object.\nEnvironment\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: None\nOS: Mac OSX 10.11.6\nGCC version: Could not collect\nCMake version: version 3.7.1\nPython version: 3.5\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nVersions of relevant libraries:\n[pip3] numpy (1.14.2)\n[pip3] torch (0.4.1)\n[pip3] torchvision (0.2.1)\n[conda] pytorch                   0.4.1           py35_cuda0.0_cudnn0.0_1    pytorch\n[conda] torch                     0.4.0a0+65a8ac0           \n[conda] torchvision               0.2.1                    py35_1    pytorch", "body": "## \ud83d\udc1b Bug\r\n\r\nIt seems like it's not possible to pass `nn.Parameter` as arguments to `torch.distributions.Normal`.\r\n\r\n## To Reproduce\r\n\r\nThe following code\r\n\r\n```\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass VariationalPosterior(nn.Module):\r\n    def __init__(self):\r\n        super(VariationalPosterior, self).__init__()\r\n        self.loc = nn.Parameter(torch.zeros(()))\r\n        self.logscale = nn.Parameter(torch.zeros(()))\r\n    \r\n    def get_dist(self):\r\n        return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\r\n\r\nvariational_posterior = VariationalPosterior()\r\nprint(torch.__version__)\r\nprint(variational_posterior.get_dist())\r\n```\r\n\r\nprints\r\n\r\n```\r\n0.4.1\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-15-6d1be9715576> in <module>()\r\n     13 variational_posterior = VariationalPosterior()\r\n     14 print(torch.__version__)\r\n---> 15 print(variational_posterior.get_dist())\r\n\r\n<ipython-input-15-6d1be9715576> in get_dist(self)\r\n      9 \r\n     10     def get_dist(self):\r\n---> 11         return torch.distributions.Normal(loc=self.loc, scale=torch.exp(self.logscale))\r\n     12 \r\n     13 variational_posterior = VariationalPosterior()\r\n\r\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/normal.py in __init__(self, loc, scale, validate_args)\r\n     42 \r\n     43     def __init__(self, loc, scale, validate_args=None):\r\n---> 44         self.loc, self.scale = broadcast_all(loc, scale)\r\n     45         if isinstance(loc, Number) and isinstance(scale, Number):\r\n     46             batch_shape = torch.Size()\r\n\r\n/Users/tuananhle/anaconda/lib/python3.5/site-packages/torch/distributions/utils.py in broadcast_all(*values)\r\n     69     tensor_idxs = [i for i in range(len(values)) if values[i].__class__.__name__ == 'Tensor']\r\n     70     if len(scalar_idxs) + len(tensor_idxs) != len(values):\r\n---> 71         raise ValueError('Input arguments must all be instances of numbers.Number or torch.tensor.')\r\n     72     if tensor_idxs:\r\n     73         broadcast_shape = _broadcast_shape([values[i].size() for i in tensor_idxs])\r\n\r\nValueError: Input arguments must all be instances of numbers.Number or torch.tensor.\r\n```\r\n\r\n## Expected behavior\r\n\r\nExpected to produce an `torch.distributions.Normal` object.\r\n\r\n## Environment\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.11.6\r\nGCC version: Could not collect\r\nCMake version: version 3.7.1\r\n\r\nPython version: 3.5\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.2)\r\n[pip3] torch (0.4.1)\r\n[pip3] torchvision (0.2.1)\r\n[conda] pytorch                   0.4.1           py35_cuda0.0_cudnn0.0_1    pytorch\r\n[conda] torch                     0.4.0a0+65a8ac0           <pip>\r\n[conda] torchvision               0.2.1                    py35_1    pytorch"}