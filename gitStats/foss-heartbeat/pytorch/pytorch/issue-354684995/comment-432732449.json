{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/432732449", "html_url": "https://github.com/pytorch/pytorch/issues/10942#issuecomment-432732449", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10942", "id": 432732449, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMjczMjQ0OQ==", "user": {"login": "stephldp", "id": 13196226, "node_id": "MDQ6VXNlcjEzMTk2MjI2", "avatar_url": "https://avatars2.githubusercontent.com/u/13196226?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stephldp", "html_url": "https://github.com/stephldp", "followers_url": "https://api.github.com/users/stephldp/followers", "following_url": "https://api.github.com/users/stephldp/following{/other_user}", "gists_url": "https://api.github.com/users/stephldp/gists{/gist_id}", "starred_url": "https://api.github.com/users/stephldp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stephldp/subscriptions", "organizations_url": "https://api.github.com/users/stephldp/orgs", "repos_url": "https://api.github.com/users/stephldp/repos", "events_url": "https://api.github.com/users/stephldp/events{/privacy}", "received_events_url": "https://api.github.com/users/stephldp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-24T16:35:52Z", "updated_at": "2018-10-24T16:35:52Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>Same issue when trying to export model to ONNX (I want to convert the model to CoreML).</p>\n<p>Here is the model definition: (it comes from <a href=\"https://github.com/qiuqiangkong/dcase2018_task2\">https://github.com/qiuqiangkong/dcase2018_task2</a>)</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">VggishConvBlock</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">in_channels</span>, <span class=\"pl-smi\">out_channels</span>):\n        \n        <span class=\"pl-c1\">super</span>(VggishConvBlock, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        \n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span>in_channels, \n                              <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span>out_channels,\n                              <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>),\n                              <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n                              \n        <span class=\"pl-c1\">self</span>.conv2 <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span>out_channels, \n                              <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span>out_channels,\n                              <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>),\n                              <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>), <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n                              \n        <span class=\"pl-c1\">self</span>.bn1 <span class=\"pl-k\">=</span> nn.BatchNorm2d(out_channels)\n        \n        <span class=\"pl-c1\">self</span>.bn2 <span class=\"pl-k\">=</span> nn.BatchNorm2d(out_channels)\n        \n        <span class=\"pl-c1\">self</span>.init_weights()\n        \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">init_weights</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        \n        init_layer(<span class=\"pl-c1\">self</span>.conv1)\n        init_layer(<span class=\"pl-c1\">self</span>.conv2)\n        init_bn(<span class=\"pl-c1\">self</span>.bn1)\n        init_bn(<span class=\"pl-c1\">self</span>.bn2)\n        \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>):\n        \n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.bn1(<span class=\"pl-c1\">self</span>.conv1(x)))\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.bn2(<span class=\"pl-c1\">self</span>.conv2(x)))\n        x <span class=\"pl-k\">=</span> F.max_pool2d(x, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>), <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>))\n        \n        <span class=\"pl-k\">return</span> x\n    \n    \n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Vggish</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">classes_num</span>):\n        \n        <span class=\"pl-c1\">super</span>(Vggish, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n\n        <span class=\"pl-c1\">self</span>.conv_block1 <span class=\"pl-k\">=</span> VggishConvBlock(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>)\n        <span class=\"pl-c1\">self</span>.conv_block2 <span class=\"pl-k\">=</span> VggishConvBlock(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>, <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>)\n        <span class=\"pl-c1\">self</span>.conv_block3 <span class=\"pl-k\">=</span> VggishConvBlock(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">128</span>, <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>)\n        <span class=\"pl-c1\">self</span>.conv_block4 <span class=\"pl-k\">=</span> VggishConvBlock(<span class=\"pl-v\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>, <span class=\"pl-v\">out_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">512</span>)\n\n        <span class=\"pl-c1\">self</span>.fc_final <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">512</span>, classes_num, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n        <span class=\"pl-c1\">self</span>.init_weights()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">init_weights</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n\n        init_layer(<span class=\"pl-c1\">self</span>.fc_final)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">return_bottleneck</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n        (_, seq_len, mel_bins) <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.shape\n\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.view(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, seq_len, mel_bins)\n        <span class=\"pl-s\"><span class=\"pl-pds\">'''</span>(samples_num, feature_maps, time_steps, freq_num)<span class=\"pl-pds\">'''</span></span>\n\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv_block1(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv_block2(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv_block3(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv_block4(x)\n\n        x <span class=\"pl-k\">=</span> F.max_pool2d(x, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span>x.shape[<span class=\"pl-c1\">2</span>:])\n        x <span class=\"pl-k\">=</span> x.view(x.shape[<span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">2</span>])\n\n        x <span class=\"pl-k\">=</span> F.log_softmax(<span class=\"pl-c1\">self</span>.fc_final(x), <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-k\">return</span> x\n\nmodel <span class=\"pl-k\">=</span> Vggish(<span class=\"pl-c1\">41</span>)\ndummy_input <span class=\"pl-k\">=</span> Variable(torch.FloatTensor(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">62</span>))\ntorch.onnx.export(model, dummy_input, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>model.proto<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">verbose</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)</pre></div>\n<p>I get the following error:</p>\n<pre><code>Traceback (most recent call last):\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1599, in &lt;module&gt;\n      globals = debugger.run(setup['file'], None, None, is_module)\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1026, in run\n      pydev_imports.execfile(file, globals, locals)  # execute the script\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\n      exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n    File \"convert_onnx.py\", line 39, in &lt;module&gt;\n      torch.onnx.export(model, input, 'model.proto', verbose=True)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\n      return utils.export(*args, **kwargs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\n      operator_export_type=operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\n      example_outputs, propagate)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 226, in _model_to_graph\n      graph = _optimize_graph(graph, operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 154, in _optimize_graph\n      graph = torch._C._jit_pass_onnx(graph, operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 52, in _run_symbolic_function\n      return utils._run_symbolic_function(*args, **kwargs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 503, in _run_symbolic_function\n      return fn(g, *inputs, **attrs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in wrapper\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in &lt;listcomp&gt;\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44, in _parse_arg\n      raise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")\n    RuntimeError: ONNX symbolic expected a constant value in the trace\n</code></pre>\n<p>When I check the function _parse_arg (File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44), I get the following argument passed as value:</p>\n<pre><code>    value = {Value} 237 defined in (%237 : int[] = onnx::Concat[axis=0](%235, %236), scope: Vggish)\n</code></pre>\n<p>Thanks for help!</p>", "body_text": "Hello,\nSame issue when trying to export model to ONNX (I want to convert the model to CoreML).\nHere is the model definition: (it comes from https://github.com/qiuqiangkong/dcase2018_task2)\nclass VggishConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        \n        super(VggishConvBlock, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=in_channels, \n                              out_channels=out_channels,\n                              kernel_size=(3, 3), stride=(1, 1),\n                              padding=(1, 1), bias=False)\n                              \n        self.conv2 = nn.Conv2d(in_channels=out_channels, \n                              out_channels=out_channels,\n                              kernel_size=(3, 3), stride=(1, 1),\n                              padding=(1, 1), bias=False)\n                              \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        \n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.init_weights()\n        \n    def init_weights(self):\n        \n        init_layer(self.conv1)\n        init_layer(self.conv2)\n        init_bn(self.bn1)\n        init_bn(self.bn2)\n        \n    def forward(self, input):\n        \n        x = input\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2))\n        \n        return x\n    \n    \nclass Vggish(nn.Module):\n    def __init__(self, classes_num):\n        \n        super(Vggish, self).__init__()\n\n        self.conv_block1 = VggishConvBlock(in_channels=1, out_channels=64)\n        self.conv_block2 = VggishConvBlock(in_channels=64, out_channels=128)\n        self.conv_block3 = VggishConvBlock(in_channels=128, out_channels=256)\n        self.conv_block4 = VggishConvBlock(in_channels=256, out_channels=512)\n\n        self.fc_final = nn.Linear(512, classes_num, bias=True)\n\n        self.init_weights()\n\n    def init_weights(self):\n\n        init_layer(self.fc_final)\n\n    def forward(self, input, return_bottleneck=False):\n        (_, seq_len, mel_bins) = input.shape\n\n        x = input.view(-1, 1, seq_len, mel_bins)\n        '''(samples_num, feature_maps, time_steps, freq_num)'''\n\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n\n        x = F.max_pool2d(x, kernel_size=x.shape[2:])\n        x = x.view(x.shape[0:2])\n\n        x = F.log_softmax(self.fc_final(x), dim=-1)\n\nreturn x\n\nmodel = Vggish(41)\ndummy_input = Variable(torch.FloatTensor(1, 64, 62))\ntorch.onnx.export(model, dummy_input, 'model.proto', verbose=True)\nI get the following error:\nTraceback (most recent call last):\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1599, in <module>\n      globals = debugger.run(setup['file'], None, None, is_module)\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1026, in run\n      pydev_imports.execfile(file, globals, locals)  # execute the script\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\n      exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n    File \"convert_onnx.py\", line 39, in <module>\n      torch.onnx.export(model, input, 'model.proto', verbose=True)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\n      return utils.export(*args, **kwargs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\n      operator_export_type=operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\n      example_outputs, propagate)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 226, in _model_to_graph\n      graph = _optimize_graph(graph, operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 154, in _optimize_graph\n      graph = torch._C._jit_pass_onnx(graph, operator_export_type)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 52, in _run_symbolic_function\n      return utils._run_symbolic_function(*args, **kwargs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 503, in _run_symbolic_function\n      return fn(g, *inputs, **attrs)\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in wrapper\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in <listcomp>\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44, in _parse_arg\n      raise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")\n    RuntimeError: ONNX symbolic expected a constant value in the trace\n\nWhen I check the function _parse_arg (File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44), I get the following argument passed as value:\n    value = {Value} 237 defined in (%237 : int[] = onnx::Concat[axis=0](%235, %236), scope: Vggish)\n\nThanks for help!", "body": "Hello,\r\n\r\nSame issue when trying to export model to ONNX (I want to convert the model to CoreML).\r\n\r\nHere is the model definition: (it comes from https://github.com/qiuqiangkong/dcase2018_task2)\r\n\r\n```python\r\nclass VggishConvBlock(nn.Module):\r\n    def __init__(self, in_channels, out_channels):\r\n        \r\n        super(VggishConvBlock, self).__init__()\r\n        \r\n        self.conv1 = nn.Conv2d(in_channels=in_channels, \r\n                              out_channels=out_channels,\r\n                              kernel_size=(3, 3), stride=(1, 1),\r\n                              padding=(1, 1), bias=False)\r\n                              \r\n        self.conv2 = nn.Conv2d(in_channels=out_channels, \r\n                              out_channels=out_channels,\r\n                              kernel_size=(3, 3), stride=(1, 1),\r\n                              padding=(1, 1), bias=False)\r\n                              \r\n        self.bn1 = nn.BatchNorm2d(out_channels)\r\n        \r\n        self.bn2 = nn.BatchNorm2d(out_channels)\r\n        \r\n        self.init_weights()\r\n        \r\n    def init_weights(self):\r\n        \r\n        init_layer(self.conv1)\r\n        init_layer(self.conv2)\r\n        init_bn(self.bn1)\r\n        init_bn(self.bn2)\r\n        \r\n    def forward(self, input):\r\n        \r\n        x = input\r\n        x = F.relu(self.bn1(self.conv1(x)))\r\n        x = F.relu(self.bn2(self.conv2(x)))\r\n        x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2))\r\n        \r\n        return x\r\n    \r\n    \r\nclass Vggish(nn.Module):\r\n    def __init__(self, classes_num):\r\n        \r\n        super(Vggish, self).__init__()\r\n\r\n        self.conv_block1 = VggishConvBlock(in_channels=1, out_channels=64)\r\n        self.conv_block2 = VggishConvBlock(in_channels=64, out_channels=128)\r\n        self.conv_block3 = VggishConvBlock(in_channels=128, out_channels=256)\r\n        self.conv_block4 = VggishConvBlock(in_channels=256, out_channels=512)\r\n\r\n        self.fc_final = nn.Linear(512, classes_num, bias=True)\r\n\r\n        self.init_weights()\r\n\r\n    def init_weights(self):\r\n\r\n        init_layer(self.fc_final)\r\n\r\n    def forward(self, input, return_bottleneck=False):\r\n        (_, seq_len, mel_bins) = input.shape\r\n\r\n        x = input.view(-1, 1, seq_len, mel_bins)\r\n        '''(samples_num, feature_maps, time_steps, freq_num)'''\r\n\r\n        x = self.conv_block1(x)\r\n        x = self.conv_block2(x)\r\n        x = self.conv_block3(x)\r\n        x = self.conv_block4(x)\r\n\r\n        x = F.max_pool2d(x, kernel_size=x.shape[2:])\r\n        x = x.view(x.shape[0:2])\r\n\r\n        x = F.log_softmax(self.fc_final(x), dim=-1)\r\n\r\nreturn x\r\n\r\nmodel = Vggish(41)\r\ndummy_input = Variable(torch.FloatTensor(1, 64, 62))\r\ntorch.onnx.export(model, dummy_input, 'model.proto', verbose=True)\r\n```\r\n\r\nI get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1599, in <module>\r\n      globals = debugger.run(setup['file'], None, None, is_module)\r\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 1026, in run\r\n      pydev_imports.execfile(file, globals, locals)  # execute the script\r\n    File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n      exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n    File \"convert_onnx.py\", line 39, in <module>\r\n      torch.onnx.export(model, input, 'model.proto', verbose=True)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 27, in export\r\n      return utils.export(*args, **kwargs)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 104, in export\r\n      operator_export_type=operator_export_type)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 280, in _export\r\n      example_outputs, propagate)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 226, in _model_to_graph\r\n      graph = _optimize_graph(graph, operator_export_type)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 154, in _optimize_graph\r\n      graph = torch._C._jit_pass_onnx(graph, operator_export_type)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/__init__.py\", line 52, in _run_symbolic_function\r\n      return utils._run_symbolic_function(*args, **kwargs)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/utils.py\", line 503, in _run_symbolic_function\r\n      return fn(g, *inputs, **attrs)\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in wrapper\r\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 87, in <listcomp>\r\n      args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]\r\n    File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44, in _parse_arg\r\n      raise RuntimeError(\"ONNX symbolic expected a constant value in the trace\")\r\n    RuntimeError: ONNX symbolic expected a constant value in the trace\r\n```\r\n\r\nWhen I check the function _parse_arg (File \"/Users/xyz/miniconda2/envs/machinelearning-pytorch/lib/python3.6/site-packages/torch/onnx/symbolic.py\", line 44), I get the following argument passed as value:\r\n```\r\n    value = {Value} 237 defined in (%237 : int[] = onnx::Concat[axis=0](%235, %236), scope: Vggish)\r\n```\r\nThanks for help!"}