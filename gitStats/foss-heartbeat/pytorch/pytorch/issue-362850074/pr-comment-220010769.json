{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/220010769", "pull_request_review_id": 158321946, "id": 220010769, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyMDAxMDc2OQ==", "diff_hunk": "@@ -110,6 +111,23 @@ struct CAFFE2_API TensorImpl : public c10::intrusive_ptr_target {\n \n   explicit TensorImpl(at::Storage storage) : storage_(std::move(storage)), storage_offset_(0) {\n     data_type_ = storage_ ? storage_.dtype() : caffe2::TypeMeta{};\n+    if (storage_) {", "path": "aten/src/ATen/core/TensorImpl.h", "position": 21, "original_position": 21, "commit_id": "50060b359aa134d5c8908ff45f8079a7c7e66548", "original_commit_id": "50060b359aa134d5c8908ff45f8079a7c7e66548", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "this looks fine to merge but IMO would should do things like:\r\n1) take storage_offset for constructors taking Storage\r\n2) Have a TensorTypeId for every device type we care about.\r\n3) Take is_variable(?), TensorTypeId (?) for this as well.\r\n\r\nThe logic being this is an internal type, so the callers have to know what they want anyway, so put the complexity where it belongs (the weird constructors), not on the internal type.", "created_at": "2018-09-24T22:37:55Z", "updated_at": "2018-11-23T15:51:50Z", "html_url": "https://github.com/pytorch/pytorch/pull/11973#discussion_r220010769", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11973", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/220010769"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11973#discussion_r220010769"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11973"}}, "body_html": "<p>this looks fine to merge but IMO would should do things like:</p>\n<ol>\n<li>take storage_offset for constructors taking Storage</li>\n<li>Have a TensorTypeId for every device type we care about.</li>\n<li>Take is_variable(?), TensorTypeId (?) for this as well.</li>\n</ol>\n<p>The logic being this is an internal type, so the callers have to know what they want anyway, so put the complexity where it belongs (the weird constructors), not on the internal type.</p>", "body_text": "this looks fine to merge but IMO would should do things like:\n\ntake storage_offset for constructors taking Storage\nHave a TensorTypeId for every device type we care about.\nTake is_variable(?), TensorTypeId (?) for this as well.\n\nThe logic being this is an internal type, so the callers have to know what they want anyway, so put the complexity where it belongs (the weird constructors), not on the internal type."}