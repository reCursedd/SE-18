{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/332696537", "html_url": "https://github.com/pytorch/pytorch/issues/2518#issuecomment-332696537", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2518", "id": 332696537, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMjY5NjUzNw==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-28T00:56:03Z", "updated_at": "2017-09-28T00:56:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9198933\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/negrinho\">@negrinho</a> we've been working on porting a number of autograd ops to C++.  See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"259211982\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2805\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2805/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2805\">#2805</a> for the initial work; I should have a PR up tomorrow that implements <code>torch.cat</code> in C++ as well.  Note that these implementations are currently (over)shadowed by the python definitions in variable.py; we want to do some more testing/development before we enable them by default.</p>\n<p>With <code>addmm</code>, <code>add</code>, <code>transpose</code>, and <code>cat</code> implemented as C++ ops, we are seeing the mini sequence labeler PyTorch script with OMP_NUM_THREADS=1 running in ~5.5 seconds (down from ~8.7 seconds, see <a href=\"https://github.com/gchanan/pytorch/wiki/Mini-Sequence-Labeler-PyTorch-vs-Dynet\">https://github.com/gchanan/pytorch/wiki/Mini-Sequence-Labeler-PyTorch-vs-Dynet</a> for more details).  We are seeing speedups from moving each op to C++  approximately equal to the measured total backwards time for that op in python (these are listed on the wiki above); this is because we speed up the forwards as well so we are limited to just improving the backwards time.  So, adding up the time for the ops we still need to do should bring us to ~2.5-3.5 seconds total runtime.  This time is in line with the initial estimate of ~2.8 seconds we made before we started this process.</p>\n<p>After we complete that, we have some ideas for what to optimize next, but need to do some more experiments/scoping before we know for sure what to target.  I'll keep this issue updated as we progress.</p>", "body_text": "@negrinho we've been working on porting a number of autograd ops to C++.  See #2805 for the initial work; I should have a PR up tomorrow that implements torch.cat in C++ as well.  Note that these implementations are currently (over)shadowed by the python definitions in variable.py; we want to do some more testing/development before we enable them by default.\nWith addmm, add, transpose, and cat implemented as C++ ops, we are seeing the mini sequence labeler PyTorch script with OMP_NUM_THREADS=1 running in ~5.5 seconds (down from ~8.7 seconds, see https://github.com/gchanan/pytorch/wiki/Mini-Sequence-Labeler-PyTorch-vs-Dynet for more details).  We are seeing speedups from moving each op to C++  approximately equal to the measured total backwards time for that op in python (these are listed on the wiki above); this is because we speed up the forwards as well so we are limited to just improving the backwards time.  So, adding up the time for the ops we still need to do should bring us to ~2.5-3.5 seconds total runtime.  This time is in line with the initial estimate of ~2.8 seconds we made before we started this process.\nAfter we complete that, we have some ideas for what to optimize next, but need to do some more experiments/scoping before we know for sure what to target.  I'll keep this issue updated as we progress.", "body": "@negrinho we've been working on porting a number of autograd ops to C++.  See https://github.com/pytorch/pytorch/pull/2805 for the initial work; I should have a PR up tomorrow that implements `torch.cat` in C++ as well.  Note that these implementations are currently (over)shadowed by the python definitions in variable.py; we want to do some more testing/development before we enable them by default.\r\n\r\nWith `addmm`, `add`, `transpose`, and `cat` implemented as C++ ops, we are seeing the mini sequence labeler PyTorch script with OMP_NUM_THREADS=1 running in ~5.5 seconds (down from ~8.7 seconds, see https://github.com/gchanan/pytorch/wiki/Mini-Sequence-Labeler-PyTorch-vs-Dynet for more details).  We are seeing speedups from moving each op to C++  approximately equal to the measured total backwards time for that op in python (these are listed on the wiki above); this is because we speed up the forwards as well so we are limited to just improving the backwards time.  So, adding up the time for the ops we still need to do should bring us to ~2.5-3.5 seconds total runtime.  This time is in line with the initial estimate of ~2.8 seconds we made before we started this process.\r\n\r\nAfter we complete that, we have some ideas for what to optimize next, but need to do some more experiments/scoping before we know for sure what to target.  I'll keep this issue updated as we progress."}