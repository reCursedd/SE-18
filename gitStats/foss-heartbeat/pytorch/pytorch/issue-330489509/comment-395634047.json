{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/395634047", "html_url": "https://github.com/pytorch/pytorch/issues/8267#issuecomment-395634047", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8267", "id": 395634047, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTYzNDA0Nw==", "user": {"login": "mcarilli", "id": 7799218, "node_id": "MDQ6VXNlcjc3OTkyMTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7799218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarilli", "html_url": "https://github.com/mcarilli", "followers_url": "https://api.github.com/users/mcarilli/followers", "following_url": "https://api.github.com/users/mcarilli/following{/other_user}", "gists_url": "https://api.github.com/users/mcarilli/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarilli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarilli/subscriptions", "organizations_url": "https://api.github.com/users/mcarilli/orgs", "repos_url": "https://api.github.com/users/mcarilli/repos", "events_url": "https://api.github.com/users/mcarilli/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarilli/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-08T03:19:22Z", "updated_at": "2018-06-08T03:19:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a> In this case I was using THCTensorMathReduce functors to be as \"pytorchic\" as possible.  If you don't advise that, I can easily roll my own.  That being said, you can't really write custom Cuda extensions without dealing with raw data pointers, for which THC utilities/type conversions come in handy, so the strategy wrt to THC is definitely something we're interested to hear.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> The kernel I'm writing for embedding backward will be a drop-in replacement for embedding_backward_feature_kernel in Embedding.cu, with no changes required by the C++ wrapper signatures, so the build system should be perfectly happy with it.  I feel comfortable enough with the ATen API and dispatch to adjust wrapper-side C++ without bothering your guys in the immediate term, unless there's something important you feel I should know.  Of course I appreciate the offer of help and I'll ask if I hit any roadblocks.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a> The deprecated shuffles will be removed as part of this change, and I expect a similar solution will work to remove the deprecated shuffles in THCUNN/LookupTable.cu, which I'll tackle next.</p>", "body_text": "@goldsborough In this case I was using THCTensorMathReduce functors to be as \"pytorchic\" as possible.  If you don't advise that, I can easily roll my own.  That being said, you can't really write custom Cuda extensions without dealing with raw data pointers, for which THC utilities/type conversions come in handy, so the strategy wrt to THC is definitely something we're interested to hear.\n@soumith The kernel I'm writing for embedding backward will be a drop-in replacement for embedding_backward_feature_kernel in Embedding.cu, with no changes required by the C++ wrapper signatures, so the build system should be perfectly happy with it.  I feel comfortable enough with the ATen API and dispatch to adjust wrapper-side C++ without bothering your guys in the immediate term, unless there's something important you feel I should know.  Of course I appreciate the offer of help and I'll ask if I hit any roadblocks.\n@goldsborough The deprecated shuffles will be removed as part of this change, and I expect a similar solution will work to remove the deprecated shuffles in THCUNN/LookupTable.cu, which I'll tackle next.", "body": "@goldsborough In this case I was using THCTensorMathReduce functors to be as \"pytorchic\" as possible.  If you don't advise that, I can easily roll my own.  That being said, you can't really write custom Cuda extensions without dealing with raw data pointers, for which THC utilities/type conversions come in handy, so the strategy wrt to THC is definitely something we're interested to hear.\r\n\r\n@soumith The kernel I'm writing for embedding backward will be a drop-in replacement for embedding_backward_feature_kernel in Embedding.cu, with no changes required by the C++ wrapper signatures, so the build system should be perfectly happy with it.  I feel comfortable enough with the ATen API and dispatch to adjust wrapper-side C++ without bothering your guys in the immediate term, unless there's something important you feel I should know.  Of course I appreciate the offer of help and I'll ask if I hit any roadblocks.\r\n\r\n@goldsborough The deprecated shuffles will be removed as part of this change, and I expect a similar solution will work to remove the deprecated shuffles in THCUNN/LookupTable.cu, which I'll tackle next."}