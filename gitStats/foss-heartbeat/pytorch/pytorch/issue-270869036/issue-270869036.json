{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3462", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3462/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3462/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3462/events", "html_url": "https://github.com/pytorch/pytorch/issues/3462", "id": 270869036, "node_id": "MDU6SXNzdWUyNzA4NjkwMzY=", "number": 3462, "title": "sort() and  topk() behave weirdly when given large numbers", "user": {"login": "jasonleeinf", "id": 5902998, "node_id": "MDQ6VXNlcjU5MDI5OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/5902998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonleeinf", "html_url": "https://github.com/jasonleeinf", "followers_url": "https://api.github.com/users/jasonleeinf/followers", "following_url": "https://api.github.com/users/jasonleeinf/following{/other_user}", "gists_url": "https://api.github.com/users/jasonleeinf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonleeinf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonleeinf/subscriptions", "organizations_url": "https://api.github.com/users/jasonleeinf/orgs", "repos_url": "https://api.github.com/users/jasonleeinf/repos", "events_url": "https://api.github.com/users/jasonleeinf/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonleeinf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-03T03:17:27Z", "updated_at": "2017-11-03T04:13:47Z", "closed_at": "2017-11-03T04:12:23Z", "author_association": "NONE", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\ndim <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>## pytorch</span>\na1 <span class=\"pl-k\">=</span> torch.randn(batch_size, dim)\nv1, r1 <span class=\"pl-k\">=</span> a1.sort(<span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\ninc <span class=\"pl-k\">=</span> torch.ones(batch_size)[:,<span class=\"pl-c1\">None</span>]<span class=\"pl-k\">*</span><span class=\"pl-c1\">99999999</span>\na2 <span class=\"pl-k\">=</span> inc <span class=\"pl-k\">+</span> a1\nv2, r2 <span class=\"pl-k\">=</span> a2.sort(<span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>## numpy</span>\na3 <span class=\"pl-k\">=</span> a1.numpy()\nr3 <span class=\"pl-k\">=</span> np.argsort(a3, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\ninc2 <span class=\"pl-k\">=</span> np.ones(batch_size)[:,<span class=\"pl-c1\">None</span>]<span class=\"pl-k\">*</span><span class=\"pl-c1\">99999999</span>\na4 <span class=\"pl-k\">=</span> inc2 <span class=\"pl-k\">+</span> a3\nr4 <span class=\"pl-k\">=</span> np.argsort(a4, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)</pre></div>\n<p>In the above, a matrix of large numbers, where every element is the same, is added to a matrix of small numbers (this shouldn't affect the ordering of the small matrix). Hence <code>r1, r2, r3, r4</code> should all be the same. However, <code>r2</code> is different from the rest, meaning adding a large numbers to the input makes <code>torch.sort()</code> behave weirdly. So does <code>torch.topk()</code>, presumably for the same reason.</p>\n<p>I've been getting weird results with my beam search implementation in PyTorch, and this was the culprit. In beam search you have to sort a list of large negative numbers (log probabilities of candidate translation sentences). Can anyone suggest a quick workaround? Thanks!</p>", "body_text": "import torch\nimport numpy as np\n\nbatch_size = 5\ndim = 10\n\n### pytorch\na1 = torch.randn(batch_size, dim)\nv1, r1 = a1.sort(dim=1)\n\ninc = torch.ones(batch_size)[:,None]*99999999\na2 = inc + a1\nv2, r2 = a2.sort(dim=1)\n\n### numpy\na3 = a1.numpy()\nr3 = np.argsort(a3, axis=1)\n\ninc2 = np.ones(batch_size)[:,None]*99999999\na4 = inc2 + a3\nr4 = np.argsort(a4, axis=1)\nIn the above, a matrix of large numbers, where every element is the same, is added to a matrix of small numbers (this shouldn't affect the ordering of the small matrix). Hence r1, r2, r3, r4 should all be the same. However, r2 is different from the rest, meaning adding a large numbers to the input makes torch.sort() behave weirdly. So does torch.topk(), presumably for the same reason.\nI've been getting weird results with my beam search implementation in PyTorch, and this was the culprit. In beam search you have to sort a list of large negative numbers (log probabilities of candidate translation sentences). Can anyone suggest a quick workaround? Thanks!", "body": "```python\r\nimport torch\r\nimport numpy as np\r\n\r\nbatch_size = 5\r\ndim = 10\r\n\r\n### pytorch\r\na1 = torch.randn(batch_size, dim)\r\nv1, r1 = a1.sort(dim=1)\r\n\r\ninc = torch.ones(batch_size)[:,None]*99999999\r\na2 = inc + a1\r\nv2, r2 = a2.sort(dim=1)\r\n\r\n### numpy\r\na3 = a1.numpy()\r\nr3 = np.argsort(a3, axis=1)\r\n\r\ninc2 = np.ones(batch_size)[:,None]*99999999\r\na4 = inc2 + a3\r\nr4 = np.argsort(a4, axis=1)\r\n```\r\n\r\nIn the above, a matrix of large numbers, where every element is the same, is added to a matrix of small numbers (this shouldn't affect the ordering of the small matrix). Hence `r1, r2, r3, r4` should all be the same. However, `r2` is different from the rest, meaning adding a large numbers to the input makes `torch.sort()` behave weirdly. So does `torch.topk()`, presumably for the same reason.\r\n\r\nI've been getting weird results with my beam search implementation in PyTorch, and this was the culprit. In beam search you have to sort a list of large negative numbers (log probabilities of candidate translation sentences). Can anyone suggest a quick workaround? Thanks!"}