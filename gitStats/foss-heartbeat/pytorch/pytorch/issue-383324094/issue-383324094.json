{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14299", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14299/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14299/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14299/events", "html_url": "https://github.com/pytorch/pytorch/issues/14299", "id": 383324094, "node_id": "MDU6SXNzdWUzODMzMjQwOTQ=", "number": 14299, "title": "vector<T> too long and crash on module->forward, other errors when loading TorchScript model in C++", "user": {"login": "aman-tiwari", "id": 8798016, "node_id": "MDQ6VXNlcjg3OTgwMTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8798016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aman-tiwari", "html_url": "https://github.com/aman-tiwari", "followers_url": "https://api.github.com/users/aman-tiwari/followers", "following_url": "https://api.github.com/users/aman-tiwari/following{/other_user}", "gists_url": "https://api.github.com/users/aman-tiwari/gists{/gist_id}", "starred_url": "https://api.github.com/users/aman-tiwari/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aman-tiwari/subscriptions", "organizations_url": "https://api.github.com/users/aman-tiwari/orgs", "repos_url": "https://api.github.com/users/aman-tiwari/repos", "events_url": "https://api.github.com/users/aman-tiwari/events{/privacy}", "received_events_url": "https://api.github.com/users/aman-tiwari/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T23:14:01Z", "updated_at": "2018-11-22T00:21:03Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>I'm trying to load a torchscript module serialized as in the tutorial, but I get <code>vector&lt;T&gt; too long</code> when trying to print the modules in the model, as well as a crash if <code>model-&gt;forward</code> is called:</p>\n<h2>To Reproduce</h2>\n<p>Serialize model as in the tutorial:</p>\n<div class=\"highlight highlight-source-python\"><pre>(piptorch) C:\\<span class=\"pl-ii\">...\\&gt;python</span>\nPython <span class=\"pl-c1\">3.6</span>.7 <span class=\"pl-k\">|</span>Anaconda, Inc.<span class=\"pl-k\">|</span> (default, Oct <span class=\"pl-c1\">28</span> <span class=\"pl-c1\">2018</span>, <span class=\"pl-c1\">19</span>:<span class=\"pl-c1\">44</span>:<span class=\"pl-c1\">12</span>) [<span class=\"pl-c1\">MSC</span> v.1915 <span class=\"pl-c1\">64</span> bit (<span class=\"pl-c1\">AMD64</span>)] on win32\nType <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>help<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>copyright<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>credits<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">or</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>license<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">for</span> more information.\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> torchvision\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> model <span class=\"pl-k\">=</span> torchvision.models.resnet18()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> example <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> traced_script_module <span class=\"pl-k\">=</span> torch.jit.trace(model, example)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> output <span class=\"pl-k\">=</span> traced_script_module(torch.ones(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>))\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> output[<span class=\"pl-c1\">0</span>, :<span class=\"pl-c1\">5</span>]\ntensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">0.3891</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">0.0314</span>,  <span class=\"pl-c1\">0.4143</span>,  <span class=\"pl-c1\">0.0229</span>,  <span class=\"pl-c1\">0.0064</span>], <span class=\"pl-v\">grad_fn</span><span class=\"pl-k\">=</span><span class=\"pl-k\">&lt;</span>SliceBackward<span class=\"pl-k\">&gt;</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> traced_script_module.save(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>model.pt<span class=\"pl-pds\">\"</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">exit</span>()</pre></div>\n<p>My C++ code looks like this:</p>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>pch.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>torch/script.h<span class=\"pl-pds\">&gt;</span></span> <span class=\"pl-c\"><span class=\"pl-c\">//</span> One-stop header.</span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>memory<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ConsoleApplication1.h<span class=\"pl-pds\">\"</span></span>\n\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">int</span> argc, <span class=\"pl-k\">const</span> <span class=\"pl-k\">char</span>* argv[]) {\n\t<span class=\"pl-k\">if</span> (argc != <span class=\"pl-c1\">2</span>) {\n\t\tstd::cerr &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>usage: example-app &lt;path-to-exported-script-module&gt;<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\t\t<span class=\"pl-k\">return</span> -<span class=\"pl-c1\">1</span>;\n\t}\n\tstd::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>loading: <span class=\"pl-pds\">\"</span></span> &lt;&lt; argv[<span class=\"pl-c1\">1</span>] &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span></span>;\n\tstd::ifstream <span class=\"pl-smi\">in</span>(argv[<span class=\"pl-c1\">1</span>], std::ios_base::binary);\n\t<span class=\"pl-c\"><span class=\"pl-c\">//</span> Deserialize the ScriptModule from a file using torch::jit::load().</span>\n\t<span class=\"pl-k\">try</span> {\n\t\tstd::shared_ptr&lt;torch::jit::script::Module&gt; module = <span class=\"pl-c1\">torch::jit::load</span>(in);\n\t\tin.<span class=\"pl-c1\">close</span>();\n\n\t\t<span class=\"pl-c1\">assert</span>(module != <span class=\"pl-c1\">nullptr</span>);\n\n\t\t<span class=\"pl-k\">auto</span> mods = module-&gt;<span class=\"pl-c1\">get_modules</span>();\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">const</span> <span class=\"pl-k\">auto</span>&amp; m : mods) {\n\t\t\tstd::cout &lt;&lt; m.<span class=\"pl-c1\">key</span>() &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\t\t}\n\n\t\tc10::Device <span class=\"pl-smi\">gpu</span>(c10::DeviceType::CUDA, <span class=\"pl-c1\">0</span>);\n\t\tmodule-&gt;<span class=\"pl-c1\">to</span>(gpu);\n\n\t\tstd::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>module moved to gpu ok<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n\t\ttorch::jit::Stack inputs;\n\t\t<span class=\"pl-k\">auto</span> tensor = <span class=\"pl-c1\">torch::ones</span>({ <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span> }).<span class=\"pl-c1\">to</span>(gpu);\n\t\tinputs.<span class=\"pl-c1\">push_back</span>(tensor);\n\n\t\tstd::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>inputs constructed ok<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\n\t\tmodule-&gt;<span class=\"pl-c1\">forward</span>(inputs);\n\t\tstd::cout &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ok<span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\t}\n\t<span class=\"pl-k\">catch</span> (c10::Error e) {\n\t\tin.<span class=\"pl-c1\">close</span>();\n\t\tstd::cerr &lt;&lt; e.<span class=\"pl-c1\">what</span>() &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\t}\n\t<span class=\"pl-k\">catch</span> (std::exception exn) {\n\t\tin.<span class=\"pl-c1\">close</span>();\n\t\tstd::cerr &lt;&lt; exn.<span class=\"pl-c1\">what</span>() &lt;&lt; <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">\"</span></span>;\n\t}\n}</pre></div>\n<p>But when I run the above I get:</p>\n<div class=\"highlight highlight-source-powershell\"><pre>PS C:\\Users\\a\\Documents\\libtorch<span class=\"pl-k\">-</span>shared<span class=\"pl-k\">-</span>with<span class=\"pl-k\">-</span>deps<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>\\proj\\x64\\Debug<span class=\"pl-k\">&gt;</span> .\\<span class=\"pl-c1\">ConsoleApplication1.exe</span> model.pt\nloading: model.pt\nvector<span class=\"pl-k\">&lt;</span>T<span class=\"pl-k\">&gt;</span> too long</pre></div>\n<p>If I remove the get_modules line and the part that prints the module names, I get:</p>\n<div class=\"highlight highlight-source-powershell\"><pre>PS C:\\Users\\a\\Documents\\libtorch<span class=\"pl-k\">-</span>shared<span class=\"pl-k\">-</span>with<span class=\"pl-k\">-</span>deps<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>\\proj\\x64\\Debug<span class=\"pl-k\">&gt;</span> .\\<span class=\"pl-c1\">ConsoleApplication1.exe</span> model.pt\nloading: model.pt\nmodule moved to gpu ok\ninputs constructed ok\nPS C:\\Users\\a\\Documents\\libtorch<span class=\"pl-k\">-</span>shared<span class=\"pl-k\">-</span>with<span class=\"pl-k\">-</span>deps<span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>\\proj\\x64\\Debug<span class=\"pl-k\">&gt;</span></pre></div>\n<p>(i.e, a crash when module-&gt;forward() is called)</p>\n<p>If I run it in the VS2017 debugger, the crash happens in `std::unordered_map``:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8798016/48873214-c20afc80-edba-11e8-91d9-af977f24a470.PNG\"><img src=\"https://user-images.githubusercontent.com/8798016/48873214-c20afc80-edba-11e8-91d9-af977f24a470.PNG\" alt=\"err0\" style=\"max-width:100%;\"></a></p>\n<p>Walking up the stacktrace to torch's code:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8798016/48873223-ccc59180-edba-11e8-8bab-6a8641902e7c.PNG\"><img src=\"https://user-images.githubusercontent.com/8798016/48873223-ccc59180-edba-11e8-8bab-6a8641902e7c.PNG\" alt=\"err1\" style=\"max-width:100%;\"></a></p>\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<pre><code>Collecting environment information...\nPyTorch version: 1.0\nIs debug build: No\nCUDA used to build PyTorch: 9.0\n\nOS: Microsoft Windows 10 Home\nGCC version: Could not collect\nCMake version: version 3.13.0-rc1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration: GPU 0: GeForce GTX 1070 With Max-Q Design\nNvidia driver version: 411.70\ncuDNN version: Probably one of the following:\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\cudnn64_7.dll\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     1.0                       &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>\n<p>NB: I installed Pytorch 1.0 &amp; LibTorch from <a href=\"https://github.com/peterjc123/pytorch-scripts\">https://github.com/peterjc123/pytorch-scripts</a> as I couldn't find an official module or <a href=\"https://github.com/pytorch/pytorch/issues/14203\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/14203/hovercard\">get it to build myself</a></p>\n<h2>Additional context</h2>\n<p>I had some <code>'std' ambiguous symbol</code> errors in some of the headers when I included them in visual studio 2017, of the form <code>std::vector ...</code> and <code>std::unordered_map ...</code>. I had to convert them to <code>::std::vector ... and ::std::unordered_map ...</code> to get it to work.</p>", "body_text": "\ud83d\udc1b Bug\nI'm trying to load a torchscript module serialized as in the tutorial, but I get vector<T> too long when trying to print the modules in the model, as well as a crash if model->forward is called:\nTo Reproduce\nSerialize model as in the tutorial:\n(piptorch) C:\\...\\>python\nPython 3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import torch\n>>> import torchvision\n>>> model = torchvision.models.resnet18()\n>>> example = torch.rand(1, 3, 224, 224)\n>>> traced_script_module = torch.jit.trace(model, example)\n>>> output = traced_script_module(torch.ones(1, 3, 224, 224))\n>>> output[0, :5]\ntensor([-0.3891, -0.0314,  0.4143,  0.0229,  0.0064], grad_fn=<SliceBackward>)\n>>> traced_script_module.save(\"model.pt\")\n>>> exit()\nMy C++ code looks like this:\n#include \"pch.h\"\n#include <torch/script.h> // One-stop header.\n#include <iostream>\n#include <memory>\n#include \"ConsoleApplication1.h\"\n\n\nint main(int argc, const char* argv[]) {\n\tif (argc != 2) {\n\t\tstd::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\n\t\treturn -1;\n\t}\n\tstd::cout << \"loading: \" << argv[1] << '\\n';\n\tstd::ifstream in(argv[1], std::ios_base::binary);\n\t// Deserialize the ScriptModule from a file using torch::jit::load().\n\ttry {\n\t\tstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(in);\n\t\tin.close();\n\n\t\tassert(module != nullptr);\n\n\t\tauto mods = module->get_modules();\n\t\tfor (const auto& m : mods) {\n\t\t\tstd::cout << m.key() << \"\\n\";\n\t\t}\n\n\t\tc10::Device gpu(c10::DeviceType::CUDA, 0);\n\t\tmodule->to(gpu);\n\n\t\tstd::cout << \"module moved to gpu ok\\n\";\n\n\t\ttorch::jit::Stack inputs;\n\t\tauto tensor = torch::ones({ 1, 3, 224, 224 }).to(gpu);\n\t\tinputs.push_back(tensor);\n\n\t\tstd::cout << \"inputs constructed ok\\n\";\n\n\t\tmodule->forward(inputs);\n\t\tstd::cout << \"ok\\n\";\n\t}\n\tcatch (c10::Error e) {\n\t\tin.close();\n\t\tstd::cerr << e.what() << \"\\n\";\n\t}\n\tcatch (std::exception exn) {\n\t\tin.close();\n\t\tstd::cerr << exn.what() << \"\\n\";\n\t}\n}\nBut when I run the above I get:\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug> .\\ConsoleApplication1.exe model.pt\nloading: model.pt\nvector<T> too long\nIf I remove the get_modules line and the part that prints the module names, I get:\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug> .\\ConsoleApplication1.exe model.pt\nloading: model.pt\nmodule moved to gpu ok\ninputs constructed ok\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug>\n(i.e, a crash when module->forward() is called)\nIf I run it in the VS2017 debugger, the crash happens in `std::unordered_map``:\n\nWalking up the stacktrace to torch's code:\n\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nCollecting environment information...\nPyTorch version: 1.0\nIs debug build: No\nCUDA used to build PyTorch: 9.0\n\nOS: Microsoft Windows 10 Home\nGCC version: Could not collect\nCMake version: version 3.13.0-rc1\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration: GPU 0: GeForce GTX 1070 With Max-Q Design\nNvidia driver version: 411.70\ncuDNN version: Probably one of the following:\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\cudnn64_7.dll\n\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] torch                     1.0                       <pip>\n[conda] torchvision               0.2.1                     <pip>\n\nNB: I installed Pytorch 1.0 & LibTorch from https://github.com/peterjc123/pytorch-scripts as I couldn't find an official module or get it to build myself\nAdditional context\nI had some 'std' ambiguous symbol errors in some of the headers when I included them in visual studio 2017, of the form std::vector ... and std::unordered_map .... I had to convert them to ::std::vector ... and ::std::unordered_map ... to get it to work.", "body": "## \ud83d\udc1b Bug\r\n\r\nI'm trying to load a torchscript module serialized as in the tutorial, but I get `vector<T> too long` when trying to print the modules in the model, as well as a crash if `model->forward` is called:\r\n\r\n## To Reproduce\r\n\r\nSerialize model as in the tutorial:\r\n```python\r\n(piptorch) C:\\...\\>python\r\nPython 3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> import torchvision\r\n>>> model = torchvision.models.resnet18()\r\n>>> example = torch.rand(1, 3, 224, 224)\r\n>>> traced_script_module = torch.jit.trace(model, example)\r\n>>> output = traced_script_module(torch.ones(1, 3, 224, 224))\r\n>>> output[0, :5]\r\ntensor([-0.3891, -0.0314,  0.4143,  0.0229,  0.0064], grad_fn=<SliceBackward>)\r\n>>> traced_script_module.save(\"model.pt\")\r\n>>> exit()\r\n```\r\n\r\nMy C++ code looks like this:\r\n\r\n```cpp\r\n#include \"pch.h\"\r\n#include <torch/script.h> // One-stop header.\r\n#include <iostream>\r\n#include <memory>\r\n#include \"ConsoleApplication1.h\"\r\n\r\n\r\nint main(int argc, const char* argv[]) {\r\n\tif (argc != 2) {\r\n\t\tstd::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\r\n\t\treturn -1;\r\n\t}\r\n\tstd::cout << \"loading: \" << argv[1] << '\\n';\r\n\tstd::ifstream in(argv[1], std::ios_base::binary);\r\n\t// Deserialize the ScriptModule from a file using torch::jit::load().\r\n\ttry {\r\n\t\tstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(in);\r\n\t\tin.close();\r\n\r\n\t\tassert(module != nullptr);\r\n\r\n\t\tauto mods = module->get_modules();\r\n\t\tfor (const auto& m : mods) {\r\n\t\t\tstd::cout << m.key() << \"\\n\";\r\n\t\t}\r\n\r\n\t\tc10::Device gpu(c10::DeviceType::CUDA, 0);\r\n\t\tmodule->to(gpu);\r\n\r\n\t\tstd::cout << \"module moved to gpu ok\\n\";\r\n\r\n\t\ttorch::jit::Stack inputs;\r\n\t\tauto tensor = torch::ones({ 1, 3, 224, 224 }).to(gpu);\r\n\t\tinputs.push_back(tensor);\r\n\r\n\t\tstd::cout << \"inputs constructed ok\\n\";\r\n\r\n\t\tmodule->forward(inputs);\r\n\t\tstd::cout << \"ok\\n\";\r\n\t}\r\n\tcatch (c10::Error e) {\r\n\t\tin.close();\r\n\t\tstd::cerr << e.what() << \"\\n\";\r\n\t}\r\n\tcatch (std::exception exn) {\r\n\t\tin.close();\r\n\t\tstd::cerr << exn.what() << \"\\n\";\r\n\t}\r\n}\r\n```\r\n\r\nBut when I run the above I get: \r\n```powershell\r\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug> .\\ConsoleApplication1.exe model.pt\r\nloading: model.pt\r\nvector<T> too long\r\n```\r\n\r\n\r\nIf I remove the get_modules line and the part that prints the module names, I get:\r\n\r\n```powershell\r\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug> .\\ConsoleApplication1.exe model.pt\r\nloading: model.pt\r\nmodule moved to gpu ok\r\ninputs constructed ok\r\nPS C:\\Users\\a\\Documents\\libtorch-shared-with-deps-1.0\\proj\\x64\\Debug>\r\n```\r\n(i.e, a crash when module->forward() is called)\r\n\r\nIf I run it in the VS2017 debugger, the crash happens in `std::unordered_map``:\r\n![err0](https://user-images.githubusercontent.com/8798016/48873214-c20afc80-edba-11e8-91d9-af977f24a470.PNG)\r\n\r\nWalking up the stacktrace to torch's code:\r\n![err1](https://user-images.githubusercontent.com/8798016/48873223-ccc59180-edba-11e8-8bab-6a8641902e7c.PNG)\r\n\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0\r\n\r\nOS: Microsoft Windows 10 Home\r\nGCC version: Could not collect\r\nCMake version: version 3.13.0-rc1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: GPU 0: GeForce GTX 1070 With Max-Q Design\r\nNvidia driver version: 411.70\r\ncuDNN version: Probably one of the following:\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\cudnn64_7.dll\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] torch                     1.0                       <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n\r\nNB: I installed Pytorch 1.0 & LibTorch from https://github.com/peterjc123/pytorch-scripts as I couldn't find an official module or [get it to build myself](https://github.com/pytorch/pytorch/issues/14203)\r\n\r\n## Additional context\r\n\r\nI had some `'std' ambiguous symbol` errors in some of the headers when I included them in visual studio 2017, of the form `std::vector ...` and `std::unordered_map ...`. I had to convert them to `::std::vector ... and ::std::unordered_map ...` to get it to work."}