{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4239", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4239/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4239/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4239/events", "html_url": "https://github.com/pytorch/pytorch/issues/4239", "id": 283004423, "node_id": "MDU6SXNzdWUyODMwMDQ0MjM=", "number": 4239, "title": "[Windows] Intermittent error in THAllocator.c:162 - MapViewOfFile returns 0x5 (ERROR_ACCESS_DENIED)", "user": {"login": "jhostetler", "id": 615256, "node_id": "MDQ6VXNlcjYxNTI1Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/615256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhostetler", "html_url": "https://github.com/jhostetler", "followers_url": "https://api.github.com/users/jhostetler/followers", "following_url": "https://api.github.com/users/jhostetler/following{/other_user}", "gists_url": "https://api.github.com/users/jhostetler/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhostetler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhostetler/subscriptions", "organizations_url": "https://api.github.com/users/jhostetler/orgs", "repos_url": "https://api.github.com/users/jhostetler/repos", "events_url": "https://api.github.com/users/jhostetler/events{/privacy}", "received_events_url": "https://api.github.com/users/jhostetler/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-12-18T20:05:38Z", "updated_at": "2018-01-26T06:18:08Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Following this tutorial, Section 4:<br>\n<code>http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py</code></p>\n<p>On the <strong>first run only</strong>, received following error:<br>\n<code>RuntimeError: Couldn't map view of shared file &lt;torch_4600_2309694667&gt;, error code: &lt;5&gt; at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162</code></p>\n<p>Note that <code>D:\\</code> is a DVD drive on my machine. Torch is actually installed on drive <code>C:\\</code> under <code>C:\\Users\\&lt;user-name&gt;\\AppData\\conda\\...</code><br>\nError occurred during epoch 2, between iterations 8000-10000.</p>\n<p>Re-ran 5 times afterwards without error.</p>\n<p>Windows 10 x64, Python 3.6, PyTorch 0.3.0, installed via:<br>\n<code>conda install -c peterjc123 pytorch cuda80</code></p>\n<p>(see <a href=\"url\">https://github.com/pytorch/pytorch/issues/494#issuecomment-350527200</a>)</p>\n<p>Stack trace:</p>\n<pre><code>File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 210, in __next__\n    return self._process_next_batch(batch)\n  File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 119, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 119, in &lt;listcomp&gt;\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\&lt;path elided&gt;\\torch\\utils\\data\\dataloader.py\", line 94, in default_collate\n    storage = batch[0].storage()._new_shared(numel)\n  File \"C:\\&lt;path elided&gt;\\torch\\storage.py\", line 111, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't map view of shared file &lt;torch_4600_2309694667&gt;, error code: &lt;5&gt; at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162\n</code></pre>\n<p>Code (note that my 'data/' directory is in parent directory of code directory):</p>\n<pre><code>import multiprocessing\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net, self).__init__()\n    self.conv1 = nn.Conv2d(3, 6, 5)\n    self.pool = nn.MaxPool2d(2, 2)\n    self.conv2 = nn.Conv2d(6, 16, 5)\n    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n    self.fc2 = nn.Linear(120, 84)\n    self.fc3 = nn.Linear(84, 10)\n\n  def forward(self, x):\n    x = self.pool(F.relu(self.conv1(x)))\n    x = self.pool(F.relu(self.conv2(x)))\n    x = x.view(-1, 16 * 5 * 5)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = self.fc3(x)\n    return x\n\n# Must have the next two lines or won't work on Windows\nif __name__ == \"__main__\":\n  multiprocessing.freeze_support()\n\n  transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n     \n  trainset    = torchvision.datasets.CIFAR10( root=\"../data\", train=True, transform=transform )\n  trainloader = torch.utils.data.DataLoader( trainset, batch_size=4, shuffle=True, num_workers=2 )\n\n  testset     = torchvision.datasets.CIFAR10( root=\"../data\", train=False, transform=transform )\n  testloader  = torch.utils.data.DataLoader( testset, batch_size=4, shuffle=False, num_workers=2 )\n\n  classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n\n  dataiter = iter(trainloader)\n  images, labels = dataiter.next()\n  \n  net = Net()\n  criterion = nn.CrossEntropyLoss()\n  optimizer = optim.SGD( net.parameters(), lr=0.001, momentum=0.9 )\n  \n  for epoch in range(2):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader):\n      inputs, labels = data\n      inputs, labels = autograd.Variable(inputs), autograd.Variable(labels)\n      optimizer.zero_grad()\n      \n      outputs = net( inputs )\n      loss = criterion( outputs, labels )\n      loss.backward()\n      optimizer.step()\n      \n      running_loss += loss.data[0]\n      if i % 2000 == 1999:\n        print( \"[{:d}, {:5d}] loss: {:.3f}\".format( epoch + 1, i + 1, running_loss / 2000 ) )\n        running_loss = 0\n        \n  print( \"done\" )\n</code></pre>", "body_text": "Following this tutorial, Section 4:\nhttp://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\nOn the first run only, received following error:\nRuntimeError: Couldn't map view of shared file <torch_4600_2309694667>, error code: <5> at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162\nNote that D:\\ is a DVD drive on my machine. Torch is actually installed on drive C:\\ under C:\\Users\\<user-name>\\AppData\\conda\\...\nError occurred during epoch 2, between iterations 8000-10000.\nRe-ran 5 times afterwards without error.\nWindows 10 x64, Python 3.6, PyTorch 0.3.0, installed via:\nconda install -c peterjc123 pytorch cuda80\n(see https://github.com/pytorch/pytorch/issues/494#issuecomment-350527200)\nStack trace:\nFile \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 210, in __next__\n    return self._process_next_batch(batch)\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 119, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 119, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 94, in default_collate\n    storage = batch[0].storage()._new_shared(numel)\n  File \"C:\\<path elided>\\torch\\storage.py\", line 111, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: Couldn't map view of shared file <torch_4600_2309694667>, error code: <5> at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162\n\nCode (note that my 'data/' directory is in parent directory of code directory):\nimport multiprocessing\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super(Net, self).__init__()\n    self.conv1 = nn.Conv2d(3, 6, 5)\n    self.pool = nn.MaxPool2d(2, 2)\n    self.conv2 = nn.Conv2d(6, 16, 5)\n    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n    self.fc2 = nn.Linear(120, 84)\n    self.fc3 = nn.Linear(84, 10)\n\n  def forward(self, x):\n    x = self.pool(F.relu(self.conv1(x)))\n    x = self.pool(F.relu(self.conv2(x)))\n    x = x.view(-1, 16 * 5 * 5)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = self.fc3(x)\n    return x\n\n# Must have the next two lines or won't work on Windows\nif __name__ == \"__main__\":\n  multiprocessing.freeze_support()\n\n  transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n     \n  trainset    = torchvision.datasets.CIFAR10( root=\"../data\", train=True, transform=transform )\n  trainloader = torch.utils.data.DataLoader( trainset, batch_size=4, shuffle=True, num_workers=2 )\n\n  testset     = torchvision.datasets.CIFAR10( root=\"../data\", train=False, transform=transform )\n  testloader  = torch.utils.data.DataLoader( testset, batch_size=4, shuffle=False, num_workers=2 )\n\n  classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n\n  dataiter = iter(trainloader)\n  images, labels = dataiter.next()\n  \n  net = Net()\n  criterion = nn.CrossEntropyLoss()\n  optimizer = optim.SGD( net.parameters(), lr=0.001, momentum=0.9 )\n  \n  for epoch in range(2):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader):\n      inputs, labels = data\n      inputs, labels = autograd.Variable(inputs), autograd.Variable(labels)\n      optimizer.zero_grad()\n      \n      outputs = net( inputs )\n      loss = criterion( outputs, labels )\n      loss.backward()\n      optimizer.step()\n      \n      running_loss += loss.data[0]\n      if i % 2000 == 1999:\n        print( \"[{:d}, {:5d}] loss: {:.3f}\".format( epoch + 1, i + 1, running_loss / 2000 ) )\n        running_loss = 0\n        \n  print( \"done\" )", "body": "Following this tutorial, Section 4:\r\n`http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py`\r\n\r\nOn the **first run only**, received following error:\r\n`RuntimeError: Couldn't map view of shared file <torch_4600_2309694667>, error code: <5> at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162`\r\n\r\nNote that `D:\\` is a DVD drive on my machine. Torch is actually installed on drive `C:\\` under `C:\\Users\\<user-name>\\AppData\\conda\\...`\r\nError occurred during epoch 2, between iterations 8000-10000.\r\n\r\nRe-ran 5 times afterwards without error.\r\n\r\nWindows 10 x64, Python 3.6, PyTorch 0.3.0, installed via:\r\n`conda install -c peterjc123 pytorch cuda80`\r\n\r\n(see [https://github.com/pytorch/pytorch/issues/494#issuecomment-350527200](url))\r\n\r\nStack trace:\r\n```\r\nFile \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 210, in __next__\r\n    return self._process_next_batch(batch)\r\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 230, in _process_next_batch\r\n    raise batch.exc_type(batch.exc_msg)\r\nRuntimeError: Traceback (most recent call last):\r\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 42, in _worker_loop\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 119, in default_collate\r\n    return [default_collate(samples) for samples in transposed]\r\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 119, in <listcomp>\r\n    return [default_collate(samples) for samples in transposed]\r\n  File \"C:\\<path elided>\\torch\\utils\\data\\dataloader.py\", line 94, in default_collate\r\n    storage = batch[0].storage()._new_shared(numel)\r\n  File \"C:\\<path elided>\\torch\\storage.py\", line 111, in _new_shared\r\n    return cls._new_using_filename(size)\r\nRuntimeError: Couldn't map view of shared file <torch_4600_2309694667>, error code: <5> at D:\\pytorch\\pytorch\\torch\\lib\\TH\\THAllocator.c:162\r\n```\r\n\r\nCode (note that my 'data/' directory is in parent directory of code directory):\r\n\r\n```\r\nimport multiprocessing\r\n\r\nimport torch\r\nimport torchvision\r\nimport torchvision.transforms as transforms\r\n\r\nimport torch.autograd as autograd\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\n\r\n\r\nclass Net(nn.Module):\r\n  def __init__(self):\r\n    super(Net, self).__init__()\r\n    self.conv1 = nn.Conv2d(3, 6, 5)\r\n    self.pool = nn.MaxPool2d(2, 2)\r\n    self.conv2 = nn.Conv2d(6, 16, 5)\r\n    self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n    self.fc2 = nn.Linear(120, 84)\r\n    self.fc3 = nn.Linear(84, 10)\r\n\r\n  def forward(self, x):\r\n    x = self.pool(F.relu(self.conv1(x)))\r\n    x = self.pool(F.relu(self.conv2(x)))\r\n    x = x.view(-1, 16 * 5 * 5)\r\n    x = F.relu(self.fc1(x))\r\n    x = F.relu(self.fc2(x))\r\n    x = self.fc3(x)\r\n    return x\r\n\r\n# Must have the next two lines or won't work on Windows\r\nif __name__ == \"__main__\":\r\n  multiprocessing.freeze_support()\r\n\r\n  transform = transforms.Compose(\r\n    [transforms.ToTensor(),\r\n     transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\r\n     \r\n  trainset    = torchvision.datasets.CIFAR10( root=\"../data\", train=True, transform=transform )\r\n  trainloader = torch.utils.data.DataLoader( trainset, batch_size=4, shuffle=True, num_workers=2 )\r\n\r\n  testset     = torchvision.datasets.CIFAR10( root=\"../data\", train=False, transform=transform )\r\n  testloader  = torch.utils.data.DataLoader( testset, batch_size=4, shuffle=False, num_workers=2 )\r\n\r\n  classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\r\n\r\n  dataiter = iter(trainloader)\r\n  images, labels = dataiter.next()\r\n  \r\n  net = Net()\r\n  criterion = nn.CrossEntropyLoss()\r\n  optimizer = optim.SGD( net.parameters(), lr=0.001, momentum=0.9 )\r\n  \r\n  for epoch in range(2):\r\n    running_loss = 0.0\r\n    for i, data in enumerate(trainloader):\r\n      inputs, labels = data\r\n      inputs, labels = autograd.Variable(inputs), autograd.Variable(labels)\r\n      optimizer.zero_grad()\r\n      \r\n      outputs = net( inputs )\r\n      loss = criterion( outputs, labels )\r\n      loss.backward()\r\n      optimizer.step()\r\n      \r\n      running_loss += loss.data[0]\r\n      if i % 2000 == 1999:\r\n        print( \"[{:d}, {:5d}] loss: {:.3f}\".format( epoch + 1, i + 1, running_loss / 2000 ) )\r\n        running_loss = 0\r\n        \r\n  print( \"done\" )\r\n```"}