{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197253794", "pull_request_review_id": 130963660, "id": 197253794, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzI1Mzc5NA==", "diff_hunk": "@@ -77,23 +77,30 @@ Scalar Variable::Impl::localScalar() {\n }\n \n std::shared_ptr<Function> Variable::Impl::get_grad_accumulator() {\n-  if (grad_fn_) {\n-    throw std::logic_error(\n-        \"get_grad_accumulator() should be only called on leaf Variables\");\n-  }\n-  if (!requires_grad_) {\n-    return nullptr;\n-  }\n+  // Short-circuits if accumulator requested for non-leaf\n+  if (grad_fn_) throw std::logic_error(\n+    \"get_grad_accumulator() should be only called on leaf Variables\");\n \n-  std::lock_guard<std::mutex> lock(mutex_);\n+  // Short-cicuits if no gradient is required\n+  if (!requires_grad_) return nullptr;\n \n-  auto result = grad_accumulator_.lock();\n-  if (result)\n-    return result;\n+  // Checks for up-to-date accumulator\n+  // Note: the accumulator's metadata may be outdated after a call to\n+  // set_data, for example\n+  std::lock_guard<std::mutex> lock(mutex_);\n+  auto cur_accumulator = grad_accumulator_.lock();\n+  const auto device = data_.is_cuda() ? data_.get_device() : -1;\n+  if (cur_accumulator && cur_accumulator->input_metadata(0).matches(type(), device)) { ", "path": "torch/csrc/autograd/variable.cpp", "position": null, "original_position": 28, "commit_id": "1b56a400c446aabd207a90585845ab81545bbcdd", "original_commit_id": "22005755d16488109039ddeff5a1dad5aeeb457a", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "body": "Yep; I'll move both checks there. ", "created_at": "2018-06-21T19:37:28Z", "updated_at": "2018-11-23T15:46:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/8354#discussion_r197253794", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8354", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197253794"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8354#discussion_r197253794"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8354"}}, "body_html": "<p>Yep; I'll move both checks there.</p>", "body_text": "Yep; I'll move both checks there.", "in_reply_to_id": 197228179}