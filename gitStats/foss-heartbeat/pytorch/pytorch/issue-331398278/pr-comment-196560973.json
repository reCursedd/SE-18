{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196560973", "pull_request_review_id": 130138595, "id": 196560973, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjU2MDk3Mw==", "diff_hunk": "@@ -368,6 +382,23 @@ auto Engine::evaluate_function(FunctionTask& task) -> void {\n     if (!fn_info.needed) return;\n   }\n \n+  // Sets stream (and gpu) for the function to run on\n+  #ifdef USE_CUDA \n+    int parent_device = -1;\n+    THCStream* parent_stream = nullptr;\n+    for (auto i = decltype(task.inputs.size()){0}; i < task.inputs.size(); ++i) {\n+      auto& var = task.inputs[i];\n+      if (var.defined() && var.type().is_cuda()) {\n+        parent_device = var.get_device();\n+        parent_stream = task.fn->input_metadata(i).stream();\n+        break;\n+      }      \n+    }", "path": "torch/csrc/autograd/engine.cpp", "position": null, "original_position": 90, "commit_id": "1b56a400c446aabd207a90585845ab81545bbcdd", "original_commit_id": "36598758d04d2104d5604f038ccd5a31b0377fe2", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "body": "You are correct that we could AutoStream here instead of AutoGPUStream. Might as well.\r\n\r\nExtending input_buffer.device() sounds good and should make the code look cleaner, anyway.", "created_at": "2018-06-19T20:08:32Z", "updated_at": "2018-11-23T15:45:48Z", "html_url": "https://github.com/pytorch/pytorch/pull/8354#discussion_r196560973", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8354", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196560973"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8354#discussion_r196560973"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8354"}}, "body_html": "<p>You are correct that we could AutoStream here instead of AutoGPUStream. Might as well.</p>\n<p>Extending input_buffer.device() sounds good and should make the code look cleaner, anyway.</p>", "body_text": "You are correct that we could AutoStream here instead of AutoGPUStream. Might as well.\nExtending input_buffer.device() sounds good and should make the code look cleaner, anyway.", "in_reply_to_id": 196556846}