{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197231097", "pull_request_review_id": 130935879, "id": 197231097, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzIzMTA5Nw==", "diff_hunk": "@@ -421,6 +443,18 @@ auto Engine::evaluate_function(FunctionTask& task) -> void {\n           continue;\n         }\n       }\n+\n+      #ifdef USE_CUDA\n+        // Switches to and syncs with child's stream (if needed)\n+        const auto child_device = output.is_cuda() ? output.get_device() : -1;\n+        auto child_stream = next.function->input_metadata(next.input_nr).stream();\n+        auto_gpu_stream.set(child_device, child_stream);", "path": "torch/csrc/autograd/engine.cpp", "position": null, "original_position": 52, "commit_id": "1b56a400c446aabd207a90585845ab81545bbcdd", "original_commit_id": "22005755d16488109039ddeff5a1dad5aeeb457a", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "body": "We're not switching to the child stream to synchronize the event, we're switching because we're about to put something in its input buffer, which we have to do on the device + stream for that input buffer slot. \r\n\r\nFor the same reason we can't guard on the parent_device being -1 before this. We could add an outer guard on the child_device after we acquired its device.\r\n\r\nRemember that this call is replacing the former DeviceGuard (nee AutoGPU) in InputBuffer which performed the same check. ", "created_at": "2018-06-21T18:16:32Z", "updated_at": "2018-11-23T15:46:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/8354#discussion_r197231097", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8354", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197231097"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8354#discussion_r197231097"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8354"}}, "body_html": "<p>We're not switching to the child stream to synchronize the event, we're switching because we're about to put something in its input buffer, which we have to do on the device + stream for that input buffer slot.</p>\n<p>For the same reason we can't guard on the parent_device being -1 before this. We could add an outer guard on the child_device after we acquired its device.</p>\n<p>Remember that this call is replacing the former DeviceGuard (nee AutoGPU) in InputBuffer which performed the same check.</p>", "body_text": "We're not switching to the child stream to synchronize the event, we're switching because we're about to put something in its input buffer, which we have to do on the device + stream for that input buffer slot.\nFor the same reason we can't guard on the parent_device being -1 before this. We could add an outer guard on the child_device after we acquired its device.\nRemember that this call is replacing the former DeviceGuard (nee AutoGPU) in InputBuffer which performed the same check.", "in_reply_to_id": 197226999}