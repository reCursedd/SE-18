{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196556846", "pull_request_review_id": 130129980, "id": 196556846, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjU1Njg0Ng==", "diff_hunk": "@@ -368,6 +382,23 @@ auto Engine::evaluate_function(FunctionTask& task) -> void {\n     if (!fn_info.needed) return;\n   }\n \n+  // Sets stream (and gpu) for the function to run on\n+  #ifdef USE_CUDA \n+    int parent_device = -1;\n+    THCStream* parent_stream = nullptr;\n+    for (auto i = decltype(task.inputs.size()){0}; i < task.inputs.size(); ++i) {\n+      auto& var = task.inputs[i];\n+      if (var.defined() && var.type().is_cuda()) {\n+        parent_device = var.get_device();\n+        parent_stream = task.fn->input_metadata(i).stream();\n+        break;\n+      }      \n+    }", "path": "torch/csrc/autograd/engine.cpp", "position": null, "original_position": 90, "commit_id": "1b56a400c446aabd207a90585845ab81545bbcdd", "original_commit_id": "36598758d04d2104d5604f038ccd5a31b0377fe2", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "1. There's already `input_buffer.device()`, so it would be better to use this, or extend it with a possibility of returning a stream.\r\n2. I think AutoGPU is unnecessary here, since you're already guaranteed to be on the thread associated with the device where the inputs live.", "created_at": "2018-06-19T19:54:36Z", "updated_at": "2018-11-23T15:45:48Z", "html_url": "https://github.com/pytorch/pytorch/pull/8354#discussion_r196556846", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8354", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196556846"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8354#discussion_r196556846"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8354"}}, "body_html": "<ol>\n<li>There's already <code>input_buffer.device()</code>, so it would be better to use this, or extend it with a possibility of returning a stream.</li>\n<li>I think AutoGPU is unnecessary here, since you're already guaranteed to be on the thread associated with the device where the inputs live.</li>\n</ol>", "body_text": "There's already input_buffer.device(), so it would be better to use this, or extend it with a possibility of returning a stream.\nI think AutoGPU is unnecessary here, since you're already guaranteed to be on the thread associated with the device where the inputs live."}