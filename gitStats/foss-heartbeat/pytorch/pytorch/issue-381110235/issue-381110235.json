{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14026", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14026/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14026/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14026/events", "html_url": "https://github.com/pytorch/pytorch/issues/14026", "id": 381110235, "node_id": "MDU6SXNzdWUzODExMTAyMzU=", "number": 14026, "title": "[JIT] TestJit.test_lstm_fusion_concat_cuda is flaky", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-11-15T11:05:19Z", "updated_at": "2018-11-16T19:45:33Z", "closed_at": "2018-11-16T19:45:33Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Putting a loop with manual seed 0..99 aound in the test tells me it fails for 9 of those 100 seeds.</p>\n<h2>To Reproduce</h2>\n<p>On recent master, amend the test like this:</p>\n<div class=\"highlight highlight-source-python\"><pre>diff <span class=\"pl-ii\">--</span>git a<span class=\"pl-k\">/</span>test<span class=\"pl-k\">/</span>test_jit.py b<span class=\"pl-k\">/</span>test<span class=\"pl-k\">/</span>test_jit.py\nindex a6fd537af..3ae4abe05 <span class=\"pl-c1\">100644</span>\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">-</span> a<span class=\"pl-k\">/</span>test<span class=\"pl-k\">/</span>test_jit.py\n<span class=\"pl-ii\">++</span><span class=\"pl-k\">+</span> b<span class=\"pl-k\">/</span>test<span class=\"pl-k\">/</span>test_jit.py\n<span class=\"pl-k\">@@</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">688</span>,<span class=\"pl-c1\">9</span> <span class=\"pl-k\">+</span><span class=\"pl-c1\">688</span>,<span class=\"pl-c1\">18</span> <span class=\"pl-k\">@@</span> <span class=\"pl-k\">class</span> <span class=\"pl-en\">TestJit</span>(<span class=\"pl-e\">JitTestCase</span>):\n     <span class=\"pl-en\">@unittest.skipIf</span>(<span class=\"pl-k\">not</span> <span class=\"pl-c1\">RUN_CUDA</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>fuser requires CUDA<span class=\"pl-pds\">\"</span></span>)\n     <span class=\"pl-en\">@skipIfRocm</span>\n     <span class=\"pl-k\">def</span> <span class=\"pl-en\">test_lstm_fusion_concat_cuda</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n<span class=\"pl-k\">-</span>        inputs <span class=\"pl-k\">=</span> get_lstm_inputs(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">-</span>        ge <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.checkTrace(LSTMCellC, inputs)\n<span class=\"pl-k\">-</span>        <span class=\"pl-c1\">self</span>.assertExpectedGraph(ge.graph_for(<span class=\"pl-k\">*</span>inputs))\n<span class=\"pl-k\">+</span>        fails <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n<span class=\"pl-k\">+</span>        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">100</span>):\n<span class=\"pl-k\">+</span>            <span class=\"pl-c1\">print</span> (<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\r</span><span class=\"pl-pds\">'</span></span>,i,<span class=\"pl-s\"><span class=\"pl-pds\">'</span>   <span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">end</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">+</span>            sys.stdout.flush()\n<span class=\"pl-k\">+</span>            torch.manual_seed(i)\n<span class=\"pl-k\">+</span>            <span class=\"pl-k\">try</span>:\n<span class=\"pl-k\">+</span>                inputs <span class=\"pl-k\">=</span> get_lstm_inputs(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">+</span>                ge <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.checkTrace(LSTMCellC, inputs)\n<span class=\"pl-k\">+</span>                <span class=\"pl-c1\">self</span>.assertExpectedGraph(ge.graph_for(<span class=\"pl-k\">*</span>inputs))\n<span class=\"pl-k\">+</span>            <span class=\"pl-k\">except</span>:\n<span class=\"pl-k\">+</span>                fails <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n<span class=\"pl-k\">+</span>        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>failures<span class=\"pl-pds\">\"</span></span>, fails)\n \n     <span class=\"pl-en\">@unittest.skipIf</span>(<span class=\"pl-c1\">IS_WINDOWS</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NYI: fuser support for Windows<span class=\"pl-pds\">\"</span></span>)\n     <span class=\"pl-en\">@unittest.skipIf</span>(<span class=\"pl-k\">not</span> <span class=\"pl-c1\">RUN_CUDA</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>fuser requires CUDA<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>and run.</p>\n<h2>Expected behavior</h2>\n<p>Not to produce pesky CI bugs on my pull requests.</p>\n<h2>Environment</h2>\n<p>recent master</p>\n<h2>Additional context</h2>\n<p>Seen on CI at <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"380826490\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/13985\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/13985/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/13985\">#13985</a> , fixed there by renaming the test to go after the flaky one.</p>", "body_text": "\ud83d\udc1b Bug\nPutting a loop with manual seed 0..99 aound in the test tells me it fails for 9 of those 100 seeds.\nTo Reproduce\nOn recent master, amend the test like this:\ndiff --git a/test/test_jit.py b/test/test_jit.py\nindex a6fd537af..3ae4abe05 100644\n--- a/test/test_jit.py\n+++ b/test/test_jit.py\n@@ -688,9 +688,18 @@ class TestJit(JitTestCase):\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\n     @skipIfRocm\n     def test_lstm_fusion_concat_cuda(self):\n-        inputs = get_lstm_inputs('cuda')\n-        ge = self.checkTrace(LSTMCellC, inputs)\n-        self.assertExpectedGraph(ge.graph_for(*inputs))\n+        fails = 0\n+        for i in range(100):\n+            print ('\\r',i,'   ', end='')\n+            sys.stdout.flush()\n+            torch.manual_seed(i)\n+            try:\n+                inputs = get_lstm_inputs('cuda')\n+                ge = self.checkTrace(LSTMCellC, inputs)\n+                self.assertExpectedGraph(ge.graph_for(*inputs))\n+            except:\n+                fails += 1\n+        print(\"failures\", fails)\n \n     @unittest.skipIf(IS_WINDOWS, \"NYI: fuser support for Windows\")\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\nand run.\nExpected behavior\nNot to produce pesky CI bugs on my pull requests.\nEnvironment\nrecent master\nAdditional context\nSeen on CI at #13985 , fixed there by renaming the test to go after the flaky one.", "body": "## \ud83d\udc1b Bug\r\n\r\nPutting a loop with manual seed 0..99 aound in the test tells me it fails for 9 of those 100 seeds.\r\n\r\n## To Reproduce\r\n\r\nOn recent master, amend the test like this:\r\n```python\r\ndiff --git a/test/test_jit.py b/test/test_jit.py\r\nindex a6fd537af..3ae4abe05 100644\r\n--- a/test/test_jit.py\r\n+++ b/test/test_jit.py\r\n@@ -688,9 +688,18 @@ class TestJit(JitTestCase):\r\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\r\n     @skipIfRocm\r\n     def test_lstm_fusion_concat_cuda(self):\r\n-        inputs = get_lstm_inputs('cuda')\r\n-        ge = self.checkTrace(LSTMCellC, inputs)\r\n-        self.assertExpectedGraph(ge.graph_for(*inputs))\r\n+        fails = 0\r\n+        for i in range(100):\r\n+            print ('\\r',i,'   ', end='')\r\n+            sys.stdout.flush()\r\n+            torch.manual_seed(i)\r\n+            try:\r\n+                inputs = get_lstm_inputs('cuda')\r\n+                ge = self.checkTrace(LSTMCellC, inputs)\r\n+                self.assertExpectedGraph(ge.graph_for(*inputs))\r\n+            except:\r\n+                fails += 1\r\n+        print(\"failures\", fails)\r\n \r\n     @unittest.skipIf(IS_WINDOWS, \"NYI: fuser support for Windows\")\r\n     @unittest.skipIf(not RUN_CUDA, \"fuser requires CUDA\")\r\n```\r\nand run.\r\n\r\n## Expected behavior\r\n\r\nNot to produce pesky CI bugs on my pull requests.\r\n\r\n## Environment\r\n\r\nrecent master\r\n\r\n## Additional context\r\n\r\nSeen on CI at #13985 , fixed there by renaming the test to go after the flaky one.\r\n"}