{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1567", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1567/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1567/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1567/events", "html_url": "https://github.com/pytorch/pytorch/issues/1567", "id": 228926683, "node_id": "MDU6SXNzdWUyMjg5MjY2ODM=", "number": 1567, "title": "[Feature Request] Asynchronous torch.save()", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-05-16T06:21:58Z", "updated_at": "2017-11-11T23:21:35Z", "closed_at": "2017-05-24T13:49:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Saving huge models costs a lot of IO time. It would be helpful if we could first pickle everything in RAM and then use another process to actually store them.</p>", "body_text": "Saving huge models costs a lot of IO time. It would be helpful if we could first pickle everything in RAM and then use another process to actually store them.", "body": "Saving huge models costs a lot of IO time. It would be helpful if we could first pickle everything in RAM and then use another process to actually store them. "}