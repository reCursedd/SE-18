{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/343642301", "html_url": "https://github.com/pytorch/pytorch/issues/1567#issuecomment-343642301", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1567", "id": 343642301, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MzY0MjMwMQ==", "user": {"login": "sbhaaf", "id": 19878077, "node_id": "MDQ6VXNlcjE5ODc4MDc3", "avatar_url": "https://avatars2.githubusercontent.com/u/19878077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sbhaaf", "html_url": "https://github.com/sbhaaf", "followers_url": "https://api.github.com/users/sbhaaf/followers", "following_url": "https://api.github.com/users/sbhaaf/following{/other_user}", "gists_url": "https://api.github.com/users/sbhaaf/gists{/gist_id}", "starred_url": "https://api.github.com/users/sbhaaf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sbhaaf/subscriptions", "organizations_url": "https://api.github.com/users/sbhaaf/orgs", "repos_url": "https://api.github.com/users/sbhaaf/repos", "events_url": "https://api.github.com/users/sbhaaf/events{/privacy}", "received_events_url": "https://api.github.com/users/sbhaaf/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-11T05:29:42Z", "updated_at": "2017-11-11T05:29:42Z", "author_association": "NONE", "body_html": "<p>In the case that you send a state_dict over a network, pickled or otherwise, it seems there's no good way to force the model on the receiving end to load it into CPU without first saving it to disk. If torch.load() could take a BytesIO object then this could be accomplished with map_location.</p>", "body_text": "In the case that you send a state_dict over a network, pickled or otherwise, it seems there's no good way to force the model on the receiving end to load it into CPU without first saving it to disk. If torch.load() could take a BytesIO object then this could be accomplished with map_location.", "body": "In the case that you send a state_dict over a network, pickled or otherwise, it seems there's no good way to force the model on the receiving end to load it into CPU without first saving it to disk. If torch.load() could take a BytesIO object then this could be accomplished with map_location."}