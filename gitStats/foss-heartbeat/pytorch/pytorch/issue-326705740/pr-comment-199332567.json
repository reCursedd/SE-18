{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199332567", "pull_request_review_id": 133436631, "id": 199332567, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5OTMzMjU2Nw==", "diff_hunk": "@@ -0,0 +1,208 @@\n+#pragma once\n+\n+#include <ATen/Context.h>\n+#include <ATen/Device.h>\n+#include <ATen/Layout.h>\n+#include <ATen/ScalarType.h>\n+#include <ATen/Tensor.h>\n+#include <ATen/Type.h>\n+\n+#include <cstddef>\n+#include <utility>\n+\n+namespace at {\n+\n+/// A class to encapsulate construction axes of a `Tensor`.\n+/// `TensorOptions` is a virtual class to enable overriding of certain methods\n+/// by subclasses in other libraries, such as PyTorch. In PyTorch, there is a\n+/// `torch::TensorOptions` subclass of this `TensorOptions`, which changes\n+/// `type()` to return a variable type instead of a tensor type, such that\n+/// variables are created inside factory methods, instead of tensors.\n+struct TensorOptions {\n+  /// Constructs the `TensorOptions` with valid defaults, which are:\n+  /// - dtype: float\n+  /// - device: CPU\n+  /// - layout: strided\n+  /// - requires_grad: false\n+  TensorOptions() = default;\n+\n+  /// Constructs the `TensorOptions` from the type of the given `Tensor`.\n+  /// If the `Tensor` has a CUDA type, the `device_index` will match that of the\n+  /// tensor. See the constructor from `Type` for the semantics w.r.t. the\n+  /// `type()` method.\n+  explicit TensorOptions(Tensor tensor, bool discard_runtime_type = false) {\n+    if (!discard_runtime_type) {\n+      type_ = &tensor.type();\n+    }\n+    this->dtype(tensor.dtype());\n+    this->device(tensor.device());\n+    this->layout(tensor.layout());\n+  }\n+\n+  /// Constructs the `TensorOptions` from a type and a `device_index`.\n+  ///\n+  /// If `discard_runtime_type` is false (the default), the behavior of\n+  /// `TensorOptions::type()` is changed in that it will always return this\n+  /// `type`, irrespective of any `device` or `dtype` or `layout` specified at a\n+  /// later time. This is to ensure that when a `TensorOptions` object is\n+  /// constructed from a tensor's type, and that type has a dynamic type other\n+  /// than `at::Type` (e.g. `torch::autograd::VariableType`), constructing a new\n+  /// tensor from this `TensorOptions` will use this same derived type. If\n+  /// instead the given `type` were destructured into its components (backend,\n+  /// dtype and layout), information about the runtime type of the `Type` would\n+  /// be lost. Set `discard_runtime_type` to `true` to always destructure the\n+  /// type into its components and discard its runtime type.\n+  /* implicit */ TensorOptions(\n+      const Type& type,\n+      int32_t device_index = -1,\n+      bool discard_runtime_type = false) {\n+    if (!discard_runtime_type) {\n+      type_ = &type;\n+    }\n+    this->dtype(type.scalarType());\n+    this->device({type.backend(), device_index});\n+    this->layout(type.layout());\n+  }\n+\n+  /// Constructs a `TensorOptions` object with the given layout.\n+  /* implicit */ TensorOptions(Layout layout) : TensorOptions() {\n+    this->layout(layout);\n+  }\n+\n+  /// Constructs a `TensorOptions` object with the given device.\n+  /* implicit */ TensorOptions(Device device) : TensorOptions() {\n+    this->device(device);\n+  }\n+\n+  /// Constructs a `TensorOptions` object from a backend, forwarded to the\n+  /// `Device` constructor.\n+  /* implicit */ TensorOptions(Backend backend)\n+      : TensorOptions(Device(backend)) {}\n+\n+  /// Constructs a `TensorOptions` object with the given dtype.\n+  /* implicit */ TensorOptions(ScalarType dtype) : TensorOptions() {\n+    this->dtype(dtype);\n+  }\n+\n+  /// Discards the runtime type stored if the `TensorOptions` was constructed\n+  /// from a `Tensor` or a `Type`. See the documentation of the constructor from\n+  /// a `Type` for implications on the behavior of the `type()` method on\n+  /// `TensorOptions`.\n+  const TensorOptions& discard_runtime_type() const {\n+    type_ = nullptr;\n+    return *this;\n+  }\n+\n+  // NOTE: These methods are defined in TensorOptions.cpp because I get funny\n+  // linker errors for their missing definition if they're defined in the\n+  // header. Who knows why?\n+\n+  /// Sets the device of the `TensorOptions`.\n+  TensorOptions& device(Device device) {\n+    device_ = std::move(device);\n+    return *this;\n+  }\n+\n+  /// Sets the device of the `TensorOptions` to CUDA, and then sets the device\n+  /// index to the given one.\n+  TensorOptions& device_index(int32_t device_index) {\n+    return device({Device::Type::CUDA, device_index});\n+  }\n+\n+  /// Sets the dtype of the `TensorOptions`.\n+  TensorOptions& dtype(ScalarType dtype) {\n+    dtype_ = dtype;\n+    return *this;\n+  }\n+\n+  /// Sets the layout of the `TensorOptions`.\n+  TensorOptions& layout(Layout layout) {\n+    layout_ = layout;\n+    return *this;\n+  }\n+\n+  /// Sets the `requires_grad` property of the `TensorOptions`.\n+  TensorOptions& requires_grad(bool requires_grad = true) {\n+    requires_grad_ = requires_grad;\n+    return *this;\n+  }\n+\n+  /// Returns the device of the `TensorOptions`.\n+  const Device& device() const noexcept {\n+    return device_;\n+  }\n+\n+  /// Returns the device index of the `TensorOptions`.\n+  int32_t device_index() const noexcept {\n+    return device_.index();\n+  }\n+\n+  /// Returns the dtype of the `TensorOptions`.\n+  ScalarType dtype() const noexcept {\n+    return dtype_;\n+  }\n+\n+  /// Returns the layout of the `TensorOptions`.\n+  Layout layout() const noexcept {\n+    return layout_;\n+  }\n+\n+  /// Returns the `requires_grad` property of the `TensorOptions`.\n+  bool requires_grad() const noexcept {\n+    return requires_grad_;\n+  }\n+\n+  /// Constructs an `at::Type` from the members of the `TensorOptions`.\n+  const Type& type() const {\n+    if (type_ != nullptr) {\n+      return *type_;\n+    }\n+    Backend backend;\n+    if (device_.type() == Device::Type::CPU) {\n+      backend = (layout_ == kStrided) ? kCPU : kSparseCPU;\n+    } else {\n+      backend = (layout_ == kStrided) ? kCUDA : kSparseCUDA;\n+    }\n+    return getType(backend, dtype_);", "path": "aten/src/ATen/TensorOptions.h", "position": 166, "original_position": 166, "commit_id": "c5b2af6a950b67445ad8916d364fd24456d7aa39", "original_commit_id": "c5b2af6a950b67445ad8916d364fd24456d7aa39", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "IIUC, this means that, even if people are interacting with `torch` namespace, if they do `torch::zeros({0, 1})` **without** providing a `TensorOptions`, they will get a tensor of type `CPUFloatTensor` (not a `Variable`).\r\n\r\nI'm not very familiar with this code, so please correct me if I am wrong.", "created_at": "2018-06-30T21:25:10Z", "updated_at": "2018-11-23T15:46:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/7869#discussion_r199332567", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7869", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/199332567"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7869#discussion_r199332567"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7869"}}, "body_html": "<p>IIUC, this means that, even if people are interacting with <code>torch</code> namespace, if they do <code>torch::zeros({0, 1})</code> <strong>without</strong> providing a <code>TensorOptions</code>, they will get a tensor of type <code>CPUFloatTensor</code> (not a <code>Variable</code>).</p>\n<p>I'm not very familiar with this code, so please correct me if I am wrong.</p>", "body_text": "IIUC, this means that, even if people are interacting with torch namespace, if they do torch::zeros({0, 1}) without providing a TensorOptions, they will get a tensor of type CPUFloatTensor (not a Variable).\nI'm not very familiar with this code, so please correct me if I am wrong."}