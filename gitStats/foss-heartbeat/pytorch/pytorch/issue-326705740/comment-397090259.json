{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/397090259", "html_url": "https://github.com/pytorch/pytorch/pull/7869#issuecomment-397090259", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7869", "id": 397090259, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzA5MDI1OQ==", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-13T21:18:52Z", "updated_at": "2018-06-13T21:24:25Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello again. I've made lots of updates after everyone's useful comments. I recommend looking at the individual commits I have made as they are reasonably contained.</p>\n<p>Here is a list of most important updates:</p>\n<ol>\n<li>Removed <code>torch::TensorOptions</code> and instead add code to generated <code>torch::{ones, zeros, ...}</code> that does the variable wrapping and setting of <code>requires_grad</code> inside. In the future these methods can just be aliases for those in c10. At the moment, it solves the <code>Variable</code>/<code>Tensor</code> problem without incurring any virtual dispatch overhead. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a></li>\n<li>Generalized <code>AutoGPU</code> lightly into <code>DeviceGuard</code> and codemodded everything to use this class instead. This was in response to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17890620\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dzhulgakov\">@dzhulgakov</a>'s comment and also makes sense for C++ users since we can transparently give <code>DeviceGuard</code> more functionality as more device types become available.</li>\n<li>Added back all the old factory methods, but with deprecation attributes which give nice warnings when they are used. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a></li>\n</ol>\n<p>EDIT: Note that for (1) I had to complicate <code>TensorOptions</code> slightly by giving it a <code>discard_runtime_type</code> option, which has the effect that when constructed with a <code>Type</code>, it always destructures it. This means if the <code>Type</code> is <code>VariableType</code>, its <code>Variable</code>ness is explicitly lost. This is so that in the <code>torch::</code> functions we can call e.g. <code>at::ones(..., TensorOptions(type))</code> in such a way that we always get a tensor and never a variable. Otherwise <code>at::ones</code> with a <code>VariableType</code> will give you a <code>Variable</code>, and then <code>make_variable(Variable)</code> will give you a <code>Variable</code> whose <code>data</code> is a <code>Variable</code>, which means you can't perform any operations with other <code>Tensor</code>s anymore.</p>", "body_text": "Hello again. I've made lots of updates after everyone's useful comments. I recommend looking at the individual commits I have made as they are reasonably contained.\nHere is a list of most important updates:\n\nRemoved torch::TensorOptions and instead add code to generated torch::{ones, zeros, ...} that does the variable wrapping and setting of requires_grad inside. In the future these methods can just be aliases for those in c10. At the moment, it solves the Variable/Tensor problem without incurring any virtual dispatch overhead. @zdevito @colesbury\nGeneralized AutoGPU lightly into DeviceGuard and codemodded everything to use this class instead. This was in response to @dzhulgakov's comment and also makes sense for C++ users since we can transparently give DeviceGuard more functionality as more device types become available.\nAdded back all the old factory methods, but with deprecation attributes which give nice warnings when they are used. @zdevito @gchanan\n\nEDIT: Note that for (1) I had to complicate TensorOptions slightly by giving it a discard_runtime_type option, which has the effect that when constructed with a Type, it always destructures it. This means if the Type is VariableType, its Variableness is explicitly lost. This is so that in the torch:: functions we can call e.g. at::ones(..., TensorOptions(type)) in such a way that we always get a tensor and never a variable. Otherwise at::ones with a VariableType will give you a Variable, and then make_variable(Variable) will give you a Variable whose data is a Variable, which means you can't perform any operations with other Tensors anymore.", "body": "Hello again. I've made lots of updates after everyone's useful comments. I recommend looking at the individual commits I have made as they are reasonably contained. \r\n\r\nHere is a list of most important updates:\r\n\r\n1. Removed `torch::TensorOptions` and instead add code to generated `torch::{ones, zeros, ...}` that does the variable wrapping and setting of `requires_grad` inside. In the future these methods can just be aliases for those in c10. At the moment, it solves the `Variable`/`Tensor` problem without incurring any virtual dispatch overhead. @zdevito @colesbury \r\n2. Generalized `AutoGPU` lightly into `DeviceGuard` and codemodded everything to use this class instead. This was in response to @dzhulgakov's comment and also makes sense for C++ users since we can transparently give `DeviceGuard` more functionality as more device types become available.\r\n3. Added back all the old factory methods, but with deprecation attributes which give nice warnings when they are used. @zdevito @gchanan \r\n\r\nEDIT: Note that for (1) I had to complicate `TensorOptions` slightly by giving it a `discard_runtime_type` option, which has the effect that when constructed with a `Type`, it always destructures it. This means if the `Type` is `VariableType`, its `Variable`ness is explicitly lost. This is so that in the `torch::` functions we can call e.g. `at::ones(..., TensorOptions(type))` in such a way that we always get a tensor and never a variable. Otherwise `at::ones` with a `VariableType` will give you a `Variable`, and then `make_variable(Variable)` will give you a `Variable` whose `data` is a `Variable`, which means you can't perform any operations with other `Tensor`s anymore. "}