{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7869", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7869/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7869/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7869/events", "html_url": "https://github.com/pytorch/pytorch/pull/7869", "id": 326705740, "node_id": "MDExOlB1bGxSZXF1ZXN0MTkwNzIzMTkw", "number": 7869, "title": "Create ATen tensors via TensorOptions", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-05-26T03:22:09Z", "updated_at": "2018-11-23T15:46:37Z", "closed_at": "2018-06-16T07:40:37Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/7869", "html_url": "https://github.com/pytorch/pytorch/pull/7869", "diff_url": "https://github.com/pytorch/pytorch/pull/7869.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/7869.patch"}, "body_html": "<p>This PR is a prototype / WIP for a broad change to the way tensors are created in ATen. The fundamental motivation for this PR is to make tensor creation from C++ more like in Python, which means changing the API for factory functions like <code>at::ones</code>, as well as teaching ATen about construction axes beyond the backend and scalar type, meaning especially a <code>device</code>. This change essentially lays the ground for how tensor creation will happen in c10, and thus defines a new API, currently bolted on top of existing ATen.</p>\n<p>This PR proposes the following:</p>\n<h3>Creation of a type encapsulating all construction axes of a tensor</h3>\n<p>At the moment, this type will contain:</p>\n<ul>\n<li>A scalar type,</li>\n<li>A backend,</li>\n</ul>\n<p>And in the near future shall contain (and already does somewhat in this prototype):</p>\n<ul>\n<li>A device ordinal,</li>\n<li>A layout (strided, coo_sparse etc.)</li>\n<li>A <code>requires_grad</code> boolean.</li>\n</ul>\n<p>in code:</p>\n<pre><code>struct TensorOptions {\n        size_t device = 0;\n\tLayout layout = kStrided;\n\tScalarType dtype = kFloat;\n        Backend backend = kCPU;\n\tbool requires_grad = false;\n};\n</code></pre>\n<p>Each of these fields have default values, such that a default-constructed <code>TensorOptions</code> object fully specifies a new tensor.</p>\n<p>Furthermore, this class shall have chaining methods:</p>\n<pre><code>TensorOptions().device(1).dtype(kInt)\n</code></pre>\n<p>and there shall be functions with the names of fields, that return a new <code>TensorOptions</code> instance:</p>\n<pre><code>// dtype is a free function that returns a new TensorOptions\nauto options = dtype(kFloat).requires_grad(true); \n</code></pre>\n<h3>Use of <code>TensorOptions</code> in all factory methods</h3>\n<p>The new API for tensor creation shall then be (e.g. for <code>ones</code>):</p>\n<pre><code>Tensor ones(IntList size, TensorOptions options = {}) { }\n</code></pre>\n<p>with usage examples such as</p>\n<pre><code>at::ones({2, 2}) // float cpu tensor\nat::ones({2, 2}, kInt); // int cpu tensor\nat::ones({2, 2}, type(kInt).requires_grad(true)) // int cpu tensor, which sets requires_grad for variables\n</code></pre>\n<h3>New code path</h3>\n<p>This PR also implements a new code path for factory methods. For our recollection, at the moment, we create tensors via e.g.</p>\n<pre><code>at::ones(at::CPU(at::kFloat), {3, 3})\n</code></pre>\n<p>which dispatches to</p>\n<pre><code>at::CPU(at::kFloat).ones({3, 3});\n</code></pre>\n<p>which itself calls</p>\n<pre><code>at::native::ones(at::CPU(at::kFloat), {3, 3})\n</code></pre>\n<p>which then calls</p>\n<pre><code>auto tensor = at::CPU(at::kFloat).tensor({3, 3});\ntensor.fill_(1);\n</code></pre>\n<p>This PR proposes to remove factory methods from <code>Type</code>, and skip the dispatch via <code>Type</code> altogether for all factory methods except <code>tensor</code>, which remains the fundamental source of tensors invoked by all other tensor factories:</p>\n<pre><code>at::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\n</code></pre>\n<p>now directly calls</p>\n<pre><code>at::native::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\n</code></pre>\n<p>which now does</p>\n<pre><code>// `TensorOptions::type()`  returns the type corresponding to its `backend` and `scalar_type`\nauto tensor = tensor_options.type().tensor({3, 3});\ntensor.fill_(1)\n</code></pre>\n<p>At the moment, I have implemented this for <code>ones</code>, and I think nothing broke. There should be no implications for the Python API.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a></p>\n<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #6285.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"311417040\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6285\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6285/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6285\">#6285</a><br>\n<span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #6286.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"311417474\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6286\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6286/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6286\">#6286</a><br>\n<span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #7735.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"324993822\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/7735\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/7735/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/7735\">#7735</a></p>", "body_text": "This PR is a prototype / WIP for a broad change to the way tensors are created in ATen. The fundamental motivation for this PR is to make tensor creation from C++ more like in Python, which means changing the API for factory functions like at::ones, as well as teaching ATen about construction axes beyond the backend and scalar type, meaning especially a device. This change essentially lays the ground for how tensor creation will happen in c10, and thus defines a new API, currently bolted on top of existing ATen.\nThis PR proposes the following:\nCreation of a type encapsulating all construction axes of a tensor\nAt the moment, this type will contain:\n\nA scalar type,\nA backend,\n\nAnd in the near future shall contain (and already does somewhat in this prototype):\n\nA device ordinal,\nA layout (strided, coo_sparse etc.)\nA requires_grad boolean.\n\nin code:\nstruct TensorOptions {\n        size_t device = 0;\n\tLayout layout = kStrided;\n\tScalarType dtype = kFloat;\n        Backend backend = kCPU;\n\tbool requires_grad = false;\n};\n\nEach of these fields have default values, such that a default-constructed TensorOptions object fully specifies a new tensor.\nFurthermore, this class shall have chaining methods:\nTensorOptions().device(1).dtype(kInt)\n\nand there shall be functions with the names of fields, that return a new TensorOptions instance:\n// dtype is a free function that returns a new TensorOptions\nauto options = dtype(kFloat).requires_grad(true); \n\nUse of TensorOptions in all factory methods\nThe new API for tensor creation shall then be (e.g. for ones):\nTensor ones(IntList size, TensorOptions options = {}) { }\n\nwith usage examples such as\nat::ones({2, 2}) // float cpu tensor\nat::ones({2, 2}, kInt); // int cpu tensor\nat::ones({2, 2}, type(kInt).requires_grad(true)) // int cpu tensor, which sets requires_grad for variables\n\nNew code path\nThis PR also implements a new code path for factory methods. For our recollection, at the moment, we create tensors via e.g.\nat::ones(at::CPU(at::kFloat), {3, 3})\n\nwhich dispatches to\nat::CPU(at::kFloat).ones({3, 3});\n\nwhich itself calls\nat::native::ones(at::CPU(at::kFloat), {3, 3})\n\nwhich then calls\nauto tensor = at::CPU(at::kFloat).tensor({3, 3});\ntensor.fill_(1);\n\nThis PR proposes to remove factory methods from Type, and skip the dispatch via Type altogether for all factory methods except tensor, which remains the fundamental source of tensors invoked by all other tensor factories:\nat::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\n\nnow directly calls\nat::native::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\n\nwhich now does\n// `TensorOptions::type()`  returns the type corresponding to its `backend` and `scalar_type`\nauto tensor = tensor_options.type().tensor({3, 3});\ntensor.fill_(1)\n\nAt the moment, I have implemented this for ones, and I think nothing broke. There should be no implications for the Python API.\n@zdevito @apaszke @gchanan @colesbury @ezyang\nFixes #6285\nFixes #6286\nFixes #7735", "body": "This PR is a prototype / WIP for a broad change to the way tensors are created in ATen. The fundamental motivation for this PR is to make tensor creation from C++ more like in Python, which means changing the API for factory functions like `at::ones`, as well as teaching ATen about construction axes beyond the backend and scalar type, meaning especially a `device`. This change essentially lays the ground for how tensor creation will happen in c10, and thus defines a new API, currently bolted on top of existing ATen.\r\n\r\nThis PR proposes the following:\r\n\r\n### Creation of a type encapsulating all construction axes of a tensor\r\n\r\nAt the moment, this type will contain:\r\n\r\n* A scalar type,\r\n* A backend,\r\n\r\nAnd in the near future shall contain (and already does somewhat in this prototype):\r\n\r\n* A device ordinal,\r\n* A layout (strided, coo_sparse etc.)\r\n* A `requires_grad` boolean.\r\n\r\nin code:\r\n\r\n```\r\nstruct TensorOptions {\r\n        size_t device = 0;\r\n\tLayout layout = kStrided;\r\n\tScalarType dtype = kFloat;\r\n        Backend backend = kCPU;\r\n\tbool requires_grad = false;\r\n};\r\n```\r\n\r\nEach of these fields have default values, such that a default-constructed `TensorOptions` object fully specifies a new tensor.\r\n\r\nFurthermore, this class shall have chaining methods:\r\n\r\n```\r\nTensorOptions().device(1).dtype(kInt)\r\n```\r\n\r\nand there shall be functions with the names of fields, that return a new `TensorOptions` instance:\r\n\r\n```\r\n// dtype is a free function that returns a new TensorOptions\r\nauto options = dtype(kFloat).requires_grad(true); \r\n```\r\n\r\n### Use of `TensorOptions` in all factory methods\r\n\r\nThe new API for tensor creation shall then be (e.g. for `ones`):\r\n\r\n```\r\nTensor ones(IntList size, TensorOptions options = {}) { }\r\n```\r\n\r\nwith usage examples such as\r\n\r\n```\r\nat::ones({2, 2}) // float cpu tensor\r\nat::ones({2, 2}, kInt); // int cpu tensor\r\nat::ones({2, 2}, type(kInt).requires_grad(true)) // int cpu tensor, which sets requires_grad for variables\r\n```\r\n\r\n### New code path\r\n\r\nThis PR also implements a new code path for factory methods. For our recollection, at the moment, we create tensors via e.g.\r\n\r\n```\r\nat::ones(at::CPU(at::kFloat), {3, 3})\r\n```\r\n\r\nwhich dispatches to\r\n\r\n```\r\nat::CPU(at::kFloat).ones({3, 3});\r\n```\r\n\r\nwhich itself calls\r\n\r\n```\r\nat::native::ones(at::CPU(at::kFloat), {3, 3})\r\n```\r\n\r\nwhich then calls\r\n\r\n```\r\nauto tensor = at::CPU(at::kFloat).tensor({3, 3});\r\ntensor.fill_(1);\r\n```\r\n\r\nThis PR proposes to remove factory methods from `Type`, and skip the dispatch via `Type` altogether for all factory methods except `tensor`, which remains the fundamental source of tensors invoked by all other tensor factories:\r\n\r\n```\r\nat::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\r\n```\r\n\r\nnow directly calls\r\n\r\n```\r\nat::native::ones({3, 3}, at::type(at::kFloat).device(at::CPU))\r\n```\r\n\r\nwhich now does\r\n\r\n```\r\n// `TensorOptions::type()`  returns the type corresponding to its `backend` and `scalar_type`\r\nauto tensor = tensor_options.type().tensor({3, 3});\r\ntensor.fill_(1)\r\n```\r\n\r\nAt the moment, I have implemented this for `ones`, and I think nothing broke. There should be no implications for the Python API.\r\n\r\n@zdevito @apaszke @gchanan @colesbury @ezyang \r\n\r\nFixes https://github.com/pytorch/pytorch/issues/6285\r\nFixes https://github.com/pytorch/pytorch/issues/6286\r\nFixes https://github.com/pytorch/pytorch/issues/7735"}