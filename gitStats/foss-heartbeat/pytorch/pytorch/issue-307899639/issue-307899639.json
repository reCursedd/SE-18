{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5954", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5954/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5954/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5954/events", "html_url": "https://github.com/pytorch/pytorch/issues/5954", "id": 307899639, "node_id": "MDU6SXNzdWUzMDc4OTk2Mzk=", "number": 5954, "title": "gradient for Multivariate normal ", "user": {"login": "svd3", "id": 25108784, "node_id": "MDQ6VXNlcjI1MTA4Nzg0", "avatar_url": "https://avatars1.githubusercontent.com/u/25108784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/svd3", "html_url": "https://github.com/svd3", "followers_url": "https://api.github.com/users/svd3/followers", "following_url": "https://api.github.com/users/svd3/following{/other_user}", "gists_url": "https://api.github.com/users/svd3/gists{/gist_id}", "starred_url": "https://api.github.com/users/svd3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/svd3/subscriptions", "organizations_url": "https://api.github.com/users/svd3/orgs", "repos_url": "https://api.github.com/users/svd3/repos", "events_url": "https://api.github.com/users/svd3/events{/privacy}", "received_events_url": "https://api.github.com/users/svd3/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-03-23T04:32:53Z", "updated_at": "2018-03-23T15:52:11Z", "closed_at": "2018-03-23T14:19:09Z", "author_association": "NONE", "body_html": "<p>I was trying to achieve backprop through the parameters of a multivariate normal distributions something like pathwise derivative.<br>\n<a href=\"http://pytorch.org/docs/master/distributions.html#multivariatenormal\" rel=\"nofollow\">Pytorch Docs for MultivariateNormal</a><br>\nMy loss was negative log probability, but backward() gives error. To debug I tried to generate sample from this distribution but and it returns a matrix when it should return a vector (individual sample)</p>\n<p>Here's a simple code to reproduce</p>\n<pre><code>import numpy as np\nimport torch\nfrom torch.autograd import Variable\nfrom torch.distributions.normal import Normal\n\nmu = Variable(torch.randn(5), requires_grad=True)\nC = np.random.randn((5,5)) * 0.01\nC = C.T.dot(C) # only to make it +ve semi definite\nC = Variable(torch.Tensor(C), requires_grad=True)\n\n# for my case these variables are created by a network and i need to take a backward\nm = Normal(mu, C)\n\ntarget = Variable(torch.randn(5)) # target variable is from test\n\n# need to minimize the -ve log probability of target wrt the parameters (here mu and C)\n\nloss = -m.log_prob(target) # this gives loss as a matrix with nan\n# but log_prob even for multivariate should be a scalar for single input\nloss.backward()  # loss.backward() won't work as it needs a scalar\nprint(m.sample()) # should be a vector either (5, 1) or (5, ) but it gives (5, 5) size output \n</code></pre>\n<p>I think there is some problem with implementation for MultivariateNormal</p>", "body_text": "I was trying to achieve backprop through the parameters of a multivariate normal distributions something like pathwise derivative.\nPytorch Docs for MultivariateNormal\nMy loss was negative log probability, but backward() gives error. To debug I tried to generate sample from this distribution but and it returns a matrix when it should return a vector (individual sample)\nHere's a simple code to reproduce\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\nfrom torch.distributions.normal import Normal\n\nmu = Variable(torch.randn(5), requires_grad=True)\nC = np.random.randn((5,5)) * 0.01\nC = C.T.dot(C) # only to make it +ve semi definite\nC = Variable(torch.Tensor(C), requires_grad=True)\n\n# for my case these variables are created by a network and i need to take a backward\nm = Normal(mu, C)\n\ntarget = Variable(torch.randn(5)) # target variable is from test\n\n# need to minimize the -ve log probability of target wrt the parameters (here mu and C)\n\nloss = -m.log_prob(target) # this gives loss as a matrix with nan\n# but log_prob even for multivariate should be a scalar for single input\nloss.backward()  # loss.backward() won't work as it needs a scalar\nprint(m.sample()) # should be a vector either (5, 1) or (5, ) but it gives (5, 5) size output \n\nI think there is some problem with implementation for MultivariateNormal", "body": "I was trying to achieve backprop through the parameters of a multivariate normal distributions something like pathwise derivative.\r\n[Pytorch Docs for MultivariateNormal](http://pytorch.org/docs/master/distributions.html#multivariatenormal)\r\nMy loss was negative log probability, but backward() gives error. To debug I tried to generate sample from this distribution but and it returns a matrix when it should return a vector (individual sample)\r\n\r\nHere's a simple code to reproduce\r\n```\r\nimport numpy as np\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom torch.distributions.normal import Normal\r\n\r\nmu = Variable(torch.randn(5), requires_grad=True)\r\nC = np.random.randn((5,5)) * 0.01\r\nC = C.T.dot(C) # only to make it +ve semi definite\r\nC = Variable(torch.Tensor(C), requires_grad=True)\r\n\r\n# for my case these variables are created by a network and i need to take a backward\r\nm = Normal(mu, C)\r\n\r\ntarget = Variable(torch.randn(5)) # target variable is from test\r\n\r\n# need to minimize the -ve log probability of target wrt the parameters (here mu and C)\r\n\r\nloss = -m.log_prob(target) # this gives loss as a matrix with nan\r\n# but log_prob even for multivariate should be a scalar for single input\r\nloss.backward()  # loss.backward() won't work as it needs a scalar\r\nprint(m.sample()) # should be a vector either (5, 1) or (5, ) but it gives (5, 5) size output \r\n```\r\nI think there is some problem with implementation for MultivariateNormal\r\n"}