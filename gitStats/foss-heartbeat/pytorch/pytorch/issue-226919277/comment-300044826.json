{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/300044826", "html_url": "https://github.com/pytorch/pytorch/pull/1507#issuecomment-300044826", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1507", "id": 300044826, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDA0NDgyNg==", "user": {"login": "caogang", "id": 2537027, "node_id": "MDQ6VXNlcjI1MzcwMjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/2537027?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caogang", "html_url": "https://github.com/caogang", "followers_url": "https://api.github.com/users/caogang/followers", "following_url": "https://api.github.com/users/caogang/following{/other_user}", "gists_url": "https://api.github.com/users/caogang/gists{/gist_id}", "starred_url": "https://api.github.com/users/caogang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caogang/subscriptions", "organizations_url": "https://api.github.com/users/caogang/orgs", "repos_url": "https://api.github.com/users/caogang/repos", "events_url": "https://api.github.com/users/caogang/events{/privacy}", "received_events_url": "https://api.github.com/users/caogang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-09T02:34:43Z", "updated_at": "2017-05-09T02:36:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> Thank you for your suggestions</p>\n<p>All suggestions besides the last one <code>grad_input = grad_output.masked_fill(input &gt; ctx.threshold, 0)</code> have been done in the new commit.</p>\n<p>I have tried using <code>mask_fill</code> before, but I find it doesn't work when performing twice backward.</p>\n<p>Here is my test code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">calc_gradient_penalty</span>(<span class=\"pl-smi\">netD</span>, <span class=\"pl-smi\">real_data</span>, <span class=\"pl-smi\">fake_data</span>):\n    alpha <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">1</span>)\n    alpha <span class=\"pl-k\">=</span> alpha.expand(real_data.size())\n    alpha <span class=\"pl-k\">=</span> alpha.cuda() <span class=\"pl-k\">if</span> use_cuda <span class=\"pl-k\">else</span> alpha\n\n    interpolates <span class=\"pl-k\">=</span> alpha <span class=\"pl-k\">*</span> real_data <span class=\"pl-k\">+</span> ((<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> alpha) <span class=\"pl-k\">*</span> fake_data)\n    <span class=\"pl-k\">if</span> use_cuda:\n        interpolates <span class=\"pl-k\">=</span> interpolates.cuda()\n    interpolates <span class=\"pl-k\">=</span> autograd.Variable(interpolates, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    disc_interpolates <span class=\"pl-k\">=</span> netD(interpolates)\n\n    gradients <span class=\"pl-k\">=</span> autograd.grad(<span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>disc_interpolates, <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>interpolates,\n                              <span class=\"pl-v\">grad_outputs</span><span class=\"pl-k\">=</span>torch.ones(disc_interpolates.size()).cuda() <span class=\"pl-k\">if</span> use_cuda <span class=\"pl-k\">else</span> torch.ones(disc_interpolates.size()),\n                              <span class=\"pl-v\">create_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">only_inputs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">retain_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)[<span class=\"pl-c1\">0</span>]\n\n    gradient_penalty <span class=\"pl-k\">=</span> ((gradients.norm(<span class=\"pl-c1\">2</span>, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>).mean() <span class=\"pl-k\">*</span> <span class=\"pl-c1\">LAMBDA</span>\n    <span class=\"pl-k\">return</span> gradient_penalty\n\nuse_cuda <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\n<span class=\"pl-c1\">BATCH_SIZE</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>\n<span class=\"pl-c1\">LAMBDA</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.1</span>\n<span class=\"pl-c1\">DIM</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">256</span>\nnoise <span class=\"pl-k\">=</span> torch.neg(torch.randn(<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">2</span>))\n<span class=\"pl-k\">if</span> use_cuda:\n    noise <span class=\"pl-k\">=</span> noise.cuda()\nnoisev <span class=\"pl-k\">=</span> autograd.Variable(noise)\n\nnoise1 <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">BATCH_SIZE</span>, <span class=\"pl-c1\">2</span>)\n<span class=\"pl-k\">if</span> use_cuda:\n    noise1 <span class=\"pl-k\">=</span> noise1.cuda()\nnoise1v <span class=\"pl-k\">=</span> autograd.Variable(noise1)\n\nnetD <span class=\"pl-k\">=</span> nn.Sequential(\n            nn.Linear(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">DIM</span>),\n            nn.ReLU(<span class=\"pl-c1\">True</span>),\n            nn.Linear(<span class=\"pl-c1\">DIM</span>, <span class=\"pl-c1\">DIM</span>),\n            nn.ReLU(<span class=\"pl-c1\">True</span>),\n            nn.Linear(<span class=\"pl-c1\">DIM</span>, <span class=\"pl-c1\">DIM</span>),\n            nn.ReLU(<span class=\"pl-c1\">True</span>),\n            nn.Linear(<span class=\"pl-c1\">DIM</span>, <span class=\"pl-c1\">1</span>),\n        )\nnetD.zero_grad()\n<span class=\"pl-c1\">print</span> netD\ngp <span class=\"pl-k\">=</span> calc_gradient_penalty(netD, noisev.data, noise1v.data)\ngp.backward()\n<span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> netD.parameters():\n    <span class=\"pl-c1\">print</span> p.grad</pre></div>\n<p>Then I get an error:</p>\n<div class=\"highlight highlight-source-python\"><pre>NotImplementedErrorTraceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span><span class=\"pl-k\">-</span>a841c9970f31<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n     <span class=\"pl-c1\">44</span> <span class=\"pl-c1\">print</span> netD\n     <span class=\"pl-c1\">45</span> gp <span class=\"pl-k\">=</span> calc_gradient_penalty(netD, noisev.data, noise1v.data)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">46</span> gp.backward()\n     <span class=\"pl-c1\">47</span> <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> netD.parameters():\n     <span class=\"pl-c1\">48</span>     <span class=\"pl-c1\">print</span> p.grad\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>users<span class=\"pl-k\">/</span>gang.cao<span class=\"pl-k\">/</span>env<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>autograd<span class=\"pl-k\">/</span>variable.pyc <span class=\"pl-k\">in</span> backward(<span class=\"pl-c1\">self</span>, gradient, retain_variables)\n    <span class=\"pl-c1\">150</span>                 <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">TypeError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>gradient has to be a Tensor, Variable or None<span class=\"pl-pds\">\"</span></span>)\n    <span class=\"pl-c1\">151</span>             gradient <span class=\"pl-k\">=</span> Variable(gradient, <span class=\"pl-v\">volatile</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">152</span>         <span class=\"pl-c1\">self</span>._execution_engine.run_backward((<span class=\"pl-c1\">self</span>,), (gradient,), retain_variables)\n    <span class=\"pl-c1\">153</span> \n    <span class=\"pl-c1\">154</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">register_hook</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">hook</span>):\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>users<span class=\"pl-k\">/</span>gang.cao<span class=\"pl-k\">/</span>env<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>autograd<span class=\"pl-k\">/</span>function.pyc <span class=\"pl-k\">in</span> backward(<span class=\"pl-k\">*</span>grad_outputs)\n    <span class=\"pl-c1\">170</span>         be the gradient w.r.t. the corresponding <span class=\"pl-c1\">input</span>.\n    <span class=\"pl-c1\">171</span>         <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">--&gt; 172         raise NotImplementedError</span>\n<span class=\"pl-s\">    173 </span>\n<span class=\"pl-s\">    174 </span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">NotImplementedError: </span></pre></div>\n<p>The only difference from current commit is the modification of <code>grad_input = grad_output.masked_fill(input &gt; ctx.threshold, 0)</code><br>\nI have no idea where is wrong. So I still use <code>grad_input = mask.type_as(grad_output) * grad_output</code></p>", "body_text": "@apaszke Thank you for your suggestions\nAll suggestions besides the last one grad_input = grad_output.masked_fill(input > ctx.threshold, 0) have been done in the new commit.\nI have tried using mask_fill before, but I find it doesn't work when performing twice backward.\nHere is my test code:\ndef calc_gradient_penalty(netD, real_data, fake_data):\n    alpha = torch.rand(BATCH_SIZE, 1)\n    alpha = alpha.expand(real_data.size())\n    alpha = alpha.cuda() if use_cuda else alpha\n\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n    if use_cuda:\n        interpolates = interpolates.cuda()\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n    disc_interpolates = netD(interpolates)\n\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else torch.ones(disc_interpolates.size()),\n                              create_graph=True, only_inputs=True, retain_graph=True)[0]\n\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\nuse_cuda = False\nBATCH_SIZE=256\nLAMBDA = 0.1\nDIM = 256\nnoise = torch.neg(torch.randn(BATCH_SIZE, 2))\nif use_cuda:\n    noise = noise.cuda()\nnoisev = autograd.Variable(noise)\n\nnoise1 = torch.randn(BATCH_SIZE, 2)\nif use_cuda:\n    noise1 = noise1.cuda()\nnoise1v = autograd.Variable(noise1)\n\nnetD = nn.Sequential(\n            nn.Linear(2, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, DIM),\n            nn.ReLU(True),\n            nn.Linear(DIM, 1),\n        )\nnetD.zero_grad()\nprint netD\ngp = calc_gradient_penalty(netD, noisev.data, noise1v.data)\ngp.backward()\nfor p in netD.parameters():\n    print p.grad\nThen I get an error:\nNotImplementedErrorTraceback (most recent call last)\n<ipython-input-2-a841c9970f31> in <module>()\n     44 print netD\n     45 gp = calc_gradient_penalty(netD, noisev.data, noise1v.data)\n---> 46 gp.backward()\n     47 for p in netD.parameters():\n     48     print p.grad\n\n/home/users/gang.cao/env/lib/python2.7/site-packages/torch/autograd/variable.pyc in backward(self, gradient, retain_variables)\n    150                 raise TypeError(\"gradient has to be a Tensor, Variable or None\")\n    151             gradient = Variable(gradient, volatile=True)\n--> 152         self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n    153 \n    154     def register_hook(self, hook):\n\n/home/users/gang.cao/env/lib/python2.7/site-packages/torch/autograd/function.pyc in backward(*grad_outputs)\n    170         be the gradient w.r.t. the corresponding input.\n    171         \"\"\"\n--> 172         raise NotImplementedError\n    173 \n    174 \n\nNotImplementedError: \nThe only difference from current commit is the modification of grad_input = grad_output.masked_fill(input > ctx.threshold, 0)\nI have no idea where is wrong. So I still use grad_input = mask.type_as(grad_output) * grad_output", "body": "@apaszke Thank you for your suggestions\r\n\r\nAll suggestions besides the last one `grad_input = grad_output.masked_fill(input > ctx.threshold, 0)` have been done in the new commit.\r\n\r\nI have tried using `mask_fill` before, but I find it doesn't work when performing twice backward.\r\n\r\nHere is my test code:\r\n```python\r\ndef calc_gradient_penalty(netD, real_data, fake_data):\r\n    alpha = torch.rand(BATCH_SIZE, 1)\r\n    alpha = alpha.expand(real_data.size())\r\n    alpha = alpha.cuda() if use_cuda else alpha\r\n\r\n    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\r\n    if use_cuda:\r\n        interpolates = interpolates.cuda()\r\n    interpolates = autograd.Variable(interpolates, requires_grad=True)\r\n\r\n    disc_interpolates = netD(interpolates)\r\n\r\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\r\n                              grad_outputs=torch.ones(disc_interpolates.size()).cuda() if use_cuda else torch.ones(disc_interpolates.size()),\r\n                              create_graph=True, only_inputs=True, retain_graph=True)[0]\r\n\r\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\r\n    return gradient_penalty\r\n\r\nuse_cuda = False\r\nBATCH_SIZE=256\r\nLAMBDA = 0.1\r\nDIM = 256\r\nnoise = torch.neg(torch.randn(BATCH_SIZE, 2))\r\nif use_cuda:\r\n    noise = noise.cuda()\r\nnoisev = autograd.Variable(noise)\r\n\r\nnoise1 = torch.randn(BATCH_SIZE, 2)\r\nif use_cuda:\r\n    noise1 = noise1.cuda()\r\nnoise1v = autograd.Variable(noise1)\r\n\r\nnetD = nn.Sequential(\r\n            nn.Linear(2, DIM),\r\n            nn.ReLU(True),\r\n            nn.Linear(DIM, DIM),\r\n            nn.ReLU(True),\r\n            nn.Linear(DIM, DIM),\r\n            nn.ReLU(True),\r\n            nn.Linear(DIM, 1),\r\n        )\r\nnetD.zero_grad()\r\nprint netD\r\ngp = calc_gradient_penalty(netD, noisev.data, noise1v.data)\r\ngp.backward()\r\nfor p in netD.parameters():\r\n    print p.grad\r\n```\r\n\r\nThen I get an error:\r\n```python\r\nNotImplementedErrorTraceback (most recent call last)\r\n<ipython-input-2-a841c9970f31> in <module>()\r\n     44 print netD\r\n     45 gp = calc_gradient_penalty(netD, noisev.data, noise1v.data)\r\n---> 46 gp.backward()\r\n     47 for p in netD.parameters():\r\n     48     print p.grad\r\n\r\n/home/users/gang.cao/env/lib/python2.7/site-packages/torch/autograd/variable.pyc in backward(self, gradient, retain_variables)\r\n    150                 raise TypeError(\"gradient has to be a Tensor, Variable or None\")\r\n    151             gradient = Variable(gradient, volatile=True)\r\n--> 152         self._execution_engine.run_backward((self,), (gradient,), retain_variables)\r\n    153 \r\n    154     def register_hook(self, hook):\r\n\r\n/home/users/gang.cao/env/lib/python2.7/site-packages/torch/autograd/function.pyc in backward(*grad_outputs)\r\n    170         be the gradient w.r.t. the corresponding input.\r\n    171         \"\"\"\r\n--> 172         raise NotImplementedError\r\n    173 \r\n    174 \r\n\r\nNotImplementedError: \r\n```\r\n\r\nThe only difference from current commit is the modification of `grad_input = grad_output.masked_fill(input > ctx.threshold, 0)`\r\nI have no idea where is wrong. So I still use `grad_input = mask.type_as(grad_output) * grad_output`\r\n"}