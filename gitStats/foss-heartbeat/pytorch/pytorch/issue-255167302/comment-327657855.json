{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/327657855", "html_url": "https://github.com/pytorch/pytorch/pull/2622#issuecomment-327657855", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2622", "id": 327657855, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzY1Nzg1NQ==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-07T01:38:00Z", "updated_at": "2017-09-07T01:38:00Z", "author_association": "MEMBER", "body_html": "<p>It should still be possible to avoid this copy - the main process could allocate a big tensor for a batch in shared memory, send it to the workers, and have them fill the corresponding slices. But it might be hard to implement, because one has to know the structure of the batch upfront</p>", "body_text": "It should still be possible to avoid this copy - the main process could allocate a big tensor for a batch in shared memory, send it to the workers, and have them fill the corresponding slices. But it might be hard to implement, because one has to know the structure of the batch upfront", "body": "It should still be possible to avoid this copy - the main process could allocate a big tensor for a batch in shared memory, send it to the workers, and have them fill the corresponding slices. But it might be hard to implement, because one has to know the structure of the batch upfront"}