{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5872", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5872/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5872/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5872/events", "html_url": "https://github.com/pytorch/pytorch/issues/5872", "id": 306440207, "node_id": "MDU6SXNzdWUzMDY0NDAyMDc=", "number": 5872, "title": " Invalid device ordinal at torch/csrc/cuda/Module.cpp:88", "user": {"login": "Siignature", "id": 25927343, "node_id": "MDQ6VXNlcjI1OTI3MzQz", "avatar_url": "https://avatars3.githubusercontent.com/u/25927343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Siignature", "html_url": "https://github.com/Siignature", "followers_url": "https://api.github.com/users/Siignature/followers", "following_url": "https://api.github.com/users/Siignature/following{/other_user}", "gists_url": "https://api.github.com/users/Siignature/gists{/gist_id}", "starred_url": "https://api.github.com/users/Siignature/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Siignature/subscriptions", "organizations_url": "https://api.github.com/users/Siignature/orgs", "repos_url": "https://api.github.com/users/Siignature/repos", "events_url": "https://api.github.com/users/Siignature/events{/privacy}", "received_events_url": "https://api.github.com/users/Siignature/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-19T12:21:06Z", "updated_at": "2018-03-19T13:01:22Z", "closed_at": "2018-03-19T13:01:22Z", "author_association": "NONE", "body_html": "<p>Hello all, I'm having some troubles with the assignation of the GPU. The code is the following:</p>\n<pre><code>int(gpuid)\n        if not hasattr(os.environ, 'CUDA_VISIBLE_DEVICES'):\n            if gpuid == -1:\n                gpuid = GPU.get_free_gpu(memory)\n            torch.cuda.set_device(gpuid)\n        else:\n            gpuid = os.environ['CUDA_VISIBLE_DEVICES']\n\n        logging.info('Using GPU {}'.format(gpuid))\n</code></pre>\n<p>And I obtain the next error:</p>\n<blockquote>\n<p>File \"/data/segovia/WriterExperiment/utils.py\", line 86, in set<br>\ntorch.cuda.set_device(gpuid)<br>\nFile \"/caa/Homes01/segovia/.local/lib/python3.5/site-packages/torch/cuda/<strong>init</strong>.py\", line 244, in set_device<br>\ntorch._C._cuda_setDevice(device)<br>\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88</p>\n</blockquote>\n<p>This is my GPU configuration:</p>\n<blockquote>\n<p>+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 980     Off  | 00000000:01:00.0  On |                  N/A |<br>\n| 30%   30C    P8    12W / 200W |     27MiB /  4035MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID  Type  Process name                               Usage      |<br>\n|=============================================================================|<br>\n|    0      1748    G   /usr/lib/xorg/Xorg                              24MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n</blockquote>\n<p>Thanks in advance.</p>", "body_text": "Hello all, I'm having some troubles with the assignation of the GPU. The code is the following:\nint(gpuid)\n        if not hasattr(os.environ, 'CUDA_VISIBLE_DEVICES'):\n            if gpuid == -1:\n                gpuid = GPU.get_free_gpu(memory)\n            torch.cuda.set_device(gpuid)\n        else:\n            gpuid = os.environ['CUDA_VISIBLE_DEVICES']\n\n        logging.info('Using GPU {}'.format(gpuid))\n\nAnd I obtain the next error:\n\nFile \"/data/segovia/WriterExperiment/utils.py\", line 86, in set\ntorch.cuda.set_device(gpuid)\nFile \"/caa/Homes01/segovia/.local/lib/python3.5/site-packages/torch/cuda/init.py\", line 244, in set_device\ntorch._C._cuda_setDevice(device)\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88\n\nThis is my GPU configuration:\n\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 980     Off  | 00000000:01:00.0  On |                  N/A |\n| 30%   30C    P8    12W / 200W |     27MiB /  4035MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1748    G   /usr/lib/xorg/Xorg                              24MiB |\n+-----------------------------------------------------------------------------+\n\nThanks in advance.", "body": "Hello all, I'm having some troubles with the assignation of the GPU. The code is the following:\r\n\r\n```\r\nint(gpuid)\r\n        if not hasattr(os.environ, 'CUDA_VISIBLE_DEVICES'):\r\n            if gpuid == -1:\r\n                gpuid = GPU.get_free_gpu(memory)\r\n            torch.cuda.set_device(gpuid)\r\n        else:\r\n            gpuid = os.environ['CUDA_VISIBLE_DEVICES']\r\n\r\n        logging.info('Using GPU {}'.format(gpuid))\r\n```\r\n\r\nAnd I obtain the next error:\r\n\r\n> File \"/data/segovia/WriterExperiment/utils.py\", line 86, in set\r\n    torch.cuda.set_device(gpuid)\r\n  File \"/caa/Homes01/segovia/.local/lib/python3.5/site-packages/torch/cuda/__init__.py\", line 244, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88\r\n\r\nThis is my GPU configuration:\r\n\r\n> +-----------------------------------------------------------------------------+\r\n> | NVIDIA-SMI 384.66                 Driver Version: 384.66                    |\r\n> |-------------------------------+----------------------+----------------------+\r\n> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n> |===============================+======================+======================|\r\n> |   0  GeForce GTX 980     Off  | 00000000:01:00.0  On |                  N/A |\r\n> | 30%   30C    P8    12W / 200W |     27MiB /  4035MiB |      0%      Default |\r\n> +-------------------------------+----------------------+----------------------+\r\n>                                                                                \r\n> +-----------------------------------------------------------------------------+\r\n> | Processes:                                                       GPU Memory |\r\n> |  GPU       PID  Type  Process name                               Usage      |\r\n> |=============================================================================|\r\n> |    0      1748    G   /usr/lib/xorg/Xorg                              24MiB |\r\n> +-----------------------------------------------------------------------------+\r\n\r\nThanks in advance."}