{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12218", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12218/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12218/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12218/events", "html_url": "https://github.com/pytorch/pytorch/issues/12218", "id": 365484714, "node_id": "MDU6SXNzdWUzNjU0ODQ3MTQ=", "number": 12218, "title": "Weight decay modifies grad for SGD but not for Adam", "user": {"login": "bartwojcik", "id": 19909459, "node_id": "MDQ6VXNlcjE5OTA5NDU5", "avatar_url": "https://avatars2.githubusercontent.com/u/19909459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bartwojcik", "html_url": "https://github.com/bartwojcik", "followers_url": "https://api.github.com/users/bartwojcik/followers", "following_url": "https://api.github.com/users/bartwojcik/following{/other_user}", "gists_url": "https://api.github.com/users/bartwojcik/gists{/gist_id}", "starred_url": "https://api.github.com/users/bartwojcik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bartwojcik/subscriptions", "organizations_url": "https://api.github.com/users/bartwojcik/orgs", "repos_url": "https://api.github.com/users/bartwojcik/repos", "events_url": "https://api.github.com/users/bartwojcik/events{/privacy}", "received_events_url": "https://api.github.com/users/bartwojcik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-01T14:20:38Z", "updated_at": "2018-10-02T13:26:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Seems that in step() of SGD optimizer:</p>\n<pre><code>                d_p = p.grad.data\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n</code></pre>\n<p>gradient is being modified. Yet, Adam does a copy:</p>\n<pre><code>                if group['weight_decay'] != 0:\n                    grad = grad.add(group['weight_decay'], p.data)\n</code></pre>\n<p>This behavior should be documented for both optimizers.</p>\n<p>I find it very unintuitive and surprising that gradients can be modified in simple, single step (the one without reevaluation closure), but I guess there could be some reason and that is intended behavior so I am filing this under documentation.</p>", "body_text": "Seems that in step() of SGD optimizer:\n                d_p = p.grad.data\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n\ngradient is being modified. Yet, Adam does a copy:\n                if group['weight_decay'] != 0:\n                    grad = grad.add(group['weight_decay'], p.data)\n\nThis behavior should be documented for both optimizers.\nI find it very unintuitive and surprising that gradients can be modified in simple, single step (the one without reevaluation closure), but I guess there could be some reason and that is intended behavior so I am filing this under documentation.", "body": "Seems that in step() of SGD optimizer:\r\n```\r\n                d_p = p.grad.data\r\n                if weight_decay != 0:\r\n                    d_p.add_(weight_decay, p.data)\r\n```\r\ngradient is being modified. Yet, Adam does a copy:\r\n```\r\n                if group['weight_decay'] != 0:\r\n                    grad = grad.add(group['weight_decay'], p.data)\r\n```\r\nThis behavior should be documented for both optimizers.\r\n\r\nI find it very unintuitive and surprising that gradients can be modified in simple, single step (the one without reevaluation closure), but I guess there could be some reason and that is intended behavior so I am filing this under documentation."}