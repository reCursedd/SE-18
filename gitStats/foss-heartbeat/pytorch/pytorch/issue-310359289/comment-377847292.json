{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377847292", "html_url": "https://github.com/pytorch/pytorch/issues/6176#issuecomment-377847292", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6176", "id": 377847292, "node_id": "MDEyOklzc3VlQ29tbWVudDM3Nzg0NzI5Mg==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-02T03:40:38Z", "updated_at": "2018-04-02T03:40:38Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This has been fixed on master:</p>\n<pre><code>In [6]: import torch\n   ...: input_size = 3\n   ...: hidden_size = 4\n   ...: model = nn.GRUCell(input_size, hidden_size, False).cuda()\n   ...: x = torch.randn(5, input_size).cuda()\n   ...: h = torch.randn(2, hidden_size).cuda()\n   ...: model(x, h)\n   ...:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-6-8b15dfb6b3f5&gt; in &lt;module&gt;()\n      5 x = torch.randn(5, input_size).cuda()\n      6 h = torch.randn(2, hidden_size).cuda()\n----&gt; 7 model(x, h)\n\n~/pytorch/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    369             result = self._slow_forward(*input, **kwargs)\n    370         else:\n--&gt; 371             result = self.forward(*input, **kwargs)\n    372         for hook in self._forward_hooks.values():\n    373             hook_result = hook(self, input, result)\n\n~/pytorch/torch/nn/modules/rnn.py in forward(self, input, hx)\n    754     def forward(self, input, hx):\n    755         self.check_forward_input(input)\n--&gt; 756         self.check_forward_hidden(input, hx)\n    757         return self._backend.GRUCell(\n    758             input, hx,\n\n~/pytorch/torch/nn/modules/rnn.py in check_forward_hidden(self, input, hx, hidden_label\n)\n    507             raise RuntimeError(\n    508                 \"Input batch size {} doesn't match hidden{} batch size {}\".form\nat(\n--&gt; 509                     input.size(0), hidden_label, hx.size(0)))\n    510\n    511         if hx.size(1) != self.hidden_size:\n\nRuntimeError: Input batch size 5 doesn't match hidden batch size 2\n</code></pre>\n<p>@Zenol, I'm not sure if this is exactly how you're triggering your error. If you could provide a code snippet to confirm that would be great.</p>", "body_text": "This has been fixed on master:\nIn [6]: import torch\n   ...: input_size = 3\n   ...: hidden_size = 4\n   ...: model = nn.GRUCell(input_size, hidden_size, False).cuda()\n   ...: x = torch.randn(5, input_size).cuda()\n   ...: h = torch.randn(2, hidden_size).cuda()\n   ...: model(x, h)\n   ...:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-6-8b15dfb6b3f5> in <module>()\n      5 x = torch.randn(5, input_size).cuda()\n      6 h = torch.randn(2, hidden_size).cuda()\n----> 7 model(x, h)\n\n~/pytorch/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    369             result = self._slow_forward(*input, **kwargs)\n    370         else:\n--> 371             result = self.forward(*input, **kwargs)\n    372         for hook in self._forward_hooks.values():\n    373             hook_result = hook(self, input, result)\n\n~/pytorch/torch/nn/modules/rnn.py in forward(self, input, hx)\n    754     def forward(self, input, hx):\n    755         self.check_forward_input(input)\n--> 756         self.check_forward_hidden(input, hx)\n    757         return self._backend.GRUCell(\n    758             input, hx,\n\n~/pytorch/torch/nn/modules/rnn.py in check_forward_hidden(self, input, hx, hidden_label\n)\n    507             raise RuntimeError(\n    508                 \"Input batch size {} doesn't match hidden{} batch size {}\".form\nat(\n--> 509                     input.size(0), hidden_label, hx.size(0)))\n    510\n    511         if hx.size(1) != self.hidden_size:\n\nRuntimeError: Input batch size 5 doesn't match hidden batch size 2\n\n@Zenol, I'm not sure if this is exactly how you're triggering your error. If you could provide a code snippet to confirm that would be great.", "body": "This has been fixed on master:\r\n```\r\nIn [6]: import torch\r\n   ...: input_size = 3\r\n   ...: hidden_size = 4\r\n   ...: model = nn.GRUCell(input_size, hidden_size, False).cuda()\r\n   ...: x = torch.randn(5, input_size).cuda()\r\n   ...: h = torch.randn(2, hidden_size).cuda()\r\n   ...: model(x, h)\r\n   ...:\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-6-8b15dfb6b3f5> in <module>()\r\n      5 x = torch.randn(5, input_size).cuda()\r\n      6 h = torch.randn(2, hidden_size).cuda()\r\n----> 7 model(x, h)\r\n\r\n~/pytorch/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    369             result = self._slow_forward(*input, **kwargs)\r\n    370         else:\r\n--> 371             result = self.forward(*input, **kwargs)\r\n    372         for hook in self._forward_hooks.values():\r\n    373             hook_result = hook(self, input, result)\r\n\r\n~/pytorch/torch/nn/modules/rnn.py in forward(self, input, hx)\r\n    754     def forward(self, input, hx):\r\n    755         self.check_forward_input(input)\r\n--> 756         self.check_forward_hidden(input, hx)\r\n    757         return self._backend.GRUCell(\r\n    758             input, hx,\r\n\r\n~/pytorch/torch/nn/modules/rnn.py in check_forward_hidden(self, input, hx, hidden_label\r\n)\r\n    507             raise RuntimeError(\r\n    508                 \"Input batch size {} doesn't match hidden{} batch size {}\".form\r\nat(\r\n--> 509                     input.size(0), hidden_label, hx.size(0)))\r\n    510\r\n    511         if hx.size(1) != self.hidden_size:\r\n\r\nRuntimeError: Input batch size 5 doesn't match hidden batch size 2\r\n```\r\n@Zenol, I'm not sure if this is exactly how you're triggering your error. If you could provide a code snippet to confirm that would be great."}