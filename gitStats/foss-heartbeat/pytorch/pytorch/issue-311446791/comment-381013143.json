{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/381013143", "html_url": "https://github.com/pytorch/pytorch/pull/6298#issuecomment-381013143", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6298", "id": 381013143, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTAxMzE0Mw==", "user": {"login": "salexspb", "id": 20307328, "node_id": "MDQ6VXNlcjIwMzA3MzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/20307328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/salexspb", "html_url": "https://github.com/salexspb", "followers_url": "https://api.github.com/users/salexspb/followers", "following_url": "https://api.github.com/users/salexspb/following{/other_user}", "gists_url": "https://api.github.com/users/salexspb/gists{/gist_id}", "starred_url": "https://api.github.com/users/salexspb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/salexspb/subscriptions", "organizations_url": "https://api.github.com/users/salexspb/orgs", "repos_url": "https://api.github.com/users/salexspb/repos", "events_url": "https://api.github.com/users/salexspb/events{/privacy}", "received_events_url": "https://api.github.com/users/salexspb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-13T03:44:59Z", "updated_at": "2018-04-13T03:44:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1215413\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/harrysummer\">@harrysummer</a>, let me clarify a bit more here. Basically we already  have a PredictorBase class internally. And there is GPU predictor as well. I am trying to avoid code replication.<br>\nRegarding MetaNetDef support - it is not really there, the idea behind MetaNetDef is that weights are read from a DB, not from init_net. Storing weights protobufs has 2GB limitation which doesn't work for all models.</p>\n<p>How urgent is this matter for you? I wonder if you could fork Predictor in your own project for now?<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4958441\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jerryzh168\">@jerryzh168</a> is working on the OSS version of Predictor and we can prioritize the GPU version open-source to get you unblocked.</p>\n<p>Basically after ThreadLocalPtr change lands (which needs may be a few more days) we would need to do some minor code clean up and ready to move internal predictors out.</p>", "body_text": "@harrysummer, let me clarify a bit more here. Basically we already  have a PredictorBase class internally. And there is GPU predictor as well. I am trying to avoid code replication.\nRegarding MetaNetDef support - it is not really there, the idea behind MetaNetDef is that weights are read from a DB, not from init_net. Storing weights protobufs has 2GB limitation which doesn't work for all models.\nHow urgent is this matter for you? I wonder if you could fork Predictor in your own project for now?\n@jerryzh168 is working on the OSS version of Predictor and we can prioritize the GPU version open-source to get you unblocked.\nBasically after ThreadLocalPtr change lands (which needs may be a few more days) we would need to do some minor code clean up and ready to move internal predictors out.", "body": "@harrysummer, let me clarify a bit more here. Basically we already  have a PredictorBase class internally. And there is GPU predictor as well. I am trying to avoid code replication. \r\nRegarding MetaNetDef support - it is not really there, the idea behind MetaNetDef is that weights are read from a DB, not from init_net. Storing weights protobufs has 2GB limitation which doesn't work for all models.\r\n\r\nHow urgent is this matter for you? I wonder if you could fork Predictor in your own project for now? \r\n@jerryzh168 is working on the OSS version of Predictor and we can prioritize the GPU version open-source to get you unblocked. \r\n\r\nBasically after ThreadLocalPtr change lands (which needs may be a few more days) we would need to do some minor code clean up and ready to move internal predictors out. "}