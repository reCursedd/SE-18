{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428359000", "html_url": "https://github.com/pytorch/pytorch/issues/2474#issuecomment-428359000", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2474", "id": 428359000, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODM1OTAwMA==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-09T21:28:04Z", "updated_at": "2018-10-09T21:28:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We have switched to using <code>mp.Queue</code> (not <code>SimpleQueue</code>) now. I tested the above code on master. Interestingly, it makes the worker segfault. It works with <code>num_workers=0</code>.</p>\n<p>I adapted as following to make it run:</p>\n<pre><code>import torch.utils.data\n\nclass Dataset(object):\n  def __len__(self):\n    return 100\n\n  def __getitem__(self, i):\n    return list(range(100000))\n\n\nclass Sampler(torch.utils.data.Sampler):\n  def __iter__(self):\n    return (range(100000) for batch_ind in range(100))\n\n  def __len__(self):\n    return 100\n\nd = torch.utils.data.DataLoader(dataset = Dataset(), sampler = Sampler(None), num_workers = 0)\nfor i, x in enumerate(d):\n    print(i)\n    \n</code></pre>", "body_text": "We have switched to using mp.Queue (not SimpleQueue) now. I tested the above code on master. Interestingly, it makes the worker segfault. It works with num_workers=0.\nI adapted as following to make it run:\nimport torch.utils.data\n\nclass Dataset(object):\n  def __len__(self):\n    return 100\n\n  def __getitem__(self, i):\n    return list(range(100000))\n\n\nclass Sampler(torch.utils.data.Sampler):\n  def __iter__(self):\n    return (range(100000) for batch_ind in range(100))\n\n  def __len__(self):\n    return 100\n\nd = torch.utils.data.DataLoader(dataset = Dataset(), sampler = Sampler(None), num_workers = 0)\nfor i, x in enumerate(d):\n    print(i)", "body": "We have switched to using `mp.Queue` (not `SimpleQueue`) now. I tested the above code on master. Interestingly, it makes the worker segfault. It works with `num_workers=0`.\r\n\r\nI adapted as following to make it run:\r\n```\r\nimport torch.utils.data\r\n\r\nclass Dataset(object):\r\n  def __len__(self):\r\n    return 100\r\n\r\n  def __getitem__(self, i):\r\n    return list(range(100000))\r\n\r\n\r\nclass Sampler(torch.utils.data.Sampler):\r\n  def __iter__(self):\r\n    return (range(100000) for batch_ind in range(100))\r\n\r\n  def __len__(self):\r\n    return 100\r\n\r\nd = torch.utils.data.DataLoader(dataset = Dataset(), sampler = Sampler(None), num_workers = 0)\r\nfor i, x in enumerate(d):\r\n    print(i)\r\n    \r\n```"}