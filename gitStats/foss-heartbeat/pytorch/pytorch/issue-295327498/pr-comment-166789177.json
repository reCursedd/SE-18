{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166789177", "pull_request_review_id": 94906614, "id": 166789177, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Njc4OTE3Nw==", "diff_hunk": "@@ -159,171 +264,135 @@ struct VariableViewImpl : public VariableImpl {\n   Variable base;\n \n   // The value of the version_counter at the time grad_fn was created. The\n-  // _grad_fn field is stale if attr_version != version_counter.current_version()\n-  int attr_version;\n+  // grad_fn field is stale if attr_version !=\n+  // version_counter.current_version()\n+  uint32_t attr_version = 0;\n };\n \n-inline Variable make_variable(at::Tensor data, bool requires_grad=false) {\n-  if (!data.defined()) {\n-    return Variable();\n-  }\n+//===----------------------------------------------------------------------===//\n+//                        Variable Implementation\n+//===----------------------------------------------------------------------===//\n \n-#ifndef WITH_SCALARS\n-  if (data.dim() == 0) {\n-    // don't expose 0-dim tensors to Variable API.\n-    data = data.as_strided_({1}, {1});\n-  }\n-#endif\n+inline Variable::Variable(Variable::Impl* self, bool retain)\n+    : at::Tensor(self, retain) {}\n \n-  return Variable(new VariableImpl(std::move(data), requires_grad), false);\n+inline const std::shared_ptr<Function>& Variable::grad_fn() const {\n+  return get()->get_grad_fn();\n }\n \n-inline Variable make_variable(at::Tensor data, int output_nr, std::shared_ptr<Function> grad_fn) {\n-  if (!data.defined()) {\n-    return Variable();\n-  }\n-\n-#ifndef WITH_SCALARS\n-  if (data.dim() == 0) {\n-    // don't expose 0-dim tensors to Variable API.\n-    data = data.as_strided_({1}, {1});\n-  }\n-#endif\n+inline void Variable::set_grad_accumulator(\n+    std::weak_ptr<Function> grad_accumulator) {\n+  get()->grad_accumulator = std::move(grad_accumulator);\n+}\n \n-  return Variable(new VariableImpl(std::move(data), false, output_nr, std::move(grad_fn)), false);\n+inline std::shared_ptr<Function> Variable::try_get_grad_accumulator() const {\n+  return get()->grad_accumulator.lock();\n }\n \n-Variable make_variable(at::Tensor data, std::shared_ptr<Function> grad_fn);\n+inline std::shared_ptr<Function> Variable::grad_accumulator() const {\n+  return get()->get_grad_accumulator();\n+}\n \n-inline Variable make_variable_view(Variable base, at::Tensor data, int output_nr=0,\n-                                   std::shared_ptr<Function> grad_fn=nullptr) {\n-  if (!data.defined()) {\n-    return Variable();\n-  }\n+inline void Variable::set_gradient_edge(Edge&& edge) {\n+  get()->grad_fn = std::move(edge.function);\n+  get()->output_nr = edge.input_nr;\n+}\n \n-#ifndef WITH_SCALARS\n-  if (data.dim() == 0) {\n-    // don't expose 0-dim tensors to Variable API.\n-    data = data.as_strided_({1}, {1});\n-  }\n-#endif\n+inline int Variable::output_nr() const noexcept {\n+  return get()->output_nr;\n+}\n \n-  return Variable(new VariableViewImpl(std::move(base), std::move(data), output_nr, std::move(grad_fn)), false);\n+inline void Variable::set_requires_grad(bool requires_grad) {\n+  get()->requires_grad = requires_grad;\n }\n \n+inline void Variable::set_pyobj(PyObject* pyobj) {\n+  get()->pyobj = pyobj;\n+}\n \n-inline Variable::Variable(VariableImpl * self, bool retain) : Tensor(self, retain) {\n+inline PyObject* Variable::pyobj() const noexcept {", "path": "torch/csrc/autograd/variable.h", "position": null, "original_position": 435, "commit_id": "eba1e177795cddcd1971096dbccdcd81e0dcd773", "original_commit_id": "2770506f74aa5bd4f0a6c4a3dee541a6e8e4250c", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Is there a reason why you only mark so few things `noexcept`? E.g. `set_pyobj` can't throw either", "created_at": "2018-02-07T23:22:07Z", "updated_at": "2018-11-23T15:39:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/5127#discussion_r166789177", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5127", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/166789177"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5127#discussion_r166789177"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5127"}}, "body_html": "<p>Is there a reason why you only mark so few things <code>noexcept</code>? E.g. <code>set_pyobj</code> can't throw either</p>", "body_text": "Is there a reason why you only mark so few things noexcept? E.g. set_pyobj can't throw either"}