{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6996", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6996/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6996/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6996/events", "html_url": "https://github.com/pytorch/pytorch/issues/6996", "id": 318087022, "node_id": "MDU6SXNzdWUzMTgwODcwMjI=", "number": 6996, "title": "[pytorch][0.4][bug] \"torch.min\" and \"torch.max\" ignores \"nan\" in cuda case and crash with pure \"nan\" tensor", "user": {"login": "sytrus-in-github", "id": 12224616, "node_id": "MDQ6VXNlcjEyMjI0NjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/12224616?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sytrus-in-github", "html_url": "https://github.com/sytrus-in-github", "followers_url": "https://api.github.com/users/sytrus-in-github/followers", "following_url": "https://api.github.com/users/sytrus-in-github/following{/other_user}", "gists_url": "https://api.github.com/users/sytrus-in-github/gists{/gist_id}", "starred_url": "https://api.github.com/users/sytrus-in-github/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sytrus-in-github/subscriptions", "organizations_url": "https://api.github.com/users/sytrus-in-github/orgs", "repos_url": "https://api.github.com/users/sytrus-in-github/repos", "events_url": "https://api.github.com/users/sytrus-in-github/events{/privacy}", "received_events_url": "https://api.github.com/users/sytrus-in-github/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-04-26T15:39:24Z", "updated_at": "2018-04-30T19:03:08Z", "closed_at": "2018-04-30T19:03:08Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p><code>torch.min</code> and <code>torch.max</code> ignores <code>nan</code> in cuda case and crash with pure <code>nan</code> tensor.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> torch.Tensor(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">3</span>).fill_(<span class=\"pl-c1\">1</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> a.cuda()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>nan<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a\ntensor([[  <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.],\n        [  <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>., nan.],\n        [  <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.],\n        [  <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.,   <span class=\"pl-c1\">1</span>.]], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.max(a)\ntensor(<span class=\"pl-c1\">1</span>., <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.min(a)\ntensor(<span class=\"pl-c1\">1</span>., <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:0<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> torch.Tensor(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">3</span>).fill_(<span class=\"pl-c1\">float</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>nan<span class=\"pl-pds\">'</span></span>))\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> a <span class=\"pl-k\">=</span> a.cuda()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.max(a)\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/tensor.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">57</span>, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__repr__</span>\n    <span class=\"pl-k\">return</span> torch._tensor_str._str(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">218</span>, <span class=\"pl-k\">in</span> _str\n    fmt, scale, sz <span class=\"pl-k\">=</span> _number_format(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">96</span>, <span class=\"pl-k\">in</span> _number_format\n    <span class=\"pl-k\">if</span> value <span class=\"pl-k\">!=</span> math.ceil(value.item()):\n<span class=\"pl-c1\">RuntimeError</span>: Overflow when unpacking <span class=\"pl-v\">long</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.min(a)\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/tensor.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">57</span>, <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__repr__</span>\n    <span class=\"pl-k\">return</span> torch._tensor_str._str(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">218</span>, <span class=\"pl-k\">in</span> _str\n    fmt, scale, sz <span class=\"pl-k\">=</span> _number_format(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">96</span>, <span class=\"pl-k\">in</span> _number_format\n    <span class=\"pl-k\">if</span> value <span class=\"pl-k\">!=</span> math.ceil(value.item()):\n<span class=\"pl-c1\">RuntimeError</span>: Overflow when unpacking <span class=\"pl-v\">long</span></pre></div>\n<h2>System Info</h2>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): conda</li>\n<li>Build command you used (if compiling from source):</li>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: 0.4.0</li>\n<li>Python version: 3.6.3</li>\n<li>CUDA/cuDNN version: 8 / 5</li>\n<li>GPU models and configuration: GTX 1050 Ti</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>", "body_text": "Issue description\ntorch.min and torch.max ignores nan in cuda case and crash with pure nan tensor.\nCode example\n>>> import torch\n>>> a = torch.Tensor(4, 3).fill_(1)\n>>> a = a.cuda()\n>>> a[1, 2] = float('nan')\n>>> a\ntensor([[  1.,   1.,   1.],\n        [  1.,   1., nan.],\n        [  1.,   1.,   1.],\n        [  1.,   1.,   1.]], device='cuda:0')\n>>> torch.max(a)\ntensor(1., device='cuda:0')\n>>> torch.min(a)\ntensor(1., device='cuda:0')\n>>> a = torch.Tensor(4, 3).fill_(float('nan'))\n>>> a = a.cuda()\n>>> torch.max(a)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 57, in __repr__\n    return torch._tensor_str._str(self)\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 218, in _str\n    fmt, scale, sz = _number_format(self)\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 96, in _number_format\n    if value != math.ceil(value.item()):\nRuntimeError: Overflow when unpacking long\n>>> torch.min(a)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 57, in __repr__\n    return torch._tensor_str._str(self)\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 218, in _str\n    fmt, scale, sz = _number_format(self)\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 96, in _number_format\n    if value != math.ceil(value.item()):\nRuntimeError: Overflow when unpacking long\nSystem Info\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): conda\nBuild command you used (if compiling from source):\nOS: Ubuntu 16.04\nPyTorch version: 0.4.0\nPython version: 3.6.3\nCUDA/cuDNN version: 8 / 5\nGPU models and configuration: GTX 1050 Ti\nGCC version (if compiling from source):\nCMake version:\nVersions of any other relevant libraries:", "body": "## Issue description\r\n\r\n`torch.min` and `torch.max` ignores `nan` in cuda case and crash with pure `nan` tensor.\r\n\r\n## Code example\r\n```python\r\n>>> import torch\r\n>>> a = torch.Tensor(4, 3).fill_(1)\r\n>>> a = a.cuda()\r\n>>> a[1, 2] = float('nan')\r\n>>> a\r\ntensor([[  1.,   1.,   1.],\r\n        [  1.,   1., nan.],\r\n        [  1.,   1.,   1.],\r\n        [  1.,   1.,   1.]], device='cuda:0')\r\n>>> torch.max(a)\r\ntensor(1., device='cuda:0')\r\n>>> torch.min(a)\r\ntensor(1., device='cuda:0')\r\n>>> a = torch.Tensor(4, 3).fill_(float('nan'))\r\n>>> a = a.cuda()\r\n>>> torch.max(a)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 57, in __repr__\r\n    return torch._tensor_str._str(self)\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 218, in _str\r\n    fmt, scale, sz = _number_format(self)\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 96, in _number_format\r\n    if value != math.ceil(value.item()):\r\nRuntimeError: Overflow when unpacking long\r\n>>> torch.min(a)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 57, in __repr__\r\n    return torch._tensor_str._str(self)\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 218, in _str\r\n    fmt, scale, sz = _number_format(self)\r\n  File \"anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py\", line 96, in _number_format\r\n    if value != math.ceil(value.item()):\r\nRuntimeError: Overflow when unpacking long\r\n```\r\n## System Info\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): conda\r\n- Build command you used (if compiling from source):\r\n- OS: Ubuntu 16.04\r\n- PyTorch version: 0.4.0\r\n- Python version: 3.6.3\r\n- CUDA/cuDNN version: 8 / 5\r\n- GPU models and configuration: GTX 1050 Ti\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Versions of any other relevant libraries:\r\n"}