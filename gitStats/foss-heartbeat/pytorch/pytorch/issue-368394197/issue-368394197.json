{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12501", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12501/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12501/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12501/events", "html_url": "https://github.com/pytorch/pytorch/issues/12501", "id": 368394197, "node_id": "MDU6SXNzdWUzNjgzOTQxOTc=", "number": 12501, "title": "C++: Calling Workspace::RunNet for a prediction on a different thread each time causes a GPU memory leak", "user": {"login": "amine85", "id": 5942416, "node_id": "MDQ6VXNlcjU5NDI0MTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5942416?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amine85", "html_url": "https://github.com/amine85", "followers_url": "https://api.github.com/users/amine85/followers", "following_url": "https://api.github.com/users/amine85/following{/other_user}", "gists_url": "https://api.github.com/users/amine85/gists{/gist_id}", "starred_url": "https://api.github.com/users/amine85/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amine85/subscriptions", "organizations_url": "https://api.github.com/users/amine85/orgs", "repos_url": "https://api.github.com/users/amine85/repos", "events_url": "https://api.github.com/users/amine85/events{/privacy}", "received_events_url": "https://api.github.com/users/amine85/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-10-09T20:56:01Z", "updated_at": "2018-10-18T23:12:23Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Hi,<br>\nI am trying to obtain a model prediction (on GPU) while running another piece of code in parallel (on CPU). Since I am streaming data, I instantiate a separate std::thread (or std::async) every time to call Workspace::RunNet, this causes a GPU memory leak which is not noticeable unless you are streaming data. However, if the thread used is maintained (a worker thread with the same thread_id), the leak does not occur.<br>\nThank you,</p>\n\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Given a pre-trained model, please use the following sample code to reproduce the issue:</li>\n</ol>\n\n<pre><code>// Network setup\n\ncaffe2::NetDef init_net;\ncaffe2::NetDef predict_net;\nReadProtoFromFile(init_file, &amp;init_net);\nReadProtoFromFile(predict_file, &amp;predict_net);\nauto  workspace = std::make_unique&lt;caffe2::Workspace&gt;();\nconst auto cuda_device = caffe2::TypeToProto(caffe2::CUDA);\npredict_net.mutable_device_option()-&gt;set_device_type(cuda_device);\ninit_net.mutable_device_option()-&gt;set_device_type(cuda_device);\nworkspace-&gt;CreateBlob(predict_net_.external_input(0));\nworkspace-&gt;RunNetOnce(init_net);\nworkspace-&gt;CreateNet(predict_net);\n\n// Tensors setup\n\nauto input_host_tensor = std::make_unique&lt;caffe2::TensorCPU&gt;(dims, caffe2::CPU);\ninput_host_tensor-&gt;ShareExternalPointer(some_buffer);  // some_buffer will be filled with the input data\nauto input_device_tensor = std::make_unique&lt;caffe2::TensorCUDA&gt;(dims, caffe2::CUDA);\nworkspace-&gt;GetBlob(predict_net_.external_input(0))-&gt;Reset(input_device_tensor.get());\n \n// Prediction\n\nwhile(true) {\n   FetchData(some_buffer);\n   input_device_tensor-&gt;CopyFrom(*input_host_tensor);\n\n  // This is where the leak occurs\n   std::thread my_thread(&amp;caffe2::Workspace::RunNet, workspace.get(), predict_net.name());\n\n  //\n  // some host code\n  //\n\n  my_thread.join();\n}\n\n</code></pre>\n<h2>Expected behavior</h2>\n<p>Not expecting a memory leak when executing on threads with different thread ids.</p>\n\n<h2>Environment</h2>\n<pre><code>Linux=Ubuntu 16.04.4 LTS\ncmake 3.5.1\ngcc 5.4.0\nNVIDIA CUDA 8.0\nNVIDIA cuDNN v6.0\nPytorch built from source (version to date is v1.0rc1)\n</code></pre>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\nHi,\nI am trying to obtain a model prediction (on GPU) while running another piece of code in parallel (on CPU). Since I am streaming data, I instantiate a separate std::thread (or std::async) every time to call Workspace::RunNet, this causes a GPU memory leak which is not noticeable unless you are streaming data. However, if the thread used is maintained (a worker thread with the same thread_id), the leak does not occur.\nThank you,\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nGiven a pre-trained model, please use the following sample code to reproduce the issue:\n\n\n// Network setup\n\ncaffe2::NetDef init_net;\ncaffe2::NetDef predict_net;\nReadProtoFromFile(init_file, &init_net);\nReadProtoFromFile(predict_file, &predict_net);\nauto  workspace = std::make_unique<caffe2::Workspace>();\nconst auto cuda_device = caffe2::TypeToProto(caffe2::CUDA);\npredict_net.mutable_device_option()->set_device_type(cuda_device);\ninit_net.mutable_device_option()->set_device_type(cuda_device);\nworkspace->CreateBlob(predict_net_.external_input(0));\nworkspace->RunNetOnce(init_net);\nworkspace->CreateNet(predict_net);\n\n// Tensors setup\n\nauto input_host_tensor = std::make_unique<caffe2::TensorCPU>(dims, caffe2::CPU);\ninput_host_tensor->ShareExternalPointer(some_buffer);  // some_buffer will be filled with the input data\nauto input_device_tensor = std::make_unique<caffe2::TensorCUDA>(dims, caffe2::CUDA);\nworkspace->GetBlob(predict_net_.external_input(0))->Reset(input_device_tensor.get());\n \n// Prediction\n\nwhile(true) {\n   FetchData(some_buffer);\n   input_device_tensor->CopyFrom(*input_host_tensor);\n\n  // This is where the leak occurs\n   std::thread my_thread(&caffe2::Workspace::RunNet, workspace.get(), predict_net.name());\n\n  //\n  // some host code\n  //\n\n  my_thread.join();\n}\n\n\nExpected behavior\nNot expecting a memory leak when executing on threads with different thread ids.\n\nEnvironment\nLinux=Ubuntu 16.04.4 LTS\ncmake 3.5.1\ngcc 5.4.0\nNVIDIA CUDA 8.0\nNVIDIA cuDNN v6.0\nPytorch built from source (version to date is v1.0rc1)\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\nHi, \r\nI am trying to obtain a model prediction (on GPU) while running another piece of code in parallel (on CPU). Since I am streaming data, I instantiate a separate std::thread (or std::async) every time to call Workspace::RunNet, this causes a GPU memory leak which is not noticeable unless you are streaming data. However, if the thread used is maintained (a worker thread with the same thread_id), the leak does not occur.\r\nThank you,\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\nSteps to reproduce the behavior:\r\n1. Given a pre-trained model, please use the following sample code to reproduce the issue:\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n```\r\n// Network setup\r\n\r\ncaffe2::NetDef init_net;\r\ncaffe2::NetDef predict_net;\r\nReadProtoFromFile(init_file, &init_net);\r\nReadProtoFromFile(predict_file, &predict_net);\r\nauto  workspace = std::make_unique<caffe2::Workspace>();\r\nconst auto cuda_device = caffe2::TypeToProto(caffe2::CUDA);\r\npredict_net.mutable_device_option()->set_device_type(cuda_device);\r\ninit_net.mutable_device_option()->set_device_type(cuda_device);\r\nworkspace->CreateBlob(predict_net_.external_input(0));\r\nworkspace->RunNetOnce(init_net);\r\nworkspace->CreateNet(predict_net);\r\n\r\n// Tensors setup\r\n\r\nauto input_host_tensor = std::make_unique<caffe2::TensorCPU>(dims, caffe2::CPU);\r\ninput_host_tensor->ShareExternalPointer(some_buffer);  // some_buffer will be filled with the input data\r\nauto input_device_tensor = std::make_unique<caffe2::TensorCUDA>(dims, caffe2::CUDA);\r\nworkspace->GetBlob(predict_net_.external_input(0))->Reset(input_device_tensor.get());\r\n \r\n// Prediction\r\n\r\nwhile(true) {\r\n   FetchData(some_buffer);\r\n   input_device_tensor->CopyFrom(*input_host_tensor);\r\n\r\n  // This is where the leak occurs\r\n   std::thread my_thread(&caffe2::Workspace::RunNet, workspace.get(), predict_net.name());\r\n\r\n  //\r\n  // some host code\r\n  //\r\n\r\n  my_thread.join();\r\n}\r\n\r\n```\r\n\r\n## Expected behavior\r\nNot expecting a memory leak when executing on threads with different thread ids.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n```\r\nLinux=Ubuntu 16.04.4 LTS\r\ncmake 3.5.1\r\ngcc 5.4.0\r\nNVIDIA CUDA 8.0\r\nNVIDIA cuDNN v6.0\r\nPytorch built from source (version to date is v1.0rc1)\r\n```\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}