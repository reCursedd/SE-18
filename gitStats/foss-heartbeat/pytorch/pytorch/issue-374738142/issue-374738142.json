{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13224", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13224/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13224/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13224/events", "html_url": "https://github.com/pytorch/pytorch/issues/13224", "id": 374738142, "node_id": "MDU6SXNzdWUzNzQ3MzgxNDI=", "number": 13224, "title": "Caffe2: Causes error when using flag remove_legacy_pad while converting from caffe to caffe2", "user": {"login": "parth1595", "id": 21214965, "node_id": "MDQ6VXNlcjIxMjE0OTY1", "avatar_url": "https://avatars1.githubusercontent.com/u/21214965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parth1595", "html_url": "https://github.com/parth1595", "followers_url": "https://api.github.com/users/parth1595/followers", "following_url": "https://api.github.com/users/parth1595/following{/other_user}", "gists_url": "https://api.github.com/users/parth1595/gists{/gist_id}", "starred_url": "https://api.github.com/users/parth1595/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parth1595/subscriptions", "organizations_url": "https://api.github.com/users/parth1595/orgs", "repos_url": "https://api.github.com/users/parth1595/repos", "events_url": "https://api.github.com/users/parth1595/events{/privacy}", "received_events_url": "https://api.github.com/users/parth1595/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-28T10:18:58Z", "updated_at": "2018-10-29T17:29:21Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>I was converting basic cat dog model from caffe to caffe2 framework using caffe_translator.py but in conversion it shows a legacy_padding in max pool operation argument which I don't want so i try to remove it using the caffe_translator script in which remove_legacy_pad flag is there which can be enable when we give it in argument while running the script. But it throws some error which I don't know what it is.</p>\n<p><strong>Error Log</strong><br>\nWARNING: Logging before InitGoogleLogging() is written to STDERR<br>\nW1028 15:43:38.935531   680 init.h:99] Caffe2 GlobalInit should be run before any other API calls.<br>\nTraceback (most recent call last):<br>\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 927, in <br>\ninput_dims=input_dims,<br>\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 285, in TranslateModel<br>\nreturn TranslatorRegistry.TranslateModel(*args, **kwargs)<br>\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 280, in TranslateModel<br>\nnet = _RemoveLegacyPad(net, net_params, input_dims)<br>\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 131, in _RemoveLegacyPad<br>\nws.create_blob(external_input).feed_blob(dummy_input)<br>\nAttributeError: 'caffe2.python.caffe2_pybind11_state.Blob' object has no attribute 'feed_blob'</p>", "body_text": "I was converting basic cat dog model from caffe to caffe2 framework using caffe_translator.py but in conversion it shows a legacy_padding in max pool operation argument which I don't want so i try to remove it using the caffe_translator script in which remove_legacy_pad flag is there which can be enable when we give it in argument while running the script. But it throws some error which I don't know what it is.\nError Log\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nW1028 15:43:38.935531   680 init.h:99] Caffe2 GlobalInit should be run before any other API calls.\nTraceback (most recent call last):\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 927, in \ninput_dims=input_dims,\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 285, in TranslateModel\nreturn TranslatorRegistry.TranslateModel(*args, **kwargs)\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 280, in TranslateModel\nnet = _RemoveLegacyPad(net, net_params, input_dims)\nFile \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 131, in _RemoveLegacyPad\nws.create_blob(external_input).feed_blob(dummy_input)\nAttributeError: 'caffe2.python.caffe2_pybind11_state.Blob' object has no attribute 'feed_blob'", "body": "I was converting basic cat dog model from caffe to caffe2 framework using caffe_translator.py but in conversion it shows a legacy_padding in max pool operation argument which I don't want so i try to remove it using the caffe_translator script in which remove_legacy_pad flag is there which can be enable when we give it in argument while running the script. But it throws some error which I don't know what it is. \r\n\r\n**Error Log**\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nW1028 15:43:38.935531   680 init.h:99] Caffe2 GlobalInit should be run before any other API calls.\r\nTraceback (most recent call last):\r\n  File \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 927, in <module>\r\n    input_dims=input_dims,\r\n  File \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 285, in TranslateModel\r\n    return TranslatorRegistry.TranslateModel(*args, **kwargs)\r\n  File \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 280, in TranslateModel\r\n    net = _RemoveLegacyPad(net, net_params, input_dims)\r\n  File \"/home/parthr/project/pytorch/caffe2/python/caffe_translator.py\", line 131, in _RemoveLegacyPad\r\n    ws.create_blob(external_input).feed_blob(dummy_input)\r\nAttributeError: 'caffe2.python.caffe2_pybind11_state.Blob' object has no attribute 'feed_blob'\r\n\r\n"}