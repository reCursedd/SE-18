{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234878156", "pull_request_review_id": 176613651, "id": 234878156, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDg3ODE1Ng==", "diff_hunk": "@@ -0,0 +1,243 @@\n+#include \"THCUNN.h\"\n+#include \"THCTensor.hpp\"\n+#include \"common.h\"\n+#include \"linear_upsampling.h\"\n+#include \"THCDeviceTensor.cuh\"\n+#include \"THCDeviceTensorUtils.cuh\"\n+#include \"THCDeviceUtils.cuh\"\n+#include \"THCHalf.h\"\n+#include \"THCHalfAutoNumerics.cuh\"\n+#include \"THCAtomics.cuh\"\n+\n+__constant__ int size = (1 << 10);\n+\n+template<typename Dtype>\n+__device__ Dtype access_tensor(\n+  const THCDeviceTensor<Dtype, 4> data,\n+  int channel,\n+  int batch,\n+  int width,\n+  int height,\n+  int x,\n+  int y\n+) {\n+  int access_x = max(min(x, width - 1), 0);\n+  int access_y = max(min(y, height - 1), 0);\n+  return data[batch][channel][access_y][access_x];\n+}\n+\n+template<typename Dtype, typename Acctype>\n+__device__ void inc_tensor(\n+  const THCDeviceTensor<Dtype, 4> data,\n+  int channel,\n+  int batch,\n+  int width,\n+  int height,\n+  int x,\n+  int y,\n+  Acctype value\n+) {\n+  int access_x = max(min(x, width - 1), 0);\n+  int access_y = max(min(y, height - 1), 0);\n+  atomicAdd(\n+    data[batch][channel][access_y][access_x].data(),\n+    ScalarConvert<Acctype, Dtype>::to(value)\n+  );\n+}\n+\n+template<typename Acctype>\n+__device__ Acctype bicubic_convolution1(Acctype x, Acctype A) {\n+  return ((A + 2) * x - (A + 3)) * x * x + 1;\n+}\n+\n+template<typename Acctype>\n+__device__ Acctype bicubic_convolution2(Acctype x, Acctype A) {\n+  return ((A * x - 5 * A) * x + 8 * A) * x - 4 * A;\n+}\n+\n+template<typename Acctype>\n+__device__ void THNN_(get_coefficients)(\n+  Acctype coeffs[4],\n+  Acctype t,\n+  int size\n+) {\n+  int offset = t * size;\n+  Acctype A = -0.75;", "path": "aten/src/THCUNN/SpatialUpSamplingBicubic.cu", "position": null, "original_position": 65, "commit_id": "54fcbba8e696cc10c0ab6ebd189e65f7d026b692", "original_commit_id": "e7ac9804da9af0b6bc96e1bbe71282ab01ec7fdc", "user": {"login": "hayatoikoma", "id": 2889812, "node_id": "MDQ6VXNlcjI4ODk4MTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2889812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hayatoikoma", "html_url": "https://github.com/hayatoikoma", "followers_url": "https://api.github.com/users/hayatoikoma/followers", "following_url": "https://api.github.com/users/hayatoikoma/following{/other_user}", "gists_url": "https://api.github.com/users/hayatoikoma/gists{/gist_id}", "starred_url": "https://api.github.com/users/hayatoikoma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hayatoikoma/subscriptions", "organizations_url": "https://api.github.com/users/hayatoikoma/orgs", "repos_url": "https://api.github.com/users/hayatoikoma/repos", "events_url": "https://api.github.com/users/hayatoikoma/events{/privacy}", "received_events_url": "https://api.github.com/users/hayatoikoma/received_events", "type": "User", "site_admin": false}, "body": "I agree with this opinion. Is there any specific reason for the choice of `-0.75` instead of [`-0.5` used in PIL](https://github.com/python-pillow/Pillow/blob/fdbd719da4c77c7e23e2e9e9b71d0d177f2d3369/src/libImaging/Resample.c#L45)? As `torchvision.transforms.functional.resize` uses PIL's `resize`, I may want to assume that the behavior of `interpolation` is the same as in `PIL` / `torchvision` as a PyTorch user.", "created_at": "2018-11-20T06:06:39Z", "updated_at": "2018-11-23T15:55:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/9849#discussion_r234878156", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9849", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/234878156"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9849#discussion_r234878156"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9849"}}, "body_html": "<p>I agree with this opinion. Is there any specific reason for the choice of <code>-0.75</code> instead of <a href=\"https://github.com/python-pillow/Pillow/blob/fdbd719da4c77c7e23e2e9e9b71d0d177f2d3369/src/libImaging/Resample.c#L45\"><code>-0.5</code> used in PIL</a>? As <code>torchvision.transforms.functional.resize</code> uses PIL's <code>resize</code>, I may want to assume that the behavior of <code>interpolation</code> is the same as in <code>PIL</code> / <code>torchvision</code> as a PyTorch user.</p>", "body_text": "I agree with this opinion. Is there any specific reason for the choice of -0.75 instead of -0.5 used in PIL? As torchvision.transforms.functional.resize uses PIL's resize, I may want to assume that the behavior of interpolation is the same as in PIL / torchvision as a PyTorch user.", "in_reply_to_id": 205308494}