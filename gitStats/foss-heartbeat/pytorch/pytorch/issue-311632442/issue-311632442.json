{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6313", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6313/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6313/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6313/events", "html_url": "https://github.com/pytorch/pytorch/issues/6313", "id": 311632442, "node_id": "MDU6SXNzdWUzMTE2MzI0NDI=", "number": 6313, "title": "[utils.bottleneck] Bottleneck crashes with multi-threaded data loader", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-04-05T14:24:31Z", "updated_at": "2018-11-04T17:09:39Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p><code>torch.utils.bottleneck</code> doesn't work properly when the code contains a data loader that uses more than 0 threads.</p>\n<p>Minimum reproducible example (<code>mwe.py</code>):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.utils.data\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    parser <span class=\"pl-k\">=</span> argparse.ArgumentParser(<span class=\"pl-v\">description</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>mwe<span class=\"pl-pds\">'</span></span>)\n    parser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--num-workers<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>)\n    args <span class=\"pl-k\">=</span> parser.parse_args()\n\n    data <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1000</span>)\n    target <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">10</span>)\n    dataset <span class=\"pl-k\">=</span> torch.utils.data.TensorDataset(data, target)\n    data_loader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(dataset,\n        <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span>args.num_workers)\n    <span class=\"pl-k\">for</span> i, batch <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(data_loader):\n        <span class=\"pl-k\">pass</span></pre></div>\n<p>Running the script via:</p>\n<pre><code>python -m torch.utils.bottleneck -- mwe.py --num-workers 0\n</code></pre>\n<p>works fine, while</p>\n<pre><code>python -m torch.utils.bottleneck -- mwe2.py --num-workers 1\n</code></pre>\n<p>crashes with the following stack trace:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 280, in &lt;module&gt;\n    main()\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 261, in main\n    autograd_prof_cpu, autograd_prof_cuda = run_autograd_prof(code, globs)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 155, in run_autograd_prof\n    result.append(run_prof(use_cuda=True))\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 149, in run_prof\n    exec(code, globs, None)\n  File \"mwe2.py\", line 15, in &lt;module&gt;\n    for i, batch in enumerate(data_loader):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 285, in __next__\n    return self._process_next_batch(batch)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 306, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in &lt;listcomp&gt;\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in &lt;genexpr&gt;\n    return tuple(tensor[index] for tensor in self.tensors)\nRuntimeError: /private/home/fmassa/github/pytorch/torch/csrc/autograd/profiler.h:52: initialization error\n</code></pre>\n<p>assigning this to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> , even thought I'm not sure if it's a problem in the profiler or in the <code>bottleneck</code> tool.</p>\n<p>pytorch version <code>'0.4.0a0+b21e135'</code></p>", "body_text": "torch.utils.bottleneck doesn't work properly when the code contains a data loader that uses more than 0 threads.\nMinimum reproducible example (mwe.py):\nimport argparse\nimport torch\nimport torch.utils.data\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='mwe')\n    parser.add_argument('--num-workers', default=0, type=int)\n    args = parser.parse_args()\n\n    data = torch.rand(10, 1000)\n    target = torch.rand(10)\n    dataset = torch.utils.data.TensorDataset(data, target)\n    data_loader = torch.utils.data.DataLoader(dataset,\n        batch_size=2, num_workers=args.num_workers)\n    for i, batch in enumerate(data_loader):\n        pass\nRunning the script via:\npython -m torch.utils.bottleneck -- mwe.py --num-workers 0\n\nworks fine, while\npython -m torch.utils.bottleneck -- mwe2.py --num-workers 1\n\ncrashes with the following stack trace:\nTraceback (most recent call last):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 280, in <module>\n    main()\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 261, in main\n    autograd_prof_cpu, autograd_prof_cuda = run_autograd_prof(code, globs)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 155, in run_autograd_prof\n    result.append(run_prof(use_cuda=True))\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 149, in run_prof\n    exec(code, globs, None)\n  File \"mwe2.py\", line 15, in <module>\n    for i, batch in enumerate(data_loader):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 285, in __next__\n    return self._process_next_batch(batch)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 306, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\nRuntimeError: /private/home/fmassa/github/pytorch/torch/csrc/autograd/profiler.h:52: initialization error\n\nassigning this to @zou3519 , even thought I'm not sure if it's a problem in the profiler or in the bottleneck tool.\npytorch version '0.4.0a0+b21e135'", "body": "`torch.utils.bottleneck` doesn't work properly when the code contains a data loader that uses more than 0 threads.\r\n\r\nMinimum reproducible example (`mwe.py`):\r\n```python\r\nimport argparse\r\nimport torch\r\nimport torch.utils.data\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser(description='mwe')\r\n    parser.add_argument('--num-workers', default=0, type=int)\r\n    args = parser.parse_args()\r\n\r\n    data = torch.rand(10, 1000)\r\n    target = torch.rand(10)\r\n    dataset = torch.utils.data.TensorDataset(data, target)\r\n    data_loader = torch.utils.data.DataLoader(dataset,\r\n        batch_size=2, num_workers=args.num_workers)\r\n    for i, batch in enumerate(data_loader):\r\n        pass\r\n```\r\n\r\nRunning the script via:\r\n```\r\npython -m torch.utils.bottleneck -- mwe.py --num-workers 0\r\n```\r\nworks fine, while\r\n```\r\npython -m torch.utils.bottleneck -- mwe2.py --num-workers 1\r\n```\r\ncrashes with the following stack trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 280, in <module>\r\n    main()\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 261, in main\r\n    autograd_prof_cpu, autograd_prof_cuda = run_autograd_prof(code, globs)\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 155, in run_autograd_prof\r\n    result.append(run_prof(use_cuda=True))\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/bottleneck/__main__.py\", line 149, in run_prof\r\n    exec(code, globs, None)\r\n  File \"mwe2.py\", line 15, in <module>\r\n    for i, batch in enumerate(data_loader):\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 285, in __next__\r\n    return self._process_next_batch(batch)\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 306, in _process_next_batch\r\n    raise batch.exc_type(batch.exc_msg)\r\nRuntimeError: Traceback (most recent call last):\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in __getitem__\r\n    return tuple(tensor[index] for tensor in self.tensors)\r\n  File \"/private/home/fmassa/.conda/envs/detectron_v2/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 40, in <genexpr>\r\n    return tuple(tensor[index] for tensor in self.tensors)\r\nRuntimeError: /private/home/fmassa/github/pytorch/torch/csrc/autograd/profiler.h:52: initialization error\r\n```\r\n\r\nassigning this to @zou3519 , even thought I'm not sure if it's a problem in the profiler or in the `bottleneck` tool.\r\n\r\npytorch version `'0.4.0a0+b21e135'`"}