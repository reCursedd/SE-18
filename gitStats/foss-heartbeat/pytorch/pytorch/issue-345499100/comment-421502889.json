{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/421502889", "html_url": "https://github.com/pytorch/pytorch/issues/9985#issuecomment-421502889", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9985", "id": 421502889, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTUwMjg4OQ==", "user": {"login": "PetrochukM", "id": 7424737, "node_id": "MDQ6VXNlcjc0MjQ3Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7424737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PetrochukM", "html_url": "https://github.com/PetrochukM", "followers_url": "https://api.github.com/users/PetrochukM/followers", "following_url": "https://api.github.com/users/PetrochukM/following{/other_user}", "gists_url": "https://api.github.com/users/PetrochukM/gists{/gist_id}", "starred_url": "https://api.github.com/users/PetrochukM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PetrochukM/subscriptions", "organizations_url": "https://api.github.com/users/PetrochukM/orgs", "repos_url": "https://api.github.com/users/PetrochukM/repos", "events_url": "https://api.github.com/users/PetrochukM/events{/privacy}", "received_events_url": "https://api.github.com/users/PetrochukM/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-14T22:42:46Z", "updated_at": "2018-09-14T22:42:46Z", "author_association": "NONE", "body_html": "<p>Found it, took a couple hours to isolate. <code>DataLoader</code> when interacting with <code>DistributedDataParallel</code> and <code>tqdm</code> tends to break.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> torch <span class=\"pl-k\">import</span> multiprocessing\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> DEPENDANCY: This is required for ``DistributedDataParallel``</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel</span>\n<span class=\"pl-k\">try</span>:\n    multiprocessing.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>spawn<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">except</span> <span class=\"pl-c1\">RuntimeError</span>:\n    <span class=\"pl-k\">pass</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> DEPENDANCY: This is required for ``from tqdm import tqdm``</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74</span>\nmp_lock <span class=\"pl-k\">=</span> multiprocessing.RLock()\n\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    data_iterator <span class=\"pl-k\">=</span> torch.utils.data.DataLoader([torch.tensor(i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)], <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n    <span class=\"pl-k\">for</span> batch <span class=\"pl-k\">in</span> data_iterator:\n        <span class=\"pl-k\">pass</span></pre></div>\n<pre><code>/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n</code></pre>", "body_text": "Found it, took a couple hours to isolate. DataLoader when interacting with DistributedDataParallel and tqdm tends to break.\nfrom torch import multiprocessing\n\n# DEPENDANCY: This is required for ``DistributedDataParallel``\n# https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\ntry:\n    multiprocessing.set_start_method('spawn')\nexcept RuntimeError:\n    pass\n\n# DEPENDANCY: This is required for ``from tqdm import tqdm``\n# https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74\nmp_lock = multiprocessing.RLock()\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nif __name__ == '__main__':\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\n    for batch in data_iterator:\n        pass\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))", "body": "Found it, took a couple hours to isolate. ``DataLoader`` when interacting with ``DistributedDataParallel`` and ``tqdm`` tends to break.\r\n\r\n```python\r\nfrom torch import multiprocessing\r\n\r\n# DEPENDANCY: This is required for ``DistributedDataParallel``\r\n# https://pytorch.org/docs/stable/nn.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\r\ntry:\r\n    multiprocessing.set_start_method('spawn')\r\nexcept RuntimeError:\r\n    pass\r\n\r\n# DEPENDANCY: This is required for ``from tqdm import tqdm``\r\n# https://github.com/tqdm/tqdm/blob/96d8a3c3642474144f53f74331ef2172d1c39496/tqdm/_tqdm.py#L74\r\nmp_lock = multiprocessing.RLock()\r\n\r\nimport torch\r\nfrom torch.utils.data import DataLoader\r\n\r\nif __name__ == '__main__':\r\n    data_iterator = torch.utils.data.DataLoader([torch.tensor(i) for i in range(10)], num_workers=4)\r\n    for batch in data_iterator:\r\n        pass\r\n```\r\n```\r\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n/Users/michaelp/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n```"}