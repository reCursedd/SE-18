{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/194913865", "pull_request_review_id": 128178816, "id": 194913865, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NDkxMzg2NQ==", "diff_hunk": "@@ -0,0 +1,284 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/cuda/CUDAApplyUtils.cuh\"\n+\n+namespace at {\n+namespace cuda {\n+#define MIN_NUMBER_BINS_FOR_GLOBAL_MEM 5000\n+#define FOR_KERNEL_LOOP(i, lim)                                      \\\n+  for (IndexType i = blockIdx.x * blockDim.x + threadIdx.x; i < lim; \\\n+       i += gridDim.x * blockDim.x)\n+\n+/*\n+  Memory types used for the 3 histogram implementations.\n+  See `CUDA_tensor_histogram` below.\n+ */\n+enum class CUDAHistogramMemoryType { SHARED, MULTI_BLOCK, GLOBAL };\n+\n+/*\n+  Kernel for computing the histogram of the input.\n+ */\n+template <\n+    typename output_t,\n+    typename input_t,\n+    typename IndexType,\n+    int ADims,\n+    int PDims,\n+    int BDims,\n+    CUDAHistogramMemoryType MemoryType = CUDAHistogramMemoryType::MULTI_BLOCK,\n+    typename Op>\n+__global__ void kernelHistogram1D(\n+    detail::TensorInfo<output_t, IndexType> a, /* output */\n+    detail::TensorInfo<output_t, IndexType> p, /* partial output */\n+    detail::TensorInfo<input_t, IndexType> b, /* input */\n+    int binsize,\n+    IndexType totalElements,\n+    Op getOp) {\n+  extern __shared__ unsigned char my_smem[];\n+  output_t* smem = nullptr;\n+\n+  if (MemoryType == CUDAHistogramMemoryType::SHARED) {\n+    ////////////////////////// Shared memory //////////////////////////\n+    // atomically add to block specific shared memory\n+    // then atomically add to the global output tensor\n+    smem = reinterpret_cast<output_t*>(my_smem);\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      smem[i] = 0;\n+    }\n+    __syncthreads();\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<input_t, IndexType, BDims>::get(linearIndex, b);\n+      // Use value at `b` as an offset of `smem`\n+      const IndexType pOffset = b.data[bOffset] / binsize;\n+      atomicAdd(&smem[pOffset], getOp(linearIndex));\n+    }\n+    __syncthreads();\n+    // NOTE: atomically update output bin count.\n+    //   Atomic update is imp since __syncthread() will only synchronize threads\n+    //   in a given block, not across blocks.\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      const IndexType aOffset =\n+          detail::IndexToOffset<output_t, IndexType, ADims>::get(i, a);\n+      atomicAdd(&a.data[aOffset], smem[i]);\n+    }\n+\n+  } else if (MemoryType == CUDAHistogramMemoryType::MULTI_BLOCK) {\n+    ////////////////////////// Multi Block memory //////////////////////////\n+    // atomically add to block specific global tensor\n+    // then atomically add to the global output tensor\n+    // compute histogram for the block\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<input_t, IndexType, BDims>::get(linearIndex, b);\n+      const auto bVal = b.data[bOffset];\n+      // Use value at `b` as an offset of `p`\n+      const IndexType pIdx = p.strides[0] * blockIdx.x + bVal / binsize;\n+      const IndexType pOffset =\n+          detail::IndexToOffset<output_t, IndexType, PDims>::get(pIdx, p);\n+      atomicAdd(&p.data[pOffset], getOp(linearIndex));\n+    }\n+    __syncthreads();\n+    // NOTE: atomically update output bin count.\n+    //   Atomic update is imp since __syncthread() will only synchronize threads\n+    //   in a given block, not across blocks.\n+    const IndexType pIdx = p.strides[0] * blockIdx.x;\n+    const IndexType pOffset =\n+        detail::IndexToOffset<output_t, IndexType, PDims>::get(pIdx, p);\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      const IndexType aOffset =\n+          detail::IndexToOffset<output_t, IndexType, ADims>::get(i, a);\n+      atomicAdd(&a.data[aOffset], p.data[pOffset + i]);\n+    }\n+\n+  } else {\n+    ////////////////////////// Global memory //////////////////////////\n+    // atomically add to the output tensor\n+    // compute histogram for the block\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<input_t, IndexType, BDims>::get(linearIndex, b);\n+      const auto bVal = b.data[bOffset];\n+      // Use value at `b` as an offset of `a`\n+      const IndexType aIdx = bVal / binsize;\n+      const IndexType aOffset =\n+          detail::IndexToOffset<output_t, IndexType, ADims>::get(aIdx, a);\n+      atomicAdd(&a.data[aOffset], getOp(linearIndex));\n+    }\n+  }\n+}\n+\n+#define HANDLE_CASE(MEMORY_TYPE, WEIGHTS_OP)                               \\\n+  kernelHistogram1D<output_t, input_t, IndexType, 1, 2, 1, MEMORY_TYPE>    \\\n+      <<<grid,                                                             \\\n+         block,                                                            \\\n+         (MEMORY_TYPE == CUDAHistogramMemoryType::SHARED) ? sharedMem : 0, \\\n+         at::globalContext().getCurrentCUDAStream()>>>(                    \\\n+          aInfo, pInfo, bInfo, binsize, totalElements, WEIGHTS_OP);        \\\n+  AT_ASSERTM(cudaGetLastError() == cudaSuccess, \"kernelHistogram1D failed\");\n+\n+#define HANDLE_SWITCH_CASE(mType, getOp)                        \\\n+  switch (mType) {                                              \\\n+    case CUDAHistogramMemoryType::SHARED:                       \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::SHARED, getOp);      \\\n+      break;                                                    \\\n+    case CUDAHistogramMemoryType::MULTI_BLOCK:                  \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::MULTI_BLOCK, getOp); \\\n+      break;                                                    \\\n+    default:                                                    \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::GLOBAL, getOp);      \\\n+  }\n+\n+/*\n+  Calculate the frequency of the input values.\n+\n+  `a` contains the final output or the histogram.\n+  Input `b` is assumed to be 1-D non-negative int array.\n+  `c` optionally contains the weight vector.\n+  See `help torch.bincount` for details on the math.\n+\n+  3 implementations based of input size and memory usage:\n+    case: #bins < blockDim.x\n+        SHARED: Each block atomically adds to it's own **shared** hist copy,\n+        then atomically updates the global tensor.\n+    case: blockDim.x <= #bins < MIN_NUMBER_BINS_FOR_GLOBAL_MEM\n+        MULTI_BLOCK: Each block atomically adds to it's own **global** hist\n+        copy, then atomically updates the global tensor.\n+    case: MIN_NUMBER_BINS_FOR_GLOBAL_MEM <= #bins\n+        GLOBAL: all threads atomically update to a single **global** hist copy.\n+ */\n+template <typename output_t, typename input_t, bool HasWeights>\n+bool CUDA_tensor_histogram(\n+    at::Tensor a, /* output */\n+    at::Tensor b, /* input */\n+    at::Tensor c, /* weights(optional) */\n+    int64_t nbins,\n+    int binsize,\n+    TensorArgType aType = TensorArgType::ReadWrite,\n+    TensorArgType bType = TensorArgType::ReadOnly,\n+    TensorArgType cType = TensorArgType::ReadOnly) {\n+  checkBackend(\"CUDA_tensor_histogram\", {a, b}, Backend::CUDA);\n+  if (HasWeights) {\n+    checkBackend(\"CUDA_tensor_histogram\", {c}, Backend::CUDA);\n+  }\n+  auto totalElements = b.size(0);\n+\n+  const dim3 block = getApplyBlock();\n+  dim3 grid;\n+  int64_t curDevice = current_device();\n+  if (curDevice == -1)\n+    return false;\n+  if (!getApplyGrid(totalElements, grid, curDevice)) {\n+    return false;\n+  }\n+#if CUDA_VERSION < 9000\n+  grid.x = std::min(\n+      (unsigned int)at::globalContext()\n+              .getCurrentDeviceProperties()\n+              ->multiProcessorCount *\n+          AT_APPLY_BLOCKS_PER_SM,\n+      grid.x);\n+#endif\n+\n+  CUDAHistogramMemoryType memType = CUDAHistogramMemoryType::SHARED;\n+  auto maxSharedMem =\n+      at::globalContext().getCurrentDeviceProperties()->sharedMemPerBlock;\n+  auto sharedMem = nbins * sizeof(output_t) + 8; // 8 guard bytes\n+  // determine memory type to use in the kernel\n+  if (nbins < block.x && sharedMem < maxSharedMem) {\n+    memType = CUDAHistogramMemoryType::SHARED;\n+  } else if (nbins < MIN_NUMBER_BINS_FOR_GLOBAL_MEM) {\n+    memType = CUDAHistogramMemoryType::MULTI_BLOCK;\n+  } else {\n+    memType = CUDAHistogramMemoryType::GLOBAL;\n+  }\n+\n+  // alloc memory for MULTI_BLOCK\n+  using IndexType = int64_t;\n+  auto aInfo = detail::getTensorInfo<output_t, IndexType>(a);\n+  auto bInfo = detail::getTensorInfo<input_t, IndexType>(b);\n+  detail::TensorInfo<output_t, IndexType> pInfo = aInfo;\n+  Tensor partial_output;\n+  if (memType == CUDAHistogramMemoryType::MULTI_BLOCK) {\n+    partial_output = a.type().zeros({grid.x, nbins});", "path": "aten/src/ATen/native/cuda/SummaryOps.cu", "position": null, "original_position": 205, "commit_id": "398cfbc3a790dda0aa46e99b66d0d82b4095a7b1", "original_commit_id": "d2950e4a4fd207caa43e1b952e368c60083279b2", "user": {"login": "chintak", "id": 3398558, "node_id": "MDQ6VXNlcjMzOTg1NTg=", "avatar_url": "https://avatars2.githubusercontent.com/u/3398558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chintak", "html_url": "https://github.com/chintak", "followers_url": "https://api.github.com/users/chintak/followers", "following_url": "https://api.github.com/users/chintak/following{/other_user}", "gists_url": "https://api.github.com/users/chintak/gists{/gist_id}", "starred_url": "https://api.github.com/users/chintak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chintak/subscriptions", "organizations_url": "https://api.github.com/users/chintak/orgs", "repos_url": "https://api.github.com/users/chintak/repos", "events_url": "https://api.github.com/users/chintak/events{/privacy}", "received_events_url": "https://api.github.com/users/chintak/received_events", "type": "User", "site_admin": false}, "body": "I'm seeing how I can use `cudaDeviceProp.totalGlobalMem` to make this decision.", "created_at": "2018-06-12T23:00:59Z", "updated_at": "2018-11-23T15:45:24Z", "html_url": "https://github.com/pytorch/pytorch/pull/6688#discussion_r194913865", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6688", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/194913865"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6688#discussion_r194913865"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6688"}}, "body_html": "<p>I'm seeing how I can use <code>cudaDeviceProp.totalGlobalMem</code> to make this decision.</p>", "body_text": "I'm seeing how I can use cudaDeviceProp.totalGlobalMem to make this decision.", "in_reply_to_id": 194904635}