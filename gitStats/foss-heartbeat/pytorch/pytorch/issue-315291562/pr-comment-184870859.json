{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184870859", "pull_request_review_id": 116154661, "id": 184870859, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDg3MDg1OQ==", "diff_hunk": "@@ -943,5 +944,227 @@ bool CUDA_tensor_apply4(at::Tensor a,\n   return true;\n }\n \n+#define MIN_NUMBER_BINS_FOR_GLOBAL_MEM 5000\n+#define FOR_KERNEL_LOOP(i, lim)                                      \\\n+  for (IndexType i = blockIdx.x * blockDim.x + threadIdx.x; i < lim; \\\n+       i += gridDim.x * blockDim.x)\n+\n+/*\n+  Memory types used for the 3 histogram implementations.\n+  See `CUDA_tensor_histogram` below.\n+ */\n+enum class CUDAHistogramMemoryType { MULTI_BLOCK, SHARED, GLOBAL };\n+\n+/*\n+  Kernel for computing the histogram of the input.\n+ */\n+template <\n+    typename scalar1,\n+    typename scalar2,\n+    typename IndexType,\n+    int ADims,\n+    int PDims,\n+    int BDims,\n+    CUDAHistogramMemoryType MemoryType = CUDAHistogramMemoryType::MULTI_BLOCK,\n+    typename Op>\n+__global__ void kernelHistogram1D(\n+    detail::TensorInfo<scalar1, IndexType> a, /* output */\n+    detail::TensorInfo<scalar1, IndexType> p, /* partial output */\n+    detail::TensorInfo<scalar2, IndexType> b, /* input */\n+    int binsize,\n+    IndexType totalElements,\n+    Op getOp) {\n+  extern __shared__ unsigned char my_smem[];\n+  scalar1* smem = nullptr;\n+\n+  if (MemoryType == CUDAHistogramMemoryType::SHARED) {\n+    ////////////////////////// Shared memory //////////////////////////\n+    // atomically add to block specific shared memory\n+    // then atomically add to the global output tensor\n+    smem = reinterpret_cast<scalar1*>(my_smem);\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      smem[i] = 0;\n+    }\n+    __syncthreads();\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<scalar2, IndexType, BDims>::get(linearIndex, b);\n+      // Use value at `b` as an offset of `smem`\n+      const IndexType pOffset = b.data[bOffset] / binsize;\n+      atomicAdd(&smem[pOffset], getOp(linearIndex));\n+    }\n+    __syncthreads();\n+    // NOTE: atomically update output bin count.\n+    //   Atomic update is imp since __syncthread() will only synchronize threads\n+    //   in a given block, not across blocks.\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      const IndexType aOffset =\n+          detail::IndexToOffset<scalar1, IndexType, ADims>::get(i, a);\n+      atomicAdd(&a.data[aOffset], smem[i]);\n+    }\n+\n+  } else if (MemoryType == CUDAHistogramMemoryType::MULTI_BLOCK) {\n+    ////////////////////////// Multi Block memory //////////////////////////\n+    // atomically add to block specific global tensor\n+    // then atomically add to the global output tensor\n+    // compute histogram for the block\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<scalar2, IndexType, BDims>::get(linearIndex, b);\n+      const auto bVal = b.data[bOffset];\n+      // Use value at `b` as an offset of `p`\n+      const IndexType pIdx = p.strides[0] * blockIdx.x + bVal / binsize;\n+      const IndexType pOffset =\n+          detail::IndexToOffset<scalar1, IndexType, PDims>::get(pIdx, p);\n+      atomicAdd(&p.data[pOffset], getOp(linearIndex));\n+    }\n+    __syncthreads();\n+    // NOTE: atomically update output bin count.\n+    //   Atomic update is imp since __syncthread() will only synchronize threads\n+    //   in a given block, not across blocks.\n+    const IndexType pIdx = p.strides[0] * blockIdx.x;\n+    const IndexType pOffset =\n+        detail::IndexToOffset<scalar1, IndexType, PDims>::get(pIdx, p);\n+    for (IndexType i = threadIdx.x; i < a.sizes[0]; i += blockDim.x) {\n+      const IndexType aOffset =\n+          detail::IndexToOffset<scalar1, IndexType, ADims>::get(i, a);\n+      atomicAdd(&a.data[aOffset], p.data[pOffset + i]);\n+    }\n+\n+  } else {\n+    ////////////////////////// Global memory //////////////////////////\n+    // atomically add to the output tensor\n+    // compute histogram for the block\n+    FOR_KERNEL_LOOP(linearIndex, totalElements) {\n+      // Convert `linearIndex` into an offset of `b`\n+      const IndexType bOffset =\n+          detail::IndexToOffset<scalar2, IndexType, BDims>::get(linearIndex, b);\n+      const auto bVal = b.data[bOffset];\n+      // Use value at `b` as an offset of `a`\n+      const IndexType aIdx = bVal / binsize;\n+      const IndexType aOffset =\n+          detail::IndexToOffset<scalar1, IndexType, ADims>::get(aIdx, a);\n+      atomicAdd(&a.data[aOffset], getOp(linearIndex));\n+    }\n+  }\n+}\n+\n+#define HANDLE_CASE(MEMORY_TYPE, WEIGHTS_OP)                               \\\n+  kernelHistogram1D<scalar1, scalar2, IndexType, 1, 2, 1, MEMORY_TYPE>     \\\n+      <<<grid,                                                             \\\n+         block,                                                            \\\n+         (MEMORY_TYPE == CUDAHistogramMemoryType::SHARED) ? sharedMem : 0, \\\n+         at::globalContext().getCurrentCUDAStream()>>>(                    \\\n+          aInfo, pInfo, bInfo, binsize, totalElements, WEIGHTS_OP);        \\\n+  AT_ASSERT(cudaGetLastError() == cudaSuccess, \"kernelHistogram1D failed\");\n+\n+#define HANDLE_SWITCH_CASE(mType, getOp)                                      \\\n+  switch (mType) {                                                            \\\n+    case CUDAHistogramMemoryType::SHARED:                                     \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::SHARED, getOp);                    \\\n+      break;                                                                  \\\n+    case CUDAHistogramMemoryType::MULTI_BLOCK:                                \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::MULTI_BLOCK, getOp);               \\\n+      break;                                                                  \\\n+    default:                                                                  \\\n+      std::cerr << \"WARNING: Potentially slow. \"                              \\\n+                   \"CUDA_tensor_histogram with nbins = \"                      \\\n+                << nbins << \" uses global memory with atomics.\" << std::endl; \\\n+      HANDLE_CASE(CUDAHistogramMemoryType::GLOBAL, getOp);                    \\\n+  }\n+\n+/*\n+  Calculate the frequesncy of the input values.", "path": "aten/src/ATen/cuda/CUDAApplyUtils.cuh", "position": null, "original_position": 171, "commit_id": "398cfbc3a790dda0aa46e99b66d0d82b4095a7b1", "original_commit_id": "6428429f37448ce08b2718e37ab6e9defa7b56bd", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "nit: frequency", "created_at": "2018-04-29T04:23:17Z", "updated_at": "2018-11-23T15:43:23Z", "html_url": "https://github.com/pytorch/pytorch/pull/6688#discussion_r184870859", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6688", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184870859"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6688#discussion_r184870859"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6688"}}, "body_html": "<p>nit: frequency</p>", "body_text": "nit: frequency"}