{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184089064", "pull_request_review_id": 115212806, "id": 184089064, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDA4OTA2NA==", "diff_hunk": "@@ -1578,6 +1578,52 @@ def test_nvtx(self):\n     def test_random_neg_values(self):\n         TestTorch._test_random_neg_values(self, use_cuda=True)\n \n+    def test_bincount_cuda(self):\n+        cuda = torch.device('cuda')\n+        # negative input throws\n+        with self.assertRaises(RuntimeError):\n+            torch.bincount(torch.tensor([1, -1], device=cuda))\n+        # n-d input, with n > 1 throws\n+        with self.assertRaises(RuntimeError):\n+            torch.bincount(torch.tensor([[1, 2], [3, 4]], device=cuda))\n+        # minlength < 0 throws\n+        with self.assertRaises(RuntimeError):\n+            torch.bincount(torch.tensor([1, 3], device=cuda),\n+                           torch.tensor([.2, .2], device=cuda),\n+                           minlength=-1)\n+        # floating input type throws\n+        with self.assertRaises(RuntimeError):\n+            torch.bincount(torch.tensor([1., 0.3], device=cuda))\n+\n+        # test tensor method without weights\n+        long_counts = torch.tensor([0, 3, 2, 1, 3], device=cuda).bincount()\n+        self.assertEqual(\n+            torch.tensor([1, 1, 1, 2], dtype=torch.int64, device=cuda),\n+            long_counts)\n+        # test minlength functionality\n+        int_counts = torch.bincount(\n+            torch.tensor([1, 1, 1, 1], device=cuda), minlength=5)\n+        self.assertEqual(\n+            torch.tensor([0, 4, 0, 0, 0], dtype=torch.int64, device=cuda),\n+            int_counts)\n+        # test weights\n+        byte_counts = torch.bincount(\n+            torch.tensor([0, 1, 1, 1, 4], dtype=torch.uint8, device=cuda),\n+            torch.tensor([.1, .2, .3, .4, .5], device=cuda))\n+        self.assertEqual(\n+            torch.tensor([0.1, 0.9, 0, 0, 0.5], device=cuda), byte_counts)\n+        # test large number of bins - global memory use\n+        big_exp = torch.zeros(100000000).cuda()", "path": "test/test_cuda.py", "position": null, "original_position": 39, "commit_id": "398cfbc3a790dda0aa46e99b66d0d82b4095a7b1", "original_commit_id": "c70f8328a9868a616dbe939a7635a9dd0ae465b4", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "Same as below", "created_at": "2018-04-25T14:50:32Z", "updated_at": "2018-11-23T15:43:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/6688#discussion_r184089064", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6688", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184089064"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6688#discussion_r184089064"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6688"}}, "body_html": "<p>Same as below</p>", "body_text": "Same as below"}