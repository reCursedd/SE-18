{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7721", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7721/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7721/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7721/events", "html_url": "https://github.com/pytorch/pytorch/issues/7721", "id": 324764423, "node_id": "MDU6SXNzdWUzMjQ3NjQ0MjM=", "number": 7721, "title": "Error compiling from source (OS X 10.12, CUDA 9.0, CUDNN 7.0.4)", "user": {"login": "HughRunyan", "id": 15882605, "node_id": "MDQ6VXNlcjE1ODgyNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/15882605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HughRunyan", "html_url": "https://github.com/HughRunyan", "followers_url": "https://api.github.com/users/HughRunyan/followers", "following_url": "https://api.github.com/users/HughRunyan/following{/other_user}", "gists_url": "https://api.github.com/users/HughRunyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/HughRunyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HughRunyan/subscriptions", "organizations_url": "https://api.github.com/users/HughRunyan/orgs", "repos_url": "https://api.github.com/users/HughRunyan/repos", "events_url": "https://api.github.com/users/HughRunyan/events{/privacy}", "received_events_url": "https://api.github.com/users/HughRunyan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 778855555, "node_id": "MDU6TGFiZWw3Nzg4NTU1NTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/build", "name": "build", "color": "bfdadc", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-05-21T01:54:21Z", "updated_at": "2018-05-22T21:23:41Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Installed clean OS 10.12.6 on MacBook Pro late 2013 with GT 750M video card. Been trying to get this to work for weeks, tried every tip I can find. Following error message:</p>\n<p>running install<br>\nrunning build_deps</p>\n<ul>\n<li>\n<p>WITH_CUDA=0</p>\n</li>\n<li>\n<p>[[ --with-cuda == --\\w\\i\\t\\h-\\c\\u\\d\\a ]]</p>\n</li>\n<li>\n<p>WITH_CUDA=1</p>\n</li>\n<li>\n<p>shift</p>\n</li>\n<li>\n<p>WITH_ROCM=0</p>\n</li>\n<li>\n<p>[[ --with-nnpack == --\\w\\i\\t\\h-\\r\\o\\c\\m ]]</p>\n</li>\n<li>\n<p>WITH_NNPACK=0</p>\n</li>\n<li>\n<p>[[ --with-nnpack == --\\w\\i\\t\\h-\\n\\n\\p\\a\\c\\k ]]</p>\n</li>\n<li>\n<p>WITH_NNPACK=1</p>\n</li>\n<li>\n<p>shift</p>\n</li>\n<li>\n<p>WITH_MKLDNN=0</p>\n</li>\n<li>\n<p>[[ ATen == --\\w\\i\\t\\h-\\m\\k\\l\\d\\n\\n ]]</p>\n</li>\n<li>\n<p>WITH_GLOO_IBVERBS=0</p>\n</li>\n<li>\n<p>[[ ATen == --\\w\\i\\t\\h-\\g\\l\\o\\o-\\i\\b\\v\\e\\r\\b\\s ]]</p>\n</li>\n<li>\n<p>WITH_DISTRIBUTED_MW=0</p>\n</li>\n<li>\n<p>[[ ATen == --\\w\\i\\t\\h-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d-\\m\\w ]]</p>\n</li>\n<li>\n<p>CMAKE_INSTALL='make install'</p>\n</li>\n<li>\n<p>USER_CFLAGS=</p>\n</li>\n<li>\n<p>USER_LDFLAGS=</p>\n</li>\n<li>\n<p>[[ -n '' ]]</p>\n</li>\n<li>\n<p>[[ -n '' ]]</p>\n</li>\n<li>\n<p>[[ -n '' ]]<br>\n++ dirname tools/build_pytorch_libs.sh</p>\n</li>\n<li>\n<p>cd tools/..<br>\n+++ pwd<br>\n++ printf '%q\\n' /Users/hsr/pytorch</p>\n</li>\n<li>\n<p>PWD=/Users/hsr/pytorch</p>\n</li>\n<li>\n<p>BASE_DIR=/Users/hsr/pytorch</p>\n</li>\n<li>\n<p>TORCH_LIB_DIR=/Users/hsr/pytorch/torch/lib</p>\n</li>\n<li>\n<p>INSTALL_DIR=/Users/hsr/pytorch/torch/lib/tmp_install</p>\n</li>\n<li>\n<p>THIRD_PARTY_DIR=/Users/hsr/pytorch/third_party</p>\n</li>\n<li>\n<p>CMAKE_VERSION=cmake</p>\n</li>\n<li>\n<p>C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\"'</p>\n</li>\n<li>\n<p>C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'</p>\n</li>\n<li>\n<p>LDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\" '</p>\n</li>\n<li>\n<p>LD_POSTFIX=.so.1</p>\n</li>\n<li>\n<p>LD_POSTFIX_UNVERSIONED=.so<br>\n++ uname</p>\n</li>\n<li>\n<p>[[ Darwin == \\D\\a\\r\\w\\i\\n ]]</p>\n</li>\n<li>\n<p>LDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,@loader_path'</p>\n</li>\n<li>\n<p>LD_POSTFIX=.1.dylib</p>\n</li>\n<li>\n<p>LD_POSTFIX_UNVERSIONED=.dylib</p>\n</li>\n<li>\n<p>CPP_FLAGS=' -std=c++11 '</p>\n</li>\n<li>\n<p>GLOO_FLAGS=</p>\n</li>\n<li>\n<p>THD_FLAGS=</p>\n</li>\n<li>\n<p>NCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install</p>\n</li>\n<li>\n<p>[[ 1 -eq 1 ]]</p>\n</li>\n<li>\n<p>GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install'</p>\n</li>\n<li>\n<p>[[ 0 -eq 1 ]]</p>\n</li>\n<li>\n<p>[[ 0 -eq 1 ]]</p>\n</li>\n<li>\n<p>CWRAP_FILES='/Users/hsr/pytorch/torch/lib/ATen/Declarations.cwrap;/Users/hsr/pytorch/torch/lib/THNN/generic/THNN.h;/Users/hsr/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/Users/hsr/pytorch/torch/lib/ATen/nn.yaml'</p>\n</li>\n<li>\n<p>CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'</p>\n</li>\n<li>\n<p>[[ '' -eq 1 ]]</p>\n</li>\n<li>\n<p>'[' -z 8 ']'</p>\n</li>\n<li>\n<p>BUILD_TYPE=Release</p>\n</li>\n<li>\n<p>[[ -n '' ]]</p>\n</li>\n<li>\n<p>[[ -n '' ]]</p>\n</li>\n<li>\n<p>echo 'Building in Release mode'<br>\nBuilding in Release mode</p>\n</li>\n<li>\n<p>mkdir -p torch/lib/tmp_install</p>\n</li>\n<li>\n<p>for arg in '\"$@\"'</p>\n</li>\n<li>\n<p>[[ ATen == \\n\\c\\c\\l ]]</p>\n</li>\n<li>\n<p>[[ ATen == \\g\\l\\o\\o ]]</p>\n</li>\n<li>\n<p>[[ ATen == \\A\\T\\e\\n ]]</p>\n</li>\n<li>\n<p>pushd /Users/hsr/pytorch/aten<br>\n~/pytorch/aten ~/pytorch</p>\n</li>\n<li>\n<p>build_aten</p>\n</li>\n<li>\n<p>mkdir -p build</p>\n</li>\n<li>\n<p>pushd build<br>\n~/pytorch/aten/build ~/pytorch/aten ~/pytorch</p>\n</li>\n<li>\n<p>cmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib -DCUDNN_LIBRARY=/usr/local/cuda/lib/libcudnn.7.dylib -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/Users/hsr/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS= -DWITH_ROCM=0<br>\n-- Autodetected CUDA architecture(s): 3.0<br>\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor<br>\n-- Removing -DNDEBUG from compile flags<br>\n-- MAGMA not found. Compiling without MAGMA support<br>\n-- Could not find hardware support for NEON on this machine.<br>\n-- No OMAP3 processor on this machine.<br>\n-- No OMAP4 processor on this machine.<br>\n-- SSE2 Found<br>\n-- SSE3 Found<br>\n-- AVX Found<br>\n-- AVX2 Found<br>\n-- Atomics: using GCC intrinsics<br>\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]<br>\n--   Library mkl_intel_lp64: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_lp64.dylib<br>\n--   Library mkl_intel_thread: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_thread.dylib<br>\n--   Library mkl_core: /Users/hsr/anaconda3/envs/kate/lib/libmkl_core.dylib<br>\n--   Library iomp5: /Users/hsr/anaconda3/envs/kate/lib/libiomp5.dylib<br>\n--   Library pthread: /usr/lib/libpthread.dylib<br>\n--   Library m: /usr/lib/libm.dylib<br>\n-- MKL library found<br>\n-- Found a library with BLAS API (mkl).<br>\n-- Found a library with LAPACK API. (mkl)<br>\n-- Found cuDNN: v7.0.4  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib/libcudnn.7.dylib)<br>\ndisabling MKLDNN because NO_MKLDNN is set<br>\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:25 (CMAKE_POLICY):<br>\nThe OLD behavior for policy CMP0026 will be removed from a future version<br>\nof CMake.</p>\n<p>The cmake-policies(7) manual explains that the OLD behaviors of all<br>\npolicies are deprecated and that a policy should be set to OLD only under<br>\nspecific short-term circumstances.  Projects should be ported to the NEW<br>\nbehavior and not rely on setting a policy to OLD.</p>\n</li>\n</ul>\n<p>-- Using python found in /Users/hsr/anaconda3/envs/kate/bin/python<br>\n-- TBB: using libc++.<br>\n-- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)<br>\n-- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)<br>\n-- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)<br>\n-- Configuring build for SLEEF-v3.2<br>\nTarget system: Darwin-16.7.0<br>\nTarget processor: x86_64<br>\nHost system: Darwin-16.7.0<br>\nHost processor: x86_64<br>\nDetected C compiler: AppleClang @ /Library/Developer/CommandLineTools/usr/bin/clang<br>\n-- Using option <code>-Wall -Wno-unused -Wno-attributes -Wno-unused-result -ffp-contract=off -fno-math-errno -fno-trapping-math</code> to compile libsleef<br>\n-- Building shared libs : OFF<br>\n-- MPFR : LIB_MPFR-NOTFOUND<br>\n-- GMP : LIBGMP-NOTFOUND<br>\n-- RUNNING_ON_TRAVIS : 0<br>\n-- COMPILER_SUPPORTS_OPENMP :<br>\ndisable contrib because ATEN_NO_CONTRIB is set<br>\n-- Configuring done<br>\n-- Generating done<br>\n-- Build files have been written to: /Users/hsr/pytorch/aten/build</p>\n<ul>\n<li>make install -j8<br>\n[  0%] Built target mkdisp<br>\n[  0%] Built target common<br>\n[  2%] Built target mkalias<br>\n[  2%] Built target mkrename<br>\n[  6%] Built target cpuinfo<br>\n[  6%] Built target cuda_aten_files_are_generated<br>\n[  6%] Built target aten_files_are_generated<br>\nScanning dependencies of target tbb_static<br>\n[  6%] Built target mkmasked_gnuabi<br>\n[  6%] Built target arraymap<br>\n[  6%] Built target mkrename_gnuabi<br>\n[  6%] Built target renamedsp256.h_generated<br>\n[  7%] Built target dispavx.c_generated<br>\n[  8%] Built target headers<br>\n[  9%] Built target renameSSE2.h_generated<br>\n[  9%] Built target renameAVX.h_generated<br>\n[  9%] Built target renameFMA4.h_generated<br>\n[  9%] Built target renameSSE4.h_generated<br>\n[  9%] Built target renameAVX2.h_generated<br>\n[ 10%] Built target dispsse.c_generated<br>\n[ 10%] Built target renameAVX2128.h_generated<br>\n[ 10%] Built target renamedsp128.h_generated<br>\nScanning dependencies of target sleefavx2<br>\nScanning dependencies of target sleefavx2128<br>\n[ 11%] Built target sleefsse2<br>\n[ 11%] Built target dispavx_obj<br>\n[ 11%] Built target sleefavx<br>\n[ 11%] Built target sleeffma4<br>\n[ 11%] Built target sleefsse4<br>\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimdsp.c.o<br>\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimddp.c.o<br>\nScanning dependencies of target dispsse_obj<br>\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimdsp.c.o<br>\n[ 12%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimddp.c.o<br>\n[ 12%] Building C object sleef/src/libm/CMakeFiles/dispsse_obj.dir/dispsse.c.o<br>\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o<br>\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o<br>\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/condition_variable.cpp.o<br>\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:<br>\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:26:<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:52: error: unknown type<br>\nname 'isolation_tag'<br>\ntask_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:108:27: error: use of<br>\nundeclared identifier 'no_isolation'; did you mean 'isolation'?<br>\nif ( isolation != no_isolation ) {<br>\n^~~~~~~~~~~~<br>\nisolation<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:66: note: 'isolation'<br>\ndeclared here<br>\ntask_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:109:36: error: no member<br>\nnamed 'isolation' in 'tbb::internal::task_prefix'<br>\nwhile ( curr-&gt;prefix().isolation != isolation ) {<br>\n~~~~~~~~~~~~~~ ^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:206:44: error: unknown type<br>\nname 'isolation_tag'<br>\ntask_proxy* pop( __TBB_ISOLATION_EXPR( isolation_tag isolation ) ) {<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:123:9: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(s.load()); //it's hard to rec...<br>\n^<br>\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:237:43: error: unknown<br>\ntype name 'isolation_tag'<br>\ntask* get_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:188:13: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(s.load());<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:246:31: error: unknown<br>\ntype name 'isolation_tag'<br>\ntask* get_task( size_t T, isolation_tag isolation, bool&amp; tasks_omitted );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:257:51: error: unknown<br>\ntype name 'isolation_tag'<br>\ntask* get_mailbox_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:265:75: error: unknown<br>\ntype name 'isolation_tag'<br>\n...steal_task( __TBB_ISOLATION_ARG( arena_slot&amp; victim_arena_slot, isolatio...<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:273:9: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(array0); // initial segment should be ...<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:366:115: error: unknown<br>\ntype name 'isolation_tag'<br>\n...__TBB_atomic reference_count&amp; completion_ref_count, isolation_tag isolat...<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:424:47: error: unknown<br>\ntype name 'isolation_tag'<br>\ntask* reload_tasks( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );<br>\n^<br>\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/critical_section.cpp.o<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:426:127: error: unknown<br>\ntype name 'isolation_tag'<br>\n...__TBB_ISOLATION_ARG( intptr_t top_priority, isolation_tag isolation ) );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:391:9: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(my_segment[k].load()); //if v...<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:430:52: error: unknown<br>\ntype name 'isolation_tag'<br>\ntask* winnow_task_pool ( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:434:88: error: unknown<br>\ntype name 'isolation_tag'<br>\n...size_t H0 , __TBB_ISOLATION_ARG( size_t T0, isolation_tag isolation ) );<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:409:13: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(my_segment[k].load());<br>\n^<br>\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:466:9: error:<br>\nuse of undeclared identifier 'enforce_segment_allocated'<br>\nenforce_segment_allocated(my_segment[i].load());<br>\n^<br>\n6 errors generated.<br>\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o] Error 1<br>\nmake[2]: *** Waiting for unfinished jobs....<br>\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:25:2: error:<br>\nDo not #include this internal file directly; use public TBB headers<br>\ninstead.<br>\n#error Do not #include this internal file directly; use public TBB heade...<br>\n^<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:102:31: error:<br>\nuse of undeclared identifier 'continue_msg'<br>\nclass function_body_leaf&lt; continue_msg, continue_msg, B&gt; : public fu...<br>\n^<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/<em>flow_graph_impl.h:125:38: error:<br>\nuse of undeclared identifier 'continue_msg'<br>\nclass function_body_leaf&lt; Input, continue_msg, B&gt; : public function</em>...<br>\n^<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:148:31: error:<br>\nuse of undeclared identifier 'continue_msg'<br>\nclass function_body_leaf&lt; continue_msg, Output, B &gt; : public functio...<br>\n^<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:208:40: error:<br>\nunknown class name 'task'; did you mean 'tbb::task'?<br>\nclass forward_task_bypass : public task {<br>\n^~~~<br>\ntbb::task<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/task.h:542:7: note: 'tbb::task'<br>\ndeclared here<br>\nclass task: __TBB_TASK_BASE_ACCESS interface5::internal::task_base {<br>\n^<br>\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:<br>\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:218:29: error:<br>\nuse of undeclared identifier 'SUCCESSFULLY_ENQUEUED'<br>\nif (new_task == SUCCESSFULLY_ENQUEUED) new_task = NULL;<br>\n^<br>\nfatal error: too many errors emitted, stopping now [-ferror-limit=]<br>\n[ 13%] Built target sleefavx2128<br>\n[ 14%] Built target sleefavx2<br>\n20 errors generated.<br>\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o] Error 1<br>\n[ 14%] Built target dispsse_obj<br>\nScanning dependencies of target sleef<br>\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefdp.c.o<br>\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefsp.c.o<br>\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefld.c.o<br>\nmake[1]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/all] Error 2<br>\nmake[1]: *** Waiting for unfinished jobs....<br>\n[ 15%] Linking C static library ../../lib/libsleef.a<br>\n[ 15%] Built target sleef<br>\nmake: *** [all] Error 2</li>\n</ul>\n<p>Any help appreciated, thanks for your time.</p>", "body_text": "Installed clean OS 10.12.6 on MacBook Pro late 2013 with GT 750M video card. Been trying to get this to work for weeks, tried every tip I can find. Following error message:\nrunning install\nrunning build_deps\n\n\nWITH_CUDA=0\n\n\n[[ --with-cuda == --\\w\\i\\t\\h-\\c\\u\\d\\a ]]\n\n\nWITH_CUDA=1\n\n\nshift\n\n\nWITH_ROCM=0\n\n\n[[ --with-nnpack == --\\w\\i\\t\\h-\\r\\o\\c\\m ]]\n\n\nWITH_NNPACK=0\n\n\n[[ --with-nnpack == --\\w\\i\\t\\h-\\n\\n\\p\\a\\c\\k ]]\n\n\nWITH_NNPACK=1\n\n\nshift\n\n\nWITH_MKLDNN=0\n\n\n[[ ATen == --\\w\\i\\t\\h-\\m\\k\\l\\d\\n\\n ]]\n\n\nWITH_GLOO_IBVERBS=0\n\n\n[[ ATen == --\\w\\i\\t\\h-\\g\\l\\o\\o-\\i\\b\\v\\e\\r\\b\\s ]]\n\n\nWITH_DISTRIBUTED_MW=0\n\n\n[[ ATen == --\\w\\i\\t\\h-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d-\\m\\w ]]\n\n\nCMAKE_INSTALL='make install'\n\n\nUSER_CFLAGS=\n\n\nUSER_LDFLAGS=\n\n\n[[ -n '' ]]\n\n\n[[ -n '' ]]\n\n\n[[ -n '' ]]\n++ dirname tools/build_pytorch_libs.sh\n\n\ncd tools/..\n+++ pwd\n++ printf '%q\\n' /Users/hsr/pytorch\n\n\nPWD=/Users/hsr/pytorch\n\n\nBASE_DIR=/Users/hsr/pytorch\n\n\nTORCH_LIB_DIR=/Users/hsr/pytorch/torch/lib\n\n\nINSTALL_DIR=/Users/hsr/pytorch/torch/lib/tmp_install\n\n\nTHIRD_PARTY_DIR=/Users/hsr/pytorch/third_party\n\n\nCMAKE_VERSION=cmake\n\n\nC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\"'\n\n\nC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n\n\nLDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\" '\n\n\nLD_POSTFIX=.so.1\n\n\nLD_POSTFIX_UNVERSIONED=.so\n++ uname\n\n\n[[ Darwin == \\D\\a\\r\\w\\i\\n ]]\n\n\nLDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,@loader_path'\n\n\nLD_POSTFIX=.1.dylib\n\n\nLD_POSTFIX_UNVERSIONED=.dylib\n\n\nCPP_FLAGS=' -std=c++11 '\n\n\nGLOO_FLAGS=\n\n\nTHD_FLAGS=\n\n\nNCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install\n\n\n[[ 1 -eq 1 ]]\n\n\nGLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install'\n\n\n[[ 0 -eq 1 ]]\n\n\n[[ 0 -eq 1 ]]\n\n\nCWRAP_FILES='/Users/hsr/pytorch/torch/lib/ATen/Declarations.cwrap;/Users/hsr/pytorch/torch/lib/THNN/generic/THNN.h;/Users/hsr/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/Users/hsr/pytorch/torch/lib/ATen/nn.yaml'\n\n\nCUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n\n\n[[ '' -eq 1 ]]\n\n\n'[' -z 8 ']'\n\n\nBUILD_TYPE=Release\n\n\n[[ -n '' ]]\n\n\n[[ -n '' ]]\n\n\necho 'Building in Release mode'\nBuilding in Release mode\n\n\nmkdir -p torch/lib/tmp_install\n\n\nfor arg in '\"$@\"'\n\n\n[[ ATen == \\n\\c\\c\\l ]]\n\n\n[[ ATen == \\g\\l\\o\\o ]]\n\n\n[[ ATen == \\A\\T\\e\\n ]]\n\n\npushd /Users/hsr/pytorch/aten\n~/pytorch/aten ~/pytorch\n\n\nbuild_aten\n\n\nmkdir -p build\n\n\npushd build\n~/pytorch/aten/build ~/pytorch/aten ~/pytorch\n\n\ncmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib -DCUDNN_LIBRARY=/usr/local/cuda/lib/libcudnn.7.dylib -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/Users/hsr/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS= -DWITH_ROCM=0\n-- Autodetected CUDA architecture(s): 3.0\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\n-- MAGMA not found. Compiling without MAGMA support\n-- Could not find hardware support for NEON on this machine.\n-- No OMAP3 processor on this machine.\n-- No OMAP4 processor on this machine.\n-- SSE2 Found\n-- SSE3 Found\n-- AVX Found\n-- AVX2 Found\n-- Atomics: using GCC intrinsics\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]\n--   Library mkl_intel_lp64: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_lp64.dylib\n--   Library mkl_intel_thread: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_thread.dylib\n--   Library mkl_core: /Users/hsr/anaconda3/envs/kate/lib/libmkl_core.dylib\n--   Library iomp5: /Users/hsr/anaconda3/envs/kate/lib/libiomp5.dylib\n--   Library pthread: /usr/lib/libpthread.dylib\n--   Library m: /usr/lib/libm.dylib\n-- MKL library found\n-- Found a library with BLAS API (mkl).\n-- Found a library with LAPACK API. (mkl)\n-- Found cuDNN: v7.0.4  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib/libcudnn.7.dylib)\ndisabling MKLDNN because NO_MKLDNN is set\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:25 (CMAKE_POLICY):\nThe OLD behavior for policy CMP0026 will be removed from a future version\nof CMake.\nThe cmake-policies(7) manual explains that the OLD behaviors of all\npolicies are deprecated and that a policy should be set to OLD only under\nspecific short-term circumstances.  Projects should be ported to the NEW\nbehavior and not rely on setting a policy to OLD.\n\n\n-- Using python found in /Users/hsr/anaconda3/envs/kate/bin/python\n-- TBB: using libc++.\n-- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n-- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n-- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n-- Configuring build for SLEEF-v3.2\nTarget system: Darwin-16.7.0\nTarget processor: x86_64\nHost system: Darwin-16.7.0\nHost processor: x86_64\nDetected C compiler: AppleClang @ /Library/Developer/CommandLineTools/usr/bin/clang\n-- Using option -Wall -Wno-unused -Wno-attributes -Wno-unused-result -ffp-contract=off -fno-math-errno -fno-trapping-math to compile libsleef\n-- Building shared libs : OFF\n-- MPFR : LIB_MPFR-NOTFOUND\n-- GMP : LIBGMP-NOTFOUND\n-- RUNNING_ON_TRAVIS : 0\n-- COMPILER_SUPPORTS_OPENMP :\ndisable contrib because ATEN_NO_CONTRIB is set\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/hsr/pytorch/aten/build\n\nmake install -j8\n[  0%] Built target mkdisp\n[  0%] Built target common\n[  2%] Built target mkalias\n[  2%] Built target mkrename\n[  6%] Built target cpuinfo\n[  6%] Built target cuda_aten_files_are_generated\n[  6%] Built target aten_files_are_generated\nScanning dependencies of target tbb_static\n[  6%] Built target mkmasked_gnuabi\n[  6%] Built target arraymap\n[  6%] Built target mkrename_gnuabi\n[  6%] Built target renamedsp256.h_generated\n[  7%] Built target dispavx.c_generated\n[  8%] Built target headers\n[  9%] Built target renameSSE2.h_generated\n[  9%] Built target renameAVX.h_generated\n[  9%] Built target renameFMA4.h_generated\n[  9%] Built target renameSSE4.h_generated\n[  9%] Built target renameAVX2.h_generated\n[ 10%] Built target dispsse.c_generated\n[ 10%] Built target renameAVX2128.h_generated\n[ 10%] Built target renamedsp128.h_generated\nScanning dependencies of target sleefavx2\nScanning dependencies of target sleefavx2128\n[ 11%] Built target sleefsse2\n[ 11%] Built target dispavx_obj\n[ 11%] Built target sleefavx\n[ 11%] Built target sleeffma4\n[ 11%] Built target sleefsse4\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimdsp.c.o\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimddp.c.o\nScanning dependencies of target dispsse_obj\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimdsp.c.o\n[ 12%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimddp.c.o\n[ 12%] Building C object sleef/src/libm/CMakeFiles/dispsse_obj.dir/dispsse.c.o\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/condition_variable.cpp.o\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:26:\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:52: error: unknown type\nname 'isolation_tag'\ntask_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:108:27: error: use of\nundeclared identifier 'no_isolation'; did you mean 'isolation'?\nif ( isolation != no_isolation ) {\n^~~~~~~~~~~~\nisolation\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:66: note: 'isolation'\ndeclared here\ntask_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:109:36: error: no member\nnamed 'isolation' in 'tbb::internal::task_prefix'\nwhile ( curr->prefix().isolation != isolation ) {\n~~~~~~~~~~~~~~ ^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:206:44: error: unknown type\nname 'isolation_tag'\ntask_proxy* pop( __TBB_ISOLATION_EXPR( isolation_tag isolation ) ) {\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:123:9: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(s.load()); //it's hard to rec...\n^\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:237:43: error: unknown\ntype name 'isolation_tag'\ntask* get_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:188:13: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(s.load());\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:246:31: error: unknown\ntype name 'isolation_tag'\ntask* get_task( size_t T, isolation_tag isolation, bool& tasks_omitted );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:257:51: error: unknown\ntype name 'isolation_tag'\ntask* get_mailbox_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:265:75: error: unknown\ntype name 'isolation_tag'\n...steal_task( __TBB_ISOLATION_ARG( arena_slot& victim_arena_slot, isolatio...\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:273:9: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(array0); // initial segment should be ...\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:366:115: error: unknown\ntype name 'isolation_tag'\n...__TBB_atomic reference_count& completion_ref_count, isolation_tag isolat...\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:424:47: error: unknown\ntype name 'isolation_tag'\ntask* reload_tasks( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\n^\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/critical_section.cpp.o\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:426:127: error: unknown\ntype name 'isolation_tag'\n...__TBB_ISOLATION_ARG( intptr_t top_priority, isolation_tag isolation ) );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:391:9: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(my_segment[k].load()); //if v...\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:430:52: error: unknown\ntype name 'isolation_tag'\ntask* winnow_task_pool ( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:434:88: error: unknown\ntype name 'isolation_tag'\n...size_t H0 , __TBB_ISOLATION_ARG( size_t T0, isolation_tag isolation ) );\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:409:13: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(my_segment[k].load());\n^\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:466:9: error:\nuse of undeclared identifier 'enforce_segment_allocated'\nenforce_segment_allocated(my_segment[i].load());\n^\n6 errors generated.\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o] Error 1\nmake[2]: *** Waiting for unfinished jobs....\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:25:2: error:\nDo not #include this internal file directly; use public TBB headers\ninstead.\n#error Do not #include this internal file directly; use public TBB heade...\n^\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:102:31: error:\nuse of undeclared identifier 'continue_msg'\nclass function_body_leaf< continue_msg, continue_msg, B> : public fu...\n^\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/flow_graph_impl.h:125:38: error:\nuse of undeclared identifier 'continue_msg'\nclass function_body_leaf< Input, continue_msg, B> : public function...\n^\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:148:31: error:\nuse of undeclared identifier 'continue_msg'\nclass function_body_leaf< continue_msg, Output, B > : public functio...\n^\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:208:40: error:\nunknown class name 'task'; did you mean 'tbb::task'?\nclass forward_task_bypass : public task {\n^~~~\ntbb::task\n/Users/hsr/anaconda3/envs/kate/include/tbb/task.h:542:7: note: 'tbb::task'\ndeclared here\nclass task: __TBB_TASK_BASE_ACCESS interface5::internal::task_base {\n^\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:218:29: error:\nuse of undeclared identifier 'SUCCESSFULLY_ENQUEUED'\nif (new_task == SUCCESSFULLY_ENQUEUED) new_task = NULL;\n^\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\n[ 13%] Built target sleefavx2128\n[ 14%] Built target sleefavx2\n20 errors generated.\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o] Error 1\n[ 14%] Built target dispsse_obj\nScanning dependencies of target sleef\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefdp.c.o\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefsp.c.o\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefld.c.o\nmake[1]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/all] Error 2\nmake[1]: *** Waiting for unfinished jobs....\n[ 15%] Linking C static library ../../lib/libsleef.a\n[ 15%] Built target sleef\nmake: *** [all] Error 2\n\nAny help appreciated, thanks for your time.", "body": "Installed clean OS 10.12.6 on MacBook Pro late 2013 with GT 750M video card. Been trying to get this to work for weeks, tried every tip I can find. Following error message:\r\n\r\nrunning install\r\nrunning build_deps\r\n+ WITH_CUDA=0\r\n+ [[ --with-cuda == \\-\\-\\w\\i\\t\\h\\-\\c\\u\\d\\a ]]\r\n+ WITH_CUDA=1\r\n+ shift\r\n+ WITH_ROCM=0\r\n+ [[ --with-nnpack == \\-\\-\\w\\i\\t\\h\\-\\r\\o\\c\\m ]]\r\n+ WITH_NNPACK=0\r\n+ [[ --with-nnpack == \\-\\-\\w\\i\\t\\h\\-\\n\\n\\p\\a\\c\\k ]]\r\n+ WITH_NNPACK=1\r\n+ shift\r\n+ WITH_MKLDNN=0\r\n+ [[ ATen == \\-\\-\\w\\i\\t\\h\\-\\m\\k\\l\\d\\n\\n ]]\r\n+ WITH_GLOO_IBVERBS=0\r\n+ [[ ATen == \\-\\-\\w\\i\\t\\h\\-\\g\\l\\o\\o\\-\\i\\b\\v\\e\\r\\b\\s ]]\r\n+ WITH_DISTRIBUTED_MW=0\r\n+ [[ ATen == \\-\\-\\w\\i\\t\\h\\-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d\\-\\m\\w ]]\r\n+ CMAKE_INSTALL='make install'\r\n+ USER_CFLAGS=\r\n+ USER_LDFLAGS=\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n++ dirname tools/build_pytorch_libs.sh\r\n+ cd tools/..\r\n+++ pwd\r\n++ printf '%q\\n' /Users/hsr/pytorch\r\n+ PWD=/Users/hsr/pytorch\r\n+ BASE_DIR=/Users/hsr/pytorch\r\n+ TORCH_LIB_DIR=/Users/hsr/pytorch/torch/lib\r\n+ INSTALL_DIR=/Users/hsr/pytorch/torch/lib/tmp_install\r\n+ THIRD_PARTY_DIR=/Users/hsr/pytorch/third_party\r\n+ CMAKE_VERSION=cmake\r\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\"'\r\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\r\n+ LDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\" '\r\n+ LD_POSTFIX=.so.1\r\n+ LD_POSTFIX_UNVERSIONED=.so\r\n++ uname\r\n+ [[ Darwin == \\D\\a\\r\\w\\i\\n ]]\r\n+ LDFLAGS='-L\"/Users/hsr/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,@loader_path'\r\n+ LD_POSTFIX=.1.dylib\r\n+ LD_POSTFIX_UNVERSIONED=.dylib\r\n+ CPP_FLAGS=' -std=c++11 '\r\n+ GLOO_FLAGS=\r\n+ THD_FLAGS=\r\n+ NCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install\r\n+ [[ 1 -eq 1 ]]\r\n+ GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/Users/hsr/pytorch/torch/lib/tmp_install'\r\n+ [[ 0 -eq 1 ]]\r\n+ [[ 0 -eq 1 ]]\r\n+ CWRAP_FILES='/Users/hsr/pytorch/torch/lib/ATen/Declarations.cwrap;/Users/hsr/pytorch/torch/lib/THNN/generic/THNN.h;/Users/hsr/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/Users/hsr/pytorch/torch/lib/ATen/nn.yaml'\r\n+ CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/TH\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THS\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/Users/hsr/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\r\n+ [[ '' -eq 1 ]]\r\n+ '[' -z 8 ']'\r\n+ BUILD_TYPE=Release\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n+ echo 'Building in Release mode'\r\nBuilding in Release mode\r\n+ mkdir -p torch/lib/tmp_install\r\n+ for arg in '\"$@\"'\r\n+ [[ ATen == \\n\\c\\c\\l ]]\r\n+ [[ ATen == \\g\\l\\o\\o ]]\r\n+ [[ ATen == \\A\\T\\e\\n ]]\r\n+ pushd /Users/hsr/pytorch/aten\r\n~/pytorch/aten ~/pytorch\r\n+ build_aten\r\n+ mkdir -p build\r\n+ pushd build\r\n~/pytorch/aten/build ~/pytorch/aten ~/pytorch\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib -DCUDNN_LIBRARY=/usr/local/cuda/lib/libcudnn.7.dylib -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/Users/hsr/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS= -DWITH_ROCM=0\r\n-- Autodetected CUDA architecture(s): 3.0 \r\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\r\n-- Removing -DNDEBUG from compile flags\r\n-- MAGMA not found. Compiling without MAGMA support\r\n-- Could not find hardware support for NEON on this machine.\r\n-- No OMAP3 processor on this machine.\r\n-- No OMAP4 processor on this machine.\r\n-- SSE2 Found\r\n-- SSE3 Found\r\n-- AVX Found\r\n-- AVX2 Found\r\n-- Atomics: using GCC intrinsics\r\n-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]\r\n--   Library mkl_intel_lp64: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_lp64.dylib\r\n--   Library mkl_intel_thread: /Users/hsr/anaconda3/envs/kate/lib/libmkl_intel_thread.dylib\r\n--   Library mkl_core: /Users/hsr/anaconda3/envs/kate/lib/libmkl_core.dylib\r\n--   Library iomp5: /Users/hsr/anaconda3/envs/kate/lib/libiomp5.dylib\r\n--   Library pthread: /usr/lib/libpthread.dylib\r\n--   Library m: /usr/lib/libm.dylib\r\n-- MKL library found\r\n-- Found a library with BLAS API (mkl).\r\n-- Found a library with LAPACK API. (mkl)\r\n-- Found cuDNN: v7.0.4  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib/libcudnn.7.dylib)\r\ndisabling MKLDNN because NO_MKLDNN is set\r\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:25 (CMAKE_POLICY):\r\n  The OLD behavior for policy CMP0026 will be removed from a future version\r\n  of CMake.\r\n\r\n  The cmake-policies(7) manual explains that the OLD behaviors of all\r\n  policies are deprecated and that a policy should be set to OLD only under\r\n  specific short-term circumstances.  Projects should be ported to the NEW\r\n  behavior and not rely on setting a policy to OLD.\r\n\r\n\r\n-- Using python found in /Users/hsr/anaconda3/envs/kate/bin/python\r\n-- TBB: using libc++.\r\n-- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES) \r\n-- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES) \r\n-- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND) \r\n-- Configuring build for SLEEF-v3.2\r\n   Target system: Darwin-16.7.0\r\n   Target processor: x86_64\r\n   Host system: Darwin-16.7.0\r\n   Host processor: x86_64\r\n   Detected C compiler: AppleClang @ /Library/Developer/CommandLineTools/usr/bin/clang\r\n-- Using option `-Wall -Wno-unused -Wno-attributes -Wno-unused-result -ffp-contract=off -fno-math-errno -fno-trapping-math` to compile libsleef\r\n-- Building shared libs : OFF\r\n-- MPFR : LIB_MPFR-NOTFOUND\r\n-- GMP : LIBGMP-NOTFOUND\r\n-- RUNNING_ON_TRAVIS : 0\r\n-- COMPILER_SUPPORTS_OPENMP : \r\ndisable contrib because ATEN_NO_CONTRIB is set\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /Users/hsr/pytorch/aten/build\r\n+ make install -j8\r\n[  0%] Built target mkdisp\r\n[  0%] Built target common\r\n[  2%] Built target mkalias\r\n[  2%] Built target mkrename\r\n[  6%] Built target cpuinfo\r\n[  6%] Built target cuda_aten_files_are_generated\r\n[  6%] Built target aten_files_are_generated\r\nScanning dependencies of target tbb_static\r\n[  6%] Built target mkmasked_gnuabi\r\n[  6%] Built target arraymap\r\n[  6%] Built target mkrename_gnuabi\r\n[  6%] Built target renamedsp256.h_generated\r\n[  7%] Built target dispavx.c_generated\r\n[  8%] Built target headers\r\n[  9%] Built target renameSSE2.h_generated\r\n[  9%] Built target renameAVX.h_generated\r\n[  9%] Built target renameFMA4.h_generated\r\n[  9%] Built target renameSSE4.h_generated\r\n[  9%] Built target renameAVX2.h_generated\r\n[ 10%] Built target dispsse.c_generated\r\n[ 10%] Built target renameAVX2128.h_generated\r\n[ 10%] Built target renamedsp128.h_generated\r\nScanning dependencies of target sleefavx2\r\nScanning dependencies of target sleefavx2128\r\n[ 11%] Built target sleefsse2\r\n[ 11%] Built target dispavx_obj\r\n[ 11%] Built target sleefavx\r\n[ 11%] Built target sleeffma4\r\n[ 11%] Built target sleefsse4\r\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimdsp.c.o\r\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2.dir/sleefsimddp.c.o\r\nScanning dependencies of target dispsse_obj\r\n[ 11%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimdsp.c.o\r\n[ 12%] Building C object sleef/src/libm/CMakeFiles/sleefavx2128.dir/sleefsimddp.c.o\r\n[ 12%] Building C object sleef/src/libm/CMakeFiles/dispsse_obj.dir/dispsse.c.o\r\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o\r\n[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o\r\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/condition_variable.cpp.o\r\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:\r\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:26:\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:52: error: unknown type\r\n      name 'isolation_tag'\r\n    task_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {\r\n                                                   ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:108:27: error: use of\r\n      undeclared identifier 'no_isolation'; did you mean 'isolation'?\r\n        if ( isolation != no_isolation ) {\r\n                          ^~~~~~~~~~~~\r\n                          isolation\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:102:66: note: 'isolation'\r\n      declared here\r\n    task_proxy* internal_pop( __TBB_ISOLATION_EXPR(isolation_tag isolation) ) {\r\n                                                                 ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:109:36: error: no member\r\n      named 'isolation' in 'tbb::internal::task_prefix'\r\n            while ( curr->prefix().isolation != isolation ) {\r\n                    ~~~~~~~~~~~~~~ ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/mailbox.h:206:44: error: unknown type\r\n      name 'isolation_tag'\r\n    task_proxy* pop( __TBB_ISOLATION_EXPR( isolation_tag isolation ) ) {\r\n                                           ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:123:9: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n        enforce_segment_allocated(s.load<relaxed>()); //it's hard to rec...\r\n        ^\r\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:23:\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:237:43: error: unknown\r\n      type name 'isolation_tag'\r\n    task* get_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\r\n                                          ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:188:13: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n            enforce_segment_allocated(s.load<relaxed>());\r\n            ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:246:31: error: unknown\r\n      type name 'isolation_tag'\r\n    task* get_task( size_t T, isolation_tag isolation, bool& tasks_omitted );\r\n                              ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:257:51: error: unknown\r\n      type name 'isolation_tag'\r\n    task* get_mailbox_task( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\r\n                                                  ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:265:75: error: unknown\r\n      type name 'isolation_tag'\r\n  ...steal_task( __TBB_ISOLATION_ARG( arena_slot& victim_arena_slot, isolatio...\r\n                                                                     ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:273:9: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n        enforce_segment_allocated(array0); // initial segment should be ...\r\n        ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:366:115: error: unknown\r\n      type name 'isolation_tag'\r\n  ...__TBB_atomic reference_count& completion_ref_count, isolation_tag isolat...\r\n                                                         ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:424:47: error: unknown\r\n      type name 'isolation_tag'\r\n    task* reload_tasks( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\r\n                                              ^\r\n[ 13%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/critical_section.cpp.o\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:426:127: error: unknown\r\n      type name 'isolation_tag'\r\n  ...__TBB_ISOLATION_ARG( intptr_t top_priority, isolation_tag isolation ) );\r\n                                                 ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:391:9: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n        enforce_segment_allocated(my_segment[k].load<relaxed>()); //if v...\r\n        ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:430:52: error: unknown\r\n      type name 'isolation_tag'\r\n    task* winnow_task_pool ( __TBB_ISOLATION_EXPR( isolation_tag isolation ) );\r\n                                                   ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/scheduler.h:434:88: error: unknown\r\n      type name 'isolation_tag'\r\n  ...size_t H0 , __TBB_ISOLATION_ARG( size_t T0, isolation_tag isolation ) );\r\n                                                 ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:409:13: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n            enforce_segment_allocated(my_segment[k].load<relaxed>());\r\n            ^\r\n/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp:466:9: error: \r\n      use of undeclared identifier 'enforce_segment_allocated'\r\n        enforce_segment_allocated(my_segment[i].load<relaxed>());\r\n        ^\r\n6 errors generated.\r\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/concurrent_vector.cpp.o] Error 1\r\nmake[2]: *** Waiting for unfinished jobs....\r\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:25:2: error: \r\n      Do not #include this internal file directly; use public TBB headers\r\n      instead.\r\n#error Do not #include this internal file directly; use public TBB heade...\r\n ^\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:102:31: error: \r\n      use of undeclared identifier 'continue_msg'\r\n    class function_body_leaf< continue_msg, continue_msg, B> : public fu...\r\n                              ^\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:125:38: error: \r\n      use of undeclared identifier 'continue_msg'\r\n    class function_body_leaf< Input, continue_msg, B> : public function_...\r\n                                     ^\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:148:31: error: \r\n      use of undeclared identifier 'continue_msg'\r\n    class function_body_leaf< continue_msg, Output, B > : public functio...\r\n                              ^\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:208:40: error: \r\n      unknown class name 'task'; did you mean 'tbb::task'?\r\n    class forward_task_bypass : public task {\r\n                                       ^~~~\r\n                                       tbb::task\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/task.h:542:7: note: 'tbb::task'\r\n      declared here\r\nclass task: __TBB_TASK_BASE_ACCESS interface5::internal::task_base {\r\n      ^\r\nIn file included from /Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp:28:\r\n/Users/hsr/anaconda3/envs/kate/include/tbb/internal/_flow_graph_impl.h:218:29: error: \r\n      use of undeclared identifier 'SUCCESSFULLY_ENQUEUED'\r\n            if (new_task == SUCCESSFULLY_ENQUEUED) new_task = NULL;\r\n                            ^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n[ 13%] Built target sleefavx2128\r\n[ 14%] Built target sleefavx2\r\n20 errors generated.\r\nmake[2]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/Users/hsr/pytorch/third_party/tbb/src/tbb/arena.cpp.o] Error 1\r\n[ 14%] Built target dispsse_obj\r\nScanning dependencies of target sleef\r\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefdp.c.o\r\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefsp.c.o\r\n[ 15%] Building C object sleef/src/libm/CMakeFiles/sleef.dir/sleefld.c.o\r\nmake[1]: *** [src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs....\r\n[ 15%] Linking C static library ../../lib/libsleef.a\r\n[ 15%] Built target sleef\r\nmake: *** [all] Error 2\r\n\r\nAny help appreciated, thanks for your time. "}