{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/164225639", "pull_request_review_id": 91973472, "id": 164225639, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NDIyNTYzOQ==", "diff_hunk": "@@ -7,10 +7,80 @@\n \n namespace torch { namespace jit {\n \n-// This function mutates the given graph (which should only contain a single stage)\n-// by appending nodes of a next stage, which computes the Jacobian-vector product\n-// (aka backward) of inputs to the first stage w.r.t. the outputs of the first stage.\n-void differentiate(std::shared_ptr<Graph>& graph);\n+struct Capture {\n+  enum class Kind {Input, Output};\n+  Capture(Kind kind, std::size_t offset)\n+    : kind(kind), offset(offset) {}\n+  Kind kind;\n+  std::size_t offset;\n+};\n+\n+using value_list = std::vector<Value*>;\n+// Example showcasing how Gradient is constructed:\n+//\n+// Let's assume we have a function f, `m` and `n` do not require grad\n+// (`n` can depend only on `m`):\n+//   y, n = f(x, m)\n+//\n+// Now, let's assume that the reverse of f (called f') needs to use values of `x`, `t` and `y`.\n+// `t` is an intermediate value produced in the body of f, and let's assume that it requires\n+// grad too.\n+//\n+// In this case differentiate(f) will return this:\n+//   y, n, t = f(x, m)        // `t` is appended to the output list\n+//   dx = f'(x, t, y, dy, dt) // No `dm` or `dn` because they do not require gradient\n+//                            // All needed values from f are prepended to the input list\n+//\n+//   f_real_outputs = 2       // Only first two outputs were present in f originally\n+//   df_input_captures = {O0, O2, I0} // Order matches the prefix of inputs to df\n+//                        y   t   x\n+//   df_input_vjps = {0, 2}   // i.e. connect grad_fn of y and t variables produced by f,\n+//                    y  t    // with y's output_nr = 0 and t's output_nr = 1\n+//   df_output_vjps = {0}     // i.e. connect next_function[0] of grad_fn to x's (grad_fn, output_nr).\n+struct Gradient {\n+  std::shared_ptr<Graph> f;\n+  std::shared_ptr<Graph> df;\n+\n+  // Describes how to construct outputs of f from what its graph will return.\n+  // This is necessary because some trailing outputs are intermediates produced\n+  // only to be saved for df (and should be ignored).\n+  std::size_t f_real_outputs;\n+\n+  // df inputs are split into two sections: captures are vjps (aka grad_outputs).\n+  // Captures are values the need to be saved when f is run. We handle inputs\n+  // specially, because this allows us to avoid adding extra vjps as df inputs.\n+  // VJPs are \"seeds\" for the gradient computation given for each input capture\n+  // of an Output kind.\n+  std::vector<Capture> df_input_captures;\n+  std::vector<std::size_t> df_input_vjps; // Offsets into f's outputs.", "path": "torch/csrc/jit/autodiff.h", "position": 53, "original_position": 53, "commit_id": "a41b11143e2fad09918cf66d0a60216e9ab83f5a", "original_commit_id": "a41b11143e2fad09918cf66d0a60216e9ab83f5a", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I'm not a huge fan, but it's ok. It tells you vjps for which outputs are inputs to df. I can't find a better name", "created_at": "2018-01-26T21:24:10Z", "updated_at": "2018-11-23T15:38:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/4759#discussion_r164225639", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4759", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/164225639"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4759#discussion_r164225639"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4759"}}, "body_html": "<p>I'm not a huge fan, but it's ok. It tells you vjps for which outputs are inputs to df. I can't find a better name</p>", "body_text": "I'm not a huge fan, but it's ok. It tells you vjps for which outputs are inputs to df. I can't find a better name", "in_reply_to_id": 164225008}