{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1867", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1867/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1867/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1867/events", "html_url": "https://github.com/pytorch/pytorch/pull/1867", "id": 237622724, "node_id": "MDExOlB1bGxSZXF1ZXN0MTI2ODI5MTYz", "number": 1867, "title": "Add batch sampler to DataLoader", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-06-21T18:22:09Z", "updated_at": "2018-11-23T15:33:57Z", "closed_at": "2017-06-22T18:18:34Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1867", "html_url": "https://github.com/pytorch/pytorch/pull/1867", "diff_url": "https://github.com/pytorch/pytorch/pull/1867.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1867.patch"}, "body_html": "<p>The optional batch_sampler argument combines the sampler with the<br>\ngrouping of indices into mini-batches. This allows for non-standard<br>\nbatch sizes.</p>\n<p>This is important for some sequence to sequence tasks. For example, when <a href=\"https://github.com/facebookresearch/fairseq/\">fairseq</a> evaluates on the validation or test set, it groups samples into batches only if it would not require padding. This means that some batches may be smaller than the requested batch size.</p>", "body_text": "The optional batch_sampler argument combines the sampler with the\ngrouping of indices into mini-batches. This allows for non-standard\nbatch sizes.\nThis is important for some sequence to sequence tasks. For example, when fairseq evaluates on the validation or test set, it groups samples into batches only if it would not require padding. This means that some batches may be smaller than the requested batch size.", "body": "The optional batch_sampler argument combines the sampler with the\r\ngrouping of indices into mini-batches. This allows for non-standard\r\nbatch sizes.\r\n\r\nThis is important for some sequence to sequence tasks. For example, when [fairseq](https://github.com/facebookresearch/fairseq/) evaluates on the validation or test set, it groups samples into batches only if it would not require padding. This means that some batches may be smaller than the requested batch size. "}