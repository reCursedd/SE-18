{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193265125", "pull_request_review_id": 126203218, "id": 193265125, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MzI2NTEyNQ==", "diff_hunk": "@@ -4018,6 +4018,72 @@ def parse_kwargs(desc):\n             [ 1,  2,  2,  0]])\n \"\"\")\n \n+add_docstr(torch.sparse_coo_tensor,\n+           r\"\"\"\n+sparse_coo_tensor(indices, values, size=None, dtype=None, device=None, requires_grad=False) -> Tensor\n+\n+Constructs a sparse_coo_tensor with non-zero elements at the given :attr:`indices` with the given\n+:attr:`values`.\n+\n+Args:\n+    indices (array_like): Initial data for the tensor. Can be a list, tuple,\n+        NumPy ``ndarray``, scalar, and other types. Will be cast to a :class:`torch.LongTensor`\n+        internally. The indices are the coordinates of the non-zero values in the matrix, and thus\n+        should be two-dimensional where the first dimension is the number of tensor dimensions and\n+        the second dimension is the number of non-zero values.\n+    values (array_like): Initial values for the tensor. Can be a list, tuple,\n+        NumPy ``ndarray``, scalar, and other types.\n+    size (list, tuple, or :class:`torch.Size`, optional): Size of the sparse tensor. If not\n+        provided the size will be inferred as the minimum size big enough to hold all non-zero\n+        elements.\n+    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n+        Default: if None, infers data type from :attr:`values`.\n+    device (:class:`torch.device`, optional): the desired device of returned tensor.\n+        Default: if None, uses the current device for the default tensor type\n+        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n+        for CPU tensor types and the current CUDA device for CUDA tensor types.\n+    requires_grad (bool, optional): If autograd should record operations on the\n+        returned tensor. Default: ``False``.\n+\n+\n+Example::\n+\n+    >>> i = torch.LongTensor([[0, 1, 1],\n+                              [2, 0, 2]])\n+    >>> v = torch.FloatTensor([3, 4, 5])\n+    >>> torch.sparse_coo_tensor(i, v, torch.Size([2,4]))\n+    torch.sparse.FloatTensor of size (2,4) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]])\n+    and values:\n+    tensor([ 3.,  4.,  5.])\n+    \n+    >>> torch.sparse_coo_tensor(i, v)  # Shape inference\n+    torch.sparse.FloatTensor of size (2,3) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]])\n+    and values:\n+    tensor([ 3.,  4.,  5.])\n+\n+    >>> torch.sparse_coo_tensor(i, v, torch.Size([2,4]), dtype=torch.float64,\n+                                device=torch.device('cuda:0'))\n+    torch.cuda.sparse.DoubleTensor of size (2,4) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]], device='cuda:0')\n+    and values:\n+    tensor([ 3.,  4.,  5.], dtype=torch.float64, device='cuda:0')\n+\n+    >>> torch.sparse_coo_tensor([], [], torch.Size([])) # Create an empty tensor (of size (0,))", "path": "torch/_torch_docs.py", "position": 59, "original_position": 59, "commit_id": "bf0bab9d25f4abc456d62b9f22e7e8a80bb47668", "original_commit_id": "4534134ebf331b105a20a666b5bea7b1a288e056", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Yes, there is something deeply wrong with the printing here. Can someone verify this is the case on master? If so, it sounds like a bug.", "created_at": "2018-06-06T00:56:52Z", "updated_at": "2018-11-23T15:45:00Z", "html_url": "https://github.com/pytorch/pytorch/pull/8152#discussion_r193265125", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8152", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193265125"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8152#discussion_r193265125"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8152"}}, "body_html": "<p>Yes, there is something deeply wrong with the printing here. Can someone verify this is the case on master? If so, it sounds like a bug.</p>", "body_text": "Yes, there is something deeply wrong with the printing here. Can someone verify this is the case on master? If so, it sounds like a bug.", "in_reply_to_id": 193155626}