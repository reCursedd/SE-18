{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193296520", "pull_request_review_id": 126238556, "id": 193296520, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MzI5NjUyMA==", "diff_hunk": "@@ -4018,6 +4018,72 @@ def parse_kwargs(desc):\n             [ 1,  2,  2,  0]])\n \"\"\")\n \n+add_docstr(torch.sparse_coo_tensor,\n+           r\"\"\"\n+sparse_coo_tensor(indices, values, size=None, dtype=None, device=None, requires_grad=False) -> Tensor\n+\n+Constructs a sparse_coo_tensor with non-zero elements at the given :attr:`indices` with the given\n+:attr:`values`.\n+\n+Args:\n+    indices (array_like): Initial data for the tensor. Can be a list, tuple,\n+        NumPy ``ndarray``, scalar, and other types. Will be cast to a :class:`torch.LongTensor`\n+        internally. The indices are the coordinates of the non-zero values in the matrix, and thus\n+        should be two-dimensional where the first dimension is the number of tensor dimensions and\n+        the second dimension is the number of non-zero values.\n+    values (array_like): Initial values for the tensor. Can be a list, tuple,\n+        NumPy ``ndarray``, scalar, and other types.\n+    size (list, tuple, or :class:`torch.Size`, optional): Size of the sparse tensor. If not\n+        provided the size will be inferred as the minimum size big enough to hold all non-zero\n+        elements.\n+    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n+        Default: if None, infers data type from :attr:`values`.\n+    device (:class:`torch.device`, optional): the desired device of returned tensor.\n+        Default: if None, uses the current device for the default tensor type\n+        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n+        for CPU tensor types and the current CUDA device for CUDA tensor types.\n+    requires_grad (bool, optional): If autograd should record operations on the\n+        returned tensor. Default: ``False``.\n+\n+\n+Example::\n+\n+    >>> i = torch.LongTensor([[0, 1, 1],\n+                              [2, 0, 2]])\n+    >>> v = torch.FloatTensor([3, 4, 5])\n+    >>> torch.sparse_coo_tensor(i, v, torch.Size([2,4]))\n+    torch.sparse.FloatTensor of size (2,4) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]])\n+    and values:\n+    tensor([ 3.,  4.,  5.])\n+    \n+    >>> torch.sparse_coo_tensor(i, v)  # Shape inference\n+    torch.sparse.FloatTensor of size (2,3) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]])\n+    and values:\n+    tensor([ 3.,  4.,  5.])\n+\n+    >>> torch.sparse_coo_tensor(i, v, torch.Size([2,4]), dtype=torch.float64,\n+                                device=torch.device('cuda:0'))\n+    torch.cuda.sparse.DoubleTensor of size (2,4) with indices:\n+    tensor([[ 0,  1,  1],\n+            [ 2,  0,  2]], device='cuda:0')\n+    and values:\n+    tensor([ 3.,  4.,  5.], dtype=torch.float64, device='cuda:0')\n+\n+    >>> torch.sparse_coo_tensor([], [], torch.Size([])) # Create an empty tensor (of size (0,))", "path": "torch/_torch_docs.py", "position": 59, "original_position": 59, "commit_id": "bf0bab9d25f4abc456d62b9f22e7e8a80bb47668", "original_commit_id": "4534134ebf331b105a20a666b5bea7b1a288e056", "user": {"login": "sethah", "id": 7275795, "node_id": "MDQ6VXNlcjcyNzU3OTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/7275795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sethah", "html_url": "https://github.com/sethah", "followers_url": "https://api.github.com/users/sethah/followers", "following_url": "https://api.github.com/users/sethah/following{/other_user}", "gists_url": "https://api.github.com/users/sethah/gists{/gist_id}", "starred_url": "https://api.github.com/users/sethah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sethah/subscriptions", "organizations_url": "https://api.github.com/users/sethah/orgs", "repos_url": "https://api.github.com/users/sethah/repos", "events_url": "https://api.github.com/users/sethah/events{/privacy}", "received_events_url": "https://api.github.com/users/sethah/received_events", "type": "User", "site_admin": false}, "body": "This stems from the fact that a call to `_indices()` on this empty sparse tensor ends up in the function below.\r\n\r\n```cpp\r\nTensor SparseCPUFloatType::_indices(const Tensor & self) const {\r\n    auto self_ = checked_cast_tensor<SparseCPUFloatTensor>(self.pImpl,\"self\",1, false);\r\n    if (self_->isScalar()) {\r\n      // Empty tensor\r\n      return self_->type().toScalarType(kLong).tensor({0});\r\n    }\r\n    return Tensor((new CPULongTensor(context, THSFloatTensor_newIndices(self_->tensor))),false);\r\n}\r\n```\r\n\r\nIn this situation the branch condition is true and `self_->type().toScalarType(kLong).tensor({0})` resolves to `Tensor SparseCPULongType::tensor(IntList size)`. So, the indices are an empty tensor of `SparseCPULongType`. \r\n\r\nI believe @zou3519 wrote the code for this in https://github.com/pytorch/pytorch/pull/4058.", "created_at": "2018-06-06T05:39:28Z", "updated_at": "2018-11-23T15:45:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/8152#discussion_r193296520", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8152", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/193296520"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8152#discussion_r193296520"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8152"}}, "body_html": "<p>This stems from the fact that a call to <code>_indices()</code> on this empty sparse tensor ends up in the function below.</p>\n<div class=\"highlight highlight-source-c++\"><pre>Tensor <span class=\"pl-en\">SparseCPUFloatType::_indices</span>(<span class=\"pl-k\">const</span> Tensor &amp; self) <span class=\"pl-k\">const</span> {\n    <span class=\"pl-k\">auto</span> self_ = checked_cast_tensor&lt;SparseCPUFloatTensor&gt;(self.<span class=\"pl-smi\">pImpl</span>,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>self<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">false</span>);\n    <span class=\"pl-k\">if</span> (self_-&gt;<span class=\"pl-c1\">isScalar</span>()) {\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> Empty tensor</span>\n      <span class=\"pl-k\">return</span> self_-&gt;<span class=\"pl-c1\">type</span>().<span class=\"pl-c1\">toScalarType</span>(<span class=\"pl-c1\">kLong</span>).<span class=\"pl-c1\">tensor</span>({<span class=\"pl-c1\">0</span>});\n    }\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">Tensor</span>((<span class=\"pl-k\">new</span> <span class=\"pl-c1\">CPULongTensor</span>(context, <span class=\"pl-c1\">THSFloatTensor_newIndices</span>(self_-&gt;<span class=\"pl-smi\">tensor</span>))),<span class=\"pl-c1\">false</span>);\n}</pre></div>\n<p>In this situation the branch condition is true and <code>self_-&gt;type().toScalarType(kLong).tensor({0})</code> resolves to <code>Tensor SparseCPULongType::tensor(IntList size)</code>. So, the indices are an empty tensor of <code>SparseCPULongType</code>.</p>\n<p>I believe <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> wrote the code for this in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"279902184\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4058\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4058/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4058\">#4058</a>.</p>", "body_text": "This stems from the fact that a call to _indices() on this empty sparse tensor ends up in the function below.\nTensor SparseCPUFloatType::_indices(const Tensor & self) const {\n    auto self_ = checked_cast_tensor<SparseCPUFloatTensor>(self.pImpl,\"self\",1, false);\n    if (self_->isScalar()) {\n      // Empty tensor\n      return self_->type().toScalarType(kLong).tensor({0});\n    }\n    return Tensor((new CPULongTensor(context, THSFloatTensor_newIndices(self_->tensor))),false);\n}\nIn this situation the branch condition is true and self_->type().toScalarType(kLong).tensor({0}) resolves to Tensor SparseCPULongType::tensor(IntList size). So, the indices are an empty tensor of SparseCPULongType.\nI believe @zou3519 wrote the code for this in #4058.", "in_reply_to_id": 193155626}