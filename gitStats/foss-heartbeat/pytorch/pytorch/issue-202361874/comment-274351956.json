{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/274351956", "html_url": "https://github.com/pytorch/pytorch/issues/542#issuecomment-274351956", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/542", "id": 274351956, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDM1MTk1Ng==", "user": {"login": "rasbt", "id": 5618407, "node_id": "MDQ6VXNlcjU2MTg0MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5618407?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rasbt", "html_url": "https://github.com/rasbt", "followers_url": "https://api.github.com/users/rasbt/followers", "following_url": "https://api.github.com/users/rasbt/following{/other_user}", "gists_url": "https://api.github.com/users/rasbt/gists{/gist_id}", "starred_url": "https://api.github.com/users/rasbt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rasbt/subscriptions", "organizations_url": "https://api.github.com/users/rasbt/orgs", "repos_url": "https://api.github.com/users/rasbt/repos", "events_url": "https://api.github.com/users/rasbt/events{/privacy}", "received_events_url": "https://api.github.com/users/rasbt/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-22T19:15:42Z", "updated_at": "2017-01-22T19:15:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>When I suggested this, I was thinking of a use case where we may have a bunch of model-training scripts that we want to execute in an environment where a different backend is installed (some time along the road). In this case, it would be slightly more convenient to just set the \"default\" backend instead of modifying all the 'cuda' calls to 'cl' or vice versa.</p>\n<p>However, I also agree that</p>\n<blockquote>\n<p>.cuda() and .cl() for backend specific transfers.</p>\n</blockquote>\n<p>may be a good idea to avoid cluttering the internals with <code>if ... then</code>s. (vs <code>gpu('cuda')</code> and <code>gpu('cl')</code>).</p>", "body_text": "When I suggested this, I was thinking of a use case where we may have a bunch of model-training scripts that we want to execute in an environment where a different backend is installed (some time along the road). In this case, it would be slightly more convenient to just set the \"default\" backend instead of modifying all the 'cuda' calls to 'cl' or vice versa.\nHowever, I also agree that\n\n.cuda() and .cl() for backend specific transfers.\n\nmay be a good idea to avoid cluttering the internals with if ... thens. (vs gpu('cuda') and gpu('cl')).", "body": "When I suggested this, I was thinking of a use case where we may have a bunch of model-training scripts that we want to execute in an environment where a different backend is installed (some time along the road). In this case, it would be slightly more convenient to just set the \"default\" backend instead of modifying all the 'cuda' calls to 'cl' or vice versa. \r\n\r\nHowever, I also agree that \r\n\r\n> .cuda() and .cl() for backend specific transfers.\r\n\r\nmay be a good idea to avoid cluttering the internals with `if ... then`s. (vs `gpu('cuda')` and `gpu('cl')`).\r\n\r\n"}