{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/274338459", "html_url": "https://github.com/pytorch/pytorch/issues/542#issuecomment-274338459", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/542", "id": 274338459, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDMzODQ1OQ==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-22T15:44:15Z", "updated_at": "2017-01-22T15:44:15Z", "author_association": "MEMBER", "body_html": "<p>I think that once we add support for non-CUDA technologies, there might be value in keeping both - exactly for the case then you want to use some NVIDIA GPUs, and some AMD. You can have <code>.gpu()</code> sending tensors using the currently selected \"default GPU backend\", and <code>.cuda()</code> and <code>.cl()</code> for backend specific transfers. Otherwise <code>.gpu()</code> would have to accept additional arguments, and passing them to every single call would look awful.</p>\n<p>That being said, I think that deprecating <code>.cuda()</code> in favor of <code>.gpu()</code> seems reasonable for now.</p>", "body_text": "I think that once we add support for non-CUDA technologies, there might be value in keeping both - exactly for the case then you want to use some NVIDIA GPUs, and some AMD. You can have .gpu() sending tensors using the currently selected \"default GPU backend\", and .cuda() and .cl() for backend specific transfers. Otherwise .gpu() would have to accept additional arguments, and passing them to every single call would look awful.\nThat being said, I think that deprecating .cuda() in favor of .gpu() seems reasonable for now.", "body": "I think that once we add support for non-CUDA technologies, there might be value in keeping both - exactly for the case then you want to use some NVIDIA GPUs, and some AMD. You can have `.gpu()` sending tensors using the currently selected \"default GPU backend\", and `.cuda()` and `.cl()` for backend specific transfers. Otherwise `.gpu()` would have to accept additional arguments, and passing them to every single call would look awful.\r\n\r\nThat being said, I think that deprecating `.cuda()` in favor of `.gpu()` seems reasonable for now."}