{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2344", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2344/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2344/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2344/events", "html_url": "https://github.com/pytorch/pytorch/issues/2344", "id": 248776507, "node_id": "MDU6SXNzdWUyNDg3NzY1MDc=", "number": 2344, "title": "Does CosineEmbeddingLoss support CUDA tensors?", "user": {"login": "sderygithub", "id": 7275405, "node_id": "MDQ6VXNlcjcyNzU0MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/7275405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sderygithub", "html_url": "https://github.com/sderygithub", "followers_url": "https://api.github.com/users/sderygithub/followers", "following_url": "https://api.github.com/users/sderygithub/following{/other_user}", "gists_url": "https://api.github.com/users/sderygithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/sderygithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sderygithub/subscriptions", "organizations_url": "https://api.github.com/users/sderygithub/orgs", "repos_url": "https://api.github.com/users/sderygithub/repos", "events_url": "https://api.github.com/users/sderygithub/events{/privacy}", "received_events_url": "https://api.github.com/users/sderygithub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-08T16:40:14Z", "updated_at": "2017-08-08T16:44:47Z", "closed_at": "2017-08-08T16:44:47Z", "author_association": "NONE", "body_html": "<p>Noticed this as I tried to use the CosineEmbeddingLoss with a model copied to the GPU.</p>\n<pre><code>import torch\nfrom torch.autograd import Variable\nfrom torch.nn._functions.loss import CosineEmbeddingLoss\n\ninput1 = Variable(torch.rand(5,10))\ninput1 = input1.cuda()\n\ninput2 = Variable(torch.rand(5,10))\ninput2 = input2.cuda()\n\ny = Variable(torch.FloatTensor([1.0] * input1.size()[0]))\n\nloss = CosineEmbeddingLoss()\nloss(input1, input2, y)\n\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/loss.py\", line 41, in forward\n    torch.eq(y, -1, out=_idx)\nTypeError: torch.eq received an invalid combination of arguments - got (torch.FloatTensor, int, out=torch.cuda.ByteTensor), but expected one of:\n * (torch.FloatTensor tensor, float value, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, float value, *, torch.ByteTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.ByteTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n</code></pre>\n<p>My default assumption is that I'm using cuda() wrong in some way. Thoughts?</p>", "body_text": "Noticed this as I tried to use the CosineEmbeddingLoss with a model copied to the GPU.\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn._functions.loss import CosineEmbeddingLoss\n\ninput1 = Variable(torch.rand(5,10))\ninput1 = input1.cuda()\n\ninput2 = Variable(torch.rand(5,10))\ninput2 = input2.cuda()\n\ny = Variable(torch.FloatTensor([1.0] * input1.size()[0]))\n\nloss = CosineEmbeddingLoss()\nloss(input1, input2, y)\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/loss.py\", line 41, in forward\n    torch.eq(y, -1, out=_idx)\nTypeError: torch.eq received an invalid combination of arguments - got (torch.FloatTensor, int, out=torch.cuda.ByteTensor), but expected one of:\n * (torch.FloatTensor tensor, float value, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, float value, *, torch.ByteTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.ByteTensor out)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\n\nMy default assumption is that I'm using cuda() wrong in some way. Thoughts?", "body": "Noticed this as I tried to use the CosineEmbeddingLoss with a model copied to the GPU.\r\n\r\n```\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom torch.nn._functions.loss import CosineEmbeddingLoss\r\n\r\ninput1 = Variable(torch.rand(5,10))\r\ninput1 = input1.cuda()\r\n\r\ninput2 = Variable(torch.rand(5,10))\r\ninput2 = input2.cuda()\r\n\r\ny = Variable(torch.FloatTensor([1.0] * input1.size()[0]))\r\n\r\nloss = CosineEmbeddingLoss()\r\nloss(input1, input2, y)\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/loss.py\", line 41, in forward\r\n    torch.eq(y, -1, out=_idx)\r\nTypeError: torch.eq received an invalid combination of arguments - got (torch.FloatTensor, int, out=torch.cuda.ByteTensor), but expected one of:\r\n * (torch.FloatTensor tensor, float value, *, torch.FloatTensor out)\r\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\r\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.FloatTensor out)\r\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\r\n * (torch.FloatTensor tensor, float value, *, torch.ByteTensor out)\r\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\r\n * (torch.FloatTensor tensor, torch.FloatTensor other, *, torch.ByteTensor out)\r\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, int, out=torch.cuda.ByteTensor)\r\n```\r\n\r\nMy default assumption is that I'm using cuda() wrong in some way. Thoughts?"}