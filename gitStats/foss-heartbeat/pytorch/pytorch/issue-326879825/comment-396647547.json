{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/396647547", "html_url": "https://github.com/pytorch/pytorch/pull/7889#issuecomment-396647547", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7889", "id": 396647547, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjY0NzU0Nw==", "user": {"login": "bado-lee", "id": 26222919, "node_id": "MDQ6VXNlcjI2MjIyOTE5", "avatar_url": "https://avatars1.githubusercontent.com/u/26222919?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bado-lee", "html_url": "https://github.com/bado-lee", "followers_url": "https://api.github.com/users/bado-lee/followers", "following_url": "https://api.github.com/users/bado-lee/following{/other_user}", "gists_url": "https://api.github.com/users/bado-lee/gists{/gist_id}", "starred_url": "https://api.github.com/users/bado-lee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bado-lee/subscriptions", "organizations_url": "https://api.github.com/users/bado-lee/orgs", "repos_url": "https://api.github.com/users/bado-lee/repos", "events_url": "https://api.github.com/users/bado-lee/events{/privacy}", "received_events_url": "https://api.github.com/users/bado-lee/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T16:13:27Z", "updated_at": "2018-06-12T16:13:27Z", "author_association": "NONE", "body_html": "<p><a href=\"https://discuss.pytorch.org/t/how-to-use-torch-optim-lr-scheduler-exponentiallr/12444/5\" rel=\"nofollow\">https://discuss.pytorch.org/t/how-to-use-torch-optim-lr-scheduler-exponentiallr/12444/5</a><br>\nI think above is what pretty much everyone would do. Given the name is \"step\".<br>\nBut current code will run with same lr for the first 200 iterations instead of 100.</p>", "body_text": "https://discuss.pytorch.org/t/how-to-use-torch-optim-lr-scheduler-exponentiallr/12444/5\nI think above is what pretty much everyone would do. Given the name is \"step\".\nBut current code will run with same lr for the first 200 iterations instead of 100.", "body": "https://discuss.pytorch.org/t/how-to-use-torch-optim-lr-scheduler-exponentiallr/12444/5\r\nI think above is what pretty much everyone would do. Given the name is \"step\".\r\nBut current code will run with same lr for the first 200 iterations instead of 100."}