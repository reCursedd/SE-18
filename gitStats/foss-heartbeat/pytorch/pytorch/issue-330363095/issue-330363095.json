{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8243", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8243/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8243/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8243/events", "html_url": "https://github.com/pytorch/pytorch/pull/8243", "id": 330363095, "node_id": "MDExOlB1bGxSZXF1ZXN0MTkzMzkxODQ2", "number": 8243, "title": "Don't override Tensor, Storage macros defined outside torch/csrc in t\u2026", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-06-07T17:16:10Z", "updated_at": "2018-06-07T20:10:11Z", "closed_at": "2018-06-07T20:10:11Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8243", "html_url": "https://github.com/pytorch/pytorch/pull/8243", "diff_url": "https://github.com/pytorch/pytorch/pull/8243.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8243.patch"}, "body_html": "<p>\u2026orch/csrc.</p>\n<p>This PR does the following:</p>\n<ol>\n<li>Removes THSTensor macros in torch/csrc, which aren't used.</li>\n<li>For macros defined outside of torch/csrc (THTensor, THTensor_, THStorage, THStorage_):<br>\na) No longer override them, i.e. previously THTensor could actually be THCTensor if a generic file was included from a file including THCP.h.<br>\nb) Instead, introduce new macros THW* (e.g. THWTensor) to represent a (potentially empty) wildcard character.</li>\n</ol>\n<p>In addition to making this code easier to read and codemod, this allows us to more freely change TH/THC; for example:<br>\ncurrently in the THC random code, the state is casted to THByteTensor*; this happens to work because the macros don't happen to override THByteTensor.</p>\n<p>But if THByteTensor just becomes an alias of THTensor (which is the plan for a single tensor type), then this no longer works (THByteTensor is now THCTensor!).</p>\n<p>The whole thing is a bit of a mess previously because you really have to understand which macros and redefined and which aren't.</p>\n<p>We could also rename the macros that live in torch/csrc (e.g. the THPTensor macros), but since that is more self contained, I punted for now.</p>", "body_text": "\u2026orch/csrc.\nThis PR does the following:\n\nRemoves THSTensor macros in torch/csrc, which aren't used.\nFor macros defined outside of torch/csrc (THTensor, THTensor_, THStorage, THStorage_):\na) No longer override them, i.e. previously THTensor could actually be THCTensor if a generic file was included from a file including THCP.h.\nb) Instead, introduce new macros THW* (e.g. THWTensor) to represent a (potentially empty) wildcard character.\n\nIn addition to making this code easier to read and codemod, this allows us to more freely change TH/THC; for example:\ncurrently in the THC random code, the state is casted to THByteTensor*; this happens to work because the macros don't happen to override THByteTensor.\nBut if THByteTensor just becomes an alias of THTensor (which is the plan for a single tensor type), then this no longer works (THByteTensor is now THCTensor!).\nThe whole thing is a bit of a mess previously because you really have to understand which macros and redefined and which aren't.\nWe could also rename the macros that live in torch/csrc (e.g. the THPTensor macros), but since that is more self contained, I punted for now.", "body": "\u2026orch/csrc.\r\n\r\nThis PR does the following:\r\n1) Removes THSTensor macros in torch/csrc, which aren't used.\r\n2) For macros defined outside of torch/csrc (THTensor, THTensor_, THStorage, THStorage_):\r\na) No longer override them, i.e. previously THTensor could actually be THCTensor if a generic file was included from a file including THCP.h.\r\nb) Instead, introduce new macros THW* (e.g. THWTensor) to represent a (potentially empty) wildcard character.\r\n\r\nIn addition to making this code easier to read and codemod, this allows us to more freely change TH/THC; for example:\r\ncurrently in the THC random code, the state is casted to THByteTensor*; this happens to work because the macros don't happen to override THByteTensor.\r\n\r\nBut if THByteTensor just becomes an alias of THTensor (which is the plan for a single tensor type), then this no longer works (THByteTensor is now THCTensor!).\r\n\r\nThe whole thing is a bit of a mess previously because you really have to understand which macros and redefined and which aren't.\r\n\r\nWe could also rename the macros that live in torch/csrc (e.g. the THPTensor macros), but since that is more self contained, I punted for now."}