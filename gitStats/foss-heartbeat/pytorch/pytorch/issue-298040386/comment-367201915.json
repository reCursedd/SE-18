{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/367201915", "html_url": "https://github.com/pytorch/pytorch/pull/5287#issuecomment-367201915", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5287", "id": 367201915, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzIwMTkxNQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-21T03:24:25Z", "updated_at": "2018-02-21T03:24:25Z", "author_association": "CONTRIBUTOR", "body_html": "<ol>\n<li>The reason that I suggested separate loss is to avoid explicitly calculating (log) softmax and to take advantage of the faster <code>CrossEntropyLoss</code>. I think the <code>reduce</code> flag in other loss functions does something else. It indicates whether to return an aggregated loss or not. Here we probably want some flag that controls whether to return (log) probability.</li>\n<li>Yeah Python is fine as a start I think, although I'd prefer this in ATen to avoid Python interpreter overhead and in case people want to use it in cpp.</li>\n</ol>", "body_text": "The reason that I suggested separate loss is to avoid explicitly calculating (log) softmax and to take advantage of the faster CrossEntropyLoss. I think the reduce flag in other loss functions does something else. It indicates whether to return an aggregated loss or not. Here we probably want some flag that controls whether to return (log) probability.\nYeah Python is fine as a start I think, although I'd prefer this in ATen to avoid Python interpreter overhead and in case people want to use it in cpp.", "body": "1. The reason that I suggested separate loss is to avoid explicitly calculating (log) softmax and to take advantage of the faster `CrossEntropyLoss`. I think the `reduce` flag in other loss functions does something else. It indicates whether to return an aggregated loss or not. Here we probably want some flag that controls whether to return (log) probability.\r\n2. Yeah Python is fine as a start I think, although I'd prefer this in ATen to avoid Python interpreter overhead and in case people want to use it in cpp."}