{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/367427548", "html_url": "https://github.com/pytorch/pytorch/pull/5287#issuecomment-367427548", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5287", "id": 367427548, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzQyNzU0OA==", "user": {"login": "elanmart", "id": 10772830, "node_id": "MDQ6VXNlcjEwNzcyODMw", "avatar_url": "https://avatars3.githubusercontent.com/u/10772830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elanmart", "html_url": "https://github.com/elanmart", "followers_url": "https://api.github.com/users/elanmart/followers", "following_url": "https://api.github.com/users/elanmart/following{/other_user}", "gists_url": "https://api.github.com/users/elanmart/gists{/gist_id}", "starred_url": "https://api.github.com/users/elanmart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elanmart/subscriptions", "organizations_url": "https://api.github.com/users/elanmart/orgs", "repos_url": "https://api.github.com/users/elanmart/repos", "events_url": "https://api.github.com/users/elanmart/events{/privacy}", "received_events_url": "https://api.github.com/users/elanmart/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-21T18:41:18Z", "updated_at": "2018-02-21T18:41:18Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> If I understood You correctly, using <code>CrossEntropyLoss</code> should ultimately give the same result as using current implementation followed by <code>-output.mean()</code>, right? Then <code>reduce</code> flag would make sense (up to a sign)?</p>\n<p>Can you take a look at the new commit if this is what you had in mind?</p>\n<p>Running a quick test with <code>return_logprob=False</code> doesn't really give any speedup.</p>", "body_text": "@SsnL If I understood You correctly, using CrossEntropyLoss should ultimately give the same result as using current implementation followed by -output.mean(), right? Then reduce flag would make sense (up to a sign)?\nCan you take a look at the new commit if this is what you had in mind?\nRunning a quick test with return_logprob=False doesn't really give any speedup.", "body": "@SsnL If I understood You correctly, using `CrossEntropyLoss` should ultimately give the same result as using current implementation followed by `-output.mean()`, right? Then `reduce` flag would make sense (up to a sign)?\r\n\r\nCan you take a look at the new commit if this is what you had in mind? \r\n\r\nRunning a quick test with `return_logprob=False` doesn't really give any speedup."}