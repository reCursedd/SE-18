{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175875611", "pull_request_review_id": 105080028, "id": 175875611, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTg3NTYxMQ==", "diff_hunk": "@@ -0,0 +1,207 @@\n+import torch\n+\n+from . import Sequential, ModuleList, Linear\n+from .module import Module\n+from ..functional import log_softmax, cross_entropy\n+\n+\n+class AdaptiveLogSoftmax(Module):\n+    r\"\"\"Efficient softmax approximation as described in\n+    `Efficient softmax approximation for GPUs`_ by Edouard Grave, Armand Joulin,\n+     Moustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou.\n+\n+    Adaptive softmax is an approximate strategy for training models with large\n+    output spaces. It is most effective when the label distribution is highly\n+    imbalanced, for example in natural language modelling, where the word\n+    frequency distribution approximately follows the `Zipf's law`_.\n+\n+    Adaptive softmax partitions the labels into several clusters, according to\n+    their frequency. These clusters may contain different number of targets\n+    each.\n+    Additionally, clusters containig less frequent labels assign lower\n+    dimensional embeddings to those labels, which speeds up the computation.\n+    For each minibatch, only clusters for which at least one target is\n+    present are used.\n+\n+    The idea is that the cluster that the clusters that are accessed often\n+    (like the first one, containing most frequent labels), should also be cheap\n+    to compute -- that is, contain a small number of assigned targets.\n+\n+    We highly recommend taking a look at the original paper for more details.\n+\n+    ``cutoffs`` should be a Sequence of integers. It controls number of clusters\n+    and the partitioning of targets into clusters. For example setting\n+    ``cutoffs = [10, 100, 1000]`` means that first `10` targets will be assigned\n+    to the 'head' of the adaptive softmax, targets `11, 12, ..., 100` will be\n+    assigned to the first cluster, and targets `101, 102, ..., 1000` will be\n+    assigned to the second cluster, while targets\n+    `1001, 1002, ..., n_classes - 1` will be assigned to the last, third cluster\n+\n+    ``div_value`` is used to compute the size of each additional cluster,\n+    which is given as :math:`\\lfloor \\frac{in\\_features}{div\\_value^i} \\rfloor`,\n+    where :math:`i` is the cluster index (with clusters for less frequent words\n+    having larger indices, and indices starting at :math:`1`).\n+\n+    .. warning::\n+        Targets passed as inputs to this module should be sorted accoridng to\n+        their frequency. This means that the most frequent target should be\n+        represented by the index `0`, and the least frequent\n+        target should be represented by the index `n_classes - 1`.\n+\n+    .. note::\n+        To compute log-probabilities for all classes, the `predict_log_proba`\n+        method can be used.\n+\n+    Args:\n+        in_features (int): Number of features in the input tensor\n+        n_classes (int): Number of classes in the dataset.\n+        cutoffs (Sequence): Cutoffs used to assign targets to their buckets.\n+        div_value (float, optional): value used as an exponent to compute sizes\n+        of the clusters. Default: 2.0\n+\n+    Returns:\n+        A Variable of size ``N``, containing computed target log probabilities\n+        for each example\n+\n+    Shape:\n+        - Input: :math:`(N, in\\_features)`\n+        - Target: :math:`(N)` where each value is `0 <= targets[i] <= C - 1`\n+        - Output: :math:`(N)`\n+\n+    .. _Efficient softmax approximation for GPUs:\n+        https://arxiv.org/abs/1609.04309\n+\n+    .. _Zipf's law:\n+        https://en.wikipedia.org/wiki/Zipf%27s_law\n+    \"\"\"\n+\n+    def __init__(self, in_features, n_classes, cutoffs, div_value=2.,\n+                 return_logprob=False):\n+        super(AdaptiveLogSoftmax, self).__init__()\n+\n+        cutoffs = list(cutoffs)\n+\n+        if (cutoffs != sorted(cutoffs)):\n+            raise ValueError('Cutoffs should be a list of unique, positive in')\n+\n+        if (cutoffs != sorted(cutoffs)) \\\n+                or (max(cutoffs) >= (n_classes - 1)) \\\n+                or (len(set(cutoffs)) != len(cutoffs)):\n+\n+            raise ValueError(\"Cutoffs should be a sequence of unique, positive \"\n+                             \"integers sorted in an increasing order, where \"\n+                             \"each value is between 1 and n_classes-1\")\n+\n+        self.return_logprob = return_logprob\n+        self.in_features = in_features\n+        self.n_classes = n_classes\n+        self.cutoffs = cutoffs + [n_classes]\n+        self.div_value = div_value\n+\n+        self.shortlist_size = self.cutoffs[0]\n+        self.n_clusters = len(self.cutoffs) - 1\n+        self.head_size = self.shortlist_size + self.n_clusters\n+\n+        self.head = Linear(self.in_features, self.head_size)\n+        self.tail = ModuleList()\n+\n+        for i in range(self.n_clusters):\n+\n+            hsz = int(self.in_features // (self.div_value ** (i + 1)))\n+            osz = self.cutoffs[i + 1] - self.cutoffs[i]\n+\n+            projection = Sequential(\n+                Linear(self.in_features, hsz, bias=False),\n+                Linear(hsz, osz)", "path": "torch/nn/modules/adaptive.py", "position": null, "original_position": 115, "commit_id": "7f89e1506a4e2df824118d3bc6e1e31f4073fc70", "original_commit_id": "5cf5cdce51b9a44f0ead48f09643719e9fa6d5de", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "this also should have `bias=False`", "created_at": "2018-03-20T18:24:23Z", "updated_at": "2018-11-23T15:40:59Z", "html_url": "https://github.com/pytorch/pytorch/pull/5287#discussion_r175875611", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5287", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175875611"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5287#discussion_r175875611"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5287"}}, "body_html": "<p>this also should have <code>bias=False</code></p>", "body_text": "this also should have bias=False"}