{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175535039", "pull_request_review_id": 105080028, "id": 175535039, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTUzNTAzOQ==", "diff_hunk": "@@ -0,0 +1,207 @@\n+import torch\n+\n+from . import Sequential, ModuleList, Linear\n+from .module import Module\n+from ..functional import log_softmax, cross_entropy\n+\n+\n+class AdaptiveLogSoftmax(Module):\n+    r\"\"\"Efficient softmax approximation as described in\n+    `Efficient softmax approximation for GPUs`_ by Edouard Grave, Armand Joulin,\n+     Moustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou.\n+\n+    Adaptive softmax is an approximate strategy for training models with large\n+    output spaces. It is most effective when the label distribution is highly\n+    imbalanced, for example in natural language modelling, where the word\n+    frequency distribution approximately follows the `Zipf's law`_.\n+\n+    Adaptive softmax partitions the labels into several clusters, according to\n+    their frequency. These clusters may contain different number of targets\n+    each.\n+    Additionally, clusters containig less frequent labels assign lower\n+    dimensional embeddings to those labels, which speeds up the computation.\n+    For each minibatch, only clusters for which at least one target is\n+    present are used.\n+\n+    The idea is that the cluster that the clusters that are accessed often\n+    (like the first one, containing most frequent labels), should also be cheap\n+    to compute -- that is, contain a small number of assigned targets.\n+\n+    We highly recommend taking a look at the original paper for more details.\n+\n+    ``cutoffs`` should be a Sequence of integers. It controls number of clusters\n+    and the partitioning of targets into clusters. For example setting\n+    ``cutoffs = [10, 100, 1000]`` means that first `10` targets will be assigned\n+    to the 'head' of the adaptive softmax, targets `11, 12, ..., 100` will be\n+    assigned to the first cluster, and targets `101, 102, ..., 1000` will be\n+    assigned to the second cluster, while targets\n+    `1001, 1002, ..., n_classes - 1` will be assigned to the last, third cluster\n+\n+    ``div_value`` is used to compute the size of each additional cluster,\n+    which is given as :math:`\\lfloor \\frac{in\\_features}{div\\_value^i} \\rfloor`,\n+    where :math:`i` is the cluster index (with clusters for less frequent words\n+    having larger indices, and indices starting at :math:`1`).\n+\n+    .. warning::\n+        Targets passed as inputs to this module should be sorted accoridng to\n+        their frequency. This means that the most frequent target should be\n+        represented by the index `0`, and the least frequent\n+        target should be represented by the index `n_classes - 1`.\n+\n+    .. note::\n+        To compute log-probabilities for all classes, the `predict_log_proba`\n+        method can be used.\n+\n+    Args:\n+        in_features (int): Number of features in the input tensor\n+        n_classes (int): Number of classes in the dataset.\n+        cutoffs (Sequence): Cutoffs used to assign targets to their buckets.\n+        div_value (float, optional): value used as an exponent to compute sizes\n+        of the clusters. Default: 2.0\n+", "path": "torch/nn/modules/adaptive.py", "position": null, "original_position": 61, "commit_id": "7f89e1506a4e2df824118d3bc6e1e31f4073fc70", "original_commit_id": "5cf5cdce51b9a44f0ead48f09643719e9fa6d5de", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "missing doc for `return_logprob`", "created_at": "2018-03-19T18:12:23Z", "updated_at": "2018-11-23T15:40:57Z", "html_url": "https://github.com/pytorch/pytorch/pull/5287#discussion_r175535039", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5287", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175535039"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5287#discussion_r175535039"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5287"}}, "body_html": "<p>missing doc for <code>return_logprob</code></p>", "body_text": "missing doc for return_logprob"}