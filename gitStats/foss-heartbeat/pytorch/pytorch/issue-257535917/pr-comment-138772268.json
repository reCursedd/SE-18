{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/138772268", "pull_request_review_id": 62613197, "id": 138772268, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzODc3MjI2OA==", "diff_hunk": "@@ -0,0 +1,302 @@\n+#ifndef TH_GENERIC_FILE\n+#define TH_GENERIC_FILE \"generic/VolumetricAdaptiveAveragePooling.c\"\n+#else\n+\n+#define START_IND(a,b,c) (int)floor((float)(a * c) / b)\n+#define END_IND(a,b,c) (int)ceil((float)((a + 1) * c) / b)\n+// #define START_IND(a,b,c) a * c / b\n+// #define END_IND(a,b,c)  (a + 1) * c / b + ((a + 1) * c % b > 0)?1:0\n+\n+static void THNN_(VolumetricAdaptiveAveragePooling_updateOutput_frame)(\n+          real *input_p,\n+          real *output_p,\n+          long nslices,\n+          long isizeT,\n+          long isizeW,\n+          long isizeH,\n+          long osizeT,\n+          long osizeW,\n+          long osizeH,\n+          long istrideT,\n+          long istrideW,\n+          long istrideH,\n+          long strided)\n+{\n+  long k;\n+#pragma omp parallel for private(k)\n+  for (k = 0; k < nslices; k++)\n+  {\n+    /* loop over output */\n+    long ti, i, j;\n+    for(ti = 0; ti < osizeT; ti++)\n+    {\n+      int z_start = START_IND(ti, osizeT, isizeT);\n+      int z_end   = END_IND(ti, osizeT, isizeT);\n+      int kT = z_end - z_start;\n+\n+      for(i = 0; i < osizeH; i++)\n+      {\n+        int y_start = START_IND(i, osizeH, isizeH);\n+        int y_end   = END_IND(i, osizeH, isizeH);\n+        int kH = y_end - y_start;\n+\n+        for(j = 0; j < osizeW; j++)\n+        {\n+\n+          int x_start = START_IND(j, osizeW, isizeW);\n+          int x_end   = END_IND(j, osizeW, isizeW);\n+          int kW = x_end - x_start;\n+\n+          /* local pointers */\n+          real *ip = input_p  + k*strided + z_start*istrideT + y_start*istrideH + x_start*istrideW;\n+          real *op = output_p + k*osizeT*osizeW*osizeH + ti*osizeW*osizeH + i*osizeW + j;\n+\n+          /* compute local average: */\n+          real sum = 0;\n+          int x, y, z;\n+          for(z = 0; z < kT; z++)\n+          {\n+            for(y = 0; y < kH; y++)\n+            {\n+              for(x = 0; x < kW; x++)\n+              {\n+                real val = *(ip + z*istrideT + y*istrideH + x*istrideW);\n+                sum += val;\n+              }\n+            }\n+          }\n+\n+          /* set output to local average */\n+          *op = sum / kT / kW / kH;\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+void THNN_(VolumetricAdaptiveAveragePooling_updateOutput)(\n+          THNNState *state,\n+          THTensor *input,\n+          THTensor *output,\n+          int osizeT,\n+          int osizeW,\n+          int osizeH)\n+{\n+  int dimd = 0;\n+  int dimt = 1;\n+  int dimh = 2;\n+  int dimw = 3;\n+  long nbatch = 1;\n+  long nslices;\n+  long isizeT;\n+  long isizeH;\n+  long isizeW;\n+\n+  long istrideB;\n+  long istrideD;\n+  long istrideT;\n+  long istrideW;\n+  long istrideH;\n+\n+  real *input_data;\n+  real *output_data;\n+\n+\n+  THNN_ARGCHECK(input->nDimension == 4 || input->nDimension == 5, 2, input,\n+\t\t\"4D or 5D (batch mode) tensor expected for input, but got: %s\");\n+\n+  if (input->nDimension == 5)\n+  {\n+    istrideB = input->stride[0];\n+    nbatch = input->size[0];\n+    dimd++;\n+    dimt++;\n+    dimh++;\n+    dimw++;\n+  }\n+\n+  /* sizes */\n+  nslices = input->size[dimd];\n+  isizeT = input->size[dimt];\n+  isizeH = input->size[dimh];\n+  isizeW = input->size[dimw];\n+  /* strides */\n+  istrideD = input->stride[dimd];\n+  istrideT = input->stride[dimt];\n+  istrideH = input->stride[dimh];\n+  istrideW = input->stride[dimw];\n+\n+  /* resize output */\n+  if (input->nDimension == 4)\n+  {\n+    THTensor_(resize4d)(output, nslices, osizeT, osizeH, osizeW);\n+\n+    input_data = THTensor_(data)(input);\n+    output_data = THTensor_(data)(output);\n+\n+    THNN_(VolumetricAdaptiveAveragePooling_updateOutput_frame)(input_data, output_data,\n+                                                      nslices,\n+                                                      isizeT, isizeW, isizeH,\n+                                                      osizeT, osizeW, osizeH,\n+                                                      istrideT, istrideW, istrideH,\n+                                                      istrideD);\n+  }\n+  else\n+  {\n+    long p;\n+\n+    THTensor_(resize5d)(output, nbatch, nslices, osizeT, osizeH, osizeW);\n+\n+    input_data = THTensor_(data)(input);\n+    output_data = THTensor_(data)(output);\n+\n+#pragma omp parallel for private(p)\n+    for (p = 0; p < nbatch; p++)\n+    {\n+      THNN_(VolumetricAdaptiveAveragePooling_updateOutput_frame)(input_data+p*istrideB, output_data+p*nslices*osizeT*osizeW*osizeH,\n+                                                        nslices,\n+                                                        isizeT, isizeW, isizeH,\n+                                                        osizeT, osizeW, osizeH,\n+                                                        istrideT, istrideW, istrideH,\n+                                                        istrideD);\n+    }\n+  }\n+}\n+\n+static void THNN_(VolumetricAdaptiveAveragePooling_updateGradInput_frame)(\n+          real *gradInput_p,\n+          real *gradOutput_p,\n+          long nslices,\n+          long isizeT,\n+          long isizeW,\n+          long isizeH,\n+          long osizeT,\n+          long osizeW,\n+          long osizeH)\n+{\n+  long k;\n+#pragma omp parallel for private(k)\n+  for (k = 0; k < nslices; k++)\n+  {\n+    real *gradInput_p_k = gradInput_p + k*isizeT*isizeW*isizeH;\n+    real *gradOutput_p_k = gradOutput_p + k*osizeT*osizeW*osizeH;\n+\n+    /* calculate average */\n+    long ti, i, j;\n+    for(ti = 0; ti < osizeT; ti++)\n+    {\n+      int z_start = START_IND(ti, osizeT, isizeT);\n+      int z_end   = END_IND(ti, osizeT, isizeT);\n+      int kT = z_end - z_start;\n+\n+      for(i = 0; i < osizeH; i++)\n+      {\n+        int y_start = START_IND(i, osizeH, isizeH);\n+        int y_end   = END_IND(i, osizeH, isizeH);\n+        int kH = y_end - y_start;\n+\n+        for(j = 0; j < osizeW; j++)\n+        {\n+\n+          int x_start = START_IND(j, osizeW, isizeW);\n+          int x_end   = END_IND(j, osizeW, isizeW);\n+          int kW = x_end - x_start;\n+\n+          real grad_delta = gradOutput_p_k[ti*osizeH*osizeW + i*osizeW + j] / kT / kW / kH;\n+\n+          int x, y, z;\n+          for(z = z_start; z < z_end; z++)\n+          {\n+            for(y = y_start; y < y_end; y++)\n+            {\n+              for(x = x_start; x < x_end; x++)\n+              {\n+                /* update gradient */\n+                gradInput_p_k[z*isizeH*isizeW + y*isizeW + x] += grad_delta;", "path": "torch/lib/THNN/generic/VolumetricAdaptiveAveragePooling.c", "position": null, "original_position": 215, "commit_id": "24d5909882d7e19e01a6e002cff2a43e92b53724", "original_commit_id": "c032bd0e6c6a1ac592cd6039452f25ad1bd88724", "user": {"login": "ruotianluo", "id": 16023153, "node_id": "MDQ6VXNlcjE2MDIzMTUz", "avatar_url": "https://avatars2.githubusercontent.com/u/16023153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ruotianluo", "html_url": "https://github.com/ruotianluo", "followers_url": "https://api.github.com/users/ruotianluo/followers", "following_url": "https://api.github.com/users/ruotianluo/following{/other_user}", "gists_url": "https://api.github.com/users/ruotianluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ruotianluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ruotianluo/subscriptions", "organizations_url": "https://api.github.com/users/ruotianluo/orgs", "repos_url": "https://api.github.com/users/ruotianluo/repos", "events_url": "https://api.github.com/users/ruotianluo/events{/privacy}", "received_events_url": "https://api.github.com/users/ruotianluo/received_events", "type": "User", "site_admin": false}, "body": "Because it's parallelized over batch and channel dimension.", "created_at": "2017-09-14T00:24:58Z", "updated_at": "2018-11-23T15:34:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/2728#discussion_r138772268", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2728", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/138772268"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2728#discussion_r138772268"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2728"}}, "body_html": "<p>Because it's parallelized over batch and channel dimension.</p>", "body_text": "Because it's parallelized over batch and channel dimension.", "in_reply_to_id": 138769087}