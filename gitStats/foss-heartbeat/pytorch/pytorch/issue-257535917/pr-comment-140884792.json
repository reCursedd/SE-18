{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/140884792", "pull_request_review_id": 65020593, "id": 140884792, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MDg4NDc5Mg==", "diff_hunk": "@@ -0,0 +1,173 @@\n+#ifndef THC_GENERIC_FILE\n+#define THC_GENERIC_FILE \"generic/VolumetricAdaptiveAveragePooling.cu\"\n+#else\n+\n+#include \"../common.h\"\n+\n+// 5d tensor B x D x T x H x W\n+\n+void THNN_(VolumetricAdaptiveAveragePooling_updateOutput)(\n+           THCState *state,\n+           THCTensor *input,\n+           THCTensor *output,\n+           int osizeT,\n+           int osizeW,\n+           int osizeH)\n+{\n+  THCUNN_assertSameGPU(state, 2, input, output);\n+\n+  THCUNN_argCheck(state, input->nDimension == 4 || input->nDimension == 5, 2, input,\n+                  \"4D or 5D (batch mode) tensor expected for input, but got: %s\");\n+\n+\n+  real *output_data;\n+  real *input_data;\n+\n+  int64_t sizeD, isizeT, isizeH, isizeW;\n+  int64_t istrideD, istrideT, istrideH, istrideW;\n+  int64_t totalZ;\n+\n+  if (input->nDimension == 4) {\n+    sizeD = input->size[0];\n+    isizeT = input->size[1];\n+    isizeH = input->size[2];\n+    isizeW = input->size[3];\n+\n+    istrideD = input->stride[0];\n+    istrideT = input->stride[1];\n+    istrideH = input->stride[2];\n+    istrideW = input->stride[3];\n+\n+    THCTensor_(resize4d)(state, output, sizeD, osizeT, osizeH, osizeW);\n+\n+    totalZ = sizeD * osizeT;\n+  } else {\n+    input = THCTensor_(newContiguous)(state, input);\n+\n+    int64_t sizeB = input->size[0];\n+    sizeD = input->size[1];\n+    isizeT = input->size[2];\n+    isizeH = input->size[3];\n+    isizeW = input->size[4];\n+\n+    istrideD = input->stride[1];\n+    istrideT = input->stride[2];\n+    istrideH = input->stride[3];\n+    istrideW = input->stride[4];\n+\n+    THCTensor_(resize5d)(state, output, sizeB, sizeD, osizeT, osizeH, osizeW);\n+\n+    totalZ = sizeB * sizeD * osizeT;\n+  }\n+\n+  input_data = THCTensor_(data)(state, input);\n+  output_data = THCTensor_(data)(state, output);\n+\n+  int64_t offsetZ = 0;\n+  dim3 threads(32, 8);\n+  // each H*W plane is processed by blocksH thread blocks\n+  int blocksH = max((int)(16L / totalZ), 1);\n+  while (totalZ > 0) {\n+    dim3 blocks(totalZ > 65535 ? 65535 : totalZ, blocksH);\n+    cunn_VolumetricAdaptiveAveragePooling_updateOutput_kernel\n+      <<<blocks, threads, 0, THCState_getCurrentStream(state)>>>(\n+        input_data, output_data, isizeT, isizeH, isizeW, osizeT, osizeH, osizeW,\n+        istrideD, istrideT, istrideH, istrideW, offsetZ\n+      );\n+\n+    totalZ -= 65535;\n+    offsetZ += 65535;\n+    THCudaCheck(cudaGetLastError());\n+  }\n+\n+  if (input->nDimension == 5) {\n+    // clean\n+    THCTensor_(free)(state, input);\n+  }\n+}\n+\n+void THNN_(VolumetricAdaptiveAveragePooling_updateGradInput)(\n+           THCState *state,\n+           THCTensor *input,\n+           THCTensor *gradOutput,\n+           THCTensor *gradInput)\n+{\n+  THCUNN_assertSameGPU(state, 3, input, gradOutput, gradInput);\n+\n+  gradOutput = THCTensor_(newContiguous)(state, gradOutput);\n+\n+  THCTensor_(resizeAs)(state, gradInput, input);\n+  THCTensor_(zero)(state, gradInput);\n+\n+  real *gradInput_data;\n+  real *gradOutput_data;\n+\n+  int64_t sizeD, isizeT, isizeH, isizeW;\n+  int64_t osizeT, osizeH, osizeW;\n+  int64_t totalZ;\n+\n+  if (input->nDimension == 4) {\n+    sizeD = input->size[0];\n+    isizeT = input->size[1];\n+    isizeH = input->size[2];\n+    isizeW = input->size[3];\n+\n+    osizeT = gradOutput->size[1];\n+    osizeH = gradOutput->size[2];\n+    osizeW = gradOutput->size[3];\n+  } else {\n+    sizeD = input->size[1];\n+    isizeT = input->size[2];\n+    isizeH = input->size[3];\n+    isizeW = input->size[4];\n+\n+    osizeT = gradOutput->size[2];\n+    osizeH = gradOutput->size[3];\n+    osizeW = gradOutput->size[4];\n+  }\n+\n+  // somehow nonatomic is passing all test for volumetric case.", "path": "torch/lib/THCUNN/generic/VolumetricAdaptiveAveragePooling.cu", "position": 129, "original_position": 129, "commit_id": "24d5909882d7e19e01a6e002cff2a43e92b53724", "original_commit_id": "24d5909882d7e19e01a6e002cff2a43e92b53724", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "For the record, if I remember properly the `SpatialAdaptiveMaxPooling` didn't indeed pass the tests without atomic operations , so I just used it by default and didn't look back to see why it was the case :-)", "created_at": "2017-09-25T20:13:04Z", "updated_at": "2018-11-23T15:34:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/2728#discussion_r140884792", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2728", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/140884792"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2728#discussion_r140884792"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2728"}}, "body_html": "<p>For the record, if I remember properly the <code>SpatialAdaptiveMaxPooling</code> didn't indeed pass the tests without atomic operations , so I just used it by default and didn't look back to see why it was the case :-)</p>", "body_text": "For the record, if I remember properly the SpatialAdaptiveMaxPooling didn't indeed pass the tests without atomic operations , so I just used it by default and didn't look back to see why it was the case :-)", "in_reply_to_id": 140867664}