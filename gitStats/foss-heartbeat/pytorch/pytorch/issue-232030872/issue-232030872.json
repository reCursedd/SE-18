{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1674", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1674/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1674/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1674/events", "html_url": "https://github.com/pytorch/pytorch/issues/1674", "id": 232030872, "node_id": "MDU6SXNzdWUyMzIwMzA4NzI=", "number": 1674, "title": "Backward segmentation fault", "user": {"login": "onlytailei", "id": 7247925, "node_id": "MDQ6VXNlcjcyNDc5MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/7247925?v=4", "gravatar_id": "", "url": "https://api.github.com/users/onlytailei", "html_url": "https://github.com/onlytailei", "followers_url": "https://api.github.com/users/onlytailei/followers", "following_url": "https://api.github.com/users/onlytailei/following{/other_user}", "gists_url": "https://api.github.com/users/onlytailei/gists{/gist_id}", "starred_url": "https://api.github.com/users/onlytailei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/onlytailei/subscriptions", "organizations_url": "https://api.github.com/users/onlytailei/orgs", "repos_url": "https://api.github.com/users/onlytailei/repos", "events_url": "https://api.github.com/users/onlytailei/events{/privacy}", "received_events_url": "https://api.github.com/users/onlytailei/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-05-29T13:59:47Z", "updated_at": "2017-06-29T02:13:06Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>In ubuntu 14.04, cuda 7.5.<br>\nI install the pytorch with pip and python 2.7<br>\nI run the pytorch tutorial <a href=\"http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py\" rel=\"nofollow\">neural networks</a>.<br>\nFor the notebook, the kernel keeps stopping and restarting in</p>\n<pre><code>net.zero_grad()\nout.backward(torch.randn(1, 10))\n</code></pre>\n<p>In the .py version, there is a segmentation fault.<br>\nThen <em>gdb --args python neural_networks_tutorial.py</em> shows that:</p>\n<pre><code>$ gdb --args python neural_networks_tutorial.py\nGNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1\nCopyright (C) 2014 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n&lt;http://www.gnu.org/software/gdb/bugs/&gt;.\nFind the GDB manual and other documentation resources online at:\n&lt;http://www.gnu.org/software/gdb/documentation/&gt;.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from python...Reading symbols from /usr/lib/debug//usr/bin/python2.7...done.\ndone.\n(gdb) r\nStarting program: /usr/bin/python neural_networks_tutorial.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nNet (\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear (400 -&gt; 120)\n  (fc2): Linear (120 -&gt; 84)\n  (fc3): Linear (84 -&gt; 10)\n)\n10\n(6L, 1L, 5L, 5L)\n[New Thread 0x7fffd001d780 (LWP 14613)]\n[New Thread 0x7fffcfc1c800 (LWP 14614)]\n[New Thread 0x7fffcf81b880 (LWP 14615)]\n[New Thread 0x7fffcf41a900 (LWP 14616)]\n[New Thread 0x7fffcf019980 (LWP 14617)]\n[New Thread 0x7fffcec18a00 (LWP 14618)]\n[New Thread 0x7fffce817a80 (LWP 14619)]\n[New Thread 0x7fffce416b00 (LWP 14620)]\n[New Thread 0x7fffce015b80 (LWP 14621)]\n[New Thread 0x7fffcdc14c00 (LWP 14622)]\n[New Thread 0x7fffcd813c80 (LWP 14623)]\n[New Thread 0x7fffcd412d00 (LWP 14624)]\n[New Thread 0x7fffcd011d80 (LWP 14625)]\n[New Thread 0x7fffccc10e00 (LWP 14626)]\n[New Thread 0x7fffcc80fe80 (LWP 14627)]\n[New Thread 0x7fffcc40ef00 (LWP 14628)]\n[New Thread 0x7fff8fffef80 (LWP 14629)]\n[New Thread 0x7fff8fafe000 (LWP 14630)]\n[New Thread 0x7fff8f3fd080 (LWP 14631)]\n[New Thread 0x7fff8effc100 (LWP 14632)]\n[New Thread 0x7fff8ebfb180 (LWP 14633)]\n[New Thread 0x7fff8e7fa200 (LWP 14634)]\n[New Thread 0x7fff8e3f9280 (LWP 14635)]\n[New Thread 0x7fff8dff8300 (LWP 14636)]\n[New Thread 0x7fff8dbf7380 (LWP 14637)]\n[New Thread 0x7fff8d7f6400 (LWP 14638)]\n[New Thread 0x7fff8d3f5480 (LWP 14639)]\n[New Thread 0x7fff8cff4500 (LWP 14640)]\n[New Thread 0x7fff8cbf3580 (LWP 14641)]\n[New Thread 0x7fff8c7f2600 (LWP 14642)]\n[New Thread 0x7fff57fff680 (LWP 14643)]\nVariable containing:\n1.00000e-02 *\n -9.1825 -2.2400 -9.6241  8.7923 -9.5927 -5.7082  7.3887  6.0140 -8.8177 -2.8286\n[torch.FloatTensor of size 1x10]\n\n[New Thread 0x7fff54f8d700 (LWP 14644)]\n[New Thread 0x7fff4bfff700 (LWP 14645)]\n[New Thread 0x7fff4b7fe700 (LWP 14646)]\n[New Thread 0x7fff4affd700 (LWP 14647)]\n[New Thread 0x7fff5478b780 (LWP 14648)]\n[New Thread 0x7fff4a7fb800 (LWP 14649)]\n[New Thread 0x7fff4a3f9880 (LWP 14650)]\n[New Thread 0x7fff49ff7900 (LWP 14651)]\n[New Thread 0x7fff49bf5980 (LWP 14652)]\n[New Thread 0x7fff497f3a00 (LWP 14653)]\n[New Thread 0x7fff493f1a80 (LWP 14654)]\n[New Thread 0x7fff48fefb00 (LWP 14655)]\n[New Thread 0x7fff48bedb80 (LWP 14656)]\n[New Thread 0x7fff487ebc00 (LWP 14657)]\n[New Thread 0x7fff0fffec80 (LWP 14658)]\n[New Thread 0x7fff0fbfcd00 (LWP 14659)]\n[New Thread 0x7fff0f7fad80 (LWP 14660)]\n[New Thread 0x7fff0f3f8e00 (LWP 14661)]\n\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fff4bfff700 (LWP 14645)]\n0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\n(gdb) where\n#0  0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\n#1  0x00007fffda8f5dce in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#2  0x00007fffd8810d13 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#3  0x00007fffd87e0b17 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#4  0x00007fffd87e1bd3 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#5  0x00007fffd87b96f8 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#6  0x00007fffda8f57ae in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#7  0x00007fffda8f4ed9 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#8  0x00007fffda8f3ff0 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#9  0x00007fffda920ca1 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#10 0x00007fffdc196063 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_lp64.so\n#11 0x00007fffece71f61 in THFloatBlas_gemm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\n#12 0x00007fffecc0ee60 in THFloatTensor_addmm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\n#13 0x00007fffec295df0 in THNN_FloatSpatialConvolutionMM_accGradParameters_frame () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\n#14 0x00007fffec34d4ef in THNN_FloatSpatialConvolutionMM_accGradParameters () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\n#15 0x00007ffff3891f0b in torch::nn::SpatialConvolutionMM_accGradParameters (input=input@entry=0x7fff40001ef0, gradOutput=gradOutput@entry=0x7fff400066d0, \n    gradWeight=&lt;optimized out&gt;, gradBias=gradBias@entry=0x7fff40001600, finput=finput@entry=0x14b3d30, fgradInput=fgradInput@entry=0x14b3d90, kW=5, kH=5, dW=1, dH=1, \n    padW=0, padH=0, scale=scale@entry=1) at torch/csrc/nn/THNN_generic.cpp:7624\n#16 0x00007ffff38756f3 in torch::autograd::compute_grad_params (input=0x7fff40001ef0, grad_output=0x7fff400066d0, weight=weight@entry=0x7fff400015a0, \n    bias=bias@entry=0x7fff40001f70, columns=0x14b3d30, ones=0x14b3d90, kernel_size=std::vector of length 2, capacity 2 = {...}, params=...)\n---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---\n    at torch/csrc/autograd/functions/convolution.cpp:491\n#17 0x00007ffff38773e7 in torch::autograd::ConvBackward::apply (this=0x14b4058, grad_outputs=...) at torch/csrc/autograd/functions/convolution.cpp:285\n#18 0x00007ffff385bc68 in call_function (task=...) at torch/csrc/autograd/engine.cpp:132\n#19 torch::autograd::Engine::evaluate_function (this=this@entry=0x7ffff4177640 &lt;engine&gt;, task=...) at torch/csrc/autograd/engine.cpp:137\n#20 0x00007ffff385d8ab in torch::autograd::Engine::thread_main (this=this@entry=0x7ffff4177640 &lt;engine&gt;, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\n    at torch/csrc/autograd/engine.cpp:96\n#21 0x00007ffff386f264 in PythonEngine::thread_main (this=0x7ffff4177640 &lt;engine&gt;, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\n    at torch/csrc/autograd/python_engine.cpp:21\n#22 0x00007ffff3860d98 in operator()&lt;std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;, void&gt; (__object=&lt;optimized out&gt;, this=&lt;optimized out&gt;)\n    at /py/envs/py2k/gcc/include/c++/functional:601\n#23 _M_invoke&lt;0ul, 1ul&gt; (this=&lt;optimized out&gt;) at /py/envs/py2k/gcc/include/c++/functional:1732\n#24 operator() (this=&lt;optimized out&gt;) at /py/envs/py2k/gcc/include/c++/functional:1720\n#25 std::thread::_Impl&lt;std::_Bind_simple&lt;std::_Mem_fn&lt;void (torch::autograd::Engine::*)(std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt; (torch::autograd::Engine*, std::shared_ptr&lt;torch::autograd::ReadyQueue&gt;)&gt; &gt;::_M_run() (this=&lt;optimized out&gt;) at /py/envs/py2k/gcc/include/c++/thread:115\n#26 0x00007fffdcb3aa60 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n#27 0x00007ffff7bc4182 in start_thread (arg=0x7fff4bfff700) at pthread_create.c:312\n#28 0x00007ffff78f147d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n</code></pre>\n<p>There is a manually installed mkl in the system. Is that the problem? Should I compile it from source?</p>", "body_text": "In ubuntu 14.04, cuda 7.5.\nI install the pytorch with pip and python 2.7\nI run the pytorch tutorial neural networks.\nFor the notebook, the kernel keeps stopping and restarting in\nnet.zero_grad()\nout.backward(torch.randn(1, 10))\n\nIn the .py version, there is a segmentation fault.\nThen gdb --args python neural_networks_tutorial.py shows that:\n$ gdb --args python neural_networks_tutorial.py\nGNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1\nCopyright (C) 2014 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n<http://www.gnu.org/software/gdb/bugs/>.\nFind the GDB manual and other documentation resources online at:\n<http://www.gnu.org/software/gdb/documentation/>.\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from python...Reading symbols from /usr/lib/debug//usr/bin/python2.7...done.\ndone.\n(gdb) r\nStarting program: /usr/bin/python neural_networks_tutorial.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nNet (\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear (400 -> 120)\n  (fc2): Linear (120 -> 84)\n  (fc3): Linear (84 -> 10)\n)\n10\n(6L, 1L, 5L, 5L)\n[New Thread 0x7fffd001d780 (LWP 14613)]\n[New Thread 0x7fffcfc1c800 (LWP 14614)]\n[New Thread 0x7fffcf81b880 (LWP 14615)]\n[New Thread 0x7fffcf41a900 (LWP 14616)]\n[New Thread 0x7fffcf019980 (LWP 14617)]\n[New Thread 0x7fffcec18a00 (LWP 14618)]\n[New Thread 0x7fffce817a80 (LWP 14619)]\n[New Thread 0x7fffce416b00 (LWP 14620)]\n[New Thread 0x7fffce015b80 (LWP 14621)]\n[New Thread 0x7fffcdc14c00 (LWP 14622)]\n[New Thread 0x7fffcd813c80 (LWP 14623)]\n[New Thread 0x7fffcd412d00 (LWP 14624)]\n[New Thread 0x7fffcd011d80 (LWP 14625)]\n[New Thread 0x7fffccc10e00 (LWP 14626)]\n[New Thread 0x7fffcc80fe80 (LWP 14627)]\n[New Thread 0x7fffcc40ef00 (LWP 14628)]\n[New Thread 0x7fff8fffef80 (LWP 14629)]\n[New Thread 0x7fff8fafe000 (LWP 14630)]\n[New Thread 0x7fff8f3fd080 (LWP 14631)]\n[New Thread 0x7fff8effc100 (LWP 14632)]\n[New Thread 0x7fff8ebfb180 (LWP 14633)]\n[New Thread 0x7fff8e7fa200 (LWP 14634)]\n[New Thread 0x7fff8e3f9280 (LWP 14635)]\n[New Thread 0x7fff8dff8300 (LWP 14636)]\n[New Thread 0x7fff8dbf7380 (LWP 14637)]\n[New Thread 0x7fff8d7f6400 (LWP 14638)]\n[New Thread 0x7fff8d3f5480 (LWP 14639)]\n[New Thread 0x7fff8cff4500 (LWP 14640)]\n[New Thread 0x7fff8cbf3580 (LWP 14641)]\n[New Thread 0x7fff8c7f2600 (LWP 14642)]\n[New Thread 0x7fff57fff680 (LWP 14643)]\nVariable containing:\n1.00000e-02 *\n -9.1825 -2.2400 -9.6241  8.7923 -9.5927 -5.7082  7.3887  6.0140 -8.8177 -2.8286\n[torch.FloatTensor of size 1x10]\n\n[New Thread 0x7fff54f8d700 (LWP 14644)]\n[New Thread 0x7fff4bfff700 (LWP 14645)]\n[New Thread 0x7fff4b7fe700 (LWP 14646)]\n[New Thread 0x7fff4affd700 (LWP 14647)]\n[New Thread 0x7fff5478b780 (LWP 14648)]\n[New Thread 0x7fff4a7fb800 (LWP 14649)]\n[New Thread 0x7fff4a3f9880 (LWP 14650)]\n[New Thread 0x7fff49ff7900 (LWP 14651)]\n[New Thread 0x7fff49bf5980 (LWP 14652)]\n[New Thread 0x7fff497f3a00 (LWP 14653)]\n[New Thread 0x7fff493f1a80 (LWP 14654)]\n[New Thread 0x7fff48fefb00 (LWP 14655)]\n[New Thread 0x7fff48bedb80 (LWP 14656)]\n[New Thread 0x7fff487ebc00 (LWP 14657)]\n[New Thread 0x7fff0fffec80 (LWP 14658)]\n[New Thread 0x7fff0fbfcd00 (LWP 14659)]\n[New Thread 0x7fff0f7fad80 (LWP 14660)]\n[New Thread 0x7fff0f3f8e00 (LWP 14661)]\n\nProgram received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fff4bfff700 (LWP 14645)]\n0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\n(gdb) where\n#0  0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\n#1  0x00007fffda8f5dce in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#2  0x00007fffd8810d13 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#3  0x00007fffd87e0b17 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#4  0x00007fffd87e1bd3 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#5  0x00007fffd87b96f8 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\n#6  0x00007fffda8f57ae in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#7  0x00007fffda8f4ed9 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#8  0x00007fffda8f3ff0 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#9  0x00007fffda920ca1 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\n#10 0x00007fffdc196063 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_lp64.so\n#11 0x00007fffece71f61 in THFloatBlas_gemm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\n#12 0x00007fffecc0ee60 in THFloatTensor_addmm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\n#13 0x00007fffec295df0 in THNN_FloatSpatialConvolutionMM_accGradParameters_frame () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\n#14 0x00007fffec34d4ef in THNN_FloatSpatialConvolutionMM_accGradParameters () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\n#15 0x00007ffff3891f0b in torch::nn::SpatialConvolutionMM_accGradParameters (input=input@entry=0x7fff40001ef0, gradOutput=gradOutput@entry=0x7fff400066d0, \n    gradWeight=<optimized out>, gradBias=gradBias@entry=0x7fff40001600, finput=finput@entry=0x14b3d30, fgradInput=fgradInput@entry=0x14b3d90, kW=5, kH=5, dW=1, dH=1, \n    padW=0, padH=0, scale=scale@entry=1) at torch/csrc/nn/THNN_generic.cpp:7624\n#16 0x00007ffff38756f3 in torch::autograd::compute_grad_params (input=0x7fff40001ef0, grad_output=0x7fff400066d0, weight=weight@entry=0x7fff400015a0, \n    bias=bias@entry=0x7fff40001f70, columns=0x14b3d30, ones=0x14b3d90, kernel_size=std::vector of length 2, capacity 2 = {...}, params=...)\n---Type <return> to continue, or q <return> to quit---\n    at torch/csrc/autograd/functions/convolution.cpp:491\n#17 0x00007ffff38773e7 in torch::autograd::ConvBackward::apply (this=0x14b4058, grad_outputs=...) at torch/csrc/autograd/functions/convolution.cpp:285\n#18 0x00007ffff385bc68 in call_function (task=...) at torch/csrc/autograd/engine.cpp:132\n#19 torch::autograd::Engine::evaluate_function (this=this@entry=0x7ffff4177640 <engine>, task=...) at torch/csrc/autograd/engine.cpp:137\n#20 0x00007ffff385d8ab in torch::autograd::Engine::thread_main (this=this@entry=0x7ffff4177640 <engine>, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\n    at torch/csrc/autograd/engine.cpp:96\n#21 0x00007ffff386f264 in PythonEngine::thread_main (this=0x7ffff4177640 <engine>, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\n    at torch/csrc/autograd/python_engine.cpp:21\n#22 0x00007ffff3860d98 in operator()<std::shared_ptr<torch::autograd::ReadyQueue>, void> (__object=<optimized out>, this=<optimized out>)\n    at /py/envs/py2k/gcc/include/c++/functional:601\n#23 _M_invoke<0ul, 1ul> (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/functional:1732\n#24 operator() (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/functional:1720\n#25 std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/thread:115\n#26 0x00007fffdcb3aa60 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n#27 0x00007ffff7bc4182 in start_thread (arg=0x7fff4bfff700) at pthread_create.c:312\n#28 0x00007ffff78f147d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\n\nThere is a manually installed mkl in the system. Is that the problem? Should I compile it from source?", "body": "In ubuntu 14.04, cuda 7.5.\r\nI install the pytorch with pip and python 2.7\r\nI run the pytorch tutorial [neural networks](http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py). \r\nFor the notebook, the kernel keeps stopping and restarting in \r\n```\r\nnet.zero_grad()\r\nout.backward(torch.randn(1, 10))\r\n```\r\n\r\nIn the .py version, there is a segmentation fault.\r\nThen _gdb --args python neural_networks_tutorial.py_ shows that:\r\n```\r\n$ gdb --args python neural_networks_tutorial.py\r\nGNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1\r\nCopyright (C) 2014 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\r\nand \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n<http://www.gnu.org/software/gdb/documentation/>.\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python...Reading symbols from /usr/lib/debug//usr/bin/python2.7...done.\r\ndone.\r\n(gdb) r\r\nStarting program: /usr/bin/python neural_networks_tutorial.py\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nNet (\r\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\r\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\r\n  (fc1): Linear (400 -> 120)\r\n  (fc2): Linear (120 -> 84)\r\n  (fc3): Linear (84 -> 10)\r\n)\r\n10\r\n(6L, 1L, 5L, 5L)\r\n[New Thread 0x7fffd001d780 (LWP 14613)]\r\n[New Thread 0x7fffcfc1c800 (LWP 14614)]\r\n[New Thread 0x7fffcf81b880 (LWP 14615)]\r\n[New Thread 0x7fffcf41a900 (LWP 14616)]\r\n[New Thread 0x7fffcf019980 (LWP 14617)]\r\n[New Thread 0x7fffcec18a00 (LWP 14618)]\r\n[New Thread 0x7fffce817a80 (LWP 14619)]\r\n[New Thread 0x7fffce416b00 (LWP 14620)]\r\n[New Thread 0x7fffce015b80 (LWP 14621)]\r\n[New Thread 0x7fffcdc14c00 (LWP 14622)]\r\n[New Thread 0x7fffcd813c80 (LWP 14623)]\r\n[New Thread 0x7fffcd412d00 (LWP 14624)]\r\n[New Thread 0x7fffcd011d80 (LWP 14625)]\r\n[New Thread 0x7fffccc10e00 (LWP 14626)]\r\n[New Thread 0x7fffcc80fe80 (LWP 14627)]\r\n[New Thread 0x7fffcc40ef00 (LWP 14628)]\r\n[New Thread 0x7fff8fffef80 (LWP 14629)]\r\n[New Thread 0x7fff8fafe000 (LWP 14630)]\r\n[New Thread 0x7fff8f3fd080 (LWP 14631)]\r\n[New Thread 0x7fff8effc100 (LWP 14632)]\r\n[New Thread 0x7fff8ebfb180 (LWP 14633)]\r\n[New Thread 0x7fff8e7fa200 (LWP 14634)]\r\n[New Thread 0x7fff8e3f9280 (LWP 14635)]\r\n[New Thread 0x7fff8dff8300 (LWP 14636)]\r\n[New Thread 0x7fff8dbf7380 (LWP 14637)]\r\n[New Thread 0x7fff8d7f6400 (LWP 14638)]\r\n[New Thread 0x7fff8d3f5480 (LWP 14639)]\r\n[New Thread 0x7fff8cff4500 (LWP 14640)]\r\n[New Thread 0x7fff8cbf3580 (LWP 14641)]\r\n[New Thread 0x7fff8c7f2600 (LWP 14642)]\r\n[New Thread 0x7fff57fff680 (LWP 14643)]\r\nVariable containing:\r\n1.00000e-02 *\r\n -9.1825 -2.2400 -9.6241  8.7923 -9.5927 -5.7082  7.3887  6.0140 -8.8177 -2.8286\r\n[torch.FloatTensor of size 1x10]\r\n\r\n[New Thread 0x7fff54f8d700 (LWP 14644)]\r\n[New Thread 0x7fff4bfff700 (LWP 14645)]\r\n[New Thread 0x7fff4b7fe700 (LWP 14646)]\r\n[New Thread 0x7fff4affd700 (LWP 14647)]\r\n[New Thread 0x7fff5478b780 (LWP 14648)]\r\n[New Thread 0x7fff4a7fb800 (LWP 14649)]\r\n[New Thread 0x7fff4a3f9880 (LWP 14650)]\r\n[New Thread 0x7fff49ff7900 (LWP 14651)]\r\n[New Thread 0x7fff49bf5980 (LWP 14652)]\r\n[New Thread 0x7fff497f3a00 (LWP 14653)]\r\n[New Thread 0x7fff493f1a80 (LWP 14654)]\r\n[New Thread 0x7fff48fefb00 (LWP 14655)]\r\n[New Thread 0x7fff48bedb80 (LWP 14656)]\r\n[New Thread 0x7fff487ebc00 (LWP 14657)]\r\n[New Thread 0x7fff0fffec80 (LWP 14658)]\r\n[New Thread 0x7fff0fbfcd00 (LWP 14659)]\r\n[New Thread 0x7fff0f7fad80 (LWP 14660)]\r\n[New Thread 0x7fff0f3f8e00 (LWP 14661)]\r\n\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7fff4bfff700 (LWP 14645)]\r\n0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\r\n(gdb) where\r\n#0  0x00007fff5663a2c3 in mkl_blas_avx2_xsgemm_acopiedbcopy () from /usr/local/mkl/mkl/lib/intel64/libmkl_avx2.so\r\n#1  0x00007fffda8f5dce in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\r\n#2  0x00007fffd8810d13 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\r\n#3  0x00007fffd87e0b17 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\r\n#4  0x00007fffd87e1bd3 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\r\n#5  0x00007fffd87b96f8 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libiomp5.so\r\n#6  0x00007fffda8f57ae in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\r\n#7  0x00007fffda8f4ed9 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\r\n#8  0x00007fffda8f3ff0 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\r\n#9  0x00007fffda920ca1 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_thread.so\r\n#10 0x00007fffdc196063 in ?? () from /usr/local/lib/python2.7/dist-packages/torch/lib/libmkl_intel_lp64.so\r\n#11 0x00007fffece71f61 in THFloatBlas_gemm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\r\n#12 0x00007fffecc0ee60 in THFloatTensor_addmm () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTH.so.1\r\n#13 0x00007fffec295df0 in THNN_FloatSpatialConvolutionMM_accGradParameters_frame () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\r\n#14 0x00007fffec34d4ef in THNN_FloatSpatialConvolutionMM_accGradParameters () from /usr/local/lib/python2.7/dist-packages/torch/lib/libTHNN.so.1\r\n#15 0x00007ffff3891f0b in torch::nn::SpatialConvolutionMM_accGradParameters (input=input@entry=0x7fff40001ef0, gradOutput=gradOutput@entry=0x7fff400066d0, \r\n    gradWeight=<optimized out>, gradBias=gradBias@entry=0x7fff40001600, finput=finput@entry=0x14b3d30, fgradInput=fgradInput@entry=0x14b3d90, kW=5, kH=5, dW=1, dH=1, \r\n    padW=0, padH=0, scale=scale@entry=1) at torch/csrc/nn/THNN_generic.cpp:7624\r\n#16 0x00007ffff38756f3 in torch::autograd::compute_grad_params (input=0x7fff40001ef0, grad_output=0x7fff400066d0, weight=weight@entry=0x7fff400015a0, \r\n    bias=bias@entry=0x7fff40001f70, columns=0x14b3d30, ones=0x14b3d90, kernel_size=std::vector of length 2, capacity 2 = {...}, params=...)\r\n---Type <return> to continue, or q <return> to quit---\r\n    at torch/csrc/autograd/functions/convolution.cpp:491\r\n#17 0x00007ffff38773e7 in torch::autograd::ConvBackward::apply (this=0x14b4058, grad_outputs=...) at torch/csrc/autograd/functions/convolution.cpp:285\r\n#18 0x00007ffff385bc68 in call_function (task=...) at torch/csrc/autograd/engine.cpp:132\r\n#19 torch::autograd::Engine::evaluate_function (this=this@entry=0x7ffff4177640 <engine>, task=...) at torch/csrc/autograd/engine.cpp:137\r\n#20 0x00007ffff385d8ab in torch::autograd::Engine::thread_main (this=this@entry=0x7ffff4177640 <engine>, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\r\n    at torch/csrc/autograd/engine.cpp:96\r\n#21 0x00007ffff386f264 in PythonEngine::thread_main (this=0x7ffff4177640 <engine>, queue=std::shared_ptr (count 3, weak 0) 0x1583430)\r\n    at torch/csrc/autograd/python_engine.cpp:21\r\n#22 0x00007ffff3860d98 in operator()<std::shared_ptr<torch::autograd::ReadyQueue>, void> (__object=<optimized out>, this=<optimized out>)\r\n    at /py/envs/py2k/gcc/include/c++/functional:601\r\n#23 _M_invoke<0ul, 1ul> (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/functional:1732\r\n#24 operator() (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/functional:1720\r\n#25 std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (torch::autograd::Engine::*)(std::shared_ptr<torch::autograd::ReadyQueue>)> (torch::autograd::Engine*, std::shared_ptr<torch::autograd::ReadyQueue>)> >::_M_run() (this=<optimized out>) at /py/envs/py2k/gcc/include/c++/thread:115\r\n#26 0x00007fffdcb3aa60 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#27 0x00007ffff7bc4182 in start_thread (arg=0x7fff4bfff700) at pthread_create.c:312\r\n#28 0x00007ffff78f147d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\r\n```\r\n\r\nThere is a manually installed mkl in the system. Is that the problem? Should I compile it from source?"}