{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148038895", "pull_request_review_id": 73220397, "id": 148038895, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0ODAzODg5NQ==", "diff_hunk": "@@ -246,21 +253,37 @@ static void check_inplace(const Tensor& tensor) {\n     at::runtime_error(\n       \"a leaf Variable that requires grad has been used in an in-place operation.\");\n   }\n-  auto live_refs = var.version_counter().live_refs();\n-  if (live_refs > 1) {\n-    at::runtime_error(\n-      \"in-place operations can be only used on variables that don't share \"\n-      \"storage with any other variables, but detected that there are %d objects \"\n-      \"sharing it\", live_refs);\n-  }\n }\n \n-static void set_flags(Variable& var, VariableFlags flags, std::shared_ptr<Function> grad_fn) {\n+static void set_base_fn(Variable& var, std::shared_ptr<Function> grad_fn) {\n+  // Called when var is a view of another Variable. Modifes the\n+  // var.base().grad_fn() instead of var's grad_fn.\n+  //\n+  // We make a few important assumptions about the grad_fn for the in-place op:\n+  //\n+  // 1. It takes in a single grad as input (the in-place op must only produce\n+  //    a single output).\n+  // 2. It may produce multiple grad_inputs (the in-place op may use multiple\n+  //    inputs), but the grad_input for \"self\" must come first.\n+  //\n+  grad_fn->num_inputs = 1;\n+\n+  auto& base = var.base();\n+  auto copySlices = std::make_shared<CopySlices>(base, TensorGeometry(var), std::move(grad_fn));\n+  base.output_nr() = 0;\n+  base.grad_fn() = std::move(copySlices);\n+}\n+\n+static void set_flags(Variable& var, VariableFlags flags, std::shared_ptr<Function> grad_fn, bool inplace=false) {\n   var.requires_grad() = flags.requires_grad;\n   var.is_volatile() = flags.is_volatile;\n   if (grad_fn) {\n-    var.output_nr() = grad_fn->num_inputs++;\n-    var.grad_fn() = std::move(grad_fn);\n+    if (inplace && var.is_view()) {", "path": "tools/autograd/templates/VariableType.cpp", "position": null, "original_position": 53, "commit_id": "0faf2a8e86a5f3cc32aaf8640120aca134c10961", "original_commit_id": "924908320c84b00c09fdf3d94ac0291e8a513331", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "The else is correct if only one of the conditions is true. \r\n\r\nIf it's in-place we replace the `grad_fn` on Variable. The calling code sets up the `next_functions` of `grad_fn` to point to the previous `var.grad_fn`.\r\n\r\nIf it's a view, we set the `grad_fn` on Variable. The calling code sets up the `next_functions` of `grad_fn` to point to the view-backwards op. (Which may be something like TransposeBackward or AsStridedBackward)", "created_at": "2017-10-31T15:49:09Z", "updated_at": "2018-11-23T15:35:50Z", "html_url": "https://github.com/pytorch/pytorch/pull/3384#discussion_r148038895", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3384", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148038895"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3384#discussion_r148038895"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3384"}}, "body_html": "<p>The else is correct if only one of the conditions is true.</p>\n<p>If it's in-place we replace the <code>grad_fn</code> on Variable. The calling code sets up the <code>next_functions</code> of <code>grad_fn</code> to point to the previous <code>var.grad_fn</code>.</p>\n<p>If it's a view, we set the <code>grad_fn</code> on Variable. The calling code sets up the <code>next_functions</code> of <code>grad_fn</code> to point to the view-backwards op. (Which may be something like TransposeBackward or AsStridedBackward)</p>", "body_text": "The else is correct if only one of the conditions is true.\nIf it's in-place we replace the grad_fn on Variable. The calling code sets up the next_functions of grad_fn to point to the previous var.grad_fn.\nIf it's a view, we set the grad_fn on Variable. The calling code sets up the next_functions of grad_fn to point to the view-backwards op. (Which may be something like TransposeBackward or AsStridedBackward)", "in_reply_to_id": 147962067}