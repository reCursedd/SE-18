{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148579010", "pull_request_review_id": 73843984, "id": 148579010, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0ODU3OTAxMA==", "diff_hunk": "@@ -404,80 +387,78 @@ static void _wrap_outputs(THPFunction *self, t2var_type &t2var,\n     return Variable();\n   };\n \n-  // Creates a new Variable from a PyObject* of type THPTensor\n-  auto new_variable = [&get_shared_base, is_volatile, cdata](PyObject* output) -> Variable {\n-    Variable var;\n-    auto base = get_shared_base(output);\n-    if (base.defined()) {\n-      var = make_variable_view(std::move(base), torch::createTensor(output));\n-    } else {\n-      var = make_variable(torch::createTensor(output));\n+  // Wraps an output Tensor in a Variable or returns the previous wrapper in\n+  // the case of in-place modification.\n+  auto wrap_output = [&](at::Tensor data, Variable prev, bool is_modified) -> Variable {\n+    if (!prev.defined()) {\n+      return make_variable(std::move(data));\n     }\n-    var.is_volatile() = is_volatile;\n-    if (!is_volatile) {\n-      var.grad_fn() = cdata;\n-      var.requires_grad() = cdata->is_executable;\n+    if (is_modified) {\n+      if (prev.is_leaf() && prev.requires_grad()) {\n+        throw std::runtime_error(\"a leaf Variable that requires grad has been used in an in-place operation.\");\n+      }\n+      // If the input was modified, transplant the grad_fn in the graph:\n+      // grad_fn <- variable <- self  ==>  grad_fn <- self <- variable\n+      prev.get()->grad.reset();\n+      prev.get()->hooks.clear();\n+      if (auto grad_acc_fn = prev.get()->grad_accumulator.lock()) {\n+        auto grad_acc = dynamic_cast<AccumulateGrad*>(grad_acc_fn.get());\n+        grad_acc->variable.reset();\n+      }\n+      return prev;\n     }\n-    return var;\n+    // An input has been returned, but it wasn't modified. Return it as a view\n+    // so that we can attach a new grad_fn to the Variable.\n+    return make_variable_view(std::move(prev), std::move(data));", "path": "torch/csrc/autograd/python_function.cpp", "position": null, "original_position": 88, "commit_id": "0faf2a8e86a5f3cc32aaf8640120aca134c10961", "original_commit_id": "aaddf950000cdcd03389c92e28d49ba0e4df558b", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "1) Yeah, that should be fixed. test_function_returns_input tests that case\r\n\r\n2) Yeah. I think there's a few other simple special case. I'd prefer doing it in a subsequent commit. ", "created_at": "2017-11-02T16:02:43Z", "updated_at": "2018-11-23T15:35:55Z", "html_url": "https://github.com/pytorch/pytorch/pull/3384#discussion_r148579010", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3384", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/148579010"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3384#discussion_r148579010"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3384"}}, "body_html": "<ol>\n<li>\n<p>Yeah, that should be fixed. test_function_returns_input tests that case</p>\n</li>\n<li>\n<p>Yeah. I think there's a few other simple special case. I'd prefer doing it in a subsequent commit.</p>\n</li>\n</ol>", "body_text": "Yeah, that should be fixed. test_function_returns_input tests that case\n\n\nYeah. I think there's a few other simple special case. I'd prefer doing it in a subsequent commit.", "in_reply_to_id": 148549859}