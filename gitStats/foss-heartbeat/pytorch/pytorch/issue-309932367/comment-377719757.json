{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377719757", "html_url": "https://github.com/pytorch/pytorch/pull/6120#issuecomment-377719757", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6120", "id": 377719757, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzcxOTc1Nw==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-31T20:08:28Z", "updated_at": "2018-03-31T20:09:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Given the internal discussion we had about the PyTorch ONNX exporter putting the <code>axis</code> on broadcast in the wrong dimension, I now think this is patch is not going in the right direction.</p>\n<p>The <a href=\"http://pytorch.org/docs/master/notes/broadcasting.html\" rel=\"nofollow\">PyTorch/Numpy broadcast semantics</a> says that we always align the tensor to be broadcasted to the <em>end</em> of the target dimension, and then subsequently fill out any ones/zeros. So there is no substring matching to be done: you should always right-align the sizes and bail out if the broadcast is inexpressible in Caffe2. In fact, the previous code was wrong for checking if the original shape was a prefix; we should NOT do that either.</p>\n<p>It is true that this means that some models that previously exported no longer export. But this \"broadcast at any cost\" behavior is counterproductive when you want to take the networks that are traced at one shape and generalize them. Just because, at a specific shape, a broadcast was possible, doesn't mean it reflects the semantic intent of a user's broadcast.</p>\n<hr>\n<p>Concretely, we should not apply this patch, and instead modify the logic to stop checking for prefixes (and check suffixes only.)</p>", "body_text": "Given the internal discussion we had about the PyTorch ONNX exporter putting the axis on broadcast in the wrong dimension, I now think this is patch is not going in the right direction.\nThe PyTorch/Numpy broadcast semantics says that we always align the tensor to be broadcasted to the end of the target dimension, and then subsequently fill out any ones/zeros. So there is no substring matching to be done: you should always right-align the sizes and bail out if the broadcast is inexpressible in Caffe2. In fact, the previous code was wrong for checking if the original shape was a prefix; we should NOT do that either.\nIt is true that this means that some models that previously exported no longer export. But this \"broadcast at any cost\" behavior is counterproductive when you want to take the networks that are traced at one shape and generalize them. Just because, at a specific shape, a broadcast was possible, doesn't mean it reflects the semantic intent of a user's broadcast.\n\nConcretely, we should not apply this patch, and instead modify the logic to stop checking for prefixes (and check suffixes only.)", "body": "Given the internal discussion we had about the PyTorch ONNX exporter putting the `axis` on broadcast in the wrong dimension, I now think this is patch is not going in the right direction.\r\n\r\nThe [PyTorch/Numpy broadcast semantics](http://pytorch.org/docs/master/notes/broadcasting.html) says that we always align the tensor to be broadcasted to the *end* of the target dimension, and then subsequently fill out any ones/zeros. So there is no substring matching to be done: you should always right-align the sizes and bail out if the broadcast is inexpressible in Caffe2. In fact, the previous code was wrong for checking if the original shape was a prefix; we should NOT do that either.\r\n\r\nIt is true that this means that some models that previously exported no longer export. But this \"broadcast at any cost\" behavior is counterproductive when you want to take the networks that are traced at one shape and generalize them. Just because, at a specific shape, a broadcast was possible, doesn't mean it reflects the semantic intent of a user's broadcast.\r\n\r\n----\r\n\r\nConcretely, we should not apply this patch, and instead modify the logic to stop checking for prefixes (and check suffixes only.)"}