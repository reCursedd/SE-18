{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11202", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11202/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11202/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11202/events", "html_url": "https://github.com/pytorch/pytorch/issues/11202", "id": 356530949, "node_id": "MDU6SXNzdWUzNTY1MzA5NDk=", "number": 11202, "title": "[pytorch][feature request] Cosine distance / simialrity between samples of own tensor or two tensors", "user": {"login": "rragundez", "id": 16643700, "node_id": "MDQ6VXNlcjE2NjQzNzAw", "avatar_url": "https://avatars2.githubusercontent.com/u/16643700?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rragundez", "html_url": "https://github.com/rragundez", "followers_url": "https://api.github.com/users/rragundez/followers", "following_url": "https://api.github.com/users/rragundez/following{/other_user}", "gists_url": "https://api.github.com/users/rragundez/gists{/gist_id}", "starred_url": "https://api.github.com/users/rragundez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rragundez/subscriptions", "organizations_url": "https://api.github.com/users/rragundez/orgs", "repos_url": "https://api.github.com/users/rragundez/repos", "events_url": "https://api.github.com/users/rragundez/events{/privacy}", "received_events_url": "https://api.github.com/users/rragundez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-09-03T14:40:43Z", "updated_at": "2018-09-05T09:13:39Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>This issue came about when trying to find the cosine similarity between samples in two different tensors. To my surprise <code>F.cosine_similarity</code> performs cosine similarity between pairs of tensors with the same index across certain dimension. I was expecting something like:</p>\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\" rel=\"nofollow\">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html</a></p>\n<p>that is, a cosine similarity measure across all pairs of samples.<br>\nI can't really see the use cases of the current implementation of <code>F.cosine_similarity</code>. Since it is the special case of getting the diagonal of what I describe or using <code>F.pairwise_distance</code> with an extra normalize parameters. Perhaps would be nice to know what are the use cases for the current implementation.</p>\n<p>In order to mantain  compatibility, I suggest creating an <code>F.cosine_distance</code> function and layer similar to:</p>\n<p><a href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html\" rel=\"nofollow\">https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html</a></p>\n<p>which operates in tensors, similar to the sklearn implementation<br>\n<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html\" rel=\"nofollow\">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html</a></p>\n<p>I don't think this is difficult to implement btw</p>\n<h2>Code example</h2>\n<pre><code>def cosine_distance(x1, x2=None, eps=1e-8):\n    x2 = x1 if x2 is None else x2\n    w1 = x1.norm(p=2, dim=1, keepdim=True)\n    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n</code></pre>\n<p>Example:</p>\n<pre><code>&gt;&gt;&gt; m1 = torch.tensor([[0, 1],\n                   [0, 1]], dtype=torch.float64)\n&gt;&gt;&gt; cosine_distance(m1, m1)\ntensor([[0., 0.],\n        [0., 0.]], dtype=torch.float64)\n&gt;&gt;&gt; cosine_distance(m1)\ntensor([[0., 0.],\n        [0., 0.]], dtype=torch.float64)\n&gt;&gt;&gt; m2 = torch.tensor([[1, 0],\n                   [0, 1]], dtype=torch.float64) \n&gt;&gt;&gt; cosine_distance(m1, m2)\ntensor([[1., 0.],\n        [1., 0.]], dtype=torch.float64)\n&gt;&gt;&gt; m3 = torch.tensor([[0, 0],\n                   [0, 0]], dtype=torch.float64)\n&gt;&gt;&gt; cosine_distance(m3)\ntensor([[1., 1.],\n        [1., 1.]], dtype=torch.float64)\n&gt;&gt;&gt; cosine_distance(m3, m3)\ntensor([[1., 1.],\n        [1., 1.]], dtype=torch.float64)\n</code></pre>\n<p>Creation of the layer from here is straight forward. if you think this might be a good idea I would like to make a PR</p>", "body_text": "Issue description\nThis issue came about when trying to find the cosine similarity between samples in two different tensors. To my surprise F.cosine_similarity performs cosine similarity between pairs of tensors with the same index across certain dimension. I was expecting something like:\nhttp://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\nthat is, a cosine similarity measure across all pairs of samples.\nI can't really see the use cases of the current implementation of F.cosine_similarity. Since it is the special case of getting the diagonal of what I describe or using F.pairwise_distance with an extra normalize parameters. Perhaps would be nice to know what are the use cases for the current implementation.\nIn order to mantain  compatibility, I suggest creating an F.cosine_distance function and layer similar to:\nhttps://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html\nwhich operates in tensors, similar to the sklearn implementation\nhttp://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html\nI don't think this is difficult to implement btw\nCode example\ndef cosine_distance(x1, x2=None, eps=1e-8):\n    x2 = x1 if x2 is None else x2\n    w1 = x1.norm(p=2, dim=1, keepdim=True)\n    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n\nExample:\n>>> m1 = torch.tensor([[0, 1],\n                   [0, 1]], dtype=torch.float64)\n>>> cosine_distance(m1, m1)\ntensor([[0., 0.],\n        [0., 0.]], dtype=torch.float64)\n>>> cosine_distance(m1)\ntensor([[0., 0.],\n        [0., 0.]], dtype=torch.float64)\n>>> m2 = torch.tensor([[1, 0],\n                   [0, 1]], dtype=torch.float64) \n>>> cosine_distance(m1, m2)\ntensor([[1., 0.],\n        [1., 0.]], dtype=torch.float64)\n>>> m3 = torch.tensor([[0, 0],\n                   [0, 0]], dtype=torch.float64)\n>>> cosine_distance(m3)\ntensor([[1., 1.],\n        [1., 1.]], dtype=torch.float64)\n>>> cosine_distance(m3, m3)\ntensor([[1., 1.],\n        [1., 1.]], dtype=torch.float64)\n\nCreation of the layer from here is straight forward. if you think this might be a good idea I would like to make a PR", "body": "## Issue description\r\nThis issue came about when trying to find the cosine similarity between samples in two different tensors. To my surprise `F.cosine_similarity` performs cosine similarity between pairs of tensors with the same index across certain dimension. I was expecting something like:\r\n\r\nhttp://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\r\n\r\nthat is, a cosine similarity measure across all pairs of samples.\r\nI can't really see the use cases of the current implementation of `F.cosine_similarity`. Since it is the special case of getting the diagonal of what I describe or using `F.pairwise_distance` with an extra normalize parameters. Perhaps would be nice to know what are the use cases for the current implementation.\r\n\r\nIn order to mantain  compatibility, I suggest creating an `F.cosine_distance` function and layer similar to:\r\n\r\nhttps://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.cosine.html\r\n\r\nwhich operates in tensors, similar to the sklearn implementation\r\nhttp://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html\r\n\r\nI don't think this is difficult to implement btw\r\n\r\n## Code example\r\n```\r\ndef cosine_distance(x1, x2=None, eps=1e-8):\r\n    x2 = x1 if x2 is None else x2\r\n    w1 = x1.norm(p=2, dim=1, keepdim=True)\r\n    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\r\n    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\r\n```\r\nExample:\r\n```\r\n>>> m1 = torch.tensor([[0, 1],\r\n                   [0, 1]], dtype=torch.float64)\r\n>>> cosine_distance(m1, m1)\r\ntensor([[0., 0.],\r\n        [0., 0.]], dtype=torch.float64)\r\n>>> cosine_distance(m1)\r\ntensor([[0., 0.],\r\n        [0., 0.]], dtype=torch.float64)\r\n>>> m2 = torch.tensor([[1, 0],\r\n                   [0, 1]], dtype=torch.float64) \r\n>>> cosine_distance(m1, m2)\r\ntensor([[1., 0.],\r\n        [1., 0.]], dtype=torch.float64)\r\n>>> m3 = torch.tensor([[0, 0],\r\n                   [0, 0]], dtype=torch.float64)\r\n>>> cosine_distance(m3)\r\ntensor([[1., 1.],\r\n        [1., 1.]], dtype=torch.float64)\r\n>>> cosine_distance(m3, m3)\r\ntensor([[1., 1.],\r\n        [1., 1.]], dtype=torch.float64)\r\n```\r\nCreation of the layer from here is straight forward. if you think this might be a good idea I would like to make a PR"}