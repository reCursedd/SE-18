{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13304", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13304/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13304/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13304/events", "html_url": "https://github.com/pytorch/pytorch/issues/13304", "id": 375406835, "node_id": "MDU6SXNzdWUzNzU0MDY4MzU=", "number": 13304, "title": "ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79", "user": {"login": "gf19880710", "id": 35098107, "node_id": "MDQ6VXNlcjM1MDk4MTA3", "avatar_url": "https://avatars0.githubusercontent.com/u/35098107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gf19880710", "html_url": "https://github.com/gf19880710", "followers_url": "https://api.github.com/users/gf19880710/followers", "following_url": "https://api.github.com/users/gf19880710/following{/other_user}", "gists_url": "https://api.github.com/users/gf19880710/gists{/gist_id}", "starred_url": "https://api.github.com/users/gf19880710/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gf19880710/subscriptions", "organizations_url": "https://api.github.com/users/gf19880710/orgs", "repos_url": "https://api.github.com/users/gf19880710/repos", "events_url": "https://api.github.com/users/gf19880710/events{/privacy}", "received_events_url": "https://api.github.com/users/gf19880710/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-30T10:02:12Z", "updated_at": "2018-10-30T10:02:12Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Hello Great programmers:<br>\nWhen I was using FAIR's platform Detectron to do training with <em>e2e_mask_rcnn_R-101-FPN_3x_gn.yaml</em> config file, I faced this issue which indicated me to report one BUG to Pytorch.</p>\n\n<pre><code>[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 6.1526e-05 secs\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 5.3939e-05 secs\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 7.264e-06 secs\n[I net_async_base.h:198] Using specified CPU pool size: 4; NUMA node id: -1\n[I net_async_base.h:203] Created new CPU pool, size: 4; NUMA node id: -1\n[E net_async_base.cc:422] IsType&lt;T&gt;() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\nOffending Blob name: gpu_0/conv1_gn_s.\nError from operator: \ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\nframe #0: &lt;unknown function&gt; + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #1: &lt;unknown function&gt; + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #3: &lt;unknown function&gt; + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #4: &lt;unknown function&gt; + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #5: &lt;unknown function&gt; + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\nframe #6: &lt;unknown function&gt; + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\n,  op GroupNorm\nWARNING workspace.py: 187: Original python traceback for operator `1` in network `generalized_rcnn` in exception above (most recent call last):\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 132, in &lt;module&gt;\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 117, in main\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 127, in test_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 235, in test_net\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 328, in initialize_model_from_cfg\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 124, in create\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 89, in generalized_rcnn\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 229, in build_generic_detection_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/optimizer.py\", line 54, in build_data_parallel_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 169, in _single_gpu_build_func\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 63, in add_fpn_ResNet101_conv5_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 104, in add_fpn_onto_conv_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 48, in add_ResNet101_conv5_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 99, in add_ResNet_convX_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 264, in basic_gn_stem\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/detector.py\", line 450, in ConvGN\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/cnn.py\", line 165, in SpatialGN\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/brew.py\", line 107, in scope_wrapper\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/helpers/normalization.py\", line 206, in spatial_gn\nTraceback (most recent call last):\n  File \"tools/train_net.py\", line 132, in &lt;module&gt;\n    main()\n  File \"tools/train_net.py\", line 117, in main\n    test_model(checkpoints['final'], args.multi_gpu_testing, args.opts)\n  File \"tools/train_net.py\", line 127, in test_model\n    check_expected_results=True,\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\n    all_results = result_getter()\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\n    multi_gpu=multi_gpu_testing\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\n    weights_file, dataset_name, proposal_file, output_dir, gpu_id=gpu_id\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 258, in test_net\n    model, im, box_proposals, timers\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 66, in im_detect_all\n    model, im, cfg.TEST.SCALE, cfg.TEST.MAX_SIZE, boxes=box_proposals\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 158, in im_detect_bbox\n    workspace.RunNet(model.net.Proto().name)\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 219, in RunNet\n    StringifyNetName(name), num_iter, allow_fail,\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: IsType&lt;T&gt;() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\nOffending Blob name: gpu_0/conv1_gn_s.\nError from operator: \ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\nframe #0: &lt;unknown function&gt; + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #1: &lt;unknown function&gt; + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #3: &lt;unknown function&gt; + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #4: &lt;unknown function&gt; + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #5: &lt;unknown function&gt; + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\nframe #6: &lt;unknown function&gt; + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\n</code></pre>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n\n<h2>Expected behavior</h2>\n<p>no exception or bug for training and testing.</p>\n\n<h2>Environment</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<p>gengfeng@ai-work-4:~/Downloads$ python collect_env.py<br>\nCollecting environment information...<br>\nPyTorch version: 1.0.0.dev20181015<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 18.04.1 LTS<br>\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010<br>\nCMake version: version 3.11.4</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration: GPU 0: GeForce GTX 1080<br>\nNvidia driver version: 390.87<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/cuda-9.0/lib64/libcudnn.so<br>\n/usr/local/cuda-9.0/lib64/libcudnn.so.7<br>\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.2.1<br>\n/usr/local/cuda-9.0/lib64/libcudnn_static.a<br>\n/usr/local/cuda-9.1/lib64/libcudnn.so<br>\n/usr/local/cuda-9.1/lib64/libcudnn.so.7.1.3<br>\n/usr/local/cuda-9.1/lib64/libcudnn_static.a</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] cuda91                    1.0                  h4c16780_0    pytorch<br>\n[conda] pytorch-nightly           1.0.0.dev20181015 py3.6_cuda9.0.176_cudnn7.1.2_0    pytorch<br>\n[conda] torch                     0.4.0                     <br>\n[conda] torchvision               0.2.1                     </p>\n<pre><code>\nMy own configs *e2e_mask_rcnn_R-101-FPN_3x_gn.yaml*\nMODEL:\n  TYPE: generalized_rcnn\n  CONV_BODY: FPN.add_fpn_ResNet101_conv5_body\n  NUM_CLASSES: 2\n  FASTER_RCNN: True\n  MASK_ON: True\nNUM_GPUS: 1\nSOLVER:\n  WEIGHT_DECAY: 0.0001\n  LR_POLICY: steps_with_decay\n  BASE_LR: 0.002\n  GAMMA: 0.1\n  MAX_ITER: 70000\n  STEPS: [0, 40000, 60000]\nFPN:\n  FPN_ON: True\n  MULTILEVEL_ROIS: True\n  MULTILEVEL_RPN: True\n  USE_GN: True  # Note: use GN on the FPN-specific layers\nRESNETS:\n  STRIDE_1X1: False  # default True for MSRA; False for C2 or Torch models\n  TRANS_FUNC: bottleneck_gn_transformation  # Note: this is a GN bottleneck transform\n  STEM_FUNC: basic_gn_stem  # Note: this is a GN stem\n  SHORTCUT_FUNC: basic_gn_shortcut  # Note: this is a GN shortcut\nFAST_RCNN:\n  ROI_BOX_HEAD: fast_rcnn_heads.add_roi_Xconv1fc_gn_head  # Note: this is a Conv GN head\n  ROI_XFORM_METHOD: RoIAlign\n  ROI_XFORM_RESOLUTION: 7\n  ROI_XFORM_SAMPLING_RATIO: 2\nMRCNN:\n  ROI_MASK_HEAD: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs_gn  # Note: this is a GN mask head\n  RESOLUTION: 28  # (output mask resolution) default 14\n  ROI_XFORM_METHOD: RoIAlign\n  ROI_XFORM_RESOLUTION: 14  # default 7\n  ROI_XFORM_SAMPLING_RATIO: 2  # default 0\n  DILATION: 1  # default 2\n  CONV_INIT: MSRAFill  # default GaussianFill\nTRAIN:\n  WEIGHTS: https://s3-us-west-2.amazonaws.com/detectron/ImageNetPretrained/47592356/R-101-GN.pkl  # Note: a GN pre-trained model\n  DATASETS: ('coco_labelme_train',)\n  SCALES: (700,)\n  MAX_SIZE: 1333\n  BATCH_SIZE_PER_IM: 64\n  RPN_PRE_NMS_TOP_N: 2000  # Per FPN level\nTEST:\n  DATASETS: ('coco_labelme_val',)\n  SCALE: 700\n  MAX_SIZE: 1333\n  NMS: 0.5\n  RPN_PRE_NMS_TOP_N: 1000  # Per FPN level\n  RPN_POST_NMS_TOP_N: 1000\nOUTPUT_DIR: .\n</code></pre>\n<h2>Additional context</h2>\n\n<p>By the way, <em>e2e_mask_rcnn_R-50-FPN_1x.yaml</em> config works fine for me.</p>\n<p>Waiting your response, thank you .</p>", "body_text": "\ud83d\udc1b Bug\nHello Great programmers:\nWhen I was using FAIR's platform Detectron to do training with e2e_mask_rcnn_R-101-FPN_3x_gn.yaml config file, I faced this issue which indicated me to report one BUG to Pytorch.\n\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 6.1526e-05 secs\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 5.3939e-05 secs\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 7.264e-06 secs\n[I net_async_base.h:198] Using specified CPU pool size: 4; NUMA node id: -1\n[I net_async_base.h:203] Created new CPU pool, size: 4; NUMA node id: -1\n[E net_async_base.cc:422] IsType<T>() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\nOffending Blob name: gpu_0/conv1_gn_s.\nError from operator: \ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\nframe #0: <unknown function> + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #1: <unknown function> + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #3: <unknown function> + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #4: <unknown function> + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #5: <unknown function> + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\nframe #6: <unknown function> + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\n,  op GroupNorm\nWARNING workspace.py: 187: Original python traceback for operator `1` in network `generalized_rcnn` in exception above (most recent call last):\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 132, in <module>\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 117, in main\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 127, in test_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 235, in test_net\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 328, in initialize_model_from_cfg\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 124, in create\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 89, in generalized_rcnn\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 229, in build_generic_detection_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/optimizer.py\", line 54, in build_data_parallel_model\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 169, in _single_gpu_build_func\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 63, in add_fpn_ResNet101_conv5_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 104, in add_fpn_onto_conv_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 48, in add_ResNet101_conv5_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 99, in add_ResNet_convX_body\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 264, in basic_gn_stem\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/detector.py\", line 450, in ConvGN\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/cnn.py\", line 165, in SpatialGN\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/brew.py\", line 107, in scope_wrapper\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/helpers/normalization.py\", line 206, in spatial_gn\nTraceback (most recent call last):\n  File \"tools/train_net.py\", line 132, in <module>\n    main()\n  File \"tools/train_net.py\", line 117, in main\n    test_model(checkpoints['final'], args.multi_gpu_testing, args.opts)\n  File \"tools/train_net.py\", line 127, in test_model\n    check_expected_results=True,\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\n    all_results = result_getter()\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\n    multi_gpu=multi_gpu_testing\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\n    weights_file, dataset_name, proposal_file, output_dir, gpu_id=gpu_id\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 258, in test_net\n    model, im, box_proposals, timers\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 66, in im_detect_all\n    model, im, cfg.TEST.SCALE, cfg.TEST.MAX_SIZE, boxes=box_proposals\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 158, in im_detect_bbox\n    workspace.RunNet(model.net.Proto().name)\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 219, in RunNet\n    StringifyNetName(name), num_iter, allow_fail,\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\n    return func(*args, **kwargs)\nRuntimeError: IsType<T>() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\nOffending Blob name: gpu_0/conv1_gn_s.\nError from operator: \ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\nframe #0: <unknown function> + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #1: <unknown function> + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #3: <unknown function> + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #4: <unknown function> + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\nframe #5: <unknown function> + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\nframe #6: <unknown function> + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\n\nTo Reproduce\nSteps to reproduce the behavior:\n\n\n\n\n\n\nExpected behavior\nno exception or bug for training and testing.\n\nEnvironment\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\ngengfeng@ai-work-4:~/Downloads$ python collect_env.py\nCollecting environment information...\nPyTorch version: 1.0.0.dev20181015\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 18.04.1 LTS\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\nCMake version: version 3.11.4\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration: GPU 0: GeForce GTX 1080\nNvidia driver version: 390.87\ncuDNN version: Probably one of the following:\n/usr/local/cuda-9.0/lib64/libcudnn.so\n/usr/local/cuda-9.0/lib64/libcudnn.so.7\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.2.1\n/usr/local/cuda-9.0/lib64/libcudnn_static.a\n/usr/local/cuda-9.1/lib64/libcudnn.so\n/usr/local/cuda-9.1/lib64/libcudnn.so.7.1.3\n/usr/local/cuda-9.1/lib64/libcudnn_static.a\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] cuda91                    1.0                  h4c16780_0    pytorch\n[conda] pytorch-nightly           1.0.0.dev20181015 py3.6_cuda9.0.176_cudnn7.1.2_0    pytorch\n[conda] torch                     0.4.0                     \n[conda] torchvision               0.2.1                     \n\nMy own configs *e2e_mask_rcnn_R-101-FPN_3x_gn.yaml*\nMODEL:\n  TYPE: generalized_rcnn\n  CONV_BODY: FPN.add_fpn_ResNet101_conv5_body\n  NUM_CLASSES: 2\n  FASTER_RCNN: True\n  MASK_ON: True\nNUM_GPUS: 1\nSOLVER:\n  WEIGHT_DECAY: 0.0001\n  LR_POLICY: steps_with_decay\n  BASE_LR: 0.002\n  GAMMA: 0.1\n  MAX_ITER: 70000\n  STEPS: [0, 40000, 60000]\nFPN:\n  FPN_ON: True\n  MULTILEVEL_ROIS: True\n  MULTILEVEL_RPN: True\n  USE_GN: True  # Note: use GN on the FPN-specific layers\nRESNETS:\n  STRIDE_1X1: False  # default True for MSRA; False for C2 or Torch models\n  TRANS_FUNC: bottleneck_gn_transformation  # Note: this is a GN bottleneck transform\n  STEM_FUNC: basic_gn_stem  # Note: this is a GN stem\n  SHORTCUT_FUNC: basic_gn_shortcut  # Note: this is a GN shortcut\nFAST_RCNN:\n  ROI_BOX_HEAD: fast_rcnn_heads.add_roi_Xconv1fc_gn_head  # Note: this is a Conv GN head\n  ROI_XFORM_METHOD: RoIAlign\n  ROI_XFORM_RESOLUTION: 7\n  ROI_XFORM_SAMPLING_RATIO: 2\nMRCNN:\n  ROI_MASK_HEAD: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs_gn  # Note: this is a GN mask head\n  RESOLUTION: 28  # (output mask resolution) default 14\n  ROI_XFORM_METHOD: RoIAlign\n  ROI_XFORM_RESOLUTION: 14  # default 7\n  ROI_XFORM_SAMPLING_RATIO: 2  # default 0\n  DILATION: 1  # default 2\n  CONV_INIT: MSRAFill  # default GaussianFill\nTRAIN:\n  WEIGHTS: https://s3-us-west-2.amazonaws.com/detectron/ImageNetPretrained/47592356/R-101-GN.pkl  # Note: a GN pre-trained model\n  DATASETS: ('coco_labelme_train',)\n  SCALES: (700,)\n  MAX_SIZE: 1333\n  BATCH_SIZE_PER_IM: 64\n  RPN_PRE_NMS_TOP_N: 2000  # Per FPN level\nTEST:\n  DATASETS: ('coco_labelme_val',)\n  SCALE: 700\n  MAX_SIZE: 1333\n  NMS: 0.5\n  RPN_PRE_NMS_TOP_N: 1000  # Per FPN level\n  RPN_POST_NMS_TOP_N: 1000\nOUTPUT_DIR: .\n\nAdditional context\n\nBy the way, e2e_mask_rcnn_R-50-FPN_1x.yaml config works fine for me.\nWaiting your response, thank you .", "body": "## \ud83d\udc1b Bug\r\nHello Great programmers:\r\n        When I was using FAIR's platform Detectron to do training with *e2e_mask_rcnn_R-101-FPN_3x_gn.yaml* config file, I faced this issue which indicated me to report one BUG to Pytorch.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n```\r\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 6.1526e-05 secs\r\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 5.3939e-05 secs\r\n[I net_dag_utils.cc:102] Operator graph pruning prior to chain compute took: 7.264e-06 secs\r\n[I net_async_base.h:198] Using specified CPU pool size: 4; NUMA node id: -1\r\n[I net_async_base.h:203] Created new CPU pool, size: 4; NUMA node id: -1\r\n[E net_async_base.cc:422] IsType<T>() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\r\nOffending Blob name: gpu_0/conv1_gn_s.\r\nError from operator: \r\ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\r\nframe #0: <unknown function> + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\r\nframe #1: <unknown function> + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\r\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #3: <unknown function> + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #4: <unknown function> + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #5: <unknown function> + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\r\nframe #6: <unknown function> + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\r\n,  op GroupNorm\r\nWARNING workspace.py: 187: Original python traceback for operator `1` in network `generalized_rcnn` in exception above (most recent call last):\r\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 132, in <module>\r\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 117, in main\r\nWARNING workspace.py: 192:   File \"tools/train_net.py\", line 127, in test_model\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 235, in test_net\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 328, in initialize_model_from_cfg\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 124, in create\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 89, in generalized_rcnn\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 229, in build_generic_detection_model\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/optimizer.py\", line 54, in build_data_parallel_model\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/model_builder.py\", line 169, in _single_gpu_build_func\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 63, in add_fpn_ResNet101_conv5_body\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/FPN.py\", line 104, in add_fpn_onto_conv_body\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 48, in add_ResNet101_conv5_body\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 99, in add_ResNet_convX_body\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/ResNet.py\", line 264, in basic_gn_stem\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/modeling/detector.py\", line 450, in ConvGN\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/cnn.py\", line 165, in SpatialGN\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/brew.py\", line 107, in scope_wrapper\r\nWARNING workspace.py: 192:   File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/helpers/normalization.py\", line 206, in spatial_gn\r\nTraceback (most recent call last):\r\n  File \"tools/train_net.py\", line 132, in <module>\r\n    main()\r\n  File \"tools/train_net.py\", line 117, in main\r\n    test_model(checkpoints['final'], args.multi_gpu_testing, args.opts)\r\n  File \"tools/train_net.py\", line 127, in test_model\r\n    check_expected_results=True,\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 128, in run_inference\r\n    all_results = result_getter()\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 108, in result_getter\r\n    multi_gpu=multi_gpu_testing\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 159, in test_net_on_dataset\r\n    weights_file, dataset_name, proposal_file, output_dir, gpu_id=gpu_id\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test_engine.py\", line 258, in test_net\r\n    model, im, box_proposals, timers\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 66, in im_detect_all\r\n    model, im, cfg.TEST.SCALE, cfg.TEST.MAX_SIZE, boxes=box_proposals\r\n  File \"/home/gengfeng/Desktop/projects/DETECTRON/detectron/core/test.py\", line 158, in im_detect_bbox\r\n    workspace.RunNet(model.net.Proto().name)\r\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 219, in RunNet\r\n    StringifyNetName(name), num_iter, allow_fail,\r\n  File \"/home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/workspace.py\", line 180, in CallWithExceptionIntercept\r\n    return func(*args, **kwargs)\r\nRuntimeError: IsType<T>() ASSERT FAILED at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79, please report a bug to PyTorch. wrong type for the Blob instance. Blob contains nullptr (uninitialized) while caller expects caffe2::Tensor.\r\nOffending Blob name: gpu_0/conv1_gn_s.\r\nError from operator: \r\ninput: \"gpu_0/conv1\" input: \"gpu_0/conv1_gn_s\" input: \"gpu_0/conv1_gn_b\" output: \"gpu_0/conv1_gn\" output: \"gpu_0/conv1_gn_mean\" output: \"gpu_0/conv1_gn_std\" name: \"\" type: \"GroupNorm\" arg { name: \"use_cudnn\" i: 1 } arg { name: \"cudnn_exhaustive_search\" i: 0 } arg { name: \"group\" i: 32 } arg { name: \"epsilon\" f: 1e-05 } device_option { device_type: 1 device_id: 0 } (Get at /opt/conda/conda-bld/pytorch-nightly_1539602533843/work/aten/src/ATen/core/blob.h:79)\r\nframe #0: <unknown function> + 0x277d775 (0x7fa4c1984775 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\r\nframe #1: <unknown function> + 0x1321685 (0x7fa4c0528685 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2_gpu.so)\r\nframe #2: caffe2::AsyncNetBase::run(int, int) + 0x16e (0x7fa4ec15f4ee in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #3: <unknown function> + 0x1259972 (0x7fa4ec16e972 in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #4: <unknown function> + 0x124d1cb (0x7fa4ec1621cb in /home/gengfeng/anaconda3/lib/python3.6/site-packages/caffe2/python/../../torch/lib/libcaffe2.so)\r\nframe #5: <unknown function> + 0xafc5c (0x7fa4f6227c5c in /home/gengfeng/anaconda3/bin/../lib/libstdc++.so.6)\r\nframe #6: <unknown function> + 0x76db (0x7fa4fd2806db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #7: clone + 0x3f (0x7fa4fcfa988f in /lib/x86_64-linux-gnu/libc.so.6)\r\n```\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1.\r\n1.\r\n1.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\nno exception or bug for training and testing.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\ngengfeng@ai-work-4:~/Downloads$ python collect_env.py \r\nCollecting environment information...\r\nPyTorch version: 1.0.0.dev20181015\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 18.04.1 LTS\r\nGCC version: (Ubuntu 5.5.0-12ubuntu1) 5.5.0 20171010\r\nCMake version: version 3.11.4\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: GPU 0: GeForce GTX 1080\r\nNvidia driver version: 390.87\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-9.0/lib64/libcudnn.so\r\n/usr/local/cuda-9.0/lib64/libcudnn.so.7\r\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.2.1\r\n/usr/local/cuda-9.0/lib64/libcudnn_static.a\r\n/usr/local/cuda-9.1/lib64/libcudnn.so\r\n/usr/local/cuda-9.1/lib64/libcudnn.so.7.1.3\r\n/usr/local/cuda-9.1/lib64/libcudnn_static.a\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] cuda91                    1.0                  h4c16780_0    pytorch\r\n[conda] pytorch-nightly           1.0.0.dev20181015 py3.6_cuda9.0.176_cudnn7.1.2_0    pytorch\r\n[conda] torch                     0.4.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n\r\nMy own configs *e2e_mask_rcnn_R-101-FPN_3x_gn.yaml*\r\nMODEL:\r\n  TYPE: generalized_rcnn\r\n  CONV_BODY: FPN.add_fpn_ResNet101_conv5_body\r\n  NUM_CLASSES: 2\r\n  FASTER_RCNN: True\r\n  MASK_ON: True\r\nNUM_GPUS: 1\r\nSOLVER:\r\n  WEIGHT_DECAY: 0.0001\r\n  LR_POLICY: steps_with_decay\r\n  BASE_LR: 0.002\r\n  GAMMA: 0.1\r\n  MAX_ITER: 70000\r\n  STEPS: [0, 40000, 60000]\r\nFPN:\r\n  FPN_ON: True\r\n  MULTILEVEL_ROIS: True\r\n  MULTILEVEL_RPN: True\r\n  USE_GN: True  # Note: use GN on the FPN-specific layers\r\nRESNETS:\r\n  STRIDE_1X1: False  # default True for MSRA; False for C2 or Torch models\r\n  TRANS_FUNC: bottleneck_gn_transformation  # Note: this is a GN bottleneck transform\r\n  STEM_FUNC: basic_gn_stem  # Note: this is a GN stem\r\n  SHORTCUT_FUNC: basic_gn_shortcut  # Note: this is a GN shortcut\r\nFAST_RCNN:\r\n  ROI_BOX_HEAD: fast_rcnn_heads.add_roi_Xconv1fc_gn_head  # Note: this is a Conv GN head\r\n  ROI_XFORM_METHOD: RoIAlign\r\n  ROI_XFORM_RESOLUTION: 7\r\n  ROI_XFORM_SAMPLING_RATIO: 2\r\nMRCNN:\r\n  ROI_MASK_HEAD: mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs_gn  # Note: this is a GN mask head\r\n  RESOLUTION: 28  # (output mask resolution) default 14\r\n  ROI_XFORM_METHOD: RoIAlign\r\n  ROI_XFORM_RESOLUTION: 14  # default 7\r\n  ROI_XFORM_SAMPLING_RATIO: 2  # default 0\r\n  DILATION: 1  # default 2\r\n  CONV_INIT: MSRAFill  # default GaussianFill\r\nTRAIN:\r\n  WEIGHTS: https://s3-us-west-2.amazonaws.com/detectron/ImageNetPretrained/47592356/R-101-GN.pkl  # Note: a GN pre-trained model\r\n  DATASETS: ('coco_labelme_train',)\r\n  SCALES: (700,)\r\n  MAX_SIZE: 1333\r\n  BATCH_SIZE_PER_IM: 64\r\n  RPN_PRE_NMS_TOP_N: 2000  # Per FPN level\r\nTEST:\r\n  DATASETS: ('coco_labelme_val',)\r\n  SCALE: 700\r\n  MAX_SIZE: 1333\r\n  NMS: 0.5\r\n  RPN_PRE_NMS_TOP_N: 1000  # Per FPN level\r\n  RPN_POST_NMS_TOP_N: 1000\r\nOUTPUT_DIR: .\r\n```\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\nBy the way, *e2e_mask_rcnn_R-50-FPN_1x.yaml* config works fine for me.\r\n\r\nWaiting your response, thank you ."}