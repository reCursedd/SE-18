{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/349894452", "html_url": "https://github.com/pytorch/pytorch/issues/3883#issuecomment-349894452", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3883", "id": 349894452, "node_id": "MDEyOklzc3VlQ29tbWVudDM0OTg5NDQ1Mg==", "user": {"login": "danishcontractor", "id": 1113876, "node_id": "MDQ6VXNlcjExMTM4NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1113876?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danishcontractor", "html_url": "https://github.com/danishcontractor", "followers_url": "https://api.github.com/users/danishcontractor/followers", "following_url": "https://api.github.com/users/danishcontractor/following{/other_user}", "gists_url": "https://api.github.com/users/danishcontractor/gists{/gist_id}", "starred_url": "https://api.github.com/users/danishcontractor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danishcontractor/subscriptions", "organizations_url": "https://api.github.com/users/danishcontractor/orgs", "repos_url": "https://api.github.com/users/danishcontractor/repos", "events_url": "https://api.github.com/users/danishcontractor/events{/privacy}", "received_events_url": "https://api.github.com/users/danishcontractor/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-07T08:15:19Z", "updated_at": "2017-12-07T08:20:18Z", "author_association": "NONE", "body_html": "<p>I am seeing this too -- I have two runs of the same model running with different hyperparameters, one is running smoothly, this one quit with the exact same error</p>\n<pre><code>avg_loss = self.train_epoch(training_data,validation_data,batch_size,save_prefix,epoch)\n</code></pre>\n<p>File \"TourQue_v1.py\", line 759, in train_epoch<br>\ngradients = loss.backward()<br>\nFile \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 167, in backward<br>\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)<br>\nFile \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/<strong>init</strong>.py\", line 99, in backward<br>\nvariables, grad_variables, retain_graph)<br>\nRuntimeError: torch/csrc/autograd/input_buffer.cpp:14: add: Assertion <code>pos &gt;= 0 &amp;&amp; pos &lt; buffer.size()</code> failed.</p>\n<p>Running PyTorch v0.3 and training on 4 K-80 GPUs. My other run with different parameters is also running on the exact same setup but its still running. Both runs differ only in shuffle of data and a different batch size (the one that failed had a slightly larger batch size)</p>", "body_text": "I am seeing this too -- I have two runs of the same model running with different hyperparameters, one is running smoothly, this one quit with the exact same error\navg_loss = self.train_epoch(training_data,validation_data,batch_size,save_prefix,epoch)\n\nFile \"TourQue_v1.py\", line 759, in train_epoch\ngradients = loss.backward()\nFile \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 167, in backward\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\nFile \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/init.py\", line 99, in backward\nvariables, grad_variables, retain_graph)\nRuntimeError: torch/csrc/autograd/input_buffer.cpp:14: add: Assertion pos >= 0 && pos < buffer.size() failed.\nRunning PyTorch v0.3 and training on 4 K-80 GPUs. My other run with different parameters is also running on the exact same setup but its still running. Both runs differ only in shuffle of data and a different batch size (the one that failed had a slightly larger batch size)", "body": "I am seeing this too -- I have two runs of the same model running with different hyperparameters, one is running smoothly, this one quit with the exact same error\r\n\r\n\r\n    avg_loss = self.train_epoch(training_data,validation_data,batch_size,save_prefix,epoch)\r\n  File \"TourQue_v1.py\", line 759, in train_epoch\r\n    gradients = loss.backward()\r\n  File \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 167, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)\r\n  File \"/u/dcontrac/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.py\", line 99, in backward\r\n    variables, grad_variables, retain_graph)\r\nRuntimeError: torch/csrc/autograd/input_buffer.cpp:14: add: Assertion `pos >= 0 && pos < buffer.size()` failed.\r\n\r\nRunning PyTorch v0.3 and training on 4 K-80 GPUs. My other run with different parameters is also running on the exact same setup but its still running. Both runs differ only in shuffle of data and a different batch size (the one that failed had a slightly larger batch size)"}