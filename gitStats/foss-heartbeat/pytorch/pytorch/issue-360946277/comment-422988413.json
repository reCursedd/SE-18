{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/422988413", "html_url": "https://github.com/pytorch/pytorch/pull/11758#issuecomment-422988413", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11758", "id": 422988413, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjk4ODQxMw==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-19T23:13:18Z", "updated_at": "2018-09-19T23:52:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>After making some changes on the CPU kernel (removing mod &amp; div, split lines for compiler optimization, etc..), now the runtime looks much nicer:</p>\n<pre><code>&gt;&gt;&gt; m = nn.PReLU()\n&gt;&gt;&gt; x = torch.randn(100, 100, 100, requires_grad=True)\n&gt;&gt;&gt; %timeit y = m(x)\n1000 loops, best of 3: 764 \u00b5s per loop\n\n&gt;&gt;&gt; y = m(x).sum()\n&gt;&gt;&gt; %timeit y.backward(retain_graph=True)\n100 loops, best of 3: 3.06 ms per loop\n\n&gt;&gt;&gt; m = nn.PReLU(100)\n&gt;&gt;&gt; x = torch.randn(100, 100, 100, requires_grad=True)\n&gt;&gt;&gt; %timeit y = m(x)\n1000 loops, best of 3: 877 \u00b5s per loop\n\n&gt;&gt;&gt; y = m(x).sum()\n&gt;&gt;&gt; %timeit y.backward(retain_graph=True)\n100 loops, best of 3: 4.53 ms per loop\n</code></pre>\n<p>Sorry I was looking at the wrong results. Just updated...</p>", "body_text": "After making some changes on the CPU kernel (removing mod & div, split lines for compiler optimization, etc..), now the runtime looks much nicer:\n>>> m = nn.PReLU()\n>>> x = torch.randn(100, 100, 100, requires_grad=True)\n>>> %timeit y = m(x)\n1000 loops, best of 3: 764 \u00b5s per loop\n\n>>> y = m(x).sum()\n>>> %timeit y.backward(retain_graph=True)\n100 loops, best of 3: 3.06 ms per loop\n\n>>> m = nn.PReLU(100)\n>>> x = torch.randn(100, 100, 100, requires_grad=True)\n>>> %timeit y = m(x)\n1000 loops, best of 3: 877 \u00b5s per loop\n\n>>> y = m(x).sum()\n>>> %timeit y.backward(retain_graph=True)\n100 loops, best of 3: 4.53 ms per loop\n\nSorry I was looking at the wrong results. Just updated...", "body": "After making some changes on the CPU kernel (removing mod & div, split lines for compiler optimization, etc..), now the runtime looks much nicer:\r\n```\r\n>>> m = nn.PReLU()\r\n>>> x = torch.randn(100, 100, 100, requires_grad=True)\r\n>>> %timeit y = m(x)\r\n1000 loops, best of 3: 764 \u00b5s per loop\r\n\r\n>>> y = m(x).sum()\r\n>>> %timeit y.backward(retain_graph=True)\r\n100 loops, best of 3: 3.06 ms per loop\r\n\r\n>>> m = nn.PReLU(100)\r\n>>> x = torch.randn(100, 100, 100, requires_grad=True)\r\n>>> %timeit y = m(x)\r\n1000 loops, best of 3: 877 \u00b5s per loop\r\n\r\n>>> y = m(x).sum()\r\n>>> %timeit y.backward(retain_graph=True)\r\n100 loops, best of 3: 4.53 ms per loop\r\n```\r\n\r\nSorry I was looking at the wrong results. Just updated..."}