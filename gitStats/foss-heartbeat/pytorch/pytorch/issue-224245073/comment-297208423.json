{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/297208423", "html_url": "https://github.com/pytorch/pytorch/issues/1355#issuecomment-297208423", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1355", "id": 297208423, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NzIwODQyMw==", "user": {"login": "zym1010", "id": 4273204, "node_id": "MDQ6VXNlcjQyNzMyMDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4273204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zym1010", "html_url": "https://github.com/zym1010", "followers_url": "https://api.github.com/users/zym1010/followers", "following_url": "https://api.github.com/users/zym1010/following{/other_user}", "gists_url": "https://api.github.com/users/zym1010/gists{/gist_id}", "starred_url": "https://api.github.com/users/zym1010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zym1010/subscriptions", "organizations_url": "https://api.github.com/users/zym1010/orgs", "repos_url": "https://api.github.com/users/zym1010/repos", "events_url": "https://api.github.com/users/zym1010/events{/privacy}", "received_events_url": "https://api.github.com/users/zym1010/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-26T01:06:56Z", "updated_at": "2017-04-26T01:07:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> tried running the program (still 22 workers) with following setting on shared mem, and stuck again.</p>\n<pre><code>yimengzh_everyday@yimengzh:~$ ipcs -lm\n\n------ Shared Memory Limits --------\nmax number of segments = 8192\nmax seg size (kbytes) = 18014398509465599\nmax total shared memory (kbytes) = 18446744073642442748\nmin seg size (bytes) = 1\n</code></pre>\n<p>didn't try one worker. first, that would be slow; second, if the problem is really dead locking, then it would definitely disappear.</p>", "body_text": "@apaszke tried running the program (still 22 workers) with following setting on shared mem, and stuck again.\nyimengzh_everyday@yimengzh:~$ ipcs -lm\n\n------ Shared Memory Limits --------\nmax number of segments = 8192\nmax seg size (kbytes) = 18014398509465599\nmax total shared memory (kbytes) = 18446744073642442748\nmin seg size (bytes) = 1\n\ndidn't try one worker. first, that would be slow; second, if the problem is really dead locking, then it would definitely disappear.", "body": "@apaszke tried running the program (still 22 workers) with following setting on shared mem, and stuck again.\r\n\r\n~~~\r\nyimengzh_everyday@yimengzh:~$ ipcs -lm\r\n\r\n------ Shared Memory Limits --------\r\nmax number of segments = 8192\r\nmax seg size (kbytes) = 18014398509465599\r\nmax total shared memory (kbytes) = 18446744073642442748\r\nmin seg size (bytes) = 1\r\n~~~\r\n\r\ndidn't try one worker. first, that would be slow; second, if the problem is really dead locking, then it would definitely disappear."}