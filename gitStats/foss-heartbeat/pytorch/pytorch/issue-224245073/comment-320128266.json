{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/320128266", "html_url": "https://github.com/pytorch/pytorch/issues/1355#issuecomment-320128266", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1355", "id": 320128266, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDEyODI2Ng==", "user": {"login": "zhengyunqq", "id": 25950565, "node_id": "MDQ6VXNlcjI1OTUwNTY1", "avatar_url": "https://avatars2.githubusercontent.com/u/25950565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhengyunqq", "html_url": "https://github.com/zhengyunqq", "followers_url": "https://api.github.com/users/zhengyunqq/followers", "following_url": "https://api.github.com/users/zhengyunqq/following{/other_user}", "gists_url": "https://api.github.com/users/zhengyunqq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhengyunqq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhengyunqq/subscriptions", "organizations_url": "https://api.github.com/users/zhengyunqq/orgs", "repos_url": "https://api.github.com/users/zhengyunqq/repos", "events_url": "https://api.github.com/users/zhengyunqq/events{/privacy}", "received_events_url": "https://api.github.com/users/zhengyunqq/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-04T00:57:47Z", "updated_at": "2017-08-07T10:38:20Z", "author_association": "NONE", "body_html": "<p>I also met the deadlock, especially when the work_number is large. Is there any possible solution for this problem? My /dev/shm size is 32GB, with cuda 7.5, pytorch 0.1.12  and python 2.7.13. The following is related info after death. It seems related to memory. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/25950565/29018562-2d7fd166-7b8e-11e7-8ca5-acd2fae7d2ed.jpg\"><img src=\"https://user-images.githubusercontent.com/25950565/29018562-2d7fd166-7b8e-11e7-8ca5-acd2fae7d2ed.jpg\" alt=\"default\" style=\"max-width:100%;\"></a><br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/25950565/29018620-5d64607c-7b8e-11e7-82a5-88f5b48bd701.png\"><img src=\"https://user-images.githubusercontent.com/25950565/29018620-5d64607c-7b8e-11e7-82a5-88f5b48bd701.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>", "body_text": "I also met the deadlock, especially when the work_number is large. Is there any possible solution for this problem? My /dev/shm size is 32GB, with cuda 7.5, pytorch 0.1.12  and python 2.7.13. The following is related info after death. It seems related to memory. @apaszke", "body": "I also met the deadlock, especially when the work_number is large. Is there any possible solution for this problem? My /dev/shm size is 32GB, with cuda 7.5, pytorch 0.1.12  and python 2.7.13. The following is related info after death. It seems related to memory. @apaszke \r\n\r\n![default](https://user-images.githubusercontent.com/25950565/29018562-2d7fd166-7b8e-11e7-8ca5-acd2fae7d2ed.jpg)\r\n![image](https://user-images.githubusercontent.com/25950565/29018620-5d64607c-7b8e-11e7-82a5-88f5b48bd701.png)\r\n\r\n\r\n"}