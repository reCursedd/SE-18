{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/308587289", "html_url": "https://github.com/pytorch/pytorch/issues/1355#issuecomment-308587289", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1355", "id": 308587289, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODU4NzI4OQ==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-14T23:33:49Z", "updated_at": "2017-06-14T23:33:49Z", "author_association": "MEMBER", "body_html": "<p>Ok, so after investigating the problem it seems to be a weird issue. Even when I limit <code>/dev/shm</code> to be only 128MB large, Linux is happy to let us create 147MB files there, mmap them fully in memory, but will send a deadly SIGBUS to the worker once it actually tries to access the pages... I can't think of any mechanism that would allow us to check validity of the pages except for iterating over them, and touching each one, with a SIGBUS handler registered...</p>\n<p>A workaround for now is to expand <code>/dev/shm</code> with the <code>mount</code> command as I shown above. Try with 16GB (ofc if you have enough RAM).</p>", "body_text": "Ok, so after investigating the problem it seems to be a weird issue. Even when I limit /dev/shm to be only 128MB large, Linux is happy to let us create 147MB files there, mmap them fully in memory, but will send a deadly SIGBUS to the worker once it actually tries to access the pages... I can't think of any mechanism that would allow us to check validity of the pages except for iterating over them, and touching each one, with a SIGBUS handler registered...\nA workaround for now is to expand /dev/shm with the mount command as I shown above. Try with 16GB (ofc if you have enough RAM).", "body": "Ok, so after investigating the problem it seems to be a weird issue. Even when I limit `/dev/shm` to be only 128MB large, Linux is happy to let us create 147MB files there, mmap them fully in memory, but will send a deadly SIGBUS to the worker once it actually tries to access the pages... I can't think of any mechanism that would allow us to check validity of the pages except for iterating over them, and touching each one, with a SIGBUS handler registered...\r\n\r\nA workaround for now is to expand `/dev/shm` with the `mount` command as I shown above. Try with 16GB (ofc if you have enough RAM)."}