{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/345037364", "html_url": "https://github.com/pytorch/pytorch/issues/1355#issuecomment-345037364", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1355", "id": 345037364, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTAzNzM2NA==", "user": {"login": "gcr", "id": 45252, "node_id": "MDQ6VXNlcjQ1MjUy", "avatar_url": "https://avatars0.githubusercontent.com/u/45252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gcr", "html_url": "https://github.com/gcr", "followers_url": "https://api.github.com/users/gcr/followers", "following_url": "https://api.github.com/users/gcr/following{/other_user}", "gists_url": "https://api.github.com/users/gcr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gcr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gcr/subscriptions", "organizations_url": "https://api.github.com/users/gcr/orgs", "repos_url": "https://api.github.com/users/gcr/repos", "events_url": "https://api.github.com/users/gcr/events{/privacy}", "received_events_url": "https://api.github.com/users/gcr/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-16T19:32:35Z", "updated_at": "2017-11-16T19:43:46Z", "author_association": "NONE", "body_html": "<p>For what it's worth, I had this issue on Python 2.7 on ubuntu 14.04. My data loader read from a sqlite database and worked perfectly with <code>num_workers=0</code>, sometimes seemed OK with <code>num_workers=1</code>, and very quickly deadlocked for any higher value. Stack traces showed the process hung in <code>recv_bytes</code>.</p>\n<p>Things that didn't work:</p>\n<ul>\n<li>Passing <code>--shm-size 8G</code> or <code>--ipc=host</code> when launching docker</li>\n<li>Running <code>echo 16834 | sudo tee /proc/sys/kernel/shmmni</code> to increase the number of shared memory segments (the default was 4096 on my machine)</li>\n<li>Setting <code>pin_memory=True</code> or <code>pin_memory=False</code>, neither one helped</li>\n</ul>\n<p>The thing that reliably fixed my issue was porting my code to Python 3. Launching the same version of Torch inside a Python 3.6 instance (from Anaconda) completely fixed my issue and now data loading doesn't hang anymore.</p>", "body_text": "For what it's worth, I had this issue on Python 2.7 on ubuntu 14.04. My data loader read from a sqlite database and worked perfectly with num_workers=0, sometimes seemed OK with num_workers=1, and very quickly deadlocked for any higher value. Stack traces showed the process hung in recv_bytes.\nThings that didn't work:\n\nPassing --shm-size 8G or --ipc=host when launching docker\nRunning echo 16834 | sudo tee /proc/sys/kernel/shmmni to increase the number of shared memory segments (the default was 4096 on my machine)\nSetting pin_memory=True or pin_memory=False, neither one helped\n\nThe thing that reliably fixed my issue was porting my code to Python 3. Launching the same version of Torch inside a Python 3.6 instance (from Anaconda) completely fixed my issue and now data loading doesn't hang anymore.", "body": "For what it's worth, I had this issue on Python 2.7 on ubuntu 14.04. My data loader read from a sqlite database and worked perfectly with `num_workers=0`, sometimes seemed OK with `num_workers=1`, and very quickly deadlocked for any higher value. Stack traces showed the process hung in `recv_bytes`.\r\n\r\nThings that didn't work:\r\n- Passing `--shm-size 8G` or `--ipc=host` when launching docker\r\n- Running `echo 16834 | sudo tee /proc/sys/kernel/shmmni` to increase the number of shared memory segments (the default was 4096 on my machine)\r\n- Setting `pin_memory=True` or `pin_memory=False`, neither one helped\r\n\r\nThe thing that reliably fixed my issue was porting my code to Python 3. Launching the same version of Torch inside a Python 3.6 instance (from Anaconda) completely fixed my issue and now data loading doesn't hang anymore."}