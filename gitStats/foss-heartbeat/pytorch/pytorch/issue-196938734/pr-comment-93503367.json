{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93503367", "pull_request_review_id": 14032290, "id": 93503367, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDkzNTAzMzY3", "diff_hunk": "@@ -0,0 +1,78 @@\n+from .module import Module\n+from torch.autograd import Function\n+\n+\n+class PixelShuffle(Module):\n+    \"\"\"Rearranges elements in a tensor of shape [*, C*r^2, H, W] to a\n+    tensor of shape [C, H*r, W*r]. This is useful for implementing\n+    efficient sub-pixel convolution with a stride of 1/r.\n+    \"Real-Time Single Image and Video Super-Resolution Using an Efficient\n+    Sub-Pixel Convolutional Neural Network\" - Shi et. al (2016) for more details\n+    Args:\n+        upscale_factor: factor to increase spatial resolution by\n+    Input Shape: [*, channels*upscale_factor^2, height, width]\n+    Output Shape:[*, channels, height*upscale_factor, width*upscale_factor]\n+    Examples:\n+        >>> ps = nn.PixelShuffle(3)\n+        >>> input = autograd.Variable(torch.Tensor(1, 9, 4, 4))\n+        >>> output = m(input)\n+        >>> print(output.size())\n+    \"\"\"\n+\n+    def __init__(self, upscale_factor):\n+        super(PixelShuffle, self).__init__()\n+        self.upscale_factor = upscale_factor\n+\n+    def forward(self, input):\n+        return _PixelShuffleFunction(self.upscale_factor)(input)\n+\n+    def __repr__(self):\n+        return self.__class__.__name__ + ' (upscale_factor=' + str(self.upscale_factor) + ')'\n+\n+\n+class _PixelShuffleFunction(Function):\n+    def __init__(self, upscale_factor):\n+        self.upscale_factor = upscale_factor\n+        self.upscale_factor_squared = upscale_factor ** 2\n+        self._shuffle_out = None\n+        self._shuffle_in = None\n+\n+    def forward(self, input):\n+        if self._shuffle_out is None:\n+            self._shuffle_out = input.new()\n+\n+        self.save_for_backward(input)\n+\n+        batch_size = input.size(0)\n+\n+        channels = int(input.size(1) / self.upscale_factor_squared)\n+        in_height = input.size(2)\n+        in_width = input.size(3)\n+\n+        input_view = input.view(batch_size, channels, self.upscale_factor, self.upscale_factor, in_height, in_width)\n+\n+        self._shuffle_out.resize_(input_view.size(0), input_view.size(1), input_view.size(4),\n+                                  input_view.size(2), input_view.size(5), input_view.size(3))\n+\n+        self._shuffle_out.copy_(input_view.permute(0, 1, 4, 2, 5, 3))\n+\n+        out_height = in_height * self.upscale_factor\n+        out_width = in_width * self.upscale_factor\n+\n+        return self._shuffle_out.view(batch_size, channels, out_height, out_width)", "path": "torch/nn/modules/pixelshuffle.py", "position": null, "original_position": 62, "commit_id": "c1914f2fc3f2e9469bb96b10e3fb2cb724cdb6e5", "original_commit_id": "476a7c0254af82eb1fd8fbb9c6ca055a9e481b8f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Could you please rewrite that as\r\n```python\r\n_shuffle_out = input.new()\r\n\r\n# no save_for_backward\r\n# all the code until return\r\n\r\noutput = self._shuffle_out.view(batch_size, channels, out_height, out_width)\r\nself.save_for_backward(input, output)\r\nreturn output\r\n```\r\n\r\nIt will ensure that we're going to correctly track the in-place ops on the output (view doesn't do memory copy, so potentially someone can modify your internal buffer).", "created_at": "2016-12-21T19:27:20Z", "updated_at": "2018-11-23T15:32:03Z", "html_url": "https://github.com/pytorch/pytorch/pull/338#discussion_r93503367", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/338", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/93503367"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/338#discussion_r93503367"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/338"}}, "body_html": "<p>Could you please rewrite that as</p>\n<div class=\"highlight highlight-source-python\"><pre>_shuffle_out <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.new()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> no save_for_backward</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> all the code until return</span>\n\noutput <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._shuffle_out.view(batch_size, channels, out_height, out_width)\n<span class=\"pl-c1\">self</span>.save_for_backward(<span class=\"pl-c1\">input</span>, output)\n<span class=\"pl-k\">return</span> output</pre></div>\n<p>It will ensure that we're going to correctly track the in-place ops on the output (view doesn't do memory copy, so potentially someone can modify your internal buffer).</p>", "body_text": "Could you please rewrite that as\n_shuffle_out = input.new()\n\n# no save_for_backward\n# all the code until return\n\noutput = self._shuffle_out.view(batch_size, channels, out_height, out_width)\nself.save_for_backward(input, output)\nreturn output\nIt will ensure that we're going to correctly track the in-place ops on the output (view doesn't do memory copy, so potentially someone can modify your internal buffer)."}