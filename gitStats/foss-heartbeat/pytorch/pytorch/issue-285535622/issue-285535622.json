{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4447", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4447/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4447/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4447/events", "html_url": "https://github.com/pytorch/pytorch/issues/4447", "id": 285535622, "node_id": "MDU6SXNzdWUyODU1MzU2MjI=", "number": 4447, "title": "Surprising behavior of `nn.Parameter` with  `np.float64` scalars", "user": {"login": "IssamLaradji", "id": 3382128, "node_id": "MDQ6VXNlcjMzODIxMjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/3382128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IssamLaradji", "html_url": "https://github.com/IssamLaradji", "followers_url": "https://api.github.com/users/IssamLaradji/followers", "following_url": "https://api.github.com/users/IssamLaradji/following{/other_user}", "gists_url": "https://api.github.com/users/IssamLaradji/gists{/gist_id}", "starred_url": "https://api.github.com/users/IssamLaradji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IssamLaradji/subscriptions", "organizations_url": "https://api.github.com/users/IssamLaradji/orgs", "repos_url": "https://api.github.com/users/IssamLaradji/repos", "events_url": "https://api.github.com/users/IssamLaradji/events{/privacy}", "received_events_url": "https://api.github.com/users/IssamLaradji/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-02T20:58:17Z", "updated_at": "2018-01-02T21:15:10Z", "closed_at": "2018-01-02T21:14:17Z", "author_association": "NONE", "body_html": "<p><code>nn.Parameter</code> and <code>numpy.float64</code> don't seem to mix well, consider the following behavior,</p>\n<pre><code>ipdb&gt; log_v = nn.Parameter(torch.FloatTensor(np.array([-2])))\n\nipdb&gt; - 0.5 * np.log(2 * np.pi) - 0.5 * log_v \narray([[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\n1.00000e-02 *\n  8.1061\n[torch.FloatTensor of size 1]\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]], dtype=object)\n</code></pre>\n<p>Is this an expected  behavior ?</p>\n<p>Note that <code>np.log</code> returns a <code>np.float</code> type scalar</p>\n<pre><code>ipdb&gt; type(- 0.5 * np.log(2 * np.pi))\n&lt;class 'numpy.float64'&gt;\n</code></pre>\n<p>I would use <code>torch.log</code> instead of <code>np.log</code> but it seems that <code>torch</code> math operations don't work directly on scalars without first being  converted to a <code>FloatTensor</code> - which adds boiler code.</p>", "body_text": "nn.Parameter and numpy.float64 don't seem to mix well, consider the following behavior,\nipdb> log_v = nn.Parameter(torch.FloatTensor(np.array([-2])))\n\nipdb> - 0.5 * np.log(2 * np.pi) - 0.5 * log_v \narray([[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\n1.00000e-02 *\n  8.1061\n[torch.FloatTensor of size 1]\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]], dtype=object)\n\nIs this an expected  behavior ?\nNote that np.log returns a np.float type scalar\nipdb> type(- 0.5 * np.log(2 * np.pi))\n<class 'numpy.float64'>\n\nI would use torch.log instead of np.log but it seems that torch math operations don't work directly on scalars without first being  converted to a FloatTensor - which adds boiler code.", "body": "`nn.Parameter` and `numpy.float64` don't seem to mix well, consider the following behavior,\r\n\r\n```\r\nipdb> log_v = nn.Parameter(torch.FloatTensor(np.array([-2])))\r\n\r\nipdb> - 0.5 * np.log(2 * np.pi) - 0.5 * log_v \r\narray([[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[Variable containing:\r\n1.00000e-02 *\r\n  8.1061\r\n[torch.FloatTensor of size 1]\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]], dtype=object)\r\n```\r\n\r\nIs this an expected  behavior ?\r\n\r\nNote that `np.log` returns a `np.float` type scalar\r\n\r\n```\r\nipdb> type(- 0.5 * np.log(2 * np.pi))\r\n<class 'numpy.float64'>\r\n```\r\n\r\nI would use `torch.log` instead of `np.log` but it seems that `torch` math operations don't work directly on scalars without first being  converted to a `FloatTensor` - which adds boiler code."}