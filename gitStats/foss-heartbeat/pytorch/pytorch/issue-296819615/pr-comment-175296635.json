{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175296635", "pull_request_review_id": 104804707, "id": 175296635, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NTI5NjYzNQ==", "diff_hunk": "@@ -0,0 +1,31 @@\n+torch.utils.bottleneck\n+===============\n+\n+.. currentmodule:: torch.utils.bottleneck\n+\n+`torch.utils.bottleneck` is a tool that can be used as an initial step for\n+debugging bottlenecks in your program. It summarizes runs of your script with \n+the Python profiler and PyTorch's autograd profiler. \n+\n+Run it on the command line with \n+\n+::\n+\n+    python -m torch.utils.bottleneck -- /path/to/source/script.py [args]\n+\n+where [args] are any number of arguments to `script.py`, or run\n+``python -m torch.utils.bottleneck -h`` for more usage instructions.\n+\n+.. warning::\n+    Because your script will be profiled, please ensure that it exits in a \n+    finite amount of time.\n+\n+.. warning::\n+    Due to the asynchronous nature of CUDA kernels, when running against\n+    CUDA code, the cProfile output and CPU-mode autograd profilers may\n+    not show correct timings. In this case, the CUDA-mode autograd\n+    profiler is better at assigning blame to the relevant operator(s).", "path": "docs/source/bottleneck.rst", "position": 27, "original_position": 27, "commit_id": "1528ed4f2ff57111dc5224eb86864738bd56957b", "original_commit_id": "1528ed4f2ff57111dc5224eb86864738bd56957b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I'm not sure how to answer the first question. Most of the cost comes from profiling of CUDA ops so you have that, but what matters is that if CPU is running way ahead of the GPU then the (general) profiling costs will be hidden by asynchronous execution.\r\n\r\nYes, you're right of course! It's the other way around \ud83d\ude0a You're CPU bound if GPU time is much smaller or is close to CPU time.", "created_at": "2018-03-18T17:32:52Z", "updated_at": "2018-11-23T15:40:55Z", "html_url": "https://github.com/pytorch/pytorch/pull/5216#discussion_r175296635", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5216", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/175296635"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5216#discussion_r175296635"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5216"}}, "body_html": "<p>I'm not sure how to answer the first question. Most of the cost comes from profiling of CUDA ops so you have that, but what matters is that if CPU is running way ahead of the GPU then the (general) profiling costs will be hidden by asynchronous execution.</p>\n<p>Yes, you're right of course! It's the other way around <g-emoji class=\"g-emoji\" alias=\"blush\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png\">\ud83d\ude0a</g-emoji> You're CPU bound if GPU time is much smaller or is close to CPU time.</p>", "body_text": "I'm not sure how to answer the first question. Most of the cost comes from profiling of CUDA ops so you have that, but what matters is that if CPU is running way ahead of the GPU then the (general) profiling costs will be hidden by asynchronous execution.\nYes, you're right of course! It's the other way around \ud83d\ude0a You're CPU bound if GPU time is much smaller or is close to CPU time.", "in_reply_to_id": 173950045}