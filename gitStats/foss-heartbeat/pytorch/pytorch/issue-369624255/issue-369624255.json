{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12609", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12609/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12609/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12609/events", "html_url": "https://github.com/pytorch/pytorch/issues/12609", "id": 369624255, "node_id": "MDU6SXNzdWUzNjk2MjQyNTU=", "number": 12609, "title": "Request for stripped down / inference only pytorch wheels", "user": {"login": "zeryx", "id": 1892175, "node_id": "MDQ6VXNlcjE4OTIxNzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1892175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zeryx", "html_url": "https://github.com/zeryx", "followers_url": "https://api.github.com/users/zeryx/followers", "following_url": "https://api.github.com/users/zeryx/following{/other_user}", "gists_url": "https://api.github.com/users/zeryx/gists{/gist_id}", "starred_url": "https://api.github.com/users/zeryx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zeryx/subscriptions", "organizations_url": "https://api.github.com/users/zeryx/orgs", "repos_url": "https://api.github.com/users/zeryx/repos", "events_url": "https://api.github.com/users/zeryx/events{/privacy}", "received_events_url": "https://api.github.com/users/zeryx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-10-12T16:33:17Z", "updated_at": "2018-11-07T23:58:06Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"rocket\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f680.png\">\ud83d\ude80</g-emoji> Feature</h2>\n<p>Creating a precompiled pytorch wheel file that is trimmed down, inference only version.</p>\n<h2>Motivation</h2>\n<p>Right now pytorch wheels are on average ~400MB zipped -&gt; 1.+ GB unzipped, which is not a big deal for training &amp; prototyping as generally the wheels are only installed once - but that's not the case for productionizing using service providers like sagemaker / algorithmia / etc.</p>\n<h2>Pitch</h2>\n<p>If we can create a trimmed down, potentially inference only capable wheel file - we can directly improve the load time performance of these algorithms in serverless algorithm delivery environments, which could directly pytorch's ability to compete in the HPC serverless marketplace.</p>\n<h2>Alternatives</h2>\n<p>We could also provide a clear way for users to create their own wheels, by simplifying and documenting the build process somewhat to enable optional features during the compilation process.</p>\n<h2>Additional context</h2>\n<p>Full disclosure, I'm an employee at Algorithmia and this change would make my life much easier <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "body_text": "\ud83d\ude80 Feature\nCreating a precompiled pytorch wheel file that is trimmed down, inference only version.\nMotivation\nRight now pytorch wheels are on average ~400MB zipped -> 1.+ GB unzipped, which is not a big deal for training & prototyping as generally the wheels are only installed once - but that's not the case for productionizing using service providers like sagemaker / algorithmia / etc.\nPitch\nIf we can create a trimmed down, potentially inference only capable wheel file - we can directly improve the load time performance of these algorithms in serverless algorithm delivery environments, which could directly pytorch's ability to compete in the HPC serverless marketplace.\nAlternatives\nWe could also provide a clear way for users to create their own wheels, by simplifying and documenting the build process somewhat to enable optional features during the compilation process.\nAdditional context\nFull disclosure, I'm an employee at Algorithmia and this change would make my life much easier \ud83d\ude04", "body": "## \ud83d\ude80 Feature\r\nCreating a precompiled pytorch wheel file that is trimmed down, inference only version.\r\n\r\n## Motivation\r\n\r\nRight now pytorch wheels are on average ~400MB zipped -> 1.+ GB unzipped, which is not a big deal for training & prototyping as generally the wheels are only installed once - but that's not the case for productionizing using service providers like sagemaker / algorithmia / etc.\r\n\r\n## Pitch\r\n\r\nIf we can create a trimmed down, potentially inference only capable wheel file - we can directly improve the load time performance of these algorithms in serverless algorithm delivery environments, which could directly pytorch's ability to compete in the HPC serverless marketplace.\r\n\r\n## Alternatives\r\n\r\nWe could also provide a clear way for users to create their own wheels, by simplifying and documenting the build process somewhat to enable optional features during the compilation process. \r\n\r\n## Additional context\r\n\r\nFull disclosure, I'm an employee at Algorithmia and this change would make my life much easier :smile: \r\n"}