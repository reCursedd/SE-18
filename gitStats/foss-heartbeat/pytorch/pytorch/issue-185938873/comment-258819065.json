{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/258819065", "html_url": "https://github.com/pytorch/pytorch/issues/175#issuecomment-258819065", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/175", "id": 258819065, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODgxOTA2NQ==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-07T12:06:17Z", "updated_at": "2016-11-07T12:08:02Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> Why is it dysfunctional? The old interface requires you to keep the state dict anyway, and you can only use a given state dict with the params it was initially used with. Also, most times the state is completely undocumented and mixed with optimization parameters. You won't win anything by abandoning the optimizers. They clean up parts of this mess by holding the state in a way nicer form.</p>\n<p>Also, by moving the calls into the optimizer you won't ever forget to call <code>zero_grad_parameters</code>, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.</p>\n<p>I had two ideas about this:</p>\n<ol>\n<li>Allow to register gradient hooks that modify the accumulated grads</li>\n<li>Allow to leave out the <code>forward_closure</code> argument, and use previously accumulated gradient in the optimized parameters. This will probably have to throw in 2nd order methods and optimizers that need to make several forward calls.</li>\n</ol>", "body_text": "@soumith Why is it dysfunctional? The old interface requires you to keep the state dict anyway, and you can only use a given state dict with the params it was initially used with. Also, most times the state is completely undocumented and mixed with optimization parameters. You won't win anything by abandoning the optimizers. They clean up parts of this mess by holding the state in a way nicer form.\nAlso, by moving the calls into the optimizer you won't ever forget to call zero_grad_parameters, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.\nI had two ideas about this:\n\nAllow to register gradient hooks that modify the accumulated grads\nAllow to leave out the forward_closure argument, and use previously accumulated gradient in the optimized parameters. This will probably have to throw in 2nd order methods and optimizers that need to make several forward calls.", "body": "@soumith Why is it dysfunctional? The old interface requires you to keep the state dict anyway, and you can only use a given state dict with the params it was initially used with. Also, most times the state is completely undocumented and mixed with optimization parameters. You won't win anything by abandoning the optimizers. They clean up parts of this mess by holding the state in a way nicer form.\n\nAlso, by moving the calls into the optimizer you won't ever forget to call `zero_grad_parameters`, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.\n\nI had two ideas about this:\n1. Allow to register gradient hooks that modify the accumulated grads\n2. Allow to leave out the `forward_closure` argument, and use previously accumulated gradient in the optimized parameters. This will probably have to throw in 2nd order methods and optimizers that need to make several forward calls.\n"}