{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/258836294", "html_url": "https://github.com/pytorch/pytorch/issues/175#issuecomment-258836294", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/175", "id": 258836294, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODgzNjI5NA==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-07T13:34:24Z", "updated_at": "2016-11-07T13:34:24Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> the zeroing of gradients and calling backward() are only one part of the problem, which we maybe can try to solve (idk), but more importantly, more often than not scenarios are creeping up where in every iteration we are optimizing different sets of params. True for dcgan, metalearning, and anything that's not vanilla training. So in that case. we will have to create an optimizer for every set of params we are trying to optimize (which we might not know ahead of time).</p>\n<blockquote>\n<p>Also, by moving the calls into the optimizer you won't ever forget to call zero_grad_parameters, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.</p>\n</blockquote>\n<p>Yes, but I am saying that we missed quite a few ways in which one uses optim day to day.</p>", "body_text": "@apaszke the zeroing of gradients and calling backward() are only one part of the problem, which we maybe can try to solve (idk), but more importantly, more often than not scenarios are creeping up where in every iteration we are optimizing different sets of params. True for dcgan, metalearning, and anything that's not vanilla training. So in that case. we will have to create an optimizer for every set of params we are trying to optimize (which we might not know ahead of time).\n\nAlso, by moving the calls into the optimizer you won't ever forget to call zero_grad_parameters, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.\n\nYes, but I am saying that we missed quite a few ways in which one uses optim day to day.", "body": "@apaszke the zeroing of gradients and calling backward() are only one part of the problem, which we maybe can try to solve (idk), but more importantly, more often than not scenarios are creeping up where in every iteration we are optimizing different sets of params. True for dcgan, metalearning, and anything that's not vanilla training. So in that case. we will have to create an optimizer for every set of params we are trying to optimize (which we might not know ahead of time).\n\n> Also, by moving the calls into the optimizer you won't ever forget to call zero_grad_parameters, because it does it for you. Additionally, we agreed that having these forward closure that do all this complex stuff is quite unintuitive, and its why we decided to keep them as simple as possible.\n\nYes, but I am saying that we missed quite a few ways in which one uses optim day to day.\n"}