{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/335875083", "html_url": "https://github.com/pytorch/pytorch/issues/3068#issuecomment-335875083", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3068", "id": 335875083, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTg3NTA4Mw==", "user": {"login": "Vayel", "id": 6124369, "node_id": "MDQ6VXNlcjYxMjQzNjk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6124369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Vayel", "html_url": "https://github.com/Vayel", "followers_url": "https://api.github.com/users/Vayel/followers", "following_url": "https://api.github.com/users/Vayel/following{/other_user}", "gists_url": "https://api.github.com/users/Vayel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Vayel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Vayel/subscriptions", "organizations_url": "https://api.github.com/users/Vayel/orgs", "repos_url": "https://api.github.com/users/Vayel/repos", "events_url": "https://api.github.com/users/Vayel/events{/privacy}", "received_events_url": "https://api.github.com/users/Vayel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-11T16:52:51Z", "updated_at": "2017-10-11T16:53:46Z", "author_association": "NONE", "body_html": "<pre><code>RuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-13-5b641c6e7de1&gt; in &lt;module&gt;()\n      3 \n      4 show_batch(images)\n----&gt; 5 print('Prediction: ', predict(model, images))\n\n&lt;ipython-input-12-d4d02476c734&gt; in predict(model, images)\n      1 def predict(model, images):\n----&gt; 2     outputs = model(images) # Should be Variables(images)\n      3     _, predicted = torch.max(outputs.data, 1)\n      4     return predicted\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--&gt; 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n&lt;ipython-input-7-ac002affe945&gt; in forward(self, x)\n      6 \n      7     def forward(self, x):\n----&gt; 8         h_relu = F.relu(self.linear1(x.view(BATCH_SIZE, -1))) # Flatten images\n      9         y_pred = self.linear2(h_relu)\n     10         return y_pred\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--&gt; 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/linear.py in forward(self, input)\n     51 \n     52     def forward(self, input):\n---&gt; 53         return F.linear(input, self.weight, self.bias)\n     54 \n     55     def __repr__(self):\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/functional.py in linear(input, weight, bias)\n    551     if input.dim() == 2 and bias is not None:\n    552         # fused op is marginally faster\n--&gt; 553         return torch.addmm(bias, input, weight.t())\n    554 \n    555     output = input.matmul(weight.t())\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in addmm(cls, *args)\n    922         @classmethod\n    923         def addmm(cls, *args):\n--&gt; 924             return cls._blas(Addmm, args, False)\n    925 \n    926         @classmethod\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in _blas(cls, args, inplace)\n    918             else:\n    919                 tensors = args\n--&gt; 920             return cls.apply(*(tensors + (alpha, beta, inplace)))\n    921 \n    922         @classmethod\n\nRuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition\n</code></pre>", "body_text": "RuntimeError                              Traceback (most recent call last)\n<ipython-input-13-5b641c6e7de1> in <module>()\n      3 \n      4 show_batch(images)\n----> 5 print('Prediction: ', predict(model, images))\n\n<ipython-input-12-d4d02476c734> in predict(model, images)\n      1 def predict(model, images):\n----> 2     outputs = model(images) # Should be Variables(images)\n      3     _, predicted = torch.max(outputs.data, 1)\n      4     return predicted\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n<ipython-input-7-ac002affe945> in forward(self, x)\n      6 \n      7     def forward(self, x):\n----> 8         h_relu = F.relu(self.linear1(x.view(BATCH_SIZE, -1))) # Flatten images\n      9         y_pred = self.linear2(h_relu)\n     10         return y_pred\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/linear.py in forward(self, input)\n     51 \n     52     def forward(self, input):\n---> 53         return F.linear(input, self.weight, self.bias)\n     54 \n     55     def __repr__(self):\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/functional.py in linear(input, weight, bias)\n    551     if input.dim() == 2 and bias is not None:\n    552         # fused op is marginally faster\n--> 553         return torch.addmm(bias, input, weight.t())\n    554 \n    555     output = input.matmul(weight.t())\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in addmm(cls, *args)\n    922         @classmethod\n    923         def addmm(cls, *args):\n--> 924             return cls._blas(Addmm, args, False)\n    925 \n    926         @classmethod\n\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in _blas(cls, args, inplace)\n    918             else:\n    919                 tensors = args\n--> 920             return cls.apply(*(tensors + (alpha, beta, inplace)))\n    921 \n    922         @classmethod\n\nRuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition", "body": "```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-13-5b641c6e7de1> in <module>()\r\n      3 \r\n      4 show_batch(images)\r\n----> 5 print('Prediction: ', predict(model, images))\r\n\r\n<ipython-input-12-d4d02476c734> in predict(model, images)\r\n      1 def predict(model, images):\r\n----> 2     outputs = model(images) # Should be Variables(images)\r\n      3     _, predicted = torch.max(outputs.data, 1)\r\n      4     return predicted\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-7-ac002affe945> in forward(self, x)\r\n      6 \r\n      7     def forward(self, x):\r\n----> 8         h_relu = F.relu(self.linear1(x.view(BATCH_SIZE, -1))) # Flatten images\r\n      9         y_pred = self.linear2(h_relu)\r\n     10         return y_pred\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/modules/linear.py in forward(self, input)\r\n     51 \r\n     52     def forward(self, input):\r\n---> 53         return F.linear(input, self.weight, self.bias)\r\n     54 \r\n     55     def __repr__(self):\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/nn/functional.py in linear(input, weight, bias)\r\n    551     if input.dim() == 2 and bias is not None:\r\n    552         # fused op is marginally faster\r\n--> 553         return torch.addmm(bias, input, weight.t())\r\n    554 \r\n    555     output = input.matmul(weight.t())\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in addmm(cls, *args)\r\n    922         @classmethod\r\n    923         def addmm(cls, *args):\r\n--> 924             return cls._blas(Addmm, args, False)\r\n    925 \r\n    926         @classmethod\r\n\r\n~/miniconda3/envs/ml_lab/lib/python3.6/site-packages/torch/autograd/variable.py in _blas(cls, args, inplace)\r\n    918             else:\r\n    919                 tensors = args\r\n--> 920             return cls.apply(*(tensors + (alpha, beta, inplace)))\r\n    921 \r\n    922         @classmethod\r\n\r\nRuntimeError: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition\r\n```"}