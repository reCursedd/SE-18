{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12324", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12324/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12324/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12324/events", "html_url": "https://github.com/pytorch/pytorch/issues/12324", "id": 366799403, "node_id": "MDU6SXNzdWUzNjY3OTk0MDM=", "number": 12324, "title": "test_autograd.TestAutograd.test_ctc_loss fails : cuda runtime error : too many resources requested", "user": {"login": "avmgithub", "id": 9083746, "node_id": "MDQ6VXNlcjkwODM3NDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9083746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avmgithub", "html_url": "https://github.com/avmgithub", "followers_url": "https://api.github.com/users/avmgithub/followers", "following_url": "https://api.github.com/users/avmgithub/following{/other_user}", "gists_url": "https://api.github.com/users/avmgithub/gists{/gist_id}", "starred_url": "https://api.github.com/users/avmgithub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avmgithub/subscriptions", "organizations_url": "https://api.github.com/users/avmgithub/orgs", "repos_url": "https://api.github.com/users/avmgithub/repos", "events_url": "https://api.github.com/users/avmgithub/events{/privacy}", "received_events_url": "https://api.github.com/users/avmgithub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1076922545, "node_id": "MDU6TGFiZWwxMDc2OTIyNTQ1", "url": "https://api.github.com/repos/pytorch/pytorch/labels/autograd", "name": "autograd", "color": "dd7a92", "default": false}, {"id": 778855555, "node_id": "MDU6TGFiZWw3Nzg4NTU1NTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/build", "name": "build", "color": "bfdadc", "default": false}, {"id": 679955625, "node_id": "MDU6TGFiZWw2Nzk5NTU2MjU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/crash", "name": "crash", "color": "d93f0b", "default": false}, {"id": 1076930055, "node_id": "MDU6TGFiZWwxMDc2OTMwMDU1", "url": "https://api.github.com/repos/pytorch/pytorch/labels/cuda", "name": "cuda", "color": "a3e88b", "default": false}, {"id": 1076923012, "node_id": "MDU6TGFiZWwxMDc2OTIzMDEy", "url": "https://api.github.com/repos/pytorch/pytorch/labels/loss", "name": "loss", "color": "56ce06", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-04T13:48:51Z", "updated_at": "2018-10-11T00:11:04Z", "closed_at": "2018-10-11T00:11:04Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>When running :  python -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v<br>\nThe test fails with :   RuntimeError: cuda runtime error (7) : too many resources requested for launch at /pytorch/aten/src/ATen/native/cuda/LossCTC.cu:537</p>\n<p>If I hardcode   threads_batch = 8;   in pytorch/aten/src/ATen/native/cuda/LossCTC.cu  around line 522, the test passes.</p>\n<h2>To Reproduce</h2>\n<p>python -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v</p>\n\n<h2>Expected behavior</h2>\n<p>Should pass test.</p>\n<h2>Environment</h2>\n<ul>\n<li>PyTorch Version (e.g., 1.0): torch (1.0.0a0+b911ca9)</li>\n<li>OS (e.g., Linux):  RH 7.5    ppc64le   P9</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source):  source</li>\n<li>Build command you used (if compiling from source):   python setup.py install</li>\n<li>Python version:  3.6</li>\n<li>CUDA/cuDNN version:  10   or  9.2   /   7.1.3</li>\n<li>GPU models and configuration:   4 x Voltas</li>\n<li>Any other relevant information:</li>\n</ul>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\nWhen running :  python -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v\nThe test fails with :   RuntimeError: cuda runtime error (7) : too many resources requested for launch at /pytorch/aten/src/ATen/native/cuda/LossCTC.cu:537\nIf I hardcode   threads_batch = 8;   in pytorch/aten/src/ATen/native/cuda/LossCTC.cu  around line 522, the test passes.\nTo Reproduce\npython -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v\n\nExpected behavior\nShould pass test.\nEnvironment\n\nPyTorch Version (e.g., 1.0): torch (1.0.0a0+b911ca9)\nOS (e.g., Linux):  RH 7.5    ppc64le   P9\nHow you installed PyTorch (conda, pip, source):  source\nBuild command you used (if compiling from source):   python setup.py install\nPython version:  3.6\nCUDA/cuDNN version:  10   or  9.2   /   7.1.3\nGPU models and configuration:   4 x Voltas\nAny other relevant information:\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\nWhen running :  python -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v\r\nThe test fails with :   RuntimeError: cuda runtime error (7) : too many resources requested for launch at /pytorch/aten/src/ATen/native/cuda/LossCTC.cu:537\r\n\r\nIf I hardcode   threads_batch = 8;   in pytorch/aten/src/ATen/native/cuda/LossCTC.cu  around line 522, the test passes.\r\n\r\n## To Reproduce\r\npython -m unittest -q test_autograd.TestAutograd.test_ctc_loss -v\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nShould pass test.\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): torch (1.0.0a0+b911ca9)\r\n - OS (e.g., Linux):  RH 7.5    ppc64le   P9\r\n - How you installed PyTorch (`conda`, `pip`, source):  source\r\n - Build command you used (if compiling from source):   python setup.py install\r\n - Python version:  3.6\r\n - CUDA/cuDNN version:  10   or  9.2   /   7.1.3\r\n - GPU models and configuration:   4 x Voltas\r\n - Any other relevant information:  \r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}