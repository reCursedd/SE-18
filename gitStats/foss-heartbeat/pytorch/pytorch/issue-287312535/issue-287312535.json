{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4573", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4573/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4573/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4573/events", "html_url": "https://github.com/pytorch/pytorch/issues/4573", "id": 287312535, "node_id": "MDU6SXNzdWUyODczMTI1MzU=", "number": 4573, "title": "Documentation for \"char_rnn_classification_tutorial\" has wrong output cell calculation", "user": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-10T04:33:46Z", "updated_at": "2018-01-10T11:59:41Z", "closed_at": "2018-01-10T11:35:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> Looks like <a href=\"http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\" rel=\"nofollow\">this tutorial</a> has a bug in this code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">RNN</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_size</span>, <span class=\"pl-smi\">hidden_size</span>, <span class=\"pl-smi\">output_size</span>):\n        <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">RNN</span>, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n\n        <span class=\"pl-c1\">self</span>.hidden_size <span class=\"pl-k\">=</span> hidden_size\n\n        <span class=\"pl-c1\">self</span>.i2h <span class=\"pl-k\">=</span> nn.Linear(input_size <span class=\"pl-k\">+</span> hidden_size, hidden_size)\n        <span class=\"pl-c1\">self</span>.i2o <span class=\"pl-k\">=</span> nn.Linear(input_size <span class=\"pl-k\">+</span> hidden_size, output_size)\n        <span class=\"pl-c1\">self</span>.softmax <span class=\"pl-k\">=</span> nn.LogSoftmax(<span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">hidden</span>):\n        combined <span class=\"pl-k\">=</span> torch.cat((<span class=\"pl-c1\">input</span>, hidden), <span class=\"pl-c1\">1</span>)\n        hidden <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2h(combined)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2o(combined)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.softmax(output)\n        <span class=\"pl-k\">return</span> output, hidden\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">initHidden</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> Variable(torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">self</span>.hidden_size))\n\nn_hidden <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>\nrnn <span class=\"pl-k\">=</span> RNN(n_letters, n_hidden, n_categories)</pre></div>\n<p>Looks like the output of the forward pass is done on the input and NOT on the processed data as computed by the RNN cell (ie: self.i2h(combined))</p>\n<p>So, this:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">hidden</span>):\n        combined <span class=\"pl-k\">=</span> torch.cat((<span class=\"pl-c1\">input</span>, hidden), <span class=\"pl-c1\">1</span>)\n        hidden <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2h(combined)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2o(combined)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.softmax(output)\n        <span class=\"pl-k\">return</span> output, hidden</pre></div>\n<p>Should become:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">hidden</span>):\n        combined <span class=\"pl-k\">=</span> torch.cat((<span class=\"pl-c1\">input</span>, hidden), <span class=\"pl-c1\">1</span>)\n        hidden <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2h(combined)\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.i2o(hidden) <span class=\"pl-c\"><span class=\"pl-c\">#</span> this line needs to be changed    </span>\n        output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.softmax(output)\n        <span class=\"pl-k\">return</span> output, hidden</pre></div>\n<p>If you guys agree, I'm happy to make that minor (but frustrating if you don't know what's going on) change to the docs.</p>", "body_text": "@soumith Looks like this tutorial has a bug in this code:\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)\n        output = self.i2o(combined)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return Variable(torch.zeros(1, self.hidden_size))\n\nn_hidden = 128\nrnn = RNN(n_letters, n_hidden, n_categories)\nLooks like the output of the forward pass is done on the input and NOT on the processed data as computed by the RNN cell (ie: self.i2h(combined))\nSo, this:\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)\n        output = self.i2o(combined)\n        output = self.softmax(output)\n        return output, hidden\nShould become:\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)\n        output = self.i2o(hidden) # this line needs to be changed    \n        output = self.softmax(output)\n        return output, hidden\nIf you guys agree, I'm happy to make that minor (but frustrating if you don't know what's going on) change to the docs.", "body": "@soumith Looks like [this tutorial](http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) has a bug in this code:      \r\n\r\n```python   \r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nclass RNN(nn.Module):\r\n    def __init__(self, input_size, hidden_size, output_size):\r\n        super(RNN, self).__init__()\r\n\r\n        self.hidden_size = hidden_size\r\n\r\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\r\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\r\n        self.softmax = nn.LogSoftmax(dim=1)\r\n\r\n    def forward(self, input, hidden):\r\n        combined = torch.cat((input, hidden), 1)\r\n        hidden = self.i2h(combined)\r\n        output = self.i2o(combined)\r\n        output = self.softmax(output)\r\n        return output, hidden\r\n\r\n    def initHidden(self):\r\n        return Variable(torch.zeros(1, self.hidden_size))\r\n\r\nn_hidden = 128\r\nrnn = RNN(n_letters, n_hidden, n_categories)\r\n```    \r\n\r\nLooks like the output of the forward pass is done on the input and NOT on the processed data as computed by the RNN cell (ie: self.i2h(combined))   \r\n\r\nSo, this:    \r\n```python    \r\n    def forward(self, input, hidden):\r\n        combined = torch.cat((input, hidden), 1)\r\n        hidden = self.i2h(combined)\r\n        output = self.i2o(combined)\r\n        output = self.softmax(output)\r\n        return output, hidden\r\n```   \r\nShould become:    \r\n```python    \r\n    def forward(self, input, hidden):\r\n        combined = torch.cat((input, hidden), 1)\r\n        hidden = self.i2h(combined)\r\n        output = self.i2o(hidden) # this line needs to be changed    \r\n        output = self.softmax(output)\r\n        return output, hidden\r\n```\r\n  \r\nIf you guys agree, I'm happy to make that minor (but frustrating if you don't know what's going on) change to the docs.   "}