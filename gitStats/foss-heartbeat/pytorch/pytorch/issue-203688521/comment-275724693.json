{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/275724693", "html_url": "https://github.com/pytorch/pytorch/issues/610#issuecomment-275724693", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/610", "id": 275724693, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTcyNDY5Mw==", "user": {"login": "Kontrakt", "id": 12998284, "node_id": "MDQ6VXNlcjEyOTk4Mjg0", "avatar_url": "https://avatars2.githubusercontent.com/u/12998284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kontrakt", "html_url": "https://github.com/Kontrakt", "followers_url": "https://api.github.com/users/Kontrakt/followers", "following_url": "https://api.github.com/users/Kontrakt/following{/other_user}", "gists_url": "https://api.github.com/users/Kontrakt/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kontrakt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kontrakt/subscriptions", "organizations_url": "https://api.github.com/users/Kontrakt/orgs", "repos_url": "https://api.github.com/users/Kontrakt/repos", "events_url": "https://api.github.com/users/Kontrakt/events{/privacy}", "received_events_url": "https://api.github.com/users/Kontrakt/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-27T17:36:01Z", "updated_at": "2017-01-27T17:36:01Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> You are right, it's not hard to bypass it, but it feels a bit annoying to get such errors.</p>\n<p>In torch <code>gradInput</code> was resized to the input shapes <a href=\"https://github.com/torch/nn/blob/e1efc6345f3dec8b631f91f640c11a4b7dd9e012/CMul.lua#L80\">example</a>. Are there reasons we can't do the same in pytorch?</p>", "body_text": "@fmassa You are right, it's not hard to bypass it, but it feels a bit annoying to get such errors.\nIn torch gradInput was resized to the input shapes example. Are there reasons we can't do the same in pytorch?", "body": "@fmassa You are right, it's not hard to bypass it, but it feels a bit annoying to get such errors.\r\n\r\nIn torch `gradInput` was resized to the input shapes [example](https://github.com/torch/nn/blob/e1efc6345f3dec8b631f91f640c11a4b7dd9e012/CMul.lua#L80). Are there reasons we can't do the same in pytorch?"}