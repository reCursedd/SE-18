{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2734", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2734/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2734/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2734/events", "html_url": "https://github.com/pytorch/pytorch/pull/2734", "id": 257692677, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQxMDU0MTg3", "number": 2734, "title": "remove zero padding in orthogonal initialization", "user": {"login": "alykhantejani", "id": 687194, "node_id": "MDQ6VXNlcjY4NzE5NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/687194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alykhantejani", "html_url": "https://github.com/alykhantejani", "followers_url": "https://api.github.com/users/alykhantejani/followers", "following_url": "https://api.github.com/users/alykhantejani/following{/other_user}", "gists_url": "https://api.github.com/users/alykhantejani/gists{/gist_id}", "starred_url": "https://api.github.com/users/alykhantejani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alykhantejani/subscriptions", "organizations_url": "https://api.github.com/users/alykhantejani/orgs", "repos_url": "https://api.github.com/users/alykhantejani/repos", "events_url": "https://api.github.com/users/alykhantejani/events{/privacy}", "received_events_url": "https://api.github.com/users/alykhantejani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-14T11:56:46Z", "updated_at": "2017-09-15T03:13:54Z", "closed_at": "2017-09-15T03:13:44Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/2734", "html_url": "https://github.com/pytorch/pytorch/pull/2734", "diff_url": "https://github.com/pytorch/pytorch/pull/2734.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/2734.patch"}, "body_html": "<p>PR <a href=\"https://github.com/pytorch/pytorch/pull/1453\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/1453/hovercard\">#1453</a> switched from using svd to qr factorization to get a semi-orthogonal matrix for orthogonal initialization. However, this padded a orthogonal matrix with 0 elements to become the same size as the input tensor. While this is not wrong (rows are still orthonormal), having a lot of weights set to 0 may not be desirable.</p>\n<p>PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"257066050\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2708\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2708/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2708\">#2708</a> wanted to remove this zero padding by transposing the input if <code>rows</code> &lt; <code>cols</code> and then transposing back at the end. In theory this will work, there were just a few errors in the PR causing the tests to fail:</p>\n<ol>\n<li>the transposes were not happening in place so not changing the tensor</li>\n<li>the transpose should be done on the flat representation, in the form presented in the PR it will only work for 2D weigh tensors (for linear layers).</li>\n</ol>\n<p>This PR addresses these two issues and should achieve the affect that <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"257066050\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2708\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2708/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2708\">#2708</a> wants.</p>", "body_text": "PR #1453 switched from using svd to qr factorization to get a semi-orthogonal matrix for orthogonal initialization. However, this padded a orthogonal matrix with 0 elements to become the same size as the input tensor. While this is not wrong (rows are still orthonormal), having a lot of weights set to 0 may not be desirable.\nPR #2708 wanted to remove this zero padding by transposing the input if rows < cols and then transposing back at the end. In theory this will work, there were just a few errors in the PR causing the tests to fail:\n\nthe transposes were not happening in place so not changing the tensor\nthe transpose should be done on the flat representation, in the form presented in the PR it will only work for 2D weigh tensors (for linear layers).\n\nThis PR addresses these two issues and should achieve the affect that #2708 wants.", "body": "PR [#1453](https://github.com/pytorch/pytorch/pull/1453) switched from using svd to qr factorization to get a semi-orthogonal matrix for orthogonal initialization. However, this padded a orthogonal matrix with 0 elements to become the same size as the input tensor. While this is not wrong (rows are still orthonormal), having a lot of weights set to 0 may not be desirable. \r\n\r\nPR #2708 wanted to remove this zero padding by transposing the input if `rows` < `cols` and then transposing back at the end. In theory this will work, there were just a few errors in the PR causing the tests to fail:\r\n1) the transposes were not happening in place so not changing the tensor\r\n2) the transpose should be done on the flat representation, in the form presented in the PR it will only work for 2D weigh tensors (for linear layers).\r\n\r\nThis PR addresses these two issues and should achieve the affect that #2708 wants."}