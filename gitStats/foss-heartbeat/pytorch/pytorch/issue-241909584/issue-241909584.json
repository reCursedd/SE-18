{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2045", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2045/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2045/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2045/events", "html_url": "https://github.com/pytorch/pytorch/issues/2045", "id": 241909584, "node_id": "MDU6SXNzdWUyNDE5MDk1ODQ=", "number": 2045, "title": "shared cuda tensor consumes GPU memory in every process", "user": {"login": "gliese581gg", "id": 15100232, "node_id": "MDQ6VXNlcjE1MTAwMjMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15100232?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gliese581gg", "html_url": "https://github.com/gliese581gg", "followers_url": "https://api.github.com/users/gliese581gg/followers", "following_url": "https://api.github.com/users/gliese581gg/following{/other_user}", "gists_url": "https://api.github.com/users/gliese581gg/gists{/gist_id}", "starred_url": "https://api.github.com/users/gliese581gg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gliese581gg/subscriptions", "organizations_url": "https://api.github.com/users/gliese581gg/orgs", "repos_url": "https://api.github.com/users/gliese581gg/repos", "events_url": "https://api.github.com/users/gliese581gg/events{/privacy}", "received_events_url": "https://api.github.com/users/gliese581gg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 553773019, "node_id": "MDU6TGFiZWw1NTM3NzMwMTk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs-reproduction", "name": "needs-reproduction", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-07-11T02:54:50Z", "updated_at": "2017-07-13T06:41:31Z", "closed_at": "2017-07-13T06:29:52Z", "author_association": "NONE", "body_html": "<p>when I ran follwing code,</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.multiprocessing <span class=\"pl-k\">as</span> mp\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">worker</span>(<span class=\"pl-smi\">tensor</span>):\n\t<span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span> :\n\t\ttensor <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">0.01</span>\n\t\ttime.sleep(<span class=\"pl-c1\">1</span>)\n\t\t\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\t\n\tmp.set_start_method(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>forkserver<span class=\"pl-pds\">'</span></span>)\t\t\n\ttt <span class=\"pl-k\">=</span> np.ones((<span class=\"pl-c1\">100</span>,<span class=\"pl-c1\">100</span>,<span class=\"pl-c1\">100</span>))\n\n\tt <span class=\"pl-k\">=</span> torch.from_numpy(tt)\n\tt<span class=\"pl-k\">=</span>t.share_memory_() <span class=\"pl-c\"><span class=\"pl-c\">#</span>share 1</span>\n\tt <span class=\"pl-k\">=</span> t.cuda(<span class=\"pl-k\">async</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\t<span class=\"pl-c\"><span class=\"pl-c\">#</span>t=t.share_memory_() #share 2. did not work.</span>\n\n\tprocesses <span class=\"pl-k\">=</span> []\n\t<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n\t\tp <span class=\"pl-k\">=</span> mp.Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>worker , <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(   t   ,) )\n\t\tp.daemon<span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\t\n\t\tp.start()\n\t\tprocesses.append(p)\n\t\t\n\t<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>running<span class=\"pl-pds\">'</span></span>)\n\ttime.sleep(<span class=\"pl-c1\">10</span>)\n\t<span class=\"pl-c1\">print</span> (t)\n\t\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n\tmain()\n</pre></div>\n<p>all processes consumed a lot of GPU memories as if each process had copied version of cuda tensor.</p>\n<p>(data is shared as I expected.)</p>\n<p>It does not happens when I use cpu tensors.</p>\n<p>How can I share cuda tensors without consuming additional GPU memory?</p>", "body_text": "when I ran follwing code,\nimport torch.multiprocessing as mp\nfrom torch.autograd import Variable\nimport torch\nimport numpy as np\nimport time\n\ndef worker(tensor):\n\twhile True :\n\t\ttensor += 0.01\n\t\ttime.sleep(1)\n\t\t\ndef main():\t\n\tmp.set_start_method('forkserver')\t\t\n\ttt = np.ones((100,100,100))\n\n\tt = torch.from_numpy(tt)\n\tt=t.share_memory_() #share 1\n\tt = t.cuda(async=True)\n\t#t=t.share_memory_() #share 2. did not work.\n\n\tprocesses = []\n\tfor i in range(10):\n\t\tp = mp.Process(target=worker , args=(   t   ,) )\n\t\tp.daemon=True\t\n\t\tp.start()\n\t\tprocesses.append(p)\n\t\t\n\tprint('running')\n\ttime.sleep(10)\n\tprint (t)\n\t\nif __name__ == '__main__':\n\tmain()\n\nall processes consumed a lot of GPU memories as if each process had copied version of cuda tensor.\n(data is shared as I expected.)\nIt does not happens when I use cpu tensors.\nHow can I share cuda tensors without consuming additional GPU memory?", "body": "when I ran follwing code,\r\n\r\n\r\n```python\r\nimport torch.multiprocessing as mp\r\nfrom torch.autograd import Variable\r\nimport torch\r\nimport numpy as np\r\nimport time\r\n\r\ndef worker(tensor):\r\n\twhile True :\r\n\t\ttensor += 0.01\r\n\t\ttime.sleep(1)\r\n\t\t\r\ndef main():\t\r\n\tmp.set_start_method('forkserver')\t\t\r\n\ttt = np.ones((100,100,100))\r\n\r\n\tt = torch.from_numpy(tt)\r\n\tt=t.share_memory_() #share 1\r\n\tt = t.cuda(async=True)\r\n\t#t=t.share_memory_() #share 2. did not work.\r\n\r\n\tprocesses = []\r\n\tfor i in range(10):\r\n\t\tp = mp.Process(target=worker , args=(   t   ,) )\r\n\t\tp.daemon=True\t\r\n\t\tp.start()\r\n\t\tprocesses.append(p)\r\n\t\t\r\n\tprint('running')\r\n\ttime.sleep(10)\r\n\tprint (t)\r\n\t\r\nif __name__ == '__main__':\r\n\tmain()\r\n\r\n```\r\n\r\nall processes consumed a lot of GPU memories as if each process had copied version of cuda tensor.\r\n\r\n(data is shared as I expected.)\r\n\r\nIt does not happens when I use cpu tensors.\r\n\r\nHow can I share cuda tensors without consuming additional GPU memory?"}