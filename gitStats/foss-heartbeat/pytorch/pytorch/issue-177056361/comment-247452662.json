{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/247452662", "html_url": "https://github.com/pytorch/pytorch/issues/29#issuecomment-247452662", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/29", "id": 247452662, "node_id": "MDEyOklzc3VlQ29tbWVudDI0NzQ1MjY2Mg==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-15T20:54:49Z", "updated_at": "2016-09-15T20:54:49Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5702157\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/adamlerer\">@adamlerer</a>, you're thinking about modules defining the structure of you're network which is a torch/nn notion that is much less prevalent in the Chainer style networks. For example, other than ChainList (Sequential), I don't know of any concrete modules in Chainer that take in arbitrary modules in their constructor. If you go through the Chainer examples, they don't use ChainList (nn.Sequential) at all.</p>\n<p>One reason is that if every operation within a Sequential has to be reflected as a Module. I find this often makes code harder to understand. For example, in vision networks there's typically a <code>view()</code> right before the FC-layer. As a module, this is really annoying; everyone get's it wrong -- they forget the <code>setNumInputDims</code> call, and you have to know the exact size (the number of features) you want to view. As a function call, it's much simpler: <code>x = x.view(x.size(0), -1)</code>, but you can't stick that in a nn.Sequential.</p>\n<p>Composability in general is nice, but module occurring multiple times <em>breaks</em> composability of some basic operations. For example, we saw this with <code>getParameter()</code> in Torch. In pseudo-code, <code>getParameters(a+b) != getParameters(a) + getParameters(b)</code>. Same with any other operation that acts on modules or weights/biases.</p>\n<p>Functions offer a better way to compose operations than modules:</p>\n<pre><code>def call_twice(M, x):\n   return M(M(x))\n\ncall_twice(linear, input)\n</code></pre>", "body_text": "@adamlerer, you're thinking about modules defining the structure of you're network which is a torch/nn notion that is much less prevalent in the Chainer style networks. For example, other than ChainList (Sequential), I don't know of any concrete modules in Chainer that take in arbitrary modules in their constructor. If you go through the Chainer examples, they don't use ChainList (nn.Sequential) at all.\nOne reason is that if every operation within a Sequential has to be reflected as a Module. I find this often makes code harder to understand. For example, in vision networks there's typically a view() right before the FC-layer. As a module, this is really annoying; everyone get's it wrong -- they forget the setNumInputDims call, and you have to know the exact size (the number of features) you want to view. As a function call, it's much simpler: x = x.view(x.size(0), -1), but you can't stick that in a nn.Sequential.\nComposability in general is nice, but module occurring multiple times breaks composability of some basic operations. For example, we saw this with getParameter() in Torch. In pseudo-code, getParameters(a+b) != getParameters(a) + getParameters(b). Same with any other operation that acts on modules or weights/biases.\nFunctions offer a better way to compose operations than modules:\ndef call_twice(M, x):\n   return M(M(x))\n\ncall_twice(linear, input)", "body": "@adamlerer, you're thinking about modules defining the structure of you're network which is a torch/nn notion that is much less prevalent in the Chainer style networks. For example, other than ChainList (Sequential), I don't know of any concrete modules in Chainer that take in arbitrary modules in their constructor. If you go through the Chainer examples, they don't use ChainList (nn.Sequential) at all.\n\nOne reason is that if every operation within a Sequential has to be reflected as a Module. I find this often makes code harder to understand. For example, in vision networks there's typically a `view()` right before the FC-layer. As a module, this is really annoying; everyone get's it wrong -- they forget the `setNumInputDims` call, and you have to know the exact size (the number of features) you want to view. As a function call, it's much simpler: `x = x.view(x.size(0), -1)`, but you can't stick that in a nn.Sequential.\n\nComposability in general is nice, but module occurring multiple times _breaks_ composability of some basic operations. For example, we saw this with `getParameter()` in Torch. In pseudo-code, `getParameters(a+b) != getParameters(a) + getParameters(b)`. Same with any other operation that acts on modules or weights/biases.\n\nFunctions offer a better way to compose operations than modules:\n\n```\ndef call_twice(M, x):\n   return M(M(x))\n\ncall_twice(linear, input)\n```\n"}