{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7535", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7535/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7535/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7535/events", "html_url": "https://github.com/pytorch/pytorch/issues/7535", "id": 322592424, "node_id": "MDU6SXNzdWUzMjI1OTI0MjQ=", "number": 7535, "title": "[feature request] Global GPU Flag", "user": {"login": "svaisakh", "id": 22019235, "node_id": "MDQ6VXNlcjIyMDE5MjM1", "avatar_url": "https://avatars1.githubusercontent.com/u/22019235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/svaisakh", "html_url": "https://github.com/svaisakh", "followers_url": "https://api.github.com/users/svaisakh/followers", "following_url": "https://api.github.com/users/svaisakh/following{/other_user}", "gists_url": "https://api.github.com/users/svaisakh/gists{/gist_id}", "starred_url": "https://api.github.com/users/svaisakh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/svaisakh/subscriptions", "organizations_url": "https://api.github.com/users/svaisakh/orgs", "repos_url": "https://api.github.com/users/svaisakh/repos", "events_url": "https://api.github.com/users/svaisakh/events{/privacy}", "received_events_url": "https://api.github.com/users/svaisakh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-13T13:07:06Z", "updated_at": "2018-09-14T14:29:28Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>The <a href=\"https://pytorch.org/2018/04/22/0_4_0-migration-guide.html\" rel=\"nofollow\">PyTorch 0.4 Migration Guide</a>, simplifies writing device-agnostic code as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> at beginning of the script</span>\ndevice <span class=\"pl-k\">=</span> torch.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cuda:0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">if</span> torch.cuda.is_available() <span class=\"pl-k\">else</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cpu<span class=\"pl-pds\">\"</span></span>)\n\n<span class=\"pl-c1\">...</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> then whenever you get a new Tensor or Module</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> this won't copy if they are already on the desired device</span>\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> data.to(device)\nmodel <span class=\"pl-k\">=</span> MyModule(<span class=\"pl-c1\">...</span>).to(device)</pre></div>\n<p>However, this is still not clean.</p>\n<p>Ideally, we would like PyTorch to move everything over to the GPU, if it's available...<br>\nmuch like TensorFlow.</p>\n<p>I tried setting the global tensor type to a cuda tensor using the <code>torch.set_default_tensor_type()</code> method.</p>\n<p>However, there are some fundamental problems with setting the default tensor type.</p>\n<ul>\n<li>\n<p>Dataloaders give normal (non-cuda) tensors by default. They have to be manually cast using the <code>Tensor.to()</code> method.</p>\n</li>\n<li>\n<p>Many methods are simply not implemented for <code>torch.cuda.*Tensor</code>. Thus, setting the global tensor type to cuda fails.</p>\n</li>\n<li>\n<p>Conversions to numpy using the <code>numpy()</code> method aren\u2019t available for cuda tensors. One has to go <code>x.cpu().numpy()</code>.<br>\nAlthough this chain is agnostic, it defeats the purpose.</p>\n</li>\n</ul>\n<hr>\n<p>I find that I use methods like <code>.to(device)</code> and <code>.cpu()</code> far too often in my projects.</p>\n<p>In my view, <em>it makes the code more verbose than it needs to be</em> and makes it just a little harder to read.</p>\n<p><strong>I think that there is room for a global <code>use_gpu</code> flag that can enable developers to run the entire subsequent code in the GPU, where required.</strong></p>\n<p>Specifically, my request is the following:</p>\n<h4>1. Abolish need for the <code>.to(device)</code> suffix:</h4>\n<p>Circumvent it by letting the developer set the device using a global method like <code>torch.set_default_device()</code> or a convinience method/flag like <code>use_gpu</code></p>\n<p>Then, whenever, an error is encountered because a CUDA tensor is expected in place of a regular tensor or vice-versa, automatically cast the tensor to the expected device.</p>\n<p>Additionally,<br>\na. Move <code>nn.Module</code> automatically to the default device.<br>\nb. Move the yield of <code>DataLoader</code>s to the default device.</p>\n<p>Prevent the need to manually cast to the default device.</p>\n<h4>2. Add the numpy() method to cuda tensors:</h4>\n<p>The existing way is to move the tensor to cpu first.<br>\nThus, we have <code>x.cpu().numpy()</code>, which is agnostic but redundant.</p>\n<h4>3. Use GPU by default if available:</h4>\n<p>PyTorch is built from the ground up with the Deep Learning community in mind.</p>\n<p>With most Deep Learning done on GPUs, they be considered as the default device automatically.</p>\n<p><em>Let PyTorch give first preference to the GPU.</em></p>", "body_text": "The PyTorch 0.4 Migration Guide, simplifies writing device-agnostic code as follows:\n# at beginning of the script\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n...\n\n# then whenever you get a new Tensor or Module\n# this won't copy if they are already on the desired device\ninput = data.to(device)\nmodel = MyModule(...).to(device)\nHowever, this is still not clean.\nIdeally, we would like PyTorch to move everything over to the GPU, if it's available...\nmuch like TensorFlow.\nI tried setting the global tensor type to a cuda tensor using the torch.set_default_tensor_type() method.\nHowever, there are some fundamental problems with setting the default tensor type.\n\n\nDataloaders give normal (non-cuda) tensors by default. They have to be manually cast using the Tensor.to() method.\n\n\nMany methods are simply not implemented for torch.cuda.*Tensor. Thus, setting the global tensor type to cuda fails.\n\n\nConversions to numpy using the numpy() method aren\u2019t available for cuda tensors. One has to go x.cpu().numpy().\nAlthough this chain is agnostic, it defeats the purpose.\n\n\n\nI find that I use methods like .to(device) and .cpu() far too often in my projects.\nIn my view, it makes the code more verbose than it needs to be and makes it just a little harder to read.\nI think that there is room for a global use_gpu flag that can enable developers to run the entire subsequent code in the GPU, where required.\nSpecifically, my request is the following:\n1. Abolish need for the .to(device) suffix:\nCircumvent it by letting the developer set the device using a global method like torch.set_default_device() or a convinience method/flag like use_gpu\nThen, whenever, an error is encountered because a CUDA tensor is expected in place of a regular tensor or vice-versa, automatically cast the tensor to the expected device.\nAdditionally,\na. Move nn.Module automatically to the default device.\nb. Move the yield of DataLoaders to the default device.\nPrevent the need to manually cast to the default device.\n2. Add the numpy() method to cuda tensors:\nThe existing way is to move the tensor to cpu first.\nThus, we have x.cpu().numpy(), which is agnostic but redundant.\n3. Use GPU by default if available:\nPyTorch is built from the ground up with the Deep Learning community in mind.\nWith most Deep Learning done on GPUs, they be considered as the default device automatically.\nLet PyTorch give first preference to the GPU.", "body": "The [PyTorch 0.4 Migration Guide](https://pytorch.org/2018/04/22/0_4_0-migration-guide.html), simplifies writing device-agnostic code as follows:\r\n\r\n```python\r\n# at beginning of the script\r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n\r\n...\r\n\r\n# then whenever you get a new Tensor or Module\r\n# this won't copy if they are already on the desired device\r\ninput = data.to(device)\r\nmodel = MyModule(...).to(device)\r\n```\r\n\r\nHowever, this is still not clean.\r\n\r\nIdeally, we would like PyTorch to move everything over to the GPU, if it's available...\r\nmuch like TensorFlow.\r\n\r\nI tried setting the global tensor type to a cuda tensor using the ```torch.set_default_tensor_type()``` method.\r\n\r\nHowever, there are some fundamental problems with setting the default tensor type.\r\n\r\n* Dataloaders give normal (non-cuda) tensors by default. They have to be manually cast using the `Tensor.to()` method.\r\n\r\n* Many methods are simply not implemented for `torch.cuda.*Tensor`. Thus, setting the global tensor type to cuda fails.\r\n\r\n* Conversions to numpy using the `numpy()` method aren\u2019t available for cuda tensors. One has to go `x.cpu().numpy()`.\r\nAlthough this chain is agnostic, it defeats the purpose.\r\n\r\n<hr>\r\n\r\nI find that I use methods like `.to(device)` and `.cpu()` far too often in my projects.\r\n\r\nIn my view, _it makes the code more verbose than it needs to be_ and makes it just a little harder to read.\r\n\r\n**I think that there is room for a global `use_gpu` flag that can enable developers to run the entire subsequent code in the GPU, where required.**\r\n\r\nSpecifically, my request is the following:\r\n\r\n#### 1. Abolish need for the `.to(device)` suffix:\r\nCircumvent it by letting the developer set the device using a global method like `torch.set_default_device()` or a convinience method/flag like `use_gpu`\r\n\r\nThen, whenever, an error is encountered because a CUDA tensor is expected in place of a regular tensor or vice-versa, automatically cast the tensor to the expected device.\r\n\r\nAdditionally,\r\na. Move `nn.Module` automatically to the default device.\r\nb. Move the yield of `DataLoader`s to the default device.\r\n\r\nPrevent the need to manually cast to the default device.\r\n\r\n#### 2. Add the numpy() method to cuda tensors:\r\nThe existing way is to move the tensor to cpu first.\r\nThus, we have `x.cpu().numpy()`, which is agnostic but redundant.\r\n\r\n#### 3. Use GPU by default if available:\r\nPyTorch is built from the ground up with the Deep Learning community in mind.\r\n\r\nWith most Deep Learning done on GPUs, they be considered as the default device automatically.\r\n\r\n_Let PyTorch give first preference to the GPU._"}