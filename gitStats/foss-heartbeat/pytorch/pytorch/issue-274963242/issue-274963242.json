{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3761", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3761/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3761/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3761/events", "html_url": "https://github.com/pytorch/pytorch/issues/3761", "id": 274963242, "node_id": "MDU6SXNzdWUyNzQ5NjMyNDI=", "number": 3761, "title": "Issue with DataParallel", "user": {"login": "mmoghimi", "id": 419486, "node_id": "MDQ6VXNlcjQxOTQ4Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/419486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmoghimi", "html_url": "https://github.com/mmoghimi", "followers_url": "https://api.github.com/users/mmoghimi/followers", "following_url": "https://api.github.com/users/mmoghimi/following{/other_user}", "gists_url": "https://api.github.com/users/mmoghimi/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmoghimi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmoghimi/subscriptions", "organizations_url": "https://api.github.com/users/mmoghimi/orgs", "repos_url": "https://api.github.com/users/mmoghimi/repos", "events_url": "https://api.github.com/users/mmoghimi/events{/privacy}", "received_events_url": "https://api.github.com/users/mmoghimi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-17T18:58:28Z", "updated_at": "2017-12-01T22:31:07Z", "closed_at": "2017-12-01T22:06:54Z", "author_association": "NONE", "body_html": "<p>I'm getting an assertion error for the following code. The code work without the DataParallel.</p>\n<pre><code>class MyCustomNet(torch.nn.Module):\n  def __init__(self):\n    super(MyCustomNet, self).__init__()\n    self.lin = torch.nn.Linear(10, 1)\n    self.feature_to_select = torch.nn.Parameter(torch.LongTensor(np.random.randint(0, 10, (1,))), requires_grad=False)\n  def forward(self, x):\n    return x.index_select(1, self.feature_to_select) + self.lin(x)\n\nnet = MyCustomNet()\nnet.eval()\nnet.cuda()\ndata = torch.autograd.Variable(torch.FloatTensor(np.random.random((10, 10))), volatile=True).cuda()\n\nnet = torch.nn.DataParallel(net)\nout = net(data)\n</code></pre>\n<p>and this is the error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"reproduce_bug.py\", line 51, in &lt;module&gt;\n    out = net(data)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 224, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 70, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 67, in parallel_apply\n    raise output\nAssertionError\n</code></pre>", "body_text": "I'm getting an assertion error for the following code. The code work without the DataParallel.\nclass MyCustomNet(torch.nn.Module):\n  def __init__(self):\n    super(MyCustomNet, self).__init__()\n    self.lin = torch.nn.Linear(10, 1)\n    self.feature_to_select = torch.nn.Parameter(torch.LongTensor(np.random.randint(0, 10, (1,))), requires_grad=False)\n  def forward(self, x):\n    return x.index_select(1, self.feature_to_select) + self.lin(x)\n\nnet = MyCustomNet()\nnet.eval()\nnet.cuda()\ndata = torch.autograd.Variable(torch.FloatTensor(np.random.random((10, 10))), volatile=True).cuda()\n\nnet = torch.nn.DataParallel(net)\nout = net(data)\n\nand this is the error:\nTraceback (most recent call last):\n  File \"reproduce_bug.py\", line 51, in <module>\n    out = net(data)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 224, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 70, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 67, in parallel_apply\n    raise output\nAssertionError", "body": "I'm getting an assertion error for the following code. The code work without the DataParallel.\r\n\r\n```\r\nclass MyCustomNet(torch.nn.Module):\r\n  def __init__(self):\r\n    super(MyCustomNet, self).__init__()\r\n    self.lin = torch.nn.Linear(10, 1)\r\n    self.feature_to_select = torch.nn.Parameter(torch.LongTensor(np.random.randint(0, 10, (1,))), requires_grad=False)\r\n  def forward(self, x):\r\n    return x.index_select(1, self.feature_to_select) + self.lin(x)\r\n\r\nnet = MyCustomNet()\r\nnet.eval()\r\nnet.cuda()\r\ndata = torch.autograd.Variable(torch.FloatTensor(np.random.random((10, 10))), volatile=True).cuda()\r\n\r\nnet = torch.nn.DataParallel(net)\r\nout = net(data)\r\n```\r\nand this is the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"reproduce_bug.py\", line 51, in <module>\r\n    out = net(data)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 224, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 60, in forward\r\n    outputs = self.parallel_apply(replicas, inputs, kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 70, in parallel_apply\r\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 67, in parallel_apply\r\n    raise output\r\nAssertionError\r\n```"}