{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203657032", "pull_request_review_id": 138587979, "id": 203657032, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzY1NzAzMg==", "diff_hunk": "@@ -105,53 +103,63 @@ class IDeepFeeder : public BlobFeederBase {\n       return itensor::data_type::data_undef;\n   }\n \n- public:\n-   void FeedTensor(\n-       const DeviceOption& option,\n-       PyArrayObject *original_array,\n-       itensor *tensor) {\n-     PyArrayObject *array = PyArray_GETCONTIGUOUS(original_array);\n-     auto g = MakeGuard([&]() {Py_XDECREF(array); });\n-\n-     const auto npy_type = PyArray_TYPE(array);\n-     const TypeMeta& meta = NumpyTypeToCaffe(npy_type);\n-     CAFFE_ENFORCE(\n-        meta.id() != CaffeTypeId::uninitialized(),\n-        \"This numpy data type is not supported: \",\n-        PyArray_TYPE(array),\n-        \".\");\n-\n-     int ndim = PyArray_NDIM(array);\n-     npy_intp* npy_dims = PyArray_DIMS(array);\n-\n-     itensor::dims adims;\n-     for (int i = 0; i < ndim; i++) {\n-       adims.push_back(static_cast<itensor::dims::value_type>(\n-             npy_dims[i]));\n-     }\n-\n-     switch (npy_type) {\n-      case NPY_OBJECT:\n-      case NPY_UNICODE:\n-        CAFFE_THROW(\"IDeep doesn't support string\");\n-        break;\n-      default:\n-        auto type = type_transform(meta);\n+public:\n+  void FeedTensor(const DeviceOption &option, PyArrayObject *original_array,\n+                  itensor *tensor) {\n+    PyArrayObject *array = PyArray_GETCONTIGUOUS(original_array);\n+    auto g = MakeGuard([&]() { Py_XDECREF(array); });\n+    const auto npy_type = PyArray_TYPE(array);\n+    const TypeMeta &meta = NumpyTypeToCaffe(npy_type);\n+    CAFFE_ENFORCE(meta.id() != CaffeTypeId::uninitialized(),\n+                  \"This numpy data type is not supported: \",\n+                  PyArray_TYPE(array), \".\");\n+\n+    int ndim = PyArray_NDIM(array);\n+    npy_intp *npy_dims = PyArray_DIMS(array);\n+\n+    itensor::dims adims;\n+    for (int i = 0; i < ndim; i++) {\n+      adims.push_back(static_cast<itensor::dims::value_type>(npy_dims[i]));\n+    }\n+\n+    switch (npy_type) {\n+    case NPY_OBJECT:\n+    case NPY_UNICODE:\n+      CAFFE_THROW(\"IDeep doesn't support string\");\n+      break;\n+    default:\n+      auto type = type_transform(meta);\n+      if (tensor->get_dims() != adims || type != tensor->get_data_type()) {\n         tensor->resize(adims, type);\n-        tensor->reorder_from(adims, type,\n-            static_cast<void *>(PyArray_DATA(array)));\n-     }\n-   }\n-\n-   void Feed(const DeviceOption& option, PyArrayObject* original_array,\n-       Blob* blob) {\n-      try {\n+      }\n+      tensor->reorder_from(adims, type,\n+                           static_cast<void *>(PyArray_DATA(array)));\n+    }\n+  }\n+\n+  void Feed(const DeviceOption &option, PyArrayObject *original_array,\n+            Blob *blob) {\n+    try {\n+      PyArrayObject *array = PyArray_GETCONTIGUOUS(original_array);\n+      auto g = MakeGuard([&]() { Py_XDECREF(array); });\n+\n+      const auto npy_type = PyArray_TYPE(array);\n+      const TypeMeta &meta = NumpyTypeToCaffe(npy_type);\n+      // TODO: if necessary, use dispatcher.\n+      if (meta.Match<float>()) {\n         FeedTensor(option, original_array, blob->GetMutable<itensor>());\n-      } catch (ideep::error& e) {\n-        VLOG(1) << \"IDEEP error: \" << e.message;\n-        throw;\n+      } else {\n+        DeviceOption cpu_option(option);\n+        cpu_option.set_device_type(DeviceType::CPU);\n+        TensorFeeder<CPUContext> cpu_tensor_feeder;\n+        cpu_tensor_feeder.FeedTensor(cpu_option, original_array,\n+                                     blob->GetMutable<TensorCPU>());\n       }\n-   }\n+    } catch (ideep::error &e) {\n+      VLOG(1) << \"IDEEP error: \" << e.message;", "path": "caffe2/python/pybind_state_ideep.cc", "position": null, "original_position": 203, "commit_id": "cc98b46560711afe7c8c01068da0592966398bee", "original_commit_id": "2c0f6a2993e50c1e14ba652885e9a9b8a9221c01", "user": {"login": "gujinghui", "id": 31264804, "node_id": "MDQ6VXNlcjMxMjY0ODA0", "avatar_url": "https://avatars2.githubusercontent.com/u/31264804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gujinghui", "html_url": "https://github.com/gujinghui", "followers_url": "https://api.github.com/users/gujinghui/followers", "following_url": "https://api.github.com/users/gujinghui/following{/other_user}", "gists_url": "https://api.github.com/users/gujinghui/gists{/gist_id}", "starred_url": "https://api.github.com/users/gujinghui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gujinghui/subscriptions", "organizations_url": "https://api.github.com/users/gujinghui/orgs", "repos_url": "https://api.github.com/users/gujinghui/repos", "events_url": "https://api.github.com/users/gujinghui/events{/privacy}", "received_events_url": "https://api.github.com/users/gujinghui/received_events", "type": "User", "site_admin": false}, "body": "Fixed", "created_at": "2018-07-19T09:21:26Z", "updated_at": "2018-11-23T15:47:41Z", "html_url": "https://github.com/pytorch/pytorch/pull/9164#discussion_r203657032", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9164", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203657032"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9164#discussion_r203657032"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9164"}}, "body_html": "<p>Fixed</p>", "body_text": "Fixed", "in_reply_to_id": 203490300}