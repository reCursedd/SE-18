{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10176", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10176/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10176/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10176/events", "html_url": "https://github.com/pytorch/pytorch/issues/10176", "id": 347149537, "node_id": "MDU6SXNzdWUzNDcxNDk1Mzc=", "number": 10176, "title": "[Caffe2] Modelling using Ops instead of Helper Functions", "user": {"login": "CarlosYeverino", "id": 25825048, "node_id": "MDQ6VXNlcjI1ODI1MDQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/25825048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CarlosYeverino", "html_url": "https://github.com/CarlosYeverino", "followers_url": "https://api.github.com/users/CarlosYeverino/followers", "following_url": "https://api.github.com/users/CarlosYeverino/following{/other_user}", "gists_url": "https://api.github.com/users/CarlosYeverino/gists{/gist_id}", "starred_url": "https://api.github.com/users/CarlosYeverino/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CarlosYeverino/subscriptions", "organizations_url": "https://api.github.com/users/CarlosYeverino/orgs", "repos_url": "https://api.github.com/users/CarlosYeverino/repos", "events_url": "https://api.github.com/users/CarlosYeverino/events{/privacy}", "received_events_url": "https://api.github.com/users/CarlosYeverino/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-08-02T19:46:49Z", "updated_at": "2018-08-06T17:35:30Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi all,</p>\n<p>how could I do the LeNet model using only Ops instead of helper functiones like below?</p>\n<pre><code>from caffe2.python import model_helper, brew\nm= model_helper.ModelHelper(name=\"train_net\")\n\n#LeNet model\n        conv1 = brew.conv(m, 'data', 'conv1', dim_in=1, dim_out=20, kernel=5)\n        pool1 = brew.max_pool(m, conv1, 'pool1', kernel=2, stride=2)\n        conv2 = brew.conv(m, pool1, 'conv2', dim_in=20, dim_out=50, kernel=5)\n        pool2 = brew.max_pool(m, conv2, 'pool2', kernel=2, stride=2)\n        fc3 = brew.fc(m, pool2, 'fc3', dim_in=50 * 4 * 4, dim_out=500)\n        relu = brew.relu(m, fc3, fc3)\n        pred = brew.fc(m, relu, 'pred', 500, 10)\n        softmax = brew.softmax(m, pred, 'softmax')\n</code></pre>\n<p>From the Ops catalogue, I know that the corresponding fc layer and pred are:</p>\n<pre><code>from caffe2.python import model_helper\nm = model_helper.ModelHelper(name=\"train_net\")\n\nweight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\nbias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])\n\n#LeNet model\n        #conv1 = m.net.Conv\n        #pool1 = m.net.MaxPool\n        #conv2 = m.net.Conv\n        #pool2 = m.net.MaxPool\n        fc3 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc3\")\n        #relu = m.net.Relu\n        pred = m.net.Relu(relu, \"pred\")\n        #softmax = m.net.Softmax\n</code></pre>\n<p>How should I set the <strong>ConvPoolOpBase</strong> operator (mentioned in the catalogue) which provides the stride and kernel size, or the pads\u2019 sizes in each direction for Conv and MaxPool layers?<br>\n<a href=\"https://caffe2.ai/docs/operators-catalogue.html#conv\" rel=\"nofollow\">https://caffe2.ai/docs/operators-catalogue.html#conv</a></p>", "body_text": "Hi all,\nhow could I do the LeNet model using only Ops instead of helper functiones like below?\nfrom caffe2.python import model_helper, brew\nm= model_helper.ModelHelper(name=\"train_net\")\n\n#LeNet model\n        conv1 = brew.conv(m, 'data', 'conv1', dim_in=1, dim_out=20, kernel=5)\n        pool1 = brew.max_pool(m, conv1, 'pool1', kernel=2, stride=2)\n        conv2 = brew.conv(m, pool1, 'conv2', dim_in=20, dim_out=50, kernel=5)\n        pool2 = brew.max_pool(m, conv2, 'pool2', kernel=2, stride=2)\n        fc3 = brew.fc(m, pool2, 'fc3', dim_in=50 * 4 * 4, dim_out=500)\n        relu = brew.relu(m, fc3, fc3)\n        pred = brew.fc(m, relu, 'pred', 500, 10)\n        softmax = brew.softmax(m, pred, 'softmax')\n\nFrom the Ops catalogue, I know that the corresponding fc layer and pred are:\nfrom caffe2.python import model_helper\nm = model_helper.ModelHelper(name=\"train_net\")\n\nweight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\nbias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])\n\n#LeNet model\n        #conv1 = m.net.Conv\n        #pool1 = m.net.MaxPool\n        #conv2 = m.net.Conv\n        #pool2 = m.net.MaxPool\n        fc3 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc3\")\n        #relu = m.net.Relu\n        pred = m.net.Relu(relu, \"pred\")\n        #softmax = m.net.Softmax\n\nHow should I set the ConvPoolOpBase operator (mentioned in the catalogue) which provides the stride and kernel size, or the pads\u2019 sizes in each direction for Conv and MaxPool layers?\nhttps://caffe2.ai/docs/operators-catalogue.html#conv", "body": "Hi all,\r\n\r\nhow could I do the LeNet model using only Ops instead of helper functiones like below?\r\n\r\n```\r\nfrom caffe2.python import model_helper, brew\r\nm= model_helper.ModelHelper(name=\"train_net\")\r\n\r\n#LeNet model\r\n        conv1 = brew.conv(m, 'data', 'conv1', dim_in=1, dim_out=20, kernel=5)\r\n        pool1 = brew.max_pool(m, conv1, 'pool1', kernel=2, stride=2)\r\n        conv2 = brew.conv(m, pool1, 'conv2', dim_in=20, dim_out=50, kernel=5)\r\n        pool2 = brew.max_pool(m, conv2, 'pool2', kernel=2, stride=2)\r\n        fc3 = brew.fc(m, pool2, 'fc3', dim_in=50 * 4 * 4, dim_out=500)\r\n        relu = brew.relu(m, fc3, fc3)\r\n        pred = brew.fc(m, relu, 'pred', 500, 10)\r\n        softmax = brew.softmax(m, pred, 'softmax')\r\n```\r\n\r\nFrom the Ops catalogue, I know that the corresponding fc layer and pred are:\r\n```\r\nfrom caffe2.python import model_helper\r\nm = model_helper.ModelHelper(name=\"train_net\")\r\n\r\nweight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\r\nbias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])\r\n\r\n#LeNet model\r\n        #conv1 = m.net.Conv\r\n        #pool1 = m.net.MaxPool\r\n        #conv2 = m.net.Conv\r\n        #pool2 = m.net.MaxPool\r\n        fc3 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc3\")\r\n        #relu = m.net.Relu\r\n        pred = m.net.Relu(relu, \"pred\")\r\n        #softmax = m.net.Softmax\r\n```\r\n\r\nHow should I set the **ConvPoolOpBase** operator (mentioned in the catalogue) which provides the stride and kernel size, or the pads\u2019 sizes in each direction for Conv and MaxPool layers?\r\nhttps://caffe2.ai/docs/operators-catalogue.html#conv"}