{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/369191167", "html_url": "https://github.com/pytorch/pytorch/issues/5285#issuecomment-369191167", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5285", "id": 369191167, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTE5MTE2Nw==", "user": {"login": "EKami", "id": 4030626, "node_id": "MDQ6VXNlcjQwMzA2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/4030626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EKami", "html_url": "https://github.com/EKami", "followers_url": "https://api.github.com/users/EKami/followers", "following_url": "https://api.github.com/users/EKami/following{/other_user}", "gists_url": "https://api.github.com/users/EKami/gists{/gist_id}", "starred_url": "https://api.github.com/users/EKami/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EKami/subscriptions", "organizations_url": "https://api.github.com/users/EKami/orgs", "repos_url": "https://api.github.com/users/EKami/repos", "events_url": "https://api.github.com/users/EKami/events{/privacy}", "received_events_url": "https://api.github.com/users/EKami/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-28T10:10:37Z", "updated_at": "2018-02-28T10:10:37Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> Ok so I ran a little benchmark on both the GPU and the CPU of the following script:</p>\n<pre><code>import signal\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nmodel = nn.Conv2d(64, 3, kernel_size=9, padding=4).cuda() # cuda removed for CPU\nx = Variable(torch.randn([16, 64, 224, 224])).cuda() # cuda removed for CPU\nmodel(x)\nprint(\"Done\")\nsignal.pause()\n</code></pre>\n<p>Here are the results:<br>\nOn GPU:</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1403      G   /usr/lib/xorg/Xorg                            90MiB |\n|    0      7061      C   python                                      1341MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>On CPU:</p>\n<pre><code>$ps -eo size,pid,user,command --sort -size | awk '{ hr=$1/1024 ; printf(\"%13.2f Mb \",hr) } { for ( x=4 ; x&lt;=NF ; x++ ) { printf(\"%s \",$x) } print \"\" }' |cut -d \"\" -f2 | cut -d \"-\" -f1 &gt; output\n\n         0.00 Mb COMMAND\n     16607.09 Mb python test.py\n      1172.36 Mb node current/index.js\n       696.78 Mb /usr/lib/x86_64\n       641.43 Mb /usr/bin/dockerd\n       506.49 Mb /usr/lib/x86_64\n       438.69 Mb /usr/sbin/unity\n       427.19 Mb /usr/lib/snapd/snapd\n       ....\n</code></pre>\n<p>But once the program reaches the <code>signal.pause()</code> the memory get freed up after a while.<br>\nDo you really think this is still normal?<br>\nEven if it's not a memory leak is there an alternative for me to run the code on CPU without it taking 17gb but 1.5gb instead as on the GPU? Thanks</p>", "body_text": "@fmassa Ok so I ran a little benchmark on both the GPU and the CPU of the following script:\nimport signal\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nmodel = nn.Conv2d(64, 3, kernel_size=9, padding=4).cuda() # cuda removed for CPU\nx = Variable(torch.randn([16, 64, 224, 224])).cuda() # cuda removed for CPU\nmodel(x)\nprint(\"Done\")\nsignal.pause()\n\nHere are the results:\nOn GPU:\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1403      G   /usr/lib/xorg/Xorg                            90MiB |\n|    0      7061      C   python                                      1341MiB |\n+-----------------------------------------------------------------------------+\n\nOn CPU:\n$ps -eo size,pid,user,command --sort -size | awk '{ hr=$1/1024 ; printf(\"%13.2f Mb \",hr) } { for ( x=4 ; x<=NF ; x++ ) { printf(\"%s \",$x) } print \"\" }' |cut -d \"\" -f2 | cut -d \"-\" -f1 > output\n\n         0.00 Mb COMMAND\n     16607.09 Mb python test.py\n      1172.36 Mb node current/index.js\n       696.78 Mb /usr/lib/x86_64\n       641.43 Mb /usr/bin/dockerd\n       506.49 Mb /usr/lib/x86_64\n       438.69 Mb /usr/sbin/unity\n       427.19 Mb /usr/lib/snapd/snapd\n       ....\n\nBut once the program reaches the signal.pause() the memory get freed up after a while.\nDo you really think this is still normal?\nEven if it's not a memory leak is there an alternative for me to run the code on CPU without it taking 17gb but 1.5gb instead as on the GPU? Thanks", "body": "@fmassa Ok so I ran a little benchmark on both the GPU and the CPU of the following script:\r\n```\r\nimport signal\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\nmodel = nn.Conv2d(64, 3, kernel_size=9, padding=4).cuda() # cuda removed for CPU\r\nx = Variable(torch.randn([16, 64, 224, 224])).cuda() # cuda removed for CPU\r\nmodel(x)\r\nprint(\"Done\")\r\nsignal.pause()\r\n```\r\n\r\nHere are the results:\r\nOn GPU:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1403      G   /usr/lib/xorg/Xorg                            90MiB |\r\n|    0      7061      C   python                                      1341MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nOn CPU:\r\n```\r\n$ps -eo size,pid,user,command --sort -size | awk '{ hr=$1/1024 ; printf(\"%13.2f Mb \",hr) } { for ( x=4 ; x<=NF ; x++ ) { printf(\"%s \",$x) } print \"\" }' |cut -d \"\" -f2 | cut -d \"-\" -f1 > output\r\n\r\n         0.00 Mb COMMAND\r\n     16607.09 Mb python test.py\r\n      1172.36 Mb node current/index.js\r\n       696.78 Mb /usr/lib/x86_64\r\n       641.43 Mb /usr/bin/dockerd\r\n       506.49 Mb /usr/lib/x86_64\r\n       438.69 Mb /usr/sbin/unity\r\n       427.19 Mb /usr/lib/snapd/snapd\r\n       ....\r\n```\r\nBut once the program reaches the `signal.pause()` the memory get freed up after a while.\r\nDo you really think this is still normal?\r\nEven if it's not a memory leak is there an alternative for me to run the code on CPU without it taking 17gb but 1.5gb instead as on the GPU? Thanks"}