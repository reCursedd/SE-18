{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/369258532", "html_url": "https://github.com/pytorch/pytorch/issues/5285#issuecomment-369258532", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5285", "id": 369258532, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTI1ODUzMg==", "user": {"login": "EKami", "id": 4030626, "node_id": "MDQ6VXNlcjQwMzA2MjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/4030626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EKami", "html_url": "https://github.com/EKami", "followers_url": "https://api.github.com/users/EKami/followers", "following_url": "https://api.github.com/users/EKami/following{/other_user}", "gists_url": "https://api.github.com/users/EKami/gists{/gist_id}", "starred_url": "https://api.github.com/users/EKami/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EKami/subscriptions", "organizations_url": "https://api.github.com/users/EKami/orgs", "repos_url": "https://api.github.com/users/EKami/repos", "events_url": "https://api.github.com/users/EKami/events{/privacy}", "received_events_url": "https://api.github.com/users/EKami/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-28T14:36:41Z", "updated_at": "2018-02-28T14:36:41Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>One question: it seems that you want to generate an image that is of size 1800x1800 (8x upsample of 224x224), is that right?</p>\n</blockquote>\n<p>Yes, when I run inference I only process 1 batch at a time but my resulting image can be even bigger than 1800x1800 (depending on the input image size). <a href=\"https://github.com/EKami/Torchlite/blob/master/torchlite/eval/eval.py#L11\">Here is the code</a> which does that. It seems that there isn't much hope for CPU inference for me for now considering the upscaling factor will take even more memory I believe.</p>", "body_text": "One question: it seems that you want to generate an image that is of size 1800x1800 (8x upsample of 224x224), is that right?\n\nYes, when I run inference I only process 1 batch at a time but my resulting image can be even bigger than 1800x1800 (depending on the input image size). Here is the code which does that. It seems that there isn't much hope for CPU inference for me for now considering the upscaling factor will take even more memory I believe.", "body": "> One question: it seems that you want to generate an image that is of size 1800x1800 (8x upsample of 224x224), is that right?\r\n\r\nYes, when I run inference I only process 1 batch at a time but my resulting image can be even bigger than 1800x1800 (depending on the input image size). [Here is the code](https://github.com/EKami/Torchlite/blob/master/torchlite/eval/eval.py#L11) which does that. It seems that there isn't much hope for CPU inference for me for now considering the upscaling factor will take even more memory I believe."}