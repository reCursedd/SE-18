{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/368939959", "html_url": "https://github.com/pytorch/pytorch/issues/5285#issuecomment-368939959", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5285", "id": 368939959, "node_id": "MDEyOklzc3VlQ29tbWVudDM2ODkzOTk1OQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-27T16:34:11Z", "updated_at": "2018-02-27T16:34:11Z", "author_association": "MEMBER", "body_html": "<p>The 15GB of RAM for this input size wouldn't surprise me, because we use the (memory consuming) unfolding of the image to perform the convolution.<br>\nIn your example, the unfolded image has size of roughly <code>16 * 64 * 9 * 9 * 224 * 224 * 4</code> which is roughly 15GB (<a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/SpatialConvolutionMM.c#L192\">exact code here</a>).</p>\n<p>The dimensions of the input image are too big for the kernel size.</p>", "body_text": "The 15GB of RAM for this input size wouldn't surprise me, because we use the (memory consuming) unfolding of the image to perform the convolution.\nIn your example, the unfolded image has size of roughly 16 * 64 * 9 * 9 * 224 * 224 * 4 which is roughly 15GB (exact code here).\nThe dimensions of the input image are too big for the kernel size.", "body": "The 15GB of RAM for this input size wouldn't surprise me, because we use the (memory consuming) unfolding of the image to perform the convolution.\r\nIn your example, the unfolded image has size of roughly `16 * 64 * 9 * 9 * 224 * 224 * 4` which is roughly 15GB ([exact code here](https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/SpatialConvolutionMM.c#L192)).\r\n\r\nThe dimensions of the input image are too big for the kernel size."}