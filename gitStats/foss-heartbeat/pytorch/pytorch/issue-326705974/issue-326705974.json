{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7871", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7871/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7871/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7871/events", "html_url": "https://github.com/pytorch/pytorch/issues/7871", "id": 326705974, "node_id": "MDU6SXNzdWUzMjY3MDU5NzQ=", "number": 7871, "title": "[PyTorch] [ONNX] All RNNs fail to export without bias weights", "user": {"login": "ryanleary", "id": 2212584, "node_id": "MDQ6VXNlcjIyMTI1ODQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/2212584?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryanleary", "html_url": "https://github.com/ryanleary", "followers_url": "https://api.github.com/users/ryanleary/followers", "following_url": "https://api.github.com/users/ryanleary/following{/other_user}", "gists_url": "https://api.github.com/users/ryanleary/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryanleary/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryanleary/subscriptions", "organizations_url": "https://api.github.com/users/ryanleary/orgs", "repos_url": "https://api.github.com/users/ryanleary/repos", "events_url": "https://api.github.com/users/ryanleary/events{/privacy}", "received_events_url": "https://api.github.com/users/ryanleary/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 693805995, "node_id": "MDU6TGFiZWw2OTM4MDU5OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/onnx", "name": "onnx", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-05-26T03:26:49Z", "updated_at": "2018-05-29T14:02:36Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>This issue exists in 0.4 and master (at least) and can be demonstrated with the following code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> onnx\n<span class=\"pl-k\">import</span> io\n\nrnn_types <span class=\"pl-k\">=</span> [torch.nn.<span class=\"pl-c1\">RNN</span>, torch.nn.<span class=\"pl-c1\">LSTM</span>, torch.nn.<span class=\"pl-c1\">GRU</span>]\n\n<span class=\"pl-k\">for</span> rnn_type <span class=\"pl-k\">in</span> rnn_types:\n    f <span class=\"pl-k\">=</span> io.BytesIO()\n    model <span class=\"pl-k\">=</span> rnn_type(<span class=\"pl-v\">input_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">hidden_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">num_layers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    <span class=\"pl-k\">try</span>:\n        torch.onnx.export(model, torch.rand(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>), f)\n    <span class=\"pl-k\">except</span> <span class=\"pl-c1\">ValueError</span>:\n        <span class=\"pl-c1\">print</span>(rnn_type.<span class=\"pl-c1\">__name__</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>failed to export<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p>which returns</p>\n<pre><code>RNN failed to export\nLSTM failed to export\nGRU failed to export\n</code></pre>\n<p>the underlying issue is in <code>transform_weights</code> in <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic.py#L914\">https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic.py#L914</a>. Should be able to simply add a case here to initialize zero'd tensors.</p>\n<p>cc: <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11729078\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jekbradbury\">@jekbradbury</a></p>", "body_text": "This issue exists in 0.4 and master (at least) and can be demonstrated with the following code:\nimport torch\nimport onnx\nimport io\n\nrnn_types = [torch.nn.RNN, torch.nn.LSTM, torch.nn.GRU]\n\nfor rnn_type in rnn_types:\n    f = io.BytesIO()\n    model = rnn_type(input_size=4, hidden_size=2, num_layers=1, bias=False)\n    try:\n        torch.onnx.export(model, torch.rand(2, 3, 4), f)\n    except ValueError:\n        print(rnn_type.__name__, \"failed to export\")\nwhich returns\nRNN failed to export\nLSTM failed to export\nGRU failed to export\n\nthe underlying issue is in transform_weights in https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic.py#L914. Should be able to simply add a case here to initialize zero'd tensors.\ncc: @jekbradbury", "body": "This issue exists in 0.4 and master (at least) and can be demonstrated with the following code:\r\n\r\n```python\r\nimport torch\r\nimport onnx\r\nimport io\r\n\r\nrnn_types = [torch.nn.RNN, torch.nn.LSTM, torch.nn.GRU]\r\n\r\nfor rnn_type in rnn_types:\r\n    f = io.BytesIO()\r\n    model = rnn_type(input_size=4, hidden_size=2, num_layers=1, bias=False)\r\n    try:\r\n        torch.onnx.export(model, torch.rand(2, 3, 4), f)\r\n    except ValueError:\r\n        print(rnn_type.__name__, \"failed to export\")\r\n```\r\n\r\nwhich returns\r\n\r\n```\r\nRNN failed to export\r\nLSTM failed to export\r\nGRU failed to export\r\n```\r\n\r\nthe underlying issue is in `transform_weights` in https://github.com/pytorch/pytorch/blob/master/torch/onnx/symbolic.py#L914. Should be able to simply add a case here to initialize zero'd tensors.\r\n\r\ncc: @jekbradbury "}