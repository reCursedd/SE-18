{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1541", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1541/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1541/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1541/events", "html_url": "https://github.com/pytorch/pytorch/issues/1541", "id": 228104205, "node_id": "MDU6SXNzdWUyMjgxMDQyMDU=", "number": 1541, "title": "InstanceNorm eval mode", "user": {"login": "abhiskk", "id": 3365035, "node_id": "MDQ6VXNlcjMzNjUwMzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/3365035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhiskk", "html_url": "https://github.com/abhiskk", "followers_url": "https://api.github.com/users/abhiskk/followers", "following_url": "https://api.github.com/users/abhiskk/following{/other_user}", "gists_url": "https://api.github.com/users/abhiskk/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhiskk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhiskk/subscriptions", "organizations_url": "https://api.github.com/users/abhiskk/orgs", "repos_url": "https://api.github.com/users/abhiskk/repos", "events_url": "https://api.github.com/users/abhiskk/events{/privacy}", "received_events_url": "https://api.github.com/users/abhiskk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-05-11T20:00:24Z", "updated_at": "2017-05-21T17:27:49Z", "closed_at": "2017-05-21T17:27:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The <code>InstanceNorm</code> module in <code>eval</code> mode is supposed to behave in the same way as in the <code>train</code> mode (<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/instancenorm.py#L55-L57\">ref</a>), this is done by keeping the module in the <code>train</code> mode even if <code>eval()</code> is called.</p>\n<div class=\"highlight highlight-source-python\"><pre>net <span class=\"pl-k\">=</span> torch.nn.InstanceNorm2d(<span class=\"pl-c1\">3</span>)\nnet.eval()\n<span class=\"pl-c1\">print</span>(net.training) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints True</span></pre></div>\n<p>but if you have <code>InstanceNorm2d</code> as a sub-module, the eval mode for <code>InstanceNorm2d</code> module doesn't behave as it is expected to:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">CustomNet</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(CustomNet, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.in1 <span class=\"pl-k\">=</span> torch.nn.InstanceNorm2d(<span class=\"pl-c1\">3</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\">X</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.in1(X)\n\ncustom_net <span class=\"pl-k\">=</span> CustomNet()\ncustom_net.eval()\n<span class=\"pl-c1\">print</span>(custom_net.in1.training) <span class=\"pl-c\"><span class=\"pl-c\">#</span> prints False</span></pre></div>\n<p>I suspect this happens because <code>eval</code> from a module calls <code>train(False)</code>, which bypasses the overload. Is this behavior expected?</p>", "body_text": "The InstanceNorm module in eval mode is supposed to behave in the same way as in the train mode (ref), this is done by keeping the module in the train mode even if eval() is called.\nnet = torch.nn.InstanceNorm2d(3)\nnet.eval()\nprint(net.training) # prints True\nbut if you have InstanceNorm2d as a sub-module, the eval mode for InstanceNorm2d module doesn't behave as it is expected to:\nclass CustomNet(torch.nn.Module):\n    def __init__(self):\n        super(CustomNet, self).__init__()\n        self.in1 = torch.nn.InstanceNorm2d(3)\n\n    def forward(X):\n        return self.in1(X)\n\ncustom_net = CustomNet()\ncustom_net.eval()\nprint(custom_net.in1.training) # prints False\nI suspect this happens because eval from a module calls train(False), which bypasses the overload. Is this behavior expected?", "body": "The `InstanceNorm` module in `eval` mode is supposed to behave in the same way as in the `train` mode ([ref](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/instancenorm.py#L55-L57)), this is done by keeping the module in the `train` mode even if `eval()` is called.\r\n\r\n```python\r\nnet = torch.nn.InstanceNorm2d(3)\r\nnet.eval()\r\nprint(net.training) # prints True\r\n```\r\n\r\nbut if you have `InstanceNorm2d` as a sub-module, the eval mode for `InstanceNorm2d` module doesn't behave as it is expected to:\r\n\r\n```python\r\nclass CustomNet(torch.nn.Module):\r\n    def __init__(self):\r\n        super(CustomNet, self).__init__()\r\n        self.in1 = torch.nn.InstanceNorm2d(3)\r\n\r\n    def forward(X):\r\n        return self.in1(X)\r\n\r\ncustom_net = CustomNet()\r\ncustom_net.eval()\r\nprint(custom_net.in1.training) # prints False\r\n```\r\n\r\nI suspect this happens because `eval` from a module calls `train(False)`, which bypasses the overload. Is this behavior expected?"}