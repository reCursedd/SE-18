{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/365777683", "html_url": "https://github.com/pytorch/pytorch/issues/5239#issuecomment-365777683", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5239", "id": 365777683, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTc3NzY4Mw==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T23:18:45Z", "updated_at": "2018-02-14T23:18:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9203906\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shiranD\">@shiranD</a> Yes, you can still use a GPU. That flag controls whether some operations are dispatched to our GPU implementation (THNN) or NVIDIA's GPU implementation (CUDNN). Usually the second is faster, that's why we dispatch to CUDNN by default. However, in your case, CUDNN RNN (which is considered as a single autograd op in PyTorch) doesn't support double backward, but the THNN RNN (which is just a series of autograd operations) does. So it works, albeit some potential slow downs.</p>\n<p>About the last sentence in my comment above, personally and empirically, I'm not sure how much gradient penalty helps. There are some intuition around it, such as smoothing D around the manifold etc., and some people have been reporting that it reduces sensitivity to hyperparameters a bit in certain z=&gt;img GAN settings. But I haven't found it to very effective in non z=&gt;img setting, such as simply adversarial loss. Considering that sequence data is a completely different domain that image, I'm just not very certain that whether it will help.</p>", "body_text": "@shiranD Yes, you can still use a GPU. That flag controls whether some operations are dispatched to our GPU implementation (THNN) or NVIDIA's GPU implementation (CUDNN). Usually the second is faster, that's why we dispatch to CUDNN by default. However, in your case, CUDNN RNN (which is considered as a single autograd op in PyTorch) doesn't support double backward, but the THNN RNN (which is just a series of autograd operations) does. So it works, albeit some potential slow downs.\nAbout the last sentence in my comment above, personally and empirically, I'm not sure how much gradient penalty helps. There are some intuition around it, such as smoothing D around the manifold etc., and some people have been reporting that it reduces sensitivity to hyperparameters a bit in certain z=>img GAN settings. But I haven't found it to very effective in non z=>img setting, such as simply adversarial loss. Considering that sequence data is a completely different domain that image, I'm just not very certain that whether it will help.", "body": "@shiranD Yes, you can still use a GPU. That flag controls whether some operations are dispatched to our GPU implementation (THNN) or NVIDIA's GPU implementation (CUDNN). Usually the second is faster, that's why we dispatch to CUDNN by default. However, in your case, CUDNN RNN (which is considered as a single autograd op in PyTorch) doesn't support double backward, but the THNN RNN (which is just a series of autograd operations) does. So it works, albeit some potential slow downs.\r\n\r\nAbout the last sentence in my comment above, personally and empirically, I'm not sure how much gradient penalty helps. There are some intuition around it, such as smoothing D around the manifold etc., and some people have been reporting that it reduces sensitivity to hyperparameters a bit in certain z=>img GAN settings. But I haven't found it to very effective in non z=>img setting, such as simply adversarial loss. Considering that sequence data is a completely different domain that image, I'm just not very certain that whether it will help."}