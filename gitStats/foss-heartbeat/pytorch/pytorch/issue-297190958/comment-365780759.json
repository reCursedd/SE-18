{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/365780759", "html_url": "https://github.com/pytorch/pytorch/issues/5239#issuecomment-365780759", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5239", "id": 365780759, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTc4MDc1OQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T23:35:17Z", "updated_at": "2018-02-14T23:35:56Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9203906\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shiranD\">@shiranD</a> I actually mean the non GAN setting, but with adversarial loss. For example in style transfer, you may want some thing to be indistinguishable with another, but it's not a generative model. Yes, when I read WGAN paper, I was excited as well. The theory is nice and clean and intuitively makes sense. However, you need to keep in mind that very little of GAN theory applies to real settings. For example, many intuition come from that D is the inner optimizing loop (min-max formulation), but this is nearly never what is done in practice. In the end, due to the lack of a nice and complete theory of GAN, the theories and intuitions tell us what we should try and what might work. But we still need to try to see whether it works.</p>\n<p>edit: these are just my 2 cents.</p>", "body_text": "@shiranD I actually mean the non GAN setting, but with adversarial loss. For example in style transfer, you may want some thing to be indistinguishable with another, but it's not a generative model. Yes, when I read WGAN paper, I was excited as well. The theory is nice and clean and intuitively makes sense. However, you need to keep in mind that very little of GAN theory applies to real settings. For example, many intuition come from that D is the inner optimizing loop (min-max formulation), but this is nearly never what is done in practice. In the end, due to the lack of a nice and complete theory of GAN, the theories and intuitions tell us what we should try and what might work. But we still need to try to see whether it works.\nedit: these are just my 2 cents.", "body": "@shiranD I actually mean the non GAN setting, but with adversarial loss. For example in style transfer, you may want some thing to be indistinguishable with another, but it's not a generative model. Yes, when I read WGAN paper, I was excited as well. The theory is nice and clean and intuitively makes sense. However, you need to keep in mind that very little of GAN theory applies to real settings. For example, many intuition come from that D is the inner optimizing loop (min-max formulation), but this is nearly never what is done in practice. In the end, due to the lack of a nice and complete theory of GAN, the theories and intuitions tell us what we should try and what might work. But we still need to try to see whether it works.\r\n\r\nedit: these are just my 2 cents."}