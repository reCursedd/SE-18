{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/365775799", "html_url": "https://github.com/pytorch/pytorch/issues/5239#issuecomment-365775799", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5239", "id": 365775799, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NTc3NTc5OQ==", "user": {"login": "shiranD", "id": 9203906, "node_id": "MDQ6VXNlcjkyMDM5MDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9203906?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shiranD", "html_url": "https://github.com/shiranD", "followers_url": "https://api.github.com/users/shiranD/followers", "following_url": "https://api.github.com/users/shiranD/following{/other_user}", "gists_url": "https://api.github.com/users/shiranD/gists{/gist_id}", "starred_url": "https://api.github.com/users/shiranD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shiranD/subscriptions", "organizations_url": "https://api.github.com/users/shiranD/orgs", "repos_url": "https://api.github.com/users/shiranD/repos", "events_url": "https://api.github.com/users/shiranD/events{/privacy}", "received_events_url": "https://api.github.com/users/shiranD/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-14T23:09:52Z", "updated_at": "2018-02-14T23:09:52Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">First,\nThanks for replying and sharing with me what you know \u2013 it\u2019s very helpful (I also realized that you are from the developers community \u2013 which is awesome!)\nI\u2019m not sure I understood the last sentence \u201cI don't even know if gradient penalty with recurrent discriminator would help\u201d. I guess I\u2019m not sure what you meant by that.\nAlso, if I set torch.backends.cudnn.enabled=False can I still use a gpu? Would that be meaningful? Because if the model is on CPU and the data is on GPU they might be a lot of overhead and at some point both would end up being on the CPU? Does that make sense? I guess I really want to use the gpus I have but if it would increase runtime I\u2019m missing the point and I prefer just using a cpu\nI guess I would like to know what is your take on that\n\nThanks,\nShiran\n\nFrom: Tongzhou Wang &lt;notifications@github.com&gt;\nReply-To: pytorch/pytorch &lt;reply@reply.github.com&gt;\nDate: Wednesday, February 14, 2018 at 2:47 PM\nTo: pytorch/pytorch &lt;pytorch@noreply.github.com&gt;\nCc: Shiran Dudy &lt;dudy@ohsu.edu&gt;, Author &lt;author@noreply.github.com&gt;\nSubject: Re: [pytorch/pytorch] A bug that appears when running with CUDA and does not when using cpu (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"297190958\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5239\" href=\"https://github.com/pytorch/pytorch/issues/5239\">#5239</a>)\n\n\nWell the reason is CPU (and non-cudnn GPU) RNNs are implemented entirely using autograd, all operations of which supports double backward. If you really want to use the non-cudnn GPU RNN, just set torch.backends.cudnn.enabled=False. Then you should be able to do the same thing on GPU. That said, TBH, I don't even know if gradient penalty with recurrent discriminator would help.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub&lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"297190958\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5239\" href=\"https://github.com/pytorch/pytorch/issues/5239#issuecomment-365770715\">#5239 (comment)</a>&gt;, or mute the thread&lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AIxwwomu7WpsgL_ImHWCZcU5ME_PNzwdks5tU2KSgaJpZM4SFu0B\">https://github.com/notifications/unsubscribe-auth/AIxwwomu7WpsgL_ImHWCZcU5ME_PNzwdks5tU2KSgaJpZM4SFu0B</a>&gt;.</div>", "body_text": "First,\nThanks for replying and sharing with me what you know \u2013 it\u2019s very helpful (I also realized that you are from the developers community \u2013 which is awesome!)\nI\u2019m not sure I understood the last sentence \u201cI don't even know if gradient penalty with recurrent discriminator would help\u201d. I guess I\u2019m not sure what you meant by that.\nAlso, if I set torch.backends.cudnn.enabled=False can I still use a gpu? Would that be meaningful? Because if the model is on CPU and the data is on GPU they might be a lot of overhead and at some point both would end up being on the CPU? Does that make sense? I guess I really want to use the gpus I have but if it would increase runtime I\u2019m missing the point and I prefer just using a cpu\nI guess I would like to know what is your take on that\n\nThanks,\nShiran\n\nFrom: Tongzhou Wang <notifications@github.com>\nReply-To: pytorch/pytorch <reply@reply.github.com>\nDate: Wednesday, February 14, 2018 at 2:47 PM\nTo: pytorch/pytorch <pytorch@noreply.github.com>\nCc: Shiran Dudy <dudy@ohsu.edu>, Author <author@noreply.github.com>\nSubject: Re: [pytorch/pytorch] A bug that appears when running with CUDA and does not when using cpu (#5239)\n\n\nWell the reason is CPU (and non-cudnn GPU) RNNs are implemented entirely using autograd, all operations of which supports double backward. If you really want to use the non-cudnn GPU RNN, just set torch.backends.cudnn.enabled=False. Then you should be able to do the same thing on GPU. That said, TBH, I don't even know if gradient penalty with recurrent discriminator would help.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<#5239 (comment)>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AIxwwomu7WpsgL_ImHWCZcU5ME_PNzwdks5tU2KSgaJpZM4SFu0B>.", "body": "First,\r\nThanks for replying and sharing with me what you know \u2013 it\u2019s very helpful (I also realized that you are from the developers community \u2013 which is awesome!)\r\nI\u2019m not sure I understood the last sentence \u201cI don't even know if gradient penalty with recurrent discriminator would help\u201d. I guess I\u2019m not sure what you meant by that.\r\nAlso, if I set torch.backends.cudnn.enabled=False can I still use a gpu? Would that be meaningful? Because if the model is on CPU and the data is on GPU they might be a lot of overhead and at some point both would end up being on the CPU? Does that make sense? I guess I really want to use the gpus I have but if it would increase runtime I\u2019m missing the point and I prefer just using a cpu\r\nI guess I would like to know what is your take on that\r\n\r\nThanks,\r\nShiran\r\n\r\nFrom: Tongzhou Wang <notifications@github.com>\r\nReply-To: pytorch/pytorch <reply@reply.github.com>\r\nDate: Wednesday, February 14, 2018 at 2:47 PM\r\nTo: pytorch/pytorch <pytorch@noreply.github.com>\r\nCc: Shiran Dudy <dudy@ohsu.edu>, Author <author@noreply.github.com>\r\nSubject: Re: [pytorch/pytorch] A bug that appears when running with CUDA and does not when using cpu (#5239)\r\n\r\n\r\nWell the reason is CPU (and non-cudnn GPU) RNNs are implemented entirely using autograd, all operations of which supports double backward. If you really want to use the non-cudnn GPU RNN, just set torch.backends.cudnn.enabled=False. Then you should be able to do the same thing on GPU. That said, TBH, I don't even know if gradient penalty with recurrent discriminator would help.\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/pytorch/pytorch/issues/5239#issuecomment-365770715>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AIxwwomu7WpsgL_ImHWCZcU5ME_PNzwdks5tU2KSgaJpZM4SFu0B>.\r\n"}