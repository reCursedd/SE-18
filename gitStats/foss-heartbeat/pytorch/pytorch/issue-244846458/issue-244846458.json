{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2187", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2187/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2187/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2187/events", "html_url": "https://github.com/pytorch/pytorch/issues/2187", "id": 244846458, "node_id": "MDU6SXNzdWUyNDQ4NDY0NTg=", "number": 2187, "title": "Newest version(origin/master) memory issue on GPU", "user": {"login": "shwoo93", "id": 13035722, "node_id": "MDQ6VXNlcjEzMDM1NzIy", "avatar_url": "https://avatars2.githubusercontent.com/u/13035722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shwoo93", "html_url": "https://github.com/shwoo93", "followers_url": "https://api.github.com/users/shwoo93/followers", "following_url": "https://api.github.com/users/shwoo93/following{/other_user}", "gists_url": "https://api.github.com/users/shwoo93/gists{/gist_id}", "starred_url": "https://api.github.com/users/shwoo93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shwoo93/subscriptions", "organizations_url": "https://api.github.com/users/shwoo93/orgs", "repos_url": "https://api.github.com/users/shwoo93/repos", "events_url": "https://api.github.com/users/shwoo93/events{/privacy}", "received_events_url": "https://api.github.com/users/shwoo93/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 553773019, "node_id": "MDU6TGFiZWw1NTM3NzMwMTk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs-reproduction", "name": "needs-reproduction", "color": "e99695", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-07-22T13:09:55Z", "updated_at": "2017-08-30T23:26:49Z", "closed_at": "2017-08-30T23:26:48Z", "author_association": "NONE", "body_html": "<p>I have worked for pytorch with official released version but there were some limits related to GPU. For example, executing torch.range() on GPU gave me the below error,</p>\n<p><strong>torch.cuda.FloatTensor doesn't implement stateless method arange</strong></p>\n<p>Therefore I just cloned pytorch git and build the docker image from the provided dockerfile.<br>\nFinally, the code execution of torch.range() on GPU was not the problem but I got an another issue.</p>\n<p><strong>RuntimeError: cuda runtime error (2) : out of memory at /tmp/pip-ikrnhryb-build/torch/lib/THC/generic/THCStorage.cu:66</strong></p>\n<p>Firstly, I tried to change batch_size from 16 to 8 but gave me the same error.<br>\nI tried batch_size 2 and 1 as well  but result in with the below errors respectively.</p>\n<p><strong>invalid argument 2: sizes do not match at /tmp/pip-ikrnhryb-build/torch/lib/THC/generated/../generic/TH  --&gt; batch_size = 2</strong></p>\n<p><strong>assert len(modules) == len(devices) --&gt; batch_size = 1</strong></p>\n<p>Since now there is a memory issue with the latest version, I am wondering if it will take some times to be completely stable. Or is there any way to resolve this situation?</p>\n<p>Need your help!</p>", "body_text": "I have worked for pytorch with official released version but there were some limits related to GPU. For example, executing torch.range() on GPU gave me the below error,\ntorch.cuda.FloatTensor doesn't implement stateless method arange\nTherefore I just cloned pytorch git and build the docker image from the provided dockerfile.\nFinally, the code execution of torch.range() on GPU was not the problem but I got an another issue.\nRuntimeError: cuda runtime error (2) : out of memory at /tmp/pip-ikrnhryb-build/torch/lib/THC/generic/THCStorage.cu:66\nFirstly, I tried to change batch_size from 16 to 8 but gave me the same error.\nI tried batch_size 2 and 1 as well  but result in with the below errors respectively.\ninvalid argument 2: sizes do not match at /tmp/pip-ikrnhryb-build/torch/lib/THC/generated/../generic/TH  --> batch_size = 2\nassert len(modules) == len(devices) --> batch_size = 1\nSince now there is a memory issue with the latest version, I am wondering if it will take some times to be completely stable. Or is there any way to resolve this situation?\nNeed your help!", "body": "I have worked for pytorch with official released version but there were some limits related to GPU. For example, executing torch.range() on GPU gave me the below error, \r\n\r\n**torch.cuda.FloatTensor doesn't implement stateless method arange**\r\n\r\nTherefore I just cloned pytorch git and build the docker image from the provided dockerfile.\r\nFinally, the code execution of torch.range() on GPU was not the problem but I got an another issue.\r\n\r\n**RuntimeError: cuda runtime error (2) : out of memory at /tmp/pip-ikrnhryb-build/torch/lib/THC/generic/THCStorage.cu:66**\r\n\r\nFirstly, I tried to change batch_size from 16 to 8 but gave me the same error. \r\nI tried batch_size 2 and 1 as well  but result in with the below errors respectively.\r\n\r\n**invalid argument 2: sizes do not match at /tmp/pip-ikrnhryb-build/torch/lib/THC/generated/../generic/TH  --> batch_size = 2**\r\n\r\n**assert len(modules) == len(devices) --> batch_size = 1**\r\n\r\nSince now there is a memory issue with the latest version, I am wondering if it will take some times to be completely stable. Or is there any way to resolve this situation?\r\n\r\nNeed your help!"}