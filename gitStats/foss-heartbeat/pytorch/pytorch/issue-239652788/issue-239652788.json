{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1953", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1953/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1953/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1953/events", "html_url": "https://github.com/pytorch/pytorch/issues/1953", "id": 239652788, "node_id": "MDU6SXNzdWUyMzk2NTI3ODg=", "number": 1953, "title": "Advanced indexing on the GPU", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-30T01:17:17Z", "updated_at": "2017-07-10T20:06:01Z", "closed_at": "2017-07-10T20:06:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For advanced indexing with the duplicate indexes, it is expected that the last one should win, e.g. with the input</p>\n<pre><code>  0   1   2   3   4\n  5   6   7   8   9\n 10  11  12  13  14\n 15  16  17  18  19\n</code></pre>\n<p><code>indexer = [slice(None, None, None), [0, 1, 1, 2, 2]]</code> and val</p>\n<pre><code> 16  12   0  14  10\n 19  17   2   7   4\n  5   9   6   1  15\n 13  11   3   8  18\n</code></pre>\n<p>the expected output of <code>input[indexer]=val</code> is</p>\n<pre><code>16   0  10   3   4\n19   2   4   8   9\n 5   6  15  13  14\n13   3  18  18  19\n</code></pre>\n<p>there are tests checking that. Yet the kernels doing the indexing (indexCopyLargeIndex and indexCopySmallIndex) provide no such guarantee - if the same dstOffset is shared by several threads, there is no guarantee on which write would be last, and no effort is made before launching the kernels to make sure that dstOffsets would be unique for all threads. This is not really fixable until the indices are de-duplicated and only the unique dstOffsets are present in those kernels. I don't know the best way to handle this. Disable advanced indexing with dupes, say results is undefined, de-dupe the indices? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4529377\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/killeent\">@killeent</a></p>", "body_text": "For advanced indexing with the duplicate indexes, it is expected that the last one should win, e.g. with the input\n  0   1   2   3   4\n  5   6   7   8   9\n 10  11  12  13  14\n 15  16  17  18  19\n\nindexer = [slice(None, None, None), [0, 1, 1, 2, 2]] and val\n 16  12   0  14  10\n 19  17   2   7   4\n  5   9   6   1  15\n 13  11   3   8  18\n\nthe expected output of input[indexer]=val is\n16   0  10   3   4\n19   2   4   8   9\n 5   6  15  13  14\n13   3  18  18  19\n\nthere are tests checking that. Yet the kernels doing the indexing (indexCopyLargeIndex and indexCopySmallIndex) provide no such guarantee - if the same dstOffset is shared by several threads, there is no guarantee on which write would be last, and no effort is made before launching the kernels to make sure that dstOffsets would be unique for all threads. This is not really fixable until the indices are de-duplicated and only the unique dstOffsets are present in those kernels. I don't know the best way to handle this. Disable advanced indexing with dupes, say results is undefined, de-dupe the indices? @killeent", "body": "For advanced indexing with the duplicate indexes, it is expected that the last one should win, e.g. with the input \r\n```\r\n  0   1   2   3   4\r\n  5   6   7   8   9\r\n 10  11  12  13  14\r\n 15  16  17  18  19\r\n``` \r\n```indexer = [slice(None, None, None), [0, 1, 1, 2, 2]]``` and val\r\n```\r\n 16  12   0  14  10\r\n 19  17   2   7   4\r\n  5   9   6   1  15\r\n 13  11   3   8  18\r\n```\r\nthe expected output of ```input[indexer]=val``` is\r\n``` \r\n16   0  10   3   4\r\n19   2   4   8   9\r\n 5   6  15  13  14\r\n13   3  18  18  19\r\n```\r\nthere are tests checking that. Yet the kernels doing the indexing (indexCopyLargeIndex and indexCopySmallIndex) provide no such guarantee - if the same dstOffset is shared by several threads, there is no guarantee on which write would be last, and no effort is made before launching the kernels to make sure that dstOffsets would be unique for all threads. This is not really fixable until the indices are de-duplicated and only the unique dstOffsets are present in those kernels. I don't know the best way to handle this. Disable advanced indexing with dupes, say results is undefined, de-dupe the indices? @killeent \r\n"}