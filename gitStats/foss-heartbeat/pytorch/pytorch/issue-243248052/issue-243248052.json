{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2119", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2119/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2119/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2119/events", "html_url": "https://github.com/pytorch/pytorch/issues/2119", "id": 243248052, "node_id": "MDU6SXNzdWUyNDMyNDgwNTI=", "number": 2119, "title": "ConvTranspose3d with output_size raises ValueError", "user": {"login": "jjmetzger", "id": 17736757, "node_id": "MDQ6VXNlcjE3NzM2NzU3", "avatar_url": "https://avatars2.githubusercontent.com/u/17736757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jjmetzger", "html_url": "https://github.com/jjmetzger", "followers_url": "https://api.github.com/users/jjmetzger/followers", "following_url": "https://api.github.com/users/jjmetzger/following{/other_user}", "gists_url": "https://api.github.com/users/jjmetzger/gists{/gist_id}", "starred_url": "https://api.github.com/users/jjmetzger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jjmetzger/subscriptions", "organizations_url": "https://api.github.com/users/jjmetzger/orgs", "repos_url": "https://api.github.com/users/jjmetzger/repos", "events_url": "https://api.github.com/users/jjmetzger/events{/privacy}", "received_events_url": "https://api.github.com/users/jjmetzger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-07-16T15:49:12Z", "updated_at": "2018-10-24T16:24:37Z", "closed_at": "2018-10-24T16:24:37Z", "author_association": "NONE", "body_html": "<p>ConvTranspose3d doesn't seem to accept a 5D output_size (this works with a 4D output_size and ConvTranspose2d), I think due to the following lines in nn/modules/conv.py (the <code>output_size[-2:]</code> forces output_size to be 2D, but k is 3 in case of 3D).</p>\n<div class=\"highlight highlight-source-python\"><pre>k <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.dim() <span class=\"pl-k\">-</span> <span class=\"pl-c1\">2</span>\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(output_size) <span class=\"pl-k\">==</span> k <span class=\"pl-k\">+</span> <span class=\"pl-c1\">2</span>:\n    output_size <span class=\"pl-k\">=</span> output_size[<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>:]\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">len</span>(output_size) <span class=\"pl-k\">!=</span> k:\n    <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output_size must have <span class=\"pl-c1\">{}</span> or <span class=\"pl-c1\">{}</span> elements (got <span class=\"pl-c1\">{}</span>)<span class=\"pl-pds\">\"</span></span>\n        .format(k, k <span class=\"pl-k\">+</span> <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">len</span>(output_size)))</pre></div>\n<p>Below is a minimal example to reproduce this. Using the commented line without the output_size requirement works.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(Net, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> nn.ConvTranspose3d(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">3</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.conv1(x, <span class=\"pl-v\">output_size</span><span class=\"pl-k\">=</span>torch.Size((<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">64</span>,<span class=\"pl-c1\">64</span>,<span class=\"pl-c1\">64</span>))) \n<span class=\"pl-c\"><span class=\"pl-c\">#</span>         return self.conv1(x) </span>\n\nnet <span class=\"pl-k\">=</span> Net()\n\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> Variable(torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">64</span>))\nout <span class=\"pl-k\">=</span> net(<span class=\"pl-c1\">input</span>)\n<span class=\"pl-c1\">print</span>(out.size())</pre></div>", "body_text": "ConvTranspose3d doesn't seem to accept a 5D output_size (this works with a 4D output_size and ConvTranspose2d), I think due to the following lines in nn/modules/conv.py (the output_size[-2:] forces output_size to be 2D, but k is 3 in case of 3D).\nk = input.dim() - 2\nif len(output_size) == k + 2:\n    output_size = output_size[-2:]\nif len(output_size) != k:\n    raise ValueError(\n        \"output_size must have {} or {} elements (got {})\"\n        .format(k, k + 2, len(output_size)))\nBelow is a minimal example to reproduce this. Using the commented line without the output_size requirement works.\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.ConvTranspose3d(10, 10, 3)\n\n    def forward(self, x):\n        return self.conv1(x, output_size=torch.Size((1,10,64,64,64))) \n#         return self.conv1(x) \n\nnet = Net()\n\ninput = Variable(torch.randn(1, 10, 64, 64, 64))\nout = net(input)\nprint(out.size())", "body": "ConvTranspose3d doesn't seem to accept a 5D output_size (this works with a 4D output_size and ConvTranspose2d), I think due to the following lines in nn/modules/conv.py (the ```output_size[-2:]``` forces output_size to be 2D, but k is 3 in case of 3D).\r\n\r\n```python\r\nk = input.dim() - 2\r\nif len(output_size) == k + 2:\r\n    output_size = output_size[-2:]\r\nif len(output_size) != k:\r\n    raise ValueError(\r\n        \"output_size must have {} or {} elements (got {})\"\r\n        .format(k, k + 2, len(output_size)))\r\n```\r\n\r\nBelow is a minimal example to reproduce this. Using the commented line without the output_size requirement works.\r\n\r\n```python\r\nimport torch\r\nfrom torch.autograd import Variable\r\nimport torch.nn as nn\r\n\r\nclass Net(nn.Module):\r\n\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.ConvTranspose3d(10, 10, 3)\r\n\r\n    def forward(self, x):\r\n        return self.conv1(x, output_size=torch.Size((1,10,64,64,64))) \r\n#         return self.conv1(x) \r\n\r\nnet = Net()\r\n\r\ninput = Variable(torch.randn(1, 10, 64, 64, 64))\r\nout = net(input)\r\nprint(out.size())\r\n```"}