{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/379277625", "html_url": "https://github.com/pytorch/pytorch/issues/4247#issuecomment-379277625", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4247", "id": 379277625, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTI3NzYyNQ==", "user": {"login": "gasse", "id": 1726818, "node_id": "MDQ6VXNlcjE3MjY4MTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1726818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gasse", "html_url": "https://github.com/gasse", "followers_url": "https://api.github.com/users/gasse/followers", "following_url": "https://api.github.com/users/gasse/following{/other_user}", "gists_url": "https://api.github.com/users/gasse/gists{/gist_id}", "starred_url": "https://api.github.com/users/gasse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gasse/subscriptions", "organizations_url": "https://api.github.com/users/gasse/orgs", "repos_url": "https://api.github.com/users/gasse/repos", "events_url": "https://api.github.com/users/gasse/events{/privacy}", "received_events_url": "https://api.github.com/users/gasse/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-06T14:51:28Z", "updated_at": "2018-04-06T14:51:28Z", "author_association": "NONE", "body_html": "<p>By the way, a workaround to do summation over a specific dimensions of a sparse vector is as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> torch.sparse.FloatTensor(\n    <span class=\"pl-v\">indices</span><span class=\"pl-k\">=</span>torch.LongTensor([[<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>]]),\n    <span class=\"pl-v\">values</span><span class=\"pl-k\">=</span>torch.FloatTensor([<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>]),\n    <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>])\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sum over second dimension</span>\nx <span class=\"pl-k\">=</span> torch.sparse.FloatTensor(\n        <span class=\"pl-v\">indices</span><span class=\"pl-k\">=</span>torch.stack([\n            x._indices()[<span class=\"pl-c1\">0</span>],\n            torch.LongTensor(<span class=\"pl-c1\">1</span>).zero_().expand_as(x._indices()[<span class=\"pl-c1\">0</span>]),\n        ]),\n        <span class=\"pl-v\">values</span><span class=\"pl-k\">=</span>x._values(),\n        <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[x.shape[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">1</span>])\n\n<span class=\"pl-c1\">print</span>(x)\n<span class=\"pl-c1\">print</span>(x.coalesce())  <span class=\"pl-c\"><span class=\"pl-c\">#</span> here summation is actually done</span>\n<span class=\"pl-c1\">print</span>(x.to_dense())  <span class=\"pl-c\"><span class=\"pl-c\">#</span> here too</span></pre></div>", "body_text": "By the way, a workaround to do summation over a specific dimensions of a sparse vector is as follows:\nx = torch.sparse.FloatTensor(\n    indices=torch.LongTensor([[0, 1, 1], [2, 0, 2]]),\n    values=torch.FloatTensor([3, 4, 5]),\n    size=[2, 3])\n\n# sum over second dimension\nx = torch.sparse.FloatTensor(\n        indices=torch.stack([\n            x._indices()[0],\n            torch.LongTensor(1).zero_().expand_as(x._indices()[0]),\n        ]),\n        values=x._values(),\n        size=[x.shape[0], 1])\n\nprint(x)\nprint(x.coalesce())  # here summation is actually done\nprint(x.to_dense())  # here too", "body": "By the way, a workaround to do summation over a specific dimensions of a sparse vector is as follows:\r\n\r\n```python\r\nx = torch.sparse.FloatTensor(\r\n    indices=torch.LongTensor([[0, 1, 1], [2, 0, 2]]),\r\n    values=torch.FloatTensor([3, 4, 5]),\r\n    size=[2, 3])\r\n\r\n# sum over second dimension\r\nx = torch.sparse.FloatTensor(\r\n        indices=torch.stack([\r\n            x._indices()[0],\r\n            torch.LongTensor(1).zero_().expand_as(x._indices()[0]),\r\n        ]),\r\n        values=x._values(),\r\n        size=[x.shape[0], 1])\r\n\r\nprint(x)\r\nprint(x.coalesce())  # here summation is actually done\r\nprint(x.to_dense())  # here too\r\n```"}