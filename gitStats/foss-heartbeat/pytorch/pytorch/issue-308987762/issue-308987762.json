{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6041", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6041/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6041/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6041/events", "html_url": "https://github.com/pytorch/pytorch/issues/6041", "id": 308987762, "node_id": "MDU6SXNzdWUzMDg5ODc3NjI=", "number": 6041, "title": "torch.cuda.is_available() returns False", "user": {"login": "tiagoft", "id": 3904558, "node_id": "MDQ6VXNlcjM5MDQ1NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/3904558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tiagoft", "html_url": "https://github.com/tiagoft", "followers_url": "https://api.github.com/users/tiagoft/followers", "following_url": "https://api.github.com/users/tiagoft/following{/other_user}", "gists_url": "https://api.github.com/users/tiagoft/gists{/gist_id}", "starred_url": "https://api.github.com/users/tiagoft/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tiagoft/subscriptions", "organizations_url": "https://api.github.com/users/tiagoft/orgs", "repos_url": "https://api.github.com/users/tiagoft/repos", "events_url": "https://api.github.com/users/tiagoft/events{/privacy}", "received_events_url": "https://api.github.com/users/tiagoft/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-03-27T14:14:25Z", "updated_at": "2018-08-02T03:39:46Z", "closed_at": "2018-03-27T16:19:50Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>I am having trouble using cuda with Pytorch. I am migrating from Theano (maybe this is a problem?). I tried installing pytorch from pip, then uninstalled and tried with conda, and tried compiling from source using <code>python setup install</code>.</p>\n<p>It seems that CUDA works everywhere else in the system. I am supposing that this could be a permission issue or an issue with a broken path somewhere? I see that many people are having the same problem; have you been able to solve it somehow?</p>\n<p>Thanks!</p>\n<p>This is some info about my system and my installation:</p>\n<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: 0.4.0a0+1ab248d (as stated in torch.__version__)</li>\n<li>How you installed PyTorch (conda, pip, source): from source, although I have tried pip and conda and had the same problem.</li>\n<li>Python version: 2.7</li>\n<li>CUDA/cuDNN version: 8.0 / 7.2.1</li>\n<li>GPU models and configuration: Geforce GTX1070</li>\n<li>GCC version (if compiling from source): 5.4.1</li>\n</ul>\n<p>~$ nvcc --version<br>\nnvcc: NVIDIA (R) Cuda compiler driver<br>\nCopyright (c) 2005-2016 NVIDIA Corporation<br>\nBuilt on Sun_Sep__4_22:14:01_CDT_2016<br>\nCuda compilation tools, release 8.0, V8.0.44</p>\n<p>~$ nvidia-smi<br>\nTue Mar 27 10:59:19 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 390.42                 Driver Version: 390.42                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |<br>\n|  0%   49C    P8     6W / 151W |    266MiB /  8118MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1452      G   /usr/lib/xorg/Xorg                           144MiB |<br>\n|    0      2751      G   compiz                                       118MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>~$ python -c 'import torch; print torch.cuda.is_available()'<br>\nFalse</p>\n<p>~$ python -c 'import torch; print torch.rand(2,3).cuda()'<br>\nTHCudaCheck FAIL file=/home/username/pytorch/aten/src/THC/THCGeneral.cpp line=70 error=30 : unknown error<br>\nTraceback (most recent call last):<br>\nFile \"\", line 1, in <br>\nRuntimeError: cuda runtime error (30) : unknown error at /home/username/pytorch/aten/src/THC/THCGeneral.cpp:70</p>\n<p>I was under the impression that pytorch was not finding CUDA in runtime, so I tried:<br>\n~$ CUDA_HOME=\"/usr/local/cuda\" python -c 'import torch; print torch.cuda.is_available()'<br>\nFalse</p>", "body_text": "Hello,\nI am having trouble using cuda with Pytorch. I am migrating from Theano (maybe this is a problem?). I tried installing pytorch from pip, then uninstalled and tried with conda, and tried compiling from source using python setup install.\nIt seems that CUDA works everywhere else in the system. I am supposing that this could be a permission issue or an issue with a broken path somewhere? I see that many people are having the same problem; have you been able to solve it somehow?\nThanks!\nThis is some info about my system and my installation:\n\nOS: Ubuntu 16.04\nPyTorch version: 0.4.0a0+1ab248d (as stated in torch.__version__)\nHow you installed PyTorch (conda, pip, source): from source, although I have tried pip and conda and had the same problem.\nPython version: 2.7\nCUDA/cuDNN version: 8.0 / 7.2.1\nGPU models and configuration: Geforce GTX1070\nGCC version (if compiling from source): 5.4.1\n\n~$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Sun_Sep__4_22:14:01_CDT_2016\nCuda compilation tools, release 8.0, V8.0.44\n~$ nvidia-smi\nTue Mar 27 10:59:19 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.42                 Driver Version: 390.42                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |\n|  0%   49C    P8     6W / 151W |    266MiB /  8118MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1452      G   /usr/lib/xorg/Xorg                           144MiB |\n|    0      2751      G   compiz                                       118MiB |\n+-----------------------------------------------------------------------------+\n~$ python -c 'import torch; print torch.cuda.is_available()'\nFalse\n~$ python -c 'import torch; print torch.rand(2,3).cuda()'\nTHCudaCheck FAIL file=/home/username/pytorch/aten/src/THC/THCGeneral.cpp line=70 error=30 : unknown error\nTraceback (most recent call last):\nFile \"\", line 1, in \nRuntimeError: cuda runtime error (30) : unknown error at /home/username/pytorch/aten/src/THC/THCGeneral.cpp:70\nI was under the impression that pytorch was not finding CUDA in runtime, so I tried:\n~$ CUDA_HOME=\"/usr/local/cuda\" python -c 'import torch; print torch.cuda.is_available()'\nFalse", "body": "Hello,\r\n\r\nI am having trouble using cuda with Pytorch. I am migrating from Theano (maybe this is a problem?). I tried installing pytorch from pip, then uninstalled and tried with conda, and tried compiling from source using `python setup install`.\r\n\r\nIt seems that CUDA works everywhere else in the system. I am supposing that this could be a permission issue or an issue with a broken path somewhere? I see that many people are having the same problem; have you been able to solve it somehow?\r\n\r\nThanks!\r\n\r\nThis is some info about my system and my installation:\r\n\r\n- OS: Ubuntu 16.04\r\n- PyTorch version: 0.4.0a0+1ab248d (as stated in torch.\\_\\_version\\_\\_)\r\n- How you installed PyTorch (conda, pip, source): from source, although I have tried pip and conda and had the same problem.\r\n- Python version: 2.7\r\n- CUDA/cuDNN version: 8.0 / 7.2.1\r\n- GPU models and configuration: Geforce GTX1070\r\n- GCC version (if compiling from source): 5.4.1\r\n\r\n~$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Sun_Sep__4_22:14:01_CDT_2016\r\nCuda compilation tools, release 8.0, V8.0.44\r\n\r\n~$ nvidia-smi \r\nTue Mar 27 10:59:19 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.42                 Driver Version: 390.42                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |\r\n|  0%   49C    P8     6W / 151W |    266MiB /  8118MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1452      G   /usr/lib/xorg/Xorg                           144MiB |\r\n|    0      2751      G   compiz                                       118MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n~$ python -c 'import torch; print torch.cuda.is_available()'\r\nFalse\r\n\r\n~$ python -c 'import torch; print torch.rand(2,3).cuda()'\r\nTHCudaCheck FAIL file=/home/username/pytorch/aten/src/THC/THCGeneral.cpp line=70 error=30 : unknown error\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nRuntimeError: cuda runtime error (30) : unknown error at /home/username/pytorch/aten/src/THC/THCGeneral.cpp:70\r\n\r\nI was under the impression that pytorch was not finding CUDA in runtime, so I tried:\r\n~$ CUDA_HOME=\"/usr/local/cuda\" python -c 'import torch; print torch.cuda.is_available()'\r\nFalse\r\n\r\n\r\n\r\n"}