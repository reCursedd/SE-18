{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355412983", "html_url": "https://github.com/pytorch/pytorch/issues/4392#issuecomment-355412983", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4392", "id": 355412983, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTQxMjk4Mw==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T22:08:10Z", "updated_at": "2018-01-04T22:08:10Z", "author_association": "MEMBER", "body_html": "<p>I really like this idea. I think fast-by-default is important: both in terms of start-up time and speed of convolutions. Many researchers don't know or forget about the cudnn.benchmark flag.</p>\n<p>There are a few simple things we can do to make this reasonable:</p>\n<ol>\n<li>Limit the size of the global cache (evict old entries)</li>\n<li>Only benchmark a convolution after we see the same shape \"key\" multiple times. We can keep the count in another in-memory LRU cache with a smaller size than the global cache.</li>\n</ol>\n<p>(2) is a variation of <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>'s \"weakly on\" by default. (We might be saying the same thing). It means that if we see many variations of input shapes, we won't waste any time benchmarking them, nor will we evict useful entries from the global cache.</p>", "body_text": "I really like this idea. I think fast-by-default is important: both in terms of start-up time and speed of convolutions. Many researchers don't know or forget about the cudnn.benchmark flag.\nThere are a few simple things we can do to make this reasonable:\n\nLimit the size of the global cache (evict old entries)\nOnly benchmark a convolution after we see the same shape \"key\" multiple times. We can keep the count in another in-memory LRU cache with a smaller size than the global cache.\n\n(2) is a variation of @apaszke's \"weakly on\" by default. (We might be saying the same thing). It means that if we see many variations of input shapes, we won't waste any time benchmarking them, nor will we evict useful entries from the global cache.", "body": "I really like this idea. I think fast-by-default is important: both in terms of start-up time and speed of convolutions. Many researchers don't know or forget about the cudnn.benchmark flag.\r\n\r\nThere are a few simple things we can do to make this reasonable:\r\n1) Limit the size of the global cache (evict old entries)\r\n2) Only benchmark a convolution after we see the same shape \"key\" multiple times. We can keep the count in another in-memory LRU cache with a smaller size than the global cache.\r\n\r\n(2) is a variation of @apaszke's \"weakly on\" by default. (We might be saying the same thing). It means that if we see many variations of input shapes, we won't waste any time benchmarking them, nor will we evict useful entries from the global cache."}