{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189372131", "pull_request_review_id": 121546111, "id": 189372131, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4OTM3MjEzMQ==", "diff_hunk": "@@ -65,132 +65,128 @@ def set_printoptions(\n         PRINT_OPTS.linewidth = linewidth\n \n \n-def _get_min_log_scale():\n-    min_positive = float_info.min * float_info.epsilon  # get smallest denormal\n-    if min_positive == 0:  # use smallest normal if DAZ/FTZ is set\n-        min_positive = float_info.min\n-    return math.ceil(math.log(min_positive, 10))\n+class _Formatter(object):\n+    def __init__(self, tensor):\n+        tensor = tensor.view(tensor.nelement())", "path": "torch/_tensor_str.py", "position": null, "original_position": 11, "commit_id": "10f7365bedb1b558eb54600e42c9300eda3c28f3", "original_commit_id": "106c33422ad109fcc5743bc11da68ac435f840ab", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "this isn't right, see the failing tests (you have to make the tensor contiguous).  What's the advantage of this over the old code given you may have to make the entire tensor contiguous?", "created_at": "2018-05-18T19:31:14Z", "updated_at": "2018-11-23T15:44:17Z", "html_url": "https://github.com/pytorch/pytorch/pull/7632#discussion_r189372131", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7632", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/189372131"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7632#discussion_r189372131"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7632"}}, "body_html": "<p>this isn't right, see the failing tests (you have to make the tensor contiguous).  What's the advantage of this over the old code given you may have to make the entire tensor contiguous?</p>", "body_text": "this isn't right, see the failing tests (you have to make the tensor contiguous).  What's the advantage of this over the old code given you may have to make the entire tensor contiguous?"}