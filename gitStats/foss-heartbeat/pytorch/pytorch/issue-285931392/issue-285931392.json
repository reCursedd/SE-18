{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4472", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4472/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4472/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4472/events", "html_url": "https://github.com/pytorch/pytorch/issues/4472", "id": 285931392, "node_id": "MDU6SXNzdWUyODU5MzEzOTI=", "number": 4472, "title": "Build Error: no matching function for call to setattr(torch::jit::Node*&, ...)", "user": {"login": "araffin", "id": 1973948, "node_id": "MDQ6VXNlcjE5NzM5NDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1973948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/araffin", "html_url": "https://github.com/araffin", "followers_url": "https://api.github.com/users/araffin/followers", "following_url": "https://api.github.com/users/araffin/following{/other_user}", "gists_url": "https://api.github.com/users/araffin/gists{/gist_id}", "starred_url": "https://api.github.com/users/araffin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/araffin/subscriptions", "organizations_url": "https://api.github.com/users/araffin/orgs", "repos_url": "https://api.github.com/users/araffin/repos", "events_url": "https://api.github.com/users/araffin/events{/privacy}", "received_events_url": "https://api.github.com/users/araffin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-04T09:50:57Z", "updated_at": "2018-01-05T12:08:57Z", "closed_at": "2018-01-04T13:45:39Z", "author_association": "NONE", "body_html": "<p>Hello,<br>\nI'm trying to build pytorch (I tried both v3_buildfix and master branch) on a raspberry pi 3 but i'm getting that error:</p>\n<pre><code>torch/csrc/autograd/generated/VariableType.cpp: In member function \u2018virtual std::tuple&lt;at::Tensor, at::Tensor&gt; torch::autograd::VariableType::prelu_backward(const at::Tensor&amp;, const at::Tensor&amp;, const at::Tensor&amp;, std::array&lt;bool, 2u&gt;) const\u2019:\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: error: no matching function for call to \u2018setattr(torch::jit::Node*&amp;, torch::jit::Symbol, std::array&lt;bool, 2u&gt;&amp;)\u2019\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\n                                                                 ^\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, int64_t)\n static void setattr(jit::Node* n, jit::Symbol name, int64_t v)            \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note:   no known conversion for argument 3 from \u2018std::array&lt;bool, 2u&gt;\u2019 to \u2018int64_t {aka long long int}\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const at::Scalar&amp;)\n static void setattr(jit::Node* n, jit::Symbol name, const at::Scalar&amp; v)  \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note:   no known conversion for argument 3 from \u2018std::array&lt;bool, 2u&gt;\u2019 to \u2018const at::Scalar&amp;\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const IntList&amp;)\n static void setattr(jit::Node* n, jit::Symbol name, const at::IntList&amp; v) \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note:   no known conversion for argument 3 from \u2018std::array&lt;bool, 2u&gt;\u2019 to \u2018const IntList&amp; {aka const at::ArrayRef&lt;long long int&gt;&amp;}\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, bool)\n static void setattr(jit::Node* n, jit::Symbol name, bool v)               \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note:   no known conversion for argument 3 from \u2018std::array&lt;bool, 2u&gt;\u2019 to \u2018bool\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, double)\n static void setattr(jit::Node* n, jit::Symbol name, double v)             \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note:   no known conversion for argument 3 from \u2018std::array&lt;bool, 2u&gt;\u2019 to \u2018double\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note: candidate: template&lt;long unsigned int N&gt; void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, std::array&lt;bool, N&gt;)\n static void setattr(jit::Node* n, jit::Symbol name, std::array&lt;bool, N&gt; v)\n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note:   template argument deduction/substitution failed:\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: note:   mismatched types \u2018long unsigned int\u2019 and \u2018unsigned int\u2019\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\n\n\nerror: command 'arm-linux-gnueabihf-gcc' failed with exit status 1arm-linux-gnueabihf-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/home/enstar/pytorch -I/home/enstar/pytorch/torch/csrc -I/home/enstar/pytorch/torch/lib/pybind11/include -I/home/enstar/pytorch/torch/lib/tmp_install/include -I/home/enstar/pytorch/torch/lib/tmp_install/include/TH -I/home/enstar/pytorch/torch/lib/tmp_install/include/THNN -I/home/enstar/pytorch/torch/lib/tmp_install/include/ATen -I/home/enstar/.local/lib/python2.7/site-packages/numpy/core/include -I/usr/include/python2.7 -c torch/csrc/autograd/functions/convolution.cpp -o build/temp.linux-armv7l-2.7/torch/csrc/autograd/functions/convolution.o -D_THP_CORE -std=c++11 -Wno-write-strings -fno-strict-aliasing -Wno-missing-braces -DWITH_NUMPY\n\n</code></pre>\n<p>Note: I'm building without CUDA and DISTRIBUTED support.</p>\n<p>OS:  Ubuntu 16.04 (Mate)<br>\ngcc: arm-linux-gnueabihf-gcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609<br>\ncmake:  v3.5.1</p>", "body_text": "Hello,\nI'm trying to build pytorch (I tried both v3_buildfix and master branch) on a raspberry pi 3 but i'm getting that error:\ntorch/csrc/autograd/generated/VariableType.cpp: In member function \u2018virtual std::tuple<at::Tensor, at::Tensor> torch::autograd::VariableType::prelu_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, std::array<bool, 2u>) const\u2019:\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: error: no matching function for call to \u2018setattr(torch::jit::Node*&, torch::jit::Symbol, std::array<bool, 2u>&)\u2019\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\n                                                                 ^\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, int64_t)\n static void setattr(jit::Node* n, jit::Symbol name, int64_t v)            \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018int64_t {aka long long int}\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const at::Scalar&)\n static void setattr(jit::Node* n, jit::Symbol name, const at::Scalar& v)  \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018const at::Scalar&\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const IntList&)\n static void setattr(jit::Node* n, jit::Symbol name, const at::IntList& v) \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018const IntList& {aka const at::ArrayRef<long long int>&}\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, bool)\n static void setattr(jit::Node* n, jit::Symbol name, bool v)               \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018bool\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, double)\n static void setattr(jit::Node* n, jit::Symbol name, double v)             \n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018double\u2019\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note: candidate: template<long unsigned int N> void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, std::array<bool, N>)\n static void setattr(jit::Node* n, jit::Symbol name, std::array<bool, N> v)\n             ^\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note:   template argument deduction/substitution failed:\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: note:   mismatched types \u2018long unsigned int\u2019 and \u2018unsigned int\u2019\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\n\n\nerror: command 'arm-linux-gnueabihf-gcc' failed with exit status 1arm-linux-gnueabihf-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/home/enstar/pytorch -I/home/enstar/pytorch/torch/csrc -I/home/enstar/pytorch/torch/lib/pybind11/include -I/home/enstar/pytorch/torch/lib/tmp_install/include -I/home/enstar/pytorch/torch/lib/tmp_install/include/TH -I/home/enstar/pytorch/torch/lib/tmp_install/include/THNN -I/home/enstar/pytorch/torch/lib/tmp_install/include/ATen -I/home/enstar/.local/lib/python2.7/site-packages/numpy/core/include -I/usr/include/python2.7 -c torch/csrc/autograd/functions/convolution.cpp -o build/temp.linux-armv7l-2.7/torch/csrc/autograd/functions/convolution.o -D_THP_CORE -std=c++11 -Wno-write-strings -fno-strict-aliasing -Wno-missing-braces -DWITH_NUMPY\n\n\nNote: I'm building without CUDA and DISTRIBUTED support.\nOS:  Ubuntu 16.04 (Mate)\ngcc: arm-linux-gnueabihf-gcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\ncmake:  v3.5.1", "body": "Hello,\r\nI'm trying to build pytorch (I tried both v3_buildfix and master branch) on a raspberry pi 3 but i'm getting that error:\r\n\r\n```\r\ntorch/csrc/autograd/generated/VariableType.cpp: In member function \u2018virtual std::tuple<at::Tensor, at::Tensor> torch::autograd::VariableType::prelu_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, std::array<bool, 2u>) const\u2019:\r\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: error: no matching function for call to \u2018setattr(torch::jit::Node*&, torch::jit::Symbol, std::array<bool, 2u>&)\u2019\r\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\r\n                                                                 ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, int64_t)\r\n static void setattr(jit::Node* n, jit::Symbol name, int64_t v)            \r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:32:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018int64_t {aka long long int}\u2019\r\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const at::Scalar&)\r\n static void setattr(jit::Node* n, jit::Symbol name, const at::Scalar& v)  \r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:33:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018const at::Scalar&\u2019\r\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, const IntList&)\r\n static void setattr(jit::Node* n, jit::Symbol name, const at::IntList& v) \r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:34:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018const IntList& {aka const at::ArrayRef<long long int>&}\u2019\r\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, bool)\r\n static void setattr(jit::Node* n, jit::Symbol name, bool v)               \r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:35:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018bool\u2019\r\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note: candidate: void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, double)\r\n static void setattr(jit::Node* n, jit::Symbol name, double v)             \r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:36:13: note:   no known conversion for argument 3 from \u2018std::array<bool, 2u>\u2019 to \u2018double\u2019\r\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note: candidate: template<long unsigned int N> void torch::autograd::setattr(torch::jit::Node*, torch::jit::Symbol, std::array<bool, N>)\r\n static void setattr(jit::Node* n, jit::Symbol name, std::array<bool, N> v)\r\n             ^\r\ntorch/csrc/autograd/generated/VariableType.cpp:38:13: note:   template argument deduction/substitution failed:\r\ntorch/csrc/autograd/generated/VariableType.cpp:6114:65: note:   mismatched types \u2018long unsigned int\u2019 and \u2018unsigned int\u2019\r\n       setattr(n, jit::stringToSymbol(\"output_mask\"), output_mask);\r\n\r\n\r\nerror: command 'arm-linux-gnueabihf-gcc' failed with exit status 1arm-linux-gnueabihf-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/home/enstar/pytorch -I/home/enstar/pytorch/torch/csrc -I/home/enstar/pytorch/torch/lib/pybind11/include -I/home/enstar/pytorch/torch/lib/tmp_install/include -I/home/enstar/pytorch/torch/lib/tmp_install/include/TH -I/home/enstar/pytorch/torch/lib/tmp_install/include/THNN -I/home/enstar/pytorch/torch/lib/tmp_install/include/ATen -I/home/enstar/.local/lib/python2.7/site-packages/numpy/core/include -I/usr/include/python2.7 -c torch/csrc/autograd/functions/convolution.cpp -o build/temp.linux-armv7l-2.7/torch/csrc/autograd/functions/convolution.o -D_THP_CORE -std=c++11 -Wno-write-strings -fno-strict-aliasing -Wno-missing-braces -DWITH_NUMPY\r\n\r\n```\r\nNote: I'm building without CUDA and DISTRIBUTED support.\r\n\r\nOS:  Ubuntu 16.04 (Mate)\r\ngcc: arm-linux-gnueabihf-gcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\ncmake:  v3.5.1"}