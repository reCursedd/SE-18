{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11309", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11309/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11309/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11309/events", "html_url": "https://github.com/pytorch/pytorch/issues/11309", "id": 357440215, "node_id": "MDU6SXNzdWUzNTc0NDAyMTU=", "number": 11309, "title": "Cannot build from source", "user": {"login": "labor00", "id": 36332518, "node_id": "MDQ6VXNlcjM2MzMyNTE4", "avatar_url": "https://avatars3.githubusercontent.com/u/36332518?v=4", "gravatar_id": "", "url": "https://api.github.com/users/labor00", "html_url": "https://github.com/labor00", "followers_url": "https://api.github.com/users/labor00/followers", "following_url": "https://api.github.com/users/labor00/following{/other_user}", "gists_url": "https://api.github.com/users/labor00/gists{/gist_id}", "starred_url": "https://api.github.com/users/labor00/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/labor00/subscriptions", "organizations_url": "https://api.github.com/users/labor00/orgs", "repos_url": "https://api.github.com/users/labor00/repos", "events_url": "https://api.github.com/users/labor00/events{/privacy}", "received_events_url": "https://api.github.com/users/labor00/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-05T23:30:26Z", "updated_at": "2018-09-07T03:05:11Z", "closed_at": "2018-09-07T03:05:11Z", "author_association": "NONE", "body_html": "<p>I got this error when trying to build pytorch from master</p>\n<div class=\"highlight highlight-source-shell\"><pre>In file included from ../caffe2/core/logging.h:27:0,\n                 from ../caffe2/core/types.h:9,\n                 from ../caffe2/utils/math.h:17,\n                 from ../caffe2/utils/math_cpu.cc:14:\n../caffe2/utils/math_cpu.cc: In <span class=\"pl-k\">function</span> <span class=\"pl-en\">\u2018void</span> caffe2::math::GemmEx(CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, T, const T<span class=\"pl-k\">*</span>, int, const T<span class=\"pl-k\">*</span>, int, T, T<span class=\"pl-k\">*</span>, int, Context<span class=\"pl-k\">*</span>) [with T <span class=\"pl-k\">=</span> float<span class=\"pl-k\">;</span> Context <span class=\"pl-k\">=</span> caffe2::CPUContext<span class=\"pl-k\">;</span> Engine <span class=\"pl-k\">=</span> caffe2::DefaultEngine]\u2019:\n../caffe2/core/logging_is_not_google_glog.h:93:15: warning: this statement may fall through [-Wimplicit-fallthrough<span class=\"pl-k\">=</span>]\n     ::caffe2::MessageLogger<span class=\"pl-s\"><span class=\"pl-pds\">((</span>char<span class=\"pl-k\">*</span>)__FILE__<span class=\"pl-k\">,</span> __LINE__<span class=\"pl-k\">,</span> n).stream()</span>\n<span class=\"pl-s\">               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>\n<span class=\"pl-s\">../caffe<span class=\"pl-c1\">2</span>/utils/math_cpu.cc:<span class=\"pl-c1\">177</span>:<span class=\"pl-c1\">11</span>: note: in expansion of macro \u2018LOG\u2019</span>\n<span class=\"pl-s\">           LOG(FATAL) &lt;&lt; \"Unexpected CBLAS_TRANSPOSE for trans_B\";</span>\n<span class=\"pl-s\">           ^</span>\n<span class=\"pl-s\">../caffe<span class=\"pl-c1\">2</span>/utils/math_cpu.cc:<span class=\"pl-c1\">180</span>:<span class=\"pl-c1\">5</span>: note: here</span>\n<span class=\"pl-s\">     case CblasTrans: {</span>\n<span class=\"pl-s\">     ^~~~</span>\n<span class=\"pl-s\">In file included from ../caffe<span class=\"pl-c1\">2</span>/core/logging.h:<span class=\"pl-c1\">27</span>:<span class=\"pl-c1\">0</span>,</span>\n<span class=\"pl-s\">                 from ../caffe<span class=\"pl-c1\">2</span>/core/types.h:<span class=\"pl-c1\">9</span>,</span>\n<span class=\"pl-s\">                 from ../caffe<span class=\"pl-c1\">2</span>/utils/math.h:<span class=\"pl-c1\">17</span>,</span>\n<span class=\"pl-s\">                 from ../caffe<span class=\"pl-c1\">2</span>/utils/math_cpu.cc:<span class=\"pl-c1\">14</span>:</span>\n<span class=\"pl-s\">../caffe<span class=\"pl-c1\">2</span>/core/logging_is_not_google_glog.h:<span class=\"pl-c1\">93</span>:<span class=\"pl-c1\">15</span>: warning: this statement may fall through [-Wimplicit-fallthrough=]</span>\n<span class=\"pl-s\">     ::caffe<span class=\"pl-c1\">2</span>::MessageLogger((char*)__FILE__, __LINE__, n).stream()</span>\n<span class=\"pl-s\">               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>\n<span class=\"pl-s\">../caffe<span class=\"pl-c1\">2</span>/utils/math_cpu.cc:<span class=\"pl-c1\">200</span>:<span class=\"pl-c1\">11</span>: note: in expansion of macro \u2018LOG\u2019</span>\n<span class=\"pl-s\">           LOG(FATAL) &lt;&lt; \"Unexpected CBLAS_TRANSPOSE for trans_B\";</span>\n<span class=\"pl-s\">           ^</span>\n<span class=\"pl-s\">../caffe<span class=\"pl-c1\">2</span>/utils/math_cpu.cc:<span class=\"pl-c1\">203</span>:<span class=\"pl-c1\">5</span>: note: here</span>\n<span class=\"pl-s\">     default:</span>\n<span class=\"pl-s\">     ^~~~~~~</span>\n<span class=\"pl-s\">[<span class=\"pl-c1\">1184</span>/<span class=\"pl-c1\">1525</span>] Building NVCC (Device) object caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/caffe<span class=\"pl-c1\">2</span>_gpu_generated_logit_op.cu.o</span>\n<span class=\"pl-s\">FAILED: caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o </span>\n<span class=\"pl-s\">cd /home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators &amp;&amp; /usr/bin/cmake -E make_directory /home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/. &amp;&amp; /usr/bin/cmake -D verbose:BOOL=OFF -D build_configuration:STRING=Release -D generated_file:STRING=/home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/./caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o -D generated_cubin_file:STRING=/home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/./caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o.cubin.txt -P /home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o.Release.cmake</span>\n<span class=\"pl-s\"><span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>disk<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>.pytorch<span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>caffe<span class=\"pl-c1\">2</span><span class=\"pl-k\">/</span>operators<span class=\"pl-k\">/</span>utility_ops.h<span class=\"pl-k\">:</span> In member function \u2018bool caffe<span class=\"pl-c1\">2</span><span class=\"pl-k\">::</span>WeightedSumOp<span class=\"pl-k\">&lt;</span>Context<span class=\"pl-k\">&gt;::</span>DoRunWithType()\u2019<span class=\"pl-k\">:</span></span>\n<span class=\"pl-s\"><span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>disk<span class=\"pl-c1\">0</span><span class=\"pl-k\">/</span>.pytorch<span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>caffe<span class=\"pl-c1\">2</span><span class=\"pl-k\">/</span>operators<span class=\"pl-k\">/</span>utility_ops.h<span class=\"pl-k\">:</span><span class=\"pl-c1\">328</span><span class=\"pl-k\">:</span><span class=\"pl-c1\">55</span><span class=\"pl-k\">:</span> error<span class=\"pl-k\">:</span> cannot call member function \u2018int caffe<span class=\"pl-c1\">2</span><span class=\"pl-k\">::</span>OperatorBase<span class=\"pl-k\">::</span>InputSize() const\u2019 without object</span>\n<span class=\"pl-s\">     const int input_size = InputSize();</span>\n<span class=\"pl-s\">                        ~~~~~~~~~~~~~~~~               ^ </span>\n<span class=\"pl-s\">CMake Error at caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o.Release.cmake:<span class=\"pl-c1\">279</span> (message):</span>\n<span class=\"pl-s\">  Error generating file</span>\n<span class=\"pl-s\">  /home/disk<span class=\"pl-c1\">0</span>/.pytorch/pytorch/build/caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/./caffe<span class=\"pl-c1\">2</span>_gpu_generated_loss_op.cu.o</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">[<span class=\"pl-c1\">1191</span>/<span class=\"pl-c1\">1525</span>] Building NVCC (Device) object caffe<span class=\"pl-c1\">2</span>/CMakeFiles/caffe<span class=\"pl-c1\">2</span>_gpu.dir/operators/caffe<span class=\"pl-c1\">2</span>_gpu_generated_multi_class_accuracy_op.cu.o</span>\n<span class=\"pl-s\">ninja: build stopped: subcommand failed.</span>\n<span class=\"pl-s\">Failed to run 'bash ../tools/build_pytorch_libs.sh --use-cuda --use-nnpack nccl caffe<span class=\"pl-c1\">2</span> libshm gloo c<span class=\"pl-c1\">10</span>d THD'</span></pre></div>\n<p>Since for some time building pytorch also means to build   caffe2 is there any easy way to control where the the caffe2 installation look for libraries? For instance  I had to update the system version of the Eigen library instead of using -DCMAKE_DISABLE_FIND_PACKAGE_Eigen3 to force the build system to use the version in the third_party folder.</p>\n<p>thanks</p>\n<p>Collecting environment information...<br>\nPyTorch version: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/68c2e014cbb97b43f87819a0cdc295006b0e9bb6/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/68c2e014cbb97b43f87819a0cdc295006b0e9bb6\"><tt>68c2e01</tt></a><br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Fedora release 28 (Twenty Eight)<br>\nGCC version: (GCC) 7.3.0<br>\nCMake version: version 3.11.2</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.2.148<br>\nGPU models and configuration: GPU 0: GeForce GTX 1080<br>\nNvidia driver version: 396.45<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/cuda-9.2/lib64/libcudnn.so.7.2.1<br>\n/usr/local/cuda-9.2/lib64/libcudnn_static.a</p>", "body_text": "I got this error when trying to build pytorch from master\nIn file included from ../caffe2/core/logging.h:27:0,\n                 from ../caffe2/core/types.h:9,\n                 from ../caffe2/utils/math.h:17,\n                 from ../caffe2/utils/math_cpu.cc:14:\n../caffe2/utils/math_cpu.cc: In function \u2018void caffe2::math::GemmEx(CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, T, const T*, int, const T*, int, T, T*, int, Context*) [with T = float; Context = caffe2::CPUContext; Engine = caffe2::DefaultEngine]\u2019:\n../caffe2/core/logging_is_not_google_glog.h:93:15: warning: this statement may fall through [-Wimplicit-fallthrough=]\n     ::caffe2::MessageLogger((char*)__FILE__, __LINE__, n).stream()\n               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n../caffe2/utils/math_cpu.cc:177:11: note: in expansion of macro \u2018LOG\u2019\n           LOG(FATAL) << \"Unexpected CBLAS_TRANSPOSE for trans_B\";\n           ^\n../caffe2/utils/math_cpu.cc:180:5: note: here\n     case CblasTrans: {\n     ^~~~\nIn file included from ../caffe2/core/logging.h:27:0,\n                 from ../caffe2/core/types.h:9,\n                 from ../caffe2/utils/math.h:17,\n                 from ../caffe2/utils/math_cpu.cc:14:\n../caffe2/core/logging_is_not_google_glog.h:93:15: warning: this statement may fall through [-Wimplicit-fallthrough=]\n     ::caffe2::MessageLogger((char*)__FILE__, __LINE__, n).stream()\n               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n../caffe2/utils/math_cpu.cc:200:11: note: in expansion of macro \u2018LOG\u2019\n           LOG(FATAL) << \"Unexpected CBLAS_TRANSPOSE for trans_B\";\n           ^\n../caffe2/utils/math_cpu.cc:203:5: note: here\n     default:\n     ^~~~~~~\n[1184/1525] Building NVCC (Device) object caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_logit_op.cu.o\nFAILED: caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_loss_op.cu.o \ncd /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators && /usr/bin/cmake -E make_directory /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/. && /usr/bin/cmake -D verbose:BOOL=OFF -D build_configuration:STRING=Release -D generated_file:STRING=/home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o -D generated_cubin_file:STRING=/home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o.cubin.txt -P /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_loss_op.cu.o.Release.cmake\n/home/disk0/.pytorch/pytorch/caffe2/operators/utility_ops.h: In member function \u2018bool caffe2::WeightedSumOp<Context>::DoRunWithType()\u2019:\n/home/disk0/.pytorch/pytorch/caffe2/operators/utility_ops.h:328:55: error: cannot call member function \u2018int caffe2::OperatorBase::InputSize() const\u2019 without object\n     const int input_size = InputSize();\n                        ~~~~~~~~~~~~~~~~               ^ \nCMake Error at caffe2_gpu_generated_loss_op.cu.o.Release.cmake:279 (message):\n  Error generating file\n  /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o\n\n\n[1191/1525] Building NVCC (Device) object caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_multi_class_accuracy_op.cu.o\nninja: build stopped: subcommand failed.\nFailed to run 'bash ../tools/build_pytorch_libs.sh --use-cuda --use-nnpack nccl caffe2 libshm gloo c10d THD'\nSince for some time building pytorch also means to build   caffe2 is there any easy way to control where the the caffe2 installation look for libraries? For instance  I had to update the system version of the Eigen library instead of using -DCMAKE_DISABLE_FIND_PACKAGE_Eigen3 to force the build system to use the version in the third_party folder.\nthanks\nCollecting environment information...\nPyTorch version: 68c2e01\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Fedora release 28 (Twenty Eight)\nGCC version: (GCC) 7.3.0\nCMake version: version 3.11.2\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.148\nGPU models and configuration: GPU 0: GeForce GTX 1080\nNvidia driver version: 396.45\ncuDNN version: Probably one of the following:\n/usr/local/cuda-9.2/lib64/libcudnn.so.7.2.1\n/usr/local/cuda-9.2/lib64/libcudnn_static.a", "body": "I got this error when trying to build pytorch from master\r\n```bash\r\nIn file included from ../caffe2/core/logging.h:27:0,\r\n                 from ../caffe2/core/types.h:9,\r\n                 from ../caffe2/utils/math.h:17,\r\n                 from ../caffe2/utils/math_cpu.cc:14:\r\n../caffe2/utils/math_cpu.cc: In function \u2018void caffe2::math::GemmEx(CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, int, int, int, T, const T*, int, const T*, int, T, T*, int, Context*) [with T = float; Context = caffe2::CPUContext; Engine = caffe2::DefaultEngine]\u2019:\r\n../caffe2/core/logging_is_not_google_glog.h:93:15: warning: this statement may fall through [-Wimplicit-fallthrough=]\r\n     ::caffe2::MessageLogger((char*)__FILE__, __LINE__, n).stream()\r\n               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n../caffe2/utils/math_cpu.cc:177:11: note: in expansion of macro \u2018LOG\u2019\r\n           LOG(FATAL) << \"Unexpected CBLAS_TRANSPOSE for trans_B\";\r\n           ^\r\n../caffe2/utils/math_cpu.cc:180:5: note: here\r\n     case CblasTrans: {\r\n     ^~~~\r\nIn file included from ../caffe2/core/logging.h:27:0,\r\n                 from ../caffe2/core/types.h:9,\r\n                 from ../caffe2/utils/math.h:17,\r\n                 from ../caffe2/utils/math_cpu.cc:14:\r\n../caffe2/core/logging_is_not_google_glog.h:93:15: warning: this statement may fall through [-Wimplicit-fallthrough=]\r\n     ::caffe2::MessageLogger((char*)__FILE__, __LINE__, n).stream()\r\n               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n../caffe2/utils/math_cpu.cc:200:11: note: in expansion of macro \u2018LOG\u2019\r\n           LOG(FATAL) << \"Unexpected CBLAS_TRANSPOSE for trans_B\";\r\n           ^\r\n../caffe2/utils/math_cpu.cc:203:5: note: here\r\n     default:\r\n     ^~~~~~~\r\n[1184/1525] Building NVCC (Device) object caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_logit_op.cu.o\r\nFAILED: caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_loss_op.cu.o \r\ncd /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators && /usr/bin/cmake -E make_directory /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/. && /usr/bin/cmake -D verbose:BOOL=OFF -D build_configuration:STRING=Release -D generated_file:STRING=/home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o -D generated_cubin_file:STRING=/home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o.cubin.txt -P /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_loss_op.cu.o.Release.cmake\r\n/home/disk0/.pytorch/pytorch/caffe2/operators/utility_ops.h: In member function \u2018bool caffe2::WeightedSumOp<Context>::DoRunWithType()\u2019:\r\n/home/disk0/.pytorch/pytorch/caffe2/operators/utility_ops.h:328:55: error: cannot call member function \u2018int caffe2::OperatorBase::InputSize() const\u2019 without object\r\n     const int input_size = InputSize();\r\n                        ~~~~~~~~~~~~~~~~               ^ \r\nCMake Error at caffe2_gpu_generated_loss_op.cu.o.Release.cmake:279 (message):\r\n  Error generating file\r\n  /home/disk0/.pytorch/pytorch/build/caffe2/CMakeFiles/caffe2_gpu.dir/operators/./caffe2_gpu_generated_loss_op.cu.o\r\n\r\n\r\n[1191/1525] Building NVCC (Device) object caffe2/CMakeFiles/caffe2_gpu.dir/operators/caffe2_gpu_generated_multi_class_accuracy_op.cu.o\r\nninja: build stopped: subcommand failed.\r\nFailed to run 'bash ../tools/build_pytorch_libs.sh --use-cuda --use-nnpack nccl caffe2 libshm gloo c10d THD'\r\n```\r\nSince for some time building pytorch also means to build   caffe2 is there any easy way to control where the the caffe2 installation look for libraries? For instance  I had to update the system version of the Eigen library instead of using -DCMAKE_DISABLE_FIND_PACKAGE_Eigen3 to force the build system to use the version in the third_party folder.\r\n\r\nthanks\r\n\r\nCollecting environment information...\r\nPyTorch version: 68c2e014cbb\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Fedora release 28 (Twenty Eight)\r\nGCC version: (GCC) 7.3.0\r\nCMake version: version 3.11.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.148\r\nGPU models and configuration: GPU 0: GeForce GTX 1080\r\nNvidia driver version: 396.45\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-9.2/lib64/libcudnn.so.7.2.1\r\n/usr/local/cuda-9.2/lib64/libcudnn_static.a"}