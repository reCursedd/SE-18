{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150396114", "pull_request_review_id": 75941306, "id": 150396114, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MDM5NjExNA==", "diff_hunk": "@@ -0,0 +1,288 @@\n+#include \"interpreter.h\"\n+#include \"torch/csrc/jit/ir.h\"\n+#include \"torch/csrc/jit/generated/aten_dispatch.h\"\n+#ifdef WITH_CUDA\n+#include \"torch/csrc/jit/fusion_compiler.h\"\n+#endif\n+\n+namespace torch { namespace jit {\n+\n+using InputList = const std::vector<at::Tensor> &;\n+using OutputList = std::vector<at::Tensor>&;\n+using Callback = std::function<void(InputList, OutputList)>;\n+// Returns a function implementing functionality of a given node,\n+// or nullptr if it's a no-op for autograd.\n+Callback getCallback(Node *node) {\n+  IR_IFM(node, PythonOp)\n+    throw NotImplementedException();\n+  IR_ELSEIFM(CppOp)\n+    throw NotImplementedException();\n+  IR_ELSEIF(Select)\n+    barf(\"getCallback() on select?\");\n+  IR_ELSEIF(FusionGroup)\n+#ifdef WITH_CUDA\n+    auto fusion_fn = sharedFusionCompiler().getOrCompile(*value->g(kSubgraph));\n+    return [fusion_fn](InputList inputs, OutputList outputs) {\n+      fusion_fn->launch(inputs, outputs);\n+    };\n+#else\n+    throw std::runtime_error(\"don't know how to execute FusionGroups without CUDA\");\n+#endif\n+  IR_ELSEIF(Constant)\n+    auto t = value->t(kvalue);\n+    return [t](InputList inputs, OutputList outputs) {\n+      outputs.push_back(t);\n+    };\n+  IR_ELSEIF(Undefined)\n+    return [](InputList inputs, OutputList outputs) {\n+      outputs.push_back(at::Tensor());\n+    };\n+  IR_ELSE()\n+    return getTensorOp(node).op;\n+  IR_END()\n+}\n+\n+\n+// We need some lists for inputs and outputs. To keep all the memory\n+// contiguous we allocate a single vector and use offsets into the vector\n+// which are stored in the RegList struct\n+// start is an offset into int_data of Function if this list is integers\n+// and bool_data of Function if this list is booleans (only free_flags)\n+struct RegList {\n+  int start;\n+  int size;\n+};\n+\n+struct UseList {\n+  // values to be used\n+  RegList values;\n+  // boolean flags indicating whether to free the Tensor after this use\n+  RegList free_flags;\n+};\n+\n+// one instruction plus meta-data\n+struct Instruction {\n+  Callback callback;\n+  UseList inputs;\n+  RegList outputs;\n+};\n+\n+struct Stage {\n+  RegList inputs; // inputs to define for the stage\n+  UseList outputs; // values consumed by the return\n+  std::vector<Instruction> instructions;\n+};\n+\n+// pre-processing that happens once per graph\n+struct FunctionImpl {\n+  FunctionImpl(std::shared_ptr<Graph> & graph)\n+  : graph(graph) {\n+    int64_t cur_stage = -1;\n+    size_t input_pos = 0;\n+    size_t output_pos = 0;\n+    // step 1: encode all operators and stages into registers and fill in\n+    // input/output lists\n+    for(auto node : graph->nodes()) {\n+      if(node->kind() == kSelect)\n+        continue;\n+      insertStagesTo(cur_stage, node->stage(), input_pos, output_pos);\n+      cur_stage = node->stage();\n+      stages.back().instructions.emplace_back();\n+      auto & inst = stages.back().instructions.back();\n+      intListBegin(inst.inputs.values);\n+      for(auto input : node->inputs()) {\n+        intListInsert(inst.inputs.values, getOrAllocateRegister(input, true));\n+      }\n+      intListBegin(inst.outputs);\n+      for(auto output : node->outputs()) {\n+        intListInsert(inst.outputs, getOrAllocateRegister(output));\n+      }\n+      inst.callback = getCallback(node);", "path": "torch/csrc/jit/interpreter.cpp", "position": null, "original_position": 100, "commit_id": "8421d51b4f4545fc569a2522ca31ebdb0796a7ac", "original_commit_id": "71f42be9e2351f659845bfda434e4d5b303f49e5", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Wouldn't it be more natural to just do\r\n```cpp\r\nInstruction inst;\r\n// initialize everything here\r\nstages.back().instructions.push_back(std::move(inst));\r\n```", "created_at": "2017-11-11T23:24:42Z", "updated_at": "2018-11-23T15:36:24Z", "html_url": "https://github.com/pytorch/pytorch/pull/3634#discussion_r150396114", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3634", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/150396114"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3634#discussion_r150396114"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3634"}}, "body_html": "<p>Wouldn't it be more natural to just do</p>\n<div class=\"highlight highlight-source-c++\"><pre>Instruction inst;\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> initialize everything here</span>\nstages.back().instructions.push_back(std::move(inst));</pre></div>", "body_text": "Wouldn't it be more natural to just do\nInstruction inst;\n// initialize everything here\nstages.back().instructions.push_back(std::move(inst));"}