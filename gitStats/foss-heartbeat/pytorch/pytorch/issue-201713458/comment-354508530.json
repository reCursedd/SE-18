{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/354508530", "html_url": "https://github.com/pytorch/pytorch/issues/488#issuecomment-354508530", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/488", "id": 354508530, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NDUwODUzMA==", "user": {"login": "hughperkins", "id": 123560, "node_id": "MDQ6VXNlcjEyMzU2MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/123560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughperkins", "html_url": "https://github.com/hughperkins", "followers_url": "https://api.github.com/users/hughperkins/followers", "following_url": "https://api.github.com/users/hughperkins/following{/other_user}", "gists_url": "https://api.github.com/users/hughperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughperkins/subscriptions", "organizations_url": "https://api.github.com/users/hughperkins/orgs", "repos_url": "https://api.github.com/users/hughperkins/repos", "events_url": "https://api.github.com/users/hughperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/hughperkins/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-29T22:37:50Z", "updated_at": "2018-01-01T20:48:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Oh, Arm. I see, you (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9366725\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mirh\">@mirh</a>) want to run pytorch models on arm, eg/ie on cell-phones?</p>\n<p>That makes sense. As to how to achieve that ... I reckon that:</p>\n<ul>\n<li>\n<ol>\n<li>port pytorch to work on arm gpus, and</li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>get pytorch to work on cellphones (maybe it does? but seems like something that at least ios would (strongly) discourage?)</li>\n</ol>\n</li>\n</ul>\n<p>... sounds hard. Training a model on a cell-phone sounds quite battery-draining. I wonder whether it might be worth focusing on runnign prediction on the phone, using a pre-trained model, and handle training in the cloud? Running networks on phones seems fairly standard. For example, Huawei is pretty into doing so, <a href=\"https://www.androidauthority.com/huawei-announces-kirin-970-797788/\" rel=\"nofollow\">https://www.androidauthority.com/huawei-announces-kirin-970-797788/</a> .</p>\n<p>There are probably ways and means to export trained models into various formats that can be run on a phone, maybe using something that the manufacturer provides.  For example, I think that this is how one would use a Movidius usb key <a href=\"https://developer.movidius.com/\" rel=\"nofollow\">https://developer.movidius.com/</a> . And then there's also nnef <a href=\"https://www.khronos.org/nnef\" rel=\"nofollow\">https://www.khronos.org/nnef</a> (edit: and onnx :) )</p>", "body_text": "Oh, Arm. I see, you (@mirh) want to run pytorch models on arm, eg/ie on cell-phones?\nThat makes sense. As to how to achieve that ... I reckon that:\n\n\n\nport pytorch to work on arm gpus, and\n\n\n\n\nget pytorch to work on cellphones (maybe it does? but seems like something that at least ios would (strongly) discourage?)\n\n\n\n... sounds hard. Training a model on a cell-phone sounds quite battery-draining. I wonder whether it might be worth focusing on runnign prediction on the phone, using a pre-trained model, and handle training in the cloud? Running networks on phones seems fairly standard. For example, Huawei is pretty into doing so, https://www.androidauthority.com/huawei-announces-kirin-970-797788/ .\nThere are probably ways and means to export trained models into various formats that can be run on a phone, maybe using something that the manufacturer provides.  For example, I think that this is how one would use a Movidius usb key https://developer.movidius.com/ . And then there's also nnef https://www.khronos.org/nnef (edit: and onnx :) )", "body": "Oh, Arm. I see, you (@mirh) want to run pytorch models on arm, eg/ie on cell-phones?\r\n\r\nThat makes sense. As to how to achieve that ... I reckon that:\r\n\r\n- 1. port pytorch to work on arm gpus, and\r\n- 2. get pytorch to work on cellphones (maybe it does? but seems like something that at least ios would (strongly) discourage?)\r\n\r\n... sounds hard. Training a model on a cell-phone sounds quite battery-draining. I wonder whether it might be worth focusing on runnign prediction on the phone, using a pre-trained model, and handle training in the cloud? Running networks on phones seems fairly standard. For example, Huawei is pretty into doing so, https://www.androidauthority.com/huawei-announces-kirin-970-797788/ .\r\n\r\nThere are probably ways and means to export trained models into various formats that can be run on a phone, maybe using something that the manufacturer provides.  For example, I think that this is how one would use a Movidius usb key https://developer.movidius.com/ . And then there's also nnef https://www.khronos.org/nnef (edit: and onnx :) )"}