{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13538", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13538/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13538/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13538/events", "html_url": "https://github.com/pytorch/pytorch/pull/13538", "id": 377022751, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI4MDk5MzE1", "number": 13538, "title": "Duplicate bias blobs shared by different conv ops to handle scale correctly", "user": {"login": "viswanathgs", "id": 172884, "node_id": "MDQ6VXNlcjE3Mjg4NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/172884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/viswanathgs", "html_url": "https://github.com/viswanathgs", "followers_url": "https://api.github.com/users/viswanathgs/followers", "following_url": "https://api.github.com/users/viswanathgs/following{/other_user}", "gists_url": "https://api.github.com/users/viswanathgs/gists{/gist_id}", "starred_url": "https://api.github.com/users/viswanathgs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/viswanathgs/subscriptions", "organizations_url": "https://api.github.com/users/viswanathgs/orgs", "repos_url": "https://api.github.com/users/viswanathgs/repos", "events_url": "https://api.github.com/users/viswanathgs/events{/privacy}", "received_events_url": "https://api.github.com/users/viswanathgs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-03T04:41:13Z", "updated_at": "2018-11-04T12:17:08Z", "closed_at": "2018-11-04T12:17:08Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/13538", "html_url": "https://github.com/pytorch/pytorch/pull/13538", "diff_url": "https://github.com/pytorch/pytorch/pull/13538.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/13538.patch"}, "body_html": "<p>Summary:<br>\nIn architectures such as FPN (<a href=\"https://arxiv.org/abs/1612.03144\" rel=\"nofollow\">https://arxiv.org/abs/1612.03144</a>), few Conv<br>\nops share the same weight and bias and are run at different scales of<br>\nthe input. Since 'bias_scale = input_scale * weight_scale', sharing<br>\nthe same bias blob among multiple Conv ops means that we need<br>\ndifferent bias scale for each of the ops. To achieve this, we just<br>\nduplicate those bias blobs that are used by multiple Conv ops before performing<br>\nint8 rewrite.</p>\n<p>Reviewed By: csummersea</p>\n<p>Differential Revision: D12854062</p>", "body_text": "Summary:\nIn architectures such as FPN (https://arxiv.org/abs/1612.03144), few Conv\nops share the same weight and bias and are run at different scales of\nthe input. Since 'bias_scale = input_scale * weight_scale', sharing\nthe same bias blob among multiple Conv ops means that we need\ndifferent bias scale for each of the ops. To achieve this, we just\nduplicate those bias blobs that are used by multiple Conv ops before performing\nint8 rewrite.\nReviewed By: csummersea\nDifferential Revision: D12854062", "body": "Summary:\nIn architectures such as FPN (https://arxiv.org/abs/1612.03144), few Conv\nops share the same weight and bias and are run at different scales of\nthe input. Since 'bias_scale = input_scale * weight_scale', sharing\nthe same bias blob among multiple Conv ops means that we need\ndifferent bias scale for each of the ops. To achieve this, we just\nduplicate those bias blobs that are used by multiple Conv ops before performing\nint8 rewrite.\n\nReviewed By: csummersea\n\nDifferential Revision: D12854062\n"}