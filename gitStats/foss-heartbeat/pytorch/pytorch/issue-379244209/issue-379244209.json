{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13775", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13775/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13775/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13775/events", "html_url": "https://github.com/pytorch/pytorch/issues/13775", "id": 379244209, "node_id": "MDU6SXNzdWUzNzkyNDQyMDk=", "number": 13775, "title": "Dataset loader ToCuda() transform collate_fn fails", "user": {"login": "dizcza", "id": 7688337, "node_id": "MDQ6VXNlcjc2ODgzMzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7688337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dizcza", "html_url": "https://github.com/dizcza", "followers_url": "https://api.github.com/users/dizcza/followers", "following_url": "https://api.github.com/users/dizcza/following{/other_user}", "gists_url": "https://api.github.com/users/dizcza/gists{/gist_id}", "starred_url": "https://api.github.com/users/dizcza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dizcza/subscriptions", "organizations_url": "https://api.github.com/users/dizcza/orgs", "repos_url": "https://api.github.com/users/dizcza/repos", "events_url": "https://api.github.com/users/dizcza/events{/privacy}", "received_events_url": "https://api.github.com/users/dizcza/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-11-09T17:02:47Z", "updated_at": "2018-11-10T07:25:44Z", "closed_at": "2018-11-10T07:25:44Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>When moving <code>tensor = tensor.cuda()</code> in data preprocesing routine, loader <code>collate_fn</code> fails.<br>\nThe reason why I've moved <code>.cuda()</code> to data-loader is that I need to <code>torch.matmul(input, matrix)</code> each input batch, and the matrix is large. Doing so in CPU is slow.</p>\n<h2>To Reproduce</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.utils.data\n<span class=\"pl-k\">import</span> torchvision\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ToCuda</span>:\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">self</span>.is_cuda <span class=\"pl-k\">=</span> torch.cuda.is_available()\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">tensor</span>):\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.is_cuda:\n            tensor <span class=\"pl-k\">=</span> tensor.cuda()\n        <span class=\"pl-k\">return</span> tensor\n\ntransform <span class=\"pl-k\">=</span> torchvision.transforms.Compose([torchvision.transforms.ToTensor(), ToCuda()])\ndataset <span class=\"pl-k\">=</span> torchvision.datasets.MNIST(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../data<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">transform</span><span class=\"pl-k\">=</span>transform)\nloader <span class=\"pl-k\">=</span> torch.utils.data.DataLoader(dataset, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>, <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n\nmodel <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">784</span>, <span class=\"pl-c1\">10</span>)\nmodel <span class=\"pl-k\">=</span> model.cuda()\n\n<span class=\"pl-k\">for</span> images, labels <span class=\"pl-k\">in</span> loader:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>it works<span class=\"pl-pds\">'</span></span>)</pre></div>\n<h2>Expected behavior</h2>\n<p>It prints 'it works' a few times.</p>\n<p>Traceback.</p>\n<pre><code>/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \n    Found GPU0 GeForce GTX 760 which is of cuda capability 3.0.\n    PyTorch no longer supports this GPU because it is too old.\n    \n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\nTHCudaCheck FAIL file=/tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp line=508 error=3 : initialization error\nTraceback (most recent call last):\n  File \"gpu_transform.py\", line 25, in &lt;module&gt;\n    for images, labels in loader:\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 339, in __next__\n    return self._process_next_batch(batch)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 360, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in &lt;listcomp&gt;\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\", line 77, in __getitem__\n    img = self.transform(img)\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"gpu_transform.py\", line 13, in __call__\n    tensor = tensor.cuda()\nRuntimeError: cuda runtime error (3) : initialization error at /tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp:508\n</code></pre>\n<p>If I change <code>num_workers = 0</code>, everything works. If I don't use <code>ToCuda()</code> transform, it works fine as well.</p>\n<h2>Environment</h2>\n<p>pytorch v0.4.1 built from source (tag 0.4.1) in Ubuntu 16.04 docker.<br>\ntorchvision 0.2.1<br>\npython 3.6.6 (conda)<br>\nOS: Ubuntu 18.04</p>\n<ul>\n<li>Build command you used (if compiling from source): default config</li>\n</ul>", "body_text": "\ud83d\udc1b Bug\nWhen moving tensor = tensor.cuda() in data preprocesing routine, loader collate_fn fails.\nThe reason why I've moved .cuda() to data-loader is that I need to torch.matmul(input, matrix) each input batch, and the matrix is large. Doing so in CPU is slow.\nTo Reproduce\nimport torch\nimport torch.utils.data\nimport torchvision\n\nclass ToCuda:\n\n    def __init__(self):\n        self.is_cuda = torch.cuda.is_available()\n\n    def __call__(self, tensor):\n        if self.is_cuda:\n            tensor = tensor.cuda()\n        return tensor\n\ntransform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), ToCuda()])\ndataset = torchvision.datasets.MNIST('../data', transform=transform)\nloader = torch.utils.data.DataLoader(dataset, batch_size=256, num_workers=1)\n\nmodel = torch.nn.Linear(784, 10)\nmodel = model.cuda()\n\nfor images, labels in loader:\n    print('it works')\nExpected behavior\nIt prints 'it works' a few times.\nTraceback.\n/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \n    Found GPU0 GeForce GTX 760 which is of cuda capability 3.0.\n    PyTorch no longer supports this GPU because it is too old.\n    \n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\nTHCudaCheck FAIL file=/tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp line=508 error=3 : initialization error\nTraceback (most recent call last):\n  File \"gpu_transform.py\", line 25, in <module>\n    for images, labels in loader:\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 339, in __next__\n    return self._process_next_batch(batch)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 360, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nRuntimeError: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\", line 77, in __getitem__\n    img = self.transform(img)\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"gpu_transform.py\", line 13, in __call__\n    tensor = tensor.cuda()\nRuntimeError: cuda runtime error (3) : initialization error at /tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp:508\n\nIf I change num_workers = 0, everything works. If I don't use ToCuda() transform, it works fine as well.\nEnvironment\npytorch v0.4.1 built from source (tag 0.4.1) in Ubuntu 16.04 docker.\ntorchvision 0.2.1\npython 3.6.6 (conda)\nOS: Ubuntu 18.04\n\nBuild command you used (if compiling from source): default config", "body": "## \ud83d\udc1b Bug\r\n\r\nWhen moving `tensor = tensor.cuda()` in data preprocesing routine, loader `collate_fn` fails.\r\nThe reason why I've moved `.cuda()` to data-loader is that I need to `torch.matmul(input, matrix)` each input batch, and the matrix is large. Doing so in CPU is slow.\r\n\r\n## To Reproduce\r\n\r\n```python\r\nimport torch\r\nimport torch.utils.data\r\nimport torchvision\r\n\r\nclass ToCuda:\r\n\r\n    def __init__(self):\r\n        self.is_cuda = torch.cuda.is_available()\r\n\r\n    def __call__(self, tensor):\r\n        if self.is_cuda:\r\n            tensor = tensor.cuda()\r\n        return tensor\r\n\r\ntransform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), ToCuda()])\r\ndataset = torchvision.datasets.MNIST('../data', transform=transform)\r\nloader = torch.utils.data.DataLoader(dataset, batch_size=256, num_workers=1)\r\n\r\nmodel = torch.nn.Linear(784, 10)\r\nmodel = model.cuda()\r\n\r\nfor images, labels in loader:\r\n    print('it works')\r\n```\r\n\r\n## Expected behavior\r\nIt prints 'it works' a few times.\r\n\r\nTraceback.\r\n\r\n```\r\n/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \r\n    Found GPU0 GeForce GTX 760 which is of cuda capability 3.0.\r\n    PyTorch no longer supports this GPU because it is too old.\r\n    \r\n  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\r\nTHCudaCheck FAIL file=/tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp line=508 error=3 : initialization error\r\nTraceback (most recent call last):\r\n  File \"gpu_transform.py\", line 25, in <module>\r\n    for images, labels in loader:\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 339, in __next__\r\n    return self._process_next_batch(batch)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 360, in _process_next_batch\r\n    raise batch.exc_type(batch.exc_msg)\r\nRuntimeError: Traceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in _worker_loop\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 113, in <listcomp>\r\n    samples = collate_fn([dataset[i] for i in batch_indices])\r\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\", line 77, in __getitem__\r\n    img = self.transform(img)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\r\n    img = t(img)\r\n  File \"gpu_transform.py\", line 13, in __call__\r\n    tensor = tensor.cuda()\r\nRuntimeError: cuda runtime error (3) : initialization error at /tmp/pip-req-build-g4r2xzft/aten/src/THC/THCCachingAllocator.cpp:508\r\n```\r\n\r\nIf I change `num_workers = 0`, everything works. If I don't use `ToCuda()` transform, it works fine as well.\r\n\r\n## Environment\r\n\r\npytorch v0.4.1 built from source (tag 0.4.1) in Ubuntu 16.04 docker.\r\ntorchvision 0.2.1\r\npython 3.6.6 (conda)\r\nOS: Ubuntu 18.04\r\n\r\n - Build command you used (if compiling from source): default config\r\n"}