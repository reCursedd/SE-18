{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/437480718", "html_url": "https://github.com/pytorch/pytorch/issues/13775#issuecomment-437480718", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13775", "id": 437480718, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzQ4MDcxOA==", "user": {"login": "dizcza", "id": 7688337, "node_id": "MDQ6VXNlcjc2ODgzMzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/7688337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dizcza", "html_url": "https://github.com/dizcza", "followers_url": "https://api.github.com/users/dizcza/followers", "following_url": "https://api.github.com/users/dizcza/following{/other_user}", "gists_url": "https://api.github.com/users/dizcza/gists{/gist_id}", "starred_url": "https://api.github.com/users/dizcza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dizcza/subscriptions", "organizations_url": "https://api.github.com/users/dizcza/orgs", "repos_url": "https://api.github.com/users/dizcza/repos", "events_url": "https://api.github.com/users/dizcza/events{/privacy}", "received_events_url": "https://api.github.com/users/dizcza/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-09T20:09:31Z", "updated_at": "2018-11-09T20:09:31Z", "author_association": "NONE", "body_html": "<p>I don't find it in the link. Thanks for your help. I suppose I should add this line before I import torchvision, right? Because, if I import torchvision first and then include this line with the rest of the code under <code>if __name__ == \"__main__\"</code>, it gives</p>\n<pre><code>Traceback (most recent call last):\n  File \"gpu_transform.py\", line 8, in &lt;module&gt;\n    torch.multiprocessing.set_start_method('spawn')\n  File \"/opt/conda/lib/python3.6/multiprocessing/context.py\", line 242, in set_start_method\n    raise RuntimeError('context has already been set')\nRuntimeError: context has already been set\n</code></pre>\n<p>I've also tried setting <code>force=True</code> flag. But it leads to</p>\n<pre><code>/opt/conda/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n</code></pre>\n<p>after the program is quit.</p>", "body_text": "I don't find it in the link. Thanks for your help. I suppose I should add this line before I import torchvision, right? Because, if I import torchvision first and then include this line with the rest of the code under if __name__ == \"__main__\", it gives\nTraceback (most recent call last):\n  File \"gpu_transform.py\", line 8, in <module>\n    torch.multiprocessing.set_start_method('spawn')\n  File \"/opt/conda/lib/python3.6/multiprocessing/context.py\", line 242, in set_start_method\n    raise RuntimeError('context has already been set')\nRuntimeError: context has already been set\n\nI've also tried setting force=True flag. But it leads to\n/opt/conda/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n  len(cache))\n\nafter the program is quit.", "body": "I don't find it in the link. Thanks for your help. I suppose I should add this line before I import torchvision, right? Because, if I import torchvision first and then include this line with the rest of the code under `if __name__ == \"__main__\"`, it gives\r\n```\r\nTraceback (most recent call last):\r\n  File \"gpu_transform.py\", line 8, in <module>\r\n    torch.multiprocessing.set_start_method('spawn')\r\n  File \"/opt/conda/lib/python3.6/multiprocessing/context.py\", line 242, in set_start_method\r\n    raise RuntimeError('context has already been set')\r\nRuntimeError: context has already been set\r\n```\r\nI've also tried setting `force=True` flag. But it leads to\r\n```\r\n/opt/conda/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n```\r\nafter the program is quit."}