{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157400128", "pull_request_review_id": 84034004, "id": 157400128, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NzQwMDEyOA==", "diff_hunk": "@@ -68,8 +143,73 @@ def forward(self, *inputs, **kwargs):\n         outputs = self.parallel_apply(replicas, inputs, kwargs)\n         return self.gather(outputs, self.output_device)\n \n+    def __getstate__(self):\n+        state = super(DataParallel, self).__getstate__().copy()\n+        del state['_invalidate_cache'], state['_replicas'], state['_orig_params'], \\\n+            state['_orig_buffers'], state['_repl_params'], state['_repl_buffers']\n+        return state\n+\n+    def __setstate__(self, state):\n+        super(DataParallel, self).__setstate__(state)\n+        self._init_cache()\n+\n     def replicate(self, module, device_ids):\n-        return replicate(module, device_ids)\n+        if not self._replicas:", "path": "torch/nn/parallel/data_parallel.py", "position": 115, "original_position": 112, "commit_id": "c5c1ea3f10708605a4db8f34fef481240a0c86e1", "original_commit_id": "b118a470ad6b58258f7a035fcfaea2b73402cab1", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "So, IIUC, all of these shenanigans are so that we don't break BC by having DataParallel end up with \"stale\" replicas when someone edits one of the submodules, correct?  Would it be possible to also add a \"no magic\" version of DataParallel which applies the breaking change but doesn't require all of these shenanigans to detect when to invalidate the cache?", "created_at": "2017-12-18T04:39:49Z", "updated_at": "2018-11-23T15:37:29Z", "html_url": "https://github.com/pytorch/pytorch/pull/4216#discussion_r157400128", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4216", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157400128"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4216#discussion_r157400128"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4216"}}, "body_html": "<p>So, IIUC, all of these shenanigans are so that we don't break BC by having DataParallel end up with \"stale\" replicas when someone edits one of the submodules, correct?  Would it be possible to also add a \"no magic\" version of DataParallel which applies the breaking change but doesn't require all of these shenanigans to detect when to invalidate the cache?</p>", "body_text": "So, IIUC, all of these shenanigans are so that we don't break BC by having DataParallel end up with \"stale\" replicas when someone edits one of the submodules, correct?  Would it be possible to also add a \"no magic\" version of DataParallel which applies the breaking change but doesn't require all of these shenanigans to detect when to invalidate the cache?"}