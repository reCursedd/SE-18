{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/424601225", "html_url": "https://github.com/pytorch/pytorch/issues/12006#issuecomment-424601225", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12006", "id": 424601225, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDYwMTIyNQ==", "user": {"login": "sundw2014", "id": 12440834, "node_id": "MDQ6VXNlcjEyNDQwODM0", "avatar_url": "https://avatars1.githubusercontent.com/u/12440834?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sundw2014", "html_url": "https://github.com/sundw2014", "followers_url": "https://api.github.com/users/sundw2014/followers", "following_url": "https://api.github.com/users/sundw2014/following{/other_user}", "gists_url": "https://api.github.com/users/sundw2014/gists{/gist_id}", "starred_url": "https://api.github.com/users/sundw2014/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sundw2014/subscriptions", "organizations_url": "https://api.github.com/users/sundw2014/orgs", "repos_url": "https://api.github.com/users/sundw2014/repos", "events_url": "https://api.github.com/users/sundw2014/events{/privacy}", "received_events_url": "https://api.github.com/users/sundw2014/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-26T06:34:16Z", "updated_at": "2018-09-26T07:14:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In this case, the shape of the input is <code>NxC</code>. If <code>N&gt;131070</code>, cuDNN can't handle it and it will be processed by THCUNN.</p>\n<p>According to the following code in THCUNN, it will be inefficient because <code>input.getSize(0) = N, input.getSize(2) = 1</code> and <code>N</code> is large. So <strong>2d input to <code>torch.nn.BatchNorm1d</code> will cause low utilization of GPU</strong>. To solve this problem, we can transpose and reshape the input to <code>1xCxN</code>. According to my test, cuDNN has the same problem.<br>\n<div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/8ff435c8f60033d6f7795202d145e738a551ee84/aten/src/THCUNN/BatchNormalization.cu#L171-L176\">pytorch/aten/src/THCUNN/BatchNormalization.cu</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 171 to 176\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/8ff435c8f60033d6f7795202d145e738a551ee84\">8ff435c</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L171\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"171\"></td>\n          <td id=\"LC171\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> batch = <span class=\"pl-c1\">0</span>; batch &lt; input.<span class=\"pl-c1\">getSize</span>(<span class=\"pl-c1\">0</span>); batch++) { </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L172\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"172\"></td>\n          <td id=\"LC172\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> x = <span class=\"pl-c1\">threadIdx</span>.<span class=\"pl-smi\">x</span>; x &lt; input.<span class=\"pl-c1\">getSize</span>(<span class=\"pl-c1\">2</span>); x += <span class=\"pl-c1\">blockDim</span>.<span class=\"pl-smi\">x</span>) { </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L173\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"173\"></td>\n          <td id=\"LC173\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     Dtype inp = input[batch][plane][x].<span class=\"pl-c1\">ldg</span>(); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L174\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"174\"></td>\n          <td id=\"LC174\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     output[batch][plane][x] = ScalarConvert&lt;Acctype, Dtype&gt;::<span class=\"pl-c1\">to</span>(<span class=\"pl-bu\">gamma</span> * (inp - mean) * invstd + beta); </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L175\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"175\"></td>\n          <td id=\"LC175\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">   } </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L176\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"176\"></td>\n          <td id=\"LC176\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> } </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>", "body_text": "In this case, the shape of the input is NxC. If N>131070, cuDNN can't handle it and it will be processed by THCUNN.\nAccording to the following code in THCUNN, it will be inefficient because input.getSize(0) = N, input.getSize(2) = 1 and N is large. So 2d input to torch.nn.BatchNorm1d will cause low utilization of GPU. To solve this problem, we can transpose and reshape the input to 1xCxN. According to my test, cuDNN has the same problem.\n\n  \n    \n      pytorch/aten/src/THCUNN/BatchNormalization.cu\n    \n    \n        Lines 171 to 176\n      in\n      8ff435c\n    \n    \n    \n    \n\n        \n          \n           for (int batch = 0; batch < input.getSize(0); batch++) { \n        \n\n        \n          \n             for (int x = threadIdx.x; x < input.getSize(2); x += blockDim.x) { \n        \n\n        \n          \n               Dtype inp = input[batch][plane][x].ldg(); \n        \n\n        \n          \n               output[batch][plane][x] = ScalarConvert<Acctype, Dtype>::to(gamma * (inp - mean) * invstd + beta); \n        \n\n        \n          \n             } \n        \n\n        \n          \n           }", "body": "In this case, the shape of the input is ```NxC```. If ```N>131070```, cuDNN can't handle it and it will be processed by THCUNN.\r\n\r\nAccording to the following code in THCUNN, it will be inefficient because ```input.getSize(0) = N, input.getSize(2) = 1``` and ```N``` is large. So __2d input to ```torch.nn.BatchNorm1d``` will cause low utilization of GPU__. To solve this problem, we can transpose and reshape the input to ```1xCxN```. According to my test, cuDNN has the same problem.\r\nhttps://github.com/pytorch/pytorch/blob/8ff435c8f60033d6f7795202d145e738a551ee84/aten/src/THCUNN/BatchNormalization.cu#L171-L176"}