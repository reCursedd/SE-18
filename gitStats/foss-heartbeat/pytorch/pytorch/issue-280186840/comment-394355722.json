{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/394355722", "html_url": "https://github.com/pytorch/pytorch/issues/4073#issuecomment-394355722", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4073", "id": 394355722, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDM1NTcyMg==", "user": {"login": "ClementPinard", "id": 4380424, "node_id": "MDQ6VXNlcjQzODA0MjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4380424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ClementPinard", "html_url": "https://github.com/ClementPinard", "followers_url": "https://api.github.com/users/ClementPinard/followers", "following_url": "https://api.github.com/users/ClementPinard/following{/other_user}", "gists_url": "https://api.github.com/users/ClementPinard/gists{/gist_id}", "starred_url": "https://api.github.com/users/ClementPinard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ClementPinard/subscriptions", "organizations_url": "https://api.github.com/users/ClementPinard/orgs", "repos_url": "https://api.github.com/users/ClementPinard/repos", "events_url": "https://api.github.com/users/ClementPinard/events{/privacy}", "received_events_url": "https://api.github.com/users/ClementPinard/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-04T13:32:35Z", "updated_at": "2018-06-04T13:37:29Z", "author_association": "NONE", "body_html": "<p>Basically, for each point in your output map, you compute the correlation of the two inputs, as if the patch of your <code>input2</code> was a kernel of convolution applied on patch of \u0300<code>input1</code></p>\n<p>other than padding there are 4 fundamental arguments to apply :<br>\nkernel size, displacement size, stride and dilation (for simplicity, we'll assume stride and dilation of 1 for now)</p>\n<p>with a maximum displacement size, you would get this mapping :<br>\n<code>Input1 BxCxHxW Input2 BxCxHxW -&gt; Output BxHxWxHxW</code><br>\nwhich means you get to treat every possible patch of Input2 as normal convolution kernel, applied to the whole Input1<br>\nthe minimum displacement you would get :<br>\n<code> Output BxHxWx1x1\u00a0</code><br>\nThe operation done is then just a bunch of inner products, for all <code>(n,i,j)</code> you compute the inner product of the two C-dimension vectors <code>&lt;Input1[n,:,i,j], Input2[n,:,i,j]&gt;</code> and then you apply a avgPool2d of your map with a stride of 1 and kernel_size of your correlation kernel size.</p>\n<p>As all these operations are very similar to convolution, I have been studying on how we can make these operations simple GEMM calls, whether it is batched/strided or not (see <a href=\"https://devblogs.nvidia.com/cublas-strided-batched-matrix-multiply/#more-7561\" rel=\"nofollow\">here</a> ), inspired by this presentation : <a href=\"http://www.prime-project.org/wp-content/uploads/sites/206/2018/02/Talk-10-David-Gregg-Parallel-Multi-Channel-Convolution-using-General-Matrix-Multiplication.pdf\" rel=\"nofollow\">http://www.prime-project.org/wp-content/uploads/sites/206/2018/02/Talk-10-David-Gregg-Parallel-Multi-Channel-Convolution-using-General-Matrix-Multiplication.pdf</a> , but I cam across nothing conclusive, it seems we are bound to make batch GEMM call of very little matrices, and unable to benefit from CuBLAS capabilities.</p>\n<p>I think the best options might be :</p>\n<ul>\n<li>Do what the paper did with convolution, but instead of a GEMM primitive, we use a inner product primitive : construct every possible broadcast inner product of C-dimensional pixels (with spatial shift induced by displacement) followed by a avgpooling</li>\n<li>Do what Fitsum Reda did in NVIDIA's repo : transpose both inputs to be <code>BxHxWxC</code> and then perform explicit correlation operation</li>\n</ul>\n<p>I have not looked carefully in the backward operation yet, but it seems that the same kind of correlation operations will be done.</p>\n<p>It seemed to me that Reda's technique was optimizable, especially  with the transposition and all the multiplications that were done multiple times across different correlation operation, but I don't have any proof that this is not the best way to deal with that very peculiar module</p>", "body_text": "Basically, for each point in your output map, you compute the correlation of the two inputs, as if the patch of your input2 was a kernel of convolution applied on patch of \u0300input1\nother than padding there are 4 fundamental arguments to apply :\nkernel size, displacement size, stride and dilation (for simplicity, we'll assume stride and dilation of 1 for now)\nwith a maximum displacement size, you would get this mapping :\nInput1 BxCxHxW Input2 BxCxHxW -> Output BxHxWxHxW\nwhich means you get to treat every possible patch of Input2 as normal convolution kernel, applied to the whole Input1\nthe minimum displacement you would get :\n Output BxHxWx1x1\u00a0\nThe operation done is then just a bunch of inner products, for all (n,i,j) you compute the inner product of the two C-dimension vectors <Input1[n,:,i,j], Input2[n,:,i,j]> and then you apply a avgPool2d of your map with a stride of 1 and kernel_size of your correlation kernel size.\nAs all these operations are very similar to convolution, I have been studying on how we can make these operations simple GEMM calls, whether it is batched/strided or not (see here ), inspired by this presentation : http://www.prime-project.org/wp-content/uploads/sites/206/2018/02/Talk-10-David-Gregg-Parallel-Multi-Channel-Convolution-using-General-Matrix-Multiplication.pdf , but I cam across nothing conclusive, it seems we are bound to make batch GEMM call of very little matrices, and unable to benefit from CuBLAS capabilities.\nI think the best options might be :\n\nDo what the paper did with convolution, but instead of a GEMM primitive, we use a inner product primitive : construct every possible broadcast inner product of C-dimensional pixels (with spatial shift induced by displacement) followed by a avgpooling\nDo what Fitsum Reda did in NVIDIA's repo : transpose both inputs to be BxHxWxC and then perform explicit correlation operation\n\nI have not looked carefully in the backward operation yet, but it seems that the same kind of correlation operations will be done.\nIt seemed to me that Reda's technique was optimizable, especially  with the transposition and all the multiplications that were done multiple times across different correlation operation, but I don't have any proof that this is not the best way to deal with that very peculiar module", "body": "Basically, for each point in your output map, you compute the correlation of the two inputs, as if the patch of your `input2` was a kernel of convolution applied on patch of \u0300`input1`\r\n\r\nother than padding there are 4 fundamental arguments to apply :\r\nkernel size, displacement size, stride and dilation (for simplicity, we'll assume stride and dilation of 1 for now)\r\n\r\nwith a maximum displacement size, you would get this mapping :\r\n``` Input1 BxCxHxW Input2 BxCxHxW -> Output BxHxWxHxW ```\r\nwhich means you get to treat every possible patch of Input2 as normal convolution kernel, applied to the whole Input1\r\nthe minimum displacement you would get :\r\n``` Output BxHxWx1x1\u00a0```\r\nThe operation done is then just a bunch of inner products, for all `(n,i,j)` you compute the inner product of the two C-dimension vectors `<Input1[n,:,i,j], Input2[n,:,i,j]>` and then you apply a avgPool2d of your map with a stride of 1 and kernel_size of your correlation kernel size.\r\n\r\nAs all these operations are very similar to convolution, I have been studying on how we can make these operations simple GEMM calls, whether it is batched/strided or not (see [here](https://devblogs.nvidia.com/cublas-strided-batched-matrix-multiply/#more-7561) ), inspired by this presentation : http://www.prime-project.org/wp-content/uploads/sites/206/2018/02/Talk-10-David-Gregg-Parallel-Multi-Channel-Convolution-using-General-Matrix-Multiplication.pdf , but I cam across nothing conclusive, it seems we are bound to make batch GEMM call of very little matrices, and unable to benefit from CuBLAS capabilities.\r\n\r\nI think the best options might be :\r\n - Do what the paper did with convolution, but instead of a GEMM primitive, we use a inner product primitive : construct every possible broadcast inner product of C-dimensional pixels (with spatial shift induced by displacement) followed by a avgpooling\r\n - Do what Fitsum Reda did in NVIDIA's repo : transpose both inputs to be `BxHxWxC` and then perform explicit correlation operation\r\n\r\nI have not looked carefully in the backward operation yet, but it seems that the same kind of correlation operations will be done.\r\n\r\nIt seemed to me that Reda's technique was optimizable, especially  with the transposition and all the multiplications that were done multiple times across different correlation operation, but I don't have any proof that this is not the best way to deal with that very peculiar module"}