{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4334", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4334/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4334/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4334/events", "html_url": "https://github.com/pytorch/pytorch/issues/4334", "id": 284309770, "node_id": "MDU6SXNzdWUyODQzMDk3NzA=", "number": 4334, "title": "torch.cuda.device_count() returns 1 using 4 TitanX setup.", "user": {"login": "tamis-laan", "id": 3178666, "node_id": "MDQ6VXNlcjMxNzg2NjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/3178666?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamis-laan", "html_url": "https://github.com/tamis-laan", "followers_url": "https://api.github.com/users/tamis-laan/followers", "following_url": "https://api.github.com/users/tamis-laan/following{/other_user}", "gists_url": "https://api.github.com/users/tamis-laan/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamis-laan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamis-laan/subscriptions", "organizations_url": "https://api.github.com/users/tamis-laan/orgs", "repos_url": "https://api.github.com/users/tamis-laan/repos", "events_url": "https://api.github.com/users/tamis-laan/events{/privacy}", "received_events_url": "https://api.github.com/users/tamis-laan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-23T14:43:27Z", "updated_at": "2017-12-26T08:59:53Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>nvidia-smi:</p>\n<pre><code>+-----------------------------------------------------------------------------+                            \u2502\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |                            \u2502\n|-------------------------------+----------------------+----------------------+                            \u2502\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                            \u2502\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                            \u2502 |===============================+======================+======================|                            \u2502\n|   0  GeForce GTX 108...  On   | 00000000:02:00.0 Off |                  N/A |                            \u2502\n| 20%   27C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   1  GeForce GTX 108...  On   | 00000000:03:00.0 Off |                  N/A |                            \u2502\n| 20%   30C    P8    18W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   2  GeForce GTX 108...  On   | 00000000:82:00.0 Off |                  N/A |                            \u2502\n| 20%   25C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   3  GeForce GTX 108...  On   | 00000000:83:00.0 Off |                  N/A |                            \u2502\n| 20%   26C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n                                                                                                            \u2502\n+-----------------------------------------------------------------------------+                            \u2502\n| Processes:                                                       GPU Memory |                            \u2502\n|  GPU       PID  Type  Process name                               Usage      |                            \u2502\n|=============================================================================|                            \u2502\n|  No running processes found                                                 |                            \u2502\n+-----------------------------------------------------------------------------+ \n</code></pre>\n<p>When I start 3 python instances where each selects a different GPU's and first print the number of devices using torch.cuda.device_cout() I get:</p>\n<pre><code>#devices: 1\n \nFile \"/home/xxxxx/code/xxxxx/xxxxx/xxxxx/xxxxx.py\", line 38, in main                    \nFile \"/home/xxxxx/env/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 223, in set_device    torch._C._cuda_setDevice(device)                                                                        \nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88             \nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=88 error=10 : invalid device ordinal\n\n</code></pre>\n<p>When I run the same code on a node with 4 GTX1080Ti GPU's pytorch correctly detects all graphics cards and the code runs properly.</p>\n<p>Is this a setup problem? Or is this a issue related to pytorch?</p>\n<p>I would like to add that when I select a node with 4x GTX980Ti pytorch also only detects 1 device.</p>", "body_text": "nvidia-smi:\n+-----------------------------------------------------------------------------+                            \u2502\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |                            \u2502\n|-------------------------------+----------------------+----------------------+                            \u2502\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                            \u2502\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                            \u2502 |===============================+======================+======================|                            \u2502\n|   0  GeForce GTX 108...  On   | 00000000:02:00.0 Off |                  N/A |                            \u2502\n| 20%   27C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   1  GeForce GTX 108...  On   | 00000000:03:00.0 Off |                  N/A |                            \u2502\n| 20%   30C    P8    18W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   2  GeForce GTX 108...  On   | 00000000:82:00.0 Off |                  N/A |                            \u2502\n| 20%   25C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n|   3  GeForce GTX 108...  On   | 00000000:83:00.0 Off |                  N/A |                            \u2502\n| 20%   26C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\n+-------------------------------+----------------------+----------------------+                            \u2502\n                                                                                                            \u2502\n+-----------------------------------------------------------------------------+                            \u2502\n| Processes:                                                       GPU Memory |                            \u2502\n|  GPU       PID  Type  Process name                               Usage      |                            \u2502\n|=============================================================================|                            \u2502\n|  No running processes found                                                 |                            \u2502\n+-----------------------------------------------------------------------------+ \n\nWhen I start 3 python instances where each selects a different GPU's and first print the number of devices using torch.cuda.device_cout() I get:\n#devices: 1\n \nFile \"/home/xxxxx/code/xxxxx/xxxxx/xxxxx/xxxxx.py\", line 38, in main                    \nFile \"/home/xxxxx/env/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 223, in set_device    torch._C._cuda_setDevice(device)                                                                        \nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88             \nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=88 error=10 : invalid device ordinal\n\n\nWhen I run the same code on a node with 4 GTX1080Ti GPU's pytorch correctly detects all graphics cards and the code runs properly.\nIs this a setup problem? Or is this a issue related to pytorch?\nI would like to add that when I select a node with 4x GTX980Ti pytorch also only detects 1 device.", "body": "nvidia-smi:\r\n\r\n```\r\n+-----------------------------------------------------------------------------+                            \u2502\r\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |                            \u2502\r\n|-------------------------------+----------------------+----------------------+                            \u2502\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                            \u2502\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                            \u2502 |===============================+======================+======================|                            \u2502\r\n|   0  GeForce GTX 108...  On   | 00000000:02:00.0 Off |                  N/A |                            \u2502\r\n| 20%   27C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\r\n+-------------------------------+----------------------+----------------------+                            \u2502\r\n|   1  GeForce GTX 108...  On   | 00000000:03:00.0 Off |                  N/A |                            \u2502\r\n| 20%   30C    P8    18W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\r\n+-------------------------------+----------------------+----------------------+                            \u2502\r\n|   2  GeForce GTX 108...  On   | 00000000:82:00.0 Off |                  N/A |                            \u2502\r\n| 20%   25C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\r\n+-------------------------------+----------------------+----------------------+                            \u2502\r\n|   3  GeForce GTX 108...  On   | 00000000:83:00.0 Off |                  N/A |                            \u2502\r\n| 20%   26C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |                            \u2502\r\n+-------------------------------+----------------------+----------------------+                            \u2502\r\n                                                                                                            \u2502\r\n+-----------------------------------------------------------------------------+                            \u2502\r\n| Processes:                                                       GPU Memory |                            \u2502\r\n|  GPU       PID  Type  Process name                               Usage      |                            \u2502\r\n|=============================================================================|                            \u2502\r\n|  No running processes found                                                 |                            \u2502\r\n+-----------------------------------------------------------------------------+ \r\n```\r\n\r\nWhen I start 3 python instances where each selects a different GPU's and first print the number of devices using torch.cuda.device_cout() I get:\r\n\r\n```\r\n#devices: 1\r\n \r\nFile \"/home/xxxxx/code/xxxxx/xxxxx/xxxxx/xxxxx.py\", line 38, in main                    \r\nFile \"/home/xxxxx/env/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 223, in set_device    torch._C._cuda_setDevice(device)                                                                        \r\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:88             \r\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=88 error=10 : invalid device ordinal\r\n\r\n```\r\nWhen I run the same code on a node with 4 GTX1080Ti GPU's pytorch correctly detects all graphics cards and the code runs properly.\r\n\r\nIs this a setup problem? Or is this a issue related to pytorch?\r\n\r\nI would like to add that when I select a node with 4x GTX980Ti pytorch also only detects 1 device."}