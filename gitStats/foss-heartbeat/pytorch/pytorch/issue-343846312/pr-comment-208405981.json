{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208405981", "pull_request_review_id": 144201841, "id": 208405981, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwODQwNTk4MQ==", "diff_hunk": "@@ -72,6 +78,107 @@ static void applyGesv(Tensor& b, Tensor& A, std::vector<int64_t> infos) {\n   }\n }\n \n+std::tuple<Tensor&,Tensor&> _gesv_single_out_cpu(\n+    Tensor& sol, Tensor& lu,\n+    const Tensor& self, const Tensor& A) {\n+#ifndef USE_LAPACK\n+  AT_ERROR(\"gesv: LAPACK library not found in compilation\");\n+#endif\n+  int64_t bx = self.size(0);\n+  int64_t by = (self.dim() == 1) ? 1 : self.size(1);\n+  int64_t ax = A.size(0);\n+  int64_t ay = A.size(1);\n+  int info = 0;\n+  Tensor temp_sol;\n+  Tensor temp_lu;\n+\n+  /* Init to column major format. `sol` and `lu` need to be contiguous\n+   * since we pass sol.data() and lu.data() to Lapack */\n+  bool tc_sol = isTransposeContiguous(sol);\n+  auto self_t = self.view({bx, by}).t();\n+  if (!tc_sol &&\n+      !sol.is_contiguous() &&\n+      sol.dim() == 2 &&\n+      sol.size(0) == bx &&\n+      sol.size(1) == by) {\n+    // eg. torch.gesv(.., out=(n[::2], ...))\n+    temp_sol = self_t.clone();\n+  }\n+\n+  if (!temp_sol.defined()) {\n+    if (tc_sol) {\n+      sol.t().resize_({by, bx});\n+    } else {\n+      sol.resize_({by, bx});\n+    }\n+    if (&self == &sol) {\n+      // note: not a comprehensive check. Will fail for views\n+      if (!tc_sol) {\n+        sol.copy_(self_t.clone());\n+      }\n+    } else {\n+      if (tc_sol) {\n+        sol.t().copy_(self_t);\n+      } else {\n+        sol.copy_(self_t);\n+      }\n+    }\n+  }", "path": "aten/src/ATen/native/Gesv.cpp", "position": null, "original_position": 71, "commit_id": "6c573ec2fe05deacdb8541c2229f21fa51d96e30", "original_commit_id": "2a3644b8476df19d674a3982c37e918cdc61c89a", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Additionally, I wonder if this kind of structure will make it clearer.\r\n\r\n```c++\r\n// gesv takes in two tensors and returns them in-place. so unless the output\r\n// args are the same as input args, we will need to make a copy.\r\n\r\n// these tensors will be the input and output args to the lapack call.\r\n// they may be sol and lu, or may be a buffer, indicated by flags sol_buffer\r\n// and lu_buffer.\r\nTensor sol_lapack_arg;\r\nTensor lu_lapack_arg;\r\n\r\nbool sol_correct_shape = sol.size(0) == bx && sol.size(1) == by;\r\nbool sol_buffer = false;\r\n\r\n// now we detect if we need to use a buffer and/or resize the out arguments.\r\n//\r\n// our strategy is the same for each out arg. bellow we use (sol, self) pair\r\n// for demonstration purpose. \r\n// 1. if sol has correct shape and is fortran contig\r\n//    copy self into sol (if self is not sol)\r\n//    call lapack gesv using sol\r\n// 2. if sol has correct shape but isn't fortran contig\r\n//    make a buffer, copy self into the buffer s.t. it is fortran contig\r\n//    call lapack gesv using the buffer\r\n//    copy the buffer content into sol\r\n// 3. if sol has incorrect shape, then we have to resize\r\n//    resize sol inplace, and make it fortran contig and holding content of self\r\n//    call lapack gesv using sol\r\n\r\nif (sol_correct_shape && tc_sol) {\r\n    if (&sol != &self) {\r\n        sol.copy_(self);\r\n    }\r\n    sol_lapack_arg = sol;\r\n} else if (sol_correct_shape) {  // shape right but not fortran contiguous\r\n    sol_lapack_arg = self.t().clone().t_(); // make it fortran contiguous\r\n    sol_buffer = true;\r\n} else {  // wrong shape, resize_\r\n    // since shape is wrong, resize_ call will make it (fortran) contiguous\r\n    sol_lapack_arg = sol.resize_({by, bx}).t_().copy_(self);  \r\n}\r\n\r\n// same for lu\r\n\r\nAT_DISPATCH_FLOATING_TYPES(self.type(), \"gesv\", [&]{\r\n    auto ipiv = at::empty({bx}, sol.options().dtype(kInt));\r\n    lapackGesv<scalar_t>(bx, by, lu_lapack_arg.data<scalar_t>, bx, \r\n                         ipiv.data<int>(), sol_lapack_arg.data<scalar_t>, \r\n                         bx, &info);\r\n    });\r\ncheckErrors({info});\r\n\r\nif (sol_buffer) {\r\n    sol.copy_(sol_lapack_arg);\r\n}\r\n\r\n// same for lu\r\n\r\nreturn std::make_tuple(sol, lu);\r\n```", "created_at": "2018-08-07T22:32:48Z", "updated_at": "2018-11-23T15:48:58Z", "html_url": "https://github.com/pytorch/pytorch/pull/9742#discussion_r208405981", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9742", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/208405981"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9742#discussion_r208405981"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9742"}}, "body_html": "<p>Additionally, I wonder if this kind of structure will make it clearer.</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\">//</span> gesv takes in two tensors and returns them in-place. so unless the output</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> args are the same as input args, we will need to make a copy.</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> these tensors will be the input and output args to the lapack call.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> they may be sol and lu, or may be a buffer, indicated by flags sol_buffer</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> and lu_buffer.</span>\nTensor sol_lapack_arg;\nTensor lu_lapack_arg;\n\n<span class=\"pl-k\">bool</span> sol_correct_shape = sol.size(<span class=\"pl-c1\">0</span>) == bx &amp;&amp; sol.size(<span class=\"pl-c1\">1</span>) == by;\n<span class=\"pl-k\">bool</span> sol_buffer = <span class=\"pl-c1\">false</span>;\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> now we detect if we need to use a buffer and/or resize the out arguments.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span></span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> our strategy is the same for each out arg. bellow we use (sol, self) pair</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> for demonstration purpose. </span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> 1. if sol has correct shape and is fortran contig</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    copy self into sol (if self is not sol)</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    call lapack gesv using sol</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> 2. if sol has correct shape but isn't fortran contig</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    make a buffer, copy self into the buffer s.t. it is fortran contig</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    call lapack gesv using the buffer</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    copy the buffer content into sol</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> 3. if sol has incorrect shape, then we have to resize</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    resize sol inplace, and make it fortran contig and holding content of self</span>\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    call lapack gesv using sol</span>\n\n<span class=\"pl-k\">if</span> (sol_correct_shape &amp;&amp; tc_sol) {\n    <span class=\"pl-k\">if</span> (&amp;sol != &amp;self) {\n        sol.<span class=\"pl-c1\">copy_</span>(self);\n    }\n    sol_lapack_arg = sol;\n} <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span> (sol_correct_shape) {  <span class=\"pl-c\"><span class=\"pl-c\">//</span> shape right but not fortran contiguous</span>\n    sol_lapack_arg = self.<span class=\"pl-c1\">t</span>().<span class=\"pl-c1\">clone</span>().<span class=\"pl-c1\">t_</span>(); <span class=\"pl-c\"><span class=\"pl-c\">//</span> make it fortran contiguous</span>\n    sol_buffer = <span class=\"pl-c1\">true</span>;\n} <span class=\"pl-k\">else</span> {  <span class=\"pl-c\"><span class=\"pl-c\">//</span> wrong shape, resize_</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> since shape is wrong, resize_ call will make it (fortran) contiguous</span>\n    sol_lapack_arg = sol.<span class=\"pl-c1\">resize_</span>({by, bx}).<span class=\"pl-c1\">t_</span>().<span class=\"pl-c1\">copy_</span>(self);  \n}\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> same for lu</span>\n\n<span class=\"pl-en\">AT_DISPATCH_FLOATING_TYPES</span>(self.type(), \"gesv\", [&amp;]{\n    <span class=\"pl-k\">auto</span> ipiv = <span class=\"pl-c1\">at::empty</span>({bx}, sol.<span class=\"pl-c1\">options</span>().<span class=\"pl-c1\">dtype</span>(<span class=\"pl-c1\">kInt</span>));\n    lapackGesv&lt;<span class=\"pl-c1\">scalar_t</span>&gt;(bx, by, lu_lapack_arg.<span class=\"pl-smi\">data</span>&lt;<span class=\"pl-c1\">scalar_t</span>&gt;, bx, \n                         ipiv.<span class=\"pl-smi\">data</span>&lt;<span class=\"pl-k\">int</span>&gt;(), sol_lapack_arg.<span class=\"pl-smi\">data</span>&lt;<span class=\"pl-c1\">scalar_t</span>&gt;, \n                         bx, &amp;info);\n    });\n<span class=\"pl-en\">checkErrors</span>({info});\n\n<span class=\"pl-k\">if</span> (sol_buffer) {\n    sol.<span class=\"pl-c1\">copy_</span>(sol_lapack_arg);\n}\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> same for lu</span>\n\n<span class=\"pl-k\">return</span> std::make_tuple(sol, lu);</pre></div>", "body_text": "Additionally, I wonder if this kind of structure will make it clearer.\n// gesv takes in two tensors and returns them in-place. so unless the output\n// args are the same as input args, we will need to make a copy.\n\n// these tensors will be the input and output args to the lapack call.\n// they may be sol and lu, or may be a buffer, indicated by flags sol_buffer\n// and lu_buffer.\nTensor sol_lapack_arg;\nTensor lu_lapack_arg;\n\nbool sol_correct_shape = sol.size(0) == bx && sol.size(1) == by;\nbool sol_buffer = false;\n\n// now we detect if we need to use a buffer and/or resize the out arguments.\n//\n// our strategy is the same for each out arg. bellow we use (sol, self) pair\n// for demonstration purpose. \n// 1. if sol has correct shape and is fortran contig\n//    copy self into sol (if self is not sol)\n//    call lapack gesv using sol\n// 2. if sol has correct shape but isn't fortran contig\n//    make a buffer, copy self into the buffer s.t. it is fortran contig\n//    call lapack gesv using the buffer\n//    copy the buffer content into sol\n// 3. if sol has incorrect shape, then we have to resize\n//    resize sol inplace, and make it fortran contig and holding content of self\n//    call lapack gesv using sol\n\nif (sol_correct_shape && tc_sol) {\n    if (&sol != &self) {\n        sol.copy_(self);\n    }\n    sol_lapack_arg = sol;\n} else if (sol_correct_shape) {  // shape right but not fortran contiguous\n    sol_lapack_arg = self.t().clone().t_(); // make it fortran contiguous\n    sol_buffer = true;\n} else {  // wrong shape, resize_\n    // since shape is wrong, resize_ call will make it (fortran) contiguous\n    sol_lapack_arg = sol.resize_({by, bx}).t_().copy_(self);  \n}\n\n// same for lu\n\nAT_DISPATCH_FLOATING_TYPES(self.type(), \"gesv\", [&]{\n    auto ipiv = at::empty({bx}, sol.options().dtype(kInt));\n    lapackGesv<scalar_t>(bx, by, lu_lapack_arg.data<scalar_t>, bx, \n                         ipiv.data<int>(), sol_lapack_arg.data<scalar_t>, \n                         bx, &info);\n    });\ncheckErrors({info});\n\nif (sol_buffer) {\n    sol.copy_(sol_lapack_arg);\n}\n\n// same for lu\n\nreturn std::make_tuple(sol, lu);", "in_reply_to_id": 208400973}