{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213481466", "pull_request_review_id": 150328233, "id": 213481466, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMzQ4MTQ2Ng==", "diff_hunk": "@@ -1,30 +1,94 @@\n+#include <utility>\n #include \"ATen/ATen.h\"\n \n namespace at { namespace native {\n \n-static inline void checkInputs(const Tensor& self, const Tensor& A) {\n-  if (A.size(-1) != A.size(-2)) {\n-    AT_ERROR(\"A must be batches of square matrices, \"\n-        \"but they are %lld by %lld matrices\",\n-        (long long)A.size(-1), (long long)A.size(-2));\n+static inline bool isTransposeContiguous(Tensor& self) {\n+  return self.dim() == 2 &&\n+          self.stride(0) == 1 &&\n+          self.stride(1) == self.size(0);\n+}\n+\n+/* gesv takes (self, A) and returns (sol, lu).\n+ * (i)  output tensors (sol, lu) may be same as input tensors (self, A)\n+ * (ii) for 2D matrices, .t_() represents their column-major format\n+ *\n+ * Before passing pointers to Lapack, we need to ensure that these pointers\n+ * represent Fortran-contiguous tensors in column-major format\n+ *\n+ * Cases:\n+ * 1) `out` has correct shape but elements do not form a contiguous\n+ * chunk of memory. Since shape is correct, we don't resize_ it. Instead, we\n+ * clone the input tensor into a buffer, use the buffer for Lapack and finally\n+ * copy the buffer to the output tensor.\n+ *\n+ * 2) out.t() is contiguous:\n+ *    (i)  &in == &out: use out.data() as is. Do nothing\n+ *    (ii) &in != &out: copy in.t() to out.t()\n+ * 3) out.t() is not contiguous:\n+ *    - resize_ should fix contiguity/size issues\n+ *    (i)  &in == &out: copy in.t().clone() to out (same tensor)\n+ *    (ii) &in != &out: copy in.t() to out\n+ */\n+static inline void prepareTensorsForLapack(\n+    const Tensor& in, Tensor& out, Tensor& temp) {\n+  int64_t x = in.size(0);\n+  int64_t y = (in.dim() == 1) ? 1 : in.size(1);\n+  bool out_tc = isTransposeContiguous(out);\n+  bool out_correct_shape =\n+    out.dim() == 2 && out.size(0) == x && out.size(1) == y;\n+\n+  // view potential 1D `in` as 2D\n+  auto in_t = in.view({x, y}).t_();\n+\n+  if (!out_tc && !out.is_contiguous() && out_correct_shape) {", "path": "aten/src/ATen/native/Gesv.h", "position": 49, "original_position": 49, "commit_id": "6c573ec2fe05deacdb8541c2229f21fa51d96e30", "original_commit_id": "5341fee0443fab16c4386954242d6bb1e0b30cf2", "user": {"login": "animesht", "id": 1777276, "node_id": "MDQ6VXNlcjE3NzcyNzY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1777276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/animesht", "html_url": "https://github.com/animesht", "followers_url": "https://api.github.com/users/animesht/followers", "following_url": "https://api.github.com/users/animesht/following{/other_user}", "gists_url": "https://api.github.com/users/animesht/gists{/gist_id}", "starred_url": "https://api.github.com/users/animesht/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/animesht/subscriptions", "organizations_url": "https://api.github.com/users/animesht/orgs", "repos_url": "https://api.github.com/users/animesht/repos", "events_url": "https://api.github.com/users/animesht/events{/privacy}", "received_events_url": "https://api.github.com/users/animesht/received_events", "type": "User", "site_admin": false}, "body": "Well, not exactly, since we still want to resize when it is not the correct shape, it's just that the `resize` in the latter two conditions doesn't do anything if `out_correct_shape` is true. I think this is probably the most succinct way to write it without making the if-else ladder long and unnecessarily nested (since the exact cases are described in the comment above, it shouldn't be too hard to understand)", "created_at": "2018-08-28T21:39:10Z", "updated_at": "2018-11-23T15:50:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/9742#discussion_r213481466", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9742", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/213481466"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9742#discussion_r213481466"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9742"}}, "body_html": "<p>Well, not exactly, since we still want to resize when it is not the correct shape, it's just that the <code>resize</code> in the latter two conditions doesn't do anything if <code>out_correct_shape</code> is true. I think this is probably the most succinct way to write it without making the if-else ladder long and unnecessarily nested (since the exact cases are described in the comment above, it shouldn't be too hard to understand)</p>", "body_text": "Well, not exactly, since we still want to resize when it is not the correct shape, it's just that the resize in the latter two conditions doesn't do anything if out_correct_shape is true. I think this is probably the most succinct way to write it without making the if-else ladder long and unnecessarily nested (since the exact cases are described in the comment above, it shouldn't be too hard to understand)", "in_reply_to_id": 213126908}