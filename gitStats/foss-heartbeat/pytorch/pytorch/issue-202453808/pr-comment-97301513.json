{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/97301513", "pull_request_review_id": 17905554, "id": 97301513, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk3MzAxNTEz", "diff_hunk": "@@ -225,6 +225,14 @@ void cudnn_convolution_forward(\n   size_t workspaceSize;\n   CHECK(cudnnGetConvolutionForwardWorkspaceSize(handle, idesc.desc, wdesc.desc,\n       cdesc.desc, odesc.desc, fwdAlg, &workspaceSize));\n+  size_t memFree;\n+  size_t memTotal;\n+  cudaMemGetInfo(&memFree, &memTotal);", "path": "torch/csrc/cudnn/Conv.cpp", "position": 6, "original_position": 6, "commit_id": "bcaceb4a8a692d28e2aa5e93802e98776d10d659", "original_commit_id": "bcaceb4a8a692d28e2aa5e93802e98776d10d659", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "@fmassa I think that the problem is that the workspace size returned might be larger than can be satisfied by the caching allocator. In this case `Workspace` will call `THCudaMalloc` and that will give you OOM. But I haven't verified that, it's just a guess.", "created_at": "2017-01-23T11:45:33Z", "updated_at": "2018-11-23T15:32:16Z", "html_url": "https://github.com/pytorch/pytorch/pull/552#discussion_r97301513", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/552", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/97301513"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/552#discussion_r97301513"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/552"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> I think that the problem is that the workspace size returned might be larger than can be satisfied by the caching allocator. In this case <code>Workspace</code> will call <code>THCudaMalloc</code> and that will give you OOM. But I haven't verified that, it's just a guess.</p>", "body_text": "@fmassa I think that the problem is that the workspace size returned might be larger than can be satisfied by the caching allocator. In this case Workspace will call THCudaMalloc and that will give you OOM. But I haven't verified that, it's just a guess.", "in_reply_to_id": 97278080}