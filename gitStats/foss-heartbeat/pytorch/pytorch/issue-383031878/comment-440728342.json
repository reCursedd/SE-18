{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/440728342", "html_url": "https://github.com/pytorch/pytorch/pull/14271#issuecomment-440728342", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/14271", "id": 440728342, "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDcyODM0Mg==", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-21T16:29:29Z", "updated_at": "2018-11-21T16:29:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This does not guarantee that all pending collectives have completed, only that all collectives that used <em>the same communicator</em> as the barrier will have completed. Multiple NCCL communicators can run in parallel (thus on different streams) and you have to synchronize with all of them in order to guarantee that pending collectives completed when the barrier completes.</p>\n<p>There are two ways to do this (that I can think of):</p>\n<ol>\n<li><code>cudaDeviceSynchronize</code> on all devices that have been used in the past</li>\n<li>Record an event for every device for every NCCL communicator after queuing a collective. When running the barrier, do a <code>cudaStreamWaitEvent</code> on all of them before kicking off the barrier operation.</li>\n</ol>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=38511765\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mruberry\">@mruberry</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7799218\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mcarilli\">@mcarilli</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> Did I miss anything or make incorrect assumptions here?</p>", "body_text": "This does not guarantee that all pending collectives have completed, only that all collectives that used the same communicator as the barrier will have completed. Multiple NCCL communicators can run in parallel (thus on different streams) and you have to synchronize with all of them in order to guarantee that pending collectives completed when the barrier completes.\nThere are two ways to do this (that I can think of):\n\ncudaDeviceSynchronize on all devices that have been used in the past\nRecord an event for every device for every NCCL communicator after queuing a collective. When running the barrier, do a cudaStreamWaitEvent on all of them before kicking off the barrier operation.\n\n@mruberry @mcarilli @ngimel Did I miss anything or make incorrect assumptions here?", "body": "This does not guarantee that all pending collectives have completed, only that all collectives that used *the same communicator* as the barrier will have completed. Multiple NCCL communicators can run in parallel (thus on different streams) and you have to synchronize with all of them in order to guarantee that pending collectives completed when the barrier completes.\r\n\r\nThere are two ways to do this (that I can think of):\r\n1. `cudaDeviceSynchronize` on all devices that have been used in the past\r\n2. Record an event for every device for every NCCL communicator after queuing a collective. When running the barrier, do a `cudaStreamWaitEvent` on all of them before kicking off the barrier operation.\r\n\r\n@mruberry @mcarilli @ngimel Did I miss anything or make incorrect assumptions here?"}