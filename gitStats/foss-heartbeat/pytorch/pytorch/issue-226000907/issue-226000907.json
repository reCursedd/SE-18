{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1455", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1455/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1455/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1455/events", "html_url": "https://github.com/pytorch/pytorch/issues/1455", "id": 226000907, "node_id": "MDU6SXNzdWUyMjYwMDA5MDc=", "number": 1455, "title": "Memory leak?", "user": {"login": "ketranm", "id": 1192597, "node_id": "MDQ6VXNlcjExOTI1OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1192597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ketranm", "html_url": "https://github.com/ketranm", "followers_url": "https://api.github.com/users/ketranm/followers", "following_url": "https://api.github.com/users/ketranm/following{/other_user}", "gists_url": "https://api.github.com/users/ketranm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ketranm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ketranm/subscriptions", "organizations_url": "https://api.github.com/users/ketranm/orgs", "repos_url": "https://api.github.com/users/ketranm/repos", "events_url": "https://api.github.com/users/ketranm/events{/privacy}", "received_events_url": "https://api.github.com/users/ketranm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-05-03T14:15:45Z", "updated_at": "2017-05-03T22:38:57Z", "closed_at": "2017-05-03T22:38:57Z", "author_association": "NONE", "body_html": "<p>For replication, I use <a href=\"https://github.com/pytorch/examples/tree/master/word_language_model\">word_language_model</a></p>\n<pre><code> python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40\n</code></pre>\n<p>Errors</p>\n<pre><code>THCudaCheck FAIL file=/home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\nTraceback (most recent call last):\n  File \"main.py\", line 163, in &lt;module&gt;\n    train()\n  File \"main.py\", line 136, in train\n    loss.backward()\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 144, in backward\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 279, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 287, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in backward_extended\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in &lt;genexpr&gt;\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\nRuntimeError: cuda runtime error (2) : out of memory at /home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu:66\n</code></pre>", "body_text": "For replication, I use word_language_model\n python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40\n\nErrors\nTHCudaCheck FAIL file=/home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\nTraceback (most recent call last):\n  File \"main.py\", line 163, in <module>\n    train()\n  File \"main.py\", line 136, in train\n    loss.backward()\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 144, in backward\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 279, in _do_backward\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 287, in backward\n    result = self.backward_extended(*nested_gradients)\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in backward_extended\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in <genexpr>\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\nRuntimeError: cuda runtime error (2) : out of memory at /home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu:66", "body": "For replication, I use [word_language_model](https://github.com/pytorch/examples/tree/master/word_language_model)\r\n```\r\n python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40\r\n```\r\n\r\nErrors\r\n```\r\nTHCudaCheck FAIL file=/home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 163, in <module>\r\n    train()\r\n  File \"main.py\", line 136, in train\r\n    loss.backward()\r\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.py\", line 144, in backward\r\n    self._execution_engine.run_backward((self,), (gradient,), retain_variables)\r\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 279, in _do_backward\r\n    result = super(NestedIOFunction, self)._do_backward(gradients, retain_variables)\r\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/autograd/function.py\", line 287, in backward\r\n    result = self.backward_extended(*nested_gradients)\r\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in backward_extended\r\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\r\n  File \"/home/mktran/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.py\", line 319, in <genexpr>\r\n    grad_weight = [tuple(w.new().resize_as_(w) for w in layer_weight) for layer_weight in weight]\r\nRuntimeError: cuda runtime error (2) : out of memory at /home/mktran/pytorch/torch/lib/THC/generic/THCStorage.cu:66\r\n```"}