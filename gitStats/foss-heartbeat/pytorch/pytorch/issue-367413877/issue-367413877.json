{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12409", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12409/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12409/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12409/events", "html_url": "https://github.com/pytorch/pytorch/issues/12409", "id": 367413877, "node_id": "MDU6SXNzdWUzNjc0MTM4Nzc=", "number": 12409, "title": "nn.functional.interpolate very slow for fp16 (half) precision inputs", "user": {"login": "tstandley", "id": 17170654, "node_id": "MDQ6VXNlcjE3MTcwNjU0", "avatar_url": "https://avatars2.githubusercontent.com/u/17170654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tstandley", "html_url": "https://github.com/tstandley", "followers_url": "https://api.github.com/users/tstandley/followers", "following_url": "https://api.github.com/users/tstandley/following{/other_user}", "gists_url": "https://api.github.com/users/tstandley/gists{/gist_id}", "starred_url": "https://api.github.com/users/tstandley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tstandley/subscriptions", "organizations_url": "https://api.github.com/users/tstandley/orgs", "repos_url": "https://api.github.com/users/tstandley/repos", "events_url": "https://api.github.com/users/tstandley/events{/privacy}", "received_events_url": "https://api.github.com/users/tstandley/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-06T02:02:12Z", "updated_at": "2018-10-08T17:40:30Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n\n<p>nn.funcitonal.interpolate runs several times slower for fp16 inputs.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Run a neural network that has interpolation (up-sampling) under fp16. Note the slowness.</li>\n<li>Convert the values to floats, run the same interpolation, then convert back to half. Note that it's less slow.</li>\n<li>The network still suffers from the overhead of converting from half to float.</li>\n</ol>\n\n<h2>Expected behavior</h2>\n<p>The same or better performance when using fp16.</p>\n<h2>Environment</h2>\n<p>Collecting environment information...<br>\nPyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.7<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration:<br>\nGPU 0: TITAN V<br>\nGPU 1: TITAN V</p>\n<p>Nvidia driver version: 396.54<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.15.1)<br>\n[pip] numpydoc (0.8.0)<br>\n[pip] torch (0.4.1)<br>\n[pip] torchvision (0.2.1)<br>\n[conda] cuda92                    1.0                           0    pytorch<br>\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch<br>\n[conda] torchvision               0.2.1                    py37_1    pytorch</p>", "body_text": "\ud83d\udc1b Bug\n\nnn.funcitonal.interpolate runs several times slower for fp16 inputs.\nTo Reproduce\nSteps to reproduce the behavior:\n\nRun a neural network that has interpolation (up-sampling) under fp16. Note the slowness.\nConvert the values to floats, run the same interpolation, then convert back to half. Note that it's less slow.\nThe network still suffers from the overhead of converting from half to float.\n\n\nExpected behavior\nThe same or better performance when using fp16.\nEnvironment\nCollecting environment information...\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: TITAN V\nGPU 1: TITAN V\nNvidia driver version: 396.54\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] numpy (1.15.1)\n[pip] numpydoc (0.8.0)\n[pip] torch (0.4.1)\n[pip] torchvision (0.2.1)\n[conda] cuda92                    1.0                           0    pytorch\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\n[conda] torchvision               0.2.1                    py37_1    pytorch", "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nnn.funcitonal.interpolate runs several times slower for fp16 inputs. \r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run a neural network that has interpolation (up-sampling) under fp16. Note the slowness.\r\n2. Convert the values to floats, run the same interpolation, then convert back to half. Note that it's less slow.\r\n3. The network still suffers from the overhead of converting from half to float. \r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nThe same or better performance when using fp16.\r\n\r\n## Environment\r\n\r\nCollecting environment information...\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: TITAN V\r\nGPU 1: TITAN V\r\n\r\nNvidia driver version: 396.54\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.1)\r\n[pip] numpydoc (0.8.0)\r\n[pip] torch (0.4.1)\r\n[pip] torchvision (0.2.1)\r\n[conda] cuda92                    1.0                           0    pytorch\r\n[conda] pytorch                   0.4.1           py37_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\r\n[conda] torchvision               0.2.1                    py37_1    pytorch\r\n\r\n\r\n"}