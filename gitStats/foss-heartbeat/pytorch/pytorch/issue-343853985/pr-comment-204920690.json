{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204920690", "pull_request_review_id": 140034348, "id": 204920690, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNDkyMDY5MA==", "diff_hunk": "@@ -292,85 +239,314 @@ void encodeBlock(onnx::GraphProto * p_g, Block *b,\n       true_branch->set_name(\"then_branch\");\n       true_branch->set_type(onnx::AttributeProto_AttributeType_GRAPH);\n       auto true_g = true_branch->mutable_g();\n-      encodeBlock(true_g, node->blocks()[0], {}, ctx, raw_data_export_map);\n+      EncodeBlock(true_g, node->blocks()[0]);\n \n       auto false_branch = p_n->add_attribute();\n       false_branch->set_name(\"else_branch\");\n       false_branch->set_type(onnx::AttributeProto_AttributeType_GRAPH);\n       auto false_g = false_branch->mutable_g();\n-      encodeBlock(false_g, node->blocks()[1], {}, ctx, raw_data_export_map);\n+      EncodeBlock(false_g, node->blocks()[1]);\n     }\n   }\n   auto num_initializers = initializers.size();\n-  JIT_ASSERT(b->inputs().size() >= num_initializers);\n-  size_t inputs_count = b->inputs().size() - num_initializers;\n+  JIT_ASSERT(block->inputs().size() >= num_initializers);\n+  size_t inputs_count = block->inputs().size() - num_initializers;\n   for (auto & tensor : initializers) {\n     // TODO: stop using positions to determine which initializers\n     // match to which inputs\n-    std::string name = p_g->input(inputs_count++).name();\n-    auto p = p_g->add_initializer();\n+    std::string name = graph_proto->input(inputs_count++).name();\n+    auto p = graph_proto->add_initializer();\n     p->set_name(name);\n-    if (raw_data_export_map) {\n-      encodeTensor(p, tensor, name, raw_data_export_map);\n-    } else {\n-      encodeTensor(p, tensor, {});\n-    }\n+    EncodeTensor(p, tensor, name);\n   }\n }\n \n-void encodeModel(onnx::ModelProto* p_m, const std::shared_ptr<Graph>& g,\n-                 const std::vector<at::Tensor>& initializers,\n-                 RawDataExportMap* raw_data_export_map = nullptr,\n-                 onnx_torch::OperatorExportTypes operator_export_type\n-                   = onnx_torch::OperatorExportTypes::ONNX) {\n-  onnx::GraphProto* p_g = p_m->mutable_graph();\n-  ExportContext ctx;\n-  ctx.operator_export_type = operator_export_type;\n-  encodeGraph(p_g, g, initializers, &ctx, raw_data_export_map);\n+void JitEncoder::AddAttribute(onnx::NodeProto *node_proto, const jit::Node *node, const jit::Symbol name) {\n+  auto attr = node_proto->add_attribute();\n+  JIT_ASSERT(name.is_attr());\n+  attr->set_name(name.toUnqualString());\n+  switch(node->kindOf(name)) {\n+    case AttributeKind::f:\n+      attr->set_f(node->f(name));\n+      attr->set_type(onnx::AttributeProto_AttributeType_FLOAT);\n+      break;\n+    case AttributeKind::fs:\n+      attr->set_type(onnx::AttributeProto_AttributeType_FLOATS);\n+      for(auto & v : node->fs(name))\n+        attr->add_floats(v);\n+      break;\n+    case AttributeKind::i:\n+      attr->set_type(onnx::AttributeProto_AttributeType_INT);\n+      attr->set_i(node->i(name));\n+      break;\n+    case AttributeKind::is:\n+      attr->set_type(onnx::AttributeProto_AttributeType_INTS);\n+      for(auto & v : node->is(name))\n+        attr->add_ints(v);\n+      break;\n+    case AttributeKind::s:\n+      attr->set_type(onnx::AttributeProto_AttributeType_STRING);\n+      attr->set_s(node->s(name));\n+      break;\n+    case AttributeKind::ss:\n+      attr->set_type(onnx::AttributeProto_AttributeType_STRINGS);\n+      for(auto & v : node->ss(name))\n+        attr->add_strings(v);\n+      break;\n+    case AttributeKind::t: {\n+      attr->set_type(onnx::AttributeProto_AttributeType_TENSOR);\n+      auto t = attr->mutable_t();\n+      EncodeTensor(t, node->t(name));\n+    } break;\n+    case AttributeKind::ts:\n+      attr->set_type(onnx::AttributeProto_AttributeType_TENSORS);\n+      for(auto & v : node->ts(name)) {\n+        auto t = attr->add_tensors();\n+        EncodeTensor(t, v);\n+      }\n+      break;\n+    case AttributeKind::g: {\n+      attr->set_type(onnx::AttributeProto_AttributeType_GRAPH);\n+      auto g = attr->mutable_g();\n+      EncodeGraph(g, node->g(name));\n+    } break;\n+    case AttributeKind::gs:\n+      attr->set_type(onnx::AttributeProto_AttributeType_GRAPHS);\n+      for(auto & v : node->gs(name)) {\n+        auto g = attr->add_graphs();\n+        EncodeGraph(g, v);\n+      }\n+      break;\n+  }\n }\n \n-namespace {\n-std::string getNodeStackTraceString(Node* n) {\n-  std::stringstream ss;\n-  if (n->getSourceLocation()) {\n-    n->getSourceLocation()->highlight(ss);\n+void JitEncoder::EncodeTensor(\n+    onnx::TensorProto *tensor_proto,\n+    const at::Tensor &tensor,\n+    const at::optional<std::string> external_ref) {\n+  for(auto d : tensor.sizes()) {\n+    tensor_proto->add_dims(d);\n+  }\n+  tensor_proto->set_data_type(ATenTypeToOnnxType(tensor.type().scalarType()));\n+  // CPU's HalfTensor doesn't have contiguous(), so first calling contiguous()\n+  auto t = tensor.contiguous().toBackend(at::kCPU);\n+  // Add a buffer to the raw_data_export_map for the caller to dump into an\n+  // external data store. If external_ref is not specified, we instead dump\n+  // the contiguous data into the protobuf itself\n+  if (defer_weight_export_) {", "path": "torch/csrc/jit/export.cpp", "position": null, "original_position": 519, "commit_id": "f622bcc6b1e23e942cca8615b87321ebc91e4273", "original_commit_id": "dfe899efbacf40f945fd85e4d49e3d0748317f4d", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "Oh, I see that this is virtual and overridden.", "created_at": "2018-07-24T21:41:03Z", "updated_at": "2018-11-23T15:48:01Z", "html_url": "https://github.com/pytorch/pytorch/pull/9746#discussion_r204920690", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9746", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/204920690"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9746#discussion_r204920690"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9746"}}, "body_html": "<p>Oh, I see that this is virtual and overridden.</p>", "body_text": "Oh, I see that this is virtual and overridden.", "in_reply_to_id": 204919999}