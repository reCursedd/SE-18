{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/409369292", "html_url": "https://github.com/pytorch/pytorch/pull/9864#issuecomment-409369292", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9864", "id": 409369292, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTM2OTI5Mg==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-31T21:11:22Z", "updated_at": "2018-07-31T21:11:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>test failure looks legit: <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/372d1d67356f054db64bdfb4787871ecdbbcbe0b/test/test_jit.py#L2228-L2253\">pytorch/test/test_jit.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n        Lines 2228 to 2253\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/372d1d67356f054db64bdfb4787871ecdbbcbe0b\">372d1d6</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L2228\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2228\"></td>\n          <td id=\"LC2228\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">def</span> <span class=\"pl-en\">test_pack_padded_pad_packed_trace</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2229\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2229\"></td>\n          <td id=\"LC2229\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">from</span> torch.nn.utils.rnn <span class=\"pl-k\">import</span> pack_padded_sequence, pad_packed_sequence </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2230\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2230\"></td>\n          <td id=\"LC2230\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     T, B, C <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">7</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2231\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2231\"></td>\n          <td id=\"LC2231\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2232\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2232\"></td>\n          <td id=\"LC2232\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">class</span> <span class=\"pl-en\">PadPackedWrapper</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2233\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2233\"></td>\n          <td id=\"LC2233\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2234\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2234\"></td>\n          <td id=\"LC2234\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-c1\">super</span>(PadPackedWrapper, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>() </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2235\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2235\"></td>\n          <td id=\"LC2235\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2236\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2236\"></td>\n          <td id=\"LC2236\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">seq_lens</span>): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2237\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2237\"></td>\n          <td id=\"LC2237\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             x <span class=\"pl-k\">=</span> pack_padded_sequence(x, seq_lens) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2238\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2238\"></td>\n          <td id=\"LC2238\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             x, _ <span class=\"pl-k\">=</span> pad_packed_sequence(x) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2239\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2239\"></td>\n          <td id=\"LC2239\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             <span class=\"pl-k\">return</span> x </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2240\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2240\"></td>\n          <td id=\"LC2240\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2241\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2241\"></td>\n          <td id=\"LC2241\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     x <span class=\"pl-k\">=</span> np.ones((T, B, C)) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2242\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2242\"></td>\n          <td id=\"LC2242\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     seq_lens <span class=\"pl-k\">=</span> np.array([<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.int32) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2243\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2243\"></td>\n          <td id=\"LC2243\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-c\"><span class=\"pl-c\">#</span> set padding value so we can test equivalence</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2244\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2244\"></td>\n          <td id=\"LC2244\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     <span class=\"pl-k\">for</span> b <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(B): </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2245\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2245\"></td>\n          <td id=\"LC2245\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">         <span class=\"pl-k\">if</span> seq_lens[b] <span class=\"pl-k\">&lt;</span> T: </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2246\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2246\"></td>\n          <td id=\"LC2246\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">             x[seq_lens[b]:, b, :] <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span> </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2247\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2247\"></td>\n          <td id=\"LC2247\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     seq_lens <span class=\"pl-k\">=</span> torch.from_numpy(seq_lens) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2248\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2248\"></td>\n          <td id=\"LC2248\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     x <span class=\"pl-k\">=</span> torch.autograd.Variable(torch.from_numpy(x), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2249\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2249\"></td>\n          <td id=\"LC2249\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2250\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2250\"></td>\n          <td id=\"LC2250\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     m <span class=\"pl-k\">=</span> PadPackedWrapper() </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2251\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2251\"></td>\n          <td id=\"LC2251\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     m_traced <span class=\"pl-k\">=</span> torch.jit.trace(x, seq_lens)(m) </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2252\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2252\"></td>\n          <td id=\"LC2252\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">  </td>\n        </tr>\n\n        <tr class=\"border-0\">\n          <td id=\"L2253\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"2253\"></td>\n          <td id=\"LC2253\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\">     y <span class=\"pl-k\">=</span> m(x, seq_lens) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>", "body_text": "test failure looks legit: \n  \n    \n      pytorch/test/test_jit.py\n    \n    \n        Lines 2228 to 2253\n      in\n      372d1d6\n    \n    \n    \n    \n\n        \n          \n           def test_pack_padded_pad_packed_trace(self): \n        \n\n        \n          \n               from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n        \n\n        \n          \n               T, B, C = 3, 5, 7 \n        \n\n        \n          \n            \n        \n\n        \n          \n               class PadPackedWrapper(torch.nn.Module): \n        \n\n        \n          \n                   def __init__(self): \n        \n\n        \n          \n                       super(PadPackedWrapper, self).__init__() \n        \n\n        \n          \n            \n        \n\n        \n          \n                   def forward(self, x, seq_lens): \n        \n\n        \n          \n                       x = pack_padded_sequence(x, seq_lens) \n        \n\n        \n          \n                       x, _ = pad_packed_sequence(x) \n        \n\n        \n          \n                       return x \n        \n\n        \n          \n            \n        \n\n        \n          \n               x = np.ones((T, B, C)) \n        \n\n        \n          \n               seq_lens = np.array([3, 3, 2, 2, 1], dtype=np.int32) \n        \n\n        \n          \n               # set padding value so we can test equivalence \n        \n\n        \n          \n               for b in range(B): \n        \n\n        \n          \n                   if seq_lens[b] < T: \n        \n\n        \n          \n                       x[seq_lens[b]:, b, :] = 0 \n        \n\n        \n          \n               seq_lens = torch.from_numpy(seq_lens) \n        \n\n        \n          \n               x = torch.autograd.Variable(torch.from_numpy(x), requires_grad=True) \n        \n\n        \n          \n            \n        \n\n        \n          \n               m = PadPackedWrapper() \n        \n\n        \n          \n               m_traced = torch.jit.trace(x, seq_lens)(m) \n        \n\n        \n          \n            \n        \n\n        \n          \n               y = m(x, seq_lens)", "body": "test failure looks legit: https://github.com/pytorch/pytorch/blob/372d1d67356f054db64bdfb4787871ecdbbcbe0b/test/test_jit.py#L2228-L2253"}