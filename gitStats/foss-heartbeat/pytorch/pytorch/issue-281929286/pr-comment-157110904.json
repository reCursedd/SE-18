{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157110904", "pull_request_review_id": 83701477, "id": 157110904, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NzExMDkwNA==", "diff_hunk": "@@ -0,0 +1,271 @@\n+#pragma once\n+\n+#include <sstream>\n+\n+namespace at {\n+\n+/*\n+ * The basic strategy for apply is as follows:\n+ *\n+ * 1. Starting with the outermost index, loop until we reach a dimension where the\n+ * data is no longer contiguous, i.e. the stride at that dimension is not equal to\n+ * the size of the tensor defined by the outer dimensions. Let's call this outer\n+ * (contiguous) tensor A. Note that if the Tensor is contiguous, then A is equal\n+ * to the entire Tensor. Let's call the inner tensor B.\n+ *\n+ * 2. We loop through the indices in B, starting at its outermost dimension. For\n+ * example, if B is a 2x2 matrix, then we do:\n+ *\n+ * B[0][0]\n+ * B[0][1]\n+ * B[1][0]\n+ * B[1][1]\n+ *\n+ * We set the offset into the underlying storage as (storageOffset + stride_B * index_B),\n+ * i.e. basically we compute the offset into the storage as we would normally for a\n+ * Tensor. But because we are guaranteed the subsequent data is contiguous in memory, we\n+ * can simply loop for sizeof(A) iterations and perform the operation, without having to\n+ * follow the order described by the strides of A.\n+ *\n+ * 3. As an optimization, we merge dimensions of A that are contiguous in memory. For\n+ * example, if A is a 3x3x3x3 tensor narrowed from a 3x3x4x3 tensor, then the first two\n+ * dimensions can be merged for the purposes of APPLY, reducing the number of nested\n+ * loops.\n+ */\n+\n+static inline void check_correct_backend(const Tensor &t, unsigned int pos) {", "path": "aten/src/ATen/CPUApplyUtils.h", "position": 36, "original_position": 36, "commit_id": "196bdb8fd5e5819c66bbef8a9e5a57aedf5a7ec1", "original_commit_id": "6fe366fd1187dab09efe19941cdc793f9feee8a7", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Just for information's sake, there's also some checking code at https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Check.h\r\n\r\nHowever, I am not sure I should recommend you try using it here, because I am not yet sure if allocating these TensorArg structs caused the 10% slowdown in the cuDNN dispatch path :^)", "created_at": "2017-12-15T02:13:06Z", "updated_at": "2018-11-23T15:37:23Z", "html_url": "https://github.com/pytorch/pytorch/pull/4161#discussion_r157110904", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4161", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/157110904"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4161#discussion_r157110904"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4161"}}, "body_html": "<p>Just for information's sake, there's also some checking code at <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Check.h\">https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Check.h</a></p>\n<p>However, I am not sure I should recommend you try using it here, because I am not yet sure if allocating these TensorArg structs caused the 10% slowdown in the cuDNN dispatch path :^)</p>", "body_text": "Just for information's sake, there's also some checking code at https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/Check.h\nHowever, I am not sure I should recommend you try using it here, because I am not yet sure if allocating these TensorArg structs caused the 10% slowdown in the cuDNN dispatch path :^)"}