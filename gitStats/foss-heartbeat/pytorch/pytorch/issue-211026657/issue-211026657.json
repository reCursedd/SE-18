{"url": "https://api.github.com/repos/pytorch/pytorch/issues/882", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/882/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/882/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/882/events", "html_url": "https://github.com/pytorch/pytorch/issues/882", "id": 211026657, "node_id": "MDU6SXNzdWUyMTEwMjY2NTc=", "number": 882, "title": "ByteTensor not working with F.conv2d?", "user": {"login": "transedward", "id": 7189930, "node_id": "MDQ6VXNlcjcxODk5MzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/7189930?v=4", "gravatar_id": "", "url": "https://api.github.com/users/transedward", "html_url": "https://github.com/transedward", "followers_url": "https://api.github.com/users/transedward/followers", "following_url": "https://api.github.com/users/transedward/following{/other_user}", "gists_url": "https://api.github.com/users/transedward/gists{/gist_id}", "starred_url": "https://api.github.com/users/transedward/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/transedward/subscriptions", "organizations_url": "https://api.github.com/users/transedward/orgs", "repos_url": "https://api.github.com/users/transedward/repos", "events_url": "https://api.github.com/users/transedward/events{/privacy}", "received_events_url": "https://api.github.com/users/transedward/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-01T09:40:31Z", "updated_at": "2018-04-04T10:57:14Z", "closed_at": "2017-03-01T11:35:05Z", "author_association": "NONE", "body_html": "<p><code>print(model(Variable(obs, volatile=True)))</code></p>\n<p>I encounter when executing this line</p>\n<p>obs is a size(1, 4, 84, 84) ByteTensor corresponding to (input_size, channels, height, width)</p>\n<p>Here is my model definition:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">DQN</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">in_channels</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-smi\">num_actions</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">18</span>):\n        <span class=\"pl-c1\">super</span>(<span class=\"pl-c1\">DQN</span>, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> nn.Conv2d(in_channels, <span class=\"pl-c1\">32</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n        <span class=\"pl-c1\">self</span>.conv2 <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n        <span class=\"pl-c1\">self</span>.conv3 <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">64</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">self</span>.fc4 <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">7</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">7</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">64</span>, <span class=\"pl-c1\">512</span>)\n        <span class=\"pl-c1\">self</span>.fc5 <span class=\"pl-k\">=</span> nn.Linear(<span class=\"pl-c1\">512</span>, num_actions)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv1(x))\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv2(x))\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv3(x))\n        x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.fc4(x.view(x.size(<span class=\"pl-c1\">0</span>), <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)))\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.fc5(x)</pre></div>\n<p>Below are errors:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>module.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">208</span> \n    <span class=\"pl-c1\">209</span>     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">input</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">210</span>         result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">211</span>         <span class=\"pl-k\">for</span> hook <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>._forward_hooks.values():\n    <span class=\"pl-c1\">212</span>             hook_result <span class=\"pl-k\">=</span> hook(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, result)\n\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">25</span><span class=\"pl-k\">-</span><span class=\"pl-ii\">3131e91fac28</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, x)\n     <span class=\"pl-c1\">17</span> \n     <span class=\"pl-c1\">18</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">19</span>         x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv1(x))\n     <span class=\"pl-c1\">20</span>         x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv2(x))\n     <span class=\"pl-c1\">21</span>         x <span class=\"pl-k\">=</span> F.relu(<span class=\"pl-c1\">self</span>.conv3(x))\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>module.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">208</span> \n    <span class=\"pl-c1\">209</span>     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">input</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">210</span>         result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-c1\">211</span>         <span class=\"pl-k\">for</span> hook <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>._forward_hooks.values():\n    <span class=\"pl-c1\">212</span>             hook_result <span class=\"pl-k\">=</span> hook(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, result)\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>)\n    <span class=\"pl-c1\">235</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>):\n    <span class=\"pl-c1\">236</span>         <span class=\"pl-k\">return</span> F.conv2d(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight, <span class=\"pl-c1\">self</span>.bias, <span class=\"pl-c1\">self</span>.stride,\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">237</span>                         <span class=\"pl-c1\">self</span>.padding, <span class=\"pl-c1\">self</span>.dilation, <span class=\"pl-c1\">self</span>.groups)\n    <span class=\"pl-c1\">238</span> \n    <span class=\"pl-c1\">239</span> \n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>functional.py <span class=\"pl-k\">in</span> conv2d(<span class=\"pl-c1\">input</span>, weight, bias, stride, padding, dilation, groups)\n     <span class=\"pl-c1\">35</span>     f <span class=\"pl-k\">=</span> ConvNd(_pair(stride), _pair(padding), _pair(dilation), <span class=\"pl-c1\">False</span>,\n     <span class=\"pl-c1\">36</span>                _pair(<span class=\"pl-c1\">0</span>), groups)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">37</span>     <span class=\"pl-k\">return</span> f(<span class=\"pl-c1\">input</span>, weight, bias) <span class=\"pl-k\">if</span> bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span> <span class=\"pl-k\">else</span> f(<span class=\"pl-c1\">input</span>, weight)\n     <span class=\"pl-c1\">38</span> \n     <span class=\"pl-c1\">39</span> \n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>_functions<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, weight, bias)\n     <span class=\"pl-c1\">32</span>         <span class=\"pl-k\">if</span> k <span class=\"pl-k\">==</span> <span class=\"pl-c1\">3</span>:\n     <span class=\"pl-c1\">33</span>             <span class=\"pl-c1\">input</span>, weight <span class=\"pl-k\">=</span> _view4d(<span class=\"pl-c1\">input</span>, weight)\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">34</span>         output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._update_output(<span class=\"pl-c1\">input</span>, weight, bias)\n     <span class=\"pl-c1\">35</span>         <span class=\"pl-k\">if</span> k <span class=\"pl-k\">==</span> <span class=\"pl-c1\">3</span>:\n     <span class=\"pl-c1\">36</span>             output, <span class=\"pl-k\">=</span> _view3d(output)\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>_functions<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> _update_output(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, weight, bias)\n     <span class=\"pl-c1\">89</span> \n     <span class=\"pl-c1\">90</span>         <span class=\"pl-c1\">self</span>._bufs <span class=\"pl-k\">=</span> [[] <span class=\"pl-k\">for</span> g <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>.groups)]\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">91</span>         <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._thnn(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>update_output<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">input</span>, weight, bias)\n     <span class=\"pl-c1\">92</span> \n     <span class=\"pl-c1\">93</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">_grad_input</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">weight</span>, <span class=\"pl-smi\">grad_output</span>):\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>_functions<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> _thnn(<span class=\"pl-c1\">self</span>, fn_name, <span class=\"pl-c1\">input</span>, weight, <span class=\"pl-k\">*</span>args)\n    <span class=\"pl-c1\">148</span>         impl <span class=\"pl-k\">=</span> _thnn_convs[<span class=\"pl-c1\">self</span>.thnn_class_name(<span class=\"pl-c1\">input</span>)]\n    <span class=\"pl-c1\">149</span>         <span class=\"pl-k\">if</span> <span class=\"pl-c1\">self</span>.groups <span class=\"pl-k\">==</span> <span class=\"pl-c1\">1</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">150</span>             <span class=\"pl-k\">return</span> impl[fn_name](<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">self</span>._bufs[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">input</span>, weight, <span class=\"pl-k\">*</span>args)\n    <span class=\"pl-c1\">151</span>         <span class=\"pl-k\">else</span>:\n    <span class=\"pl-c1\">152</span>             res <span class=\"pl-k\">=</span> []\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>_functions<span class=\"pl-k\">/</span>conv.py <span class=\"pl-k\">in</span> call_update_output(<span class=\"pl-c1\">self</span>, bufs, <span class=\"pl-c1\">input</span>, weight, bias)\n    <span class=\"pl-c1\">220</span> <span class=\"pl-k\">def</span> <span class=\"pl-en\">make_update_output</span>(<span class=\"pl-smi\">fn</span>):\n    <span class=\"pl-c1\">221</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">call_update_output</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">bufs</span>, <span class=\"pl-smi\">input</span>, <span class=\"pl-smi\">weight</span>, <span class=\"pl-smi\">bias</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">222</span>         backend <span class=\"pl-k\">=</span> type2backend[<span class=\"pl-c1\">type</span>(<span class=\"pl-c1\">input</span>)]\n    <span class=\"pl-c1\">223</span>         bufs.extend([<span class=\"pl-c1\">input</span>.new(), <span class=\"pl-c1\">input</span>.new()])\n    <span class=\"pl-c1\">224</span>         output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.new(<span class=\"pl-k\">*</span><span class=\"pl-c1\">self</span>._output_size(<span class=\"pl-c1\">input</span>, weight))\n\n<span class=\"pl-k\">/</span>Users<span class=\"pl-k\">/</span>mac<span class=\"pl-k\">/</span>anaconda<span class=\"pl-k\">/</span>envs<span class=\"pl-k\">/</span>py35<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.5<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>_thnn<span class=\"pl-k\">/</span><span class=\"pl-c1\">__init__</span>.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-c1\">self</span>, name)\n     <span class=\"pl-c1\">13</span> \n     <span class=\"pl-c1\">14</span>     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">name</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">15</span>         <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.backends[name].load()\n     <span class=\"pl-c1\">16</span> \n     <span class=\"pl-c1\">17</span> \n\n<span class=\"pl-c1\">KeyError</span>: <span class=\"pl-k\">&lt;</span><span class=\"pl-k\">class</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.ByteTensor<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">&gt;</span></pre></div>", "body_text": "print(model(Variable(obs, volatile=True)))\nI encounter when executing this line\nobs is a size(1, 4, 84, 84) ByteTensor corresponding to (input_size, channels, height, width)\nHere is my model definition:\nclass DQN(nn.Module):\n    def __init__(self, in_channels=4, num_actions=18):\n        super(DQN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n        self.fc5 = nn.Linear(512, num_actions)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n        return self.fc5(x)\nBelow are errors:\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    208 \n    209     def __call__(self, *input, **kwargs):\n--> 210         result = self.forward(*input, **kwargs)\n    211         for hook in self._forward_hooks.values():\n    212             hook_result = hook(self, input, result)\n\n<ipython-input-25-3131e91fac28> in forward(self, x)\n     17 \n     18     def forward(self, x):\n---> 19         x = F.relu(self.conv1(x))\n     20         x = F.relu(self.conv2(x))\n     21         x = F.relu(self.conv3(x))\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    208 \n    209     def __call__(self, *input, **kwargs):\n--> 210         result = self.forward(*input, **kwargs)\n    211         for hook in self._forward_hooks.values():\n    212             hook_result = hook(self, input, result)\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/conv.py in forward(self, input)\n    235     def forward(self, input):\n    236         return F.conv2d(input, self.weight, self.bias, self.stride,\n--> 237                         self.padding, self.dilation, self.groups)\n    238 \n    239 \n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py in conv2d(input, weight, bias, stride, padding, dilation, groups)\n     35     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n     36                _pair(0), groups)\n---> 37     return f(input, weight, bias) if bias is not None else f(input, weight)\n     38 \n     39 \n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in forward(self, input, weight, bias)\n     32         if k == 3:\n     33             input, weight = _view4d(input, weight)\n---> 34         output = self._update_output(input, weight, bias)\n     35         if k == 3:\n     36             output, = _view3d(output)\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in _update_output(self, input, weight, bias)\n     89 \n     90         self._bufs = [[] for g in range(self.groups)]\n---> 91         return self._thnn('update_output', input, weight, bias)\n     92 \n     93     def _grad_input(self, input, weight, grad_output):\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in _thnn(self, fn_name, input, weight, *args)\n    148         impl = _thnn_convs[self.thnn_class_name(input)]\n    149         if self.groups == 1:\n--> 150             return impl[fn_name](self, self._bufs[0], input, weight, *args)\n    151         else:\n    152             res = []\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in call_update_output(self, bufs, input, weight, bias)\n    220 def make_update_output(fn):\n    221     def call_update_output(self, bufs, input, weight, bias):\n--> 222         backend = type2backend[type(input)]\n    223         bufs.extend([input.new(), input.new()])\n    224         output = input.new(*self._output_size(input, weight))\n\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/_thnn/__init__.py in __getitem__(self, name)\n     13 \n     14     def __getitem__(self, name):\n---> 15         return self.backends[name].load()\n     16 \n     17 \n\nKeyError: <class 'torch.ByteTensor'>", "body": "`print(model(Variable(obs, volatile=True)))`\r\n\r\nI encounter when executing this line\r\n\r\nobs is a size(1, 4, 84, 84) ByteTensor corresponding to (input_size, channels, height, width)\r\n\r\nHere is my model definition:\r\n\r\n```py\r\nclass DQN(nn.Module):\r\n    def __init__(self, in_channels=4, num_actions=18):\r\n        super(DQN, self).__init__()\r\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\r\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\r\n        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\r\n        self.fc4 = nn.Linear(7 * 7 * 64, 512)\r\n        self.fc5 = nn.Linear(512, num_actions)\r\n\r\n    def forward(self, x):\r\n        x = F.relu(self.conv1(x))\r\n        x = F.relu(self.conv2(x))\r\n        x = F.relu(self.conv3(x))\r\n        x = F.relu(self.fc4(x.view(x.size(0), -1)))\r\n        return self.fc5(x)\r\n```\r\n\r\nBelow are errors:\r\n```py\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    208 \r\n    209     def __call__(self, *input, **kwargs):\r\n--> 210         result = self.forward(*input, **kwargs)\r\n    211         for hook in self._forward_hooks.values():\r\n    212             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-25-3131e91fac28> in forward(self, x)\r\n     17 \r\n     18     def forward(self, x):\r\n---> 19         x = F.relu(self.conv1(x))\r\n     20         x = F.relu(self.conv2(x))\r\n     21         x = F.relu(self.conv3(x))\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    208 \r\n    209     def __call__(self, *input, **kwargs):\r\n--> 210         result = self.forward(*input, **kwargs)\r\n    211         for hook in self._forward_hooks.values():\r\n    212             hook_result = hook(self, input, result)\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/conv.py in forward(self, input)\r\n    235     def forward(self, input):\r\n    236         return F.conv2d(input, self.weight, self.bias, self.stride,\r\n--> 237                         self.padding, self.dilation, self.groups)\r\n    238 \r\n    239 \r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py in conv2d(input, weight, bias, stride, padding, dilation, groups)\r\n     35     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\r\n     36                _pair(0), groups)\r\n---> 37     return f(input, weight, bias) if bias is not None else f(input, weight)\r\n     38 \r\n     39 \r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in forward(self, input, weight, bias)\r\n     32         if k == 3:\r\n     33             input, weight = _view4d(input, weight)\r\n---> 34         output = self._update_output(input, weight, bias)\r\n     35         if k == 3:\r\n     36             output, = _view3d(output)\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in _update_output(self, input, weight, bias)\r\n     89 \r\n     90         self._bufs = [[] for g in range(self.groups)]\r\n---> 91         return self._thnn('update_output', input, weight, bias)\r\n     92 \r\n     93     def _grad_input(self, input, weight, grad_output):\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in _thnn(self, fn_name, input, weight, *args)\r\n    148         impl = _thnn_convs[self.thnn_class_name(input)]\r\n    149         if self.groups == 1:\r\n--> 150             return impl[fn_name](self, self._bufs[0], input, weight, *args)\r\n    151         else:\r\n    152             res = []\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/conv.py in call_update_output(self, bufs, input, weight, bias)\r\n    220 def make_update_output(fn):\r\n    221     def call_update_output(self, bufs, input, weight, bias):\r\n--> 222         backend = type2backend[type(input)]\r\n    223         bufs.extend([input.new(), input.new()])\r\n    224         output = input.new(*self._output_size(input, weight))\r\n\r\n/Users/mac/anaconda/envs/py35/lib/python3.5/site-packages/torch/_thnn/__init__.py in __getitem__(self, name)\r\n     13 \r\n     14     def __getitem__(self, name):\r\n---> 15         return self.backends[name].load()\r\n     16 \r\n     17 \r\n\r\nKeyError: <class 'torch.ByteTensor'>\r\n```"}