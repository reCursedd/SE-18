{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/274271397", "html_url": "https://github.com/pytorch/pytorch/issues/517#issuecomment-274271397", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/517", "id": 274271397, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NDI3MTM5Nw==", "user": {"login": "shawnjhenry", "id": 9464836, "node_id": "MDQ6VXNlcjk0NjQ4MzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/9464836?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shawnjhenry", "html_url": "https://github.com/shawnjhenry", "followers_url": "https://api.github.com/users/shawnjhenry/followers", "following_url": "https://api.github.com/users/shawnjhenry/following{/other_user}", "gists_url": "https://api.github.com/users/shawnjhenry/gists{/gist_id}", "starred_url": "https://api.github.com/users/shawnjhenry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shawnjhenry/subscriptions", "organizations_url": "https://api.github.com/users/shawnjhenry/orgs", "repos_url": "https://api.github.com/users/shawnjhenry/repos", "events_url": "https://api.github.com/users/shawnjhenry/events{/privacy}", "received_events_url": "https://api.github.com/users/shawnjhenry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-21T16:21:35Z", "updated_at": "2017-01-21T16:36:54Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1455742\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/braingineer\">@braingineer</a> When doing backpropagation through time, at time step <code>t</code> the gradient is computed using the gradient of time step <code>t+1</code> with respect to the hidden state(s), which are the output(s) of time step <code>t</code>.  Therefore, the gradient from <code>t+1</code> has to be masked identically to the output of <code>t</code>.</p>\n<p>Masking using sentinel values seems like a bad idea to me.  In the (admittedly unlikely if you do things carefully but you never know) situation where a coordinate that shouldn't be masked happens to take on the sentinel value, you'll prevent that coordinate from learning.</p>\n<p>For instance, if you compute the mask immediately after an embedding lookup and use a sentinel value of zero, if any of the embeddings that shouldn't be masked happen to have zeros in them, those coordinate will never learn.</p>", "body_text": "@braingineer When doing backpropagation through time, at time step t the gradient is computed using the gradient of time step t+1 with respect to the hidden state(s), which are the output(s) of time step t.  Therefore, the gradient from t+1 has to be masked identically to the output of t.\nMasking using sentinel values seems like a bad idea to me.  In the (admittedly unlikely if you do things carefully but you never know) situation where a coordinate that shouldn't be masked happens to take on the sentinel value, you'll prevent that coordinate from learning.\nFor instance, if you compute the mask immediately after an embedding lookup and use a sentinel value of zero, if any of the embeddings that shouldn't be masked happen to have zeros in them, those coordinate will never learn.", "body": "@braingineer When doing backpropagation through time, at time step `t` the gradient is computed using the gradient of time step `t+1` with respect to the hidden state(s), which are the output(s) of time step `t`.  Therefore, the gradient from `t+1` has to be masked identically to the output of `t`.\r\n\r\nMasking using sentinel values seems like a bad idea to me.  In the (admittedly unlikely if you do things carefully but you never know) situation where a coordinate that shouldn't be masked happens to take on the sentinel value, you'll prevent that coordinate from learning.\r\n\r\nFor instance, if you compute the mask immediately after an embedding lookup and use a sentinel value of zero, if any of the embeddings that shouldn't be masked happen to have zeros in them, those coordinate will never learn."}