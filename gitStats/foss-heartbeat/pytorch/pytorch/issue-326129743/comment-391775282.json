{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/391775282", "html_url": "https://github.com/pytorch/pytorch/pull/7809#issuecomment-391775282", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7809", "id": 391775282, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTc3NTI4Mg==", "user": {"login": "jekbradbury", "id": 11729078, "node_id": "MDQ6VXNlcjExNzI5MDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11729078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jekbradbury", "html_url": "https://github.com/jekbradbury", "followers_url": "https://api.github.com/users/jekbradbury/followers", "following_url": "https://api.github.com/users/jekbradbury/following{/other_user}", "gists_url": "https://api.github.com/users/jekbradbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/jekbradbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jekbradbury/subscriptions", "organizations_url": "https://api.github.com/users/jekbradbury/orgs", "repos_url": "https://api.github.com/users/jekbradbury/repos", "events_url": "https://api.github.com/users/jekbradbury/events{/privacy}", "received_events_url": "https://api.github.com/users/jekbradbury/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-24T16:21:11Z", "updated_at": "2018-05-24T16:24:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>One potential problem is that <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"322453596\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/7511\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/7511/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/7511\">#7511</a> brings PyTorch closer to ONNX spec conformance but doesn't get us all the way there (cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1388690\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/anderspapitto\">@anderspapitto</a>). The ONNX spec gives the output as <code>[seq_length, num_directions, batch_size, hidden_size]</code>, while PyTorch produces <code>seq_len, batch, hidden_size * num_directions</code>. Since we're trying to convert the output of the ONNX RNN/LSTM/GRU node into the shape that PyTorch produces, we need to first move <code>num_directions</code> into the last dimension slot, then reshape into a 3D tensor. Just doing a reshape will give the wrong results.<br>\nCurrently we have</p>\n<pre><code>if bidirectional:\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\n</code></pre>\n<p>That is, only a reshape.<br>\nWhat we need is:</p>\n<pre><code>if bidirectional:\n    # Reorder dimensions from seq_len, num_directions, batch, hidden_size in ONNX\n    # to seq_len, batch, hidden_size * num_directions\n    prev_output = g.op('Transpose', prev_output, perm_i=[0, 2, 3, 1])\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\n</code></pre>\n<p>Plus the equivalent changes on the C++ side (for detecting and moving PackPadded/PadPacked) and in Caffe2.</p>", "body_text": "One potential problem is that #7511 brings PyTorch closer to ONNX spec conformance but doesn't get us all the way there (cc @anderspapitto). The ONNX spec gives the output as [seq_length, num_directions, batch_size, hidden_size], while PyTorch produces seq_len, batch, hidden_size * num_directions. Since we're trying to convert the output of the ONNX RNN/LSTM/GRU node into the shape that PyTorch produces, we need to first move num_directions into the last dimension slot, then reshape into a 3D tensor. Just doing a reshape will give the wrong results.\nCurrently we have\nif bidirectional:\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\n\nThat is, only a reshape.\nWhat we need is:\nif bidirectional:\n    # Reorder dimensions from seq_len, num_directions, batch, hidden_size in ONNX\n    # to seq_len, batch, hidden_size * num_directions\n    prev_output = g.op('Transpose', prev_output, perm_i=[0, 2, 3, 1])\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\n\nPlus the equivalent changes on the C++ side (for detecting and moving PackPadded/PadPacked) and in Caffe2.", "body": "One potential problem is that https://github.com/pytorch/pytorch/pull/7511 brings PyTorch closer to ONNX spec conformance but doesn't get us all the way there (cc @anderspapitto). The ONNX spec gives the output as `[seq_length, num_directions, batch_size, hidden_size]`, while PyTorch produces `seq_len, batch, hidden_size * num_directions`. Since we're trying to convert the output of the ONNX RNN/LSTM/GRU node into the shape that PyTorch produces, we need to first move `num_directions` into the last dimension slot, then reshape into a 3D tensor. Just doing a reshape will give the wrong results.\r\nCurrently we have\r\n```\r\nif bidirectional:\r\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\r\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\r\n```\r\nThat is, only a reshape.\r\nWhat we need is:\r\n```\r\nif bidirectional:\r\n    # Reorder dimensions from seq_len, num_directions, batch, hidden_size in ONNX\r\n    # to seq_len, batch, hidden_size * num_directions\r\n    prev_output = g.op('Transpose', prev_output, perm_i=[0, 2, 3, 1])\r\n    prev_output = g.op('Reshape', prev_output, g.op('Constant', value_t=torch.LongTensor([0, 1, 0, -1])))\r\nprev_output = g.op('Squeeze', prev_output, axes_i=[1])\r\n```\r\nPlus the equivalent changes on the C++ side (for detecting and moving PackPadded/PadPacked) and in Caffe2."}