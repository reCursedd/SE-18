{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210425501", "pull_request_review_id": 146639175, "id": 210425501, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMDQyNTUwMQ==", "diff_hunk": "@@ -47,6 +47,81 @@ std::tuple<Tensor, Tensor> _unique_cpu_template(\n   }\n   return std::make_tuple(output, inverse_indices);\n }\n+\n+template <typename scalar_t>\n+std::tuple<Tensor, Tensor> _unique_dim_cpu_template(\n+    const Tensor& self,\n+    const int64_t dim,\n+    const bool return_inverse) {\n+  // reshape tensor as [dim, -1]\n+  Tensor input_flat = self.transpose(dim, 0);\n+  std::vector<int64_t> orig_sizes(input_flat.sizes().begin(), input_flat.sizes().end());\n+  input_flat = input_flat.contiguous().view({input_flat.size(0), -1});\n+\n+  std::vector<int64_t> indices(input_flat.size(0));\n+  std::iota(indices.begin(), indices.end(), 0);\n+  int64_t numel = input_flat.size(1);\n+  scalar_t* input_flat_ptr = ((scalar_t*)input_flat.data_ptr());\n+\n+  // sort indices using data\n+  std::sort(indices.begin(), indices.end(),\n+    [&](int64_t a, int64_t b) -> bool {\n+      for (int64_t i = 0; i < numel; ++i) {\n+        scalar_t lhs = input_flat_ptr[i + a * numel];\n+        scalar_t rhs = input_flat_ptr[i + b * numel];\n+        if (lhs < rhs) {\n+          return true;\n+        } else if (lhs > rhs) {\n+          return false;\n+        }\n+      }\n+      return false;\n+    });\n+\n+  Tensor input_sorted = at::empty(input_flat.sizes(), input_flat.type());\n+  for (int i = 0; i < indices.size(); ++i) {\n+    input_sorted[i] = input_flat[indices[i]];\n+  }\n+ \n+  // pre-calculate mask for inverse_indices\n+  Tensor mask = at::empty(input_sorted.size(0), self.type().toScalarType(kLong));\n+  mask[0] = 1;\n+  int mask_idx = 1;\n+\n+  std::vector<Tensor> input_unbind = at::unbind(input_sorted, 0);\n+  auto last = std::unique(input_unbind.begin(), input_unbind.end(), [&](Tensor a, Tensor b) {", "path": "aten/src/ATen/native/Unique.cpp", "position": null, "original_position": 46, "commit_id": "5a8ecf2e7c59e42c089cd3d41a66041990730b1b", "original_commit_id": "cbafa5b2b3fcaa704fd43c92a57d00a2e23114cb", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Yes, without the mask and the cumsum call.\r\n\r\nThere are two reasons for this:\r\n1) I think it will be faster and may be less code\r\n2) The current implementation assumes a certain implementation of std::unique that may not be true. (That unique traverses input_unbind once in order). While this is probably true for all implementations, I don't think it's guaranteed by the standard.", "created_at": "2018-08-15T22:09:45Z", "updated_at": "2018-11-23T15:49:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/10423#discussion_r210425501", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10423", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210425501"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10423#discussion_r210425501"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10423"}}, "body_html": "<p>Yes, without the mask and the cumsum call.</p>\n<p>There are two reasons for this:</p>\n<ol>\n<li>I think it will be faster and may be less code</li>\n<li>The current implementation assumes a certain implementation of std::unique that may not be true. (That unique traverses input_unbind once in order). While this is probably true for all implementations, I don't think it's guaranteed by the standard.</li>\n</ol>", "body_text": "Yes, without the mask and the cumsum call.\nThere are two reasons for this:\n\nI think it will be faster and may be less code\nThe current implementation assumes a certain implementation of std::unique that may not be true. (That unique traverses input_unbind once in order). While this is probably true for all implementations, I don't think it's guaranteed by the standard.", "in_reply_to_id": 209964206}