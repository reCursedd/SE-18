{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210429053", "pull_request_review_id": 146643171, "id": 210429053, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMDQyOTA1Mw==", "diff_hunk": "@@ -69,6 +70,92 @@ template <typename scalar_t>\n     return std::tuple<Tensor, Tensor>(output, inverse_indices);\n \n   }\n+\n+template <typename scalar_t>\n+  std::tuple<Tensor, Tensor> _unique_dim_cuda_template(\n+    const Tensor& self,\n+    const int64_t dim,\n+    const bool return_inverse) {\n+\n+    cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n+    auto allocator = THCThrustAllocator(globalContext().lazyInitCUDA());\n+    auto policy = thrust::cuda::par(allocator).on(stream);\n+\n+    Tensor input_flat = self.transpose(dim, 0);\n+    auto orig_sizes = input_flat.sizes().vec();\n+    input_flat = input_flat.contiguous().view({input_flat.size(0), -1});\n+\n+    scalar_t* input_flat_ptr = input_flat.data<scalar_t>();\n+\n+    Tensor indices = at::arange(0, input_flat.size(0), self.type().toScalarType(kLong));\n+    int64_t* indices_ptr = indices.data<int64_t>();\n+    int64_t numel = input_flat.size(1);\n+\n+    // sort indices using data\n+    thrust::sort(policy, indices_ptr, indices_ptr + indices.numel(),\n+      [=] __device__ (int64_t a, int64_t b) -> bool {\n+        for (int64_t i = 0; i < numel; ++i) {\n+          scalar_t lhs = input_flat_ptr[i + a * numel];\n+          scalar_t rhs = input_flat_ptr[i + b * numel];\n+          if (lhs < rhs) {\n+            return true;\n+          } else if (lhs > rhs) {\n+            return false;\n+          }\n+        }\n+        return false;\n+      });\n+\n+    Tensor input_sorted = input_flat.index_select(0, indices);\n+\n+    // get unique tensors\n+    scalar_t* input_sorted_ptr = input_sorted.data<scalar_t>();    \n+    Tensor input_sorted_indices = at::arange(0, input_sorted.size(0), self.type().toScalarType(kLong));\n+    int64_t* input_sorted_indices_ptr = input_sorted_indices.data<int64_t>();\n+    auto last = thrust::unique(policy, input_sorted_indices_ptr, input_sorted_indices_ptr + input_sorted_indices.numel(),\n+      [=] __device__ (int64_t a, int64_t b) -> bool {\n+        for (int64_t i = 0; i < numel; ++i) {\n+          scalar_t lhs = input_sorted_ptr[i + a * numel];\n+          scalar_t rhs = input_sorted_ptr[i + b * numel];\n+          if (lhs != rhs) {\n+            return false;\n+          }\n+        }\n+        return true;\n+      });\n+    input_sorted_indices.resize_(last - input_sorted_indices_ptr);\n+    Tensor output = input_sorted.index_select(0, input_sorted_indices);\n+\n+    // // reshape back\n+    std::vector<int64_t> new_sizes(orig_sizes.begin(), orig_sizes.end());", "path": "aten/src/ATen/native/cuda/Unique.cu", "position": null, "original_position": 69, "commit_id": "5a8ecf2e7c59e42c089cd3d41a66041990730b1b", "original_commit_id": "cbafa5b2b3fcaa704fd43c92a57d00a2e23114cb", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "In that case you can just use the copy-constructor. (It's fine to make a copy here).\r\n\r\nThis will work:\r\n\r\n```\r\nstd::vector<int64_t> new_sizes = orig_sizes;\r\n```\r\n\r\nI generally prefer this syntax:\r\n\r\n```\r\nauto new_sizes = std::vector<int64_t>(orig_sizes);\r\n```", "created_at": "2018-08-15T22:25:56Z", "updated_at": "2018-11-23T15:49:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/10423#discussion_r210429053", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10423", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210429053"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10423#discussion_r210429053"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10423"}}, "body_html": "<p>In that case you can just use the copy-constructor. (It's fine to make a copy here).</p>\n<p>This will work:</p>\n<pre><code>std::vector&lt;int64_t&gt; new_sizes = orig_sizes;\n</code></pre>\n<p>I generally prefer this syntax:</p>\n<pre><code>auto new_sizes = std::vector&lt;int64_t&gt;(orig_sizes);\n</code></pre>", "body_text": "In that case you can just use the copy-constructor. (It's fine to make a copy here).\nThis will work:\nstd::vector<int64_t> new_sizes = orig_sizes;\n\nI generally prefer this syntax:\nauto new_sizes = std::vector<int64_t>(orig_sizes);", "in_reply_to_id": 209757401}