{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/401558779", "html_url": "https://github.com/pytorch/pytorch/pull/9052#issuecomment-401558779", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9052", "id": 401558779, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTU1ODc3OQ==", "user": {"login": "vishwakftw", "id": 23639302, "node_id": "MDQ6VXNlcjIzNjM5MzAy", "avatar_url": "https://avatars2.githubusercontent.com/u/23639302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vishwakftw", "html_url": "https://github.com/vishwakftw", "followers_url": "https://api.github.com/users/vishwakftw/followers", "following_url": "https://api.github.com/users/vishwakftw/following{/other_user}", "gists_url": "https://api.github.com/users/vishwakftw/gists{/gist_id}", "starred_url": "https://api.github.com/users/vishwakftw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vishwakftw/subscriptions", "organizations_url": "https://api.github.com/users/vishwakftw/orgs", "repos_url": "https://api.github.com/users/vishwakftw/repos", "events_url": "https://api.github.com/users/vishwakftw/events{/privacy}", "received_events_url": "https://api.github.com/users/vishwakftw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-30T18:38:23Z", "updated_at": "2018-06-30T18:38:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>A few comments: <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a></p>\n<ol>\n<li>Naming - <code>pinverse</code> instead of <code>pinv</code>: PyTorch has <code>inverse</code> for matrix inverse, hence the convention.</li>\n<li>Tests in <code>test_autograd.py</code>: I had a thought about it initially, but pseudoinverses are discontinuous. Derivatives exist for a constant rank only. Ref: <a href=\"https://mathoverflow.net/questions/25778/analytical-formula-for-numerical-derivative-of-the-matrix-pseudo-inverse\" rel=\"nofollow\">https://mathoverflow.net/questions/25778/analytical-formula-for-numerical-derivative-of-the-matrix-pseudo-inverse</a></li>\n</ol>", "body_text": "A few comments: @SsnL\n\nNaming - pinverse instead of pinv: PyTorch has inverse for matrix inverse, hence the convention.\nTests in test_autograd.py: I had a thought about it initially, but pseudoinverses are discontinuous. Derivatives exist for a constant rank only. Ref: https://mathoverflow.net/questions/25778/analytical-formula-for-numerical-derivative-of-the-matrix-pseudo-inverse", "body": "A few comments: @SsnL \r\n1. Naming - `pinverse` instead of `pinv`: PyTorch has `inverse` for matrix inverse, hence the convention.\r\n2. Tests in `test_autograd.py`: I had a thought about it initially, but pseudoinverses are discontinuous. Derivatives exist for a constant rank only. Ref: https://mathoverflow.net/questions/25778/analytical-formula-for-numerical-derivative-of-the-matrix-pseudo-inverse"}