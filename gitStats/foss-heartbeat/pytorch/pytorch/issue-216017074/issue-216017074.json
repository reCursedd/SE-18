{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1058", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1058/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1058/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1058/events", "html_url": "https://github.com/pytorch/pytorch/issues/1058", "id": 216017074, "node_id": "MDU6SXNzdWUyMTYwMTcwNzQ=", "number": 1058, "title": "CosineEmbeddingLoss tensor sizes not matching when grad_output != 1", "user": {"login": "MatthiasKohl", "id": 344856, "node_id": "MDQ6VXNlcjM0NDg1Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/344856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MatthiasKohl", "html_url": "https://github.com/MatthiasKohl", "followers_url": "https://api.github.com/users/MatthiasKohl/followers", "following_url": "https://api.github.com/users/MatthiasKohl/following{/other_user}", "gists_url": "https://api.github.com/users/MatthiasKohl/gists{/gist_id}", "starred_url": "https://api.github.com/users/MatthiasKohl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MatthiasKohl/subscriptions", "organizations_url": "https://api.github.com/users/MatthiasKohl/orgs", "repos_url": "https://api.github.com/users/MatthiasKohl/repos", "events_url": "https://api.github.com/users/MatthiasKohl/events{/privacy}", "received_events_url": "https://api.github.com/users/MatthiasKohl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2017-03-22T10:34:40Z", "updated_at": "2017-03-23T00:06:57Z", "closed_at": "2017-03-23T00:06:57Z", "author_association": "NONE", "body_html": "<p>The following code produces an error for me (torch version string 0.1.10_2):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\ncos_loss <span class=\"pl-k\">=</span> nn.CosineEmbeddingLoss()\nt1 <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">5</span>)\nt2 <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">5</span>)\nlab <span class=\"pl-k\">=</span> t1.sum(<span class=\"pl-c1\">1</span>).ge(<span class=\"pl-c1\">0</span>).long() <span class=\"pl-k\">*</span> <span class=\"pl-c1\">2</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>\nloss1 <span class=\"pl-k\">=</span> cos_loss(Variable(t1, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>), Variable(t2), Variable(lab))\nloss2 <span class=\"pl-k\">=</span> loss1 <span class=\"pl-k\">/</span> <span class=\"pl-c1\">10</span>\nloss2.backward()</pre></div>\n<p>Error is:<br>\nRuntimeError: inconsistent tensor size at /data/users/soumith/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:842</p>\n<p>I don't think this should produce an error. Can you tell me if this is already known/being fixed or how we should work around it ? I'm assuming that in nn/_functions/loss - <code>CosineEmbeddingLoss(Function)</code> - <code>backward()</code>, you should be doing something like <code>gw1.mul_(grad_output[0])</code> at the end instead of <code>gw1.mul_(grad_output)</code></p>", "body_text": "The following code produces an error for me (torch version string 0.1.10_2):\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\ncos_loss = nn.CosineEmbeddingLoss()\nt1 = torch.randn(10, 5)\nt2 = torch.randn(10, 5)\nlab = t1.sum(1).ge(0).long() * 2 - 1\nloss1 = cos_loss(Variable(t1, requires_grad=True), Variable(t2), Variable(lab))\nloss2 = loss1 / 10\nloss2.backward()\nError is:\nRuntimeError: inconsistent tensor size at /data/users/soumith/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:842\nI don't think this should produce an error. Can you tell me if this is already known/being fixed or how we should work around it ? I'm assuming that in nn/_functions/loss - CosineEmbeddingLoss(Function) - backward(), you should be doing something like gw1.mul_(grad_output[0]) at the end instead of gw1.mul_(grad_output)", "body": "The following code produces an error for me (torch version string 0.1.10_2):\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\n\r\ncos_loss = nn.CosineEmbeddingLoss()\r\nt1 = torch.randn(10, 5)\r\nt2 = torch.randn(10, 5)\r\nlab = t1.sum(1).ge(0).long() * 2 - 1\r\nloss1 = cos_loss(Variable(t1, requires_grad=True), Variable(t2), Variable(lab))\r\nloss2 = loss1 / 10\r\nloss2.backward()\r\n```\r\nError is:\r\nRuntimeError: inconsistent tensor size at /data/users/soumith/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:842\r\n\r\nI don't think this should produce an error. Can you tell me if this is already known/being fixed or how we should work around it ? I'm assuming that in nn/_functions/loss - `CosineEmbeddingLoss(Function)` - `backward()`, you should be doing something like `gw1.mul_(grad_output[0])` at the end instead of `gw1.mul_(grad_output)`"}