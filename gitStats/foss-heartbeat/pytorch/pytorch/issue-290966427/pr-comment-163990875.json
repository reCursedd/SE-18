{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163990875", "pull_request_review_id": 91698596, "id": 163990875, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Mzk5MDg3NQ==", "diff_hunk": "@@ -421,7 +421,7 @@ at::Tensor _convolution_nogroup(\n           stride, padding, output_padding, dilation);\n     } else if (dim == 5) {\n       return at::thnn_conv_transpose3d(\n-        input, weight, bias,\n+        input, weight, kernel_size, bias,", "path": "aten/src/ATen/native/Convolution.cpp", "position": 5, "original_position": 5, "commit_id": "3a88ed4d44796f853ebf4248391cbf4d64f08271", "original_commit_id": "fdfb2811930294d68a5a617c508b3806d779249e", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "@fmassa you are right. These values can be computed from output size. However, the original code uses kernel sizes to check the shape of `gradOutput`, and I don't want to relax the check. Furthermore, I don't understand why this is going to a big issue. Every other 3D THNN function I've seen that uses a kernel has these as input arguments.", "created_at": "2018-01-25T22:45:28Z", "updated_at": "2018-11-23T15:38:36Z", "html_url": "https://github.com/pytorch/pytorch/pull/4812#discussion_r163990875", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4812", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/163990875"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4812#discussion_r163990875"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4812"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a> you are right. These values can be computed from output size. However, the original code uses kernel sizes to check the shape of <code>gradOutput</code>, and I don't want to relax the check. Furthermore, I don't understand why this is going to a big issue. Every other 3D THNN function I've seen that uses a kernel has these as input arguments.</p>", "body_text": "@fmassa you are right. These values can be computed from output size. However, the original code uses kernel sizes to check the shape of gradOutput, and I don't want to relax the check. Furthermore, I don't understand why this is going to a big issue. Every other 3D THNN function I've seen that uses a kernel has these as input arguments.", "in_reply_to_id": 163782838}