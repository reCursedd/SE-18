{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179900210", "pull_request_review_id": 110237737, "id": 179900210, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3OTkwMDIxMA==", "diff_hunk": "@@ -0,0 +1,416 @@\n+#include \"caffe2/opt/backend_cutting.h\"\n+#include \"caffe2/core/logging.h\"\n+#include \"nomnigraph/Converters/Caffe2.h\"\n+#include \"nomnigraph/Converters/Dot.h\"\n+#include \"nomnigraph/Representations/NeuralNet.h\"\n+\n+#include <algorithm>\n+#include <fstream>\n+#include <queue>\n+\n+namespace caffe2 {\n+namespace opt {\n+\n+namespace {\n+\n+using NodeRef = nom::repr::NNGraph::NodeRef;\n+using EdgeRef = nom::repr::NNGraph::EdgeRef;\n+\n+class GroupAnnotation {\n+ public:\n+  GroupAnnotation(int i, int g = -1) : group(g), in_degree(i) {}\n+  int group;\n+  int in_degree;\n+  bool needs_transform{true};\n+};\n+\n+struct VisitorContext {\n+  VisitorContext(std::function<bool(const caffe2::OperatorDef&)> func)\n+      : predicate(func) {}\n+  std::unordered_map<NodeRef, GroupAnnotation> infos;\n+  std::unordered_set<NodeRef> frontier;\n+  std::vector<NodeRef> current_group;\n+  std::function<bool(const caffe2::OperatorDef&)> predicate;\n+\n+  int group{0};\n+  bool find_supported{true};\n+};\n+\n+std::string ShowNode(NodeRef node) {\n+  auto* node_data = node->data().get();\n+  if (isa<nom::repr::NeuralNetData>(node_data)) {\n+    const auto* nn_tensor = dyn_cast<const nom::repr::NeuralNetData>(node_data);\n+    return MakeString(\"Tensor: \", nn_tensor->getName());\n+  } else if (isa<nom::repr::NeuralNetOperator>(node_data)) {\n+    const auto* nn_op = dyn_cast<const nom::repr::NeuralNetOperator>(node_data);\n+    const auto* op_def = reinterpret_cast<const caffe2::OperatorDef*>(\n+        nn_op->getAnnotation()->getSaved());\n+    CAFFE_ENFORCE(op_def);\n+    return MakeString(\"Op: \", op_def->type());\n+  } else {\n+    CAFFE_THROW(\"Known node\");\n+  }\n+}\n+\n+void DumpGraph(nom::repr::NNGraph* g) {\n+  auto nnprinter = [](typename nom::repr::NNGraph::NodeRef node) {\n+    std::map<std::string, std::string> labelMap;\n+    assert(node->data() && \"Node doesn't have data, can't render it\");\n+    if (isa<nom::repr::NeuralNetOperator>(node->data())) {\n+      auto* op = dyn_cast<nom::repr::NeuralNetOperator>(node->data().get());\n+      labelMap[\"label\"] =\n+          op->getName() + \" (\" + std::to_string((unsigned long long)node) + \")\";\n+      auto* annotation = op->getAnnotation();\n+      if (annotation && isa<nom::repr::DeviceAnnotation>(annotation)) {\n+        auto device_annotation =\n+            dyn_cast<nom::repr::DeviceAnnotation>(annotation);\n+        labelMap[\"label\"] += \"\\\\n[\" + device_annotation->getDevice() + \"]\";\n+        auto hash = std::hash<std::string>{}(device_annotation->getDevice());\n+        std::stringstream hex_stream;\n+        hex_stream << std::hex << hash;\n+        labelMap[\"color\"] = \"#\" + hex_stream.str().substr(0, 6);\n+        labelMap[\"fontcolor\"] = labelMap[\"color\"];\n+      }\n+      labelMap[\"shape\"] = \"box\";\n+    } else if (isa<nom::repr::Data>(node->data())) {\n+      auto tensor = dyn_cast<nom::repr::NeuralNetData>(node->data().get());\n+      labelMap[\"label\"] = tensor->getName();\n+      labelMap[\"label\"] += \"_\" + std::to_string(tensor->getVersion()) + \" \" +\n+          std::to_string((unsigned long long)node);\n+    }\n+    return labelMap;\n+  };\n+\n+  std::ofstream out(\"dump.dot\");\n+  out << nom::converters::convertToDotString(g, nnprinter);\n+  out.close();\n+}\n+\n+// Explore the graph in topological order until we hit stopping nodes. This is\n+// based on Khan's algorithm:\n+// https://en.wikipedia.org/wiki/Topological_sorting#Kahn's_algorithm\n+// Precondition: nodes in `current_frontier` must have satisfy `in_degree == 0`\n+void Explore(\n+    const std::vector<NodeRef>& current_frontier,\n+    VisitorContext* context) {\n+  std::queue<NodeRef> q;\n+  for (const auto n : current_frontier) {\n+    q.push(n);\n+  }\n+\n+  while (!q.empty()) {\n+    auto node = q.front();\n+    q.pop();\n+    auto& info = context->infos.at(node);\n+\n+    // Check if the node is supported, stop exploring further if not supported\n+    auto* node_data = node->data().get();\n+    if (isa<nom::repr::NeuralNetOperator>(node_data)) {\n+      const auto* nn_op =\n+          dyn_cast<const nom::repr::NeuralNetOperator>(node_data);\n+      const auto* op_def = reinterpret_cast<const caffe2::OperatorDef*>(\n+          nn_op->getAnnotation()->getSaved());\n+      bool wanted = context->predicate(*op_def);\n+      wanted = context->find_supported ? wanted : (!wanted);\n+      if (!wanted) {\n+        context->frontier.emplace(node);\n+        continue;\n+      }\n+    }\n+\n+    // Adding to current group\n+    info.group = context->group;\n+    info.needs_transform = context->find_supported;\n+    context->current_group.push_back(node);\n+\n+    // Continue exploring its fanouts\n+    for (const auto& out_edge : node->getOutEdges()) {\n+      auto child_node = out_edge->head();\n+      auto& child_info = context->infos.at(child_node);\n+      if (--child_info.in_degree == 0) {\n+        q.push(child_node);\n+      }\n+    }\n+  }\n+}\n+\n+// Note: subgraph always starts with ops and ends with tensors, except for the\n+// very first group, which can be all tensors\n+struct TransformSubgraph {\n+  explicit TransformSubgraph(\n+      std::vector<NodeRef>&& f,\n+      std::vector<NodeRef>&& n,\n+      int id,\n+      bool need)\n+      : input_nodes(std::move(f)),\n+        nodes(std::move(n)),\n+        group_id(id),\n+        needed(need) {}\n+\n+  TransformSubgraph(TransformSubgraph&& rhs) noexcept\n+      : input_nodes(std::move(rhs.input_nodes)),\n+        nodes(std::move(rhs.nodes)),\n+        external_input_refs(std::move(rhs.external_input_refs)),\n+        external_output_refs(std::move(rhs.external_output_refs)),\n+        group_id(rhs.group_id),\n+        needed(rhs.needed) {}\n+\n+  TransformSubgraph& operator=(TransformSubgraph&& rhs) noexcept {\n+    input_nodes = std::move(rhs.input_nodes);\n+    nodes = std::move(rhs.nodes);\n+    external_input_refs = std::move(external_input_refs);\n+    external_output_refs = std::move(external_output_refs);\n+    group_id = rhs.group_id;\n+    needed = rhs.needed;\n+    return *this;\n+  }\n+\n+  void Print() const {\n+    LOG(INFO) << \"Group :\" << group_id;\n+    LOG(INFO) << \"  Input Nodes: \";\n+    for (const auto i : input_nodes) {\n+      LOG(INFO) << \"    \" << ShowNode(i);\n+    }\n+    LOG(INFO) << \"  Nodes: \";\n+    for (const auto i : nodes) {\n+      LOG(INFO) << \"    \" << ShowNode(i);\n+    }\n+  }\n+\n+  std::vector<NodeRef> input_nodes;\n+  std::vector<NodeRef> nodes;\n+  std::unordered_map<std::string, NodeRef> external_input_refs;\n+  std::unordered_map<std::string, NodeRef> external_output_refs;\n+  int group_id{-1};\n+  bool needed{true};\n+};\n+\n+// Merge subgraph\n+// Precondition: subgraphs appear in topological order in the list\n+void MergeSubgraph(\n+    std::vector<TransformSubgraph>* subs,\n+    std::unordered_map<NodeRef, GroupAnnotation>* infos) {\n+\n+\n+}\n+\n+caffe2::NetDef ConvertToC2Net(\n+    const TransformSubgraph& sub,\n+    const std::unordered_map<NodeRef, GroupAnnotation>& infos) {\n+  caffe2::NetDef net;\n+  for (auto node : sub.nodes) {\n+    auto* node_data = node->data().get();\n+    if (isa<nom::repr::NeuralNetOperator>(node_data)) {\n+      const auto* nn_op =\n+          dyn_cast<const nom::repr::NeuralNetOperator>(node_data);\n+      const auto* op_def = reinterpret_cast<const caffe2::OperatorDef*>(\n+          nn_op->getAnnotation()->getSaved());\n+      net.add_op()->CopyFrom(*op_def);\n+    } \n+  }\n+  for (const auto kv : sub.external_input_refs) {\n+    net.add_external_input(kv.first);\n+    LOG(INFO) << \"Adding external input: \" << kv.first;\n+  }\n+  for (const auto& kv : sub.external_output_refs) {\n+    net.add_external_output(kv.first);\n+    LOG(INFO) << \"Adding external output: \" << kv.first;\n+  }\n+\n+  return net;\n+}\n+\n+void DetectBoundaryReferences(\n+    TransformSubgraph* subgraph,\n+    const std::unordered_map<NodeRef, GroupAnnotation>& infos) {\n+  for (auto node: subgraph->nodes) {\n+    auto* node_data = node->data().get();\n+    // inputs\n+    for (auto in_edge : node->getInEdges()) {", "path": "caffe2/opt/backend_cutting.cc", "position": null, "original_position": 229, "commit_id": "1ee73c81942d0c6028cb697cbce6d1bc59ddf91b", "original_commit_id": "530f829b767352cd263d16d8bd7850e1bea61953", "user": {"login": "yinghai", "id": 1100089, "node_id": "MDQ6VXNlcjExMDAwODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1100089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinghai", "html_url": "https://github.com/yinghai", "followers_url": "https://api.github.com/users/yinghai/followers", "following_url": "https://api.github.com/users/yinghai/following{/other_user}", "gists_url": "https://api.github.com/users/yinghai/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinghai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinghai/subscriptions", "organizations_url": "https://api.github.com/users/yinghai/orgs", "repos_url": "https://api.github.com/users/yinghai/repos", "events_url": "https://api.github.com/users/yinghai/events{/privacy}", "received_events_url": "https://api.github.com/users/yinghai/received_events", "type": "User", "site_admin": false}, "body": "Hmm, I do not get this. Could you clarify a bit? ", "created_at": "2018-04-07T00:07:39Z", "updated_at": "2018-11-23T15:41:59Z", "html_url": "https://github.com/pytorch/pytorch/pull/6368#discussion_r179900210", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6368", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/179900210"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6368#discussion_r179900210"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6368"}}, "body_html": "<p>Hmm, I do not get this. Could you clarify a bit?</p>", "body_text": "Hmm, I do not get this. Could you clarify a bit?", "in_reply_to_id": 179897989}