{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1203", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1203/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1203/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1203/events", "html_url": "https://github.com/pytorch/pytorch/issues/1203", "id": 219928183, "node_id": "MDU6SXNzdWUyMTk5MjgxODM=", "number": 1203, "title": "batch_size of pack_padded_sequence", "user": {"login": "RangoHU", "id": 5505172, "node_id": "MDQ6VXNlcjU1MDUxNzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5505172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RangoHU", "html_url": "https://github.com/RangoHU", "followers_url": "https://api.github.com/users/RangoHU/followers", "following_url": "https://api.github.com/users/RangoHU/following{/other_user}", "gists_url": "https://api.github.com/users/RangoHU/gists{/gist_id}", "starred_url": "https://api.github.com/users/RangoHU/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RangoHU/subscriptions", "organizations_url": "https://api.github.com/users/RangoHU/orgs", "repos_url": "https://api.github.com/users/RangoHU/repos", "events_url": "https://api.github.com/users/RangoHU/events{/privacy}", "received_events_url": "https://api.github.com/users/RangoHU/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-06T14:59:30Z", "updated_at": "2017-04-06T15:03:31Z", "closed_at": "2017-04-06T15:03:11Z", "author_association": "NONE", "body_html": "<p>Hello, I have a question about the bacth_size of a PackedSequence. The toy code is as follow:</p>\n<p>Code:</p>\n<pre><code>x = Variable(torch.randn(10, 20, 30))\nlens = [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]\nx = pack_padded_sequence(x, lens, batch_first=True)\nprint x\n</code></pre>\n<p>Output:</p>\n<pre><code>PackedSequence(data=Variable containing:\n 1.0801  0.3946  0.4798  ...  -1.1052  0.7187  0.7739\n 1.2224  0.5616  0.4438  ...   0.4786 -0.0984  0.7566\n 2.2416 -1.2815  0.0442  ...   1.1248  1.1361  1.1236\n          ...             \u22f1             ...          \n-0.4377  0.6860 -0.7715  ...  -0.7121 -1.7311  0.7555\n 0.6080 -1.5501 -1.0429  ...   2.4519 -0.1884 -0.0611\n 1.4053  0.1409 -1.5822  ...  -0.2042 -1.4964 -0.0310\n[torch.FloatTensor of size 76x30]\n, batch_sizes=[10, 9, 8, 7, 7, 7, 7, 7, 7, 7])\n</code></pre>\n<p>The question is how come the batch_size is [10, 9, 8, 7, 7, 7, 7, 7, 7, 7] instead of [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]?</p>\n<p>Thanks!</p>", "body_text": "Hello, I have a question about the bacth_size of a PackedSequence. The toy code is as follow:\nCode:\nx = Variable(torch.randn(10, 20, 30))\nlens = [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]\nx = pack_padded_sequence(x, lens, batch_first=True)\nprint x\n\nOutput:\nPackedSequence(data=Variable containing:\n 1.0801  0.3946  0.4798  ...  -1.1052  0.7187  0.7739\n 1.2224  0.5616  0.4438  ...   0.4786 -0.0984  0.7566\n 2.2416 -1.2815  0.0442  ...   1.1248  1.1361  1.1236\n          ...             \u22f1             ...          \n-0.4377  0.6860 -0.7715  ...  -0.7121 -1.7311  0.7555\n 0.6080 -1.5501 -1.0429  ...   2.4519 -0.1884 -0.0611\n 1.4053  0.1409 -1.5822  ...  -0.2042 -1.4964 -0.0310\n[torch.FloatTensor of size 76x30]\n, batch_sizes=[10, 9, 8, 7, 7, 7, 7, 7, 7, 7])\n\nThe question is how come the batch_size is [10, 9, 8, 7, 7, 7, 7, 7, 7, 7] instead of [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]?\nThanks!", "body": "Hello, I have a question about the bacth_size of a PackedSequence. The toy code is as follow:\r\n\r\nCode:\r\n```\r\nx = Variable(torch.randn(10, 20, 30))\r\nlens = [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]\r\nx = pack_padded_sequence(x, lens, batch_first=True)\r\nprint x\r\n```\r\n\r\nOutput:\r\n```\r\nPackedSequence(data=Variable containing:\r\n 1.0801  0.3946  0.4798  ...  -1.1052  0.7187  0.7739\r\n 1.2224  0.5616  0.4438  ...   0.4786 -0.0984  0.7566\r\n 2.2416 -1.2815  0.0442  ...   1.1248  1.1361  1.1236\r\n          ...             \u22f1             ...          \r\n-0.4377  0.6860 -0.7715  ...  -0.7121 -1.7311  0.7555\r\n 0.6080 -1.5501 -1.0429  ...   2.4519 -0.1884 -0.0611\r\n 1.4053  0.1409 -1.5822  ...  -0.2042 -1.4964 -0.0310\r\n[torch.FloatTensor of size 76x30]\r\n, batch_sizes=[10, 9, 8, 7, 7, 7, 7, 7, 7, 7])\r\n```\r\nThe question is how come the batch_size is [10, 9, 8, 7, 7, 7, 7, 7, 7, 7] instead of [10, 10, 10, 10, 10, 10, 10, 3, 2, 1]?\r\n\r\nThanks!\r\n\r\n\r\n"}