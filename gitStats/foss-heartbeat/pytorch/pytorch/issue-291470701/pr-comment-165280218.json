{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/165280218", "pull_request_review_id": 93190484, "id": 165280218, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NTI4MDIxOA==", "diff_hunk": "@@ -0,0 +1,252 @@\n+import imp\n+import os\n+import re\n+import subprocess\n+import sys\n+import sysconfig\n+import tempfile\n+import warnings\n+\n+from setuptools.command.build_ext import build_ext\n+\n+MINIMUM_GCC_VERSION = (4, 9)\n+ABI_INCOMPATIBILITY_WARNING = '''\n+Your compiler ({}) may be ABI-incompatible with PyTorch.\n+Please use a compiler that is ABI-compatible with GCC 4.9 and above.\n+See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.'''\n+\n+\n+def check_compiler_abi_compatibility(compiler):\n+    '''\n+    Verifies that the given compiler is ABI-compatible with PyTorch.\n+\n+    Arguments:\n+        compiler (str): The compiler executable name to check (e.g. 'g++')\n+\n+    Returns:\n+        False if the compiler is (likely) ABI-incompatible with PyTorch,\n+        else True.\n+    '''\n+    try:\n+        info = subprocess.check_output('{} --version'.format(compiler).split())\n+    except Exception:\n+        _, error, _ = sys.exc_info()\n+        warnings.warn('Error checking compiler version: {}'.format(error))\n+    else:\n+        info = info.decode().lower()\n+        if 'gcc' in info:\n+            # Sometimes the version is given as \"major.x\" instead of semver.\n+            version = re.search(r'(\\d+)\\.(\\d+|x)', info)\n+            if version is not None:\n+                major, minor = version.groups()\n+                minor = 0 if minor == 'x' else int(minor)\n+                if (int(major), minor) >= MINIMUM_GCC_VERSION:\n+                    return True\n+                else:\n+                    # Append the detected version for the warning.\n+                    compiler = '{} {}'.format(compiler, version.group(0))\n+\n+    warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))\n+    return False\n+\n+\n+class BuildExtension(build_ext):\n+    \"\"\"A custom build extension for adding compiler-specific options.\"\"\"\n+\n+    def build_extensions(self):\n+        # On some platforms, like Windows, compiler_cxx is not available.\n+        if hasattr(self.compiler, 'compiler_cxx'):\n+            compiler = self.compiler.compiler_cxx[0]\n+        else:\n+            compiler = os.environ.get('CXX', 'c++')\n+        check_compiler_abi_compatibility(compiler)\n+        for extension in self.extensions:\n+            extension.extra_compile_args = ['-std=c++11']\n+        build_ext.build_extensions(self)\n+\n+\n+def include_paths():\n+    here = os.path.abspath(__file__)\n+    torch_path = os.path.dirname(os.path.dirname(here))\n+    return [os.path.join(torch_path, 'lib', 'include')]\n+\n+\n+def load(name,\n+         sources,\n+         extra_cflags=None,\n+         extra_ldflags=None,\n+         extra_include_paths=None,\n+         build_directory=None,\n+         verbose=False):\n+    '''\n+    Loads a C++ PyTorch extension.\n+\n+    To load an extension, a Ninja build file is emitted, which is used to\n+    compile the given sources into a dynamic library. This library is\n+    subsequently loaded into the current Python process as a module and\n+    returned from this function, ready for use.\n+\n+    By default, the directory to which the build file is emitted and the\n+    resulting library compiled to is `<tmp>/torch_extensions`, where `<tmp>` is\n+    the temporary folder on the current platform. This location can be\n+    overriden in two ways. First, if the `TORCH_EXTENSIONS_DIR` environment\n+    variable is set, it replaces `<tmp>` and all extensions will be compiled\n+    into subfolders of this directory. Second, if the `build_directory`\n+    argument to this function is supplied, it overrides the entire path, i.e.\n+    the library will be compiled into that folder directly.\n+\n+    To compile the sources, the default system compiler (`c++`) is used, which\n+    can be overriden by setting the CXX environment variable. To pass\n+    additional arguments to the compilation process, `extra_cflags` or\n+    `extra_ldflags` can be provided. For example, to compile your extension\n+    with optimizations, pass `extra_cflags=['-O3']`. You can also use\n+    `extra_cflags` to pass further include directories (`-I`).\n+\n+    Args:\n+        name: The name of the module to build.\n+        sources: A list of relative or absolute paths to C++ source files.\n+        extra_cflags: optional list of compiler flags to forward to the build.\n+        extra_ldflags: optional list of linker flags to forward to the build.\n+        extra_include_paths: optional list of include directories to forward\n+            to the build.\n+        build_directory: optional path to use as build workspace.\n+        verbose: If `True`, turns on verbose logging of load steps.\n+\n+    Returns:\n+        The loaded PyTorch extension as a Python module.\n+    '''\n+\n+    verify_ninja_availability()\n+\n+    # Allows sources to be a single path or a list of paths.\n+    if isinstance(sources, str):\n+        sources = [sources]\n+\n+    if build_directory is None:\n+        build_directory = _get_build_directory(name, verbose)\n+\n+    build_file_path = os.path.join(build_directory, 'build.ninja')\n+    if verbose:\n+        print('Emitting ninja build file {}...'.format(build_file_path))\n+    # NOTE: Emitting a new ninja build file does not cause re-compilation if\n+    # the sources did not change, so it's ok to re-emit (and it's fast).\n+    _write_ninja_file(build_file_path, name, sources, extra_cflags or [],\n+                      extra_ldflags or [], extra_include_paths or [])\n+\n+    if verbose:\n+        print('Building extension module {}...'.format(name))\n+    _build_extension_module(name, build_directory)\n+\n+    if verbose:\n+        print('Loading extension module {}...'.format(name))\n+    return _import_module_from_library(name, build_directory)\n+\n+\n+def verify_ninja_availability():\n+    try:\n+        check = 'ninja --version'.split()\n+        subprocess.check_call(check, stdout=open(os.devnull))\n+    except OSError:\n+        raise RuntimeError(\"Ninja is required to load C++ extensions\")\n+\n+\n+def _get_build_directory(name, verbose):\n+    root_extensions_directory = os.environ.get('TORCH_EXTENSIONS_DIR')\n+    if root_extensions_directory is None:\n+        # tempfile.gettempdir() will be /tmp on UNIX and \\TEMP on Windows.\n+        root_extensions_directory = os.path.join(tempfile.gettempdir(),\n+                                                 'torch_extensions')\n+\n+    if verbose:\n+        print('Using {} as PyTorch extensions root...'.format(\n+            root_extensions_directory))\n+\n+    build_directory = os.path.join(root_extensions_directory, name)\n+    if not os.path.exists(build_directory):\n+        if verbose:\n+            print('Creating extension directory {}...'.format(build_directory))\n+        # This is like mkdir -p, i.e. will also create parent directories.\n+        os.makedirs(build_directory)\n+\n+    return build_directory\n+\n+\n+def _build_extension_module(name, build_directory):\n+    try:\n+        subprocess.check_output(\n+            ['ninja', '-v'], stderr=subprocess.STDOUT, cwd=build_directory)\n+    except subprocess.CalledProcessError:\n+        # Python 2 and 3 compatible way of getting the error object.\n+        _, error, _ = sys.exc_info()\n+        # error.output contains the stdout and stderr of the build attempt.\n+        raise RuntimeError(\"Error building extension '{}': {}\".format(\n+            name, error.output.decode()))\n+\n+\n+def _import_module_from_library(module_name, path):\n+    # https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path\n+    file, path, description = imp.find_module(module_name, [path])\n+    # Close the .so file after load.\n+    with file:\n+        return imp.load_module(module_name, file, path, description)\n+\n+\n+def _write_ninja_file(path, name, sources, extra_cflags, extra_ldflags,\n+                      extra_include_paths):\n+    # Version 1.3 is required for the `deps` directive.", "path": "torch/utils/cpp_extension.py", "position": 141, "original_position": 196, "commit_id": "b59581fc5713bac320c0a0942d28cf43203f7d3e", "original_commit_id": "e4f78115a6805c57d813d2b8f681d4b9af42d4ea", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "@zdevito I've decided to rewrite this without the ninja writer so that we don't have to depend on the ninja Python module, i.e. it's no longer required to have `pip install ninja` (which installs the `ninja` Python module *and* the `ninja` command line tool/build system), it's sufficient to have the `ninja` build system, which you get from `apt-get install ninja-build`, `brew install ninja`, `conda install ninja` etc.\r\nIt also removes the pain of having to install `ninja` with `pip` in the CI.", "created_at": "2018-02-01T07:56:10Z", "updated_at": "2018-11-23T15:38:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/4842#discussion_r165280218", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4842", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/165280218"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4842#discussion_r165280218"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4842"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=370202\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zdevito\">@zdevito</a> I've decided to rewrite this without the ninja writer so that we don't have to depend on the ninja Python module, i.e. it's no longer required to have <code>pip install ninja</code> (which installs the <code>ninja</code> Python module <em>and</em> the <code>ninja</code> command line tool/build system), it's sufficient to have the <code>ninja</code> build system, which you get from <code>apt-get install ninja-build</code>, <code>brew install ninja</code>, <code>conda install ninja</code> etc.<br>\nIt also removes the pain of having to install <code>ninja</code> with <code>pip</code> in the CI.</p>", "body_text": "@zdevito I've decided to rewrite this without the ninja writer so that we don't have to depend on the ninja Python module, i.e. it's no longer required to have pip install ninja (which installs the ninja Python module and the ninja command line tool/build system), it's sufficient to have the ninja build system, which you get from apt-get install ninja-build, brew install ninja, conda install ninja etc.\nIt also removes the pain of having to install ninja with pip in the CI."}