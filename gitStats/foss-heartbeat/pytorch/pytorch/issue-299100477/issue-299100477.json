{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5338", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5338/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5338/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5338/events", "html_url": "https://github.com/pytorch/pytorch/issues/5338", "id": 299100477, "node_id": "MDU6SXNzdWUyOTkxMDA0Nzc=", "number": 5338, "title": "Hang after running hogwild models in sequence", "user": {"login": "jef5ez", "id": 1209327, "node_id": "MDQ6VXNlcjEyMDkzMjc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1209327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jef5ez", "html_url": "https://github.com/jef5ez", "followers_url": "https://api.github.com/users/jef5ez/followers", "following_url": "https://api.github.com/users/jef5ez/following{/other_user}", "gists_url": "https://api.github.com/users/jef5ez/gists{/gist_id}", "starred_url": "https://api.github.com/users/jef5ez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jef5ez/subscriptions", "organizations_url": "https://api.github.com/users/jef5ez/orgs", "repos_url": "https://api.github.com/users/jef5ez/repos", "events_url": "https://api.github.com/users/jef5ez/events{/privacy}", "received_events_url": "https://api.github.com/users/jef5ez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-02-21T19:37:40Z", "updated_at": "2018-05-14T19:32:20Z", "closed_at": null, "author_association": "NONE", "body_html": "<ul>\n<li>OS: Ubuntu 16.04</li>\n<li>PyTorch version: 0.3.1</li>\n<li>How you installed PyTorch (conda, pip, source): conda</li>\n<li>Python version: 3.6.2<br>\nNot using gpu the moment.</li>\n</ul>\n<p>I was trying to run some models multiple time to get runtime and performance metrics and reproduced my issue on the mnist-hogwild example: <a href=\"https://github.com/pytorch/examples/blob/master/mnist_hogwild/main.py\">https://github.com/pytorch/examples/blob/master/mnist_hogwild/main.py</a><br>\nI basically wrapped the main function here and called it multiple times in a for loop. The problem only occurs if you use the model inside a subprocess and then also try to call it in the main process. On the second iteration of the loop everything seems to hang and has to be manually killed.</p>\n<p>Using set_start_method(\"spawn\") only complained about the context already being started.<br>\nWhat seems to work is using mp.get_context(\"spawn\") and then creating subprocesses off of that like so: <a href=\"https://gist.github.com/jef5ez/7ecc7d4e8eeeaa81454cbf48ef6ae0c3\">https://gist.github.com/jef5ez/7ecc7d4e8eeeaa81454cbf48ef6ae0c3</a><br>\nThis seems to run through all the iterations but also gives a warning once finished:<br>\n...python3.6/multiprocessing/semaphore_tracker.py:129: UserWarning: semaphore_tracker: There<br>\nappear to be 8 leaked semaphores to clean up at shutdown<br>\nlen(cache))</p>", "body_text": "OS: Ubuntu 16.04\nPyTorch version: 0.3.1\nHow you installed PyTorch (conda, pip, source): conda\nPython version: 3.6.2\nNot using gpu the moment.\n\nI was trying to run some models multiple time to get runtime and performance metrics and reproduced my issue on the mnist-hogwild example: https://github.com/pytorch/examples/blob/master/mnist_hogwild/main.py\nI basically wrapped the main function here and called it multiple times in a for loop. The problem only occurs if you use the model inside a subprocess and then also try to call it in the main process. On the second iteration of the loop everything seems to hang and has to be manually killed.\nUsing set_start_method(\"spawn\") only complained about the context already being started.\nWhat seems to work is using mp.get_context(\"spawn\") and then creating subprocesses off of that like so: https://gist.github.com/jef5ez/7ecc7d4e8eeeaa81454cbf48ef6ae0c3\nThis seems to run through all the iterations but also gives a warning once finished:\n...python3.6/multiprocessing/semaphore_tracker.py:129: UserWarning: semaphore_tracker: There\nappear to be 8 leaked semaphores to clean up at shutdown\nlen(cache))", "body": "- OS: Ubuntu 16.04\r\n- PyTorch version: 0.3.1\r\n- How you installed PyTorch (conda, pip, source): conda\r\n- Python version: 3.6.2\r\nNot using gpu the moment.\r\n\r\nI was trying to run some models multiple time to get runtime and performance metrics and reproduced my issue on the mnist-hogwild example: https://github.com/pytorch/examples/blob/master/mnist_hogwild/main.py\r\nI basically wrapped the main function here and called it multiple times in a for loop. The problem only occurs if you use the model inside a subprocess and then also try to call it in the main process. On the second iteration of the loop everything seems to hang and has to be manually killed.\r\n\r\nUsing set_start_method(\"spawn\") only complained about the context already being started.\r\nWhat seems to work is using mp.get_context(\"spawn\") and then creating subprocesses off of that like so: https://gist.github.com/jef5ez/7ecc7d4e8eeeaa81454cbf48ef6ae0c3\r\nThis seems to run through all the iterations but also gives a warning once finished:\r\n...python3.6/multiprocessing/semaphore_tracker.py:129: UserWarning: semaphore_tracker: There \r\nappear to be 8 leaked semaphores to clean up at shutdown\r\n  len(cache))\r\n"}