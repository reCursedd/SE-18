{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10978", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10978/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10978/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10978/events", "html_url": "https://github.com/pytorch/pytorch/issues/10978", "id": 354920577, "node_id": "MDU6SXNzdWUzNTQ5MjA1Nzc=", "number": 10978, "title": "[feature request] padding for torch.cat ", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-08-28T22:01:36Z", "updated_at": "2018-09-13T12:29:29Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>Currently, <code>torch.cat</code> only allows to concatenate equal-dimensional Tensors (except in the dimension catting).</p>\n<p>For example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cat([x, y], <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\ntensor([[<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>.],\n              [<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>.],\n              [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]])\n\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cat([x, y], <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\n<span class=\"pl-c1\">RuntimeError</span>: invalid argument <span class=\"pl-c1\">0</span>: Sizes of tensors must match <span class=\"pl-k\">except</span> <span class=\"pl-k\">in</span> dimension <span class=\"pl-c1\">0</span>. Got <span class=\"pl-c1\">3</span> <span class=\"pl-k\">and</span> <span class=\"pl-c1\">4</span> <span class=\"pl-k\">in</span> dimension <span class=\"pl-c1\">1</span> at ..<span class=\"pl-k\">/</span>aten<span class=\"pl-k\">/</span>src<span class=\"pl-k\">/</span><span class=\"pl-c1\">TH</span><span class=\"pl-k\">/</span>generic<span class=\"pl-k\">/</span>THTensorMoreMath.cpp:<span class=\"pl-c1\">1348</span></pre></div>\n<p>The proposal is to add a <code>padding</code> option to <code>torch.cat</code>, which will find the maximum size of Tensors in each dimension, and will place each Tensor within that larger padded Tensor.</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.cat(TensorList, dim, <span class=\"pl-v\">pad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">pad_value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>)</pre></div>\n<p>Example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cat([x, y], <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">pad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">pad_value</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.5</span>)\n\ntensor([[<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0.5</span>],\n              [<span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">1</span>., <span class=\"pl-c1\">0.5</span>],\n              [<span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>., <span class=\"pl-c1\">0</span>.]])</pre></div>\n<p>If the TensorList has size mismatches in multiple dimensions, the output size will be computed by finding the max of sizes in each dimension, except the dimension being concatenated.</p>\n<p>For example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">1</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cat([x, y], <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">pad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>).size()\ntorch.Size([<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>])</pre></div>", "body_text": "Currently, torch.cat only allows to concatenate equal-dimensional Tensors (except in the dimension catting).\nFor example:\n>>> x = torch.ones(2, 3)\n>>> y = torch.zeros(1, 3)\n>>> torch.cat([x, y], dim=0)\n\ntensor([[1., 1., 1.],\n              [1., 1., 1.],\n              [0., 0., 0.]])\n\n>>> x = torch.ones(2, 3)\n>>> y = torch.zeros(1, 4)\n>>> torch.cat([x, y], dim=0)\n\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 4 in dimension 1 at ../aten/src/TH/generic/THTensorMoreMath.cpp:1348\nThe proposal is to add a padding option to torch.cat, which will find the maximum size of Tensors in each dimension, and will place each Tensor within that larger padded Tensor.\ntorch.cat(TensorList, dim, pad=True, pad_value=0.0)\nExample:\n>>> x = torch.ones(2, 3)\n>>> y = torch.zeros(1, 4)\n>>> torch.cat([x, y], dim=0, pad=True, pad_value=0.5)\n\ntensor([[1., 1., 1., 0.5],\n              [1., 1., 1., 0.5],\n              [0., 0., 0., 0.]])\nIf the TensorList has size mismatches in multiple dimensions, the output size will be computed by finding the max of sizes in each dimension, except the dimension being concatenated.\nFor example:\n>>> x = torch.ones(1, 2, 3, 4, 5)\n>>> y = torch.ones(3, 9, 2, 5, 1)\n>>> torch.cat([x, y], dim=0, pad=True).size()\ntorch.Size([4, 9, 3, 5, 5])", "body": "Currently, `torch.cat` only allows to concatenate equal-dimensional Tensors (except in the dimension catting).\r\n\r\nFor example:\r\n\r\n```python\r\n>>> x = torch.ones(2, 3)\r\n>>> y = torch.zeros(1, 3)\r\n>>> torch.cat([x, y], dim=0)\r\n\r\ntensor([[1., 1., 1.],\r\n              [1., 1., 1.],\r\n              [0., 0., 0.]])\r\n\r\n>>> x = torch.ones(2, 3)\r\n>>> y = torch.zeros(1, 4)\r\n>>> torch.cat([x, y], dim=0)\r\n\r\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 4 in dimension 1 at ../aten/src/TH/generic/THTensorMoreMath.cpp:1348\r\n```\r\n\r\nThe proposal is to add a `padding` option to `torch.cat`, which will find the maximum size of Tensors in each dimension, and will place each Tensor within that larger padded Tensor.\r\n\r\n```python\r\ntorch.cat(TensorList, dim, pad=True, pad_value=0.0)\r\n```\r\n\r\nExample:\r\n\r\n```python\r\n>>> x = torch.ones(2, 3)\r\n>>> y = torch.zeros(1, 4)\r\n>>> torch.cat([x, y], dim=0, pad=True, pad_value=0.5)\r\n\r\ntensor([[1., 1., 1., 0.5],\r\n              [1., 1., 1., 0.5],\r\n              [0., 0., 0., 0.]])\r\n```\r\n\r\nIf the TensorList has size mismatches in multiple dimensions, the output size will be computed by finding the max of sizes in each dimension, except the dimension being concatenated.\r\n\r\nFor example:\r\n\r\n```python\r\n>>> x = torch.ones(1, 2, 3, 4, 5)\r\n>>> y = torch.ones(3, 9, 2, 5, 1)\r\n>>> torch.cat([x, y], dim=0, pad=True).size()\r\ntorch.Size([4, 9, 3, 5, 5])\r\n```"}