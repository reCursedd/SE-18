{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176755553", "pull_request_review_id": 106518479, "id": 176755553, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3Njc1NTU1Mw==", "diff_hunk": "@@ -7,41 +7,48 @@ cd .jenkins/perf_test\n \n echo \"Running CPU perf test for PyTorch...\"\n \n-# Get last master commit hash\n-export PYTORCH_COMMIT_ID=$(git log --format=\"%H\" -n 1)\n+pip install awscli\n \n-# Get baseline file from https://github.com/yf225/perf-tests\n-if [ -f /var/lib/jenkins/host-workspace/perf_test_numbers_cpu.json ]; then\n-    cp /var/lib/jenkins/host-workspace/perf_test_numbers_cpu.json perf_test_numbers_cpu.json\n-else\n-    curl https://raw.githubusercontent.com/yf225/perf-tests/master/perf_test_numbers_cpu.json -O\n+export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\n+export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n+\n+if [[ \"$COMMIT_SOURCE\" == *master* ]]; then\n+    # Get current master commit hash\n+    export MASTER_COMMIT_ID=$(git log --format=\"%H\" -n 1)\n fi\n \n-if [[ \"$GIT_COMMIT\" == *origin/master* ]]; then\n+# Get baseline file from ossci-perf-test S3 bucket\n+aws s3 cp s3://ossci-perf-test/pytorch/cpu_runtime/LATEST_TESTED_COMMIT LATEST_TESTED_COMMIT\n+export LATEST_TESTED_COMMIT=\"$(cat LATEST_TESTED_COMMIT)\"\n+aws s3 cp s3://ossci-perf-test/pytorch/cpu_runtime/${LATEST_TESTED_COMMIT}.json cpu_runtime.json\n+\n+if [[ \"$COMMIT_SOURCE\" == *master* ]]; then\n     # Prepare new baseline file\n-    cp perf_test_numbers_cpu.json new_perf_test_numbers_cpu.json\n-    python update_commit_hash.py new_perf_test_numbers_cpu.json ${PYTORCH_COMMIT_ID}\n+    cp cpu_runtime.json new_cpu_runtime.json\n+    python update_commit_hash.py new_cpu_runtime.json ${MASTER_COMMIT_ID}\n fi\n \n # Include tests\n . ./test_cpu_speed_mini_sequence_labeler.sh\n . ./test_cpu_speed_mnist.sh\n \n # Run tests\n-if [[ \"$GIT_COMMIT\" == *origin/master* ]]; then\n+if [[ \"$COMMIT_SOURCE\" == *master* ]]; then\n     run_test test_cpu_speed_mini_sequence_labeler 20 compare_and_update\n     run_test test_cpu_speed_mnist 20 compare_and_update\n else\n     run_test test_cpu_speed_mini_sequence_labeler 20 compare_with_baseline\n     run_test test_cpu_speed_mnist 20 compare_with_baseline\n fi\n \n-if [[ \"$GIT_COMMIT\" == *origin/master* ]]; then\n-    # Push new baseline file\n-    cp new_perf_test_numbers_cpu.json /var/lib/jenkins/host-workspace/perf_test_numbers_cpu.json\n-    cd /var/lib/jenkins/host-workspace\n-    git config --global user.email jenkins@ci.pytorch.org\n-    git config --global user.name Jenkins\n-    git add perf_test_numbers_cpu.json\n-    git commit -m \"New CPU perf test baseline from ${PYTORCH_COMMIT_ID}\"\n+if [[ \"$COMMIT_SOURCE\" == *master* ]]; then\n+    aws s3 cp new_cpu_runtime.json s3://ossci-perf-test/pytorch/cpu_runtime/${MASTER_COMMIT_ID}.json --acl public-read", "path": ".jenkins/short-perf-test-cpu.sh", "position": null, "original_position": 58, "commit_id": "f99787cd5de72a1fc49df9ff63087b98f1bafe4e", "original_commit_id": "0aae26a911db310203210fa8f257005cd2a75f85", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "This is subject to a race condition, where if an update occurs between when you read and write, you lose the update. It's OK to say, \"I don't think that's going to happen\" but in that case it should be called out in the code.", "created_at": "2018-03-23T14:39:09Z", "updated_at": "2018-11-23T15:41:02Z", "html_url": "https://github.com/pytorch/pytorch/pull/5951#discussion_r176755553", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5951", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/176755553"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5951#discussion_r176755553"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5951"}}, "body_html": "<p>This is subject to a race condition, where if an update occurs between when you read and write, you lose the update. It's OK to say, \"I don't think that's going to happen\" but in that case it should be called out in the code.</p>", "body_text": "This is subject to a race condition, where if an update occurs between when you read and write, you lose the update. It's OK to say, \"I don't think that's going to happen\" but in that case it should be called out in the code."}