{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/330367959", "html_url": "https://github.com/pytorch/pytorch/issues/2778#issuecomment-330367959", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2778", "id": 330367959, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDM2Nzk1OQ==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-18T21:56:37Z", "updated_at": "2017-09-18T21:56:37Z", "author_association": "MEMBER", "body_html": "<p>this is expected, because of CuDNN being non-deterministic in it's backward w.r.t. weights.</p>\n<p>As you've already found out, if you want determinism in this case you can add this to the top of your script:</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.backends.cudnn.enabled<span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span></pre></div>\n<p>The CuDNN library has several algorithms to compute backward, one with FFT, one with gemm, etc. and only some of them are non-deterministic. This is why you are seeing that if you change the sizes slightly, the algorithm is becoming deterministic.</p>", "body_text": "this is expected, because of CuDNN being non-deterministic in it's backward w.r.t. weights.\nAs you've already found out, if you want determinism in this case you can add this to the top of your script:\ntorch.backends.cudnn.enabled=False\nThe CuDNN library has several algorithms to compute backward, one with FFT, one with gemm, etc. and only some of them are non-deterministic. This is why you are seeing that if you change the sizes slightly, the algorithm is becoming deterministic.", "body": "this is expected, because of CuDNN being non-deterministic in it's backward w.r.t. weights.\r\n\r\nAs you've already found out, if you want determinism in this case you can add this to the top of your script:\r\n\r\n```python\r\ntorch.backends.cudnn.enabled=False\r\n```\r\n\r\nThe CuDNN library has several algorithms to compute backward, one with FFT, one with gemm, etc. and only some of them are non-deterministic. This is why you are seeing that if you change the sizes slightly, the algorithm is becoming deterministic."}