{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2302", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2302/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2302/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2302/events", "html_url": "https://github.com/pytorch/pytorch/issues/2302", "id": 248235246, "node_id": "MDU6SXNzdWUyNDgyMzUyNDY=", "number": 2302, "title": "Out of memory when extract features from pictures, only on ubuntu.", "user": {"login": "xwzy", "id": 13077117, "node_id": "MDQ6VXNlcjEzMDc3MTE3", "avatar_url": "https://avatars3.githubusercontent.com/u/13077117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xwzy", "html_url": "https://github.com/xwzy", "followers_url": "https://api.github.com/users/xwzy/followers", "following_url": "https://api.github.com/users/xwzy/following{/other_user}", "gists_url": "https://api.github.com/users/xwzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/xwzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xwzy/subscriptions", "organizations_url": "https://api.github.com/users/xwzy/orgs", "repos_url": "https://api.github.com/users/xwzy/repos", "events_url": "https://api.github.com/users/xwzy/events{/privacy}", "received_events_url": "https://api.github.com/users/xwzy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-06T09:12:09Z", "updated_at": "2017-08-06T12:04:33Z", "closed_at": "2017-08-06T12:04:33Z", "author_association": "NONE", "body_html": "<p>I use res152-net to extract features from pictures, but with an 8G memory ubuntu PC, can only extract less than 30 pics and my PC will crash with 8G + 8G(swap) memory full.</p>\n<p>Is there any way to free some memory when inference?</p>\n<p>Note: This problem only occurs on ubuntu, my mac with 16G memory is good to predict with high memory pressure.(Later I found that the virtual memory on mac is allocated dynamically, and It can use more than 50G memory in total.)</p>\n<p>Code:</p>\n<pre><code>import torchvision, torch, os\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom dataset import DATASET\nfrom tqdm import tqdm\n\nmydata = DATASET(os.getcwd())\nmodel = torchvision.models.resnet152(pretrained=True)\nnew_classifier = nn.Sequential(*list(model.children())[:-1])\nmodel.classifier = new_classifier\nmodel.eval()\n\npos1 = model(Variable(mydata[0][0].view(1, 3, 224, 224)))\nfor index in tqdm(range(1, 1000)):\n    f = model(Variable(mydata[index][0].view(1, 3, 224, 224)))\n    pos1 = torch.cat((pos1, f))\n\nwith open('pos1_fea.pt', 'wb') as f:\n    torch.save(pos1, f)\n</code></pre>", "body_text": "I use res152-net to extract features from pictures, but with an 8G memory ubuntu PC, can only extract less than 30 pics and my PC will crash with 8G + 8G(swap) memory full.\nIs there any way to free some memory when inference?\nNote: This problem only occurs on ubuntu, my mac with 16G memory is good to predict with high memory pressure.(Later I found that the virtual memory on mac is allocated dynamically, and It can use more than 50G memory in total.)\nCode:\nimport torchvision, torch, os\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom dataset import DATASET\nfrom tqdm import tqdm\n\nmydata = DATASET(os.getcwd())\nmodel = torchvision.models.resnet152(pretrained=True)\nnew_classifier = nn.Sequential(*list(model.children())[:-1])\nmodel.classifier = new_classifier\nmodel.eval()\n\npos1 = model(Variable(mydata[0][0].view(1, 3, 224, 224)))\nfor index in tqdm(range(1, 1000)):\n    f = model(Variable(mydata[index][0].view(1, 3, 224, 224)))\n    pos1 = torch.cat((pos1, f))\n\nwith open('pos1_fea.pt', 'wb') as f:\n    torch.save(pos1, f)", "body": "I use res152-net to extract features from pictures, but with an 8G memory ubuntu PC, can only extract less than 30 pics and my PC will crash with 8G + 8G(swap) memory full.\r\n\r\nIs there any way to free some memory when inference?\r\n\r\nNote: This problem only occurs on ubuntu, my mac with 16G memory is good to predict with high memory pressure.(Later I found that the virtual memory on mac is allocated dynamically, and It can use more than 50G memory in total.)\r\n\r\nCode:\r\n```\r\nimport torchvision, torch, os\r\nfrom torch import nn\r\nfrom torch.autograd import Variable\r\nfrom dataset import DATASET\r\nfrom tqdm import tqdm\r\n\r\nmydata = DATASET(os.getcwd())\r\nmodel = torchvision.models.resnet152(pretrained=True)\r\nnew_classifier = nn.Sequential(*list(model.children())[:-1])\r\nmodel.classifier = new_classifier\r\nmodel.eval()\r\n\r\npos1 = model(Variable(mydata[0][0].view(1, 3, 224, 224)))\r\nfor index in tqdm(range(1, 1000)):\r\n    f = model(Variable(mydata[index][0].view(1, 3, 224, 224)))\r\n    pos1 = torch.cat((pos1, f))\r\n\r\nwith open('pos1_fea.pt', 'wb') as f:\r\n    torch.save(pos1, f)\r\n```"}