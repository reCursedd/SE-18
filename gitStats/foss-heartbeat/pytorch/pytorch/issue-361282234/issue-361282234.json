{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11795", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11795/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11795/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11795/events", "html_url": "https://github.com/pytorch/pytorch/issues/11795", "id": 361282234, "node_id": "MDU6SXNzdWUzNjEyODIyMzQ=", "number": 11795, "title": "[TensorIterator] bug when performing inter-scalar ops on the GPU", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-18T12:34:39Z", "updated_at": "2018-09-21T21:21:43Z", "closed_at": "2018-09-21T21:21:43Z", "author_association": "MEMBER", "body_html": "<p>When performing operations between scalar tensors of different types, type promotion happens in TensorIterator. But it seems that the results of inter-type operations are not correct when performing operations on the GPU.</p>\n<p>The following code gives unexpected results on the GPU. CPU works fine</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\ntorch.<span class=\"pl-c1\">__version__</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> '1.0.0a0+91b6458', master from today</span>\n\na <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1.5</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> float tensor</span>\nb <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> int64 tensor</span>\n<span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">*</span> b)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tensor(2.8026e-45, device='cuda:0')</span>\n\na <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1.5</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> float tensor</span>\nb <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">True</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> uint8 tensor</span>\n<span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">*</span> b)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tensor(2.8026e-45, device='cuda:0')</span>\n<span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">+</span> b)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tensor(1.5000, device='cuda:0')</span>\n<span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">-</span> b)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> tensor(1.5000, device='cuda:0')</span></pre></div>\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a></p>", "body_text": "When performing operations between scalar tensors of different types, type promotion happens in TensorIterator. But it seems that the results of inter-type operations are not correct when performing operations on the GPU.\nThe following code gives unexpected results on the GPU. CPU works fine\nimport torch\n\ntorch.__version__\n# '1.0.0a0+91b6458', master from today\n\na = torch.tensor(1.5, device='cuda')  # float tensor\nb = torch.tensor(1, device='cuda')  # int64 tensor\nprint(a * b)\n# tensor(2.8026e-45, device='cuda:0')\n\na = torch.tensor(1.5, device='cuda')  # float tensor\nb = torch.tensor(True, device='cuda') # uint8 tensor\nprint(a * b)\n# tensor(2.8026e-45, device='cuda:0')\nprint(a + b)\n# tensor(1.5000, device='cuda:0')\nprint(a - b)\n# tensor(1.5000, device='cuda:0')\ncc @colesbury", "body": "When performing operations between scalar tensors of different types, type promotion happens in TensorIterator. But it seems that the results of inter-type operations are not correct when performing operations on the GPU.\r\n\r\nThe following code gives unexpected results on the GPU. CPU works fine\r\n```python\r\nimport torch\r\n\r\ntorch.__version__\r\n# '1.0.0a0+91b6458', master from today\r\n\r\na = torch.tensor(1.5, device='cuda')  # float tensor\r\nb = torch.tensor(1, device='cuda')  # int64 tensor\r\nprint(a * b)\r\n# tensor(2.8026e-45, device='cuda:0')\r\n\r\na = torch.tensor(1.5, device='cuda')  # float tensor\r\nb = torch.tensor(True, device='cuda') # uint8 tensor\r\nprint(a * b)\r\n# tensor(2.8026e-45, device='cuda:0')\r\nprint(a + b)\r\n# tensor(1.5000, device='cuda:0')\r\nprint(a - b)\r\n# tensor(1.5000, device='cuda:0')\r\n```\r\n\r\ncc @colesbury "}