{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4829", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4829/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4829/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4829/events", "html_url": "https://github.com/pytorch/pytorch/issues/4829", "id": 291192427, "node_id": "MDU6SXNzdWUyOTExOTI0Mjc=", "number": 4829, "title": " [Feature Request] Adding clip_grap_value and supporting sparse gradients", "user": {"login": "berzjackson", "id": 1171221, "node_id": "MDQ6VXNlcjExNzEyMjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/1171221?v=4", "gravatar_id": "", "url": "https://api.github.com/users/berzjackson", "html_url": "https://github.com/berzjackson", "followers_url": "https://api.github.com/users/berzjackson/followers", "following_url": "https://api.github.com/users/berzjackson/following{/other_user}", "gists_url": "https://api.github.com/users/berzjackson/gists{/gist_id}", "starred_url": "https://api.github.com/users/berzjackson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/berzjackson/subscriptions", "organizations_url": "https://api.github.com/users/berzjackson/orgs", "repos_url": "https://api.github.com/users/berzjackson/repos", "events_url": "https://api.github.com/users/berzjackson/events{/privacy}", "received_events_url": "https://api.github.com/users/berzjackson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679954154, "node_id": "MDU6TGFiZWw2Nzk5NTQxNTQ=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/sparse", "name": "sparse", "color": "bfd4f2", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-24T12:34:07Z", "updated_at": "2018-09-12T21:16:27Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>1.It would be great to have another common gradient clipping strategy, i.e. clip_grad_value in PyTorch. Compared to clip_grad_norm, which is sensitive to the total number of parameters in the model, clip_grad_value will be easier to use as tuning max_value will be more straightforward than tuning max_norm. Still, AFAIK clip_grad_norm is the recommended way to do gradient clipping since it preserves the direction of the gradients while clip_grad_value does not.</p>\n<p>2.The current implementation of clip_grad_norm can not handle sparse gradients. A common use case is when sparse=True in nn.Embedding layers.</p>\n<p>I will issue a PR if people feel this is worth adding.</p>", "body_text": "1.It would be great to have another common gradient clipping strategy, i.e. clip_grad_value in PyTorch. Compared to clip_grad_norm, which is sensitive to the total number of parameters in the model, clip_grad_value will be easier to use as tuning max_value will be more straightforward than tuning max_norm. Still, AFAIK clip_grad_norm is the recommended way to do gradient clipping since it preserves the direction of the gradients while clip_grad_value does not.\n2.The current implementation of clip_grad_norm can not handle sparse gradients. A common use case is when sparse=True in nn.Embedding layers.\nI will issue a PR if people feel this is worth adding.", "body": "1.It would be great to have another common gradient clipping strategy, i.e. clip_grad_value in PyTorch. Compared to clip_grad_norm, which is sensitive to the total number of parameters in the model, clip_grad_value will be easier to use as tuning max_value will be more straightforward than tuning max_norm. Still, AFAIK clip_grad_norm is the recommended way to do gradient clipping since it preserves the direction of the gradients while clip_grad_value does not.\r\n\r\n2.The current implementation of clip_grad_norm can not handle sparse gradients. A common use case is when sparse=True in nn.Embedding layers.\r\n\r\nI will issue a PR if people feel this is worth adding."}