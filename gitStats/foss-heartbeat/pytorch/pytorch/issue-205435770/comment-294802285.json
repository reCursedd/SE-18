{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/294802285", "html_url": "https://github.com/pytorch/pytorch/issues/686#issuecomment-294802285", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/686", "id": 294802285, "node_id": "MDEyOklzc3VlQ29tbWVudDI5NDgwMjI4NQ==", "user": {"login": "adelsalehali1982", "id": 11198282, "node_id": "MDQ6VXNlcjExMTk4Mjgy", "avatar_url": "https://avatars3.githubusercontent.com/u/11198282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adelsalehali1982", "html_url": "https://github.com/adelsalehali1982", "followers_url": "https://api.github.com/users/adelsalehali1982/followers", "following_url": "https://api.github.com/users/adelsalehali1982/following{/other_user}", "gists_url": "https://api.github.com/users/adelsalehali1982/gists{/gist_id}", "starred_url": "https://api.github.com/users/adelsalehali1982/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adelsalehali1982/subscriptions", "organizations_url": "https://api.github.com/users/adelsalehali1982/orgs", "repos_url": "https://api.github.com/users/adelsalehali1982/repos", "events_url": "https://api.github.com/users/adelsalehali1982/events{/privacy}", "received_events_url": "https://api.github.com/users/adelsalehali1982/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-18T11:47:07Z", "updated_at": "2017-04-18T17:48:54Z", "author_association": "NONE", "body_html": "<p>I am trying to run this code :<br>\n<a href=\"https://github.com/kuangliu/pytorch-cifar\">https://github.com/kuangliu/pytorch-cifar</a></p>\n<pre><code>but getting this error :\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=84 error=10 : invalid device ordinal\nTraceback (most recent call last):\n  File \"main.py\", line 136, in &lt;module&gt;\n    train(epoch)\n  File \"main.py\", line 86, in train\n    outputs = net(inputs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 57, in forward\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 68, in scatter\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\n    inputs = scatter(inputs, target_gpus, dim)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\n    return scatter_map(inputs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\n    return tuple(zip(*map(scatter_map, obj)))\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\n    return Scatter(target_gpus, dim=dim)(obj)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/_functions.py\", line 59, in forward\n    outputs = comm.scatter(input, self.target_gpus, self.chunk_sizes, self.dim, streams)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/comm.py\", line 162, in scatter\n    with torch.cuda.device(device), torch.cuda.stream(stream):\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.py\", line 132, in __enter__\n    torch._C._cuda_setDevice(self.idx)\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:84\n</code></pre>\n<hr>\n<p>I have cuda 8.0 which works will with theano<br>\nubuntu 14.04 and my GPU card has more than 3.0 computation capability</p>", "body_text": "I am trying to run this code :\nhttps://github.com/kuangliu/pytorch-cifar\nbut getting this error :\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=84 error=10 : invalid device ordinal\nTraceback (most recent call last):\n  File \"main.py\", line 136, in <module>\n    train(epoch)\n  File \"main.py\", line 86, in train\n    outputs = net(inputs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 57, in forward\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 68, in scatter\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\n    inputs = scatter(inputs, target_gpus, dim)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\n    return scatter_map(inputs)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\n    return tuple(zip(*map(scatter_map, obj)))\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\n    return Scatter(target_gpus, dim=dim)(obj)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/_functions.py\", line 59, in forward\n    outputs = comm.scatter(input, self.target_gpus, self.chunk_sizes, self.dim, streams)\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/comm.py\", line 162, in scatter\n    with torch.cuda.device(device), torch.cuda.stream(stream):\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.py\", line 132, in __enter__\n    torch._C._cuda_setDevice(self.idx)\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:84\n\n\nI have cuda 8.0 which works will with theano\nubuntu 14.04 and my GPU card has more than 3.0 computation capability", "body": "I am trying to run this code :\r\nhttps://github.com/kuangliu/pytorch-cifar\r\n\r\n```\r\nbut getting this error :\r\nTHCudaCheck FAIL file=torch/csrc/cuda/Module.cpp line=84 error=10 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 136, in <module>\r\n    train(epoch)\r\n  File \"main.py\", line 86, in train\r\n    outputs = net(inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py\", line 206, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 57, in forward\r\n    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 68, in scatter\r\n    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 30, in scatter_kwargs\r\n    inputs = scatter(inputs, target_gpus, dim)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 25, in scatter\r\n    return scatter_map(inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 18, in scatter_map\r\n    return tuple(zip(*map(scatter_map, obj)))\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/scatter_gather.py\", line 15, in scatter_map\r\n    return Scatter(target_gpus, dim=dim)(obj)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/nn/parallel/_functions.py\", line 59, in forward\r\n    outputs = comm.scatter(input, self.target_gpus, self.chunk_sizes, self.dim, streams)\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/comm.py\", line 162, in scatter\r\n    with torch.cuda.device(device), torch.cuda.stream(stream):\r\n  File \"/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.py\", line 132, in __enter__\r\n    torch._C._cuda_setDevice(self.idx)\r\nRuntimeError: cuda runtime error (10) : invalid device ordinal at torch/csrc/cuda/Module.cpp:84\r\n```\r\n--------------------------------------------\r\nI have cuda 8.0 which works will with theano \r\nubuntu 14.04 and my GPU card has more than 3.0 computation capability\r\n\r\n\r\n \r\n\r\n\r\n"}