{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/367822064", "html_url": "https://github.com/pytorch/pytorch/issues/5306#issuecomment-367822064", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5306", "id": 367822064, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NzgyMjA2NA==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-22T21:06:20Z", "updated_at": "2018-02-22T21:07:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=690386\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DavidNemeskey\">@DavidNemeskey</a> Oops, I missed your message and kept editing the comment above. There are three more questions, if you don't mind ;)</p>\n<p>Re 2: Well, in the experiments I ran there, the weights are being initialized randomly, differently, which easily explains the difference in perplexity. But this is <em>far far</em> more difference than what you reported in your experiments. And when the initial loss is this far out, I would guess that the weight initialization is not being done correctly. I can't easily tell, because I can't tell if TF is actually successfully loading the saved weights, because the TF script is nondeterministic.</p>\n<p>I also ran one more experiment, which is I took your new loss function and slapped it on <code>word_language_model</code>, using the wikitext data set. The model trained correctly but the perplexity is too large. But I am concerned because this doesn't match your experiments at all.</p>", "body_text": "@DavidNemeskey Oops, I missed your message and kept editing the comment above. There are three more questions, if you don't mind ;)\nRe 2: Well, in the experiments I ran there, the weights are being initialized randomly, differently, which easily explains the difference in perplexity. But this is far far more difference than what you reported in your experiments. And when the initial loss is this far out, I would guess that the weight initialization is not being done correctly. I can't easily tell, because I can't tell if TF is actually successfully loading the saved weights, because the TF script is nondeterministic.\nI also ran one more experiment, which is I took your new loss function and slapped it on word_language_model, using the wikitext data set. The model trained correctly but the perplexity is too large. But I am concerned because this doesn't match your experiments at all.", "body": "@DavidNemeskey Oops, I missed your message and kept editing the comment above. There are three more questions, if you don't mind ;)\r\n\r\nRe 2: Well, in the experiments I ran there, the weights are being initialized randomly, differently, which easily explains the difference in perplexity. But this is *far far* more difference than what you reported in your experiments. And when the initial loss is this far out, I would guess that the weight initialization is not being done correctly. I can't easily tell, because I can't tell if TF is actually successfully loading the saved weights, because the TF script is nondeterministic.\r\n\r\nI also ran one more experiment, which is I took your new loss function and slapped it on `word_language_model`, using the wikitext data set. The model trained correctly but the perplexity is too large. But I am concerned because this doesn't match your experiments at all."}