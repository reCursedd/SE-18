{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9984", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9984/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9984/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9984/events", "html_url": "https://github.com/pytorch/pytorch/issues/9984", "id": 345498662, "node_id": "MDU6SXNzdWUzNDU0OTg2NjI=", "number": 9984, "title": "torch.device and torch.nn.parallel.data_parallel compatibility", "user": {"login": "PetrochukM", "id": 7424737, "node_id": "MDQ6VXNlcjc0MjQ3Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7424737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PetrochukM", "html_url": "https://github.com/PetrochukM", "followers_url": "https://api.github.com/users/PetrochukM/followers", "following_url": "https://api.github.com/users/PetrochukM/following{/other_user}", "gists_url": "https://api.github.com/users/PetrochukM/gists{/gist_id}", "starred_url": "https://api.github.com/users/PetrochukM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PetrochukM/subscriptions", "organizations_url": "https://api.github.com/users/PetrochukM/orgs", "repos_url": "https://api.github.com/users/PetrochukM/repos", "events_url": "https://api.github.com/users/PetrochukM/events{/privacy}", "received_events_url": "https://api.github.com/users/PetrochukM/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-07-29T03:47:07Z", "updated_at": "2018-09-12T03:29:27Z", "closed_at": "2018-09-12T03:29:27Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p><code>torch.nn.parallel.data_parallel</code> does not accept <code>torch.device</code></p>\n<h2>Code example</h2>\n<pre><code>import torch\nnet = torch.nn.LSTM(10, 10)\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda')) # Does not work\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda').index) # Works\n</code></pre>\n<pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in data_parallel\n    return gather(outputs, output_device, dim)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 67, in gather\n    return gather_map(outputs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 62, in gather_map\n    return type(out)(map(gather_map, zip(*outputs)))\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 54, in gather_map\n    return Gather.apply(target_device, dim, *outputs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 65, in forward\n    return comm.gather(inputs, ctx.dim, ctx.target_device)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/cuda/comm.py\", line 160, in gather\n    return torch._C._gather(tensors, dim, destination)\nTypeError: _gather(): incompatible function arguments. The following argument types are supported:\n    1. (tensors: List[at::Tensor], dim: int, destination_index: Optional[int]) -&gt; at::Tensor\n\nInvoked with: (tensor([[[-0.0603, -0.0166, -0.0857,  0.0781,  0.1473,  0.1543,  0.0239,\n           0.0820,  0.0887, -0.0435]]],\n       device='cuda:0', grad_fn=&lt;CudnnRnnBackward&gt;),), 0, device(type='cuda')\n</code></pre>\n<h2>System Info</h2>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): pip</li>\n<li>PyTorch version: 0.4.1</li>\n<li>Python version: 3.5.2</li>\n</ul>", "body_text": "Issue description\ntorch.nn.parallel.data_parallel does not accept torch.device\nCode example\nimport torch\nnet = torch.nn.LSTM(10, 10)\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda')) # Does not work\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda').index) # Works\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in data_parallel\n    return gather(outputs, output_device, dim)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 67, in gather\n    return gather_map(outputs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 62, in gather_map\n    return type(out)(map(gather_map, zip(*outputs)))\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 54, in gather_map\n    return Gather.apply(target_device, dim, *outputs)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 65, in forward\n    return comm.gather(inputs, ctx.dim, ctx.target_device)\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/cuda/comm.py\", line 160, in gather\n    return torch._C._gather(tensors, dim, destination)\nTypeError: _gather(): incompatible function arguments. The following argument types are supported:\n    1. (tensors: List[at::Tensor], dim: int, destination_index: Optional[int]) -> at::Tensor\n\nInvoked with: (tensor([[[-0.0603, -0.0166, -0.0857,  0.0781,  0.1473,  0.1543,  0.0239,\n           0.0820,  0.0887, -0.0435]]],\n       device='cuda:0', grad_fn=<CudnnRnnBackward>),), 0, device(type='cuda')\n\nSystem Info\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): pip\nPyTorch version: 0.4.1\nPython version: 3.5.2", "body": "## Issue description\r\n\r\n``torch.nn.parallel.data_parallel`` does not accept ``torch.device``\r\n\r\n## Code example\r\n\r\n```\r\nimport torch\r\nnet = torch.nn.LSTM(10, 10)\r\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda')) # Does not work\r\ntorch.nn.parallel.data_parallel(module=net.cuda(), inputs=torch.randn(1, 1, 10).cuda(), output_device=torch.device('cuda').index) # Works\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in data_parallel\r\n    return gather(outputs, output_device, dim)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 67, in gather\r\n    return gather_map(outputs)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 62, in gather_map\r\n    return type(out)(map(gather_map, zip(*outputs)))\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line 54, in gather_map\r\n    return Gather.apply(target_device, dim, *outputs)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 65, in forward\r\n    return comm.gather(inputs, ctx.dim, ctx.target_device)\r\n  File \"/home/michaelp/.local/lib/python3.5/site-packages/torch/cuda/comm.py\", line 160, in gather\r\n    return torch._C._gather(tensors, dim, destination)\r\nTypeError: _gather(): incompatible function arguments. The following argument types are supported:\r\n    1. (tensors: List[at::Tensor], dim: int, destination_index: Optional[int]) -> at::Tensor\r\n\r\nInvoked with: (tensor([[[-0.0603, -0.0166, -0.0857,  0.0781,  0.1473,  0.1543,  0.0239,\r\n           0.0820,  0.0887, -0.0435]]],\r\n       device='cuda:0', grad_fn=<CudnnRnnBackward>),), 0, device(type='cuda')\r\n```\r\n\r\n## System Info\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): pip\r\n- PyTorch version: 0.4.1\r\n- Python version: 3.5.2\r\n"}