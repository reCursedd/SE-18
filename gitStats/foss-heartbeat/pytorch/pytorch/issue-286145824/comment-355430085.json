{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355430085", "html_url": "https://github.com/pytorch/pytorch/pull/4487#issuecomment-355430085", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4487", "id": 355430085, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTQzMDA4NQ==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T23:34:55Z", "updated_at": "2018-01-04T23:34:55Z", "author_association": "MEMBER", "body_html": "<p>Previously, we did not profile \"fall through functions\". Many of these functions are now profiled, with the exception of things like size/stride/storage_offset.</p>\n<p>Previously, we did not bind functions that were missing derivative definitions. We now generate bindings (and throw not implemented exceptions in backwards). This should make it easier to write and test native functions before writing the derivative formula.</p>\n<p>Previously, we had derivative definitions for things like <code>&lt;</code>, <code>&gt;</code>, <code>==</code>. These are now limited to the in-place versions, since the out-of-place versions return BoolTensor (ByteTensor), which is never differentiable. The corresponding tests in <code>test_autograd.py</code> are deleted because they otherwise throw \"output does not require grad\".</p>", "body_text": "Previously, we did not profile \"fall through functions\". Many of these functions are now profiled, with the exception of things like size/stride/storage_offset.\nPreviously, we did not bind functions that were missing derivative definitions. We now generate bindings (and throw not implemented exceptions in backwards). This should make it easier to write and test native functions before writing the derivative formula.\nPreviously, we had derivative definitions for things like <, >, ==. These are now limited to the in-place versions, since the out-of-place versions return BoolTensor (ByteTensor), which is never differentiable. The corresponding tests in test_autograd.py are deleted because they otherwise throw \"output does not require grad\".", "body": "Previously, we did not profile \"fall through functions\". Many of these functions are now profiled, with the exception of things like size/stride/storage_offset.\r\n\r\nPreviously, we did not bind functions that were missing derivative definitions. We now generate bindings (and throw not implemented exceptions in backwards). This should make it easier to write and test native functions before writing the derivative formula.\r\n\r\nPreviously, we had derivative definitions for things like `<`, `>`, `==`. These are now limited to the in-place versions, since the out-of-place versions return BoolTensor (ByteTensor), which is never differentiable. The corresponding tests in `test_autograd.py` are deleted because they otherwise throw \"output does not require grad\"."}