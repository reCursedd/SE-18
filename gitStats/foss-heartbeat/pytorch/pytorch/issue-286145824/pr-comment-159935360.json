{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159935360", "pull_request_review_id": 86970904, "id": 159935360, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTkzNTM2MA==", "diff_hunk": "@@ -2236,36 +2236,6 @@ class dont_convert(tuple):\n     ('det', lambda: random_fullrank_matrix_distinct_singular_value(S), (), 'distinct_postive_s', (), [skipIfNoLapack]),\n     ('svd', lambda: random_fullrank_matrix_distinct_singular_value(S), (), '', (), [skipIfNoLapack]),\n     ('gesv', (S, S), ((S, S),), '', (), [skipIfNoLapack]),\n-    ('eq', (S, S, S), ((S, S, S),)),", "path": "test/test_autograd.py", "position": 4, "original_position": 4, "commit_id": "e135e7863dad9e6c6fc43085459880f5ad3d0126", "original_commit_id": "202fd3eb9a2f59e7d1460f03beb5e8026164210d", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "but these did test some useful stuff like that inplace worked; we are just throwing that away?  Can't we just skip the specific part of the check that triggers the error if the return type of the function is non-differentiable?", "created_at": "2018-01-05T17:29:17Z", "updated_at": "2018-11-23T15:37:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/4487#discussion_r159935360", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4487", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159935360"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4487#discussion_r159935360"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4487"}}, "body_html": "<p>but these did test some useful stuff like that inplace worked; we are just throwing that away?  Can't we just skip the specific part of the check that triggers the error if the return type of the function is non-differentiable?</p>", "body_text": "but these did test some useful stuff like that inplace worked; we are just throwing that away?  Can't we just skip the specific part of the check that triggers the error if the return type of the function is non-differentiable?", "in_reply_to_id": 159885604}