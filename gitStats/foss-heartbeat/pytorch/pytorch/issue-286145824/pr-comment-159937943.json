{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159937943", "pull_request_review_id": 86973500, "id": 159937943, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1OTkzNzk0Mw==", "diff_hunk": "@@ -15,106 +16,96 @@\n #       - The function's output is not differentiable\n #       - The function has no data dependency on its input\n #\n-#     These are currently called \"fallthrough\" functions, although\n-#     they are not entirely fallthrough; for example, if the function\n-#     in question returns a tensor, we have to wrap it in a\n-#     (does not require grad) variable to abide by the API contract\n-#     of Variable.\n-#\n #   - Some function don't need a backwards implementation because they\n-#     are implement as a composition of other (differentiable) ATen\n+#     are implemented as a composition of other (differentiable) ATen\n #     functions.  These are dispatched directly to the Type superclass,\n #     which will in turn dispatch back to VariableType for its\n #     differentiable subcomponents.\n+#\n+from __future__ import print_function\n+import sys\n+from .utils import CodeTemplate, nested_dict\n+from .gen_autograd import VIEW_FUNCTIONS, template_path, write\n+from .gen_autograd_functions import uses_grad\n+\n+VARIABLE_TYPE_H = CodeTemplate.from_file(template_path + '/VariableType.h')\n+VARIABLE_TYPE_CPP = CodeTemplate.from_file(template_path + '/VariableType.cpp')\n+\n+# These functions are written manually in templates/VariableType.cpp\n+MANUAL_IMPLEMENTATIONS = {\n+    'contiguous', 'resize_', 'resize_as_'\n+}\n+\n+# These functions we don't want to record for tracing, because we always want\n+# to trace their constituent parts.  This is a temporary hack in lieue\n+# of proper scopes, where subsequent compilation passes can ask for the unfolding\n+# on demand.  Only concrete ATen methods can be disabled this way; it will have\n+# NO EFFECT otherwise.\n+DONT_RECORD_TRACE = {\n+    'convolution', 'conv1d', 'conv2d', 'conv3d', 'conv_transpose1d',\n+    'conv_transpose2d', 'conv_transpose3d',\n+}\n \n-import argparse\n-import copy\n-import os\n-import re\n-import yaml\n-from collections import defaultdict\n-from .utils import CodeTemplate, write, nested_dict, YamlLoader\n+# These functions are not worth profiling because they are very cheap and may\n+# be called very often.\n+DONT_PROFILE = {\n+    'data_ptr', 'get_device', 'is_contiguous', 'is_cuda', 'is_distributed',\n+    'is_same_size', 'is_set_to', 'is_signed', 'is_sparse', 'numel',\n+    'size', 'storage_offset', 'stride',\n+}\n \n+DONT_REQUIRE_DERIVATIVE = {\n+    # These  only depend on the input Tensor's shape and device, not the data\n+    'ones_like', 'zeros_like',\n+    # These are only implemented on integral types\n+    '__and__', '__iand__', '__ilshift__', '__ior__', '__irshift__', '__ixor__',\n+    '__lshift__', '__or__', '__rshift__', '__xor__',\n+}\n \n METHOD_DECLARATION = CodeTemplate(\"\"\"\\\n virtual ${return_type} ${method_prefix_derived}${api_name}(${formals}) const override;\n \"\"\")\n \n METHOD_DEFINITION = CodeTemplate(\"\"\"\\\n ${return_type} VariableType::${method_prefix_derived}${api_name}(${formals}) const {\n-    ${type_definition_body}\n+  ${type_definition_body}", "path": "tools/autograd/gen_variable_type.py", "position": 87, "original_position": 84, "commit_id": "e135e7863dad9e6c6fc43085459880f5ad3d0126", "original_commit_id": "202fd3eb9a2f59e7d1460f03beb5e8026164210d", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Indentation fixes! \ud83d\ude04 \r\n\r\nHere's the full generated code: [VariableType.cpp](https://gist.github.com/colesbury/f073eb601b2d95859244c724f0bb11c4).", "created_at": "2018-01-05T17:42:20Z", "updated_at": "2018-11-23T15:37:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/4487#discussion_r159937943", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4487", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/159937943"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4487#discussion_r159937943"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4487"}}, "body_html": "<p>Indentation fixes! <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>\n<p>Here's the full generated code: <a href=\"https://gist.github.com/colesbury/f073eb601b2d95859244c724f0bb11c4\">VariableType.cpp</a>.</p>", "body_text": "Indentation fixes! \ud83d\ude04\nHere's the full generated code: VariableType.cpp.", "in_reply_to_id": 159890024}