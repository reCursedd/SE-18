{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4775", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4775/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4775/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4775/events", "html_url": "https://github.com/pytorch/pytorch/pull/4775", "id": 290347235, "node_id": "MDExOlB1bGxSZXF1ZXN0MTY0MjIwNTMy", "number": 4775, "title": "New index computation strategy in Functions.cpp (Tensor/TensorList)", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-22T04:22:48Z", "updated_at": "2018-01-27T20:46:09Z", "closed_at": "2018-01-27T20:46:09Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4775", "html_url": "https://github.com/pytorch/pytorch/pull/4775", "diff_url": "https://github.com/pytorch/pytorch/pull/4775.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4775.patch"}, "body_html": "<pre><code>commit e25e0b801b243d35db6190cd60db29834583ddf5\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Fri Jan 19 16:56:22 2018 -0800\n\n    New index computation strategy in Functions.cpp (Tensor/TensorList)\n    \n    When generating autograd::Function wrappers for ATen functions, we need\n    to take derivative expressions in derivatives.yaml (identified by name)\n    and correlate them with the correct index they should take in\n    grad_inputs (identified positionally only).  Previously, this\n    computation was done *statically* in load_derivatives.py (set_up_derivatives)\n    and then we hard-coded indices in the generated Functions.cpp.\n    This is sufficient for supporting ATen operations which consist solely\n    of Tensor arguments, or a single TensorList argument.  However, this\n    strategy will not work for mixed Tensor/TensorList arguments, as the\n    index of any Tensor after a TensorList is not known at codegen time,\n    since it will vary depending on the length of the TensorList, e.g.,\n    \n      foo({x1, x2}, y)      ==&gt;  y is index 2\n      foo({x1, x2, x3}, y)  ==&gt;  y is index 3\n    \n    This commit introduces a new strategy for generating these indices which\n    pushes index computation to *runtime* (though any decent C++ optimizer\n    can re-optimize the index computation back into constants; this was\n    verified in Godbolt.)  Instead of hard-coding constants, a small\n    IndexRangeGenerator object is created and used to generate the correct\n    index ranges (std::pair&lt;size_t, size_t&gt;) for each argument.\n    \n    Here is an example of mm rewritten in the new codegen format:\n    \n      variable_list MmBackward::apply(const variable_list&amp; grads) {\n        IndexRangeGenerator gen;\n        auto self_ix = gen.range(1);\n        auto mat2_ix = gen.range(1);\n        variable_list grad_inputs(gen.size());\n        auto&amp; grad = grads[0];\n        auto self = self_.unpack();\n        auto mat2 = mat2_.unpack();\n        if (should_compute_output({ mat2_ix })) {\n          auto grad_result = mm_mat2_backward(grad, self, mat2_sizes, mat2.strides(), 1);\n          copy_range(grad_inputs, mat2_ix, grad_result);\n        }\n        if (should_compute_output({ self_ix })) {\n          auto grad_result = mm_mat1_backward(grad, mat2, self_sizes, self.strides(), 1);\n          copy_range(grad_inputs, self_ix, grad_result);\n        }\n        return grad_inputs;\n      }\n    \n    Unlike before, where self_ix and mat2_ix were hardcoded as 0 and 1,\n    we derive them by invoking IndexRangeGenerator (which internally\n    is just a little counter which bumps up each invocation of 'range').\n    Each _ix variable actually represents a range, as can be seen here.\n    \n      variable_list CatBackward::apply(const variable_list&amp; grads) {\n        IndexRangeGenerator gen;\n        auto tensors_ix = gen.range(tensors_size_);\n        variable_list grad_inputs(gen.size());\n        auto&amp; grad = grads[0];\n        if (should_compute_output({ tensors_ix })) {\n          auto grad_result = cat_tensors_backward(grad, tensors_sizes_dim, dim);\n          copy_range(grad_inputs, tensors_ix, grad_result);\n        }\n        return grad_inputs;\n      }\n    \n    The invocation of 'copy_range' reads a TensorList returned by the\n    backward function into the correct entries in grad_inputs.\n    tensors_size_ is a new member of CatBackward which is filled with\n    the size of the forward input tensor when cat is originally invoked.\n    \n    With this new code generation strategy, we can completely eliminate\n    the special cases for Tensor and TensorList in index selection, and\n    we can smoothly support mixed Tensor/TensorList by making multiple\n    invocations of gen.range() with non-one arguments.\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n</code></pre>\n<p>This is stacked on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"290330456\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4772\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4772/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4772\">#4772</a>, review only the last commit.</p>", "body_text": "commit e25e0b801b243d35db6190cd60db29834583ddf5\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Fri Jan 19 16:56:22 2018 -0800\n\n    New index computation strategy in Functions.cpp (Tensor/TensorList)\n    \n    When generating autograd::Function wrappers for ATen functions, we need\n    to take derivative expressions in derivatives.yaml (identified by name)\n    and correlate them with the correct index they should take in\n    grad_inputs (identified positionally only).  Previously, this\n    computation was done *statically* in load_derivatives.py (set_up_derivatives)\n    and then we hard-coded indices in the generated Functions.cpp.\n    This is sufficient for supporting ATen operations which consist solely\n    of Tensor arguments, or a single TensorList argument.  However, this\n    strategy will not work for mixed Tensor/TensorList arguments, as the\n    index of any Tensor after a TensorList is not known at codegen time,\n    since it will vary depending on the length of the TensorList, e.g.,\n    \n      foo({x1, x2}, y)      ==>  y is index 2\n      foo({x1, x2, x3}, y)  ==>  y is index 3\n    \n    This commit introduces a new strategy for generating these indices which\n    pushes index computation to *runtime* (though any decent C++ optimizer\n    can re-optimize the index computation back into constants; this was\n    verified in Godbolt.)  Instead of hard-coding constants, a small\n    IndexRangeGenerator object is created and used to generate the correct\n    index ranges (std::pair<size_t, size_t>) for each argument.\n    \n    Here is an example of mm rewritten in the new codegen format:\n    \n      variable_list MmBackward::apply(const variable_list& grads) {\n        IndexRangeGenerator gen;\n        auto self_ix = gen.range(1);\n        auto mat2_ix = gen.range(1);\n        variable_list grad_inputs(gen.size());\n        auto& grad = grads[0];\n        auto self = self_.unpack();\n        auto mat2 = mat2_.unpack();\n        if (should_compute_output({ mat2_ix })) {\n          auto grad_result = mm_mat2_backward(grad, self, mat2_sizes, mat2.strides(), 1);\n          copy_range(grad_inputs, mat2_ix, grad_result);\n        }\n        if (should_compute_output({ self_ix })) {\n          auto grad_result = mm_mat1_backward(grad, mat2, self_sizes, self.strides(), 1);\n          copy_range(grad_inputs, self_ix, grad_result);\n        }\n        return grad_inputs;\n      }\n    \n    Unlike before, where self_ix and mat2_ix were hardcoded as 0 and 1,\n    we derive them by invoking IndexRangeGenerator (which internally\n    is just a little counter which bumps up each invocation of 'range').\n    Each _ix variable actually represents a range, as can be seen here.\n    \n      variable_list CatBackward::apply(const variable_list& grads) {\n        IndexRangeGenerator gen;\n        auto tensors_ix = gen.range(tensors_size_);\n        variable_list grad_inputs(gen.size());\n        auto& grad = grads[0];\n        if (should_compute_output({ tensors_ix })) {\n          auto grad_result = cat_tensors_backward(grad, tensors_sizes_dim, dim);\n          copy_range(grad_inputs, tensors_ix, grad_result);\n        }\n        return grad_inputs;\n      }\n    \n    The invocation of 'copy_range' reads a TensorList returned by the\n    backward function into the correct entries in grad_inputs.\n    tensors_size_ is a new member of CatBackward which is filled with\n    the size of the forward input tensor when cat is originally invoked.\n    \n    With this new code generation strategy, we can completely eliminate\n    the special cases for Tensor and TensorList in index selection, and\n    we can smoothly support mixed Tensor/TensorList by making multiple\n    invocations of gen.range() with non-one arguments.\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\n\nThis is stacked on #4772, review only the last commit.", "body": "```\r\ncommit e25e0b801b243d35db6190cd60db29834583ddf5\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Fri Jan 19 16:56:22 2018 -0800\r\n\r\n    New index computation strategy in Functions.cpp (Tensor/TensorList)\r\n    \r\n    When generating autograd::Function wrappers for ATen functions, we need\r\n    to take derivative expressions in derivatives.yaml (identified by name)\r\n    and correlate them with the correct index they should take in\r\n    grad_inputs (identified positionally only).  Previously, this\r\n    computation was done *statically* in load_derivatives.py (set_up_derivatives)\r\n    and then we hard-coded indices in the generated Functions.cpp.\r\n    This is sufficient for supporting ATen operations which consist solely\r\n    of Tensor arguments, or a single TensorList argument.  However, this\r\n    strategy will not work for mixed Tensor/TensorList arguments, as the\r\n    index of any Tensor after a TensorList is not known at codegen time,\r\n    since it will vary depending on the length of the TensorList, e.g.,\r\n    \r\n      foo({x1, x2}, y)      ==>  y is index 2\r\n      foo({x1, x2, x3}, y)  ==>  y is index 3\r\n    \r\n    This commit introduces a new strategy for generating these indices which\r\n    pushes index computation to *runtime* (though any decent C++ optimizer\r\n    can re-optimize the index computation back into constants; this was\r\n    verified in Godbolt.)  Instead of hard-coding constants, a small\r\n    IndexRangeGenerator object is created and used to generate the correct\r\n    index ranges (std::pair<size_t, size_t>) for each argument.\r\n    \r\n    Here is an example of mm rewritten in the new codegen format:\r\n    \r\n      variable_list MmBackward::apply(const variable_list& grads) {\r\n        IndexRangeGenerator gen;\r\n        auto self_ix = gen.range(1);\r\n        auto mat2_ix = gen.range(1);\r\n        variable_list grad_inputs(gen.size());\r\n        auto& grad = grads[0];\r\n        auto self = self_.unpack();\r\n        auto mat2 = mat2_.unpack();\r\n        if (should_compute_output({ mat2_ix })) {\r\n          auto grad_result = mm_mat2_backward(grad, self, mat2_sizes, mat2.strides(), 1);\r\n          copy_range(grad_inputs, mat2_ix, grad_result);\r\n        }\r\n        if (should_compute_output({ self_ix })) {\r\n          auto grad_result = mm_mat1_backward(grad, mat2, self_sizes, self.strides(), 1);\r\n          copy_range(grad_inputs, self_ix, grad_result);\r\n        }\r\n        return grad_inputs;\r\n      }\r\n    \r\n    Unlike before, where self_ix and mat2_ix were hardcoded as 0 and 1,\r\n    we derive them by invoking IndexRangeGenerator (which internally\r\n    is just a little counter which bumps up each invocation of 'range').\r\n    Each _ix variable actually represents a range, as can be seen here.\r\n    \r\n      variable_list CatBackward::apply(const variable_list& grads) {\r\n        IndexRangeGenerator gen;\r\n        auto tensors_ix = gen.range(tensors_size_);\r\n        variable_list grad_inputs(gen.size());\r\n        auto& grad = grads[0];\r\n        if (should_compute_output({ tensors_ix })) {\r\n          auto grad_result = cat_tensors_backward(grad, tensors_sizes_dim, dim);\r\n          copy_range(grad_inputs, tensors_ix, grad_result);\r\n        }\r\n        return grad_inputs;\r\n      }\r\n    \r\n    The invocation of 'copy_range' reads a TensorList returned by the\r\n    backward function into the correct entries in grad_inputs.\r\n    tensors_size_ is a new member of CatBackward which is filled with\r\n    the size of the forward input tensor when cat is originally invoked.\r\n    \r\n    With this new code generation strategy, we can completely eliminate\r\n    the special cases for Tensor and TensorList in index selection, and\r\n    we can smoothly support mixed Tensor/TensorList by making multiple\r\n    invocations of gen.range() with non-one arguments.\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n```\r\n\r\nThis is stacked on #4772, review only the last commit."}