{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/174886119", "pull_request_review_id": 104326462, "id": 174886119, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3NDg4NjExOQ==", "diff_hunk": "@@ -7,18 +8,33 @@\n namespace at {\n namespace native {\n \n-constexpr size_t _THRESHOLD = 32768;\n+// This parameter is heuristically chosen to determine the minimum number of\n+// work that warrants paralellism. For example, when summing an array, it is\n+// deemed inefficient to parallelise over arrays shorter than 32768. Further,\n+// no parallel algorithm (such as parallel_reduce) should split work into\n+// smaller than GRAIN_SIZE chunks.\n+constexpr size_t GRAIN_SIZE = 32768;\n \n template <class T, template <class> class PRED>\n T parallel_reduce(T (*f)(const T *, size_t, size_t, T), const T *data,\n                   size_t start, size_t end, T init_) {\n+\n+  static tbb::task_scheduler_init tbbinit;", "path": "aten/src/ATen/native/cpu/Parallel.h", "position": null, "original_position": 22, "commit_id": "f811874db6271f4f1ca3eb7340a62cec88afa0cc", "original_commit_id": "354a2f656c4db2ddc23bd606f2ac69accd52bf6d", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "body": "Using thread_local static variables seem to do the trick. The thread_local keyword makes sure that there will be a new variable per thread and also removes any need to guard for data races. The static variable makes sure it's linked internally. \r\n\r\nOn task_scheduler_init, it needs to be called before the first usage of any tbb function. It initializes the scheduler with the passed parameters (number of threads). Any tbb construct (such as the parallel algorithm) will spawn a default thread pool if this hasn't been called before. The default will consume all available cores. See [the documentation](https://www.threadingbuildingblocks.org/docs/help/reference/task_scheduler/task_scheduler_init_cls.html):\r\n\r\n\"To override the automatic defaults for task scheduling, a task_scheduler_init must become active before the first use of task scheduling services.\r\n\"\r\nThere are two potential issues:\r\nWe must direct any usage of tbb to Parallel.h to make sure tbb is initialized first.\r\nWhile the current scheduler might be limited in the number of cores used, the overall market is not. That means, if there are two threads, they each will spawn the number of threads as specified by torch.set_num_thread. As far as I know this behavior is consistent with OpenMP.\r\n\r\nOne advantage, as far as I can tell, is that tbb will use a market to limited the number of overall worker threads. So that even if each cpp thread requests 60 threads for each tbb scheduler, the overall number of workers will be limited to the maximum number of cores available and the associated number of worker threads is divided by the number of active schedulers. This should prevent oversubscription. \r\n\r\nSee https://software.intel.com/en-us/blogs/2011/04/09/tbb-initialization-termination-and-resource-management-details-juicy-and-gory", "created_at": "2018-03-15T18:28:11Z", "updated_at": "2018-11-23T15:40:48Z", "html_url": "https://github.com/pytorch/pytorch/pull/5723#discussion_r174886119", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5723", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/174886119"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5723#discussion_r174886119"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5723"}}, "body_html": "<p>Using thread_local static variables seem to do the trick. The thread_local keyword makes sure that there will be a new variable per thread and also removes any need to guard for data races. The static variable makes sure it's linked internally.</p>\n<p>On task_scheduler_init, it needs to be called before the first usage of any tbb function. It initializes the scheduler with the passed parameters (number of threads). Any tbb construct (such as the parallel algorithm) will spawn a default thread pool if this hasn't been called before. The default will consume all available cores. See <a href=\"https://www.threadingbuildingblocks.org/docs/help/reference/task_scheduler/task_scheduler_init_cls.html\" rel=\"nofollow\">the documentation</a>:</p>\n<p>\"To override the automatic defaults for task scheduling, a task_scheduler_init must become active before the first use of task scheduling services.<br>\n\"<br>\nThere are two potential issues:<br>\nWe must direct any usage of tbb to Parallel.h to make sure tbb is initialized first.<br>\nWhile the current scheduler might be limited in the number of cores used, the overall market is not. That means, if there are two threads, they each will spawn the number of threads as specified by torch.set_num_thread. As far as I know this behavior is consistent with OpenMP.</p>\n<p>One advantage, as far as I can tell, is that tbb will use a market to limited the number of overall worker threads. So that even if each cpp thread requests 60 threads for each tbb scheduler, the overall number of workers will be limited to the maximum number of cores available and the associated number of worker threads is divided by the number of active schedulers. This should prevent oversubscription.</p>\n<p>See <a href=\"https://software.intel.com/en-us/blogs/2011/04/09/tbb-initialization-termination-and-resource-management-details-juicy-and-gory\" rel=\"nofollow\">https://software.intel.com/en-us/blogs/2011/04/09/tbb-initialization-termination-and-resource-management-details-juicy-and-gory</a></p>", "body_text": "Using thread_local static variables seem to do the trick. The thread_local keyword makes sure that there will be a new variable per thread and also removes any need to guard for data races. The static variable makes sure it's linked internally.\nOn task_scheduler_init, it needs to be called before the first usage of any tbb function. It initializes the scheduler with the passed parameters (number of threads). Any tbb construct (such as the parallel algorithm) will spawn a default thread pool if this hasn't been called before. The default will consume all available cores. See the documentation:\n\"To override the automatic defaults for task scheduling, a task_scheduler_init must become active before the first use of task scheduling services.\n\"\nThere are two potential issues:\nWe must direct any usage of tbb to Parallel.h to make sure tbb is initialized first.\nWhile the current scheduler might be limited in the number of cores used, the overall market is not. That means, if there are two threads, they each will spawn the number of threads as specified by torch.set_num_thread. As far as I know this behavior is consistent with OpenMP.\nOne advantage, as far as I can tell, is that tbb will use a market to limited the number of overall worker threads. So that even if each cpp thread requests 60 threads for each tbb scheduler, the overall number of workers will be limited to the maximum number of cores available and the associated number of worker threads is divided by the number of active schedulers. This should prevent oversubscription.\nSee https://software.intel.com/en-us/blogs/2011/04/09/tbb-initialization-termination-and-resource-management-details-juicy-and-gory", "in_reply_to_id": 174503439}