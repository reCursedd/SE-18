{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/372499103", "html_url": "https://github.com/pytorch/pytorch/pull/5723#issuecomment-372499103", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5723", "id": 372499103, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjQ5OTEwMw==", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-12T23:45:17Z", "updated_at": "2018-03-12T23:45:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Added support for changing number of threads at runtime. Consider the following script</p>\n<pre><code>import torch\nimport time\nimport gc\nimport argparse\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process some integers.')\n    parser.add_argument('threads', type=int)\n    parser.add_argument('--decrease', action='store_true')\n    args = parser.parse_args()\n\n    tv = torch.randn(1000 * 1000 * 10)\n    num_thread = args.threads\n    torch.set_num_threads(num_thread)\n    tstart = time.time()\n    for i in range(100000):\n        tv.sum()\n        if args.decrease and i % 10000 == 0:\n            gc.collect()\n            elapsed = time.time() - tstart\n            tstart = time.time()\n            num_thread = num_thread / 2\n            print(\"decreasing to: \" + str(num_thread) + \" prev elapsed: \" + str(elapsed))\n            torch.set_num_threads(num_thread)\n</code></pre>\n<p>And output</p>\n<pre><code>decreasing to: 16 prev elapsed: 0.0332319736481\ndecreasing to: 8 prev elapsed: 1.24536299706\ndecreasing to: 4 prev elapsed: 2.19691586494\ndecreasing to: 2 prev elapsed: 4.26764798164\ndecreasing to: 1 prev elapsed: 7.82375693321\ndecreasing to: 0 prev elapsed: 15.4659228325\ndecreasing to: 0 prev elapsed: 0.84959602356\ndecreasing to: 0 prev elapsed: 0.842261075974\ndecreasing to: 0 prev elapsed: 0.804984092712\ndecreasing to: 0 prev elapsed: 0.823231220245\n\n Performance counter stats for 'python sum_stress.py 32 --decrease':\n\n     354283.766260      task-clock (msec)         #    9.613 CPUs utilized          \n           581,664      context-switches          #    0.002 M/sec                  \n             4,625      cpu-migrations            #    0.013 K/sec                  \n            49,221      page-faults               #    0.139 K/sec                  \n   779,103,968,909      cycles                    #    2.199 GHz                    \n   &lt;not supported&gt;      stalled-cycles-frontend  \n   &lt;not supported&gt;      stalled-cycles-backend   \n   395,023,334,546      instructions              #    0.51  insns per cycle        \n    56,253,880,001      branches                  #  158.782 M/sec                  \n       165,331,982      branch-misses             #    0.29% of all branches        \n\n      36.854981344 seconds time elapsed\n</code></pre>", "body_text": "Added support for changing number of threads at runtime. Consider the following script\nimport torch\nimport time\nimport gc\nimport argparse\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process some integers.')\n    parser.add_argument('threads', type=int)\n    parser.add_argument('--decrease', action='store_true')\n    args = parser.parse_args()\n\n    tv = torch.randn(1000 * 1000 * 10)\n    num_thread = args.threads\n    torch.set_num_threads(num_thread)\n    tstart = time.time()\n    for i in range(100000):\n        tv.sum()\n        if args.decrease and i % 10000 == 0:\n            gc.collect()\n            elapsed = time.time() - tstart\n            tstart = time.time()\n            num_thread = num_thread / 2\n            print(\"decreasing to: \" + str(num_thread) + \" prev elapsed: \" + str(elapsed))\n            torch.set_num_threads(num_thread)\n\nAnd output\ndecreasing to: 16 prev elapsed: 0.0332319736481\ndecreasing to: 8 prev elapsed: 1.24536299706\ndecreasing to: 4 prev elapsed: 2.19691586494\ndecreasing to: 2 prev elapsed: 4.26764798164\ndecreasing to: 1 prev elapsed: 7.82375693321\ndecreasing to: 0 prev elapsed: 15.4659228325\ndecreasing to: 0 prev elapsed: 0.84959602356\ndecreasing to: 0 prev elapsed: 0.842261075974\ndecreasing to: 0 prev elapsed: 0.804984092712\ndecreasing to: 0 prev elapsed: 0.823231220245\n\n Performance counter stats for 'python sum_stress.py 32 --decrease':\n\n     354283.766260      task-clock (msec)         #    9.613 CPUs utilized          \n           581,664      context-switches          #    0.002 M/sec                  \n             4,625      cpu-migrations            #    0.013 K/sec                  \n            49,221      page-faults               #    0.139 K/sec                  \n   779,103,968,909      cycles                    #    2.199 GHz                    \n   <not supported>      stalled-cycles-frontend  \n   <not supported>      stalled-cycles-backend   \n   395,023,334,546      instructions              #    0.51  insns per cycle        \n    56,253,880,001      branches                  #  158.782 M/sec                  \n       165,331,982      branch-misses             #    0.29% of all branches        \n\n      36.854981344 seconds time elapsed", "body": "Added support for changing number of threads at runtime. Consider the following script\r\n\r\n```\r\nimport torch\r\nimport time\r\nimport gc\r\nimport argparse\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser(description='Process some integers.')\r\n    parser.add_argument('threads', type=int)\r\n    parser.add_argument('--decrease', action='store_true')\r\n    args = parser.parse_args()\r\n\r\n    tv = torch.randn(1000 * 1000 * 10)\r\n    num_thread = args.threads\r\n    torch.set_num_threads(num_thread)\r\n    tstart = time.time()\r\n    for i in range(100000):\r\n        tv.sum()\r\n        if args.decrease and i % 10000 == 0:\r\n            gc.collect()\r\n            elapsed = time.time() - tstart\r\n            tstart = time.time()\r\n            num_thread = num_thread / 2\r\n            print(\"decreasing to: \" + str(num_thread) + \" prev elapsed: \" + str(elapsed))\r\n            torch.set_num_threads(num_thread)\r\n```\r\n\r\nAnd output\r\n\r\n```\r\ndecreasing to: 16 prev elapsed: 0.0332319736481\r\ndecreasing to: 8 prev elapsed: 1.24536299706\r\ndecreasing to: 4 prev elapsed: 2.19691586494\r\ndecreasing to: 2 prev elapsed: 4.26764798164\r\ndecreasing to: 1 prev elapsed: 7.82375693321\r\ndecreasing to: 0 prev elapsed: 15.4659228325\r\ndecreasing to: 0 prev elapsed: 0.84959602356\r\ndecreasing to: 0 prev elapsed: 0.842261075974\r\ndecreasing to: 0 prev elapsed: 0.804984092712\r\ndecreasing to: 0 prev elapsed: 0.823231220245\r\n\r\n Performance counter stats for 'python sum_stress.py 32 --decrease':\r\n\r\n     354283.766260      task-clock (msec)         #    9.613 CPUs utilized          \r\n           581,664      context-switches          #    0.002 M/sec                  \r\n             4,625      cpu-migrations            #    0.013 K/sec                  \r\n            49,221      page-faults               #    0.139 K/sec                  \r\n   779,103,968,909      cycles                    #    2.199 GHz                    \r\n   <not supported>      stalled-cycles-frontend  \r\n   <not supported>      stalled-cycles-backend   \r\n   395,023,334,546      instructions              #    0.51  insns per cycle        \r\n    56,253,880,001      branches                  #  158.782 M/sec                  \r\n       165,331,982      branch-misses             #    0.29% of all branches        \r\n\r\n      36.854981344 seconds time elapsed\r\n```"}