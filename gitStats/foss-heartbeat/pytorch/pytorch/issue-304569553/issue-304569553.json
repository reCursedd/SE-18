{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5723", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5723/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5723/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5723/events", "html_url": "https://github.com/pytorch/pytorch/pull/5723", "id": 304569553, "node_id": "MDExOlB1bGxSZXF1ZXN0MTc0NTE2NjU0", "number": 5723, "title": "tbb set_num_threads", "user": {"login": "cpuhrsch", "id": 1716488, "node_id": "MDQ6VXNlcjE3MTY0ODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1716488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpuhrsch", "html_url": "https://github.com/cpuhrsch", "followers_url": "https://api.github.com/users/cpuhrsch/followers", "following_url": "https://api.github.com/users/cpuhrsch/following{/other_user}", "gists_url": "https://api.github.com/users/cpuhrsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpuhrsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpuhrsch/subscriptions", "organizations_url": "https://api.github.com/users/cpuhrsch/orgs", "repos_url": "https://api.github.com/users/cpuhrsch/repos", "events_url": "https://api.github.com/users/cpuhrsch/events{/privacy}", "received_events_url": "https://api.github.com/users/cpuhrsch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-03-12T22:54:14Z", "updated_at": "2018-11-23T15:40:53Z", "closed_at": "2018-03-19T17:40:57Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/5723", "html_url": "https://github.com/pytorch/pytorch/pull/5723", "diff_url": "https://github.com/pytorch/pytorch/pull/5723.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/5723.patch"}, "body_html": "<p>This PR hooks up TBB with set_num_threads and also cleans up the code within ReduceOps.cpp a bit.</p>\n<p>You can see that the restriction works using the following script</p>\n<pre><code>import torch\nimport argparse\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process some integers.')\n    parser.add_argument('threads', type=int)\n    args = parser.parse_args()\n\n    tv = torch.randn(1000 * 1000 * 10)\n    if args.threads &gt; 0:\n        torch.set_num_threads(args.threads)\n    for _ in range(10000):\n        tv.sum()\n</code></pre>\n<pre><code>(base) [16:44:39: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 5\n\n Performance counter stats for 'python sum_stress.py 5':\n\n      17327.154266      task-clock (msec)         #    3.721 CPUs utilized          \n               962      context-switches          #    0.056 K/sec                  \n                90      cpu-migrations            #    0.005 K/sec                  \n            22,517      page-faults               #    0.001 M/sec                  \n    38,071,989,548      cycles                    #    2.197 GHz                    \n   &lt;not supported&gt;      stalled-cycles-frontend  \n   &lt;not supported&gt;      stalled-cycles-backend   \n    31,333,390,416      instructions              #    0.82  insns per cycle        \n     3,732,742,496      branches                  #  215.427 M/sec                  \n         8,014,202      branch-misses             #    0.21% of all branches        \n\n       4.656548693 seconds time elapsed\n\n(base) [16:44:44: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 2\n\n Performance counter stats for 'python sum_stress.py 2':\n\n      16708.310926      task-clock (msec)         #    1.780 CPUs utilized          \n             1,893      context-switches          #    0.113 K/sec                  \n                85      cpu-migrations            #    0.005 K/sec                  \n            21,486      page-faults               #    0.001 M/sec                  \n    36,683,508,608      cycles                    #    2.196 GHz                    \n   &lt;not supported&gt;      stalled-cycles-frontend  \n   &lt;not supported&gt;      stalled-cycles-backend   \n    30,414,604,047      instructions              #    0.83  insns per cycle        \n     3,536,252,326      branches                  #  211.646 M/sec                  \n         5,265,418      branch-misses             #    0.15% of all branches        \n\n       9.386758238 seconds time elapsed\n\n(base) [16:51:54: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 0\n\n Performance counter stats for 'python sum_stress.py 0':\n\n      47343.842407      task-clock (msec)         #   19.877 CPUs utilized          \n           135,891      context-switches          #    0.003 M/sec                  \n               623      cpu-migrations            #    0.013 K/sec                  \n            21,791      page-faults               #    0.460 K/sec                  \n   104,047,864,558      cycles                    #    2.198 GHz                    \n   &lt;not supported&gt;      stalled-cycles-frontend  \n   &lt;not supported&gt;      stalled-cycles-backend   \n    46,576,686,318      instructions              #    0.45  insns per cycle        \n     7,054,117,917      branches                  #  148.998 M/sec                  \n        33,104,250      branch-misses             #    0.47% of all branches        \n\n       2.381825636 seconds time elapsed\n\n(base) [16:52:18: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 1\n\n Performance counter stats for 'python sum_stress.py 1':\n\n      16819.557761      task-clock (msec)         #    0.991 CPUs utilized          \n               905      context-switches          #    0.054 K/sec                  \n                79      cpu-migrations            #    0.005 K/sec                  \n            23,798      page-faults               #    0.001 M/sec                  \n    36,957,423,434      cycles                    #    2.197 GHz                    \n   &lt;not supported&gt;      stalled-cycles-frontend  \n   &lt;not supported&gt;      stalled-cycles-backend   \n    30,260,079,596      instructions              #    0.82  insns per cycle        \n     3,503,067,589      branches                  #  208.273 M/sec                  \n         5,049,148      branch-misses             #    0.14% of all branches        \n\n      16.969856749 seconds time elapsed\n</code></pre>", "body_text": "This PR hooks up TBB with set_num_threads and also cleans up the code within ReduceOps.cpp a bit.\nYou can see that the restriction works using the following script\nimport torch\nimport argparse\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process some integers.')\n    parser.add_argument('threads', type=int)\n    args = parser.parse_args()\n\n    tv = torch.randn(1000 * 1000 * 10)\n    if args.threads > 0:\n        torch.set_num_threads(args.threads)\n    for _ in range(10000):\n        tv.sum()\n\n(base) [16:44:39: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 5\n\n Performance counter stats for 'python sum_stress.py 5':\n\n      17327.154266      task-clock (msec)         #    3.721 CPUs utilized          \n               962      context-switches          #    0.056 K/sec                  \n                90      cpu-migrations            #    0.005 K/sec                  \n            22,517      page-faults               #    0.001 M/sec                  \n    38,071,989,548      cycles                    #    2.197 GHz                    \n   <not supported>      stalled-cycles-frontend  \n   <not supported>      stalled-cycles-backend   \n    31,333,390,416      instructions              #    0.82  insns per cycle        \n     3,732,742,496      branches                  #  215.427 M/sec                  \n         8,014,202      branch-misses             #    0.21% of all branches        \n\n       4.656548693 seconds time elapsed\n\n(base) [16:44:44: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 2\n\n Performance counter stats for 'python sum_stress.py 2':\n\n      16708.310926      task-clock (msec)         #    1.780 CPUs utilized          \n             1,893      context-switches          #    0.113 K/sec                  \n                85      cpu-migrations            #    0.005 K/sec                  \n            21,486      page-faults               #    0.001 M/sec                  \n    36,683,508,608      cycles                    #    2.196 GHz                    \n   <not supported>      stalled-cycles-frontend  \n   <not supported>      stalled-cycles-backend   \n    30,414,604,047      instructions              #    0.83  insns per cycle        \n     3,536,252,326      branches                  #  211.646 M/sec                  \n         5,265,418      branch-misses             #    0.15% of all branches        \n\n       9.386758238 seconds time elapsed\n\n(base) [16:51:54: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 0\n\n Performance counter stats for 'python sum_stress.py 0':\n\n      47343.842407      task-clock (msec)         #   19.877 CPUs utilized          \n           135,891      context-switches          #    0.003 M/sec                  \n               623      cpu-migrations            #    0.013 K/sec                  \n            21,791      page-faults               #    0.460 K/sec                  \n   104,047,864,558      cycles                    #    2.198 GHz                    \n   <not supported>      stalled-cycles-frontend  \n   <not supported>      stalled-cycles-backend   \n    46,576,686,318      instructions              #    0.45  insns per cycle        \n     7,054,117,917      branches                  #  148.998 M/sec                  \n        33,104,250      branch-misses             #    0.47% of all branches        \n\n       2.381825636 seconds time elapsed\n\n(base) [16:52:18: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 1\n\n Performance counter stats for 'python sum_stress.py 1':\n\n      16819.557761      task-clock (msec)         #    0.991 CPUs utilized          \n               905      context-switches          #    0.054 K/sec                  \n                79      cpu-migrations            #    0.005 K/sec                  \n            23,798      page-faults               #    0.001 M/sec                  \n    36,957,423,434      cycles                    #    2.197 GHz                    \n   <not supported>      stalled-cycles-frontend  \n   <not supported>      stalled-cycles-backend   \n    30,260,079,596      instructions              #    0.82  insns per cycle        \n     3,503,067,589      branches                  #  208.273 M/sec                  \n         5,049,148      branch-misses             #    0.14% of all branches        \n\n      16.969856749 seconds time elapsed", "body": "This PR hooks up TBB with set_num_threads and also cleans up the code within ReduceOps.cpp a bit.\r\n\r\nYou can see that the restriction works using the following script\r\n\r\n```\r\nimport torch\r\nimport argparse\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser(description='Process some integers.')\r\n    parser.add_argument('threads', type=int)\r\n    args = parser.parse_args()\r\n\r\n    tv = torch.randn(1000 * 1000 * 10)\r\n    if args.threads > 0:\r\n        torch.set_num_threads(args.threads)\r\n    for _ in range(10000):\r\n        tv.sum()\r\n```\r\n\r\n```\r\n(base) [16:44:39: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 5\r\n\r\n Performance counter stats for 'python sum_stress.py 5':\r\n\r\n      17327.154266      task-clock (msec)         #    3.721 CPUs utilized          \r\n               962      context-switches          #    0.056 K/sec                  \r\n                90      cpu-migrations            #    0.005 K/sec                  \r\n            22,517      page-faults               #    0.001 M/sec                  \r\n    38,071,989,548      cycles                    #    2.197 GHz                    \r\n   <not supported>      stalled-cycles-frontend  \r\n   <not supported>      stalled-cycles-backend   \r\n    31,333,390,416      instructions              #    0.82  insns per cycle        \r\n     3,732,742,496      branches                  #  215.427 M/sec                  \r\n         8,014,202      branch-misses             #    0.21% of all branches        \r\n\r\n       4.656548693 seconds time elapsed\r\n\r\n(base) [16:44:44: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 2\r\n\r\n Performance counter stats for 'python sum_stress.py 2':\r\n\r\n      16708.310926      task-clock (msec)         #    1.780 CPUs utilized          \r\n             1,893      context-switches          #    0.113 K/sec                  \r\n                85      cpu-migrations            #    0.005 K/sec                  \r\n            21,486      page-faults               #    0.001 M/sec                  \r\n    36,683,508,608      cycles                    #    2.196 GHz                    \r\n   <not supported>      stalled-cycles-frontend  \r\n   <not supported>      stalled-cycles-backend   \r\n    30,414,604,047      instructions              #    0.83  insns per cycle        \r\n     3,536,252,326      branches                  #  211.646 M/sec                  \r\n         5,265,418      branch-misses             #    0.15% of all branches        \r\n\r\n       9.386758238 seconds time elapsed\r\n\r\n(base) [16:51:54: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 0\r\n\r\n Performance counter stats for 'python sum_stress.py 0':\r\n\r\n      47343.842407      task-clock (msec)         #   19.877 CPUs utilized          \r\n           135,891      context-switches          #    0.003 M/sec                  \r\n               623      cpu-migrations            #    0.013 K/sec                  \r\n            21,791      page-faults               #    0.460 K/sec                  \r\n   104,047,864,558      cycles                    #    2.198 GHz                    \r\n   <not supported>      stalled-cycles-frontend  \r\n   <not supported>      stalled-cycles-backend   \r\n    46,576,686,318      instructions              #    0.45  insns per cycle        \r\n     7,054,117,917      branches                  #  148.998 M/sec                  \r\n        33,104,250      branch-misses             #    0.47% of all branches        \r\n\r\n       2.381825636 seconds time elapsed\r\n\r\n(base) [16:52:18: cpuhrsch@devfair0129 benchmarks]$ perf stat python sum_stress.py 1\r\n\r\n Performance counter stats for 'python sum_stress.py 1':\r\n\r\n      16819.557761      task-clock (msec)         #    0.991 CPUs utilized          \r\n               905      context-switches          #    0.054 K/sec                  \r\n                79      cpu-migrations            #    0.005 K/sec                  \r\n            23,798      page-faults               #    0.001 M/sec                  \r\n    36,957,423,434      cycles                    #    2.197 GHz                    \r\n   <not supported>      stalled-cycles-frontend  \r\n   <not supported>      stalled-cycles-backend   \r\n    30,260,079,596      instructions              #    0.82  insns per cycle        \r\n     3,503,067,589      branches                  #  208.273 M/sec                  \r\n         5,049,148      branch-misses             #    0.14% of all branches        \r\n\r\n      16.969856749 seconds time elapsed\r\n```"}