{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9125", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9125/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9125/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9125/events", "html_url": "https://github.com/pytorch/pytorch/pull/9125", "id": 337734574, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk4ODQxNzMx", "number": 9125, "title": "Remove template parameter from Tensor", "user": {"login": "jerryzh168", "id": 4958441, "node_id": "MDQ6VXNlcjQ5NTg0NDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/4958441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jerryzh168", "html_url": "https://github.com/jerryzh168", "followers_url": "https://api.github.com/users/jerryzh168/followers", "following_url": "https://api.github.com/users/jerryzh168/following{/other_user}", "gists_url": "https://api.github.com/users/jerryzh168/gists{/gist_id}", "starred_url": "https://api.github.com/users/jerryzh168/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jerryzh168/subscriptions", "organizations_url": "https://api.github.com/users/jerryzh168/orgs", "repos_url": "https://api.github.com/users/jerryzh168/repos", "events_url": "https://api.github.com/users/jerryzh168/events{/privacy}", "received_events_url": "https://api.github.com/users/jerryzh168/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-03T03:40:17Z", "updated_at": "2018-07-26T17:14:50Z", "closed_at": "2018-07-26T17:14:50Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9125", "html_url": "https://github.com/pytorch/pytorch/pull/9125", "diff_url": "https://github.com/pytorch/pytorch/pull/9125.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9125.patch"}, "body_html": "<p>Summary:<br>\nUse inheritance for polymorphism, and remove template parameter<br>\nThis is to change the templating in call sites, the core implementations will change later</p>\n<p>We removed template parameter from Tensor as an effort to Pytorch and Caffe2 backend unification.</p>\n<h2>New caffe2::Tensor class</h2>\n<p>Before Caffe2 Tensor class was compile-time fixed to bind to a particular device/context. With this change, we're making it a runtime property (stored inside the tensor), but preserve the same semantics. For example, one has to specify device type in order to create a Tensor - there are no uninitialized tensors. More specifically the changes are:</p>\n<ol>\n<li>We added an extra argument <em>DeviceType</em> to most of the constructors of the tensor, e.g. (Tensor(DeviceType type)),</li>\n<li>Semantics of constructor Tensor(const Tensor&amp; src, ContextForCopy* context); is changed, in this constructor, the second context is passed in to enable us to call the templated Copy function, it could be in a different context as source and target previously, now we'll enforce that the context should have same device type as src, if it is provided.</li>\n<li>To preserve 'get-or-construct' semantics of Blob, we added specialized getter Blob::GetMutableTensor that verifies both that Blob contains a Tensor and that it's of a correct type</li>\n<li>Specifically, Tensor type is not default-constructible any more (as we don't have unknown device tensors) and thus some of the code handling STL containers needs to change</li>\n</ol>\n<p>For details about how the tensor class look like right now, please see <a href=\"https://github.com/pytorch/pytorch/blob/master/caffe2/core/tensor.h\">https://github.com/pytorch/pytorch/blob/master/caffe2/core/tensor.h</a></p>\n<p>We did a massive codemod of the fbsource and hopefully covered majority of usages. However, there are probably a few that slipped through the contbuild. You might need to refactor your custom code according the following guide:</p>\n<pre><code># Tensor\n## Type\nusing TensorCPU = Tensor&lt;CPUContext&gt;; --&gt; using TensorCPU = Tensor;\n\n## Construction\n### As class member variable\nTensorCPU x; --&gt; Tensor x{CPU};\n// TensorCPU is just Tensor&lt;CPUContext&gt;, if Tensor is templated on Context,\n// we'll write:\nTensor&lt;Context&gt; x; --&gt; Tensor x{Context::GetDeviceType()};\n// In the following we'll just use TensorCPU as example\n### As local variable\nTensorCPU x; --&gt; Tensor x(CPU);\n### make_unique\nmake_unique&lt;TensorCPU&gt;() --&gt; make_unique&lt;Tensor&gt;(CPU)\n### Constructor by context\nCUDAContext context;\n// y is a TensorCPU\nTensorCPU x(y, &amp;context); // this constructor is removed\n\n--&gt;\n\nTensor x(y, &amp;context, CPU);\n## Containers\n### Vector initialization\n vector&lt;TensorCPU&gt; tensors(numTensors);\n --&gt;\n vector&lt;TensorCPU&gt; tensors;\n for (auto i = 0; i &lt; numTensors; ++i) {\n   tensors.emplace_back(CPU);\n }\n### Vector access\nNo change\n### Map construction\nmap&lt;string, TensorCPU&gt; tensor_map;\ntensor_map.insert(std::pair&lt;string, TensorCPU&gt;(name, TensorCPU()));\n--&gt;\ntensor_map.emplace(name, Tensor(CPU));\n \n### Map access ([])\nmap&lt;TensorCPU&gt; map;\nmap[name]\n--&gt; \nmap.emplace(name, Tensor(CPU));\n map.at(name);\n\n# Blob\nGetMutable&lt;TensorCPU&gt; --&gt; GetMutableTensor(CPU)\n\n# Note for Get function we just keep it as Get&lt;TensorCPU&gt;()(equivalent to Get&lt;Tensor&gt;()) at this moment\n# Since it won't affect the current running code\n# ideally it should be rewritten as following, which gives an extra verification\n# on the type of tensor contained in the blob\nGet&lt;TensorCPU&gt;() --&gt; Get&lt;Tensor&gt;(CPU);\n</code></pre>\n<h2>Context and StaticContext</h2>\n<p>We virtualized the functions in Context in order to achieve runtime polymorphism. The static functions has been split into a StaticContext class, which has one to one correspondence with DeviceType (CPU, CUDA etc.) and it has a global singleton object. We'll store a pointer to the singleton in Tensor to indicate the context of Tensor.<br>\nOriginal Context class contained routines to copy between different contexts, however, most of the time the use case is between three types of copies: CopyToCPU, CopyFromCPU and CopySameDevice, therefore, in the new Context, while we still keep the one general templated function that can copy between arbitrary contexts (CopyBytes), we rewrote the other uses of the Copy into these three special variants of copies that do not rely on template.</p>\n<pre><code># Context\nCopy&lt;int, CPUContext, CUDAContext&gt;(...) --&gt; CopyFromCPU&lt;int&gt;(...)\nCopy&lt;int, CUDAContext, CPUContext&gt;(...) --&gt; CopyToCPU&lt;int&gt;(...)\nCopy&lt;int, CUDAContext, CUDAContext&gt;(...) --&gt; CopySameDevice&lt;int&gt;(...)\nSimilarily,\nCopy&lt;CPUContext, CUDAContext&gt;(...) --&gt; CopyFromCPU(...)\nWe also have calls using CopyItems/CopyBytes\n\nAs a side note, the distinction between three copies is that:\n- CopyBytes is copy of data pointed by raw pointers (void*)\n- Copy is templated on the data type that we want to copy (T*)\n- CopyItems get the type info from explicitly passed TypeMeta\n</code></pre>\n<p>Differential Revision: D8121878</p>", "body_text": "Summary:\nUse inheritance for polymorphism, and remove template parameter\nThis is to change the templating in call sites, the core implementations will change later\nWe removed template parameter from Tensor as an effort to Pytorch and Caffe2 backend unification.\nNew caffe2::Tensor class\nBefore Caffe2 Tensor class was compile-time fixed to bind to a particular device/context. With this change, we're making it a runtime property (stored inside the tensor), but preserve the same semantics. For example, one has to specify device type in order to create a Tensor - there are no uninitialized tensors. More specifically the changes are:\n\nWe added an extra argument DeviceType to most of the constructors of the tensor, e.g. (Tensor(DeviceType type)),\nSemantics of constructor Tensor(const Tensor& src, ContextForCopy* context); is changed, in this constructor, the second context is passed in to enable us to call the templated Copy function, it could be in a different context as source and target previously, now we'll enforce that the context should have same device type as src, if it is provided.\nTo preserve 'get-or-construct' semantics of Blob, we added specialized getter Blob::GetMutableTensor that verifies both that Blob contains a Tensor and that it's of a correct type\nSpecifically, Tensor type is not default-constructible any more (as we don't have unknown device tensors) and thus some of the code handling STL containers needs to change\n\nFor details about how the tensor class look like right now, please see https://github.com/pytorch/pytorch/blob/master/caffe2/core/tensor.h\nWe did a massive codemod of the fbsource and hopefully covered majority of usages. However, there are probably a few that slipped through the contbuild. You might need to refactor your custom code according the following guide:\n# Tensor\n## Type\nusing TensorCPU = Tensor<CPUContext>; --> using TensorCPU = Tensor;\n\n## Construction\n### As class member variable\nTensorCPU x; --> Tensor x{CPU};\n// TensorCPU is just Tensor<CPUContext>, if Tensor is templated on Context,\n// we'll write:\nTensor<Context> x; --> Tensor x{Context::GetDeviceType()};\n// In the following we'll just use TensorCPU as example\n### As local variable\nTensorCPU x; --> Tensor x(CPU);\n### make_unique\nmake_unique<TensorCPU>() --> make_unique<Tensor>(CPU)\n### Constructor by context\nCUDAContext context;\n// y is a TensorCPU\nTensorCPU x(y, &context); // this constructor is removed\n\n-->\n\nTensor x(y, &context, CPU);\n## Containers\n### Vector initialization\n vector<TensorCPU> tensors(numTensors);\n -->\n vector<TensorCPU> tensors;\n for (auto i = 0; i < numTensors; ++i) {\n   tensors.emplace_back(CPU);\n }\n### Vector access\nNo change\n### Map construction\nmap<string, TensorCPU> tensor_map;\ntensor_map.insert(std::pair<string, TensorCPU>(name, TensorCPU()));\n-->\ntensor_map.emplace(name, Tensor(CPU));\n \n### Map access ([])\nmap<TensorCPU> map;\nmap[name]\n--> \nmap.emplace(name, Tensor(CPU));\n map.at(name);\n\n# Blob\nGetMutable<TensorCPU> --> GetMutableTensor(CPU)\n\n# Note for Get function we just keep it as Get<TensorCPU>()(equivalent to Get<Tensor>()) at this moment\n# Since it won't affect the current running code\n# ideally it should be rewritten as following, which gives an extra verification\n# on the type of tensor contained in the blob\nGet<TensorCPU>() --> Get<Tensor>(CPU);\n\nContext and StaticContext\nWe virtualized the functions in Context in order to achieve runtime polymorphism. The static functions has been split into a StaticContext class, which has one to one correspondence with DeviceType (CPU, CUDA etc.) and it has a global singleton object. We'll store a pointer to the singleton in Tensor to indicate the context of Tensor.\nOriginal Context class contained routines to copy between different contexts, however, most of the time the use case is between three types of copies: CopyToCPU, CopyFromCPU and CopySameDevice, therefore, in the new Context, while we still keep the one general templated function that can copy between arbitrary contexts (CopyBytes), we rewrote the other uses of the Copy into these three special variants of copies that do not rely on template.\n# Context\nCopy<int, CPUContext, CUDAContext>(...) --> CopyFromCPU<int>(...)\nCopy<int, CUDAContext, CPUContext>(...) --> CopyToCPU<int>(...)\nCopy<int, CUDAContext, CUDAContext>(...) --> CopySameDevice<int>(...)\nSimilarily,\nCopy<CPUContext, CUDAContext>(...) --> CopyFromCPU(...)\nWe also have calls using CopyItems/CopyBytes\n\nAs a side note, the distinction between three copies is that:\n- CopyBytes is copy of data pointed by raw pointers (void*)\n- Copy is templated on the data type that we want to copy (T*)\n- CopyItems get the type info from explicitly passed TypeMeta\n\nDifferential Revision: D8121878", "body": "Summary:\r\nUse inheritance for polymorphism, and remove template parameter\r\nThis is to change the templating in call sites, the core implementations will change later\r\n\r\nWe removed template parameter from Tensor as an effort to Pytorch and Caffe2 backend unification.\r\n\r\n## New caffe2::Tensor class\r\n\r\nBefore Caffe2 Tensor class was compile-time fixed to bind to a particular device/context. With this change, we're making it a runtime property (stored inside the tensor), but preserve the same semantics. For example, one has to specify device type in order to create a Tensor - there are no uninitialized tensors. More specifically the changes are:\r\n\r\n1. We added an extra argument *DeviceType* to most of the constructors of the tensor, e.g. (Tensor(DeviceType type)),\r\n2. Semantics of constructor Tensor(const Tensor<SrcContext>& src, ContextForCopy* context); is changed, in this constructor, the second context is passed in to enable us to call the templated Copy function, it could be in a different context as source and target previously, now we'll enforce that the context should have same device type as src, if it is provided.\r\n3. To preserve 'get-or-construct' semantics of Blob, we added specialized getter Blob::GetMutableTensor that verifies both that Blob contains a Tensor and that it's of a correct type\r\n4. Specifically, Tensor type is not default-constructible any more (as we don't have unknown device tensors) and thus some of the code handling STL containers needs to change\r\n\r\nFor details about how the tensor class look like right now, please see https://github.com/pytorch/pytorch/blob/master/caffe2/core/tensor.h\r\n\r\nWe did a massive codemod of the fbsource and hopefully covered majority of usages. However, there are probably a few that slipped through the contbuild. You might need to refactor your custom code according the following guide:\r\n```\r\n# Tensor\r\n## Type\r\nusing TensorCPU = Tensor<CPUContext>; --> using TensorCPU = Tensor;\r\n\r\n## Construction\r\n### As class member variable\r\nTensorCPU x; --> Tensor x{CPU};\r\n// TensorCPU is just Tensor<CPUContext>, if Tensor is templated on Context,\r\n// we'll write:\r\nTensor<Context> x; --> Tensor x{Context::GetDeviceType()};\r\n// In the following we'll just use TensorCPU as example\r\n### As local variable\r\nTensorCPU x; --> Tensor x(CPU);\r\n### make_unique\r\nmake_unique<TensorCPU>() --> make_unique<Tensor>(CPU)\r\n### Constructor by context\r\nCUDAContext context;\r\n// y is a TensorCPU\r\nTensorCPU x(y, &context); // this constructor is removed\r\n\r\n-->\r\n\r\nTensor x(y, &context, CPU);\r\n## Containers\r\n### Vector initialization\r\n vector<TensorCPU> tensors(numTensors);\r\n -->\r\n vector<TensorCPU> tensors;\r\n for (auto i = 0; i < numTensors; ++i) {\r\n   tensors.emplace_back(CPU);\r\n }\r\n### Vector access\r\nNo change\r\n### Map construction\r\nmap<string, TensorCPU> tensor_map;\r\ntensor_map.insert(std::pair<string, TensorCPU>(name, TensorCPU()));\r\n-->\r\ntensor_map.emplace(name, Tensor(CPU));\r\n \r\n### Map access ([])\r\nmap<TensorCPU> map;\r\nmap[name]\r\n--> \r\nmap.emplace(name, Tensor(CPU));\r\n map.at(name);\r\n\r\n# Blob\r\nGetMutable<TensorCPU> --> GetMutableTensor(CPU)\r\n\r\n# Note for Get function we just keep it as Get<TensorCPU>()(equivalent to Get<Tensor>()) at this moment\r\n# Since it won't affect the current running code\r\n# ideally it should be rewritten as following, which gives an extra verification\r\n# on the type of tensor contained in the blob\r\nGet<TensorCPU>() --> Get<Tensor>(CPU);\r\n```\r\n## Context and StaticContext\r\n\r\nWe virtualized the functions in Context in order to achieve runtime polymorphism. The static functions has been split into a StaticContext class, which has one to one correspondence with DeviceType (CPU, CUDA etc.) and it has a global singleton object. We'll store a pointer to the singleton in Tensor to indicate the context of Tensor.\r\nOriginal Context class contained routines to copy between different contexts, however, most of the time the use case is between three types of copies: CopyToCPU, CopyFromCPU and CopySameDevice, therefore, in the new Context, while we still keep the one general templated function that can copy between arbitrary contexts (CopyBytes), we rewrote the other uses of the Copy into these three special variants of copies that do not rely on template.\r\n```\r\n# Context\r\nCopy<int, CPUContext, CUDAContext>(...) --> CopyFromCPU<int>(...)\r\nCopy<int, CUDAContext, CPUContext>(...) --> CopyToCPU<int>(...)\r\nCopy<int, CUDAContext, CUDAContext>(...) --> CopySameDevice<int>(...)\r\nSimilarily,\r\nCopy<CPUContext, CUDAContext>(...) --> CopyFromCPU(...)\r\nWe also have calls using CopyItems/CopyBytes\r\n\r\nAs a side note, the distinction between three copies is that:\r\n- CopyBytes is copy of data pointed by raw pointers (void*)\r\n- Copy is templated on the data type that we want to copy (T*)\r\n- CopyItems get the type info from explicitly passed TypeMeta\r\n```\r\n\r\nDifferential Revision: D8121878\r\n"}