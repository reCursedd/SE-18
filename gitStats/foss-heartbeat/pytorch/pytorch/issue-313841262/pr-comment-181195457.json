{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181195457", "pull_request_review_id": 111755110, "id": 181195457, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MTE5NTQ1Nw==", "diff_hunk": "@@ -0,0 +1,550 @@\n+/**\n+ * Copyright (c) 2016-present, Facebook, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#include <string>\n+\n+#include \"caffe2/core/init.h\"\n+#include \"caffe2/core/logging.h\"\n+#include \"caffe2/core/operator.h\"\n+#include \"caffe2/core/timer.h\"\n+#include \"caffe2/core/types.h\"\n+#include \"caffe2/proto/caffe2.pb.h\"\n+#include \"caffe2/utils/proto_utils.h\"\n+#include \"caffe2/utils/string_utils.h\"\n+\n+CAFFE2_DEFINE_string(net, \"\", \"The given net to benchmark.\");\n+CAFFE2_DEFINE_string(\n+    optimized_net,\n+    \"\",\n+    \"Output filename for optimized NetDef protobuf.\");\n+CAFFE2_DEFINE_string(\n+    init_net,\n+    \"\",\n+    \"The given net to initialize any parameters.\");\n+CAFFE2_DEFINE_string(\n+    input,\n+    \"\",\n+    \"Input that is needed for running the network. If \"\n+    \"multiple input needed, use comma separated string.\");\n+CAFFE2_DEFINE_string(\n+    input_file,\n+    \"\",\n+    \"Input file that contain the serialized protobuf for \"\n+    \"the input blobs. If multiple input needed, use comma \"\n+    \"separated string. Must have the same number of items \"\n+    \"as input does.\");\n+CAFFE2_DEFINE_string(\n+    input_dims,\n+    \"\",\n+    \"Alternate to input_files, if all inputs are simple \"\n+    \"float TensorCPUs, specify the dimension using comma \"\n+    \"separated numbers. If multiple input needed, use \"\n+    \"semicolon to separate the dimension of different \"\n+    \"tensors.\");\n+CAFFE2_DEFINE_string(input_type, \"\", \"Input type (uint8_t/float)\");\n+CAFFE2_DEFINE_bool(\n+    try_winograd_fp16,\n+    true,\n+    \"Consider WINOGRAD_FP16 NNPACK algorithm in auto-tuning.\");\n+CAFFE2_DEFINE_int(\n+    samples,\n+    7,\n+    \"The number of samples of warm-up & main iterations to run.\");\n+CAFFE2_DEFINE_int(warmup, 5, \"The number of warm-up iterations to run.\");\n+CAFFE2_DEFINE_int(iter, 15, \"The number of iterations to run.\");\n+\n+using std::string;\n+using std::unique_ptr;\n+using std::vector;\n+\n+struct InputDescription {\n+  InputDescription(const string& name, const caffe2::BlobProto& blob)\n+      : name(name), blob(blob) {}\n+\n+  InputDescription(const string& name, caffe2::BlobProto&& blob)\n+      : name(name), blob(blob) {}\n+\n+  InputDescription(const string& name, const vector<int> shape, bool is_float)\n+      : name(name), shape(shape), is_float(is_float) {}\n+\n+  string name;\n+  /*\n+   * Protobuf with blob data and metadata.\n+   * If this value is not initialized, a new blob is created based on shape and\n+   * is_float values.\n+   */\n+  caffe2::BlobProto blob;\n+  /* Shape of the input (ignored if blob is initialized). */\n+  vector<int> shape;\n+  /* If true, input is of float type. Otherwise, it is of uint8_t type. */\n+  bool is_float;\n+};\n+\n+bool benchmark(\n+    const vector<InputDescription>& inputs,\n+    const caffe2::NetDef& ref_def,\n+    const caffe2::NetDef& alt_def,\n+    const caffe2::NetDef& init_net,\n+    uint32_t iterations,\n+    float* millis) {\n+  unique_ptr<caffe2::Workspace> ref_workspace(new caffe2::Workspace());\n+  CAFFE_ENFORCE(ref_workspace->RunNetOnce(init_net));\n+\n+  unique_ptr<caffe2::Workspace> alt_workspace(new caffe2::Workspace());\n+  CAFFE_ENFORCE(alt_workspace->RunNetOnce(init_net));\n+\n+  for (const InputDescription& input : inputs) {\n+    if (false /* input.blob.IsInitialized() */) {\n+      ref_workspace->CreateBlob(input.name)->Deserialize(input.blob);\n+      alt_workspace->CreateBlob(input.name)->Deserialize(input.blob);\n+    } else {\n+      caffe2::TensorCPU* ref_tensor = ref_workspace->CreateBlob(input.name)\n+                                          ->GetMutable<caffe2::TensorCPU>();\n+      caffe2::TensorCPU* alt_tensor = alt_workspace->CreateBlob(input.name)\n+                                          ->GetMutable<caffe2::TensorCPU>();\n+      ref_tensor->Resize(input.shape);\n+      alt_tensor->Resize(input.shape);\n+      if (input.is_float) {\n+        ref_tensor->mutable_data<float>();\n+        alt_tensor->mutable_data<float>();\n+      } else {\n+        ref_tensor->mutable_data<uint8_t>();\n+        alt_tensor->mutable_data<uint8_t>();\n+      }\n+    }\n+  }\n+\n+  caffe2::NetBase* ref_net = ref_workspace->CreateNet(ref_def);\n+  caffe2::NetBase* alt_net = alt_workspace->CreateNet(alt_def);\n+\n+  CAFFE_ENFORCE(alt_net->Run(), \"Warmup run for alternative net has failed.\");\n+\n+  vector<float> ref_millis(caffe2::FLAGS_samples);\n+  vector<float> alt_millis(caffe2::FLAGS_samples);\n+  for (int n = 0; n < caffe2::FLAGS_samples; n++) {\n+    {\n+      /* Reference network */\n+      for (int i = 0; i < caffe2::FLAGS_warmup; i++) {\n+        CAFFE_ENFORCE(\n+            ref_net->Run(), \"Warmup run for reference net has failed.\");\n+      }\n+      caffe2::Timer timer;\n+      for (int i = 0; i < caffe2::FLAGS_iter; i++) {\n+        CAFFE_ENFORCE(\n+            ref_net->Run(), \"Main run \", i, \" for reference net has failed.\");\n+      }\n+      ref_millis[n] = timer.MilliSeconds();\n+    }\n+    {\n+      /* Alternative network */\n+      for (int i = 0; i < caffe2::FLAGS_warmup; i++) {\n+        CAFFE_ENFORCE(\n+            alt_net->Run(), \"Warmup run for reference net has failed.\");\n+      }\n+      caffe2::Timer timer;\n+      for (int i = 0; i < caffe2::FLAGS_iter; i++) {\n+        CAFFE_ENFORCE(\n+            alt_net->Run(), \"Main run \", i, \" for reference net has failed.\");\n+      }\n+      alt_millis[n] = timer.MilliSeconds();\n+    }\n+  }\n+  std::sort(ref_millis.begin(), ref_millis.end());\n+  std::sort(alt_millis.begin(), alt_millis.end());\n+  millis[0] = ref_millis[caffe2::FLAGS_samples / 2] / caffe2::FLAGS_iter;\n+  millis[1] = alt_millis[caffe2::FLAGS_samples / 2] / caffe2::FLAGS_iter;\n+  return millis[1] < millis[0];\n+}\n+\n+void try_nnpack_convolution(\n+    const vector<InputDescription>& inputs,\n+    const caffe2::NetDef& init_net,\n+    caffe2::NetDef& best_net,\n+    int conv_index,\n+    std::string algorithm,\n+    std::string strategy,\n+    int shared_buffer) {\n+  caffe2::NetDef candidate_net(best_net);\n+  caffe2::OperatorDef* candidate_conv = candidate_net.mutable_op(conv_index);\n+  CHECK_NOTNULL(candidate_conv);\n+  caffe2::AddArgument(\"engine\", string(\"NNPACK\"), candidate_conv);\n+  caffe2::AddArgument(\"algo\", algorithm, candidate_conv);\n+  caffe2::AddArgument(\n+      \"convolution_transform_strategy\", strategy, candidate_conv);\n+  caffe2::AddArgument(\"shared_buffer\", shared_buffer, candidate_conv);\n+  float millis[2] = {0.0f, 0.0f};\n+  if (benchmark(\n+          inputs,\n+          best_net,\n+          candidate_net,\n+          init_net,\n+          caffe2::FLAGS_iter,\n+          millis)) {\n+    std::cout << \"\\tImprovement \" << std::fixed << std::setprecision(2)\n+              << millis[0] << \" ms -> \" << millis[1] << \" ms: \"\n+              << \"engine = \\\"NNPACK\\\", \"\n+              << \"algo = \\\"\" << algorithm << \"\\\", \"\n+              << \"convolution_transform_strategy = \\\"\" << strategy << \"\\\", \"\n+              << \"shared_buffer = \" << shared_buffer << std::endl;\n+    best_net.Clear();\n+    best_net.CopyFrom(candidate_net);\n+  }\n+}\n+\n+string op_name(const caffe2::OperatorDef& op, int index) {\n+  if (op.has_name() && op.name().size() != 0) {\n+    return \"\\\"\" + op.name() + \"\\\"\";\n+  } else {\n+    return \"#\" + caffe2::to_string(index);\n+  }\n+}\n+\n+int main(int argc, char** argv) {\n+  caffe2::GlobalInit(&argc, &argv);\n+\n+  /* Validate arguments */\n+  CAFFE_ENFORCE(\n+      caffe2::FLAGS_net.size() != 0,\n+      \"Unspecified path to input network protobuf\");\n+  CAFFE_ENFORCE(\n+      caffe2::FLAGS_optimized_net.size() != 0,\n+      \"Unspecified path to output network protobuf\");\n+  CAFFE_ENFORCE(\n+      caffe2::FLAGS_init_net.size() != 0,\n+      \"Unspecified path to input initialization protobuf\");\n+\n+  /* Parse input-related options and load data. */\n+  vector<InputDescription> inputs;\n+  if (caffe2::FLAGS_input.size()) {\n+    vector<string> input_names = caffe2::split(',', caffe2::FLAGS_input);\n+    if (caffe2::FLAGS_input_file.size()) {\n+      CAFFE_ENFORCE_EQ(\n+          0,\n+          caffe2::FLAGS_input_dims.size(),\n+          \"Input file and input dims options are mutually exclusive\");\n+      CAFFE_ENFORCE_EQ(\n+          0,\n+          caffe2::FLAGS_input_type.size(),\n+          \"Input file and input type options are mutually exclusive\");\n+\n+      vector<string> input_paths = caffe2::split(',', caffe2::FLAGS_input_file);\n+      CAFFE_ENFORCE_EQ(\n+          input_paths.size(),\n+          input_paths.size(),\n+          \"Input name and file should have the same number.\");\n+      for (size_t i = 0; i < input_paths.size(); i++) {\n+        caffe2::BlobProto blob_proto;\n+        CAFFE_ENFORCE(caffe2::ReadProtoFromFile(input_paths[i], &blob_proto));\n+        inputs.push_back(\n+            InputDescription(input_names[i], std::move(blob_proto)));\n+      }\n+    } else if (\n+        caffe2::FLAGS_input_dims.size() || caffe2::FLAGS_input_type.size()) {\n+      CAFFE_ENFORCE_NE(\n+          0,\n+          caffe2::FLAGS_input_dims.size(),\n+          \"Input dims must be specified when input files are not specified.\");\n+      CAFFE_ENFORCE_NE(\n+          0,\n+          caffe2::FLAGS_input_type.size(),\n+          \"Input types must be specified when input files are not specified.\");\n+\n+      vector<string> input_dims_list =\n+          caffe2::split(';', caffe2::FLAGS_input_dims);\n+      CAFFE_ENFORCE_EQ(\n+          input_names.size(),\n+          input_dims_list.size(),\n+          \"Input names and input dims should have the same number of items.\");\n+      vector<string> input_type_list =\n+          caffe2::split(';', caffe2::FLAGS_input_type);\n+      CAFFE_ENFORCE_EQ(\n+          input_names.size(),\n+          input_type_list.size(),\n+          \"Input names and input types should have the same number of items.\");\n+      for (size_t i = 0; i < input_names.size(); ++i) {\n+        vector<string> input_dims_str = caffe2::split(',', input_dims_list[i]);\n+        vector<int> input_dims;\n+        for (const string& s : input_dims_str) {\n+          input_dims.push_back(caffe2::stoi(s));\n+        }\n+        if (input_type_list[i] == \"uint8_t\") {\n+          inputs.push_back(InputDescription(input_names[i], input_dims, false));\n+        } else if (input_type_list[i] == \"float\") {\n+          inputs.push_back(InputDescription(input_names[i], input_dims, true));\n+        } else {\n+          CAFFE_THROW(\n+              \"Unsupported input type \",\n+              input_type_list[i],\n+              \" for input \",\n+              input_names[i]);\n+        }\n+      }\n+    } else {\n+      CAFFE_THROW(\n+          \"You requested input tensors, but neither input_file nor input_dims + input_type is set.\");\n+    }\n+  }\n+\n+  /* Load all parameters into a workspace, so we can lookup their shapes when\n+   * needed. */\n+  unique_ptr<caffe2::Workspace> paramWorkspace(new caffe2::Workspace());\n+  caffe2::NetDef init_net;\n+  CAFFE_ENFORCE(ReadProtoFromFile(caffe2::FLAGS_init_net, &init_net));\n+  CAFFE_ENFORCE(paramWorkspace->RunNetOnce(init_net));\n+\n+  caffe2::NetDef input_net;\n+  CAFFE_ENFORCE(ReadProtoFromFile(caffe2::FLAGS_net, &input_net));\n+  caffe2::NetDef best_net(input_net);\n+\n+  for (int op_index = 0; op_index < input_net.op_size(); op_index++) {\n+    const caffe2::OperatorDef& op = input_net.op(op_index);\n+\n+    if (op.type() == \"Conv\") {\n+      CAFFE_ENFORCE(\n+          op.input_size() >= 2, \"Conv operator must have 2 or 3 inputs\");\n+      caffe2::Blob* kernel_blob = paramWorkspace->GetBlob(op.input(1));\n+      CAFFE_ENFORCE(\n+          kernel_blob != nullptr,\n+          \"Weights blob \",\n+          op.input(1),\n+          \" for Conv operator \",\n+          op.name(),\n+          \" is not initialized\");\n+      const caffe2::TensorCPU kernel_tensor =\n+          kernel_blob->Get<caffe2::TensorCPU>();\n+\n+      if (kernel_tensor.ndim() == 4) {", "path": "binaries/autotuner.cc", "position": 329, "original_position": 329, "commit_id": "fa1ef10b045c6a37dbe7c1ab8b924c9410eddc05", "original_commit_id": "fa1ef10b045c6a37dbe7c1ab8b924c9410eddc05", "user": {"login": "bwasti", "id": 4842908, "node_id": "MDQ6VXNlcjQ4NDI5MDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/4842908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bwasti", "html_url": "https://github.com/bwasti", "followers_url": "https://api.github.com/users/bwasti/followers", "following_url": "https://api.github.com/users/bwasti/following{/other_user}", "gists_url": "https://api.github.com/users/bwasti/gists{/gist_id}", "starred_url": "https://api.github.com/users/bwasti/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bwasti/subscriptions", "organizations_url": "https://api.github.com/users/bwasti/orgs", "repos_url": "https://api.github.com/users/bwasti/repos", "events_url": "https://api.github.com/users/bwasti/events{/privacy}", "received_events_url": "https://api.github.com/users/bwasti/received_events", "type": "User", "site_admin": false}, "body": "I'm not entirely sure why you need the logic to check everything before attempting NNPACK -- wouldn't it be simpler to just try every Conv? or are there cases where the backend would actually crash and ruin the autotuning", "created_at": "2018-04-12T19:26:09Z", "updated_at": "2018-11-23T15:42:19Z", "html_url": "https://github.com/pytorch/pytorch/pull/6557#discussion_r181195457", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6557", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/181195457"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6557#discussion_r181195457"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6557"}}, "body_html": "<p>I'm not entirely sure why you need the logic to check everything before attempting NNPACK -- wouldn't it be simpler to just try every Conv? or are there cases where the backend would actually crash and ruin the autotuning</p>", "body_text": "I'm not entirely sure why you need the logic to check everything before attempting NNPACK -- wouldn't it be simpler to just try every Conv? or are there cases where the backend would actually crash and ruin the autotuning"}