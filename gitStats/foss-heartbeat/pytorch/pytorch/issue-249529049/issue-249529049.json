{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2383", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2383/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2383/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2383/events", "html_url": "https://github.com/pytorch/pytorch/issues/2383", "id": 249529049, "node_id": "MDU6SXNzdWUyNDk1MjkwNDk=", "number": 2383, "title": "GPU 0 always allocates memory when cuDNN RNN modules are used", "user": {"login": "jihunchoi", "id": 1898501, "node_id": "MDQ6VXNlcjE4OTg1MDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1898501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jihunchoi", "html_url": "https://github.com/jihunchoi", "followers_url": "https://api.github.com/users/jihunchoi/followers", "following_url": "https://api.github.com/users/jihunchoi/following{/other_user}", "gists_url": "https://api.github.com/users/jihunchoi/gists{/gist_id}", "starred_url": "https://api.github.com/users/jihunchoi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jihunchoi/subscriptions", "organizations_url": "https://api.github.com/users/jihunchoi/orgs", "repos_url": "https://api.github.com/users/jihunchoi/repos", "events_url": "https://api.github.com/users/jihunchoi/events{/privacy}", "received_events_url": "https://api.github.com/users/jihunchoi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-11T03:08:52Z", "updated_at": "2017-08-25T15:09:11Z", "closed_at": "2017-08-25T15:09:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In a multi-GPU environment, even when the ID of GPU (other than 0) is specified when calling <code>.cuda(..)</code>, it seems that cuDNN RNN modules (<code>nn.RNN</code>, <code>nn.GRU</code>) allocate some amount of memory in GPU 0.</p>\n<p>The following is the code to reproduce the issue:</p>\n<pre><code>In [1]: import torch\n\nIn [2]: from torch import nn\n\nIn [3]: torch.__version__\nOut[3]: '0.2.0_2'\n\nIn [4]: cudnn_lstm = nn.LSTM(3, 4)\n\nIn [5]: cudnn_lstm.cuda(2)\nOut[5]: LSTM(3, 4)\n\nIn [6]: !nvidia-smi\nFri Aug 11 12:05:49 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n| 23%   39C    P2    60W / 250W |    275MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN Xp            On   | 00000000:04:00.0 Off |                  N/A |\n| 23%   38C    P8    17W / 250W |     10MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN Xp            On   | 00000000:83:00.0 Off |                  N/A |\n| 23%   40C    P2    60W / 250W |    347MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN Xp            On   | 00000000:84:00.0 Off |                  N/A |\n| 23%   30C    P8     8W / 250W |     10MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      265MiB |\n|    2     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      337MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>\n<p>It seems than modules other than cuDNN RNN, such as <code>nn.Linear</code> and <code>nn.Conv1d</code>, work as expected and do not consume memory on GPU 0.<br>\nOf course the amount of memory allocation is quite small and can be ignored in most cases, however it can be problematic when almost all memory of GPU 0 is already in use by some other processes.<br>\n(One can specify <code>CUDA_VISIBLE_DEVICES</code> to avoid this problem though)</p>", "body_text": "In a multi-GPU environment, even when the ID of GPU (other than 0) is specified when calling .cuda(..), it seems that cuDNN RNN modules (nn.RNN, nn.GRU) allocate some amount of memory in GPU 0.\nThe following is the code to reproduce the issue:\nIn [1]: import torch\n\nIn [2]: from torch import nn\n\nIn [3]: torch.__version__\nOut[3]: '0.2.0_2'\n\nIn [4]: cudnn_lstm = nn.LSTM(3, 4)\n\nIn [5]: cudnn_lstm.cuda(2)\nOut[5]: LSTM(3, 4)\n\nIn [6]: !nvidia-smi\nFri Aug 11 12:05:49 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n| 23%   39C    P2    60W / 250W |    275MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  TITAN Xp            On   | 00000000:04:00.0 Off |                  N/A |\n| 23%   38C    P8    17W / 250W |     10MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  TITAN Xp            On   | 00000000:83:00.0 Off |                  N/A |\n| 23%   40C    P2    60W / 250W |    347MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  TITAN Xp            On   | 00000000:84:00.0 Off |                  N/A |\n| 23%   30C    P8     8W / 250W |     10MiB / 12189MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      265MiB |\n|    2     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      337MiB |\n+-----------------------------------------------------------------------------+\n\nIt seems than modules other than cuDNN RNN, such as nn.Linear and nn.Conv1d, work as expected and do not consume memory on GPU 0.\nOf course the amount of memory allocation is quite small and can be ignored in most cases, however it can be problematic when almost all memory of GPU 0 is already in use by some other processes.\n(One can specify CUDA_VISIBLE_DEVICES to avoid this problem though)", "body": "In a multi-GPU environment, even when the ID of GPU (other than 0) is specified when calling `.cuda(..)`, it seems that cuDNN RNN modules (`nn.RNN`, `nn.GRU`) allocate some amount of memory in GPU 0.\r\n\r\nThe following is the code to reproduce the issue:\r\n```\r\nIn [1]: import torch\r\n\r\nIn [2]: from torch import nn\r\n\r\nIn [3]: torch.__version__\r\nOut[3]: '0.2.0_2'\r\n\r\nIn [4]: cudnn_lstm = nn.LSTM(3, 4)\r\n\r\nIn [5]: cudnn_lstm.cuda(2)\r\nOut[5]: LSTM(3, 4)\r\n\r\nIn [6]: !nvidia-smi\r\nFri Aug 11 12:05:49 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\r\n| 23%   39C    P2    60W / 250W |    275MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN Xp            On   | 00000000:04:00.0 Off |                  N/A |\r\n| 23%   38C    P8    17W / 250W |     10MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN Xp            On   | 00000000:83:00.0 Off |                  N/A |\r\n| 23%   40C    P2    60W / 250W |    347MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN Xp            On   | 00000000:84:00.0 Off |                  N/A |\r\n| 23%   30C    P8     8W / 250W |     10MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      265MiB |\r\n|    2     33124    C   /home/jhchoi/anaconda3/envs/ml/bin/python      337MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nIt seems than modules other than cuDNN RNN, such as `nn.Linear` and `nn.Conv1d`, work as expected and do not consume memory on GPU 0.\r\nOf course the amount of memory allocation is quite small and can be ignored in most cases, however it can be problematic when almost all memory of GPU 0 is already in use by some other processes.\r\n(One can specify `CUDA_VISIBLE_DEVICES` to avoid this problem though)"}