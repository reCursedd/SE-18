{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10261", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10261/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10261/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10261/events", "html_url": "https://github.com/pytorch/pytorch/pull/10261", "id": 348013952, "node_id": "MDExOlB1bGxSZXF1ZXN0MjA2NDY1NTMz", "number": 10261, "title": "Cleaner semantics for Reserve", "user": {"login": "jerryzh168", "id": 4958441, "node_id": "MDQ6VXNlcjQ5NTg0NDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/4958441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jerryzh168", "html_url": "https://github.com/jerryzh168", "followers_url": "https://api.github.com/users/jerryzh168/followers", "following_url": "https://api.github.com/users/jerryzh168/following{/other_user}", "gists_url": "https://api.github.com/users/jerryzh168/gists{/gist_id}", "starred_url": "https://api.github.com/users/jerryzh168/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jerryzh168/subscriptions", "organizations_url": "https://api.github.com/users/jerryzh168/orgs", "repos_url": "https://api.github.com/users/jerryzh168/repos", "events_url": "https://api.github.com/users/jerryzh168/events{/privacy}", "received_events_url": "https://api.github.com/users/jerryzh168/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-08-06T17:25:16Z", "updated_at": "2018-08-06T21:41:19Z", "closed_at": "2018-08-06T21:41:19Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10261", "html_url": "https://github.com/pytorch/pytorch/pull/10261", "diff_url": "https://github.com/pytorch/pytorch/pull/10261.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10261.patch"}, "body_html": "<p>Summary:</p>\n<ol>\n<li>Reserve<br>\nCurrently, Reserve will allocate new memory and old data in the tensor is also preserved,<br>\nand Resize is relying on this behavior in some call-site, e.g. <a href=\"https://github.com/pytorch/pytorch/blob/master/caffe2/operators/reservoir_sampling.cc#L103\">https://github.com/pytorch/pytorch/blob/master/caffe2/operators/reservoir_sampling.cc#L103</a>, where we should be using Extend.<br>\nWe want to bring semantics of Reserve to be more aligned with std::vector, i.e. we want it to be<br>\nan optimization about memory allocation and remove the semantics about preserving the data. We'll remove the guarantee that data will be preserved after Reserve, and Extend will be the only API that preserves old data when we do in-place extension of memory. This also helps with the later refactoring on split Storage from Tensor.<br>\nAlso, we'll only pass in the outer dimension to Reserve which means the later dimensions should be set before we call Reserve.</li>\n<li>Extend/Shrink<br>\nPreviously, Extend actually means ExtendBy and Shrink means ShrinkTo, I would like to add a ExtendTo for convenience, and change Shrink to ShrinkTo.<br>\nOld functions calling Extend is still there, although it actually means Extend by, but I think it still makes sense to have it.</li>\n<li>Usage Patterns</li>\n</ol>\n<p>The expected usage patterns right now is:</p>\n<pre><code>t-&gt;Resize({0, 32, 32, 32});\nt-&gt;template mutable_data&lt;T&gt;(); // set meta_\nt-&gt;Reserve(100);\nauto* t_data = t-&gt;template mutable_data&lt;T&gt;();\n// feed data to tensor using t_data\nfor (int i = 0; i &lt; 100; ++i) {\n  t-&gt;Extend(1, 50, &amp;context_);\n  // you can continue to use t_data if you have reserved enough space\n  // otherwise, you should call t-&gt;template mutable_data&lt;T&gt; again to\n  // get the new data pointer since Extend will allocate new memory even\n  // though the original data is preserved.\n}\n</code></pre>\n<p>Reviewed By: ezyang</p>\n<p>Differential Revision: D9128147</p>", "body_text": "Summary:\n\nReserve\nCurrently, Reserve will allocate new memory and old data in the tensor is also preserved,\nand Resize is relying on this behavior in some call-site, e.g. https://github.com/pytorch/pytorch/blob/master/caffe2/operators/reservoir_sampling.cc#L103, where we should be using Extend.\nWe want to bring semantics of Reserve to be more aligned with std::vector, i.e. we want it to be\nan optimization about memory allocation and remove the semantics about preserving the data. We'll remove the guarantee that data will be preserved after Reserve, and Extend will be the only API that preserves old data when we do in-place extension of memory. This also helps with the later refactoring on split Storage from Tensor.\nAlso, we'll only pass in the outer dimension to Reserve which means the later dimensions should be set before we call Reserve.\nExtend/Shrink\nPreviously, Extend actually means ExtendBy and Shrink means ShrinkTo, I would like to add a ExtendTo for convenience, and change Shrink to ShrinkTo.\nOld functions calling Extend is still there, although it actually means Extend by, but I think it still makes sense to have it.\nUsage Patterns\n\nThe expected usage patterns right now is:\nt->Resize({0, 32, 32, 32});\nt->template mutable_data<T>(); // set meta_\nt->Reserve(100);\nauto* t_data = t->template mutable_data<T>();\n// feed data to tensor using t_data\nfor (int i = 0; i < 100; ++i) {\n  t->Extend(1, 50, &context_);\n  // you can continue to use t_data if you have reserved enough space\n  // otherwise, you should call t->template mutable_data<T> again to\n  // get the new data pointer since Extend will allocate new memory even\n  // though the original data is preserved.\n}\n\nReviewed By: ezyang\nDifferential Revision: D9128147", "body": "Summary:\n1. Reserve\nCurrently, Reserve will allocate new memory and old data in the tensor is also preserved,\nand Resize is relying on this behavior in some call-site, e.g. https://github.com/pytorch/pytorch/blob/master/caffe2/operators/reservoir_sampling.cc#L103, where we should be using Extend.\nWe want to bring semantics of Reserve to be more aligned with std::vector, i.e. we want it to be\nan optimization about memory allocation and remove the semantics about preserving the data. We'll remove the guarantee that data will be preserved after Reserve, and Extend will be the only API that preserves old data when we do in-place extension of memory. This also helps with the later refactoring on split Storage from Tensor.\nAlso, we'll only pass in the outer dimension to Reserve which means the later dimensions should be set before we call Reserve.\n2. Extend/Shrink\nPreviously, Extend actually means ExtendBy and Shrink means ShrinkTo, I would like to add a ExtendTo for convenience, and change Shrink to ShrinkTo.\nOld functions calling Extend is still there, although it actually means Extend by, but I think it still makes sense to have it.\n3. Usage Patterns\n\nThe expected usage patterns right now is:\n```\nt->Resize({0, 32, 32, 32});\nt->template mutable_data<T>(); // set meta_\nt->Reserve(100);\nauto* t_data = t->template mutable_data<T>();\n// feed data to tensor using t_data\nfor (int i = 0; i < 100; ++i) {\n  t->Extend(1, 50, &context_);\n  // you can continue to use t_data if you have reserved enough space\n  // otherwise, you should call t->template mutable_data<T> again to\n  // get the new data pointer since Extend will allocate new memory even\n  // though the original data is preserved.\n}\n```\n\nReviewed By: ezyang\n\nDifferential Revision: D9128147\n"}