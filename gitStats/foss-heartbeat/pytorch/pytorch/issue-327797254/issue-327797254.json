{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7951", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7951/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7951/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7951/events", "html_url": "https://github.com/pytorch/pytorch/issues/7951", "id": 327797254, "node_id": "MDU6SXNzdWUzMjc3OTcyNTQ=", "number": 7951, "title": "New scalars of type IntTensor breaking division", "user": {"login": "Mxbonn", "id": 11473168, "node_id": "MDQ6VXNlcjExNDczMTY4", "avatar_url": "https://avatars3.githubusercontent.com/u/11473168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mxbonn", "html_url": "https://github.com/Mxbonn", "followers_url": "https://api.github.com/users/Mxbonn/followers", "following_url": "https://api.github.com/users/Mxbonn/following{/other_user}", "gists_url": "https://api.github.com/users/Mxbonn/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mxbonn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mxbonn/subscriptions", "organizations_url": "https://api.github.com/users/Mxbonn/orgs", "repos_url": "https://api.github.com/users/Mxbonn/repos", "events_url": "https://api.github.com/users/Mxbonn/events{/privacy}", "received_events_url": "https://api.github.com/users/Mxbonn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-30T16:02:24Z", "updated_at": "2018-08-14T19:00:46Z", "closed_at": "2018-08-14T19:00:45Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Functions that used to return an int pre 0.4 now return IntTensor which has different division behavior.</p>\n<p>Provide a short description.</p>\n<h2>Code example</h2>\n<p>&lt; Pytorch 0.4</p>\n<pre><code>In [1]: a = torch.ByteTensor([1,1,1,0])\n\nIn [2]: a.sum()\nOut[2]: 3\n\nIn [3]: a.sum() / 2\nOut[3]: 1.5\n</code></pre>\n<p>and now since Pytorch 0.4</p>\n<pre><code>In [1]: a = torch.ByteTensor([1,1,1,0])\n\nIn [2]: a.sum()\nOut[2]: tensor(3)\n\nIn [3]: a.sum() / 2\nOut[3]: 1\n</code></pre>\n<hr>\n<p>This is probably intended behavior but it seems to me that it would be better to make operations such as sum return a FloatTensor instead of an IntTensor.</p>", "body_text": "Issue description\nFunctions that used to return an int pre 0.4 now return IntTensor which has different division behavior.\nProvide a short description.\nCode example\n< Pytorch 0.4\nIn [1]: a = torch.ByteTensor([1,1,1,0])\n\nIn [2]: a.sum()\nOut[2]: 3\n\nIn [3]: a.sum() / 2\nOut[3]: 1.5\n\nand now since Pytorch 0.4\nIn [1]: a = torch.ByteTensor([1,1,1,0])\n\nIn [2]: a.sum()\nOut[2]: tensor(3)\n\nIn [3]: a.sum() / 2\nOut[3]: 1\n\n\nThis is probably intended behavior but it seems to me that it would be better to make operations such as sum return a FloatTensor instead of an IntTensor.", "body": "## Issue description\r\nFunctions that used to return an int pre 0.4 now return IntTensor which has different division behavior.\r\n\r\nProvide a short description.\r\n\r\n## Code example\r\n< Pytorch 0.4\r\n```\r\nIn [1]: a = torch.ByteTensor([1,1,1,0])\r\n\r\nIn [2]: a.sum()\r\nOut[2]: 3\r\n\r\nIn [3]: a.sum() / 2\r\nOut[3]: 1.5\r\n```\r\nand now since Pytorch 0.4\r\n```\r\nIn [1]: a = torch.ByteTensor([1,1,1,0])\r\n\r\nIn [2]: a.sum()\r\nOut[2]: tensor(3)\r\n\r\nIn [3]: a.sum() / 2\r\nOut[3]: 1\r\n```\r\n\r\n----\r\nThis is probably intended behavior but it seems to me that it would be better to make operations such as sum return a FloatTensor instead of an IntTensor. \r\n\r\n"}