{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/331800609", "html_url": "https://github.com/pytorch/pytorch/issues/2829#issuecomment-331800609", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2829", "id": 331800609, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTgwMDYwOQ==", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-25T07:36:35Z", "updated_at": "2017-09-25T07:47:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi, I'm the puller of lr_scheduler.</p>\n<p>Actually, <code>get_lr</code> is designed to be more like an internal function for computing instead of fetching the learning rate (although it is not going to make inconsistent outcome unless the LRs are changed externally) Sorry for the confusion.</p>\n<p>For fetching, you could use <code>[ group['lr'] for group in optim.param_groups ]</code> for now (Yep, it's tedious). Maybe what needs to be done is to rename <code>get_lr</code> to <code>compute_lr</code> and create another function called <code>get_lr</code>. But this shortcut also seems weird, as it wraps too many functionalities of the optimizer.</p>", "body_text": "Hi, I'm the puller of lr_scheduler.\nActually, get_lr is designed to be more like an internal function for computing instead of fetching the learning rate (although it is not going to make inconsistent outcome unless the LRs are changed externally) Sorry for the confusion.\nFor fetching, you could use [ group['lr'] for group in optim.param_groups ] for now (Yep, it's tedious). Maybe what needs to be done is to rename get_lr to compute_lr and create another function called get_lr. But this shortcut also seems weird, as it wraps too many functionalities of the optimizer.", "body": "Hi, I'm the puller of lr_scheduler.\r\n\r\nActually, `get_lr` is designed to be more like an internal function for computing instead of fetching the learning rate (although it is not going to make inconsistent outcome unless the LRs are changed externally) Sorry for the confusion.\r\n\r\nFor fetching, you could use `[ group['lr'] for group in optim.param_groups ]` for now (Yep, it's tedious). Maybe what needs to be done is to rename `get_lr` to `compute_lr` and create another function called `get_lr`. But this shortcut also seems weird, as it wraps too many functionalities of the optimizer."}