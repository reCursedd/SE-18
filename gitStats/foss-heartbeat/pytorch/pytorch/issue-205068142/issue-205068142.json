{"url": "https://api.github.com/repos/pytorch/pytorch/issues/683", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/683/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/683/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/683/events", "html_url": "https://github.com/pytorch/pytorch/issues/683", "id": 205068142, "node_id": "MDU6SXNzdWUyMDUwNjgxNDI=", "number": 683, "title": "Using generators instead of iterators for sampling (DataLoader)", "user": {"login": "bobbens", "id": 54677, "node_id": "MDQ6VXNlcjU0Njc3", "avatar_url": "https://avatars1.githubusercontent.com/u/54677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bobbens", "html_url": "https://github.com/bobbens", "followers_url": "https://api.github.com/users/bobbens/followers", "following_url": "https://api.github.com/users/bobbens/following{/other_user}", "gists_url": "https://api.github.com/users/bobbens/gists{/gist_id}", "starred_url": "https://api.github.com/users/bobbens/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bobbens/subscriptions", "organizations_url": "https://api.github.com/users/bobbens/orgs", "repos_url": "https://api.github.com/users/bobbens/repos", "events_url": "https://api.github.com/users/bobbens/events{/privacy}", "received_events_url": "https://api.github.com/users/bobbens/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-02-03T04:12:15Z", "updated_at": "2017-05-16T14:47:44Z", "closed_at": "2017-02-06T08:34:53Z", "author_association": "NONE", "body_html": "<p>Instead of using iterators, I want to use generators (infinite iterators) for sampling with DataLoader. For this purpose I have wrapper a generator in an iterator class, and made <code>__len__</code> return a very large number. While this does work, it has two issue:</p>\n<ol>\n<li>When you hit <code>__len__</code> it'll stop iterating and you'll not necessarily ned with a full batch.</li>\n<li>DataLoader uses multiple processes, not threads, for loading, so the generator gets copied, and since <code>__getitem__</code> ignores the index (it is randomly generating with the generator), all the processes have the same random seed so you get the same output for all the generators in the batch.</li>\n</ol>\n<p>So while I understand this is a fairly low priority issue, since I assume most people are fine with using iterators, the easiest way would be to add a new class DataGenerator, like DataLoader, except it does not have <code>__len__</code> and initializes and runs separate iterators in each process. Although it should also be possible to say add another parameter to DataLoader and handle it there. I can do a pull request if interested.</p>", "body_text": "Instead of using iterators, I want to use generators (infinite iterators) for sampling with DataLoader. For this purpose I have wrapper a generator in an iterator class, and made __len__ return a very large number. While this does work, it has two issue:\n\nWhen you hit __len__ it'll stop iterating and you'll not necessarily ned with a full batch.\nDataLoader uses multiple processes, not threads, for loading, so the generator gets copied, and since __getitem__ ignores the index (it is randomly generating with the generator), all the processes have the same random seed so you get the same output for all the generators in the batch.\n\nSo while I understand this is a fairly low priority issue, since I assume most people are fine with using iterators, the easiest way would be to add a new class DataGenerator, like DataLoader, except it does not have __len__ and initializes and runs separate iterators in each process. Although it should also be possible to say add another parameter to DataLoader and handle it there. I can do a pull request if interested.", "body": "Instead of using iterators, I want to use generators (infinite iterators) for sampling with DataLoader. For this purpose I have wrapper a generator in an iterator class, and made ```__len__``` return a very large number. While this does work, it has two issue:\r\n\r\n 1. When you hit ```__len__``` it'll stop iterating and you'll not necessarily ned with a full batch.\r\n 2. DataLoader uses multiple processes, not threads, for loading, so the generator gets copied, and since ```__getitem__``` ignores the index (it is randomly generating with the generator), all the processes have the same random seed so you get the same output for all the generators in the batch.\r\n\r\nSo while I understand this is a fairly low priority issue, since I assume most people are fine with using iterators, the easiest way would be to add a new class DataGenerator, like DataLoader, except it does not have ```__len__``` and initializes and runs separate iterators in each process. Although it should also be possible to say add another parameter to DataLoader and handle it there. I can do a pull request if interested."}