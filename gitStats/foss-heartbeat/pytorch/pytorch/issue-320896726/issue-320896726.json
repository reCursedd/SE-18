{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7343", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7343/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7343/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7343/events", "html_url": "https://github.com/pytorch/pytorch/issues/7343", "id": 320896726, "node_id": "MDU6SXNzdWUzMjA4OTY3MjY=", "number": 7343, "title": "[memory leak] [PyTorch] create_graph=True w/ custom grad ", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-07T17:57:29Z", "updated_at": "2018-05-07T19:57:53Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">import</span> gc\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> _ <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">del</span> _\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cuda.synchronize()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> gc.collect()\n<span class=\"pl-c1\">0</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(torch.cuda.memory_allocated())\n<span class=\"pl-c1\">865280</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">1</span>, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y <span class=\"pl-k\">=</span> x.tanh()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> y.backward(torch.ones_like(y), <span class=\"pl-v\">create_graph</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">del</span> x, y\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> torch.cuda.synchronize()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> gc.collect()\n<span class=\"pl-c1\">0</span>\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">print</span>(torch.cuda.memory_allocated())\n<span class=\"pl-c1\">867328</span></pre></div>\n<p>leaks with <code>y  = x.tanh()</code> but not with <code>y = x  + 1</code>.</p>\n<p>Discovered when running code in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"320115344\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/7270\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/7270/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/7270\">#7270</a></p>", "body_text": ">>> import torch\n>>> import gc\n>>> _ = torch.randn(1, device='cuda')\n>>> del _\n>>> torch.cuda.synchronize()\n>>> gc.collect()\n0\n>>> print(torch.cuda.memory_allocated())\n865280\n>>> x = torch.randn(1, device='cuda', requires_grad=True)\n>>> y = x.tanh()\n>>> y.backward(torch.ones_like(y), create_graph=True)\n>>> del x, y\n>>> torch.cuda.synchronize()\n>>> gc.collect()\n0\n>>> print(torch.cuda.memory_allocated())\n867328\nleaks with y  = x.tanh() but not with y = x  + 1.\nDiscovered when running code in #7270", "body": "```python\r\n>>> import torch\r\n>>> import gc\r\n>>> _ = torch.randn(1, device='cuda')\r\n>>> del _\r\n>>> torch.cuda.synchronize()\r\n>>> gc.collect()\r\n0\r\n>>> print(torch.cuda.memory_allocated())\r\n865280\r\n>>> x = torch.randn(1, device='cuda', requires_grad=True)\r\n>>> y = x.tanh()\r\n>>> y.backward(torch.ones_like(y), create_graph=True)\r\n>>> del x, y\r\n>>> torch.cuda.synchronize()\r\n>>> gc.collect()\r\n0\r\n>>> print(torch.cuda.memory_allocated())\r\n867328\r\n```\r\n\r\nleaks with `y  = x.tanh()` but not with `y = x  + 1`.\r\n\r\nDiscovered when running code in #7270 "}