{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4908", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4908/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4908/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4908/events", "html_url": "https://github.com/pytorch/pytorch/issues/4908", "id": 292491892, "node_id": "MDU6SXNzdWUyOTI0OTE4OTI=", "number": 4908, "title": "torch.cuda.get_device_capability() is ludicrously expensive", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 838476895, "node_id": "MDU6TGFiZWw4Mzg0NzY4OTU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/hackamonth", "name": "hackamonth", "color": "0e8a16", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-29T17:23:48Z", "updated_at": "2018-03-30T20:39:23Z", "closed_at": "2018-03-30T20:39:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Running:</p>\n<pre><code>import torch\nimport time\n\nfor j in range(10):\n  s = time.time()\n  for i in range(10):\n    torch.cuda.get_device_capability(torch.cuda.current_device())\n  e = time.time()\n  print((e-s)/10)\n</code></pre>\n<p>I get:</p>\n<pre><code>aten-rnn$ python bench-get-device-capability.py \n0.2659363985061646\n0.0003546237945556641\n0.000339508056640625\n0.00035924911499023436\n0.0004879951477050781\n0.0003418445587158203\n0.0003411054611206055\n0.00034160614013671874\n0.0006665945053100586\n0.0003442287445068359\n</code></pre>\n<p>That's something like 350us a pop!</p>\n<p>This matters. I noticed this behavior because I was benchmarking WLM, and when I commented out the test in <code>torch/backends/cudnn/__init__.py</code> the runtime shot down from 57.768s to 53.246s. We seem to call the RNN descriptor initialization twice per batch, and then another ~1200 times every time we do validation. The math works out:</p>\n<pre><code>&gt;&gt;&gt; (2983*2 + 1200*2)*350\n2928100\n</code></pre>\n<p>which is the correct order of magnitude change in runtime.</p>\n<p>We should cache this. But maybe look at this more carefully after  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"292030452\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4881\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4881/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4881\">#4881</a> lands, because the caching might need to be done in C++ land.</p>\n<ul>\n<li>OS: Linux [redacted] 4.4.0-92-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"182343932\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/115\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/115/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/115\">#115</a>-Ubuntu SMP Thu Aug 10 09:04:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</li>\n<li>PyTorch version: HEAD (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/2d829d15af98b5fde12d199456b9902dd0930b56/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/2d829d15af98b5fde12d199456b9902dd0930b56\"><tt>2d829d1</tt></a>)</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: 3.6.4</li>\n<li>CUDA/cuDNN version: CUDA 9.0, V9.0.176 / cuDNN 7.0.3 / Driver Version: 384.81</li>\n<li>GPU models and configuration: Quadro GP100</li>\n<li>GCC version (if compiling from source): gcc (GCC) 5.3.0</li>\n</ul>", "body_text": "Running:\nimport torch\nimport time\n\nfor j in range(10):\n  s = time.time()\n  for i in range(10):\n    torch.cuda.get_device_capability(torch.cuda.current_device())\n  e = time.time()\n  print((e-s)/10)\n\nI get:\naten-rnn$ python bench-get-device-capability.py \n0.2659363985061646\n0.0003546237945556641\n0.000339508056640625\n0.00035924911499023436\n0.0004879951477050781\n0.0003418445587158203\n0.0003411054611206055\n0.00034160614013671874\n0.0006665945053100586\n0.0003442287445068359\n\nThat's something like 350us a pop!\nThis matters. I noticed this behavior because I was benchmarking WLM, and when I commented out the test in torch/backends/cudnn/__init__.py the runtime shot down from 57.768s to 53.246s. We seem to call the RNN descriptor initialization twice per batch, and then another ~1200 times every time we do validation. The math works out:\n>>> (2983*2 + 1200*2)*350\n2928100\n\nwhich is the correct order of magnitude change in runtime.\nWe should cache this. But maybe look at this more carefully after  #4881 lands, because the caching might need to be done in C++ land.\n\nOS: Linux [redacted] 4.4.0-92-generic #115-Ubuntu SMP Thu Aug 10 09:04:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nPyTorch version: HEAD (2d829d1)\nHow you installed PyTorch (conda, pip, source): source\nPython version: 3.6.4\nCUDA/cuDNN version: CUDA 9.0, V9.0.176 / cuDNN 7.0.3 / Driver Version: 384.81\nGPU models and configuration: Quadro GP100\nGCC version (if compiling from source): gcc (GCC) 5.3.0", "body": "Running:\r\n\r\n```\r\nimport torch\r\nimport time\r\n\r\nfor j in range(10):\r\n  s = time.time()\r\n  for i in range(10):\r\n    torch.cuda.get_device_capability(torch.cuda.current_device())\r\n  e = time.time()\r\n  print((e-s)/10)\r\n```\r\n\r\nI get:\r\n\r\n```\r\naten-rnn$ python bench-get-device-capability.py \r\n0.2659363985061646\r\n0.0003546237945556641\r\n0.000339508056640625\r\n0.00035924911499023436\r\n0.0004879951477050781\r\n0.0003418445587158203\r\n0.0003411054611206055\r\n0.00034160614013671874\r\n0.0006665945053100586\r\n0.0003442287445068359\r\n```\r\n\r\nThat's something like 350us a pop!\r\n\r\nThis matters. I noticed this behavior because I was benchmarking WLM, and when I commented out the test in `torch/backends/cudnn/__init__.py` the runtime shot down from 57.768s to 53.246s. We seem to call the RNN descriptor initialization twice per batch, and then another ~1200 times every time we do validation. The math works out:\r\n\r\n```\r\n>>> (2983*2 + 1200*2)*350\r\n2928100\r\n```\r\n\r\nwhich is the correct order of magnitude change in runtime.\r\n\r\nWe should cache this. But maybe look at this more carefully after  #4881 lands, because the caching might need to be done in C++ land.\r\n\r\n- OS: Linux [redacted] 4.4.0-92-generic #115-Ubuntu SMP Thu Aug 10 09:04:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n- PyTorch version: HEAD (2d829d15af98b5fde12d199456b9902dd0930b56)\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: 3.6.4\r\n- CUDA/cuDNN version: CUDA 9.0, V9.0.176 / cuDNN 7.0.3 / Driver Version: 384.81\r\n- GPU models and configuration: Quadro GP100\r\n- GCC version (if compiling from source): gcc (GCC) 5.3.0"}