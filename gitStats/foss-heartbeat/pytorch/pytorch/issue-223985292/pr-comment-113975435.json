{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/113975435", "pull_request_review_id": 35411102, "id": 113975435, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMzk3NTQzNQ==", "diff_hunk": "@@ -582,29 +582,95 @@ def pixel_shuffle(input, upscale_factor):\n def upsample_nearest(input, size=None, scale_factor=None):\n     \"\"\"Upsamples the input, using nearest neighbours' pixel values.\n \n-    Currently only spatial upsampling is supported (i.e. expected inputs\n-    are 4 dimensional).\n+    Currently spatial and volumetric upsampling are supported (i.e. expected inputs\n+    are 4 or 5 dimensional).\n \n     Args:\n         input (Variable): input\n-        size (int or Tuple[int, int]): output spatial size.\n+        size (int or Tuple[int, int] or Tuple[int, int, int]): output spatial size.\n         scale_factor (int): multiplier for spatial size. Has to be an integer.\n     \"\"\"\n-    return _functions.thnn.UpsamplingNearest2d(size, scale_factor)(input)\n+    if input.dim() == 4:\n+        assert type(size) == int or len(size) == 2, '4D tensors expect size as int or Tuple[int, int]'\n+        return _functions.thnn.UpsamplingNearest2d(_pair(size), scale_factor)(input)\n+    elif input.dim() == 5:\n+        assert type(size) == int or len(size) == 3, '5D tensors expect size as int or Tuple[int, int, int]'\n+        return _functions.thnn.UpsamplingNearest3d(_triple(size), scale_factor)(input)\n+    else:\n+        raise NotImplementedError(\"Only 4D and 5D upsampling is supported for now\")\n \n \n def upsample_bilinear(input, size=None, scale_factor=None):\n-    \"\"\"Upscales the input, using the bilinear upsampling.\n+    \"\"\"Upscales the input, using bilinear upsampling.\n \n-    Currently only spatial upsampling is supported (i.e. expected inputs\n-    are 4 dimensional).\n+    Expected inputs are spatial (4 dimensional). Use upsample_trilinear for volumetric (5 dimensional)\n+    inputs.\n \n     Args:\n         input (Variable): input\n         size (int or Tuple[int, int]): output spatial size.\n         scale_factor (int): multiplier for spatial size. Has to be an integer.\n     \"\"\"\n-    return _functions.thnn.UpsamplingBilinear2d(size, scale_factor)(input)\n+    assert input.dim() == 4, \"4D tensors expected in input\"\n+    assert type(size) == int or len(size) == 2, '4D tensors expect size as int or Tuple[int, int]'\n+    return _functions.thnn.UpsamplingBilinear2d(_pair(size), scale_factor)(input)\n+\n+\n+def upsample_trilinear(input, size=None, scale_factor=None):\n+    \"\"\"Upscales the input, using trilinear upsampling.\n+\n+    Expected inputs are volumetric (5 dimensional). Use upsample_bilinear for spatial (4 dimensional)\n+    inputs.\n+\n+    Args:\n+        input (Variable): input\n+        size (int or Tuple[int, int, int]): output spatial size.\n+        scale_factor (int): multiplier for spatial size. Has to be an integer.\n+    \"\"\"\n+    assert input.dim() == 5, \"5D tensors expected in input\"\n+    assert type(size) == int or len(size) == 3, '5D tensors expect size as int or Tuple[int, int, int]'\n+    return _functions.thnn.UpsamplingTrilinear3d(_triple(size), scale_factor)(input)\n+\n+\n+def subsample(input, weight, bias, size, stride=1):\n+    \"\"\"Subsamples the input by averaging over input neighborhoods of given size with given stride,\n+    multiplying by weight and adding bias to the result.\n+    The function preserves the number of channels (i.e. ``in_channels==out_channels``)\n+    Weight and bias are learned 1D tensors of size (in_channels).\n+\n+    Currently only spatial and volumetric subsampling are supported (i.e. expected\n+    inputs are 4 or 5 dimensional).\n+\n+    See :class:`~torch.nn.Subsample2d` and :class:`~torch.nn.Subsample3d` for details and output shape.\n+\n+    Args:\n+        input (Variable): input tensor (minibatch x in_channels x iH x iW)\n+          or (minibatch x in_channels x iD x iH x iW)\n+        weight: weight tensor (in_channels)\n+        bias: bias tensor (in_channels)\n+        size (int or Tuple[int, int] or Tuple[int, int, int]): size of the neighborhood over which\n+          input is averaged to produce the output\n+        stride (int or Tuple[int, int] or Tuple[int, int, int]): the stride of the averaging operation.\n+          Default: 1\n+\n+    Examples:\n+        >>> weight = autograd.Variable(torch.randn(10))\n+        >>> bias = autograd.Variable(torch.randn(10))\n+        >>> inputs = autograd.Variable(torch.randn(1,10,4,4))\n+        >>> F.subsample(inputs, weight, bias, 2, stride=2)\n+    \"\"\"\n+    if input.dim() == 4:", "path": "torch/nn/functional.py", "position": 89, "original_position": 89, "commit_id": "aed92eb7a1eab72bddbb596a003a4f32b65cfc01", "original_commit_id": "abe58e09db9645e7d1769daf66a0fbc79d55227e", "user": {"login": "andrewgiessel", "id": 1160997, "node_id": "MDQ6VXNlcjExNjA5OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1160997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewgiessel", "html_url": "https://github.com/andrewgiessel", "followers_url": "https://api.github.com/users/andrewgiessel/followers", "following_url": "https://api.github.com/users/andrewgiessel/following{/other_user}", "gists_url": "https://api.github.com/users/andrewgiessel/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewgiessel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewgiessel/subscriptions", "organizations_url": "https://api.github.com/users/andrewgiessel/orgs", "repos_url": "https://api.github.com/users/andrewgiessel/repos", "events_url": "https://api.github.com/users/andrewgiessel/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewgiessel/received_events", "type": "User", "site_admin": false}, "body": "if you want subsample and upsample to follow the same tuple casting conventions, these need changing, too, but I'm not going to be thorough ", "created_at": "2017-04-28T17:01:21Z", "updated_at": "2018-11-23T15:33:14Z", "html_url": "https://github.com/pytorch/pytorch/pull/1348#discussion_r113975435", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1348", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/113975435"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1348#discussion_r113975435"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1348"}}, "body_html": "<p>if you want subsample and upsample to follow the same tuple casting conventions, these need changing, too, but I'm not going to be thorough</p>", "body_text": "if you want subsample and upsample to follow the same tuple casting conventions, these need changing, too, but I'm not going to be thorough"}