{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/300099969", "html_url": "https://github.com/pytorch/pytorch/issues/1516#issuecomment-300099969", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1516", "id": 300099969, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDA5OTk2OQ==", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-09T08:41:56Z", "updated_at": "2017-05-09T08:57:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>See also: the same exp. on tensorflow. The result is consistent with the \"correct gradient\" in the preivew test.<br>\n<a href=\"https://github.com/Jiaming-Liu/pytorch-misc/blob/master/test_tf_binary_cross_entropy.ipynb\">https://github.com/Jiaming-Liu/pytorch-misc/blob/master/test_tf_binary_cross_entropy.ipynb</a></p>\n<p>BTW, it seems that torch.nn.MultiLabelSoftMarginLoss scales down the gradient by the number of classes by default. Is there any particular reason for it?</p>", "body_text": "See also: the same exp. on tensorflow. The result is consistent with the \"correct gradient\" in the preivew test.\nhttps://github.com/Jiaming-Liu/pytorch-misc/blob/master/test_tf_binary_cross_entropy.ipynb\nBTW, it seems that torch.nn.MultiLabelSoftMarginLoss scales down the gradient by the number of classes by default. Is there any particular reason for it?", "body": "See also: the same exp. on tensorflow. The result is consistent with the \"correct gradient\" in the preivew test.\r\nhttps://github.com/Jiaming-Liu/pytorch-misc/blob/master/test_tf_binary_cross_entropy.ipynb\r\n\r\nBTW, it seems that torch.nn.MultiLabelSoftMarginLoss scales down the gradient by the number of classes by default. Is there any particular reason for it?"}