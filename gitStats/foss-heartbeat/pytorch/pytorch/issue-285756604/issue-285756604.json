{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4460", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4460/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4460/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4460/events", "html_url": "https://github.com/pytorch/pytorch/pull/4460", "id": 285756604, "node_id": "MDExOlB1bGxSZXF1ZXN0MTYwOTYyMDI4", "number": 4460, "title": "Fix CUDA double backwards", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-03T17:35:09Z", "updated_at": "2018-11-23T15:37:53Z", "closed_at": "2018-01-06T15:58:06Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4460", "html_url": "https://github.com/pytorch/pytorch/pull/4460", "diff_url": "https://github.com/pytorch/pytorch/pull/4460.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4460.patch"}, "body_html": "<p>CUDA double backwards was broken, and we didn't know about it. Fix it.</p>\n<p>Each commit is a logical unit of work.</p>\n<pre><code>commit 9ae56c3bb4a26e01269031d4205263952ceadc79\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Wed Jan 3 09:27:24 2018 -0800\n\n    Actually test CUDA double-backwards codepath.\n    \n    Previously, we only tested CPU double-backwards, which is bad!\n    This would have caught #4422 (still not fixed, so those tests\n    are manually disabled.)\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n\ncommit e80a9949c19ba979b63e8faeb984b34c6929d4c2\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Wed Jan 3 08:14:51 2018 -0800\n\n    Check for out of bounds grads access in derivatives.yaml\n    \n    This test would have caught the OOB in thnn_conv_depthwise2d_backward\n    \n    Fixes #4457\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n\ncommit c8b34c46b508c3636d60a9bd297e755baeff7b20\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Wed Jan 3 08:14:27 2018 -0800\n\n    s/uses_grad/uses_single_grad/ for more clarity.\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n\ncommit 563936c3b81b4c0a37e4348d36af2265f98feabf\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Wed Jan 3 09:18:18 2018 -0800\n\n    Fix 'invalid argument 4: weight tensor has to be contiguous'\n    \n    Weight can be non-contiguous due to double backwards, where\n    we transpose the weight.  I'm not very happy with this fix\n    but it seems to make the tests pass.\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n\ncommit af1283c24c9d39465342654cd4b9b2eca6d1d9c6\nAuthor: Edward Z. Yang &lt;ezyang@fb.com&gt;\nDate:   Wed Jan 3 08:39:04 2018 -0800\n\n    Fix two bugs in thnn_conv_depthwise2d_backward gradient.\n    \n    - Out of bounds grads[2] access (thnn_conv_depthwise2d_backward\n      doesn't compute bias gradient)\n    \n    - Groups was not set appropriately for depthwise convolution\n    \n    Signed-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n</code></pre>", "body_text": "CUDA double backwards was broken, and we didn't know about it. Fix it.\nEach commit is a logical unit of work.\ncommit 9ae56c3bb4a26e01269031d4205263952ceadc79\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Wed Jan 3 09:27:24 2018 -0800\n\n    Actually test CUDA double-backwards codepath.\n    \n    Previously, we only tested CPU double-backwards, which is bad!\n    This would have caught #4422 (still not fixed, so those tests\n    are manually disabled.)\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\n\ncommit e80a9949c19ba979b63e8faeb984b34c6929d4c2\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Wed Jan 3 08:14:51 2018 -0800\n\n    Check for out of bounds grads access in derivatives.yaml\n    \n    This test would have caught the OOB in thnn_conv_depthwise2d_backward\n    \n    Fixes #4457\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\n\ncommit c8b34c46b508c3636d60a9bd297e755baeff7b20\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Wed Jan 3 08:14:27 2018 -0800\n\n    s/uses_grad/uses_single_grad/ for more clarity.\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\n\ncommit 563936c3b81b4c0a37e4348d36af2265f98feabf\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Wed Jan 3 09:18:18 2018 -0800\n\n    Fix 'invalid argument 4: weight tensor has to be contiguous'\n    \n    Weight can be non-contiguous due to double backwards, where\n    we transpose the weight.  I'm not very happy with this fix\n    but it seems to make the tests pass.\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\n\ncommit af1283c24c9d39465342654cd4b9b2eca6d1d9c6\nAuthor: Edward Z. Yang <ezyang@fb.com>\nDate:   Wed Jan 3 08:39:04 2018 -0800\n\n    Fix two bugs in thnn_conv_depthwise2d_backward gradient.\n    \n    - Out of bounds grads[2] access (thnn_conv_depthwise2d_backward\n      doesn't compute bias gradient)\n    \n    - Groups was not set appropriately for depthwise convolution\n    \n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>", "body": "CUDA double backwards was broken, and we didn't know about it. Fix it.\r\n\r\nEach commit is a logical unit of work.\r\n\r\n```\r\ncommit 9ae56c3bb4a26e01269031d4205263952ceadc79\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Wed Jan 3 09:27:24 2018 -0800\r\n\r\n    Actually test CUDA double-backwards codepath.\r\n    \r\n    Previously, we only tested CPU double-backwards, which is bad!\r\n    This would have caught #4422 (still not fixed, so those tests\r\n    are manually disabled.)\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\ncommit e80a9949c19ba979b63e8faeb984b34c6929d4c2\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Wed Jan 3 08:14:51 2018 -0800\r\n\r\n    Check for out of bounds grads access in derivatives.yaml\r\n    \r\n    This test would have caught the OOB in thnn_conv_depthwise2d_backward\r\n    \r\n    Fixes #4457\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\ncommit c8b34c46b508c3636d60a9bd297e755baeff7b20\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Wed Jan 3 08:14:27 2018 -0800\r\n\r\n    s/uses_grad/uses_single_grad/ for more clarity.\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\ncommit 563936c3b81b4c0a37e4348d36af2265f98feabf\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Wed Jan 3 09:18:18 2018 -0800\r\n\r\n    Fix 'invalid argument 4: weight tensor has to be contiguous'\r\n    \r\n    Weight can be non-contiguous due to double backwards, where\r\n    we transpose the weight.  I'm not very happy with this fix\r\n    but it seems to make the tests pass.\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\ncommit af1283c24c9d39465342654cd4b9b2eca6d1d9c6\r\nAuthor: Edward Z. Yang <ezyang@fb.com>\r\nDate:   Wed Jan 3 08:39:04 2018 -0800\r\n\r\n    Fix two bugs in thnn_conv_depthwise2d_backward gradient.\r\n    \r\n    - Out of bounds grads[2] access (thnn_conv_depthwise2d_backward\r\n      doesn't compute bias gradient)\r\n    \r\n    - Groups was not set appropriately for depthwise convolution\r\n    \r\n    Signed-off-by: Edward Z. Yang <ezyang@fb.com>\r\n```"}