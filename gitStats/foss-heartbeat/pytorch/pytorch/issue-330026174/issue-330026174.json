{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8212", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8212/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8212/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8212/events", "html_url": "https://github.com/pytorch/pytorch/issues/8212", "id": 330026174, "node_id": "MDU6SXNzdWUzMzAwMjYxNzQ=", "number": 8212, "title": "In-place operations with nondeterministic results should warn", "user": {"login": "davidbau", "id": 3458792, "node_id": "MDQ6VXNlcjM0NTg3OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3458792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidbau", "html_url": "https://github.com/davidbau", "followers_url": "https://api.github.com/users/davidbau/followers", "following_url": "https://api.github.com/users/davidbau/following{/other_user}", "gists_url": "https://api.github.com/users/davidbau/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidbau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidbau/subscriptions", "organizations_url": "https://api.github.com/users/davidbau/orgs", "repos_url": "https://api.github.com/users/davidbau/repos", "events_url": "https://api.github.com/users/davidbau/events{/privacy}", "received_events_url": "https://api.github.com/users/davidbau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2018-06-06T20:45:58Z", "updated_at": "2018-06-21T19:56:56Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Sometimes an in-place division where the denominator comes from the same tensor will yield unpredictable results.  For example, if you want an array that counts from 0 to 100 in each of 50 rows, but actually you want to normalize to the range [0..1], it seems natural to write:</p>\n<pre><code>import torch\nc = torch.arange(101)[None,:].repeat(50, 1)\nc /= c[:,100:]\nprint(c.max())\n</code></pre>\n<p>However, running this on CPU repeatedly will produce an unpredictable max, e.g., 82, 95, 87, etc, rather than the expected 1.0.</p>\n<p>This operation appears to be reliable on numpy, and for many array shapes it also works fine in pytorch.  But it fails on certain sizes, leading to oddly rare and difficult-to-find bugs.</p>\n<p>Should <code>c /= c[:,-1:]</code> be reliable?  If not, would it be reasonable to warn on such operations?</p>", "body_text": "Sometimes an in-place division where the denominator comes from the same tensor will yield unpredictable results.  For example, if you want an array that counts from 0 to 100 in each of 50 rows, but actually you want to normalize to the range [0..1], it seems natural to write:\nimport torch\nc = torch.arange(101)[None,:].repeat(50, 1)\nc /= c[:,100:]\nprint(c.max())\n\nHowever, running this on CPU repeatedly will produce an unpredictable max, e.g., 82, 95, 87, etc, rather than the expected 1.0.\nThis operation appears to be reliable on numpy, and for many array shapes it also works fine in pytorch.  But it fails on certain sizes, leading to oddly rare and difficult-to-find bugs.\nShould c /= c[:,-1:] be reliable?  If not, would it be reasonable to warn on such operations?", "body": "Sometimes an in-place division where the denominator comes from the same tensor will yield unpredictable results.  For example, if you want an array that counts from 0 to 100 in each of 50 rows, but actually you want to normalize to the range [0..1], it seems natural to write:\r\n\r\n```\r\nimport torch\r\nc = torch.arange(101)[None,:].repeat(50, 1)\r\nc /= c[:,100:]\r\nprint(c.max())\r\n```\r\n\r\nHowever, running this on CPU repeatedly will produce an unpredictable max, e.g., 82, 95, 87, etc, rather than the expected 1.0.\r\n\r\nThis operation appears to be reliable on numpy, and for many array shapes it also works fine in pytorch.  But it fails on certain sizes, leading to oddly rare and difficult-to-find bugs.\r\n\r\nShould `c /= c[:,-1:]` be reliable?  If not, would it be reasonable to warn on such operations?\r\n"}