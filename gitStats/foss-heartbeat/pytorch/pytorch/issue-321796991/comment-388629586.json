{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/388629586", "html_url": "https://github.com/pytorch/pytorch/issues/7455#issuecomment-388629586", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7455", "id": 388629586, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODYyOTU4Ng==", "user": {"login": "mdraw", "id": 6719909, "node_id": "MDQ6VXNlcjY3MTk5MDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6719909?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mdraw", "html_url": "https://github.com/mdraw", "followers_url": "https://api.github.com/users/mdraw/followers", "following_url": "https://api.github.com/users/mdraw/following{/other_user}", "gists_url": "https://api.github.com/users/mdraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/mdraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mdraw/subscriptions", "organizations_url": "https://api.github.com/users/mdraw/orgs", "repos_url": "https://api.github.com/users/mdraw/repos", "events_url": "https://api.github.com/users/mdraw/events{/privacy}", "received_events_url": "https://api.github.com/users/mdraw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-13T14:09:05Z", "updated_at": "2018-05-13T14:09:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>See <a href=\"https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/5\" rel=\"nofollow\">https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/5</a>. The <code>cross_entropy()</code> function that's shown there should work with smoothed labels that have the same dimension as the network outputs.</p>\n<p>I don't think <code>CrossEntropyLoss()</code> should directly support a <code>label_smoothing</code> option, since label smoothing can be done in many different ways and the smoothing itself can be easily done manually by the user. But I agree it should at least be mentioned in the docs how to deal with targets that can't be represented by scalar values, or add support for passing (k-hot/smoothed) targets to <code>CrossEntropyLoss</code>.</p>", "body_text": "See https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/5. The cross_entropy() function that's shown there should work with smoothed labels that have the same dimension as the network outputs.\nI don't think CrossEntropyLoss() should directly support a label_smoothing option, since label smoothing can be done in many different ways and the smoothing itself can be easily done manually by the user. But I agree it should at least be mentioned in the docs how to deal with targets that can't be represented by scalar values, or add support for passing (k-hot/smoothed) targets to CrossEntropyLoss.", "body": "See https://discuss.pytorch.org/t/cross-entropy-with-one-hot-targets/13580/5. The `cross_entropy()` function that's shown there should work with smoothed labels that have the same dimension as the network outputs.\n\nI don't think `CrossEntropyLoss()` should directly support a `label_smoothing` option, since label smoothing can be done in many different ways and the smoothing itself can be easily done manually by the user. But I agree it should at least be mentioned in the docs how to deal with targets that can't be represented by scalar values, or add support for passing (k-hot/smoothed) targets to `CrossEntropyLoss`. "}