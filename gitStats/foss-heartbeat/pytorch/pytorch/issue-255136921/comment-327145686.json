{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/327145686", "html_url": "https://github.com/pytorch/pytorch/issues/2618#issuecomment-327145686", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2618", "id": 327145686, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzE0NTY4Ng==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-05T11:15:15Z", "updated_at": "2017-09-05T18:25:59Z", "author_association": "MEMBER", "body_html": "<p>While adding a <code>square</code> function is an easy solution, I wonder if for this particular case it wouldn't be better to dispatch the <code>pow</code> implementations depending on the power that is used, and would benefit users right away.<br>\nThis is something that I thought should be done already by cmath, but it seems that it's not the case.<br>\nInstead of writing our own version of <code>TH_pow</code> and replacing it in <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THTensorMath.c#L2915\">here</a>, which would incur evaluating conditions for every element of the array, we could just replace <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THTensorMath.c#L2915\">this line</a> with a dedicated function that dispatches to <code>a * a</code> if <code>base == 2</code>.</p>\n<p>Something like</p>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">void</span> <span class=\"pl-en\">THTensor_</span>(pow)(THTensor *r_, THTensor *t, real value)\n{\n  <span class=\"pl-c1\">THTensor_</span>(resizeAs)(r_, t);\n  <span class=\"pl-k\">if</span>(value == <span class=\"pl-c1\">2</span>) {\n    <span class=\"pl-c1\">THTensor_</span>(cmul)(r_, t_, t_);\n  }\n  <span class=\"pl-k\">else</span> {\n    <span class=\"pl-c1\">TH_TENSOR_APPLY2</span>(real, t, real, r_, *r__data = <span class=\"pl-c1\">pow</span>(*t_data, value););\n  }\n}   </pre></div>\n<p>What do you think?</p>", "body_text": "While adding a square function is an easy solution, I wonder if for this particular case it wouldn't be better to dispatch the pow implementations depending on the power that is used, and would benefit users right away.\nThis is something that I thought should be done already by cmath, but it seems that it's not the case.\nInstead of writing our own version of TH_pow and replacing it in here, which would incur evaluating conditions for every element of the array, we could just replace this line with a dedicated function that dispatches to a * a if base == 2.\nSomething like\nvoid THTensor_(pow)(THTensor *r_, THTensor *t, real value)\n{\n  THTensor_(resizeAs)(r_, t);\n  if(value == 2) {\n    THTensor_(cmul)(r_, t_, t_);\n  }\n  else {\n    TH_TENSOR_APPLY2(real, t, real, r_, *r__data = pow(*t_data, value););\n  }\n}   \nWhat do you think?", "body": "While adding a `square` function is an easy solution, I wonder if for this particular case it wouldn't be better to dispatch the `pow` implementations depending on the power that is used, and would benefit users right away.\r\nThis is something that I thought should be done already by cmath, but it seems that it's not the case.\r\nInstead of writing our own version of `TH_pow` and replacing it in [here](https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THTensorMath.c#L2915), which would incur evaluating conditions for every element of the array, we could just replace [this line](https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THTensorMath.c#L2915) with a dedicated function that dispatches to `a * a` if `base == 2`.\r\n\r\nSomething like\r\n```c\r\nvoid THTensor_(pow)(THTensor *r_, THTensor *t, real value)\r\n{\r\n  THTensor_(resizeAs)(r_, t);\r\n  if(value == 2) {\r\n    THTensor_(cmul)(r_, t_, t_);\r\n  }\r\n  else {\r\n    TH_TENSOR_APPLY2(real, t, real, r_, *r__data = pow(*t_data, value););\r\n  }\r\n}   \r\n```\r\n\r\nWhat do you think?"}