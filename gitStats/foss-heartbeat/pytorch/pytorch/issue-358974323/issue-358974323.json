{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11514", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11514/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11514/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11514/events", "html_url": "https://github.com/pytorch/pytorch/issues/11514", "id": 358974323, "node_id": "MDU6SXNzdWUzNTg5NzQzMjM=", "number": 11514, "title": "[feature request] - Allow sequences lengths to be 0 in PackSequence", "user": {"login": "mfuntowicz", "id": 2241520, "node_id": "MDQ6VXNlcjIyNDE1MjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/2241520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mfuntowicz", "html_url": "https://github.com/mfuntowicz", "followers_url": "https://api.github.com/users/mfuntowicz/followers", "following_url": "https://api.github.com/users/mfuntowicz/following{/other_user}", "gists_url": "https://api.github.com/users/mfuntowicz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mfuntowicz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mfuntowicz/subscriptions", "organizations_url": "https://api.github.com/users/mfuntowicz/orgs", "repos_url": "https://api.github.com/users/mfuntowicz/repos", "events_url": "https://api.github.com/users/mfuntowicz/events{/privacy}", "received_events_url": "https://api.github.com/users/mfuntowicz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-11T10:00:49Z", "updated_at": "2018-09-17T18:07:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi,</p>\n<h3>Context</h3>\n<p>I'm currently working on some NLP stuff which includes working on character-level encoding through RNNs. For this, I'm using pack_padded_sequence/pad_packed_sequence which does the job for word-level encoding, but starts to be a little bit more annoying for the chars.</p>\n<p><strong><em>I'm using batch_first=True axis, but the same can be easily applied to batch_first=False</em></strong></p>\n<p>The character tensor's shape is [B, W, C, *], where B is the batch axis, W is the word axis and C is the character axis for each word  (In our case we flatten the first two axis B and W as each word is independent from each other, resulting in a forwarded tensor's shape: [B x W, C, *]).</p>\n<p>Then, as W already contains some padded indexes, some C entries are then padded entries, thus having length = 0 which throw the following error when trying to use pack_padded_sequence :</p>\n<p><code>ValueError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is &lt;= 0</code></p>\n<p>It seems that this behaviour comes from the following: <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/PackedSequence.cpp#L22\">https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/PackedSequence.cpp#L22</a></p>\n<h3>Proposition</h3>\n<p>It would be interesting to relax the constraint on the sequence length to be &gt;= 0 in PackSequence, and handling the \"0-case\" directly as it is currently done to generate each batch that will go to the RNN.</p>\n<p>Thanks,<br>\nMorgan</p>", "body_text": "Hi,\nContext\nI'm currently working on some NLP stuff which includes working on character-level encoding through RNNs. For this, I'm using pack_padded_sequence/pad_packed_sequence which does the job for word-level encoding, but starts to be a little bit more annoying for the chars.\nI'm using batch_first=True axis, but the same can be easily applied to batch_first=False\nThe character tensor's shape is [B, W, C, *], where B is the batch axis, W is the word axis and C is the character axis for each word  (In our case we flatten the first two axis B and W as each word is independent from each other, resulting in a forwarded tensor's shape: [B x W, C, *]).\nThen, as W already contains some padded indexes, some C entries are then padded entries, thus having length = 0 which throw the following error when trying to use pack_padded_sequence :\nValueError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0\nIt seems that this behaviour comes from the following: https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/PackedSequence.cpp#L22\nProposition\nIt would be interesting to relax the constraint on the sequence length to be >= 0 in PackSequence, and handling the \"0-case\" directly as it is currently done to generate each batch that will go to the RNN.\nThanks,\nMorgan", "body": "Hi, \r\n\r\n### Context\r\nI'm currently working on some NLP stuff which includes working on character-level encoding through RNNs. For this, I'm using pack_padded_sequence/pad_packed_sequence which does the job for word-level encoding, but starts to be a little bit more annoying for the chars. \r\n\r\n**_I'm using batch_first=True axis, but the same can be easily applied to batch_first=False_**\r\n\r\nThe character tensor's shape is [B, W, C, *], where B is the batch axis, W is the word axis and C is the character axis for each word  (In our case we flatten the first two axis B and W as each word is independent from each other, resulting in a forwarded tensor's shape: [B x W, C, *]).\r\n\r\nThen, as W already contains some padded indexes, some C entries are then padded entries, thus having length = 0 which throw the following error when trying to use pack_padded_sequence : \r\n\r\n`ValueError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0`\r\n\r\nIt seems that this behaviour comes from the following: https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/PackedSequence.cpp#L22\r\n\r\n### Proposition\r\n\r\nIt would be interesting to relax the constraint on the sequence length to be >= 0 in PackSequence, and handling the \"0-case\" directly as it is currently done to generate each batch that will go to the RNN.\r\n\r\nThanks,\r\nMorgan"}