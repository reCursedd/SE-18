{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428471468", "html_url": "https://github.com/pytorch/pytorch/issues/12483#issuecomment-428471468", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12483", "id": 428471468, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODQ3MTQ2OA==", "user": {"login": "Kathrine94", "id": 27257067, "node_id": "MDQ6VXNlcjI3MjU3MDY3", "avatar_url": "https://avatars2.githubusercontent.com/u/27257067?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kathrine94", "html_url": "https://github.com/Kathrine94", "followers_url": "https://api.github.com/users/Kathrine94/followers", "following_url": "https://api.github.com/users/Kathrine94/following{/other_user}", "gists_url": "https://api.github.com/users/Kathrine94/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kathrine94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kathrine94/subscriptions", "organizations_url": "https://api.github.com/users/Kathrine94/orgs", "repos_url": "https://api.github.com/users/Kathrine94/repos", "events_url": "https://api.github.com/users/Kathrine94/events{/privacy}", "received_events_url": "https://api.github.com/users/Kathrine94/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-10T07:44:34Z", "updated_at": "2018-10-10T07:44:34Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>can you provide the shape/strides/dilation etc? Also what GPU are you using?</p>\n</blockquote>\n<p>This is my code:</p>\n<p>import torch<br>\nimport torch.nn as nn<br>\nimport torch.nn.functional as F<br>\nfrom torch.autograd import Variable<br>\nimport math<br>\nfrom functools import partial</p>\n<p>import torch.utils.model_zoo as model_zoo</p>\n<p>def conv3x3x3(in_planes, out_planes, stride=1):<br>\n# 3x3x3 convolution with padding<br>\nreturn nn.Conv3d(<br>\nin_planes,<br>\nout_planes,<br>\nkernel_size=3,<br>\nstride=stride,<br>\npadding=1,<br>\nbias=False)</p>\n<p>def downsample_basic_block(x, planes, stride):<br>\nout = F.avg_pool3d(x, kernel_size=1, stride=stride)<br>\nzero_pads = torch.Tensor(<br>\nout.size(0), planes - out.size(1), out.size(2), out.size(3),<br>\nout.size(4)).zero_()<br>\nif isinstance(out.data, torch.cuda.FloatTensor):<br>\nzero_pads = zero_pads.cuda()</p>\n<pre><code>out = Variable(torch.cat([out.data, zero_pads], dim=1))\n\nreturn out\n</code></pre>\n<p>class BasicBlock(nn.Module):<br>\nexpansion = 1</p>\n<pre><code>def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(BasicBlock, self).__init__()\n    self.conv1 = conv3x3x3(inplanes, planes, stride)\n    self.bn1 = nn.BatchNorm3d(planes)\n    self.relu = nn.ReLU(inplace=True)\n    self.conv2 = conv3x3x3(planes, planes)\n    self.bn2 = nn.BatchNorm3d(planes)\n    self.downsample = downsample\n    self.stride = stride\n\ndef forward(self, x):\n    residual = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n\n    if self.downsample is not None:\n        residual = self.downsample(x)\n\n    out += residual\n    out = self.relu(out)\n\n    return out\n</code></pre>\n<p>class Bottleneck(nn.Module):<br>\nexpansion = 4</p>\n<pre><code>def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(Bottleneck, self).__init__()\n    self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n    self.bn1 = nn.BatchNorm3d(planes)\n    self.conv2 = nn.Conv3d(\n        planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn2 = nn.BatchNorm3d(planes)\n    self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n    self.bn3 = nn.BatchNorm3d(planes * 4)\n    self.relu = nn.ReLU(inplace=True)\n    self.downsample = downsample\n    self.stride = stride\n\ndef forward(self, x):\n    residual = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n    out = self.relu(out)\n\n    out = self.conv3(out)\n    out = self.bn3(out)\n\n    if self.downsample is not None:\n        residual = self.downsample(x)\n\n    out += residual\n    out = self.relu(out)\n\n    return out\n</code></pre>\n<p>class ResNet(nn.Module):</p>\n<pre><code>def __init__(self,\n             block,\n             layers,\n             sample_size,\n             sample_duration,\n             shortcut_type='B',\n             num_classes=400):\n    self.inplanes = 64\n    super(ResNet, self).__init__()\n    self.conv1 = nn.Conv3d(\n        3,\n        64,\n        kernel_size=7,\n        stride=(1, 2, 2),\n        padding=(3, 3, 3),\n        bias=False)\n    self.bn1 = nn.BatchNorm3d(64)\n    self.relu = nn.ReLU(inplace=True)\n    self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n    self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n    self.layer2 = self._make_layer(\n        block, 128, layers[1], shortcut_type, stride=2)\n    self.layer3 = self._make_layer(\n        block, 256, layers[2], shortcut_type, stride=2)\n    self.layer4 = self._make_layer(\n        block, 512, layers[3], shortcut_type, stride=2)\n\n    self.avgpool = nn.AvgPool3d((1, 7, 7), stride=1)\n    \n    self.conv1x1_1 = nn.Sequential(\n        nn.Conv3d(512, num_classes, (1, 1, 1))\n    )\n    \n\ndef _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        if shortcut_type == 'A':\n            downsample = partial(\n                downsample_basic_block,\n                planes=planes * block.expansion,\n                stride=stride)\n        else:\n            downsample = nn.Sequential(\n                nn.Conv3d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\ndef forward(self, x):\n    x = self.conv1(x)\n    x = self.bn1(x)\n    x = self.relu(x)\n    x = self.maxpool(x)\n\n    x = self.layer1(x)\n    x = self.layer2(x)\n    x = self.layer3(x)\n    x = self.layer4(x)\n\n\n    x = self.avgpool(x)\n   \n    x = self.conv1x1_1(x)\n    x = x.squeeze(2).squeeze(2).squeeze(2)\n\n    return x\n</code></pre>\n<p>def get_fine_tuning_parameters(model, ft_begin_index):<br>\nif ft_begin_index == 0:<br>\nreturn model.parameters()</p>\n<pre><code>ft_module_names = []\nfor i in range(ft_begin_index, 5):\n    ft_module_names.append('layer{}'.format(i))\nft_module_names.append('fc')\n\nparameters = []\nfor k, v in model.named_parameters():\n    for ft_module in ft_module_names:\n        if ft_module in k:\n            parameters.append({'params': v})\n            break\n    else:\n        parameters.append({'params': v, 'lr': 0.0})\n\nreturn parameters\n</code></pre>\n<p>def resnet10(**kwargs):<br>\n\"\"\"Constructs a ResNet-18 model.<br>\n\"\"\"<br>\nmodel = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)<br>\nreturn model</p>\n<p>def resnet18(**kwargs):<br>\n\"\"\"Constructs a ResNet-18 model.<br>\n\"\"\"<br>\nmodel = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)<br>\nreturn model</p>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\nimport torch<br>\nmodel = resnet18(sample_size=224, sample_duration=16, num_classes=1)<br>\nmodel = model.cuda()<br>\nbs = 3<br>\nfor i in range(100):<br>\ndata = torch.randn(bs, 3, 16, 224, 224).cuda()<br>\nc = model(data)<br>\nc.sum().backward()</p>\n<p>My GPU is TitanXp</p>", "body_text": "can you provide the shape/strides/dilation etc? Also what GPU are you using?\n\nThis is my code:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom functools import partial\nimport torch.utils.model_zoo as model_zoo\ndef conv3x3x3(in_planes, out_planes, stride=1):\n# 3x3x3 convolution with padding\nreturn nn.Conv3d(\nin_planes,\nout_planes,\nkernel_size=3,\nstride=stride,\npadding=1,\nbias=False)\ndef downsample_basic_block(x, planes, stride):\nout = F.avg_pool3d(x, kernel_size=1, stride=stride)\nzero_pads = torch.Tensor(\nout.size(0), planes - out.size(1), out.size(2), out.size(3),\nout.size(4)).zero_()\nif isinstance(out.data, torch.cuda.FloatTensor):\nzero_pads = zero_pads.cuda()\nout = Variable(torch.cat([out.data, zero_pads], dim=1))\n\nreturn out\n\nclass BasicBlock(nn.Module):\nexpansion = 1\ndef __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(BasicBlock, self).__init__()\n    self.conv1 = conv3x3x3(inplanes, planes, stride)\n    self.bn1 = nn.BatchNorm3d(planes)\n    self.relu = nn.ReLU(inplace=True)\n    self.conv2 = conv3x3x3(planes, planes)\n    self.bn2 = nn.BatchNorm3d(planes)\n    self.downsample = downsample\n    self.stride = stride\n\ndef forward(self, x):\n    residual = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n\n    if self.downsample is not None:\n        residual = self.downsample(x)\n\n    out += residual\n    out = self.relu(out)\n\n    return out\n\nclass Bottleneck(nn.Module):\nexpansion = 4\ndef __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(Bottleneck, self).__init__()\n    self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n    self.bn1 = nn.BatchNorm3d(planes)\n    self.conv2 = nn.Conv3d(\n        planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn2 = nn.BatchNorm3d(planes)\n    self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n    self.bn3 = nn.BatchNorm3d(planes * 4)\n    self.relu = nn.ReLU(inplace=True)\n    self.downsample = downsample\n    self.stride = stride\n\ndef forward(self, x):\n    residual = x\n\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.conv2(out)\n    out = self.bn2(out)\n    out = self.relu(out)\n\n    out = self.conv3(out)\n    out = self.bn3(out)\n\n    if self.downsample is not None:\n        residual = self.downsample(x)\n\n    out += residual\n    out = self.relu(out)\n\n    return out\n\nclass ResNet(nn.Module):\ndef __init__(self,\n             block,\n             layers,\n             sample_size,\n             sample_duration,\n             shortcut_type='B',\n             num_classes=400):\n    self.inplanes = 64\n    super(ResNet, self).__init__()\n    self.conv1 = nn.Conv3d(\n        3,\n        64,\n        kernel_size=7,\n        stride=(1, 2, 2),\n        padding=(3, 3, 3),\n        bias=False)\n    self.bn1 = nn.BatchNorm3d(64)\n    self.relu = nn.ReLU(inplace=True)\n    self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n    self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n    self.layer2 = self._make_layer(\n        block, 128, layers[1], shortcut_type, stride=2)\n    self.layer3 = self._make_layer(\n        block, 256, layers[2], shortcut_type, stride=2)\n    self.layer4 = self._make_layer(\n        block, 512, layers[3], shortcut_type, stride=2)\n\n    self.avgpool = nn.AvgPool3d((1, 7, 7), stride=1)\n    \n    self.conv1x1_1 = nn.Sequential(\n        nn.Conv3d(512, num_classes, (1, 1, 1))\n    )\n    \n\ndef _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        if shortcut_type == 'A':\n            downsample = partial(\n                downsample_basic_block,\n                planes=planes * block.expansion,\n                stride=stride)\n        else:\n            downsample = nn.Sequential(\n                nn.Conv3d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\ndef forward(self, x):\n    x = self.conv1(x)\n    x = self.bn1(x)\n    x = self.relu(x)\n    x = self.maxpool(x)\n\n    x = self.layer1(x)\n    x = self.layer2(x)\n    x = self.layer3(x)\n    x = self.layer4(x)\n\n\n    x = self.avgpool(x)\n   \n    x = self.conv1x1_1(x)\n    x = x.squeeze(2).squeeze(2).squeeze(2)\n\n    return x\n\ndef get_fine_tuning_parameters(model, ft_begin_index):\nif ft_begin_index == 0:\nreturn model.parameters()\nft_module_names = []\nfor i in range(ft_begin_index, 5):\n    ft_module_names.append('layer{}'.format(i))\nft_module_names.append('fc')\n\nparameters = []\nfor k, v in model.named_parameters():\n    for ft_module in ft_module_names:\n        if ft_module in k:\n            parameters.append({'params': v})\n            break\n    else:\n        parameters.append({'params': v, 'lr': 0.0})\n\nreturn parameters\n\ndef resnet10(**kwargs):\n\"\"\"Constructs a ResNet-18 model.\n\"\"\"\nmodel = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\nreturn model\ndef resnet18(**kwargs):\n\"\"\"Constructs a ResNet-18 model.\n\"\"\"\nmodel = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\nreturn model\nif name == 'main':\nimport torch\nmodel = resnet18(sample_size=224, sample_duration=16, num_classes=1)\nmodel = model.cuda()\nbs = 3\nfor i in range(100):\ndata = torch.randn(bs, 3, 16, 224, 224).cuda()\nc = model(data)\nc.sum().backward()\nMy GPU is TitanXp", "body": "> can you provide the shape/strides/dilation etc? Also what GPU are you using?\r\n\r\nThis is my code:\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\nimport math\r\nfrom functools import partial\r\n\r\n\r\nimport torch.utils.model_zoo as model_zoo\r\n\r\n\r\n\r\ndef conv3x3x3(in_planes, out_planes, stride=1):\r\n    # 3x3x3 convolution with padding\r\n    return nn.Conv3d(\r\n        in_planes,\r\n        out_planes,\r\n        kernel_size=3,\r\n        stride=stride,\r\n        padding=1,\r\n        bias=False)\r\n\r\n\r\ndef downsample_basic_block(x, planes, stride):\r\n    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\r\n    zero_pads = torch.Tensor(\r\n        out.size(0), planes - out.size(1), out.size(2), out.size(3),\r\n        out.size(4)).zero_()\r\n    if isinstance(out.data, torch.cuda.FloatTensor):\r\n        zero_pads = zero_pads.cuda()\r\n\r\n    out = Variable(torch.cat([out.data, zero_pads], dim=1))\r\n\r\n    return out\r\n\r\n\r\nclass BasicBlock(nn.Module):\r\n    expansion = 1\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(BasicBlock, self).__init__()\r\n        self.conv1 = conv3x3x3(inplanes, planes, stride)\r\n        self.bn1 = nn.BatchNorm3d(planes)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.conv2 = conv3x3x3(planes, planes)\r\n        self.bn2 = nn.BatchNorm3d(planes)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n\r\n        if self.downsample is not None:\r\n            residual = self.downsample(x)\r\n\r\n        out += residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\n\r\nclass Bottleneck(nn.Module):\r\n    expansion = 4\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(Bottleneck, self).__init__()\r\n        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\r\n        self.bn1 = nn.BatchNorm3d(planes)\r\n        self.conv2 = nn.Conv3d(\r\n            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n        self.bn2 = nn.BatchNorm3d(planes)\r\n        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\r\n        self.bn3 = nn.BatchNorm3d(planes * 4)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv3(out)\r\n        out = self.bn3(out)\r\n\r\n        if self.downsample is not None:\r\n            residual = self.downsample(x)\r\n\r\n        out += residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self,\r\n                 block,\r\n                 layers,\r\n                 sample_size,\r\n                 sample_duration,\r\n                 shortcut_type='B',\r\n                 num_classes=400):\r\n        self.inplanes = 64\r\n        super(ResNet, self).__init__()\r\n        self.conv1 = nn.Conv3d(\r\n            3,\r\n            64,\r\n            kernel_size=7,\r\n            stride=(1, 2, 2),\r\n            padding=(3, 3, 3),\r\n            bias=False)\r\n        self.bn1 = nn.BatchNorm3d(64)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\r\n        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\r\n        self.layer2 = self._make_layer(\r\n            block, 128, layers[1], shortcut_type, stride=2)\r\n        self.layer3 = self._make_layer(\r\n            block, 256, layers[2], shortcut_type, stride=2)\r\n        self.layer4 = self._make_layer(\r\n            block, 512, layers[3], shortcut_type, stride=2)\r\n\r\n        self.avgpool = nn.AvgPool3d((1, 7, 7), stride=1)\r\n        \r\n        self.conv1x1_1 = nn.Sequential(\r\n            nn.Conv3d(512, num_classes, (1, 1, 1))\r\n        )\r\n        \r\n\r\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            if shortcut_type == 'A':\r\n                downsample = partial(\r\n                    downsample_basic_block,\r\n                    planes=planes * block.expansion,\r\n                    stride=stride)\r\n            else:\r\n                downsample = nn.Sequential(\r\n                    nn.Conv3d(\r\n                        self.inplanes,\r\n                        planes * block.expansion,\r\n                        kernel_size=1,\r\n                        stride=stride,\r\n                        bias=False), nn.BatchNorm3d(planes * block.expansion))\r\n\r\n        layers = []\r\n        layers.append(block(self.inplanes, planes, stride, downsample))\r\n        self.inplanes = planes * block.expansion\r\n        for i in range(1, blocks):\r\n            layers.append(block(self.inplanes, planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n        x = self.maxpool(x)\r\n\r\n        x = self.layer1(x)\r\n        x = self.layer2(x)\r\n        x = self.layer3(x)\r\n        x = self.layer4(x)\r\n\r\n\r\n        x = self.avgpool(x)\r\n       \r\n        x = self.conv1x1_1(x)\r\n        x = x.squeeze(2).squeeze(2).squeeze(2)\r\n\r\n        return x\r\n\r\n\r\ndef get_fine_tuning_parameters(model, ft_begin_index):\r\n    if ft_begin_index == 0:\r\n        return model.parameters()\r\n        \r\n\r\n    ft_module_names = []\r\n    for i in range(ft_begin_index, 5):\r\n        ft_module_names.append('layer{}'.format(i))\r\n    ft_module_names.append('fc')\r\n\r\n    parameters = []\r\n    for k, v in model.named_parameters():\r\n        for ft_module in ft_module_names:\r\n            if ft_module in k:\r\n                parameters.append({'params': v})\r\n                break\r\n        else:\r\n            parameters.append({'params': v, 'lr': 0.0})\r\n\r\n    return parameters\r\n\r\n\r\ndef resnet10(**kwargs):\r\n    \"\"\"Constructs a ResNet-18 model.\r\n    \"\"\"\r\n    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\r\n    return model\r\n\r\n\r\ndef resnet18(**kwargs):\r\n    \"\"\"Constructs a ResNet-18 model.\r\n    \"\"\"\r\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\r\n    return model\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    import torch\r\n    model = resnet18(sample_size=224, sample_duration=16, num_classes=1)\r\n    model = model.cuda()\r\n    bs = 3\r\n    for i in range(100):\r\n        data = torch.randn(bs, 3, 16, 224, 224).cuda()\r\n        c = model(data)\r\n        c.sum().backward()\r\n    \r\nMy GPU is TitanXp"}