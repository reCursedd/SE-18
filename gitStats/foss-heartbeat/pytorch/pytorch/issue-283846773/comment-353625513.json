{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/353625513", "html_url": "https://github.com/pytorch/pytorch/issues/4293#issuecomment-353625513", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4293", "id": 353625513, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzYyNTUxMw==", "user": {"login": "floringogianu", "id": 1670348, "node_id": "MDQ6VXNlcjE2NzAzNDg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1670348?v=4", "gravatar_id": "", "url": "https://api.github.com/users/floringogianu", "html_url": "https://github.com/floringogianu", "followers_url": "https://api.github.com/users/floringogianu/followers", "following_url": "https://api.github.com/users/floringogianu/following{/other_user}", "gists_url": "https://api.github.com/users/floringogianu/gists{/gist_id}", "starred_url": "https://api.github.com/users/floringogianu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/floringogianu/subscriptions", "organizations_url": "https://api.github.com/users/floringogianu/orgs", "repos_url": "https://api.github.com/users/floringogianu/repos", "events_url": "https://api.github.com/users/floringogianu/events{/privacy}", "received_events_url": "https://api.github.com/users/floringogianu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-22T15:59:33Z", "updated_at": "2017-12-22T15:59:33Z", "author_association": "NONE", "body_html": "<p>I worked mostly with code that was using <code>multiprocessing</code> and shared <code>cuda</code> tensors between processes and I felt it happened most often with this kind of code, either when using single or multiple GPUs (don't know if NCCL was being involved - I was not using stuff like <code>torch.nn.DataParallel</code>).</p>\n<p>But colleagues confirmed this happening on single-process code also (stuff like doing inference through a pretrained VGG-net, etc.). Indeed all the machines where I've encountered this behavior were multi-GPU.</p>", "body_text": "I worked mostly with code that was using multiprocessing and shared cuda tensors between processes and I felt it happened most often with this kind of code, either when using single or multiple GPUs (don't know if NCCL was being involved - I was not using stuff like torch.nn.DataParallel).\nBut colleagues confirmed this happening on single-process code also (stuff like doing inference through a pretrained VGG-net, etc.). Indeed all the machines where I've encountered this behavior were multi-GPU.", "body": "I worked mostly with code that was using `multiprocessing` and shared `cuda` tensors between processes and I felt it happened most often with this kind of code, either when using single or multiple GPUs (don't know if NCCL was being involved - I was not using stuff like `torch.nn.DataParallel`). \r\n\r\nBut colleagues confirmed this happening on single-process code also (stuff like doing inference through a pretrained VGG-net, etc.). Indeed all the machines where I've encountered this behavior were multi-GPU."}