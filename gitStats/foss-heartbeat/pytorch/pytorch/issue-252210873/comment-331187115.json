{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/331187115", "html_url": "https://github.com/pytorch/pytorch/issues/2517#issuecomment-331187115", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2517", "id": 331187115, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTE4NzExNQ==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-21T15:10:17Z", "updated_at": "2017-09-21T15:10:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> Did you want to fix <code>torch.cuda.is_available()</code> to avoid initializing the CUDA driver as well? Because we actually have to return yes or no in this case (unlike seed which doesn't have to return anything), it will be difficult to do it unless we're willing to spawn a subprocess to do the test for us (and if that subprocess dies, we assume CUDA was already initialized and go ahead and call <code>cudaGetDeviceCount</code>.)</p>", "body_text": "@colesbury Did you want to fix torch.cuda.is_available() to avoid initializing the CUDA driver as well? Because we actually have to return yes or no in this case (unlike seed which doesn't have to return anything), it will be difficult to do it unless we're willing to spawn a subprocess to do the test for us (and if that subprocess dies, we assume CUDA was already initialized and go ahead and call cudaGetDeviceCount.)", "body": "@colesbury Did you want to fix `torch.cuda.is_available()` to avoid initializing the CUDA driver as well? Because we actually have to return yes or no in this case (unlike seed which doesn't have to return anything), it will be difficult to do it unless we're willing to spawn a subprocess to do the test for us (and if that subprocess dies, we assume CUDA was already initialized and go ahead and call `cudaGetDeviceCount`.)"}