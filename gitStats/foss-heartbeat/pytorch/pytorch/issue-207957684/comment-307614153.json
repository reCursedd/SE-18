{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/307614153", "html_url": "https://github.com/pytorch/pytorch/issues/755#issuecomment-307614153", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/755", "id": 307614153, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYxNDE1Mw==", "user": {"login": "PhilippPelz", "id": 1299153, "node_id": "MDQ6VXNlcjEyOTkxNTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1299153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilippPelz", "html_url": "https://github.com/PhilippPelz", "followers_url": "https://api.github.com/users/PhilippPelz/followers", "following_url": "https://api.github.com/users/PhilippPelz/following{/other_user}", "gists_url": "https://api.github.com/users/PhilippPelz/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilippPelz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilippPelz/subscriptions", "organizations_url": "https://api.github.com/users/PhilippPelz/orgs", "repos_url": "https://api.github.com/users/PhilippPelz/repos", "events_url": "https://api.github.com/users/PhilippPelz/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilippPelz/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-11T08:25:06Z", "updated_at": "2017-06-11T08:25:06Z", "author_association": "NONE", "body_html": "<p>This now runs:</p>\n<p>import torch as th<br>\nimport numpy as np</p>\n<p>a = np.array([1+1j,2+2j])<br>\nb = np.array([3+3j,4+4j])<br>\nath = th.from_numpy(a)<br>\nbth = th.from_numpy(b)<br>\nath_cuda = ath.cuda()<br>\nath_cuda += bth.cuda()<br>\nath = ath_cuda.cpu()<br>\nprint(ath.numpy())</p>\n<p>Out: [ 4.+4.j  6.+6.j]</p>\n<p>along with most of the math functions.<br>\nI'll add convenience functions and ffts over the next weeks. I guess there need to be tests for everything before you can merge this. If you know anyone else who is interested in complex tensors and would be willing to contribute to writing the tests, that would be awesome. This paper springs to mind: <a href=\"https://arxiv.org/abs/1705.09792\" rel=\"nofollow\">Deep Complex Networks</a>, maybe those guys would be interested.<br>\nI won't have the time to write all the tests on my own.</p>", "body_text": "This now runs:\nimport torch as th\nimport numpy as np\na = np.array([1+1j,2+2j])\nb = np.array([3+3j,4+4j])\nath = th.from_numpy(a)\nbth = th.from_numpy(b)\nath_cuda = ath.cuda()\nath_cuda += bth.cuda()\nath = ath_cuda.cpu()\nprint(ath.numpy())\nOut: [ 4.+4.j  6.+6.j]\nalong with most of the math functions.\nI'll add convenience functions and ffts over the next weeks. I guess there need to be tests for everything before you can merge this. If you know anyone else who is interested in complex tensors and would be willing to contribute to writing the tests, that would be awesome. This paper springs to mind: Deep Complex Networks, maybe those guys would be interested.\nI won't have the time to write all the tests on my own.", "body": "This now runs:\r\n\r\nimport torch as th\r\nimport numpy as np\r\n\r\na = np.array([1+1j,2+2j])\r\nb = np.array([3+3j,4+4j])\r\nath = th.from_numpy(a)\r\nbth = th.from_numpy(b)\r\nath_cuda = ath.cuda()\r\nath_cuda += bth.cuda()\r\nath = ath_cuda.cpu()\r\nprint(ath.numpy())\r\n\r\nOut: [ 4.+4.j  6.+6.j]\r\n\r\nalong with most of the math functions.\r\nI'll add convenience functions and ffts over the next weeks. I guess there need to be tests for everything before you can merge this. If you know anyone else who is interested in complex tensors and would be willing to contribute to writing the tests, that would be awesome. This paper springs to mind: [Deep Complex Networks](https://arxiv.org/abs/1705.09792), maybe those guys would be interested.\r\nI won't have the time to write all the tests on my own.\r\n"}