{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4213", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4213/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4213/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4213/events", "html_url": "https://github.com/pytorch/pytorch/issues/4213", "id": 282675007, "node_id": "MDU6SXNzdWUyODI2NzUwMDc=", "number": 4213, "title": "index_add_ & index_copy_ do not properly check tensor sizes on GPU", "user": {"login": "yongjik", "id": 31876421, "node_id": "MDQ6VXNlcjMxODc2NDIx", "avatar_url": "https://avatars2.githubusercontent.com/u/31876421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongjik", "html_url": "https://github.com/yongjik", "followers_url": "https://api.github.com/users/yongjik/followers", "following_url": "https://api.github.com/users/yongjik/following{/other_user}", "gists_url": "https://api.github.com/users/yongjik/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongjik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongjik/subscriptions", "organizations_url": "https://api.github.com/users/yongjik/orgs", "repos_url": "https://api.github.com/users/yongjik/repos", "events_url": "https://api.github.com/users/yongjik/events{/privacy}", "received_events_url": "https://api.github.com/users/yongjik/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-17T07:04:27Z", "updated_at": "2018-01-04T12:17:03Z", "closed_at": "2018-01-04T12:17:03Z", "author_association": "CONTRIBUTOR", "body_html": "<pre><code>A = torch.zeros(5, 4)\nB = torch.arange(0, 9).view(3, 3)\nC = torch.arange(0, 15).view(3, 5)\nidxs = torch.LongTensor([0, 2, 4])\n\nA.index_add_(0, idxs, B)\n# RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\n  [3] to have the same number of elements, but got 4, 4 and 3 elements\n  respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\n\nA.index_add_(0, idxs, C)\n# RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\n  [5] to have the same number of elements, but got 4, 4 and 5 elements\n  respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\n</code></pre>\n<p>So far so good.  But if we use CUDA...</p>\n<pre><code>A = torch.zeros(5, 4).cuda()\nB = torch.arange(0, 9).view(3, 3).cuda()\nC = torch.arange(0, 15).view(3, 5).cuda()\nidxs = torch.LongTensor([0, 2, 4]).cuda()\n\nA.index_add_(0, idxs, B)\nprint(A)\n#    0  1  2  0\n#    0  0  0  0\n#    3  4  5  0\n#    0  0  0  0\n#    6  7  8  0\n#   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n</code></pre>\n<p>OK, this looks wrong...</p>\n<pre><code>A.zero_()\nA.index_add_(0, idxs, C)\nprint(A)\n#     0   1   2   3\n#     4   0   0   0\n#     5   6   7   8\n#     9   0   0   0\n#    10  11  12  13\n#   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n</code></pre>\n<p>Now this looks definitely wrong.</p>\n<p>Increase C's dimension to something like (3, 500), and it overwrites other tensors or triggers asserts.</p>\n<p>Same thing happens with index_copy_.</p>", "body_text": "A = torch.zeros(5, 4)\nB = torch.arange(0, 9).view(3, 3)\nC = torch.arange(0, 15).view(3, 5)\nidxs = torch.LongTensor([0, 2, 4])\n\nA.index_add_(0, idxs, B)\n# RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\n  [3] to have the same number of elements, but got 4, 4 and 3 elements\n  respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\n\nA.index_add_(0, idxs, C)\n# RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\n  [5] to have the same number of elements, but got 4, 4 and 5 elements\n  respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\n\nSo far so good.  But if we use CUDA...\nA = torch.zeros(5, 4).cuda()\nB = torch.arange(0, 9).view(3, 3).cuda()\nC = torch.arange(0, 15).view(3, 5).cuda()\nidxs = torch.LongTensor([0, 2, 4]).cuda()\n\nA.index_add_(0, idxs, B)\nprint(A)\n#    0  1  2  0\n#    0  0  0  0\n#    3  4  5  0\n#    0  0  0  0\n#    6  7  8  0\n#   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n\nOK, this looks wrong...\nA.zero_()\nA.index_add_(0, idxs, C)\nprint(A)\n#     0   1   2   3\n#     4   0   0   0\n#     5   6   7   8\n#     9   0   0   0\n#    10  11  12  13\n#   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n\nNow this looks definitely wrong.\nIncrease C's dimension to something like (3, 500), and it overwrites other tensors or triggers asserts.\nSame thing happens with index_copy_.", "body": "    A = torch.zeros(5, 4)\r\n    B = torch.arange(0, 9).view(3, 3)\r\n    C = torch.arange(0, 15).view(3, 5)\r\n    idxs = torch.LongTensor([0, 2, 4])\r\n\r\n    A.index_add_(0, idxs, B)\r\n    # RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\r\n      [3] to have the same number of elements, but got 4, 4 and 3 elements\r\n      respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\r\n\r\n    A.index_add_(0, idxs, C)\r\n    # RuntimeError: inconsistent tensor size, expected r_ [4], t [4] and src\r\n      [5] to have the same number of elements, but got 4, 4 and 5 elements\r\n      respectively at (...)/aten/src/TH/generic/THTensorMath.c:1008\r\n\r\nSo far so good.  But if we use CUDA...\r\n\r\n    A = torch.zeros(5, 4).cuda()\r\n    B = torch.arange(0, 9).view(3, 3).cuda()\r\n    C = torch.arange(0, 15).view(3, 5).cuda()\r\n    idxs = torch.LongTensor([0, 2, 4]).cuda()\r\n\r\n    A.index_add_(0, idxs, B)\r\n    print(A)\r\n    #    0  1  2  0\r\n    #    0  0  0  0\r\n    #    3  4  5  0\r\n    #    0  0  0  0\r\n    #    6  7  8  0\r\n    #   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\r\n\r\nOK, this looks wrong...\r\n\r\n    A.zero_()\r\n    A.index_add_(0, idxs, C)\r\n    print(A)\r\n    #     0   1   2   3\r\n    #     4   0   0   0\r\n    #     5   6   7   8\r\n    #     9   0   0   0\r\n    #    10  11  12  13\r\n    #   [torch.cuda.FloatTensor of size 5x4 (GPU 0)]\r\n\r\nNow this looks definitely wrong.\r\n\r\nIncrease C's dimension to something like (3, 500), and it overwrites other tensors or triggers asserts.\r\n\r\nSame thing happens with index_copy_.\r\n"}