{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/308277445", "html_url": "https://github.com/pytorch/pytorch/issues/1787#issuecomment-308277445", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1787", "id": 308277445, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODI3NzQ0NQ==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-13T23:30:34Z", "updated_at": "2017-06-13T23:30:34Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The issue is that the Broadcast code gets generated at the cwrap level, which only deals with tensors, so autograd's expand never ends up getting invoked.</p>\n<p>It would be nice if this were to happen automatically, but I don't see an easy way to do it; would maybe take something like unifying tensors/Variables or rewriting some of autograd in C.</p>\n<p>This issue is conceptually similar to how pointwise operations of different shapes are handled in autograd, e.g.: <div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/5a63a6d47fb20f65546c8d4a9195f04a8ea559c0/torch/autograd/_functions/basic_ops.py#L55\">pytorch/torch/autograd/_functions/basic_ops.py</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 55\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/5a63a6d47fb20f65546c8d4a9195f04a8ea559c0\">5a63a6d</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L55\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"55\"></td>\n          <td id=\"LC55\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> <span class=\"pl-k\">return</span> grad_output.mul(b), maybe_view(grad_output.mul(a), ctx.b_size) </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n where the backwards has to reshape the output based on the tensor function changing the shape of the inputs.</p>\n<p>Probably the easiest way to implement this is just to add expand calls to the relevant functions in variable.py; sort of unfortunate that each function needs to be modified but I don't see an easier way.</p>", "body_text": "The issue is that the Broadcast code gets generated at the cwrap level, which only deals with tensors, so autograd's expand never ends up getting invoked.\nIt would be nice if this were to happen automatically, but I don't see an easy way to do it; would maybe take something like unifying tensors/Variables or rewriting some of autograd in C.\nThis issue is conceptually similar to how pointwise operations of different shapes are handled in autograd, e.g.: \n  \n    \n      pytorch/torch/autograd/_functions/basic_ops.py\n    \n    \n         Line 55\n      in\n      5a63a6d\n    \n    \n    \n    \n\n        \n          \n           return grad_output.mul(b), maybe_view(grad_output.mul(a), ctx.b_size) \n        \n    \n  \n\n where the backwards has to reshape the output based on the tensor function changing the shape of the inputs.\nProbably the easiest way to implement this is just to add expand calls to the relevant functions in variable.py; sort of unfortunate that each function needs to be modified but I don't see an easier way.", "body": "The issue is that the Broadcast code gets generated at the cwrap level, which only deals with tensors, so autograd's expand never ends up getting invoked.\r\n\r\nIt would be nice if this were to happen automatically, but I don't see an easy way to do it; would maybe take something like unifying tensors/Variables or rewriting some of autograd in C.\r\n\r\nThis issue is conceptually similar to how pointwise operations of different shapes are handled in autograd, e.g.: https://github.com/pytorch/pytorch/blob/5a63a6d47fb20f65546c8d4a9195f04a8ea559c0/torch/autograd/_functions/basic_ops.py#L55 where the backwards has to reshape the output based on the tensor function changing the shape of the inputs.\r\n\r\nProbably the easiest way to implement this is just to add expand calls to the relevant functions in variable.py; sort of unfortunate that each function needs to be modified but I don't see an easier way."}