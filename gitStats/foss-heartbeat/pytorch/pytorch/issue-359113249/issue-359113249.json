{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11518", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11518/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11518/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11518/events", "html_url": "https://github.com/pytorch/pytorch/issues/11518", "id": 359113249, "node_id": "MDU6SXNzdWUzNTkxMTMyNDk=", "number": 11518, "title": "Pytorch v0.4.1 fails to build on Nvidia Drive PX2", "user": {"login": "jeff-hawke", "id": 36192189, "node_id": "MDQ6VXNlcjM2MTkyMTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/36192189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeff-hawke", "html_url": "https://github.com/jeff-hawke", "followers_url": "https://api.github.com/users/jeff-hawke/followers", "following_url": "https://api.github.com/users/jeff-hawke/following{/other_user}", "gists_url": "https://api.github.com/users/jeff-hawke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeff-hawke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeff-hawke/subscriptions", "organizations_url": "https://api.github.com/users/jeff-hawke/orgs", "repos_url": "https://api.github.com/users/jeff-hawke/repos", "events_url": "https://api.github.com/users/jeff-hawke/events{/privacy}", "received_events_url": "https://api.github.com/users/jeff-hawke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-11T15:59:02Z", "updated_at": "2018-09-20T16:27:18Z", "closed_at": "2018-09-20T16:27:18Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Building Pytorch 0.4.1 from source on a Nvidia Drive PX2 (Driveworks 0.6) currently does not work, due to an odd Nvidia print statement which breaks the CUDA architecture detection: running any CUDA process results in the following print statement to std out:<br>\n<code>nvrm_gpu: Bug 200215060 workaround enabled.</code><br>\nUnfortunately there's nothing I can do (rather, that I've found) to work around this or suppress it - it's part of the CUDA 9.0 install which comes with the Driveworks SDK for these PX2s.</p>\n<p>This breaks the CUDA architecture detection in <code>&lt;pytorch_root&gt;/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake</code> <a href=\"https://github.com/pytorch/pytorch/blob/v0.4.1/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake#L56\">here</a> from function <code>CUDA_DETECT_INSTALLED_GPUS</code>:</p>\n<ul>\n<li>This function writes and compiles a short cpp program which prints the CUDA device architectures, and caches the program output in CMakeCache.</li>\n<li>Instead of printing <code>6.1 6.2</code> to stdout as expected on this device, this additional print statement results in <code>CUDA_GPU_DETECT_OUTPUT</code> being set to: <code>nvrm_gpu: Bug 200215060 workaround enabled.\\n6.1 6.2</code></li>\n<li>This newline breaks CMakeCache, which doesn't handle newlines in cached variables.</li>\n<li>In addition, the output results in a number of <code>message(SEND_ERROR &lt;&gt;)</code> from each parsed string (stating that 'nvrm_gpu:', 'Bug', '200215060', ...  aren't valid architectures, understandably).</li>\n</ul>\n<p>This can be fixed by adding a one-line addition to <a href=\"https://github.com/pytorch/pytorch/blob/v0.4.1/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake#L90\">line 90</a> of this .cmake file, parsing the program output to ensure it has a list of sensible possible architecture version in the <code>compute_capabilities</code> variable (floats, e.g, 6.1, 6.2, etc)<br>\n<code>string(REGEX MATCHALL \"[0-9]+\\\\.[0-9]+\" compute_capabilities \"${compute_capabilities}\")</code></p>\n<p>With this patch, pytorch 0.4.1 builds happily.</p>\n<p>If you have any other suggestions for a fix or workaround, I'd be happy to try them.</p>\n<h2>Code example</h2>\n<p>Reproduceable on multiple PX2s with this version of driveworks, python 3.5, a fresh checkout of 0.4.1, and the following install command:</p>\n<p><code>MAX_JOBS=1 python3 setup.py install --user</code></p>\n<h2>System Info</h2>\n<p>CUDA used to build PyTorch: 9.0.225<br>\nOS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1<br>\nPython version: 3.5<br>\nCUDA runtime version: 9.0.225<br>\ncuDNN version: Probably one of the following:<br>\n/usr/lib/aarch64-linux-gnu/libcudnn.so.7.0.4<br>\n/usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a</p>", "body_text": "Issue description\nBuilding Pytorch 0.4.1 from source on a Nvidia Drive PX2 (Driveworks 0.6) currently does not work, due to an odd Nvidia print statement which breaks the CUDA architecture detection: running any CUDA process results in the following print statement to std out:\nnvrm_gpu: Bug 200215060 workaround enabled.\nUnfortunately there's nothing I can do (rather, that I've found) to work around this or suppress it - it's part of the CUDA 9.0 install which comes with the Driveworks SDK for these PX2s.\nThis breaks the CUDA architecture detection in <pytorch_root>/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake here from function CUDA_DETECT_INSTALLED_GPUS:\n\nThis function writes and compiles a short cpp program which prints the CUDA device architectures, and caches the program output in CMakeCache.\nInstead of printing 6.1 6.2 to stdout as expected on this device, this additional print statement results in CUDA_GPU_DETECT_OUTPUT being set to: nvrm_gpu: Bug 200215060 workaround enabled.\\n6.1 6.2\nThis newline breaks CMakeCache, which doesn't handle newlines in cached variables.\nIn addition, the output results in a number of message(SEND_ERROR <>) from each parsed string (stating that 'nvrm_gpu:', 'Bug', '200215060', ...  aren't valid architectures, understandably).\n\nThis can be fixed by adding a one-line addition to line 90 of this .cmake file, parsing the program output to ensure it has a list of sensible possible architecture version in the compute_capabilities variable (floats, e.g, 6.1, 6.2, etc)\nstring(REGEX MATCHALL \"[0-9]+\\\\.[0-9]+\" compute_capabilities \"${compute_capabilities}\")\nWith this patch, pytorch 0.4.1 builds happily.\nIf you have any other suggestions for a fix or workaround, I'd be happy to try them.\nCode example\nReproduceable on multiple PX2s with this version of driveworks, python 3.5, a fresh checkout of 0.4.1, and the following install command:\nMAX_JOBS=1 python3 setup.py install --user\nSystem Info\nCUDA used to build PyTorch: 9.0.225\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.5\nCUDA runtime version: 9.0.225\ncuDNN version: Probably one of the following:\n/usr/lib/aarch64-linux-gnu/libcudnn.so.7.0.4\n/usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a", "body": "## Issue description\r\n\r\nBuilding Pytorch 0.4.1 from source on a Nvidia Drive PX2 (Driveworks 0.6) currently does not work, due to an odd Nvidia print statement which breaks the CUDA architecture detection: running any CUDA process results in the following print statement to std out:\r\n`nvrm_gpu: Bug 200215060 workaround enabled.`\r\nUnfortunately there's nothing I can do (rather, that I've found) to work around this or suppress it - it's part of the CUDA 9.0 install which comes with the Driveworks SDK for these PX2s.\r\n\r\nThis breaks the CUDA architecture detection in `<pytorch_root>/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake` [here](https://github.com/pytorch/pytorch/blob/v0.4.1/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake#L56) from function `CUDA_DETECT_INSTALLED_GPUS`:\r\n- This function writes and compiles a short cpp program which prints the CUDA device architectures, and caches the program output in CMakeCache. \r\n- Instead of printing `6.1 6.2` to stdout as expected on this device, this additional print statement results in `CUDA_GPU_DETECT_OUTPUT` being set to: `nvrm_gpu: Bug 200215060 workaround enabled.\\n6.1 6.2` \r\n- This newline breaks CMakeCache, which doesn't handle newlines in cached variables.\r\n- In addition, the output results in a number of `message(SEND_ERROR <>)` from each parsed string (stating that 'nvrm_gpu:', 'Bug', '200215060', ...  aren't valid architectures, understandably).\r\n\r\nThis can be fixed by adding a one-line addition to [line 90](https://github.com/pytorch/pytorch/blob/v0.4.1/cmake/Modules_CUDA_fix/upstream/FindCUDA/select_compute_arch.cmake#L90) of this .cmake file, parsing the program output to ensure it has a list of sensible possible architecture version in the `compute_capabilities` variable (floats, e.g, 6.1, 6.2, etc)\r\n`string(REGEX MATCHALL \"[0-9]+\\\\.[0-9]+\" compute_capabilities \"${compute_capabilities}\")`\r\n\r\nWith this patch, pytorch 0.4.1 builds happily.\r\n\r\nIf you have any other suggestions for a fix or workaround, I'd be happy to try them.\r\n\r\n## Code example\r\n\r\nReproduceable on multiple PX2s with this version of driveworks, python 3.5, a fresh checkout of 0.4.1, and the following install command:\r\n\r\n`MAX_JOBS=1 python3 setup.py install --user`\r\n\r\n## System Info\r\nCUDA used to build PyTorch: 9.0.225\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\nPython version: 3.5\r\nCUDA runtime version: 9.0.225\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/aarch64-linux-gnu/libcudnn.so.7.0.4\r\n/usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a\r\n"}