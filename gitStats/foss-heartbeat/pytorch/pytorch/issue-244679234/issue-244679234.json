{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2178", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2178/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2178/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2178/events", "html_url": "https://github.com/pytorch/pytorch/issues/2178", "id": 244679234, "node_id": "MDU6SXNzdWUyNDQ2NzkyMzQ=", "number": 2178, "title": "Problem when using DataLoader with a 1-dimensional FloatTensor", "user": {"login": "benjamin-work", "id": 29862381, "node_id": "MDQ6VXNlcjI5ODYyMzgx", "avatar_url": "https://avatars1.githubusercontent.com/u/29862381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benjamin-work", "html_url": "https://github.com/benjamin-work", "followers_url": "https://api.github.com/users/benjamin-work/followers", "following_url": "https://api.github.com/users/benjamin-work/following{/other_user}", "gists_url": "https://api.github.com/users/benjamin-work/gists{/gist_id}", "starred_url": "https://api.github.com/users/benjamin-work/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benjamin-work/subscriptions", "organizations_url": "https://api.github.com/users/benjamin-work/orgs", "repos_url": "https://api.github.com/users/benjamin-work/repos", "events_url": "https://api.github.com/users/benjamin-work/events{/privacy}", "received_events_url": "https://api.github.com/users/benjamin-work/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-07-21T14:06:17Z", "updated_at": "2017-09-01T07:30:09Z", "closed_at": "2017-09-01T07:30:08Z", "author_association": "NONE", "body_html": "<p>When I use <code>DataLoader</code> with a 1-dimensional <code>FloatTensor</code>, the resulting batches will be <code>DoubleTensor</code>. Here is a snippet:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> DataLoader, TensorDataset\n<span class=\"pl-k\">from</span> torch.utils.data.dataloader <span class=\"pl-k\">import</span> default_collate\n\nX <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">10</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 2-dimensional</span>\ny <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">100</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1-dimensional</span>\n\n<span class=\"pl-c1\">type</span>(X), <span class=\"pl-c1\">type</span>(y)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> (torch.FloatTensor, torch.FloatTensor)  &lt;- so far so good</span>\n\ndataset <span class=\"pl-k\">=</span> TensorDataset(X, y)\nloader <span class=\"pl-k\">=</span> DataLoader(dataset, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>)\nxx, yy <span class=\"pl-k\">=</span> <span class=\"pl-c1\">next</span>(<span class=\"pl-c1\">iter</span>(loader))\n<span class=\"pl-c1\">type</span>(xx), <span class=\"pl-c1\">type</span>(yy)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> (torch.FloatTensor, torch.DoubleTensor)  &lt;- unexpected</span></pre></div>\n<p>This was unexpected, since the incoming <code>y</code> is float and its batches are double.</p>\n<p>The reason for this behavior seems to be that <code>DataLoaderIter</code> sends each row separately to <code>default_collate</code>. A row from the dataset in this case is a tuple of <code>FloatTensor</code> (from <code>X</code>) and float (from <code>y</code>). <code>default_collate</code> hits the last condition and transposes the data. For <code>X</code>, this is okay, but <code>y</code> now becomes a list of floats, which <code>default_collate</code> converts to a <code>DoubleTensor</code>.</p>\n<p>This behavior can be replicated like this:</p>\n<pre><code>xi, yi = default_collate([(X[i], y[i]) for i in range(100)])\ntype(xi), type(yi)  # (torch.FloatTensor, torch.DoubleTensor)\n</code></pre>\n<p>I'm not sure whether this is a bug or a user error.</p>", "body_text": "When I use DataLoader with a 1-dimensional FloatTensor, the resulting batches will be DoubleTensor. Here is a snippet:\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data.dataloader import default_collate\n\nX = torch.zeros(100, 10)  # 2-dimensional\ny = torch.zeros(100)  # 1-dimensional\n\ntype(X), type(y)  # (torch.FloatTensor, torch.FloatTensor)  <- so far so good\n\ndataset = TensorDataset(X, y)\nloader = DataLoader(dataset, batch_size=10)\nxx, yy = next(iter(loader))\ntype(xx), type(yy)  # (torch.FloatTensor, torch.DoubleTensor)  <- unexpected\nThis was unexpected, since the incoming y is float and its batches are double.\nThe reason for this behavior seems to be that DataLoaderIter sends each row separately to default_collate. A row from the dataset in this case is a tuple of FloatTensor (from X) and float (from y). default_collate hits the last condition and transposes the data. For X, this is okay, but y now becomes a list of floats, which default_collate converts to a DoubleTensor.\nThis behavior can be replicated like this:\nxi, yi = default_collate([(X[i], y[i]) for i in range(100)])\ntype(xi), type(yi)  # (torch.FloatTensor, torch.DoubleTensor)\n\nI'm not sure whether this is a bug or a user error.", "body": "When I use `DataLoader` with a 1-dimensional `FloatTensor`, the resulting batches will be `DoubleTensor`. Here is a snippet:\r\n\r\n```python\r\nimport torch\r\nfrom torch.utils.data import DataLoader, TensorDataset\r\nfrom torch.utils.data.dataloader import default_collate\r\n\r\nX = torch.zeros(100, 10)  # 2-dimensional\r\ny = torch.zeros(100)  # 1-dimensional\r\n\r\ntype(X), type(y)  # (torch.FloatTensor, torch.FloatTensor)  <- so far so good\r\n\r\ndataset = TensorDataset(X, y)\r\nloader = DataLoader(dataset, batch_size=10)\r\nxx, yy = next(iter(loader))\r\ntype(xx), type(yy)  # (torch.FloatTensor, torch.DoubleTensor)  <- unexpected\r\n```\r\n\r\nThis was unexpected, since the incoming `y` is float and its batches are double.\r\n\r\nThe reason for this behavior seems to be that `DataLoaderIter` sends each row separately to `default_collate`. A row from the dataset in this case is a tuple of `FloatTensor` (from `X`) and float (from `y`). `default_collate` hits the last condition and transposes the data. For `X`, this is okay, but `y` now becomes a list of floats, which `default_collate` converts to a `DoubleTensor`.\r\n\r\nThis behavior can be replicated like this:\r\n\r\n```\r\nxi, yi = default_collate([(X[i], y[i]) for i in range(100)])\r\ntype(xi), type(yi)  # (torch.FloatTensor, torch.DoubleTensor)\r\n```\r\n\r\nI'm not sure whether this is a bug or a user error."}