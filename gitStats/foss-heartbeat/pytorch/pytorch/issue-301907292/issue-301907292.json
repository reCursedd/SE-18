{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5534", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5534/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5534/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5534/events", "html_url": "https://github.com/pytorch/pytorch/issues/5534", "id": 301907292, "node_id": "MDU6SXNzdWUzMDE5MDcyOTI=", "number": 5534, "title": "Freeing a deep computation graph causes a stack overflow", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-03-02T21:15:13Z", "updated_at": "2018-04-27T19:49:59Z", "closed_at": "2018-04-27T19:49:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The code below will segfault due to a stack overflow. If the computation graph is very linear, like the below, such that freeing a Function leads to the immediate free of another Function, a stack overflow can occur.</p>\n<p>This stack overflow occurs some ~16% earlier on master than on v0.3.1.</p>\n<pre><code>import torch\nfrom torch.autograd import Variable\n\ndef test(n):\n    # In the second of two loops, the computation graph from the first is freed\n    for j in range(0, 2):\n        x = Variable(torch.FloatTensor(range(9)), requires_grad=True) \n        time_step = 0.002\n        y = x.clone()\n        \n        # build deeply nested computation graph\n        for i in range(n):\n            y = y + y*time_step    \n        print('Loop: {}'.format(j))\n\n# Smallest n such that test(n) causes a stack overflow\n\n# On 0.3.1 from conda install\ntest(65461)\n\n# On master\ntest(52330)\n</code></pre>\n<p>I'm looking into fixing it.</p>", "body_text": "The code below will segfault due to a stack overflow. If the computation graph is very linear, like the below, such that freeing a Function leads to the immediate free of another Function, a stack overflow can occur.\nThis stack overflow occurs some ~16% earlier on master than on v0.3.1.\nimport torch\nfrom torch.autograd import Variable\n\ndef test(n):\n    # In the second of two loops, the computation graph from the first is freed\n    for j in range(0, 2):\n        x = Variable(torch.FloatTensor(range(9)), requires_grad=True) \n        time_step = 0.002\n        y = x.clone()\n        \n        # build deeply nested computation graph\n        for i in range(n):\n            y = y + y*time_step    \n        print('Loop: {}'.format(j))\n\n# Smallest n such that test(n) causes a stack overflow\n\n# On 0.3.1 from conda install\ntest(65461)\n\n# On master\ntest(52330)\n\nI'm looking into fixing it.", "body": "The code below will segfault due to a stack overflow. If the computation graph is very linear, like the below, such that freeing a Function leads to the immediate free of another Function, a stack overflow can occur. \r\n\r\nThis stack overflow occurs some ~16% earlier on master than on v0.3.1.\r\n```\r\nimport torch\r\nfrom torch.autograd import Variable\r\n\r\ndef test(n):\r\n    # In the second of two loops, the computation graph from the first is freed\r\n    for j in range(0, 2):\r\n        x = Variable(torch.FloatTensor(range(9)), requires_grad=True) \r\n        time_step = 0.002\r\n        y = x.clone()\r\n        \r\n        # build deeply nested computation graph\r\n        for i in range(n):\r\n            y = y + y*time_step    \r\n        print('Loop: {}'.format(j))\r\n\r\n# Smallest n such that test(n) causes a stack overflow\r\n\r\n# On 0.3.1 from conda install\r\ntest(65461)\r\n\r\n# On master\r\ntest(52330)\r\n```\r\n\r\nI'm looking into fixing it."}