{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9278", "id": 200193670, "node_id": "MDExOlB1bGxSZXF1ZXN0MjAwMTkzNjcw", "html_url": "https://github.com/pytorch/pytorch/pull/9278", "diff_url": "https://github.com/pytorch/pytorch/pull/9278.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9278.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9278", "number": 9278, "state": "closed", "locked": false, "title": "Unify THAllocator and THCDeviceAllocator with at::Allocator/Deleter", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Stacked on #9148\r\n\r\n```\r\nThe design might look a little strange, but there were a lot of\r\nconstraints feeding into it:\r\n\r\n- It must support the reallocation usage-pattern, where, given\r\n  an existing Storage, we allocate a new region of memory,\r\n  copy the existing data to it, and then deallocate the old\r\n  region of memory.\r\n\r\n- Creation of a deleter for memory MUST avoid dynamic allocations\r\n  in the common case.  We've done some benchmarking in Caffe2\r\n  where dynamic allocation for deleters is ruinously expensive,\r\n  and it's really hard to avoid these performance tarpits in\r\n  very general function wrappers like std::function or\r\n  folly::Function (while benchmarking this, we discovered that\r\n  folly::Function's move constructor was way more expensive\r\n  than it should be).\r\n\r\n- We need to be able to deallocate data that comes from external\r\n  sources, e.g., dlpack and numpy tensors.  Most notably,\r\n  you often cannot deallocate these with merely the void*\r\n  data pointer; you need some extra, out-of-band information\r\n  (e.g., the managing struct) to deallocate it.  Sometimes,\r\n  you may even want to resize data living in an external source!\r\n\r\n- The \"core\" allocators need to support being wrapped in a Thrust\r\n  allocator, so you need to be implement the following two functions:\r\n\r\n    char* allocate(size_t);\r\n    void deallocate(char*, size_t);\r\n\r\n- We need to support tensors which contain non-POD, non-trivially\r\n  copyable data; specifically tensors of std::string.  This is\r\n  an upcoming requirement from Caffe2.  It's dirty AF, but\r\n  it's really useful.\r\n\r\nHere is the billing of changes:\r\n\r\n- Built-in support for realloc() has been DROPPED ENTIRELY.\r\n  Instead, you're expected to allocate and then copy from\r\n  the old memory to the new memory if you want to do a\r\n  reallocation.  This is what you'd generally have expected\r\n  to occur; and axing realloc() from the design lets us avoid\r\n  some tricky correctness issues with std::realloc(), namely\r\n  the fact that we must refuse the realloc if the type of the\r\n  elements are not trivially copyeable.  If it really matters,\r\n  we can add this back, but there really needs to be a good\r\n  explanation WHY you need fast resizing reallocations (by in\r\n  large, people don't resize their storages, and it should\r\n  be acceptable to have a performance degradation when they\r\n  do).\r\n\r\n- TH_STORAGE_FREEMEM is no more; instead, if you want a\r\n  storage which doesn't free its result, you just give it\r\n  an empty deleter.\r\n\r\n- What we used to call an \"allocator\" has been split into two\r\n  concepts, an allocator and a deleter.  True to their names,\r\n  allocators know how to allocate, and deleters know how to\r\n  delete the things allocators produce.\r\n\r\n  This is NOT just a simple split of the previous\r\n  THAllocator/THCAllocator design:\r\n\r\n    - Unlike previously, where the \"context\" of an THAllocator\r\n      was allocate prior to even allocating, and then used\r\n      for the entire lifetime of the storage (even if a\r\n      reallocation happens), the notion of context has been\r\n      isolated to the Deleter (a Deleter plus a context is\r\n      a BoundDeleter); this context is *freshly manufactured*\r\n      when you do an allocation with an Allocator.\r\n\r\n    - We definitely need some sort of context for deleters,\r\n      because sometimes we need more information than the data\r\n      pointer itself to properly deallocate.  A simple example\r\n      is a dlpack tensor; to free the data, we need an\r\n      enclosing struct which contains the actual function pointer\r\n      to perform deletion.\r\n\r\n      Allocation of the deleter at *allocation* time allows\r\n      us to support some resizing use-cases in the absence of\r\n      built-in support for realloc().  If a context lifetime\r\n      is tied to a storage, there's no where to put a second\r\n      context for temporary memory before you perform a copy\r\n      from old to new.\r\n\r\n    - By default, allocators don't support \"raw\" allocations\r\n      and deallocations with raw pointers.  This is because\r\n      some allocations may return a different context every\r\n      time, in which case you need to reconstruct the context\r\n      at delete time (because all you got was a void*, not\r\n      a unique_ptr that carries the deleter).\r\n\r\n- THCDeviceAllocator has a few more changes.\r\n\r\n    - It used to return a cudaError_t.  Now, allocators\r\n      are expected to check the error status immediately and throw\r\n      an exception if there was an error.  It turns out that this\r\n      is what was immediately done after all occurrences of\r\n      allocate/release, so it wasn't a big deal (although some\r\n      subsidiary interfaces had to themselves be converted to\r\n      not return cudaError_t).\r\n\r\n      There is one notable exception to this, and it is how\r\n      we handle CUDA OOM: if this occurs, we attempt to return\r\n      unused memory to the system and try again.  This is now\r\n      handled by a catch-all try-catch block.  The cost of\r\n      catching the exception is probably the least of your worries\r\n      if you're about to OOM.\r\n\r\n    - It used to take the CUDA stream to perform the allocation\r\n      on as an argument.  However, it turned out that all call\r\n      sites, this stream was the stream for the current device.\r\n      So we can push this into the allocator (and the choice,\r\n      in the future, could be made explicitly by twiddling\r\n      thread local state.)\r\n\r\n    - It held two extra methods, emptyCache and cacheInfo, specifically\r\n      for interacting with some state in THCCachingAllocator.\r\n      But this \"generality\" was a lie, since THCCachingAllocator\r\n      was the only allocator that actually implemented these\r\n      methods, and there is actually a bunch of code in THC\r\n      which assumes that it is the caching allocator that is\r\n      the underlying allocator for CUDA allocations.  So I\r\n      folded these two methods into this interface as\r\n      THCCachingAllocator_emptyCache and THCCachingAllocator_cacheInfo.\r\n\r\n    - It held its context directly inside the THCDeviceAllocator\r\n      struct.  This context has been moved out into whatever\r\n      is holding the at::Allocator*.\r\n\r\n- The APIs for getting at allocators/deleters is now a little different.\r\n\r\n    - Previously there were a bunch of static variables you could get\r\n      the address of (e.g., &THDefaultAllocator); now there is a\r\n      function getTHDefaultAllocator().\r\n\r\n    - Some \"allocators\" didn't actually know how to allocate (e.g.,\r\n      the IPC \"allocator\").  These have been deleted; you only have\r\n      deleters for these allocators now.\r\n\r\n    - Deleters have a convention that there is a make() static\r\n      method, which will construct an appropriate at::BoundDeleter\r\n      for that method (they take as arguments any context they need).\r\n\r\n- Storage sharing was a lot of work to wrangle, but I think I've\r\n  tamed the beast.\r\n\r\n    - Deleters for storage sharing (and some other deleters) follow\r\n      the convention that their context is dynamically allocated memory\r\n      whose lifetime is tied to the data in question.  So many\r\n      invocations of Deleter::make(ctx) actually *steal* the ctx\r\n      in question; however, we can't write this as an actual\r\n      unique_ptr because we want deallocation to be handled externally.\r\n\r\n    - Sometimes, we need to pull out the file descriptor from a\r\n      tensor.  Previously, it was pulled out of the allocator context.\r\n      We still do morally the same thing, pulling out this information\r\n      from the deleter context; however, there is a nice static\r\n      method getContext() which checks if the conversion is valid\r\n      before pulling it out for you.  The returned pointer is NON-owning.\r\n\r\n- I renamed the std::function deleter into\r\n  InefficientStdFunctionDeleter, to emphasize the fact that it does\r\n  a dynamic allocation to save the std::function deleter.\r\n\r\nTODO:\r\n\r\n- Windows libshm is in shambles and needs to be fixed.\r\n\r\nPerhaps for the future:\r\n\r\n- newFromFd is now unconditionally calling cudaPointerGetAttributes\r\n  even though this is unnecessary, because we know what the device\r\n  is from higher up in the callstack.  We can fix this by making\r\n  newWithDataAndAllocator also take an explicit device argument.\r\n\r\n- Consider statically distinguishing between allocators that\r\n  support raw_allocate/raw_deallocate, and those which don't.\r\n  The Thrust constraint applies only to the CUDA device allocator;\r\n  you never need to allocate CPU memory this way\r\n\r\n- Really want to get rid of storage views. Ugh.\r\n\r\nNontrivial bugs I noticed when preparing this patch:\r\n\r\n- I forgot to placement-new unique pointers and attempted to\r\n  assign them directly on uninitialized memory; very bad!  Sam\r\n  Gross has encouraged me to replace this with a proper constructor\r\n  but I keep putting it off, because once everything goes in\r\n  StorageImpl there really will be a proper constructor.\r\n\r\n- I rewrote a number of APIs to use newWithDataAndAllocator\r\n  instead of newWithAllocator, calling the allocator at the\r\n  call site (because they required \"allocation context\" which\r\n  we no longer give to \"allocators\").  When I did this, I forgot\r\n  to insert the multiplication with sizeof(real) to scale from\r\n  numels to number of bytes.\r\n\r\n- The implementation of swap on storages was missing it for\r\n  scalarType and backend.  It was benign (because the only case\r\n  we call swap is when these are the same), but I fixed it anyway.\r\n\r\n- I accidentally returned a nullptr unique_ptr with no deleter,\r\n  even though there was a legitimate one.  This matters, because\r\n  some code still shoves its hands in the deleter context to\r\n  get extra metadata about the function.\r\n\r\n- I used std::move() on a unique_ptr, and then did a boolean\r\n  test on the pointer aftewards (always false!)\r\n\r\nSigned-off-by: Edward Z. Yang <ezyang@fb.com>\r\n```", "created_at": "2018-07-09T19:14:52Z", "updated_at": "2018-11-23T15:47:04Z", "closed_at": "2018-07-13T03:26:13Z", "merged_at": null, "merge_commit_sha": "75b3bf0eeb2d6d9cbb336832d0979b72cd9521cf", "assignee": null, "assignees": [], "requested_reviewers": [{"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "requested_teams": [], "labels": [], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9278/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/9278/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9278/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/82d33a23e34e8469313d1631b7321f5d6689e33c", "head": {"label": "ezyang:pr/allocator-deleter", "ref": "pr/allocator-deleter", "sha": "82d33a23e34e8469313d1631b7321f5d6689e33c", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "repo": {"id": 101798885, "node_id": "MDEwOlJlcG9zaXRvcnkxMDE3OTg4ODU=", "name": "pytorch", "full_name": "ezyang/pytorch", "private": false, "owner": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/ezyang/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/ezyang/pytorch", "forks_url": "https://api.github.com/repos/ezyang/pytorch/forks", "keys_url": "https://api.github.com/repos/ezyang/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/ezyang/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/ezyang/pytorch/teams", "hooks_url": "https://api.github.com/repos/ezyang/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/ezyang/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/ezyang/pytorch/events", "assignees_url": "https://api.github.com/repos/ezyang/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/ezyang/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/ezyang/pytorch/tags", "blobs_url": "https://api.github.com/repos/ezyang/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/ezyang/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/ezyang/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/ezyang/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/ezyang/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/ezyang/pytorch/languages", "stargazers_url": "https://api.github.com/repos/ezyang/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/ezyang/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/ezyang/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/ezyang/pytorch/subscription", "commits_url": "https://api.github.com/repos/ezyang/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/ezyang/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/ezyang/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/ezyang/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/ezyang/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/ezyang/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/ezyang/pytorch/merges", "archive_url": "https://api.github.com/repos/ezyang/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/ezyang/pytorch/downloads", "issues_url": "https://api.github.com/repos/ezyang/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/ezyang/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/ezyang/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/ezyang/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/ezyang/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/ezyang/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/ezyang/pytorch/deployments", "created_at": "2017-08-29T19:28:39Z", "updated_at": "2018-10-29T15:06:40Z", "pushed_at": "2018-11-21T22:30:09Z", "git_url": "git://github.com/ezyang/pytorch.git", "ssh_url": "git@github.com:ezyang/pytorch.git", "clone_url": "https://github.com/ezyang/pytorch.git", "svn_url": "https://github.com/ezyang/pytorch", "homepage": "http://pytorch.org", "size": 88254, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 2, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 2, "watchers": 1, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "d0d18208140474bab5360391d64337fdc07ba987", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T12:35:43Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21589, "watchers_count": 21589, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5153, "mirror_url": null, "archived": false, "open_issues_count": 2196, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5153, "open_issues": 2196, "watchers": 21589, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9278"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/9278"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/9278"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/9278/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9278/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/9278/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/82d33a23e34e8469313d1631b7321f5d6689e33c"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>Stacked on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"338065480\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9148\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9148/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9148\">#9148</a></p>\n<pre><code>The design might look a little strange, but there were a lot of\nconstraints feeding into it:\n\n- It must support the reallocation usage-pattern, where, given\n  an existing Storage, we allocate a new region of memory,\n  copy the existing data to it, and then deallocate the old\n  region of memory.\n\n- Creation of a deleter for memory MUST avoid dynamic allocations\n  in the common case.  We've done some benchmarking in Caffe2\n  where dynamic allocation for deleters is ruinously expensive,\n  and it's really hard to avoid these performance tarpits in\n  very general function wrappers like std::function or\n  folly::Function (while benchmarking this, we discovered that\n  folly::Function's move constructor was way more expensive\n  than it should be).\n\n- We need to be able to deallocate data that comes from external\n  sources, e.g., dlpack and numpy tensors.  Most notably,\n  you often cannot deallocate these with merely the void*\n  data pointer; you need some extra, out-of-band information\n  (e.g., the managing struct) to deallocate it.  Sometimes,\n  you may even want to resize data living in an external source!\n\n- The \"core\" allocators need to support being wrapped in a Thrust\n  allocator, so you need to be implement the following two functions:\n\n    char* allocate(size_t);\n    void deallocate(char*, size_t);\n\n- We need to support tensors which contain non-POD, non-trivially\n  copyable data; specifically tensors of std::string.  This is\n  an upcoming requirement from Caffe2.  It's dirty AF, but\n  it's really useful.\n\nHere is the billing of changes:\n\n- Built-in support for realloc() has been DROPPED ENTIRELY.\n  Instead, you're expected to allocate and then copy from\n  the old memory to the new memory if you want to do a\n  reallocation.  This is what you'd generally have expected\n  to occur; and axing realloc() from the design lets us avoid\n  some tricky correctness issues with std::realloc(), namely\n  the fact that we must refuse the realloc if the type of the\n  elements are not trivially copyeable.  If it really matters,\n  we can add this back, but there really needs to be a good\n  explanation WHY you need fast resizing reallocations (by in\n  large, people don't resize their storages, and it should\n  be acceptable to have a performance degradation when they\n  do).\n\n- TH_STORAGE_FREEMEM is no more; instead, if you want a\n  storage which doesn't free its result, you just give it\n  an empty deleter.\n\n- What we used to call an \"allocator\" has been split into two\n  concepts, an allocator and a deleter.  True to their names,\n  allocators know how to allocate, and deleters know how to\n  delete the things allocators produce.\n\n  This is NOT just a simple split of the previous\n  THAllocator/THCAllocator design:\n\n    - Unlike previously, where the \"context\" of an THAllocator\n      was allocate prior to even allocating, and then used\n      for the entire lifetime of the storage (even if a\n      reallocation happens), the notion of context has been\n      isolated to the Deleter (a Deleter plus a context is\n      a BoundDeleter); this context is *freshly manufactured*\n      when you do an allocation with an Allocator.\n\n    - We definitely need some sort of context for deleters,\n      because sometimes we need more information than the data\n      pointer itself to properly deallocate.  A simple example\n      is a dlpack tensor; to free the data, we need an\n      enclosing struct which contains the actual function pointer\n      to perform deletion.\n\n      Allocation of the deleter at *allocation* time allows\n      us to support some resizing use-cases in the absence of\n      built-in support for realloc().  If a context lifetime\n      is tied to a storage, there's no where to put a second\n      context for temporary memory before you perform a copy\n      from old to new.\n\n    - By default, allocators don't support \"raw\" allocations\n      and deallocations with raw pointers.  This is because\n      some allocations may return a different context every\n      time, in which case you need to reconstruct the context\n      at delete time (because all you got was a void*, not\n      a unique_ptr that carries the deleter).\n\n- THCDeviceAllocator has a few more changes.\n\n    - It used to return a cudaError_t.  Now, allocators\n      are expected to check the error status immediately and throw\n      an exception if there was an error.  It turns out that this\n      is what was immediately done after all occurrences of\n      allocate/release, so it wasn't a big deal (although some\n      subsidiary interfaces had to themselves be converted to\n      not return cudaError_t).\n\n      There is one notable exception to this, and it is how\n      we handle CUDA OOM: if this occurs, we attempt to return\n      unused memory to the system and try again.  This is now\n      handled by a catch-all try-catch block.  The cost of\n      catching the exception is probably the least of your worries\n      if you're about to OOM.\n\n    - It used to take the CUDA stream to perform the allocation\n      on as an argument.  However, it turned out that all call\n      sites, this stream was the stream for the current device.\n      So we can push this into the allocator (and the choice,\n      in the future, could be made explicitly by twiddling\n      thread local state.)\n\n    - It held two extra methods, emptyCache and cacheInfo, specifically\n      for interacting with some state in THCCachingAllocator.\n      But this \"generality\" was a lie, since THCCachingAllocator\n      was the only allocator that actually implemented these\n      methods, and there is actually a bunch of code in THC\n      which assumes that it is the caching allocator that is\n      the underlying allocator for CUDA allocations.  So I\n      folded these two methods into this interface as\n      THCCachingAllocator_emptyCache and THCCachingAllocator_cacheInfo.\n\n    - It held its context directly inside the THCDeviceAllocator\n      struct.  This context has been moved out into whatever\n      is holding the at::Allocator*.\n\n- The APIs for getting at allocators/deleters is now a little different.\n\n    - Previously there were a bunch of static variables you could get\n      the address of (e.g., &amp;THDefaultAllocator); now there is a\n      function getTHDefaultAllocator().\n\n    - Some \"allocators\" didn't actually know how to allocate (e.g.,\n      the IPC \"allocator\").  These have been deleted; you only have\n      deleters for these allocators now.\n\n    - Deleters have a convention that there is a make() static\n      method, which will construct an appropriate at::BoundDeleter\n      for that method (they take as arguments any context they need).\n\n- Storage sharing was a lot of work to wrangle, but I think I've\n  tamed the beast.\n\n    - Deleters for storage sharing (and some other deleters) follow\n      the convention that their context is dynamically allocated memory\n      whose lifetime is tied to the data in question.  So many\n      invocations of Deleter::make(ctx) actually *steal* the ctx\n      in question; however, we can't write this as an actual\n      unique_ptr because we want deallocation to be handled externally.\n\n    - Sometimes, we need to pull out the file descriptor from a\n      tensor.  Previously, it was pulled out of the allocator context.\n      We still do morally the same thing, pulling out this information\n      from the deleter context; however, there is a nice static\n      method getContext() which checks if the conversion is valid\n      before pulling it out for you.  The returned pointer is NON-owning.\n\n- I renamed the std::function deleter into\n  InefficientStdFunctionDeleter, to emphasize the fact that it does\n  a dynamic allocation to save the std::function deleter.\n\nTODO:\n\n- Windows libshm is in shambles and needs to be fixed.\n\nPerhaps for the future:\n\n- newFromFd is now unconditionally calling cudaPointerGetAttributes\n  even though this is unnecessary, because we know what the device\n  is from higher up in the callstack.  We can fix this by making\n  newWithDataAndAllocator also take an explicit device argument.\n\n- Consider statically distinguishing between allocators that\n  support raw_allocate/raw_deallocate, and those which don't.\n  The Thrust constraint applies only to the CUDA device allocator;\n  you never need to allocate CPU memory this way\n\n- Really want to get rid of storage views. Ugh.\n\nNontrivial bugs I noticed when preparing this patch:\n\n- I forgot to placement-new unique pointers and attempted to\n  assign them directly on uninitialized memory; very bad!  Sam\n  Gross has encouraged me to replace this with a proper constructor\n  but I keep putting it off, because once everything goes in\n  StorageImpl there really will be a proper constructor.\n\n- I rewrote a number of APIs to use newWithDataAndAllocator\n  instead of newWithAllocator, calling the allocator at the\n  call site (because they required \"allocation context\" which\n  we no longer give to \"allocators\").  When I did this, I forgot\n  to insert the multiplication with sizeof(real) to scale from\n  numels to number of bytes.\n\n- The implementation of swap on storages was missing it for\n  scalarType and backend.  It was benign (because the only case\n  we call swap is when these are the same), but I fixed it anyway.\n\n- I accidentally returned a nullptr unique_ptr with no deleter,\n  even though there was a legitimate one.  This matters, because\n  some code still shoves its hands in the deleter context to\n  get extra metadata about the function.\n\n- I used std::move() on a unique_ptr, and then did a boolean\n  test on the pointer aftewards (always false!)\n\nSigned-off-by: Edward Z. Yang &lt;ezyang@fb.com&gt;\n</code></pre>", "body_text": "Stacked on #9148\nThe design might look a little strange, but there were a lot of\nconstraints feeding into it:\n\n- It must support the reallocation usage-pattern, where, given\n  an existing Storage, we allocate a new region of memory,\n  copy the existing data to it, and then deallocate the old\n  region of memory.\n\n- Creation of a deleter for memory MUST avoid dynamic allocations\n  in the common case.  We've done some benchmarking in Caffe2\n  where dynamic allocation for deleters is ruinously expensive,\n  and it's really hard to avoid these performance tarpits in\n  very general function wrappers like std::function or\n  folly::Function (while benchmarking this, we discovered that\n  folly::Function's move constructor was way more expensive\n  than it should be).\n\n- We need to be able to deallocate data that comes from external\n  sources, e.g., dlpack and numpy tensors.  Most notably,\n  you often cannot deallocate these with merely the void*\n  data pointer; you need some extra, out-of-band information\n  (e.g., the managing struct) to deallocate it.  Sometimes,\n  you may even want to resize data living in an external source!\n\n- The \"core\" allocators need to support being wrapped in a Thrust\n  allocator, so you need to be implement the following two functions:\n\n    char* allocate(size_t);\n    void deallocate(char*, size_t);\n\n- We need to support tensors which contain non-POD, non-trivially\n  copyable data; specifically tensors of std::string.  This is\n  an upcoming requirement from Caffe2.  It's dirty AF, but\n  it's really useful.\n\nHere is the billing of changes:\n\n- Built-in support for realloc() has been DROPPED ENTIRELY.\n  Instead, you're expected to allocate and then copy from\n  the old memory to the new memory if you want to do a\n  reallocation.  This is what you'd generally have expected\n  to occur; and axing realloc() from the design lets us avoid\n  some tricky correctness issues with std::realloc(), namely\n  the fact that we must refuse the realloc if the type of the\n  elements are not trivially copyeable.  If it really matters,\n  we can add this back, but there really needs to be a good\n  explanation WHY you need fast resizing reallocations (by in\n  large, people don't resize their storages, and it should\n  be acceptable to have a performance degradation when they\n  do).\n\n- TH_STORAGE_FREEMEM is no more; instead, if you want a\n  storage which doesn't free its result, you just give it\n  an empty deleter.\n\n- What we used to call an \"allocator\" has been split into two\n  concepts, an allocator and a deleter.  True to their names,\n  allocators know how to allocate, and deleters know how to\n  delete the things allocators produce.\n\n  This is NOT just a simple split of the previous\n  THAllocator/THCAllocator design:\n\n    - Unlike previously, where the \"context\" of an THAllocator\n      was allocate prior to even allocating, and then used\n      for the entire lifetime of the storage (even if a\n      reallocation happens), the notion of context has been\n      isolated to the Deleter (a Deleter plus a context is\n      a BoundDeleter); this context is *freshly manufactured*\n      when you do an allocation with an Allocator.\n\n    - We definitely need some sort of context for deleters,\n      because sometimes we need more information than the data\n      pointer itself to properly deallocate.  A simple example\n      is a dlpack tensor; to free the data, we need an\n      enclosing struct which contains the actual function pointer\n      to perform deletion.\n\n      Allocation of the deleter at *allocation* time allows\n      us to support some resizing use-cases in the absence of\n      built-in support for realloc().  If a context lifetime\n      is tied to a storage, there's no where to put a second\n      context for temporary memory before you perform a copy\n      from old to new.\n\n    - By default, allocators don't support \"raw\" allocations\n      and deallocations with raw pointers.  This is because\n      some allocations may return a different context every\n      time, in which case you need to reconstruct the context\n      at delete time (because all you got was a void*, not\n      a unique_ptr that carries the deleter).\n\n- THCDeviceAllocator has a few more changes.\n\n    - It used to return a cudaError_t.  Now, allocators\n      are expected to check the error status immediately and throw\n      an exception if there was an error.  It turns out that this\n      is what was immediately done after all occurrences of\n      allocate/release, so it wasn't a big deal (although some\n      subsidiary interfaces had to themselves be converted to\n      not return cudaError_t).\n\n      There is one notable exception to this, and it is how\n      we handle CUDA OOM: if this occurs, we attempt to return\n      unused memory to the system and try again.  This is now\n      handled by a catch-all try-catch block.  The cost of\n      catching the exception is probably the least of your worries\n      if you're about to OOM.\n\n    - It used to take the CUDA stream to perform the allocation\n      on as an argument.  However, it turned out that all call\n      sites, this stream was the stream for the current device.\n      So we can push this into the allocator (and the choice,\n      in the future, could be made explicitly by twiddling\n      thread local state.)\n\n    - It held two extra methods, emptyCache and cacheInfo, specifically\n      for interacting with some state in THCCachingAllocator.\n      But this \"generality\" was a lie, since THCCachingAllocator\n      was the only allocator that actually implemented these\n      methods, and there is actually a bunch of code in THC\n      which assumes that it is the caching allocator that is\n      the underlying allocator for CUDA allocations.  So I\n      folded these two methods into this interface as\n      THCCachingAllocator_emptyCache and THCCachingAllocator_cacheInfo.\n\n    - It held its context directly inside the THCDeviceAllocator\n      struct.  This context has been moved out into whatever\n      is holding the at::Allocator*.\n\n- The APIs for getting at allocators/deleters is now a little different.\n\n    - Previously there were a bunch of static variables you could get\n      the address of (e.g., &THDefaultAllocator); now there is a\n      function getTHDefaultAllocator().\n\n    - Some \"allocators\" didn't actually know how to allocate (e.g.,\n      the IPC \"allocator\").  These have been deleted; you only have\n      deleters for these allocators now.\n\n    - Deleters have a convention that there is a make() static\n      method, which will construct an appropriate at::BoundDeleter\n      for that method (they take as arguments any context they need).\n\n- Storage sharing was a lot of work to wrangle, but I think I've\n  tamed the beast.\n\n    - Deleters for storage sharing (and some other deleters) follow\n      the convention that their context is dynamically allocated memory\n      whose lifetime is tied to the data in question.  So many\n      invocations of Deleter::make(ctx) actually *steal* the ctx\n      in question; however, we can't write this as an actual\n      unique_ptr because we want deallocation to be handled externally.\n\n    - Sometimes, we need to pull out the file descriptor from a\n      tensor.  Previously, it was pulled out of the allocator context.\n      We still do morally the same thing, pulling out this information\n      from the deleter context; however, there is a nice static\n      method getContext() which checks if the conversion is valid\n      before pulling it out for you.  The returned pointer is NON-owning.\n\n- I renamed the std::function deleter into\n  InefficientStdFunctionDeleter, to emphasize the fact that it does\n  a dynamic allocation to save the std::function deleter.\n\nTODO:\n\n- Windows libshm is in shambles and needs to be fixed.\n\nPerhaps for the future:\n\n- newFromFd is now unconditionally calling cudaPointerGetAttributes\n  even though this is unnecessary, because we know what the device\n  is from higher up in the callstack.  We can fix this by making\n  newWithDataAndAllocator also take an explicit device argument.\n\n- Consider statically distinguishing between allocators that\n  support raw_allocate/raw_deallocate, and those which don't.\n  The Thrust constraint applies only to the CUDA device allocator;\n  you never need to allocate CPU memory this way\n\n- Really want to get rid of storage views. Ugh.\n\nNontrivial bugs I noticed when preparing this patch:\n\n- I forgot to placement-new unique pointers and attempted to\n  assign them directly on uninitialized memory; very bad!  Sam\n  Gross has encouraged me to replace this with a proper constructor\n  but I keep putting it off, because once everything goes in\n  StorageImpl there really will be a proper constructor.\n\n- I rewrote a number of APIs to use newWithDataAndAllocator\n  instead of newWithAllocator, calling the allocator at the\n  call site (because they required \"allocation context\" which\n  we no longer give to \"allocators\").  When I did this, I forgot\n  to insert the multiplication with sizeof(real) to scale from\n  numels to number of bytes.\n\n- The implementation of swap on storages was missing it for\n  scalarType and backend.  It was benign (because the only case\n  we call swap is when these are the same), but I fixed it anyway.\n\n- I accidentally returned a nullptr unique_ptr with no deleter,\n  even though there was a legitimate one.  This matters, because\n  some code still shoves its hands in the deleter context to\n  get extra metadata about the function.\n\n- I used std::move() on a unique_ptr, and then did a boolean\n  test on the pointer aftewards (always false!)\n\nSigned-off-by: Edward Z. Yang <ezyang@fb.com>", "merged": false, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": null, "comments": 1, "review_comments": 7, "maintainer_can_modify": false, "commits": 21, "additions": 1017, "deletions": 1068, "changed_files": 44}