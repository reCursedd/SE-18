{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6613", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6613/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6613/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6613/events", "html_url": "https://github.com/pytorch/pytorch/issues/6613", "id": 314417509, "node_id": "MDU6SXNzdWUzMTQ0MTc1MDk=", "number": 6613, "title": "[caffe2] benchmark performance for different operators ", "user": {"login": "qzhong0605", "id": 9197259, "node_id": "MDQ6VXNlcjkxOTcyNTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/9197259?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qzhong0605", "html_url": "https://github.com/qzhong0605", "followers_url": "https://api.github.com/users/qzhong0605/followers", "following_url": "https://api.github.com/users/qzhong0605/following{/other_user}", "gists_url": "https://api.github.com/users/qzhong0605/gists{/gist_id}", "starred_url": "https://api.github.com/users/qzhong0605/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qzhong0605/subscriptions", "organizations_url": "https://api.github.com/users/qzhong0605/orgs", "repos_url": "https://api.github.com/users/qzhong0605/repos", "events_url": "https://api.github.com/users/qzhong0605/events{/privacy}", "received_events_url": "https://api.github.com/users/qzhong0605/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-04-15T13:53:18Z", "updated_at": "2018-04-16T17:15:00Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>The environment of server is the following:</p>\n<ul>\n<li>Framework:  Caffe2</li>\n<li>OS: Centos-7.3.1611</li>\n<li>CUDA/cuDNN version: CUDA-8.0(cudnn-6.0)</li>\n<li>GPU: Tesla K80</li>\n<li>GCC version: gcc-4.8</li>\n<li>CMake version: cmake3</li>\n</ul>\n<p>I want to test the performance on different convolution and fully-connected operators. But I got a rather ridiculous result, where different convolution operators may have great difference performance among each other.<br>\nI follow the method from the <code>caffe2/python/convnet_benchmarks.py</code> file.  What I did is to build a model net which contains only one operator, such as ConvOp operator, for obtaining performance. Now<br>\nthe result is the following:</p>\n<blockquote>\n<p>======begin** EigenConvOp(CPU)benchmark=====================<br>\nStarting benchmark.<br>\nRunning warmup runs.<br>\nMain runs.<br>\nMain run finished. Microseconds per iter: 21989.7. Iters per second: 45.4759<br>\n=======end EigenConvOp(CPU) benchmark=======================</p>\n<p>=======begin ConvOp(CPU) benchmark=========================<br>\nStarting benchmark.<br>\nRunning warmup runs.<br>\nMain runs.<br>\nMain run finished. Microseconds per iter: 426.187. Iters per second: 2346.39<br>\n=======end ConvOp(CPU) benchmark==========================</p>\n<p>=======begin MKLDNNConvOp(CPU) benchmark==================<br>\nI0415 21:44:07.254658 23478 operator.cc:165] Engine MKLDNN is not available for operator Conv.<br>\nStarting benchmark.<br>\nRunning warmup runs.<br>\nMain runs.<br>\nMain run finished. Microseconds per iter: 426.828. Iters per second: 2342.86<br>\n=======begin MKLDNNConvOp(CPU) benchmark===================</p>\n</blockquote>\n<p>The <code>EigenConvOp</code> is too slow and the time of it  50 times than others. I think the result is wrong and I guess there are some problems on  <code>workspace.BenchmarkNet</code> method.<br>\nWhen I look the  <code>net_dag.cc:DAGNetBase::TEST_Benchmark</code> method,  I found everything was ok.<br>\nAnyone has a effective method to benchmark different operator performance?</p>", "body_text": "The environment of server is the following:\n\nFramework:  Caffe2\nOS: Centos-7.3.1611\nCUDA/cuDNN version: CUDA-8.0(cudnn-6.0)\nGPU: Tesla K80\nGCC version: gcc-4.8\nCMake version: cmake3\n\nI want to test the performance on different convolution and fully-connected operators. But I got a rather ridiculous result, where different convolution operators may have great difference performance among each other.\nI follow the method from the caffe2/python/convnet_benchmarks.py file.  What I did is to build a model net which contains only one operator, such as ConvOp operator, for obtaining performance. Now\nthe result is the following:\n\n======begin** EigenConvOp(CPU)benchmark=====================\nStarting benchmark.\nRunning warmup runs.\nMain runs.\nMain run finished. Microseconds per iter: 21989.7. Iters per second: 45.4759\n=======end EigenConvOp(CPU) benchmark=======================\n=======begin ConvOp(CPU) benchmark=========================\nStarting benchmark.\nRunning warmup runs.\nMain runs.\nMain run finished. Microseconds per iter: 426.187. Iters per second: 2346.39\n=======end ConvOp(CPU) benchmark==========================\n=======begin MKLDNNConvOp(CPU) benchmark==================\nI0415 21:44:07.254658 23478 operator.cc:165] Engine MKLDNN is not available for operator Conv.\nStarting benchmark.\nRunning warmup runs.\nMain runs.\nMain run finished. Microseconds per iter: 426.828. Iters per second: 2342.86\n=======begin MKLDNNConvOp(CPU) benchmark===================\n\nThe EigenConvOp is too slow and the time of it  50 times than others. I think the result is wrong and I guess there are some problems on  workspace.BenchmarkNet method.\nWhen I look the  net_dag.cc:DAGNetBase::TEST_Benchmark method,  I found everything was ok.\nAnyone has a effective method to benchmark different operator performance?", "body": "The environment of server is the following:\r\n- Framework:  Caffe2\r\n- OS: Centos-7.3.1611\r\n- CUDA/cuDNN version: CUDA-8.0(cudnn-6.0)\r\n- GPU: Tesla K80\r\n- GCC version: gcc-4.8\r\n- CMake version: cmake3\r\n\r\nI want to test the performance on different convolution and fully-connected operators. But I got a rather ridiculous result, where different convolution operators may have great difference performance among each other.\r\nI follow the method from the `caffe2/python/convnet_benchmarks.py` file.  What I did is to build a model net which contains only one operator, such as ConvOp operator, for obtaining performance. Now \r\nthe result is the following:\r\n\r\n> ======begin** EigenConvOp(CPU)benchmark=====================\r\n> Starting benchmark.\r\n> Running warmup runs.\r\n> Main runs.\r\n> Main run finished. Microseconds per iter: 21989.7. Iters per second: 45.4759\r\n> =======end EigenConvOp(CPU) benchmark=======================\r\n> \r\n> \r\n> =======begin ConvOp(CPU) benchmark=========================\r\n> Starting benchmark.\r\n> Running warmup runs.\r\n> Main runs.\r\n> Main run finished. Microseconds per iter: 426.187. Iters per second: 2346.39\r\n> =======end ConvOp(CPU) benchmark==========================\r\n> \r\n> \r\n> =======begin MKLDNNConvOp(CPU) benchmark==================\r\n> I0415 21:44:07.254658 23478 operator.cc:165] Engine MKLDNN is not available for operator Conv.\r\n> Starting benchmark.\r\n> Running warmup runs.\r\n> Main runs.\r\n> Main run finished. Microseconds per iter: 426.828. Iters per second: 2342.86\r\n> =======begin MKLDNNConvOp(CPU) benchmark===================\r\n> \r\n\r\n The `EigenConvOp` is too slow and the time of it  50 times than others. I think the result is wrong and I guess there are some problems on  `workspace.BenchmarkNet` method. \r\n When I look the  `net_dag.cc:DAGNetBase::TEST_Benchmark` method,  I found everything was ok.\r\nAnyone has a effective method to benchmark different operator performance?\r\n"}