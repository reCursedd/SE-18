{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3021", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3021/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3021/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3021/events", "html_url": "https://github.com/pytorch/pytorch/issues/3021", "id": 263694719, "node_id": "MDU6SXNzdWUyNjM2OTQ3MTk=", "number": 3021, "title": "CPU scaling issue", "user": {"login": "loudinthecloud", "id": 3178431, "node_id": "MDQ6VXNlcjMxNzg0MzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3178431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loudinthecloud", "html_url": "https://github.com/loudinthecloud", "followers_url": "https://api.github.com/users/loudinthecloud/followers", "following_url": "https://api.github.com/users/loudinthecloud/following{/other_user}", "gists_url": "https://api.github.com/users/loudinthecloud/gists{/gist_id}", "starred_url": "https://api.github.com/users/loudinthecloud/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loudinthecloud/subscriptions", "organizations_url": "https://api.github.com/users/loudinthecloud/orgs", "repos_url": "https://api.github.com/users/loudinthecloud/repos", "events_url": "https://api.github.com/users/loudinthecloud/events{/privacy}", "received_events_url": "https://api.github.com/users/loudinthecloud/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-10-08T05:33:44Z", "updated_at": "2017-10-09T11:36:39Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Platform: c4.4xlarge EC2 instance (16 vCPUs)<br>\nOS: Fedora cloud 26-1.5<br>\nVersion: PyTorch v0.2.0</p>\n<p>Description:<br>\nRunning 4 workloads on all cores is x8 slower than pinning each workload to 4 different cpus.</p>\n<p>How-to reproduce:</p>\n<pre><code>git clone git@github.com:loudinthecloud/pytorch-ntm.git\ngit checkout d08291fac4dccaa3c8d081bad06802d9e4d737ea\nsudo pip3 install -r requirements\n</code></pre>\n<p>The following yields 220 ms/sequence (while not utilizing the CPUs fully):</p>\n<pre><code>taskset -c 0-3 ./train.py --seed 5 --checkpoint-interval 0\ntaskset -c 4-7 ./train.py --seed 50 --checkpoint-interval 0\ntaskset -c 8-11 ./train.py --seed 500 --checkpoint-interval 0\ntaskset -c 12-15 ./train.py --seed 5000 --checkpoint-interval 0\n</code></pre>\n<p>The following yields 1850 ms/sequence:</p>\n<pre><code>./train.py --seed 5 --checkpoint-interval 0\n./train.py --seed 50 --checkpoint-interval 0\n./train.py --seed 500 --checkpoint-interval 0\n./train.py --seed 5000 --checkpoint-interval 0\n</code></pre>\n<p>And moreover, all the CPUs are 100% utilized...</p>\n<p>Motivation:<br>\nI wanted to scale training on multi-core systems, a single workload not utilized the cpus fully, so I thought about utilizing the rest of the resources by running multiple workloads.</p>", "body_text": "Platform: c4.4xlarge EC2 instance (16 vCPUs)\nOS: Fedora cloud 26-1.5\nVersion: PyTorch v0.2.0\nDescription:\nRunning 4 workloads on all cores is x8 slower than pinning each workload to 4 different cpus.\nHow-to reproduce:\ngit clone git@github.com:loudinthecloud/pytorch-ntm.git\ngit checkout d08291fac4dccaa3c8d081bad06802d9e4d737ea\nsudo pip3 install -r requirements\n\nThe following yields 220 ms/sequence (while not utilizing the CPUs fully):\ntaskset -c 0-3 ./train.py --seed 5 --checkpoint-interval 0\ntaskset -c 4-7 ./train.py --seed 50 --checkpoint-interval 0\ntaskset -c 8-11 ./train.py --seed 500 --checkpoint-interval 0\ntaskset -c 12-15 ./train.py --seed 5000 --checkpoint-interval 0\n\nThe following yields 1850 ms/sequence:\n./train.py --seed 5 --checkpoint-interval 0\n./train.py --seed 50 --checkpoint-interval 0\n./train.py --seed 500 --checkpoint-interval 0\n./train.py --seed 5000 --checkpoint-interval 0\n\nAnd moreover, all the CPUs are 100% utilized...\nMotivation:\nI wanted to scale training on multi-core systems, a single workload not utilized the cpus fully, so I thought about utilizing the rest of the resources by running multiple workloads.", "body": "Platform: c4.4xlarge EC2 instance (16 vCPUs)\r\nOS: Fedora cloud 26-1.5\r\nVersion: PyTorch v0.2.0\r\n\r\nDescription:\r\nRunning 4 workloads on all cores is x8 slower than pinning each workload to 4 different cpus.\r\n\r\nHow-to reproduce:\r\n```\r\ngit clone git@github.com:loudinthecloud/pytorch-ntm.git\r\ngit checkout d08291fac4dccaa3c8d081bad06802d9e4d737ea\r\nsudo pip3 install -r requirements\r\n```\r\n\r\nThe following yields 220 ms/sequence (while not utilizing the CPUs fully):\r\n```\r\ntaskset -c 0-3 ./train.py --seed 5 --checkpoint-interval 0\r\ntaskset -c 4-7 ./train.py --seed 50 --checkpoint-interval 0\r\ntaskset -c 8-11 ./train.py --seed 500 --checkpoint-interval 0\r\ntaskset -c 12-15 ./train.py --seed 5000 --checkpoint-interval 0\r\n```\r\n\r\nThe following yields 1850 ms/sequence:\r\n```\r\n./train.py --seed 5 --checkpoint-interval 0\r\n./train.py --seed 50 --checkpoint-interval 0\r\n./train.py --seed 500 --checkpoint-interval 0\r\n./train.py --seed 5000 --checkpoint-interval 0\r\n```\r\nAnd moreover, all the CPUs are 100% utilized...\r\n\r\nMotivation:\r\nI wanted to scale training on multi-core systems, a single workload not utilized the cpus fully, so I thought about utilizing the rest of the resources by running multiple workloads."}