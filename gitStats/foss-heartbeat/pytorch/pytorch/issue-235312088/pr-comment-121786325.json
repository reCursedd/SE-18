{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121786325", "pull_request_review_id": 43843475, "id": 121786325, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTc4NjMyNQ==", "diff_hunk": "@@ -2698,6 +2707,8 @@\n \n If :attr:`mat` is a `n x m` Tensor, :attr:`vec` is a 1D Tensor of size `m`, :attr:`out` will be 1D of size `n`.\n \n+.. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.", "path": "torch/_torch_docs.py", "position": 45, "original_position": 45, "commit_id": "07c3ae79bba7dcb5aeb730b192c3ba01a828319c", "original_commit_id": "07c3ae79bba7dcb5aeb730b192c3ba01a828319c", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "body": "Good questions.\r\n\r\nThere are 5 relevant functions: mm, bmm, mv, ger, dot.\r\n\r\nIn the way I've structured the documentation, I only mention matmul in cases where there is broadcast behavior that allows you to do the equivalent ops with broadcasting; So: bmm (broadcast over batches) and mm (really squeeze/unsqueeze if one of the ops is 1-d, but close enough).\r\n\r\nThere is equivalent behavior in matmul independent of broadcasting in bmm, mm, dot, mv.  There isn't really in ger (you have to manually unsqueeze/squeeze the elements to get the equivalent).\r\n\r\nSo, there are really 3 combinations:\r\n1) equivalent + broadcasting: mm, bmm\r\n2) equivalent: dot, mv\r\n3) not equivalent: ger\r\n\r\nI prefer the term \"more general\" for matmul over \"low level\" for (mm, bmm, mv, dot).  So maybe the right thing to do for these cases are:\r\n1) Mention \"more general\" matmul with broadcasting support\r\n2) Mention \"more general\" matmul (no broadcasting support is separate note)\r\n3) Leave as is\r\n\r\nThoughts?\r\n", "created_at": "2017-06-13T20:22:11Z", "updated_at": "2018-11-23T15:33:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/1781#discussion_r121786325", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1781", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121786325"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1781#discussion_r121786325"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1781"}}, "body_html": "<p>Good questions.</p>\n<p>There are 5 relevant functions: mm, bmm, mv, ger, dot.</p>\n<p>In the way I've structured the documentation, I only mention matmul in cases where there is broadcast behavior that allows you to do the equivalent ops with broadcasting; So: bmm (broadcast over batches) and mm (really squeeze/unsqueeze if one of the ops is 1-d, but close enough).</p>\n<p>There is equivalent behavior in matmul independent of broadcasting in bmm, mm, dot, mv.  There isn't really in ger (you have to manually unsqueeze/squeeze the elements to get the equivalent).</p>\n<p>So, there are really 3 combinations:</p>\n<ol>\n<li>equivalent + broadcasting: mm, bmm</li>\n<li>equivalent: dot, mv</li>\n<li>not equivalent: ger</li>\n</ol>\n<p>I prefer the term \"more general\" for matmul over \"low level\" for (mm, bmm, mv, dot).  So maybe the right thing to do for these cases are:</p>\n<ol>\n<li>Mention \"more general\" matmul with broadcasting support</li>\n<li>Mention \"more general\" matmul (no broadcasting support is separate note)</li>\n<li>Leave as is</li>\n</ol>\n<p>Thoughts?</p>", "body_text": "Good questions.\nThere are 5 relevant functions: mm, bmm, mv, ger, dot.\nIn the way I've structured the documentation, I only mention matmul in cases where there is broadcast behavior that allows you to do the equivalent ops with broadcasting; So: bmm (broadcast over batches) and mm (really squeeze/unsqueeze if one of the ops is 1-d, but close enough).\nThere is equivalent behavior in matmul independent of broadcasting in bmm, mm, dot, mv.  There isn't really in ger (you have to manually unsqueeze/squeeze the elements to get the equivalent).\nSo, there are really 3 combinations:\n\nequivalent + broadcasting: mm, bmm\nequivalent: dot, mv\nnot equivalent: ger\n\nI prefer the term \"more general\" for matmul over \"low level\" for (mm, bmm, mv, dot).  So maybe the right thing to do for these cases are:\n\nMention \"more general\" matmul with broadcasting support\nMention \"more general\" matmul (no broadcasting support is separate note)\nLeave as is\n\nThoughts?", "in_reply_to_id": 121782917}