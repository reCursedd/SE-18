{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/401422046", "html_url": "https://github.com/pytorch/pytorch/issues/1637#issuecomment-401422046", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1637", "id": 401422046, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTQyMjA0Ng==", "user": {"login": "gwern", "id": 352559, "node_id": "MDQ6VXNlcjM1MjU1OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/352559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gwern", "html_url": "https://github.com/gwern", "followers_url": "https://api.github.com/users/gwern/followers", "following_url": "https://api.github.com/users/gwern/following{/other_user}", "gists_url": "https://api.github.com/users/gwern/gists{/gist_id}", "starred_url": "https://api.github.com/users/gwern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gwern/subscriptions", "organizations_url": "https://api.github.com/users/gwern/orgs", "repos_url": "https://api.github.com/users/gwern/repos", "events_url": "https://api.github.com/users/gwern/events{/privacy}", "received_events_url": "https://api.github.com/users/gwern/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-29T17:31:18Z", "updated_at": "2018-06-29T17:31:18Z", "author_association": "NONE", "body_html": "<p>Just leaving another comment about the workaround: I built a Threadripper/2x1080ti workstation and began the Fast.ai course. Training on a single GPU worked fine, so I thought I'd try both, using <code>DataParallel</code>. The Python process would spin at 100% unkillably, with small GPU utilization, requiring a reboot. The p2p CUDA sample would likewise hang at the first benchmark. Adding the IOMMU line in Grub and rebooting fixed both problems (could get the P2P benchmark within seconds, and dual-GPU training overnight ran without a hitch) and doesn't thus far appear to have caused any side-effects.</p>", "body_text": "Just leaving another comment about the workaround: I built a Threadripper/2x1080ti workstation and began the Fast.ai course. Training on a single GPU worked fine, so I thought I'd try both, using DataParallel. The Python process would spin at 100% unkillably, with small GPU utilization, requiring a reboot. The p2p CUDA sample would likewise hang at the first benchmark. Adding the IOMMU line in Grub and rebooting fixed both problems (could get the P2P benchmark within seconds, and dual-GPU training overnight ran without a hitch) and doesn't thus far appear to have caused any side-effects.", "body": "Just leaving another comment about the workaround: I built a Threadripper/2x1080ti workstation and began the Fast.ai course. Training on a single GPU worked fine, so I thought I'd try both, using `DataParallel`. The Python process would spin at 100% unkillably, with small GPU utilization, requiring a reboot. The p2p CUDA sample would likewise hang at the first benchmark. Adding the IOMMU line in Grub and rebooting fixed both problems (could get the P2P benchmark within seconds, and dual-GPU training overnight ran without a hitch) and doesn't thus far appear to have caused any side-effects."}