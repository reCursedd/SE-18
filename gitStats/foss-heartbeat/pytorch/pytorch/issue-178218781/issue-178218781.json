{"url": "https://api.github.com/repos/pytorch/pytorch/issues/43", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/43/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/43/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/43/events", "html_url": "https://github.com/pytorch/pytorch/issues/43", "id": 178218781, "node_id": "MDU6SXNzdWUxNzgyMTg3ODE=", "number": 43, "title": "fix bad error message", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-09-21T00:59:35Z", "updated_at": "2016-09-25T23:19:31Z", "closed_at": "2016-09-25T23:19:31Z", "author_association": "MEMBER", "body_html": "<div class=\"highlight highlight-source-python\"><pre>m <span class=\"pl-k\">=</span> nn.Conv2d(<span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">32</span>, (<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>))\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> autograd.Variable(torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">16</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">10</span>))\nm(<span class=\"pl-c1\">input</span>)</pre></div>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">57</span><span class=\"pl-k\">-</span>ad2f7eaad9e5<span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">1</span> m(<span class=\"pl-c1\">input</span>)\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>miniconda2<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>module.pyc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>)\n     <span class=\"pl-c1\">64</span>\n     <span class=\"pl-c1\">65</span>     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">input</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">66</span>         result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>)\n     <span class=\"pl-c1\">67</span>         <span class=\"pl-k\">for</span> hook <span class=\"pl-k\">in</span> <span class=\"pl-c1\">self</span>.forward_hooks.values():\n     <span class=\"pl-c1\">68</span>             hook(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, result)\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>miniconda2<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>modules<span class=\"pl-k\">/</span>conv.pyc <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>)\n    <span class=\"pl-c1\">140</span>             <span class=\"pl-k\">return</span> func(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight)\n    <span class=\"pl-c1\">141</span>         <span class=\"pl-k\">else</span>:\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">142</span>             <span class=\"pl-k\">return</span> func(<span class=\"pl-c1\">input</span>, <span class=\"pl-c1\">self</span>.weight, <span class=\"pl-c1\">self</span>.bias)\n    <span class=\"pl-c1\">143</span>\n    <span class=\"pl-c1\">144</span>\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>miniconda2<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>autograd<span class=\"pl-k\">/</span>function.pyc <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>)\n     <span class=\"pl-c1\">16</span>\n     <span class=\"pl-c1\">17</span>     <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">input</span>):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">18</span>         <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>._do_forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>)\n     <span class=\"pl-c1\">19</span>\n     <span class=\"pl-c1\">20</span>     <span class=\"pl-k\">def</span> <span class=\"pl-en\">save_for_backward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">tensors</span>):\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>miniconda2<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>autograd<span class=\"pl-k\">/</span>function.pyc <span class=\"pl-k\">in</span> _do_forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>)\n     <span class=\"pl-c1\">44</span>             <span class=\"pl-c1\">self</span>.previous_functions <span class=\"pl-k\">=</span> [(arg.creator, <span class=\"pl-c1\">id</span>(arg)) <span class=\"pl-k\">for</span> arg <span class=\"pl-k\">in</span> <span class=\"pl-c1\">input</span>]\n     <span class=\"pl-c1\">45</span>\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">46</span>         raw_output <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span>unpacked_input)\n     <span class=\"pl-c1\">47</span>         <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(raw_output, <span class=\"pl-c1\">tuple</span>):\n     <span class=\"pl-c1\">48</span>             raw_output <span class=\"pl-k\">=</span> (raw_output,)\n\n<span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>soumith<span class=\"pl-k\">/</span>local<span class=\"pl-k\">/</span>miniconda2<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python2.7<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>nn<span class=\"pl-k\">/</span>functions<span class=\"pl-k\">/</span>thnn<span class=\"pl-k\">/</span>auto.pyc <span class=\"pl-k\">in</span> forward(<span class=\"pl-c1\">self</span>, <span class=\"pl-c1\">input</span>, <span class=\"pl-k\">*</span>params)\n    <span class=\"pl-c1\">134</span>             <span class=\"pl-c1\">self</span>.save_for_backward(<span class=\"pl-c1\">input</span>, <span class=\"pl-k\">*</span>params)\n    <span class=\"pl-c1\">135</span>\n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">136</span>         <span class=\"pl-c1\">getattr</span>(<span class=\"pl-c1\">self</span>._backend, update_output.name)(<span class=\"pl-c1\">self</span>._backend.library_state, <span class=\"pl-c1\">input</span>, output, <span class=\"pl-k\">*</span>args)\n    <span class=\"pl-c1\">137</span>         <span class=\"pl-k\">return</span> output\n    <span class=\"pl-c1\">138</span>\n\n<span class=\"pl-c1\">ValueError</span>: Invalid arguments! Got (<span class=\"pl-c1\">int</span>, FloatTensor, FloatTensor, DoubleTensor, DoubleTensor, FloatTensor, FloatTensor, <span class=\"pl-c1\">int</span>, <span class=\"pl-c1\">int</span>, <span class=\"pl-c1\">int</span>, <span class=\"pl-c1\">int</span>, <span class=\"pl-c1\">int</span>, <span class=\"pl-c1\">int</span>), but expected (<span class=\"pl-c1\">int</span> state, torch.FloatTensor <span class=\"pl-c1\">input</span>, torch.FloatTensor output, torch.FloatTensor weight, [torch.FloatTensor bias <span class=\"pl-k\">or</span> <span class=\"pl-c1\">None</span>], torch.FloatTensor finput, torch.FloatTensor fgradInput, <span class=\"pl-c1\">int</span> kW, <span class=\"pl-c1\">int</span> kH, <span class=\"pl-c1\">int</span> dW, <span class=\"pl-c1\">int</span> dH, <span class=\"pl-c1\">int</span> padW, <span class=\"pl-c1\">int</span> padH)</pre></div>", "body_text": "m = nn.Conv2d(16, 32, (3, 3))\ninput = autograd.Variable(torch.randn(3, 16, 10, 10))\nm(input)\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-57-ad2f7eaad9e5> in <module>()\n----> 1 m(input)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc in __call__(self, *input)\n     64\n     65     def __call__(self, *input):\n---> 66         result = self.forward(*input)\n     67         for hook in self.forward_hooks.values():\n     68             hook(self, input, result)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc in forward(self, input)\n    140             return func(input, self.weight)\n    141         else:\n--> 142             return func(input, self.weight, self.bias)\n    143\n    144\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/autograd/function.pyc in __call__(self, *input)\n     16\n     17     def __call__(self, *input):\n---> 18         return self._do_forward(*input)\n     19\n     20     def save_for_backward(self, *tensors):\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/autograd/function.pyc in _do_forward(self, *input)\n     44             self.previous_functions = [(arg.creator, id(arg)) for arg in input]\n     45\n---> 46         raw_output = self.forward(*unpacked_input)\n     47         if not isinstance(raw_output, tuple):\n     48             raw_output = (raw_output,)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/functions/thnn/auto.pyc in forward(self, input, *params)\n    134             self.save_for_backward(input, *params)\n    135\n--> 136         getattr(self._backend, update_output.name)(self._backend.library_state, input, output, *args)\n    137         return output\n    138\n\nValueError: Invalid arguments! Got (int, FloatTensor, FloatTensor, DoubleTensor, DoubleTensor, FloatTensor, FloatTensor, int, int, int, int, int, int), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, [torch.FloatTensor bias or None], torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH)", "body": "``` python\nm = nn.Conv2d(16, 32, (3, 3))\ninput = autograd.Variable(torch.randn(3, 16, 10, 10))\nm(input)\n```\n\n``` python\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-57-ad2f7eaad9e5> in <module>()\n----> 1 m(input)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc in __call__(self, *input)\n     64\n     65     def __call__(self, *input):\n---> 66         result = self.forward(*input)\n     67         for hook in self.forward_hooks.values():\n     68             hook(self, input, result)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc in forward(self, input)\n    140             return func(input, self.weight)\n    141         else:\n--> 142             return func(input, self.weight, self.bias)\n    143\n    144\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/autograd/function.pyc in __call__(self, *input)\n     16\n     17     def __call__(self, *input):\n---> 18         return self._do_forward(*input)\n     19\n     20     def save_for_backward(self, *tensors):\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/autograd/function.pyc in _do_forward(self, *input)\n     44             self.previous_functions = [(arg.creator, id(arg)) for arg in input]\n     45\n---> 46         raw_output = self.forward(*unpacked_input)\n     47         if not isinstance(raw_output, tuple):\n     48             raw_output = (raw_output,)\n\n/home/soumith/local/miniconda2/lib/python2.7/site-packages/torch/nn/functions/thnn/auto.pyc in forward(self, input, *params)\n    134             self.save_for_backward(input, *params)\n    135\n--> 136         getattr(self._backend, update_output.name)(self._backend.library_state, input, output, *args)\n    137         return output\n    138\n\nValueError: Invalid arguments! Got (int, FloatTensor, FloatTensor, DoubleTensor, DoubleTensor, FloatTensor, FloatTensor, int, int, int, int, int, int), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, [torch.FloatTensor bias or None], torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH)\n```\n"}