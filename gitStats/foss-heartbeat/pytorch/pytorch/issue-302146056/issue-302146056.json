{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5560", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5560/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5560/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5560/events", "html_url": "https://github.com/pytorch/pytorch/issues/5560", "id": 302146056, "node_id": "MDU6SXNzdWUzMDIxNDYwNTY=", "number": 5560, "title": "\"Reduce Failed to Synchronise\" in F.binary_cross_entropy ", "user": {"login": "angusturner", "id": 18481607, "node_id": "MDQ6VXNlcjE4NDgxNjA3", "avatar_url": "https://avatars0.githubusercontent.com/u/18481607?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angusturner", "html_url": "https://github.com/angusturner", "followers_url": "https://api.github.com/users/angusturner/followers", "following_url": "https://api.github.com/users/angusturner/following{/other_user}", "gists_url": "https://api.github.com/users/angusturner/gists{/gist_id}", "starred_url": "https://api.github.com/users/angusturner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angusturner/subscriptions", "organizations_url": "https://api.github.com/users/angusturner/orgs", "repos_url": "https://api.github.com/users/angusturner/repos", "events_url": "https://api.github.com/users/angusturner/events{/privacy}", "received_events_url": "https://api.github.com/users/angusturner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-03-05T01:38:37Z", "updated_at": "2018-05-14T19:37:15Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Since upgrading PyTorch to the master branch, I am occasionally receiving the following error:</p>\n<pre><code>/home/user/cuda-ubuntu-16.04-ec2/pytorch/aten/src/THCUNN/BCECriterion.cu:30: Acctype bce_functor&lt;Dtype, Acctype&gt;::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references&lt;thrust::device_reference&lt;float&gt;, thrust::device_reference&lt;float&gt;, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [0,0,0], thread: [223,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\nTraceback (most recent call last):\n  File \"train_model.py\", line 138, in &lt;module&gt;\n    train_model(config)\n  File \"train_model.py\", line 105, in train_model\n    worker.train(train_loader, plot_lr=plot_lr, on_iter=on_iter)\n  File \"/home/user/src/worker.py\", line 204, in train\n    time_loss = F.binary_cross_entropy(time_pred, time_hist.float())\n  File \"/home/user/miniconda3/envs/cuda/lib/python3.6/site-packages/torch/nn/functional.py\", line 1507, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(input, target, weight, size_average, reduce)\nRuntimeError: reduce failed to synchronize: device-side assert triggered\n</code></pre>\n<p>In this trace, <code>time_loss</code> is the output of a linear network with <code>nn.Sigmoid()</code> on the output, and <code>time_hist</code> is from a binary dataset, which I am confident is correct (because I can complete multiple epoch before it fails).</p>\n<p>I haven't checked if <code>F.binary_cross_entropy_with_logits</code> fixes the issue.</p>\n<p>System details:</p>\n<ul>\n<li>OS: Ubuntu 16.0.4</li>\n<li>PyTorch version: 0.4.0a0+55c64e5</li>\n<li>How you installed PyTorch (conda, pip, source): source</li>\n<li>Python version: Python 3.6.1</li>\n<li>CUDA/cuDNN version: CUDA release 9.0, V9.0.176 / CUDNN 7005</li>\n<li>GPU models and configuration: 4x Nvidia M60</li>\n<li>GCC version (if compiling from source): GCC 4.4.7</li>\n</ul>", "body_text": "Since upgrading PyTorch to the master branch, I am occasionally receiving the following error:\n/home/user/cuda-ubuntu-16.04-ec2/pytorch/aten/src/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [223,0,0] Assertion `input >= 0. && input <= 1.` failed.\nTraceback (most recent call last):\n  File \"train_model.py\", line 138, in <module>\n    train_model(config)\n  File \"train_model.py\", line 105, in train_model\n    worker.train(train_loader, plot_lr=plot_lr, on_iter=on_iter)\n  File \"/home/user/src/worker.py\", line 204, in train\n    time_loss = F.binary_cross_entropy(time_pred, time_hist.float())\n  File \"/home/user/miniconda3/envs/cuda/lib/python3.6/site-packages/torch/nn/functional.py\", line 1507, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(input, target, weight, size_average, reduce)\nRuntimeError: reduce failed to synchronize: device-side assert triggered\n\nIn this trace, time_loss is the output of a linear network with nn.Sigmoid() on the output, and time_hist is from a binary dataset, which I am confident is correct (because I can complete multiple epoch before it fails).\nI haven't checked if F.binary_cross_entropy_with_logits fixes the issue.\nSystem details:\n\nOS: Ubuntu 16.0.4\nPyTorch version: 0.4.0a0+55c64e5\nHow you installed PyTorch (conda, pip, source): source\nPython version: Python 3.6.1\nCUDA/cuDNN version: CUDA release 9.0, V9.0.176 / CUDNN 7005\nGPU models and configuration: 4x Nvidia M60\nGCC version (if compiling from source): GCC 4.4.7", "body": "Since upgrading PyTorch to the master branch, I am occasionally receiving the following error:\r\n\r\n```\r\n/home/user/cuda-ubuntu-16.04-ec2/pytorch/aten/src/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [223,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\nTraceback (most recent call last):\r\n  File \"train_model.py\", line 138, in <module>\r\n    train_model(config)\r\n  File \"train_model.py\", line 105, in train_model\r\n    worker.train(train_loader, plot_lr=plot_lr, on_iter=on_iter)\r\n  File \"/home/user/src/worker.py\", line 204, in train\r\n    time_loss = F.binary_cross_entropy(time_pred, time_hist.float())\r\n  File \"/home/user/miniconda3/envs/cuda/lib/python3.6/site-packages/torch/nn/functional.py\", line 1507, in binary_cross_entropy\r\n    return torch._C._nn.binary_cross_entropy(input, target, weight, size_average, reduce)\r\nRuntimeError: reduce failed to synchronize: device-side assert triggered\r\n```\r\n\r\nIn this trace, `time_loss` is the output of a linear network with `nn.Sigmoid()` on the output, and `time_hist` is from a binary dataset, which I am confident is correct (because I can complete multiple epoch before it fails).\r\n\r\nI haven't checked if `F.binary_cross_entropy_with_logits` fixes the issue.\r\n\r\nSystem details:\r\n- OS: Ubuntu 16.0.4\r\n- PyTorch version: 0.4.0a0+55c64e5\r\n- How you installed PyTorch (conda, pip, source): source\r\n- Python version: Python 3.6.1\r\n- CUDA/cuDNN version: CUDA release 9.0, V9.0.176 / CUDNN 7005\r\n- GPU models and configuration: 4x Nvidia M60\r\n- GCC version (if compiling from source): GCC 4.4.7"}