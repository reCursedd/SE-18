{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/413116713", "html_url": "https://github.com/pytorch/pytorch/issues/10459#issuecomment-413116713", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10459", "id": 413116713, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzExNjcxMw==", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-15T07:27:17Z", "updated_at": "2018-08-15T07:27:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Multi-head dot product attention is also used in the <a href=\"https://arxiv.org/abs/1806.01822\" rel=\"nofollow\">relational memory core</a> and in place of the (pairwise) relation net in <a href=\"https://arxiv.org/abs/1806.01830\" rel=\"nofollow\">\"relational deep reinforcement learning\"</a>, so the concept is more general than NLP. More broadly there's also <a href=\"https://arxiv.org/abs/1711.07971\" rel=\"nofollow\">non-local blocks</a>, so it may be worth considering how they might share abstract components.</p>\n<p>Going by <a href=\"http://nlp.seas.harvard.edu/2018/04/03/attention.html\" rel=\"nofollow\">The Annotated Transformer</a>, it seems like multi-head attention is the most non-trivial module, then positional encodings, and then it's generally a composition of existing layers. In the same way that <code>torchvision</code> contains ResNets and other CV models, wouldn't a full transformer model for NLP fit better into <code>torchtext</code>?</p>", "body_text": "Multi-head dot product attention is also used in the relational memory core and in place of the (pairwise) relation net in \"relational deep reinforcement learning\", so the concept is more general than NLP. More broadly there's also non-local blocks, so it may be worth considering how they might share abstract components.\nGoing by The Annotated Transformer, it seems like multi-head attention is the most non-trivial module, then positional encodings, and then it's generally a composition of existing layers. In the same way that torchvision contains ResNets and other CV models, wouldn't a full transformer model for NLP fit better into torchtext?", "body": "Multi-head dot product attention is also used in the [relational memory core](https://arxiv.org/abs/1806.01822) and in place of the (pairwise) relation net in [\"relational deep reinforcement learning\"](https://arxiv.org/abs/1806.01830), so the concept is more general than NLP. More broadly there's also [non-local blocks](https://arxiv.org/abs/1711.07971), so it may be worth considering how they might share abstract components.\r\n\r\nGoing by [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html), it seems like multi-head attention is the most non-trivial module, then positional encodings, and then it's generally a composition of existing layers. In the same way that `torchvision` contains ResNets and other CV models, wouldn't a full transformer model for NLP fit better into `torchtext`?"}