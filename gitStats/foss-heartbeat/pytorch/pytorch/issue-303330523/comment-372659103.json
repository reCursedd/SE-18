{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/372659103", "html_url": "https://github.com/pytorch/pytorch/pull/5626#issuecomment-372659103", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5626", "id": 372659103, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjY1OTEwMw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-13T13:08:50Z", "updated_at": "2018-03-13T13:08:50Z", "author_association": "MEMBER", "body_html": "<p>I am a bit ambivalent about this PR. This is not really a pressing issue for C++ users, because they can define a ReLU alias as a one liner. What's more, the refactor that would separate nn parts from general linear algebra parts would also cause breakages for them so it's even safer for them to do it that way.</p>\n<p>Additionally, this adds <code>Tensor.relu</code> that we never had, and never plan to have. If we <strong>really</strong> want to merge this, then I would be ok with having it as a namespace only thing in C++ (left for a clean up later), but it <em>should never appear in the <code>torch.</code> namespace in Python</em> (nor as a Variable method).</p>", "body_text": "I am a bit ambivalent about this PR. This is not really a pressing issue for C++ users, because they can define a ReLU alias as a one liner. What's more, the refactor that would separate nn parts from general linear algebra parts would also cause breakages for them so it's even safer for them to do it that way.\nAdditionally, this adds Tensor.relu that we never had, and never plan to have. If we really want to merge this, then I would be ok with having it as a namespace only thing in C++ (left for a clean up later), but it should never appear in the torch. namespace in Python (nor as a Variable method).", "body": "I am a bit ambivalent about this PR. This is not really a pressing issue for C++ users, because they can define a ReLU alias as a one liner. What's more, the refactor that would separate nn parts from general linear algebra parts would also cause breakages for them so it's even safer for them to do it that way.\r\n\r\nAdditionally, this adds `Tensor.relu` that we never had, and never plan to have. If we **really** want to merge this, then I would be ok with having it as a namespace only thing in C++ (left for a clean up later), but it *should never appear in the `torch.` namespace in Python* (nor as a Variable method)."}