{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11737", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11737/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11737/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11737/events", "html_url": "https://github.com/pytorch/pytorch/issues/11737", "id": 360606471, "node_id": "MDU6SXNzdWUzNjA2MDY0NzE=", "number": 11737, "title": "torch.utils.cpp_extension.load doesn't change device after moving the model", "user": {"login": "bonlime", "id": 14337581, "node_id": "MDQ6VXNlcjE0MzM3NTgx", "avatar_url": "https://avatars0.githubusercontent.com/u/14337581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bonlime", "html_url": "https://github.com/bonlime", "followers_url": "https://api.github.com/users/bonlime/followers", "following_url": "https://api.github.com/users/bonlime/following{/other_user}", "gists_url": "https://api.github.com/users/bonlime/gists{/gist_id}", "starred_url": "https://api.github.com/users/bonlime/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bonlime/subscriptions", "organizations_url": "https://api.github.com/users/bonlime/orgs", "repos_url": "https://api.github.com/users/bonlime/repos", "events_url": "https://api.github.com/users/bonlime/events{/privacy}", "received_events_url": "https://api.github.com/users/bonlime/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-16T05:46:25Z", "updated_at": "2018-09-17T15:32:42Z", "closed_at": "2018-09-17T15:32:42Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>After using torch.utils.cpp_extension.load, returned module always puts tensors at GPU 0 ('cuda:0')<br>\nIt causes problems when model is moved to another GPU.<br>\nIn my example I used code from <a href=\"https://github.com/mapillary/inplace_abn\">https://github.com/mapillary/inplace_abn</a><br>\nSee also <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"360604118\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/mapillary/inplace_abn/issues/52\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mapillary/inplace_abn/issues/52/hovercard\" href=\"https://github.com/mapillary/inplace_abn/issues/52\">mapillary/inplace_abn#52</a></p>\n<h2>Code example</h2>\n<pre><code>\"\"\"\nexample from https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/502_GPU.py\nDependencies:\ntorch: 0.4\ntorchvision\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as Data\nimport torchvision\n\nfrom modules.bn import InPlaceABN \n\n#===================================#\n# Change to cuda:0 to make it work  #\ndevice = torch.device('cuda:1')     #\nprint(device)                       #\n#===================================#\n\nEPOCH = 1\nBATCH_SIZE = 50\nLR = 0.001\nDOWNLOAD_MNIST = True\n\ntrain_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\ntrain_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),\n                                   nn.ReLU(), nn.MaxPool2d(kernel_size=2),)\n        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2),)\n        \n        self.bn = InPlaceABN(32)\n        self.out = nn.Linear(32 * 7 * 7, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.bn(x)\n        x = x.view(x.size(0), -1)\n        output = self.out(x)\n        return output\n\ncnn = CNN()\n\ncnn.to(device)      # Moves all model parameters and buffers to the GPU\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\nloss_func = nn.CrossEntropyLoss().cuda(device)\n\nfor epoch in range(EPOCH):\n    for step, (x, y) in enumerate(train_loader):\n        \n        b_x = x.to(device)     # Tensor on GPU\n        b_y = y.to(device)     # Tensor on GPU\n        \n        # This is where error happens\n        output = cnn(b_x)\n        loss = loss_func(output, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 50 == 0:\n            print(\"Test passed\")\n            break\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-2-c7d32883c675&gt; in &lt;module&gt;()\n     60         b_y = y.to(device)     # Tensor on GPU\n     61 \n---&gt; 62         output = cnn(b_x)\n     63         loss = loss_func(output, b_y)\n     64         optimizer.zero_grad()\n\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--&gt; 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n&lt;ipython-input-2-c7d32883c675&gt; in forward(self, x)\n     41         x = self.conv1(x)\n     42         x = self.conv2(x)\n---&gt; 43         x = self.bn(x)\n     44         x = x.view(x.size(0), -1)\n     45         output = self.out(x)\n\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--&gt; 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/kaggle_salt/modules/bn.py in forward(self, x)\n    106     def forward(self, x):\n    107         return inplace_abn(x, self.weight, self.bias, self.running_mean, self.running_var,\n--&gt; 108                            self.training, self.momentum, self.eps, self.activation, self.slope)\n    109 \n    110 \n\n~/kaggle_salt/modules/functions.py in forward(ctx, x, weight, bias, running_mean, running_var, training, momentum, eps, activation, slope)\n     97 \n     98             # Update running stats\n---&gt; 99             running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * mean)\n    100             running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * var * count / (count - 1))\n    101 \n\nRuntimeError: arguments are located on different GPUs at /pytorch/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:233\n</code></pre>\n<h2>System Info</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).<br>\nPyTorch version: 0.4.0<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 8.0.61</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4<br>\nCMake version: version 3.12.0</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti<br>\nGPU 3: GeForce GTX 1080 Ti</p>\n<p>Nvidia driver version: 384.130<br>\ncuDNN version: Probably one of the following:<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.6<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.6.0.21<br>\n/usr/local/cuda-8.0/lib64/libcudnn_static.a<br>\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.0.5<br>\n/usr/local/cuda-9.0/lib64/libcudnn_static.a</p>", "body_text": "Issue description\nAfter using torch.utils.cpp_extension.load, returned module always puts tensors at GPU 0 ('cuda:0')\nIt causes problems when model is moved to another GPU.\nIn my example I used code from https://github.com/mapillary/inplace_abn\nSee also mapillary/inplace_abn#52\nCode example\n\"\"\"\nexample from https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/502_GPU.py\nDependencies:\ntorch: 0.4\ntorchvision\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as Data\nimport torchvision\n\nfrom modules.bn import InPlaceABN \n\n#===================================#\n# Change to cuda:0 to make it work  #\ndevice = torch.device('cuda:1')     #\nprint(device)                       #\n#===================================#\n\nEPOCH = 1\nBATCH_SIZE = 50\nLR = 0.001\nDOWNLOAD_MNIST = True\n\ntrain_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\ntrain_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),\n                                   nn.ReLU(), nn.MaxPool2d(kernel_size=2),)\n        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2),)\n        \n        self.bn = InPlaceABN(32)\n        self.out = nn.Linear(32 * 7 * 7, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.bn(x)\n        x = x.view(x.size(0), -1)\n        output = self.out(x)\n        return output\n\ncnn = CNN()\n\ncnn.to(device)      # Moves all model parameters and buffers to the GPU\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\nloss_func = nn.CrossEntropyLoss().cuda(device)\n\nfor epoch in range(EPOCH):\n    for step, (x, y) in enumerate(train_loader):\n        \n        b_x = x.to(device)     # Tensor on GPU\n        b_y = y.to(device)     # Tensor on GPU\n        \n        # This is where error happens\n        output = cnn(b_x)\n        loss = loss_func(output, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 50 == 0:\n            print(\"Test passed\")\n            break\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-2-c7d32883c675> in <module>()\n     60         b_y = y.to(device)     # Tensor on GPU\n     61 \n---> 62         output = cnn(b_x)\n     63         loss = loss_func(output, b_y)\n     64         optimizer.zero_grad()\n\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--> 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n<ipython-input-2-c7d32883c675> in forward(self, x)\n     41         x = self.conv1(x)\n     42         x = self.conv2(x)\n---> 43         x = self.bn(x)\n     44         x = x.view(x.size(0), -1)\n     45         output = self.out(x)\n\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    489             result = self._slow_forward(*input, **kwargs)\n    490         else:\n--> 491             result = self.forward(*input, **kwargs)\n    492         for hook in self._forward_hooks.values():\n    493             hook_result = hook(self, input, result)\n\n~/kaggle_salt/modules/bn.py in forward(self, x)\n    106     def forward(self, x):\n    107         return inplace_abn(x, self.weight, self.bias, self.running_mean, self.running_var,\n--> 108                            self.training, self.momentum, self.eps, self.activation, self.slope)\n    109 \n    110 \n\n~/kaggle_salt/modules/functions.py in forward(ctx, x, weight, bias, running_mean, running_var, training, momentum, eps, activation, slope)\n     97 \n     98             # Update running stats\n---> 99             running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * mean)\n    100             running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * var * count / (count - 1))\n    101 \n\nRuntimeError: arguments are located on different GPUs at /pytorch/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:233\n\nSystem Info\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nPyTorch version: 0.4.0\nIs debug build: No\nCUDA used to build PyTorch: 8.0.61\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\nCMake version: version 3.12.0\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\nNvidia driver version: 384.130\ncuDNN version: Probably one of the following:\n/usr/local/cuda-8.0/lib64/libcudnn.so\n/usr/local/cuda-8.0/lib64/libcudnn.so.6\n/usr/local/cuda-8.0/lib64/libcudnn.so.6.0.21\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.0.5\n/usr/local/cuda-9.0/lib64/libcudnn_static.a", "body": "## Issue description\r\nAfter using torch.utils.cpp_extension.load, returned module always puts tensors at GPU 0 ('cuda:0')\r\nIt causes problems when model is moved to another GPU. \r\nIn my example I used code from https://github.com/mapillary/inplace_abn\r\nSee also mapillary/inplace_abn#52\r\n\r\n## Code example\r\n```\r\n\"\"\"\r\nexample from https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/502_GPU.py\r\nDependencies:\r\ntorch: 0.4\r\ntorchvision\r\n\"\"\"\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.utils.data as Data\r\nimport torchvision\r\n\r\nfrom modules.bn import InPlaceABN \r\n\r\n#===================================#\r\n# Change to cuda:0 to make it work  #\r\ndevice = torch.device('cuda:1')     #\r\nprint(device)                       #\r\n#===================================#\r\n\r\nEPOCH = 1\r\nBATCH_SIZE = 50\r\nLR = 0.001\r\nDOWNLOAD_MNIST = True\r\n\r\ntrain_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\r\ntrain_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\r\n\r\n\r\nclass CNN(nn.Module):\r\n    def __init__(self):\r\n        super(CNN, self).__init__()\r\n        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),\r\n                                   nn.ReLU(), nn.MaxPool2d(kernel_size=2),)\r\n        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2),)\r\n        \r\n        self.bn = InPlaceABN(32)\r\n        self.out = nn.Linear(32 * 7 * 7, 10)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.conv2(x)\r\n        x = self.bn(x)\r\n        x = x.view(x.size(0), -1)\r\n        output = self.out(x)\r\n        return output\r\n\r\ncnn = CNN()\r\n\r\ncnn.to(device)      # Moves all model parameters and buffers to the GPU\r\n\r\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\r\nloss_func = nn.CrossEntropyLoss().cuda(device)\r\n\r\nfor epoch in range(EPOCH):\r\n    for step, (x, y) in enumerate(train_loader):\r\n        \r\n        b_x = x.to(device)     # Tensor on GPU\r\n        b_y = y.to(device)     # Tensor on GPU\r\n        \r\n        # This is where error happens\r\n        output = cnn(b_x)\r\n        loss = loss_func(output, b_y)\r\n        optimizer.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n\r\n        if step % 50 == 0:\r\n            print(\"Test passed\")\r\n            break\r\n\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-c7d32883c675> in <module>()\r\n     60         b_y = y.to(device)     # Tensor on GPU\r\n     61 \r\n---> 62         output = cnn(b_x)\r\n     63         loss = loss_func(output, b_y)\r\n     64         optimizer.zero_grad()\r\n\r\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    489             result = self._slow_forward(*input, **kwargs)\r\n    490         else:\r\n--> 491             result = self.forward(*input, **kwargs)\r\n    492         for hook in self._forward_hooks.values():\r\n    493             hook_result = hook(self, input, result)\r\n\r\n<ipython-input-2-c7d32883c675> in forward(self, x)\r\n     41         x = self.conv1(x)\r\n     42         x = self.conv2(x)\r\n---> 43         x = self.bn(x)\r\n     44         x = x.view(x.size(0), -1)\r\n     45         output = self.out(x)\r\n\r\n~/torch-py3/lib/python3.5/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    489             result = self._slow_forward(*input, **kwargs)\r\n    490         else:\r\n--> 491             result = self.forward(*input, **kwargs)\r\n    492         for hook in self._forward_hooks.values():\r\n    493             hook_result = hook(self, input, result)\r\n\r\n~/kaggle_salt/modules/bn.py in forward(self, x)\r\n    106     def forward(self, x):\r\n    107         return inplace_abn(x, self.weight, self.bias, self.running_mean, self.running_var,\r\n--> 108                            self.training, self.momentum, self.eps, self.activation, self.slope)\r\n    109 \r\n    110 \r\n\r\n~/kaggle_salt/modules/functions.py in forward(ctx, x, weight, bias, running_mean, running_var, training, momentum, eps, activation, slope)\r\n     97 \r\n     98             # Update running stats\r\n---> 99             running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * mean)\r\n    100             running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * var * count / (count - 1))\r\n    101 \r\n\r\nRuntimeError: arguments are located on different GPUs at /pytorch/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:233\r\n```\r\n## System Info\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\nPyTorch version: 0.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 8.0.61\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 384.130\r\ncuDNN version: Probably one of the following:\r\n/usr/local/cuda-8.0/lib64/libcudnn.so\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.6\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.6.0.21\r\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n/usr/local/cuda-9.0/lib64/libcudnn.so.7.0.5\r\n/usr/local/cuda-9.0/lib64/libcudnn_static.a\r\n"}