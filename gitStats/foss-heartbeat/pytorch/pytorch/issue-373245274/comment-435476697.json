{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/435476697", "html_url": "https://github.com/pytorch/pytorch/issues/13023#issuecomment-435476697", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13023", "id": 435476697, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTQ3NjY5Nw==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-02T18:58:34Z", "updated_at": "2018-11-02T18:58:34Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>Exactly. Those are very very stateful objects, and do a lot of preprocessing in the background, so I'm not sure if that's even feasible and useful in many cases. I'd err on the side of simplicity and avoid implementing that.</p>\n</blockquote>\n<p>Being able to pause &amp; continue is still very useful, especially when you have huge amount of samples per epoch. Since we are already able to serialize tensors, maybe this isn't too big a problem. I'll investigate and see.</p>\n<blockquote>\n<blockquote>\n<p>It's used a lot, but not standard so we can't rely on that.<br>\nI'm not sure if I understand. Can you please elaborate?</p>\n</blockquote>\n</blockquote>\n<p>I was talking about that returning <code>self</code> in <code>__iter__</code> can't be relied upon. And yes, you can't use the for loop syntax in this case, but I would say that if you need advanced options like this, asking them to use the iterator object explicitly is reasonable :).</p>\n<blockquote>\n<p>Can you also please elaborate on the API and maybe post an example? I'm not exactly sure how would someone use it based on your description.</p>\n</blockquote>\n<p>We abandoned that idea. Now the new idea is to introduce a function maybe called <code>torch.utils.data.get_worker_id</code> which returns worker id in worker processes, and errors in main process.</p>", "body_text": "Exactly. Those are very very stateful objects, and do a lot of preprocessing in the background, so I'm not sure if that's even feasible and useful in many cases. I'd err on the side of simplicity and avoid implementing that.\n\nBeing able to pause & continue is still very useful, especially when you have huge amount of samples per epoch. Since we are already able to serialize tensors, maybe this isn't too big a problem. I'll investigate and see.\n\n\nIt's used a lot, but not standard so we can't rely on that.\nI'm not sure if I understand. Can you please elaborate?\n\n\nI was talking about that returning self in __iter__ can't be relied upon. And yes, you can't use the for loop syntax in this case, but I would say that if you need advanced options like this, asking them to use the iterator object explicitly is reasonable :).\n\nCan you also please elaborate on the API and maybe post an example? I'm not exactly sure how would someone use it based on your description.\n\nWe abandoned that idea. Now the new idea is to introduce a function maybe called torch.utils.data.get_worker_id which returns worker id in worker processes, and errors in main process.", "body": "> Exactly. Those are very very stateful objects, and do a lot of preprocessing in the background, so I'm not sure if that's even feasible and useful in many cases. I'd err on the side of simplicity and avoid implementing that. \r\n\r\nBeing able to pause & continue is still very useful, especially when you have huge amount of samples per epoch. Since we are already able to serialize tensors, maybe this isn't too big a problem. I'll investigate and see.\r\n\r\n>> It's used a lot, but not standard so we can't rely on that.\r\n> I'm not sure if I understand. Can you please elaborate?\r\n\r\nI was talking about that returning `self` in `__iter__` can't be relied upon. And yes, you can't use the for loop syntax in this case, but I would say that if you need advanced options like this, asking them to use the iterator object explicitly is reasonable :).\r\n\r\n> Can you also please elaborate on the API and maybe post an example? I'm not exactly sure how would someone use it based on your description.\r\n\r\nWe abandoned that idea. Now the new idea is to introduce a function maybe called `torch.utils.data.get_worker_id` which returns worker id in worker processes, and errors in main process."}