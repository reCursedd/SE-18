{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/434445352", "html_url": "https://github.com/pytorch/pytorch/issues/13023#issuecomment-434445352", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13023", "id": 434445352, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDQ0NTM1Mg==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-30T19:52:54Z", "updated_at": "2018-10-30T19:52:54Z", "author_association": "MEMBER", "body_html": "<p>A few questions regarding your points:</p>\n<blockquote>\n<p>Iterator Serialization</p>\n</blockquote>\n<p>Do you expect the iterator to resume from the beginning or from the particular place at which it was serialized? If you thought about the first case, why would be serialize the iterator instead of the data loader?</p>\n<blockquote>\n<p>Examples of Bulk Loading</p>\n</blockquote>\n<p>Yes, please. We might want to add code like that to the core as well.</p>\n<blockquote>\n<p>Expose Sampler iterator</p>\n</blockquote>\n<p>Sounds reasonable. The only downside I see with this approach is that it's impossible to do that while having the nice <code>for</code> loop syntax, since Python calls <code>iter</code> for you in that case, but I guess that's fine. I'm not sure if returning <code>self</code> from <code>__iter__</code> is a standard practice or not.</p>\n<p>NB implementing a flag that enforces strict consistency is possible too (we could flush the pipeline, and retry with new sample indices), but it's not all that simple, so I'd wait until it's really needed before we proceed.</p>\n<blockquote>\n<p>More flexible <code>worker_init_fn</code></p>\n</blockquote>\n<p>I don't think I fully understand the API. It seems to me that it would be much simpler to just accept an extra argument in the data loader, which would be a list of length equal to <code>num_workers</code>, where every element is a tuple of args to append to <code>init_worker_fn</code>.</p>\n<blockquote>\n<p>Bridging C++ and Python DataLoaders</p>\n</blockquote>\n<p>That is currently very hard because they have different semantics (C++ data loaders can only have a single iterator at any time, as they heavily rely on mutation of internal state). IMHO we should make C++ iterators behave exactly like those in Python.</p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a> is also adding a bunch of exciting features into the C++ DataLoader to allow for greater flexibility (e.g., see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"372752949\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12960\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12960/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12960\">#12960</a> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"373153128\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12999\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12999/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12999\">#12999</a>)</p>\n</blockquote>\n<p>I'd really like us to discuss those changes more before we introduce them, because currently we're making Python and C++ worlds more and more different, which contradicts the previous point.</p>", "body_text": "A few questions regarding your points:\n\nIterator Serialization\n\nDo you expect the iterator to resume from the beginning or from the particular place at which it was serialized? If you thought about the first case, why would be serialize the iterator instead of the data loader?\n\nExamples of Bulk Loading\n\nYes, please. We might want to add code like that to the core as well.\n\nExpose Sampler iterator\n\nSounds reasonable. The only downside I see with this approach is that it's impossible to do that while having the nice for loop syntax, since Python calls iter for you in that case, but I guess that's fine. I'm not sure if returning self from __iter__ is a standard practice or not.\nNB implementing a flag that enforces strict consistency is possible too (we could flush the pipeline, and retry with new sample indices), but it's not all that simple, so I'd wait until it's really needed before we proceed.\n\nMore flexible worker_init_fn\n\nI don't think I fully understand the API. It seems to me that it would be much simpler to just accept an extra argument in the data loader, which would be a list of length equal to num_workers, where every element is a tuple of args to append to init_worker_fn.\n\nBridging C++ and Python DataLoaders\n\nThat is currently very hard because they have different semantics (C++ data loaders can only have a single iterator at any time, as they heavily rely on mutation of internal state). IMHO we should make C++ iterators behave exactly like those in Python.\n\n@goldsborough is also adding a bunch of exciting features into the C++ DataLoader to allow for greater flexibility (e.g., see #12960 #12999)\n\nI'd really like us to discuss those changes more before we introduce them, because currently we're making Python and C++ worlds more and more different, which contradicts the previous point.", "body": "A few questions regarding your points:\r\n\r\n> Iterator Serialization\r\n\r\nDo you expect the iterator to resume from the beginning or from the particular place at which it was serialized? If you thought about the first case, why would be serialize the iterator instead of the data loader?\r\n\r\n> Examples of Bulk Loading\r\n\r\nYes, please. We might want to add code like that to the core as well.\r\n\r\n> Expose Sampler iterator\r\n\r\nSounds reasonable. The only downside I see with this approach is that it's impossible to do that while having the nice `for` loop syntax, since Python calls `iter` for you in that case, but I guess that's fine. I'm not sure if returning `self` from `__iter__` is a standard practice or not.\r\n\r\nNB implementing a flag that enforces strict consistency is possible too (we could flush the pipeline, and retry with new sample indices), but it's not all that simple, so I'd wait until it's really needed before we proceed.\r\n\r\n> More flexible `worker_init_fn`\r\n\r\nI don't think I fully understand the API. It seems to me that it would be much simpler to just accept an extra argument in the data loader, which would be a list of length equal to `num_workers`, where every element is a tuple of args to append to `init_worker_fn`.\r\n\r\n> Bridging C++ and Python DataLoaders\r\n\r\nThat is currently very hard because they have different semantics (C++ data loaders can only have a single iterator at any time, as they heavily rely on mutation of internal state). IMHO we should make C++ iterators behave exactly like those in Python.\r\n\r\n> @goldsborough is also adding a bunch of exciting features into the C++ DataLoader to allow for greater flexibility (e.g., see #12960 #12999)\r\n\r\nI'd really like us to discuss those changes more before we introduce them, because currently we're making Python and C++ worlds more and more different, which contradicts the previous point."}