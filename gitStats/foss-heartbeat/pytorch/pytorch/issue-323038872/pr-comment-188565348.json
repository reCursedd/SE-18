{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188565348", "pull_request_review_id": 120566689, "id": 188565348, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4ODU2NTM0OA==", "diff_hunk": "@@ -0,0 +1,326 @@\n+#include \"TcpStore.hpp\"\n+\n+#include <poll.h>\n+#include <unistd.h>\n+#include <system_error>\n+\n+namespace c10d {\n+\n+namespace {\n+\n+enum class QueryType : std::uint8_t {\n+  SET,\n+  GET,\n+  ADD,\n+  CHECK\n+};\n+\n+enum class CheckResponseType : std::uint8_t {\n+  READY,\n+  NOT_READY\n+};\n+\n+} // anonymous namespace\n+\n+// TCPStoreDaemon class methods\n+// Simply start the daemon thread\n+TCPStoreDaemon::TCPStoreDaemon(int storeListenSocket) :\n+  storeListenSocket_(storeListenSocket)\n+{\n+  daemonThread_ = std::thread(&TCPStoreDaemon::run, this);\n+}\n+\n+TCPStoreDaemon::~TCPStoreDaemon() {\n+\n+  // Stop the run\n+  stop();\n+\n+  // Join the thread\n+  join();\n+\n+  // Close unclosed sockets\n+  for (auto socket : sockets_) {\n+    if (socket != -1) {\n+      ::close(socket);\n+    }\n+  }\n+  // Now close the rest control pipe\n+  for (auto fd : controlPipeFd_) {\n+    if (fd != -1) {\n+      ::close(fd);\n+    }\n+  }\n+}\n+\n+void TCPStoreDaemon::join() {\n+  daemonThread_.join();\n+}\n+\n+void TCPStoreDaemon::run() {\n+\n+  // Create the control pipe\n+  controlPipeFd_ = std::vector<int>{-1, -1};\n+  if (pipe(controlPipeFd_.data()) == -1) {\n+    throw std::runtime_error(\"Failed to create the control pipe to start the \"\n+                             \"TCPStoreDaemon run\");\n+  }\n+\n+  std::vector<struct pollfd> fds;\n+  fds.push_back({ .fd = storeListenSocket_, .events = POLLIN });\n+  // Push the read end of the pipe to signal the stopping of the daemon run\n+  fds.push_back({ .fd = controlPipeFd_[0], .events = POLLHUP });\n+\n+  // receive the queries\n+  bool finished = false;\n+  while (!finished) {\n+    for (size_t i = 0; i < sockets_.size(); i++) {\n+      fds[i].revents = 0;\n+    }\n+\n+    SYSCHECK(::poll(fds.data(), fds.size(), -1));\n+\n+    /**\n+     * TCPStore's listening socket has an event and it should now be able to\n+     * accept new connections.\n+     */\n+    if (fds[0].revents != 0) {\n+      if (fds[0].revents ^ POLLIN) {\n+        throw std::system_error(ECONNABORTED, std::system_category(),\n+            \"Unexpected poll revent on the master's listening socket: \" +\n+            std::to_string(fds[0].revents));\n+      }\n+      int sockFd = std::get<0>(tcputil::accept(storeListenSocket_));\n+      sockets_.push_back(sockFd);\n+      fds.push_back({ .fd = sockFd, .events = POLLIN });\n+    }\n+    /**\n+     * The pipe receives an event which tells us to shutdown the daemon\n+     */\n+    if (fds[1].revents != 0) {\n+      // Will be POLLUP when the pipe is closed\n+      if (fds[1].revents ^ POLLHUP) {\n+        throw std::system_error(ECONNABORTED, std::system_category(),\n+            \"Unexpected poll revent on the control pipe's reading fd: \" +\n+            std::to_string(fds[1].revents));\n+      }\n+      finished = true;\n+      break;\n+    }\n+    /**\n+     * Skipping the fds[0] and fds[1],\n+     * fds[0] is master's listening socket\n+     * fds[1] is control pipe's reading fd\n+     */\n+    for (size_t fdIdx = 2; fdIdx < fds.size(); ++fdIdx) {\n+      if (fds[fdIdx].revents == 0) {\n+        continue;\n+      }\n+\n+      if (fds[fdIdx].revents ^ POLLIN) {\n+        throw std::system_error(ECONNABORTED, std::system_category(),\n+            \"Unexpected poll revent: \" +\n+            std::to_string(fds[fdIdx].revents) + \" on socket: \" +\n+            std::to_string(fds[fdIdx].fd));\n+      }\n+      // Now query the socket that has the event\n+      try {\n+        query(fds[fdIdx].fd);\n+      } catch (...) {\n+        /**\n+         * There was an error when processing query. Probably an exception\n+         * occurred in recv/send what would indicate that socket on the other\n+         * side has been closed. If the closing was due to normal exit, then the\n+         * store should continue executing. Otherwise, if it was different\n+         * exception, other connections will get an exception once they try to\n+         * use the store. We will go ahead and close this connection whenever\n+         * we hit an exception here.\n+         */\n+        ::close(fds[fdIdx].fd);\n+        fds.erase(fds.begin() + fdIdx);\n+        sockets_.erase(sockets_.begin() + fdIdx - 2);\n+        --fdIdx;\n+        continue;\n+      }\n+    }\n+  }\n+}\n+\n+void TCPStoreDaemon::stop() {\n+  if (controlPipeFd_.size() == 2 && controlPipeFd_[1] != -1) {\n+    // close the write end of the pipe\n+    ::close(controlPipeFd_[1]);\n+    controlPipeFd_[1] = -1;\n+  }\n+}\n+\n+/**\n+ * query communicates with the worker. The format\n+ * of the query is as follows:\n+ * type of query | size of arg1 | arg1 | size of arg2 | arg2 | ...\n+ * or, in the case of wait\n+ * type of query | number of args | size of arg1 | arg1 | ...\n+ */\n+void TCPStoreDaemon::query(int socket) {\n+\n+  QueryType qt;\n+  tcputil::recvBytes<QueryType>(socket, &qt, 1);\n+\n+  if (qt == QueryType::SET) {\n+    setHandler(socket);\n+\n+  } else if (qt == QueryType::ADD) {\n+    addHandler(socket);\n+\n+  } else if (qt == QueryType::GET) {\n+    getHandler(socket);\n+\n+  } else if (qt == QueryType::CHECK) {\n+    checkHandler(socket);\n+\n+  } else {\n+    throw std::runtime_error(\"Unexpected query type\");\n+  }\n+}\n+\n+void TCPStoreDaemon::setHandler(int socket) {\n+  std::string key = tcputil::recvString(socket);\n+  tcpStore_[key] = tcputil::recvVector<uint8_t>(socket);\n+}\n+\n+void TCPStoreDaemon::addHandler(int socket) {\n+  std::string key = tcputil::recvString(socket);\n+  int64_t addVal = tcputil::recvValue<int64_t>(socket);\n+\n+  if (tcpStore_.find(key) != tcpStore_.end()) {\n+    auto buf = reinterpret_cast<const char*>(tcpStore_[key].data());\n+    auto len = tcpStore_[key].size();\n+    addVal += std::stoll(std::string(buf, len));\n+  }\n+  auto addValStr = std::to_string(addVal);\n+  tcpStore_[key] = std::vector<uint8_t>(addValStr.begin(), addValStr.end());\n+  // Now send the new value\n+  tcputil::sendValue<int64_t>(socket, addVal);\n+}\n+\n+void TCPStoreDaemon::getHandler(int socket) {\n+  std::string key = tcputil::recvString(socket);\n+  auto data = tcpStore_.at(key);\n+  tcputil::sendVector<uint8_t>(socket, data);\n+}\n+\n+void TCPStoreDaemon::checkHandler(int socket) {\n+  SizeType nargs;\n+  tcputil::recvBytes<SizeType>(socket, &nargs, 1);\n+  std::vector<std::string> keys(nargs);\n+  for (size_t i = 0; i < nargs; i++) {\n+    keys[i] = tcputil::recvString(socket);\n+  }\n+  // Now we have received all the keys\n+  if (checkAndUpdate(keys)) {\n+    tcputil::sendValue<CheckResponseType>(socket, CheckResponseType::READY);\n+  } else {\n+    tcputil::sendValue<CheckResponseType>(socket, CheckResponseType::NOT_READY);\n+  }\n+}\n+\n+bool TCPStoreDaemon::checkAndUpdate(std::vector<std::string>& keys) const {\n+  bool ret = true;\n+  for (auto it = keys.begin(); it != keys.end();) {\n+    if (tcpStore_.count(*it) == 0) {\n+      ret = false;\n+      it++;\n+    } else {\n+      it = keys.erase(it);\n+    }\n+  }\n+  return ret;\n+}\n+\n+// TCPStore class methods\n+TCPStore::TCPStore(const std::string& masterAddr,\n+                   PortType masterPort,\n+                   bool isServer)\n+ : isServer_(isServer)\n+ , tcpStoreAddr_(masterAddr)\n+ , tcpStorePort_(masterPort)\n+\n+{\n+  if (isServer_) {\n+    // Opening up the listening socket\n+    std::tie(masterListenSocket_, std::ignore) = tcputil::listen(masterPort);\n+    // Now start the daemon\n+    tcpStoreDaemon_ = std::unique_ptr<TCPStoreDaemon>(\n+        new TCPStoreDaemon(masterListenSocket_)\n+    );\n+  }\n+  // Connect to the daemon\n+  storeSocket_ = tcputil::connect(tcpStoreAddr_, tcpStorePort_);\n+}\n+\n+TCPStore::~TCPStore() {\n+  ::close(storeSocket_);\n+  if (isServer_) {\n+    /**\n+     * Store daemon should end because of closed connection.\n+     * daemon destructor should join the thread\n+     */\n+    tcpStoreDaemon_.reset(nullptr);\n+    ::close(masterListenSocket_);\n+  }\n+}\n+\n+void TCPStore::set(const std::string& key, const std::vector<uint8_t>& data) {\n+  tcputil::sendValue<QueryType>(storeSocket_, QueryType::SET);\n+  tcputil::sendString(storeSocket_, key, true);\n+  tcputil::sendVector<uint8_t>(storeSocket_, data);\n+}\n+\n+std::vector<uint8_t> TCPStore::get(const std::string& key) {\n+  wait({key});\n+  tcputil::sendValue<QueryType>(storeSocket_, QueryType::GET);\n+  tcputil::sendString(storeSocket_, key);\n+  return tcputil::recvVector<uint8_t>(storeSocket_);\n+}\n+\n+int64_t TCPStore::add(const std::string& key, int64_t value) {\n+  tcputil::sendValue<QueryType>(storeSocket_, QueryType::ADD);\n+  tcputil::sendString(storeSocket_, key, true);\n+  tcputil::sendValue<int64_t>(storeSocket_, value);\n+  return tcputil::recvValue<int64_t>(storeSocket_);\n+}\n+\n+bool TCPStore::check(const std::vector<std::string>& keys) {\n+\n+  tcputil::sendValue<QueryType>(storeSocket_, QueryType::CHECK);\n+  SizeType nkeys = keys.size();\n+  tcputil::sendBytes<SizeType>(storeSocket_, &nkeys, 1, (nkeys > 0));\n+  for (size_t i = 0; i < nkeys; i++) {\n+    tcputil::sendString(storeSocket_, keys[i], (i != (nkeys - 1)));\n+  }\n+  auto checkResponse = tcputil::recvValue<CheckResponseType>(storeSocket_);\n+  if (checkResponse == CheckResponseType::READY) {\n+    return true;\n+  } else if (checkResponse == CheckResponseType::NOT_READY) {\n+    return false;\n+  } else {\n+    throw std::runtime_error(\"ready or not_ready response expected\");\n+  }\n+}\n+\n+void TCPStore::wait(\n+    const std::vector<std::string>& keys,\n+    const std::chrono::milliseconds& timeout) {\n+\n+  const auto start = std::chrono::steady_clock::now();\n+  while (!check(keys)) {\n+    const auto elapsed = std::chrono::duration_cast<std::chrono::seconds>(\n+        std::chrono::steady_clock::now() - start);\n+    if (timeout != kNoTimeout && elapsed > timeout) {\n+      throw std::runtime_error(\"Wait timeout\");\n+    }\n+    /* sleep override */\n+    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n+  }", "path": "torch/lib/c10d/TcpStore.cpp", "position": null, "original_position": 323, "commit_id": "ba48f051925b6a9d49113e5d8ca43ebd3f551993", "original_commit_id": "50e1362121ebf7c31269eb9b3d5f4e1ec40dd481", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Perhaps this should just become the default implementation of `wait` for different stores? I think we're using the same strategy both in here and in the file one. Wdyt @pietern?", "created_at": "2018-05-16T09:47:33Z", "updated_at": "2018-11-23T15:44:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/7560#discussion_r188565348", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7560", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/188565348"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7560#discussion_r188565348"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7560"}}, "body_html": "<p>Perhaps this should just become the default implementation of <code>wait</code> for different stores? I think we're using the same strategy both in here and in the file one. Wdyt <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9845\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pietern\">@pietern</a>?</p>", "body_text": "Perhaps this should just become the default implementation of wait for different stores? I think we're using the same strategy both in here and in the file one. Wdyt @pietern?"}