{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3016", "id": 145263517, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ1MjYzNTE3", "html_url": "https://github.com/pytorch/pytorch/pull/3016", "diff_url": "https://github.com/pytorch/pytorch/pull/3016.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3016.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3016", "number": 3016, "state": "closed", "locked": false, "title": "Introduce scopes during tracing", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "body": "This PR introduces scopes (or namespaces) in order to group operations in the tracing IR, e.g.\r\n\r\n```python\r\nx = Variable(torch.Tensor([0.4]), requires_grad=True)\r\ny = Variable(torch.Tensor([0.7]), requires_grad=True)\r\n\r\ndef doit(x, y):\r\n    tracing_state = torch.jit.get_tracing_state(x,y)\r\n    if tracing_state:\r\n        tracing_state.push_scope('Foo')\r\n    z = Variable(torch.Tensor([0.7]), requires_grad=True)\r\n    out = torch.sigmoid(torch.tanh(x * (y + z)))\r\n    if tracing_state:\r\n        tracing_state.pop_scope()\r\n    return out\r\n\r\ntraced, _ = torch.jit.trace(doit, (x, y))\r\ng = torch._C._jit_get_graph(traced)\r\nprint(g)\r\n```\r\n\r\noutputs\r\n\r\n```\r\ngraph(%1 : Float(1)\r\n      %2 : Float(1)) {\r\n  %3 : Float(1) = Constant[value=<Tensor>](), uses = [%4.i1], scope: Foo;\r\n  %5 : Float(1) = ^Add(False)(%2, %3), uses = [[%6.i1]], scope: Foo;\r\n  %7 : Float(1) = ^Mul()(%1, %5), uses = [[%8.i0]], scope: Foo;\r\n  %9 : Float(1) = ^Tanh()(%7), uses = [[%10.i0]], scope: Foo;\r\n  %11 : Float(1) = ^Sigmoid()(%9), uses = [[%0.i0]], scope: Foo;\r\n  return (%11);\r\n}\r\n```\r\n\r\nScopes work like a stack: they can be pushed and popped manually (as in the example above). Modules automatically push a scope during `__call__` and pops it before returning. The scope is named as `className$id`, where id is the value of the Python `id` function:\r\n\r\n```python\r\nclass Net(nn.Module):\r\n\r\n        def __init__(self):\r\n            super(Net, self).__init__()\r\n            self.layer1 = nn.Sequential(nn.Linear(2,2), nn.ReLU())\r\n\r\n        def forward(self, x):\r\n            return self.layer1(x)\r\n\r\n    net = Net()\r\n\r\n    t = Variable(torch.ones(2), requires_grad=True)\r\n\r\n    traced, _ = torch.jit.trace(net, (t, ))\r\n    g = torch._C._jit_get_graph(traced)\r\n    print(g)\r\n```\r\n\r\noutputs\r\n\r\n```\r\ngraph(%1 : Float(2)\r\n      %2 : Float(2, 2)\r\n      %3 : Float(2)) {\r\n  %5 : Float(2!, 2!) = ^Transpose(0, 1)(%2), uses = [[%10.i2]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %7 : Float(1, 2), %8 : Handle = ^Unsqueeze(0)(%1), uses = [[%10.i1], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %9 : Float(1, 2) = Constant[value=<Tensor>](), uses = [%10.i0], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %11 : Float(1, 2), %12 : Handle = ^Addmm(0, 1, True)(%9, %7, %5), uses = [[%13.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %14 : Float(2), %15 : Handle = ^Squeeze(0, True)(%11), uses = [[%16.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %17 : Float(2) = ^Add(True)(%14, %3), uses = [[%18.i0]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\r\n  %19 : Float(2), %20 : Handle = ^Threshold(0, 0, False)(%17), uses = [[%0.i0], []], scope: Net$4569918736.Sequential$4569919312.ReLU$4569919184;\r\n  return (%19);\r\n}\r\n``` \r\n\r\n*Tests fail at the moment* because the expected output of traces differs, as I added a `scope` description. I'm not sure it belongs there, at the moment it's handy for debugging purposes. If we decide to keep them this way I'll update the expected output.\r\n\r\nUnder the hood, scope names are implemented using interned strings.\r\n\r\n/cc @ezyang @fmassa", "created_at": "2017-10-06T23:17:54Z", "updated_at": "2018-11-23T15:37:02Z", "closed_at": "2017-12-04T17:19:07Z", "merged_at": "2017-12-04T17:19:07Z", "merge_commit_sha": "4eb8e1276511a07ced781e7b36da39cedc4f15cc", "assignee": null, "assignees": [], "requested_reviewers": [], "requested_teams": [], "labels": [], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3016/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3016/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3016/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/1ef21e12c8ecdbfde2a5ac10e2ab8f5b4c5cc7f7", "head": {"label": "lantiga:scopes", "ref": "scopes", "sha": "1ef21e12c8ecdbfde2a5ac10e2ab8f5b4c5cc7f7", "user": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "repo": {"id": 87643601, "node_id": "MDEwOlJlcG9zaXRvcnk4NzY0MzYwMQ==", "name": "pytorch", "full_name": "lantiga/pytorch", "private": false, "owner": {"login": "lantiga", "id": 191033, "node_id": "MDQ6VXNlcjE5MTAzMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/191033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lantiga", "html_url": "https://github.com/lantiga", "followers_url": "https://api.github.com/users/lantiga/followers", "following_url": "https://api.github.com/users/lantiga/following{/other_user}", "gists_url": "https://api.github.com/users/lantiga/gists{/gist_id}", "starred_url": "https://api.github.com/users/lantiga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lantiga/subscriptions", "organizations_url": "https://api.github.com/users/lantiga/orgs", "repos_url": "https://api.github.com/users/lantiga/repos", "events_url": "https://api.github.com/users/lantiga/events{/privacy}", "received_events_url": "https://api.github.com/users/lantiga/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/lantiga/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/lantiga/pytorch", "forks_url": "https://api.github.com/repos/lantiga/pytorch/forks", "keys_url": "https://api.github.com/repos/lantiga/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/lantiga/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/lantiga/pytorch/teams", "hooks_url": "https://api.github.com/repos/lantiga/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/lantiga/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/lantiga/pytorch/events", "assignees_url": "https://api.github.com/repos/lantiga/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/lantiga/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/lantiga/pytorch/tags", "blobs_url": "https://api.github.com/repos/lantiga/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/lantiga/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/lantiga/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/lantiga/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/lantiga/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/lantiga/pytorch/languages", "stargazers_url": "https://api.github.com/repos/lantiga/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/lantiga/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/lantiga/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/lantiga/pytorch/subscription", "commits_url": "https://api.github.com/repos/lantiga/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/lantiga/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/lantiga/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/lantiga/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/lantiga/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/lantiga/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/lantiga/pytorch/merges", "archive_url": "https://api.github.com/repos/lantiga/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/lantiga/pytorch/downloads", "issues_url": "https://api.github.com/repos/lantiga/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/lantiga/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/lantiga/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/lantiga/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/lantiga/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/lantiga/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/lantiga/pytorch/deployments", "created_at": "2017-04-08T15:26:35Z", "updated_at": "2017-04-08T15:26:40Z", "pushed_at": "2018-09-27T14:17:29Z", "git_url": "git://github.com/lantiga/pytorch.git", "ssh_url": "git@github.com:lantiga/pytorch.git", "clone_url": "https://github.com/lantiga/pytorch.git", "svn_url": "https://github.com/lantiga/pytorch", "homepage": "http://pytorch.org", "size": 75447, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 0, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "710f6d6958a04d7f99735ed01543bb15f97b86cc", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T05:35:41Z", "pushed_at": "2018-11-24T05:34:07Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89651, "stargazers_count": 21577, "watchers_count": 21577, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5149, "mirror_url": null, "archived": false, "open_issues_count": 2193, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5149, "open_issues": 2193, "watchers": 21577, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3016"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3016"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/3016"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/3016/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3016/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3016/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/1ef21e12c8ecdbfde2a5ac10e2ab8f5b4c5cc7f7"}}, "author_association": "COLLABORATOR", "body_html": "<p>This PR introduces scopes (or namespaces) in order to group operations in the tracing IR, e.g.</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> Variable(torch.Tensor([<span class=\"pl-c1\">0.4</span>]), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\ny <span class=\"pl-k\">=</span> Variable(torch.Tensor([<span class=\"pl-c1\">0.7</span>]), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">doit</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>):\n    tracing_state <span class=\"pl-k\">=</span> torch.jit.get_tracing_state(x,y)\n    <span class=\"pl-k\">if</span> tracing_state:\n        tracing_state.push_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Foo<span class=\"pl-pds\">'</span></span>)\n    z <span class=\"pl-k\">=</span> Variable(torch.Tensor([<span class=\"pl-c1\">0.7</span>]), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    out <span class=\"pl-k\">=</span> torch.sigmoid(torch.tanh(x <span class=\"pl-k\">*</span> (y <span class=\"pl-k\">+</span> z)))\n    <span class=\"pl-k\">if</span> tracing_state:\n        tracing_state.pop_scope()\n    <span class=\"pl-k\">return</span> out\n\ntraced, _ <span class=\"pl-k\">=</span> torch.jit.trace(doit, (x, y))\ng <span class=\"pl-k\">=</span> torch._C._jit_get_graph(traced)\n<span class=\"pl-c1\">print</span>(g)</pre></div>\n<p>outputs</p>\n<pre><code>graph(%1 : Float(1)\n      %2 : Float(1)) {\n  %3 : Float(1) = Constant[value=&lt;Tensor&gt;](), uses = [%4.i1], scope: Foo;\n  %5 : Float(1) = ^Add(False)(%2, %3), uses = [[%6.i1]], scope: Foo;\n  %7 : Float(1) = ^Mul()(%1, %5), uses = [[%8.i0]], scope: Foo;\n  %9 : Float(1) = ^Tanh()(%7), uses = [[%10.i0]], scope: Foo;\n  %11 : Float(1) = ^Sigmoid()(%9), uses = [[%0.i0]], scope: Foo;\n  return (%11);\n}\n</code></pre>\n<p>Scopes work like a stack: they can be pushed and popped manually (as in the example above). Modules automatically push a scope during <code>__call__</code> and pops it before returning. The scope is named as <code>className$id</code>, where id is the value of the Python <code>id</code> function:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            <span class=\"pl-c1\">super</span>(Net, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n            <span class=\"pl-c1\">self</span>.layer1 <span class=\"pl-k\">=</span> nn.Sequential(nn.Linear(<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">2</span>), nn.ReLU())\n\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n            <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.layer1(x)\n\n    net <span class=\"pl-k\">=</span> Net()\n\n    t <span class=\"pl-k\">=</span> Variable(torch.ones(<span class=\"pl-c1\">2</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    traced, _ <span class=\"pl-k\">=</span> torch.jit.trace(net, (t, ))\n    g <span class=\"pl-k\">=</span> torch._C._jit_get_graph(traced)\n    <span class=\"pl-c1\">print</span>(g)</pre></div>\n<p>outputs</p>\n<pre><code>graph(%1 : Float(2)\n      %2 : Float(2, 2)\n      %3 : Float(2)) {\n  %5 : Float(2!, 2!) = ^Transpose(0, 1)(%2), uses = [[%10.i2]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %7 : Float(1, 2), %8 : Handle = ^Unsqueeze(0)(%1), uses = [[%10.i1], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %9 : Float(1, 2) = Constant[value=&lt;Tensor&gt;](), uses = [%10.i0], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %11 : Float(1, 2), %12 : Handle = ^Addmm(0, 1, True)(%9, %7, %5), uses = [[%13.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %14 : Float(2), %15 : Handle = ^Squeeze(0, True)(%11), uses = [[%16.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %17 : Float(2) = ^Add(True)(%14, %3), uses = [[%18.i0]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %19 : Float(2), %20 : Handle = ^Threshold(0, 0, False)(%17), uses = [[%0.i0], []], scope: Net$4569918736.Sequential$4569919312.ReLU$4569919184;\n  return (%19);\n}\n</code></pre>\n<p><em>Tests fail at the moment</em> because the expected output of traces differs, as I added a <code>scope</code> description. I'm not sure it belongs there, at the moment it's handy for debugging purposes. If we decide to keep them this way I'll update the expected output.</p>\n<p>Under the hood, scope names are implemented using interned strings.</p>\n<p>/cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a></p>", "body_text": "This PR introduces scopes (or namespaces) in order to group operations in the tracing IR, e.g.\nx = Variable(torch.Tensor([0.4]), requires_grad=True)\ny = Variable(torch.Tensor([0.7]), requires_grad=True)\n\ndef doit(x, y):\n    tracing_state = torch.jit.get_tracing_state(x,y)\n    if tracing_state:\n        tracing_state.push_scope('Foo')\n    z = Variable(torch.Tensor([0.7]), requires_grad=True)\n    out = torch.sigmoid(torch.tanh(x * (y + z)))\n    if tracing_state:\n        tracing_state.pop_scope()\n    return out\n\ntraced, _ = torch.jit.trace(doit, (x, y))\ng = torch._C._jit_get_graph(traced)\nprint(g)\noutputs\ngraph(%1 : Float(1)\n      %2 : Float(1)) {\n  %3 : Float(1) = Constant[value=<Tensor>](), uses = [%4.i1], scope: Foo;\n  %5 : Float(1) = ^Add(False)(%2, %3), uses = [[%6.i1]], scope: Foo;\n  %7 : Float(1) = ^Mul()(%1, %5), uses = [[%8.i0]], scope: Foo;\n  %9 : Float(1) = ^Tanh()(%7), uses = [[%10.i0]], scope: Foo;\n  %11 : Float(1) = ^Sigmoid()(%9), uses = [[%0.i0]], scope: Foo;\n  return (%11);\n}\n\nScopes work like a stack: they can be pushed and popped manually (as in the example above). Modules automatically push a scope during __call__ and pops it before returning. The scope is named as className$id, where id is the value of the Python id function:\nclass Net(nn.Module):\n\n        def __init__(self):\n            super(Net, self).__init__()\n            self.layer1 = nn.Sequential(nn.Linear(2,2), nn.ReLU())\n\n        def forward(self, x):\n            return self.layer1(x)\n\n    net = Net()\n\n    t = Variable(torch.ones(2), requires_grad=True)\n\n    traced, _ = torch.jit.trace(net, (t, ))\n    g = torch._C._jit_get_graph(traced)\n    print(g)\noutputs\ngraph(%1 : Float(2)\n      %2 : Float(2, 2)\n      %3 : Float(2)) {\n  %5 : Float(2!, 2!) = ^Transpose(0, 1)(%2), uses = [[%10.i2]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %7 : Float(1, 2), %8 : Handle = ^Unsqueeze(0)(%1), uses = [[%10.i1], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %9 : Float(1, 2) = Constant[value=<Tensor>](), uses = [%10.i0], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %11 : Float(1, 2), %12 : Handle = ^Addmm(0, 1, True)(%9, %7, %5), uses = [[%13.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %14 : Float(2), %15 : Handle = ^Squeeze(0, True)(%11), uses = [[%16.i0], []], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %17 : Float(2) = ^Add(True)(%14, %3), uses = [[%18.i0]], scope: Net$4569918736.Sequential$4569919312.Linear$4569919120;\n  %19 : Float(2), %20 : Handle = ^Threshold(0, 0, False)(%17), uses = [[%0.i0], []], scope: Net$4569918736.Sequential$4569919312.ReLU$4569919184;\n  return (%19);\n}\n\nTests fail at the moment because the expected output of traces differs, as I added a scope description. I'm not sure it belongs there, at the moment it's handy for debugging purposes. If we decide to keep them this way I'll update the expected output.\nUnder the hood, scope names are implemented using interned strings.\n/cc @ezyang @fmassa", "merged": true, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "comments": 44, "review_comments": 111, "maintainer_can_modify": false, "commits": 9, "additions": 242, "deletions": 11, "changed_files": 11}