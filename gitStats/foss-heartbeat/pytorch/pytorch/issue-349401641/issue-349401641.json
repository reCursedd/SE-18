{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10396", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10396/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10396/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10396/events", "html_url": "https://github.com/pytorch/pytorch/issues/10396", "id": 349401641, "node_id": "MDU6SXNzdWUzNDk0MDE2NDE=", "number": 10396, "title": "[feature request] Provide a way to redirect shared memory prefix \"/torch_\"", "user": {"login": "sleepfin", "id": 7370869, "node_id": "MDQ6VXNlcjczNzA4Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/7370869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sleepfin", "html_url": "https://github.com/sleepfin", "followers_url": "https://api.github.com/users/sleepfin/followers", "following_url": "https://api.github.com/users/sleepfin/following{/other_user}", "gists_url": "https://api.github.com/users/sleepfin/gists{/gist_id}", "starred_url": "https://api.github.com/users/sleepfin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sleepfin/subscriptions", "organizations_url": "https://api.github.com/users/sleepfin/orgs", "repos_url": "https://api.github.com/users/sleepfin/repos", "events_url": "https://api.github.com/users/sleepfin/events{/privacy}", "received_events_url": "https://api.github.com/users/sleepfin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 545367190, "node_id": "MDU6TGFiZWw1NDUzNjcxOTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-08-10T07:13:32Z", "updated_at": "2018-08-21T07:49:57Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>If you have a question or would like help and support, please ask at our<br>\n<a href=\"https://discuss.pytorch.org/\" rel=\"nofollow\">forums</a>.</p>\n<p>If you are submitting a feature request, please preface the title with [feature request].<br>\nIf you are submitting a bug report, please fill in the following details.</p>\n<h2>Issue description</h2>\n<p>Shared memory in pytorch always use \u2018/torch_xxx' but there may be not enough space.<br>\nSo I get error like:</p>\n<pre><code>RuntimeError: unable to write to file &lt;/torch_76_3625483894&gt; at /pytorch/aten/src/TH/THAllocator.c:383\n</code></pre>\n<p>Related code:</p>\n<p><div class=\"border rounded-1 my-2\">\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\n    <p class=\"mb-0 text-bold\">\n      <a href=\"https://github.com/pytorch/pytorch/blob/4a6fbf03c62bcfbfdc60d955b48f5c44bfe42173/torch/csrc/generic/StorageSharing.cpp#L41\">pytorch/torch/csrc/generic/StorageSharing.cpp</a>\n    </p>\n    <p class=\"mb-0 text-gray-light\">\n         Line 41\n      in\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/pytorch/pytorch/commit/4a6fbf03c62bcfbfdc60d955b48f5c44bfe42173\">4a6fbf0</a>\n    </p>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\n\n        <tbody><tr class=\"border-0\">\n          <td id=\"L41\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"41\"></td>\n          <td id=\"LC41\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> std::string handle = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/torch_<span class=\"pl-pds\">\"</span></span>; </td>\n        </tr>\n    </tbody></table>\n  </div>\n</div>\n</p>\n<pre><code>std::string handle = \"/torch_\";\n</code></pre>\n<p>Can u provide a way to config or redirect the location of shared memory using environment variable. If the environment variable is not set, \"/torch_\" is used as default.</p>\n<h2>Code example</h2>\n<p>Please try to provide a minimal example to repro the bug.<br>\nError messages and stack traces are also helpful.</p>\n<h2>System Info</h2>\n<p>Please copy and paste the output from our<br>\n<a href=\"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\" rel=\"nofollow\">environment collection script</a><br>\n(or fill out the checklist below manually).</p>\n<p>You can get the script and run it with:</p>\n<pre><code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n</code></pre>\n<ul>\n<li>PyTorch or Caffe2: PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source): pip</li>\n<li>Build command you used (if compiling from source):</li>\n<li>OS: CentOS 7</li>\n<li>PyTorch version: 0.4.1</li>\n<li>Python version: 2.7 &amp; 3.6</li>\n<li>CUDA/cuDNN version:</li>\n<li>GPU models and configuration:</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Versions of any other relevant libraries:</li>\n</ul>", "body_text": "If you have a question or would like help and support, please ask at our\nforums.\nIf you are submitting a feature request, please preface the title with [feature request].\nIf you are submitting a bug report, please fill in the following details.\nIssue description\nShared memory in pytorch always use \u2018/torch_xxx' but there may be not enough space.\nSo I get error like:\nRuntimeError: unable to write to file </torch_76_3625483894> at /pytorch/aten/src/TH/THAllocator.c:383\n\nRelated code:\n\n  \n    \n      pytorch/torch/csrc/generic/StorageSharing.cpp\n    \n    \n         Line 41\n      in\n      4a6fbf0\n    \n    \n    \n    \n\n        \n          \n           std::string handle = \"/torch_\"; \n        \n    \n  \n\n\nstd::string handle = \"/torch_\";\n\nCan u provide a way to config or redirect the location of shared memory using environment variable. If the environment variable is not set, \"/torch_\" is used as default.\nCode example\nPlease try to provide a minimal example to repro the bug.\nError messages and stack traces are also helpful.\nSystem Info\nPlease copy and paste the output from our\nenvironment collection script\n(or fill out the checklist below manually).\nYou can get the script and run it with:\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n# For security purposes, please check the contents of collect_env.py before running it.\npython collect_env.py\n\n\nPyTorch or Caffe2: PyTorch\nHow you installed PyTorch (conda, pip, source): pip\nBuild command you used (if compiling from source):\nOS: CentOS 7\nPyTorch version: 0.4.1\nPython version: 2.7 & 3.6\nCUDA/cuDNN version:\nGPU models and configuration:\nGCC version (if compiling from source):\nCMake version:\nVersions of any other relevant libraries:", "body": "If you have a question or would like help and support, please ask at our\r\n[forums](https://discuss.pytorch.org/).\r\n\r\nIf you are submitting a feature request, please preface the title with [feature request].\r\nIf you are submitting a bug report, please fill in the following details.\r\n\r\n## Issue description\r\n\r\nShared memory in pytorch always use \u2018/torch_xxx' but there may be not enough space.\r\nSo I get error like:\r\n\r\n```\r\nRuntimeError: unable to write to file </torch_76_3625483894> at /pytorch/aten/src/TH/THAllocator.c:383\r\n```\r\n\r\nRelated code: \r\n\r\nhttps://github.com/pytorch/pytorch/blob/4a6fbf03c62bcfbfdc60d955b48f5c44bfe42173/torch/csrc/generic/StorageSharing.cpp#L41\r\n\r\n```\r\nstd::string handle = \"/torch_\";\r\n```\r\n\r\nCan u provide a way to config or redirect the location of shared memory using environment variable. If the environment variable is not set, \"/torch_\" is used as default.\r\n\r\n## Code example\r\n\r\nPlease try to provide a minimal example to repro the bug.\r\nError messages and stack traces are also helpful.\r\n\r\n## System Info\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\n- PyTorch or Caffe2: PyTorch\r\n- How you installed PyTorch (conda, pip, source): pip\r\n- Build command you used (if compiling from source):\r\n- OS: CentOS 7\r\n- PyTorch version: 0.4.1\r\n- Python version: 2.7 & 3.6\r\n- CUDA/cuDNN version: \r\n- GPU models and configuration:\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Versions of any other relevant libraries:\r\n"}