{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10207", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10207/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10207/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10207/events", "html_url": "https://github.com/pytorch/pytorch/issues/10207", "id": 347423380, "node_id": "MDU6SXNzdWUzNDc0MjMzODA=", "number": 10207, "title": "a strange torch.no_grad behaviour when used with lazy_property from distributions", "user": {"login": "serhii-havrylov", "id": 5736469, "node_id": "MDQ6VXNlcjU3MzY0Njk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5736469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/serhii-havrylov", "html_url": "https://github.com/serhii-havrylov", "followers_url": "https://api.github.com/users/serhii-havrylov/followers", "following_url": "https://api.github.com/users/serhii-havrylov/following{/other_user}", "gists_url": "https://api.github.com/users/serhii-havrylov/gists{/gist_id}", "starred_url": "https://api.github.com/users/serhii-havrylov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/serhii-havrylov/subscriptions", "organizations_url": "https://api.github.com/users/serhii-havrylov/orgs", "repos_url": "https://api.github.com/users/serhii-havrylov/repos", "events_url": "https://api.github.com/users/serhii-havrylov/events{/privacy}", "received_events_url": "https://api.github.com/users/serhii-havrylov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 819357941, "node_id": "MDU6TGFiZWw4MTkzNTc5NDE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributions", "name": "distributions", "color": "39d651", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-08-03T14:41:14Z", "updated_at": "2018-08-03T16:18:33Z", "closed_at": "2018-08-03T16:18:33Z", "author_association": "NONE", "body_html": "<p>Recently I encountered a weird bug, that can be reproduced with the next snippet of code:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.nn <span class=\"pl-k\">import</span> functional <span class=\"pl-k\">as</span> F\n<span class=\"pl-k\">from</span> torch.distributions.one_hot_categorical <span class=\"pl-k\">import</span> OneHotCategorical\n\n\nscores <span class=\"pl-k\">=</span> torch.tensor([[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>],\n                       [<span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nprobs <span class=\"pl-k\">=</span> F.softmax(scores, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\ncat <span class=\"pl-k\">=</span> OneHotCategorical(probs)\n\n<span class=\"pl-c1\">print</span>(cat.logits.requires_grad)\n<span class=\"pl-k\">with</span> torch.no_grad():\n    <span class=\"pl-c1\">print</span>(cat.logits.requires_grad)\n\nsample <span class=\"pl-k\">=</span> cat.sample()\nlog_prob <span class=\"pl-k\">=</span> cat.log_prob(sample)\nloss <span class=\"pl-k\">=</span> log_prob.sum()\nloss.backward()</pre></div>\n<p>If one removes the print function right before the <code>no_grad</code> context manager there is going to be a runtime error when calling <code>backward</code>: <code>RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn</code></p>\n<p>It turns out that calling lazy property <code>cat.logits</code> within the <code>no_grad</code> context manager will create an attribute which doesn't require grad and if one uses <code>cat.logits</code> outside <code>no_grad</code> it still will not require grad, even though it should. You can see this strange interplay of <code>lazy_property</code> and <code>no_grad</code> in this example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.distributions.utils <span class=\"pl-k\">import</span> lazy_property\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">MyScores</span>:\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">score</span>):\n        <span class=\"pl-c1\">self</span>.score <span class=\"pl-k\">=</span> score\n\n    <span class=\"pl-en\">@lazy_property</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">negative_score</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-k\">-</span><span class=\"pl-c1\">self</span>.score\n\n\nscores <span class=\"pl-k\">=</span> torch.tensor([[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>],\n                       [<span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">4</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.float32, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\nmy_scores <span class=\"pl-k\">=</span> MyScores(scores)\n\n<span class=\"pl-k\">with</span> torch.no_grad():\n    <span class=\"pl-c1\">print</span>(my_scores.negative_score.requires_grad)\n\nloss <span class=\"pl-k\">=</span> my_scores.negative_score.sum()\nloss.backward()</pre></div>\n<p>This is not necessarily a bug, because the expected behaviour of the <code>no_grad</code> that whatever computations are created inside this context manager they are not going to require grad. So calling <code>my_scores.negative_score</code> within <code>no_grad</code> will create <code>negative_score</code> attribute which will not require grad as expected. The thing is that it is somewhat counterintuitive that my_scores.negative_score still doesn't require grad outside of the context manager. A user doesn't really know that it is a lazy property and expects it to have the same <code>require_grad</code> property as in the <code>probs</code> variable. Thus, the usage of the <code>lazy_property</code> within distributions can lead to the somewhat obscure bugs.</p>\n<p>In my case I was sampling some noise, and used <code>logits</code> to obtain correct <code>dtype</code> and <code>device</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">with</span> torch.no_grad():\n     uniforms <span class=\"pl-k\">=</span> T.empty(sample_shape, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>cat.logits.dtype, <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span>cat.logits.device).uniform_()</pre></div>\n<p>It was really surprising to see <code>RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn</code> later when calling <code>loss.backward()</code></p>\n<p>PyTorch version is 0.4</p>", "body_text": "Recently I encountered a weird bug, that can be reproduced with the next snippet of code:\nimport torch\nfrom torch.nn import functional as F\nfrom torch.distributions.one_hot_categorical import OneHotCategorical\n\n\nscores = torch.tensor([[1, 4, 2],\n                       [8, 4, 4]], dtype=torch.float32, requires_grad=True)\nprobs = F.softmax(scores, dim=-1)\ncat = OneHotCategorical(probs)\n\nprint(cat.logits.requires_grad)\nwith torch.no_grad():\n    print(cat.logits.requires_grad)\n\nsample = cat.sample()\nlog_prob = cat.log_prob(sample)\nloss = log_prob.sum()\nloss.backward()\nIf one removes the print function right before the no_grad context manager there is going to be a runtime error when calling backward: RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\nIt turns out that calling lazy property cat.logits within the no_grad context manager will create an attribute which doesn't require grad and if one uses cat.logits outside no_grad it still will not require grad, even though it should. You can see this strange interplay of lazy_property and no_grad in this example:\nimport torch\nfrom torch.distributions.utils import lazy_property\n\n\nclass MyScores:\n    def __init__(self, score):\n        self.score = score\n\n    @lazy_property\n    def negative_score(self):\n        return -self.score\n\n\nscores = torch.tensor([[1, 4, 2],\n                       [8, 4, 4]], dtype=torch.float32, requires_grad=True)\nmy_scores = MyScores(scores)\n\nwith torch.no_grad():\n    print(my_scores.negative_score.requires_grad)\n\nloss = my_scores.negative_score.sum()\nloss.backward()\nThis is not necessarily a bug, because the expected behaviour of the no_grad that whatever computations are created inside this context manager they are not going to require grad. So calling my_scores.negative_score within no_grad will create negative_score attribute which will not require grad as expected. The thing is that it is somewhat counterintuitive that my_scores.negative_score still doesn't require grad outside of the context manager. A user doesn't really know that it is a lazy property and expects it to have the same require_grad property as in the probs variable. Thus, the usage of the lazy_property within distributions can lead to the somewhat obscure bugs.\nIn my case I was sampling some noise, and used logits to obtain correct dtype and device:\nwith torch.no_grad():\n     uniforms = T.empty(sample_shape, dtype=cat.logits.dtype, device=cat.logits.device).uniform_()\nIt was really surprising to see RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn later when calling loss.backward()\nPyTorch version is 0.4", "body": "Recently I encountered a weird bug, that can be reproduced with the next snippet of code:\r\n\r\n```python\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.distributions.one_hot_categorical import OneHotCategorical\r\n\r\n\r\nscores = torch.tensor([[1, 4, 2],\r\n                       [8, 4, 4]], dtype=torch.float32, requires_grad=True)\r\nprobs = F.softmax(scores, dim=-1)\r\ncat = OneHotCategorical(probs)\r\n\r\nprint(cat.logits.requires_grad)\r\nwith torch.no_grad():\r\n    print(cat.logits.requires_grad)\r\n\r\nsample = cat.sample()\r\nlog_prob = cat.log_prob(sample)\r\nloss = log_prob.sum()\r\nloss.backward()\r\n```\r\nIf one removes the print function right before the `no_grad` context manager there is going to be a runtime error when calling `backward`: `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`\r\n\r\nIt turns out that calling lazy property `cat.logits` within the `no_grad` context manager will create an attribute which doesn't require grad and if one uses `cat.logits` outside `no_grad` it still will not require grad, even though it should. You can see this strange interplay of `lazy_property` and `no_grad` in this example: \r\n\r\n```python\r\nimport torch\r\nfrom torch.distributions.utils import lazy_property\r\n\r\n\r\nclass MyScores:\r\n    def __init__(self, score):\r\n        self.score = score\r\n\r\n    @lazy_property\r\n    def negative_score(self):\r\n        return -self.score\r\n\r\n\r\nscores = torch.tensor([[1, 4, 2],\r\n                       [8, 4, 4]], dtype=torch.float32, requires_grad=True)\r\nmy_scores = MyScores(scores)\r\n\r\nwith torch.no_grad():\r\n    print(my_scores.negative_score.requires_grad)\r\n\r\nloss = my_scores.negative_score.sum()\r\nloss.backward()\r\n```\r\nThis is not necessarily a bug, because the expected behaviour of the `no_grad` that whatever computations are created inside this context manager they are not going to require grad. So calling `my_scores.negative_score` within `no_grad` will create `negative_score` attribute which will not require grad as expected. The thing is that it is somewhat counterintuitive that my_scores.negative_score still doesn't require grad outside of the context manager. A user doesn't really know that it is a lazy property and expects it to have the same `require_grad` property as in the `probs` variable. Thus, the usage of the `lazy_property` within distributions can lead to the somewhat obscure bugs.\r\n\r\nIn my case I was sampling some noise, and used `logits` to obtain correct `dtype` and `device`:\r\n```python\r\nwith torch.no_grad():\r\n     uniforms = T.empty(sample_shape, dtype=cat.logits.dtype, device=cat.logits.device).uniform_()\r\n```\r\nIt was really surprising to see `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn` later when calling `loss.backward()`\r\n\r\nPyTorch version is 0.4"}