{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/410289841", "html_url": "https://github.com/pytorch/pytorch/issues/10207#issuecomment-410289841", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10207", "id": 410289841, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDI4OTg0MQ==", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-03T15:30:11Z", "updated_at": "2018-08-03T15:31:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>IIRC <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1762463\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/neerajprad\">@neerajprad</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1093846\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alicanb\">@alicanb</a> and I encountered this problem early, and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> recommended always using <code>with torch.grad_enabled():</code> inside <code>@lazy_property</code> methods in case the gradient was enabled later on. I don't believe we ever made a complete pass over the <code>@lazy_property</code> implementations to make this consistent across all distributions.</p>\n<p>Also IIRC our recommended strategy to disable gradients was to ensure that a distribution is <em>created</em> inside a <code>with torch.no_grad()</code> context; this way its parameters should be detached (due to <code>.expand()</code> or <code>broadcast_tensors()</code> being called internally).</p>", "body_text": "IIRC @neerajprad and @alicanb and I encountered this problem early, and @apaszke recommended always using with torch.grad_enabled(): inside @lazy_property methods in case the gradient was enabled later on. I don't believe we ever made a complete pass over the @lazy_property implementations to make this consistent across all distributions.\nAlso IIRC our recommended strategy to disable gradients was to ensure that a distribution is created inside a with torch.no_grad() context; this way its parameters should be detached (due to .expand() or broadcast_tensors() being called internally).", "body": "IIRC @neerajprad and @alicanb and I encountered this problem early, and @apaszke recommended always using `with torch.grad_enabled():` inside `@lazy_property` methods in case the gradient was enabled later on. I don't believe we ever made a complete pass over the `@lazy_property` implementations to make this consistent across all distributions.\r\n\r\nAlso IIRC our recommended strategy to disable gradients was to ensure that a distribution is *created* inside a `with torch.no_grad()` context; this way its parameters should be detached (due to `.expand()` or `broadcast_tensors()` being called internally)."}