{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196530892", "pull_request_review_id": 130101599, "id": 196530892, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjUzMDg5Mg==", "diff_hunk": "@@ -205,4 +220,28 @@ inline TensorOptions device_index(int32_t device_index) {\n inline TensorOptions requires_grad(bool requires_grad = true) {\n   return TensorOptions().requires_grad(requires_grad);\n }\n+\n+// From Tensor.h:\n+\n+inline Tensor Tensor::to(TensorOptions options, bool non_blocking) {\n+  DeviceGuard guard(options.device());\n+  auto copy = options.type().copy(*this, non_blocking);\n+  if (copy.is_variable()) {\n+    copy.set_requires_grad(options.requires_grad());", "path": "aten/src/ATen/TensorOptions.h", "position": null, "original_position": 96, "commit_id": "263a16b0ca61f55e33019d2781f4485c2322fe0f", "original_commit_id": "7fa96ac2f35cf3eaccc915ce27c1e061051a9de9", "user": {"login": "goldsborough", "id": 6429851, "node_id": "MDQ6VXNlcjY0Mjk4NTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6429851?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldsborough", "html_url": "https://github.com/goldsborough", "followers_url": "https://api.github.com/users/goldsborough/followers", "following_url": "https://api.github.com/users/goldsborough/following{/other_user}", "gists_url": "https://api.github.com/users/goldsborough/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldsborough/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldsborough/subscriptions", "organizations_url": "https://api.github.com/users/goldsborough/orgs", "repos_url": "https://api.github.com/users/goldsborough/repos", "events_url": "https://api.github.com/users/goldsborough/events{/privacy}", "received_events_url": "https://api.github.com/users/goldsborough/received_events", "type": "User", "site_admin": false}, "body": "Although I guess I was concerned that people would write `to(tensor.options().requires_grad())` and then be confused that the `requires_grad` has no effect. This is not an issue in PyTorch since `to()` does not have `requires_grad`, but it's a bit hard to work around here. Do you think we should add a check for `requires_grad` being set in the `TensorOptions` and warning the user that is ignored? I feel like it would be better to avoid this unexpected behavior and just set `requires_grad` to that of the `TensorOptions`. ", "created_at": "2018-06-19T18:23:19Z", "updated_at": "2018-11-23T15:45:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/8643#discussion_r196530892", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8643", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196530892"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8643#discussion_r196530892"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8643"}}, "body_html": "<p>Although I guess I was concerned that people would write <code>to(tensor.options().requires_grad())</code> and then be confused that the <code>requires_grad</code> has no effect. This is not an issue in PyTorch since <code>to()</code> does not have <code>requires_grad</code>, but it's a bit hard to work around here. Do you think we should add a check for <code>requires_grad</code> being set in the <code>TensorOptions</code> and warning the user that is ignored? I feel like it would be better to avoid this unexpected behavior and just set <code>requires_grad</code> to that of the <code>TensorOptions</code>.</p>", "body_text": "Although I guess I was concerned that people would write to(tensor.options().requires_grad()) and then be confused that the requires_grad has no effect. This is not an issue in PyTorch since to() does not have requires_grad, but it's a bit hard to work around here. Do you think we should add a check for requires_grad being set in the TensorOptions and warning the user that is ignored? I feel like it would be better to avoid this unexpected behavior and just set requires_grad to that of the TensorOptions.", "in_reply_to_id": 196485441}