{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/337972229", "html_url": "https://github.com/pytorch/pytorch/issues/3164#issuecomment-337972229", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3164", "id": 337972229, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzk3MjIyOQ==", "user": {"login": "josephcourtney", "id": 5942706, "node_id": "MDQ6VXNlcjU5NDI3MDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5942706?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josephcourtney", "html_url": "https://github.com/josephcourtney", "followers_url": "https://api.github.com/users/josephcourtney/followers", "following_url": "https://api.github.com/users/josephcourtney/following{/other_user}", "gists_url": "https://api.github.com/users/josephcourtney/gists{/gist_id}", "starred_url": "https://api.github.com/users/josephcourtney/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josephcourtney/subscriptions", "organizations_url": "https://api.github.com/users/josephcourtney/orgs", "repos_url": "https://api.github.com/users/josephcourtney/repos", "events_url": "https://api.github.com/users/josephcourtney/events{/privacy}", "received_events_url": "https://api.github.com/users/josephcourtney/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-19T17:01:30Z", "updated_at": "2017-10-19T17:01:30Z", "author_association": "NONE", "body_html": "<p>A MAGMA queue wraps a CUDA queue and has associated handles to a CUDA stream, cuBLAS, and cuSparse. On my system with a 1080 Ti, the first time a queue is created it takes ~270 ms, subsequent queues take ~0.47 ms but they all share the same CUDA stream and cuBLAS handle. The cuSparse handle changes with each queue creation but I think that is because I am not using cuSparse so the handle leads nowhere.</p>\n<p>Since there seems to be relatively little penalty to repeated calls to create queues, it might be reasonable to just create the queue in each wrapper for batched MAGMA functions. I will try wrapping magma_dgesv_batched with MAGMA queue creation and cleanup inside the wrapper.</p>", "body_text": "A MAGMA queue wraps a CUDA queue and has associated handles to a CUDA stream, cuBLAS, and cuSparse. On my system with a 1080 Ti, the first time a queue is created it takes ~270 ms, subsequent queues take ~0.47 ms but they all share the same CUDA stream and cuBLAS handle. The cuSparse handle changes with each queue creation but I think that is because I am not using cuSparse so the handle leads nowhere.\nSince there seems to be relatively little penalty to repeated calls to create queues, it might be reasonable to just create the queue in each wrapper for batched MAGMA functions. I will try wrapping magma_dgesv_batched with MAGMA queue creation and cleanup inside the wrapper.", "body": "A MAGMA queue wraps a CUDA queue and has associated handles to a CUDA stream, cuBLAS, and cuSparse. On my system with a 1080 Ti, the first time a queue is created it takes ~270 ms, subsequent queues take ~0.47 ms but they all share the same CUDA stream and cuBLAS handle. The cuSparse handle changes with each queue creation but I think that is because I am not using cuSparse so the handle leads nowhere. \r\n\r\nSince there seems to be relatively little penalty to repeated calls to create queues, it might be reasonable to just create the queue in each wrapper for batched MAGMA functions. I will try wrapping magma_dgesv_batched with MAGMA queue creation and cleanup inside the wrapper. "}