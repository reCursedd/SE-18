{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/138133567", "pull_request_review_id": 61667278, "id": 138133567, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEzODEzMzU2Nw==", "diff_hunk": "@@ -6,80 +6,55 @@\n #include \"torch/csrc/autograd/functions/utils.h\"\n #include \"torch/csrc/utils/auto_gpu.h\"\n \n+using at::Tensor;\n+\n namespace torch { namespace autograd {\n \n-AccumulateGrad::AccumulateGrad(std::shared_ptr<Variable> _variable)\n-    : variable(_variable)\n-    , variable_grad(_variable->grad) {\n-  is_executable = _variable->requires_grad;\n+AccumulateGrad::AccumulateGrad(Variable variable_)\n+   : variable(std::move(variable_)) {\n   num_inputs = 1;\n-}\n-\n-auto AccumulateGrad::acc_inplace(std::shared_ptr<Variable>& grad,\n-    std::shared_ptr<Variable>& new_grad) -> void {\n-  auto& grad_data = grad->data;\n-  auto& new_grad_data = new_grad->data;\n-  AutoGPU guard(grad_data);\n-\n-  if (grad_data.type().isSparse() && !new_grad_data.type().isSparse()) {\n-    grad->data = new_grad_data + grad_data;\n-  } else {\n-    grad_data += new_grad_data;\n-  }\n+  is_executable = 1;\n }\n \n auto AccumulateGrad::apply(const variable_list& grads) -> variable_list {\n   // XXX: this method is not thread-safe!\n   check_input_variables(\"AccumulateGrad\", grads, 1, 0);\n-  auto new_grad = grads[0];\n-\n-  if (!new_grad) return {};\n-\n-  auto var = variable.lock();\n-  // It's possible that the Variable went out of scope and was freed.\n-  // We still need to handle the unlikely case of someone holding to its grad.\n-  if (!var) {\n-    auto var_grad = variable_grad.lock();\n-    // Everything was freed. Nothing to do.\n-    if (!var_grad) return variable_list();\n-    // Now here's the hard part. If both the new_grad and var_grad are volatile\n-    // then we just acumulate the data in place (as we'd do if the Variable was\n-    // alive). Otherwise, we'd need to perform the out-of-place reduction, but\n-    // since the user only holds a reference to .grad and there's no way to\n-    // give him the new Value, we just assume that they know these attributes\n-    // are changing when using higher order graphs.\n-    if (!var_grad->is_volatile || !new_grad->is_volatile) return variable_list();\n-    acc_inplace(var_grad, new_grad);\n-    return variable_list();\n-  }\n \n-  if (var->grad_fn)\n+  if (!grads[0].defined())\n+    return {};", "path": "torch/csrc/autograd/functions/accumulate_grad.cpp", "position": null, "original_position": 58, "commit_id": "e281c83541d5d06a4f149d51bb51ad426813bc56", "original_commit_id": "afa8bdcd28be0147df9cd97286c792e39c2f2608", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We should call hooks if there are any", "created_at": "2017-09-11T17:14:03Z", "updated_at": "2018-11-23T15:34:33Z", "html_url": "https://github.com/pytorch/pytorch/pull/2676#discussion_r138133567", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2676", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/138133567"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2676#discussion_r138133567"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2676"}}, "body_html": "<p>We should call hooks if there are any</p>", "body_text": "We should call hooks if there are any"}