{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12406", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12406/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12406/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12406/events", "html_url": "https://github.com/pytorch/pytorch/issues/12406", "id": 367394778, "node_id": "MDU6SXNzdWUzNjczOTQ3Nzg=", "number": 12406, "title": "torch.bmm Segmentation Fault with mixed CPU / GPU", "user": {"login": "jcjohnson", "id": 2718714, "node_id": "MDQ6VXNlcjI3MTg3MTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2718714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcjohnson", "html_url": "https://github.com/jcjohnson", "followers_url": "https://api.github.com/users/jcjohnson/followers", "following_url": "https://api.github.com/users/jcjohnson/following{/other_user}", "gists_url": "https://api.github.com/users/jcjohnson/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcjohnson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcjohnson/subscriptions", "organizations_url": "https://api.github.com/users/jcjohnson/orgs", "repos_url": "https://api.github.com/users/jcjohnson/repos", "events_url": "https://api.github.com/users/jcjohnson/events{/privacy}", "received_events_url": "https://api.github.com/users/jcjohnson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-05T23:06:11Z", "updated_at": "2018-10-08T01:57:06Z", "closed_at": "2018-10-08T01:57:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Most torch functions throw a user-friendly exception when they encounter tensors on incompatible devices; however torch.bmm segfaults instead.</p>\n<h2>To Reproduce</h2>\n<p>In an interactive shell:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;</span> x <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>).cpu()\n<span class=\"pl-k\">&gt;</span> x.mm(x.cuda())\nTraceback (most recent call last):\nFile <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  <span class=\"pl-c1\">RuntimeError</span>: Expected <span class=\"pl-c1\">object</span> of backend <span class=\"pl-c1\">CPU</span> but got backend <span class=\"pl-c1\">CUDA</span> <span class=\"pl-k\">for</span> argument <span class=\"pl-c\"><span class=\"pl-c\">#</span>2 'mat2'</span>\n\nx[<span class=\"pl-c1\">None</span>].bmm(x[<span class=\"pl-c1\">None</span>].cuda())\n<span class=\"pl-k\">&gt;</span> Segmentation fault</pre></div>\n<h2>Expected behavior</h2>\n<p>torch.bmm should throw an exception like torch.mm rather than segfault</p>\n<h2>Environment</h2>\n<p>PyTorch version: 1.0.0.dev20181005<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.7<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: Quadro GP100<br>\nGPU 1: Quadro GP100</p>\n<p>Nvidia driver version: 396.26<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] numpy (1.15.2)<br>\n[pip] torch (1.0.0.dev20181005)<br>\n[conda] pytorch-nightly           1.0.0.dev20181005 py3.7_cuda9.0.176_cudnn7.1.2_0    pytorch</p>", "body_text": "Most torch functions throw a user-friendly exception when they encounter tensors on incompatible devices; however torch.bmm segfaults instead.\nTo Reproduce\nIn an interactive shell:\n> x = torch.randn(3, 3).cpu()\n> x.mm(x.cuda())\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\n  RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'\n\nx[None].bmm(x[None].cuda())\n> Segmentation fault\nExpected behavior\ntorch.bmm should throw an exception like torch.mm rather than segfault\nEnvironment\nPyTorch version: 1.0.0.dev20181005\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.7\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: Quadro GP100\nGPU 1: Quadro GP100\nNvidia driver version: 396.26\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] numpy (1.15.2)\n[pip] torch (1.0.0.dev20181005)\n[conda] pytorch-nightly           1.0.0.dev20181005 py3.7_cuda9.0.176_cudnn7.1.2_0    pytorch", "body": "Most torch functions throw a user-friendly exception when they encounter tensors on incompatible devices; however torch.bmm segfaults instead.\r\n\r\n## To Reproduce\r\nIn an interactive shell: \r\n\r\n```python\r\n> x = torch.randn(3, 3).cpu()\r\n> x.mm(x.cuda())\r\nTraceback (most recent call last):\r\nFile \"<stdin>\", line 1, in <module>\r\n  RuntimeError: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'\r\n\r\nx[None].bmm(x[None].cuda())\r\n> Segmentation fault\r\n```\r\n\r\n## Expected behavior\r\n\r\ntorch.bmm should throw an exception like torch.mm rather than segfault\r\n\r\n## Environment\r\nPyTorch version: 1.0.0.dev20181005\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration:\r\nGPU 0: Quadro GP100\r\nGPU 1: Quadro GP100\r\n\r\nNvidia driver version: 396.26\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.2)\r\n[pip] torch (1.0.0.dev20181005)\r\n[conda] pytorch-nightly           1.0.0.dev20181005 py3.7_cuda9.0.176_cudnn7.1.2_0    pytorch\r\n"}