{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/192267513", "pull_request_review_id": 124986558, "id": 192267513, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5MjI2NzUxMw==", "diff_hunk": "@@ -235,30 +305,68 @@ void ProcessGroupGloo::createAlgorithm(AlgorithmEntry& entry) {\n template <typename T>\n void ProcessGroupGloo::createAllreduce(AlgorithmEntry& entry) {\n   const auto& key = entry.key;\n+  const auto& backend = key.type->backend();\n \n   // Create algorithm against first context\n   auto& context = contexts_[0];\n-  entry.algorithm = std::unique_ptr<::gloo::Algorithm>(\n-      new ::gloo::AllreduceHalvingDoubling<T>(\n-          context,\n-          getDataPointers<T>(entry.src),\n-          entry.src[0].numel(),\n-          reductionFunction<T>(key.reduceOp)));\n+\n+  if (backend == at::kCPU) {\n+    entry.algorithm = std::unique_ptr<::gloo::Algorithm>(\n+        new ::gloo::AllreduceHalvingDoubling<T>(\n+            context,\n+            getDataPointers<T>(entry.src),\n+            entry.src[0].numel(),\n+            reductionFunction<T>(key.reduceOp)));\n+    return;\n+  }\n+\n+  if (backend == at::kCUDA) {\n+    entry.algorithm = std::unique_ptr<::gloo::Algorithm>(", "path": "torch/lib/c10d/ProcessGroupGloo.cpp", "position": 158, "original_position": 158, "commit_id": "b7e7f6c93df088eafff4c0a99ce4476519a4f489", "original_commit_id": "06958c99d838b51594db5c686acc493837e503bb", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "It would be nice to support GPU direct when creating the algorithm and when IB is available.  Can you create a TODO to automatically enable GPU direct when the device supports it?", "created_at": "2018-05-31T23:44:58Z", "updated_at": "2018-11-23T15:44:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/7694#discussion_r192267513", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7694", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/192267513"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7694#discussion_r192267513"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7694"}}, "body_html": "<p>It would be nice to support GPU direct when creating the algorithm and when IB is available.  Can you create a TODO to automatically enable GPU direct when the device supports it?</p>", "body_text": "It would be nice to support GPU direct when creating the algorithm and when IB is available.  Can you create a TODO to automatically enable GPU direct when the device supports it?"}