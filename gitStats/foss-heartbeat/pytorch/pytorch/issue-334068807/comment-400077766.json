{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/400077766", "html_url": "https://github.com/pytorch/pytorch/issues/8686#issuecomment-400077766", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8686", "id": 400077766, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDA3Nzc2Ng==", "user": {"login": "ptrblck", "id": 11662379, "node_id": "MDQ6VXNlcjExNjYyMzc5", "avatar_url": "https://avatars3.githubusercontent.com/u/11662379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptrblck", "html_url": "https://github.com/ptrblck", "followers_url": "https://api.github.com/users/ptrblck/followers", "following_url": "https://api.github.com/users/ptrblck/following{/other_user}", "gists_url": "https://api.github.com/users/ptrblck/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptrblck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptrblck/subscriptions", "organizations_url": "https://api.github.com/users/ptrblck/orgs", "repos_url": "https://api.github.com/users/ptrblck/repos", "events_url": "https://api.github.com/users/ptrblck/events{/privacy}", "received_events_url": "https://api.github.com/users/ptrblck/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-25T20:04:29Z", "updated_at": "2018-06-25T20:04:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I've created an initial version of the fix, which returns <code>torch.tensor([])</code> for zero-length splits.</p>\n<div class=\"highlight highlight-source-python\"><pre>tensor <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>)\nsplit_sizes <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>]\nsplits <span class=\"pl-k\">=</span> tensor.split(split_sizes, <span class=\"pl-c1\">0</span>)\n<span class=\"pl-k\">for</span> split <span class=\"pl-k\">in</span> splits:\n    <span class=\"pl-c1\">print</span>(split.shape)\n\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">0</span>])\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">0</span>])\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>])\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">0</span>])\n<span class=\"pl-k\">&gt;</span> torch.Size([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>])</pre></div>\n<p>Basically I've tried to implement <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a>'s Python code.</p>\n<p>Also I've added a test case to <code>test_split</code> in <code>test_torch.py</code>.</p>\n<p>Unfortunately the dimension for zero-sized <code>tensors</code> will be <code>1</code>, while the splits can have an arbitrary dimension.<br>\nCould this be a problem in some use cases?</p>", "body_text": "I've created an initial version of the fix, which returns torch.tensor([]) for zero-length splits.\ntensor = torch.randn(4, 2)\nsplit_sizes = [0, 1, 0, 2, 0, 1]\nsplits = tensor.split(split_sizes, 0)\nfor split in splits:\n    print(split.shape)\n\n> torch.Size([0])\n> torch.Size([1, 2])\n> torch.Size([0])\n> torch.Size([2, 2])\n> torch.Size([0])\n> torch.Size([1, 2])\nBasically I've tried to implement @fmassa's Python code.\nAlso I've added a test case to test_split in test_torch.py.\nUnfortunately the dimension for zero-sized tensors will be 1, while the splits can have an arbitrary dimension.\nCould this be a problem in some use cases?", "body": "I've created an initial version of the fix, which returns `torch.tensor([])` for zero-length splits.\r\n```python\r\ntensor = torch.randn(4, 2)\r\nsplit_sizes = [0, 1, 0, 2, 0, 1]\r\nsplits = tensor.split(split_sizes, 0)\r\nfor split in splits:\r\n    print(split.shape)\r\n\r\n> torch.Size([0])\r\n> torch.Size([1, 2])\r\n> torch.Size([0])\r\n> torch.Size([2, 2])\r\n> torch.Size([0])\r\n> torch.Size([1, 2])\r\n```\r\nBasically I've tried to implement @fmassa's Python code.\r\n\r\nAlso I've added a test case to `test_split` in `test_torch.py`.\r\n\r\nUnfortunately the dimension for zero-sized `tensors` will be `1`, while the splits can have an arbitrary dimension.\r\nCould this be a problem in some use cases?"}