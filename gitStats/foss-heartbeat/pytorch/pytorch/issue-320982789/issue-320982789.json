{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7356", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7356/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7356/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7356/events", "html_url": "https://github.com/pytorch/pytorch/issues/7356", "id": 320982789, "node_id": "MDU6SXNzdWUzMjA5ODI3ODk=", "number": 7356, "title": "cpp-extensions strange behaviour during cusparse function call", "user": {"login": "Daulbaev", "id": 7610126, "node_id": "MDQ6VXNlcjc2MTAxMjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/7610126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Daulbaev", "html_url": "https://github.com/Daulbaev", "followers_url": "https://api.github.com/users/Daulbaev/followers", "following_url": "https://api.github.com/users/Daulbaev/following{/other_user}", "gists_url": "https://api.github.com/users/Daulbaev/gists{/gist_id}", "starred_url": "https://api.github.com/users/Daulbaev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Daulbaev/subscriptions", "organizations_url": "https://api.github.com/users/Daulbaev/orgs", "repos_url": "https://api.github.com/users/Daulbaev/repos", "events_url": "https://api.github.com/users/Daulbaev/events{/privacy}", "received_events_url": "https://api.github.com/users/Daulbaev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-05-07T22:39:21Z", "updated_at": "2018-05-08T12:50:09Z", "closed_at": "2018-05-08T12:50:09Z", "author_association": "NONE", "body_html": "<p>I'm trying to use cpp-extensions with CUDA to convert csr matrix to csc matrix.</p>\n<p>I've written the following function:</p>\n<pre><code>std::vector&lt;at::Tensor&gt; csr_to_csc_cuda(\nat::Tensor A_data, \nat::Tensor A_indices, \nat::Tensor A_indptr, \nint n_cols) \n{\n    auto state = at::globalContext().lazyInitCUDA();\n    auto handle = THCState_getCurrentSparseHandle(state);\n    int nnz = A_data.size(0);\n    int m = A_indptr.size(0) - 1;\n    auto B_data = at::infer_type(A_data).tensor({nnz}); \n    auto B_indptr = at::infer_type(A_indptr).tensor({nnz}); \n    auto B_indices = at::infer_type(A_indices).tensor({n_cols + 1}); \n    cusparseDcsr2csc(handle, m, n_cols, nnz, \n        A_data.data&lt;double&gt;(), \n        A_indptr.data&lt;int&gt;(), \n        A_indices.data&lt;int&gt;(), \n        B_data.data&lt;double&gt;(), \n        B_indptr.data&lt;int&gt;(), \n        B_indices.data&lt;int&gt;(), \n        CUSPARSE_ACTION_NUMERIC, \n        CUSPARSE_INDEX_BASE_ZERO);\n    return {B_data, B_indptr, B_indices};\n}\n</code></pre>\n<p>which simply calls cusparseDcsr2csc. I also Included all headers, added .cpp file with an interface an so on.<br>\nThen I built the whole project and there were no errors. But when I try to import this function Python raises a strange ImportError: /opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/dmg_cuda-0.0.0-py3.6-linux-x86_64.egg/dmg_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: cusparseDcsr2csc</p>\n<p>I am not sufficiently familiar with CUDA internal structure, but some people with the same problem simply added some more compilation flags to manage it. Could you tell me what's wrong?</p>\n<p>P.S. I've also written cusparseDcsrmm2, and it works well (but the resulting array is stored in Fortran-style ordering).</p>", "body_text": "I'm trying to use cpp-extensions with CUDA to convert csr matrix to csc matrix.\nI've written the following function:\nstd::vector<at::Tensor> csr_to_csc_cuda(\nat::Tensor A_data, \nat::Tensor A_indices, \nat::Tensor A_indptr, \nint n_cols) \n{\n    auto state = at::globalContext().lazyInitCUDA();\n    auto handle = THCState_getCurrentSparseHandle(state);\n    int nnz = A_data.size(0);\n    int m = A_indptr.size(0) - 1;\n    auto B_data = at::infer_type(A_data).tensor({nnz}); \n    auto B_indptr = at::infer_type(A_indptr).tensor({nnz}); \n    auto B_indices = at::infer_type(A_indices).tensor({n_cols + 1}); \n    cusparseDcsr2csc(handle, m, n_cols, nnz, \n        A_data.data<double>(), \n        A_indptr.data<int>(), \n        A_indices.data<int>(), \n        B_data.data<double>(), \n        B_indptr.data<int>(), \n        B_indices.data<int>(), \n        CUSPARSE_ACTION_NUMERIC, \n        CUSPARSE_INDEX_BASE_ZERO);\n    return {B_data, B_indptr, B_indices};\n}\n\nwhich simply calls cusparseDcsr2csc. I also Included all headers, added .cpp file with an interface an so on.\nThen I built the whole project and there were no errors. But when I try to import this function Python raises a strange ImportError: /opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/dmg_cuda-0.0.0-py3.6-linux-x86_64.egg/dmg_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: cusparseDcsr2csc\nI am not sufficiently familiar with CUDA internal structure, but some people with the same problem simply added some more compilation flags to manage it. Could you tell me what's wrong?\nP.S. I've also written cusparseDcsrmm2, and it works well (but the resulting array is stored in Fortran-style ordering).", "body": "I'm trying to use cpp-extensions with CUDA to convert csr matrix to csc matrix.\r\n\r\nI've written the following function:\r\n```\r\nstd::vector<at::Tensor> csr_to_csc_cuda(\r\nat::Tensor A_data, \r\nat::Tensor A_indices, \r\nat::Tensor A_indptr, \r\nint n_cols) \r\n{\r\n    auto state = at::globalContext().lazyInitCUDA();\r\n    auto handle = THCState_getCurrentSparseHandle(state);\r\n    int nnz = A_data.size(0);\r\n    int m = A_indptr.size(0) - 1;\r\n    auto B_data = at::infer_type(A_data).tensor({nnz}); \r\n    auto B_indptr = at::infer_type(A_indptr).tensor({nnz}); \r\n    auto B_indices = at::infer_type(A_indices).tensor({n_cols + 1}); \r\n    cusparseDcsr2csc(handle, m, n_cols, nnz, \r\n        A_data.data<double>(), \r\n        A_indptr.data<int>(), \r\n        A_indices.data<int>(), \r\n        B_data.data<double>(), \r\n        B_indptr.data<int>(), \r\n        B_indices.data<int>(), \r\n        CUSPARSE_ACTION_NUMERIC, \r\n        CUSPARSE_INDEX_BASE_ZERO);\r\n    return {B_data, B_indptr, B_indices};\r\n}\r\n```\r\n\r\nwhich simply calls cusparseDcsr2csc. I also Included all headers, added .cpp file with an interface an so on.\r\nThen I built the whole project and there were no errors. But when I try to import this function Python raises a strange ImportError: /opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/dmg_cuda-0.0.0-py3.6-linux-x86_64.egg/dmg_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: cusparseDcsr2csc\r\n\r\nI am not sufficiently familiar with CUDA internal structure, but some people with the same problem simply added some more compilation flags to manage it. Could you tell me what's wrong?\r\n\r\nP.S. I've also written cusparseDcsrmm2, and it works well (but the resulting array is stored in Fortran-style ordering). "}