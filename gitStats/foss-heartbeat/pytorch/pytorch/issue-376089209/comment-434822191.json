{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/434822191", "html_url": "https://github.com/pytorch/pytorch/pull/13399#issuecomment-434822191", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13399", "id": 434822191, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDgyMjE5MQ==", "user": {"login": "resistor", "id": 9796, "node_id": "MDQ6VXNlcjk3OTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/9796?v=4", "gravatar_id": "", "url": "https://api.github.com/users/resistor", "html_url": "https://github.com/resistor", "followers_url": "https://api.github.com/users/resistor/followers", "following_url": "https://api.github.com/users/resistor/following{/other_user}", "gists_url": "https://api.github.com/users/resistor/gists{/gist_id}", "starred_url": "https://api.github.com/users/resistor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/resistor/subscriptions", "organizations_url": "https://api.github.com/users/resistor/orgs", "repos_url": "https://api.github.com/users/resistor/repos", "events_url": "https://api.github.com/users/resistor/events{/privacy}", "received_events_url": "https://api.github.com/users/resistor/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-31T19:43:53Z", "updated_at": "2018-10-31T19:44:27Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> Depressingly, there's not a good precedent to follow here.</p>\n<ul>\n<li>\n<p>IEEE 754-201X defines operators <code>maximum</code> and <code>maximumNumber</code> which respectively propagate NaNs and squash NaNs.</p>\n</li>\n<li>\n<p>std::max uses a ternary operator <code>(a &gt; b) ? a : b</code> which does not match either of the defined IEEE 754 operations, and is not commutative.</p>\n</li>\n<li>\n<p>C differs from C++, with <code>fmax</code> matching IEEE 754 <code>maximumNumber</code></p>\n</li>\n<li>\n<p>NumPy defines <code>max</code> which matches IEEE 754 <code>maximum</code> and <code>maxnan</code> which matches <code>maximumNumber</code></p>\n</li>\n<li>\n<p>X86:  SSE <code>MAXPS</code> matches std::max definition, with the same issues.  AVX-512 <code>VRANGE</code> can implement the IEEE 754 operators.</p>\n</li>\n<li>\n<p>ARMv8:  NEON provides <code>fmax</code> which matches IEEE 754 <code>maximum</code> and <code>fmaxnm</code> which matches <code>maximumNumber</code></p>\n</li>\n</ul>\n<p>Based on prior discussion, my understanding is that we want to follow the NumPy example in PyTorch of propagating NaNs by default.  In my opinion the best option, if we don't want to keep the existing name, is to standardize on the IEEE 754 operator names, since all of the others are overloaded across architectures and languages.</p>", "body_text": "@colesbury Depressingly, there's not a good precedent to follow here.\n\n\nIEEE 754-201X defines operators maximum and maximumNumber which respectively propagate NaNs and squash NaNs.\n\n\nstd::max uses a ternary operator (a > b) ? a : b which does not match either of the defined IEEE 754 operations, and is not commutative.\n\n\nC differs from C++, with fmax matching IEEE 754 maximumNumber\n\n\nNumPy defines max which matches IEEE 754 maximum and maxnan which matches maximumNumber\n\n\nX86:  SSE MAXPS matches std::max definition, with the same issues.  AVX-512 VRANGE can implement the IEEE 754 operators.\n\n\nARMv8:  NEON provides fmax which matches IEEE 754 maximum and fmaxnm which matches maximumNumber\n\n\nBased on prior discussion, my understanding is that we want to follow the NumPy example in PyTorch of propagating NaNs by default.  In my opinion the best option, if we don't want to keep the existing name, is to standardize on the IEEE 754 operator names, since all of the others are overloaded across architectures and languages.", "body": "@colesbury Depressingly, there's not a good precedent to follow here.\r\n\r\n* IEEE 754-201X defines operators `maximum` and `maximumNumber` which respectively propagate NaNs and squash NaNs.\r\n\r\n* std::max uses a ternary operator `(a > b) ? a : b` which does not match either of the defined IEEE 754 operations, and is not commutative.\r\n* C differs from C++, with `fmax` matching IEEE 754 `maximumNumber`\r\n* NumPy defines `max` which matches IEEE 754 `maximum` and `maxnan` which matches `maximumNumber`\r\n\r\n* X86:  SSE `MAXPS` matches std::max definition, with the same issues.  AVX-512 `VRANGE` can implement the IEEE 754 operators.\r\n* ARMv8:  NEON provides `fmax` which matches IEEE 754 `maximum` and `fmaxnm` which matches `maximumNumber`\r\n\r\nBased on prior discussion, my understanding is that we want to follow the NumPy example in PyTorch of propagating NaNs by default.  In my opinion the best option, if we don't want to keep the existing name, is to standardize on the IEEE 754 operator names, since all of the others are overloaded across architectures and languages."}