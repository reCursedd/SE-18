{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/436462377", "html_url": "https://github.com/pytorch/pytorch/issues/12603#issuecomment-436462377", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12603", "id": 436462377, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjQ2MjM3Nw==", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-07T00:44:22Z", "updated_at": "2018-11-07T00:46:14Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3921062\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/acgtyrant\">@acgtyrant</a> Regardless of either using the old distributed or new c10d library, I always hit this error</p>\n<pre><code>pytest ddp_repro.py\n===================================== test session starts =====================================\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\nrootdir: /private/home/tengli/github_issues, inifile:\ncollected 7 items\n\nddp_repro.py ..FF...                                                                    [100%]\n\n========================================== FAILURES ===========================================\n_____________________ test_conv_weight_grad_between_local_and_distributed _____________________\n\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\n\n         [[ 0.7853]]],\n\n\n   ...3127]],\n\n         [[ 0.1651]]],\n\n\n        [[[-0.0723]],\n\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\n\n    def test_conv_weight_grad_between_local_and_distributed(\n            conv_instances):\n        local, distributed_0, distributed_1 = conv_instances\n        allclose(\n                local.conv.weight.grad,\n&gt;               distributed_0.conv_weight_grad)\n\nddp_repro.py:129:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nx = tensor([[[[-0.2382]],\n\n         [[-0.0656]]],\n\n\n        [[[-0.2382]],\n\n         [[-0.0656]]]], device='cuda:0')\ny = tensor([[[[-0.5355]],\n\n         [[-0.0308]]],\n\n\n        [[[-0.5355]],\n\n         [[-0.0308]]]], device='cuda:0')\n\n    def allclose(x, y):\n        adiff = (x - y).abs()\n        if (y == 0).all():\n            rdiff = 'NaN'\n        else:\n            rdiff = (adiff / y).abs().max()\n&gt;       assert torch.allclose(x, y), (\n                'Tensor close check failed\\n'\n                '{}\\n'\n                '{}\\n'\n                'adiff={}\\n'\n                'rdiff={}\\n'\n        ).format(x, y, adiff, rdiff)\nE       AssertionError: Tensor close check failed\nE         tensor([[[[-0.2382]],\nE\nE                  [[-0.0656]]],\nE\nE\nE                 [[[-0.2382]],\nE\nE                  [[-0.0656]]]], device='cuda:0')\nE         tensor([[[[-0.5355]],\nE\nE                  [[-0.0308]]],\nE\nE\nE                 [[[-0.5355]],\nE\nE                  [[-0.0308]]]], device='cuda:0')\nE         adiff=tensor([[[[0.2973]],\nE\nE                  [[0.0348]]],\nE\nE\nE                 [[[0.2973]],\nE\nE                  [[0.0348]]]], device='cuda:0')\nE         rdiff=1.1295044422149658\nE\nE       assert False\nE        +  where False = &lt;built-in method allclose of type object at 0x7f3bd46cbc00&gt;(tensor([[[[-0.2382]],\\n\\n         [[-0.0656]]],\\n\\n\\n        [[[-0.2382]],\\n\\n         [[-0.0656]]]], device='cuda:0'), tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'))\nE        +    where &lt;built-in method allclose of type object at 0x7f3bd46cbc00&gt; = torch.allclose\n\nddp_repro.py:97: AssertionError\n_________________________ test_conv_weight_grad_between_distributeds __________________________\n\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\n\n         [[ 0.7853]]],\n\n\n   ...3127]],\n\n         [[ 0.1651]]],\n\n\n        [[[-0.0723]],\n\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\n\n    def test_conv_weight_grad_between_distributeds(\n            conv_instances):\n        local, distributed_0, distributed_1 = conv_instances\n        allclose(\n                distributed_0.conv_weight_grad,\n&gt;               distributed_1.conv_weight_grad)\n\nddp_repro.py:137:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nx = tensor([[[[-0.5355]],\n\n         [[-0.0308]]],\n\n\n        [[[-0.5355]],\n\n         [[-0.0308]]]], device='cuda:0')\ny = tensor([[[[ 0.0590]],\n\n         [[-0.1003]]],\n\n\n        [[[ 0.0590]],\n\n         [[-0.1003]]]], device='cuda:0')\n\n    def allclose(x, y):\n        adiff = (x - y).abs()\n        if (y == 0).all():\n            rdiff = 'NaN'\n        else:\n            rdiff = (adiff / y).abs().max()\n&gt;       assert torch.allclose(x, y), (\n                'Tensor close check failed\\n'\n                '{}\\n'\n                '{}\\n'\n                'adiff={}\\n'\n                'rdiff={}\\n'\n        ).format(x, y, adiff, rdiff)\nE       AssertionError: Tensor close check failed\nE         tensor([[[[-0.5355]],\nE\nE                  [[-0.0308]]],\nE\nE\nE                 [[[-0.5355]],\nE\nE                  [[-0.0308]]]], device='cuda:0')\nE         tensor([[[[ 0.0590]],\nE\nE                  [[-0.1003]]],\nE\nE\nE                 [[[ 0.0590]],\nE\nE                  [[-0.1003]]]], device='cuda:0')\nE         adiff=tensor([[[[0.5945]],\nE\nE                  [[0.0695]]],\nE\nE\nE                 [[[0.5945]],\nE\nE                  [[0.0695]]]], device='cuda:0')\nE         rdiff=10.069564819335938\nE\nE       assert False\nE        +  where False = &lt;built-in method allclose of type object at 0x7f3bd46cbc00&gt;(tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'), tensor([[[[ 0.0590]],\\n\\n         [[-0.1003]]],\\n\\n\\n        [[[ 0.0590]],\\n\\n         [[-0.1003]]]], device='cuda:0'))\nE        +    where &lt;built-in method allclose of type object at 0x7f3bd46cbc00&gt; = torch.allclose\n\nddp_repro.py:97: AssertionError\n============================= 2 failed, 5 passed in 9.67 seconds ==============================\n</code></pre>\n<p>When you say all tests passed, what tests are you specifically referring to</p>", "body_text": "@acgtyrant Regardless of either using the old distributed or new c10d library, I always hit this error\npytest ddp_repro.py\n===================================== test session starts =====================================\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\nrootdir: /private/home/tengli/github_issues, inifile:\ncollected 7 items\n\nddp_repro.py ..FF...                                                                    [100%]\n\n========================================== FAILURES ===========================================\n_____________________ test_conv_weight_grad_between_local_and_distributed _____________________\n\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\n\n         [[ 0.7853]]],\n\n\n   ...3127]],\n\n         [[ 0.1651]]],\n\n\n        [[[-0.0723]],\n\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\n\n    def test_conv_weight_grad_between_local_and_distributed(\n            conv_instances):\n        local, distributed_0, distributed_1 = conv_instances\n        allclose(\n                local.conv.weight.grad,\n>               distributed_0.conv_weight_grad)\n\nddp_repro.py:129:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nx = tensor([[[[-0.2382]],\n\n         [[-0.0656]]],\n\n\n        [[[-0.2382]],\n\n         [[-0.0656]]]], device='cuda:0')\ny = tensor([[[[-0.5355]],\n\n         [[-0.0308]]],\n\n\n        [[[-0.5355]],\n\n         [[-0.0308]]]], device='cuda:0')\n\n    def allclose(x, y):\n        adiff = (x - y).abs()\n        if (y == 0).all():\n            rdiff = 'NaN'\n        else:\n            rdiff = (adiff / y).abs().max()\n>       assert torch.allclose(x, y), (\n                'Tensor close check failed\\n'\n                '{}\\n'\n                '{}\\n'\n                'adiff={}\\n'\n                'rdiff={}\\n'\n        ).format(x, y, adiff, rdiff)\nE       AssertionError: Tensor close check failed\nE         tensor([[[[-0.2382]],\nE\nE                  [[-0.0656]]],\nE\nE\nE                 [[[-0.2382]],\nE\nE                  [[-0.0656]]]], device='cuda:0')\nE         tensor([[[[-0.5355]],\nE\nE                  [[-0.0308]]],\nE\nE\nE                 [[[-0.5355]],\nE\nE                  [[-0.0308]]]], device='cuda:0')\nE         adiff=tensor([[[[0.2973]],\nE\nE                  [[0.0348]]],\nE\nE\nE                 [[[0.2973]],\nE\nE                  [[0.0348]]]], device='cuda:0')\nE         rdiff=1.1295044422149658\nE\nE       assert False\nE        +  where False = <built-in method allclose of type object at 0x7f3bd46cbc00>(tensor([[[[-0.2382]],\\n\\n         [[-0.0656]]],\\n\\n\\n        [[[-0.2382]],\\n\\n         [[-0.0656]]]], device='cuda:0'), tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'))\nE        +    where <built-in method allclose of type object at 0x7f3bd46cbc00> = torch.allclose\n\nddp_repro.py:97: AssertionError\n_________________________ test_conv_weight_grad_between_distributeds __________________________\n\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\n\n         [[ 0.7853]]],\n\n\n   ...3127]],\n\n         [[ 0.1651]]],\n\n\n        [[[-0.0723]],\n\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\n\n    def test_conv_weight_grad_between_distributeds(\n            conv_instances):\n        local, distributed_0, distributed_1 = conv_instances\n        allclose(\n                distributed_0.conv_weight_grad,\n>               distributed_1.conv_weight_grad)\n\nddp_repro.py:137:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nx = tensor([[[[-0.5355]],\n\n         [[-0.0308]]],\n\n\n        [[[-0.5355]],\n\n         [[-0.0308]]]], device='cuda:0')\ny = tensor([[[[ 0.0590]],\n\n         [[-0.1003]]],\n\n\n        [[[ 0.0590]],\n\n         [[-0.1003]]]], device='cuda:0')\n\n    def allclose(x, y):\n        adiff = (x - y).abs()\n        if (y == 0).all():\n            rdiff = 'NaN'\n        else:\n            rdiff = (adiff / y).abs().max()\n>       assert torch.allclose(x, y), (\n                'Tensor close check failed\\n'\n                '{}\\n'\n                '{}\\n'\n                'adiff={}\\n'\n                'rdiff={}\\n'\n        ).format(x, y, adiff, rdiff)\nE       AssertionError: Tensor close check failed\nE         tensor([[[[-0.5355]],\nE\nE                  [[-0.0308]]],\nE\nE\nE                 [[[-0.5355]],\nE\nE                  [[-0.0308]]]], device='cuda:0')\nE         tensor([[[[ 0.0590]],\nE\nE                  [[-0.1003]]],\nE\nE\nE                 [[[ 0.0590]],\nE\nE                  [[-0.1003]]]], device='cuda:0')\nE         adiff=tensor([[[[0.5945]],\nE\nE                  [[0.0695]]],\nE\nE\nE                 [[[0.5945]],\nE\nE                  [[0.0695]]]], device='cuda:0')\nE         rdiff=10.069564819335938\nE\nE       assert False\nE        +  where False = <built-in method allclose of type object at 0x7f3bd46cbc00>(tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'), tensor([[[[ 0.0590]],\\n\\n         [[-0.1003]]],\\n\\n\\n        [[[ 0.0590]],\\n\\n         [[-0.1003]]]], device='cuda:0'))\nE        +    where <built-in method allclose of type object at 0x7f3bd46cbc00> = torch.allclose\n\nddp_repro.py:97: AssertionError\n============================= 2 failed, 5 passed in 9.67 seconds ==============================\n\nWhen you say all tests passed, what tests are you specifically referring to", "body": "@acgtyrant Regardless of either using the old distributed or new c10d library, I always hit this error\r\n\r\n```\r\npytest ddp_repro.py\r\n===================================== test session starts =====================================\r\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\r\nrootdir: /private/home/tengli/github_issues, inifile:\r\ncollected 7 items\r\n\r\nddp_repro.py ..FF...                                                                    [100%]\r\n\r\n========================================== FAILURES ===========================================\r\n_____________________ test_conv_weight_grad_between_local_and_distributed _____________________\r\n\r\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\r\n\r\n         [[ 0.7853]]],\r\n\r\n\r\n   ...3127]],\r\n\r\n         [[ 0.1651]]],\r\n\r\n\r\n        [[[-0.0723]],\r\n\r\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\r\n\r\n    def test_conv_weight_grad_between_local_and_distributed(\r\n            conv_instances):\r\n        local, distributed_0, distributed_1 = conv_instances\r\n        allclose(\r\n                local.conv.weight.grad,\r\n>               distributed_0.conv_weight_grad)\r\n\r\nddp_repro.py:129:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nx = tensor([[[[-0.2382]],\r\n\r\n         [[-0.0656]]],\r\n\r\n\r\n        [[[-0.2382]],\r\n\r\n         [[-0.0656]]]], device='cuda:0')\r\ny = tensor([[[[-0.5355]],\r\n\r\n         [[-0.0308]]],\r\n\r\n\r\n        [[[-0.5355]],\r\n\r\n         [[-0.0308]]]], device='cuda:0')\r\n\r\n    def allclose(x, y):\r\n        adiff = (x - y).abs()\r\n        if (y == 0).all():\r\n            rdiff = 'NaN'\r\n        else:\r\n            rdiff = (adiff / y).abs().max()\r\n>       assert torch.allclose(x, y), (\r\n                'Tensor close check failed\\n'\r\n                '{}\\n'\r\n                '{}\\n'\r\n                'adiff={}\\n'\r\n                'rdiff={}\\n'\r\n        ).format(x, y, adiff, rdiff)\r\nE       AssertionError: Tensor close check failed\r\nE         tensor([[[[-0.2382]],\r\nE\r\nE                  [[-0.0656]]],\r\nE\r\nE\r\nE                 [[[-0.2382]],\r\nE\r\nE                  [[-0.0656]]]], device='cuda:0')\r\nE         tensor([[[[-0.5355]],\r\nE\r\nE                  [[-0.0308]]],\r\nE\r\nE\r\nE                 [[[-0.5355]],\r\nE\r\nE                  [[-0.0308]]]], device='cuda:0')\r\nE         adiff=tensor([[[[0.2973]],\r\nE\r\nE                  [[0.0348]]],\r\nE\r\nE\r\nE                 [[[0.2973]],\r\nE\r\nE                  [[0.0348]]]], device='cuda:0')\r\nE         rdiff=1.1295044422149658\r\nE\r\nE       assert False\r\nE        +  where False = <built-in method allclose of type object at 0x7f3bd46cbc00>(tensor([[[[-0.2382]],\\n\\n         [[-0.0656]]],\\n\\n\\n        [[[-0.2382]],\\n\\n         [[-0.0656]]]], device='cuda:0'), tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'))\r\nE        +    where <built-in method allclose of type object at 0x7f3bd46cbc00> = torch.allclose\r\n\r\nddp_repro.py:97: AssertionError\r\n_________________________ test_conv_weight_grad_between_distributeds __________________________\r\n\r\nconv_instances = (namespace(conv=Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1)), x=tensor([[[[-1.4238]],\r\n\r\n         [[ 0.7853]]],\r\n\r\n\r\n   ...3127]],\r\n\r\n         [[ 0.1651]]],\r\n\r\n\r\n        [[[-0.0723]],\r\n\r\n         [[ 0.0610]]]], device='cuda:0', requires_grad=True)))\r\n\r\n    def test_conv_weight_grad_between_distributeds(\r\n            conv_instances):\r\n        local, distributed_0, distributed_1 = conv_instances\r\n        allclose(\r\n                distributed_0.conv_weight_grad,\r\n>               distributed_1.conv_weight_grad)\r\n\r\nddp_repro.py:137:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nx = tensor([[[[-0.5355]],\r\n\r\n         [[-0.0308]]],\r\n\r\n\r\n        [[[-0.5355]],\r\n\r\n         [[-0.0308]]]], device='cuda:0')\r\ny = tensor([[[[ 0.0590]],\r\n\r\n         [[-0.1003]]],\r\n\r\n\r\n        [[[ 0.0590]],\r\n\r\n         [[-0.1003]]]], device='cuda:0')\r\n\r\n    def allclose(x, y):\r\n        adiff = (x - y).abs()\r\n        if (y == 0).all():\r\n            rdiff = 'NaN'\r\n        else:\r\n            rdiff = (adiff / y).abs().max()\r\n>       assert torch.allclose(x, y), (\r\n                'Tensor close check failed\\n'\r\n                '{}\\n'\r\n                '{}\\n'\r\n                'adiff={}\\n'\r\n                'rdiff={}\\n'\r\n        ).format(x, y, adiff, rdiff)\r\nE       AssertionError: Tensor close check failed\r\nE         tensor([[[[-0.5355]],\r\nE\r\nE                  [[-0.0308]]],\r\nE\r\nE\r\nE                 [[[-0.5355]],\r\nE\r\nE                  [[-0.0308]]]], device='cuda:0')\r\nE         tensor([[[[ 0.0590]],\r\nE\r\nE                  [[-0.1003]]],\r\nE\r\nE\r\nE                 [[[ 0.0590]],\r\nE\r\nE                  [[-0.1003]]]], device='cuda:0')\r\nE         adiff=tensor([[[[0.5945]],\r\nE\r\nE                  [[0.0695]]],\r\nE\r\nE\r\nE                 [[[0.5945]],\r\nE\r\nE                  [[0.0695]]]], device='cuda:0')\r\nE         rdiff=10.069564819335938\r\nE\r\nE       assert False\r\nE        +  where False = <built-in method allclose of type object at 0x7f3bd46cbc00>(tensor([[[[-0.5355]],\\n\\n         [[-0.0308]]],\\n\\n\\n        [[[-0.5355]],\\n\\n         [[-0.0308]]]], device='cuda:0'), tensor([[[[ 0.0590]],\\n\\n         [[-0.1003]]],\\n\\n\\n        [[[ 0.0590]],\\n\\n         [[-0.1003]]]], device='cuda:0'))\r\nE        +    where <built-in method allclose of type object at 0x7f3bd46cbc00> = torch.allclose\r\n\r\nddp_repro.py:97: AssertionError\r\n============================= 2 failed, 5 passed in 9.67 seconds ==============================\r\n```\r\n\r\nWhen you say all tests passed, what tests are you specifically referring to"}