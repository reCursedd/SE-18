{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/438508630", "html_url": "https://github.com/pytorch/pytorch/issues/12603#issuecomment-438508630", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12603", "id": 438508630, "node_id": "MDEyOklzc3VlQ29tbWVudDQzODUwODYzMA==", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-14T01:55:40Z", "updated_at": "2018-11-14T02:20:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3921062\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/acgtyrant\">@acgtyrant</a></p>\n<p>OK, I spent some time today digging into this issue.</p>\n<p>The short story is: there is nothing wrong with the current DistributedDataParallel (DDP)</p>\n<p>Here is why:<br>\nIn your repro code, you are assigning a new module parameter weight after the DDP constructor.  What happens internally at DDP is that:</p>\n<p>(1) During the construction of DDP, it will read through all the module's parameters, and register the call-back function (to reduce the gradients) to every single parameter.<br>\n(2) During the backward, these reduction call-back functions will be called when the parameter's gradient is available.</p>\n<p>If you change the parameter yourself to a new one after wrapping up your model to DDP, the backward hook call-back function has actually already registered on the old parameter, and the new parameter's hook won't get called. That's why in your repro program, the gradient reduction function is not triggered at all and you got the wrong gradients.</p>\n<p>The old DDP (nccl code path) happens to work because it was able to all-reduce all parameters even though there is only one hook is called (there is supposed to be two, one for weight, one for bias). But since the new DDP as well as the old DDP (gloo code path) needs to provide parameter bucketing and communication overlapping for DDP performance reasons, we need to ensure that every single parameter's backward hook is called.</p>\n<p>Therefore, you should never change the actual parameter to a new one after wrapping up your model with DDP. This is by the DDP design and we should document this better.</p>\n<p>So if you change your repro code to:</p>\n<pre><code>    model =  torch.nn.Conv2d(channels, channels, 1).cuda()\n    model.weight = torch.nn.Parameter(\n            conv_weight_distributed)\n    torch.nn.init.constant_(model.bias, 0)\n    conv_distributed = torch.nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[rank])\n\n    y = conv_distributed(x)\n</code></pre>\n<p>It should work without any problem.</p>\n<pre><code>pytest --capture=sys ddp_repro.py\n========================================================= test session starts =========================================================\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\nrootdir: /private/home/tengli/github_issues, inifile:\ncollected 7 items\n\nddp_repro.py start\nstart\nregister hook: 139881643889864\nregister hook: 140578281600056\nregister hook: 139881643890008\nregister hook: 140578281600200\nhook: 140578281600056\nbucket ready size: [[1]], bucket size: [2]\nhook: 140578281600200\nbucket ready size: [[2]], bucket size: [2]\nfull\nqueue reduction : 0\nsave model\nhook: 139881643889864\nbucket ready size: [[1]], bucket size: [2]\nhook: 139881643890008\nbucket ready size: [[2]], bucket size: [2]\nfull\nqueue reduction : 0\nsave model\n.......                                                                                                            [100%]\n\n====================================================== 7 passed in 9.42 seconds =======================================================\ntengli@devfair033:~/github_issues$\n</code></pre>\n<p>Let me know if you have more questions.</p>", "body_text": "@acgtyrant\nOK, I spent some time today digging into this issue.\nThe short story is: there is nothing wrong with the current DistributedDataParallel (DDP)\nHere is why:\nIn your repro code, you are assigning a new module parameter weight after the DDP constructor.  What happens internally at DDP is that:\n(1) During the construction of DDP, it will read through all the module's parameters, and register the call-back function (to reduce the gradients) to every single parameter.\n(2) During the backward, these reduction call-back functions will be called when the parameter's gradient is available.\nIf you change the parameter yourself to a new one after wrapping up your model to DDP, the backward hook call-back function has actually already registered on the old parameter, and the new parameter's hook won't get called. That's why in your repro program, the gradient reduction function is not triggered at all and you got the wrong gradients.\nThe old DDP (nccl code path) happens to work because it was able to all-reduce all parameters even though there is only one hook is called (there is supposed to be two, one for weight, one for bias). But since the new DDP as well as the old DDP (gloo code path) needs to provide parameter bucketing and communication overlapping for DDP performance reasons, we need to ensure that every single parameter's backward hook is called.\nTherefore, you should never change the actual parameter to a new one after wrapping up your model with DDP. This is by the DDP design and we should document this better.\nSo if you change your repro code to:\n    model =  torch.nn.Conv2d(channels, channels, 1).cuda()\n    model.weight = torch.nn.Parameter(\n            conv_weight_distributed)\n    torch.nn.init.constant_(model.bias, 0)\n    conv_distributed = torch.nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[rank])\n\n    y = conv_distributed(x)\n\nIt should work without any problem.\npytest --capture=sys ddp_repro.py\n========================================================= test session starts =========================================================\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\nrootdir: /private/home/tengli/github_issues, inifile:\ncollected 7 items\n\nddp_repro.py start\nstart\nregister hook: 139881643889864\nregister hook: 140578281600056\nregister hook: 139881643890008\nregister hook: 140578281600200\nhook: 140578281600056\nbucket ready size: [[1]], bucket size: [2]\nhook: 140578281600200\nbucket ready size: [[2]], bucket size: [2]\nfull\nqueue reduction : 0\nsave model\nhook: 139881643889864\nbucket ready size: [[1]], bucket size: [2]\nhook: 139881643890008\nbucket ready size: [[2]], bucket size: [2]\nfull\nqueue reduction : 0\nsave model\n.......                                                                                                            [100%]\n\n====================================================== 7 passed in 9.42 seconds =======================================================\ntengli@devfair033:~/github_issues$\n\nLet me know if you have more questions.", "body": "@acgtyrant \r\n\r\nOK, I spent some time today digging into this issue. \r\n\r\nThe short story is: there is nothing wrong with the current DistributedDataParallel (DDP)\r\n\r\nHere is why:  \r\nIn your repro code, you are assigning a new module parameter weight after the DDP constructor.  What happens internally at DDP is that: \r\n\r\n(1) During the construction of DDP, it will read through all the module's parameters, and register the call-back function (to reduce the gradients) to every single parameter.\r\n(2) During the backward, these reduction call-back functions will be called when the parameter's gradient is available.\r\n\r\nIf you change the parameter yourself to a new one after wrapping up your model to DDP, the backward hook call-back function has actually already registered on the old parameter, and the new parameter's hook won't get called. That's why in your repro program, the gradient reduction function is not triggered at all and you got the wrong gradients.\r\n\r\nThe old DDP (nccl code path) happens to work because it was able to all-reduce all parameters even though there is only one hook is called (there is supposed to be two, one for weight, one for bias). But since the new DDP as well as the old DDP (gloo code path) needs to provide parameter bucketing and communication overlapping for DDP performance reasons, we need to ensure that every single parameter's backward hook is called.\r\n\r\nTherefore, you should never change the actual parameter to a new one after wrapping up your model with DDP. This is by the DDP design and we should document this better. \r\n\r\nSo if you change your repro code to:\r\n  \r\n```\r\n    model =  torch.nn.Conv2d(channels, channels, 1).cuda()\r\n    model.weight = torch.nn.Parameter(\r\n            conv_weight_distributed)\r\n    torch.nn.init.constant_(model.bias, 0)\r\n    conv_distributed = torch.nn.parallel.DistributedDataParallel(\r\n            model,\r\n            device_ids=[rank])\r\n\r\n    y = conv_distributed(x)\r\n```\r\n\r\nIt should work without any problem. \r\n```\r\npytest --capture=sys ddp_repro.py\r\n========================================================= test session starts =========================================================\r\nplatform linux -- Python 3.6.5, pytest-3.8.2, py-1.6.0, pluggy-0.7.1\r\nrootdir: /private/home/tengli/github_issues, inifile:\r\ncollected 7 items\r\n\r\nddp_repro.py start\r\nstart\r\nregister hook: 139881643889864\r\nregister hook: 140578281600056\r\nregister hook: 139881643890008\r\nregister hook: 140578281600200\r\nhook: 140578281600056\r\nbucket ready size: [[1]], bucket size: [2]\r\nhook: 140578281600200\r\nbucket ready size: [[2]], bucket size: [2]\r\nfull\r\nqueue reduction : 0\r\nsave model\r\nhook: 139881643889864\r\nbucket ready size: [[1]], bucket size: [2]\r\nhook: 139881643890008\r\nbucket ready size: [[2]], bucket size: [2]\r\nfull\r\nqueue reduction : 0\r\nsave model\r\n.......                                                                                                            [100%]\r\n\r\n====================================================== 7 passed in 9.42 seconds =======================================================\r\ntengli@devfair033:~/github_issues$\r\n```\r\n\r\nLet me know if you have more questions."}