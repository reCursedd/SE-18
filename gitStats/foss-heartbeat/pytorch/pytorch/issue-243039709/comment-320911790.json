{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/320911790", "html_url": "https://github.com/pytorch/pytorch/pull/2103#issuecomment-320911790", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2103", "id": 320911790, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDkxMTc5MA==", "user": {"login": "alykhantejani", "id": 687194, "node_id": "MDQ6VXNlcjY4NzE5NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/687194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alykhantejani", "html_url": "https://github.com/alykhantejani", "followers_url": "https://api.github.com/users/alykhantejani/followers", "following_url": "https://api.github.com/users/alykhantejani/following{/other_user}", "gists_url": "https://api.github.com/users/alykhantejani/gists{/gist_id}", "starred_url": "https://api.github.com/users/alykhantejani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alykhantejani/subscriptions", "organizations_url": "https://api.github.com/users/alykhantejani/orgs", "repos_url": "https://api.github.com/users/alykhantejani/repos", "events_url": "https://api.github.com/users/alykhantejani/events{/privacy}", "received_events_url": "https://api.github.com/users/alykhantejani/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-08T10:05:21Z", "updated_at": "2017-08-08T10:05:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7891333\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jvmancuso\">@jvmancuso</a> The issue with <code>test_noncontig</code> is because the function tries to zero the gradients of the params <a href=\"https://github.com/pytorch/pytorch/blob/f484a5fee8ee30d51903f99b5f4c0ce212ca0cfa/test/common_nn.py#L665\">here</a> which calls this <a href=\"https://github.com/pytorch/pytorch/blob/977f9644c08680df69df108b037cdd5ee9f47f94/test/test_nn.py#L256\">snippet of code</a> which only zeros gradients for <code>weight</code> and <code>bias</code> and not the other params in this module (<code>weight_mu</code> etc.)</p>\n<p>I'm not quite sure why <code>_zero_grad_parameters</code> explicitly names <code>weight</code> and <code>bias</code>, but perhaps this function can be replaced with a call to <code>module. zero_grad ()</code>. Although there is a <code>detach()</code> call in <code>_zero_grad_parameters</code>, so if this is actually needed this function can instead loop through the modules parameters and manually zero the grads and detach.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> wdyt?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7891333\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jvmancuso\">@jvmancuso</a> in terms of the other test failing, try and pull in changes from upstream/master as you currently have merge conflicts anyway.</p>", "body_text": "@jvmancuso The issue with test_noncontig is because the function tries to zero the gradients of the params here which calls this snippet of code which only zeros gradients for weight and bias and not the other params in this module (weight_mu etc.)\nI'm not quite sure why _zero_grad_parameters explicitly names weight and bias, but perhaps this function can be replaced with a call to module. zero_grad (). Although there is a detach() call in _zero_grad_parameters, so if this is actually needed this function can instead loop through the modules parameters and manually zero the grads and detach.\n@soumith @apaszke wdyt?\n@jvmancuso in terms of the other test failing, try and pull in changes from upstream/master as you currently have merge conflicts anyway.", "body": "@jvmancuso The issue with `test_noncontig` is because the function tries to zero the gradients of the params [here](https://github.com/pytorch/pytorch/blob/f484a5fee8ee30d51903f99b5f4c0ce212ca0cfa/test/common_nn.py#L665) which calls this [snippet of code](https://github.com/pytorch/pytorch/blob/977f9644c08680df69df108b037cdd5ee9f47f94/test/test_nn.py#L256) which only zeros gradients for `weight` and `bias` and not the other params in this module (`weight_mu` etc.)\r\n\r\nI'm not quite sure why `_zero_grad_parameters` explicitly names `weight` and `bias`, but perhaps this function can be replaced with a call to `module. zero_grad ()`. Although there is a `detach()` call in `_zero_grad_parameters`, so if this is actually needed this function can instead loop through the modules parameters and manually zero the grads and detach.\r\n\r\n@soumith @apaszke wdyt?\r\n\r\n@jvmancuso in terms of the other test failing, try and pull in changes from upstream/master as you currently have merge conflicts anyway."}