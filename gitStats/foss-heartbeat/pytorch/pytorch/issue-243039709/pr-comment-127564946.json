{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/127564946", "pull_request_review_id": 50169881, "id": 127564946, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyNzU2NDk0Ng==", "diff_hunk": "@@ -115,4 +116,109 @@ def __repr__(self):\n             + ', in2_features=' + str(self.in2_features) \\\n             + ', out_features=' + str(self.out_features) + ')'\n \n+\n+class NoisyLinear(Module):\n+    \"\"\"Applies a noisy linear transformation to the incoming data.\n+    During training:\n+        :math:`y = (mu_w + sigma_w \\cdot epsilon_w)x\n+            + mu_b + sigma_b \\cdot epsilon_b`\n+    During evaluation:\n+        :math:`y = mu_w * x + mu_b`\n+    More details can be found in the paper `Noisy Networks for Exploration` _ .\n+    Args:\n+        in_features: size of each input sample\n+        out_features: size of each output sample\n+        bias: If set to False, the layer will not learn an additive bias.\n+            Default: True\n+        factorised: whether or not to use factorised noise.\n+            Default: True\n+        std_init: constant for weight_sigma and bias_sigma initialization.\n+            If None, defaults to 0.017 for independent and 0.4 for factorised.\n+            Default: None\n+    Shape:\n+        - Input: :math:`(N, in\\_features)`\n+        - Output: :math:`(N, out\\_features)`\n+    Attributes:\n+        weight: the learnable weights of the module of shape\n+            (out_features x in_features)\n+        bias:   the learnable bias of the module of shape (out_features)\n+    Methods:\n+        reset_noise: resamples the noise tensors\n+    Examples::\n+        >>> m = nn.NoisyLinear(20, 30)\n+        >>> input = autograd.Variable(torch.randn(128, 20))\n+        >>> output = m(input)\n+        >>> m.reset_noise()\n+        >>> output_new = m(input)\n+        >>> print(output)\n+        >>> print(output_new)\n+    \"\"\"\n+    def __init__(self, in_features, out_features, bias=True, factorised=True, std_init=None):", "path": "torch/nn/modules/linear.py", "position": null, "original_position": 58, "commit_id": "82337532f2880ab4f42cfa98f9596c351fa90974", "original_commit_id": "06c7a39f4f89c4494e7abbe1d1534159356834da", "user": {"login": "alykhantejani", "id": 687194, "node_id": "MDQ6VXNlcjY4NzE5NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/687194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alykhantejani", "html_url": "https://github.com/alykhantejani", "followers_url": "https://api.github.com/users/alykhantejani/followers", "following_url": "https://api.github.com/users/alykhantejani/following{/other_user}", "gists_url": "https://api.github.com/users/alykhantejani/gists{/gist_id}", "starred_url": "https://api.github.com/users/alykhantejani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alykhantejani/subscriptions", "organizations_url": "https://api.github.com/users/alykhantejani/orgs", "repos_url": "https://api.github.com/users/alykhantejani/repos", "events_url": "https://api.github.com/users/alykhantejani/events{/privacy}", "received_events_url": "https://api.github.com/users/alykhantejani/received_events", "type": "User", "site_admin": false}, "body": "Should we be using the US English `factorized` (with a `z`)?", "created_at": "2017-07-14T23:05:13Z", "updated_at": "2018-11-23T15:34:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/2103#discussion_r127564946", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2103", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/127564946"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2103#discussion_r127564946"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2103"}}, "body_html": "<p>Should we be using the US English <code>factorized</code> (with a <code>z</code>)?</p>", "body_text": "Should we be using the US English factorized (with a z)?"}