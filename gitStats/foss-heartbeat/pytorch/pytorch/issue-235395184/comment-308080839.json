{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/308080839", "html_url": "https://github.com/pytorch/pytorch/issues/1785#issuecomment-308080839", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1785", "id": 308080839, "node_id": "MDEyOklzc3VlQ29tbWVudDMwODA4MDgzOQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-13T10:57:45Z", "updated_at": "2017-06-13T10:57:45Z", "author_association": "MEMBER", "body_html": "<p>Oups...<br>\nI believe we have <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/lib/THC/generic/THCTensorRandom.h\"><code>bernoulli</code> in THC for ByteTensors</a>, so we should maybe just enable it for cuda tensors in <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/csrc/generic/methods/TensorRandom.cwrap#L446\">here</a>.<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I could send a quick fix to AlphaDropout (making it a bit less efficient by casting to <code>byte</code> after calling <code>bernoulli</code>), but a proper fix would be to enable bernoulli to cuda. Do you think it's as easy as removing the <code>!IS_CUDA</code>?</p>", "body_text": "Oups...\nI believe we have bernoulli in THC for ByteTensors, so we should maybe just enable it for cuda tensors in here.\n@apaszke I could send a quick fix to AlphaDropout (making it a bit less efficient by casting to byte after calling bernoulli), but a proper fix would be to enable bernoulli to cuda. Do you think it's as easy as removing the !IS_CUDA?", "body": "Oups...\r\nI believe we have [`bernoulli` in THC for ByteTensors](https://github.com/pytorch/pytorch/blob/master/torch/lib/THC/generic/THCTensorRandom.h), so we should maybe just enable it for cuda tensors in [here](https://github.com/pytorch/pytorch/blob/master/torch/csrc/generic/methods/TensorRandom.cwrap#L446).\r\n@apaszke I could send a quick fix to AlphaDropout (making it a bit less efficient by casting to `byte` after calling `bernoulli`), but a proper fix would be to enable bernoulli to cuda. Do you think it's as easy as removing the `!IS_CUDA`?"}