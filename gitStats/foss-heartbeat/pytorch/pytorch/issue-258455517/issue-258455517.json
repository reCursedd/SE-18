{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2774", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2774/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2774/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2774/events", "html_url": "https://github.com/pytorch/pytorch/issues/2774", "id": 258455517, "node_id": "MDU6SXNzdWUyNTg0NTU1MTc=", "number": 2774, "title": "None Grad with Custom Loss", "user": {"login": "lucabergamini", "id": 27865235, "node_id": "MDQ6VXNlcjI3ODY1MjM1", "avatar_url": "https://avatars1.githubusercontent.com/u/27865235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucabergamini", "html_url": "https://github.com/lucabergamini", "followers_url": "https://api.github.com/users/lucabergamini/followers", "following_url": "https://api.github.com/users/lucabergamini/following{/other_user}", "gists_url": "https://api.github.com/users/lucabergamini/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucabergamini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucabergamini/subscriptions", "organizations_url": "https://api.github.com/users/lucabergamini/orgs", "repos_url": "https://api.github.com/users/lucabergamini/repos", "events_url": "https://api.github.com/users/lucabergamini/events{/privacy}", "received_events_url": "https://api.github.com/users/lucabergamini/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-18T12:02:48Z", "updated_at": "2017-09-27T15:37:53Z", "closed_at": "2017-09-27T15:37:53Z", "author_association": "NONE", "body_html": "<p>Greetings, I'm trying a custom loss to minimize the IoU (intersection over union) between two rectangles, giving the coords of the four vertexes for both of them. What I'm trying to do for the single rectangle is basically to create a score map with 1 if the point is inside the bounds and 0 otherwise, where the points came from a grid 224x224 (I'm working on imagenet based networks). From there i can easily compute the intersection and union of two rectangles simply by sum and product of the masks. The forward part works smoothly, and so does the backward. However, even if I don't get any error, the grads are None everywhere, thus the network does not learn anything. Here is a minimum example which shows the problem (mind that replacing my loss with the MSE works as expected). I guess the gradient is lost somewhere, but I can't find where..</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> numpy\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">from</span> torch.nn <span class=\"pl-k\">import</span> MSELoss\n\n<span class=\"pl-k\">from</span> torch.nn.modules.loss <span class=\"pl-k\">import</span> _Loss\n<span class=\"pl-k\">from</span> matplotlib <span class=\"pl-k\">import</span> pyplot\n\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">IoU_real</span>(<span class=\"pl-e\">_Loss</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(_Loss, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> define the grid</span>\n        bounds <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">224</span>, <span class=\"pl-c1\">224</span>)\n        grid <span class=\"pl-k\">=</span> numpy.mgrid[<span class=\"pl-c1\">0</span>:bounds[<span class=\"pl-c1\">0</span>], <span class=\"pl-c1\">0</span>:bounds[<span class=\"pl-c1\">1</span>]]\n        <span class=\"pl-c1\">self</span>.grid <span class=\"pl-k\">=</span> numpy.concatenate((grid[<span class=\"pl-c1\">0</span>][<span class=\"pl-c1\">...</span>, numpy.newaxis], grid[<span class=\"pl-c1\">1</span>][<span class=\"pl-c1\">...</span>, numpy.newaxis]), <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n        <span class=\"pl-c1\">self</span>.grid <span class=\"pl-k\">=</span> Variable(torch.FloatTensor(<span class=\"pl-c1\">self</span>.grid).cuda(), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_get_mask</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">rect</span>):\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">        get the rectangle area on the grid as a 2-values mask</span>\n<span class=\"pl-s\">        :param rect: 4x2 rect coords</span>\n<span class=\"pl-s\">        :return: 224x224 image with 2-values (0 stands for outside, 1 for inside)</span>\n<span class=\"pl-s\">        <span class=\"pl-pds\">\"\"\"</span></span>\n\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>get coefficients of the 4 lines which limit the rectangle area</span>\n        coeff_x <span class=\"pl-k\">=</span> []\n        coeff_y <span class=\"pl-k\">=</span> []\n        coeff_q <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">4</span>):\n            <span class=\"pl-k\">if</span> i <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">3</span>:\n                p_1 <span class=\"pl-k\">=</span> rect[i]\n                p_2 <span class=\"pl-k\">=</span> rect[i <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>]\n            <span class=\"pl-k\">else</span>:\n                p_1 <span class=\"pl-k\">=</span> rect[i]\n                p_2 <span class=\"pl-k\">=</span> rect[<span class=\"pl-c1\">0</span>]\n\n            coeff_x.append(p_1[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">-</span> p_2[<span class=\"pl-c1\">1</span>])\n            coeff_y.append(p_2[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">-</span> p_1[<span class=\"pl-c1\">0</span>])\n            coeff_q.append(p_1[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> p_2[<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">-</span> p_2[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">*</span> p_1[<span class=\"pl-c1\">1</span>])\n\n        coeff_x <span class=\"pl-k\">=</span> torch.cat(coeff_x)\n        coeff_y <span class=\"pl-k\">=</span> torch.cat(coeff_y)\n        coeff_q <span class=\"pl-k\">=</span> torch.cat(coeff_q)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>test every point in the grid against the equations</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> 224*224*1-&gt; 224*224*4 -&gt; 224*224*4</span>\n        score <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.grid[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">0</span>:<span class=\"pl-c1\">1</span>] <span class=\"pl-k\">*</span> coeff_x <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.grid[<span class=\"pl-c1\">...</span>, <span class=\"pl-c1\">1</span>:<span class=\"pl-c1\">2</span>] <span class=\"pl-k\">*</span> coeff_y <span class=\"pl-k\">+</span> coeff_q\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>now intersect the area</span>\n        score_final <span class=\"pl-k\">=</span> Variable(torch.ones(<span class=\"pl-c1\">list</span>(score.size())[:<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]).cuda(), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(<span class=\"pl-c1\">4</span>):\n            score_final <span class=\"pl-k\">=</span> score_final <span class=\"pl-k\">*</span> (score[<span class=\"pl-c1\">...</span>, i] <span class=\"pl-k\">&lt;=</span> <span class=\"pl-c1\">0</span>).float()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>return the map</span>\n        <span class=\"pl-k\">return</span> score_final\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">per_element_loss</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">out</span>, <span class=\"pl-smi\">label</span>):\n        out <span class=\"pl-k\">=</span> torch.squeeze(out)\n        label <span class=\"pl-k\">=</span> torch.squeeze(label)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>get both maskes</span>\n        m_1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._get_mask(out)\n        m_2 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._get_mask(label)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>show them for debug</span>\n        pyplot.imshow((m_1 <span class=\"pl-k\">+</span> m_2).data.cpu().numpy(), <span class=\"pl-v\">cmap</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Greys<span class=\"pl-pds\">\"</span></span>)\n        pyplot.show()\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>intersection is where the two cohexists</span>\n        intersection <span class=\"pl-k\">=</span> torch.sum(m_1 <span class=\"pl-k\">*</span> m_2)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>union is the sum minus the intersection, otherwise it would be counted twice</span>\n        union <span class=\"pl-k\">=</span> torch.sum(m_1 <span class=\"pl-k\">+</span> m_2) <span class=\"pl-k\">-</span> intersection\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>small fuzzy</span>\n        iou <span class=\"pl-k\">=</span> intersection <span class=\"pl-k\">/</span> (union <span class=\"pl-k\">+</span> <span class=\"pl-c1\">10e-08</span>)\n        <span class=\"pl-k\">return</span> iou\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">outs</span>, <span class=\"pl-smi\">labels</span>):\n        <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span>\n<span class=\"pl-s\">        :param outs: out vertices as  n_el*1*4*2 </span>\n<span class=\"pl-s\">        :param labels: target vertices as  n_el*1*4*2</span>\n<span class=\"pl-s\">        :return: iou  </span>\n<span class=\"pl-s\">        <span class=\"pl-pds\">\"\"\"</span></span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>define the accumulator</span>\n        iou_final <span class=\"pl-k\">=</span> Variable(torch.FloatTensor(numpy.zeros(<span class=\"pl-c1\">1</span>)).cuda(), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>iterate over couples</span>\n        <span class=\"pl-k\">for</span> (out, label) <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(outs, labels):\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> the metric is in fact 1-IoU (because we wat to minimize the loss)</span>\n            iou_final <span class=\"pl-k\">=</span> iou_final <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> <span class=\"pl-c1\">self</span>.per_element_loss(out, label))\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>average</span>\n        <span class=\"pl-k\">return</span> iou_final <span class=\"pl-k\">/</span> <span class=\"pl-c1\">len</span>(outs)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>two rectangles</span>\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> numpy.array(((<span class=\"pl-c1\">50</span>, <span class=\"pl-c1\">50</span>), (<span class=\"pl-c1\">50</span>, <span class=\"pl-c1\">100</span>), (<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>), (<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">50</span>)))\n    target <span class=\"pl-k\">=</span> numpy.array(((<span class=\"pl-c1\">50</span>, <span class=\"pl-c1\">50</span>), (<span class=\"pl-c1\">50</span>, <span class=\"pl-c1\">100</span>), (<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>), (<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">50</span>)))\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>torch</span>\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> Variable(torch.FloatTensor(<span class=\"pl-c1\">input</span>)).cuda()\n    target <span class=\"pl-k\">=</span> Variable(torch.FloatTensor(target)).cuda()\n    target <span class=\"pl-k\">=</span> target.view(<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>we just add a bias</span>\n    bias <span class=\"pl-k\">=</span> Variable(torch.ones(<span class=\"pl-c1\">8</span>).cuda() <span class=\"pl-k\">*</span> <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>instantiate the loss</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>MSE works..</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>loss = MSELoss().cuda()</span>\n    loss <span class=\"pl-k\">=</span> IoU_real().cuda()\n\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span>.view(<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>)\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">input</span> <span class=\"pl-k\">+</span> bias\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>compute the output</span>\n    res <span class=\"pl-k\">=</span> loss(<span class=\"pl-c1\">input</span>.view(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>), target.view(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>) <span class=\"pl-k\">+</span> <span class=\"pl-c1\">20</span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>IoU is not 0, so we should have a gradient wrt bias</span>\n    <span class=\"pl-c1\">print</span> res\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>do the backprop</span>\n    res.backward()\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span>print the gradient</span>\n    <span class=\"pl-c1\">print</span> bias.grad\n\n\n\n</pre></div>\n<p>The code shows the two rectangles overlayed, and the IoU Loss is not 1, so it should propagate some gradient back..</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/27865235/30541047-ee70764e-9c79-11e7-8c94-894585b7f8f4.png\"><img src=\"https://user-images.githubusercontent.com/27865235/30541047-ee70764e-9c79-11e7-8c94-894585b7f8f4.png\" alt=\"figure_1\" style=\"max-width:100%;\"></a></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/27865235/30541066-077c743a-9c7a-11e7-9942-7634eb461ec6.png\"><img src=\"https://user-images.githubusercontent.com/27865235/30541066-077c743a-9c7a-11e7-9942-7634eb461ec6.png\" alt=\"figure_2\" style=\"max-width:100%;\"></a></p>", "body_text": "Greetings, I'm trying a custom loss to minimize the IoU (intersection over union) between two rectangles, giving the coords of the four vertexes for both of them. What I'm trying to do for the single rectangle is basically to create a score map with 1 if the point is inside the bounds and 0 otherwise, where the points came from a grid 224x224 (I'm working on imagenet based networks). From there i can easily compute the intersection and union of two rectangles simply by sum and product of the masks. The forward part works smoothly, and so does the backward. However, even if I don't get any error, the grads are None everywhere, thus the network does not learn anything. Here is a minimum example which shows the problem (mind that replacing my loss with the MSE works as expected). I guess the gradient is lost somewhere, but I can't find where..\nimport torch\nimport numpy\nfrom torch.autograd import Variable\nfrom torch.nn import MSELoss\n\nfrom torch.nn.modules.loss import _Loss\nfrom matplotlib import pyplot\n\n\n\nclass IoU_real(_Loss):\n    def __init__(self):\n        super(_Loss, self).__init__()\n        # define the grid\n        bounds = (224, 224)\n        grid = numpy.mgrid[0:bounds[0], 0:bounds[1]]\n        self.grid = numpy.concatenate((grid[0][..., numpy.newaxis], grid[1][..., numpy.newaxis]), axis=-1)\n        self.grid = Variable(torch.FloatTensor(self.grid).cuda(), requires_grad=True)\n\n    def _get_mask(self, rect):\n        \"\"\"\n        get the rectangle area on the grid as a 2-values mask\n        :param rect: 4x2 rect coords\n        :return: 224x224 image with 2-values (0 stands for outside, 1 for inside)\n        \"\"\"\n\n\n        #get coefficients of the 4 lines which limit the rectangle area\n        coeff_x = []\n        coeff_y = []\n        coeff_q = []\n        for i in xrange(4):\n            if i != 3:\n                p_1 = rect[i]\n                p_2 = rect[i + 1]\n            else:\n                p_1 = rect[i]\n                p_2 = rect[0]\n\n            coeff_x.append(p_1[1] - p_2[1])\n            coeff_y.append(p_2[0] - p_1[0])\n            coeff_q.append(p_1[0] * p_2[1] - p_2[0] * p_1[1])\n\n        coeff_x = torch.cat(coeff_x)\n        coeff_y = torch.cat(coeff_y)\n        coeff_q = torch.cat(coeff_q)\n\n        #test every point in the grid against the equations\n        # 224*224*1-> 224*224*4 -> 224*224*4\n        score = self.grid[..., 0:1] * coeff_x + self.grid[..., 1:2] * coeff_y + coeff_q\n        #now intersect the area\n        score_final = Variable(torch.ones(list(score.size())[:-1]).cuda(), requires_grad=True)\n        for i in xrange(4):\n            score_final = score_final * (score[..., i] <= 0).float()\n        #return the map\n        return score_final\n\n    def per_element_loss(self, out, label):\n        out = torch.squeeze(out)\n        label = torch.squeeze(label)\n        #get both maskes\n        m_1 = self._get_mask(out)\n        m_2 = self._get_mask(label)\n        #show them for debug\n        pyplot.imshow((m_1 + m_2).data.cpu().numpy(), cmap=\"Greys\")\n        pyplot.show()\n        #intersection is where the two cohexists\n        intersection = torch.sum(m_1 * m_2)\n        #union is the sum minus the intersection, otherwise it would be counted twice\n        union = torch.sum(m_1 + m_2) - intersection\n        #small fuzzy\n        iou = intersection / (union + 10e-08)\n        return iou\n\n    def forward(self, outs, labels):\n        \"\"\"\n        :param outs: out vertices as  n_el*1*4*2 \n        :param labels: target vertices as  n_el*1*4*2\n        :return: iou  \n        \"\"\"\n        #define the accumulator\n        iou_final = Variable(torch.FloatTensor(numpy.zeros(1)).cuda(), requires_grad=True)\n        #iterate over couples\n        for (out, label) in zip(outs, labels):\n            # the metric is in fact 1-IoU (because we wat to minimize the loss)\n            iou_final = iou_final + (1 - self.per_element_loss(out, label))\n        #average\n        return iou_final / len(outs)\n\n\nif __name__ == \"__main__\":\n    #two rectangles\n    input = numpy.array(((50, 50), (50, 100), (100, 100), (100, 50)))\n    target = numpy.array(((50, 50), (50, 100), (100, 100), (100, 50)))\n    #torch\n    input = Variable(torch.FloatTensor(input)).cuda()\n    target = Variable(torch.FloatTensor(target)).cuda()\n    target = target.view(1, -1)\n    #we just add a bias\n    bias = Variable(torch.ones(8).cuda() * 10, requires_grad=True)\n    #instantiate the loss\n    #MSE works..\n    #loss = MSELoss().cuda()\n    loss = IoU_real().cuda()\n\n    input = input.view(1, -1)\n    input = input + bias\n    #compute the output\n    res = loss(input.view(1, 1, 4, 2), target.view(1, 1, 4, 2) + 20)\n    #IoU is not 0, so we should have a gradient wrt bias\n    print res\n    #do the backprop\n    res.backward()\n    #print the gradient\n    print bias.grad\n\n\n\n\nThe code shows the two rectangles overlayed, and the IoU Loss is not 1, so it should propagate some gradient back..", "body": "Greetings, I'm trying a custom loss to minimize the IoU (intersection over union) between two rectangles, giving the coords of the four vertexes for both of them. What I'm trying to do for the single rectangle is basically to create a score map with 1 if the point is inside the bounds and 0 otherwise, where the points came from a grid 224x224 (I'm working on imagenet based networks). From there i can easily compute the intersection and union of two rectangles simply by sum and product of the masks. The forward part works smoothly, and so does the backward. However, even if I don't get any error, the grads are None everywhere, thus the network does not learn anything. Here is a minimum example which shows the problem (mind that replacing my loss with the MSE works as expected). I guess the gradient is lost somewhere, but I can't find where..\r\n\r\n```python\r\n\r\nimport torch\r\nimport numpy\r\nfrom torch.autograd import Variable\r\nfrom torch.nn import MSELoss\r\n\r\nfrom torch.nn.modules.loss import _Loss\r\nfrom matplotlib import pyplot\r\n\r\n\r\n\r\nclass IoU_real(_Loss):\r\n    def __init__(self):\r\n        super(_Loss, self).__init__()\r\n        # define the grid\r\n        bounds = (224, 224)\r\n        grid = numpy.mgrid[0:bounds[0], 0:bounds[1]]\r\n        self.grid = numpy.concatenate((grid[0][..., numpy.newaxis], grid[1][..., numpy.newaxis]), axis=-1)\r\n        self.grid = Variable(torch.FloatTensor(self.grid).cuda(), requires_grad=True)\r\n\r\n    def _get_mask(self, rect):\r\n        \"\"\"\r\n        get the rectangle area on the grid as a 2-values mask\r\n        :param rect: 4x2 rect coords\r\n        :return: 224x224 image with 2-values (0 stands for outside, 1 for inside)\r\n        \"\"\"\r\n\r\n\r\n        #get coefficients of the 4 lines which limit the rectangle area\r\n        coeff_x = []\r\n        coeff_y = []\r\n        coeff_q = []\r\n        for i in xrange(4):\r\n            if i != 3:\r\n                p_1 = rect[i]\r\n                p_2 = rect[i + 1]\r\n            else:\r\n                p_1 = rect[i]\r\n                p_2 = rect[0]\r\n\r\n            coeff_x.append(p_1[1] - p_2[1])\r\n            coeff_y.append(p_2[0] - p_1[0])\r\n            coeff_q.append(p_1[0] * p_2[1] - p_2[0] * p_1[1])\r\n\r\n        coeff_x = torch.cat(coeff_x)\r\n        coeff_y = torch.cat(coeff_y)\r\n        coeff_q = torch.cat(coeff_q)\r\n\r\n        #test every point in the grid against the equations\r\n        # 224*224*1-> 224*224*4 -> 224*224*4\r\n        score = self.grid[..., 0:1] * coeff_x + self.grid[..., 1:2] * coeff_y + coeff_q\r\n        #now intersect the area\r\n        score_final = Variable(torch.ones(list(score.size())[:-1]).cuda(), requires_grad=True)\r\n        for i in xrange(4):\r\n            score_final = score_final * (score[..., i] <= 0).float()\r\n        #return the map\r\n        return score_final\r\n\r\n    def per_element_loss(self, out, label):\r\n        out = torch.squeeze(out)\r\n        label = torch.squeeze(label)\r\n        #get both maskes\r\n        m_1 = self._get_mask(out)\r\n        m_2 = self._get_mask(label)\r\n        #show them for debug\r\n        pyplot.imshow((m_1 + m_2).data.cpu().numpy(), cmap=\"Greys\")\r\n        pyplot.show()\r\n        #intersection is where the two cohexists\r\n        intersection = torch.sum(m_1 * m_2)\r\n        #union is the sum minus the intersection, otherwise it would be counted twice\r\n        union = torch.sum(m_1 + m_2) - intersection\r\n        #small fuzzy\r\n        iou = intersection / (union + 10e-08)\r\n        return iou\r\n\r\n    def forward(self, outs, labels):\r\n        \"\"\"\r\n        :param outs: out vertices as  n_el*1*4*2 \r\n        :param labels: target vertices as  n_el*1*4*2\r\n        :return: iou  \r\n        \"\"\"\r\n        #define the accumulator\r\n        iou_final = Variable(torch.FloatTensor(numpy.zeros(1)).cuda(), requires_grad=True)\r\n        #iterate over couples\r\n        for (out, label) in zip(outs, labels):\r\n            # the metric is in fact 1-IoU (because we wat to minimize the loss)\r\n            iou_final = iou_final + (1 - self.per_element_loss(out, label))\r\n        #average\r\n        return iou_final / len(outs)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    #two rectangles\r\n    input = numpy.array(((50, 50), (50, 100), (100, 100), (100, 50)))\r\n    target = numpy.array(((50, 50), (50, 100), (100, 100), (100, 50)))\r\n    #torch\r\n    input = Variable(torch.FloatTensor(input)).cuda()\r\n    target = Variable(torch.FloatTensor(target)).cuda()\r\n    target = target.view(1, -1)\r\n    #we just add a bias\r\n    bias = Variable(torch.ones(8).cuda() * 10, requires_grad=True)\r\n    #instantiate the loss\r\n    #MSE works..\r\n    #loss = MSELoss().cuda()\r\n    loss = IoU_real().cuda()\r\n\r\n    input = input.view(1, -1)\r\n    input = input + bias\r\n    #compute the output\r\n    res = loss(input.view(1, 1, 4, 2), target.view(1, 1, 4, 2) + 20)\r\n    #IoU is not 0, so we should have a gradient wrt bias\r\n    print res\r\n    #do the backprop\r\n    res.backward()\r\n    #print the gradient\r\n    print bias.grad\r\n\r\n\r\n\r\n\r\n```\r\n\r\n\r\nThe code shows the two rectangles overlayed, and the IoU Loss is not 1, so it should propagate some gradient back..\r\n\r\n![figure_1](https://user-images.githubusercontent.com/27865235/30541047-ee70764e-9c79-11e7-8c94-894585b7f8f4.png)\r\n\r\n![figure_2](https://user-images.githubusercontent.com/27865235/30541066-077c743a-9c7a-11e7-9942-7634eb461ec6.png)\r\n"}