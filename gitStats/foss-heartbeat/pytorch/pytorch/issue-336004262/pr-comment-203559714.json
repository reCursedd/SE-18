{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203559714", "pull_request_review_id": 138474614, "id": 203559714, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzU1OTcxNA==", "diff_hunk": "@@ -20,49 +22,61 @@\n //      .build()\n //\n // [MyKernel.cpp / MyKernel.cu]\n-//   cpu_binary_kernel(iter, [](float a, float b) {\n+//   binary_kernel(iter, [](float a, float b) {\n //     return a + b;\n //   });\n //\n //   gpu_binary_kernel(iter, []GPU_LAMBDA(float a, float b) -> float {\n //     return a + b;\n //   });\n //\n-// This inspired by NumPy's Array Iterator API (NpyIter).\n+// Note [Result type computation]\n+// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+// TensorIterator handles limited mixed-type operations. The result type is\n+// computed using promoteTypes on the types of the operands with the following\n+// precedence:\n+//\n+// 1) Tensors with dim 1 or higher\n+// 2) Tensors with dim 0 that aren't wrapped numbers (e.g. `tensor(5)`)\n+// 3) Tensors with dim 0 that are wrapped numbers (e.g. `5`)\n+//\n+// So if there are any tensors of dim 1 or higher, then 0-dim tensors do not\n+// affect the result type. This behavior was chosen to preserve backwards\n+// compatibility and is *likely to change* in the near future.", "path": "aten/src/ATen/native/TensorIterator.h", "position": 45, "original_position": 35, "commit_id": "b2efd9cc7a5dcff977b0be9aff2ca3bc0cfa159d", "original_commit_id": "bdf5c0b6a9d1832f8f7c04bf116a02fde1ad1e93", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "Currently, `int_tensor + 2.5` returns an int tensor. This behavior is preserved in this PR. In the future, if we adopt https://github.com/pytorch/pytorch/issues/9515, it will return a floating-point tensor.", "created_at": "2018-07-18T23:13:29Z", "updated_at": "2018-11-23T15:47:40Z", "html_url": "https://github.com/pytorch/pytorch/pull/8919#discussion_r203559714", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8919", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/203559714"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8919#discussion_r203559714"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8919"}}, "body_html": "<p>Currently, <code>int_tensor + 2.5</code> returns an int tensor. This behavior is preserved in this PR. In the future, if we adopt <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"342120125\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9515\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/9515/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/9515\">#9515</a>, it will return a floating-point tensor.</p>", "body_text": "Currently, int_tensor + 2.5 returns an int tensor. This behavior is preserved in this PR. In the future, if we adopt #9515, it will return a floating-point tensor.", "in_reply_to_id": 203203727}