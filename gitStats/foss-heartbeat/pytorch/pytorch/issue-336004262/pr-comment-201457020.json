{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/201457020", "pull_request_review_id": 135943123, "id": 201457020, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMTQ1NzAyMA==", "diff_hunk": "@@ -0,0 +1,213 @@\n+#pragma once\n+\n+#include <ATen/ATen.h>\n+#include <ATen/SmallVector.h>\n+#include <ATen/optional.h>\n+#include <ATen/detail/ScalarTypeConversions.h>\n+\n+// TensorIterator is a helper class for element-wise operations, such as\n+// arithmetic, comparisions, and trigonometric functions. It handles\n+// broadcasting and type conversions of operands.\n+//\n+// The files Loops.h and Loops.cuh provide functions to build kernels that\n+// use TensorIterator.\n+//\n+// Example:\n+//\n+//   auto iter = TensorIterator::Builder()\n+//      .add_output(output)\n+//      .add_input(input)\n+//      .build()\n+//\n+// [MyKernel.cpp / MyKernel.cu]\n+//   cpu_binary_kernel(iter, [](float a, float b) {\n+//     return a + b;\n+//   });\n+//\n+//   gpu_binary_kernel(iter, []GPU_LAMBDA(float a, float b) -> float {\n+//     return a + b;\n+//   });\n+//\n+// This inspired by NumPy's Array Iterator API (NpyIter).\n+\n+namespace at {\n+\n+struct OperandInfo {\n+  OperandInfo() {}\n+  OperandInfo(const Tensor& t) : tensor_(const_cast<Tensor*>(&t)) {}\n+\n+  /// Stride after broadcasting. The stride is in bytes, not number of elements.\n+  DimVector stride_;\n+\n+  /// The original tensor operand. Note that the strides, data pointer, and\n+  /// other attributes may differ from due to dimension reordering and\n+  /// coalescing.\n+  Tensor* tensor_;\n+\n+  /// The desired type for the operand. This may be different from the actual\n+  /// tensor type, in which case casting is necessary.\n+  Type* type_ = nullptr;\n+\n+  /// The data pointer. This may be different from tensor.data_ptr() if the\n+  /// iterator is split.\n+  void* data_ = nullptr;\n+\n+  /// True if the kernel needs to handle a cast operation for this operand.\n+  bool needs_cast_ = false;\n+\n+  bool is_output_ = false;\n+\n+  bool is_read_write_ = false;\n+};\n+\n+enum class IteratorFlags {\n+  COMMON_DTYPE = 1,\n+  ALLOW_CPU_SCALARS = 2,\n+};\n+\n+struct SplitUntil32Bit;\n+\n+struct TensorIterator {\n+  struct Builder;\n+  friend struct Builder;\n+\n+  TensorIterator() {}\n+\n+  using loop_t = const std::function<void(int, char**, const int64_t*, int64_t)>&;\n+\n+  static std::unique_ptr<TensorIterator> binary_op(const Tensor& a, const Tensor& b, Tensor& out);\n+  static TensorIterator reduce_op(const Tensor& a, IntList dims);\n+\n+  int ndim() const { return shape_.size(); }\n+  IntList shape() const { return shape_; }\n+  int64_t numel() const;\n+  int ntensors() const { return operands_.size(); }\n+\n+  /// 1-dimensional iteration and no buffering or type conversion\n+  bool is_trivial_1d() const;\n+\n+  /// Accessors for each operand\n+  IntList strides(int arg) const { return operands_[arg].stride_; }\n+  void* data_ptr(int arg) const;\n+  const Type& type(int arg=0) const {\n+    AT_ASSERT(operands_[arg].type_);\n+    return *operands_[arg].type_;\n+  }\n+  ScalarType dtype(int arg) const { return type(arg).scalarType(); }\n+  Backend backend(int arg=0) const { return type(arg).backend(); }\n+  bool is_scalar(int arg) const;\n+  bool is_cpu_scalar(int arg) const;\n+\n+  Tensor output(int arg=0) const {\n+    AT_ASSERT(arg < num_outputs_);\n+    return *operands_[arg].tensor_;\n+  }\n+\n+  /// Removes an operand from this iterator\n+  void remove_operand(int arg);\n+  /// Removes a dimension from iteration\n+  void remove_dimension(int dim);\n+  /// Shrinks an iterated dimension\n+  void narrow(int dim, int64_t start, int64_t size);\n+\n+  /// Splits this TensorIterator into two iterators. Together they iterate over\n+  /// the entire operation. Used by `with_32bit_indexing()`.\n+  std::unique_ptr<TensorIterator> split();\n+\n+  template <typename T>\n+  T scalar_value(int arg) {\n+    auto& op = operands_[arg];\n+    return at::detail::load<T>(op.data_, op.tensor_->type().scalarType());\n+  }\n+\n+  void for_each(loop_t loop);\n+  void serial_for_each(loop_t loop, ArrayRef<char*> base_ptrs, IntList inner_strides, int64_t start, int64_t size);\n+\n+  /// Create a strides array for a Tensor with shape of this iterator. The\n+  /// parameter `element_size` specifies the size of Tensor's data type in\n+  /// bytes (e.g. `4` for `float`)\n+  DimVector compatible_stride(int element_size) const;\n+\n+  /// Inverts the re-ordering done by reorder_dimensions. This can only be\n+  /// called *before* coalesce_dimensions() is called.\n+  DimVector invert_perm(IntList input) const;\n+\n+  /// Helper functions for CPU iteration\n+  DimVector make_counter(int64_t linear_offset) const;\n+  void increment_counter(DimVector& counter, int64_t n) const;\n+  DimVector get_inner_strides() const;\n+  SmallVector<char*, 4> get_data_ptrs(ArrayRef<char*> base, IntList counter) const;\n+  SmallVector<char*, 4> get_base_ptrs() const;\n+\n+  /// true if the stride computation can use 32-bit arithmetic. Used by GPU kernels\n+  bool can_use_32bit_indexing() const;\n+\n+  /// An \"iteratable\" objet that recursively splits this iterator into sub-iterators\n+  /// that can use 32-bit indexing.\n+  SplitUntil32Bit with_32bit_indexing() const;\n+\n+protected:\n+  void mark_outputs();\n+  void compute_shape();\n+  void compute_strides();\n+  void reorder_dimensions();\n+  void compute_common_type();\n+  void allocate_outputs();\n+  void coalesce_dimensions();\n+  void check_type_conversions();\n+\n+private:\n+  DimVector shape_;\n+  DimVector perm_;\n+  SmallVector<OperandInfo, 4> operands_;\n+  int num_outputs_ = 0;\n+};\n+\n+struct TensorIterator::Builder {\n+  Builder() : iter_(new TensorIterator()) {};\n+\n+  Builder& add_output(const Tensor& output) {\n+    iter_->operands_.emplace_back(output);\n+    iter_->num_outputs_++;\n+    return *this;\n+  }\n+\n+  Builder& add_input(const Tensor& input) {\n+    iter_->operands_.emplace_back(input);\n+    return *this;\n+  }\n+\n+  std::unique_ptr<TensorIterator> build();\n+\n+private:\n+  std::unique_ptr<TensorIterator> iter_;\n+};\n+\n+/// A container-like struct that acts as if it contains splits of a\n+/// TensorIterator that can use 32-bit indexing. Taken together the splits cover\n+/// the original TensorIterator.\n+struct SplitUntil32Bit {\n+  struct iterator {\n+    iterator() {};\n+    iterator(const TensorIterator& iter);\n+\n+    TensorIterator& operator*() const;\n+    iterator& operator++();\n+    bool operator!=(const iterator& other) {\n+      return !vec.empty() || !other.vec.empty();", "path": "aten/src/ATen/native/TensorIterator.h", "position": null, "original_position": 197, "commit_id": "b2efd9cc7a5dcff977b0be9aff2ca3bc0cfa159d", "original_commit_id": "38d31d836a8c373b2f34acc35953c2ad910bca3e", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "The C++11 range-base for loop requires the \"iterator\" to support `!=` to the end iterator. Two iterators are equal only if they're both empty. I'll redefine this in terms of an `operator==` because that might make it a bit more clear.", "created_at": "2018-07-10T18:56:14Z", "updated_at": "2018-11-23T15:47:04Z", "html_url": "https://github.com/pytorch/pytorch/pull/8919#discussion_r201457020", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8919", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/201457020"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8919#discussion_r201457020"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8919"}}, "body_html": "<p>The C++11 range-base for loop requires the \"iterator\" to support <code>!=</code> to the end iterator. Two iterators are equal only if they're both empty. I'll redefine this in terms of an <code>operator==</code> because that might make it a bit more clear.</p>", "body_text": "The C++11 range-base for loop requires the \"iterator\" to support != to the end iterator. Two iterators are equal only if they're both empty. I'll redefine this in terms of an operator== because that might make it a bit more clear.", "in_reply_to_id": 201139863}