{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/200678958", "pull_request_review_id": 135046544, "id": 200678958, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMDY3ODk1OA==", "diff_hunk": "@@ -130,4 +130,39 @@ inline std::vector<Tensor> expand_outplace(TensorList to_expand) {\n   return result;\n }\n \n+// Sums `tensor` repeatedly to produce a tensor of shape `shape`.\n+// Precondition: is_expandable_to(shape, tensor.sizes()) must be true\n+static inline Tensor reduce_to(Tensor tensor, IntList shape) {\n+  if (shape.size() == 0) {\n+    return tensor.sum();\n+  }\n+  Tensor result = tensor;\n+  while (result.dim() > (int64_t)shape.size()) {\n+    result = result.sum(0, false);\n+  }\n+  for (int64_t i = 0; i < result.dim(); ++i) {\n+    if (shape[i] == 1 && result.sizes()[i] > 1) {\n+      result = result.sum(i, true);\n+    }\n+  }", "path": "aten/src/ATen/ExpandUtils.h", "position": 18, "original_position": 18, "commit_id": "b2efd9cc7a5dcff977b0be9aff2ca3bc0cfa159d", "original_commit_id": "38d31d836a8c373b2f34acc35953c2ad910bca3e", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Shouldn't we sum the tensor starting from the last dimensions and do the last ones only at the end? We might also want to reshape it, because it's possible that some dimension could have been folded.", "created_at": "2018-07-06T14:56:00Z", "updated_at": "2018-11-23T15:46:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/8919#discussion_r200678958", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8919", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/200678958"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8919#discussion_r200678958"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8919"}}, "body_html": "<p>Shouldn't we sum the tensor starting from the last dimensions and do the last ones only at the end? We might also want to reshape it, because it's possible that some dimension could have been folded.</p>", "body_text": "Shouldn't we sum the tensor starting from the last dimensions and do the last ones only at the end? We might also want to reshape it, because it's possible that some dimension could have been folded."}