{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1634", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1634/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1634/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1634/events", "html_url": "https://github.com/pytorch/pytorch/issues/1634", "id": 230834964, "node_id": "MDU6SXNzdWUyMzA4MzQ5NjQ=", "number": 1634, "title": "Variable.clone() does not clone to the same device", "user": {"login": "el3ment", "id": 2135235, "node_id": "MDQ6VXNlcjIxMzUyMzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2135235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/el3ment", "html_url": "https://github.com/el3ment", "followers_url": "https://api.github.com/users/el3ment/followers", "following_url": "https://api.github.com/users/el3ment/following{/other_user}", "gists_url": "https://api.github.com/users/el3ment/gists{/gist_id}", "starred_url": "https://api.github.com/users/el3ment/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/el3ment/subscriptions", "organizations_url": "https://api.github.com/users/el3ment/orgs", "repos_url": "https://api.github.com/users/el3ment/repos", "events_url": "https://api.github.com/users/el3ment/events{/privacy}", "received_events_url": "https://api.github.com/users/el3ment/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-05-23T20:31:34Z", "updated_at": "2017-05-23T21:59:54Z", "closed_at": "2017-05-23T21:59:54Z", "author_association": "NONE", "body_html": "<p>We have a custom Function that passes input and output memory to a cuda kernel. In order for the backward pass to work we need the output memory (which is allocated in the function) to be on the same device as the input. Calling input1.clone() put it on the last device.</p>", "body_text": "We have a custom Function that passes input and output memory to a cuda kernel. In order for the backward pass to work we need the output memory (which is allocated in the function) to be on the same device as the input. Calling input1.clone() put it on the last device.", "body": "We have a custom Function that passes input and output memory to a cuda kernel. In order for the backward pass to work we need the output memory (which is allocated in the function) to be on the same device as the input. Calling input1.clone() put it on the last device."}