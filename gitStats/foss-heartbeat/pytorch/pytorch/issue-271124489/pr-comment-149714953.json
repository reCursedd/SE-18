{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149714953", "pull_request_review_id": 75152545, "id": 149714953, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0OTcxNDk1Mw==", "diff_hunk": "@@ -0,0 +1,253 @@\n+#include <sys/wait.h>\n+#include <set>\n+#include <atomic>\n+#include <signal.h>\n+#include \"THP.h\"\n+\n+// In cases like DataLoader, if a worker process die due to bus error/segfault\n+// or just hang, the main process, if implemented with\n+// multiprocessing.queue.SimpleQueue, will hang waiting for data. This is\n+// difficult to avoid on PyTorch side as it can be caused by limited shm, or\n+// other libraries users call in the workers. The following methods is an effort\n+// to do our best provide some error message to users when such unfortunate\n+// events happen.\n+\n+// TODO: The following don't work on Windows. Specifically, waitpid calls and\n+// SIGCHLD handler.\n+\n+#ifndef _WIN32\n+\n+// Critical signal handlers should be registered on worker processes before\n+// doing work.\n+// Python handle is _set_worker_signal_handlers().\n+#define SIGNAL_HANDLER(SIGNAL, HANDLER_NAME, ERROR_MSG)                       \\\n+static void HANDLER_NAME(int sig, siginfo_t *info, void *ctx)                 \\\n+{                                                                             \\\n+    write(STDERR_FILENO, ERROR_MSG, sizeof(ERROR_MSG) / sizeof(char));        \\\n+    _exit(EXIT_FAILURE);                                                      \\\n+}\n+\n+// signal(2) is really not portable. So use sigaction.\n+// http://man7.org/linux/man-pages/man2/signal.2.html\n+static int setSignalHandler(int signal, void(*handler)(int, siginfo_t *, void *), struct sigaction *old_sa_ptr)\n+{\n+  struct sigaction sa;\n+  sa.sa_sigaction = handler;\n+  sa.sa_flags = SA_RESTART|SA_SIGINFO|SA_NOCLDSTOP;\n+  sigemptyset(&sa.sa_mask);\n+  return sigaction(signal, &sa, old_sa_ptr);\n+}\n+\n+SIGNAL_HANDLER(SIGBUS, handler_SIGBUS, \"ERROR: Unexpected bus error encountered in worker. \"\n+  \"This might be caused by insufficient shared memory (shm).\\n\");\n+SIGNAL_HANDLER(SIGSEGV, handler_SIGSEGV, \"ERROR: Unexpected segmentation fault encountered in worker.\\n\");\n+\n+PyObject *THPModule_setWorkerSignalHandlers(PyObject *module, PyObject *arg) {\n+  HANDLE_TH_ERRORS\n+  int error = 0;\n+  error |= setSignalHandler(SIGBUS, &handler_SIGBUS, NULL) != 0;\n+  error |= setSignalHandler(SIGSEGV, &handler_SIGSEGV, NULL) != 0;\n+  return PyBool_FromLong(!error);\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static std::vector<pid_t> worker_pid_vec = {};\n+// The following are needed since std::vector is not asynchronous safe.\n+static std::atomic<pid_t *> worker_pids;\n+static std::atomic<size_t> num_worker_pids(0);\n+// Pipe used as a lock to avoid update of the above and SIGCHLD handler in parallel.\n+static int comm_pipe[2] = {-1, -1};\n+\n+static int updatePIDsArray() {\n+\n+  size_t new_size =  worker_pid_vec.size();\n+  auto new_ptr = (pid_t *)malloc(sizeof(pid_t) * new_size);\n+  for (size_t idx = 0; idx < new_size; idx++) {\n+    new_ptr[idx] = worker_pid_vec[idx];\n+  }\n+\n+  // Block SIGCHLD handler for this thread so SIGCHLD handler can't interrupt", "path": "torch/csrc/DataLoader.cpp", "position": null, "original_position": 69, "commit_id": "5733b553bcf269fb3782f7a0dbd4a12918998a5e", "original_commit_id": "6d44ba85cb3478342a521f1be15bcb31b1d1b989", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Okay, here is what happens. When we update the array, the updating thread:\r\n\r\n1. blocks SIGCHLD signal from this thread, so the handler can't interrupt the update on this thread.\r\n2. reads from a pipe, which acts like a lock, and writes to it after finishing. (The handler similarly also reads from the lock before reading the contents of the array, and write afterwards. )\r\n\r\nSince multiple threads can't run this function in parallel due to GIL, I think this should work.", "created_at": "2017-11-08T16:08:50Z", "updated_at": "2018-11-23T15:36:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149714953", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3474", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149714953"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149714953"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3474"}}, "body_html": "<p>Okay, here is what happens. When we update the array, the updating thread:</p>\n<ol>\n<li>blocks SIGCHLD signal from this thread, so the handler can't interrupt the update on this thread.</li>\n<li>reads from a pipe, which acts like a lock, and writes to it after finishing. (The handler similarly also reads from the lock before reading the contents of the array, and write afterwards. )</li>\n</ol>\n<p>Since multiple threads can't run this function in parallel due to GIL, I think this should work.</p>", "body_text": "Okay, here is what happens. When we update the array, the updating thread:\n\nblocks SIGCHLD signal from this thread, so the handler can't interrupt the update on this thread.\nreads from a pipe, which acts like a lock, and writes to it after finishing. (The handler similarly also reads from the lock before reading the contents of the array, and write afterwards. )\n\nSince multiple threads can't run this function in parallel due to GIL, I think this should work."}