{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/151763518", "pull_request_review_id": 77528703, "id": 151763518, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MTc2MzUxOA==", "diff_hunk": "@@ -0,0 +1,244 @@\n+#include <sys/wait.h>\n+#include <set>\n+#include <atomic>\n+#include <signal.h>\n+#include \"THP.h\"\n+\n+// In cases like DataLoader, if a worker process die due to bus error/segfault\n+// or just hang, the main process, if implemented with\n+// multiprocessing.queue.SimpleQueue, will hang waiting for data. This is\n+// difficult to avoid on PyTorch side as it can be caused by limited shm, or\n+// other libraries users call in the workers. The following methods is an effort\n+// to do our best provide some error message to users when such unfortunate\n+// events happen.\n+\n+// TODO: The following don't work on Windows. Specifically, waitid calls and\n+// SIGCHLD handler. Currently, dummy implementation is provided for Windows.\n+\n+#ifndef _WIN32\n+\n+// Critical signal handlers should be registered on worker processes before\n+// doing work.\n+// Python handle is _set_worker_signal_handlers().\n+#define SIGNAL_HANDLER(SIGNAL, HANDLER_NAME, ERROR_MSG)                       \\\n+static void HANDLER_NAME(int sig, siginfo_t *info, void *ctx)                 \\\n+{                                                                             \\\n+    write(STDERR_FILENO, ERROR_MSG, sizeof(ERROR_MSG) / sizeof(char));        \\\n+    _exit(EXIT_FAILURE);                                                      \\\n+}\n+\n+// signal(2) is really not portable. So use sigaction.\n+// http://man7.org/linux/man-pages/man2/signal.2.html\n+static void setSignalHandler(int signal, void(*handler)(int, siginfo_t *, void *), struct sigaction *old_sa_ptr)\n+{\n+  struct sigaction sa;\n+  sa.sa_sigaction = handler;\n+  sa.sa_flags = SA_RESTART|SA_SIGINFO|SA_NOCLDSTOP;\n+  sigemptyset(&sa.sa_mask);\n+  if (sigaction(signal, &sa, old_sa_ptr) != 0) {\n+    std::ostringstream oss;\n+    oss << \"An error occurred while setting handler for \" << strsignal(signal);\n+    throw std::runtime_error(oss.str());\n+  }\n+}\n+\n+SIGNAL_HANDLER(SIGBUS, handler_SIGBUS, \"ERROR: Unexpected bus error encountered in worker. \"\n+  \"This might be caused by insufficient shared memory (shm).\\n\");\n+SIGNAL_HANDLER(SIGSEGV, handler_SIGSEGV, \"ERROR: Unexpected segmentation fault encountered in worker.\\n\");\n+\n+PyObject *THPModule_setWorkerSignalHandlers(PyObject *module, PyObject *arg) {\n+  HANDLE_TH_ERRORS\n+  setSignalHandler(SIGBUS, &handler_SIGBUS, NULL);\n+  setSignalHandler(SIGSEGV, &handler_SIGSEGV, NULL);\n+  Py_RETURN_TRUE;\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static std::set<pid_t> worker_pid_set = {};\n+// The following are needed since std::set is not asynchronous safe.\n+static std::atomic<pid_t *> worker_pids;\n+static std::atomic<size_t> num_worker_pids(0);\n+// Pipe used as a lock to avoid update of the above and SIGCHLD handler in parallel.\n+static int comm_pipe[2] = {-1, -1};\n+\n+static void updatePIDsArray() {\n+  size_t new_size =  worker_pid_set.size();\n+  auto new_ptr = (pid_t *)malloc(sizeof(pid_t) * new_size);\n+  size_t idx = 0;\n+  for (auto it = worker_pid_set.begin(); it != worker_pid_set.end(); it++, idx++) {\n+    new_ptr[idx] = *it;\n+  }\n+\n+  // Block SIGCHLD handler for this thread so SIGCHLD handler can't interrupt\n+  // from this thread\n+  sigset_t sigset, old_sigset;\n+  sigemptyset(&sigset);\n+  sigaddset(&sigset, SIGCHLD);\n+  if (sigprocmask(SIG_BLOCK, &sigset, &old_sigset) != 0) {\n+    throw std::runtime_error(\"An error occurred while setting worker information \"\n+      \"for DataLoader SIGCHLD handler\");\n+  }\n+  // Acquire ``lock'' so handlers on other threads can't interrupt\n+  char c;\n+  read(comm_pipe[0], &c, 1);\n+\n+  pid_t *old_ptr = worker_pids;\n+  num_worker_pids = new_size;\n+  worker_pids = new_ptr;\n+  free(old_ptr);\n+\n+  // Release ``lock''\n+  write(comm_pipe[1], &c, 1);\n+  // Restore handler for this thread.\n+  if (sigprocmask(SIG_SETMASK, &old_sigset, NULL) != 0) {\n+    throw std::runtime_error(\"An error occurred while setting DataLoader SIGCHLD handler\");\n+  }\n+}\n+\n+static struct sigaction orig_SIGCHLD_sa;\n+\n+// SIGCHLD hander should be registered on main loader process to catch any\n+// worker failing.\n+// Python handles are _set_main_signal_handers_for_workers() and\n+// _remove_main_signal_handers_for_workers().\n+static void handler_SIGCHLD_main(int sig, siginfo_t *info, void *ctx) {\n+  // Acquire ``lock'' so make sure that worker_pids won't change\n+  char c;\n+  read(comm_pipe[0], &c, 1);\n+\n+  int error;\n+  siginfo_t infop;\n+\n+  // Only check the pids we care about so that Python can see other processes'\n+  // status.\n+  for (size_t i = 0; i < num_worker_pids; i++) {\n+    // Use waitid rather than waitpid so that we can set NOWAIT, and that Python\n+    // can get whatever info it wants about the child process.\n+    error = waitid(P_PID, worker_pids[i], &infop, WEXITED|WNOHANG|WNOWAIT);\n+    if (error < 0)  // ignore errors\n+      continue;\n+    if ((infop.si_code == CLD_EXITED && infop.si_status != 0) ||  // exit with error\n+        (infop.si_code == CLD_KILLED) ||\n+        (infop.si_code == CLD_DUMPED)) {\n+      _exit(EXIT_FAILURE);\n+    }\n+  }\n+\n+  // Release ``lock''\n+  write(comm_pipe[1], &c, 1);\n+\n+  // Call the overridden handler.\n+  if ((orig_SIGCHLD_sa.sa_flags | SA_SIGINFO) != 0) {\n+    // handler is sa_sigaction, this shouldn't really be SIG_IGN or SIG_DFL, but\n+    // sa_sigaction and sa_handler happen to be a union, and this fact is\n+    // apparently used by Python, so check here.\n+    // https://stackoverflow.com/a/24080440\n+    if (orig_SIGCHLD_sa.sa_sigaction == (void (*)(int, siginfo_t *, void *)) SIG_IGN) {\n+      // SIG_IGN for SIGCHLD is to reap the child and do nothing else.\n+      while (waitpid(-1, 0, WNOHANG) > 0) {}\n+    } else if (orig_SIGCHLD_sa.sa_sigaction != (void (*)(int, siginfo_t *, void *)) SIG_DFL) {\n+      // SIG_DFL for SIGCHLD is to leave the child as a zombie (do nothing)\n+      orig_SIGCHLD_sa.sa_sigaction(sig, info, ctx);\n+    }\n+  } else {\n+    // handler is sa_handler\n+    if (orig_SIGCHLD_sa.sa_handler == SIG_IGN) {\n+      while (waitpid(-1, 0, WNOHANG) > 0) {}\n+    } else if (orig_SIGCHLD_sa.sa_handler != SIG_DFL) {\n+      orig_SIGCHLD_sa.sa_handler(sig);\n+    }\n+  }\n+}\n+\n+static int isSIGCHLDHanderSet() {\n+  struct sigaction sa;\n+  int error = sigaction(SIGCHLD, NULL, &sa);\n+  if (error == 0) {\n+    return ((sa.sa_flags | SA_SIGINFO) != 0) && (sa.sa_sigaction == &handler_SIGCHLD_main);\n+  } else {\n+    throw std::runtime_error(\"An error occurred while checking DataLoader SIGCHLD handler\");\n+  }\n+}\n+\n+// We don't want to exit on any SIGCHLD from any child. child_pids is a tuple\n+// of pids we are interested in.\n+PyObject *THPModule_setMainSignalHandlers(PyObject *module, PyObject *child_pids) {\n+  HANDLE_TH_ERRORS\n+  // assert these types are lock free, just to be safe\n+  THPUtils_assert(worker_pids.is_lock_free(), \"worker_pids is not lock free\");\n+  THPUtils_assert(num_worker_pids.is_lock_free(), \"num_worker_pids is not lock free\");\n+\n+  THPUtils_assert(PyTuple_Check(child_pids), \"_set_main_signal_handlers_for_workers \"\n+        \"expects a tuple, but got %s\", THPUtils_typename(child_pids));\n+\n+  if (comm_pipe[0] == -1) {\n+    // we have GIL here so we are fine\n+    if (pipe(comm_pipe) != 0) {\n+      throw std::runtime_error(\"An error occurred while setting DataLoader SIGCHLD handler\");\n+    }\n+    char c = '_';\n+    write(comm_pipe[1], &c, 1);\n+  }\n+\n+  auto size = PyTuple_GET_SIZE(child_pids);\n+  for (int idx = 0; idx < size; idx++) {\n+    PyObject* obj = PyTuple_GET_ITEM(child_pids, idx);\n+    worker_pid_set.insert((pid_t) THPUtils_unpackLong(obj));\n+  }\n+  updatePIDsArray();\n+\n+  // To avoid chain calling our handler, check if the current handler is already\n+  // set as ours.\n+  if (!isSIGCHLDHanderSet()) {\n+    setSignalHandler(SIGCHLD, &handler_SIGCHLD_main, &orig_SIGCHLD_sa);", "path": "torch/csrc/DataLoader.cpp", "position": null, "original_position": 193, "commit_id": "5733b553bcf269fb3782f7a0dbd4a12918998a5e", "original_commit_id": "a1dc5921e479817d37b86d612cbc2f81275c277d", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We should have a global lock for adding / removing workers, or we can race with setting / removing handlers", "created_at": "2017-11-17T18:59:05Z", "updated_at": "2018-11-23T15:36:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/3474#discussion_r151763518", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3474", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/151763518"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3474#discussion_r151763518"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3474"}}, "body_html": "<p>We should have a global lock for adding / removing workers, or we can race with setting / removing handlers</p>", "body_text": "We should have a global lock for adding / removing workers, or we can race with setting / removing handlers"}