{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/152371413", "pull_request_review_id": 78223556, "id": 152371413, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1MjM3MTQxMw==", "diff_hunk": "@@ -0,0 +1,244 @@\n+#include <sys/wait.h>\n+#include <set>\n+#include <atomic>\n+#include <signal.h>\n+#include \"THP.h\"\n+\n+// In cases like DataLoader, if a worker process die due to bus error/segfault\n+// or just hang, the main process, if implemented with\n+// multiprocessing.queue.SimpleQueue, will hang waiting for data. This is\n+// difficult to avoid on PyTorch side as it can be caused by limited shm, or\n+// other libraries users call in the workers. The following methods is an effort\n+// to do our best provide some error message to users when such unfortunate\n+// events happen.\n+\n+// TODO: The following don't work on Windows. Specifically, waitid calls and\n+// SIGCHLD handler. Currently, dummy implementation is provided for Windows.\n+\n+#ifndef _WIN32\n+\n+// Critical signal handlers should be registered on worker processes before\n+// doing work.\n+// Python handle is _set_worker_signal_handlers().\n+#define SIGNAL_HANDLER(SIGNAL, HANDLER_NAME, ERROR_MSG)                       \\\n+static void HANDLER_NAME(int sig, siginfo_t *info, void *ctx)                 \\\n+{                                                                             \\\n+    write(STDERR_FILENO, ERROR_MSG, sizeof(ERROR_MSG) / sizeof(char));        \\\n+    _exit(EXIT_FAILURE);                                                      \\\n+}\n+\n+// signal(2) is really not portable. So use sigaction.\n+// http://man7.org/linux/man-pages/man2/signal.2.html\n+static void setSignalHandler(int signal, void(*handler)(int, siginfo_t *, void *), struct sigaction *old_sa_ptr)\n+{\n+  struct sigaction sa;\n+  sa.sa_sigaction = handler;\n+  sa.sa_flags = SA_RESTART|SA_SIGINFO|SA_NOCLDSTOP;\n+  sigemptyset(&sa.sa_mask);\n+  if (sigaction(signal, &sa, old_sa_ptr) != 0) {\n+    std::ostringstream oss;\n+    oss << \"An error occurred while setting handler for \" << strsignal(signal);\n+    throw std::runtime_error(oss.str());\n+  }\n+}\n+\n+SIGNAL_HANDLER(SIGBUS, handler_SIGBUS, \"ERROR: Unexpected bus error encountered in worker. \"\n+  \"This might be caused by insufficient shared memory (shm).\\n\");\n+SIGNAL_HANDLER(SIGSEGV, handler_SIGSEGV, \"ERROR: Unexpected segmentation fault encountered in worker.\\n\");\n+\n+PyObject *THPModule_setWorkerSignalHandlers(PyObject *module, PyObject *arg) {\n+  HANDLE_TH_ERRORS\n+  setSignalHandler(SIGBUS, &handler_SIGBUS, NULL);\n+  setSignalHandler(SIGSEGV, &handler_SIGSEGV, NULL);\n+  Py_RETURN_TRUE;\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static std::set<pid_t> worker_pid_set = {};\n+// The following are needed since std::set is not asynchronous safe.\n+static std::atomic<pid_t *> worker_pids;\n+static std::atomic<size_t> num_worker_pids(0);\n+// Pipe used as a lock to avoid update of the above and SIGCHLD handler in parallel.\n+static int comm_pipe[2] = {-1, -1};\n+\n+static void updatePIDsArray() {\n+  size_t new_size =  worker_pid_set.size();\n+  auto new_ptr = (pid_t *)malloc(sizeof(pid_t) * new_size);\n+  size_t idx = 0;\n+  for (auto it = worker_pid_set.begin(); it != worker_pid_set.end(); it++, idx++) {\n+    new_ptr[idx] = *it;\n+  }\n+\n+  // Block SIGCHLD handler for this thread so SIGCHLD handler can't interrupt\n+  // from this thread\n+  sigset_t sigset, old_sigset;\n+  sigemptyset(&sigset);\n+  sigaddset(&sigset, SIGCHLD);\n+  if (sigprocmask(SIG_BLOCK, &sigset, &old_sigset) != 0) {\n+    throw std::runtime_error(\"An error occurred while setting worker information \"\n+      \"for DataLoader SIGCHLD handler\");\n+  }\n+  // Acquire ``lock'' so handlers on other threads can't interrupt\n+  char c;\n+  read(comm_pipe[0], &c, 1);", "path": "torch/csrc/DataLoader.cpp", "position": null, "original_position": 83, "commit_id": "5733b553bcf269fb3782f7a0dbd4a12918998a5e", "original_commit_id": "a1dc5921e479817d37b86d612cbc2f81275c277d", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "Good point. I'm already using `std:atomic`, but I think I still need to think of how to properly free old array pointer.", "created_at": "2017-11-21T19:02:33Z", "updated_at": "2018-11-23T15:36:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/3474#discussion_r152371413", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3474", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/152371413"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3474#discussion_r152371413"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3474"}}, "body_html": "<p>Good point. I'm already using <code>std:atomic</code>, but I think I still need to think of how to properly free old array pointer.</p>", "body_text": "Good point. I'm already using std:atomic, but I think I still need to think of how to properly free old array pointer.", "in_reply_to_id": 151762659}