{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/342245804", "html_url": "https://github.com/pytorch/pytorch/pull/3474#issuecomment-342245804", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3474", "id": 342245804, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjI0NTgwNA==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-06T18:45:50Z", "updated_at": "2017-11-06T18:49:13Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> Indeed, only the main proc puts to that queue and it may lock during doing so. It will lock if DataLoader puts more than 64Kb (SimpleQueue is implemented by default using system pipes, if I understand correctly). This may happen in the extreme case when index is some serialized object or a very long Python array. You can easily repro this by creating a SimpleQueue and putting <code>range(1000000)</code> in it.</p>\n<p>Then, if for some reason the reason the workers are blocked too, no-one will read from the other side of <code>index_queue</code>, so <code>index_queue.put</code> would lock indefinitely. This may theoretically happen during data loader priming, when the main thread can't consume from <code>data_queue</code>, so in the case of small number of workers and large serialized batch objects and indices data loader priming should hang.</p>\n<p>I tried to showcase this scenario here but hit another problem first: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"250953181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2474\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2474/hovercard?comment_id=323203974&amp;comment_type=issue_comment\" href=\"https://github.com/pytorch/pytorch/issues/2474#issuecomment-323203974\">#2474 (comment)</a></p>\n<p>Having the timeout option cover this case will be a great safeguard.</p>", "body_text": "@SsnL Indeed, only the main proc puts to that queue and it may lock during doing so. It will lock if DataLoader puts more than 64Kb (SimpleQueue is implemented by default using system pipes, if I understand correctly). This may happen in the extreme case when index is some serialized object or a very long Python array. You can easily repro this by creating a SimpleQueue and putting range(1000000) in it.\nThen, if for some reason the reason the workers are blocked too, no-one will read from the other side of index_queue, so index_queue.put would lock indefinitely. This may theoretically happen during data loader priming, when the main thread can't consume from data_queue, so in the case of small number of workers and large serialized batch objects and indices data loader priming should hang.\nI tried to showcase this scenario here but hit another problem first: #2474 (comment)\nHaving the timeout option cover this case will be a great safeguard.", "body": "@SsnL Indeed, only the main proc puts to that queue and it may lock during doing so. It will lock if DataLoader puts more than 64Kb (SimpleQueue is implemented by default using system pipes, if I understand correctly). This may happen in the extreme case when index is some serialized object or a very long Python array. You can easily repro this by creating a SimpleQueue and putting `range(1000000)` in it.\r\n\r\nThen, if for some reason the reason the workers are blocked too, no-one will read from the other side of `index_queue`, so `index_queue.put` would lock indefinitely. This may theoretically happen during data loader priming, when the main thread can't consume from `data_queue`, so in the case of small number of workers and large serialized batch objects and indices data loader priming should hang.\r\n\r\nI tried to showcase this scenario here but hit another problem first: https://github.com/pytorch/pytorch/issues/2474#issuecomment-323203974\r\n\r\nHaving the timeout option cover this case will be a great safeguard."}