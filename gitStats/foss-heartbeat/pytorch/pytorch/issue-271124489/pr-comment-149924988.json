{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149924988", "pull_request_review_id": 75389225, "id": 149924988, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0OTkyNDk4OA==", "diff_hunk": "@@ -0,0 +1,253 @@\n+#include <sys/wait.h>\n+#include <set>\n+#include <atomic>\n+#include <signal.h>\n+#include \"THP.h\"\n+\n+// In cases like DataLoader, if a worker process die due to bus error/segfault\n+// or just hang, the main process, if implemented with\n+// multiprocessing.queue.SimpleQueue, will hang waiting for data. This is\n+// difficult to avoid on PyTorch side as it can be caused by limited shm, or\n+// other libraries users call in the workers. The following methods is an effort\n+// to do our best provide some error message to users when such unfortunate\n+// events happen.\n+\n+// TODO: The following don't work on Windows. Specifically, waitpid calls and\n+// SIGCHLD handler.\n+\n+#ifndef _WIN32\n+\n+// Critical signal handlers should be registered on worker processes before\n+// doing work.\n+// Python handle is _set_worker_signal_handlers().\n+#define SIGNAL_HANDLER(SIGNAL, HANDLER_NAME, ERROR_MSG)                       \\\n+static void HANDLER_NAME(int sig, siginfo_t *info, void *ctx)                 \\\n+{                                                                             \\\n+    write(STDERR_FILENO, ERROR_MSG, sizeof(ERROR_MSG) / sizeof(char));        \\\n+    _exit(EXIT_FAILURE);                                                      \\\n+}\n+\n+// signal(2) is really not portable. So use sigaction.\n+// http://man7.org/linux/man-pages/man2/signal.2.html\n+static int setSignalHandler(int signal, void(*handler)(int, siginfo_t *, void *), struct sigaction *old_sa_ptr)\n+{\n+  struct sigaction sa;\n+  sa.sa_sigaction = handler;\n+  sa.sa_flags = SA_RESTART|SA_SIGINFO|SA_NOCLDSTOP;\n+  sigemptyset(&sa.sa_mask);\n+  return sigaction(signal, &sa, old_sa_ptr);\n+}\n+\n+SIGNAL_HANDLER(SIGBUS, handler_SIGBUS, \"ERROR: Unexpected bus error encountered in worker. \"\n+  \"This might be caused by insufficient shared memory (shm).\\n\");\n+SIGNAL_HANDLER(SIGSEGV, handler_SIGSEGV, \"ERROR: Unexpected segmentation fault encountered in worker.\\n\");\n+\n+PyObject *THPModule_setWorkerSignalHandlers(PyObject *module, PyObject *arg) {\n+  HANDLE_TH_ERRORS\n+  int error = 0;\n+  error |= setSignalHandler(SIGBUS, &handler_SIGBUS, NULL) != 0;\n+  error |= setSignalHandler(SIGSEGV, &handler_SIGSEGV, NULL) != 0;\n+  return PyBool_FromLong(!error);\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static std::vector<pid_t> worker_pid_vec = {};\n+// The following are needed since std::vector is not asynchronous safe.\n+static std::atomic<pid_t *> worker_pids;\n+static std::atomic<size_t> num_worker_pids(0);\n+// Pipe used as a lock to avoid update of the above and SIGCHLD handler in parallel.\n+static int comm_pipe[2] = {-1, -1};\n+\n+static int updatePIDsArray() {\n+\n+  size_t new_size =  worker_pid_vec.size();\n+  auto new_ptr = (pid_t *)malloc(sizeof(pid_t) * new_size);\n+  for (size_t idx = 0; idx < new_size; idx++) {\n+    new_ptr[idx] = worker_pid_vec[idx];\n+  }\n+\n+  // Block SIGCHLD handler for this thread so SIGCHLD handler can't interrupt\n+  // from this thread\n+  sigset_t sigset, old_sigset;\n+  sigemptyset(&sigset);\n+  sigaddset(&sigset, SIGCHLD);\n+  if (sigprocmask(SIG_BLOCK, &sigset, &old_sigset) != 0) {\n+    return -1;\n+  }\n+  // Acquire ``lock'' so handlers on other threads can't interrupt\n+  char c;\n+  read(comm_pipe[0], &c, 1);\n+\n+  pid_t *old_ptr = worker_pids;\n+  if (new_size < num_worker_pids) {\n+    num_worker_pids = new_size;\n+    worker_pids = new_ptr;\n+  } else {\n+    worker_pids = new_ptr;\n+    num_worker_pids = new_size;\n+  }\n+  free(old_ptr);\n+\n+  // Release ``lock''\n+  write(comm_pipe[1], &c, 1);\n+  // Restore handler for this thread.\n+  if (sigprocmask(SIG_SETMASK, &old_sigset, NULL) != 0) {\n+    return -1;\n+  }\n+  return 0;\n+}\n+\n+static struct sigaction orig_SIGCHLD_sa;\n+\n+// SIGCHLD hander should be registered on main loader process to catch any\n+// worker failing.\n+// Python handles are _set_main_signal_handers_for_workers() and\n+// _remove_main_signal_handers_for_workers().\n+static void handler_SIGCHLD_main(int sig, siginfo_t *info, void *ctx) {\n+  // Acquire ``lock'' so make sure that worker_pids won't change\n+  char c;\n+  read(comm_pipe[0], &c, 1);\n+\n+  int error;\n+  siginfo_t infop;\n+\n+  // Only check the pids we care about so that Python can see other processes'\n+  // status.\n+  for (size_t i = 0; i < num_worker_pids; i++) {\n+    // Use waitid rather than waitpid so that we can set NOWAIT, and that Python\n+    // can get whatever info it wants about the child process.\n+    error = waitid(P_PID, worker_pids[i], &infop, WEXITED|WNOHANG|WNOWAIT);\n+    if (error < 0)  // ignore errors\n+      continue;\n+    if ((infop.si_code == CLD_EXITED && infop.si_status != 0) ||  // exit with error\n+        (infop.si_code == CLD_KILLED) ||\n+        (infop.si_code == CLD_DUMPED) ||\n+        (infop.si_code == CLD_TRAPPED)) {", "path": "torch/csrc/DataLoader.cpp", "position": null, "original_position": 125, "commit_id": "5733b553bcf269fb3782f7a0dbd4a12918998a5e", "original_commit_id": "6d44ba85cb3478342a521f1be15bcb31b1d1b989", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "isn't `CLD_TRAPPED` for debugging? That doesn't seem like a good enough reason to abort everything", "created_at": "2017-11-09T10:41:04Z", "updated_at": "2018-11-23T15:36:14Z", "html_url": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149924988", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3474", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149924988"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149924988"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3474"}}, "body_html": "<p>isn't <code>CLD_TRAPPED</code> for debugging? That doesn't seem like a good enough reason to abort everything</p>", "body_text": "isn't CLD_TRAPPED for debugging? That doesn't seem like a good enough reason to abort everything"}