{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/342337694", "html_url": "https://github.com/pytorch/pytorch/pull/3474#issuecomment-342337694", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3474", "id": 342337694, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjMzNzY5NA==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-07T00:46:33Z", "updated_at": "2017-11-07T00:46:33Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Yes I used that. But Queue is already there for interthread communication.\nI just extended its usage. The inter process communication is still via\nSimpleQueue. Adding one for index_queue would mean adding another thread\njust for timeout. I\u2019m not sure that is what we want. Maybe <a class=\"user-mention\" href=\"https://github.com/colesbury\">@colesbury</a> or\n<a class=\"user-mention\" href=\"https://github.com/apaszke\">@apaszke</a> has more thoughts on this?</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mon, Nov 6, 2017 at 19:42 Vadim Kantorov ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/SsnL\">@SsnL</a> &lt;<a href=\"https://github.com/ssnl\">https://github.com/ssnl</a>&gt; I saw you used queue.Queue (instead of\n multiprocessing.SimpleQueue for data_queue if timeout &gt; 0:\n <a href=\"https://github.com/SsnL/pytorch/blob/55158acd5c8c51e6ebad13f52a53c108580d8caf/torch/utils/data/dataloader.py#L176-L177\">https://github.com/SsnL/pytorch/blob/55158acd5c8c51e6ebad13f52a53c108580d8caf/torch/utils/data/dataloader.py#L176-L177</a>\n\n Could you use queue.Queue for index_queue in that case as well? put method\n also has an optional timeout argument\n\n And probably queue.Queue has a larger message size compared to\n multiprocessing.SimpleQueue.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"271124489\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3474\" href=\"https://github.com/pytorch/pytorch/pull/3474#issuecomment-342336884\">#3474 (comment)</a>&gt;, or mute\n the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AFaWZZriAcCMSiL_yvJ5DuoxE1AHvIqaks5sz6dngaJpZM4QRtCP\">https://github.com/notifications/unsubscribe-auth/AFaWZZriAcCMSiL_yvJ5DuoxE1AHvIqaks5sz6dngaJpZM4QRtCP</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Yes I used that. But Queue is already there for interthread communication.\nI just extended its usage. The inter process communication is still via\nSimpleQueue. Adding one for index_queue would mean adding another thread\njust for timeout. I\u2019m not sure that is what we want. Maybe @colesbury or\n@apaszke has more thoughts on this?\n\u2026\nOn Mon, Nov 6, 2017 at 19:42 Vadim Kantorov ***@***.***> wrote:\n @SsnL <https://github.com/ssnl> I saw you used queue.Queue (instead of\n multiprocessing.SimpleQueue for data_queue if timeout > 0:\n https://github.com/SsnL/pytorch/blob/55158acd5c8c51e6ebad13f52a53c108580d8caf/torch/utils/data/dataloader.py#L176-L177\n\n Could you use queue.Queue for index_queue in that case as well? put method\n also has an optional timeout argument\n\n And probably queue.Queue has a larger message size compared to\n multiprocessing.SimpleQueue.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#3474 (comment)>, or mute\n the thread\n <https://github.com/notifications/unsubscribe-auth/AFaWZZriAcCMSiL_yvJ5DuoxE1AHvIqaks5sz6dngaJpZM4QRtCP>\n .", "body": "Yes I used that. But Queue is already there for interthread communication.\nI just extended its usage. The inter process communication is still via\nSimpleQueue. Adding one for index_queue would mean adding another thread\njust for timeout. I\u2019m not sure that is what we want. Maybe @colesbury or\n@apaszke has more thoughts on this?\n\nOn Mon, Nov 6, 2017 at 19:42 Vadim Kantorov <notifications@github.com>\nwrote:\n\n> @SsnL <https://github.com/ssnl> I saw you used queue.Queue (instead of\n> multiprocessing.SimpleQueue for data_queue if timeout > 0:\n> https://github.com/SsnL/pytorch/blob/55158acd5c8c51e6ebad13f52a53c108580d8caf/torch/utils/data/dataloader.py#L176-L177\n>\n> Could you use queue.Queue for index_queue in that case as well? put method\n> also has an optional timeout argument\n>\n> And probably queue.Queue has a larger message size compared to\n> multiprocessing.SimpleQueue.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pytorch/pytorch/pull/3474#issuecomment-342336884>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AFaWZZriAcCMSiL_yvJ5DuoxE1AHvIqaks5sz6dngaJpZM4QRtCP>\n> .\n>\n"}