{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149517604", "pull_request_review_id": 74924464, "id": 149517604, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0OTUxNzYwNA==", "diff_hunk": "@@ -0,0 +1,204 @@\n+#include <sys/wait.h>\n+#include <set>\n+#include <atomic>\n+#include <signal.h>\n+#include \"THP.h\"\n+\n+// In cases like DataLoader, if a worker process die due to bus error/segfault\n+// or just hang, the main process, if implemented with\n+// multiprocessing.queue.SimpleQueue, will hang waiting for data. This is\n+// difficult to avoid on PyTorch side as it can be caused by limited shm, or\n+// other libraries users call in the workers. The following methods is an effort\n+// to do our best provide some error message to users when such unfortunate\n+// events happen.\n+\n+// TODO: The following don't work on Windows. Specifically, waitpid calls and\n+// SIGCHLD handler.\n+\n+#ifndef _WIN32\n+\n+// Critical signal handlers should be registered on worker processes before\n+// doing work.\n+// Python handle is _set_worker_signal_handlers().\n+#define SIGNAL_HANDLER(SIGNAL, HANDLER_NAME, ERROR_MSG)                       \\\n+static void HANDLER_NAME(int sig, siginfo_t *info, void *ctx)                 \\\n+{                                                                             \\\n+    write(STDERR_FILENO, ERROR_MSG, sizeof(ERROR_MSG) / sizeof(char));        \\\n+    _exit(EXIT_FAILURE);                                                      \\\n+}\n+\n+// signal(2) is really not portable. So use sigaction.\n+// http://man7.org/linux/man-pages/man2/signal.2.html\n+static int setSignalHandler(int signal, void(*handler)(int, siginfo_t *, void *), struct sigaction *old_sa_ptr)\n+{\n+  struct sigaction sa;\n+  sa.sa_sigaction = handler;\n+  sa.sa_flags = SA_RESTART|SA_SIGINFO|SA_NOCLDSTOP;\n+  sigemptyset(&sa.sa_mask);\n+  return sigaction(signal, &sa, old_sa_ptr);\n+}\n+\n+SIGNAL_HANDLER(SIGBUS, handler_SIGBUS, \"ERROR: Unexpected bus error encountered in worker. \"\n+  \"This might be caused by insufficient shared memory (shm).\\n\");\n+SIGNAL_HANDLER(SIGSEGV, handler_SIGSEGV, \"ERROR: Unexpected segmentation fault encountered in worker.\\n\");\n+\n+PyObject *THPModule_setWorkerSignalHandlers(PyObject *module, PyObject *arg) {\n+  HANDLE_TH_ERRORS\n+  int error = 0;\n+  error |= setSignalHandler(SIGBUS, &handler_SIGBUS, NULL) != 0;\n+  error |= setSignalHandler(SIGSEGV, &handler_SIGSEGV, NULL) != 0;\n+  return PyBool_FromLong(!error);\n+  END_HANDLE_TH_ERRORS\n+}\n+\n+static std::vector<pid_t> worker_pid_vec = {};\n+// The following are needed since std::vector is not asynchronous safe.\n+static std::atomic<pid_t *> worker_pids;\n+static std::atomic<size_t> num_worker_pids(0);\n+\n+static void updatePIDsArray() {\n+  size_t new_size =  worker_pid_vec.size();\n+  auto new_ptr = (pid_t *)malloc(sizeof(pid_t) * new_size);\n+  for (size_t idx = 0; idx < new_size; idx++) {\n+    new_ptr[idx] = worker_pid_vec[idx];\n+  }\n+  pid_t *old_ptr = worker_pids;\n+  if (new_size < num_worker_pids) {\n+    num_worker_pids = new_size;\n+    worker_pids = new_ptr;\n+  } else {\n+    worker_pids = new_ptr;\n+    num_worker_pids = new_size;\n+  }\n+  free(old_ptr);", "path": "torch/csrc/DataLoader.cpp", "position": null, "original_position": 73, "commit_id": "5733b553bcf269fb3782f7a0dbd4a12918998a5e", "original_commit_id": "afe8bf1a549a8f212a86026180e59259798886e8", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Well the signal can be handled in a thread that's different than the one running this function. Signal handlers can be parallel with parts of the program", "created_at": "2017-11-07T22:02:42Z", "updated_at": "2018-11-23T15:36:09Z", "html_url": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149517604", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3474", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/149517604"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3474#discussion_r149517604"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3474"}}, "body_html": "<p>Well the signal can be handled in a thread that's different than the one running this function. Signal handlers can be parallel with parts of the program</p>", "body_text": "Well the signal can be handled in a thread that's different than the one running this function. Signal handlers can be parallel with parts of the program", "in_reply_to_id": 149511897}