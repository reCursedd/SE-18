{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/342248773", "html_url": "https://github.com/pytorch/pytorch/pull/3474#issuecomment-342248773", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3474", "id": 342248773, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjI0ODc3Mw==", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-06T18:55:36Z", "updated_at": "2017-11-06T19:01:00Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a> This would happen even if indices object is small, but the workers for some reason are very slow or locked (it just would take some time to fill 64Kb queue). Can we detect if the queue contains a near-critical number of bytes before putting on it? and showing a UserWarning the first time it happens</p>\n<p>Though it would sure complicate the logic.</p>\n<p>In practice this situation happens when <code>multiprocessing.set_start_method('spawn')</code> is not called and OpenCV (resizing and image decoding primarily) is used in worker threads without explicit <code>cv2.setNumThreads(0)</code> (for python2 which doens't have spawn). Then the workers would block, but the user sees an exception in <code>index_queue.put</code>. This happened for me, and that's how I became aware of all this.</p>", "body_text": "@SsnL This would happen even if indices object is small, but the workers for some reason are very slow or locked (it just would take some time to fill 64Kb queue). Can we detect if the queue contains a near-critical number of bytes before putting on it? and showing a UserWarning the first time it happens\nThough it would sure complicate the logic.\nIn practice this situation happens when multiprocessing.set_start_method('spawn') is not called and OpenCV (resizing and image decoding primarily) is used in worker threads without explicit cv2.setNumThreads(0) (for python2 which doens't have spawn). Then the workers would block, but the user sees an exception in index_queue.put. This happened for me, and that's how I became aware of all this.", "body": "@SsnL This would happen even if indices object is small, but the workers for some reason are very slow or locked (it just would take some time to fill 64Kb queue). Can we detect if the queue contains a near-critical number of bytes before putting on it? and showing a UserWarning the first time it happens\r\n\r\nThough it would sure complicate the logic.\r\n\r\nIn practice this situation happens when `multiprocessing.set_start_method('spawn')` is not called and OpenCV (resizing and image decoding primarily) is used in worker threads without explicit `cv2.setNumThreads(0)` (for python2 which doens't have spawn). Then the workers would block, but the user sees an exception in `index_queue.put`. This happened for me, and that's how I became aware of all this."}