{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347981943", "html_url": "https://github.com/pytorch/pytorch/pull/3474#issuecomment-347981943", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3474", "id": 347981943, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Nzk4MTk0Mw==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T20:12:13Z", "updated_at": "2017-11-29T20:18:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The set was not properly cleared. This is fixed in new commit.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> I tested on OSX and they all work just as in CentOS except that the main process can't get what signal kills the worker process. The exit code != 0 case is still fine. I don't think it is a big issue. Here is an output comparison:</p>\n<p>OSX:</p>\n<pre><code>ERROR: Unexpected segmentation fault encountered in worker.\nTraceback (most recent call last):\n  File \"ds.py\", line 17, in &lt;module&gt;\n    for i, data in enumerate(it):\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in __next__\n    idx, batch = self._get_batch()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 233, in _get_batch\n    return self.data_queue.get()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n    res = self._reader.recv_bytes()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n    buf = self._recv(4)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 163, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 16545) is killed by signal: Unknown signal: 0.\n</code></pre>\n<p>CentOS</p>\n<pre><code>ERROR: Unexpected segmentation fault encountered in worker.\nTraceback (most recent call last):\n  File \"ds.py\", line 17, in &lt;module&gt;\n    for i, data in enumerate(it):\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 254, in __next__\n    idx, batch = self._get_batch()\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 233, in _get_batch\n    return self.data_queue.get()\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n    res = self._reader.recv_bytes()\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n    buf = self._recv(4)\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 163, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 1864508) is killed by signal: Segmentation fault.\n</code></pre>", "body_text": "The set was not properly cleared. This is fixed in new commit.\n@apaszke I tested on OSX and they all work just as in CentOS except that the main process can't get what signal kills the worker process. The exit code != 0 case is still fine. I don't think it is a big issue. Here is an output comparison:\nOSX:\nERROR: Unexpected segmentation fault encountered in worker.\nTraceback (most recent call last):\n  File \"ds.py\", line 17, in <module>\n    for i, data in enumerate(it):\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in __next__\n    idx, batch = self._get_batch()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 233, in _get_batch\n    return self.data_queue.get()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n    res = self._reader.recv_bytes()\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n    buf = self._recv(4)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 163, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 16545) is killed by signal: Unknown signal: 0.\n\nCentOS\nERROR: Unexpected segmentation fault encountered in worker.\nTraceback (most recent call last):\n  File \"ds.py\", line 17, in <module>\n    for i, data in enumerate(it):\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 254, in __next__\n    idx, batch = self._get_batch()\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 233, in _get_batch\n    return self.data_queue.get()\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n    res = self._reader.recv_bytes()\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n    buf = self._recv(4)\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 163, in handler\n    _error_if_any_worker_fails()\nRuntimeError: DataLoader worker (pid 1864508) is killed by signal: Segmentation fault.", "body": "The set was not properly cleared. This is fixed in new commit. \r\n\r\n@apaszke I tested on OSX and they all work just as in CentOS except that the main process can't get what signal kills the worker process. The exit code != 0 case is still fine. I don't think it is a big issue. Here is an output comparison:\r\n\r\nOSX:\r\n```\r\nERROR: Unexpected segmentation fault encountered in worker.\r\nTraceback (most recent call last):\r\n  File \"ds.py\", line 17, in <module>\r\n    for i, data in enumerate(it):\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in __next__\r\n    idx, batch = self._get_batch()\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 233, in _get_batch\r\n    return self.data_queue.get()\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\r\n    res = self._reader.recv_bytes()\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\r\n    buf = self._recv_bytes(maxlength)\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\r\n    buf = self._recv(4)\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\r\n    chunk = read(handle, remaining)\r\n  File \"/Users/ssnl/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 163, in handler\r\n    _error_if_any_worker_fails()\r\nRuntimeError: DataLoader worker (pid 16545) is killed by signal: Unknown signal: 0.\r\n```\r\n\r\nCentOS\r\n```\r\nERROR: Unexpected segmentation fault encountered in worker.\r\nTraceback (most recent call last):\r\n  File \"ds.py\", line 17, in <module>\r\n    for i, data in enumerate(it):\r\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 254, in __next__\r\n    idx, batch = self._get_batch()\r\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 233, in _get_batch\r\n    return self.data_queue.get()\r\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\r\n    res = self._reader.recv_bytes()\r\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\r\n    buf = self._recv_bytes(maxlength)\r\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\r\n    buf = self._recv(4)\r\n  File \"/home/ssnl/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\r\n    chunk = read(handle, remaining)\r\n  File \"/home/ssnl/sftp/pytorch/torch/utils/data/dataloader.py\", line 163, in handler\r\n    _error_if_any_worker_fails()\r\nRuntimeError: DataLoader worker (pid 1864508) is killed by signal: Segmentation fault.\r\n```\r\n"}