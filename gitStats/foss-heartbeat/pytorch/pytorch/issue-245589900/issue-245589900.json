{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2209", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2209/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2209/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2209/events", "html_url": "https://github.com/pytorch/pytorch/issues/2209", "id": 245589900, "node_id": "MDU6SXNzdWUyNDU1ODk5MDA=", "number": 2209, "title": "Issues with Loss1 + 0*Loss2 and graph computation ", "user": {"login": "WendyShang", "id": 4813789, "node_id": "MDQ6VXNlcjQ4MTM3ODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4813789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WendyShang", "html_url": "https://github.com/WendyShang", "followers_url": "https://api.github.com/users/WendyShang/followers", "following_url": "https://api.github.com/users/WendyShang/following{/other_user}", "gists_url": "https://api.github.com/users/WendyShang/gists{/gist_id}", "starred_url": "https://api.github.com/users/WendyShang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WendyShang/subscriptions", "organizations_url": "https://api.github.com/users/WendyShang/orgs", "repos_url": "https://api.github.com/users/WendyShang/repos", "events_url": "https://api.github.com/users/WendyShang/events{/privacy}", "received_events_url": "https://api.github.com/users/WendyShang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-07-26T02:43:15Z", "updated_at": "2018-05-27T08:01:10Z", "closed_at": "2017-07-26T22:52:15Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>I found some absurd errors when trying to replicate my luatorch code to pytorch. After some serious debugging, my intuition tells me it goes down to some intrinsic parts of PyTorch.</p>\n<p>I run on master brunch; to run the code I provided, place it into examples/vae/ folder, then run python xxx.py to reproduce the errors.</p>\n<p>I attached a few modifications of examples/vae/main.py in the zip file <a href=\"https://github.com/pytorch/pytorch/files/1175297/pytorch_debug.zip\">pytorch_debug.zip</a></p>\n<p>(1) main_conv_new_rep.py: this code runs, but note that I modified the reparametrization part and got rid of KLD error.</p>\n<p>(2) main_conv_new_rep_KLD.py: this code DOES NOT run, and gives the error message (below) with the only difference between the previous code to be KLD (line 144),I set KLD to be 0.  set KLD to be 0.**</p>\n<pre><code>\noat, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [65,0,0], thread: [59,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor&lt;Dtype, Acctype&gt;::operator()(Tuple) [with Tuple = thrust::tuple&lt;float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [65,0,0], thread: [60,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor&lt;Dtype, Acctype&gt;::operator()(Tuple) [with Tuple = thrust::tuple&lt;float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [65,0,0], thread: [61,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor&lt;Dtype, Acctype&gt;::operator()(Tuple) [with Tuple = thrust::tuple&lt;float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [65,0,0], thread: [62,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor&lt;Dtype, Acctype&gt;::operator()(Tuple) [with Tuple = thrust::tuple&lt;float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type&gt;, Dtype = float, Acctype = float]: block: [65,0,0], thread: [63,0,0] Assertion `input &gt;= 0. &amp;&amp; input &lt;= 1.` failed.\nCUDA error after cudaEventDestroy in future dtor: device-side assert triggeredTraceback (most recent call last):\n  File \"main_conv_new_rep_kl.py\", line 188, in &lt;module&gt;\n    train(epoch)\n  File \"main_conv_new_rep_kl.py\", line 159, in train\n    loss = loss_function(recon_batch, data, mu, logvar)\n  File \"main_conv_new_rep_kl.py\", line 135, in loss_function\n    BCE = reconstruction_function(recon_x, x)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 225, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/loss.py\", line 34, in forward\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/loss.py\", line 28, in forward\n    result = super(BCELoss, self).forward(input, target)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\n    output, *self.additional_args)\nRuntimeError: cudaEventSynchronize in future::wait: device-side assert triggered\n</code></pre>\n<p>(3) main_conv_old_rep.py: this code DOES NOT run, gives the same error, and the only difference between this and the first one main_conv_new_rep.py is that I used the original reparametrization function (line 120), which is mathematically equivalent (and should be computationally equivalent as well).</p>\n<p>If someone can possibly look into this, I would greatly appreciate the effort! since it is a little bit time sensitive... Thanks!</p>", "body_text": "Hello,\nI found some absurd errors when trying to replicate my luatorch code to pytorch. After some serious debugging, my intuition tells me it goes down to some intrinsic parts of PyTorch.\nI run on master brunch; to run the code I provided, place it into examples/vae/ folder, then run python xxx.py to reproduce the errors.\nI attached a few modifications of examples/vae/main.py in the zip file pytorch_debug.zip\n(1) main_conv_new_rep.py: this code runs, but note that I modified the reparametrization part and got rid of KLD error.\n(2) main_conv_new_rep_KLD.py: this code DOES NOT run, and gives the error message (below) with the only difference between the previous code to be KLD (line 144),I set KLD to be 0.  set KLD to be 0.**\n\noat, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [59,0,0] Assertion `input >= 0. && input <= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [60,0,0] Assertion `input >= 0. && input <= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [61,0,0] Assertion `input >= 0. && input <= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [62,0,0] Assertion `input >= 0. && input <= 1.` failed.\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [63,0,0] Assertion `input >= 0. && input <= 1.` failed.\nCUDA error after cudaEventDestroy in future dtor: device-side assert triggeredTraceback (most recent call last):\n  File \"main_conv_new_rep_kl.py\", line 188, in <module>\n    train(epoch)\n  File \"main_conv_new_rep_kl.py\", line 159, in train\n    loss = loss_function(recon_batch, data, mu, logvar)\n  File \"main_conv_new_rep_kl.py\", line 135, in loss_function\n    BCE = reconstruction_function(recon_x, x)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 225, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/loss.py\", line 34, in forward\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/loss.py\", line 28, in forward\n    result = super(BCELoss, self).forward(input, target)\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\n    output, *self.additional_args)\nRuntimeError: cudaEventSynchronize in future::wait: device-side assert triggered\n\n(3) main_conv_old_rep.py: this code DOES NOT run, gives the same error, and the only difference between this and the first one main_conv_new_rep.py is that I used the original reparametrization function (line 120), which is mathematically equivalent (and should be computationally equivalent as well).\nIf someone can possibly look into this, I would greatly appreciate the effort! since it is a little bit time sensitive... Thanks!", "body": "Hello, \r\n\r\nI found some absurd errors when trying to replicate my luatorch code to pytorch. After some serious debugging, my intuition tells me it goes down to some intrinsic parts of PyTorch. \r\n\r\nI run on master brunch; to run the code I provided, place it into examples/vae/ folder, then run python xxx.py to reproduce the errors. \r\n\r\nI attached a few modifications of examples/vae/main.py in the zip file [pytorch_debug.zip](https://github.com/pytorch/pytorch/files/1175297/pytorch_debug.zip)\r\n\r\n(1) main_conv_new_rep.py: this code runs, but note that I modified the reparametrization part and got rid of KLD error.\r\n\r\n(2) main_conv_new_rep_KLD.py: this code DOES NOT run, and gives the error message (below) with the only difference between the previous code to be KLD (line 144),I set KLD to be 0.  set KLD to be 0.** \r\n```\r\n\r\noat, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [59,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [60,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [61,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [62,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\n/home/shangw/pytorch/torch/lib/THCUNN/BCECriterion.cu:30: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::tuple<float, float, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [65,0,0], thread: [63,0,0] Assertion `input >= 0. && input <= 1.` failed.\r\nCUDA error after cudaEventDestroy in future dtor: device-side assert triggeredTraceback (most recent call last):\r\n  File \"main_conv_new_rep_kl.py\", line 188, in <module>\r\n    train(epoch)\r\n  File \"main_conv_new_rep_kl.py\", line 159, in train\r\n    loss = loss_function(recon_batch, data, mu, logvar)\r\n  File \"main_conv_new_rep_kl.py\", line 135, in loss_function\r\n    BCE = reconstruction_function(recon_x, x)\r\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 225, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/modules/loss.py\", line 34, in forward\r\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\r\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/loss.py\", line 28, in forward\r\n    result = super(BCELoss, self).forward(input, target)\r\n  File \"/home/shangw/local/anaconda3/envs/py35s/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\r\n    output, *self.additional_args)\r\nRuntimeError: cudaEventSynchronize in future::wait: device-side assert triggered\r\n```\r\n\r\n(3) main_conv_old_rep.py: this code DOES NOT run, gives the same error, and the only difference between this and the first one main_conv_new_rep.py is that I used the original reparametrization function (line 120), which is mathematically equivalent (and should be computationally equivalent as well). \r\n\r\nIf someone can possibly look into this, I would greatly appreciate the effort! since it is a little bit time sensitive... Thanks! "}