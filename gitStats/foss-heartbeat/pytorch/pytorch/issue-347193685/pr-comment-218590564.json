{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218590564", "pull_request_review_id": 156563736, "id": 218590564, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxODU5MDU2NA==", "diff_hunk": "@@ -19,5 +19,34 @@ DECLARE_DISPATCH(rnn_packed_fn, gru_packed_cudnn_stub);\n DECLARE_DISPATCH(rnn_packed_fn, rnn_tanh_packed_cudnn_stub);\n DECLARE_DISPATCH(rnn_packed_fn, rnn_relu_packed_cudnn_stub);\n \n-}} // namespace at::native\n+void check_device(const Tensor& input, const TensorList& params, const TensorList& hiddens) {\n+  auto input_device = input.device();\n+  bool input_device_is_cuda = input_device.is_cuda();\n+\n+  auto check_tensors = [&](const std::string& name, const Tensor& t) {\n+    if (!t.defined()) return;\n+    auto t_device = t.device();\n+    bool t_device_is_cuda = t_device.is_cuda();", "path": "aten/src/ATen/native/RNN.h", "position": null, "original_position": 12, "commit_id": "18150acbd02c1c69eb26873bd01652b73665368e", "original_commit_id": "e8fff55b23894d97f08bf429fae8d7cdf5ca8e97", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "As I suggested, in my previous review, pretty much all of those could be simply `t.device() == input.device()` (you can cache `input.device()` outside of the loop).", "created_at": "2018-09-18T20:51:57Z", "updated_at": "2018-11-23T15:51:37Z", "html_url": "https://github.com/pytorch/pytorch/pull/10185#discussion_r218590564", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10185", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/218590564"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10185#discussion_r218590564"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10185"}}, "body_html": "<p>As I suggested, in my previous review, pretty much all of those could be simply <code>t.device() == input.device()</code> (you can cache <code>input.device()</code> outside of the loop).</p>", "body_text": "As I suggested, in my previous review, pretty much all of those could be simply t.device() == input.device() (you can cache input.device() outside of the loop)."}