{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/351784336", "html_url": "https://github.com/pytorch/pytorch/issues/4081#issuecomment-351784336", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4081", "id": 351784336, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTc4NDMzNg==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-14T17:43:00Z", "updated_at": "2017-12-14T17:43:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Memcopies are in forward, and generated code for backward still uses \"self\" rather than \"output\", I guess changes to <code>gen_variable_type.py</code> are necessary, as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=655866\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/colesbury\">@colesbury</a> was saying.</p>\n<pre><code>Tensor VariableType::threshold_backward(const Tensor &amp; grad_output, const Tensor &amp; self, Scalar threshold, Scalar value) const {\n    profiler::RecordFunction profiler(\"threshold_backward\");\n    auto&amp; grad_output_ = unpack(grad_output, \"grad_output\", 0);\n    auto&amp; self_ = unpack(self, \"self\", 1);\n    std::shared_ptr&lt;ThresholdBackwardBackward&gt; grad_fn;\n    auto flags = compute_flags({ grad_output, self });\n    if (flags.requires_grad) {\n      grad_fn = std::make_shared&lt;ThresholdBackwardBackward&gt;();\n      grad_fn-&gt;next_functions = compute_next_functions({ grad_output, self });\n      grad_fn-&gt;self_ = SavedVariable(self, false);\n      grad_fn-&gt;threshold = threshold;\n      grad_fn-&gt;value = value;\n    }\n    auto ret = as_variable(baseType-&gt;threshold_backward(grad_output_, self_, threshold, value));\n    set_flags(ret, flags, grad_fn);\n    if (jit::tracer::isTracing({ grad_output, self })) {\n      jit::Node *n = jit::tracer::recordTrace( \"threshold_backward\", { grad_output, self }, { ret } );\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\n      setattr(n, jit::stringToSymbol(\"value\"), value);\n    }\n    return Tensor(std::move(ret));\n}\nTensor VariableType::threshold_(Tensor &amp; self, Scalar threshold, Scalar value) const {\n    profiler::RecordFunction profiler(\"threshold_\");\n    auto&amp; self_ = unpack(self, \"self\", 0);\n    check_inplace(self);\n    std::shared_ptr&lt;ThresholdBackward&gt; grad_fn;\n    auto flags = compute_flags({ self });\n    if (flags.requires_grad) {\n      grad_fn = std::make_shared&lt;ThresholdBackward&gt;();\n      grad_fn-&gt;next_functions = compute_next_functions({ self });\n      grad_fn-&gt;self_ = SavedVariable(self.clone(), false);\n      grad_fn-&gt;threshold = threshold;\n      grad_fn-&gt;value = value;\n    }\n    baseType-&gt;threshold_forward_(self_, threshold, value);\n    increment_version(self);\n    set_flags(static_cast&lt;Variable&amp;&gt;(self), flags, grad_fn, true);\n    if (jit::tracer::isTracing({ self })) {\n      jit::Node *n = jit::tracer::recordTrace( \"threshold\", { self }, { self } );\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\n      setattr(n, jit::stringToSymbol(\"value\"), value);\n    }\n    return self;\n}\n</code></pre>", "body_text": "Memcopies are in forward, and generated code for backward still uses \"self\" rather than \"output\", I guess changes to gen_variable_type.py are necessary, as @colesbury was saying.\nTensor VariableType::threshold_backward(const Tensor & grad_output, const Tensor & self, Scalar threshold, Scalar value) const {\n    profiler::RecordFunction profiler(\"threshold_backward\");\n    auto& grad_output_ = unpack(grad_output, \"grad_output\", 0);\n    auto& self_ = unpack(self, \"self\", 1);\n    std::shared_ptr<ThresholdBackwardBackward> grad_fn;\n    auto flags = compute_flags({ grad_output, self });\n    if (flags.requires_grad) {\n      grad_fn = std::make_shared<ThresholdBackwardBackward>();\n      grad_fn->next_functions = compute_next_functions({ grad_output, self });\n      grad_fn->self_ = SavedVariable(self, false);\n      grad_fn->threshold = threshold;\n      grad_fn->value = value;\n    }\n    auto ret = as_variable(baseType->threshold_backward(grad_output_, self_, threshold, value));\n    set_flags(ret, flags, grad_fn);\n    if (jit::tracer::isTracing({ grad_output, self })) {\n      jit::Node *n = jit::tracer::recordTrace( \"threshold_backward\", { grad_output, self }, { ret } );\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\n      setattr(n, jit::stringToSymbol(\"value\"), value);\n    }\n    return Tensor(std::move(ret));\n}\nTensor VariableType::threshold_(Tensor & self, Scalar threshold, Scalar value) const {\n    profiler::RecordFunction profiler(\"threshold_\");\n    auto& self_ = unpack(self, \"self\", 0);\n    check_inplace(self);\n    std::shared_ptr<ThresholdBackward> grad_fn;\n    auto flags = compute_flags({ self });\n    if (flags.requires_grad) {\n      grad_fn = std::make_shared<ThresholdBackward>();\n      grad_fn->next_functions = compute_next_functions({ self });\n      grad_fn->self_ = SavedVariable(self.clone(), false);\n      grad_fn->threshold = threshold;\n      grad_fn->value = value;\n    }\n    baseType->threshold_forward_(self_, threshold, value);\n    increment_version(self);\n    set_flags(static_cast<Variable&>(self), flags, grad_fn, true);\n    if (jit::tracer::isTracing({ self })) {\n      jit::Node *n = jit::tracer::recordTrace( \"threshold\", { self }, { self } );\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\n      setattr(n, jit::stringToSymbol(\"value\"), value);\n    }\n    return self;\n}", "body": "Memcopies are in forward, and generated code for backward still uses \"self\" rather than \"output\", I guess changes to ```gen_variable_type.py``` are necessary, as @colesbury was saying.\r\n```\r\nTensor VariableType::threshold_backward(const Tensor & grad_output, const Tensor & self, Scalar threshold, Scalar value) const {\r\n    profiler::RecordFunction profiler(\"threshold_backward\");\r\n    auto& grad_output_ = unpack(grad_output, \"grad_output\", 0);\r\n    auto& self_ = unpack(self, \"self\", 1);\r\n    std::shared_ptr<ThresholdBackwardBackward> grad_fn;\r\n    auto flags = compute_flags({ grad_output, self });\r\n    if (flags.requires_grad) {\r\n      grad_fn = std::make_shared<ThresholdBackwardBackward>();\r\n      grad_fn->next_functions = compute_next_functions({ grad_output, self });\r\n      grad_fn->self_ = SavedVariable(self, false);\r\n      grad_fn->threshold = threshold;\r\n      grad_fn->value = value;\r\n    }\r\n    auto ret = as_variable(baseType->threshold_backward(grad_output_, self_, threshold, value));\r\n    set_flags(ret, flags, grad_fn);\r\n    if (jit::tracer::isTracing({ grad_output, self })) {\r\n      jit::Node *n = jit::tracer::recordTrace( \"threshold_backward\", { grad_output, self }, { ret } );\r\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\r\n      setattr(n, jit::stringToSymbol(\"value\"), value);\r\n    }\r\n    return Tensor(std::move(ret));\r\n}\r\nTensor VariableType::threshold_(Tensor & self, Scalar threshold, Scalar value) const {\r\n    profiler::RecordFunction profiler(\"threshold_\");\r\n    auto& self_ = unpack(self, \"self\", 0);\r\n    check_inplace(self);\r\n    std::shared_ptr<ThresholdBackward> grad_fn;\r\n    auto flags = compute_flags({ self });\r\n    if (flags.requires_grad) {\r\n      grad_fn = std::make_shared<ThresholdBackward>();\r\n      grad_fn->next_functions = compute_next_functions({ self });\r\n      grad_fn->self_ = SavedVariable(self.clone(), false);\r\n      grad_fn->threshold = threshold;\r\n      grad_fn->value = value;\r\n    }\r\n    baseType->threshold_forward_(self_, threshold, value);\r\n    increment_version(self);\r\n    set_flags(static_cast<Variable&>(self), flags, grad_fn, true);\r\n    if (jit::tracer::isTracing({ self })) {\r\n      jit::Node *n = jit::tracer::recordTrace( \"threshold\", { self }, { self } );\r\n      setattr(n, jit::stringToSymbol(\"threshold\"), threshold);\r\n      setattr(n, jit::stringToSymbol(\"value\"), value);\r\n    }\r\n    return self;\r\n}\r\n```"}