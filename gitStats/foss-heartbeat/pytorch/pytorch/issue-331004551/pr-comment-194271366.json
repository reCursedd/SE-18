{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/194271366", "pull_request_review_id": 127410905, "id": 194271366, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NDI3MTM2Ng==", "diff_hunk": "@@ -93,35 +93,74 @@ def _enforce_cudnn(input):\n     @staticmethod\n     def forward(ctx, theta, size):\n         assert type(size) == torch.Size\n-        N, C, H, W = size\n-        ctx.size = size\n-        if theta.is_cuda:\n-            AffineGridGenerator._enforce_cudnn(theta)\n-            assert False\n-        ctx.is_cuda = False\n-        base_grid = theta.new(N, H, W, 3)\n-        linear_points = torch.linspace(-1, 1, W) if W > 1 else torch.Tensor([-1])\n-        base_grid[:, :, :, 0] = torch.ger(torch.ones(H), linear_points).expand_as(base_grid[:, :, :, 0])\n-        linear_points = torch.linspace(-1, 1, H) if H > 1 else torch.Tensor([-1])\n-        base_grid[:, :, :, 1] = torch.ger(linear_points, torch.ones(W)).expand_as(base_grid[:, :, :, 1])\n-        base_grid[:, :, :, 2] = 1\n-        ctx.base_grid = base_grid\n-        grid = torch.bmm(base_grid.view(N, H * W, 3), theta.transpose(1, 2))\n-        grid = grid.view(N, H, W, 2)\n+\n+        if len(size) == 5:\n+            N, C, D, H, W = size\n+            ctx.size = size\n+            ctx.is_cuda = theta.is_cuda\n+            base_grid = theta.new(N, D, H, W, 4)\n+\n+            w_points = (torch.linspace(-1, 1, W) if W > 1 else torch.Tensor([-1]))\n+            h_points = (torch.linspace(-1, 1, H) if H > 1 else torch.Tensor([-1])).unsqueeze(-1)\n+            d_points = (torch.linspace(-1, 1, D) if D > 1 else torch.Tensor([-1])).unsqueeze(-1).unsqueeze(-1)\n+\n+            base_grid[:, :, :, :, 0] = w_points\n+            base_grid[:, :, :, :, 1] = h_points\n+            base_grid[:, :, :, :, 2] = d_points\n+            base_grid[:, :, :, :, 3] = 1\n+            ctx.base_grid = base_grid\n+            grid = torch.bmm(base_grid.view(N, D * H * W, 4), theta.transpose(1, 2))\n+            grid = grid.view(N, D, H, W, 3)\n+\n+        elif len(size) == 4:\n+            N, C, H, W = size\n+            ctx.size = size\n+            if theta.is_cuda:\n+                AffineGridGenerator._enforce_cudnn(theta)\n+                assert False\n+            ctx.is_cuda = False", "path": "torch/nn/_functions/vision.py", "position": null, "original_position": 53, "commit_id": "b74a18beaf09cc711516acc6e9b88ca97b0bb2cf", "original_commit_id": "dd64ad7838614b7e9a91d049eae333a326ae19c0", "user": {"login": "elistevens", "id": 138016, "node_id": "MDQ6VXNlcjEzODAxNg==", "avatar_url": "https://avatars0.githubusercontent.com/u/138016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elistevens", "html_url": "https://github.com/elistevens", "followers_url": "https://api.github.com/users/elistevens/followers", "following_url": "https://api.github.com/users/elistevens/following{/other_user}", "gists_url": "https://api.github.com/users/elistevens/gists{/gist_id}", "starred_url": "https://api.github.com/users/elistevens/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elistevens/subscriptions", "organizations_url": "https://api.github.com/users/elistevens/orgs", "repos_url": "https://api.github.com/users/elistevens/repos", "events_url": "https://api.github.com/users/elistevens/events{/privacy}", "received_events_url": "https://api.github.com/users/elistevens/received_events", "type": "User", "site_admin": false}, "body": "This `if theta.is_cuda:` check seems needlessly restrictive. The `def affine_grid_generator(theta, size):` function handles the dispatch between CPU and CUDA; why repeat the check here as well?", "created_at": "2018-06-10T21:44:10Z", "updated_at": "2018-11-23T15:45:18Z", "html_url": "https://github.com/pytorch/pytorch/pull/8322#discussion_r194271366", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8322", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/194271366"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8322#discussion_r194271366"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8322"}}, "body_html": "<p>This <code>if theta.is_cuda:</code> check seems needlessly restrictive. The <code>def affine_grid_generator(theta, size):</code> function handles the dispatch between CPU and CUDA; why repeat the check here as well?</p>", "body_text": "This if theta.is_cuda: check seems needlessly restrictive. The def affine_grid_generator(theta, size): function handles the dispatch between CPU and CUDA; why repeat the check here as well?"}