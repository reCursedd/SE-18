{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/198215328", "pull_request_review_id": 132105874, "id": 198215328, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5ODIxNTMyOA==", "diff_hunk": "@@ -93,35 +93,74 @@ def _enforce_cudnn(input):\n     @staticmethod\n     def forward(ctx, theta, size):\n         assert type(size) == torch.Size\n-        N, C, H, W = size\n-        ctx.size = size\n-        if theta.is_cuda:\n-            AffineGridGenerator._enforce_cudnn(theta)\n-            assert False\n-        ctx.is_cuda = False\n-        base_grid = theta.new(N, H, W, 3)\n-        linear_points = torch.linspace(-1, 1, W) if W > 1 else torch.Tensor([-1])\n-        base_grid[:, :, :, 0] = torch.ger(torch.ones(H), linear_points).expand_as(base_grid[:, :, :, 0])\n-        linear_points = torch.linspace(-1, 1, H) if H > 1 else torch.Tensor([-1])\n-        base_grid[:, :, :, 1] = torch.ger(linear_points, torch.ones(W)).expand_as(base_grid[:, :, :, 1])\n-        base_grid[:, :, :, 2] = 1\n-        ctx.base_grid = base_grid\n-        grid = torch.bmm(base_grid.view(N, H * W, 3), theta.transpose(1, 2))\n-        grid = grid.view(N, H, W, 2)\n+\n+        if len(size) == 5:\n+            N, C, D, H, W = size\n+            ctx.size = size\n+            ctx.is_cuda = theta.is_cuda\n+            base_grid = theta.new(N, D, H, W, 4)\n+\n+            w_points = (torch.linspace(-1, 1, W) if W > 1 else torch.Tensor([-1]))\n+            h_points = (torch.linspace(-1, 1, H) if H > 1 else torch.Tensor([-1])).unsqueeze(-1)\n+            d_points = (torch.linspace(-1, 1, D) if D > 1 else torch.Tensor([-1])).unsqueeze(-1).unsqueeze(-1)\n+\n+            base_grid[:, :, :, :, 0] = w_points\n+            base_grid[:, :, :, :, 1] = h_points\n+            base_grid[:, :, :, :, 2] = d_points\n+            base_grid[:, :, :, :, 3] = 1\n+            ctx.base_grid = base_grid\n+            grid = torch.bmm(base_grid.view(N, D * H * W, 4), theta.transpose(1, 2))\n+            grid = grid.view(N, D, H, W, 3)\n+\n+        elif len(size) == 4:\n+            N, C, H, W = size\n+            ctx.size = size\n+            if theta.is_cuda:\n+                AffineGridGenerator._enforce_cudnn(theta)\n+                assert False\n+            ctx.is_cuda = False\n+            base_grid = theta.new(N, H, W, 3)\n+            linear_points = torch.linspace(-1, 1, W) if W > 1 else torch.Tensor([-1])\n+            base_grid[:, :, :, 0] = torch.ger(torch.ones(H), linear_points).expand_as(base_grid[:, :, :, 0])\n+            linear_points = torch.linspace(-1, 1, H) if H > 1 else torch.Tensor([-1])\n+            base_grid[:, :, :, 1] = torch.ger(linear_points, torch.ones(W)).expand_as(base_grid[:, :, :, 1])\n+            base_grid[:, :, :, 2] = 1\n+            ctx.base_grid = base_grid\n+            grid = torch.bmm(base_grid.view(N, H * W, 3), theta.transpose(1, 2))\n+            grid = grid.view(N, H, W, 2)\n+        else:\n+            raise RuntimeError(\"AffineGridGenerator needs 4d (spatial) or 5d (volumetric) inputs.\")\n+\n         return grid\n \n     @staticmethod\n     @once_differentiable\n     def backward(ctx, grad_grid):\n-        N, C, H, W = ctx.size\n-        assert grad_grid.size() == torch.Size([N, H, W, 2])\n-        assert ctx.is_cuda == grad_grid.is_cuda\n-        if grad_grid.is_cuda:\n-            AffineGridGenerator._enforce_cudnn(grad_grid)\n+        if len(ctx.size) == 5:\n+            N, C, D, H, W = ctx.size", "path": "torch/nn/_functions/vision.py", "position": null, "original_position": 77, "commit_id": "b74a18beaf09cc711516acc6e9b88ca97b0bb2cf", "original_commit_id": "dd64ad7838614b7e9a91d049eae333a326ae19c0", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "There seem to be a lot of redundant code between these two `if` cases. Can you make them share part of it?", "created_at": "2018-06-26T16:36:52Z", "updated_at": "2018-11-23T15:46:21Z", "html_url": "https://github.com/pytorch/pytorch/pull/8322#discussion_r198215328", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8322", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/198215328"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8322#discussion_r198215328"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8322"}}, "body_html": "<p>There seem to be a lot of redundant code between these two <code>if</code> cases. Can you make them share part of it?</p>", "body_text": "There seem to be a lot of redundant code between these two if cases. Can you make them share part of it?"}