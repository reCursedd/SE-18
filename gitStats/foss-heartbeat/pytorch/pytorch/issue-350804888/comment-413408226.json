{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/413408226", "html_url": "https://github.com/pytorch/pytorch/issues/10537#issuecomment-413408226", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10537", "id": 413408226, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzQwODIyNg==", "user": {"login": "wqn628", "id": 17527574, "node_id": "MDQ6VXNlcjE3NTI3NTc0", "avatar_url": "https://avatars0.githubusercontent.com/u/17527574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wqn628", "html_url": "https://github.com/wqn628", "followers_url": "https://api.github.com/users/wqn628/followers", "following_url": "https://api.github.com/users/wqn628/following{/other_user}", "gists_url": "https://api.github.com/users/wqn628/gists{/gist_id}", "starred_url": "https://api.github.com/users/wqn628/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wqn628/subscriptions", "organizations_url": "https://api.github.com/users/wqn628/orgs", "repos_url": "https://api.github.com/users/wqn628/repos", "events_url": "https://api.github.com/users/wqn628/events{/privacy}", "received_events_url": "https://api.github.com/users/wqn628/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-16T02:55:34Z", "updated_at": "2018-08-16T02:58:29Z", "author_association": "NONE", "body_html": "<pre><code>class LSTM(nn.Module):\ndef init(self, input_size, hidden_layer, hidden_size, num_classes,\nrnn_type=\u2018lstm\u2019, dropout=0.0, bidirect=True, residual=False):\nsuper(LSTM, self).init()\nif bidirect:\nlayer = [nn.LSTM( input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=bidirect, dropout=dropout)]\nfor i in range(hidden_layer):\nlayer.append(nn.LSTM(hidden_size2, hidden_size, batch_first=True, dropout=0.0, bidirectional=bidirect))\nself.lstm = nn.Sequential(layer)\nself.lstm.add_module(\u201cconn\u201d,nn.LSTM(hidden_size2, num_classes, batch_first=True, dropout=0.0, bidirectional=bidirect))\ndef forward(self, x, input_len):\nmax_length = x.shape[1]\nx = rnn_pack.pack_padded_sequence(x, input_len, batch_first=True)\nx = self.lstm(x)\nout , _ = rnn_pack.pad_packed_sequence(x, total_length=max_length, batch_first=True)\nreturn out\n</code></pre>\n<pre><code>    if th.cuda.is_available():\n        if args.multi_gpu == 1:\n            if th.cuda.device_count() &gt; 1:\n                logger.info(\"Let's use {} GPUs!\".format(th.cuda.device_count()))\n                nnet = nn.DataParallel(nnet, device_ids=[0,1,2]) # dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs\n            elif th.cuda.device_count() == 1:\n                logger.info(\"!!!WARNINGS:Only 1 GPU detected and Let's use the only one GPUs!!!\")\n            else:\n                logger.info(\"!!!!!ERROR!!!!!\")\n        else:\n            logger.info(\"!!!Training on single GPU!!!\")\n          \n    else:\n        logger.info(\"!!!WARNINGS:NO GPUs detected! AND The Net Will Be Trained On CPU!!!\")\n    logger.info(nnet)\n    criterion = nn.CrossEntropyLoss()\n</code></pre>\n<pre><code>def train_one_epoch(nnet, criterion, optimizer, train_loader, num_parallel, is_rnn=False):\nnnet.train()\npos_frames = 0.0\ntrain_frames = 0.0\nfor index, (key, feats, labels, len_list) in enumerate(train_loader):\nprint \u201c=============\u201d\nprint key\nprint feats.shape ##(12,T,)\nprint labels.shape ##(12,T)\n#print type(len_list)\n#print len_list.shape\nprint \u201c=============\u201d\nlabels = labels.view(labels.shape[0], labels.shape[1])\ninput_len = np.array(len_list)\ninput_sort_id = np.argsort(-input_len)\ninput_len = input_len[input_sort_id]\nfeat_mat = feats[th.LongTensor(input_sort_id)]\nfeat_mat = Variable(feat_mat.cuda())\ninput_unsort_id = th.LongTensor(np.argsort(input_sort_id))\noptimizer.zero_grad()\nif is_rnn:\nlabel_mat = labels.view(labels.size(0) * labels.size(1))\ntargets = Variable(label_mat.cuda())\nout = nnet(feat_mat, input_len)\nout = out[input_unsort_id]\nout_num = out.shape[2]\nmax_frame = int(max(len_list))\n .......\n</code></pre>\n<p>the error \uff1a</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/17527574/44184717-e368a680-a142-11e8-8618-e0d4457b3384.png\"><img src=\"https://user-images.githubusercontent.com/17527574/44184717-e368a680-a142-11e8-8618-e0d4457b3384.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>", "body_text": "class LSTM(nn.Module):\ndef init(self, input_size, hidden_layer, hidden_size, num_classes,\nrnn_type=\u2018lstm\u2019, dropout=0.0, bidirect=True, residual=False):\nsuper(LSTM, self).init()\nif bidirect:\nlayer = [nn.LSTM( input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=bidirect, dropout=dropout)]\nfor i in range(hidden_layer):\nlayer.append(nn.LSTM(hidden_size2, hidden_size, batch_first=True, dropout=0.0, bidirectional=bidirect))\nself.lstm = nn.Sequential(layer)\nself.lstm.add_module(\u201cconn\u201d,nn.LSTM(hidden_size2, num_classes, batch_first=True, dropout=0.0, bidirectional=bidirect))\ndef forward(self, x, input_len):\nmax_length = x.shape[1]\nx = rnn_pack.pack_padded_sequence(x, input_len, batch_first=True)\nx = self.lstm(x)\nout , _ = rnn_pack.pad_packed_sequence(x, total_length=max_length, batch_first=True)\nreturn out\n\n    if th.cuda.is_available():\n        if args.multi_gpu == 1:\n            if th.cuda.device_count() > 1:\n                logger.info(\"Let's use {} GPUs!\".format(th.cuda.device_count()))\n                nnet = nn.DataParallel(nnet, device_ids=[0,1,2]) # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n            elif th.cuda.device_count() == 1:\n                logger.info(\"!!!WARNINGS:Only 1 GPU detected and Let's use the only one GPUs!!!\")\n            else:\n                logger.info(\"!!!!!ERROR!!!!!\")\n        else:\n            logger.info(\"!!!Training on single GPU!!!\")\n          \n    else:\n        logger.info(\"!!!WARNINGS:NO GPUs detected! AND The Net Will Be Trained On CPU!!!\")\n    logger.info(nnet)\n    criterion = nn.CrossEntropyLoss()\n\ndef train_one_epoch(nnet, criterion, optimizer, train_loader, num_parallel, is_rnn=False):\nnnet.train()\npos_frames = 0.0\ntrain_frames = 0.0\nfor index, (key, feats, labels, len_list) in enumerate(train_loader):\nprint \u201c=============\u201d\nprint key\nprint feats.shape ##(12,T,)\nprint labels.shape ##(12,T)\n#print type(len_list)\n#print len_list.shape\nprint \u201c=============\u201d\nlabels = labels.view(labels.shape[0], labels.shape[1])\ninput_len = np.array(len_list)\ninput_sort_id = np.argsort(-input_len)\ninput_len = input_len[input_sort_id]\nfeat_mat = feats[th.LongTensor(input_sort_id)]\nfeat_mat = Variable(feat_mat.cuda())\ninput_unsort_id = th.LongTensor(np.argsort(input_sort_id))\noptimizer.zero_grad()\nif is_rnn:\nlabel_mat = labels.view(labels.size(0) * labels.size(1))\ntargets = Variable(label_mat.cuda())\nout = nnet(feat_mat, input_len)\nout = out[input_unsort_id]\nout_num = out.shape[2]\nmax_frame = int(max(len_list))\n .......\n\nthe error \uff1a", "body": "```\r\nclass LSTM(nn.Module):\r\ndef init(self, input_size, hidden_layer, hidden_size, num_classes,\r\nrnn_type=\u2018lstm\u2019, dropout=0.0, bidirect=True, residual=False):\r\nsuper(LSTM, self).init()\r\nif bidirect:\r\nlayer = [nn.LSTM( input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=bidirect, dropout=dropout)]\r\nfor i in range(hidden_layer):\r\nlayer.append(nn.LSTM(hidden_size2, hidden_size, batch_first=True, dropout=0.0, bidirectional=bidirect))\r\nself.lstm = nn.Sequential(layer)\r\nself.lstm.add_module(\u201cconn\u201d,nn.LSTM(hidden_size2, num_classes, batch_first=True, dropout=0.0, bidirectional=bidirect))\r\ndef forward(self, x, input_len):\r\nmax_length = x.shape[1]\r\nx = rnn_pack.pack_padded_sequence(x, input_len, batch_first=True)\r\nx = self.lstm(x)\r\nout , _ = rnn_pack.pad_packed_sequence(x, total_length=max_length, batch_first=True)\r\nreturn out\r\n```\r\n\r\n```\r\n    if th.cuda.is_available():\r\n        if args.multi_gpu == 1:\r\n            if th.cuda.device_count() > 1:\r\n                logger.info(\"Let's use {} GPUs!\".format(th.cuda.device_count()))\r\n                nnet = nn.DataParallel(nnet, device_ids=[0,1,2]) # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\r\n            elif th.cuda.device_count() == 1:\r\n                logger.info(\"!!!WARNINGS:Only 1 GPU detected and Let's use the only one GPUs!!!\")\r\n            else:\r\n                logger.info(\"!!!!!ERROR!!!!!\")\r\n        else:\r\n            logger.info(\"!!!Training on single GPU!!!\")\r\n          \r\n    else:\r\n        logger.info(\"!!!WARNINGS:NO GPUs detected! AND The Net Will Be Trained On CPU!!!\")\r\n    logger.info(nnet)\r\n    criterion = nn.CrossEntropyLoss()\r\n```\r\n\r\n```\r\ndef train_one_epoch(nnet, criterion, optimizer, train_loader, num_parallel, is_rnn=False):\r\nnnet.train()\r\npos_frames = 0.0\r\ntrain_frames = 0.0\r\nfor index, (key, feats, labels, len_list) in enumerate(train_loader):\r\nprint \u201c=============\u201d\r\nprint key\r\nprint feats.shape ##(12,T,)\r\nprint labels.shape ##(12,T)\r\n#print type(len_list)\r\n#print len_list.shape\r\nprint \u201c=============\u201d\r\nlabels = labels.view(labels.shape[0], labels.shape[1])\r\ninput_len = np.array(len_list)\r\ninput_sort_id = np.argsort(-input_len)\r\ninput_len = input_len[input_sort_id]\r\nfeat_mat = feats[th.LongTensor(input_sort_id)]\r\nfeat_mat = Variable(feat_mat.cuda())\r\ninput_unsort_id = th.LongTensor(np.argsort(input_sort_id))\r\noptimizer.zero_grad()\r\nif is_rnn:\r\nlabel_mat = labels.view(labels.size(0) * labels.size(1))\r\ntargets = Variable(label_mat.cuda())\r\nout = nnet(feat_mat, input_len)\r\nout = out[input_unsort_id]\r\nout_num = out.shape[2]\r\nmax_frame = int(max(len_list))\r\n .......\r\n```\r\n\r\nthe error \uff1a\r\n\r\n![image](https://user-images.githubusercontent.com/17527574/44184717-e368a680-a142-11e8-8618-e0d4457b3384.png)\r\n"}