{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2940", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2940/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2940/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2940/events", "html_url": "https://github.com/pytorch/pytorch/issues/2940", "id": 262258839, "node_id": "MDU6SXNzdWUyNjIyNTg4Mzk=", "number": 2940, "title": "in-place operation error thrown after mutation instead of before", "user": {"login": "willwhitney", "id": 597829, "node_id": "MDQ6VXNlcjU5NzgyOQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/597829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/willwhitney", "html_url": "https://github.com/willwhitney", "followers_url": "https://api.github.com/users/willwhitney/followers", "following_url": "https://api.github.com/users/willwhitney/following{/other_user}", "gists_url": "https://api.github.com/users/willwhitney/gists{/gist_id}", "starred_url": "https://api.github.com/users/willwhitney/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/willwhitney/subscriptions", "organizations_url": "https://api.github.com/users/willwhitney/orgs", "repos_url": "https://api.github.com/users/willwhitney/repos", "events_url": "https://api.github.com/users/willwhitney/events{/privacy}", "received_events_url": "https://api.github.com/users/willwhitney/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-10-02T23:21:32Z", "updated_at": "2017-10-21T18:07:42Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>When you call an in-place op on a leaf Variable that requires grad, pytorch throws an error. However, it first mutates that variable.</p>\n<p>Does this break the graph? It seems like the variable shouldn't get mutated.</p>\n<pre><code>&gt;&gt;&gt; a\nVariable containing:\n 0.6285  0.0864  0.0217  0.8061  0.9542\n 0.9619  0.9678  0.9665  0.6608  0.9865\n 0.7041  0.5659  0.0866  0.2487  0.9058\n 0.3969  0.8566  0.4314  0.0243  0.3414\n 0.5087  0.7177  0.2486  0.9656  0.4393\n[torch.FloatTensor of size 5x5]\n\n&gt;&gt;&gt; a.add_(noise)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 322, in add_\n    return self._add(other, True)\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 313, in _add\n    return Add.apply(self, other, inplace)\nRuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n&gt;&gt;&gt; a\nVariable containing:\n 0.5088  0.0052 -0.2603 -0.9549  1.1598\n 1.3255  1.3079  1.7067  1.8954 -0.5464\n 0.0219 -1.0987  0.2794  0.4004 -0.0731\n-0.5973 -0.2672  0.9868 -1.1371  1.6382\n 1.0826  0.7228 -1.6244  2.4482 -0.5585\n[torch.FloatTensor of size 5x5]\n</code></pre>\n<p>Found on pytorch 0.2.0.</p>", "body_text": "When you call an in-place op on a leaf Variable that requires grad, pytorch throws an error. However, it first mutates that variable.\nDoes this break the graph? It seems like the variable shouldn't get mutated.\n>>> a\nVariable containing:\n 0.6285  0.0864  0.0217  0.8061  0.9542\n 0.9619  0.9678  0.9665  0.6608  0.9865\n 0.7041  0.5659  0.0866  0.2487  0.9058\n 0.3969  0.8566  0.4314  0.0243  0.3414\n 0.5087  0.7177  0.2486  0.9656  0.4393\n[torch.FloatTensor of size 5x5]\n\n>>> a.add_(noise)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 322, in add_\n    return self._add(other, True)\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 313, in _add\n    return Add.apply(self, other, inplace)\nRuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n>>> a\nVariable containing:\n 0.5088  0.0052 -0.2603 -0.9549  1.1598\n 1.3255  1.3079  1.7067  1.8954 -0.5464\n 0.0219 -1.0987  0.2794  0.4004 -0.0731\n-0.5973 -0.2672  0.9868 -1.1371  1.6382\n 1.0826  0.7228 -1.6244  2.4482 -0.5585\n[torch.FloatTensor of size 5x5]\n\nFound on pytorch 0.2.0.", "body": "When you call an in-place op on a leaf Variable that requires grad, pytorch throws an error. However, it first mutates that variable.\r\n\r\nDoes this break the graph? It seems like the variable shouldn't get mutated.\r\n\r\n```\r\n>>> a\r\nVariable containing:\r\n 0.6285  0.0864  0.0217  0.8061  0.9542\r\n 0.9619  0.9678  0.9665  0.6608  0.9865\r\n 0.7041  0.5659  0.0866  0.2487  0.9058\r\n 0.3969  0.8566  0.4314  0.0243  0.3414\r\n 0.5087  0.7177  0.2486  0.9656  0.4393\r\n[torch.FloatTensor of size 5x5]\r\n\r\n>>> a.add_(noise)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 322, in add_\r\n    return self._add(other, True)\r\n  File \"/Users/willw/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\", line 313, in _add\r\n    return Add.apply(self, other, inplace)\r\nRuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\r\n>>> a\r\nVariable containing:\r\n 0.5088  0.0052 -0.2603 -0.9549  1.1598\r\n 1.3255  1.3079  1.7067  1.8954 -0.5464\r\n 0.0219 -1.0987  0.2794  0.4004 -0.0731\r\n-0.5973 -0.2672  0.9868 -1.1371  1.6382\r\n 1.0826  0.7228 -1.6244  2.4482 -0.5585\r\n[torch.FloatTensor of size 5x5]\r\n```\r\n\r\nFound on pytorch 0.2.0."}