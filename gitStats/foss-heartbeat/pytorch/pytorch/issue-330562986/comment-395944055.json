{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/395944055", "html_url": "https://github.com/pytorch/pytorch/pull/8278#issuecomment-395944055", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8278", "id": 395944055, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTk0NDA1NQ==", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-09T06:18:46Z", "updated_at": "2018-06-09T06:19:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Currently the .backward() contract allows multiple threads to call it concurrently. If you naively allow a \"main thread\" to take over the role of the current \"cpu thread\" then you will have multiple \"cpu threads\" (per <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> on multiple threads per device).</p>\n<p>Replacing one of the engine's threads with the main thread either requires changing the (implicit) contract or doing some careful concurrency work. For example, the contract could be changed so that backward() (and grad()) calls from \"main\" threads are synchronized so that the next one doesn't start until the prior one completes. Not to say that would be a reasonable change, just one hypothetical way of addressing the issue. Per <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> other point, if the thread doesn't take over a GPU thread then it's likely not doing much, either. Taking over a GPU thread can be even more complicated as the \"main\" thread may be set to a different GPU than most (or all) of the work in backward(), and currently there is no mechanism for determining which GPU will be used most during a backwards pass. One idea there is to heuristically (optimistically) take over for GPU 0 all the time.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> last suggestion also would change the contract if implemented naively. If you backward() on a single thread myopically then multiple backwards() entered by different \"main\" threads can violate the non-reentrancy of functions during the backward pass. This would allow a new type of error to appear. I imagine this issue could be addressed, however.</p>", "body_text": "Currently the .backward() contract allows multiple threads to call it concurrently. If you naively allow a \"main thread\" to take over the role of the current \"cpu thread\" then you will have multiple \"cpu threads\" (per @apaszke on multiple threads per device).\nReplacing one of the engine's threads with the main thread either requires changing the (implicit) contract or doing some careful concurrency work. For example, the contract could be changed so that backward() (and grad()) calls from \"main\" threads are synchronized so that the next one doesn't start until the prior one completes. Not to say that would be a reasonable change, just one hypothetical way of addressing the issue. Per @apaszke other point, if the thread doesn't take over a GPU thread then it's likely not doing much, either. Taking over a GPU thread can be even more complicated as the \"main\" thread may be set to a different GPU than most (or all) of the work in backward(), and currently there is no mechanism for determining which GPU will be used most during a backwards pass. One idea there is to heuristically (optimistically) take over for GPU 0 all the time.\n@apaszke last suggestion also would change the contract if implemented naively. If you backward() on a single thread myopically then multiple backwards() entered by different \"main\" threads can violate the non-reentrancy of functions during the backward pass. This would allow a new type of error to appear. I imagine this issue could be addressed, however.", "body": "Currently the .backward() contract allows multiple threads to call it concurrently. If you naively allow a \"main thread\" to take over the role of the current \"cpu thread\" then you will have multiple \"cpu threads\" (per @apaszke on multiple threads per device).\r\n\r\nReplacing one of the engine's threads with the main thread either requires changing the (implicit) contract or doing some careful concurrency work. For example, the contract could be changed so that backward() (and grad()) calls from \"main\" threads are synchronized so that the next one doesn't start until the prior one completes. Not to say that would be a reasonable change, just one hypothetical way of addressing the issue. Per @apaszke other point, if the thread doesn't take over a GPU thread then it's likely not doing much, either. Taking over a GPU thread can be even more complicated as the \"main\" thread may be set to a different GPU than most (or all) of the work in backward(), and currently there is no mechanism for determining which GPU will be used most during a backwards pass. One idea there is to heuristically (optimistically) take over for GPU 0 all the time. \r\n\r\n@apaszke last suggestion also would change the contract if implemented naively. If you backward() on a single thread myopically then multiple backwards() entered by different \"main\" threads can violate the non-reentrancy of functions during the backward pass. This would allow a new type of error to appear. I imagine this issue could be addressed, however. \r\n"}