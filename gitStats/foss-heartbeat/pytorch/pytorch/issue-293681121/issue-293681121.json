{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4995", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4995/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4995/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4995/events", "html_url": "https://github.com/pytorch/pytorch/pull/4995", "id": 293681121, "node_id": "MDExOlB1bGxSZXF1ZXN0MTY2NjQ5OTU0", "number": 4995, "title": "Fix reduction functions to respect the stride of the output", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 825466279, "node_id": "MDU6TGFiZWw4MjU0NjYyNzk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/0.3.1", "name": "0.3.1", "color": "aefcae", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-02-01T20:58:06Z", "updated_at": "2018-11-23T15:39:09Z", "closed_at": "2018-02-06T15:50:29Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4995", "html_url": "https://github.com/pytorch/pytorch/pull/4995", "diff_url": "https://github.com/pytorch/pytorch/pull/4995.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4995.patch"}, "body_html": "<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #4974.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"293341335\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4974\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4974/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4974\">#4974</a></p>\n<p>Consider reduction ops like <code>torch.sum</code>, <code>torch.prod</code>, etc, of the form<br>\n<code>reduce_op(output, input, keepdim)</code></p>\n<p>Let <code>output_size</code> be the size of the output with <code>keepdim=False</code>, and <code>output_keepdim_size</code> be the size of the output with <code>keepdim=True</code>.</p>\n<p>Right now, what happens in a reduce op is the following:<br>\nwe have an <code>input</code> and an <code>output</code>. <code>output</code> is always resized to <code>output_keepdim_size</code>. Then, the reduction op is performed with that size, and output is finally either squeezed to <code>output_size</code> or kept at <code>output_keepdim_size</code> depending on what <code>keepdim</code> is.</p>\n<p>The problem with what currently happens is that if <code>keepdim=False</code>and <code>output</code> initially has size <code>output_size</code> then <code>output</code> will be resized to <code>output_keepdim_size</code>, the reduce op will be performed, and then output will be squeezed to <code>output_size</code>. This resize is not a no-op and will affect <code>output</code>'s contiguity.</p>\n<p>This PR fixes the issue by always unsqueezing <code>output</code> to <code>output_keepdim_size</code>. This operation preserves <code>output</code>'s contiguity.</p>\n<p>This fixes the following operations:</p>\n<ul>\n<li>mean</li>\n<li>median</li>\n<li>mode</li>\n<li>norm</li>\n<li>prod</li>\n<li>sum</li>\n<li>std</li>\n<li>var</li>\n<li>max</li>\n<li>min</li>\n</ul>\n<h3>Test Plan</h3>\n<p>New unit tests</p>", "body_text": "Fixes #4974\nConsider reduction ops like torch.sum, torch.prod, etc, of the form\nreduce_op(output, input, keepdim)\nLet output_size be the size of the output with keepdim=False, and output_keepdim_size be the size of the output with keepdim=True.\nRight now, what happens in a reduce op is the following:\nwe have an input and an output. output is always resized to output_keepdim_size. Then, the reduction op is performed with that size, and output is finally either squeezed to output_size or kept at output_keepdim_size depending on what keepdim is.\nThe problem with what currently happens is that if keepdim=Falseand output initially has size output_size then output will be resized to output_keepdim_size, the reduce op will be performed, and then output will be squeezed to output_size. This resize is not a no-op and will affect output's contiguity.\nThis PR fixes the issue by always unsqueezing output to output_keepdim_size. This operation preserves output's contiguity.\nThis fixes the following operations:\n\nmean\nmedian\nmode\nnorm\nprod\nsum\nstd\nvar\nmax\nmin\n\nTest Plan\nNew unit tests", "body": "Fixes #4974 \r\n\r\nConsider reduction ops like `torch.sum`, `torch.prod`, etc, of the form\r\n`reduce_op(output, input, keepdim)`\r\n\r\nLet `output_size` be the size of the output with `keepdim=False`, and `output_keepdim_size` be the size of the output with `keepdim=True`.\r\n\r\nRight now, what happens in a reduce op is the following:\r\nwe have an `input` and an `output`. `output` is always resized to `output_keepdim_size`. Then, the reduction op is performed with that size, and output is finally either squeezed to `output_size` or kept at `output_keepdim_size` depending on what `keepdim` is.\r\n\r\nThe problem with what currently happens is that if `keepdim=False`and `output` initially has size `output_size` then `output` will be resized to `output_keepdim_size`, the reduce op will be performed, and then output will be squeezed to `output_size`. This resize is not a no-op and will affect `output`'s contiguity. \r\n\r\nThis PR fixes the issue by always unsqueezing `output` to `output_keepdim_size`. This operation preserves `output`'s contiguity.\r\n\r\nThis fixes the following operations:\r\n- mean\r\n- median\r\n- mode\r\n- norm\r\n- prod\r\n- sum\r\n- std\r\n- var\r\n- max\r\n- min\r\n\r\n### Test Plan\r\nNew unit tests"}