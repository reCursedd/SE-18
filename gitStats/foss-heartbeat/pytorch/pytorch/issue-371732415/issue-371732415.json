{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12841", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12841/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12841/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12841/events", "html_url": "https://github.com/pytorch/pytorch/pull/12841", "id": 371732415, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI0MTEzOTYz", "number": 12841, "title": "Speed up tensor.get_device(), is_cuda(), is_sparse() by avoiding dispatches", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-10-18T22:06:13Z", "updated_at": "2018-11-23T15:53:36Z", "closed_at": "2018-10-26T02:59:11Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/12841", "html_url": "https://github.com/pytorch/pytorch/pull/12841", "diff_url": "https://github.com/pytorch/pytorch/pull/12841.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/12841.patch"}, "body_html": "<p><code>tensor.get_device()</code> went through two dispatches: once to the native<br>\nfunction<br>\n<code>get_device()</code>, and another when <code>get_device</code> calls <code>_th_get_device()</code>.<br>\nThis PR avoids the dispatch by directly implementing the <code>get_device</code><br>\nfunction<br>\nas a method on Tensor.</p>\n<p>Future Work:</p>\n<ul>\n<li>Investigate caching Device on TensorImpl. This will probably bring the<br>\ntensor.get_device down to 2ns, but I'm not sure it's worth it.</li>\n</ul>\n<p>before:</p>\n<pre><code>------------------------------------------------------------------------\nBenchmark                                 Time           CPU Iterations\n------------------------------------------------------------------------\nBM_TensorTypeId                           0 ns          0 ns 1000000000\nBM_TensorType                             8 ns          8 ns   89407911\nBM_TensorIsCuda                          24 ns         24 ns   29313017\nBM_TensorIsSparse                        27 ns         27 ns   26083160\nBM_TensorTypeIsCuda                      11 ns         11 ns   65128120\nBM_TensorNumel                           11 ns         11 ns   68314492\nBM_TensorGetDevice                       71 ns         71 ns    9633125\nBM_DeviceGuardCtor                      173 ns        173 ns    4067173\nBM_DeviceGuard                          232 ns        232 ns    3009690\n</code></pre>\n<p>after:</p>\n<pre><code>------------------------------------------------------------------------\nBenchmark                                 Time           CPU Iterations\n------------------------------------------------------------------------\nBM_TensorTypeId                           0 ns          0 ns 1000000000\nBM_TensorType                            10 ns         10 ns   69803872\nBM_TensorIsCuda                           2 ns          2 ns  321626683\nBM_TensorIsSparse                         6 ns          6 ns  177045382\nBM_TensorNumel                           12 ns         12 ns   58770533\nBM_TensorGetDevice                        4 ns          4 ns  128113396\nBM_DeviceGuardCtor                       52 ns         52 ns   14997278\nBM_DeviceGuard                          158 ns        158 ns    5767248\n\n</code></pre>", "body_text": "tensor.get_device() went through two dispatches: once to the native\nfunction\nget_device(), and another when get_device calls _th_get_device().\nThis PR avoids the dispatch by directly implementing the get_device\nfunction\nas a method on Tensor.\nFuture Work:\n\nInvestigate caching Device on TensorImpl. This will probably bring the\ntensor.get_device down to 2ns, but I'm not sure it's worth it.\n\nbefore:\n------------------------------------------------------------------------\nBenchmark                                 Time           CPU Iterations\n------------------------------------------------------------------------\nBM_TensorTypeId                           0 ns          0 ns 1000000000\nBM_TensorType                             8 ns          8 ns   89407911\nBM_TensorIsCuda                          24 ns         24 ns   29313017\nBM_TensorIsSparse                        27 ns         27 ns   26083160\nBM_TensorTypeIsCuda                      11 ns         11 ns   65128120\nBM_TensorNumel                           11 ns         11 ns   68314492\nBM_TensorGetDevice                       71 ns         71 ns    9633125\nBM_DeviceGuardCtor                      173 ns        173 ns    4067173\nBM_DeviceGuard                          232 ns        232 ns    3009690\n\nafter:\n------------------------------------------------------------------------\nBenchmark                                 Time           CPU Iterations\n------------------------------------------------------------------------\nBM_TensorTypeId                           0 ns          0 ns 1000000000\nBM_TensorType                            10 ns         10 ns   69803872\nBM_TensorIsCuda                           2 ns          2 ns  321626683\nBM_TensorIsSparse                         6 ns          6 ns  177045382\nBM_TensorNumel                           12 ns         12 ns   58770533\nBM_TensorGetDevice                        4 ns          4 ns  128113396\nBM_DeviceGuardCtor                       52 ns         52 ns   14997278\nBM_DeviceGuard                          158 ns        158 ns    5767248", "body": "`tensor.get_device()` went through two dispatches: once to the native\r\nfunction\r\n`get_device()`, and another when `get_device` calls `_th_get_device()`.\r\nThis PR avoids the dispatch by directly implementing the `get_device`\r\nfunction\r\nas a method on Tensor.\r\n\r\nFuture Work:\r\n- Investigate caching Device on TensorImpl. This will probably bring the\r\n  tensor.get_device down to 2ns, but I'm not sure it's worth it.\r\n\r\nbefore:\r\n```\r\n------------------------------------------------------------------------\r\nBenchmark                                 Time           CPU Iterations\r\n------------------------------------------------------------------------\r\nBM_TensorTypeId                           0 ns          0 ns 1000000000\r\nBM_TensorType                             8 ns          8 ns   89407911\r\nBM_TensorIsCuda                          24 ns         24 ns   29313017\r\nBM_TensorIsSparse                        27 ns         27 ns   26083160\r\nBM_TensorTypeIsCuda                      11 ns         11 ns   65128120\r\nBM_TensorNumel                           11 ns         11 ns   68314492\r\nBM_TensorGetDevice                       71 ns         71 ns    9633125\r\nBM_DeviceGuardCtor                      173 ns        173 ns    4067173\r\nBM_DeviceGuard                          232 ns        232 ns    3009690\r\n```\r\n\r\nafter:\r\n```\r\n------------------------------------------------------------------------\r\nBenchmark                                 Time           CPU Iterations\r\n------------------------------------------------------------------------\r\nBM_TensorTypeId                           0 ns          0 ns 1000000000\r\nBM_TensorType                            10 ns         10 ns   69803872\r\nBM_TensorIsCuda                           2 ns          2 ns  321626683\r\nBM_TensorIsSparse                         6 ns          6 ns  177045382\r\nBM_TensorNumel                           12 ns         12 ns   58770533\r\nBM_TensorGetDevice                        4 ns          4 ns  128113396\r\nBM_DeviceGuardCtor                       52 ns         52 ns   14997278\r\nBM_DeviceGuard                          158 ns        158 ns    5767248\r\n\r\n```"}