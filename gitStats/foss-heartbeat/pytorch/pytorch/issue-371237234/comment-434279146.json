{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/434279146", "html_url": "https://github.com/pytorch/pytorch/issues/12780#issuecomment-434279146", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12780", "id": 434279146, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDI3OTE0Ng==", "user": {"login": "phi-go", "id": 28248770, "node_id": "MDQ6VXNlcjI4MjQ4Nzcw", "avatar_url": "https://avatars0.githubusercontent.com/u/28248770?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phi-go", "html_url": "https://github.com/phi-go", "followers_url": "https://api.github.com/users/phi-go/followers", "following_url": "https://api.github.com/users/phi-go/following{/other_user}", "gists_url": "https://api.github.com/users/phi-go/gists{/gist_id}", "starred_url": "https://api.github.com/users/phi-go/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phi-go/subscriptions", "organizations_url": "https://api.github.com/users/phi-go/orgs", "repos_url": "https://api.github.com/users/phi-go/repos", "events_url": "https://api.github.com/users/phi-go/events{/privacy}", "received_events_url": "https://api.github.com/users/phi-go/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-30T12:22:07Z", "updated_at": "2018-10-30T15:06:32Z", "author_association": "NONE", "body_html": "<p>EDIT:<br>\nIt seems append is the problem not stack. Returning the list from the function results in a list with only one entry.</p>\n<p>I'm facing a similar bug. Minimal code example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\n<span class=\"pl-k\">from</span> torch.jit <span class=\"pl-k\">import</span> script\n\n\n<span class=\"pl-en\">@script</span>\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">update_tensor</span>(<span class=\"pl-smi\">tensor</span>):\n    tensor_prime <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(tensor)):\n        n <span class=\"pl-k\">=</span> tensor[i]\n        tensor_prime.append(n)\n    nodes_prime <span class=\"pl-k\">=</span> torch.stack(tensor_prime)\n    <span class=\"pl-k\">return</span> nodes_prime\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    tensor <span class=\"pl-k\">=</span> torch.FloatTensor(<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">2</span>).random_()\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">3</span>):\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>=<span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">*</span><span class=\"pl-c1\">20</span>)\n        <span class=\"pl-c1\">print</span>(tensor.shape)\n        <span class=\"pl-c1\">print</span>(tensor)\n        tensor <span class=\"pl-k\">=</span> update_tensor(tensor)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    main()</pre></div>\n<p>Output with PYTORCH_JIT=1:</p>\n<pre><code>====================\ntorch.Size([4, 2])\ntensor([[ 1808538.,  7064277.],\n        [  239404., 11649655.],\n        [ 1407555., 12730792.],\n        [11626145.,  6317278.]])\n====================\ntorch.Size([1, 2])\ntensor([[1808538., 7064277.]])\n====================\ntorch.Size([1, 2])\ntensor([[1808538., 7064277.]])\n</code></pre>\n<p>Output with PYTORCH_JIT=0:</p>\n<pre><code>====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n</code></pre>\n<p>Seems like stack only takes the first tensor in the list and ignores the others.</p>\n<p>Version: <code>https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181008-cp36-cp36m-linux_x86_64.whl</code></p>", "body_text": "EDIT:\nIt seems append is the problem not stack. Returning the list from the function results in a list with only one entry.\nI'm facing a similar bug. Minimal code example:\nimport torch\n\nfrom torch.jit import script\n\n\n@script\ndef update_tensor(tensor):\n    tensor_prime = []\n    for i in range(len(tensor)):\n        n = tensor[i]\n        tensor_prime.append(n)\n    nodes_prime = torch.stack(tensor_prime)\n    return nodes_prime\n\n\ndef main():\n    tensor = torch.FloatTensor(4, 2).random_()\n\n    for i in range(3):\n        print(\"=\"*20)\n        print(tensor.shape)\n        print(tensor)\n        tensor = update_tensor(tensor)\n\n\nif __name__ == \"__main__\":\n    main()\nOutput with PYTORCH_JIT=1:\n====================\ntorch.Size([4, 2])\ntensor([[ 1808538.,  7064277.],\n        [  239404., 11649655.],\n        [ 1407555., 12730792.],\n        [11626145.,  6317278.]])\n====================\ntorch.Size([1, 2])\ntensor([[1808538., 7064277.]])\n====================\ntorch.Size([1, 2])\ntensor([[1808538., 7064277.]])\n\nOutput with PYTORCH_JIT=0:\n====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n====================\ntorch.Size([4, 2])\ntensor([[ 9087322., 11016173.],\n        [ 4673285.,  9341248.],\n        [ 1091294.,  1047240.],\n        [ 6966788., 12850260.]])\n\nSeems like stack only takes the first tensor in the list and ignores the others.\nVersion: https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181008-cp36-cp36m-linux_x86_64.whl", "body": "EDIT:\r\nIt seems append is the problem not stack. Returning the list from the function results in a list with only one entry.\r\n\r\nI'm facing a similar bug. Minimal code example:\r\n\r\n```python\r\nimport torch\r\n\r\nfrom torch.jit import script\r\n\r\n\r\n@script\r\ndef update_tensor(tensor):\r\n    tensor_prime = []\r\n    for i in range(len(tensor)):\r\n        n = tensor[i]\r\n        tensor_prime.append(n)\r\n    nodes_prime = torch.stack(tensor_prime)\r\n    return nodes_prime\r\n\r\n\r\ndef main():\r\n    tensor = torch.FloatTensor(4, 2).random_()\r\n\r\n    for i in range(3):\r\n        print(\"=\"*20)\r\n        print(tensor.shape)\r\n        print(tensor)\r\n        tensor = update_tensor(tensor)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nOutput with PYTORCH_JIT=1:\r\n\r\n```\r\n====================\r\ntorch.Size([4, 2])\r\ntensor([[ 1808538.,  7064277.],\r\n        [  239404., 11649655.],\r\n        [ 1407555., 12730792.],\r\n        [11626145.,  6317278.]])\r\n====================\r\ntorch.Size([1, 2])\r\ntensor([[1808538., 7064277.]])\r\n====================\r\ntorch.Size([1, 2])\r\ntensor([[1808538., 7064277.]])\r\n```\r\n\r\nOutput with PYTORCH_JIT=0:\r\n\r\n```\r\n====================\r\ntorch.Size([4, 2])\r\ntensor([[ 9087322., 11016173.],\r\n        [ 4673285.,  9341248.],\r\n        [ 1091294.,  1047240.],\r\n        [ 6966788., 12850260.]])\r\n====================\r\ntorch.Size([4, 2])\r\ntensor([[ 9087322., 11016173.],\r\n        [ 4673285.,  9341248.],\r\n        [ 1091294.,  1047240.],\r\n        [ 6966788., 12850260.]])\r\n====================\r\ntorch.Size([4, 2])\r\ntensor([[ 9087322., 11016173.],\r\n        [ 4673285.,  9341248.],\r\n        [ 1091294.,  1047240.],\r\n        [ 6966788., 12850260.]])\r\n```\r\n\r\nSeems like stack only takes the first tensor in the list and ignores the others.\r\n\r\nVersion: `https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181008-cp36-cp36m-linux_x86_64.whl`"}