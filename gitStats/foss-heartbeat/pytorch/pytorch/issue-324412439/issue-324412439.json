{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7674", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7674/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7674/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7674/events", "html_url": "https://github.com/pytorch/pytorch/issues/7674", "id": 324412439, "node_id": "MDU6SXNzdWUzMjQ0MTI0Mzk=", "number": 7674, "title": "[PyTorch] proposed enhancement: make varargs more flexible", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-05-18T13:32:37Z", "updated_at": "2018-07-31T11:22:21Z", "closed_at": "2018-07-31T11:22:21Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We currently only support int varargs when they are the only argument in the Python torch wrapping. This limits, for example, the use of varargs in einsum.</p>\n<p>The root cause is in <a href=\"https://github.com/pytorch/pytorch/blob/c58893eb9eb9fca2c61aaee1c7013983569dad61/torch/csrc/utils/python_arg_parser.h#L14\">the pattern for using <code>PythonArgParser</code> with the templated <code>ParsedArgs</code> as documented in the comment at the top of <code>torch/csrc/utils/python_arg_parser.h</code></a>.<br>\nThe fact that <code>ParsedArgs</code> are accessible without <code>PythonArgParser</code> keeps us from doing Python object allocations (for a slice of arguments to assign to the vararg) that could be cleaned up in the destructor of <code>PythonArgParser</code> without feeling dirty.<br>\nI see two obivous ways out:</p>\n<ol>\n<li>move the <code>ParsedArgs</code> structure into PythonArgParser and make that templated (but I would guess  that there was a reason to not do that all along - possibly duplicated functions)</li>\n<li>add a <code>std::vector&lt;PyObject*&gt; varargs</code> to <code>ParsedArgs</code> that gets the varargs.</li>\n</ol>\n<p>Would either of these be acceptable?</p>\n<p>Best regards</p>\n<p>Thomas</p>", "body_text": "We currently only support int varargs when they are the only argument in the Python torch wrapping. This limits, for example, the use of varargs in einsum.\nThe root cause is in the pattern for using PythonArgParser with the templated ParsedArgs as documented in the comment at the top of torch/csrc/utils/python_arg_parser.h.\nThe fact that ParsedArgs are accessible without PythonArgParser keeps us from doing Python object allocations (for a slice of arguments to assign to the vararg) that could be cleaned up in the destructor of PythonArgParser without feeling dirty.\nI see two obivous ways out:\n\nmove the ParsedArgs structure into PythonArgParser and make that templated (but I would guess  that there was a reason to not do that all along - possibly duplicated functions)\nadd a std::vector<PyObject*> varargs to ParsedArgs that gets the varargs.\n\nWould either of these be acceptable?\nBest regards\nThomas", "body": "We currently only support int varargs when they are the only argument in the Python torch wrapping. This limits, for example, the use of varargs in einsum.\r\n\r\nThe root cause is in [the pattern for using `PythonArgParser` with the templated `ParsedArgs` as documented in the comment at the top of `torch/csrc/utils/python_arg_parser.h`](https://github.com/pytorch/pytorch/blob/c58893eb9eb9fca2c61aaee1c7013983569dad61/torch/csrc/utils/python_arg_parser.h#L14).\r\nThe fact that `ParsedArgs` are accessible without `PythonArgParser` keeps us from doing Python object allocations (for a slice of arguments to assign to the vararg) that could be cleaned up in the destructor of `PythonArgParser` without feeling dirty.\r\nI see two obivous ways out:\r\n1. move the `ParsedArgs` structure into PythonArgParser and make that templated (but I would guess  that there was a reason to not do that all along - possibly duplicated functions)\r\n2. add a `std::vector<PyObject*> varargs` to `ParsedArgs` that gets the varargs.\r\n\r\nWould either of these be acceptable?\r\n\r\nBest regards\r\n\r\nThomas"}