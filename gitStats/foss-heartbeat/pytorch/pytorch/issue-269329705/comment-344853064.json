{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/344853064", "html_url": "https://github.com/pytorch/pytorch/pull/3341#issuecomment-344853064", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3341", "id": 344853064, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NDg1MzA2NA==", "user": {"login": "hughperkins", "id": 123560, "node_id": "MDQ6VXNlcjEyMzU2MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/123560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughperkins", "html_url": "https://github.com/hughperkins", "followers_url": "https://api.github.com/users/hughperkins/followers", "following_url": "https://api.github.com/users/hughperkins/following{/other_user}", "gists_url": "https://api.github.com/users/hughperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughperkins/subscriptions", "organizations_url": "https://api.github.com/users/hughperkins/orgs", "repos_url": "https://api.github.com/users/hughperkins/repos", "events_url": "https://api.github.com/users/hughperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/hughperkins/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-16T08:40:42Z", "updated_at": "2017-11-16T08:42:08Z", "author_association": "CONTRIBUTOR", "body_html": "<p>We want to show there is actually gradient being backpropagated. If random number generator is not invariant across hardware, then I guess we may as well remove the seed. I'd rather not put <code>eps</code>, since <code>eps</code> is used for showing things are effectively the same, whereas we want to check that the gradient is effectively not the same, ie not zero.</p>\n<p>What are your thoughts on how we can demonstrate that there is a gradient being back-propagated?</p>\n<p>Hmmm. Perhaps, we should replace <code>.min()</code> with <code>.mean()</code> or <code>.max()</code>? <code>.min()</code> does seem ... fragile.</p>\n<p>(Edit: and/or <code>.var()</code>, <code>.std()</code> perhaps?)</p>\n<p>(Edit2: I shall change to <code>.std()</code> I think)</p>", "body_text": "We want to show there is actually gradient being backpropagated. If random number generator is not invariant across hardware, then I guess we may as well remove the seed. I'd rather not put eps, since eps is used for showing things are effectively the same, whereas we want to check that the gradient is effectively not the same, ie not zero.\nWhat are your thoughts on how we can demonstrate that there is a gradient being back-propagated?\nHmmm. Perhaps, we should replace .min() with .mean() or .max()? .min() does seem ... fragile.\n(Edit: and/or .var(), .std() perhaps?)\n(Edit2: I shall change to .std() I think)", "body": "We want to show there is actually gradient being backpropagated. If random number generator is not invariant across hardware, then I guess we may as well remove the seed. I'd rather not put `eps`, since `eps` is used for showing things are effectively the same, whereas we want to check that the gradient is effectively not the same, ie not zero.\r\n\r\nWhat are your thoughts on how we can demonstrate that there is a gradient being back-propagated?\r\n\r\nHmmm. Perhaps, we should replace `.min()` with `.mean()` or `.max()`? `.min()` does seem ... fragile.\r\n\r\n(Edit: and/or `.var()`, `.std()` perhaps?)\r\n\r\n(Edit2: I shall change to `.std()` I think)"}