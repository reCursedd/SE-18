{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/391204079", "html_url": "https://github.com/pytorch/pytorch/pull/7737#issuecomment-391204079", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7737", "id": 391204079, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTIwNDA3OQ==", "user": {"login": "jvmancuso", "id": 7891333, "node_id": "MDQ6VXNlcjc4OTEzMzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/7891333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvmancuso", "html_url": "https://github.com/jvmancuso", "followers_url": "https://api.github.com/users/jvmancuso/followers", "following_url": "https://api.github.com/users/jvmancuso/following{/other_user}", "gists_url": "https://api.github.com/users/jvmancuso/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvmancuso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvmancuso/subscriptions", "organizations_url": "https://api.github.com/users/jvmancuso/orgs", "repos_url": "https://api.github.com/users/jvmancuso/repos", "events_url": "https://api.github.com/users/jvmancuso/events{/privacy}", "received_events_url": "https://api.github.com/users/jvmancuso/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-23T02:53:11Z", "updated_at": "2018-05-23T02:53:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>so, question.  in order to maintain the current behavior, e.g. to use torch.set_grad_enabled(False) imperatively, I need to be able to save the input to set_grad_enabled as an attribute, then change <strong>enter</strong> to set the grad mode to that attribute's value:</p>\n<pre><code>def __init__(self, mode):\n    self.prev = torch.is_grad_enabled()\n    torch._C.set_grad_enabled(mode)\n    self.mode = mode\n\ndef __enter__(self):\n    torch.set_grad_enabled(self.mode)\n\ndef __exit__(self, *args):\n    torch.set_grad_enabled(self.prev)\n    return False\n</code></pre>\n<p>however, if I do that, then any time it's instantiated, including when it wraps a function, the underlying grad mode will be changed.  this seems like unwanted behavior, and maybe it's best to not use this one as a decorator?  open to other suggestions.</p>", "body_text": "so, question.  in order to maintain the current behavior, e.g. to use torch.set_grad_enabled(False) imperatively, I need to be able to save the input to set_grad_enabled as an attribute, then change enter to set the grad mode to that attribute's value:\ndef __init__(self, mode):\n    self.prev = torch.is_grad_enabled()\n    torch._C.set_grad_enabled(mode)\n    self.mode = mode\n\ndef __enter__(self):\n    torch.set_grad_enabled(self.mode)\n\ndef __exit__(self, *args):\n    torch.set_grad_enabled(self.prev)\n    return False\n\nhowever, if I do that, then any time it's instantiated, including when it wraps a function, the underlying grad mode will be changed.  this seems like unwanted behavior, and maybe it's best to not use this one as a decorator?  open to other suggestions.", "body": "so, question.  in order to maintain the current behavior, e.g. to use torch.set_grad_enabled(False) imperatively, I need to be able to save the input to set_grad_enabled as an attribute, then change __enter__ to set the grad mode to that attribute's value:\r\n\r\n```\r\ndef __init__(self, mode):\r\n    self.prev = torch.is_grad_enabled()\r\n    torch._C.set_grad_enabled(mode)\r\n    self.mode = mode\r\n\r\ndef __enter__(self):\r\n    torch.set_grad_enabled(self.mode)\r\n\r\ndef __exit__(self, *args):\r\n    torch.set_grad_enabled(self.prev)\r\n    return False\r\n```\r\n\r\nhowever, if I do that, then any time it's instantiated, including when it wraps a function, the underlying grad mode will be changed.  this seems like unwanted behavior, and maybe it's best to not use this one as a decorator?  open to other suggestions."}