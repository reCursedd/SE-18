{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/315096810", "html_url": "https://github.com/pytorch/pytorch/issues/1776#issuecomment-315096810", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1776", "id": 315096810, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTA5NjgxMA==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-13T14:35:56Z", "updated_at": "2017-07-13T14:35:56Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=29353643\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/magzHL\">@magzHL</a></p>\n<blockquote>\n<p>Since the easy use of gpu accelerated backward functions is one of the main reasons for me to use pytorch</p>\n</blockquote>\n<p>This is still totally fine with pytorch. The issue here is that inside the backward function, another autograd forward/backward is done, which is not supported at the moment. It's a fairly big change, but it seems reasonable to do. We wont be working on it in the next 2 months or so.</p>", "body_text": "@magzHL\n\nSince the easy use of gpu accelerated backward functions is one of the main reasons for me to use pytorch\n\nThis is still totally fine with pytorch. The issue here is that inside the backward function, another autograd forward/backward is done, which is not supported at the moment. It's a fairly big change, but it seems reasonable to do. We wont be working on it in the next 2 months or so.", "body": "@magzHL  \r\n> Since the easy use of gpu accelerated backward functions is one of the main reasons for me to use pytorch\r\n\r\nThis is still totally fine with pytorch. The issue here is that inside the backward function, another autograd forward/backward is done, which is not supported at the moment. It's a fairly big change, but it seems reasonable to do. We wont be working on it in the next 2 months or so."}