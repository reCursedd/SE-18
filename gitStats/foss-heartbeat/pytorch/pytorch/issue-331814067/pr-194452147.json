{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8409", "id": 194452147, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk0NDUyMTQ3", "html_url": "https://github.com/pytorch/pytorch/pull/8409", "diff_url": "https://github.com/pytorch/pytorch/pull/8409.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8409.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8409", "number": 8409, "state": "closed", "locked": false, "title": "Port THS to ATen.", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "The basic structure of the patch:\r\n\r\n- All kernels in aten/src/THS got rewritten as native\r\n  functions in aten/src/ATen/native/sparse\r\n\r\n  I took the liberty to rename some of the kernels,\r\n  opting for a longer, more transparent names than\r\n  things like 'spaddcmul'.\r\n\r\n- Instead of holding fields for sparse tensor in the TH\r\n  C struct THSTensor, they are now held in a C++ class\r\n  SparseTensorImpl (this explains why I had to do this\r\n  all in one go; I can't have *two* reps for sparse\r\n  tensors!)\r\n\r\n  Along the way, we change a key internal representation\r\n  invariant: an \"empty\" sparse tensor has dimI == 1 and\r\n  dimV == 0 (this is different from dimI == 0 and dimV == 0\r\n  we had before); this ensures that we maintain the invariant\r\n  that dim == dimI + dimV.  \"Scalar\" sparse tensors are\r\n  made illegal, because there really is no way to properly\r\n  express them in COO format.\r\n\r\n- Because we haven't ported THCS or any of the traditional\r\n  dense TH implementations, there is a new set of adapter\r\n  functions in native/LegacyBridge.cpp exclusively devoted\r\n  to deciding whether or not to go to the new native implementation\r\n  or back to the legacy TH binding (prefixed with th_).\r\n  The intent is that when everything gets ported, we can\r\n  delete this file.\r\n\r\n- I've kept the stubs for all the THS functions, but they now all\r\n  error if you try to actually call them.  Eventually, we should\r\n  replace these with calls to ATen so that everything keeps\r\n  working.\r\n\r\n- I gobbled up SparseMM (SparseMM.cpp is no more). It was tasty.\r\n\r\nThere are some miscellaneous improvements which were needed for other\r\nchanges in this patch:\r\n\r\n- There is now AT_FORALL_SCALAR_TYPES_EXCEPT_HALF, which does what\r\n  it says on the tin.\r\n\r\n- axpy templated function moved to BlasUtils.h, there's a new macro\r\n  which lets you easily forward to all of the TH functions. We also expose\r\n  THBlas_(copy).  I'm not terribly pleased with these functions but\r\n  they seem to serve a purpose they need.\r\n\r\n- New method on Tensor to get TensorImpl*, unsafeGetTensorImpl\r\n\r\n- accessor() is now this-const, since const-correctness on Tensor is a lie\r\n\r\n- New toSparse()/toDense() methods on Type; now you can call these\r\n  directly without having to manually apply at::toSparse/toDense\r\n  on the Backend and then running toBackend yourself.\r\n\r\nChanges to the kernels:\r\n\r\n- Previously, the whole body of all kernels was compiled for\r\n  every supported scalar type.  In our new implementation,\r\n  the scalar dispatch has been pushed into the smallest extent\r\n  which (1) is not in a type loop and (2) requires statically\r\n  knowing the scalar type.  These sites all use\r\n  AT_DISPATCH_ALL_TYPES.  I tried to use lambdas as much as\r\n  possible, but sometimes it was not possible when a OpenMP\r\n  pragma was used.\r\n\r\n- Anywhere we tested if the nDimension of a tensor was zero,\r\n  we replaced with a test that numel is zero.  Because, as we\r\n  known, nDimension of zero-size tensors in TH is zero, and\r\n  that's wrong wrong wrong (and not done this way in ATen).\r\n\r\nSome subtleties:\r\n\r\n- Places where previously fastget1d was used, I now use a\r\n  TensorAccessor.  However, you have to be careful about grabbing\r\n  the accessor, because sometimes you will be accessor'ing\r\n  indices/values and they are empty, which means they will\r\n  be *1D* (\"oh, aren't indices always 2D?\" Nope. Nyet.)\r\n  So, essentially, it is only safe to grab an accessor *after*\r\n  you have checked that nnz != 0.  All of these shenanigans\r\n  will go away when we properly support zero-size dimensions.\r\n\r\n  A few places, we test for this case just by wrapping the loop\r\n  in a conditional on nnz.  Some other places this is not so easy,\r\n  so we instead short-circuit the function with a special case for\r\n  when nnz == 0 (usually, these implementations are degenerate).\r\n\r\n- There is a very subtle but important difference between\r\n  _sparse_get_impl(self)->indices() and self._indices();\r\n  the latter may return a view!  This is because nnz is\r\n  not guaranteed to match the dimensions of indices/values;\r\n  you can \"truncate\" a sparse tensor by setting the nnz.\r\n  Actually, I think this is not a good idea and we should\r\n  enforce a stronger invariant, but for this patch I slavishly\r\n  adhere to the old ways, and as such I have to be very\r\n  careful if I want to resize something, I had better use\r\n  the former and not the latter.\r\n\r\n- I had to reimplement broadcasting by hand (thus the s_\r\n  and non-s_ functions in the sparse native files).  There\r\n  is a very important distinction between foo_out and foo_,\r\n  so it is important that the LegacyBridge function always\r\n  call to the lower layer, and not try to avoid boilerplate\r\n  by calling to another LegacyBridge function first.\r\n  I did NOT put broadcasting in LegacyBridge (even though,\r\n  ultimately, that's where it must live), because the th_\r\n  functions which are invoked from LegacyBridge handle\r\n  broadcasting themselves, and I don't want to broadcast\r\n  twice.\r\n\r\n- Sparse function MUST explicitly specify the Type they\r\n  dispatch from, otherwise Variable wrapping/unwrapping will\r\n  not work correctly.  If you use _get_sparse_impl, that is\r\n  sufficient to levy this requirement.\r\n\r\n- The \"has native\" tests in LegacyBridge.cpp are not 100%,\r\n  because some of the functions are mixed dense-sparse functions,\r\n  and so you can't just say, \"Oh, if it's sparse and CPU, call\r\n  the native sparse implementation.\"  This is handled on a\r\n  case by case basis.  There is some especially complex\r\n  logic for add(), which has dense-dense, sparse-sparse\r\n  and dense-sparse implementations.\r\n\r\n- I added some uses of SparseTensorRef in native_functions.yaml,\r\n  but you will notice that these are all on native_* functions,\r\n  and not the actual, top-level functions.  So the SparseTensorRef\r\n  is purely documentary (helping you not call the wrong overload)\r\n  but there is no magic; we do the wrapping ourselves the hard\r\n  way. (This is in constrast to the TH binding code which is magical.)\r\n  Except for _sparse_mask; _sparse_mask is magical.\r\n\r\n- There is a raw_copy_sparse_ method, which is really my way of\r\n  getting around the fact that copy_ has never been implemented\r\n  for sparse tensors (even before this patch), but there IS a\r\n  super secret, internal way of doing these copies that the THS\r\n  code used, and which I needed to get my hands on when I did this\r\n  port.  We should refactor so that either (a) copy_ does support\r\n  sparse-sparse copy natively, or (b) we do this other ways.\r\n\r\n- Irritatingly, I must explicitly resize_as_ before copy_ into\r\n  a tensor.  This was not the case with THTensor_(copy) but I don't\r\n  have any direct binding that doesn't have this requirement.\r\n\r\n- For some reason, the sparse tensor constructor accepts a scalar\r\n  tensor for the values tensor.  This is kind of weird because\r\n  you always need an nnz-dimension.  However, the old code supported\r\n  this and just expanded it into a 1D size 0 tensor; so we need some\r\n  explicit code to do this.\r\n\r\nThere are maybe a bit more AT_ASSERTs in some of the kernels\r\nthan is wise.  I added them all when I was debugging and was\r\nloathe to remove them.\r\n\r\nSigned-off-by: Edward Z. Yang <ezyang@fb.com>\r\n\r\nTODO: I claim that I have \"error\"ed out all of the old THS functions, but this has not actually been done yet except for one function.", "created_at": "2018-06-13T02:00:44Z", "updated_at": "2018-11-23T15:45:40Z", "closed_at": "2018-06-15T21:52:22Z", "merged_at": "2018-06-15T21:52:22Z", "merge_commit_sha": "711e5a6ceb46fcfe90dc8ca176c94c4f44dfbc17", "assignee": null, "assignees": [], "requested_reviewers": [{"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, {"login": "Yangqing", "id": 551151, "node_id": "MDQ6VXNlcjU1MTE1MQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/551151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yangqing", "html_url": "https://github.com/Yangqing", "followers_url": "https://api.github.com/users/Yangqing/followers", "following_url": "https://api.github.com/users/Yangqing/following{/other_user}", "gists_url": "https://api.github.com/users/Yangqing/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yangqing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yangqing/subscriptions", "organizations_url": "https://api.github.com/users/Yangqing/orgs", "repos_url": "https://api.github.com/users/Yangqing/repos", "events_url": "https://api.github.com/users/Yangqing/events{/privacy}", "received_events_url": "https://api.github.com/users/Yangqing/received_events", "type": "User", "site_admin": false}, {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, {"login": "anderspapitto", "id": 1388690, "node_id": "MDQ6VXNlcjEzODg2OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1388690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anderspapitto", "html_url": "https://github.com/anderspapitto", "followers_url": "https://api.github.com/users/anderspapitto/followers", "following_url": "https://api.github.com/users/anderspapitto/following{/other_user}", "gists_url": "https://api.github.com/users/anderspapitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/anderspapitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anderspapitto/subscriptions", "organizations_url": "https://api.github.com/users/anderspapitto/orgs", "repos_url": "https://api.github.com/users/anderspapitto/repos", "events_url": "https://api.github.com/users/anderspapitto/events{/privacy}", "received_events_url": "https://api.github.com/users/anderspapitto/received_events", "type": "User", "site_admin": false}, {"login": "smessmer", "id": 2373925, "node_id": "MDQ6VXNlcjIzNzM5MjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/2373925?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smessmer", "html_url": "https://github.com/smessmer", "followers_url": "https://api.github.com/users/smessmer/followers", "following_url": "https://api.github.com/users/smessmer/following{/other_user}", "gists_url": "https://api.github.com/users/smessmer/gists{/gist_id}", "starred_url": "https://api.github.com/users/smessmer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smessmer/subscriptions", "organizations_url": "https://api.github.com/users/smessmer/orgs", "repos_url": "https://api.github.com/users/smessmer/repos", "events_url": "https://api.github.com/users/smessmer/events{/privacy}", "received_events_url": "https://api.github.com/users/smessmer/received_events", "type": "User", "site_admin": false}, {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, {"login": "bddppq", "id": 9300575, "node_id": "MDQ6VXNlcjkzMDA1NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/9300575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bddppq", "html_url": "https://github.com/bddppq", "followers_url": "https://api.github.com/users/bddppq/followers", "following_url": "https://api.github.com/users/bddppq/following{/other_user}", "gists_url": "https://api.github.com/users/bddppq/gists{/gist_id}", "starred_url": "https://api.github.com/users/bddppq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bddppq/subscriptions", "organizations_url": "https://api.github.com/users/bddppq/orgs", "repos_url": "https://api.github.com/users/bddppq/repos", "events_url": "https://api.github.com/users/bddppq/events{/privacy}", "received_events_url": "https://api.github.com/users/bddppq/received_events", "type": "User", "site_admin": false}, {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}], "requested_teams": [], "labels": [], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8409/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8409/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8409/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/cdf42cdb1df7b90da99aa5914ec208ab1d396d2e", "head": {"label": "ezyang:pr/ths-to-aten", "ref": "pr/ths-to-aten", "sha": "cdf42cdb1df7b90da99aa5914ec208ab1d396d2e", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "repo": {"id": 101798885, "node_id": "MDEwOlJlcG9zaXRvcnkxMDE3OTg4ODU=", "name": "pytorch", "full_name": "ezyang/pytorch", "private": false, "owner": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/ezyang/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/ezyang/pytorch", "forks_url": "https://api.github.com/repos/ezyang/pytorch/forks", "keys_url": "https://api.github.com/repos/ezyang/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/ezyang/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/ezyang/pytorch/teams", "hooks_url": "https://api.github.com/repos/ezyang/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/ezyang/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/ezyang/pytorch/events", "assignees_url": "https://api.github.com/repos/ezyang/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/ezyang/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/ezyang/pytorch/tags", "blobs_url": "https://api.github.com/repos/ezyang/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/ezyang/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/ezyang/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/ezyang/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/ezyang/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/ezyang/pytorch/languages", "stargazers_url": "https://api.github.com/repos/ezyang/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/ezyang/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/ezyang/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/ezyang/pytorch/subscription", "commits_url": "https://api.github.com/repos/ezyang/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/ezyang/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/ezyang/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/ezyang/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/ezyang/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/ezyang/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/ezyang/pytorch/merges", "archive_url": "https://api.github.com/repos/ezyang/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/ezyang/pytorch/downloads", "issues_url": "https://api.github.com/repos/ezyang/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/ezyang/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/ezyang/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/ezyang/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/ezyang/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/ezyang/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/ezyang/pytorch/deployments", "created_at": "2017-08-29T19:28:39Z", "updated_at": "2018-10-29T15:06:40Z", "pushed_at": "2018-11-21T22:30:09Z", "git_url": "git://github.com/ezyang/pytorch.git", "ssh_url": "git@github.com:ezyang/pytorch.git", "clone_url": "https://github.com/ezyang/pytorch.git", "svn_url": "https://github.com/ezyang/pytorch", "homepage": "http://pytorch.org", "size": 88254, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 2, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 2, "watchers": 1, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "b002aee0ff5eeea7172e4037b3d5936202cb6aef", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T14:27:35Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21591, "watchers_count": 21591, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5154, "mirror_url": null, "archived": false, "open_issues_count": 2196, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5154, "open_issues": 2196, "watchers": 21591, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8409"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8409"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/8409"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/8409/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8409/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8409/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/cdf42cdb1df7b90da99aa5914ec208ab1d396d2e"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>The basic structure of the patch:</p>\n<ul>\n<li>\n<p>All kernels in aten/src/THS got rewritten as native<br>\nfunctions in aten/src/ATen/native/sparse</p>\n<p>I took the liberty to rename some of the kernels,<br>\nopting for a longer, more transparent names than<br>\nthings like 'spaddcmul'.</p>\n</li>\n<li>\n<p>Instead of holding fields for sparse tensor in the TH<br>\nC struct THSTensor, they are now held in a C++ class<br>\nSparseTensorImpl (this explains why I had to do this<br>\nall in one go; I can't have <em>two</em> reps for sparse<br>\ntensors!)</p>\n<p>Along the way, we change a key internal representation<br>\ninvariant: an \"empty\" sparse tensor has dimI == 1 and<br>\ndimV == 0 (this is different from dimI == 0 and dimV == 0<br>\nwe had before); this ensures that we maintain the invariant<br>\nthat dim == dimI + dimV.  \"Scalar\" sparse tensors are<br>\nmade illegal, because there really is no way to properly<br>\nexpress them in COO format.</p>\n</li>\n<li>\n<p>Because we haven't ported THCS or any of the traditional<br>\ndense TH implementations, there is a new set of adapter<br>\nfunctions in native/LegacyBridge.cpp exclusively devoted<br>\nto deciding whether or not to go to the new native implementation<br>\nor back to the legacy TH binding (prefixed with th_).<br>\nThe intent is that when everything gets ported, we can<br>\ndelete this file.</p>\n</li>\n<li>\n<p>I've kept the stubs for all the THS functions, but they now all<br>\nerror if you try to actually call them.  Eventually, we should<br>\nreplace these with calls to ATen so that everything keeps<br>\nworking.</p>\n</li>\n<li>\n<p>I gobbled up SparseMM (SparseMM.cpp is no more). It was tasty.</p>\n</li>\n</ul>\n<p>There are some miscellaneous improvements which were needed for other<br>\nchanges in this patch:</p>\n<ul>\n<li>\n<p>There is now AT_FORALL_SCALAR_TYPES_EXCEPT_HALF, which does what<br>\nit says on the tin.</p>\n</li>\n<li>\n<p>axpy templated function moved to BlasUtils.h, there's a new macro<br>\nwhich lets you easily forward to all of the TH functions. We also expose<br>\nTHBlas_(copy).  I'm not terribly pleased with these functions but<br>\nthey seem to serve a purpose they need.</p>\n</li>\n<li>\n<p>New method on Tensor to get TensorImpl*, unsafeGetTensorImpl</p>\n</li>\n<li>\n<p>accessor() is now this-const, since const-correctness on Tensor is a lie</p>\n</li>\n<li>\n<p>New toSparse()/toDense() methods on Type; now you can call these<br>\ndirectly without having to manually apply at::toSparse/toDense<br>\non the Backend and then running toBackend yourself.</p>\n</li>\n</ul>\n<p>Changes to the kernels:</p>\n<ul>\n<li>\n<p>Previously, the whole body of all kernels was compiled for<br>\nevery supported scalar type.  In our new implementation,<br>\nthe scalar dispatch has been pushed into the smallest extent<br>\nwhich (1) is not in a type loop and (2) requires statically<br>\nknowing the scalar type.  These sites all use<br>\nAT_DISPATCH_ALL_TYPES.  I tried to use lambdas as much as<br>\npossible, but sometimes it was not possible when a OpenMP<br>\npragma was used.</p>\n</li>\n<li>\n<p>Anywhere we tested if the nDimension of a tensor was zero,<br>\nwe replaced with a test that numel is zero.  Because, as we<br>\nknown, nDimension of zero-size tensors in TH is zero, and<br>\nthat's wrong wrong wrong (and not done this way in ATen).</p>\n</li>\n</ul>\n<p>Some subtleties:</p>\n<ul>\n<li>\n<p>Places where previously fastget1d was used, I now use a<br>\nTensorAccessor.  However, you have to be careful about grabbing<br>\nthe accessor, because sometimes you will be accessor'ing<br>\nindices/values and they are empty, which means they will<br>\nbe <em>1D</em> (\"oh, aren't indices always 2D?\" Nope. Nyet.)<br>\nSo, essentially, it is only safe to grab an accessor <em>after</em><br>\nyou have checked that nnz != 0.  All of these shenanigans<br>\nwill go away when we properly support zero-size dimensions.</p>\n<p>A few places, we test for this case just by wrapping the loop<br>\nin a conditional on nnz.  Some other places this is not so easy,<br>\nso we instead short-circuit the function with a special case for<br>\nwhen nnz == 0 (usually, these implementations are degenerate).</p>\n</li>\n<li>\n<p>There is a very subtle but important difference between<br>\n_sparse_get_impl(self)-&gt;indices() and self._indices();<br>\nthe latter may return a view!  This is because nnz is<br>\nnot guaranteed to match the dimensions of indices/values;<br>\nyou can \"truncate\" a sparse tensor by setting the nnz.<br>\nActually, I think this is not a good idea and we should<br>\nenforce a stronger invariant, but for this patch I slavishly<br>\nadhere to the old ways, and as such I have to be very<br>\ncareful if I want to resize something, I had better use<br>\nthe former and not the latter.</p>\n</li>\n<li>\n<p>I had to reimplement broadcasting by hand (thus the s_<br>\nand non-s_ functions in the sparse native files).  There<br>\nis a very important distinction between foo_out and foo_,<br>\nso it is important that the LegacyBridge function always<br>\ncall to the lower layer, and not try to avoid boilerplate<br>\nby calling to another LegacyBridge function first.<br>\nI did NOT put broadcasting in LegacyBridge (even though,<br>\nultimately, that's where it must live), because the th_<br>\nfunctions which are invoked from LegacyBridge handle<br>\nbroadcasting themselves, and I don't want to broadcast<br>\ntwice.</p>\n</li>\n<li>\n<p>Sparse function MUST explicitly specify the Type they<br>\ndispatch from, otherwise Variable wrapping/unwrapping will<br>\nnot work correctly.  If you use _get_sparse_impl, that is<br>\nsufficient to levy this requirement.</p>\n</li>\n<li>\n<p>The \"has native\" tests in LegacyBridge.cpp are not 100%,<br>\nbecause some of the functions are mixed dense-sparse functions,<br>\nand so you can't just say, \"Oh, if it's sparse and CPU, call<br>\nthe native sparse implementation.\"  This is handled on a<br>\ncase by case basis.  There is some especially complex<br>\nlogic for add(), which has dense-dense, sparse-sparse<br>\nand dense-sparse implementations.</p>\n</li>\n<li>\n<p>I added some uses of SparseTensorRef in native_functions.yaml,<br>\nbut you will notice that these are all on native_* functions,<br>\nand not the actual, top-level functions.  So the SparseTensorRef<br>\nis purely documentary (helping you not call the wrong overload)<br>\nbut there is no magic; we do the wrapping ourselves the hard<br>\nway. (This is in constrast to the TH binding code which is magical.)<br>\nExcept for _sparse_mask; _sparse_mask is magical.</p>\n</li>\n<li>\n<p>There is a raw_copy_sparse_ method, which is really my way of<br>\ngetting around the fact that copy_ has never been implemented<br>\nfor sparse tensors (even before this patch), but there IS a<br>\nsuper secret, internal way of doing these copies that the THS<br>\ncode used, and which I needed to get my hands on when I did this<br>\nport.  We should refactor so that either (a) copy_ does support<br>\nsparse-sparse copy natively, or (b) we do this other ways.</p>\n</li>\n<li>\n<p>Irritatingly, I must explicitly resize_as_ before copy_ into<br>\na tensor.  This was not the case with THTensor_(copy) but I don't<br>\nhave any direct binding that doesn't have this requirement.</p>\n</li>\n<li>\n<p>For some reason, the sparse tensor constructor accepts a scalar<br>\ntensor for the values tensor.  This is kind of weird because<br>\nyou always need an nnz-dimension.  However, the old code supported<br>\nthis and just expanded it into a 1D size 0 tensor; so we need some<br>\nexplicit code to do this.</p>\n</li>\n</ul>\n<p>There are maybe a bit more AT_ASSERTs in some of the kernels<br>\nthan is wise.  I added them all when I was debugging and was<br>\nloathe to remove them.</p>\n<p>Signed-off-by: Edward Z. Yang <a href=\"mailto:ezyang@fb.com\">ezyang@fb.com</a></p>\n<p>TODO: I claim that I have \"error\"ed out all of the old THS functions, but this has not actually been done yet except for one function.</p>", "body_text": "The basic structure of the patch:\n\n\nAll kernels in aten/src/THS got rewritten as native\nfunctions in aten/src/ATen/native/sparse\nI took the liberty to rename some of the kernels,\nopting for a longer, more transparent names than\nthings like 'spaddcmul'.\n\n\nInstead of holding fields for sparse tensor in the TH\nC struct THSTensor, they are now held in a C++ class\nSparseTensorImpl (this explains why I had to do this\nall in one go; I can't have two reps for sparse\ntensors!)\nAlong the way, we change a key internal representation\ninvariant: an \"empty\" sparse tensor has dimI == 1 and\ndimV == 0 (this is different from dimI == 0 and dimV == 0\nwe had before); this ensures that we maintain the invariant\nthat dim == dimI + dimV.  \"Scalar\" sparse tensors are\nmade illegal, because there really is no way to properly\nexpress them in COO format.\n\n\nBecause we haven't ported THCS or any of the traditional\ndense TH implementations, there is a new set of adapter\nfunctions in native/LegacyBridge.cpp exclusively devoted\nto deciding whether or not to go to the new native implementation\nor back to the legacy TH binding (prefixed with th_).\nThe intent is that when everything gets ported, we can\ndelete this file.\n\n\nI've kept the stubs for all the THS functions, but they now all\nerror if you try to actually call them.  Eventually, we should\nreplace these with calls to ATen so that everything keeps\nworking.\n\n\nI gobbled up SparseMM (SparseMM.cpp is no more). It was tasty.\n\n\nThere are some miscellaneous improvements which were needed for other\nchanges in this patch:\n\n\nThere is now AT_FORALL_SCALAR_TYPES_EXCEPT_HALF, which does what\nit says on the tin.\n\n\naxpy templated function moved to BlasUtils.h, there's a new macro\nwhich lets you easily forward to all of the TH functions. We also expose\nTHBlas_(copy).  I'm not terribly pleased with these functions but\nthey seem to serve a purpose they need.\n\n\nNew method on Tensor to get TensorImpl*, unsafeGetTensorImpl\n\n\naccessor() is now this-const, since const-correctness on Tensor is a lie\n\n\nNew toSparse()/toDense() methods on Type; now you can call these\ndirectly without having to manually apply at::toSparse/toDense\non the Backend and then running toBackend yourself.\n\n\nChanges to the kernels:\n\n\nPreviously, the whole body of all kernels was compiled for\nevery supported scalar type.  In our new implementation,\nthe scalar dispatch has been pushed into the smallest extent\nwhich (1) is not in a type loop and (2) requires statically\nknowing the scalar type.  These sites all use\nAT_DISPATCH_ALL_TYPES.  I tried to use lambdas as much as\npossible, but sometimes it was not possible when a OpenMP\npragma was used.\n\n\nAnywhere we tested if the nDimension of a tensor was zero,\nwe replaced with a test that numel is zero.  Because, as we\nknown, nDimension of zero-size tensors in TH is zero, and\nthat's wrong wrong wrong (and not done this way in ATen).\n\n\nSome subtleties:\n\n\nPlaces where previously fastget1d was used, I now use a\nTensorAccessor.  However, you have to be careful about grabbing\nthe accessor, because sometimes you will be accessor'ing\nindices/values and they are empty, which means they will\nbe 1D (\"oh, aren't indices always 2D?\" Nope. Nyet.)\nSo, essentially, it is only safe to grab an accessor after\nyou have checked that nnz != 0.  All of these shenanigans\nwill go away when we properly support zero-size dimensions.\nA few places, we test for this case just by wrapping the loop\nin a conditional on nnz.  Some other places this is not so easy,\nso we instead short-circuit the function with a special case for\nwhen nnz == 0 (usually, these implementations are degenerate).\n\n\nThere is a very subtle but important difference between\n_sparse_get_impl(self)->indices() and self._indices();\nthe latter may return a view!  This is because nnz is\nnot guaranteed to match the dimensions of indices/values;\nyou can \"truncate\" a sparse tensor by setting the nnz.\nActually, I think this is not a good idea and we should\nenforce a stronger invariant, but for this patch I slavishly\nadhere to the old ways, and as such I have to be very\ncareful if I want to resize something, I had better use\nthe former and not the latter.\n\n\nI had to reimplement broadcasting by hand (thus the s_\nand non-s_ functions in the sparse native files).  There\nis a very important distinction between foo_out and foo_,\nso it is important that the LegacyBridge function always\ncall to the lower layer, and not try to avoid boilerplate\nby calling to another LegacyBridge function first.\nI did NOT put broadcasting in LegacyBridge (even though,\nultimately, that's where it must live), because the th_\nfunctions which are invoked from LegacyBridge handle\nbroadcasting themselves, and I don't want to broadcast\ntwice.\n\n\nSparse function MUST explicitly specify the Type they\ndispatch from, otherwise Variable wrapping/unwrapping will\nnot work correctly.  If you use _get_sparse_impl, that is\nsufficient to levy this requirement.\n\n\nThe \"has native\" tests in LegacyBridge.cpp are not 100%,\nbecause some of the functions are mixed dense-sparse functions,\nand so you can't just say, \"Oh, if it's sparse and CPU, call\nthe native sparse implementation.\"  This is handled on a\ncase by case basis.  There is some especially complex\nlogic for add(), which has dense-dense, sparse-sparse\nand dense-sparse implementations.\n\n\nI added some uses of SparseTensorRef in native_functions.yaml,\nbut you will notice that these are all on native_* functions,\nand not the actual, top-level functions.  So the SparseTensorRef\nis purely documentary (helping you not call the wrong overload)\nbut there is no magic; we do the wrapping ourselves the hard\nway. (This is in constrast to the TH binding code which is magical.)\nExcept for _sparse_mask; _sparse_mask is magical.\n\n\nThere is a raw_copy_sparse_ method, which is really my way of\ngetting around the fact that copy_ has never been implemented\nfor sparse tensors (even before this patch), but there IS a\nsuper secret, internal way of doing these copies that the THS\ncode used, and which I needed to get my hands on when I did this\nport.  We should refactor so that either (a) copy_ does support\nsparse-sparse copy natively, or (b) we do this other ways.\n\n\nIrritatingly, I must explicitly resize_as_ before copy_ into\na tensor.  This was not the case with THTensor_(copy) but I don't\nhave any direct binding that doesn't have this requirement.\n\n\nFor some reason, the sparse tensor constructor accepts a scalar\ntensor for the values tensor.  This is kind of weird because\nyou always need an nnz-dimension.  However, the old code supported\nthis and just expanded it into a 1D size 0 tensor; so we need some\nexplicit code to do this.\n\n\nThere are maybe a bit more AT_ASSERTs in some of the kernels\nthan is wise.  I added them all when I was debugging and was\nloathe to remove them.\nSigned-off-by: Edward Z. Yang ezyang@fb.com\nTODO: I claim that I have \"error\"ed out all of the old THS functions, but this has not actually been done yet except for one function.", "merged": true, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "comments": 3, "review_comments": 56, "maintainer_can_modify": false, "commits": 38, "additions": 2870, "deletions": 1168, "changed_files": 36}