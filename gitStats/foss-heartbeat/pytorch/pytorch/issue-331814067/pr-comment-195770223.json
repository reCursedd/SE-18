{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195770223", "pull_request_review_id": 129204897, "id": 195770223, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTc3MDIyMw==", "diff_hunk": "@@ -1164,3 +1164,383 @@\n   dispatch:\n     CPU: _s_poisson_cpu\n     CUDA: _s_poisson_cuda\n+\n+# When more variants get ported to native, this dispatch will get more\n+# complicated\n+\n+- func: native_norm(Tensor self, Scalar p=2) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: norm_sparse\n+\n+- func: norm(Tensor self, Scalar p=2) -> Tensor\n+  variants: method, function\n+\n+- func: native_clone(Tensor self) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: clone_sparse\n+\n+- func: clone(Tensor self) -> Tensor\n+\n+- func: native_resize_as_(Tensor self, Tensor the_template) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: resize_as_sparse_\n+\n+- func: resize_as_(Tensor self, Tensor the_template) -> Tensor\n+\n+- func: native_pow_out(Tensor result, Tensor self, Scalar exponent) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: pow_out_sparse_scalar\n+\n+- func: native_pow(Tensor self, Scalar exponent) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: pow_sparse_scalar\n+\n+- func: pow_out(Tensor result, Tensor self, Scalar exponent) -> Tensor\n+  variants: function\n+\n+- func: pow(Tensor self, Scalar exponent) -> Tensor\n+  variants: method, function\n+\n+- func: native_zero_(Tensor self) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: zero_sparse_\n+\n+- func: zero_(Tensor self) -> Tensor\n+\n+\n+\n+- func: s_native_add_out(Tensor result, Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_add_out_sparse_cpu\n+\n+- func: native_add_out(Tensor result, Tensor self, SparseTensorRef other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: add_out_dense_sparse_cpu\n+\n+- func: s_native_add(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_add_sparse_cpu\n+\n+- func: native_add(Tensor self, SparseTensorRef other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: add_dense_sparse_cpu\n+\n+- func: s_native_add_(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_add_sparse_cpu_\n+\n+- func: native_add_(Tensor self, SparseTensorRef other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: add_dense_sparse_cpu_\n+\n+- func: add_out(Tensor result, Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+\n+- func: add(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: method, function\n+\n+- func: add_(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: method\n+\n+\n+\n+- func: s_native_sub_out(Tensor result, Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_sub_out_sparse_cpu\n+\n+- func: s_native_sub(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_sub_sparse_cpu\n+\n+- func: s_native_sub_(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_sub_sparse_cpu_\n+\n+- func: sub_out(Tensor result, Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: function\n+\n+- func: sub(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: method, function\n+\n+- func: sub_(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor\n+  variants: method\n+\n+\n+\n+- func: s_native_mul_out(Tensor result, Tensor self, Tensor other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_mul_out_sparse_cpu\n+\n+- func: s_native_mul(Tensor self, Tensor other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_mul_sparse_cpu\n+\n+- func: s_native_mul_(Tensor self, Tensor other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: s_mul_sparse_cpu_\n+\n+- func: native_mul_out(Tensor result, Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: mul_out_sparse_scalar\n+\n+- func: native_mul(Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: mul_sparse_scalar\n+\n+- func: native_mul_(Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: mul_sparse_scalar_\n+\n+- func: mul_out(Tensor result, Tensor self, Tensor other) -> Tensor\n+  variants: function\n+\n+- func: mul_out(Tensor result, Tensor self, Scalar other) -> Tensor\n+  variants: function\n+\n+- func: mul(Tensor self, Tensor other) -> Tensor\n+  variants: method, function\n+\n+- func: mul(Tensor self, Scalar other) -> Tensor\n+  variants: method, function\n+\n+- func: mul_(Tensor self, Tensor other) -> Tensor\n+  variants: method\n+\n+- func: mul_(Tensor self, Scalar other) -> Tensor\n+  variants: method\n+\n+\n+\n+- func: native_div_out(Tensor result, Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: div_out_sparse_scalar\n+\n+- func: native_div(Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: div_sparse_scalar\n+\n+- func: native_div_(Tensor self, Scalar other) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: div_sparse_scalar_\n+\n+- func: div_out(Tensor result, Tensor self, Scalar other) -> Tensor\n+  variants: function\n+\n+- func: div(Tensor self, Scalar other) -> Tensor\n+  variants: method, function\n+\n+- func: div_(Tensor self, Scalar other) -> Tensor\n+  variants: method\n+\n+\n+- func: s_native_addmm_out(Tensor result, Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: s_addmm_out_sparse_dense_cpu\n+\n+- func: s_native_addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: s_addmm_sparse_dense_cpu\n+\n+- func: s_native_addmm_(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: function\n+  dispatch:\n+    CPU: s_addmm_sparse_dense_cpu_\n+\n+- func: addmm_out(Tensor result, Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: function\n+\n+- func: addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: method, function\n+\n+- func: addmm_(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -> Tensor\n+  variants: method\n+\n+\n+- func: native_tensor(Type self_ty) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: new_sparse\n+\n+- func: native_tensor(Type self_ty, IntList size) -> Tensor\n+  variants: function\n+  dispatch:\n+    SparseCPU: new_with_size_sparse\n+\n+- func: tensor(Type dtype) -> Tensor\n+  variants: function\n+\n+- func: tensor(Type dtype, IntList size) -> Tensor\n+  variants: function\n+\n+\n+# NB: The function overloads are removed to avoid a nasty bug where\n+# you say at::native_sparse_coo_tensor(indices, values), and then\n+# it does the dispatch based on indices (wrong wrong wrong!)  Without\n+# the variants, you must call this on type directly.\n+#\n+# Maybe this meant we were supposed to take a dtype as an argument here.\n+# Hmmmmm.\n+\n+- func: native_sparse_coo_tensor(IndexTensor indices, Tensor values) -> Tensor\n+  variants: []", "path": "aten/src/ATen/native/native_functions.yaml", "position": 248, "original_position": 248, "commit_id": "cdf42cdb1df7b90da99aa5914ec208ab1d396d2e", "original_commit_id": "557a724094be5fd8737c29bee24b7c8b9a4f2e82", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "`variants: []` means, don't generate `at::native_sparse_coo_tensor` or `Tensor:: native_sparse_coo_tensor`, but do create a method on `Type`. But I think I'm going to see if I can just make these take a `Type`.", "created_at": "2018-06-15T15:04:29Z", "updated_at": "2018-11-23T15:45:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/8409#discussion_r195770223", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8409", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195770223"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8409#discussion_r195770223"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8409"}}, "body_html": "<p><code>variants: []</code> means, don't generate <code>at::native_sparse_coo_tensor</code> or <code>Tensor:: native_sparse_coo_tensor</code>, but do create a method on <code>Type</code>. But I think I'm going to see if I can just make these take a <code>Type</code>.</p>", "body_text": "variants: [] means, don't generate at::native_sparse_coo_tensor or Tensor:: native_sparse_coo_tensor, but do create a method on Type. But I think I'm going to see if I can just make these take a Type.", "in_reply_to_id": 195563476}