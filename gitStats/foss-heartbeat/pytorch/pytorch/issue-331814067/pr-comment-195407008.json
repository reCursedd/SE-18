{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195407008", "pull_request_review_id": 128769659, "id": 195407008, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTQwNzAwOA==", "diff_hunk": "@@ -0,0 +1,64 @@\n+#include <ATen/ATen.h>\n+#include <ATen/SparseTensorImpl.h>\n+\n+namespace at {\n+\n+// SparseTensorImpl defaults to a [0] size tensor with one sparse dimension and\n+// no dense dimensions.  This is kind of arbitrary but we want the math to work\n+// out.\n+SparseTensorImpl::SparseTensorImpl(Type * type)\n+    : TensorImpl(type)\n+    , size_{0}\n+    , dimI_(1)\n+    , dimV_(0)\n+    , indices_(type->toDense().toScalarType(ScalarType::Long).tensor())\n+    , values_(type->toDense().tensor()) {\n+      AT_ASSERT(type->is_sparse() && !type->is_variable_or_undefined());\n+    }\n+\n+const char * SparseTensorImpl::toString() const {\n+  // TODO: also give back type information\n+  return \"SparseTensor\";\n+}\n+IntList SparseTensorImpl::sizes() const {\n+  return size_;\n+}\n+IntList SparseTensorImpl::strides() const {\n+  AT_ERROR(\"sparse tensors do not have strides\");\n+}\n+int64_t SparseTensorImpl::dim() const {\n+  return dimI_ + dimV_;\n+}\n+Scalar SparseTensorImpl::localScalar() {\n+  AT_ERROR(\"sparse tensors cannot be scalars\");\n+}\n+void * SparseTensorImpl::unsafeGetTH(bool retain) {\n+  AT_ERROR(\"unsafeGetTH not supported for new style TensorImpl\");\n+}\n+std::unique_ptr<Storage> SparseTensorImpl::storage() {\n+  AT_ERROR(\"sparse tensors do not have storage\");\n+}\n+\n+void SparseTensorImpl::set_indices_and_values(const Tensor& indices, const Tensor& values) {\n+  // TODO: Explicit empty test is needed because we don't handle size zero\n+  // dimensions at the moment\n+  bool empty = values.numel() == 0;\n+  AT_CHECK(values.type().toSparse() == type(), \"values type must match sparse tensor type\");\n+  AT_CHECK(indices.type().scalarType() == kLong);\n+  AT_CHECK(indices.type().backend() == values.type().backend());\n+  if (!empty) {\n+    AT_CHECK(indices.dim() == 2, \"indices must be nDim x nnz\");\n+    AT_CHECK(indices.size(1) == values.size(0), \"indices and values must have same nnz\");\n+    AT_CHECK(indices.size(0) == dimI_, \"indices has incorrect first dimension, expected \", dimI_, \", got \", indices.size(0));\n+    AT_CHECK(values.dim() == dimV_ + 1, \"values has incorrect number of dimensions, expected \", dimV_ + 1, \", got \", values.dim());\n+  } else {\n+    AT_CHECK(indices.numel() == 0, \"if values is empty, indices must be empty too\");\n+  }\n+  indices_ = indices;\n+  values_ = values;\n+  nnz_ = empty ? 0 : values.size(0);", "path": "aten/src/ATen/SparseTensorImpl.cpp", "position": null, "original_position": 59, "commit_id": "cdf42cdb1df7b90da99aa5914ec208ab1d396d2e", "original_commit_id": "28ac9cd875555f60e7f2089f317e01c36fe07cd7", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "Yes, but it's an accident. I think it's clearer this way. I added this comment:\r\n\r\n```\r\n  // TODO: Eliminate this ternary when we handle size zero dimensions.\r\n  // (Actually, this will \"accidentally\" work today because all zero-size\r\n  // tensors have size [0], and so you'll get 0 when empty is zero; but it's\r\n  // more explicit this way.)\r\n```", "created_at": "2018-06-14T12:43:46Z", "updated_at": "2018-11-23T15:45:32Z", "html_url": "https://github.com/pytorch/pytorch/pull/8409#discussion_r195407008", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8409", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195407008"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8409#discussion_r195407008"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8409"}}, "body_html": "<p>Yes, but it's an accident. I think it's clearer this way. I added this comment:</p>\n<pre><code>  // TODO: Eliminate this ternary when we handle size zero dimensions.\n  // (Actually, this will \"accidentally\" work today because all zero-size\n  // tensors have size [0], and so you'll get 0 when empty is zero; but it's\n  // more explicit this way.)\n</code></pre>", "body_text": "Yes, but it's an accident. I think it's clearer this way. I added this comment:\n  // TODO: Eliminate this ternary when we handle size zero dimensions.\n  // (Actually, this will \"accidentally\" work today because all zero-size\n  // tensors have size [0], and so you'll get 0 when empty is zero; but it's\n  // more explicit this way.)", "in_reply_to_id": 195291345}