{"url": "https://api.github.com/repos/pytorch/pytorch/issues/473", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/473/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/473/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/473/events", "html_url": "https://github.com/pytorch/pytorch/issues/473", "id": 201488188, "node_id": "MDU6SXNzdWUyMDE0ODgxODg=", "number": 473, "title": "Autograd IndexCopy is broken", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-01-18T06:10:37Z", "updated_at": "2017-06-23T17:04:05Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>This happens when the index tensor contains duplicate elements. If this is not allowed index_copy_ should raise an exception when this happens and we should fix the test. Otherwise we need to fix the autograd op.</p>\n<p>Here's an example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> <span class=\"pl-k\">*</span>\nx <span class=\"pl-k\">=</span> Variable(torch.zeros(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-c1\">print</span>(x)\ny <span class=\"pl-k\">=</span> Variable(torch.range(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">25</span>).view(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>), <span class=\"pl-v\">requires_grad</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-c1\">print</span>(y)\nidx <span class=\"pl-k\">=</span> Variable(torch.LongTensor([<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0</span>]))\nz <span class=\"pl-k\">=</span> x.index_copy(<span class=\"pl-c1\">0</span>, idx, y)\n<span class=\"pl-c1\">print</span>(z)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note only the last row of y is copied to the first row of z. No other rows of y are used.</span>\nz.backward(torch.ones(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>))\n<span class=\"pl-c1\">print</span>(y.grad)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Incorrectly all ones. Only the last row of y.grad should be non-zero.</span></pre></div>", "body_text": "This happens when the index tensor contains duplicate elements. If this is not allowed index_copy_ should raise an exception when this happens and we should fix the test. Otherwise we need to fix the autograd op.\nHere's an example:\nimport torch\nfrom torch.autograd import *\nx = Variable(torch.zeros(5, 5), requires_grad=True)\nprint(x)\ny = Variable(torch.range(1, 25).view(5, 5), requires_grad=True)\nprint(y)\nidx = Variable(torch.LongTensor([0, 0, 0, 0, 0]))\nz = x.index_copy(0, idx, y)\nprint(z)  # Note only the last row of y is copied to the first row of z. No other rows of y are used.\nz.backward(torch.ones(5, 5))\nprint(y.grad)  # Incorrectly all ones. Only the last row of y.grad should be non-zero.", "body": "This happens when the index tensor contains duplicate elements. If this is not allowed index_copy_ should raise an exception when this happens and we should fix the test. Otherwise we need to fix the autograd op.\r\n\r\nHere's an example:\r\n\r\n```python\r\nimport torch\r\nfrom torch.autograd import *\r\nx = Variable(torch.zeros(5, 5), requires_grad=True)\r\nprint(x)\r\ny = Variable(torch.range(1, 25).view(5, 5), requires_grad=True)\r\nprint(y)\r\nidx = Variable(torch.LongTensor([0, 0, 0, 0, 0]))\r\nz = x.index_copy(0, idx, y)\r\nprint(z)  # Note only the last row of y is copied to the first row of z. No other rows of y are used.\r\nz.backward(torch.ones(5, 5))\r\nprint(y.grad)  # Incorrectly all ones. Only the last row of y.grad should be non-zero.\r\n```\r\n\r\n"}