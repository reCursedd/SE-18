{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11663", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11663/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11663/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11663/events", "html_url": "https://github.com/pytorch/pytorch/issues/11663", "id": 360047251, "node_id": "MDU6SXNzdWUzNjAwNDcyNTE=", "number": 11663, "title": "Scalar division wrongly mutates data type of divisor", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-09-13T20:08:33Z", "updated_at": "2018-09-14T20:41:43Z", "closed_at": "2018-09-14T20:41:43Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>While debugging some JIT issues, I bumped into this issue that causes subtle failures downstream, since we don't expect the data type of the operands to be mutated. It seems to only affect PyTorch scalars. cc.<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a></p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">30</span>]: a, b <span class=\"pl-k\">=</span> torch.tensor(<span class=\"pl-c1\">1</span>), torch.tensor(<span class=\"pl-c1\">2</span>)\n\nIn [<span class=\"pl-c1\">31</span>]: a.type(), a.data.type(), b.type(), b.data.type()\nOut[<span class=\"pl-c1\">31</span>]:\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>)\n\nIn [<span class=\"pl-c1\">32</span>]: a.float() <span class=\"pl-k\">/</span> b\nOut[<span class=\"pl-c1\">32</span>]: tensor(<span class=\"pl-c1\">0.5000</span>)\n\nIn [<span class=\"pl-c1\">33</span>]: a.type(), a.data.type(), b.type(), b.data.type()\nOut[<span class=\"pl-c1\">33</span>]:\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.LongTensor<span class=\"pl-pds\">'</span></span>,\n <span class=\"pl-s\"><span class=\"pl-pds\">'</span>torch.FloatTensor<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> this seems to have been wrongly mutated</span></pre></div>\n<h2>System Info</h2>\n<pre><code>PyTorch version: 0.5.0a0+35d52db\nIs debug build: Yes\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] torch (0.5.0a0+35d52db, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+35d52db           &lt;pip&gt;\n[conda] torchfile                 0.1.0                     &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "Issue description\nWhile debugging some JIT issues, I bumped into this issue that causes subtle failures downstream, since we don't expect the data type of the operands to be mutated. It seems to only affect PyTorch scalars. cc.@apaszke, @soumith\nCode example\nIn [30]: a, b = torch.tensor(1), torch.tensor(2)\n\nIn [31]: a.type(), a.data.type(), b.type(), b.data.type()\nOut[31]:\n('torch.LongTensor',\n 'torch.LongTensor',\n 'torch.LongTensor',\n 'torch.LongTensor')\n\nIn [32]: a.float() / b\nOut[32]: tensor(0.5000)\n\nIn [33]: a.type(), a.data.type(), b.type(), b.data.type()\nOut[33]:\n('torch.LongTensor',\n 'torch.LongTensor',\n 'torch.LongTensor',\n 'torch.FloatTensor')  # this seems to have been wrongly mutated\nSystem Info\nPyTorch version: 0.5.0a0+35d52db\nIs debug build: Yes\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] torch (0.5.0a0+35d52db, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+35d52db           <pip>\n[conda] torchfile                 0.1.0                     <pip>\n[conda] torchvision               0.2.1                     <pip>", "body": "## Issue description\r\n\r\nWhile debugging some JIT issues, I bumped into this issue that causes subtle failures downstream, since we don't expect the data type of the operands to be mutated. It seems to only affect PyTorch scalars. cc.@apaszke, @soumith \r\n\r\n## Code example\r\n\r\n```python\r\nIn [30]: a, b = torch.tensor(1), torch.tensor(2)\r\n\r\nIn [31]: a.type(), a.data.type(), b.type(), b.data.type()\r\nOut[31]:\r\n('torch.LongTensor',\r\n 'torch.LongTensor',\r\n 'torch.LongTensor',\r\n 'torch.LongTensor')\r\n\r\nIn [32]: a.float() / b\r\nOut[32]: tensor(0.5000)\r\n\r\nIn [33]: a.type(), a.data.type(), b.type(), b.data.type()\r\nOut[33]:\r\n('torch.LongTensor',\r\n 'torch.LongTensor',\r\n 'torch.LongTensor',\r\n 'torch.FloatTensor')  # this seems to have been wrongly mutated\r\n```\r\n\r\n## System Info\r\n```\r\nPyTorch version: 0.5.0a0+35d52db\r\nIs debug build: Yes\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.0)\r\n[pip] torch (0.5.0a0+35d52db, /Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages)\r\n[pip] torchfile (0.1.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] torch                     0.5.0a0+35d52db           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```\r\n\r\n"}