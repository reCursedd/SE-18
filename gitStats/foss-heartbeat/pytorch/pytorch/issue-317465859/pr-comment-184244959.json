{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184244959", "pull_request_review_id": 115401016, "id": 184244959, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NDI0NDk1OQ==", "diff_hunk": "@@ -0,0 +1,117 @@\n+r\"\"\"Spectral Normalization from https://arxiv.org/abs/1802.05957\"\"\"\n+import torch\n+from torch.nn.parameter import Parameter\n+\n+\n+def l2normalize(v, eps=1e-12):\n+    \"\"\"Scale to inputs norm to 1.\"\"\"\n+    denom = v.norm(p=2) + eps\n+    return v / denom\n+\n+\n+class SpectralNorm(object):", "path": "torch/nn/utils/spectral_norm.py", "position": null, "original_position": 12, "commit_id": "540b4b5dc6f80a93950d7b1a4c113a4536267b83", "original_commit_id": "f97e236303e0d1db1c3d718a0823c98a987e31c8", "user": {"login": "crcrpar", "id": 16191443, "node_id": "MDQ6VXNlcjE2MTkxNDQz", "avatar_url": "https://avatars2.githubusercontent.com/u/16191443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crcrpar", "html_url": "https://github.com/crcrpar", "followers_url": "https://api.github.com/users/crcrpar/followers", "following_url": "https://api.github.com/users/crcrpar/following{/other_user}", "gists_url": "https://api.github.com/users/crcrpar/gists{/gist_id}", "starred_url": "https://api.github.com/users/crcrpar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crcrpar/subscriptions", "organizations_url": "https://api.github.com/users/crcrpar/orgs", "repos_url": "https://api.github.com/users/crcrpar/repos", "events_url": "https://api.github.com/users/crcrpar/events{/privacy}", "received_events_url": "https://api.github.com/users/crcrpar/received_events", "type": "User", "site_admin": false}, "body": "This normalizes weights of layers, not outputs of layers.\r\nSo, I think it's preferable to implement like `WeightNorm` for flexibility.", "created_at": "2018-04-26T00:47:24Z", "updated_at": "2018-11-23T15:43:12Z", "html_url": "https://github.com/pytorch/pytorch/pull/6929#discussion_r184244959", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6929", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/184244959"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6929#discussion_r184244959"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6929"}}, "body_html": "<p>This normalizes weights of layers, not outputs of layers.<br>\nSo, I think it's preferable to implement like <code>WeightNorm</code> for flexibility.</p>", "body_text": "This normalizes weights of layers, not outputs of layers.\nSo, I think it's preferable to implement like WeightNorm for flexibility.", "in_reply_to_id": 184177664}