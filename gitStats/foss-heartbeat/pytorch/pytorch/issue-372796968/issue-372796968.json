{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12978", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12978/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12978/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12978/events", "html_url": "https://github.com/pytorch/pytorch/issues/12978", "id": 372796968, "node_id": "MDU6SXNzdWUzNzI3OTY5Njg=", "number": 12978, "title": "CPU Fusion compiler fails on NVIDIA AGX Xavier", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-23T03:52:33Z", "updated_at": "2018-10-23T19:22:28Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<pre><code>======================================================================\nERROR: test_ge_optimized (__main__.TestJit)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test_jit.py\", line 200, in wrapper\n    fn(*args, **kwargs)\n  File \"test_jit.py\", line 1423, in test_ge_optimized\n    self.run_ge_tests(True, False)\n  File \"test_jit.py\", line 1397, in run_ge_tests\n    optimize=optimize)\n  File \"test_jit.py\", line 297, in checkTrace\n    ge = torch.jit.trace(func, input_tensors, optimize=optimize, check_tolerance=check_tolerance)\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 572, in trace\n    _check_trace([example_inputs], func, executor_options, module, check_tolerance)\n  File \"/home/nvidia/code/pytorch/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\n    return func(*args, **kwargs)\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 474, in _check_trace\n    traced_outs = run_mod_and_filter_tensor_outputs(module, inputs, 'trace')\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 443, in run_mod_and_filter_tensor_outputs\n    ' with test inputs.\\nException:\\n' + indent(str(e)))\nTracingCheckError: Tracing failed sanity checks!\nEncountered an exception while running the trace with test inputs.\nException:\n        Failed to compile a fused CPU kernel (runCompiler at /home/nvidia/code/pytorch/torch/csrc/jit/fusers/cpu/fused_kernel.cpp:56)\n        frame #0: &lt;unknown function&gt; + 0x5dc044 (0x7f5fdde044 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #1: torch::jit::cpufuser::CPUFusedKernel::CPUFusedKernel(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, torch::jit::AnnotatedGraph&amp;, torch::jit::cpufuser::CPUFusionCompilerConfig&amp;)\n+ 0xe2c (0x7f5fddf74c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #2: torch::jit::FusionHandleImpl::compileSpec(torch::jit::FusionArgSpec const&amp;, std::vector&lt;long, std::allocator&lt;long&gt; &gt; const&amp;) + 0x8c4 (0x7f5fdcc6ec in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #3: torch::jit::FusionHandleImpl::run(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) + 0x2b8 (0x7f5fdcdd78 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #4: &lt;unknown function&gt; + 0x532a3c (0x7f5fd34a3c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #5: &lt;unknown function&gt; + 0x4b7fd0 (0x7f5fcb9fd0 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #6: &lt;unknown function&gt; + 0x4a2e98 (0x7f5fca4e98 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #7: &lt;unknown function&gt; + 0x3defc4 (0x7f70f11fc4 in /home/nvidia/code/pytorch/torch/_C.so)\n        frame #8: &lt;unknown function&gt; + 0x3c0cd4 (0x7f70ef3cd4 in /home/nvidia/code/pytorch/torch/_C.so)\n        frame #9: &lt;unknown function&gt; + 0x11bed4 (0x7f70c4eed4 in /home/nvidia/code/pytorch/torch/_C.so)\n        &lt;omitting python frames&gt;\n</code></pre>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<ol>\n<li>Run <code>test_jit.py</code></li>\n</ol>\n<h2>Environment</h2>\n<ul>\n<li>\n<p>PyTorch version: 1.0.0a0+01227f3</p>\n</li>\n<li>\n<p>Is debug build: No</p>\n</li>\n<li>\n<p>CUDA used to build PyTorch: 10.0.117</p>\n</li>\n<li>\n<p>OS: Ubuntu 18.04 LTS</p>\n</li>\n<li>\n<p>GCC version: (Ubuntu/Linaro 7.3.0-27ubuntu1~18.04) 7.3.0</p>\n</li>\n<li>\n<p>CMake version: version 3.10.2</p>\n</li>\n<li>\n<p>Python version: 2.7</p>\n</li>\n<li>\n<p>Is CUDA available: Yes</p>\n</li>\n<li>\n<p>CUDA runtime version: 10.0.117</p>\n</li>\n<li>\n<p>GPU models and configuration: Could not collect</p>\n</li>\n<li>\n<p>Nvidia driver version: Could not collect</p>\n</li>\n<li>\n<p>cuDNN version: Probably one of the following:</p>\n<ul>\n<li>/usr/lib/aarch64-linux-gnu/libcudnn.so.7.3.0</li>\n<li>/usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a</li>\n</ul>\n</li>\n</ul>\n<p>Versions of relevant libraries:</p>\n<ul>\n<li>[pip] Could not collect</li>\n<li>[conda] Could not collect</li>\n</ul>", "body_text": "\ud83d\udc1b Bug\n======================================================================\nERROR: test_ge_optimized (__main__.TestJit)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"test_jit.py\", line 200, in wrapper\n    fn(*args, **kwargs)\n  File \"test_jit.py\", line 1423, in test_ge_optimized\n    self.run_ge_tests(True, False)\n  File \"test_jit.py\", line 1397, in run_ge_tests\n    optimize=optimize)\n  File \"test_jit.py\", line 297, in checkTrace\n    ge = torch.jit.trace(func, input_tensors, optimize=optimize, check_tolerance=check_tolerance)\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 572, in trace\n    _check_trace([example_inputs], func, executor_options, module, check_tolerance)\n  File \"/home/nvidia/code/pytorch/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\n    return func(*args, **kwargs)\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 474, in _check_trace\n    traced_outs = run_mod_and_filter_tensor_outputs(module, inputs, 'trace')\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 443, in run_mod_and_filter_tensor_outputs\n    ' with test inputs.\\nException:\\n' + indent(str(e)))\nTracingCheckError: Tracing failed sanity checks!\nEncountered an exception while running the trace with test inputs.\nException:\n        Failed to compile a fused CPU kernel (runCompiler at /home/nvidia/code/pytorch/torch/csrc/jit/fusers/cpu/fused_kernel.cpp:56)\n        frame #0: <unknown function> + 0x5dc044 (0x7f5fdde044 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #1: torch::jit::cpufuser::CPUFusedKernel::CPUFusedKernel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, torch::jit::AnnotatedGraph&, torch::jit::cpufuser::CPUFusionCompilerConfig&)\n+ 0xe2c (0x7f5fddf74c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #2: torch::jit::FusionHandleImpl::compileSpec(torch::jit::FusionArgSpec const&, std::vector<long, std::allocator<long> > const&) + 0x8c4 (0x7f5fdcc6ec in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #3: torch::jit::FusionHandleImpl::run(std::vector<c10::IValue, std::allocator<c10::IValue> >&) + 0x2b8 (0x7f5fdcdd78 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #4: <unknown function> + 0x532a3c (0x7f5fd34a3c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #5: <unknown function> + 0x4b7fd0 (0x7f5fcb9fd0 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #6: <unknown function> + 0x4a2e98 (0x7f5fca4e98 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\n        frame #7: <unknown function> + 0x3defc4 (0x7f70f11fc4 in /home/nvidia/code/pytorch/torch/_C.so)\n        frame #8: <unknown function> + 0x3c0cd4 (0x7f70ef3cd4 in /home/nvidia/code/pytorch/torch/_C.so)\n        frame #9: <unknown function> + 0x11bed4 (0x7f70c4eed4 in /home/nvidia/code/pytorch/torch/_C.so)\n        <omitting python frames>\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nRun test_jit.py\n\nEnvironment\n\n\nPyTorch version: 1.0.0a0+01227f3\n\n\nIs debug build: No\n\n\nCUDA used to build PyTorch: 10.0.117\n\n\nOS: Ubuntu 18.04 LTS\n\n\nGCC version: (Ubuntu/Linaro 7.3.0-27ubuntu1~18.04) 7.3.0\n\n\nCMake version: version 3.10.2\n\n\nPython version: 2.7\n\n\nIs CUDA available: Yes\n\n\nCUDA runtime version: 10.0.117\n\n\nGPU models and configuration: Could not collect\n\n\nNvidia driver version: Could not collect\n\n\ncuDNN version: Probably one of the following:\n\n/usr/lib/aarch64-linux-gnu/libcudnn.so.7.3.0\n/usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a\n\n\n\nVersions of relevant libraries:\n\n[pip] Could not collect\n[conda] Could not collect", "body": "## \ud83d\udc1b Bug\r\n\r\n```\r\n======================================================================\r\nERROR: test_ge_optimized (__main__.TestJit)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"test_jit.py\", line 200, in wrapper\r\n    fn(*args, **kwargs)\r\n  File \"test_jit.py\", line 1423, in test_ge_optimized\r\n    self.run_ge_tests(True, False)\r\n  File \"test_jit.py\", line 1397, in run_ge_tests\r\n    optimize=optimize)\r\n  File \"test_jit.py\", line 297, in checkTrace\r\n    ge = torch.jit.trace(func, input_tensors, optimize=optimize, check_tolerance=check_tolerance)\r\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 572, in trace\r\n    _check_trace([example_inputs], func, executor_options, module, check_tolerance)\r\n  File \"/home/nvidia/code/pytorch/torch/autograd/grad_mode.py\", line 43, in decorate_no_grad\r\n    return func(*args, **kwargs)\r\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 474, in _check_trace\r\n    traced_outs = run_mod_and_filter_tensor_outputs(module, inputs, 'trace')\r\n  File \"/home/nvidia/code/pytorch/torch/jit/__init__.py\", line 443, in run_mod_and_filter_tensor_outputs\r\n    ' with test inputs.\\nException:\\n' + indent(str(e)))\r\nTracingCheckError: Tracing failed sanity checks!\r\nEncountered an exception while running the trace with test inputs.\r\nException:\r\n        Failed to compile a fused CPU kernel (runCompiler at /home/nvidia/code/pytorch/torch/csrc/jit/fusers/cpu/fused_kernel.cpp:56)\r\n        frame #0: <unknown function> + 0x5dc044 (0x7f5fdde044 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #1: torch::jit::cpufuser::CPUFusedKernel::CPUFusedKernel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, torch::jit::AnnotatedGraph&, torch::jit::cpufuser::CPUFusionCompilerConfig&)\r\n+ 0xe2c (0x7f5fddf74c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #2: torch::jit::FusionHandleImpl::compileSpec(torch::jit::FusionArgSpec const&, std::vector<long, std::allocator<long> > const&) + 0x8c4 (0x7f5fdcc6ec in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #3: torch::jit::FusionHandleImpl::run(std::vector<c10::IValue, std::allocator<c10::IValue> >&) + 0x2b8 (0x7f5fdcdd78 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #4: <unknown function> + 0x532a3c (0x7f5fd34a3c in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #5: <unknown function> + 0x4b7fd0 (0x7f5fcb9fd0 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #6: <unknown function> + 0x4a2e98 (0x7f5fca4e98 in /home/nvidia/code/pytorch/torch/lib/libtorch.so.1)\r\n        frame #7: <unknown function> + 0x3defc4 (0x7f70f11fc4 in /home/nvidia/code/pytorch/torch/_C.so)\r\n        frame #8: <unknown function> + 0x3c0cd4 (0x7f70ef3cd4 in /home/nvidia/code/pytorch/torch/_C.so)\r\n        frame #9: <unknown function> + 0x11bed4 (0x7f70c4eed4 in /home/nvidia/code/pytorch/torch/_C.so)\r\n        <omitting python frames>\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run `test_jit.py`\r\n\r\n\r\n## Environment\r\n\r\n- PyTorch version: 1.0.0a0+01227f3\r\n- Is debug build: No\r\n- CUDA used to build PyTorch: 10.0.117\r\n\r\n- OS: Ubuntu 18.04 LTS\r\n- GCC version: (Ubuntu/Linaro 7.3.0-27ubuntu1~18.04) 7.3.0\r\n- CMake version: version 3.10.2\r\n\r\n- Python version: 2.7\r\n- Is CUDA available: Yes\r\n- CUDA runtime version: 10.0.117\r\n- GPU models and configuration: Could not collect\r\n- Nvidia driver version: Could not collect\r\n- cuDNN version: Probably one of the following:\r\n    - /usr/lib/aarch64-linux-gnu/libcudnn.so.7.3.0\r\n    - /usr/lib/aarch64-linux-gnu/libcudnn_static_v7.a\r\n\r\nVersions of relevant libraries:\r\n- [pip] Could not collect\r\n- [conda] Could not collect"}