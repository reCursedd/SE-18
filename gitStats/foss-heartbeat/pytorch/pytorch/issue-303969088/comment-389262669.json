{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/389262669", "html_url": "https://github.com/pytorch/pytorch/issues/5672#issuecomment-389262669", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5672", "id": 389262669, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTI2MjY2OQ==", "user": {"login": "juniorrojas", "id": 2767767, "node_id": "MDQ6VXNlcjI3Njc3Njc=", "avatar_url": "https://avatars3.githubusercontent.com/u/2767767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juniorrojas", "html_url": "https://github.com/juniorrojas", "followers_url": "https://api.github.com/users/juniorrojas/followers", "following_url": "https://api.github.com/users/juniorrojas/following{/other_user}", "gists_url": "https://api.github.com/users/juniorrojas/gists{/gist_id}", "starred_url": "https://api.github.com/users/juniorrojas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juniorrojas/subscriptions", "organizations_url": "https://api.github.com/users/juniorrojas/orgs", "repos_url": "https://api.github.com/users/juniorrojas/repos", "events_url": "https://api.github.com/users/juniorrojas/events{/privacy}", "received_events_url": "https://api.github.com/users/juniorrojas/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-15T18:13:36Z", "updated_at": "2018-05-15T18:13:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is an example that computes a 2x2x2 sparse (<code>a</code>) - dense (<code>b</code>) bmm using a python array to store the sparse matrices. The expected output is a dense tensor. As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> said, the ideal implementation would encode the batch of sparse matrices using a pytorch tensor where only the first dimension is dense, but I'm not sure either if pytorch currently supports that.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\na1 <span class=\"pl-k\">=</span> torch.sparse.FloatTensor(\n    torch.LongTensor([\n        [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n        [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>]\n    ]),\n    torch.FloatTensor([\n        <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>\n    ]),\n    torch.Size([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>])\n)\na2 <span class=\"pl-k\">=</span> torch.sparse.FloatTensor(\n    torch.LongTensor([\n        [<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>],\n        [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>]\n    ]),\n    torch.FloatTensor([\n        <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>\n    ]),\n    torch.Size([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>])\n)\na <span class=\"pl-k\">=</span> [a1, a2]\n\nb <span class=\"pl-k\">=</span> torch.FloatTensor([\n    [\n        [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>],\n        [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>]\n    ],\n    [\n        [<span class=\"pl-c1\">3</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">4</span>],\n        [<span class=\"pl-c1\">1</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">9</span>]\n    ]\n])\n\nab <span class=\"pl-k\">=</span> torch.stack([ai.mm(bi) <span class=\"pl-k\">for</span> ai, bi <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(a, b)])\n<span class=\"pl-c1\">print</span>(ab)</pre></div>", "body_text": "This is an example that computes a 2x2x2 sparse (a) - dense (b) bmm using a python array to store the sparse matrices. The expected output is a dense tensor. As @zou3519 said, the ideal implementation would encode the batch of sparse matrices using a pytorch tensor where only the first dimension is dense, but I'm not sure either if pytorch currently supports that.\nimport torch\n\na1 = torch.sparse.FloatTensor(\n    torch.LongTensor([\n        [0, 1],\n        [0, 1]\n    ]),\n    torch.FloatTensor([\n        3, 4\n    ]),\n    torch.Size([2, 2])\n)\na2 = torch.sparse.FloatTensor(\n    torch.LongTensor([\n        [0, 1],\n        [1, 0]\n    ]),\n    torch.FloatTensor([\n        2, 1\n    ]),\n    torch.Size([2, 2])\n)\na = [a1, a2]\n\nb = torch.FloatTensor([\n    [\n        [2, 1],\n        [1, 4]\n    ],\n    [\n        [3, -4],\n        [1, -9]\n    ]\n])\n\nab = torch.stack([ai.mm(bi) for ai, bi in zip(a, b)])\nprint(ab)", "body": "This is an example that computes a 2x2x2 sparse (`a`) - dense (`b`) bmm using a python array to store the sparse matrices. The expected output is a dense tensor. As @zou3519 said, the ideal implementation would encode the batch of sparse matrices using a pytorch tensor where only the first dimension is dense, but I'm not sure either if pytorch currently supports that.\r\n\r\n```py\r\nimport torch\r\n\r\na1 = torch.sparse.FloatTensor(\r\n    torch.LongTensor([\r\n        [0, 1],\r\n        [0, 1]\r\n    ]),\r\n    torch.FloatTensor([\r\n        3, 4\r\n    ]),\r\n    torch.Size([2, 2])\r\n)\r\na2 = torch.sparse.FloatTensor(\r\n    torch.LongTensor([\r\n        [0, 1],\r\n        [1, 0]\r\n    ]),\r\n    torch.FloatTensor([\r\n        2, 1\r\n    ]),\r\n    torch.Size([2, 2])\r\n)\r\na = [a1, a2]\r\n\r\nb = torch.FloatTensor([\r\n    [\r\n        [2, 1],\r\n        [1, 4]\r\n    ],\r\n    [\r\n        [3, -4],\r\n        [1, -9]\r\n    ]\r\n])\r\n\r\nab = torch.stack([ai.mm(bi) for ai, bi in zip(a, b)])\r\nprint(ab)\r\n```"}