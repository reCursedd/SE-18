{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6516", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6516/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6516/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6516/events", "html_url": "https://github.com/pytorch/pytorch/issues/6516", "id": 313456067, "node_id": "MDU6SXNzdWUzMTM0NTYwNjc=", "number": 6516, "title": "[feature request] Multiple batch dimensions for torch.rfft", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}], "state": "closed", "locked": false, "assignee": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-04-11T19:26:22Z", "updated_at": "2018-04-12T19:05:39Z", "closed_at": "2018-04-12T19:05:28Z", "author_association": "NONE", "body_html": "<p>I think it makes sense, since <code>signal_ndim</code> is explicit and is always required.</p>\n<div class=\"highlight highlight-source-python\"><pre>torch.rfft(torch.Tensor(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>).cuda(), <span class=\"pl-v\">signal_ndim</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> works</span>\ntorch.rfft(torch.Tensor(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>).cuda(), <span class=\"pl-v\">signal_ndim</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> RuntimeError: Given signal_ndim=1, expected an input tensor of 1D or 2D (batch mode), but got input torch.cuda.FloatTensor[2, 4, 5]</span></pre></div>", "body_text": "I think it makes sense, since signal_ndim is explicit and is always required.\ntorch.rfft(torch.Tensor(2, 4).cuda(), signal_ndim = 1) # works\ntorch.rfft(torch.Tensor(2, 4, 5).cuda(), signal_ndim = 1)\n# RuntimeError: Given signal_ndim=1, expected an input tensor of 1D or 2D (batch mode), but got input torch.cuda.FloatTensor[2, 4, 5]", "body": "I think it makes sense, since `signal_ndim` is explicit and is always required.\r\n```python\r\ntorch.rfft(torch.Tensor(2, 4).cuda(), signal_ndim = 1) # works\r\ntorch.rfft(torch.Tensor(2, 4, 5).cuda(), signal_ndim = 1)\r\n# RuntimeError: Given signal_ndim=1, expected an input tensor of 1D or 2D (batch mode), but got input torch.cuda.FloatTensor[2, 4, 5]\r\n```"}