{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4858", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4858/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4858/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4858/events", "html_url": "https://github.com/pytorch/pytorch/issues/4858", "id": 291717947, "node_id": "MDU6SXNzdWUyOTE3MTc5NDc=", "number": 4858, "title": "CUDA multinomial with replacement can select zero-probability events", "user": {"login": "coventry", "id": 70152, "node_id": "MDQ6VXNlcjcwMTUy", "avatar_url": "https://avatars0.githubusercontent.com/u/70152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/coventry", "html_url": "https://github.com/coventry", "followers_url": "https://api.github.com/users/coventry/followers", "following_url": "https://api.github.com/users/coventry/following{/other_user}", "gists_url": "https://api.github.com/users/coventry/gists{/gist_id}", "starred_url": "https://api.github.com/users/coventry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/coventry/subscriptions", "organizations_url": "https://api.github.com/users/coventry/orgs", "repos_url": "https://api.github.com/users/coventry/repos", "events_url": "https://api.github.com/users/coventry/events{/privacy}", "received_events_url": "https://api.github.com/users/coventry/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2018-01-25T21:14:48Z", "updated_at": "2018-08-15T20:26:50Z", "closed_at": "2018-08-15T20:26:50Z", "author_association": "NONE", "body_html": "<p>I'm running Ubuntu 16.04.3 on an AWS P3.2xlarge, with the NVIDIA libcuda1-384 package, version 384.111-0ubuntu0.16.04.1, and pytorch version 0.3.0.post4 and cuda90, installed via conda.</p>\n<p>In some circumstances, the CUDA multinomial sampler with <code>replacement=True</code> can sample an event with zero probability.</p>\n<p>The script below reproduces this. I haven't tried to reduce the distribution to a minimal case.  The output is below the script.</p>\n<p>I've attached <a href=\"https://github.com/pytorch/pytorch/files/1665704/failed_state.pt.gz\">the RNG state</a> just prior to the failure. Reproduction from this state is demonstrated in the script.</p>\n<p>Bests regards,<br>\nAlex</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch <span class=\"pl-k\">as</span> T\n<span class=\"pl-k\">import</span> os\n\nfreqs <span class=\"pl-k\">=</span> T.cuda.FloatTensor([\n    <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>,\n    <span class=\"pl-c1\">0.03178183361887932</span>, <span class=\"pl-c1\">0.027680952101945877</span>, <span class=\"pl-c1\">0.033176131546497345</span>,\n    <span class=\"pl-c1\">0.046052902936935425</span>, <span class=\"pl-c1\">0.07742464542388916</span>, <span class=\"pl-c1\">0.11543981730937958</span>,\n    <span class=\"pl-c1\">0.14148041605949402</span>, <span class=\"pl-c1\">0.15784293413162231</span>, <span class=\"pl-c1\">0.13180233538150787</span>,\n    <span class=\"pl-c1\">0.08271478116512299</span>, <span class=\"pl-c1\">0.049702685326337814</span>, <span class=\"pl-c1\">0.027557924389839172</span>,\n    <span class=\"pl-c1\">0.018125897273421288</span>, <span class=\"pl-c1\">0.011851548217236996</span>, <span class=\"pl-c1\">0.010252203792333603</span>,\n    <span class=\"pl-c1\">0.007422595750540495</span>, <span class=\"pl-c1\">0.005372154992073774</span>, <span class=\"pl-c1\">0.0045109698548913</span>,\n    <span class=\"pl-c1\">0.0036087757907807827</span>, <span class=\"pl-c1\">0.0035267581697553396</span>, <span class=\"pl-c1\">0.0018864056328311563</span>,\n    <span class=\"pl-c1\">0.0024605290964245796</span>, <span class=\"pl-c1\">0.0022964938543736935</span>, <span class=\"pl-c1\">0.0018453967059031129</span>,\n    <span class=\"pl-c1\">0.0010662291897460818</span>, <span class=\"pl-c1\">0.0009842115687206388</span>, <span class=\"pl-c1\">0.00045109697384759784</span>,\n    <span class=\"pl-c1\">0.0007791675161570311</span>, <span class=\"pl-c1\">0.00020504408166743815</span>, <span class=\"pl-c1\">0.00020504408166743815</span>,\n    <span class=\"pl-c1\">0.00020504408166743815</span>, <span class=\"pl-c1\">0.00012302644609007984</span>, <span class=\"pl-c1\">0.0</span>,\n    <span class=\"pl-c1\">0.00012302644609007984</span>, <span class=\"pl-c1\">4.100881778867915e-05</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>,\n    <span class=\"pl-c1\">0.0</span>, <span class=\"pl-c1\">0.0</span>])\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1_000_000_000</span>):\n    state <span class=\"pl-k\">=</span> T.cuda.get_rng_state()\n    sample <span class=\"pl-k\">=</span> T.multinomial(freqs, <span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">True</span>)\n    <span class=\"pl-k\">if</span> freqs[sample].min() <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>:\n        <span class=\"pl-k\">break</span>\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">failure after </span><span class=\"pl-c1\">{</span>i<span class=\"pl-c1\">}</span><span class=\"pl-s\"> iterations</span><span class=\"pl-pds\">'</span>)\nsample_idx <span class=\"pl-k\">=</span> (freqs[sample] <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>).nonzero()[<span class=\"pl-c1\">0</span>][<span class=\"pl-c1\">0</span>]\nsampled <span class=\"pl-k\">=</span> sample[sample_idx]\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{</span>sample_idx<span class=\"pl-c1\">}</span><span class=\"pl-s\">th element of last sample was </span><span class=\"pl-c1\">{</span>sampled<span class=\"pl-c1\">}</span><span class=\"pl-s\">, </span><span class=\"pl-pds\">'</span>\n      <span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-s\">which has probability </span><span class=\"pl-c1\">{</span>freqs[sampled]<span class=\"pl-c1\">}</span><span class=\"pl-pds\">'</span>)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">SAVE_PATH</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>failed_state.pt<span class=\"pl-pds\">'</span></span>\nT.save(state, <span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">SAVE_PATH</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>wb<span class=\"pl-pds\">'</span></span>))\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-s\">RNG state saved to `</span><span class=\"pl-c1\">{</span><span class=\"pl-c1\">SAVE_PATH</span><span class=\"pl-c1\">}</span><span class=\"pl-s\">`</span><span class=\"pl-pds\">'</span>)\n\nT.cuda.set_rng_state(T.load(<span class=\"pl-c1\">open</span>(<span class=\"pl-c1\">SAVE_PATH</span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>)))\n<span class=\"pl-k\">assert</span> freqs[T.multinomial(freqs, <span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">True</span>)].min() <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\">f</span><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span><span class=\"pl-s\">pytorch version: </span><span class=\"pl-c1\">{</span>T.<span class=\"pl-c1\">__version__</span><span class=\"pl-c1\">}</span><span class=\"pl-cce\">\\n</span><span class=\"pl-pds\">'</span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Operating system:<span class=\"pl-pds\">'</span></span>)\nos.system(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lsb_release -a<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span>GPU information:<span class=\"pl-pds\">'</span></span>)\nos.system(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>nvidia-smi<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">72</span><span class=\"pl-k\">*</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span>)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-cce\">\\n</span>CUDA library information:<span class=\"pl-pds\">'</span></span>)\nos.system(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>dpkg -l | grep -i cuda<span class=\"pl-pds\">'</span></span>)</pre></div>\n<pre><code>ubuntu@ip-172-30-1-60:~/workdir$ python -i fail.py \n------------------------------------------------------------------------\nfailure after 4309 iterations\n631th element of last sample was 0, which has probability 0.0\n------------------------------------------------------------------------\n\nRNG state saved to `failed_state.pt`\n------------------------------------------------------------------------\n\npytorch version: 0.3.0.post4\n\n------------------------------------------------------------------------\nOperating system:\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.3 LTS\nRelease:        16.04\nCodename:       xenial\n------------------------------------------------------------------------\n\nGPU information:\nThu Jan 25 21:17:03 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n| N/A   38C    P0    46W / 300W |   4558MiB / 16152MiB |     31%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0       988      C   python                                       738MiB |\n|    0     15193      C   python                                      3810MiB |\n+-----------------------------------------------------------------------------+\n------------------------------------------------------------------------\n\nCUDA library information:\nii  libcuda1-384                                    384.111-0ubuntu0.16.04.1     amd64                        NVIDIA CUDA runtime library\n</code></pre>", "body_text": "I'm running Ubuntu 16.04.3 on an AWS P3.2xlarge, with the NVIDIA libcuda1-384 package, version 384.111-0ubuntu0.16.04.1, and pytorch version 0.3.0.post4 and cuda90, installed via conda.\nIn some circumstances, the CUDA multinomial sampler with replacement=True can sample an event with zero probability.\nThe script below reproduces this. I haven't tried to reduce the distribution to a minimal case.  The output is below the script.\nI've attached the RNG state just prior to the failure. Reproduction from this state is demonstrated in the script.\nBests regards,\nAlex\nimport torch as T\nimport os\n\nfreqs = T.cuda.FloatTensor([\n    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n    0.03178183361887932, 0.027680952101945877, 0.033176131546497345,\n    0.046052902936935425, 0.07742464542388916, 0.11543981730937958,\n    0.14148041605949402, 0.15784293413162231, 0.13180233538150787,\n    0.08271478116512299, 0.049702685326337814, 0.027557924389839172,\n    0.018125897273421288, 0.011851548217236996, 0.010252203792333603,\n    0.007422595750540495, 0.005372154992073774, 0.0045109698548913,\n    0.0036087757907807827, 0.0035267581697553396, 0.0018864056328311563,\n    0.0024605290964245796, 0.0022964938543736935, 0.0018453967059031129,\n    0.0010662291897460818, 0.0009842115687206388, 0.00045109697384759784,\n    0.0007791675161570311, 0.00020504408166743815, 0.00020504408166743815,\n    0.00020504408166743815, 0.00012302644609007984, 0.0,\n    0.00012302644609007984, 4.100881778867915e-05, 0.0, 0.0, 0.0, 0.0,\n    0.0, 0.0])\n\nfor i in range(1_000_000_000):\n    state = T.cuda.get_rng_state()\n    sample = T.multinomial(freqs, 1000, True)\n    if freqs[sample].min() == 0:\n        break\n\nprint(72*'-')\nprint(f'failure after {i} iterations')\nsample_idx = (freqs[sample] == 0).nonzero()[0][0]\nsampled = sample[sample_idx]\nprint(f'{sample_idx}th element of last sample was {sampled}, '\n      f'which has probability {freqs[sampled]}')\n\nprint(72*'-')\nSAVE_PATH = 'failed_state.pt'\nT.save(state, open(SAVE_PATH, 'wb'))\nprint(f'\\nRNG state saved to `{SAVE_PATH}`')\n\nT.cuda.set_rng_state(T.load(open(SAVE_PATH, 'rb')))\nassert freqs[T.multinomial(freqs, 1000, True)].min() == 0\n\nprint(72*'-')\nprint(f'\\npytorch version: {T.__version__}\\n')\nprint(72*'-')\nprint('Operating system:')\nos.system('lsb_release -a')\nprint(72*'-')\nprint('\\nGPU information:')\nos.system('nvidia-smi')\nprint(72*'-')\nprint('\\nCUDA library information:')\nos.system('dpkg -l | grep -i cuda')\nubuntu@ip-172-30-1-60:~/workdir$ python -i fail.py \n------------------------------------------------------------------------\nfailure after 4309 iterations\n631th element of last sample was 0, which has probability 0.0\n------------------------------------------------------------------------\n\nRNG state saved to `failed_state.pt`\n------------------------------------------------------------------------\n\npytorch version: 0.3.0.post4\n\n------------------------------------------------------------------------\nOperating system:\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.3 LTS\nRelease:        16.04\nCodename:       xenial\n------------------------------------------------------------------------\n\nGPU information:\nThu Jan 25 21:17:03 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n| N/A   38C    P0    46W / 300W |   4558MiB / 16152MiB |     31%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0       988      C   python                                       738MiB |\n|    0     15193      C   python                                      3810MiB |\n+-----------------------------------------------------------------------------+\n------------------------------------------------------------------------\n\nCUDA library information:\nii  libcuda1-384                                    384.111-0ubuntu0.16.04.1     amd64                        NVIDIA CUDA runtime library", "body": "I'm running Ubuntu 16.04.3 on an AWS P3.2xlarge, with the NVIDIA libcuda1-384 package, version 384.111-0ubuntu0.16.04.1, and pytorch version 0.3.0.post4 and cuda90, installed via conda.\r\n\r\nIn some circumstances, the CUDA multinomial sampler with `replacement=True` can sample an event with zero probability.\r\n\r\nThe script below reproduces this. I haven't tried to reduce the distribution to a minimal case.  The output is below the script.\r\n\r\nI've attached [the RNG state](https://github.com/pytorch/pytorch/files/1665704/failed_state.pt.gz) just prior to the failure. Reproduction from this state is demonstrated in the script.\r\n\r\nBests regards,\r\nAlex\r\n\r\n```python\r\nimport torch as T\r\nimport os\r\n\r\nfreqs = T.cuda.FloatTensor([\r\n    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\r\n    0.03178183361887932, 0.027680952101945877, 0.033176131546497345,\r\n    0.046052902936935425, 0.07742464542388916, 0.11543981730937958,\r\n    0.14148041605949402, 0.15784293413162231, 0.13180233538150787,\r\n    0.08271478116512299, 0.049702685326337814, 0.027557924389839172,\r\n    0.018125897273421288, 0.011851548217236996, 0.010252203792333603,\r\n    0.007422595750540495, 0.005372154992073774, 0.0045109698548913,\r\n    0.0036087757907807827, 0.0035267581697553396, 0.0018864056328311563,\r\n    0.0024605290964245796, 0.0022964938543736935, 0.0018453967059031129,\r\n    0.0010662291897460818, 0.0009842115687206388, 0.00045109697384759784,\r\n    0.0007791675161570311, 0.00020504408166743815, 0.00020504408166743815,\r\n    0.00020504408166743815, 0.00012302644609007984, 0.0,\r\n    0.00012302644609007984, 4.100881778867915e-05, 0.0, 0.0, 0.0, 0.0,\r\n    0.0, 0.0])\r\n\r\nfor i in range(1_000_000_000):\r\n    state = T.cuda.get_rng_state()\r\n    sample = T.multinomial(freqs, 1000, True)\r\n    if freqs[sample].min() == 0:\r\n        break\r\n\r\nprint(72*'-')\r\nprint(f'failure after {i} iterations')\r\nsample_idx = (freqs[sample] == 0).nonzero()[0][0]\r\nsampled = sample[sample_idx]\r\nprint(f'{sample_idx}th element of last sample was {sampled}, '\r\n      f'which has probability {freqs[sampled]}')\r\n\r\nprint(72*'-')\r\nSAVE_PATH = 'failed_state.pt'\r\nT.save(state, open(SAVE_PATH, 'wb'))\r\nprint(f'\\nRNG state saved to `{SAVE_PATH}`')\r\n\r\nT.cuda.set_rng_state(T.load(open(SAVE_PATH, 'rb')))\r\nassert freqs[T.multinomial(freqs, 1000, True)].min() == 0\r\n\r\nprint(72*'-')\r\nprint(f'\\npytorch version: {T.__version__}\\n')\r\nprint(72*'-')\r\nprint('Operating system:')\r\nos.system('lsb_release -a')\r\nprint(72*'-')\r\nprint('\\nGPU information:')\r\nos.system('nvidia-smi')\r\nprint(72*'-')\r\nprint('\\nCUDA library information:')\r\nos.system('dpkg -l | grep -i cuda')\r\n```\r\n\r\n```\r\nubuntu@ip-172-30-1-60:~/workdir$ python -i fail.py \r\n------------------------------------------------------------------------\r\nfailure after 4309 iterations\r\n631th element of last sample was 0, which has probability 0.0\r\n------------------------------------------------------------------------\r\n\r\nRNG state saved to `failed_state.pt`\r\n------------------------------------------------------------------------\r\n\r\npytorch version: 0.3.0.post4\r\n\r\n------------------------------------------------------------------------\r\nOperating system:\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 16.04.3 LTS\r\nRelease:        16.04\r\nCodename:       xenial\r\n------------------------------------------------------------------------\r\n\r\nGPU information:\r\nThu Jan 25 21:17:03 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   38C    P0    46W / 300W |   4558MiB / 16152MiB |     31%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0       988      C   python                                       738MiB |\r\n|    0     15193      C   python                                      3810MiB |\r\n+-----------------------------------------------------------------------------+\r\n------------------------------------------------------------------------\r\n\r\nCUDA library information:\r\nii  libcuda1-384                                    384.111-0ubuntu0.16.04.1     amd64                        NVIDIA CUDA runtime library\r\n```"}