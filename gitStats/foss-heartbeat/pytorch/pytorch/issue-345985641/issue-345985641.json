{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10041", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10041/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10041/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10041/events", "html_url": "https://github.com/pytorch/pytorch/issues/10041", "id": 345985641, "node_id": "MDU6SXNzdWUzNDU5ODU2NDE=", "number": 10041, "title": "[JIT] Support torch.distributions.utils.broadcast_all()", "user": {"login": "fritzo", "id": 648532, "node_id": "MDQ6VXNlcjY0ODUzMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/648532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fritzo", "html_url": "https://github.com/fritzo", "followers_url": "https://api.github.com/users/fritzo/followers", "following_url": "https://api.github.com/users/fritzo/following{/other_user}", "gists_url": "https://api.github.com/users/fritzo/gists{/gist_id}", "starred_url": "https://api.github.com/users/fritzo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fritzo/subscriptions", "organizations_url": "https://api.github.com/users/fritzo/orgs", "repos_url": "https://api.github.com/users/fritzo/repos", "events_url": "https://api.github.com/users/fritzo/events{/privacy}", "received_events_url": "https://api.github.com/users/fritzo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-31T00:13:40Z", "updated_at": "2018-08-02T02:19:30Z", "closed_at": "2018-08-02T02:19:30Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Problem</h2>\n<p>The main blocker to using torch.distributions in the JIT is the <code>broadcast_all()</code> function that is used in every distribution's <code>__init__()</code> method. Currently <code>broadcast_all()</code> calls <code>torch._C._infer_size()</code> under the hood, which results in a JIT error</p>\n<pre><code>RuntimeError: expected int at position 0, but got: Tensor\n</code></pre>\n<p>An expensive workaround is to replace the non-jittable <code>torch._C._infer_size()</code> invocation with a <code>torch.sum(*values).size()</code> which is jittable, roughly</p>\n<div class=\"highlight highlight-source-diff\"><pre><span class=\"pl-md\"><span class=\"pl-md\">-</span> broadcast_shape = torch.Size()</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span> for i in tensor_idxs:</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>     broadcast_shape = torch._C._infer_size(values[i].shape, broadcast_shape)</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span> broadcast_shape = sum(values).shape    # expensive workaround</span></pre></div>\n<h2>Proposed solution</h2>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1762463\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/neerajprad\">@neerajprad</a> suggested implementing a C++ version of <code>broadcast_all()</code>, which would have the added benefit of speeding up non-jitted code.</p>", "body_text": "Problem\nThe main blocker to using torch.distributions in the JIT is the broadcast_all() function that is used in every distribution's __init__() method. Currently broadcast_all() calls torch._C._infer_size() under the hood, which results in a JIT error\nRuntimeError: expected int at position 0, but got: Tensor\n\nAn expensive workaround is to replace the non-jittable torch._C._infer_size() invocation with a torch.sum(*values).size() which is jittable, roughly\n- broadcast_shape = torch.Size()\n- for i in tensor_idxs:\n-     broadcast_shape = torch._C._infer_size(values[i].shape, broadcast_shape)\n+ broadcast_shape = sum(values).shape    # expensive workaround\nProposed solution\n@soumith and @neerajprad suggested implementing a C++ version of broadcast_all(), which would have the added benefit of speeding up non-jitted code.", "body": "## Problem\r\n\r\nThe main blocker to using torch.distributions in the JIT is the `broadcast_all()` function that is used in every distribution's `__init__()` method. Currently `broadcast_all()` calls `torch._C._infer_size()` under the hood, which results in a JIT error\r\n```\r\nRuntimeError: expected int at position 0, but got: Tensor\r\n```\r\nAn expensive workaround is to replace the non-jittable `torch._C._infer_size()` invocation with a `torch.sum(*values).size()` which is jittable, roughly\r\n```diff\r\n- broadcast_shape = torch.Size()\r\n- for i in tensor_idxs:\r\n-     broadcast_shape = torch._C._infer_size(values[i].shape, broadcast_shape)\r\n+ broadcast_shape = sum(values).shape    # expensive workaround\r\n```\r\n\r\n## Proposed solution\r\n\r\n@soumith and @neerajprad suggested implementing a C++ version of `broadcast_all()`, which would have the added benefit of speeding up non-jitted code."}