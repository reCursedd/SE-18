{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215982094", "pull_request_review_id": 153371633, "id": 215982094, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNTk4MjA5NA==", "diff_hunk": "@@ -46,14 +65,83 @@ struct AT_CORE_API LegacyTypeDeleter {\n class AT_CORE_API LegacyTypeDispatch {\n public:\n   using TypeUniquePtr = std::unique_ptr<Type, LegacyTypeDeleter>;\n+  // WARNING: This function has the precondition that you have\n+  // initialized the type you want to call.  This initialization\n+  // step is generally done by Context, or assumed because you\n+  // have a Tensor and thus the Type of that Tensor must already\n+  // be initialized.\n   Type* getNonVariableTypeRaw(Backend p, ScalarType s) {\n     return type_registry[static_cast<int>(p)][static_cast<int>(s)].get();\n   }\n+  Type * getNonVariableTypeOpt(Backend p, ScalarType s) {\n+    if (p != Backend::Undefined) {\n+      initBackendIfNeeded(backendToDeviceType(p));\n+      initComplexIfNeeded(s);\n+    }\n+    auto type = getNonVariableTypeRaw(p, s);\n+\n+    if(!type) {\n+      // there is only a single Undefined Type.\n+      if (p == Backend::Undefined || s == ScalarType::Undefined) {\n+        return getNonVariableTypeRaw(Backend::Undefined, ScalarType::Undefined);\n+      }\n+    }\n+\n+    return type;\n+  }\n+\n+  Type & getNonVariableType(Backend p, ScalarType s) {\n+    auto* type = getNonVariableTypeOpt(p, s);\n+    if (!type) AT_ERROR(toString(p), toString(s), \"Type is not enabled.\");\n+    return *type;\n+  }\n+\n+  Type* getTypeRaw(Backend p, ScalarType s, bool is_variable) {\n+    auto baseType = getNonVariableTypeRaw(p, s);\n+    if (is_variable) {\n+      return &detail::getVariableHooks().getVariableTypeFromBaseType(*baseType);\n+    } else {\n+      return baseType;\n+    }\n+  }\n+  Type & getVariableType(Backend p, ScalarType s) {\n+    auto& baseType = getNonVariableType(p, s);\n+    return detail::getVariableHooks().getVariableTypeFromBaseType(baseType);\n+  }\n+  Type & getType(Backend p, ScalarType s, bool is_variable) {\n+    if (is_variable) {\n+      return getVariableType(p, s);\n+    } else {\n+      return getNonVariableType(p, s);\n+    }\n+  }\n   void registerType(Backend b, ScalarType s, TypeUniquePtr&& t) {\n     type_registry[static_cast<int>(b)][static_cast<int>(s)] = std::move(t);\n     detail::getVariableHooks().registerVariableTypeFor(this, b, s);\n   }\n private:\n+  void initBackendIfNeeded(DeviceType p) {", "path": "aten/src/ATen/core/LegacyTypeDispatch.h", "position": null, "original_position": 88, "commit_id": "606bd66fc2771e10f8b835fd1f49a39c3be09bac", "original_commit_id": "959a424b57eee0f9537290de44c514d2ab3ba163", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "LegacyTypeDispatch may not actually have types for CPU or CUDA loaded at the time you try to access them. If they're not loaded (this can only be true the first time we try to initialize them), we have to go request them to actually be loaded. This might involve properly initializing CUDA, for example, which we want to do lazily because it is quite costly.", "created_at": "2018-09-07T14:41:44Z", "updated_at": "2018-11-23T15:50:45Z", "html_url": "https://github.com/pytorch/pytorch/pull/11331#discussion_r215982094", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11331", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/215982094"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11331#discussion_r215982094"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11331"}}, "body_html": "<p>LegacyTypeDispatch may not actually have types for CPU or CUDA loaded at the time you try to access them. If they're not loaded (this can only be true the first time we try to initialize them), we have to go request them to actually be loaded. This might involve properly initializing CUDA, for example, which we want to do lazily because it is quite costly.</p>", "body_text": "LegacyTypeDispatch may not actually have types for CPU or CUDA loaded at the time you try to access them. If they're not loaded (this can only be true the first time we try to initialize them), we have to go request them to actually be loaded. This might involve properly initializing CUDA, for example, which we want to do lazily because it is quite costly.", "in_reply_to_id": 215713485}