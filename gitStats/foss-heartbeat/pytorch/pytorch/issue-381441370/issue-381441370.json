{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14078", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14078/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14078/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14078/events", "html_url": "https://github.com/pytorch/pytorch/issues/14078", "id": 381441370, "node_id": "MDU6SXNzdWUzODE0NDEzNzA=", "number": 14078, "title": "Build failing at torch/lib/c10d/ProcessGroupMPI.cpp", "user": {"login": "sadatnfs", "id": 19790145, "node_id": "MDQ6VXNlcjE5NzkwMTQ1", "avatar_url": "https://avatars2.githubusercontent.com/u/19790145?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sadatnfs", "html_url": "https://github.com/sadatnfs", "followers_url": "https://api.github.com/users/sadatnfs/followers", "following_url": "https://api.github.com/users/sadatnfs/following{/other_user}", "gists_url": "https://api.github.com/users/sadatnfs/gists{/gist_id}", "starred_url": "https://api.github.com/users/sadatnfs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sadatnfs/subscriptions", "organizations_url": "https://api.github.com/users/sadatnfs/orgs", "repos_url": "https://api.github.com/users/sadatnfs/repos", "events_url": "https://api.github.com/users/sadatnfs/events{/privacy}", "received_events_url": "https://api.github.com/users/sadatnfs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1002728630, "node_id": "MDU6TGFiZWwxMDAyNzI4NjMw", "url": "https://api.github.com/repos/pytorch/pytorch/labels/1.0", "name": "1.0", "color": "f9db31", "default": false}, {"id": 679953883, "node_id": "MDU6TGFiZWw2Nzk5NTM4ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/distributed", "name": "distributed", "color": "c2e0c6", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-11-16T04:25:31Z", "updated_at": "2018-11-18T06:44:19Z", "closed_at": "2018-11-17T02:55:02Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>PyTorch fails to finish building, with a possible bug (see below).</p>\n<div class=\"highlight highlight-source-shell\"><pre>Scanning dependencies of target caffe2_observers\n[ 92%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/data_channels/DataChannelTCP.cpp.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/net_observer_reporter_print.cc.o\n\ufffd[91m/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp: In destructor \u2018virtual <span class=\"pl-en\">c10d::ProcessGroupMPI::AsyncWork::~AsyncWork</span>()\u2019:\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: error: throw will always call <span class=\"pl-en\">terminate</span>() [-Werror<span class=\"pl-k\">=</span>terminate]\n         <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Attempted destruction of AsyncWork before work has completed<span class=\"pl-pds\">\"</span></span>)<span class=\"pl-k\">;</span>\n                                                                       ^\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: note: <span class=\"pl-k\">in</span> C++11 destructors default to noexcept\n\ufffd[0m[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/function.cpp.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/accumulate_grad.cpp.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/ps_roi_pool_op.cc.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/observer_config.cc.o\n\ufffd[91mcc1plus: all warnings being treated as errors\n\ufffd[0m\ufffd[91mmake[2]: <span class=\"pl-k\">***</span> [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o] Error 1\n\ufffd[0m\ufffd[91mmake[2]: <span class=\"pl-k\">***</span> Waiting <span class=\"pl-k\">for</span> unfinished jobs....\n\ufffd[0mcaffe2/torch/lib/c10d/CMakeFiles/c10d.dir/build.make:230: recipe <span class=\"pl-k\">for</span> target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o<span class=\"pl-pds\">'</span></span> failed\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/basic_ops.cpp.o\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethod.cpp.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/perf_observer.cc.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/roi_pool_f_op.cc.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/sample_as_op.cc.o\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethodEnv.cpp.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/comm.cpp.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/select_smooth_l1_loss_op.cc.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/tensor.cpp.o\nCMakeFiles/Makefile2:7496: recipe <span class=\"pl-k\">for</span> target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all<span class=\"pl-pds\">'</span></span> failed\n\ufffd[91mmake[1]: <span class=\"pl-k\">***</span> [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all] Error 2\n\ufffd[0m\ufffd[91mmake[1]: <span class=\"pl-k\">***</span> Waiting <span class=\"pl-k\">for</span> unfinished jobs....\n...\n...\n...\n[ 99%] Linking CXX shared library ../../lib/libtorch.so\n[ 99%] Built target torch\nMakefile:138: recipe <span class=\"pl-k\">for</span> target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>all<span class=\"pl-pds\">'</span></span> failed\n\ufffd[91mmake: <span class=\"pl-k\">***</span> [all] Error 2\n<span class=\"pl-en\">\ufffd[0msetup.py::build_deps::run</span>()\nFailed to run <span class=\"pl-s\"><span class=\"pl-pds\">'</span>bash ../tools/build_pytorch_libs.sh --use-fbgemm --use-nnpack --use-mkldnn --use-qnnpack caffe2<span class=\"pl-pds\">'</span></span></pre></div>\n<h2>To Reproduce</h2>\n<div class=\"highlight highlight-source-shell\"><pre> <span class=\"pl-c1\">cd</span> /opt <span class=\"pl-k\">&amp;&amp;</span> git clone --recursive https://github.com/pytorch/pytorch \\\n    <span class=\"pl-k\">&amp;&amp;</span> <span class=\"pl-c1\">cd</span> pytorch <span class=\"pl-k\">&amp;&amp;</span> git submodule update --init <span class=\"pl-k\">&amp;&amp;</span> \\\n    <span class=\"pl-c1\">cd</span> /opt/pytorch/third_party/ideep/mkl-dnn <span class=\"pl-k\">&amp;&amp;</span> \\\n    git pull https://github.com/intel/mkl-dnn.git --no-commit  --rebase <span class=\"pl-k\">&amp;&amp;</span> \\\n    <span class=\"pl-c1\">cd</span> /opt/pytorch <span class=\"pl-k\">&amp;&amp;</span> \\\n    sed -i <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s/\"Use MKLDNN\" OFF/\"Use MKLDNN\" ON /g<span class=\"pl-pds\">'</span></span> CMakeLists.txt <span class=\"pl-k\">&amp;&amp;</span> \\\n    sed -i <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s/\"Use DISTRIBUTED\" OFF/\"Use DISTRIBUTED\" ON /g<span class=\"pl-pds\">'</span></span> CMakeLists.txt <span class=\"pl-k\">&amp;&amp;</span> \\\n    sed -i <span class=\"pl-s\"><span class=\"pl-pds\">'</span>s/for parallel code\" OFF/for parallel code\" ON /g<span class=\"pl-pds\">'</span></span> CMakeLists.txt <span class=\"pl-k\">&amp;&amp;</span> \\\n    PYTHON_EXECUTABLE=/opt/conda/bin/python \\\n    PYTHON_LIBRARY=/opt/conda/lib/libpython3.6m.so \\\n    PYTHON_INCLUDE_DIR=/opt/conda/include/python3.6m \\\n    FULL_CAFFE2=1 \\\n    USE_OPENMP=1 \\\n    USE_MKL=1 \\\n    USE_MKLDNN=1 \\\n    USE_MKLML=1 \\\n    USE_SYSTEM_EIGEN_INSTALL=1 \\\n    USE_ZMQ=1 \\\n    USE_DISTRIBUTED=1 \\\n    MKLDNN_LIBRARY=/usr/local/lib \\\n    MKLDNN_INCLUDE_DIR=/usr/local/include \\\n    MKLDNN_LIB_DIR=/usr/local/lib \\\n    python setup.py install <span class=\"pl-k\">&amp;&amp;</span> \\\n    <span class=\"pl-c1\">cd</span> /opt <span class=\"pl-k\">&amp;&amp;</span> rm -rf /opt/pytorch <span class=\"pl-k\">&amp;&amp;</span> \\\n    <span class=\"pl-c1\">cd</span> /usr/lib <span class=\"pl-k\">&amp;&amp;</span> sudo ldconfig</pre></div>\n<h2>Environment</h2>\n<ul>\n<li>PyTorch Version (e.g., 1.0): Master branch (1.0)</li>\n<li>OS (e.g., Linux): Debian:Stretch</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): source</li>\n<li>Build command you used (if compiling from source): see above</li>\n<li>Python version: 3.6</li>\n<li>CUDA/cuDNN version: N/A</li>\n<li>GPU models and configuration: N/A</li>\n<li>Any other relevant information: N/A</li>\n</ul>\n<h2>Additional context</h2>\n", "body_text": "\ud83d\udc1b Bug\nPyTorch fails to finish building, with a possible bug (see below).\nScanning dependencies of target caffe2_observers\n[ 92%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/data_channels/DataChannelTCP.cpp.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/net_observer_reporter_print.cc.o\n\ufffd[91m/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp: In destructor \u2018virtual c10d::ProcessGroupMPI::AsyncWork::~AsyncWork()\u2019:\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: error: throw will always call terminate() [-Werror=terminate]\n         \"Attempted destruction of AsyncWork before work has completed\");\n                                                                       ^\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: note: in C++11 destructors default to noexcept\n\ufffd[0m[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/function.cpp.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/accumulate_grad.cpp.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/ps_roi_pool_op.cc.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/observer_config.cc.o\n\ufffd[91mcc1plus: all warnings being treated as errors\n\ufffd[0m\ufffd[91mmake[2]: *** [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o] Error 1\n\ufffd[0m\ufffd[91mmake[2]: *** Waiting for unfinished jobs....\n\ufffd[0mcaffe2/torch/lib/c10d/CMakeFiles/c10d.dir/build.make:230: recipe for target 'caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o' failed\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/basic_ops.cpp.o\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethod.cpp.o\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/perf_observer.cc.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/roi_pool_f_op.cc.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/sample_as_op.cc.o\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethodEnv.cpp.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/comm.cpp.o\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/select_smooth_l1_loss_op.cc.o\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/tensor.cpp.o\nCMakeFiles/Makefile2:7496: recipe for target 'caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all' failed\n\ufffd[91mmake[1]: *** [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all] Error 2\n\ufffd[0m\ufffd[91mmake[1]: *** Waiting for unfinished jobs....\n...\n...\n...\n[ 99%] Linking CXX shared library ../../lib/libtorch.so\n[ 99%] Built target torch\nMakefile:138: recipe for target 'all' failed\n\ufffd[91mmake: *** [all] Error 2\n\ufffd[0msetup.py::build_deps::run()\nFailed to run 'bash ../tools/build_pytorch_libs.sh --use-fbgemm --use-nnpack --use-mkldnn --use-qnnpack caffe2'\nTo Reproduce\n cd /opt && git clone --recursive https://github.com/pytorch/pytorch \\\n    && cd pytorch && git submodule update --init && \\\n    cd /opt/pytorch/third_party/ideep/mkl-dnn && \\\n    git pull https://github.com/intel/mkl-dnn.git --no-commit  --rebase && \\\n    cd /opt/pytorch && \\\n    sed -i 's/\"Use MKLDNN\" OFF/\"Use MKLDNN\" ON /g' CMakeLists.txt && \\\n    sed -i 's/\"Use DISTRIBUTED\" OFF/\"Use DISTRIBUTED\" ON /g' CMakeLists.txt && \\\n    sed -i 's/for parallel code\" OFF/for parallel code\" ON /g' CMakeLists.txt && \\\n    PYTHON_EXECUTABLE=/opt/conda/bin/python \\\n    PYTHON_LIBRARY=/opt/conda/lib/libpython3.6m.so \\\n    PYTHON_INCLUDE_DIR=/opt/conda/include/python3.6m \\\n    FULL_CAFFE2=1 \\\n    USE_OPENMP=1 \\\n    USE_MKL=1 \\\n    USE_MKLDNN=1 \\\n    USE_MKLML=1 \\\n    USE_SYSTEM_EIGEN_INSTALL=1 \\\n    USE_ZMQ=1 \\\n    USE_DISTRIBUTED=1 \\\n    MKLDNN_LIBRARY=/usr/local/lib \\\n    MKLDNN_INCLUDE_DIR=/usr/local/include \\\n    MKLDNN_LIB_DIR=/usr/local/lib \\\n    python setup.py install && \\\n    cd /opt && rm -rf /opt/pytorch && \\\n    cd /usr/lib && sudo ldconfig\nEnvironment\n\nPyTorch Version (e.g., 1.0): Master branch (1.0)\nOS (e.g., Linux): Debian:Stretch\nHow you installed PyTorch (conda, pip, source): source\nBuild command you used (if compiling from source): see above\nPython version: 3.6\nCUDA/cuDNN version: N/A\nGPU models and configuration: N/A\nAny other relevant information: N/A\n\nAdditional context", "body": "## \ud83d\udc1b Bug\r\n\r\nPyTorch fails to finish building, with a possible bug (see below).\r\n\r\n```bash \r\nScanning dependencies of target caffe2_observers\r\n[ 92%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/data_channels/DataChannelTCP.cpp.o\r\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/net_observer_reporter_print.cc.o\r\n\u001b[91m/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp: In destructor \u2018virtual c10d::ProcessGroupMPI::AsyncWork::~AsyncWork()\u2019:\r\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: error: throw will always call terminate() [-Werror=terminate]\r\n         \"Attempted destruction of AsyncWork before work has completed\");\r\n                                                                       ^\r\n/opt/pytorch/torch/lib/c10d/ProcessGroupMPI.cpp:154:71: note: in C++11 destructors default to noexcept\r\n\u001b[0m[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/function.cpp.o\r\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/accumulate_grad.cpp.o\r\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/ps_roi_pool_op.cc.o\r\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/observer_config.cc.o\r\n\u001b[91mcc1plus: all warnings being treated as errors\r\n\u001b[0m\u001b[91mmake[2]: *** [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o] Error 1\r\n\u001b[0m\u001b[91mmake[2]: *** Waiting for unfinished jobs....\r\n\u001b[0mcaffe2/torch/lib/c10d/CMakeFiles/c10d.dir/build.make:230: recipe for target 'caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/ProcessGroupMPI.cpp.o' failed\r\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/basic_ops.cpp.o\r\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethod.cpp.o\r\n[ 93%] Building CXX object modules/observers/CMakeFiles/caffe2_observers.dir/perf_observer.cc.o\r\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/roi_pool_f_op.cc.o\r\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/sample_as_op.cc.o\r\n[ 93%] Building CXX object caffe2/torch/lib/THD/CMakeFiles/THD.dir/base/init_methods/InitMethodEnv.cpp.o\r\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/comm.cpp.o\r\n[ 93%] Building CXX object modules/detectron/CMakeFiles/caffe2_detectron_ops.dir/select_smooth_l1_loss_op.cc.o\r\n[ 93%] Building CXX object caffe2/torch/CMakeFiles/torch.dir/csrc/autograd/functions/tensor.cpp.o\r\nCMakeFiles/Makefile2:7496: recipe for target 'caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all' failed\r\n\u001b[91mmake[1]: *** [caffe2/torch/lib/c10d/CMakeFiles/c10d.dir/all] Error 2\r\n\u001b[0m\u001b[91mmake[1]: *** Waiting for unfinished jobs....\r\n...\r\n...\r\n...\r\n[ 99%] Linking CXX shared library ../../lib/libtorch.so\r\n[ 99%] Built target torch\r\nMakefile:138: recipe for target 'all' failed\r\n\u001b[91mmake: *** [all] Error 2\r\n\u001b[0msetup.py::build_deps::run()\r\nFailed to run 'bash ../tools/build_pytorch_libs.sh --use-fbgemm --use-nnpack --use-mkldnn --use-qnnpack caffe2'\r\n```\r\n\r\n## To Reproduce\r\n```bash \r\n cd /opt && git clone --recursive https://github.com/pytorch/pytorch \\\r\n    && cd pytorch && git submodule update --init && \\\r\n    cd /opt/pytorch/third_party/ideep/mkl-dnn && \\\r\n    git pull https://github.com/intel/mkl-dnn.git --no-commit  --rebase && \\\r\n    cd /opt/pytorch && \\\r\n    sed -i 's/\"Use MKLDNN\" OFF/\"Use MKLDNN\" ON /g' CMakeLists.txt && \\\r\n    sed -i 's/\"Use DISTRIBUTED\" OFF/\"Use DISTRIBUTED\" ON /g' CMakeLists.txt && \\\r\n    sed -i 's/for parallel code\" OFF/for parallel code\" ON /g' CMakeLists.txt && \\\r\n    PYTHON_EXECUTABLE=/opt/conda/bin/python \\\r\n    PYTHON_LIBRARY=/opt/conda/lib/libpython3.6m.so \\\r\n    PYTHON_INCLUDE_DIR=/opt/conda/include/python3.6m \\\r\n    FULL_CAFFE2=1 \\\r\n    USE_OPENMP=1 \\\r\n    USE_MKL=1 \\\r\n    USE_MKLDNN=1 \\\r\n    USE_MKLML=1 \\\r\n    USE_SYSTEM_EIGEN_INSTALL=1 \\\r\n    USE_ZMQ=1 \\\r\n    USE_DISTRIBUTED=1 \\\r\n    MKLDNN_LIBRARY=/usr/local/lib \\\r\n    MKLDNN_INCLUDE_DIR=/usr/local/include \\\r\n    MKLDNN_LIB_DIR=/usr/local/lib \\\r\n    python setup.py install && \\\r\n    cd /opt && rm -rf /opt/pytorch && \\\r\n    cd /usr/lib && sudo ldconfig\r\n```\r\n\r\n## Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): Master branch (1.0) \r\n - OS (e.g., Linux): Debian:Stretch\r\n - How you installed PyTorch (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): see above\r\n - Python version: 3.6\r\n - CUDA/cuDNN version: N/A\r\n - GPU models and configuration: N/A\r\n - Any other relevant information: N/A\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n"}