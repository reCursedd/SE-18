{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233989451", "pull_request_review_id": 175532725, "id": 233989451, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMzk4OTQ1MQ==", "diff_hunk": "@@ -833,57 +834,83 @@ TEST(DataLoaderTest, RespectsTimeout) {\n   ASSERT_LT(duration.count(), 1);\n }\n \n+struct Barrier {\n+  void wait(size_t target) {\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    ++counter_;\n+    cv_.wait(lock, [this, target] { return this->counter_ == target; });\n+    cv_.notify_all();\n+  }\n+\n+  size_t counter_{0};\n+  std::condition_variable cv_;\n+  std::mutex mutex_;\n+};\n+\n+namespace ordering_test {\n namespace {\n-std::atomic<size_t> ordering_test_counter{0};\n-std::condition_variable ordering_test_cv;\n-std::mutex ordering_test_mutex;\n-const std::array<size_t, 4> ordering_test_order = {3, 1, 0, 2};\n-std::atomic<size_t> ordering_test_index{0};\n+const size_t kNumberOfWorkers = 10;\n+const std::vector<size_t> kOrderInWhichWorkersReturnTheirBatch =\n+    {3, 7, 0, 5, 4, 8, 2, 1, 9, 6};\n } // namespace\n \n-struct OrderingTestDataset : datasets::BatchDataset<DummyDataset, int> {\n-  OrderingTestDataset() = default;\n+struct Dataset : datasets::BatchDataset<Dataset, size_t> {\n+  Dataset() = default;\n \n   // This copy constructor will be called when we copy the dataset into a\n   // particular thread.\n-  OrderingTestDataset(const OrderingTestDataset& other)\n-      : id(ordering_test_counter++) {}\n-\n-  OrderingTestDataset(OrderingTestDataset&& other) noexcept = default;\n-  OrderingTestDataset& operator=(const OrderingTestDataset& other) = delete;\n-  OrderingTestDataset& operator=(OrderingTestDataset&& other) noexcept = delete;\n-\n-  int get_batch(torch::ArrayRef<size_t> indices) override {\n-    std::unique_lock<std::mutex> lock(ordering_test_mutex);\n-    // block until order.at(index) == my_thread_id (until it's this thread's\n-    // turn)\n-    ordering_test_cv.wait(lock, [this] {\n-      return ordering_test_order.at(ordering_test_index.load()) == this->id;\n-    });\n-    // Make one step in the order.\n-    ++ordering_test_index;\n+  Dataset(const Dataset& other) {\n+    static std::atomic<size_t> counter{0};\n+    thread_id_ = counter.fetch_add(1);\n+  }\n+\n+  Dataset(Dataset&& other) noexcept = default;\n+  Dataset& operator=(const Dataset& other) = delete;\n+  Dataset& operator=(Dataset&& other) noexcept = delete;\n+\n+  size_t get_batch(torch::ArrayRef<size_t> indices) override {\n+    static Barrier barrier;\n+    static auto order_iterator = kOrderInWhichWorkersReturnTheirBatch.begin();\n+    static std::condition_variable cv;\n+    static std::mutex mutex;\n+\n+    // Wait for all threads to get an index batch and arrive here.\n+    barrier.wait(kNumberOfWorkers);", "path": "test/cpp/api/dataloader.cpp", "position": null, "original_position": 76, "commit_id": "5580beff9774c75bcf0e178627d70e842a68a136", "original_commit_id": "b22ae9b293dc62ce41df41e0868c20dde86f9491", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "body": "OK, so if I understand correctly, the old code could have let a thread out before all the indices were assigned to worker thread, and so after it (very speedily) finished processing its batch, it would grab another one, starving the actual thread. In that case, I would expect the code to have deadlocked, because now the thread is never going to see its index show up again in the test order.\r\n\r\nYou've solved this by forcing all `get_batch` calls to block until the worker threads have each grabbed a Dataset. But... I kind of don't see why, fundamentally, `enforce_ordering` shouldn't work even if a worker thread finishes up their work and starts working on another index. You're still releasing threads based on their thread ID, but shouldn't you release them on the value of `indices.front()`? That's the thing you actually care about!", "created_at": "2018-11-15T20:04:13Z", "updated_at": "2018-11-23T15:54:56Z", "html_url": "https://github.com/pytorch/pytorch/pull/14038#discussion_r233989451", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/14038", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/233989451"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/14038#discussion_r233989451"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/14038"}}, "body_html": "<p>OK, so if I understand correctly, the old code could have let a thread out before all the indices were assigned to worker thread, and so after it (very speedily) finished processing its batch, it would grab another one, starving the actual thread. In that case, I would expect the code to have deadlocked, because now the thread is never going to see its index show up again in the test order.</p>\n<p>You've solved this by forcing all <code>get_batch</code> calls to block until the worker threads have each grabbed a Dataset. But... I kind of don't see why, fundamentally, <code>enforce_ordering</code> shouldn't work even if a worker thread finishes up their work and starts working on another index. You're still releasing threads based on their thread ID, but shouldn't you release them on the value of <code>indices.front()</code>? That's the thing you actually care about!</p>", "body_text": "OK, so if I understand correctly, the old code could have let a thread out before all the indices were assigned to worker thread, and so after it (very speedily) finished processing its batch, it would grab another one, starving the actual thread. In that case, I would expect the code to have deadlocked, because now the thread is never going to see its index show up again in the test order.\nYou've solved this by forcing all get_batch calls to block until the worker threads have each grabbed a Dataset. But... I kind of don't see why, fundamentally, enforce_ordering shouldn't work even if a worker thread finishes up their work and starts working on another index. You're still releasing threads based on their thread ID, but shouldn't you release them on the value of indices.front()? That's the thing you actually care about!"}