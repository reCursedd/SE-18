{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12276", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12276/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12276/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12276/events", "html_url": "https://github.com/pytorch/pytorch/issues/12276", "id": 366141985, "node_id": "MDU6SXNzdWUzNjYxNDE5ODU=", "number": 12276, "title": "[Windows] Exception in Torch.Multiprocessing.Queue", "user": {"login": "sanctifier", "id": 39151126, "node_id": "MDQ6VXNlcjM5MTUxMTI2", "avatar_url": "https://avatars1.githubusercontent.com/u/39151126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sanctifier", "html_url": "https://github.com/sanctifier", "followers_url": "https://api.github.com/users/sanctifier/followers", "following_url": "https://api.github.com/users/sanctifier/following{/other_user}", "gists_url": "https://api.github.com/users/sanctifier/gists{/gist_id}", "starred_url": "https://api.github.com/users/sanctifier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sanctifier/subscriptions", "organizations_url": "https://api.github.com/users/sanctifier/orgs", "repos_url": "https://api.github.com/users/sanctifier/repos", "events_url": "https://api.github.com/users/sanctifier/events{/privacy}", "received_events_url": "https://api.github.com/users/sanctifier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 790080431, "node_id": "MDU6TGFiZWw3OTAwODA0MzE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/windows", "name": "windows", "color": "fcff6b", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-10-03T01:38:00Z", "updated_at": "2018-10-04T00:03:08Z", "closed_at": "2018-10-04T00:03:08Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>I want to train multiple CNN models individually on multiple GPUs installed in a single PC. Once the training is finished, the models are expected to be returned to the main thread.</p>\n<p>I employed torch.multiprocessing to implement this. Namely, I defined a CNN class inherited from nn.Module and the associated train(), test() methods for asynchronous calls.</p>\n<p>The CNN aims at MNIST dataset for test purpose.  The models and the MNIST built-in dataloaders are all initialized before torch.multiprocessing is invoked.</p>\n<p>Torch.multiprocessing creates Process object hooking train() and its arguments, i.e., model, GPU, dataloader and a queue of class torch.multiprocessing.Queue.</p>\n<p>In train(), the trained model is pushed to the queue by \"queue.put(model)\".</p>\n<p>In main(), the model is retrieved from queue by \"model=queue.get()\" once all training completed.</p>\n<p>However, the statement \"model=queue.get()\" triggers \"AttributeError: Can't get attribute 'CNN' on &lt;module 'ptvsd.<strong>main</strong>' ...&gt;\"</p>\n<h2>Code example</h2>\n<pre><code>import time\nimport torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.multiprocessing as mp\n\n\nprint(torch.__version__)\nprint(torchvision.__version__)\n\n\n# MNIST Dataset\ntrain_dataset = dsets.MNIST(root='./Mnist_data/',                 \n                            train=True,                     \n                            transform=transforms.ToTensor(),\n                            download=True)                  \n\ntest_dataset = dsets.MNIST(root='./Mnist_data/',                  \n                        train=False,                     \n                        transform=transforms.ToTensor())\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                        batch_size=200, \n                                        shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                        batch_size=200, \n                                        shuffle=False)\n# CNN Model (2 conv layer)\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.fc = nn.Linear(7*7*32, 10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out \n\nassert torch.cuda.is_available()\n\ntorch.backends.cudnn.benchmark=True\n\nGPU_COUNT = torch.cuda.device_count()\n\nGPUs = []\nfor index in range(GPU_COUNT):\n    GPUs.append(torch.device(f'cuda:{index}'))\n\ndef train(model, GPU, train_loader, queue):\n    num_epochs = 1    \n    learning_rate = 0.01\n\n    model.cuda(device=GPU)\n    model.train()        \n    # Loss and Optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n        \n    # Train the Model\n    info = '\\n'\n    start = time.time()     \n    for epoch in range(num_epochs):\n        correct = 0\n        total = 0   \n        for i, (images, labels) in enumerate(train_loader):                      \n            # Forward + Backward + Optimize\n            optimizer.zero_grad()\n            outputs = model(images.cuda(device=GPU))\n            loss = criterion(outputs, labels.cuda(device=GPU))\n            loss.backward()\n            optimizer.step()\n            \n            if (i+1) % 100 == 0:\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted.cpu() == labels).sum()\n                info = info + f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4}, ACC: {float(100*correct/total):.4}\\n'\n        torch.cuda.empty_cache()\n        \n    info = info + f'time elapsed: {time.time()-start}\\n' \n    print(info)\n    model.cpu()\n    queue.put(model)    \n\ndef test(model, GPU, test_loader): \n    model.cuda(device=GPU)\n    # Test the Model\n    correct = 0\n    total = 0\n    for images, labels in test_loader:  \n        outputs = model(images.cuda(device=GPU))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted.cpu() == labels).sum()  \n    info = f'Test Accuracy of the model on the test images: {float(100 * correct / total):.4}'\n    return info \n\n# training and test\nif __name__ == \"__main__\":\n    models = []\n    for _ in range(GPU_COUNT):\n        model = CNN()        \n        model.cpu()\n        model.share_memory()\n        models.append(model)\n\n    # parallel processing    \n    start = time.time()\n    processes = []\n    queue = mp.Queue()\n    for GPU in GPUs:\n        p = mp.Process(target=train, args=(models[index], GPU, train_loader, queue))\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()                    \n    print(f'Total Time elapsed: {int(time.time() - start)}s')\n\n    index = 0\n    while not queue.empty():\n        model = queue.get()\n        output = test(model, GPUs[index], test_loader)\n        print(output)\n        index = index + 1\n</code></pre>\n<p>Error messages:<br>\nException has occurred: AttributeError<br>\nCan't get attribute 'CNN' on &lt;module 'ptvsd.<strong>main</strong>' from 'c:\\Users\\Administrator\\.vscode\\extensions\\ms-python.python-2018.8.0\\pythonFiles\\experimental\\ptvsd\\ptvsd\\<strong>main</strong>.py'&gt;</p>\n<h2>System Info</h2>\n<ul>\n<li>PyTorch or Caffe2:  PyTorch</li>\n<li>How you installed PyTorch (conda, pip, source):  \"conda install pytorch cuda91\"</li>\n<li>Build command you used (if compiling from source):</li>\n<li>OS: Windows 10 Home Edition</li>\n<li>PyTorch version: 0.4.1</li>\n<li>Python version:  3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]</li>\n<li>CUDA/cuDNN version: 9.1.85/7005</li>\n<li>GPU models and configuration: GPU 0 = GeForce GTX 1060</li>\n<li>GCC version (if compiling from source):</li>\n<li>CMake version:</li>\n<li>Versions of any other relevant libraries: torchvision (0.2.1)</li>\n</ul>", "body_text": "Issue description\nI want to train multiple CNN models individually on multiple GPUs installed in a single PC. Once the training is finished, the models are expected to be returned to the main thread.\nI employed torch.multiprocessing to implement this. Namely, I defined a CNN class inherited from nn.Module and the associated train(), test() methods for asynchronous calls.\nThe CNN aims at MNIST dataset for test purpose.  The models and the MNIST built-in dataloaders are all initialized before torch.multiprocessing is invoked.\nTorch.multiprocessing creates Process object hooking train() and its arguments, i.e., model, GPU, dataloader and a queue of class torch.multiprocessing.Queue.\nIn train(), the trained model is pushed to the queue by \"queue.put(model)\".\nIn main(), the model is retrieved from queue by \"model=queue.get()\" once all training completed.\nHowever, the statement \"model=queue.get()\" triggers \"AttributeError: Can't get attribute 'CNN' on <module 'ptvsd.main' ...>\"\nCode example\nimport time\nimport torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.multiprocessing as mp\n\n\nprint(torch.__version__)\nprint(torchvision.__version__)\n\n\n# MNIST Dataset\ntrain_dataset = dsets.MNIST(root='./Mnist_data/',                 \n                            train=True,                     \n                            transform=transforms.ToTensor(),\n                            download=True)                  \n\ntest_dataset = dsets.MNIST(root='./Mnist_data/',                  \n                        train=False,                     \n                        transform=transforms.ToTensor())\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                        batch_size=200, \n                                        shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                        batch_size=200, \n                                        shuffle=False)\n# CNN Model (2 conv layer)\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.fc = nn.Linear(7*7*32, 10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out \n\nassert torch.cuda.is_available()\n\ntorch.backends.cudnn.benchmark=True\n\nGPU_COUNT = torch.cuda.device_count()\n\nGPUs = []\nfor index in range(GPU_COUNT):\n    GPUs.append(torch.device(f'cuda:{index}'))\n\ndef train(model, GPU, train_loader, queue):\n    num_epochs = 1    \n    learning_rate = 0.01\n\n    model.cuda(device=GPU)\n    model.train()        \n    # Loss and Optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n        \n    # Train the Model\n    info = '\\n'\n    start = time.time()     \n    for epoch in range(num_epochs):\n        correct = 0\n        total = 0   \n        for i, (images, labels) in enumerate(train_loader):                      \n            # Forward + Backward + Optimize\n            optimizer.zero_grad()\n            outputs = model(images.cuda(device=GPU))\n            loss = criterion(outputs, labels.cuda(device=GPU))\n            loss.backward()\n            optimizer.step()\n            \n            if (i+1) % 100 == 0:\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted.cpu() == labels).sum()\n                info = info + f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4}, ACC: {float(100*correct/total):.4}\\n'\n        torch.cuda.empty_cache()\n        \n    info = info + f'time elapsed: {time.time()-start}\\n' \n    print(info)\n    model.cpu()\n    queue.put(model)    \n\ndef test(model, GPU, test_loader): \n    model.cuda(device=GPU)\n    # Test the Model\n    correct = 0\n    total = 0\n    for images, labels in test_loader:  \n        outputs = model(images.cuda(device=GPU))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted.cpu() == labels).sum()  \n    info = f'Test Accuracy of the model on the test images: {float(100 * correct / total):.4}'\n    return info \n\n# training and test\nif __name__ == \"__main__\":\n    models = []\n    for _ in range(GPU_COUNT):\n        model = CNN()        \n        model.cpu()\n        model.share_memory()\n        models.append(model)\n\n    # parallel processing    \n    start = time.time()\n    processes = []\n    queue = mp.Queue()\n    for GPU in GPUs:\n        p = mp.Process(target=train, args=(models[index], GPU, train_loader, queue))\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()                    \n    print(f'Total Time elapsed: {int(time.time() - start)}s')\n\n    index = 0\n    while not queue.empty():\n        model = queue.get()\n        output = test(model, GPUs[index], test_loader)\n        print(output)\n        index = index + 1\n\nError messages:\nException has occurred: AttributeError\nCan't get attribute 'CNN' on <module 'ptvsd.main' from 'c:\\Users\\Administrator\\.vscode\\extensions\\ms-python.python-2018.8.0\\pythonFiles\\experimental\\ptvsd\\ptvsd\\main.py'>\nSystem Info\n\nPyTorch or Caffe2:  PyTorch\nHow you installed PyTorch (conda, pip, source):  \"conda install pytorch cuda91\"\nBuild command you used (if compiling from source):\nOS: Windows 10 Home Edition\nPyTorch version: 0.4.1\nPython version:  3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\nCUDA/cuDNN version: 9.1.85/7005\nGPU models and configuration: GPU 0 = GeForce GTX 1060\nGCC version (if compiling from source):\nCMake version:\nVersions of any other relevant libraries: torchvision (0.2.1)", "body": "## Issue description\r\nI want to train multiple CNN models individually on multiple GPUs installed in a single PC. Once the training is finished, the models are expected to be returned to the main thread.  \r\n\r\nI employed torch.multiprocessing to implement this. Namely, I defined a CNN class inherited from nn.Module and the associated train(), test() methods for asynchronous calls. \r\n\r\nThe CNN aims at MNIST dataset for test purpose.  The models and the MNIST built-in dataloaders are all initialized before torch.multiprocessing is invoked. \r\n\r\nTorch.multiprocessing creates Process object hooking train() and its arguments, i.e., model, GPU, dataloader and a queue of class torch.multiprocessing.Queue. \r\n\r\nIn train(), the trained model is pushed to the queue by \"queue.put(model)\". \r\n\r\nIn main(), the model is retrieved from queue by \"model=queue.get()\" once all training completed. \r\n\r\nHowever, the statement \"model=queue.get()\" triggers \"AttributeError: Can't get attribute 'CNN' on <module 'ptvsd.__main__' ...>\"\r\n\r\n\r\n## Code example\r\n    import time\r\n    import torch \r\n    import torch.nn as nn\r\n    import torchvision\r\n    import torchvision.datasets as dsets\r\n    import torchvision.transforms as transforms\r\n    import torch.nn.functional as F\r\n    import torch.multiprocessing as mp\r\n\r\n\r\n    print(torch.__version__)\r\n    print(torchvision.__version__)\r\n\r\n\r\n    # MNIST Dataset\r\n    train_dataset = dsets.MNIST(root='./Mnist_data/',                 \r\n                                train=True,                     \r\n                                transform=transforms.ToTensor(),\r\n                                download=True)                  \r\n\r\n    test_dataset = dsets.MNIST(root='./Mnist_data/',                  \r\n                            train=False,                     \r\n                            transform=transforms.ToTensor())\r\n\r\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\r\n                                            batch_size=200, \r\n                                            shuffle=True)\r\n\r\n    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\r\n                                            batch_size=200, \r\n                                            shuffle=False)\r\n    # CNN Model (2 conv layer)\r\n    class CNN(nn.Module):\r\n        def __init__(self):\r\n            super(CNN, self).__init__()\r\n            self.layer1 = nn.Sequential(\r\n                nn.Conv2d(1, 16, kernel_size=5, padding=2),\r\n                nn.BatchNorm2d(16),\r\n                nn.ReLU(),\r\n                nn.MaxPool2d(2))\r\n            self.layer2 = nn.Sequential(\r\n                nn.Conv2d(16, 32, kernel_size=5, padding=2),\r\n                nn.BatchNorm2d(32),\r\n                nn.ReLU(),\r\n                nn.MaxPool2d(2))\r\n            self.fc = nn.Linear(7*7*32, 10)\r\n            \r\n        def forward(self, x):\r\n            out = self.layer1(x)\r\n            out = self.layer2(out)\r\n            out = out.view(out.size(0), -1)\r\n            out = self.fc(out)\r\n            return out \r\n\r\n    assert torch.cuda.is_available()\r\n\r\n    torch.backends.cudnn.benchmark=True\r\n\r\n    GPU_COUNT = torch.cuda.device_count()\r\n\r\n    GPUs = []\r\n    for index in range(GPU_COUNT):\r\n        GPUs.append(torch.device(f'cuda:{index}'))\r\n\r\n    def train(model, GPU, train_loader, queue):\r\n        num_epochs = 1    \r\n        learning_rate = 0.01\r\n\r\n        model.cuda(device=GPU)\r\n        model.train()        \r\n        # Loss and Optimizer\r\n        criterion = nn.CrossEntropyLoss()\r\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n            \r\n        # Train the Model\r\n        info = '\\n'\r\n        start = time.time()     \r\n        for epoch in range(num_epochs):\r\n            correct = 0\r\n            total = 0   \r\n            for i, (images, labels) in enumerate(train_loader):                      \r\n                # Forward + Backward + Optimize\r\n                optimizer.zero_grad()\r\n                outputs = model(images.cuda(device=GPU))\r\n                loss = criterion(outputs, labels.cuda(device=GPU))\r\n                loss.backward()\r\n                optimizer.step()\r\n                \r\n                if (i+1) % 100 == 0:\r\n                    _, predicted = torch.max(outputs.data, 1)\r\n                    total += labels.size(0)\r\n                    correct += (predicted.cpu() == labels).sum()\r\n                    info = info + f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4}, ACC: {float(100*correct/total):.4}\\n'\r\n            torch.cuda.empty_cache()\r\n            \r\n        info = info + f'time elapsed: {time.time()-start}\\n' \r\n        print(info)\r\n        model.cpu()\r\n        queue.put(model)    \r\n\r\n    def test(model, GPU, test_loader): \r\n        model.cuda(device=GPU)\r\n        # Test the Model\r\n        correct = 0\r\n        total = 0\r\n        for images, labels in test_loader:  \r\n            outputs = model(images.cuda(device=GPU))\r\n            _, predicted = torch.max(outputs.data, 1)\r\n            total += labels.size(0)\r\n            correct += (predicted.cpu() == labels).sum()  \r\n        info = f'Test Accuracy of the model on the test images: {float(100 * correct / total):.4}'\r\n        return info \r\n\r\n    # training and test\r\n    if __name__ == \"__main__\":\r\n        models = []\r\n        for _ in range(GPU_COUNT):\r\n            model = CNN()        \r\n            model.cpu()\r\n            model.share_memory()\r\n            models.append(model)\r\n\r\n        # parallel processing    \r\n        start = time.time()\r\n        processes = []\r\n        queue = mp.Queue()\r\n        for GPU in GPUs:\r\n            p = mp.Process(target=train, args=(models[index], GPU, train_loader, queue))\r\n            p.start()\r\n            processes.append(p)\r\n        for p in processes:\r\n            p.join()                    \r\n        print(f'Total Time elapsed: {int(time.time() - start)}s')\r\n\r\n        index = 0\r\n        while not queue.empty():\r\n            model = queue.get()\r\n            output = test(model, GPUs[index], test_loader)\r\n            print(output)\r\n            index = index + 1\r\n\r\nError messages:\r\nException has occurred: AttributeError\r\nCan't get attribute 'CNN' on <module 'ptvsd.__main__' from 'c:\\\\Users\\\\Administrator\\\\.vscode\\\\extensions\\\\ms-python.python-2018.8.0\\\\pythonFiles\\\\experimental\\\\ptvsd\\\\ptvsd\\\\__main__.py'>\r\n\r\n## System Info\r\n\r\n- PyTorch or Caffe2:  PyTorch \r\n- How you installed PyTorch (conda, pip, source):  \"conda install pytorch cuda91\"\r\n- Build command you used (if compiling from source): \r\n- OS: Windows 10 Home Edition\r\n- PyTorch version: 0.4.1\r\n- Python version:  3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\r\n- CUDA/cuDNN version: 9.1.85/7005\r\n- GPU models and configuration: GPU 0 = GeForce GTX 1060\r\n- GCC version (if compiling from source):\r\n- CMake version:\r\n- Versions of any other relevant libraries: torchvision (0.2.1)"}