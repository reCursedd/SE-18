{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2284", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2284/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2284/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2284/events", "html_url": "https://github.com/pytorch/pytorch/issues/2284", "id": 247676378, "node_id": "MDU6SXNzdWUyNDc2NzYzNzg=", "number": 2284, "title": "questions about torchvision.transforms.Scale", "user": {"login": "icoz69", "id": 22427667, "node_id": "MDQ6VXNlcjIyNDI3NjY3", "avatar_url": "https://avatars0.githubusercontent.com/u/22427667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/icoz69", "html_url": "https://github.com/icoz69", "followers_url": "https://api.github.com/users/icoz69/followers", "following_url": "https://api.github.com/users/icoz69/following{/other_user}", "gists_url": "https://api.github.com/users/icoz69/gists{/gist_id}", "starred_url": "https://api.github.com/users/icoz69/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/icoz69/subscriptions", "organizations_url": "https://api.github.com/users/icoz69/orgs", "repos_url": "https://api.github.com/users/icoz69/repos", "events_url": "https://api.github.com/users/icoz69/events{/privacy}", "received_events_url": "https://api.github.com/users/icoz69/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-03T11:29:08Z", "updated_at": "2017-08-06T03:04:55Z", "closed_at": "2017-08-06T03:04:55Z", "author_association": "NONE", "body_html": "<p>hi,<br>\ni have questions when using torchvision.transforms.Scale to resize the training images<br>\ni want to resize all images to 32 * 128 pixels , what is the correct way ?</p>\n<p>mine was :<br>\ntransform = transforms.Compose(<br>\n[transforms.Scale((32,128)),<br>\ntransforms.ToTensor(),<br>\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</p>\n<p>but it turned out to be wrong. i change it to [32,128] or {32,128}, all wrong.</p>\n<p>thanks</p>", "body_text": "hi,\ni have questions when using torchvision.transforms.Scale to resize the training images\ni want to resize all images to 32 * 128 pixels , what is the correct way ?\nmine was :\ntransform = transforms.Compose(\n[transforms.Scale((32,128)),\ntransforms.ToTensor(),\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\nbut it turned out to be wrong. i change it to [32,128] or {32,128}, all wrong.\nthanks", "body": "hi,\r\ni have questions when using torchvision.transforms.Scale to resize the training images\r\ni want to resize all images to 32 * 128 pixels , what is the correct way ?\r\n\r\nmine was :\r\ntransform = transforms.Compose(\r\n[transforms.Scale((32,128)),\r\ntransforms.ToTensor(),\r\ntransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n\r\nbut it turned out to be wrong. i change it to [32,128] or {32,128}, all wrong.\r\n\r\nthanks"}