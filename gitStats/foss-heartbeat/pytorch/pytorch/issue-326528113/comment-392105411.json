{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/392105411", "html_url": "https://github.com/pytorch/pytorch/issues/7844#issuecomment-392105411", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7844", "id": 392105411, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjEwNTQxMQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-25T16:05:51Z", "updated_at": "2018-05-25T16:05:51Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The particular sentence you referenced is wrong, but you still can't initialize optimizer before moving modules in general</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> l <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> o <span class=\"pl-k\">=</span> torch.optim.Adagrad(l.parameters())\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> l.cuda()\nLinear(<span class=\"pl-v\">in_features</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">out_features</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> l(torch.randn(<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda<span class=\"pl-pds\">'</span></span>)).sum().backward()\n<span class=\"pl-k\">&gt;&gt;</span><span class=\"pl-k\">&gt;</span> o.step()\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;stdin&gt;<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">1</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/ssnl/sftp/pytorch/torch/optim/adagrad.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">92</span>, <span class=\"pl-k\">in</span> step\n    state[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>sum<span class=\"pl-pds\">'</span></span>].addcmul_(<span class=\"pl-c1\">1</span>, grad, grad)\n<span class=\"pl-c1\">RuntimeError</span>: Expected <span class=\"pl-c1\">object</span> of <span class=\"pl-c1\">type</span> torch.FloatTensor but found <span class=\"pl-c1\">type</span> torch.cuda.FloatTensor <span class=\"pl-k\">for</span> argument <span class=\"pl-c\"><span class=\"pl-c\">#</span>4 'tensor1'</span></pre></div>", "body_text": "The particular sentence you referenced is wrong, but you still can't initialize optimizer before moving modules in general\n>>> l = torch.nn.Linear(3, 3)\n>>> o = torch.optim.Adagrad(l.parameters())\n>>> l.cuda()\nLinear(in_features=3, out_features=3, bias=True)\n>>> l(torch.randn(1,3,device='cuda')).sum().backward()\n>>> o.step()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/ssnl/sftp/pytorch/torch/optim/adagrad.py\", line 92, in step\n    state['sum'].addcmul_(1, grad, grad)\nRuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #4 'tensor1'", "body": "The particular sentence you referenced is wrong, but you still can't initialize optimizer before moving modules in general\r\n```py\r\n>>> l = torch.nn.Linear(3, 3)\r\n>>> o = torch.optim.Adagrad(l.parameters())\r\n>>> l.cuda()\r\nLinear(in_features=3, out_features=3, bias=True)\r\n>>> l(torch.randn(1,3,device='cuda')).sum().backward()\r\n>>> o.step()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ssnl/sftp/pytorch/torch/optim/adagrad.py\", line 92, in step\r\n    state['sum'].addcmul_(1, grad, grad)\r\nRuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #4 'tensor1'\r\n```"}