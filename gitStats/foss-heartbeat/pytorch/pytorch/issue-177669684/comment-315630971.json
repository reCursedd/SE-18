{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/315630971", "html_url": "https://github.com/pytorch/pytorch/issues/39#issuecomment-315630971", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/39", "id": 315630971, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTYzMDk3MQ==", "user": {"login": "hughperkins", "id": 123560, "node_id": "MDQ6VXNlcjEyMzU2MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/123560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughperkins", "html_url": "https://github.com/hughperkins", "followers_url": "https://api.github.com/users/hughperkins/followers", "following_url": "https://api.github.com/users/hughperkins/following{/other_user}", "gists_url": "https://api.github.com/users/hughperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughperkins/subscriptions", "organizations_url": "https://api.github.com/users/hughperkins/orgs", "repos_url": "https://api.github.com/users/hughperkins/repos", "events_url": "https://api.github.com/users/hughperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/hughperkins/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-16T19:23:10Z", "updated_at": "2017-07-16T19:23:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Just generally, I think that <strong>all</strong> c errors should be caught, and converted to something more meaningful, at the python level. The c errors are good for dev debugging of the c libraries, but are really a pain when trying to write actual models.  Another error, which might or might not be included above (hard to tell):</p>\n<pre><code>Traceback (most recent call last):\n  File \"seq2seq_attention.py\", line 116, in &lt;module&gt;\n    state, enc_loss = encode(input_encoded, state)\n  File \"seq2seq_attention.py\", line 105, in encode\n    enc_loss += criterion(pred_c, autograd.Variable(torch.LongTensor([input_c_encoded.item()])))\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 36, in forward\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\n    output, *self.additional_args)\nRuntimeError: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/miniconda2/conda-bld/pytorch_1493757886437/work/torch/lib/THNN/generic/ClassNLLCriterion.c:50\n</code></pre>\n<p>There are a few issues really:</p>\n<ul>\n<li>it's hard to search through the stack trace to figure out which line of one's one code is the last thing before it goes into torch code\n<ul>\n<li>solution: cut the stack trace off wherever it passes into the torch library (in this case, cut everything from module.py line 206 forards off</li>\n<li>provide an option to display this stuff anywyay, like <code>torch.StackTraces.show_all(True)</code>, or whatever (no opinoin on the exact command, it's pytorch-dev only mostly anyway)</li>\n</ul>\n</li>\n<li>it's hard to figure out which tensors are at fault. eg you pass in three tensors to a torch python method, which ones are mismatching etc?\n<ul>\n<li>solution: somehow map the error message to the correct tensor. I realize this is generally really hard/impossible. But I'm at least making the observation that it would be nice, if someone can figure out how to make it possible :-)</li>\n</ul>\n</li>\n<li>doesnt show the actual and expected sizes of the tensors going in. Like, 'When you called <code>foobar(spam, eggs, chips)</code>, len(spam[:,0,:]) was 10, and len(eggs(0, :, :) was 5, and they should be the same', or something\n<ul>\n<li>solution: at least print out the sizes of the relevant tensors etc, even from the c code would be nice, rather than just calling assert</li>\n</ul>\n</li>\n</ul>\n<p>One challenge is that it's hard to tell where is the entry point into the pytorch library from someones code: an entrypoint in one persons code might be used by the entry point funcgtion in another persons code. and putting exception stuff all over the place probably wont be graet for performance.  One option that occurs to me, just after finishing writing the above, could be to make some kind of 'prettifier', that takes all the stack trace output, and automatically beuatifies it a bit. So, a user can just call <code>print(prettify(some_exception))</code> or similar</p>\n<ul>\n<li>obviously this would need all required information to be present somehow/somewhere in the stack trace. eg the c code should print out the tensor dimensions etc, in some easy-to-parse format, somewhere</li>\n<li>however it does have a few advantages:\n<ul>\n<li>could be a separate project from core, could even be pluggable, so doesnt involve changing core code (beyond making sure core code dumps all required information somewhere, during an exception)</li>\n<li>wont have any performance impact etc, unless someone explicitly calls prettify</li>\n</ul>\n</li>\n</ul>\n<p>Note that I'm not really thinking of actually contributing to any of these fixes :-P . Just logging it here for completeness.  I might <em>occasionally</em> add one single error message or something, though it'd be nice to somehow decide on /document a standard framework/pattern for doing this first perhaps.</p>", "body_text": "Just generally, I think that all c errors should be caught, and converted to something more meaningful, at the python level. The c errors are good for dev debugging of the c libraries, but are really a pain when trying to write actual models.  Another error, which might or might not be included above (hard to tell):\nTraceback (most recent call last):\n  File \"seq2seq_attention.py\", line 116, in <module>\n    state, enc_loss = encode(input_encoded, state)\n  File \"seq2seq_attention.py\", line 105, in encode\n    enc_loss += criterion(pred_c, autograd.Variable(torch.LongTensor([input_c_encoded.item()])))\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 36, in forward\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\n    output, *self.additional_args)\nRuntimeError: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/miniconda2/conda-bld/pytorch_1493757886437/work/torch/lib/THNN/generic/ClassNLLCriterion.c:50\n\nThere are a few issues really:\n\nit's hard to search through the stack trace to figure out which line of one's one code is the last thing before it goes into torch code\n\nsolution: cut the stack trace off wherever it passes into the torch library (in this case, cut everything from module.py line 206 forards off\nprovide an option to display this stuff anywyay, like torch.StackTraces.show_all(True), or whatever (no opinoin on the exact command, it's pytorch-dev only mostly anyway)\n\n\nit's hard to figure out which tensors are at fault. eg you pass in three tensors to a torch python method, which ones are mismatching etc?\n\nsolution: somehow map the error message to the correct tensor. I realize this is generally really hard/impossible. But I'm at least making the observation that it would be nice, if someone can figure out how to make it possible :-)\n\n\ndoesnt show the actual and expected sizes of the tensors going in. Like, 'When you called foobar(spam, eggs, chips), len(spam[:,0,:]) was 10, and len(eggs(0, :, :) was 5, and they should be the same', or something\n\nsolution: at least print out the sizes of the relevant tensors etc, even from the c code would be nice, rather than just calling assert\n\n\n\nOne challenge is that it's hard to tell where is the entry point into the pytorch library from someones code: an entrypoint in one persons code might be used by the entry point funcgtion in another persons code. and putting exception stuff all over the place probably wont be graet for performance.  One option that occurs to me, just after finishing writing the above, could be to make some kind of 'prettifier', that takes all the stack trace output, and automatically beuatifies it a bit. So, a user can just call print(prettify(some_exception)) or similar\n\nobviously this would need all required information to be present somehow/somewhere in the stack trace. eg the c code should print out the tensor dimensions etc, in some easy-to-parse format, somewhere\nhowever it does have a few advantages:\n\ncould be a separate project from core, could even be pluggable, so doesnt involve changing core code (beyond making sure core code dumps all required information somewhere, during an exception)\nwont have any performance impact etc, unless someone explicitly calls prettify\n\n\n\nNote that I'm not really thinking of actually contributing to any of these fixes :-P . Just logging it here for completeness.  I might occasionally add one single error message or something, though it'd be nice to somehow decide on /document a standard framework/pattern for doing this first perhaps.", "body": "Just generally, I think that __all__ c errors should be caught, and converted to something more meaningful, at the python level. The c errors are good for dev debugging of the c libraries, but are really a pain when trying to write actual models.  Another error, which might or might not be included above (hard to tell):\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"seq2seq_attention.py\", line 116, in <module>\r\n    state, enc_loss = encode(input_encoded, state)\r\n  File \"seq2seq_attention.py\", line 105, in encode\r\n    enc_loss += criterion(pred_c, autograd.Variable(torch.LongTensor([input_c_encoded.item()])))\r\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 206, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 36, in forward\r\n    return backend_fn(self.size_average, weight=self.weight)(input, target)\r\n  File \"/Users/hugh2/conda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\", line 41, in forward\r\n    output, *self.additional_args)\r\nRuntimeError: Assertion `THIndexTensor_(size)(target, 0) == batch_size' failed.  at /Users/soumith/miniconda2/conda-bld/pytorch_1493757886437/work/torch/lib/THNN/generic/ClassNLLCriterion.c:50\r\n```\r\n\r\nThere are a few issues really:\r\n- it's hard to search through the stack trace to figure out which line of one's one code is the last thing before it goes into torch code\r\n  - solution: cut the stack trace off wherever it passes into the torch library (in this case, cut everything from module.py line 206 forards off\r\n  - provide an option to display this stuff anywyay, like `torch.StackTraces.show_all(True)`, or whatever (no opinoin on the exact command, it's pytorch-dev only mostly anyway)\r\n- it's hard to figure out which tensors are at fault. eg you pass in three tensors to a torch python method, which ones are mismatching etc?\r\n   - solution: somehow map the error message to the correct tensor. I realize this is generally really hard/impossible. But I'm at least making the observation that it would be nice, if someone can figure out how to make it possible :-)\r\n- doesnt show the actual and expected sizes of the tensors going in. Like, 'When you called `foobar(spam, eggs, chips)`, len(spam[:,0,:]) was 10, and len(eggs(0, :, :) was 5, and they should be the same', or something\r\n   - solution: at least print out the sizes of the relevant tensors etc, even from the c code would be nice, rather than just calling assert\r\n\r\nOne challenge is that it's hard to tell where is the entry point into the pytorch library from someones code: an entrypoint in one persons code might be used by the entry point funcgtion in another persons code. and putting exception stuff all over the place probably wont be graet for performance.  One option that occurs to me, just after finishing writing the above, could be to make some kind of 'prettifier', that takes all the stack trace output, and automatically beuatifies it a bit. So, a user can just call `print(prettify(some_exception))` or similar\r\n- obviously this would need all required information to be present somehow/somewhere in the stack trace. eg the c code should print out the tensor dimensions etc, in some easy-to-parse format, somewhere\r\n- however it does have a few advantages:\r\n  - could be a separate project from core, could even be pluggable, so doesnt involve changing core code (beyond making sure core code dumps all required information somewhere, during an exception)\r\n  - wont have any performance impact etc, unless someone explicitly calls prettify\r\n\r\nNote that I'm not really thinking of actually contributing to any of these fixes :-P . Just logging it here for completeness.  I might *occasionally* add one single error message or something, though it'd be nice to somehow decide on /document a standard framework/pattern for doing this first perhaps.\r\n"}