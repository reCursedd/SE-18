{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195259109", "pull_request_review_id": 128591955, "id": 195259109, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTI1OTEwOQ==", "diff_hunk": "@@ -0,0 +1,98 @@\n+#pragma once\n+\n+/**\n+ * To register your own tensor types, do in a header file:\n+ *   C10_DECLARE_TENSOR_TYPE(MY_TENSOR)\n+ * and in one (!) cpp file:\n+ *   C10_DEFINE_TENSOR_TYPE(MY_TENSOR)\n+ * Both must be in the same namespace.\n+ */\n+\n+#include \"caffe2/core/dispatch/TensorTypeId.h\"\n+#include \"caffe2/core/common.h\"\n+#include <atomic>\n+#include \"flat_hash_map/flat_hash_map.h\"", "path": "caffe2/core/dispatch/TensorTypeIdRegistration.h", "position": null, "original_position": 14, "commit_id": "e98041959adca7661a009c729d6a1699a81b19aa", "original_commit_id": "e412d966fa9b56ac481082cad9619b4528e30c2b", "user": {"login": "Yangqing", "id": 551151, "node_id": "MDQ6VXNlcjU1MTE1MQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/551151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Yangqing", "html_url": "https://github.com/Yangqing", "followers_url": "https://api.github.com/users/Yangqing/followers", "following_url": "https://api.github.com/users/Yangqing/following{/other_user}", "gists_url": "https://api.github.com/users/Yangqing/gists{/gist_id}", "starred_url": "https://api.github.com/users/Yangqing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Yangqing/subscriptions", "organizations_url": "https://api.github.com/users/Yangqing/orgs", "repos_url": "https://api.github.com/users/Yangqing/repos", "events_url": "https://api.github.com/users/Yangqing/events{/privacy}", "received_events_url": "https://api.github.com/users/Yangqing/received_events", "type": "User", "site_admin": false}, "body": "Yeah, my thought about array was mainly because of code size considerations, and also to help avoiding the third party2 header distribution problem. Speed is probably going to be the same since flat hash map is pretty much like that.", "created_at": "2018-06-13T22:48:05Z", "updated_at": "2018-11-23T15:45:28Z", "html_url": "https://github.com/pytorch/pytorch/pull/8389#discussion_r195259109", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8389", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195259109"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8389#discussion_r195259109"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8389"}}, "body_html": "<p>Yeah, my thought about array was mainly because of code size considerations, and also to help avoiding the third party2 header distribution problem. Speed is probably going to be the same since flat hash map is pretty much like that.</p>", "body_text": "Yeah, my thought about array was mainly because of code size considerations, and also to help avoiding the third party2 header distribution problem. Speed is probably going to be the same since flat hash map is pretty much like that.", "in_reply_to_id": 194966498}