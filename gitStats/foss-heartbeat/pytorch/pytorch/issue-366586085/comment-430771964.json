{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430771964", "html_url": "https://github.com/pytorch/pytorch/issues/12309#issuecomment-430771964", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12309", "id": 430771964, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDc3MTk2NA==", "user": {"login": "shriphani", "id": 357480, "node_id": "MDQ6VXNlcjM1NzQ4MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/357480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shriphani", "html_url": "https://github.com/shriphani", "followers_url": "https://api.github.com/users/shriphani/followers", "following_url": "https://api.github.com/users/shriphani/following{/other_user}", "gists_url": "https://api.github.com/users/shriphani/gists{/gist_id}", "starred_url": "https://api.github.com/users/shriphani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shriphani/subscriptions", "organizations_url": "https://api.github.com/users/shriphani/orgs", "repos_url": "https://api.github.com/users/shriphani/repos", "events_url": "https://api.github.com/users/shriphani/events{/privacy}", "received_events_url": "https://api.github.com/users/shriphani/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-17T20:13:52Z", "updated_at": "2018-10-17T20:13:52Z", "author_association": "NONE", "body_html": "<p>Here's an example where I run into this sort of stuff:</p>\n<pre><code>out, hidden = lstm(input, hidden)\nlogits = w(out) # is nn.linear\nchoice = logits.softmax(dim=-1).multinomial() # goes pfft here because of dimension\n</code></pre>\n<p>I think the right fix is broadcasting along the dim argument (which doesn't exist atm) no ?</p>", "body_text": "Here's an example where I run into this sort of stuff:\nout, hidden = lstm(input, hidden)\nlogits = w(out) # is nn.linear\nchoice = logits.softmax(dim=-1).multinomial() # goes pfft here because of dimension\n\nI think the right fix is broadcasting along the dim argument (which doesn't exist atm) no ?", "body": "Here's an example where I run into this sort of stuff:\r\n\r\n```\r\nout, hidden = lstm(input, hidden)\r\nlogits = w(out) # is nn.linear\r\nchoice = logits.softmax(dim=-1).multinomial() # goes pfft here because of dimension\r\n````\r\n\r\nI think the right fix is broadcasting along the dim argument (which doesn't exist atm) no ?"}