{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/421505790", "html_url": "https://github.com/pytorch/pytorch/pull/11719#issuecomment-421505790", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11719", "id": 421505790, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTUwNTc5MA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-14T23:02:04Z", "updated_at": "2018-09-14T23:02:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a>, Yes, I can do that.<br>\nTest failure is legit,</p>\n<pre><code> ======================================================================\n22:32:33 FAIL: test_passing_one_positional_but_not_the_second (__main__.TestCustomOperators)\n22:32:33 ----------------------------------------------------------------------\n22:32:33 RuntimeError: Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\n22:32:33 \n22:32:33 During handling of the above exception, another exception occurred:\n22:32:33 \n22:32:33 Traceback (most recent call last):\n22:32:33   File \"test_jit.py\", line 7796, in test_passing_one_positional_but_not_the_second\n22:32:33     torch.ops.aten.log_softmax(torch.ones(5))\n22:32:33 AssertionError: \"aten::log_softmax\\(\\) is missing value for argument 'dim'.\" does not match \"Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\"\n</code></pre>\n<p>but I'm not sure what's the preferred fix should be. FWIW, some operators already have overloads that are not supported from python, e.g.</p>\n<pre><code>In [3]: torch.ops.aten.sum(torch.ones(5))\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-3-acd80e61fcec&gt; in &lt;module&gt;()\n----&gt; 1 torch.ops.aten.sum(torch.ones(5))\n\n/workspace/ngimel/pytorch_upstream/torch/_ops.py in __getattr__(self, op_name)\n     56         # for overloads and raise an exception if there are more than one.\n     57         qualified_op_name = '{}::{}'.format(self.name, op_name)\n---&gt; 58         op = torch._C._jit_get_operation(qualified_op_name)\n     59         # let the script frontend know that op is identical to the builtin op\n     60         # with qualified_op_name\n\nRuntimeError: Found 5 overloads for operator aten::sum! Overloads are not supported from Python.\n</code></pre>\n<p>so log_softmax erroring out with similar message is not necessarily a big problem (?) .</p>", "body_text": "@SsnL, Yes, I can do that.\nTest failure is legit,\n ======================================================================\n22:32:33 FAIL: test_passing_one_positional_but_not_the_second (__main__.TestCustomOperators)\n22:32:33 ----------------------------------------------------------------------\n22:32:33 RuntimeError: Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\n22:32:33 \n22:32:33 During handling of the above exception, another exception occurred:\n22:32:33 \n22:32:33 Traceback (most recent call last):\n22:32:33   File \"test_jit.py\", line 7796, in test_passing_one_positional_but_not_the_second\n22:32:33     torch.ops.aten.log_softmax(torch.ones(5))\n22:32:33 AssertionError: \"aten::log_softmax\\(\\) is missing value for argument 'dim'.\" does not match \"Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\"\n\nbut I'm not sure what's the preferred fix should be. FWIW, some operators already have overloads that are not supported from python, e.g.\nIn [3]: torch.ops.aten.sum(torch.ones(5))\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-3-acd80e61fcec> in <module>()\n----> 1 torch.ops.aten.sum(torch.ones(5))\n\n/workspace/ngimel/pytorch_upstream/torch/_ops.py in __getattr__(self, op_name)\n     56         # for overloads and raise an exception if there are more than one.\n     57         qualified_op_name = '{}::{}'.format(self.name, op_name)\n---> 58         op = torch._C._jit_get_operation(qualified_op_name)\n     59         # let the script frontend know that op is identical to the builtin op\n     60         # with qualified_op_name\n\nRuntimeError: Found 5 overloads for operator aten::sum! Overloads are not supported from Python.\n\nso log_softmax erroring out with similar message is not necessarily a big problem (?) .", "body": "@ssnl, Yes, I can do that. \r\nTest failure is legit,\r\n```\r\n ======================================================================\r\n22:32:33 FAIL: test_passing_one_positional_but_not_the_second (__main__.TestCustomOperators)\r\n22:32:33 ----------------------------------------------------------------------\r\n22:32:33 RuntimeError: Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\r\n22:32:33 \r\n22:32:33 During handling of the above exception, another exception occurred:\r\n22:32:33 \r\n22:32:33 Traceback (most recent call last):\r\n22:32:33   File \"test_jit.py\", line 7796, in test_passing_one_positional_but_not_the_second\r\n22:32:33     torch.ops.aten.log_softmax(torch.ones(5))\r\n22:32:33 AssertionError: \"aten::log_softmax\\(\\) is missing value for argument 'dim'.\" does not match \"Found 2 overloads for operator aten::log_softmax! Overloads are not supported from Python.\"\r\n``` \r\nbut I'm not sure what's the preferred fix should be. FWIW, some operators already have overloads that are not supported from python, e.g.\r\n```\r\nIn [3]: torch.ops.aten.sum(torch.ones(5))\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-acd80e61fcec> in <module>()\r\n----> 1 torch.ops.aten.sum(torch.ones(5))\r\n\r\n/workspace/ngimel/pytorch_upstream/torch/_ops.py in __getattr__(self, op_name)\r\n     56         # for overloads and raise an exception if there are more than one.\r\n     57         qualified_op_name = '{}::{}'.format(self.name, op_name)\r\n---> 58         op = torch._C._jit_get_operation(qualified_op_name)\r\n     59         # let the script frontend know that op is identical to the builtin op\r\n     60         # with qualified_op_name\r\n\r\nRuntimeError: Found 5 overloads for operator aten::sum! Overloads are not supported from Python.\r\n```\r\nso log_softmax erroring out with similar message is not necessarily a big problem (?) . "}