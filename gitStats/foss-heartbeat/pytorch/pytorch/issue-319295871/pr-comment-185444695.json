{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185444695", "pull_request_review_id": 116832546, "id": 185444695, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTQ0NDY5NQ==", "diff_hunk": "@@ -88,14 +88,27 @@ def rebuild_storage_filename(cls, manager, handle, size):\n     return storage._shared_decref()\n \n \n-def rebuild_storage_cuda(cls, device, handle, size, offset, view_size):\n+def rebuild_storage_cuda(cls, device, handle, size, offset, view_size, originating_pid):", "path": "torch/multiprocessing/reductions.py", "position": 5, "original_position": 5, "commit_id": "e0826233531c527ef55ef7119e750f0a311e90f2", "original_commit_id": "e0826233531c527ef55ef7119e750f0a311e90f2", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Does this handle a situation where process `A` sends a tensor to `B`, and then `B` sends it back to `A`? I think in that case `originating_pid` would point to that of `B`. Additionally, that's not a very robust mechanism, because pids behave effectively like Python's `id` - you're guaranteed that it's unique for as long as a process is alive, but it can be reused once it dies, so you can't be 100% sure if this message was sent by you or not.\r\n\r\nMaybe a better fix would be to just always normalize the storages in the cache to point to the beginning of the data block?", "created_at": "2018-05-02T09:48:45Z", "updated_at": "2018-11-23T15:43:31Z", "html_url": "https://github.com/pytorch/pytorch/pull/7146#discussion_r185444695", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/7146", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/185444695"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/7146#discussion_r185444695"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/7146"}}, "body_html": "<p>Does this handle a situation where process <code>A</code> sends a tensor to <code>B</code>, and then <code>B</code> sends it back to <code>A</code>? I think in that case <code>originating_pid</code> would point to that of <code>B</code>. Additionally, that's not a very robust mechanism, because pids behave effectively like Python's <code>id</code> - you're guaranteed that it's unique for as long as a process is alive, but it can be reused once it dies, so you can't be 100% sure if this message was sent by you or not.</p>\n<p>Maybe a better fix would be to just always normalize the storages in the cache to point to the beginning of the data block?</p>", "body_text": "Does this handle a situation where process A sends a tensor to B, and then B sends it back to A? I think in that case originating_pid would point to that of B. Additionally, that's not a very robust mechanism, because pids behave effectively like Python's id - you're guaranteed that it's unique for as long as a process is alive, but it can be reused once it dies, so you can't be 100% sure if this message was sent by you or not.\nMaybe a better fix would be to just always normalize the storages in the cache to point to the beginning of the data block?"}