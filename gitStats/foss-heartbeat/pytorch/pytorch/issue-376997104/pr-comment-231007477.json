{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231007477", "pull_request_review_id": 171864804, "id": 231007477, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMTAwNzQ3Nw==", "diff_hunk": "@@ -0,0 +1,32 @@\n+#pragma once\n+\n+#include \"caffe2/core/tensor.h\"\n+#include <c10/util/Array.h>\n+\n+namespace caffe2 {\n+namespace ops {\n+\n+struct LayerNorm final {\n+  static constexpr const char* name = \"LayerNorm\";\n+\n+  struct Cache final {\n+    Tensor scale = Tensor{CPU};\n+    Tensor bias = Tensor{CPU};\n+  };\n+\n+  using Signature = void(\n+      const Tensor& input,\n+      Tensor* output,\n+      Tensor* output_mean,\n+      Tensor* output_stddev,\n+      int axis,\n+      float epsilon,\n+      Cache* cache,\n+      BaseContext* context);", "path": "caffe2/operators/experimental/c10/schemas/layer_norm.h", "position": 25, "original_position": 25, "commit_id": "234a86dd9bca0d6b2b1d6b44cb186204cd6b76e3", "original_commit_id": "372aeff8b5877fe610024c23c5cef4883fff0f89", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "passing the context here is unfortunate. You seem to need it for getting current stream id. This part is not unified yet (cc @ezyang) - pytorch and c2 would create different streams.\r\n\r\nI guess, you can skip CUDA for now. For C2 implementation you can add a static method here (https://github.com/pytorch/pytorch/blob/master/caffe2/core/context_gpu.h#L222) that gives cuda_stream(CaffeCudaGetDevice()). It'd add a small overhead of extra GetDevice but would eliminate the need of passing context.\r\n\r\nIt would be not properly safe to call from PyTorch side though as the stream id would be different (until Ed's stuff lands). You can wrap it in explicit CUDAContext instance there effectively making the call blocking for now (since destructor invokes FinishDeviceComputation).", "created_at": "2018-11-06T06:11:04Z", "updated_at": "2018-11-23T15:54:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/13533#discussion_r231007477", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13533", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/231007477"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13533#discussion_r231007477"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13533"}}, "body_html": "<p>passing the context here is unfortunate. You seem to need it for getting current stream id. This part is not unified yet (cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a>) - pytorch and c2 would create different streams.</p>\n<p>I guess, you can skip CUDA for now. For C2 implementation you can add a static method here (<a href=\"https://github.com/pytorch/pytorch/blob/master/caffe2/core/context_gpu.h#L222\">https://github.com/pytorch/pytorch/blob/master/caffe2/core/context_gpu.h#L222</a>) that gives cuda_stream(CaffeCudaGetDevice()). It'd add a small overhead of extra GetDevice but would eliminate the need of passing context.</p>\n<p>It would be not properly safe to call from PyTorch side though as the stream id would be different (until Ed's stuff lands). You can wrap it in explicit CUDAContext instance there effectively making the call blocking for now (since destructor invokes FinishDeviceComputation).</p>", "body_text": "passing the context here is unfortunate. You seem to need it for getting current stream id. This part is not unified yet (cc @ezyang) - pytorch and c2 would create different streams.\nI guess, you can skip CUDA for now. For C2 implementation you can add a static method here (https://github.com/pytorch/pytorch/blob/master/caffe2/core/context_gpu.h#L222) that gives cuda_stream(CaffeCudaGetDevice()). It'd add a small overhead of extra GetDevice but would eliminate the need of passing context.\nIt would be not properly safe to call from PyTorch side though as the stream id would be different (until Ed's stuff lands). You can wrap it in explicit CUDAContext instance there effectively making the call blocking for now (since destructor invokes FinishDeviceComputation)."}