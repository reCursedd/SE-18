{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4757", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4757/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4757/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4757/events", "html_url": "https://github.com/pytorch/pytorch/issues/4757", "id": 290162753, "node_id": "MDU6SXNzdWUyOTAxNjI3NTM=", "number": 4757, "title": "pad_packed_sequence in rrn valueError: result of slicing is an empty tensor", "user": {"login": "jpilaul", "id": 614861, "node_id": "MDQ6VXNlcjYxNDg2MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/614861?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpilaul", "html_url": "https://github.com/jpilaul", "followers_url": "https://api.github.com/users/jpilaul/followers", "following_url": "https://api.github.com/users/jpilaul/following{/other_user}", "gists_url": "https://api.github.com/users/jpilaul/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpilaul/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpilaul/subscriptions", "organizations_url": "https://api.github.com/users/jpilaul/orgs", "repos_url": "https://api.github.com/users/jpilaul/repos", "events_url": "https://api.github.com/users/jpilaul/events{/privacy}", "received_events_url": "https://api.github.com/users/jpilaul/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-01-20T04:05:55Z", "updated_at": "2018-04-17T20:04:09Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>hey, I just downloaded latest torch package (pip3 install <a href=\"http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\" rel=\"nofollow\">http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl</a>) for python 3.6 and got the following error:</p>\n<p><code>File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__ result = self.forward(*input, **kwargs) File \"/u/pilaultj/Projects/enc_summary/gensen.py\", line 60, in forward h, h_t = self.encoder(src_emb) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__ result = self.forward(*input, **kwargs) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 169, in forward output, hidden = func(input, self.all_weights, hx) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 387, in forward return func(input, *fargs, **fkwargs) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 247, in forward nexth, output = func(input, hidden, weight) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 85, in forward hy, output = inner(input, hidden[l], weight[l]) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 148, in forward step_input = input[input_offset:input_offset + batch_size] File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/variable.py\", line 78, in __getitem__ return Index.apply(self, key) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\", line 89, in forward result = i.index(ctx.index) ValueError: result of slicing is an empty tensor</code></p>\n<p>The error was odd because I had tested the code on the previous pytorch package on python 3.6 and had gotten no errors... to debug, I added in rnn.py print statements for <code>input</code> and <code>len(batch_sizes)</code>  before <code> step_input = input[input_offset:input_offset + batch_size]</code></p>\n<p>This is what I get with the latest release:<br>\n`Variable containing:<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n...                   \u22f1                   ...<br>\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02<br>\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01<br>\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02<br>\n[torch.FloatTensor of size 12347x512]</p>\n<p>293`</p>\n<p>This is what I get with the prior release:<br>\n`Variable containing:<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02<br>\n...                   \u22f1                   ...<br>\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02<br>\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01<br>\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02<br>\n[torch.FloatTensor of size 12347x512]</p>\n<p>250`</p>\n<p>The batch_sizes are different (293 vs 250) from the 2 versions and it is creating errors. My previous version of torch was 0.2.0_3<br>\nThanks</p>", "body_text": "hey, I just downloaded latest torch package (pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl) for python 3.6 and got the following error:\nFile \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__ result = self.forward(*input, **kwargs) File \"/u/pilaultj/Projects/enc_summary/gensen.py\", line 60, in forward h, h_t = self.encoder(src_emb) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__ result = self.forward(*input, **kwargs) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 169, in forward output, hidden = func(input, self.all_weights, hx) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 387, in forward return func(input, *fargs, **fkwargs) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 247, in forward nexth, output = func(input, hidden, weight) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 85, in forward hy, output = inner(input, hidden[l], weight[l]) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 148, in forward step_input = input[input_offset:input_offset + batch_size] File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/variable.py\", line 78, in __getitem__ return Index.apply(self, key) File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\", line 89, in forward result = i.index(ctx.index) ValueError: result of slicing is an empty tensor\nThe error was odd because I had tested the code on the previous pytorch package on python 3.6 and had gotten no errors... to debug, I added in rnn.py print statements for input and len(batch_sizes)  before  step_input = input[input_offset:input_offset + batch_size]\nThis is what I get with the latest release:\n`Variable containing:\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n...                   \u22f1                   ...\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02\n[torch.FloatTensor of size 12347x512]\n293`\nThis is what I get with the prior release:\n`Variable containing:\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\n...                   \u22f1                   ...\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02\n[torch.FloatTensor of size 12347x512]\n250`\nThe batch_sizes are different (293 vs 250) from the 2 versions and it is creating errors. My previous version of torch was 0.2.0_3\nThanks", "body": "hey, I just downloaded latest torch package (pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl) for python 3.6 and got the following error:\r\n\r\n`File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/u/pilaultj/Projects/enc_summary/gensen.py\", line 60, in forward\r\n    h, h_t = self.encoder(src_emb)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 325, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\", line 169, in forward\r\n    output, hidden = func(input, self.all_weights, hx)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 387, in forward\r\n    return func(input, *fargs, **fkwargs)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 247, in forward\r\n    nexth, output = func(input, hidden, weight)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 85, in forward\r\n    hy, output = inner(input, hidden[l], weight[l])\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\", line 148, in forward\r\n    step_input = input[input_offset:input_offset + batch_size]\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/variable.py\", line 78, in __getitem__\r\n    return Index.apply(self, key)\r\n  File \"/u/pilaultj/.conda/envs/myenv/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\", line 89, in forward\r\n    result = i.index(ctx.index)\r\nValueError: result of slicing is an empty tensor`\r\n\r\nThe error was odd because I had tested the code on the previous pytorch package on python 3.6 and had gotten no errors... to debug, I added in rnn.py print statements for `input` and `len(batch_sizes)`  before ` step_input = input[input_offset:input_offset + batch_size]`\r\n\r\nThis is what I get with the latest release:\r\n`Variable containing:\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n                ...                   \u22f1                   ...                \r\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02\r\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01\r\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3992e-02 -4.7688e-02\r\n[torch.FloatTensor of size 12347x512]\r\n\r\n293`\r\n\r\nThis is what I get with the prior release:\r\n`Variable containing:\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n 6.4042e-03  4.6973e-03  2.0913e-03  ...  -7.4448e-02  4.2790e-03  7.9663e-02\r\n                ...                   \u22f1                   ...                \r\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02\r\n-2.0559e-02  1.9310e-01 -9.8036e-03  ...   9.4705e-02  6.7008e-02 -1.3937e-01\r\n-3.3624e-02 -2.8784e-02  4.7878e-02  ...   8.0091e-02  1.3991e-02 -4.7688e-02\r\n[torch.FloatTensor of size 12347x512]\r\n\r\n250`\r\n\r\nThe batch_sizes are different (293 vs 250) from the 2 versions and it is creating errors. My previous version of torch was 0.2.0_3\r\nThanks"}