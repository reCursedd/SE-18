{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/377124964", "html_url": "https://github.com/pytorch/pytorch/issues/6099#issuecomment-377124964", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6099", "id": 377124964, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NzEyNDk2NA==", "user": {"login": "Jeffery4000", "id": 27762422, "node_id": "MDQ6VXNlcjI3NzYyNDIy", "avatar_url": "https://avatars2.githubusercontent.com/u/27762422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jeffery4000", "html_url": "https://github.com/Jeffery4000", "followers_url": "https://api.github.com/users/Jeffery4000/followers", "following_url": "https://api.github.com/users/Jeffery4000/following{/other_user}", "gists_url": "https://api.github.com/users/Jeffery4000/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jeffery4000/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jeffery4000/subscriptions", "organizations_url": "https://api.github.com/users/Jeffery4000/orgs", "repos_url": "https://api.github.com/users/Jeffery4000/repos", "events_url": "https://api.github.com/users/Jeffery4000/events{/privacy}", "received_events_url": "https://api.github.com/users/Jeffery4000/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-29T05:21:05Z", "updated_at": "2018-03-29T05:21:05Z", "author_association": "NONE", "body_html": "<p>this the new error I am getting with tcp initialisation</p>\n<pre><code>=&gt; creating model 'resnet50'\nTraceback (most recent call last):\n  File \"main.py\", line 315, in &lt;module&gt;\n    main()\n  File \"main.py\", line 88, in main\n    model = torch.nn.parallel.DistributedDataParallel(model)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 128, in __init__\n    self.broadcast_bucket_size)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 245, in _dist_broadcast_coalesced\n    dist.broadcast(flat_tensors, 0)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/distributed/__init__.py\", line 277, in broadcast\n    return torch._C._dist_broadcast(tensor, src, group)\nRuntimeError: [enforce fail at /root/pytorch/torch/lib/gloo/gloo/transport/ibverbs/buffer.cc:57] mr_ != nullptr. ibv_reg_mr: Cannot allocate memory (did you run into the locked memory limit?)\n\n</code></pre>", "body_text": "this the new error I am getting with tcp initialisation\n=> creating model 'resnet50'\nTraceback (most recent call last):\n  File \"main.py\", line 315, in <module>\n    main()\n  File \"main.py\", line 88, in main\n    model = torch.nn.parallel.DistributedDataParallel(model)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 128, in __init__\n    self.broadcast_bucket_size)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 245, in _dist_broadcast_coalesced\n    dist.broadcast(flat_tensors, 0)\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/distributed/__init__.py\", line 277, in broadcast\n    return torch._C._dist_broadcast(tensor, src, group)\nRuntimeError: [enforce fail at /root/pytorch/torch/lib/gloo/gloo/transport/ibverbs/buffer.cc:57] mr_ != nullptr. ibv_reg_mr: Cannot allocate memory (did you run into the locked memory limit?)", "body": "this the new error I am getting with tcp initialisation\r\n```\r\n=> creating model 'resnet50'\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 315, in <module>\r\n    main()\r\n  File \"main.py\", line 88, in main\r\n    model = torch.nn.parallel.DistributedDataParallel(model)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 128, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/nn/parallel/distributed.py\", line 245, in _dist_broadcast_coalesced\r\n    dist.broadcast(flat_tensors, 0)\r\n  File \"/root/anaconda2/lib/python2.7/site-packages/torch/distributed/__init__.py\", line 277, in broadcast\r\n    return torch._C._dist_broadcast(tensor, src, group)\r\nRuntimeError: [enforce fail at /root/pytorch/torch/lib/gloo/gloo/transport/ibverbs/buffer.cc:57] mr_ != nullptr. ibv_reg_mr: Cannot allocate memory (did you run into the locked memory limit?)\r\n\r\n```"}