{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1442", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1442/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1442/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1442/events", "html_url": "https://github.com/pytorch/pytorch/issues/1442", "id": 225795077, "node_id": "MDU6SXNzdWUyMjU3OTUwNzc=", "number": 1442, "title": "Optimizers can't be moved to a different GPU", "user": {"login": "gregjohnso", "id": 17319655, "node_id": "MDQ6VXNlcjE3MzE5NjU1", "avatar_url": "https://avatars2.githubusercontent.com/u/17319655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gregjohnso", "html_url": "https://github.com/gregjohnso", "followers_url": "https://api.github.com/users/gregjohnso/followers", "following_url": "https://api.github.com/users/gregjohnso/following{/other_user}", "gists_url": "https://api.github.com/users/gregjohnso/gists{/gist_id}", "starred_url": "https://api.github.com/users/gregjohnso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gregjohnso/subscriptions", "organizations_url": "https://api.github.com/users/gregjohnso/orgs", "repos_url": "https://api.github.com/users/gregjohnso/repos", "events_url": "https://api.github.com/users/gregjohnso/events{/privacy}", "received_events_url": "https://api.github.com/users/gregjohnso/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-02T19:23:02Z", "updated_at": "2017-10-12T19:46:12Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>There is currently no good way to set the GPU id for an optimizer state. This is particuarly relevant in the use case that model training stops, and needs to be restarted on a different gpu.</p>\n<p>I'm currently working around that problem with the following:</p>\n<pre><code>def set_gpu_recursive(var, gpu_id):\n    for key in var:\n        if isinstance(var[key], dict):\n            var[key] = set_gpu_recursive(var[key], gpu_id)\n        else:\n            try:\n                var[key] = var[key].cuda(gpu_id)\n            except:\n                pass\n    return var\n\nopt.load_state_dict(torch.load(opt_save_path))\nopt.state = set_gpu_recursive(opt.state, gpu_id)\n</code></pre>", "body_text": "There is currently no good way to set the GPU id for an optimizer state. This is particuarly relevant in the use case that model training stops, and needs to be restarted on a different gpu.\nI'm currently working around that problem with the following:\ndef set_gpu_recursive(var, gpu_id):\n    for key in var:\n        if isinstance(var[key], dict):\n            var[key] = set_gpu_recursive(var[key], gpu_id)\n        else:\n            try:\n                var[key] = var[key].cuda(gpu_id)\n            except:\n                pass\n    return var\n\nopt.load_state_dict(torch.load(opt_save_path))\nopt.state = set_gpu_recursive(opt.state, gpu_id)", "body": "There is currently no good way to set the GPU id for an optimizer state. This is particuarly relevant in the use case that model training stops, and needs to be restarted on a different gpu.\r\n\r\nI'm currently working around that problem with the following:\r\n```\r\ndef set_gpu_recursive(var, gpu_id):\r\n    for key in var:\r\n        if isinstance(var[key], dict):\r\n            var[key] = set_gpu_recursive(var[key], gpu_id)\r\n        else:\r\n            try:\r\n                var[key] = var[key].cuda(gpu_id)\r\n            except:\r\n                pass\r\n    return var\r\n\r\nopt.load_state_dict(torch.load(opt_save_path))\r\nopt.state = set_gpu_recursive(opt.state, gpu_id)\r\n```\r\n"}