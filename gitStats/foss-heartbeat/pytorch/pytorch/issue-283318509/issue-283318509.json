{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4253", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4253/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4253/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4253/events", "html_url": "https://github.com/pytorch/pytorch/issues/4253", "id": 283318509, "node_id": "MDU6SXNzdWUyODMzMTg1MDk=", "number": 4253, "title": "Batch Normalization train/test difference", "user": {"login": "shekhovt", "id": 2486893, "node_id": "MDQ6VXNlcjI0ODY4OTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2486893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shekhovt", "html_url": "https://github.com/shekhovt", "followers_url": "https://api.github.com/users/shekhovt/followers", "following_url": "https://api.github.com/users/shekhovt/following{/other_user}", "gists_url": "https://api.github.com/users/shekhovt/gists{/gist_id}", "starred_url": "https://api.github.com/users/shekhovt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shekhovt/subscriptions", "organizations_url": "https://api.github.com/users/shekhovt/orgs", "repos_url": "https://api.github.com/users/shekhovt/repos", "events_url": "https://api.github.com/users/shekhovt/events{/privacy}", "received_events_url": "https://api.github.com/users/shekhovt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-12-19T17:56:54Z", "updated_at": "2017-12-20T09:32:30Z", "closed_at": "2017-12-19T18:30:56Z", "author_association": "NONE", "body_html": "<p>There is some difference in BN train/test behaviour using the exact statistics.</p>\n<pre><code>from torch import Tensor\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nx = Tensor(1000,1)\nx.uniform_()\n\nm = Tensor(1)\nv = Tensor(1)\neps = 0  # for simplicity\nF.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=1, training=True, eps=eps)\nprint((m - x.mean(dim=0)).abs().mean()) # gives 0.0\nprint((v - x.var(dim=0)).abs().mean()) # gives 0.0\n\n# Eval version\ny0 = F.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=0, training=False, eps=eps)\n# This is clear, it matches the formula\ny0a = (x-m.view([1,-1]))/torch.sqrt(v.view([1,-1]))\nprint((y0.data-y0a).abs().mean()) # something around 1E-8\n\n# Train version\ny1 = F.batch_norm(Variable(x), running_mean=Tensor(1), running_var=Tensor(1), training=True, eps=eps)\n\nprint((y0-y1).abs().mean()) # something around 1E-4, not OK\n</code></pre>\n<p>Does not seem to be a numerical accuracy issue.<br>\nMaybe train version implements somewhat different formulae? If this is intended, could you please describe it in the docs? The difference is not big and may be not important asymptotically (like a biased variance estimator), but it amplifies through layers and breaks correctness tests of something I currently develop. At least I would like to know what's going on.<br>\nThanks</p>", "body_text": "There is some difference in BN train/test behaviour using the exact statistics.\nfrom torch import Tensor\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nx = Tensor(1000,1)\nx.uniform_()\n\nm = Tensor(1)\nv = Tensor(1)\neps = 0  # for simplicity\nF.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=1, training=True, eps=eps)\nprint((m - x.mean(dim=0)).abs().mean()) # gives 0.0\nprint((v - x.var(dim=0)).abs().mean()) # gives 0.0\n\n# Eval version\ny0 = F.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=0, training=False, eps=eps)\n# This is clear, it matches the formula\ny0a = (x-m.view([1,-1]))/torch.sqrt(v.view([1,-1]))\nprint((y0.data-y0a).abs().mean()) # something around 1E-8\n\n# Train version\ny1 = F.batch_norm(Variable(x), running_mean=Tensor(1), running_var=Tensor(1), training=True, eps=eps)\n\nprint((y0-y1).abs().mean()) # something around 1E-4, not OK\n\nDoes not seem to be a numerical accuracy issue.\nMaybe train version implements somewhat different formulae? If this is intended, could you please describe it in the docs? The difference is not big and may be not important asymptotically (like a biased variance estimator), but it amplifies through layers and breaks correctness tests of something I currently develop. At least I would like to know what's going on.\nThanks", "body": "There is some difference in BN train/test behaviour using the exact statistics. \r\n\r\n\r\n```\r\nfrom torch import Tensor\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\n\r\nx = Tensor(1000,1)\r\nx.uniform_()\r\n\r\nm = Tensor(1)\r\nv = Tensor(1)\r\neps = 0  # for simplicity\r\nF.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=1, training=True, eps=eps)\r\nprint((m - x.mean(dim=0)).abs().mean()) # gives 0.0\r\nprint((v - x.var(dim=0)).abs().mean()) # gives 0.0\r\n\r\n# Eval version\r\ny0 = F.batch_norm(Variable(x), running_mean=m, running_var=v, momentum=0, training=False, eps=eps)\r\n# This is clear, it matches the formula\r\ny0a = (x-m.view([1,-1]))/torch.sqrt(v.view([1,-1]))\r\nprint((y0.data-y0a).abs().mean()) # something around 1E-8\r\n\r\n# Train version\r\ny1 = F.batch_norm(Variable(x), running_mean=Tensor(1), running_var=Tensor(1), training=True, eps=eps)\r\n\r\nprint((y0-y1).abs().mean()) # something around 1E-4, not OK\r\n```\r\nDoes not seem to be a numerical accuracy issue.\r\nMaybe train version implements somewhat different formulae? If this is intended, could you please describe it in the docs? The difference is not big and may be not important asymptotically (like a biased variance estimator), but it amplifies through layers and breaks correctness tests of something I currently develop. At least I would like to know what's going on.\r\nThanks\r\n\r\n"}