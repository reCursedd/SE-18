{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/378757512", "html_url": "https://github.com/pytorch/pytorch/issues/4619#issuecomment-378757512", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4619", "id": 378757512, "node_id": "MDEyOklzc3VlQ29tbWVudDM3ODc1NzUxMg==", "user": {"login": "ebetica", "id": 3605224, "node_id": "MDQ6VXNlcjM2MDUyMjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/3605224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebetica", "html_url": "https://github.com/ebetica", "followers_url": "https://api.github.com/users/ebetica/followers", "following_url": "https://api.github.com/users/ebetica/following{/other_user}", "gists_url": "https://api.github.com/users/ebetica/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebetica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebetica/subscriptions", "organizations_url": "https://api.github.com/users/ebetica/orgs", "repos_url": "https://api.github.com/users/ebetica/repos", "events_url": "https://api.github.com/users/ebetica/events{/privacy}", "received_events_url": "https://api.github.com/users/ebetica/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-04T21:54:01Z", "updated_at": "2018-04-04T21:54:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3768583\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gchanan\">@gchanan</a> I think what Ed meant is something like</p>\n<div class=\"highlight highlight-source-c++\"><pre>at::Tensor x, y;\n{\n  AutoGPU <span class=\"pl-smi\">autogpu</span>(<span class=\"pl-c1\">0</span>);\n  x = <span class=\"pl-c1\">at::CUDA</span>(at::<span class=\"pl-c1\">kFloat</span>).<span class=\"pl-c1\">randn</span>({<span class=\"pl-c1\">100</span>});\n  y = <span class=\"pl-c1\">at::CUDA</span>(at::<span class=\"pl-c1\">kFloat</span>).<span class=\"pl-c1\">randn</span>({<span class=\"pl-c1\">100</span>});\n}\n{\n  AutoGPU <span class=\"pl-smi\">autogpu</span>(<span class=\"pl-c1\">1</span>);\n  <span class=\"pl-k\">auto</span> z = x * y; <span class=\"pl-c\"><span class=\"pl-c\">//</span> What happens here? Error | Copy z to GPU 1 | keep z on GPU 0</span>\n}</pre></div>\n<p>I'm not sure what the best solution is here.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a></p>\n<p>If a third party lib includes auto_gpu.h without doing a <code>#define WITH_CUDA</code>, then they try to use it, the things in auto_gpu.h wrapped with <code>WITH_CUDA</code> will not compile and it won't work. The solution I can see is to split it out into a .cpp so CUDA is baked into the pytorch .so.</p>", "body_text": "@gchanan I think what Ed meant is something like\nat::Tensor x, y;\n{\n  AutoGPU autogpu(0);\n  x = at::CUDA(at::kFloat).randn({100});\n  y = at::CUDA(at::kFloat).randn({100});\n}\n{\n  AutoGPU autogpu(1);\n  auto z = x * y; // What happens here? Error | Copy z to GPU 1 | keep z on GPU 0\n}\nI'm not sure what the best solution is here.\n@goldsborough\nIf a third party lib includes auto_gpu.h without doing a #define WITH_CUDA, then they try to use it, the things in auto_gpu.h wrapped with WITH_CUDA will not compile and it won't work. The solution I can see is to split it out into a .cpp so CUDA is baked into the pytorch .so.", "body": "@gchanan I think what Ed meant is something like\r\n\r\n```c++\r\nat::Tensor x, y;\r\n{\r\n  AutoGPU autogpu(0);\r\n  x = at::CUDA(at::kFloat).randn({100});\r\n  y = at::CUDA(at::kFloat).randn({100});\r\n}\r\n{\r\n  AutoGPU autogpu(1);\r\n  auto z = x * y; // What happens here? Error | Copy z to GPU 1 | keep z on GPU 0\r\n}\r\n```\r\n\r\nI'm not sure what the best solution is here.\r\n\r\n@goldsborough \r\n\r\nIf a third party lib includes auto_gpu.h without doing a `#define WITH_CUDA`, then they try to use it, the things in auto_gpu.h wrapped with `WITH_CUDA` will not compile and it won't work. The solution I can see is to split it out into a .cpp so CUDA is baked into the pytorch .so."}