{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/388593286", "html_url": "https://github.com/pytorch/pytorch/issues/7313#issuecomment-388593286", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7313", "id": 388593286, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODU5MzI4Ng==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-13T00:50:01Z", "updated_at": "2018-05-13T00:50:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Incidentally, we have also been working on abstracting reparameterization <a href=\"https://github.com/NVIDIA/apex/tree/master/apex/reparameterization\">https://github.com/NVIDIA/apex/tree/master/apex/reparameterization</a>. Current implementation puts boilerplate code to reparameterization.py, with weight norm defining just particular weight recomputation functions. The recomputation of weight is controlled by <code>self.evaluated</code> which is set to true at evaluation and toggled to false in backward (which may be crude enough, but worked not to recompute weight at each time step of rnn).<br>\nIt is still a hook-based implementation, and conceptually I agree that all the same things can be achieved by module wrappers.</p>", "body_text": "Incidentally, we have also been working on abstracting reparameterization https://github.com/NVIDIA/apex/tree/master/apex/reparameterization. Current implementation puts boilerplate code to reparameterization.py, with weight norm defining just particular weight recomputation functions. The recomputation of weight is controlled by self.evaluated which is set to true at evaluation and toggled to false in backward (which may be crude enough, but worked not to recompute weight at each time step of rnn).\nIt is still a hook-based implementation, and conceptually I agree that all the same things can be achieved by module wrappers.", "body": "Incidentally, we have also been working on abstracting reparameterization https://github.com/NVIDIA/apex/tree/master/apex/reparameterization. Current implementation puts boilerplate code to reparameterization.py, with weight norm defining just particular weight recomputation functions. The recomputation of weight is controlled by `self.evaluated` which is set to true at evaluation and toggled to false in backward (which may be crude enough, but worked not to recompute weight at each time step of rnn). \r\nIt is still a hook-based implementation, and conceptually I agree that all the same things can be achieved by module wrappers.  "}