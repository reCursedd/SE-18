{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/381653210", "html_url": "https://github.com/pytorch/pytorch/pull/6599#issuecomment-381653210", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6599", "id": 381653210, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTY1MzIxMA==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-16T15:50:16Z", "updated_at": "2018-04-16T15:50:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think we do eventually want to deprecate <code>set_default_tensor_type</code>; the issue is how to do that in a sensible and backwards compatible way.  E.g. the most straightforward addition would be <code>set_default_device</code> or <code>set_default_device_type</code>, (default of 'cpu'), but this has strange semantics, e.g.:</p>\n<p>Today:</p>\n<pre><code>with torch.cuda.device(1):\n   torch.randn((5,5)).type()\n'torch.FloatTensor'\n</code></pre>\n<p>So, do I have to set the default device type to cuda before my cuda device ctx managers work?  Maybe the correct thing to do at the moment is to add <code>torch.device_ctx_manager</code> and <code>torch.device_of</code> managers and those manage the default tensor type and (if necessary) the current cuda device.  We still have more bits mapping to fewer bits, but we can recommend using these instead of the <code>cuda</code> equivalents and <code>default_tensor_types</code>, and they can eventually control something other than <code>default_tensor_type</code>.  Thoughts?</p>", "body_text": "I think we do eventually want to deprecate set_default_tensor_type; the issue is how to do that in a sensible and backwards compatible way.  E.g. the most straightforward addition would be set_default_device or set_default_device_type, (default of 'cpu'), but this has strange semantics, e.g.:\nToday:\nwith torch.cuda.device(1):\n   torch.randn((5,5)).type()\n'torch.FloatTensor'\n\nSo, do I have to set the default device type to cuda before my cuda device ctx managers work?  Maybe the correct thing to do at the moment is to add torch.device_ctx_manager and torch.device_of managers and those manage the default tensor type and (if necessary) the current cuda device.  We still have more bits mapping to fewer bits, but we can recommend using these instead of the cuda equivalents and default_tensor_types, and they can eventually control something other than default_tensor_type.  Thoughts?", "body": "I think we do eventually want to deprecate `set_default_tensor_type`; the issue is how to do that in a sensible and backwards compatible way.  E.g. the most straightforward addition would be `set_default_device` or `set_default_device_type`, (default of 'cpu'), but this has strange semantics, e.g.:\r\n\r\nToday:\r\n```\r\nwith torch.cuda.device(1):\r\n   torch.randn((5,5)).type()\r\n'torch.FloatTensor'\r\n```\r\n\r\nSo, do I have to set the default device type to cuda before my cuda device ctx managers work?  Maybe the correct thing to do at the moment is to add `torch.device_ctx_manager` and `torch.device_of` managers and those manage the default tensor type and (if necessary) the current cuda device.  We still have more bits mapping to fewer bits, but we can recommend using these instead of the `cuda` equivalents and `default_tensor_types`, and they can eventually control something other than `default_tensor_type`.  Thoughts?"}