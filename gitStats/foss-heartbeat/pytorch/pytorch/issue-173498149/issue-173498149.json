{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5/events", "html_url": "https://github.com/pytorch/pytorch/issues/5", "id": 173498149, "node_id": "MDU6SXNzdWUxNzM0OTgxNDk=", "number": 5, "title": "Checklist for Release", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-08-26T16:59:48Z", "updated_at": "2017-04-28T13:41:53Z", "closed_at": "2017-04-18T21:31:43Z", "author_association": "MEMBER", "body_html": "<h2>Core</h2>\n<h3>Core Framework code</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> optim + trainer + dataset objects</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Sharing CPU tensors</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Add all operations to autograd</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Free GIL when processing big tensors</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Custom CUDA memory allocator (Sam Gross)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> multi-GPU functions</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> nccl integration</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> finish legacy.nn</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> refactor C API for extensions</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> create an example extension with TH/pytorch C API</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Checkpointing and improving torch.save / torch.load to use the same byte order</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> implement keyword arguments in cwrap</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> go over TH and try to make error messages more descriptive (e.g. if the sizes don't match )</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Sparse Tensors on CPU and GPU (Zeming)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> improve tensor printing</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> functional API for autograd variables</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Finish multiple CUDA types (Soumith)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Add stochastic nodes</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Add all modules to nn</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Improved error messages <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177669684\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/39\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/39/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/39\">#39</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> sync legacy.nn with Lua nn</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> move Trainer to torch.experimental</li>\n</ul>\n<h3>Operations</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Integrate CuDNN</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Write nn.LSTM*, nn.GRU* etc. to integrate CuDNN RNNs</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Rewrite LookupTable and SparseLinear to use SparseTensors</li>\n</ul>\n<h2>FBCode stuff</h2>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Import into FBCode</li>\n</ul>\n<h2>Open Source stuff</h2>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Binary builds</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Continuous builds for CUDA</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MNIST and ResNet18 Contbuilds</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> pip wheels</li>\n</ul>\n<h2>Backward Compatibility</h2>\n<h3>Lua Bridge</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> integrate lutorpy into pytorch (either as optional package or by default)\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> change TH indexing to 0-based and add to cwrap the 1-subtraction and addition</li>\n</ul>\n</li>\n</ul>\n<h3>Model Loading</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Build a simple model loader based on <a href=\"https://github.com/bshillingford/python-torchfile\">https://github.com/bshillingford/python-torchfile</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Apply backward-compatibility patches (they've been removed from legacy nn)</li>\n</ul>\n<h2>Framework Integration</h2>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Caffe2 Integration\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Modify TH / THC  / THNN / THCUNN to integrate them</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Have a converter that takes in a (Module and input) or (output) and auto-converts it to caffe model\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> vice versa. take a caffe protobuf and codegen a python class with loading weights</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Keras Integration\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Have a keras backend. Send in a Pull Request to fchollet/keras</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Converting models between TF and Pytorch\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Torch2TF: Same as caffe convertor pretty much!</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> TF2Torch: same as caffe, but cover ops like tf.if and tf.while</li>\n</ul>\n</li>\n</ul>\n<h2>Website</h2>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Find someone to design and code it</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Getting Started\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Binary installs\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> anaconda-based which links automatically with MKL</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Each of them for different CUDA versions. 7.0, 7.5, 8.0</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Source-based installs</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Showcase Demos / Examples / ModelZoo elegantly</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Tutorials</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Look at gym.openai.com (<a href=\"http://gym.openai.com/\" rel=\"nofollow\">http://gym.openai.com/</a>)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Developer docs</li>\n</ul>\n<h2>Documentation, Demos, Examples, Tutorials, ModelZoo</h2>\n<h3>Demos / Examples / ModelZoo</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Pre-trained models for each demo (in the model zoo)\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Create a python wrapper that allows to search and download models (like nltk)</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Simple API for retraining / using pre-trained models on custom datasets</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Documentation on how to modify the example for one's own experiments</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Most or all of them should be multi-GPU ready</li>\n</ul>\n<h3>Demos + Examples</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Basic\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Autoencoders <a href=\"https://github.com/Kaixhin/Autoencoders\">https://github.com/Kaixhin/Autoencoders</a></li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Vision\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Supervised\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> fb.resnet.torch / googlenet for image classification (sam)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> fastrcnn (francisco)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Video Classification</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> NeuralTalk2 (paszke)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Visual Q&amp;A (paszke)</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Unsupervised\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Image super-resolution (wafi2x) (soumith)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> DCGANs + Improved Training for GANs + InfoGAN</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Text 2 Image (soumith)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Pixel RNNs (soumith)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Variational AutoEncoders (joost)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Games / RL (ludc)\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Good integration with gym.openai.com (<a href=\"http://gym.openai.com/\" rel=\"nofollow\">http://gym.openai.com/</a>)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> RL examples</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> NLP / Text\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> OpenNMT - attention based Seq2seq with MT(Lerer)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Sentiment Analysis</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Memory networks for Q &amp; A (memn2n) <a href=\"https://github.com/taey16/MemN2N-python\">https://github.com/taey16/MemN2N-python</a></li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Metalearning\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Neural Turing Machine</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Learning to Learn by Gradient Descent by Gradient Descent</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Decoupled Neural Interfaces using Synthetic Gradients <a href=\"https://arxiv.org/abs/1608.05343\" rel=\"nofollow\">https://arxiv.org/abs/1608.05343</a></li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> ConvNet-Benchmarks / DeepMark scripts</li>\n</ul>\n<h3>Tutorials</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"193123723\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/288\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/288/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/288\">#288</a></li>\n</ul>\n<h3>Documentation</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Auto-generate from source / docstrings</li>\n</ul>\n<h2>Links</h2>\n<ul>\n<li>[1] <a href=\"http://elm-lang.org/blog/compiler-errors-for-humans\" rel=\"nofollow\">http://elm-lang.org/blog/compiler-errors-for-humans</a></li>\n<li>[2] <a href=\"http://elm-lang.org/blog/compilers-as-assistants\" rel=\"nofollow\">http://elm-lang.org/blog/compilers-as-assistants</a></li>\n</ul>\n<p>Postponed for next release</p>\n<ul>\n<li>lazy forward execution engine</li>\n<li>double backprop</li>\n<li>Sharing CUDA tensors</li>\n<li>look into Cython</li>\n<li>a built-in profiler for forward/backward (with automatic hints for speeding up the execution?)</li>\n</ul>\n<h2>AIViz Integration</h2>\n<ul>\n<li>\n<p>Have an intial attempt, and talk to Allan</p>\n</li>\n<li>\n<p>Serveable via some Python REST API</p>\n</li>\n<li>\n<p>figure out details for images and videos</p>\n</li>\n<li>\n<p>Audio</p>\n</li>\n<li>\n<p>wav2letter</p>\n</li>\n<li>\n<p>DeepSpeech2 for maybe Switchboard or something (Ask Gabriel)</p>\n</li>\n<li>\n<p>Sparse Models (ads?)</p>\n</li>\n</ul>\n<h2>Distributed Training</h2>\n<ul>\n<li>\n<p>simple distributed trainer like torch-distlearn / torch-ipc / torch-thrift</p>\n</li>\n<li>\n<p>Synchronous, asynchronous and Elastic SGD</p>\n</li>\n<li>\n<p>Integrate with Andrew / Yangqing's MPI library when that's ready</p>\n</li>\n<li>\n<p>Port image classification and seq2seq to this</p>\n</li>\n<li>\n<p>error handling</p>\n<ul>\n<li>create a dict for translating exceptions and adding some pytorch specific info, sort of like in Elm [1,2]</li>\n<li>make sure there's a clear error message when multiprocessing runs out of fds</li>\n</ul>\n</li>\n</ul>", "body_text": "Core\nCore Framework code\n\n optim + trainer + dataset objects\n Sharing CPU tensors\n Add all operations to autograd\n Free GIL when processing big tensors\n Custom CUDA memory allocator (Sam Gross)\n multi-GPU functions\n nccl integration\n finish legacy.nn\n refactor C API for extensions\n create an example extension with TH/pytorch C API\n Checkpointing and improving torch.save / torch.load to use the same byte order\n implement keyword arguments in cwrap\n go over TH and try to make error messages more descriptive (e.g. if the sizes don't match )\n Sparse Tensors on CPU and GPU (Zeming)\n improve tensor printing\n functional API for autograd variables\n Finish multiple CUDA types (Soumith)\n Add stochastic nodes\n Add all modules to nn\n Improved error messages #39\n sync legacy.nn with Lua nn\n move Trainer to torch.experimental\n\nOperations\n\n Integrate CuDNN\n Write nn.LSTM*, nn.GRU* etc. to integrate CuDNN RNNs\n Rewrite LookupTable and SparseLinear to use SparseTensors\n\nFBCode stuff\n\n Import into FBCode\n\nOpen Source stuff\n\n Binary builds\n Continuous builds for CUDA\n MNIST and ResNet18 Contbuilds\n pip wheels\n\nBackward Compatibility\nLua Bridge\n\n integrate lutorpy into pytorch (either as optional package or by default)\n\n change TH indexing to 0-based and add to cwrap the 1-subtraction and addition\n\n\n\nModel Loading\n\n Build a simple model loader based on https://github.com/bshillingford/python-torchfile\n Apply backward-compatibility patches (they've been removed from legacy nn)\n\nFramework Integration\n\n Caffe2 Integration\n\n Modify TH / THC  / THNN / THCUNN to integrate them\n Have a converter that takes in a (Module and input) or (output) and auto-converts it to caffe model\n\n vice versa. take a caffe protobuf and codegen a python class with loading weights\n\n\n\n\n Keras Integration\n\n Have a keras backend. Send in a Pull Request to fchollet/keras\n\n\n Converting models between TF and Pytorch\n\n Torch2TF: Same as caffe convertor pretty much!\n TF2Torch: same as caffe, but cover ops like tf.if and tf.while\n\n\n\nWebsite\n\n Find someone to design and code it\n Getting Started\n\n Binary installs\n\n anaconda-based which links automatically with MKL\n Each of them for different CUDA versions. 7.0, 7.5, 8.0\n\n\n Source-based installs\n\n\n Showcase Demos / Examples / ModelZoo elegantly\n Tutorials\n Look at gym.openai.com (http://gym.openai.com/)\n Developer docs\n\nDocumentation, Demos, Examples, Tutorials, ModelZoo\nDemos / Examples / ModelZoo\n\n Pre-trained models for each demo (in the model zoo)\n\n Create a python wrapper that allows to search and download models (like nltk)\n\n\n Simple API for retraining / using pre-trained models on custom datasets\n Documentation on how to modify the example for one's own experiments\n Most or all of them should be multi-GPU ready\n\nDemos + Examples\n\n Basic\n\n Autoencoders https://github.com/Kaixhin/Autoencoders\n\n\n Vision\n\n Supervised\n\n fb.resnet.torch / googlenet for image classification (sam)\n fastrcnn (francisco)\n Video Classification\n NeuralTalk2 (paszke)\n Visual Q&A (paszke)\n\n\n Unsupervised\n\n Image super-resolution (wafi2x) (soumith)\n DCGANs + Improved Training for GANs + InfoGAN\n Text 2 Image (soumith)\n Pixel RNNs (soumith)\n Variational AutoEncoders (joost)\n\n\n\n\n Games / RL (ludc)\n\n Good integration with gym.openai.com (http://gym.openai.com/)\n RL examples\n\n\n NLP / Text\n\n OpenNMT - attention based Seq2seq with MT(Lerer)\n Sentiment Analysis\n Memory networks for Q & A (memn2n) https://github.com/taey16/MemN2N-python\n\n\n Metalearning\n\n Neural Turing Machine\n Learning to Learn by Gradient Descent by Gradient Descent\n Decoupled Neural Interfaces using Synthetic Gradients https://arxiv.org/abs/1608.05343\n\n\n ConvNet-Benchmarks / DeepMark scripts\n\nTutorials\n\n See #288\n\nDocumentation\n\n Auto-generate from source / docstrings\n\nLinks\n\n[1] http://elm-lang.org/blog/compiler-errors-for-humans\n[2] http://elm-lang.org/blog/compilers-as-assistants\n\nPostponed for next release\n\nlazy forward execution engine\ndouble backprop\nSharing CUDA tensors\nlook into Cython\na built-in profiler for forward/backward (with automatic hints for speeding up the execution?)\n\nAIViz Integration\n\n\nHave an intial attempt, and talk to Allan\n\n\nServeable via some Python REST API\n\n\nfigure out details for images and videos\n\n\nAudio\n\n\nwav2letter\n\n\nDeepSpeech2 for maybe Switchboard or something (Ask Gabriel)\n\n\nSparse Models (ads?)\n\n\nDistributed Training\n\n\nsimple distributed trainer like torch-distlearn / torch-ipc / torch-thrift\n\n\nSynchronous, asynchronous and Elastic SGD\n\n\nIntegrate with Andrew / Yangqing's MPI library when that's ready\n\n\nPort image classification and seq2seq to this\n\n\nerror handling\n\ncreate a dict for translating exceptions and adding some pytorch specific info, sort of like in Elm [1,2]\nmake sure there's a clear error message when multiprocessing runs out of fds", "body": "## Core\r\n### Core Framework code\r\n- [x] optim + trainer + dataset objects\r\n- [x] Sharing CPU tensors\r\n- [x] Add all operations to autograd\r\n- [x] Free GIL when processing big tensors\r\n- [x] Custom CUDA memory allocator (Sam Gross)\r\n- [x] multi-GPU functions\r\n- [x] nccl integration\r\n- [x] finish legacy.nn\r\n- [x] refactor C API for extensions\r\n- [x] create an example extension with TH/pytorch C API\r\n- [x] Checkpointing and improving torch.save / torch.load to use the same byte order\r\n- [x] implement keyword arguments in cwrap\r\n- [x] go over TH and try to make error messages more descriptive (e.g. if the sizes don't match )\r\n- [ ] Sparse Tensors on CPU and GPU (Zeming)\r\n- [x] improve tensor printing\r\n- [x] functional API for autograd variables\r\n- [x] Finish multiple CUDA types (Soumith)\r\n- [x] Add stochastic nodes\r\n- [x] Add all modules to nn\r\n- [ ] Improved error messages #39 \r\n- [ ] sync legacy.nn with Lua nn\r\n- [ ] move Trainer to torch.experimental\r\n### Operations\r\n- [x] Integrate CuDNN\r\n- [x] Write nn.LSTM*, nn.GRU* etc. to integrate CuDNN RNNs\r\n- [x] Rewrite LookupTable and SparseLinear to use SparseTensors\r\n## FBCode stuff\r\n- [x] Import into FBCode\r\n## Open Source stuff\r\n- [x] Binary builds\r\n- [x] Continuous builds for CUDA\r\n- [ ] MNIST and ResNet18 Contbuilds\r\n- [x] pip wheels\r\n## Backward Compatibility\r\n### Lua Bridge\r\n- [ ] integrate lutorpy into pytorch (either as optional package or by default)\r\n   - [ ] change TH indexing to 0-based and add to cwrap the 1-subtraction and addition\r\n### Model Loading\r\n- [x] Build a simple model loader based on https://github.com/bshillingford/python-torchfile\r\n- [x] Apply backward-compatibility patches (they've been removed from legacy nn)\r\n## Framework Integration\r\n- [ ] Caffe2 Integration\r\n  - [ ] Modify TH / THC  / THNN / THCUNN to integrate them\r\n  - [ ] Have a converter that takes in a (Module and input) or (output) and auto-converts it to caffe model\r\n    - [ ] vice versa. take a caffe protobuf and codegen a python class with loading weights\r\n- [ ] Keras Integration\r\n  - [ ] Have a keras backend. Send in a Pull Request to fchollet/keras\r\n- [ ] Converting models between TF and Pytorch\r\n  - [ ] Torch2TF: Same as caffe convertor pretty much!\r\n  - [ ] TF2Torch: same as caffe, but cover ops like tf.if and tf.while\r\n## Website\r\n- [x] Find someone to design and code it\r\n- [x] Getting Started\r\n  - [x] Binary installs\r\n    - [x] anaconda-based which links automatically with MKL\r\n    - [x] Each of them for different CUDA versions. 7.0, 7.5, 8.0\r\n  - [x] Source-based installs\r\n- [ ] Showcase Demos / Examples / ModelZoo elegantly\r\n- [x] Tutorials\r\n- [x] Look at gym.openai.com (http://gym.openai.com/) \r\n- [x] Developer docs\r\n## Documentation, Demos, Examples, Tutorials, ModelZoo\r\n### Demos / Examples / ModelZoo\r\n- [x] Pre-trained models for each demo (in the model zoo)\r\n  - [x] Create a python wrapper that allows to search and download models (like nltk)\r\n- [x] Simple API for retraining / using pre-trained models on custom datasets\r\n- [x] Documentation on how to modify the example for one's own experiments\r\n- [x] Most or all of them should be multi-GPU ready\r\n### Demos + Examples\r\n- [x] Basic\r\n  - [x] Autoencoders https://github.com/Kaixhin/Autoencoders\r\n- [ ] Vision\r\n  - [ ] Supervised\r\n    - [x] fb.resnet.torch / googlenet for image classification (sam)\r\n    - [x] fastrcnn (francisco)\r\n    - [ ] Video Classification\r\n    - [ ] NeuralTalk2 (paszke)\r\n    - [x] Visual Q&A (paszke)\r\n  - [ ] Unsupervised\r\n    - [x] Image super-resolution (wafi2x) (soumith)\r\n    - [x] DCGANs + Improved Training for GANs + InfoGAN\r\n    - [ ] Text 2 Image (soumith)\r\n    - [ ] Pixel RNNs (soumith)\r\n    - [x] Variational AutoEncoders (joost)\r\n- [x] Games / RL (ludc)\r\n  - [x] Good integration with gym.openai.com (http://gym.openai.com/)\r\n  - [x] RL examples\r\n- [ ] NLP / Text\r\n    - [x] OpenNMT - attention based Seq2seq with MT(Lerer)\r\n  - [ ] Sentiment Analysis\r\n  - [ ] Memory networks for Q & A (memn2n) https://github.com/taey16/MemN2N-python\r\n- [ ] Metalearning\r\n  - [ ] Neural Turing Machine\r\n  - [x] Learning to Learn by Gradient Descent by Gradient Descent\r\n  - [ ] Decoupled Neural Interfaces using Synthetic Gradients https://arxiv.org/abs/1608.05343\r\n- [ ] ConvNet-Benchmarks / DeepMark scripts\r\n### Tutorials\r\n- [x] See #288 \r\n### Documentation\r\n- [x] Auto-generate from source / docstrings\r\n## Links\r\n- [1] http://elm-lang.org/blog/compiler-errors-for-humans\r\n- [2] http://elm-lang.org/blog/compilers-as-assistants\r\n\r\n\r\n\r\nPostponed for next release\r\n-  lazy forward execution engine\r\n-  double backprop\r\n-  Sharing CUDA tensors\r\n -  look into Cython\r\n-  a built-in profiler for forward/backward (with automatic hints for speeding up the execution?)\r\n## AIViz Integration\r\n-  Have an intial attempt, and talk to Allan\r\n\r\n-  Serveable via some Python REST API\r\n  -  figure out details for images and videos\r\n\r\n-  Audio\r\n  -  wav2letter\r\n  -  DeepSpeech2 for maybe Switchboard or something (Ask Gabriel)\r\n-  Sparse Models (ads?)\r\n\r\n## Distributed Training\r\n-  simple distributed trainer like torch-distlearn / torch-ipc / torch-thrift\r\n-  Synchronous, asynchronous and Elastic SGD\r\n-  Integrate with Andrew / Yangqing's MPI library when that's ready\r\n-  Port image classification and seq2seq to this\r\n\r\n- error handling\r\n  -  create a dict for translating exceptions and adding some pytorch specific info, sort of like in Elm [1,2]\r\n  -  make sure there's a clear error message when multiprocessing runs out of fds\r\n"}