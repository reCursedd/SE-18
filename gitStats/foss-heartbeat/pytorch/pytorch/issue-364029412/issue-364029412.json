{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12085", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12085/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12085/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12085/events", "html_url": "https://github.com/pytorch/pytorch/issues/12085", "id": 364029412, "node_id": "MDU6SXNzdWUzNjQwMjk0MTI=", "number": 12085, "title": "Multiprocessing error on Windows when input size is over 4GB", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 790080431, "node_id": "MDU6TGFiZWw3OTAwODA0MzE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/windows", "name": "windows", "color": "fcff6b", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-26T13:26:11Z", "updated_at": "2018-09-26T13:30:26Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>From this <a href=\"https://discuss.pytorch.org/t/pytorch-windows-eoferror-ran-out-of-input-when-num-workers-0/25918/2\" rel=\"nofollow\">post</a>, the following error will be thrown when the input size exceeds 4GB.</p>\n<div class=\"highlight highlight-text-python-traceback\"><pre>Traceback (most recent call last):\n  File <span class=\"pl-s\">\"train.py\"</span>, line <span class=\"pl-c1\">159</span>, in <span class=\"pl-en\">&lt;module&gt;</span>\n    main()\n  File <span class=\"pl-s\">\"train.py\"</span>, line <span class=\"pl-c1\">111</span>, in <span class=\"pl-en\">main</span>\n    <span class=\"pl-k\">for</span> i_batch, sample_batched <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(Dataloader_Train):\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\"</span>, line <span class=\"pl-c1\">451</span>, in <span class=\"pl-en\">__iter__</span>\n    <span class=\"pl-k\">return</span> _DataLoaderIter(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\"</span>, line <span class=\"pl-c1\">239</span>, in <span class=\"pl-en\">__init__</span>\n    w.start()\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\process.py\"</span>, line <span class=\"pl-c1\">105</span>, in <span class=\"pl-en\">start</span>\n    <span class=\"pl-c1\">self</span>._popen <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._Popen(<span class=\"pl-c1\">self</span>)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\"</span>, line <span class=\"pl-c1\">212</span>, in <span class=\"pl-en\">_Popen</span>\n    <span class=\"pl-k\">return</span> _default_context.get_context().Process._Popen(process_obj)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\"</span>, line <span class=\"pl-c1\">313</span>, in <span class=\"pl-en\">_Popen</span>\n    <span class=\"pl-k\">return</span> Popen(process_obj)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\popen_spawn_win32.py\"</span>, line <span class=\"pl-c1\">66</span>, in <span class=\"pl-en\">__init__</span>\n    reduction.dump(process_obj, to_child)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\reduction.py\"</span>, line <span class=\"pl-c1\">59</span>, in <span class=\"pl-en\">dump</span>\n    ForkingPickler(<span class=\"pl-v\">file</span>, protocol).dump(obj)\n<span class=\"pl-en\">OverflowError</span>: <span class=\"pl-s\">cannot serialize a bytes object larger than 4 GiB</span>\n\n(py3_pt3_orig) C:\\Users\\TestUser\\Documents\\eliaseulig\\DeepDSA&gt;Traceback (most recent call last):\n  File <span class=\"pl-s\">\"&lt;string&gt;\"</span>, line <span class=\"pl-c1\">1</span>, in <span class=\"pl-en\">&lt;module&gt;</span>\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\"</span>, line <span class=\"pl-c1\">106</span>, in <span class=\"pl-en\">spawn_main</span>\n    exitcode <span class=\"pl-k\">=</span> _main(fd)\n  File <span class=\"pl-s\">\"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\"</span>, line <span class=\"pl-c1\">116</span>, in <span class=\"pl-en\">_main</span>\n    <span class=\"pl-c1\">self</span> <span class=\"pl-k\">=</span> pickle.load(from_parent)\n<span class=\"pl-en\">EOFError</span>: <span class=\"pl-s\">Ran out of input</span></pre></div>\n<h2>Code example</h2>\n<p>Please try to provide a minimal example to repro the bug.<br>\nError messages and stack traces are also helpful.</p>", "body_text": "Issue description\nFrom this post, the following error will be thrown when the input size exceeds 4GB.\nTraceback (most recent call last):\n  File \"train.py\", line 159, in <module>\n    main()\n  File \"train.py\", line 111, in main\n    for i_batch, sample_batched in enumerate(Dataloader_Train):\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 451, in __iter__\n    return _DataLoaderIter(self)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 239, in __init__\n    w.start()\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\process.py\", line 105, in start\n    self._popen = self._Popen(self)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\", line 212, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\", line 313, in _Popen\n    return Popen(process_obj)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\n    reduction.dump(process_obj, to_child)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\reduction.py\", line 59, in dump\n    ForkingPickler(file, protocol).dump(obj)\nOverflowError: cannot serialize a bytes object larger than 4 GiB\n\n(py3_pt3_orig) C:\\Users\\TestUser\\Documents\\eliaseulig\\DeepDSA>Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\", line 106, in spawn_main\n    exitcode = _main(fd)\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\", line 116, in _main\n    self = pickle.load(from_parent)\nEOFError: Ran out of input\nCode example\nPlease try to provide a minimal example to repro the bug.\nError messages and stack traces are also helpful.", "body": "## Issue description\r\n\r\nFrom this [post](https://discuss.pytorch.org/t/pytorch-windows-eoferror-ran-out-of-input-when-num-workers-0/25918/2), the following error will be thrown when the input size exceeds 4GB.\r\n```pytb\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 159, in <module>\r\n    main()\r\n  File \"train.py\", line 111, in main\r\n    for i_batch, sample_batched in enumerate(Dataloader_Train):\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 451, in __iter__\r\n    return _DataLoaderIter(self)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 239, in __init__\r\n    w.start()\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\", line 212, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\context.py\", line 313, in _Popen\r\n    return Popen(process_obj)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\popen_spawn_win32.py\", line 66, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\reduction.py\", line 59, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nOverflowError: cannot serialize a bytes object larger than 4 GiB\r\n\r\n(py3_pt3_orig) C:\\Users\\TestUser\\Documents\\eliaseulig\\DeepDSA>Traceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\", line 106, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"C:\\Users\\TestUser\\Anaconda3\\envs\\py3_pt3_orig\\lib\\multiprocessing\\spawn.py\", line 116, in _main\r\n    self = pickle.load(from_parent)\r\nEOFError: Ran out of input\r\n```\r\n\r\n## Code example\r\n\r\nPlease try to provide a minimal example to repro the bug.\r\nError messages and stack traces are also helpful.\r\n"}