{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/343786361", "html_url": "https://github.com/pytorch/pytorch/issues/3644#issuecomment-343786361", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3644", "id": 343786361, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Mzc4NjM2MQ==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-13T01:26:22Z", "updated_at": "2017-11-13T01:43:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5921083\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mys007\">@mys007</a> I believe this is a rounding error.</p>\n<p>I took your code and modified it slightly to print out the one entry (entry (0, 2)) of the gradsI[i] and gradsI[j] matrices that seems to be responsible for the large magnitude.<br>\n<a href=\"https://gist.github.com/zou3519/de11aa86df07712784c5009ce0362787\">https://gist.github.com/zou3519/de11aa86df07712784c5009ce0362787</a></p>\n<p>The output is:</p>\n<pre><code>-------------------\n0 0 0.0 0.0\n9.737174387686579e+23 9.737174387686579e+23\n-------------------\n0 1 1.4411518807585587e+17 0.0\n9.737174387686579e+23 9.737175108262519e+23\n-------------------\n1 0 1.4411518807585587e+17 0.0\n9.737175108262519e+23 9.737174387686579e+23\n-------------------\n1 1 0.0 0.0\n9.737175108262519e+23 9.737175108262519e+23\n</code></pre>\n<p>(the two numbers in the second row of each group are <code>gradsI[i][0, 2] and gradsI[j][0, 2]</code>).<br>\nBecause we're doing floating point math, we can expect the numbers to be accurate to 7 digits, which they are. However, subtracting the numbers gives a difference of something that is ~1e17, as you noticed.</p>\n<p>Changing your code to use double tensors (I changed the line <code>input = torch.randn(n, c)</code> to <code>input = torch.randn(n, c).double()</code>) gives better results for me:</p>\n<pre><code>-------------------\n0 0 0.0 0.0\n9.737195888283742e+23 9.737195888283742e+23\n-------------------\n0 1 134217728.0 0.0\n9.737195888283742e+23 9.737195888283741e+23\n-------------------\n1 0 134217728.0 0.0\n9.737195888283741e+23 9.737195888283742e+23\n-------------------\n1 1 0.0 0.0\n9.737195888283741e+23 9.737195888283741e+23\n</code></pre>\n<p>There's still a difference but the double math has made it more precise.</p>", "body_text": "@mys007 I believe this is a rounding error.\nI took your code and modified it slightly to print out the one entry (entry (0, 2)) of the gradsI[i] and gradsI[j] matrices that seems to be responsible for the large magnitude.\nhttps://gist.github.com/zou3519/de11aa86df07712784c5009ce0362787\nThe output is:\n-------------------\n0 0 0.0 0.0\n9.737174387686579e+23 9.737174387686579e+23\n-------------------\n0 1 1.4411518807585587e+17 0.0\n9.737174387686579e+23 9.737175108262519e+23\n-------------------\n1 0 1.4411518807585587e+17 0.0\n9.737175108262519e+23 9.737174387686579e+23\n-------------------\n1 1 0.0 0.0\n9.737175108262519e+23 9.737175108262519e+23\n\n(the two numbers in the second row of each group are gradsI[i][0, 2] and gradsI[j][0, 2]).\nBecause we're doing floating point math, we can expect the numbers to be accurate to 7 digits, which they are. However, subtracting the numbers gives a difference of something that is ~1e17, as you noticed.\nChanging your code to use double tensors (I changed the line input = torch.randn(n, c) to input = torch.randn(n, c).double()) gives better results for me:\n-------------------\n0 0 0.0 0.0\n9.737195888283742e+23 9.737195888283742e+23\n-------------------\n0 1 134217728.0 0.0\n9.737195888283742e+23 9.737195888283741e+23\n-------------------\n1 0 134217728.0 0.0\n9.737195888283741e+23 9.737195888283742e+23\n-------------------\n1 1 0.0 0.0\n9.737195888283741e+23 9.737195888283741e+23\n\nThere's still a difference but the double math has made it more precise.", "body": "@mys007 I believe this is a rounding error.\r\n\r\nI took your code and modified it slightly to print out the one entry (entry (0, 2)) of the gradsI[i] and gradsI[j] matrices that seems to be responsible for the large magnitude.\r\nhttps://gist.github.com/zou3519/de11aa86df07712784c5009ce0362787\r\n\r\nThe output is:\r\n```\r\n-------------------\r\n0 0 0.0 0.0\r\n9.737174387686579e+23 9.737174387686579e+23\r\n-------------------\r\n0 1 1.4411518807585587e+17 0.0\r\n9.737174387686579e+23 9.737175108262519e+23\r\n-------------------\r\n1 0 1.4411518807585587e+17 0.0\r\n9.737175108262519e+23 9.737174387686579e+23\r\n-------------------\r\n1 1 0.0 0.0\r\n9.737175108262519e+23 9.737175108262519e+23\r\n```\r\n(the two numbers in the second row of each group are `gradsI[i][0, 2] and gradsI[j][0, 2]`).\r\nBecause we're doing floating point math, we can expect the numbers to be accurate to 7 digits, which they are. However, subtracting the numbers gives a difference of something that is ~1e17, as you noticed.\r\n\r\nChanging your code to use double tensors (I changed the line `input = torch.randn(n, c)` to `input = torch.randn(n, c).double()`) gives better results for me:\r\n```\r\n-------------------\r\n0 0 0.0 0.0\r\n9.737195888283742e+23 9.737195888283742e+23\r\n-------------------\r\n0 1 134217728.0 0.0\r\n9.737195888283742e+23 9.737195888283741e+23\r\n-------------------\r\n1 0 134217728.0 0.0\r\n9.737195888283741e+23 9.737195888283742e+23\r\n-------------------\r\n1 1 0.0 0.0\r\n9.737195888283741e+23 9.737195888283741e+23\r\n```\r\nThere's still a difference but the double math has made it more precise.\r\n\r\n"}