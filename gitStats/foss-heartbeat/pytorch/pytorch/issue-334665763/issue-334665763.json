{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8766", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8766/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8766/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8766/events", "html_url": "https://github.com/pytorch/pytorch/pull/8766", "id": 334665763, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk2NTgxNzQ0", "number": 8766, "title": "[c10d] Add performance measurement module", "user": {"login": "pietern", "id": 9845, "node_id": "MDQ6VXNlcjk4NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietern", "html_url": "https://github.com/pietern", "followers_url": "https://api.github.com/users/pietern/followers", "following_url": "https://api.github.com/users/pietern/following{/other_user}", "gists_url": "https://api.github.com/users/pietern/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietern/subscriptions", "organizations_url": "https://api.github.com/users/pietern/orgs", "repos_url": "https://api.github.com/users/pietern/repos", "events_url": "https://api.github.com/users/pietern/events{/privacy}", "received_events_url": "https://api.github.com/users/pietern/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-06-21T21:32:18Z", "updated_at": "2018-11-23T15:48:29Z", "closed_at": null, "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/8766", "html_url": "https://github.com/pytorch/pytorch/pull/8766", "diff_url": "https://github.com/pytorch/pytorch/pull/8766.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/8766.patch"}, "body_html": "<p>Example output (two processes on a shared machine, so this is by no means a controlled experiment):</p>\n<pre><code>$ python -m torch.distributed.c10d.perf --path /tmp/rdv --size 2 --rank 1\n concurrency     elements             p50             p90             p99        p50 xput\n           1         1000        0.000070        0.000089        0.000107     54.795 MB/s\n           2         1000        0.000114        0.000143        0.000174     67.086 MB/s\n           4         1000        0.000204        0.000263        0.000324     74.941 MB/s\n           8         1000        0.000435        0.000572        0.000745     70.214 MB/s\n           1        10000        0.000103        0.000125        0.000149    370.370 MB/s\n           2        10000        0.000148        0.000173        0.000197    516.129 MB/s\n           4        10000        0.000259        0.000315        0.000378    588.776 MB/s\n           8        10000        0.000548        0.000669        0.000799    556.522 MB/s\n           1       100000        0.000437        0.000515        0.000582    872.410 MB/s\n           2       100000        0.000551        0.000589        0.000670   1385.281 MB/s\n           4       100000        0.000835        0.001006        0.001171   1826.484 MB/s\n           8       100000        0.001642        0.001988        0.002258   1858.979 MB/s\n           1      1000000        0.004259        0.007038        0.012436    895.631 MB/s\n           2      1000000        0.008137        0.008695        0.009342    937.592 MB/s\n           4      1000000        0.012803        0.016692        0.019160   1191.773 MB/s\n           8      1000000        0.026787        0.036418        0.043551   1139.266 MB/s\n</code></pre>\n<p>This does not yet do multiple types and multiple tensors per call (i.e. 1 tensor per GPU). I want to add this before merging to make it a bit more complete.</p>", "body_text": "Example output (two processes on a shared machine, so this is by no means a controlled experiment):\n$ python -m torch.distributed.c10d.perf --path /tmp/rdv --size 2 --rank 1\n concurrency     elements             p50             p90             p99        p50 xput\n           1         1000        0.000070        0.000089        0.000107     54.795 MB/s\n           2         1000        0.000114        0.000143        0.000174     67.086 MB/s\n           4         1000        0.000204        0.000263        0.000324     74.941 MB/s\n           8         1000        0.000435        0.000572        0.000745     70.214 MB/s\n           1        10000        0.000103        0.000125        0.000149    370.370 MB/s\n           2        10000        0.000148        0.000173        0.000197    516.129 MB/s\n           4        10000        0.000259        0.000315        0.000378    588.776 MB/s\n           8        10000        0.000548        0.000669        0.000799    556.522 MB/s\n           1       100000        0.000437        0.000515        0.000582    872.410 MB/s\n           2       100000        0.000551        0.000589        0.000670   1385.281 MB/s\n           4       100000        0.000835        0.001006        0.001171   1826.484 MB/s\n           8       100000        0.001642        0.001988        0.002258   1858.979 MB/s\n           1      1000000        0.004259        0.007038        0.012436    895.631 MB/s\n           2      1000000        0.008137        0.008695        0.009342    937.592 MB/s\n           4      1000000        0.012803        0.016692        0.019160   1191.773 MB/s\n           8      1000000        0.026787        0.036418        0.043551   1139.266 MB/s\n\nThis does not yet do multiple types and multiple tensors per call (i.e. 1 tensor per GPU). I want to add this before merging to make it a bit more complete.", "body": "Example output (two processes on a shared machine, so this is by no means a controlled experiment):\r\n\r\n```\r\n$ python -m torch.distributed.c10d.perf --path /tmp/rdv --size 2 --rank 1\r\n concurrency     elements             p50             p90             p99        p50 xput\r\n           1         1000        0.000070        0.000089        0.000107     54.795 MB/s\r\n           2         1000        0.000114        0.000143        0.000174     67.086 MB/s\r\n           4         1000        0.000204        0.000263        0.000324     74.941 MB/s\r\n           8         1000        0.000435        0.000572        0.000745     70.214 MB/s\r\n           1        10000        0.000103        0.000125        0.000149    370.370 MB/s\r\n           2        10000        0.000148        0.000173        0.000197    516.129 MB/s\r\n           4        10000        0.000259        0.000315        0.000378    588.776 MB/s\r\n           8        10000        0.000548        0.000669        0.000799    556.522 MB/s\r\n           1       100000        0.000437        0.000515        0.000582    872.410 MB/s\r\n           2       100000        0.000551        0.000589        0.000670   1385.281 MB/s\r\n           4       100000        0.000835        0.001006        0.001171   1826.484 MB/s\r\n           8       100000        0.001642        0.001988        0.002258   1858.979 MB/s\r\n           1      1000000        0.004259        0.007038        0.012436    895.631 MB/s\r\n           2      1000000        0.008137        0.008695        0.009342    937.592 MB/s\r\n           4      1000000        0.012803        0.016692        0.019160   1191.773 MB/s\r\n           8      1000000        0.026787        0.036418        0.043551   1139.266 MB/s\r\n```\r\n\r\nThis does not yet do multiple types and multiple tensors per call (i.e. 1 tensor per GPU). I want to add this before merging to make it a bit more complete."}