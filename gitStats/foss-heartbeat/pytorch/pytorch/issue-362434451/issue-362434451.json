{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11922", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11922/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11922/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11922/events", "html_url": "https://github.com/pytorch/pytorch/issues/11922", "id": 362434451, "node_id": "MDU6SXNzdWUzNjI0MzQ0NTE=", "number": 11922, "title": "Failed to torch.save in a jupyter notebook", "user": {"login": "robbine", "id": 16010351, "node_id": "MDQ6VXNlcjE2MDEwMzUx", "avatar_url": "https://avatars1.githubusercontent.com/u/16010351?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robbine", "html_url": "https://github.com/robbine", "followers_url": "https://api.github.com/users/robbine/followers", "following_url": "https://api.github.com/users/robbine/following{/other_user}", "gists_url": "https://api.github.com/users/robbine/gists{/gist_id}", "starred_url": "https://api.github.com/users/robbine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robbine/subscriptions", "organizations_url": "https://api.github.com/users/robbine/orgs", "repos_url": "https://api.github.com/users/robbine/repos", "events_url": "https://api.github.com/users/robbine/events{/privacy}", "received_events_url": "https://api.github.com/users/robbine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 545367190, "node_id": "MDU6TGFiZWw1NDUzNjcxOTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-09-21T02:35:14Z", "updated_at": "2018-09-24T17:48:30Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>This problem occurs after several epochs of training. At the end of each epoch I used torch.save to persist a model.  I checked disk capacity, it shouldn't be a problem.<br>\nHere is the code snippet which probably caused the jupyter kernel dead.<br>\n<code>       if self._serialization_dir is not None: model_path = os.path.join(self._serialization_dir, \"model_state_epoch_{}.th\".format(epoch)) model_state = self._model.state_dict() torch.save(model_state, model_path) # **This line caused the kernel died**.</code><br>\nHere I listed all the models and I find that size of 'model_state_epoch_7.th' is only 12K which is much smaller compared with previous models.<br>\n-rw-r--r-- 1 root root  45M Sep 20 18:46 model_state_epoch_4.th<br>\n-rw-r--r-- 1 root root  45M Sep 20 18:58 model_state_epoch_5.th<br>\n-rw-r--r-- 1 root root  45M Sep 20 19:11 model_state_epoch_6.th<br>\n-rw-r--r-- 1 root root  12K Sep 21 10:28 model_state_epoch_7.th<br>\nI tried to remove the last corrupted model file and recover training. It fails at the same point again and again.<br>\nAny ideas ?</p>", "body_text": "This problem occurs after several epochs of training. At the end of each epoch I used torch.save to persist a model.  I checked disk capacity, it shouldn't be a problem.\nHere is the code snippet which probably caused the jupyter kernel dead.\n       if self._serialization_dir is not None: model_path = os.path.join(self._serialization_dir, \"model_state_epoch_{}.th\".format(epoch)) model_state = self._model.state_dict() torch.save(model_state, model_path) # **This line caused the kernel died**.\nHere I listed all the models and I find that size of 'model_state_epoch_7.th' is only 12K which is much smaller compared with previous models.\n-rw-r--r-- 1 root root  45M Sep 20 18:46 model_state_epoch_4.th\n-rw-r--r-- 1 root root  45M Sep 20 18:58 model_state_epoch_5.th\n-rw-r--r-- 1 root root  45M Sep 20 19:11 model_state_epoch_6.th\n-rw-r--r-- 1 root root  12K Sep 21 10:28 model_state_epoch_7.th\nI tried to remove the last corrupted model file and recover training. It fails at the same point again and again.\nAny ideas ?", "body": "This problem occurs after several epochs of training. At the end of each epoch I used torch.save to persist a model.  I checked disk capacity, it shouldn't be a problem. \r\nHere is the code snippet which probably caused the jupyter kernel dead.\r\n`        if self._serialization_dir is not None:\r\n            model_path = os.path.join(self._serialization_dir, \"model_state_epoch_{}.th\".format(epoch))\r\n            model_state = self._model.state_dict()\r\n            torch.save(model_state, model_path) # **This line caused the kernel died**.\r\n`\r\nHere I listed all the models and I find that size of 'model_state_epoch_7.th' is only 12K which is much smaller compared with previous models.\r\n-rw-r--r-- 1 root root  45M Sep 20 18:46 model_state_epoch_4.th\r\n-rw-r--r-- 1 root root  45M Sep 20 18:58 model_state_epoch_5.th\r\n-rw-r--r-- 1 root root  45M Sep 20 19:11 model_state_epoch_6.th\r\n-rw-r--r-- 1 root root  12K Sep 21 10:28 model_state_epoch_7.th\r\nI tried to remove the last corrupted model file and recover training. It fails at the same point again and again.\r\nAny ideas ?"}