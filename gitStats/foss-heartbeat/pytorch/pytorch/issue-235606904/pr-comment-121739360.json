{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121739360", "pull_request_review_id": 43791620, "id": 121739360, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTczOTM2MA==", "diff_hunk": "@@ -279,6 +279,36 @@ def __repr__(self):\n         return self.__class__.__name__ + inplace_str\n \n \n+class GLU(Module):\n+    \"\"\"Applies the gated linear unit function :math:`{GLU}(a, b)= a \\otimes \\sigma(b)`\n+    where `a` is the first half of the input vector and `b` is the second half.", "path": "torch/nn/modules/activation.py", "position": 6, "original_position": 6, "commit_id": "991aa38c5a497d1cfa6fd3e16fd0a2b22380a39c", "original_commit_id": "6011d52fc12036b4b244a09e1c9cb226612e640a", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "I thought about this, but it's less convenient in practice. Gated linear units are used on the outputs of convolutional layers (https://arxiv.org/abs/1612.08083, https://arxiv.org/abs/1705.03122, https://arxiv.org/abs/1705.06824). You implement this with something like:\r\n\r\n```\r\nm = nn.Conv1d(input_planes, output_planes * 2)\r\nF.glu(m(input))\r\n```\r\n\r\nFor efficiency reasons, you don't want to split the Conv1d into two separate convolutions. If you took in two separate inputs, you'd have to add splitting code everywhere before you call glu. ", "created_at": "2017-06-13T17:09:14Z", "updated_at": "2018-11-23T15:33:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/1790#discussion_r121739360", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1790", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121739360"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1790#discussion_r121739360"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1790"}}, "body_html": "<p>I thought about this, but it's less convenient in practice. Gated linear units are used on the outputs of convolutional layers (<a href=\"https://arxiv.org/abs/1612.08083\" rel=\"nofollow\">https://arxiv.org/abs/1612.08083</a>, <a href=\"https://arxiv.org/abs/1705.03122\" rel=\"nofollow\">https://arxiv.org/abs/1705.03122</a>, <a href=\"https://arxiv.org/abs/1705.06824\" rel=\"nofollow\">https://arxiv.org/abs/1705.06824</a>). You implement this with something like:</p>\n<pre><code>m = nn.Conv1d(input_planes, output_planes * 2)\nF.glu(m(input))\n</code></pre>\n<p>For efficiency reasons, you don't want to split the Conv1d into two separate convolutions. If you took in two separate inputs, you'd have to add splitting code everywhere before you call glu.</p>", "body_text": "I thought about this, but it's less convenient in practice. Gated linear units are used on the outputs of convolutional layers (https://arxiv.org/abs/1612.08083, https://arxiv.org/abs/1705.03122, https://arxiv.org/abs/1705.06824). You implement this with something like:\nm = nn.Conv1d(input_planes, output_planes * 2)\nF.glu(m(input))\n\nFor efficiency reasons, you don't want to split the Conv1d into two separate convolutions. If you took in two separate inputs, you'd have to add splitting code everywhere before you call glu.", "in_reply_to_id": 121726692}