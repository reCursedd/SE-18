{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121290515", "pull_request_review_id": 43327884, "id": 121290515, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTI5MDUxNQ==", "diff_hunk": "@@ -763,6 +763,23 @@ def test_Dropout3d(self):\n         input = torch.Tensor(num_features, b, d, w, h)\n         self._test_dropout(nn.Dropout3d, input)\n \n+    def test_AlphaDropout(self):\n+        # generate random tensor with zero mean and unit std\n+        input = torch.randn(5000)\n+\n+        mean = input.mean()\n+        std = input.std()", "path": "test/test_nn.py", "position": 9, "original_position": 9, "commit_id": "c06c7699168a15291b7454b8771ea9960456fe06", "original_commit_id": "7ab4b5f6a1d4c763b9af4bf622c96e1a7e4bd4d2", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "Yes, but I left it like that in the event we might want to add support for a more general Alpha Dropout, which accepts a `mean` and `std` parameter. Also, because the samples are not infinitely large, I'd eventually need to increase the tolerance (or the tensor size) for the checks to consistently pass if I set those values to 0 and 1.", "created_at": "2017-06-11T20:15:40Z", "updated_at": "2018-11-23T15:33:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/1775#discussion_r121290515", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1775", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121290515"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1775#discussion_r121290515"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1775"}}, "body_html": "<p>Yes, but I left it like that in the event we might want to add support for a more general Alpha Dropout, which accepts a <code>mean</code> and <code>std</code> parameter. Also, because the samples are not infinitely large, I'd eventually need to increase the tolerance (or the tensor size) for the checks to consistently pass if I set those values to 0 and 1.</p>", "body_text": "Yes, but I left it like that in the event we might want to add support for a more general Alpha Dropout, which accepts a mean and std parameter. Also, because the samples are not infinitely large, I'd eventually need to increase the tolerance (or the tensor size) for the checks to consistently pass if I set those values to 0 and 1.", "in_reply_to_id": 121290341}