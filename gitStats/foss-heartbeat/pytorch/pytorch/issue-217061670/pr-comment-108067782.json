{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/108067782", "pull_request_review_id": 29076460, "id": 108067782, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwODA2Nzc4Mg==", "diff_hunk": "@@ -3068,23 +3069,106 @@ def test_Size(self):\n         self.assertIsInstance(x[:-1], torch.Size)\n         self.assertIsInstance(x + x, torch.Size)\n \n-    def test_transpose_neg(self):\n-        x = torch.randn(10, 20, 30)\n-        ndim = 3\n \n-        for i, j in combinations(range(ndim), 2):\n-            a = x.transpose(i, j)\n-            b = x.transpose(i - ndim, j - ndim)\n-            self.assertEqual(a, b)\n-\n-            a = torch.transpose(x, i, j)\n-            b = torch.transpose(x, i - ndim, j - ndim)\n-            self.assertEqual(a, b)\n-\n-            a = x.clone()\n-            x.transpose_(i, j)\n-            x.transpose_(i - ndim, j - ndim)\n-            self.assertEqual(a, x)\n+def compare_pos_neg_dim(name, tensor_arg, arg_constr, types):\n+    def tmp(self):\n+        if isinstance(tensor_arg, list):\n+            assert 0 not in types and 1 not in types\n+            x = []\n+            for arg in tensor_arg:\n+                x.append(torch.randn(*arg))\n+                ndim = len(arg)\n+        else:\n+            x = torch.randn(*tensor_arg)\n+            ndim = len(tensor_arg)\n+\n+        n_dim_to_test = 0\n+        tmp_arg = arg_constr()\n+        for el in tmp_arg:\n+            if el is None:\n+                n_dim_to_test += 1\n+\n+        for dims_val in combinations(range(ndim), n_dim_to_test):\n+            arg = arg_constr()\n+            arg_neg = copy.copy(arg)", "path": "test/test_torch.py", "position": null, "original_position": 49, "commit_id": "37d95687c47beab841cd67003de3390414db0dca", "original_commit_id": "3e68f2e15759d496784d24321583ff29f6936159", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "body": "The problem is that if there is a random vector in the arguments, they will be different if I call `arg_constr()` again.", "created_at": "2017-03-26T18:48:00Z", "updated_at": "2018-11-23T15:32:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/1108#discussion_r108067782", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1108", "author_association": "COLLABORATOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/108067782"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1108#discussion_r108067782"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1108"}}, "body_html": "<p>The problem is that if there is a random vector in the arguments, they will be different if I call <code>arg_constr()</code> again.</p>", "body_text": "The problem is that if there is a random vector in the arguments, they will be different if I call arg_constr() again.", "in_reply_to_id": 108066597}