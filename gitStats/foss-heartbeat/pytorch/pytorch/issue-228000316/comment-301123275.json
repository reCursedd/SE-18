{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/301123275", "html_url": "https://github.com/pytorch/pytorch/issues/1539#issuecomment-301123275", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1539", "id": 301123275, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTEyMzI3NQ==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-12T16:27:05Z", "updated_at": "2017-05-12T16:27:05Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You should not expect performance boost with fp16, because cudnn LSTM uses fp32 math even for fp16 inputs, but the fact that you are seeing regressions for fp16 points to perf regressions in cublas for SGemmEx calls (when your inputs are fp16, and math is done in fp32). Thanks for reporting.</p>", "body_text": "You should not expect performance boost with fp16, because cudnn LSTM uses fp32 math even for fp16 inputs, but the fact that you are seeing regressions for fp16 points to perf regressions in cublas for SGemmEx calls (when your inputs are fp16, and math is done in fp32). Thanks for reporting.", "body": "You should not expect performance boost with fp16, because cudnn LSTM uses fp32 math even for fp16 inputs, but the fact that you are seeing regressions for fp16 points to perf regressions in cublas for SGemmEx calls (when your inputs are fp16, and math is done in fp32). Thanks for reporting. "}