{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/301125784", "html_url": "https://github.com/pytorch/pytorch/issues/1539#issuecomment-301125784", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1539", "id": 301125784, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTEyNTc4NA==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-12T16:37:58Z", "updated_at": "2017-05-12T16:37:58Z", "author_association": "CONTRIBUTOR", "body_html": "<p>fp16 compute, you mean? Not in cudnn. If you go through LSTMCell, it will likely use Hgemm for matrix-matrix multiplies. But a) for typical LSTM sizes the Hgemms are not nearly 2x performance of Sgemms or SgemmEx b) it is really hard to make your network train using fp16 math.</p>", "body_text": "fp16 compute, you mean? Not in cudnn. If you go through LSTMCell, it will likely use Hgemm for matrix-matrix multiplies. But a) for typical LSTM sizes the Hgemms are not nearly 2x performance of Sgemms or SgemmEx b) it is really hard to make your network train using fp16 math.", "body": "fp16 compute, you mean? Not in cudnn. If you go through LSTMCell, it will likely use Hgemm for matrix-matrix multiplies. But a) for typical LSTM sizes the Hgemms are not nearly 2x performance of Sgemms or SgemmEx b) it is really hard to make your network train using fp16 math. "}