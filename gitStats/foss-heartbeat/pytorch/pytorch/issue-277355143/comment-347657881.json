{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/347657881", "html_url": "https://github.com/pytorch/pytorch/issues/3919#issuecomment-347657881", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3919", "id": 347657881, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzY1Nzg4MQ==", "user": {"login": "shekhovt", "id": 2486893, "node_id": "MDQ6VXNlcjI0ODY4OTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2486893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shekhovt", "html_url": "https://github.com/shekhovt", "followers_url": "https://api.github.com/users/shekhovt/followers", "following_url": "https://api.github.com/users/shekhovt/following{/other_user}", "gists_url": "https://api.github.com/users/shekhovt/gists{/gist_id}", "starred_url": "https://api.github.com/users/shekhovt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shekhovt/subscriptions", "organizations_url": "https://api.github.com/users/shekhovt/orgs", "repos_url": "https://api.github.com/users/shekhovt/repos", "events_url": "https://api.github.com/users/shekhovt/events{/privacy}", "received_events_url": "https://api.github.com/users/shekhovt/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-28T20:45:22Z", "updated_at": "2017-11-28T20:56:55Z", "author_association": "NONE", "body_html": "<p>I checked how it is in numpy, and they support all the mentioned cases, including zero strides and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"273208546\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3653\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3653/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/3653\">#3653</a>.<br>\nIn fact, one can hack around Tensor.view through numpy:</p>\n<pre><code>import torch\nimport numpy as np\n\na = torch.Tensor(16, 8, 32, 64).transpose(-1, -2)\n#b = a.view(-1, 64, 32)  # does not work\nb = torch.from_numpy(a.numpy().reshape([-1, 64, 32]))  # works\n</code></pre>\n<p>You can verify that a and b share the same memory and inspect</p>\n<pre><code>b.numpy().strides\n(8192, 4, 256)\n</code></pre>\n<p>Only it does not work for cuda Tensors as the data pointer to device is barriered off numpy. But I hope I made my point that Tensor.view can work this way and it would be more clear and consistent.</p>", "body_text": "I checked how it is in numpy, and they support all the mentioned cases, including zero strides and #3653.\nIn fact, one can hack around Tensor.view through numpy:\nimport torch\nimport numpy as np\n\na = torch.Tensor(16, 8, 32, 64).transpose(-1, -2)\n#b = a.view(-1, 64, 32)  # does not work\nb = torch.from_numpy(a.numpy().reshape([-1, 64, 32]))  # works\n\nYou can verify that a and b share the same memory and inspect\nb.numpy().strides\n(8192, 4, 256)\n\nOnly it does not work for cuda Tensors as the data pointer to device is barriered off numpy. But I hope I made my point that Tensor.view can work this way and it would be more clear and consistent.", "body": "I checked how it is in numpy, and they support all the mentioned cases, including zero strides and #3653.\r\nIn fact, one can hack around Tensor.view through numpy:\r\n\r\n```\r\nimport torch\r\nimport numpy as np\r\n\r\na = torch.Tensor(16, 8, 32, 64).transpose(-1, -2)\r\n#b = a.view(-1, 64, 32)  # does not work\r\nb = torch.from_numpy(a.numpy().reshape([-1, 64, 32]))  # works\r\n```\r\nYou can verify that a and b share the same memory and inspect\r\n```\r\nb.numpy().strides\r\n(8192, 4, 256)\r\n```\r\nOnly it does not work for cuda Tensors as the data pointer to device is barriered off numpy. But I hope I made my point that Tensor.view can work this way and it would be more clear and consistent."}