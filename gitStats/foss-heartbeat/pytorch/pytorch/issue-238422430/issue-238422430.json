{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1907", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1907/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1907/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1907/events", "html_url": "https://github.com/pytorch/pytorch/issues/1907", "id": 238422430, "node_id": "MDU6SXNzdWUyMzg0MjI0MzA=", "number": 1907, "title": "pytorch nondeterministically hangs on CUDA tensor creation (Tegra X1)", "user": {"login": "dimatura", "id": 60116, "node_id": "MDQ6VXNlcjYwMTE2", "avatar_url": "https://avatars1.githubusercontent.com/u/60116?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dimatura", "html_url": "https://github.com/dimatura", "followers_url": "https://api.github.com/users/dimatura/followers", "following_url": "https://api.github.com/users/dimatura/following{/other_user}", "gists_url": "https://api.github.com/users/dimatura/gists{/gist_id}", "starred_url": "https://api.github.com/users/dimatura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dimatura/subscriptions", "organizations_url": "https://api.github.com/users/dimatura/orgs", "repos_url": "https://api.github.com/users/dimatura/repos", "events_url": "https://api.github.com/users/dimatura/events{/privacy}", "received_events_url": "https://api.github.com/users/dimatura/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 553773019, "node_id": "MDU6TGFiZWw1NTM3NzMwMTk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs-reproduction", "name": "needs-reproduction", "color": "e99695", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-06-26T01:36:28Z", "updated_at": "2018-10-09T02:49:50Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello all, great work with pytorch. I'm trying to use pytorch in a Jetson TX1, and it sort of works. One issue I'm running into is that it sporadically hangs when using CUDA.</p>\n<p>Some details:</p>\n<ul>\n<li>Jetson TX1, a 64-bit ARM architecture with a tegra TX1</li>\n<li>Ubuntu 16.04 aarch64</li>\n<li>CUDA 8.0, CUDNN 5105</li>\n<li>Python 2.7</li>\n<li>Built from source (conda not available yet) from git commit 7c24a (Jun 23) and from tag 1.12. Both have the same issue.</li>\n</ul>\n<p>Example program:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\na <span class=\"pl-k\">=</span> torch.FloatTensor(<span class=\"pl-c1\">2</span>).cuda()\n<span class=\"pl-c1\">print</span>(a)</pre></div>\n<p>This code will work maybe 8/10 times (subjective belief, not actually measured) and the rest, it will hang on the second line. <code>top</code> indicates the program is using ~18% CPU. The program will not respond to Ctrl-C. Suspecting some kind of concurrency issue, I tried <code>OMP_NUM_THREADS=1</code>, and <code>torch.set_num_threads(1)</code> but the issue still occurs.</p>\n<p>When not using <code>.cuda()</code> it never hangs up (and in fact starts relatively quickly compared to the cuda version --  the <code>.cuda()</code> call seems surprisingly slow).</p>", "body_text": "Hello all, great work with pytorch. I'm trying to use pytorch in a Jetson TX1, and it sort of works. One issue I'm running into is that it sporadically hangs when using CUDA.\nSome details:\n\nJetson TX1, a 64-bit ARM architecture with a tegra TX1\nUbuntu 16.04 aarch64\nCUDA 8.0, CUDNN 5105\nPython 2.7\nBuilt from source (conda not available yet) from git commit 7c24a (Jun 23) and from tag 1.12. Both have the same issue.\n\nExample program:\nimport torch\na = torch.FloatTensor(2).cuda()\nprint(a)\nThis code will work maybe 8/10 times (subjective belief, not actually measured) and the rest, it will hang on the second line. top indicates the program is using ~18% CPU. The program will not respond to Ctrl-C. Suspecting some kind of concurrency issue, I tried OMP_NUM_THREADS=1, and torch.set_num_threads(1) but the issue still occurs.\nWhen not using .cuda() it never hangs up (and in fact starts relatively quickly compared to the cuda version --  the .cuda() call seems surprisingly slow).", "body": "Hello all, great work with pytorch. I'm trying to use pytorch in a Jetson TX1, and it sort of works. One issue I'm running into is that it sporadically hangs when using CUDA. \r\n\r\nSome details:\r\n- Jetson TX1, a 64-bit ARM architecture with a tegra TX1\r\n- Ubuntu 16.04 aarch64\r\n- CUDA 8.0, CUDNN 5105\r\n- Python 2.7\r\n- Built from source (conda not available yet) from git commit 7c24a (Jun 23) and from tag 1.12. Both have the same issue.\r\n\r\nExample program:\r\n```python\r\nimport torch\r\na = torch.FloatTensor(2).cuda()\r\nprint(a)\r\n```\r\n\r\nThis code will work maybe 8/10 times (subjective belief, not actually measured) and the rest, it will hang on the second line. `top` indicates the program is using ~18% CPU. The program will not respond to Ctrl-C. Suspecting some kind of concurrency issue, I tried `OMP_NUM_THREADS=1`, and `torch.set_num_threads(1)` but the issue still occurs. \r\n\r\nWhen not using `.cuda()` it never hangs up (and in fact starts relatively quickly compared to the cuda version --  the `.cuda()` call seems surprisingly slow). \r\n\r\n"}