{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5741", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5741/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5741/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5741/events", "html_url": "https://github.com/pytorch/pytorch/issues/5741", "id": 304805611, "node_id": "MDU6SXNzdWUzMDQ4MDU2MTE=", "number": 5741, "title": "Save `self.numel()` for backwards computation", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-13T15:09:47Z", "updated_at": "2018-03-13T21:45:30Z", "closed_at": "2018-03-13T21:45:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Right now, the following derivatives.yaml declaration:</p>\n<pre><code>- name: mean(Tensor self)\n  self: grad.expand(self.sizes()) / self.numel()\n</code></pre>\n<p>produces the following backwards:</p>\n<pre><code>variable_list MeanBackward1::apply(const variable_list&amp; grads) {\n  IndexRangeGenerator gen;\n  auto self_ix = gen.range(1);\n  variable_list grad_inputs(gen.size());\n  auto&amp; grad = grads[0];\n  auto self = self_.unpack();\n  if (should_compute_output({ self_ix })) {\n    auto grad_result = grad.expand(self_sizes) / self.numel();\n    copy_range(grad_inputs, self_ix, grad_result);\n  }\n  return grad_inputs;\n}\n</code></pre>\n<p>It looks like <code>self.sizes()</code> is being saved for the backward pass, but <code>self.numel()</code> isn't, requiring saving <code>self</code> for backwards.</p>", "body_text": "Right now, the following derivatives.yaml declaration:\n- name: mean(Tensor self)\n  self: grad.expand(self.sizes()) / self.numel()\n\nproduces the following backwards:\nvariable_list MeanBackward1::apply(const variable_list& grads) {\n  IndexRangeGenerator gen;\n  auto self_ix = gen.range(1);\n  variable_list grad_inputs(gen.size());\n  auto& grad = grads[0];\n  auto self = self_.unpack();\n  if (should_compute_output({ self_ix })) {\n    auto grad_result = grad.expand(self_sizes) / self.numel();\n    copy_range(grad_inputs, self_ix, grad_result);\n  }\n  return grad_inputs;\n}\n\nIt looks like self.sizes() is being saved for the backward pass, but self.numel() isn't, requiring saving self for backwards.", "body": "Right now, the following derivatives.yaml declaration:\r\n```\r\n- name: mean(Tensor self)\r\n  self: grad.expand(self.sizes()) / self.numel()\r\n```\r\nproduces the following backwards:\r\n```\r\nvariable_list MeanBackward1::apply(const variable_list& grads) {\r\n  IndexRangeGenerator gen;\r\n  auto self_ix = gen.range(1);\r\n  variable_list grad_inputs(gen.size());\r\n  auto& grad = grads[0];\r\n  auto self = self_.unpack();\r\n  if (should_compute_output({ self_ix })) {\r\n    auto grad_result = grad.expand(self_sizes) / self.numel();\r\n    copy_range(grad_inputs, self_ix, grad_result);\r\n  }\r\n  return grad_inputs;\r\n}\r\n```\r\nIt looks like `self.sizes()` is being saved for the backward pass, but `self.numel()` isn't, requiring saving `self` for backwards."}