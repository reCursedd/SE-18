{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/256135305", "html_url": "https://github.com/pytorch/pytorch/issues/139#issuecomment-256135305", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/139", "id": 256135305, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjEzNTMwNQ==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-25T18:45:06Z", "updated_at": "2016-10-25T18:45:06Z", "author_association": "MEMBER", "body_html": "<p>Oh I pasted the wrong link. Here it is:<br>\n<a href=\"https://devtalk.nvidia.com/default/topic/494915/sharing-\" rel=\"nofollow\">https://devtalk.nvidia.com/default/topic/494915/sharing-</a><br>\ncuda-host-memory-between-processes/</p>\n<p>On Sunday, October 23, 2016, Adam Paszke &lt;<a href=\"mailto:notifications@github.com\">notifications@github.com</a><br>\njavascript:_e(%7B%7D,'cvml','notifications@github.com');&gt; wrote:</p>\n<blockquote>\n<p>I can't find any solution for the host memory sharing in the thread you<br>\nliked, they only solved the device memory sharing. We should probably ask<br>\nhow cudaHostRegisterPortable behaves if one of the processes frees the<br>\nmemory, but another one is still using it.</p>\n<p>On the other hand, if you could get a big pinned buffer mapped as shared<br>\nmemory, you could slice it and send the chunks to worker processes that<br>\nwould fill it. Once you move your tensor to shared memory, it will be the<br>\nsame for it and its slices until the program terminates (or it gets freed).</p>\n<p>\u2014<br>\nYou are receiving this because you authored the thread.<br>\nReply to this email directly, view it on GitHub<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"183753544\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/139\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/139/hovercard?comment_id=255617424&amp;comment_type=issue_comment\" href=\"https://github.com/pytorch/pytorch/issues/139#issuecomment-255617424\">#139 (comment)</a>,<br>\nor mute the thread<br>\n<a href=\"https://github.com/notifications/unsubscribe-auth/AAoB-ixxgK2DjsQLljASTjXe07lFx-eDks5q29f_gaJpZM4KaE8y\">https://github.com/notifications/unsubscribe-auth/AAoB-ixxgK2DjsQLljASTjXe07lFx-eDks5q29f_gaJpZM4KaE8y</a><br>\n.</p>\n</blockquote>", "body_text": "Oh I pasted the wrong link. Here it is:\nhttps://devtalk.nvidia.com/default/topic/494915/sharing-\ncuda-host-memory-between-processes/\nOn Sunday, October 23, 2016, Adam Paszke <notifications@github.com\njavascript:_e(%7B%7D,'cvml','notifications@github.com');> wrote:\n\nI can't find any solution for the host memory sharing in the thread you\nliked, they only solved the device memory sharing. We should probably ask\nhow cudaHostRegisterPortable behaves if one of the processes frees the\nmemory, but another one is still using it.\nOn the other hand, if you could get a big pinned buffer mapped as shared\nmemory, you could slice it and send the chunks to worker processes that\nwould fill it. Once you move your tensor to shared memory, it will be the\nsame for it and its slices until the program terminates (or it gets freed).\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\n#139 (comment),\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAoB-ixxgK2DjsQLljASTjXe07lFx-eDks5q29f_gaJpZM4KaE8y\n.", "body": "Oh I pasted the wrong link. Here it is:\nhttps://devtalk.nvidia.com/default/topic/494915/sharing-\ncuda-host-memory-between-processes/\n\nOn Sunday, October 23, 2016, Adam Paszke <notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');>> wrote:\n\n> I can't find any solution for the host memory sharing in the thread you\n> liked, they only solved the device memory sharing. We should probably ask\n> how cudaHostRegisterPortable behaves if one of the processes frees the\n> memory, but another one is still using it.\n> \n> On the other hand, if you could get a big pinned buffer mapped as shared\n> memory, you could slice it and send the chunks to worker processes that\n> would fill it. Once you move your tensor to shared memory, it will be the\n> same for it and its slices until the program terminates (or it gets freed).\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/pytorch/pytorch/issues/139#issuecomment-255617424,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAoB-ixxgK2DjsQLljASTjXe07lFx-eDks5q29f_gaJpZM4KaE8y\n> .\n"}