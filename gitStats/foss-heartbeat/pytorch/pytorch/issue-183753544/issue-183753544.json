{"url": "https://api.github.com/repos/pytorch/pytorch/issues/139", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/139/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/139/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/139/events", "html_url": "https://github.com/pytorch/pytorch/issues/139", "id": 183753544, "node_id": "MDU6SXNzdWUxODM3NTM1NDQ=", "number": 139, "title": "Support CUDA pinned memory in DataLoader", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2016-10-18T17:33:56Z", "updated_at": "2016-12-16T15:59:39Z", "closed_at": "2016-12-16T15:59:39Z", "author_association": "MEMBER", "body_html": "<p>CUDA pinned memory is important for efficient execution because it allows for faster data transfers and non-blocking CUDA copies.</p>\n<p>The copy from normal memory to pinned memory can take significant time. A batch of <code>256x3x224x224</code> FloatTensor takes about 110ms on my computer to copy. Currently we can only do the copy on the main process because inter-process shared Tensor/Storages are copied to non-page locked shared memory. For small conv nets on fast GPUs, we probably need to do the copy in the background.</p>\n<p>I believe we can page-lock the shared memory via <code>cudaHostRegister</code>. We would probably need to unregister it via <code>cudaHostUnregister</code> before freeing the memory.</p>\n<p>This would require some knowledge of CUDA in the shared memory code or at least a free hooks to call <code>cudaHostUnregister</code>.</p>", "body_text": "CUDA pinned memory is important for efficient execution because it allows for faster data transfers and non-blocking CUDA copies.\nThe copy from normal memory to pinned memory can take significant time. A batch of 256x3x224x224 FloatTensor takes about 110ms on my computer to copy. Currently we can only do the copy on the main process because inter-process shared Tensor/Storages are copied to non-page locked shared memory. For small conv nets on fast GPUs, we probably need to do the copy in the background.\nI believe we can page-lock the shared memory via cudaHostRegister. We would probably need to unregister it via cudaHostUnregister before freeing the memory.\nThis would require some knowledge of CUDA in the shared memory code or at least a free hooks to call cudaHostUnregister.", "body": "CUDA pinned memory is important for efficient execution because it allows for faster data transfers and non-blocking CUDA copies.\n\nThe copy from normal memory to pinned memory can take significant time. A batch of `256x3x224x224` FloatTensor takes about 110ms on my computer to copy. Currently we can only do the copy on the main process because inter-process shared Tensor/Storages are copied to non-page locked shared memory. For small conv nets on fast GPUs, we probably need to do the copy in the background.\n\nI believe we can page-lock the shared memory via `cudaHostRegister`. We would probably need to unregister it via `cudaHostUnregister` before freeing the memory.\n\nThis would require some knowledge of CUDA in the shared memory code or at least a free hooks to call `cudaHostUnregister`. \n"}