{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/411098517", "html_url": "https://github.com/pytorch/pytorch/pull/10305#issuecomment-411098517", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10305", "id": 411098517, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTA5ODUxNw==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-07T15:30:27Z", "updated_at": "2018-08-07T15:37:16Z", "author_association": "MEMBER", "body_html": "<p>Summary of changes:</p>\n<ol>\n<li>Kernel changes</li>\n</ol>\n<ul>\n<li>Gradients are now optional (can be nullptr) in the backward LSTM kernel. This lets us avoid allocating a zero-filled tensor in backward.</li>\n<li>Changed slightly how the indexing works (ATen's <code>TensorInfo</code> doesn't match 100% with THC's). Biases should always be 1D, all other tensors are either 2D, or are flattened to their 1D views when they are contiguous</li>\n</ul>\n<ol start=\"2\">\n<li>Dispatch code changes</li>\n</ol>\n<ul>\n<li>We only instantiate 2 specializations for every kernel now (we created 4 previously)</li>\n<li>Dispatch code relies on templates entirely now</li>\n<li>Abstracted certain duplicated patterns into helper functions</li>\n<li>Used more verbose names for variables</li>\n</ul>", "body_text": "Summary of changes:\n\nKernel changes\n\n\nGradients are now optional (can be nullptr) in the backward LSTM kernel. This lets us avoid allocating a zero-filled tensor in backward.\nChanged slightly how the indexing works (ATen's TensorInfo doesn't match 100% with THC's). Biases should always be 1D, all other tensors are either 2D, or are flattened to their 1D views when they are contiguous\n\n\nDispatch code changes\n\n\nWe only instantiate 2 specializations for every kernel now (we created 4 previously)\nDispatch code relies on templates entirely now\nAbstracted certain duplicated patterns into helper functions\nUsed more verbose names for variables", "body": "Summary of changes:\r\n1. Kernel changes\r\n  - Gradients are now optional (can be nullptr) in the backward LSTM kernel. This lets us avoid allocating a zero-filled tensor in backward.\r\n  - Changed slightly how the indexing works (ATen's `TensorInfo` doesn't match 100% with THC's). Biases should always be 1D, all other tensors are either 2D, or are flattened to their 1D views when they are contiguous\r\n2. Dispatch code changes\r\n  - We only instantiate 2 specializations for every kernel now (we created 4 previously)\r\n  - Dispatch code relies on templates entirely now\r\n  - Abstracted certain duplicated patterns into helper functions\r\n  - Used more verbose names for variables"}