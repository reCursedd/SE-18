{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/404536920", "html_url": "https://github.com/pytorch/pytorch/pull/8792#issuecomment-404536920", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8792", "id": 404536920, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDUzNjkyMA==", "user": {"login": "anderspapitto", "id": 1388690, "node_id": "MDQ6VXNlcjEzODg2OTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1388690?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anderspapitto", "html_url": "https://github.com/anderspapitto", "followers_url": "https://api.github.com/users/anderspapitto/followers", "following_url": "https://api.github.com/users/anderspapitto/following{/other_user}", "gists_url": "https://api.github.com/users/anderspapitto/gists{/gist_id}", "starred_url": "https://api.github.com/users/anderspapitto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anderspapitto/subscriptions", "organizations_url": "https://api.github.com/users/anderspapitto/orgs", "repos_url": "https://api.github.com/users/anderspapitto/repos", "events_url": "https://api.github.com/users/anderspapitto/events{/privacy}", "received_events_url": "https://api.github.com/users/anderspapitto/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-12T14:43:34Z", "updated_at": "2018-07-12T20:04:51Z", "author_association": "MEMBER", "body_html": "<p>This diff is ready for another round of review. I highlight two points of potential concern.</p>\n<ol>\n<li>The ROCM builds consistently fail due to</li>\n</ol>\n<ul>\n<li>timeouts (example <a href=\"https://ci.pytorch.org/jenkins/job/caffe2-builds/job/py2-clang3.8-rocm1.7.1-ubuntu16.04-test/2182/console\" rel=\"nofollow\">https://ci.pytorch.org/jenkins/job/caffe2-builds/job/py2-clang3.8-rocm1.7.1-ubuntu16.04-test/2182/console</a>)<br>\nor</li>\n<li>OOM  (example <a href=\"https://ci.pytorch.org/jenkins/job/pytorch-builds/job/py2-clang3.8-rocmnightly-ubuntu16.04-build/2775/console\" rel=\"nofollow\">https://ci.pytorch.org/jenkins/job/pytorch-builds/job/py2-clang3.8-rocmnightly-ubuntu16.04-build/2775/console</a>).</li>\n</ul>\n<p>This is particularly annoying because I did fix legit ROCM issues along the way, so I would like to get a clear signal that everything is now correct. However, my initial feeling is that fixing these infra-level resource issues is outside the scope of this diff.</p>\n<ol start=\"2\">\n<li>On windows, a shared library cannot expose global variables with dllexport. Straightforward application of the new TORCH_API macro results in errors messages like</li>\n</ol>\n<pre><code>C:\\Jenkins\\workspace\\pytorch-builds\\pytorch-win-ws2016-cuda9-cudnn7-py3-build\\torch/csrc/autograd/profiler.h(172): error C2492: 'thread_id': data with thread storage duration may not have dll interface\n</code></pre>\n<p>seen here <a href=\"https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-win-ws2016-cuda9-cudnn7-py3-build/12062/console\" rel=\"nofollow\">https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-win-ws2016-cuda9-cudnn7-py3-build/12062/console</a>.</p>\n<p>In this diff, I've addressed this issue by moving all the relevant thread_local global variables out of the header files, and instead exposing accessor methods across the shared-object boundary. I'm concerned that this may be a perf problem, if function call overhead is too high a cost to pay to access these profiling-related variables. So, is this a problem, and if so is there a suggested alternative approach?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6429851\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/goldsborough\">@goldsborough</a> as existing reviewers (also please bring in anyone else with relevant knowledge. E.g. I'm not sure who is most familiar with the profiling code.)</p>\n<p>edit: also <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8586039\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Jorghi12\">@Jorghi12</a> regarding the ROCM tests</p>", "body_text": "This diff is ready for another round of review. I highlight two points of potential concern.\n\nThe ROCM builds consistently fail due to\n\n\ntimeouts (example https://ci.pytorch.org/jenkins/job/caffe2-builds/job/py2-clang3.8-rocm1.7.1-ubuntu16.04-test/2182/console)\nor\nOOM  (example https://ci.pytorch.org/jenkins/job/pytorch-builds/job/py2-clang3.8-rocmnightly-ubuntu16.04-build/2775/console).\n\nThis is particularly annoying because I did fix legit ROCM issues along the way, so I would like to get a clear signal that everything is now correct. However, my initial feeling is that fixing these infra-level resource issues is outside the scope of this diff.\n\nOn windows, a shared library cannot expose global variables with dllexport. Straightforward application of the new TORCH_API macro results in errors messages like\n\nC:\\Jenkins\\workspace\\pytorch-builds\\pytorch-win-ws2016-cuda9-cudnn7-py3-build\\torch/csrc/autograd/profiler.h(172): error C2492: 'thread_id': data with thread storage duration may not have dll interface\n\nseen here https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-win-ws2016-cuda9-cudnn7-py3-build/12062/console.\nIn this diff, I've addressed this issue by moving all the relevant thread_local global variables out of the header files, and instead exposing accessor methods across the shared-object boundary. I'm concerned that this may be a perf problem, if function call overhead is too high a cost to pay to access these profiling-related variables. So, is this a problem, and if so is there a suggested alternative approach?\n@ezyang @goldsborough as existing reviewers (also please bring in anyone else with relevant knowledge. E.g. I'm not sure who is most familiar with the profiling code.)\nedit: also @Jorghi12 regarding the ROCM tests", "body": "This diff is ready for another round of review. I highlight two points of potential concern.\r\n\r\n1) The ROCM builds consistently fail due to \r\n\r\n- timeouts (example https://ci.pytorch.org/jenkins/job/caffe2-builds/job/py2-clang3.8-rocm1.7.1-ubuntu16.04-test/2182/console) \r\nor \r\n- OOM  (example https://ci.pytorch.org/jenkins/job/pytorch-builds/job/py2-clang3.8-rocmnightly-ubuntu16.04-build/2775/console). \r\n\r\nThis is particularly annoying because I did fix legit ROCM issues along the way, so I would like to get a clear signal that everything is now correct. However, my initial feeling is that fixing these infra-level resource issues is outside the scope of this diff.\r\n\r\n2) On windows, a shared library cannot expose global variables with dllexport. Straightforward application of the new TORCH_API macro results in errors messages like\r\n\r\n```\r\nC:\\Jenkins\\workspace\\pytorch-builds\\pytorch-win-ws2016-cuda9-cudnn7-py3-build\\torch/csrc/autograd/profiler.h(172): error C2492: 'thread_id': data with thread storage duration may not have dll interface\r\n```\r\n\r\nseen here https://ci.pytorch.org/jenkins/job/pytorch-builds/job/pytorch-win-ws2016-cuda9-cudnn7-py3-build/12062/console.\r\n\r\nIn this diff, I've addressed this issue by moving all the relevant thread_local global variables out of the header files, and instead exposing accessor methods across the shared-object boundary. I'm concerned that this may be a perf problem, if function call overhead is too high a cost to pay to access these profiling-related variables. So, is this a problem, and if so is there a suggested alternative approach?\r\n\r\n@ezyang @goldsborough as existing reviewers (also please bring in anyone else with relevant knowledge. E.g. I'm not sure who is most familiar with the profiling code.)\r\n\r\nedit: also @Jorghi12 regarding the ROCM tests"}