{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4341", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4341/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4341/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4341/events", "html_url": "https://github.com/pytorch/pytorch/pull/4341", "id": 284341243, "node_id": "MDExOlB1bGxSZXF1ZXN0MTU5OTg3Njk0", "number": 4341, "title": "Implement backward for pack_padded_sequence", "user": {"login": "elanmart", "id": 10772830, "node_id": "MDQ6VXNlcjEwNzcyODMw", "avatar_url": "https://avatars3.githubusercontent.com/u/10772830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elanmart", "html_url": "https://github.com/elanmart", "followers_url": "https://api.github.com/users/elanmart/followers", "following_url": "https://api.github.com/users/elanmart/following{/other_user}", "gists_url": "https://api.github.com/users/elanmart/gists{/gist_id}", "starred_url": "https://api.github.com/users/elanmart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elanmart/subscriptions", "organizations_url": "https://api.github.com/users/elanmart/orgs", "repos_url": "https://api.github.com/users/elanmart/repos", "events_url": "https://api.github.com/users/elanmart/events{/privacy}", "received_events_url": "https://api.github.com/users/elanmart/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-12-24T04:01:23Z", "updated_at": "2018-01-06T22:02:40Z", "closed_at": "2018-01-06T22:02:40Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/4341", "html_url": "https://github.com/pytorch/pytorch/pull/4341", "diff_url": "https://github.com/pytorch/pytorch/pull/4341.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/4341.patch"}, "body_html": "<p>On my machine this PR gives the following on CPU:</p>\n<div class=\"highlight highlight-source-shell\"><pre>%timeit _ = rnn_utils.pack_padded_sequence(x, <span class=\"pl-en\">lengths).data.sum().backward</span>()\n%timeit _ = old_utils.pack_padded_sequence(x, <span class=\"pl-en\">lengths).data.sum().backward</span>()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 100 loops, best of 3: 5.75 ms per loop  # this PR</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 1 loop, best of 3: 194 ms per loop      # master</span></pre></div>\n<p>and GPU</p>\n<div class=\"highlight highlight-source-shell\"><pre>%timeit _ = rnn_utils.pack_padded_sequence(x_cuda, <span class=\"pl-en\">lengths).data.sum().backward</span>()\n%timeit _ = old_utils.pack_padded_sequence(x_cuda, <span class=\"pl-en\">lengths).data.sum().backward</span>()\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 1000 loops, best of 3: 1.67 ms per loop  # this PR</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> 100 loops, best of 3: 11.5 ms per loop   # master</span></pre></div>\n<p>I've implemented this in python since I couldn't get <code>ATen</code> to accept the <code>batch_sizes</code> as input to <code>backward</code>.</p>\n<p>There's an ugly conversion from a <code>Variable</code> to <code>list</code> when creating the <code>PackedSequence</code> tuple.</p>\n<p>And also two tests are failing, because they assume that when <code>pack_padded_sequence</code> is called with <code>Tensors</code>, the <code>PackedSequence.data</code> will also be a <code>Tensor</code>, but here a <code>Function</code> converts it to <code>Variable</code>. Not sure how this should be handled.</p>\n<p>Please let me know if this PR makes sense and if there's anything I could fix. Oh, and also if I should somehow concatenate these commits into a single one.</p>", "body_text": "On my machine this PR gives the following on CPU:\n%timeit _ = rnn_utils.pack_padded_sequence(x, lengths).data.sum().backward()\n%timeit _ = old_utils.pack_padded_sequence(x, lengths).data.sum().backward()\n\n# 100 loops, best of 3: 5.75 ms per loop  # this PR\n# 1 loop, best of 3: 194 ms per loop      # master\nand GPU\n%timeit _ = rnn_utils.pack_padded_sequence(x_cuda, lengths).data.sum().backward()\n%timeit _ = old_utils.pack_padded_sequence(x_cuda, lengths).data.sum().backward()\n\n# 1000 loops, best of 3: 1.67 ms per loop  # this PR\n# 100 loops, best of 3: 11.5 ms per loop   # master\nI've implemented this in python since I couldn't get ATen to accept the batch_sizes as input to backward.\nThere's an ugly conversion from a Variable to list when creating the PackedSequence tuple.\nAnd also two tests are failing, because they assume that when pack_padded_sequence is called with Tensors, the PackedSequence.data will also be a Tensor, but here a Function converts it to Variable. Not sure how this should be handled.\nPlease let me know if this PR makes sense and if there's anything I could fix. Oh, and also if I should somehow concatenate these commits into a single one.", "body": "On my machine this PR gives the following on CPU:\r\n```bash\r\n%timeit _ = rnn_utils.pack_padded_sequence(x, lengths).data.sum().backward()\r\n%timeit _ = old_utils.pack_padded_sequence(x, lengths).data.sum().backward()\r\n\r\n# 100 loops, best of 3: 5.75 ms per loop  # this PR\r\n# 1 loop, best of 3: 194 ms per loop      # master\r\n```\r\nand GPU\r\n\r\n```bash\r\n%timeit _ = rnn_utils.pack_padded_sequence(x_cuda, lengths).data.sum().backward()\r\n%timeit _ = old_utils.pack_padded_sequence(x_cuda, lengths).data.sum().backward()\r\n\r\n# 1000 loops, best of 3: 1.67 ms per loop  # this PR\r\n# 100 loops, best of 3: 11.5 ms per loop   # master\r\n```\r\n\r\nI've implemented this in python since I couldn't get `ATen` to accept the `batch_sizes` as input to `backward`.\r\n\r\nThere's an ugly conversion from a `Variable` to `list` when creating the `PackedSequence` tuple.\r\n\r\nAnd also two tests are failing, because they assume that when `pack_padded_sequence` is called with `Tensors`, the `PackedSequence.data` will also be a `Tensor`, but here a `Function` converts it to `Variable`. Not sure how this should be handled.\r\n\r\nPlease let me know if this PR makes sense and if there's anything I could fix. Oh, and also if I should somehow concatenate these commits into a single one."}