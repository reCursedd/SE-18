{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/120725165", "pull_request_review_id": 42702965, "id": 120725165, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMDcyNTE2NQ==", "diff_hunk": "@@ -419,38 +419,43 @@ int THCSTensor_(checkGPU)(THCState *state, unsigned int nSparseTensors, unsigned\n #endif // DISABLE_CHECK_GPU\n }\n \n-void THCTensor_(sparseMask)(THCState *state, THCSTensor *r_, THCTensor *t, THCSTensor *mask) {\n-  THArgCheck(mask->coalesced, 2, \"mask is uncoalesced\");\n-  THCAssertSameGPU(THCSTensor_(checkGPU)(state, 2, 3, r_, mask, t));\n-  if(!THCSTensor_(isSameSizeAsDense)(state, mask, t)) {\n-    THError(\"sparseMask operands have incompatible sizes\");\n-  }\n-  THCSTensor_(resizeAs)(state, r_, mask);\n-  if (mask->nnz == 0) {\n+void THCTensor_(sparseSelect)(THCState *state, THCSTensor *r_, THCTensor *t, THCIndexTensor *indices_) {\n+  THCAssertSameGPU(THCSTensor_(checkGPU)(state, 2, 3, r_, indices_, t));\n+  long nDim = THCTensor_(nDimension)(state, t);\n+  long nDimI = THCudaLongTensor_size(state, indices_, 0);\n+  long nDimV = nDim - nDimI;\n+  long nnz = THCudaLongTensor_size(state, indices_, 1);\n+  THArgCheck(nDimI <= nDim, 2, \"nDim of indices must be <= nDim of tensor\");\n+  THCSTensor_(rawResize)(state, r_, nDimI, nDimV, t->size);\n+  if (nnz == 0) {\n     THCSTensor_(zero)(state, r_);\n     return;\n   }\n-  THCIndexTensor *maskIndices = THCSTensor_(newIndices)(state, mask);\n-  THCTensor *maskValues = THCSTensor_(newValues)(state, mask);\n   THCTensor *rValues = THCTensor_(new)(state);\n-  THCTensor_(resizeAs)(state, rValues, maskValues);\n-  THCSTensor_(_move)(state, r_, THCIndexTensor_(newClone)(state, maskIndices), rValues);\n-  r_->coalesced = mask->coalesced;\n-  r_->nnz = mask->nnz;\n+  long *size = THAlloc(sizeof(long) * (nDimV + 1));\n+  size[0] = nnz;\n+  for (int i = 0; i < nDimV; i++) {\n+    size[i+1] = t->size[nDimI + i];\n+  }\n+  THCTensor_(resizeNd)(state, rValues, nDimV + 1, size, NULL);\n+  THFree(size);\n+  THCudaLongTensor *rIndices = THCudaLongTensor_newClone(state, indices_);\n+  THCSTensor_(_move)(state, r_, rIndices, rValues); // consumes rIndices and rValues\n+  r_->coalesced = 1; // invariant\n \n-  THCudaLongTensor *indices = THCudaLongTensor_newWithSize1d(state, mask->nnz);\n+  THCudaLongTensor *indices = THCudaLongTensor_newWithSize1d(state, nnz);\n   THCudaLongTensor *indicesBuffer = THCudaLongTensor_new(state);\n \n   THCudaLongTensor_zero(state, indices);\n-  for (long d = 0; d < mask->nDimensionI; d++) {\n-    THCudaLongTensor_mul(state, indices, indices, mask->size[d]);\n-    THCudaLongTensor_select(state, indicesBuffer, maskIndices, 0, d);\n+  for (long d = 0; d < nDimI; d++) {", "path": "torch/lib/THCS/generic/THCSTensor.c", "position": 50, "original_position": 50, "commit_id": "3d99b56e3c3b42feafff5c1bf327746f96d4e5ae", "original_commit_id": "3d99b56e3c3b42feafff5c1bf327746f96d4e5ae", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "body": "Can you use `THCSTensor_(newFlattenedIndices)` here? Yes you'll have to refactor it to make it work since you don't have the underlying tensor any more. But this one might have some bugs, e.g. if TH_INDEX_BASE=1 this won't work properly.", "created_at": "2017-06-07T19:40:10Z", "updated_at": "2018-11-23T15:33:41Z", "html_url": "https://github.com/pytorch/pytorch/pull/1471#discussion_r120725165", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1471", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/120725165"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1471#discussion_r120725165"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1471"}}, "body_html": "<p>Can you use <code>THCSTensor_(newFlattenedIndices)</code> here? Yes you'll have to refactor it to make it work since you don't have the underlying tensor any more. But this one might have some bugs, e.g. if TH_INDEX_BASE=1 this won't work properly.</p>", "body_text": "Can you use THCSTensor_(newFlattenedIndices) here? Yes you'll have to refactor it to make it work since you don't have the underlying tensor any more. But this one might have some bugs, e.g. if TH_INDEX_BASE=1 this won't work properly."}