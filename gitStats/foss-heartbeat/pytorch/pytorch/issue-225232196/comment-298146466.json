{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/298146466", "html_url": "https://github.com/pytorch/pytorch/issues/1402#issuecomment-298146466", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1402", "id": 298146466, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODE0NjQ2Ng==", "user": {"login": "Jiaming-Liu", "id": 16099575, "node_id": "MDQ6VXNlcjE2MDk5NTc1", "avatar_url": "https://avatars3.githubusercontent.com/u/16099575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jiaming-Liu", "html_url": "https://github.com/Jiaming-Liu", "followers_url": "https://api.github.com/users/Jiaming-Liu/followers", "following_url": "https://api.github.com/users/Jiaming-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jiaming-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jiaming-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jiaming-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jiaming-Liu/orgs", "repos_url": "https://api.github.com/users/Jiaming-Liu/repos", "events_url": "https://api.github.com/users/Jiaming-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jiaming-Liu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-29T04:31:43Z", "updated_at": "2017-04-29T04:32:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For this issue, I basically do something like this and send the output to the optimizer:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">group_weight</span>(<span class=\"pl-smi\">module</span>):\n    group_decay <span class=\"pl-k\">=</span> []\n    group_no_decay <span class=\"pl-k\">=</span> []\n    <span class=\"pl-k\">for</span> m <span class=\"pl-k\">in</span> module.modules():\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(m, nn.Linear):\n            group_decay.append(m.weight)\n            <span class=\"pl-k\">if</span> m.bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                group_no_decay.append(m.bias)\n        <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(m, _ConvNd):\n            group_decay.append(m.weight)\n            <span class=\"pl-k\">if</span> m.bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                group_no_decay.append(m.bias)\n        <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">isinstance</span>(m, _BatchNorm):\n            <span class=\"pl-k\">if</span> m.bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                group_no_decay.append(m.weight)\n            <span class=\"pl-k\">if</span> m.bias <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n                group_no_decay.append(m.bias)\n\n    <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(<span class=\"pl-c1\">list</span>(module.parameters())) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">len</span>(group_decay) <span class=\"pl-k\">+</span> <span class=\"pl-c1\">len</span>(group_no_decay)\n    groups <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">dict</span>(<span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>group_decay), <span class=\"pl-c1\">dict</span>(<span class=\"pl-v\">params</span><span class=\"pl-k\">=</span>group_no_decay, <span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">.0</span>)]\n    <span class=\"pl-k\">return</span> groups</pre></div>", "body_text": "For this issue, I basically do something like this and send the output to the optimizer:\ndef group_weight(module):\n    group_decay = []\n    group_no_decay = []\n    for m in module.modules():\n        if isinstance(m, nn.Linear):\n            group_decay.append(m.weight)\n            if m.bias is not None:\n                group_no_decay.append(m.bias)\n        elif isinstance(m, _ConvNd):\n            group_decay.append(m.weight)\n            if m.bias is not None:\n                group_no_decay.append(m.bias)\n        elif isinstance(m, _BatchNorm):\n            if m.bias is not None:\n                group_no_decay.append(m.weight)\n            if m.bias is not None:\n                group_no_decay.append(m.bias)\n\n    assert len(list(module.parameters())) == len(group_decay) + len(group_no_decay)\n    groups = [dict(params=group_decay), dict(params=group_no_decay, weight_decay=.0)]\n    return groups", "body": "For this issue, I basically do something like this and send the output to the optimizer:\r\n```python\r\ndef group_weight(module):\r\n    group_decay = []\r\n    group_no_decay = []\r\n    for m in module.modules():\r\n        if isinstance(m, nn.Linear):\r\n            group_decay.append(m.weight)\r\n            if m.bias is not None:\r\n                group_no_decay.append(m.bias)\r\n        elif isinstance(m, _ConvNd):\r\n            group_decay.append(m.weight)\r\n            if m.bias is not None:\r\n                group_no_decay.append(m.bias)\r\n        elif isinstance(m, _BatchNorm):\r\n            if m.bias is not None:\r\n                group_no_decay.append(m.weight)\r\n            if m.bias is not None:\r\n                group_no_decay.append(m.bias)\r\n\r\n    assert len(list(module.parameters())) == len(group_decay) + len(group_no_decay)\r\n    groups = [dict(params=group_decay), dict(params=group_no_decay, weight_decay=.0)]\r\n    return groups\r\n```"}