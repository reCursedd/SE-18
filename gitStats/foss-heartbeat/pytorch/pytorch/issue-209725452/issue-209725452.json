{"url": "https://api.github.com/repos/pytorch/pytorch/issues/834", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/834/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/834/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/834/events", "html_url": "https://github.com/pytorch/pytorch/issues/834", "id": 209725452, "node_id": "MDU6SXNzdWUyMDk3MjU0NTI=", "number": 834, "title": "Concatenate function breaks when using GPU other than 0", "user": {"login": "ajbrock", "id": 7751273, "node_id": "MDQ6VXNlcjc3NTEyNzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/7751273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajbrock", "html_url": "https://github.com/ajbrock", "followers_url": "https://api.github.com/users/ajbrock/followers", "following_url": "https://api.github.com/users/ajbrock/following{/other_user}", "gists_url": "https://api.github.com/users/ajbrock/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajbrock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajbrock/subscriptions", "organizations_url": "https://api.github.com/users/ajbrock/orgs", "repos_url": "https://api.github.com/users/ajbrock/repos", "events_url": "https://api.github.com/users/ajbrock/events{/privacy}", "received_events_url": "https://api.github.com/users/ajbrock/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-23T10:44:20Z", "updated_at": "2017-02-23T11:56:54Z", "closed_at": "2017-02-23T11:42:29Z", "author_association": "NONE", "body_html": "<p>There's a bug in the cat() function that shows up if you try to concatenate a tensor that isn't on GPU 0; for some reason it seems to be trying to copy the concatenated tensors over to GPU 0, which then throws an illegal memory access error:</p>\n<pre><code>X,Y = torch.FloatTensor(5,4,20,20).cuda(0),torch.FloatTensor(5,8,20,20).cuda(0)\nZ = torch.cat((X,Y),1)\n</code></pre>\n<p>works fine, but</p>\n<pre><code>X,Y = torch.FloatTensor(5,4,20,20).cuda(2),torch.FloatTensor(5,8,20,20).cuda(2)\nZ = torch.cat((X,Y),1)\nZ\n</code></pre>\n<p>returns</p>\n<p><code>RuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.7_1485444530918/work/torch/lib/THC/generic/THCTensorCopy.c:65</code></p>\n<p>But only once you actually request the value of Z (you can still call cat() and it won't throw an error).  If you call Z.get_device() it will return 0. I have tried this in multiple ways (i.e. without the first call to cuda(0)) and have yet to have it behave any other way.</p>\n<p>The workaround for this (say, if you're trying to run a DenseNet) is to set torch.cuda.set_device(X.get_device()) before calling cat(), but it's not exactly an elegant solution.</p>", "body_text": "There's a bug in the cat() function that shows up if you try to concatenate a tensor that isn't on GPU 0; for some reason it seems to be trying to copy the concatenated tensors over to GPU 0, which then throws an illegal memory access error:\nX,Y = torch.FloatTensor(5,4,20,20).cuda(0),torch.FloatTensor(5,8,20,20).cuda(0)\nZ = torch.cat((X,Y),1)\n\nworks fine, but\nX,Y = torch.FloatTensor(5,4,20,20).cuda(2),torch.FloatTensor(5,8,20,20).cuda(2)\nZ = torch.cat((X,Y),1)\nZ\n\nreturns\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.7_1485444530918/work/torch/lib/THC/generic/THCTensorCopy.c:65\nBut only once you actually request the value of Z (you can still call cat() and it won't throw an error).  If you call Z.get_device() it will return 0. I have tried this in multiple ways (i.e. without the first call to cuda(0)) and have yet to have it behave any other way.\nThe workaround for this (say, if you're trying to run a DenseNet) is to set torch.cuda.set_device(X.get_device()) before calling cat(), but it's not exactly an elegant solution.", "body": "There's a bug in the cat() function that shows up if you try to concatenate a tensor that isn't on GPU 0; for some reason it seems to be trying to copy the concatenated tensors over to GPU 0, which then throws an illegal memory access error:\r\n\r\n```\r\nX,Y = torch.FloatTensor(5,4,20,20).cuda(0),torch.FloatTensor(5,8,20,20).cuda(0)\r\nZ = torch.cat((X,Y),1)\r\n```\r\n\r\nworks fine, but\r\n\r\n```\r\nX,Y = torch.FloatTensor(5,4,20,20).cuda(2),torch.FloatTensor(5,8,20,20).cuda(2)\r\nZ = torch.cat((X,Y),1)\r\nZ\r\n```\r\n\r\nreturns \r\n\r\n`RuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /data/users/soumith/miniconda2/conda-bld/pytorch-0.1.7_1485444530918/work/torch/lib/THC/generic/THCTensorCopy.c:65`\r\n\r\nBut only once you actually request the value of Z (you can still call cat() and it won't throw an error).  If you call Z.get_device() it will return 0. I have tried this in multiple ways (i.e. without the first call to cuda(0)) and have yet to have it behave any other way.\r\n\r\nThe workaround for this (say, if you're trying to run a DenseNet) is to set torch.cuda.set_device(X.get_device()) before calling cat(), but it's not exactly an elegant solution.\r\n"}