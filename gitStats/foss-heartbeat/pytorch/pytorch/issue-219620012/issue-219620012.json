{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1193", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1193/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1193/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1193/events", "html_url": "https://github.com/pytorch/pytorch/issues/1193", "id": 219620012, "node_id": "MDU6SXNzdWUyMTk2MjAwMTI=", "number": 1193, "title": "gather / scatter dont respect non-contigous out Tensor", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 491934870, "node_id": "MDU6TGFiZWw0OTE5MzQ4NzA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/dependency%20bug", "name": "dependency bug", "color": "b60205", "default": false}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/pytorch/pytorch/milestones/2", "html_url": "https://github.com/pytorch/pytorch/milestone/2", "labels_url": "https://api.github.com/repos/pytorch/pytorch/milestones/2/labels", "id": 2536200, "node_id": "MDk6TWlsZXN0b25lMjUzNjIwMA==", "number": 2, "title": "v0.2", "description": "", "creator": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 34, "state": "closed", "created_at": "2017-05-22T18:19:28Z", "updated_at": "2018-08-06T21:16:06Z", "due_on": "2017-06-04T07:00:00Z", "closed_at": "2018-08-06T21:16:06Z"}, "comments": 2, "created_at": "2017-04-05T15:17:28Z", "updated_at": "2017-11-21T01:35:36Z", "closed_at": null, "author_association": "MEMBER", "body_html": "<p>As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1908458\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tudor-berariu\">@tudor-berariu</a> reports:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\nsource <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> print(source)</span>\nidxs <span class=\"pl-k\">=</span> torch.LongTensor(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">3</span>).random_(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> print(idxs)</span>\n\na <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>)\na[<span class=\"pl-c1\">0</span>,:<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">2</span>:] <span class=\"pl-k\">=</span> torch.gather(source, <span class=\"pl-c1\">2</span>, idxs)\nb <span class=\"pl-k\">=</span> torch.zeros(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>)\ntorch.gather(source, <span class=\"pl-c1\">2</span>, idxs, <span class=\"pl-v\">out</span><span class=\"pl-k\">=</span>b[<span class=\"pl-c1\">0</span>,:<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">2</span>:])\n\n<span class=\"pl-c1\">print</span>(a)\n<span class=\"pl-c1\">print</span>(b)</pre></div>\n<pre><code>(0 ,.,.) = \n  0.0000  0.0000  0.3503  0.3527  0.3503\n  0.0000  0.0000  0.6724  0.6724  0.1911\n  0.0000  0.0000  0.2204  0.2204  0.2204\n  0.0000  0.0000  0.0000  0.0000  0.0000\n[torch.FloatTensor of size 1x4x5]\n\n(0 ,.,.) = \n  0.0000  0.0000  0.3503  0.3527  0.3503\n  0.6724  0.6724  0.1911  0.2204  0.2204\n  0.2204  0.0000  0.0000  0.0000  0.0000\n  0.0000  0.0000  0.0000  0.0000  0.0000\n[torch.FloatTensor of size 1x4x5]\n</code></pre>\n<p>We need to add the <code>freeCopyTo</code> pattern to the two functions in TH and THC</p>", "body_text": "As @tudor-berariu reports:\nimport torch\nsource = torch.rand(1, 3, 3)\n# print(source)\nidxs = torch.LongTensor(1, 3, 3).random_(0, 2)\n# print(idxs)\n\na = torch.zeros(1, 4, 5)\na[0,:3,2:] = torch.gather(source, 2, idxs)\nb = torch.zeros(1, 4, 5)\ntorch.gather(source, 2, idxs, out=b[0,:3,2:])\n\nprint(a)\nprint(b)\n(0 ,.,.) = \n  0.0000  0.0000  0.3503  0.3527  0.3503\n  0.0000  0.0000  0.6724  0.6724  0.1911\n  0.0000  0.0000  0.2204  0.2204  0.2204\n  0.0000  0.0000  0.0000  0.0000  0.0000\n[torch.FloatTensor of size 1x4x5]\n\n(0 ,.,.) = \n  0.0000  0.0000  0.3503  0.3527  0.3503\n  0.6724  0.6724  0.1911  0.2204  0.2204\n  0.2204  0.0000  0.0000  0.0000  0.0000\n  0.0000  0.0000  0.0000  0.0000  0.0000\n[torch.FloatTensor of size 1x4x5]\n\nWe need to add the freeCopyTo pattern to the two functions in TH and THC", "body": "As @tudor-berariu reports:\r\n\r\n```python\r\nimport torch\r\nsource = torch.rand(1, 3, 3)\r\n# print(source)\r\nidxs = torch.LongTensor(1, 3, 3).random_(0, 2)\r\n# print(idxs)\r\n\r\na = torch.zeros(1, 4, 5)\r\na[0,:3,2:] = torch.gather(source, 2, idxs)\r\nb = torch.zeros(1, 4, 5)\r\ntorch.gather(source, 2, idxs, out=b[0,:3,2:])\r\n\r\nprint(a)\r\nprint(b)\r\n```\r\n\r\n```\r\n(0 ,.,.) = \r\n  0.0000  0.0000  0.3503  0.3527  0.3503\r\n  0.0000  0.0000  0.6724  0.6724  0.1911\r\n  0.0000  0.0000  0.2204  0.2204  0.2204\r\n  0.0000  0.0000  0.0000  0.0000  0.0000\r\n[torch.FloatTensor of size 1x4x5]\r\n\r\n(0 ,.,.) = \r\n  0.0000  0.0000  0.3503  0.3527  0.3503\r\n  0.6724  0.6724  0.1911  0.2204  0.2204\r\n  0.2204  0.0000  0.0000  0.0000  0.0000\r\n  0.0000  0.0000  0.0000  0.0000  0.0000\r\n[torch.FloatTensor of size 1x4x5]\r\n```\r\n\r\nWe need to add the `freeCopyTo` pattern to the two functions in TH and THC"}