{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/141935380", "pull_request_review_id": 66233072, "id": 141935380, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MTkzNTM4MA==", "diff_hunk": "@@ -0,0 +1,348 @@\n+#include \"NNPACK.h\"\n+\n+#include \"TH/TH.h\"\n+#include <stdlib.h>\n+\n+namespace torch {\n+namespace nnpack {\n+\n+// Stolen from Caffe2\n+static pthreadpool_t nnpack_threadpool_ = nullptr;\n+\n+pthreadpool_t nnpack_threadpool() {\n+  if (nnpack_threadpool_ == nullptr) {\n+    enum nnp_status nnpack_status = nnp_initialize();\n+    if (nnpack_status != nnp_status_success) throw std::runtime_error(\"could not initialize NNPack\");\n+    nnpack_threadpool_ = pthreadpool_create(16);\n+  }\n+  return nnpack_threadpool_;\n+}\n+\n+// Assuming for now this is Thread-safe, but that seems like a stretch\n+static void *workspace = nullptr;\n+static size_t workspace_size = 0;\n+\n+// NNPack has alignment requirements\n+const size_t nnpack_memory_alignment_boundary = 64;\n+\n+static inline void deallocate_workspace() {\n+  if (workspace)\n+    std::free(workspace);\n+  workspace = nullptr;\n+}\n+\n+static inline void allocate_workspace() {\n+  if (workspace)\n+    deallocate_workspace();\n+  posix_memalign(&workspace, nnpack_memory_alignment_boundary, workspace_size);\n+}\n+\n+void SpatialConvolution_updateOutput(\n+    at::Tensor& input,\n+    at::Tensor& output,\n+    at::Tensor& weight,\n+    at::Tensor& bias,\n+    int kW,\n+    int kH,\n+    int padW,\n+    int padH) {\n+  // Setup parameters for the NNPack convolution output function call\n+\n+  // For now, we use the default algorithm\n+  auto algorithm = nnp_convolution_algorithm_auto;\n+\n+  // Our input Tensor must be in the form N,C,H,W\n+  if (input.ndimension() != 4) {\n+    throw std::runtime_error(\"NNPack convolutionOutput expects 4D input Tensor N,C,H,W\");\n+  }\n+  // Our weight Tensor must be in the form oC,iC,kH,kW\n+  if (weight.ndimension() != 4) {\n+    throw std::runtime_error(\"NNPack convolutionOutput expects 4D weight Tensor oC,iC,kH,kW\");\n+  }\n+  // Our weight Tensor must be in the form N,oC,oH,oW\n+  if (output.ndimension() != 4) {\n+    throw std::runtime_error(\"NNPack convolutionOutput expects 4D output Tensor N,oC,oH,oW\");\n+  }\n+\n+  // All Tensors must be float Tensors\n+  if (input.type().ID() != at::TypeID::CPUFloat ||\n+      weight.type().ID() != at::TypeID::CPUFloat ||\n+      output.type().ID() != at::TypeID::CPUFloat ||\n+      (bias.defined() && bias.type().ID() != at::TypeID::CPUFloat)) {\n+    throw std::runtime_error(\"Mismatched Tensor types in NNPack convolutionOutput\");\n+  }\n+\n+  const size_t batch_size = input.sizes()[0];\n+  const size_t input_channels = input.sizes()[1];\n+  const size_t output_channels = weight.sizes()[0];\n+  const struct nnp_size input_size = {\n+    .width = input.sizes()[3],\n+    .height = input.sizes()[2]\n+  };\n+  const struct nnp_padding input_padding = {\n+    .top = padH,\n+    .right = padW,\n+    .bottom = padH,\n+    .left = padW\n+  };\n+  const struct nnp_size kernel_size = {\n+    .width = kW,\n+    .height = kH\n+  };\n+\n+  // If we don't have a defined bias Tensor, we need to create one filled with zeroes\n+  auto bias_ = bias.defined() ? bias : input.type().zeros({output_channels});\n+\n+  // Note: we assume that the output is shaped correctly, probably should add an assert\n+\n+  auto run = [&]() -> nnp_status {\n+    return nnp_convolution_output(\n+        algorithm,\n+        batch_size,\n+        input_channels,\n+        output_channels,\n+        input_size,\n+        input_padding,\n+        kernel_size,\n+        (float*)input.data_ptr(),\n+        (float*)weight.data_ptr(),\n+        (float*)bias_.data_ptr(),\n+        (float*)output.data_ptr(),\n+        workspace, // workspace_buffer\n+        &workspace_size, // workspace_size\n+        nnp_activation_identity,\n+        nullptr, // activation parameters\n+        nnpack_threadpool(),\n+        nullptr // profile\n+    );\n+  };\n+\n+  auto size_and_allocate_ws = [&]() {\n+    // Run a single pass to get the size of memory workspace buffer\n+    auto status = run();\n+    if (status != nnp_status_success) {\n+      throw std::runtime_error(\"NNPACK SpatialConvolution_updateOutput failed\");\n+    }\n+    allocate_workspace();\n+  };\n+\n+  // If no workspace created yet, allocate it\n+  if (workspace == nullptr) {\n+    size_and_allocate_ws();\n+  }\n+\n+  // Try to run with the newly created, or existing workspace\n+  auto status = run();\n+\n+  if (status == nnp_status_insufficient_buffer) {\n+    // Need to reallocate the workspace\n+    deallocate_workspace();", "path": "torch/csrc/nnpack/NNPACK.cpp", "position": 328, "original_position": 139, "commit_id": "917f9b819b09ad90a2f46e1243a6ad6dfd2d37d7", "original_commit_id": "cdf73443cea3425f7d054d4245da9c9b039d1180", "user": {"login": "killeent", "id": 4529377, "node_id": "MDQ6VXNlcjQ1MjkzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4529377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/killeent", "html_url": "https://github.com/killeent", "followers_url": "https://api.github.com/users/killeent/followers", "following_url": "https://api.github.com/users/killeent/following{/other_user}", "gists_url": "https://api.github.com/users/killeent/gists{/gist_id}", "starred_url": "https://api.github.com/users/killeent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/killeent/subscriptions", "organizations_url": "https://api.github.com/users/killeent/orgs", "repos_url": "https://api.github.com/users/killeent/repos", "events_url": "https://api.github.com/users/killeent/events{/privacy}", "received_events_url": "https://api.github.com/users/killeent/received_events", "type": "User", "site_admin": false}, "body": "Yes, but we have to deallocate the workspace prior to the call otherwise the kernel will simply return insufficient buffer space again instead of calculating the new size that we need.", "created_at": "2017-09-29T18:25:38Z", "updated_at": "2018-11-23T15:34:52Z", "html_url": "https://github.com/pytorch/pytorch/pull/2826#discussion_r141935380", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2826", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/141935380"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2826#discussion_r141935380"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2826"}}, "body_html": "<p>Yes, but we have to deallocate the workspace prior to the call otherwise the kernel will simply return insufficient buffer space again instead of calculating the new size that we need.</p>", "body_text": "Yes, but we have to deallocate the workspace prior to the call otherwise the kernel will simply return insufficient buffer space again instead of calculating the new size that we need.", "in_reply_to_id": 141914984}