{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/333285282", "html_url": "https://github.com/pytorch/pytorch/pull/2826#issuecomment-333285282", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2826", "id": 333285282, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMzI4NTI4Mg==", "user": {"login": "Maratyszcza", "id": 1093985, "node_id": "MDQ6VXNlcjEwOTM5ODU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1093985?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Maratyszcza", "html_url": "https://github.com/Maratyszcza", "followers_url": "https://api.github.com/users/Maratyszcza/followers", "following_url": "https://api.github.com/users/Maratyszcza/following{/other_user}", "gists_url": "https://api.github.com/users/Maratyszcza/gists{/gist_id}", "starred_url": "https://api.github.com/users/Maratyszcza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Maratyszcza/subscriptions", "organizations_url": "https://api.github.com/users/Maratyszcza/orgs", "repos_url": "https://api.github.com/users/Maratyszcza/repos", "events_url": "https://api.github.com/users/Maratyszcza/events{/privacy}", "received_events_url": "https://api.github.com/users/Maratyszcza/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-30T05:30:54Z", "updated_at": "2017-09-30T05:30:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Some random notes:</p>\n<ol>\n<li><code>nnp_convolution_output</code>, <code>nnp_convolution_input_gradient</code>, <code>nnp_convolution_kernel_gradient</code> in NNPACK are not efficient when batch size, # input channels, or # output channels is small. Thus, you may want to add an option to enable/disable NNPACK on per-layer basis. You may also let users specify NNPACK algorithm on per-layer basis, default settings is not always the best.</li>\n<li>For <code>nnp_convolution_output</code> with batch size 1, <code>nnp_convolution_inference</code> nearly always would result in better performance. NNPACK doesn't, however, provide similar functions for backward pass with batch size 1.</li>\n<li>Do you use arbitrary tensor strides? I could make them work in NNPACK.</li>\n</ol>", "body_text": "Some random notes:\n\nnnp_convolution_output, nnp_convolution_input_gradient, nnp_convolution_kernel_gradient in NNPACK are not efficient when batch size, # input channels, or # output channels is small. Thus, you may want to add an option to enable/disable NNPACK on per-layer basis. You may also let users specify NNPACK algorithm on per-layer basis, default settings is not always the best.\nFor nnp_convolution_output with batch size 1, nnp_convolution_inference nearly always would result in better performance. NNPACK doesn't, however, provide similar functions for backward pass with batch size 1.\nDo you use arbitrary tensor strides? I could make them work in NNPACK.", "body": "Some random notes:\r\n1. `nnp_convolution_output`, `nnp_convolution_input_gradient`, `nnp_convolution_kernel_gradient` in NNPACK are not efficient when batch size, # input channels, or # output channels is small. Thus, you may want to add an option to enable/disable NNPACK on per-layer basis. You may also let users specify NNPACK algorithm on per-layer basis, default settings is not always the best.\r\n2. For `nnp_convolution_output` with batch size 1, `nnp_convolution_inference` nearly always would result in better performance. NNPACK doesn't, however, provide similar functions for backward pass with batch size 1.\r\n3. Do you use arbitrary tensor strides? I could make them work in NNPACK."}