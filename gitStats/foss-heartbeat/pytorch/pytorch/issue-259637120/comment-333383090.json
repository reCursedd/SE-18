{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/333383090", "html_url": "https://github.com/pytorch/pytorch/pull/2826#issuecomment-333383090", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2826", "id": 333383090, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMzM4MzA5MA==", "user": {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-01T15:08:31Z", "updated_at": "2017-10-01T15:08:31Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1093985\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Maratyszcza\">@Maratyszcza</a><br>\non (1),<br>\nit's a terrible idea to let users specify NNPACK algorithm on a per-layer basis. Extending this concept, we'll eventually get to: something like <a href=\"https://www.tensorflow.org/performance/performance_guide\" rel=\"nofollow\">the TensorFlow performance guide</a>.<br>\nWe need to come up with simple heuristics that predict at runtime if NNPACK is going to be faster. This shouldn't be that hard, as long as we take into account cache sizes, number of cores etc.</p>\n<ol start=\"3\">\n<li>yep users can give input/output tensors of arbitrary strides.</li>\n</ol>", "body_text": "@Maratyszcza\non (1),\nit's a terrible idea to let users specify NNPACK algorithm on a per-layer basis. Extending this concept, we'll eventually get to: something like the TensorFlow performance guide.\nWe need to come up with simple heuristics that predict at runtime if NNPACK is going to be faster. This shouldn't be that hard, as long as we take into account cache sizes, number of cores etc.\n\nyep users can give input/output tensors of arbitrary strides.", "body": "@Maratyszcza \r\non (1), \r\nit's a terrible idea to let users specify NNPACK algorithm on a per-layer basis. Extending this concept, we'll eventually get to: something like [the TensorFlow performance guide](https://www.tensorflow.org/performance/performance_guide).\r\nWe need to come up with simple heuristics that predict at runtime if NNPACK is going to be faster. This shouldn't be that hard, as long as we take into account cache sizes, number of cores etc.\r\n\r\n3. yep users can give input/output tensors of arbitrary strides."}