{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7885", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7885/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7885/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7885/events", "html_url": "https://github.com/pytorch/pytorch/issues/7885", "id": 326825368, "node_id": "MDU6SXNzdWUzMjY4MjUzNjg=", "number": 7885, "title": "Fit data into PyTorch RNN", "user": {"login": "FiammettaC", "id": 26167801, "node_id": "MDQ6VXNlcjI2MTY3ODAx", "avatar_url": "https://avatars2.githubusercontent.com/u/26167801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FiammettaC", "html_url": "https://github.com/FiammettaC", "followers_url": "https://api.github.com/users/FiammettaC/followers", "following_url": "https://api.github.com/users/FiammettaC/following{/other_user}", "gists_url": "https://api.github.com/users/FiammettaC/gists{/gist_id}", "starred_url": "https://api.github.com/users/FiammettaC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FiammettaC/subscriptions", "organizations_url": "https://api.github.com/users/FiammettaC/orgs", "repos_url": "https://api.github.com/users/FiammettaC/repos", "events_url": "https://api.github.com/users/FiammettaC/events{/privacy}", "received_events_url": "https://api.github.com/users/FiammettaC/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-27T15:28:33Z", "updated_at": "2018-05-29T14:01:18Z", "closed_at": "2018-05-29T14:01:18Z", "author_association": "NONE", "body_html": "<p>Hi, I am new to PyTorch and I am trying to train a simple LSTM.</p>\n<p>My input is the following:<br>\nX_train: list of vectorized sentences, padded to the same length, shape=(5441, 55)<br>\ny_train: list of list of labels converted to categorical, shape=(5441, 13122)</p>\n<p>I have some difficulties understanding if I have to modify the data in some ways or I can just fit it into my network.</p>\n<p>I was following this tutorial: <a href=\"url\">https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L38-L56</a></p>\n<p>So, I defined the following network:</p>\n<p>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</p>\n<p>sequence_length = 55 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177048587\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/28\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/28/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/28\">#28</a><br>\ninput_size = 5441 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177048587\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/28\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/28/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/28\">#28</a><br>\nhidden_size = 128<br>\nnum_layers = 2<br>\nnum_classes = vocab_size <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175552272\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10\">#10</a><br>\nbatch_size = 100<br>\nnum_epochs = 2<br>\nlearning_rate = 0.01</p>\n<p>class RNN(nn.Module):<br>\ndef <strong>init</strong>(self, input_size, hidden_size, num_layers, num_classes):<br>\nsuper(RNN, self).<strong>init</strong>()<br>\nself.hidden_size = hidden_size<br>\nself.num_layers = num_layers<br>\nself.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)<br>\nself.fc = nn.Linear(hidden_size, num_classes)</p>\n<pre><code>def forward(self, x):\n    # Set initial hidden and cell states \n    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n    \n    # Forward propagate LSTM\n    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n    \n    # Decode the hidden state of the last time step\n    out = self.fc(out[:, -1, :])\n    return out\n</code></pre>\n<p>model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)</p>\n<p>criterion = nn.CrossEntropyLoss()<br>\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</p>\n<p>total_step = len(X_train)<br>\nfor epoch in range(num_epochs):<br>\nfor i, data in enumerate(X_train):</p>\n<pre><code>    data = Variable(torch.from_numpy(np.array(X_train)).float())\n    labels = Variable(torch.from_numpy(np.array(y_train)).float())\n    \n    # Forward pass\n    outputs = model(data)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (i+1) % 100 == 0:\n        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n               .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n</code></pre>\n<p>But I get this error: TypeError: new() received an invalid combination of arguments - got (dict, int), but expected one of:</p>\n<ul>\n<li>(torch.device device)</li>\n<li>(tuple of ints size, torch.device device)<br>\ndidn't match because some of the arguments have invalid types: (dict, int)</li>\n<li>(torch.Storage storage)</li>\n<li>(Tensor other)</li>\n<li>(object data, torch.device device)<br>\ndidn't match because some of the arguments have invalid types: (dict, int)</li>\n</ul>\n<p>Can anybody help me understand what input to pass to the network? Thanks!</p>", "body_text": "Hi, I am new to PyTorch and I am trying to train a simple LSTM.\nMy input is the following:\nX_train: list of vectorized sentences, padded to the same length, shape=(5441, 55)\ny_train: list of list of labels converted to categorical, shape=(5441, 13122)\nI have some difficulties understanding if I have to modify the data in some ways or I can just fit it into my network.\nI was following this tutorial: https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L38-L56\nSo, I defined the following network:\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nsequence_length = 55 #28\ninput_size = 5441 #28\nhidden_size = 128\nnum_layers = 2\nnum_classes = vocab_size #10\nbatch_size = 100\nnum_epochs = 2\nlearning_rate = 0.01\nclass RNN(nn.Module):\ndef init(self, input_size, hidden_size, num_layers, num_classes):\nsuper(RNN, self).init()\nself.hidden_size = hidden_size\nself.num_layers = num_layers\nself.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\nself.fc = nn.Linear(hidden_size, num_classes)\ndef forward(self, x):\n    # Set initial hidden and cell states \n    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n    \n    # Forward propagate LSTM\n    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n    \n    # Decode the hidden state of the last time step\n    out = self.fc(out[:, -1, :])\n    return out\n\nmodel = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\ntotal_step = len(X_train)\nfor epoch in range(num_epochs):\nfor i, data in enumerate(X_train):\n    data = Variable(torch.from_numpy(np.array(X_train)).float())\n    labels = Variable(torch.from_numpy(np.array(y_train)).float())\n    \n    # Forward pass\n    outputs = model(data)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (i+1) % 100 == 0:\n        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n               .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\nBut I get this error: TypeError: new() received an invalid combination of arguments - got (dict, int), but expected one of:\n\n(torch.device device)\n(tuple of ints size, torch.device device)\ndidn't match because some of the arguments have invalid types: (dict, int)\n(torch.Storage storage)\n(Tensor other)\n(object data, torch.device device)\ndidn't match because some of the arguments have invalid types: (dict, int)\n\nCan anybody help me understand what input to pass to the network? Thanks!", "body": "Hi, I am new to PyTorch and I am trying to train a simple LSTM.\r\n\r\nMy input is the following: \r\nX_train: list of vectorized sentences, padded to the same length, shape=(5441, 55)\r\ny_train: list of list of labels converted to categorical, shape=(5441, 13122)\r\n\r\nI have some difficulties understanding if I have to modify the data in some ways or I can just fit it into my network.\r\n\r\nI was following this tutorial: [https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L38-L56](url)\r\n\r\nSo, I defined the following network:\r\n\r\n\r\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n\r\n\r\nsequence_length = 55 #28\r\ninput_size = 5441 #28\r\nhidden_size = 128\r\nnum_layers = 2\r\nnum_classes = vocab_size #10\r\nbatch_size = 100\r\nnum_epochs = 2\r\nlearning_rate = 0.01\r\n\r\n\r\nclass RNN(nn.Module):\r\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n        super(RNN, self).__init__()\r\n        self.hidden_size = hidden_size\r\n        self.num_layers = num_layers\r\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\r\n        self.fc = nn.Linear(hidden_size, num_classes)\r\n    \r\n    def forward(self, x):\r\n        # Set initial hidden and cell states \r\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \r\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n        \r\n        # Forward propagate LSTM\r\n        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\r\n        \r\n        # Decode the hidden state of the last time step\r\n        out = self.fc(out[:, -1, :])\r\n        return out\r\n\r\nmodel = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\r\n\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n\r\n\r\ntotal_step = len(X_train)\r\nfor epoch in range(num_epochs):\r\n    for i, data in enumerate(X_train):\r\n\r\n        data = Variable(torch.from_numpy(np.array(X_train)).float())\r\n        labels = Variable(torch.from_numpy(np.array(y_train)).float())\r\n        \r\n        # Forward pass\r\n        outputs = model(data)\r\n        loss = criterion(outputs, labels)\r\n        \r\n        # Backward and optimize\r\n        optimizer.zero_grad()\r\n        loss.backward()\r\n        optimizer.step()\r\n        \r\n        if (i+1) % 100 == 0:\r\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \r\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\r\n\r\nBut I get this error: TypeError: new() received an invalid combination of arguments - got (dict, int), but expected one of:\r\n * (torch.device device)\r\n * (tuple of ints size, torch.device device)\r\n      didn't match because some of the arguments have invalid types: (dict, int)\r\n * (torch.Storage storage)\r\n * (Tensor other)\r\n * (object data, torch.device device)\r\n      didn't match because some of the arguments have invalid types: (dict, int)\r\n\r\nCan anybody help me understand what input to pass to the network? Thanks!"}