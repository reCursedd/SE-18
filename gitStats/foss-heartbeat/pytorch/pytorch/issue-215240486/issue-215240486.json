{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1034", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1034/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1034/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1034/events", "html_url": "https://github.com/pytorch/pytorch/issues/1034", "id": 215240486, "node_id": "MDU6SXNzdWUyMTUyNDA0ODY=", "number": 1034, "title": "Comparing pytorch and theano speed", "user": {"login": "singlasahil14", "id": 6660192, "node_id": "MDQ6VXNlcjY2NjAxOTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6660192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/singlasahil14", "html_url": "https://github.com/singlasahil14", "followers_url": "https://api.github.com/users/singlasahil14/followers", "following_url": "https://api.github.com/users/singlasahil14/following{/other_user}", "gists_url": "https://api.github.com/users/singlasahil14/gists{/gist_id}", "starred_url": "https://api.github.com/users/singlasahil14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/singlasahil14/subscriptions", "organizations_url": "https://api.github.com/users/singlasahil14/orgs", "repos_url": "https://api.github.com/users/singlasahil14/repos", "events_url": "https://api.github.com/users/singlasahil14/events{/privacy}", "received_events_url": "https://api.github.com/users/singlasahil14/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-03-19T04:24:42Z", "updated_at": "2017-03-19T19:02:41Z", "closed_at": "2017-03-19T10:37:46Z", "author_association": "NONE", "body_html": "<p>I created the following two models:<br>\nPytorch model:</p>\n<pre><code>class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        return F.log_softmax(x)\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n</code></pre>\n<p>Keras model (with theano backend):</p>\n<pre><code># number of convolutional filters to use\nnb_filters = 10\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(2*nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(320))\nmodel.add(Activation('relu'))\nmodel.add(Dense(50))\nmodel.add(Activation('relu'))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n          verbose=1, validation_data=(X_test, Y_test))\nscore = model.evaluate(X_test, Y_test, verbose=0)\n</code></pre>\n<p>The time for theano model comes out to be 1 second per epoch. For pytorch model it is 6 seconds per epoch. Am I making a mistake or is pytorch really this slow?</p>", "body_text": "I created the following two models:\nPytorch model:\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        return F.log_softmax(x)\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\nKeras model (with theano backend):\n# number of convolutional filters to use\nnb_filters = 10\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(2*nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(320))\nmodel.add(Activation('relu'))\nmodel.add(Dense(50))\nmodel.add(Activation('relu'))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n          verbose=1, validation_data=(X_test, Y_test))\nscore = model.evaluate(X_test, Y_test, verbose=0)\n\nThe time for theano model comes out to be 1 second per epoch. For pytorch model it is 6 seconds per epoch. Am I making a mistake or is pytorch really this slow?", "body": "I created the following two models:\r\nPytorch model:\r\n```\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n        self.fc1 = nn.Linear(320, 50)\r\n        self.fc2 = nn.Linear(50, 10)\r\n\r\n    def forward(self, x):\r\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\r\n        x = x.view(-1, 320)\r\n        x = F.relu(self.fc1(x))\r\n        x = F.relu(self.fc2(x))\r\n        return F.log_softmax(x)\r\n\r\nmodel = Net()\r\nif args.cuda:\r\n    model.cuda()\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\r\n```\r\n\r\nKeras model (with theano backend):\r\n```\r\n# number of convolutional filters to use\r\nnb_filters = 10\r\n# size of pooling area for max pooling\r\npool_size = (2, 2)\r\n# convolution kernel size\r\nkernel_size = (5, 5)\r\n\r\nmodel = Sequential()\r\n\r\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\r\n                        border_mode='valid',\r\n                        input_shape=input_shape))\r\nmodel.add(MaxPooling2D(pool_size=pool_size))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Convolution2D(2*nb_filters, kernel_size[0], kernel_size[1]))\r\nmodel.add(MaxPooling2D(pool_size=pool_size))\r\nmodel.add(Activation('relu'))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(320))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(50))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(nb_classes))\r\nmodel.add(Activation('softmax'))\r\n\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer='adadelta',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\r\n          verbose=1, validation_data=(X_test, Y_test))\r\nscore = model.evaluate(X_test, Y_test, verbose=0)\r\n```\r\n\r\nThe time for theano model comes out to be 1 second per epoch. For pytorch model it is 6 seconds per epoch. Am I making a mistake or is pytorch really this slow?"}