{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180272685", "pull_request_review_id": 110658511, "id": 180272685, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4MDI3MjY4NQ==", "diff_hunk": "@@ -0,0 +1,423 @@\n+#include \"caffe2/contrib/tensorrt/tensorrt_tranformer.h\"\n+#include \"caffe2/contrib/tensorrt/trt_utils.h\"\n+#include \"caffe2/core/logging.h\"\n+#include \"caffe2/core/operator.h\"\n+#include \"caffe2/onnx/onnx_exporter.h\"\n+#include <onnx2trt.hpp>\n+#include <NvInfer.h>\n+\n+#include <google/protobuf/text_format.h>\n+#include <iostream>\n+#include <unordered_set>\n+\n+namespace caffe2 {\n+\n+namespace {\n+\n+// TODO(yinghai): Remove the awkward conversion between unordered_map and map\n+std::unordered_map<std::string, TensorShape> InferShapes(\n+    NetDef* init_net,\n+    NetDef* pred_net,\n+    const std::unordered_map<std::string, TensorShape>& input_shape_hints) {\n+  CaffeMap<std::string, TensorShape> shape_hints_ordered;\n+  for (const auto& kv : input_shape_hints) {\n+    shape_hints_ordered.emplace(kv.first, kv.second);\n+  }\n+  std::vector<std::unique_ptr<NetDef>> nets;\n+  nets.emplace_back(init_net);\n+  nets.emplace_back(pred_net);\n+  InferBlobShapesAndTypes(shape_hints_ordered, nets);\n+  for (auto& net : nets) {\n+    net.release();\n+  }\n+  std::unordered_map<std::string, TensorShape> shape_hints;\n+  for (const auto& kv : shape_hints_ordered) {\n+    shape_hints.emplace(kv.first, kv.second);\n+  }\n+\n+  return shape_hints;\n+}\n+\n+// Figuring out the input the tensorrt runnable subgraph\n+// `start` and `end` defines the continuous chunk of ops that can be readily\n+// converted into an TensorRT op. And this function tries to figure out what's\n+// the inputs of the to be converted TesnorRT op. What it does is that it\n+// collects the outputs from previous ops, which forms a cut boundary, and they\n+// can potential input of the TensorRT op (if referenced).\n+// `FigureOutputs` works similarly\n+std::vector<std::string> FigureInputs(\n+    const NetDef& pred_net,\n+    int start,\n+    int end,\n+    const std::vector<OperatorDef>& new_ops,\n+    const std::unordered_set<std::string>& weights,\n+    std::unordered_set<std::string>* initialization_list) {\n+  // TODO: cache this\n+  std::unordered_set<std::string> boundary_inputs;\n+  for (const auto& i : pred_net.external_input()) {\n+    boundary_inputs.emplace(i);\n+  }\n+\n+  for (const auto& op : new_ops) {\n+    for (const auto& output: op.output()) {\n+      boundary_inputs.emplace(output);\n+    }\n+  }\n+\n+  std::unordered_set<std::string> total_inputs;\n+  std::vector<std::string> total_inputs_vec;\n+  for(int i = start; i < end; ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& input: op.input()) {\n+      auto rt = total_inputs.emplace(input);\n+      if (rt.second) {\n+        if (weights.count(input)) {\n+          // We add weights as inputs too\n+          total_inputs_vec.emplace_back(input);\n+          initialization_list->emplace(input);\n+        } else if (boundary_inputs.count(input)) {\n+          VLOG(1) << \"Adding boundary input: \" << input;\n+          total_inputs_vec.emplace_back(input);\n+        }\n+      }\n+    }\n+  }\n+  return total_inputs_vec;\n+}\n+\n+// Outputs of the tensorrt runnable subgraph are computed as outputs from the\n+// ops of the subgraph that is\n+  // 1. referred by the subsequent ops\n+  // 2. in the external ouput of the net\n+std::vector<std::string>\n+FigureOutputs(const NetDef& pred_net, int start, int end) {\n+  std::unordered_set<std::string> ext_outputs;\n+  for (const auto& e: pred_net.external_output()) {\n+    ext_outputs.emplace(e);\n+  }\n+  std::unordered_set<std::string> referred_inputs;\n+  for (int i = end; i < pred_net.op_size(); ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& input: op.input()) {\n+      referred_inputs.emplace(input);\n+    }\n+  }\n+\n+  std::unordered_set<std::string> all_outputs;\n+  std::vector<std::string> all_outputs_vec;\n+  for (int i = start; i < end; ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& output: op.output()) {\n+      if (referred_inputs.count(output) || ext_outputs.count(output)) {\n+        if(all_outputs.emplace(output).second) {\n+          all_outputs_vec.emplace_back(output);\n+        }\n+      }\n+    }\n+  }\n+\n+  return all_outputs_vec;\n+}\n+\n+std::vector<::ONNX_NAMESPACE::ValueInfoProto> ConvertToValueInfo(\n+    const std::vector<std::string>& names,\n+    const std::unordered_map<std::string, TensorShape>& shape_hints) {\n+  std::vector<::ONNX_NAMESPACE::ValueInfoProto> r;\n+  for (const auto& s: names) {\n+    r.emplace_back();\n+    auto& value_info = r.back();\n+    value_info.set_name(s);\n+    const auto it = shape_hints.find(s);\n+    if (it == shape_hints.end()) {\n+      LOG(WARNING) << \"Cannot get shape of \" << s;\n+    } else {\n+      auto* tensor_type = value_info.mutable_type()->mutable_tensor_type();\n+      tensor_type->set_elem_type(\n+          ::ONNX_NAMESPACE::TensorProto_DataType::TensorProto_DataType_FLOAT);\n+      auto* shape = tensor_type->mutable_shape();\n+      for (int i = 0 ; i < it->second.dims().size(); ++i) {\n+        auto* dim = shape->add_dim();\n+        dim->set_dim_value(it->second.dims(i));\n+      }\n+    }\n+  }\n+  return r;\n+}\n+\n+void PruneUsedWeights(const NetDef& pred_net, NetDef* init_net) {\n+  std::unordered_set<std::string> used_weights;\n+  for (const auto& op: pred_net.op()) {\n+    for (const auto& i: op.input()) {\n+      used_weights.emplace(i);\n+    }\n+  }\n+\n+  int last = init_net->op_size();\n+  for (int i = 0; i < last;) {\n+    if (!used_weights.count(init_net->op(i).output(0))) {\n+      if (i != last - 1) {\n+        init_net->mutable_op()->SwapElements(i, last - 1);\n+      } else {\n+        ++i;\n+      }\n+      --last;\n+    } else {\n+      ++i;\n+    }\n+  }\n+\n+  if (last < init_net->op_size()) {\n+    init_net->mutable_op()->DeleteSubrange(last, init_net->op_size() - last);\n+  }\n+\n+  LOG(INFO) << \"New init_net op size: \" << init_net->op_size();\n+}\n+\n+void FillModelInfo(::ONNX_NAMESPACE::ModelProto* model) {\n+  model->set_ir_version(::ONNX_NAMESPACE::Version::IR_VERSION);\n+  model->set_producer_name(\"caffe2\");\n+  auto* opset_id = model->add_opset_import();\n+  opset_id->set_domain(\"\");\n+  opset_id->set_version(3);\n+}\n+} // namespace\n+\n+OperatorDef TensorRTTransformer::BuildTrtOp(\n+    const std::string& onnx_model_str,\n+    const std::unordered_map<std::string, std::vector<int>>&\n+        output_size_hints) {\n+  OperatorDef op;\n+  op.set_type(\"TensorRT\");\n+\n+  TrtLogger logger;\n+  auto trt_builder = InferObject(nvinfer1::createInferBuilder(logger));\n+  auto trt_network = InferObject(trt_builder->createNetwork());\n+  auto importer = InferObject(onnx2trt::createImporter(trt_network.get()));\n+  auto status = importer->import(onnx_model_str.data(), onnx_model_str.size(), false);\n+  if (status.is_error()) {\n+    CAFFE_THROW(\n+        \"TensorRTTransformer ERROR: \",\n+        status.file(),\n+        \":\",\n+        status.line(),\n+        \" In function \",\n+        status.func(),\n+        \":\\n\",\n+        \"[\",\n+        status.code(),\n+        \"] \",\n+        status.desc());\n+  }\n+  trt_builder->setMaxBatchSize(max_batch_size_);\n+  trt_builder->setMaxWorkspaceSize(max_workspace_size_);\n+  trt_builder->setDebugSync(debug_builder_);\n+  auto trt_engine =\n+      InferObject(trt_builder->buildCudaEngine(*trt_network.get()));\n+\n+  // Set up inputs/outputs in the order of they appearnce in getNbBindings\n+  int num_bindings = trt_engine->getNbBindings();\n+  for (int b = 0; b < num_bindings; ++b) {\n+    const auto& name = trt_engine->getBindingName(b);\n+    if (trt_engine->bindingIsInput(b)) {\n+      op.add_input(name);\n+    } else {\n+      op.add_output(name);\n+    }\n+  }\n+\n+  auto engine_plan = InferObject(trt_engine->serialize());\n+\n+  auto* serialized_engine_arg = op.add_arg();\n+  serialized_engine_arg->set_s(\"\");\n+  serialized_engine_arg->set_name(\"serialized_engine\");\n+  auto* s = serialized_engine_arg->mutable_s();\n+  s->assign((char*)engine_plan->data(), engine_plan->size());\n+\n+  auto* max_batch_size_arg = op.add_arg();\n+  max_batch_size_arg->set_name(\"max_batch_size\");\n+  max_batch_size_arg->set_i(max_batch_size_);\n+\n+  auto* verbosity_arg = op.add_arg();\n+  verbosity_arg->set_name(\"log_verbosity\");\n+  verbosity_arg->set_i(verbosity_);\n+\n+  for (int i = 0; i < op.output_size(); ++i) {\n+    const auto& o = op.output(i);\n+    const auto it = output_size_hints.find(o);\n+    if (it != output_size_hints.end()) {\n+      const auto& dims = it->second;\n+      auto* output_size_hint_arg = op.add_arg();\n+      output_size_hint_arg->set_name(MakeString(\"output_size_hint_\", i));\n+      for (const auto& d : dims) {\n+        output_size_hint_arg->add_ints(d);\n+      }\n+\n+      LOG(INFO) << \"Adding output hint: \" << o;\n+    }\n+  }\n+\n+  return op;\n+}\n+\n+void TensorRTTransformer::ClusterToTrtOp(\n+    const NetDef& init_net,\n+    const NetDef& pred_net,\n+    int start,\n+    int end,\n+    const std::unordered_set<std::string>& weights,\n+    const std::unordered_map<std::string, TensorShape>& shape_hints,\n+    ::ONNX_NAMESPACE::ModelProto* model,\n+    std::vector<OperatorDef>* new_ops) {\n+  if (model->graph().node_size() == 0) {\n+    return;\n+  }\n+  model->mutable_graph()->clear_input();\n+  model->mutable_graph()->clear_output();\n+  model->mutable_graph()->clear_initializer();\n+\n+  // Figure out the boundary outputs\n+  auto outputs = ConvertToValueInfo(FigureOutputs(pred_net, start, end), shape_hints);\n+  std::unordered_map<std::string, std::vector<int>> output_shape_hints;\n+  for (const auto& i: outputs) {\n+    model->mutable_graph()->add_output()->CopyFrom(i);\n+    auto ret = output_shape_hints.emplace(i.name(), std::vector<int>());\n+    auto& vec = ret.first->second;\n+    const auto it = shape_hints.find(i.name());\n+    CAFFE_ENFORCE(it != shape_hints.end(), \"Cannot find shape info for output \", i.name());\n+    const auto& shape = it->second;\n+    for (int k = 0; k < shape.dims().size(); ++k) {\n+      vec.push_back(shape.dims(k));\n+    }\n+  }\n+\n+  // Figure out the boundary inputs\n+  std::unordered_set<std::string> initialization_list;\n+  auto total_inputs_vec = FigureInputs(pred_net, start, end, *new_ops, weights, &initialization_list);\n+  auto inputs = ConvertToValueInfo(total_inputs_vec, shape_hints);\n+  for (const auto& i: inputs) {\n+    LOG(INFO) << \"Added input: \" << i.name();\n+    model->mutable_graph()->add_input()->CopyFrom(i);\n+  }\n+\n+  // Convert weights to initializing tensors\n+  onnx::OnnxExporter exporter;\n+  for (const auto& op: init_net.op()) {\n+    CAFFE_ENFORCE_EQ(op.output_size(), 1);\n+    auto it = initialization_list.find(op.output(0));\n+    if (it != initialization_list.end()) {\n+      auto* init_tensor = model->mutable_graph()->add_initializer();\n+      exporter.InitOpToTensorProto(op, init_tensor);\n+      initialization_list.erase(it);\n+    }\n+  }\n+  CAFFE_ENFORCE(initialization_list.empty(), \"Unfulfilled initialization list\");\n+  for (const auto& t: model->graph().initializer()) {\n+    LOG(INFO) << \"Initializer: \" << t.name();\n+  }\n+\n+  // Onnx model is ready. Call onnx-trt to convert to one trt c2 op\n+  std::string model_str;\n+  model->SerializeToString(&model_str);\n+  new_ops->emplace_back(BuildTrtOp(model_str, output_shape_hints));\n+\n+  model->mutable_graph()->clear_node();\n+}\n+\n+// Cutting off the runnable part and replace with tensor ops. Asssume the nets\n+// were topologically sorted\n+void TensorRTTransformer::Transform(\n+    NetDef* init_net,\n+    NetDef* pred_net,\n+    const std::unordered_map<std::string, TensorShape>& input_shape_hints) {\n+  const auto shape_hints = InferShapes(init_net, pred_net, input_shape_hints);\n+\n+  std::unordered_set<std::string> weights;\n+  if (init_net) {\n+    for (const auto& op : init_net->op()) {\n+      CAFFE_ENFORCE_EQ(op.type().find(\"GivenTensor\"), 0);\n+      CAFFE_ENFORCE_EQ(op.type().rfind(\"Fill\"), op.type().size() - 4);\n+      CAFFE_ENFORCE_EQ(op.output_size(), 1);\n+      for (const auto& op_output : op.output()) {\n+        weights.emplace(op_output);\n+      }\n+    }\n+  }\n+\n+  CAFFE_ENFORCE(pred_net, \"pred_net cannot be nullptr\");\n+  ::ONNX_NAMESPACE::ModelProto onnx_model;\n+  FillModelInfo(&onnx_model);\n+\n+  std::vector<OperatorDef> new_ops;\n+  bool trt_group = false;\n+  auto importer = InferObject(onnx2trt::createImporter(nullptr));\n+  int op_idx = 0;\n+  int start = 0;\n+  int end = 0;\n+  for (const OperatorDef& op : pred_net->op()) {\n+    bool support_trt = true;\n+    const OpSchema* schema = OpSchemaRegistry::Schema(op.type());\n+    caffe2::onnx::ConvertedResult results;\n+    if (!schema || schema->onnx_schema().empty()) {\n+      LOG(INFO) << \"Cannot export c2 op \" << op.type() << \" to onnx\";\n+      support_trt = false;\n+    } else {\n+      // One c2 op can be converted into multiple onnx nodes. For simplicity, we\n+      // enforce all or nothing here\n+      results = onnx::OnnxExporter().Caffe2OpToOnnxNodes(op, shape_hints);\n+      for (const auto& n : results.first) {\n+        if (!importer->supports(n)) {\n+          LOG(INFO) << \"TRT does not support ONNX node \" << n.op_type();\n+          support_trt = false;\n+          break;\n+        }\n+      }\n+    }\n+\n+    if (support_trt) {\n+      const auto& node_protos = results.first;\n+      if (!trt_group) {\n+        trt_group = true;\n+        start = op_idx;\n+      }\n+      for (const auto& n : node_protos) {\n+        auto* node = onnx_model.mutable_graph()->add_node();\n+        node->CopyFrom(n);\n+      }\n+    } else {\n+      end = op_idx;\n+      ClusterToTrtOp(\n+          *init_net,", "path": "caffe2/contrib/tensorrt/tensorrt_tranformer.cc", "position": 431, "original_position": 389, "commit_id": "66758cc2919a2a6add56c6bcda8e33f50c94044b", "original_commit_id": "ce45759d924624a90b532be892ecbf0693101d14", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "simpler case for init_net might be to just create a throw-away Workspace and run the net. Then we don't need awkward `InitOpToTensorProto` and can even support more initializers directly. What do you think?\r\n\r\nEven better option is to create this workspace at some higher level and make interface of conversion take workspace+predict_net instead of init_net+predict_net", "created_at": "2018-04-10T01:07:05Z", "updated_at": "2018-11-23T15:42:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/6150#discussion_r180272685", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6150", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/180272685"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6150#discussion_r180272685"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6150"}}, "body_html": "<p>simpler case for init_net might be to just create a throw-away Workspace and run the net. Then we don't need awkward <code>InitOpToTensorProto</code> and can even support more initializers directly. What do you think?</p>\n<p>Even better option is to create this workspace at some higher level and make interface of conversion take workspace+predict_net instead of init_net+predict_net</p>", "body_text": "simpler case for init_net might be to just create a throw-away Workspace and run the net. Then we don't need awkward InitOpToTensorProto and can even support more initializers directly. What do you think?\nEven better option is to create this workspace at some higher level and make interface of conversion take workspace+predict_net instead of init_net+predict_net"}