{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178681070", "pull_request_review_id": 108778469, "id": 178681070, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3ODY4MTA3MA==", "diff_hunk": "@@ -0,0 +1,423 @@\n+#include \"caffe2/contrib/tensorrt/tensorrt_tranformer.h\"\n+#include \"caffe2/contrib/tensorrt/trt_utils.h\"\n+#include \"caffe2/core/logging.h\"\n+#include \"caffe2/core/operator.h\"\n+#include \"caffe2/onnx/onnx_exporter.h\"\n+#include <onnx2trt.hpp>\n+#include <NvInfer.h>\n+\n+#include <google/protobuf/text_format.h>\n+#include <iostream>\n+#include <unordered_set>\n+\n+namespace caffe2 {\n+\n+namespace {\n+\n+// TODO(yinghai): Remove the awkward conversion between unordered_map and map\n+std::unordered_map<std::string, TensorShape> InferShapes(\n+    NetDef* init_net,\n+    NetDef* pred_net,\n+    const std::unordered_map<std::string, TensorShape>& input_shape_hints) {\n+  CaffeMap<std::string, TensorShape> shape_hints_ordered;\n+  for (const auto& kv : input_shape_hints) {\n+    shape_hints_ordered.emplace(kv.first, kv.second);\n+  }\n+  std::vector<std::unique_ptr<NetDef>> nets;\n+  nets.emplace_back(init_net);\n+  nets.emplace_back(pred_net);\n+  InferBlobShapesAndTypes(shape_hints_ordered, nets);\n+  for (auto& net : nets) {\n+    net.release();\n+  }\n+  std::unordered_map<std::string, TensorShape> shape_hints;\n+  for (const auto& kv : shape_hints_ordered) {\n+    shape_hints.emplace(kv.first, kv.second);\n+  }\n+\n+  return shape_hints;\n+}\n+\n+std::vector<std::string> FigureInputs(\n+    const NetDef& pred_net,\n+    int start,\n+    int end,\n+    const std::vector<OperatorDef>& new_ops,\n+    const std::unordered_set<std::string>& weights,\n+    std::unordered_set<std::string>* initialization_list) {\n+  // TODO: cache this\n+  std::unordered_set<std::string> boundary_inputs;\n+  for (const auto& i : pred_net.external_input()) {\n+    boundary_inputs.emplace(i);\n+  }\n+\n+  //\n+  for (const auto& op : new_ops) {\n+    for (const auto& output: op.output()) {\n+      boundary_inputs.emplace(output);\n+    }\n+  }\n+\n+  std::unordered_set<std::string> total_inputs;\n+  std::vector<std::string> total_inputs_vec;\n+  for(int i = start; i < end; ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& input: op.input()) {\n+      auto rt = total_inputs.emplace(input);\n+      if (rt.second) {\n+        if (weights.count(input)) {\n+          // We add weights as inputs too\n+          total_inputs_vec.emplace_back(input);\n+          initialization_list->emplace(input);\n+        } else if (boundary_inputs.count(input)) {\n+          LOG(INFO) << \"Adding boundary input: \" << input;\n+          total_inputs_vec.emplace_back(input);\n+        }\n+      }\n+    }\n+  }\n+  return total_inputs_vec;\n+}\n+\n+std::vector<std::string>\n+FigureOutputs(const NetDef& pred_net, int start, int end) {\n+  std::unordered_set<std::string> all_outputs;\n+  std::vector<std::string> all_outputs_vec;\n+  std::unordered_set<std::string> ext_outputs;\n+  for (const auto& e: pred_net.external_output()) {\n+    ext_outputs.emplace(e);\n+  }\n+  for (int i = start; i < end; ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& output: op.output()) {\n+      all_outputs.emplace(output);\n+      all_outputs_vec.emplace_back(output);\n+    }\n+  }\n+  std::unordered_set<std::string> referred_inputs;\n+  for (int i = end; i < pred_net.op_size(); ++i) {\n+    const auto& op = pred_net.op(i);\n+    for (const auto& input: op.input()) {\n+      referred_inputs.emplace(input);\n+    }\n+  }\n+  // Remove the output that is\n+  // 1. Not referred by the subsequent ops\n+  // 2. Not in the external ouput of the net\n+  all_outputs_vec.erase(\n+      std::remove_if(\n+          all_outputs_vec.begin(),\n+          all_outputs_vec.end(),\n+          [&ext_outputs, &referred_inputs](const std::string& output) {\n+            return (\n+                !referred_inputs.count(output) && !ext_outputs.count(output));\n+          }),\n+      all_outputs_vec.end());\n+  return all_outputs_vec;\n+}\n+\n+std::vector<::ONNX_NAMESPACE::ValueInfoProto> ConvertToValueInfo(\n+    const std::vector<std::string>& names,\n+    const std::unordered_map<std::string, TensorShape>& shape_hints) {\n+  std::vector<::ONNX_NAMESPACE::ValueInfoProto> r;\n+  for (const auto& s: names) {\n+    r.emplace_back();\n+    auto& value_info = r.back();\n+    value_info.set_name(s);\n+    const auto it = shape_hints.find(s);\n+    if (it == shape_hints.end()) {\n+      LOG(WARNING) << \"Cannot get shape of \" << s;\n+    } else {\n+      auto* tensor_type = value_info.mutable_type()->mutable_tensor_type();\n+      tensor_type->set_elem_type(\n+          ::ONNX_NAMESPACE::TensorProto_DataType::TensorProto_DataType_FLOAT);\n+      auto* shape = tensor_type->mutable_shape();\n+      for (int i = 0 ; i < it->second.dims().size(); ++i) {\n+        auto* dim = shape->add_dim();\n+        dim->set_dim_value(it->second.dims(i));\n+      }\n+    }\n+  }\n+  return r;\n+}\n+\n+void PruneWeights(const NetDef& pred_net, NetDef* init_net) {\n+  std::unordered_set<std::string> used_weights;\n+  for (const auto& op: pred_net.op()) {\n+    for (const auto& i: op.input()) {\n+      used_weights.emplace(i);\n+    }\n+  }\n+\n+  int last = init_net->op_size();\n+  for (int i = 0; i < last;) {\n+    if (!used_weights.count(init_net->op(i).output(0))) {\n+      if (i != last - 1) {\n+        init_net->mutable_op()->SwapElements(i, last - 1);\n+      } else {\n+        ++i;\n+      }\n+      --last;\n+    } else {\n+      ++i;\n+    }\n+  }\n+\n+  if (last < init_net->op_size()) {\n+    init_net->mutable_op()->DeleteSubrange(last, init_net->op_size() - last);\n+  }\n+\n+  LOG(INFO) << \"New init_net op size: \" << init_net->op_size();\n+}\n+\n+void FillModelInfo(::ONNX_NAMESPACE::ModelProto* model) {\n+  model->set_ir_version(::ONNX_NAMESPACE::Version::IR_VERSION);\n+  model->set_producer_name(\"caffe2\");\n+  auto* opset_id = model->add_opset_import();\n+  opset_id->set_domain(\"\");\n+  opset_id->set_version(3);\n+}\n+} // namespace\n+\n+OperatorDef TensorRTTransformer::BuildTrtOp(\n+    const std::string& onnx_model_str,\n+    const std::unordered_map<std::string, std::vector<int>>&\n+        output_size_hints) {\n+  OperatorDef op;\n+  op.set_type(\"TensorRT\");\n+\n+  TrtLogger logger;\n+  auto trt_builder = InferObject(nvinfer1::createInferBuilder(logger));\n+  auto trt_network = InferObject(trt_builder->createNetwork());\n+  auto importer = InferObject(onnx2trt::createImporter(trt_network.get()));\n+  auto status = importer->import(onnx_model_str.data(), onnx_model_str.size(), false);\n+  if (status.is_error()) {\n+    CAFFE_THROW(MakeString(\n+        \"TensorRTTransformer ERROR: \",\n+        status.file(),\n+        \":\",\n+        status.line(),\n+        \" In function \",\n+        status.func(),\n+        \":\\n\",\n+        \"[\",\n+        status.code(),\n+        \"] \",\n+        status.desc()));\n+  }\n+  trt_builder->setMaxBatchSize(max_batch_size_);\n+  trt_builder->setMaxWorkspaceSize(max_workspace_size_);\n+  trt_builder->setDebugSync(debug_builder_);\n+  auto trt_engine =\n+      InferObject(trt_builder->buildCudaEngine(*trt_network.get()));\n+\n+  // Set up inputs/outputs\n+  int num_bindings = trt_engine->getNbBindings();\n+  for (int b = 0; b < num_bindings; ++b) {\n+    const auto& name = trt_engine->getBindingName(b);\n+    if (trt_engine->bindingIsInput(b)) {\n+      op.add_input(name);\n+    } else {\n+      op.add_output(name);\n+    }\n+  }\n+\n+  auto engine_plan = InferObject(trt_engine->serialize());\n+", "path": "caffe2/contrib/tensorrt/tensorrt_tranformer.cc", "position": null, "original_position": 226, "commit_id": "66758cc2919a2a6add56c6bcda8e33f50c94044b", "original_commit_id": "1051f2359f3ec0a4d7c28794d4a3ea67360bcd3d", "user": {"login": "yinghai", "id": 1100089, "node_id": "MDQ6VXNlcjExMDAwODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/1100089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yinghai", "html_url": "https://github.com/yinghai", "followers_url": "https://api.github.com/users/yinghai/followers", "following_url": "https://api.github.com/users/yinghai/following{/other_user}", "gists_url": "https://api.github.com/users/yinghai/gists{/gist_id}", "starred_url": "https://api.github.com/users/yinghai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yinghai/subscriptions", "organizations_url": "https://api.github.com/users/yinghai/orgs", "repos_url": "https://api.github.com/users/yinghai/repos", "events_url": "https://api.github.com/users/yinghai/events{/privacy}", "received_events_url": "https://api.github.com/users/yinghai/received_events", "type": "User", "site_admin": false}, "body": "@Maratyszcza  I actually met with a weird linkage error when I tried to use `MakeArgument` here. It complains  that `MakeArugument` symbol is missing during runtime. Any idea? ", "created_at": "2018-04-02T23:52:43Z", "updated_at": "2018-11-23T15:41:32Z", "html_url": "https://github.com/pytorch/pytorch/pull/6150#discussion_r178681070", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/6150", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/178681070"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/6150#discussion_r178681070"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/6150"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1093985\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Maratyszcza\">@Maratyszcza</a>  I actually met with a weird linkage error when I tried to use <code>MakeArgument</code> here. It complains  that <code>MakeArugument</code> symbol is missing during runtime. Any idea?</p>", "body_text": "@Maratyszcza  I actually met with a weird linkage error when I tried to use MakeArgument here. It complains  that MakeArugument symbol is missing during runtime. Any idea?", "in_reply_to_id": 178413658}