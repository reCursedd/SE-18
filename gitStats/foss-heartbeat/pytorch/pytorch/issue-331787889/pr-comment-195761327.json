{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195761327", "pull_request_review_id": 129193908, "id": 195761327, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NTc2MTMyNw==", "diff_hunk": "@@ -0,0 +1,122 @@\n+#ifndef THC_GENERIC_FILE\n+#define THC_GENERIC_FILE \"generic/THCTensorKthValue.cu\"\n+#else\n+\n+THC_API void THCTensor_(kthvalue)(THCState* state,\n+                                  THCTensor* kthValue,\n+                                  THCudaLongTensor* indices,\n+                                  THCTensor* input,\n+                                  int64_t k, int dim, int keepDim) {\n+  THAssert(kthValue != NULL && indices != NULL && input != NULL);\n+  THCAssertSameGPU(THCTensor_(checkGPU)(state, 3, kthValue, indices, input));\n+  THArgCheck(THCTensor_(nDimension)(state, kthValue) <= MAX_CUTORCH_DIMS, 2, CUTORCH_DIM_WARNING);\n+  int64_t dims = THCudaLongTensor_nDimension(state, indices);\n+  THArgCheck(dims <= MAX_CUTORCH_DIMS, 3, CUTORCH_DIM_WARNING);\n+  int numDims = THCTensor_(nDimension)(state, input);\n+  THArgCheck(numDims <= MAX_CUTORCH_DIMS, 4, CUTORCH_DIM_WARNING);\n+\n+  THArgCheck(dim >= 0 && dim < numDims, 6, \"dim not in range\");\n+\n+  int64_t sliceSize = THCTensor_(size)(state, input, dim);\n+  THArgCheck(k > 0 && k <= sliceSize, 5, \"k not in range for dimension\");\n+\n+  // Build the output size, which is the dim being selected set to\n+  // size 1\n+  THLongStorage* kthValueSize = THCTensor_(newSizeOf)(state, input);\n+  THLongStorage_set(kthValueSize, dim, 1);\n+  THCTensor_(resize)(state, kthValue, kthValueSize, NULL);", "path": "aten/src/THC/generic/THCTensorKthValue.cu", "position": 27, "original_position": 27, "commit_id": "67204dac722d05387ca13d50382378d66e1c3814", "original_commit_id": "b88b13605d7ae48f3b14ef96200143b278cb14ea", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "body": "Let's say keepdim is False. Then we should attempt to avoid the resize, because the resize changes the contiguity of the inputs, which could be bad. [kthvalue](https://pytorch.org/docs/master/torch.html?highlight=kth%20value#torch.kthvalue) supports passing in \"output\" tensors that the results should be stored in.\r\n\r\n[This function](https://github.com/pytorch/pytorch/blob/b002aee0ff5eeea7172e4037b3d5936202cb6aef/aten/src/THC/THCTensor.cpp#L367-L381) might help.", "created_at": "2018-06-15T14:37:47Z", "updated_at": "2018-11-23T15:45:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/8406#discussion_r195761327", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8406", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/195761327"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8406#discussion_r195761327"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8406"}}, "body_html": "<p>Let's say keepdim is False. Then we should attempt to avoid the resize, because the resize changes the contiguity of the inputs, which could be bad. <a href=\"https://pytorch.org/docs/master/torch.html?highlight=kth%20value#torch.kthvalue\" rel=\"nofollow\">kthvalue</a> supports passing in \"output\" tensors that the results should be stored in.</p>\n<p><a href=\"https://github.com/pytorch/pytorch/blob/b002aee0ff5eeea7172e4037b3d5936202cb6aef/aten/src/THC/THCTensor.cpp#L367-L381\">This function</a> might help.</p>", "body_text": "Let's say keepdim is False. Then we should attempt to avoid the resize, because the resize changes the contiguity of the inputs, which could be bad. kthvalue supports passing in \"output\" tensors that the results should be stored in.\nThis function might help."}