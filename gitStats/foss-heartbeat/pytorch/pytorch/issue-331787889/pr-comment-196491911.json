{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196491911", "pull_request_review_id": 130054530, "id": 196491911, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NjQ5MTkxMQ==", "diff_hunk": "@@ -0,0 +1,122 @@\n+#ifndef THC_GENERIC_FILE\n+#define THC_GENERIC_FILE \"generic/THCTensorKthValue.cu\"\n+#else\n+\n+THC_API void THCTensor_(kthvalue)(THCState* state,\n+                                  THCTensor* kthValue,\n+                                  THCudaLongTensor* indices,\n+                                  THCTensor* input,\n+                                  int64_t k, int dim, int keepDim) {\n+  THAssert(kthValue != NULL && indices != NULL && input != NULL);\n+  THCAssertSameGPU(THCTensor_(checkGPU)(state, 3, kthValue, indices, input));\n+  THArgCheck(THCTensor_(nDimension)(state, kthValue) <= MAX_CUTORCH_DIMS, 2, CUTORCH_DIM_WARNING);\n+  int64_t dims = THCudaLongTensor_nDimension(state, indices);\n+  THArgCheck(dims <= MAX_CUTORCH_DIMS, 3, CUTORCH_DIM_WARNING);\n+  int numDims = THCTensor_(nDimension)(state, input);\n+  THArgCheck(numDims <= MAX_CUTORCH_DIMS, 4, CUTORCH_DIM_WARNING);\n+\n+  THArgCheck(dim >= 0 && dim < numDims, 6, \"dim not in range\");\n+\n+  int64_t sliceSize = THCTensor_(size)(state, input, dim);\n+  THArgCheck(k > 0 && k <= sliceSize, 5, \"k not in range for dimension\");\n+\n+  // Build the output size, which is the dim being selected set to\n+  // size 1\n+  THLongStorage* kthValueSize = THCTensor_(newSizeOf)(state, input);\n+  THLongStorage_set(kthValueSize, dim, 1);\n+  THCTensor_(resize)(state, kthValue, kthValueSize, NULL);", "path": "aten/src/THC/generic/THCTensorKthValue.cu", "position": 27, "original_position": 27, "commit_id": "67204dac722d05387ca13d50382378d66e1c3814", "original_commit_id": "b88b13605d7ae48f3b14ef96200143b278cb14ea", "user": {"login": "pararthshah", "id": 1484859, "node_id": "MDQ6VXNlcjE0ODQ4NTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1484859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pararthshah", "html_url": "https://github.com/pararthshah", "followers_url": "https://api.github.com/users/pararthshah/followers", "following_url": "https://api.github.com/users/pararthshah/following{/other_user}", "gists_url": "https://api.github.com/users/pararthshah/gists{/gist_id}", "starred_url": "https://api.github.com/users/pararthshah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pararthshah/subscriptions", "organizations_url": "https://api.github.com/users/pararthshah/orgs", "repos_url": "https://api.github.com/users/pararthshah/repos", "events_url": "https://api.github.com/users/pararthshah/events{/privacy}", "received_events_url": "https://api.github.com/users/pararthshah/received_events", "type": "User", "site_admin": false}, "body": "Would the same issue occur in THCTensorTopK, which does the resize as well? https://github.com/pytorch/pytorch/blob/master/aten/src/THC/generic/THCTensorTopK.cu#L27\r\n\r\nMaybe this should be done in a follow-up PR to fix both implementations.", "created_at": "2018-06-19T16:20:50Z", "updated_at": "2018-11-23T15:45:46Z", "html_url": "https://github.com/pytorch/pytorch/pull/8406#discussion_r196491911", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8406", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/196491911"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8406#discussion_r196491911"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8406"}}, "body_html": "<p>Would the same issue occur in THCTensorTopK, which does the resize as well? <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THC/generic/THCTensorTopK.cu#L27\">https://github.com/pytorch/pytorch/blob/master/aten/src/THC/generic/THCTensorTopK.cu#L27</a></p>\n<p>Maybe this should be done in a follow-up PR to fix both implementations.</p>", "body_text": "Would the same issue occur in THCTensorTopK, which does the resize as well? https://github.com/pytorch/pytorch/blob/master/aten/src/THC/generic/THCTensorTopK.cu#L27\nMaybe this should be done in a follow-up PR to fix both implementations.", "in_reply_to_id": 195761327}