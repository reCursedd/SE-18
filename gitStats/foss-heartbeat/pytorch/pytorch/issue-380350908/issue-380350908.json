{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13909", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13909/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13909/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13909/events", "html_url": "https://github.com/pytorch/pytorch/issues/13909", "id": 380350908, "node_id": "MDU6SXNzdWUzODAzNTA5MDg=", "number": 13909, "title": "FP16 overflow sometimes results in \"illegal memory access\"", "user": {"login": "myleott", "id": 231798, "node_id": "MDQ6VXNlcjIzMTc5OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/231798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/myleott", "html_url": "https://github.com/myleott", "followers_url": "https://api.github.com/users/myleott/followers", "following_url": "https://api.github.com/users/myleott/following{/other_user}", "gists_url": "https://api.github.com/users/myleott/gists{/gist_id}", "starred_url": "https://api.github.com/users/myleott/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/myleott/subscriptions", "organizations_url": "https://api.github.com/users/myleott/orgs", "repos_url": "https://api.github.com/users/myleott/repos", "events_url": "https://api.github.com/users/myleott/events{/privacy}", "received_events_url": "https://api.github.com/users/myleott/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-11-13T17:55:11Z", "updated_at": "2018-11-14T00:52:14Z", "closed_at": "2018-11-14T00:52:14Z", "author_association": "CONTRIBUTOR", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>FP16 overflow sometimes results in \"illegal memory access\". See example below.</p>\n<h2>To Reproduce</h2>\n<p>Steps to reproduce the behavior:</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\n&gt;&gt;&gt; bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\n&gt;&gt;&gt; x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\n&gt;&gt;&gt; loss = x.sum()\n&gt;&gt;&gt; loss\nTHCudaCheck FAIL file=/pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh line=69 error=77 : an illegal memory access was encountered\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/tensor.py\", line 66, in __repr__\n    return torch._tensor_str._str(self)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 275, in _str\n    tensor_str = _tensor_str(self, indent)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 193, in _tensor_str\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 84, in __init__\n    nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) &amp; tensor_view.ne(0))\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/functional.py\", line 271, in isfinite\n    return (tensor == tensor) &amp; (tensor.abs() != inf)\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh:69\n</code></pre>\n<h2>Expected behavior</h2>\n<p>In the past this would result in inf:</p>\n<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\n&gt;&gt;&gt; bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\n&gt;&gt;&gt; x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\n&gt;&gt;&gt; loss = x.sum()\n&gt;&gt;&gt; loss\ntensor(inf, device='cuda:0', dtype=torch.float16, grad_fn=&lt;SumBackward0&gt;)\n</code></pre>\n<h2>Environment</h2>\n<pre><code>PyTorch version: 1.0.0.dev20181112\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.88\nGPU models and configuration:\nGPU 0: Tesla V100-SXM2-32GB\nGPU 1: Tesla V100-SXM2-32GB\nGPU 2: Tesla V100-SXM2-32GB\nGPU 3: Tesla V100-SXM2-32GB\nGPU 4: Tesla V100-SXM2-32GB\nGPU 5: Tesla V100-SXM2-32GB\nGPU 6: Tesla V100-SXM2-32GB\nGPU 7: Tesla V100-SXM2-32GB\n\nNvidia driver version: 396.51\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.15.1)\n[pip] torch-nightly (1.0.0.dev20181112)\n[pip] torchvision-nightly (0.2.1)\n[conda] magma-cuda90              2.3.0                         1    pytorch\n[conda] magma-cuda92              2.3.0                         1    pytorch\n[conda] torch-nightly             1.0.0.dev20181112           &lt;pip&gt;\n[conda] torchvision-nightly       0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "\ud83d\udc1b Bug\nFP16 overflow sometimes results in \"illegal memory access\". See example below.\nTo Reproduce\nSteps to reproduce the behavior:\n>>> import torch\n>>> weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\n>>> bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\n>>> x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\n>>> loss = x.sum()\n>>> loss\nTHCudaCheck FAIL file=/pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh line=69 error=77 : an illegal memory access was encountered\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/tensor.py\", line 66, in __repr__\n    return torch._tensor_str._str(self)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 275, in _str\n    tensor_str = _tensor_str(self, indent)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 193, in _tensor_str\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 84, in __init__\n    nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/functional.py\", line 271, in isfinite\n    return (tensor == tensor) & (tensor.abs() != inf)\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh:69\n\nExpected behavior\nIn the past this would result in inf:\n>>> import torch\n>>> weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\n>>> bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\n>>> x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\n>>> loss = x.sum()\n>>> loss\ntensor(inf, device='cuda:0', dtype=torch.float16, grad_fn=<SumBackward0>)\n\nEnvironment\nPyTorch version: 1.0.0.dev20181112\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\n\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.2\n\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: 9.2.88\nGPU models and configuration:\nGPU 0: Tesla V100-SXM2-32GB\nGPU 1: Tesla V100-SXM2-32GB\nGPU 2: Tesla V100-SXM2-32GB\nGPU 3: Tesla V100-SXM2-32GB\nGPU 4: Tesla V100-SXM2-32GB\nGPU 5: Tesla V100-SXM2-32GB\nGPU 6: Tesla V100-SXM2-32GB\nGPU 7: Tesla V100-SXM2-32GB\n\nNvidia driver version: 396.51\ncuDNN version: Could not collect\n\nVersions of relevant libraries:\n[pip] numpy (1.15.1)\n[pip] torch-nightly (1.0.0.dev20181112)\n[pip] torchvision-nightly (0.2.1)\n[conda] magma-cuda90              2.3.0                         1    pytorch\n[conda] magma-cuda92              2.3.0                         1    pytorch\n[conda] torch-nightly             1.0.0.dev20181112           <pip>\n[conda] torchvision-nightly       0.2.1                     <pip>", "body": "## \ud83d\udc1b Bug\r\n\r\nFP16 overflow sometimes results in \"illegal memory access\". See example below.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n>>> import torch\r\n>>> weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\r\n>>> bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\r\n>>> x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\r\n>>> loss = x.sum()\r\n>>> loss\r\nTHCudaCheck FAIL file=/pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh line=69 error=77 : an illegal memory access was encountered\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/tensor.py\", line 66, in __repr__\r\n    return torch._tensor_str._str(self)\r\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 275, in _str\r\n    tensor_str = _tensor_str(self, indent)\r\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 193, in _tensor_str\r\n    formatter = _Formatter(get_summarized_data(self) if summarize else self)\r\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/_tensor_str.py\", line 84, in __init__\r\n    nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\r\n  File \"/private/home/myleott/.conda/envs/fairseq-fp16-20181030/lib/python3.6/site-packages/torch/functional.py\", line 271, in isfinite\r\n    return (tensor == tensor) & (tensor.abs() != inf)\r\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /pytorch/aten/src/THC/generated/../THCTensorMathCompareT.cuh:69\r\n```\r\n\r\n## Expected behavior\r\n\r\nIn the past this would result in inf:\r\n\r\n```\r\n>>> import torch\r\n>>> weight = torch.nn.Parameter(torch.rand(512*3, 512).cuda()).half()\r\n>>> bias = torch.nn.Parameter(torch.rand(512*3).cuda()).half()\r\n>>> x = torch.nn.functional.linear(torch.rand(32, 512).cuda().half(), weight, bias)\r\n>>> loss = x.sum()\r\n>>> loss\r\ntensor(inf, device='cuda:0', dtype=torch.float16, grad_fn=<SumBackward0>)\r\n```\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.0.0.dev20181112\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.12.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.2.88\r\nGPU models and configuration:\r\nGPU 0: Tesla V100-SXM2-32GB\r\nGPU 1: Tesla V100-SXM2-32GB\r\nGPU 2: Tesla V100-SXM2-32GB\r\nGPU 3: Tesla V100-SXM2-32GB\r\nGPU 4: Tesla V100-SXM2-32GB\r\nGPU 5: Tesla V100-SXM2-32GB\r\nGPU 6: Tesla V100-SXM2-32GB\r\nGPU 7: Tesla V100-SXM2-32GB\r\n\r\nNvidia driver version: 396.51\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.1)\r\n[pip] torch-nightly (1.0.0.dev20181112)\r\n[pip] torchvision-nightly (0.2.1)\r\n[conda] magma-cuda90              2.3.0                         1    pytorch\r\n[conda] magma-cuda92              2.3.0                         1    pytorch\r\n[conda] torch-nightly             1.0.0.dev20181112           <pip>\r\n[conda] torchvision-nightly       0.2.1                     <pip>\r\n```"}