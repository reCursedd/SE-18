{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9102", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9102/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9102/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9102/events", "html_url": "https://github.com/pytorch/pytorch/pull/9102", "id": 337515956, "node_id": "MDExOlB1bGxSZXF1ZXN0MTk4Njc3ODIy", "number": 9102, "title": "Implement batch matrix inverse", "user": {"login": "karol-arndt", "id": 15629271, "node_id": "MDQ6VXNlcjE1NjI5Mjcx", "avatar_url": "https://avatars2.githubusercontent.com/u/15629271?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karol-arndt", "html_url": "https://github.com/karol-arndt", "followers_url": "https://api.github.com/users/karol-arndt/followers", "following_url": "https://api.github.com/users/karol-arndt/following{/other_user}", "gists_url": "https://api.github.com/users/karol-arndt/gists{/gist_id}", "starred_url": "https://api.github.com/users/karol-arndt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karol-arndt/subscriptions", "organizations_url": "https://api.github.com/users/karol-arndt/orgs", "repos_url": "https://api.github.com/users/karol-arndt/repos", "events_url": "https://api.github.com/users/karol-arndt/events{/privacy}", "received_events_url": "https://api.github.com/users/karol-arndt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2018-07-02T13:21:03Z", "updated_at": "2018-11-23T15:46:58Z", "closed_at": "2018-10-28T17:42:19Z", "author_association": "NONE", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9102", "html_url": "https://github.com/pytorch/pytorch/pull/9102", "diff_url": "https://github.com/pytorch/pytorch/pull/9102.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9102.patch"}, "body_html": "<p>I was recently working on some Kalman filter stuff and found myself in need of a batch matrix inverse, so I implemented it (doing it in a Python for loop is incredibly slow, especially with CUDA). Since cuBLAS has such functionality already implemented (and the standard inverse function just passes 1 as the batch size), it's just a matter of allocating some buffers and passing data to the appropriate cuBLAS functions. The implementation is based on the <code>btrifact</code> (batch LU factorization using <code>getrf</code>) function. I also added a CPU implementation (which is really just a for loop) for the sake of completeness.</p>\n<p>I figured that this might be useful for other people, so I'm sharing it here. This is my first contribution to PyTorch and I'm not very experienced with CUDA programming, so all comments regarding the code are most welcome.</p>", "body_text": "I was recently working on some Kalman filter stuff and found myself in need of a batch matrix inverse, so I implemented it (doing it in a Python for loop is incredibly slow, especially with CUDA). Since cuBLAS has such functionality already implemented (and the standard inverse function just passes 1 as the batch size), it's just a matter of allocating some buffers and passing data to the appropriate cuBLAS functions. The implementation is based on the btrifact (batch LU factorization using getrf) function. I also added a CPU implementation (which is really just a for loop) for the sake of completeness.\nI figured that this might be useful for other people, so I'm sharing it here. This is my first contribution to PyTorch and I'm not very experienced with CUDA programming, so all comments regarding the code are most welcome.", "body": "I was recently working on some Kalman filter stuff and found myself in need of a batch matrix inverse, so I implemented it (doing it in a Python for loop is incredibly slow, especially with CUDA). Since cuBLAS has such functionality already implemented (and the standard inverse function just passes 1 as the batch size), it's just a matter of allocating some buffers and passing data to the appropriate cuBLAS functions. The implementation is based on the `btrifact` (batch LU factorization using `getrf`) function. I also added a CPU implementation (which is really just a for loop) for the sake of completeness. \r\n\r\nI figured that this might be useful for other people, so I'm sharing it here. This is my first contribution to PyTorch and I'm not very experienced with CUDA programming, so all comments regarding the code are most welcome."}