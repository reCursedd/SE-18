{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/404950023", "html_url": "https://github.com/pytorch/pytorch/issues/6124#issuecomment-404950023", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6124", "id": 404950023, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDk1MDAyMw==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-13T20:48:51Z", "updated_at": "2018-07-13T20:51:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1482399\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/isseu\">@isseu</a> has kindly agreed to take this on. Here are some notes on how to implement:</p>\n<ol>\n<li>We have a simple implementation of convolution by using im2col/vol2col to convert matrices into a Toeplitz matrix (colloquially called the \"column\" matrix in the code), and then doing a matrix multiplication to carry out the convolution. (If you don't see how this works, spend a little time with the matrices until you convince yourself it works :)</li>\n<li>The CPU implementation of im2col lives at <code>aten/src/THNN/generic/Col2Im.c</code>. Adjust it to optionally generate a <em>circular</em> Toeplitz matrix. For testing, you may find it easier to first make the function unconditionally generate a circular Toeplitz matrix, and ensure that all convolutions are circular, before carrying on. (Be aware that you need to make sure the THNN kernel is actually being called; there is logic to select which convolution kernel we use, and it does not always select THNN.)</li>\n<li>Thread your change to the call sites of im2col, which actually perform the convolution. After you fix the function sites, you'll need to modify <code>aten/src/ATen/nn.yaml</code> to adjust our code generation to handle the new signature. You might find it easiest to create a new function which performs circular convolution, and call into some generic function that takes the circular convolution as a flag.</li>\n<li>Adjust <code>_convolution</code> (defined in <code>aten/src/ATen/native/native_functions.yaml</code>) to take a flag trigger circular padding, and adjust the kernel selection logic to prefer THNN implementation when circular padding is requested.</li>\n<li>Adjust the backwards formula for convolution, so that it works in the circular padding case. (This should not be too difficult.)</li>\n<li>Write tests for it</li>\n<li>Do this again for the CUDA implementation</li>\n</ol>", "body_text": "@isseu has kindly agreed to take this on. Here are some notes on how to implement:\n\nWe have a simple implementation of convolution by using im2col/vol2col to convert matrices into a Toeplitz matrix (colloquially called the \"column\" matrix in the code), and then doing a matrix multiplication to carry out the convolution. (If you don't see how this works, spend a little time with the matrices until you convince yourself it works :)\nThe CPU implementation of im2col lives at aten/src/THNN/generic/Col2Im.c. Adjust it to optionally generate a circular Toeplitz matrix. For testing, you may find it easier to first make the function unconditionally generate a circular Toeplitz matrix, and ensure that all convolutions are circular, before carrying on. (Be aware that you need to make sure the THNN kernel is actually being called; there is logic to select which convolution kernel we use, and it does not always select THNN.)\nThread your change to the call sites of im2col, which actually perform the convolution. After you fix the function sites, you'll need to modify aten/src/ATen/nn.yaml to adjust our code generation to handle the new signature. You might find it easiest to create a new function which performs circular convolution, and call into some generic function that takes the circular convolution as a flag.\nAdjust _convolution (defined in aten/src/ATen/native/native_functions.yaml) to take a flag trigger circular padding, and adjust the kernel selection logic to prefer THNN implementation when circular padding is requested.\nAdjust the backwards formula for convolution, so that it works in the circular padding case. (This should not be too difficult.)\nWrite tests for it\nDo this again for the CUDA implementation", "body": "@isseu has kindly agreed to take this on. Here are some notes on how to implement:\r\n\r\n1. We have a simple implementation of convolution by using im2col/vol2col to convert matrices into a Toeplitz matrix (colloquially called the \"column\" matrix in the code), and then doing a matrix multiplication to carry out the convolution. (If you don't see how this works, spend a little time with the matrices until you convince yourself it works :)\r\n2. The CPU implementation of im2col lives at `aten/src/THNN/generic/Col2Im.c`. Adjust it to optionally generate a *circular* Toeplitz matrix. For testing, you may find it easier to first make the function unconditionally generate a circular Toeplitz matrix, and ensure that all convolutions are circular, before carrying on. (Be aware that you need to make sure the THNN kernel is actually being called; there is logic to select which convolution kernel we use, and it does not always select THNN.)\r\n3. Thread your change to the call sites of im2col, which actually perform the convolution. After you fix the function sites, you'll need to modify `aten/src/ATen/nn.yaml` to adjust our code generation to handle the new signature. You might find it easiest to create a new function which performs circular convolution, and call into some generic function that takes the circular convolution as a flag.\r\n4. Adjust `_convolution` (defined in `aten/src/ATen/native/native_functions.yaml`) to take a flag trigger circular padding, and adjust the kernel selection logic to prefer THNN implementation when circular padding is requested.\r\n5. Adjust the backwards formula for convolution, so that it works in the circular padding case. (This should not be too difficult.)\r\n5. Write tests for it\r\n6. Do this again for the CUDA implementation"}