{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216043346", "pull_request_review_id": 153448361, "id": 216043346, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNjA0MzM0Ng==", "diff_hunk": "@@ -595,22 +659,82 @@ std::shared_ptr<ProcessGroup::Work> ProcessGroupGloo::scatter(\n   throw std::runtime_error(\"ProcessGroupGloo does not support scatter\");\n }\n \n+at::Tensor& checkSingleTensor(std::vector<at::Tensor>& tensors) {\n+  if (tensors.size() != 1) {\n+    throw std::runtime_error(\"ProcessGroupGloo::send takes a single tensor\");\n+  }\n+  auto& tensor = tensors[0];\n+  if (!tensor.is_contiguous()) {\n+    throw std::runtime_error(\"input tensor has to be contiguous\");\n+  }\n+  if (tensor.is_sparse()) {\n+    throw std::runtime_error(\"input tensor has to be dense\");\n+  }\n+  return tensor;\n+}\n+\n std::shared_ptr<ProcessGroup::Work> ProcessGroupGloo::send(\n-    std::vector<at::Tensor>& /* unused */,\n-    int /* unused */) {\n-  throw std::runtime_error(\"ProcessGroupGloo does not support send\");\n+    std::vector<at::Tensor>& tensors,\n+    int dstRank) {\n+  auto& tensor = checkSingleTensor(tensors);\n+  auto ptr = tensor.data_ptr();\n+  auto size = tensor.numel() * tensor.type().elementSizeInBytes();\n+\n+  // Construct unbound buffer.\n+  auto& context = contexts_[0];\n+  auto buf = context->createUnboundBuffer(ptr, size);\n+  buf->send(dstRank, 0);\n+\n+  // The work captures the tensor to prevent it being deallocated and\n+  // the unbound buffer to synchronize on completion of the send.\n+  return std::shared_ptr<ProcessGroup::Work>(\n+      new SendWork(tensor, std::move(buf)));\n }\n \n std::shared_ptr<ProcessGroup::Work> ProcessGroupGloo::recv(\n-    std::vector<at::Tensor>& /* unused */,\n-    int /* unused */) {\n-  throw std::runtime_error(\"ProcessGroupGloo does not support recv\");\n+    std::vector<at::Tensor>& tensors,\n+    int srcRank) {\n+  auto& tensor = checkSingleTensor(tensors);\n+  auto ptr = tensor.data_ptr();\n+  auto size = tensor.numel() * tensor.type().elementSizeInBytes();\n+\n+  // Construct unbound buffer.\n+  auto& context = contexts_[0];\n+  auto buf = context->createUnboundBuffer(ptr, size);\n+  buf->recv(srcRank, 0);\n+\n+  // The work captures the tensor to prevent it being deallocated and\n+  // the unbound buffer to synchronize on completion of the recv.\n+  return std::shared_ptr<ProcessGroup::Work>(\n+      new RecvWork(tensor, std::move(buf), nullptr));\n }\n \n std::shared_ptr<ProcessGroup::Work> ProcessGroupGloo::recvAnysource(\n-    std::vector<at::Tensor>& /* unused */,\n-    int* /* unused */) {\n-  throw std::runtime_error(\"ProcessGroupGloo does not support recv\");\n+    std::vector<at::Tensor>& tensors,\n+    int* srcRank) {\n+  auto& tensor = checkSingleTensor(tensors);\n+  auto ptr = tensor.data_ptr();\n+  auto size = tensor.numel() * tensor.type().elementSizeInBytes();\n+\n+  // Construct unbound buffer.\n+  auto& context = contexts_[0];\n+  auto buf = context->createUnboundBuffer(ptr, size);\n+\n+  // Build list of ranks that this operation can recv from. In these\n+  // bindings we don't differentiate between ranks and can receive\n+  // from any other process in the group.\n+  std::vector<int> srcRanks;\n+  srcRanks.resize(size_);\n+  for (auto i = 0; i < size_; i++) {\n+    srcRanks.push_back(i);\n+  }\n+\n+  buf->recv(srcRanks, 0);\n+\n+  // The work captures the tensor to prevent it being deallocated and\n+  // the unbound buffer to synchronize on completion of the recv.\n+  return std::shared_ptr<ProcessGroup::Work>(\n+      new RecvWork(tensor, std::move(buf), srcRank));", "path": "torch/lib/c10d/ProcessGroupGloo.cpp", "position": null, "original_position": 159, "commit_id": "1c1b782ef25fc4bd446f7cea3033c88e1c4c8ba7", "original_commit_id": "203a237d6f237ab7ef7cd457ec5f7da83ba0ac27", "user": {"login": "teng-li", "id": 8120856, "node_id": "MDQ6VXNlcjgxMjA4NTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8120856?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teng-li", "html_url": "https://github.com/teng-li", "followers_url": "https://api.github.com/users/teng-li/followers", "following_url": "https://api.github.com/users/teng-li/following{/other_user}", "gists_url": "https://api.github.com/users/teng-li/gists{/gist_id}", "starred_url": "https://api.github.com/users/teng-li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teng-li/subscriptions", "organizations_url": "https://api.github.com/users/teng-li/orgs", "repos_url": "https://api.github.com/users/teng-li/repos", "events_url": "https://api.github.com/users/teng-li/events{/privacy}", "received_events_url": "https://api.github.com/users/teng-li/received_events", "type": "User", "site_admin": false}, "body": "make_shared", "created_at": "2018-09-07T18:08:23Z", "updated_at": "2018-11-23T15:50:47Z", "html_url": "https://github.com/pytorch/pytorch/pull/11387#discussion_r216043346", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11387", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216043346"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11387#discussion_r216043346"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11387"}}, "body_html": "<p>make_shared</p>", "body_text": "make_shared"}