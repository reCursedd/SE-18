{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4279", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4279/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4279/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4279/events", "html_url": "https://github.com/pytorch/pytorch/issues/4279", "id": 283650019, "node_id": "MDU6SXNzdWUyODM2NTAwMTk=", "number": 4279, "title": "Rationalize functions signature specification in native_functions.yaml and derivatives.yaml", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-12-20T18:08:18Z", "updated_at": "2017-12-20T18:08:18Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"283378695\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4259\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4259/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4259\">#4259</a> for a specific case: because gen_variable_type relies on dynamic_types from Declarations.cwrap in order to generate variable unpacking code, we need the <code>condition</code> of <code>torch.where</code> to end up as a <code>BoolTensor</code> in Declarations.yaml, so we type it as a <code>BoolTensor</code>.  But <code>gen_variable_type</code> does matching on <code>type</code> and not <code>dynamic_type</code>, so in derivatives.yaml you have to specify the type as a <code>Tensor</code>, which doesn't match.</p>\n<p>There are a few different ways we could solve this (and they aren't all orthogonal):</p>\n<ol>\n<li>Merge native_functions.yaml and derivatives.yaml so you only need to specify the function signature once.</li>\n<li>Have gen_variable_type look at the dynamic_type instead of type.</li>\n<li>Avoid doing specific-type unpacking.  Right now we do it to avoid a Variable dynamic_cast, but if we had some other way of telling a Variable (i.e. an open-ended typeid or bitmask with unreserved bits) we could do the unwrapping efficiently and drop the type checks.</li>\n</ol>", "body_text": "See #4259 for a specific case: because gen_variable_type relies on dynamic_types from Declarations.cwrap in order to generate variable unpacking code, we need the condition of torch.where to end up as a BoolTensor in Declarations.yaml, so we type it as a BoolTensor.  But gen_variable_type does matching on type and not dynamic_type, so in derivatives.yaml you have to specify the type as a Tensor, which doesn't match.\nThere are a few different ways we could solve this (and they aren't all orthogonal):\n\nMerge native_functions.yaml and derivatives.yaml so you only need to specify the function signature once.\nHave gen_variable_type look at the dynamic_type instead of type.\nAvoid doing specific-type unpacking.  Right now we do it to avoid a Variable dynamic_cast, but if we had some other way of telling a Variable (i.e. an open-ended typeid or bitmask with unreserved bits) we could do the unwrapping efficiently and drop the type checks.", "body": "See https://github.com/pytorch/pytorch/pull/4259 for a specific case: because gen_variable_type relies on dynamic_types from Declarations.cwrap in order to generate variable unpacking code, we need the `condition` of `torch.where` to end up as a `BoolTensor` in Declarations.yaml, so we type it as a `BoolTensor`.  But `gen_variable_type` does matching on `type` and not `dynamic_type`, so in derivatives.yaml you have to specify the type as a `Tensor`, which doesn't match.\r\n\r\nThere are a few different ways we could solve this (and they aren't all orthogonal):\r\n1) Merge native_functions.yaml and derivatives.yaml so you only need to specify the function signature once.\r\n2) Have gen_variable_type look at the dynamic_type instead of type.\r\n3) Avoid doing specific-type unpacking.  Right now we do it to avoid a Variable dynamic_cast, but if we had some other way of telling a Variable (i.e. an open-ended typeid or bitmask with unreserved bits) we could do the unwrapping efficiently and drop the type checks."}