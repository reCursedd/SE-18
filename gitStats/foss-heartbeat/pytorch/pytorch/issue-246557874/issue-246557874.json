{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2245", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2245/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2245/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2245/events", "html_url": "https://github.com/pytorch/pytorch/issues/2245", "id": 246557874, "node_id": "MDU6SXNzdWUyNDY1NTc4NzQ=", "number": 2245, "title": "Fork start method is susceptible to deadlocks", "user": {"login": "Louis-Tian", "id": 5655024, "node_id": "MDQ6VXNlcjU2NTUwMjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5655024?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Louis-Tian", "html_url": "https://github.com/Louis-Tian", "followers_url": "https://api.github.com/users/Louis-Tian/followers", "following_url": "https://api.github.com/users/Louis-Tian/following{/other_user}", "gists_url": "https://api.github.com/users/Louis-Tian/gists{/gist_id}", "starred_url": "https://api.github.com/users/Louis-Tian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Louis-Tian/subscriptions", "organizations_url": "https://api.github.com/users/Louis-Tian/orgs", "repos_url": "https://api.github.com/users/Louis-Tian/repos", "events_url": "https://api.github.com/users/Louis-Tian/events{/privacy}", "received_events_url": "https://api.github.com/users/Louis-Tian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-07-30T02:29:12Z", "updated_at": "2017-07-30T03:19:02Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Versions</h2>\n<pre><code>Ubuntu 16.04\nPython 3.6.2 \npytorch 0.1.12_2\n</code></pre>\n<h2>Issue description</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.multiprocessing <span class=\"pl-k\">as</span> mp\n<span class=\"pl-k\">import</span> torch.functional <span class=\"pl-k\">as</span> f\n<span class=\"pl-k\">import</span> threading\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> timeit <span class=\"pl-k\">import</span> timeit\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">build</span>(<span class=\"pl-smi\">cuda</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    nn <span class=\"pl-k\">=</span> torch.nn.Sequential(\n        torch.nn.Linear(<span class=\"pl-c1\">1024</span>, <span class=\"pl-c1\">1024</span>),\n        torch.nn.Linear(<span class=\"pl-c1\">1024</span>, <span class=\"pl-c1\">1</span>)\n    )\n\n    <span class=\"pl-k\">return</span> nn.cuda() <span class=\"pl-k\">if</span> cuda <span class=\"pl-k\">else</span> nn\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>(<span class=\"pl-smi\">nn</span>, <span class=\"pl-smi\">X</span>, <span class=\"pl-smi\">y</span>, <span class=\"pl-smi\">epoch</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>):\n    X <span class=\"pl-k\">=</span> torch.autograd.Variable(X)\n    y <span class=\"pl-k\">=</span> torch.autograd.Variable(y)\n    optim <span class=\"pl-k\">=</span> torch.optim.SGD(nn.parameters(), <span class=\"pl-v\">lr</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>)\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(epoch):\n        yhat <span class=\"pl-k\">=</span> nn(X)\n        loss <span class=\"pl-k\">=</span> ((yhat <span class=\"pl-k\">-</span> y) <span class=\"pl-k\">**</span> <span class=\"pl-c1\">2</span>).mean()\n        loss.backward()\n        optim.step()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">data</span>(<span class=\"pl-smi\">cuda</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>):\n    X <span class=\"pl-k\">=</span> torch.Tensor(np.random.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1024</span>))\n    y <span class=\"pl-k\">=</span> torch.Tensor(np.random.randn(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1</span>))\n    <span class=\"pl-k\">return</span> (X.cuda(), y.cuda()) <span class=\"pl-k\">if</span> cuda <span class=\"pl-k\">else</span> (X, y)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">cpu_run</span>(<span class=\"pl-smi\">i</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    nn <span class=\"pl-k\">=</span> build(<span class=\"pl-v\">cuda</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    d <span class=\"pl-k\">=</span> data(<span class=\"pl-v\">cuda</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    train(nn, <span class=\"pl-k\">*</span>d)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">seq_cpu_run</span>():\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>):\n        cpu_run()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">multiprocess_cpu_run</span>():\n    pool <span class=\"pl-k\">=</span> torch.multiprocessing.Pool(<span class=\"pl-v\">processes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n    result <span class=\"pl-k\">=</span> pool.map(cpu_run, [() <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>)])\n    pool.close()\n    pool.join()\n    <span class=\"pl-k\">return</span> result\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    <span class=\"pl-c1\">print</span>(timeit(seq_cpu_run, <span class=\"pl-v\">number</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)) <span class=\"pl-c\"><span class=\"pl-c\">#</span> 1</span>\n    <span class=\"pl-c1\">print</span>(timeit(multiprocess_cpu_run, <span class=\"pl-v\">number</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 2</span></pre></div>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> run okay alone.<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a> run okay alone.<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a> then <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> runs okay.<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> then <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a> never terminate.</p>\n<p>where<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> = seq_cpu_run, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a> = multiprocess_cpu_run</p>", "body_text": "Versions\nUbuntu 16.04\nPython 3.6.2 \npytorch 0.1.12_2\n\nIssue description\nimport torch\nimport torch.multiprocessing as mp\nimport torch.functional as f\nimport threading\nimport numpy as np\nfrom timeit import timeit\n\ndef build(cuda=False):\n    nn = torch.nn.Sequential(\n        torch.nn.Linear(1024, 1024),\n        torch.nn.Linear(1024, 1)\n    )\n\n    return nn.cuda() if cuda else nn\n\ndef train(nn, X, y, epoch=100):\n    X = torch.autograd.Variable(X)\n    y = torch.autograd.Variable(y)\n    optim = torch.optim.SGD(nn.parameters(), lr=0.1)\n    for i in range(epoch):\n        yhat = nn(X)\n        loss = ((yhat - y) ** 2).mean()\n        loss.backward()\n        optim.step()\n\ndef data(cuda=False):\n    X = torch.Tensor(np.random.randn(10, 1024))\n    y = torch.Tensor(np.random.randn(10, 1))\n    return (X.cuda(), y.cuda()) if cuda else (X, y)\n\ndef cpu_run(i=None):\n    nn = build(cuda=False)\n    d = data(cuda=False)\n    train(nn, *d)\n\ndef seq_cpu_run():\n    for i in range(5):\n        cpu_run()\n\ndef multiprocess_cpu_run():\n    pool = torch.multiprocessing.Pool(processes=1)\n    result = pool.map(cpu_run, [() for i in range(1)])\n    pool.close()\n    pool.join()\n    return result\n\nif __name__ == \"__main__\":\n    print(timeit(seq_cpu_run, number=1)) # 1\n    print(timeit(multiprocess_cpu_run, number=1))  # 2\n#1 run okay alone.\n#2 run okay alone.\n#2 then #1 runs okay.\n#1 then #2 never terminate.\nwhere\n#1 = seq_cpu_run, #2 = multiprocess_cpu_run", "body": "## Versions\r\n```\r\nUbuntu 16.04\r\nPython 3.6.2 \r\npytorch 0.1.12_2\r\n```\r\n## Issue description\r\n\r\n```python\r\nimport torch\r\nimport torch.multiprocessing as mp\r\nimport torch.functional as f\r\nimport threading\r\nimport numpy as np\r\nfrom timeit import timeit\r\n\r\ndef build(cuda=False):\r\n    nn = torch.nn.Sequential(\r\n        torch.nn.Linear(1024, 1024),\r\n        torch.nn.Linear(1024, 1)\r\n    )\r\n\r\n    return nn.cuda() if cuda else nn\r\n\r\ndef train(nn, X, y, epoch=100):\r\n    X = torch.autograd.Variable(X)\r\n    y = torch.autograd.Variable(y)\r\n    optim = torch.optim.SGD(nn.parameters(), lr=0.1)\r\n    for i in range(epoch):\r\n        yhat = nn(X)\r\n        loss = ((yhat - y) ** 2).mean()\r\n        loss.backward()\r\n        optim.step()\r\n\r\ndef data(cuda=False):\r\n    X = torch.Tensor(np.random.randn(10, 1024))\r\n    y = torch.Tensor(np.random.randn(10, 1))\r\n    return (X.cuda(), y.cuda()) if cuda else (X, y)\r\n\r\ndef cpu_run(i=None):\r\n    nn = build(cuda=False)\r\n    d = data(cuda=False)\r\n    train(nn, *d)\r\n\r\ndef seq_cpu_run():\r\n    for i in range(5):\r\n        cpu_run()\r\n\r\ndef multiprocess_cpu_run():\r\n    pool = torch.multiprocessing.Pool(processes=1)\r\n    result = pool.map(cpu_run, [() for i in range(1)])\r\n    pool.close()\r\n    pool.join()\r\n    return result\r\n\r\nif __name__ == \"__main__\":\r\n    print(timeit(seq_cpu_run, number=1)) # 1\r\n    print(timeit(multiprocess_cpu_run, number=1))  # 2\r\n``` \r\n\r\n#1 run okay alone.\r\n#2 run okay alone.\r\n#2 then #1 runs okay.\r\n#1 then #2 never terminate.\r\n\r\nwhere\r\n#1 = seq_cpu_run, #2 = multiprocess_cpu_run\r\n"}