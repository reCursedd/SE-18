{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/360168707", "html_url": "https://github.com/pytorch/pytorch/issues/3587#issuecomment-360168707", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3587", "id": 360168707, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDE2ODcwNw==", "user": {"login": "sidharthms", "id": 7098085, "node_id": "MDQ6VXNlcjcwOTgwODU=", "avatar_url": "https://avatars3.githubusercontent.com/u/7098085?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sidharthms", "html_url": "https://github.com/sidharthms", "followers_url": "https://api.github.com/users/sidharthms/followers", "following_url": "https://api.github.com/users/sidharthms/following{/other_user}", "gists_url": "https://api.github.com/users/sidharthms/gists{/gist_id}", "starred_url": "https://api.github.com/users/sidharthms/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sidharthms/subscriptions", "organizations_url": "https://api.github.com/users/sidharthms/orgs", "repos_url": "https://api.github.com/users/sidharthms/repos", "events_url": "https://api.github.com/users/sidharthms/events{/privacy}", "received_events_url": "https://api.github.com/users/sidharthms/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-24T15:21:42Z", "updated_at": "2018-01-24T15:27:06Z", "author_association": "NONE", "body_html": "<p>Is it really true that \"<code>h_n</code> should be the concatenation of the hidden state of the forward layer for the last item of the sequence and of the hidden state of the backward layer for the first item of the sequence\"? There's an issue in cudnn for torch (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"218769096\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/soumith/cudnn.torch/issues/357\" data-hovercard-type=\"issue\" data-hovercard-url=\"/soumith/cudnn.torch/issues/357/hovercard\" href=\"https://github.com/soumith/cudnn.torch/issues/357\">soumith/cudnn.torch#357</a>) that says otherwise. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> mentioned there that for an example sequence [x_1, x_2, x_3, x_4, x_5], the output sequence would be:</p>\n<pre><code>[F(x_1), B(x_1)]\n[F(x_2), B(x_2)]\n[F(x_3), B(x_3)]\n[F(x_4), B(x_4)]\n[F(x_5), B(x_5)]\n</code></pre>\n<p>The RNN code calling cuDNN in <a href=\"https://github.com/soumith/cudnn.torch/blob/master/RNN.lua\">torch</a> and <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/backends/cudnn/rnn.py\">pytorch</a> do not seem to perform any reversing of the output of <code>cudnnRNNForwardTraining</code> call so its weird that the order would be different in pytorch and torch.</p>", "body_text": "Is it really true that \"h_n should be the concatenation of the hidden state of the forward layer for the last item of the sequence and of the hidden state of the backward layer for the first item of the sequence\"? There's an issue in cudnn for torch (soumith/cudnn.torch#357) that says otherwise. @ngimel mentioned there that for an example sequence [x_1, x_2, x_3, x_4, x_5], the output sequence would be:\n[F(x_1), B(x_1)]\n[F(x_2), B(x_2)]\n[F(x_3), B(x_3)]\n[F(x_4), B(x_4)]\n[F(x_5), B(x_5)]\n\nThe RNN code calling cuDNN in torch and pytorch do not seem to perform any reversing of the output of cudnnRNNForwardTraining call so its weird that the order would be different in pytorch and torch.", "body": "Is it really true that \"`h_n` should be the concatenation of the hidden state of the forward layer for the last item of the sequence and of the hidden state of the backward layer for the first item of the sequence\"? There's an issue in cudnn for torch (soumith/cudnn.torch#357) that says otherwise. @ngimel mentioned there that for an example sequence [x_1, x_2, x_3, x_4, x_5], the output sequence would be:\r\n\r\n```\r\n[F(x_1), B(x_1)]\r\n[F(x_2), B(x_2)]\r\n[F(x_3), B(x_3)]\r\n[F(x_4), B(x_4)]\r\n[F(x_5), B(x_5)]\r\n```\r\n\r\nThe RNN code calling cuDNN in [torch](https://github.com/soumith/cudnn.torch/blob/master/RNN.lua) and [pytorch](https://github.com/pytorch/pytorch/blob/master/torch/backends/cudnn/rnn.py) do not seem to perform any reversing of the output of `cudnnRNNForwardTraining` call so its weird that the order would be different in pytorch and torch."}