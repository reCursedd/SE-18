{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7882", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7882/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7882/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7882/events", "html_url": "https://github.com/pytorch/pytorch/issues/7882", "id": 326796108, "node_id": "MDU6SXNzdWUzMjY3OTYxMDg=", "number": 7882, "title": "[Pytorch] DataLoader and python random module", "user": {"login": "thuyen", "id": 4015328, "node_id": "MDQ6VXNlcjQwMTUzMjg=", "avatar_url": "https://avatars1.githubusercontent.com/u/4015328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuyen", "html_url": "https://github.com/thuyen", "followers_url": "https://api.github.com/users/thuyen/followers", "following_url": "https://api.github.com/users/thuyen/following{/other_user}", "gists_url": "https://api.github.com/users/thuyen/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuyen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuyen/subscriptions", "organizations_url": "https://api.github.com/users/thuyen/orgs", "repos_url": "https://api.github.com/users/thuyen/repos", "events_url": "https://api.github.com/users/thuyen/events{/privacy}", "received_events_url": "https://api.github.com/users/thuyen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-27T07:57:41Z", "updated_at": "2018-05-27T21:19:45Z", "closed_at": "2018-05-27T19:49:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Even with seeding, the following script print different ouputs for <code>random.uniform</code> at the different runs. <code>random</code> module is even reseeded <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L86\">here</a>.<br>\nOutputs for <code>torch.rand</code> are the same though.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> random\n\n<span class=\"pl-k\">from</span> torch.utils.data <span class=\"pl-k\">import</span> Dataset, DataLoader\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Data</span>(<span class=\"pl-e\">Dataset</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__len__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">10000</span>\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__getitem__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">index</span>):\n        <span class=\"pl-c1\">print</span>(index, torch.rand(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>).sum().item(), random.uniform(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">1</span>))\n        <span class=\"pl-k\">return</span> <span class=\"pl-c1\">1</span>\n\nseed <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2018</span>\nrandom.seed(seed)\ntorch.manual_seed(seed)\nloader <span class=\"pl-k\">=</span> DataLoader(Data(), <span class=\"pl-v\">num_workers</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>, <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n<span class=\"pl-k\">for</span> x <span class=\"pl-k\">in</span> loader:\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>-<span class=\"pl-pds\">'</span></span><span class=\"pl-k\">*</span><span class=\"pl-c1\">10</span>)\n    <span class=\"pl-k\">break</span></pre></div>\n<p>First run</p>\n<pre><code>4717 2.202341079711914 0.9952153654478976\n4607 2.3166141510009766 0.6813692345925851\n4194 1.9806793928146362 0.6281118075687344\n2595 2.95841383934021 0.8414756141240453\n4691 0.9809015393257141 0.7622458327788627\n9868 2.521920680999756 0.5253262288522356\n7367 2.333574056625366 0.35079311205192487\n9490 3.02830171585083 0.16235006783937567\n----------\n6759 3.1252167224884033 0.4424384676992986\n</code></pre>\n<p>Next run</p>\n<pre><code>4607 2.3166141510009766 0.15198273935290807\n4194 1.9806793928146362 0.36414129463658884\n4691 0.9809015393257141 0.027569260048619926\n4717 2.202341079711914 0.5512619092026773\n7367 2.333574056625366 0.7932627754589792\n9490 3.02830171585083 0.19395324967791994\n9868 2.521920680999756 0.5497794735158222\n2595 2.95841383934021 0.782779934368899\n----------\n6759 3.1252167224884033 0.7098308465010348\n</code></pre>\n<ul>\n<li>Ubuntu 16.04</li>\n<li>Python 3.6</li>\n<li>PyTorch version: 0.4</li>\n</ul>", "body_text": "Even with seeding, the following script print different ouputs for random.uniform at the different runs. random module is even reseeded here.\nOutputs for torch.rand are the same though.\nimport torch\nimport random\n\nfrom torch.utils.data import Dataset, DataLoader\n\nclass Data(Dataset):\n    def __len__(self):\n        return 10000\n    def __getitem__(self, index):\n        print(index, torch.rand(2, 2).sum().item(), random.uniform(0, 1))\n        return 1\n\nseed = 2018\nrandom.seed(seed)\ntorch.manual_seed(seed)\nloader = DataLoader(Data(), num_workers=4, shuffle=True)\n\nfor x in loader:\n    print('-'*10)\n    break\nFirst run\n4717 2.202341079711914 0.9952153654478976\n4607 2.3166141510009766 0.6813692345925851\n4194 1.9806793928146362 0.6281118075687344\n2595 2.95841383934021 0.8414756141240453\n4691 0.9809015393257141 0.7622458327788627\n9868 2.521920680999756 0.5253262288522356\n7367 2.333574056625366 0.35079311205192487\n9490 3.02830171585083 0.16235006783937567\n----------\n6759 3.1252167224884033 0.4424384676992986\n\nNext run\n4607 2.3166141510009766 0.15198273935290807\n4194 1.9806793928146362 0.36414129463658884\n4691 0.9809015393257141 0.027569260048619926\n4717 2.202341079711914 0.5512619092026773\n7367 2.333574056625366 0.7932627754589792\n9490 3.02830171585083 0.19395324967791994\n9868 2.521920680999756 0.5497794735158222\n2595 2.95841383934021 0.782779934368899\n----------\n6759 3.1252167224884033 0.7098308465010348\n\n\nUbuntu 16.04\nPython 3.6\nPyTorch version: 0.4", "body": "Even with seeding, the following script print different ouputs for `random.uniform` at the different runs. `random` module is even reseeded [here](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L86).\r\nOutputs for `torch.rand` are the same though.\r\n```python\r\nimport torch\r\nimport random\r\n\r\nfrom torch.utils.data import Dataset, DataLoader\r\n\r\nclass Data(Dataset):\r\n    def __len__(self):\r\n        return 10000\r\n    def __getitem__(self, index):\r\n        print(index, torch.rand(2, 2).sum().item(), random.uniform(0, 1))\r\n        return 1\r\n\r\nseed = 2018\r\nrandom.seed(seed)\r\ntorch.manual_seed(seed)\r\nloader = DataLoader(Data(), num_workers=4, shuffle=True)\r\n\r\nfor x in loader:\r\n    print('-'*10)\r\n    break\r\n```\r\nFirst run\r\n```\r\n4717 2.202341079711914 0.9952153654478976\r\n4607 2.3166141510009766 0.6813692345925851\r\n4194 1.9806793928146362 0.6281118075687344\r\n2595 2.95841383934021 0.8414756141240453\r\n4691 0.9809015393257141 0.7622458327788627\r\n9868 2.521920680999756 0.5253262288522356\r\n7367 2.333574056625366 0.35079311205192487\r\n9490 3.02830171585083 0.16235006783937567\r\n----------\r\n6759 3.1252167224884033 0.4424384676992986\r\n```\r\nNext run\r\n```\r\n4607 2.3166141510009766 0.15198273935290807\r\n4194 1.9806793928146362 0.36414129463658884\r\n4691 0.9809015393257141 0.027569260048619926\r\n4717 2.202341079711914 0.5512619092026773\r\n7367 2.333574056625366 0.7932627754589792\r\n9490 3.02830171585083 0.19395324967791994\r\n9868 2.521920680999756 0.5497794735158222\r\n2595 2.95841383934021 0.782779934368899\r\n----------\r\n6759 3.1252167224884033 0.7098308465010348\r\n```\r\n- Ubuntu 16.04\r\n- Python 3.6\r\n- PyTorch version: 0.4\r\n\r\n"}