{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/385304164", "html_url": "https://github.com/pytorch/pytorch/issues/7083#issuecomment-385304164", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7083", "id": 385304164, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTMwNDE2NA==", "user": {"login": "meder411", "id": 6818607, "node_id": "MDQ6VXNlcjY4MTg2MDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6818607?v=4", "gravatar_id": "", "url": "https://api.github.com/users/meder411", "html_url": "https://github.com/meder411", "followers_url": "https://api.github.com/users/meder411/followers", "following_url": "https://api.github.com/users/meder411/following{/other_user}", "gists_url": "https://api.github.com/users/meder411/gists{/gist_id}", "starred_url": "https://api.github.com/users/meder411/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/meder411/subscriptions", "organizations_url": "https://api.github.com/users/meder411/orgs", "repos_url": "https://api.github.com/users/meder411/repos", "events_url": "https://api.github.com/users/meder411/events{/privacy}", "received_events_url": "https://api.github.com/users/meder411/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-30T02:48:02Z", "updated_at": "2018-04-30T02:51:14Z", "author_association": "NONE", "body_html": "<p>Thanks for picking this up. Here's the configuration details from the build log after running <code>python setup.py install</code>. You can see it pointing to the local libs about 2/3 way in:</p>\n<pre><code>-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\n</code></pre>\n<p><strong>FULL CONFIG LOG</strong></p>\n<pre><code>running install\nrunning build_deps\n+ WITH_CUDA=0\n+ [[ --with-cuda == \\-\\-\\w\\i\\t\\h\\-\\c\\u\\d\\a ]]\n+ WITH_CUDA=1\n+ shift\n+ WITH_NNPACK=0\n+ [[ --with-nnpack == \\-\\-\\w\\i\\t\\h\\-\\n\\n\\p\\a\\c\\k ]]\n+ WITH_NNPACK=1\n+ shift\n+ WITH_MKLDNN=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\m\\k\\l\\d\\n\\n ]]\n+ WITH_GLOO_IBVERBS=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\g\\l\\o\\o\\-\\i\\b\\v\\e\\r\\b\\s ]]\n+ WITH_DISTRIBUTED_MW=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d\\-\\m\\w ]]\n+ CMAKE_INSTALL='make install'\n+ USER_CFLAGS=\n+ USER_LDFLAGS=\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n++ dirname tools/build_pytorch_libs.sh\n+ cd tools/..\n+++ pwd\n++ printf '%q\\n' /usr/local/src/pytorch\n+ PWD=/usr/local/src/pytorch\n+ BASE_DIR=/usr/local/src/pytorch\n+ TORCH_LIB_DIR=/usr/local/src/pytorch/torch/lib\n+ INSTALL_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\n+ THIRD_PARTY_DIR=/usr/local/src/pytorch/third_party\n+ CMAKE_VERSION=cmake\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\"'\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\" '\n+ LD_POSTFIX=.so.1\n+ LD_POSTFIX_UNVERSIONED=.so\n++ uname\n+ [[ Linux == \\D\\a\\r\\w\\i\\n ]]\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,$ORIGIN'\n+ CPP_FLAGS=' -std=c++11 '\n+ GLOO_FLAGS=\n+ THD_FLAGS=\n+ NCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\n+ [[ 1 -eq 1 ]]\n+ GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install'\n+ [[ 0 -eq 1 ]]\n+ [[ 0 -eq 1 ]]\n+ CWRAP_FILES='/usr/local/src/pytorch/torch/lib/ATen/Declarations.cwrap;/usr/local/src/pytorch/torch/lib/THNN/generic/THNN.h;/usr/local/src/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/usr/local/src/pytorch/torch/lib/ATen/nn.yaml'\n+ CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n+ [[ '' -eq 1 ]]\n+ '[' -z 20 ']'\n+ BUILD_TYPE=Release\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n+ echo 'Building in Release mode'\nBuilding in Release mode\n+ mkdir -p torch/lib/tmp_install\n+ for arg in '\"$@\"'\n+ [[ nccl == \\n\\c\\c\\l ]]\n+ pushd /usr/local/src/pytorch/third_party\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ build_nccl\n+ mkdir -p build/nccl\n+ pushd build/nccl\n/usr/local/src/pytorch/third_party/build/nccl /usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ cmake ../../nccl -DCMAKE_MODULE_PATH=/usr/local/src/pytorch/cmake/FindCUDA -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install '-DCMAKE_C_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1 ' '-DCMAKE_CXX_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1  -std=c++11  ' -DCMAKE_SHARED_LINKER_FLAGS=\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE  \n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"7.0\") \n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/src/pytorch/third_party/build/nccl\n+ make install\nScanning dependencies of target nccl\n[100%] Generating lib/libnccl.so\nGrabbing  src/nccl.h                          &gt; /usr/local/src/pytorch/third_party/build/nccl/include/nccl.h\nCompiling src/libwrap.cu                      &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/libwrap.o\nCompiling src/core.cu                         &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/core.o\nCompiling src/all_gather.cu                   &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/all_gather.o\nCompiling src/all_reduce.cu                   &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/all_reduce.o\nCompiling src/broadcast.cu                    &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/broadcast.o\nCompiling src/reduce.cu                       &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/reduce.o\nCompiling src/reduce_scatter.cu               &gt; /usr/local/src/pytorch/third_party/build/nccl/obj/reduce_scatter.o\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nLinking   libnccl.so.1.3.5                    &gt; /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl.so.1.3.5\nArchiving libnccl_static.a                    &gt; /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl_static.a\n[100%] Built target nccl\nInstall the project...\n-- Install configuration: \"Release\"\n-- Installing: /usr/local/src/pytorch/torch/lib/tmp_install/include/nccl.h\n+ mkdir -p /usr/local/src/pytorch/torch/lib/tmp_install/lib\n+ cp lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1\n+ '[' '!' -f /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so ']'\n+ ln -s /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so\n+ popd\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ popd\n/usr/local/src/pytorch\n+ for arg in '\"$@\"'\n+ [[ ATen == \\n\\c\\c\\l ]]\n+ [[ ATen == \\g\\l\\o\\o ]]\n+ [[ ATen == \\A\\T\\e\\n ]]\n+ pushd /usr/local/src/pytorch/aten\n/usr/local/src/pytorch/aten /usr/local/src/pytorch\n+ build_aten\n+ mkdir -p build\n+ pushd build\n/usr/local/src/pytorch/aten/build /usr/local/src/pytorch/aten /usr/local/src/pytorch\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib64 -DCUDNN_LIBRARY=/usr/local/cuda/lib64/libcudnn.so.7 -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS=\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test SUPPORT_GLIBCXX_USE_C99\n-- Performing Test SUPPORT_GLIBCXX_USE_C99 - Success\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE  \n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"5.5\") \n-- Autodetected CUDA architecture(s): 6.1 6.1 6.1 6.1 \n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\nCMake Warning (dev) at /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:200 (if):\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\n\n  Quoted variables like \"c\" will no longer be dereferenced when the policy is\n  set to NEW.  Since the policy is not set the OLD behavior will be used.\nCall Stack (most recent call first):\n  /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:324 (_OPENMP_GET_FLAGS)\n  CMakeLists.txt:171 (FIND_PACKAGE)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \n-- Compiling with OpenMP support\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\n-- Compiling with MAGMA support\n-- MAGMA INCLUDE DIRECTORIES: /usr/local/anaconda2/include\n-- MAGMA LIBRARIES: /usr/local/anaconda2/lib/libmagma.a\n-- MAGMA V2 check: 1\n-- Could not find hardware support for NEON on this machine.\n-- No OMAP3 processor on this machine.\n-- No OMAP4 processor on this machine.\n-- Performing Test COMPILER_WORKS\n-- Performing Test COMPILER_WORKS - Success\n-- Looking for cpuid.h\n-- Looking for cpuid.h - found\n-- Performing Test HAVE_GCC_GET_CPUID\n-- Performing Test HAVE_GCC_GET_CPUID - Success\n-- Performing Test NO_GCC_EBX_FPIC_BUG\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\n-- Performing Test C_HAS_SSE1_1\n-- Performing Test C_HAS_SSE1_1 - Success\n-- Performing Test C_HAS_SSE2_1\n-- Performing Test C_HAS_SSE2_1 - Success\n-- Performing Test C_HAS_SSE3_1\n-- Performing Test C_HAS_SSE3_1 - Failed\n-- Performing Test C_HAS_SSE3_2\n-- Performing Test C_HAS_SSE3_2 - Success\n-- Performing Test C_HAS_SSE4_1_1\n-- Performing Test C_HAS_SSE4_1_1 - Failed\n-- Performing Test C_HAS_SSE4_1_2\n-- Performing Test C_HAS_SSE4_1_2 - Success\n-- Performing Test C_HAS_SSE4_2_1\n-- Performing Test C_HAS_SSE4_2_1 - Failed\n-- Performing Test C_HAS_SSE4_2_2\n-- Performing Test C_HAS_SSE4_2_2 - Success\n-- Performing Test C_HAS_AVX_1\n-- Performing Test C_HAS_AVX_1 - Failed\n-- Performing Test C_HAS_AVX_2\n-- Performing Test C_HAS_AVX_2 - Success\n-- Performing Test C_HAS_AVX2_1\n-- Performing Test C_HAS_AVX2_1 - Failed\n-- Performing Test C_HAS_AVX2_2\n-- Performing Test C_HAS_AVX2_2 - Success\n-- Performing Test CXX_HAS_SSE1_1\n-- Performing Test CXX_HAS_SSE1_1 - Success\n-- Performing Test CXX_HAS_SSE2_1\n-- Performing Test CXX_HAS_SSE2_1 - Success\n-- Performing Test CXX_HAS_SSE3_1\n-- Performing Test CXX_HAS_SSE3_1 - Failed\n-- Performing Test CXX_HAS_SSE3_2\n-- Performing Test CXX_HAS_SSE3_2 - Success\n-- Performing Test CXX_HAS_SSE4_1_1\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\n-- Performing Test CXX_HAS_SSE4_1_2\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\n-- Performing Test CXX_HAS_SSE4_2_1\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\n-- Performing Test CXX_HAS_SSE4_2_2\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\n-- Performing Test CXX_HAS_AVX_1\n-- Performing Test CXX_HAS_AVX_1 - Failed\n-- Performing Test CXX_HAS_AVX_2\n-- Performing Test CXX_HAS_AVX_2 - Success\n-- Performing Test CXX_HAS_AVX2_1\n-- Performing Test CXX_HAS_AVX2_1 - Failed\n-- Performing Test CXX_HAS_AVX2_2\n-- Performing Test CXX_HAS_AVX2_2 - Success\n-- SSE2 Found\n-- SSE3 Found\n-- AVX Found\n-- AVX2 Found\n-- Performing Test HAS_C11_ATOMICS\n-- Performing Test HAS_C11_ATOMICS - Failed\n-- Performing Test HAS_MSC_ATOMICS\n-- Performing Test HAS_MSC_ATOMICS - Failed\n-- Performing Test HAS_GCC_ATOMICS\n-- Performing Test HAS_GCC_ATOMICS - Success\n-- Atomics: using GCC intrinsics\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \n--   Library gomp: -fopenmp\n--   Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so\n--   Library m: /usr/lib/x86_64-linux-gnu/libm.so\n--   Library dl: /usr/lib/x86_64-linux-gnu/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - found\n-- MKL library found\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\n-- Performing Test BLAS_F2C_FLOAT_WORKS\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\n-- Performing Test BLAS_USE_CBLAS_DOT\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\n-- Found a library with BLAS API (mkl).\n-- Found a library with LAPACK API (mkl).\n-- Found CUDNN: /usr/local/cuda/include  \n-- Found cuDNN: v7.1.1  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so.7)\ndisabling MKLDNN because NO_MKLDNN is set\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:7 (CMAKE_POLICY):\n  The OLD behavior for policy CMP0026 will be removed from a future version\n  of CMake.\n\n  The cmake-policies(7) manual explains that the OLD behaviors of all\n  policies are deprecated and that a policy should be set to OLD only under\n  specific short-term circumstances.  Projects should be ported to the NEW\n  behavior and not rely on setting a policy to OLD.\n\n\n-- Using python found in /usr/local/anaconda2/bin/python\n-- Performing Test SUPPORTS_STDCXX11\n-- Performing Test SUPPORTS_STDCXX11 - Success\n-- Performing Test SUPPORTS_MRTM\n-- Performing Test SUPPORTS_MRTM - Success\n-- Performing Test SUPPORTS_FLIFETIME\n-- Performing Test SUPPORTS_FLIFETIME - Failed\n-- Looking for clock_gettime in rt\n-- Looking for clock_gettime in rt - found\n-- Looking for mmap\n-- Looking for mmap - found\n-- Looking for shm_open\n-- Looking for shm_open - found\n-- Looking for shm_unlink\n-- Looking for shm_unlink - found\n-- Looking for malloc_usable_size\n-- Looking for malloc_usable_size - found\n-- Performing Test C_HAS_THREAD\n-- Performing Test C_HAS_THREAD - Success\n-- Check if compiler accepts -pthread\n-- Check if compiler accepts -pthread - yes\ndisable contrib because ATEN_NO_CONTRIB is set\n-- Configuring done\n-- Generating done\nCMake Warning:\n  Manually-specified variables were not used by the project:\n\n    MKLDNN_INCLUDE_DIR\n    MKLDNN_LIBRARY\n    MKLDNN_LIB_DIR\n    NO_NNPACK\n\n\n-- Build files have been written to: /usr/local/src/pytorch/aten/build\n\n</code></pre>", "body_text": "Thanks for picking this up. Here's the configuration details from the build log after running python setup.py install. You can see it pointing to the local libs about 2/3 way in:\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\n\nFULL CONFIG LOG\nrunning install\nrunning build_deps\n+ WITH_CUDA=0\n+ [[ --with-cuda == \\-\\-\\w\\i\\t\\h\\-\\c\\u\\d\\a ]]\n+ WITH_CUDA=1\n+ shift\n+ WITH_NNPACK=0\n+ [[ --with-nnpack == \\-\\-\\w\\i\\t\\h\\-\\n\\n\\p\\a\\c\\k ]]\n+ WITH_NNPACK=1\n+ shift\n+ WITH_MKLDNN=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\m\\k\\l\\d\\n\\n ]]\n+ WITH_GLOO_IBVERBS=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\g\\l\\o\\o\\-\\i\\b\\v\\e\\r\\b\\s ]]\n+ WITH_DISTRIBUTED_MW=0\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d\\-\\m\\w ]]\n+ CMAKE_INSTALL='make install'\n+ USER_CFLAGS=\n+ USER_LDFLAGS=\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n++ dirname tools/build_pytorch_libs.sh\n+ cd tools/..\n+++ pwd\n++ printf '%q\\n' /usr/local/src/pytorch\n+ PWD=/usr/local/src/pytorch\n+ BASE_DIR=/usr/local/src/pytorch\n+ TORCH_LIB_DIR=/usr/local/src/pytorch/torch/lib\n+ INSTALL_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\n+ THIRD_PARTY_DIR=/usr/local/src/pytorch/third_party\n+ CMAKE_VERSION=cmake\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\"'\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\" '\n+ LD_POSTFIX=.so.1\n+ LD_POSTFIX_UNVERSIONED=.so\n++ uname\n+ [[ Linux == \\D\\a\\r\\w\\i\\n ]]\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,$ORIGIN'\n+ CPP_FLAGS=' -std=c++11 '\n+ GLOO_FLAGS=\n+ THD_FLAGS=\n+ NCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\n+ [[ 1 -eq 1 ]]\n+ GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install'\n+ [[ 0 -eq 1 ]]\n+ [[ 0 -eq 1 ]]\n+ CWRAP_FILES='/usr/local/src/pytorch/torch/lib/ATen/Declarations.cwrap;/usr/local/src/pytorch/torch/lib/THNN/generic/THNN.h;/usr/local/src/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/usr/local/src/pytorch/torch/lib/ATen/nn.yaml'\n+ CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\n+ [[ '' -eq 1 ]]\n+ '[' -z 20 ']'\n+ BUILD_TYPE=Release\n+ [[ -n '' ]]\n+ [[ -n '' ]]\n+ echo 'Building in Release mode'\nBuilding in Release mode\n+ mkdir -p torch/lib/tmp_install\n+ for arg in '\"$@\"'\n+ [[ nccl == \\n\\c\\c\\l ]]\n+ pushd /usr/local/src/pytorch/third_party\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ build_nccl\n+ mkdir -p build/nccl\n+ pushd build/nccl\n/usr/local/src/pytorch/third_party/build/nccl /usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ cmake ../../nccl -DCMAKE_MODULE_PATH=/usr/local/src/pytorch/cmake/FindCUDA -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install '-DCMAKE_C_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1 ' '-DCMAKE_CXX_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1  -std=c++11  ' -DCMAKE_SHARED_LINKER_FLAGS=\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE  \n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"7.0\") \n-- Configuring done\n-- Generating done\n-- Build files have been written to: /usr/local/src/pytorch/third_party/build/nccl\n+ make install\nScanning dependencies of target nccl\n[100%] Generating lib/libnccl.so\nGrabbing  src/nccl.h                          > /usr/local/src/pytorch/third_party/build/nccl/include/nccl.h\nCompiling src/libwrap.cu                      > /usr/local/src/pytorch/third_party/build/nccl/obj/libwrap.o\nCompiling src/core.cu                         > /usr/local/src/pytorch/third_party/build/nccl/obj/core.o\nCompiling src/all_gather.cu                   > /usr/local/src/pytorch/third_party/build/nccl/obj/all_gather.o\nCompiling src/all_reduce.cu                   > /usr/local/src/pytorch/third_party/build/nccl/obj/all_reduce.o\nCompiling src/broadcast.cu                    > /usr/local/src/pytorch/third_party/build/nccl/obj/broadcast.o\nCompiling src/reduce.cu                       > /usr/local/src/pytorch/third_party/build/nccl/obj/reduce.o\nCompiling src/reduce_scatter.cu               > /usr/local/src/pytorch/third_party/build/nccl/obj/reduce_scatter.o\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nptxas warning : Too big maxrregcount value specified 96, will be ignored\nLinking   libnccl.so.1.3.5                    > /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl.so.1.3.5\nArchiving libnccl_static.a                    > /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl_static.a\n[100%] Built target nccl\nInstall the project...\n-- Install configuration: \"Release\"\n-- Installing: /usr/local/src/pytorch/torch/lib/tmp_install/include/nccl.h\n+ mkdir -p /usr/local/src/pytorch/torch/lib/tmp_install/lib\n+ cp lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1\n+ '[' '!' -f /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so ']'\n+ ln -s /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so\n+ popd\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\n+ popd\n/usr/local/src/pytorch\n+ for arg in '\"$@\"'\n+ [[ ATen == \\n\\c\\c\\l ]]\n+ [[ ATen == \\g\\l\\o\\o ]]\n+ [[ ATen == \\A\\T\\e\\n ]]\n+ pushd /usr/local/src/pytorch/aten\n/usr/local/src/pytorch/aten /usr/local/src/pytorch\n+ build_aten\n+ mkdir -p build\n+ pushd build\n/usr/local/src/pytorch/aten/build /usr/local/src/pytorch/aten /usr/local/src/pytorch\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib64 -DCUDNN_LIBRARY=/usr/local/cuda/lib64/libcudnn.so.7 -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS=\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Performing Test SUPPORT_GLIBCXX_USE_C99\n-- Performing Test SUPPORT_GLIBCXX_USE_C99 - Success\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE  \n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"5.5\") \n-- Autodetected CUDA architecture(s): 6.1 6.1 6.1 6.1 \n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\n-- Removing -DNDEBUG from compile flags\nCMake Warning (dev) at /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:200 (if):\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\n  details.  Use the cmake_policy command to set the policy and suppress this\n  warning.\n\n  Quoted variables like \"c\" will no longer be dereferenced when the policy is\n  set to NEW.  Since the policy is not set the OLD behavior will be used.\nCall Stack (most recent call first):\n  /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:324 (_OPENMP_GET_FLAGS)\n  CMakeLists.txt:171 (FIND_PACKAGE)\nThis warning is for project developers.  Use -Wno-dev to suppress it.\n\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \n-- Compiling with OpenMP support\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\n-- Compiling with MAGMA support\n-- MAGMA INCLUDE DIRECTORIES: /usr/local/anaconda2/include\n-- MAGMA LIBRARIES: /usr/local/anaconda2/lib/libmagma.a\n-- MAGMA V2 check: 1\n-- Could not find hardware support for NEON on this machine.\n-- No OMAP3 processor on this machine.\n-- No OMAP4 processor on this machine.\n-- Performing Test COMPILER_WORKS\n-- Performing Test COMPILER_WORKS - Success\n-- Looking for cpuid.h\n-- Looking for cpuid.h - found\n-- Performing Test HAVE_GCC_GET_CPUID\n-- Performing Test HAVE_GCC_GET_CPUID - Success\n-- Performing Test NO_GCC_EBX_FPIC_BUG\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\n-- Performing Test C_HAS_SSE1_1\n-- Performing Test C_HAS_SSE1_1 - Success\n-- Performing Test C_HAS_SSE2_1\n-- Performing Test C_HAS_SSE2_1 - Success\n-- Performing Test C_HAS_SSE3_1\n-- Performing Test C_HAS_SSE3_1 - Failed\n-- Performing Test C_HAS_SSE3_2\n-- Performing Test C_HAS_SSE3_2 - Success\n-- Performing Test C_HAS_SSE4_1_1\n-- Performing Test C_HAS_SSE4_1_1 - Failed\n-- Performing Test C_HAS_SSE4_1_2\n-- Performing Test C_HAS_SSE4_1_2 - Success\n-- Performing Test C_HAS_SSE4_2_1\n-- Performing Test C_HAS_SSE4_2_1 - Failed\n-- Performing Test C_HAS_SSE4_2_2\n-- Performing Test C_HAS_SSE4_2_2 - Success\n-- Performing Test C_HAS_AVX_1\n-- Performing Test C_HAS_AVX_1 - Failed\n-- Performing Test C_HAS_AVX_2\n-- Performing Test C_HAS_AVX_2 - Success\n-- Performing Test C_HAS_AVX2_1\n-- Performing Test C_HAS_AVX2_1 - Failed\n-- Performing Test C_HAS_AVX2_2\n-- Performing Test C_HAS_AVX2_2 - Success\n-- Performing Test CXX_HAS_SSE1_1\n-- Performing Test CXX_HAS_SSE1_1 - Success\n-- Performing Test CXX_HAS_SSE2_1\n-- Performing Test CXX_HAS_SSE2_1 - Success\n-- Performing Test CXX_HAS_SSE3_1\n-- Performing Test CXX_HAS_SSE3_1 - Failed\n-- Performing Test CXX_HAS_SSE3_2\n-- Performing Test CXX_HAS_SSE3_2 - Success\n-- Performing Test CXX_HAS_SSE4_1_1\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\n-- Performing Test CXX_HAS_SSE4_1_2\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\n-- Performing Test CXX_HAS_SSE4_2_1\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\n-- Performing Test CXX_HAS_SSE4_2_2\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\n-- Performing Test CXX_HAS_AVX_1\n-- Performing Test CXX_HAS_AVX_1 - Failed\n-- Performing Test CXX_HAS_AVX_2\n-- Performing Test CXX_HAS_AVX_2 - Success\n-- Performing Test CXX_HAS_AVX2_1\n-- Performing Test CXX_HAS_AVX2_1 - Failed\n-- Performing Test CXX_HAS_AVX2_2\n-- Performing Test CXX_HAS_AVX2_2 - Success\n-- SSE2 Found\n-- SSE3 Found\n-- AVX Found\n-- AVX2 Found\n-- Performing Test HAS_C11_ATOMICS\n-- Performing Test HAS_C11_ATOMICS - Failed\n-- Performing Test HAS_MSC_ATOMICS\n-- Performing Test HAS_MSC_ATOMICS - Failed\n-- Performing Test HAS_GCC_ATOMICS\n-- Performing Test HAS_GCC_ATOMICS - Success\n-- Atomics: using GCC intrinsics\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of void*\n-- Check size of void* - done\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \n--   Library gomp: -fopenmp\n--   Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so\n--   Library m: /usr/lib/x86_64-linux-gnu/libm.so\n--   Library dl: /usr/lib/x86_64-linux-gnu/libdl.so\n-- Looking for cblas_sgemm\n-- Looking for cblas_sgemm - found\n-- MKL library found\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\n-- Performing Test BLAS_F2C_FLOAT_WORKS\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\n-- Performing Test BLAS_USE_CBLAS_DOT\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\n-- Found a library with BLAS API (mkl).\n-- Found a library with LAPACK API (mkl).\n-- Found CUDNN: /usr/local/cuda/include  \n-- Found cuDNN: v7.1.1  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so.7)\ndisabling MKLDNN because NO_MKLDNN is set\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:7 (CMAKE_POLICY):\n  The OLD behavior for policy CMP0026 will be removed from a future version\n  of CMake.\n\n  The cmake-policies(7) manual explains that the OLD behaviors of all\n  policies are deprecated and that a policy should be set to OLD only under\n  specific short-term circumstances.  Projects should be ported to the NEW\n  behavior and not rely on setting a policy to OLD.\n\n\n-- Using python found in /usr/local/anaconda2/bin/python\n-- Performing Test SUPPORTS_STDCXX11\n-- Performing Test SUPPORTS_STDCXX11 - Success\n-- Performing Test SUPPORTS_MRTM\n-- Performing Test SUPPORTS_MRTM - Success\n-- Performing Test SUPPORTS_FLIFETIME\n-- Performing Test SUPPORTS_FLIFETIME - Failed\n-- Looking for clock_gettime in rt\n-- Looking for clock_gettime in rt - found\n-- Looking for mmap\n-- Looking for mmap - found\n-- Looking for shm_open\n-- Looking for shm_open - found\n-- Looking for shm_unlink\n-- Looking for shm_unlink - found\n-- Looking for malloc_usable_size\n-- Looking for malloc_usable_size - found\n-- Performing Test C_HAS_THREAD\n-- Performing Test C_HAS_THREAD - Success\n-- Check if compiler accepts -pthread\n-- Check if compiler accepts -pthread - yes\ndisable contrib because ATEN_NO_CONTRIB is set\n-- Configuring done\n-- Generating done\nCMake Warning:\n  Manually-specified variables were not used by the project:\n\n    MKLDNN_INCLUDE_DIR\n    MKLDNN_LIBRARY\n    MKLDNN_LIB_DIR\n    NO_NNPACK\n\n\n-- Build files have been written to: /usr/local/src/pytorch/aten/build", "body": "Thanks for picking this up. Here's the configuration details from the build log after running `python setup.py install`. You can see it pointing to the local libs about 2/3 way in:\r\n\r\n```\r\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\r\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\r\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\r\n```\r\n\r\n**FULL CONFIG LOG**\r\n\r\n```\r\nrunning install\r\nrunning build_deps\r\n+ WITH_CUDA=0\r\n+ [[ --with-cuda == \\-\\-\\w\\i\\t\\h\\-\\c\\u\\d\\a ]]\r\n+ WITH_CUDA=1\r\n+ shift\r\n+ WITH_NNPACK=0\r\n+ [[ --with-nnpack == \\-\\-\\w\\i\\t\\h\\-\\n\\n\\p\\a\\c\\k ]]\r\n+ WITH_NNPACK=1\r\n+ shift\r\n+ WITH_MKLDNN=0\r\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\m\\k\\l\\d\\n\\n ]]\r\n+ WITH_GLOO_IBVERBS=0\r\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\g\\l\\o\\o\\-\\i\\b\\v\\e\\r\\b\\s ]]\r\n+ WITH_DISTRIBUTED_MW=0\r\n+ [[ nccl == \\-\\-\\w\\i\\t\\h\\-\\d\\i\\s\\t\\r\\i\\b\\u\\t\\e\\d\\-\\m\\w ]]\r\n+ CMAKE_INSTALL='make install'\r\n+ USER_CFLAGS=\r\n+ USER_LDFLAGS=\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n++ dirname tools/build_pytorch_libs.sh\r\n+ cd tools/..\r\n+++ pwd\r\n++ printf '%q\\n' /usr/local/src/pytorch\r\n+ PWD=/usr/local/src/pytorch\r\n+ BASE_DIR=/usr/local/src/pytorch\r\n+ TORCH_LIB_DIR=/usr/local/src/pytorch/torch/lib\r\n+ INSTALL_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\r\n+ THIRD_PARTY_DIR=/usr/local/src/pytorch/third_party\r\n+ CMAKE_VERSION=cmake\r\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\"'\r\n+ C_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\r\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\" '\r\n+ LD_POSTFIX=.so.1\r\n+ LD_POSTFIX_UNVERSIONED=.so\r\n++ uname\r\n+ [[ Linux == \\D\\a\\r\\w\\i\\n ]]\r\n+ LDFLAGS='-L\"/usr/local/src/pytorch/torch/lib/tmp_install/lib\"  -Wl,-rpath,$ORIGIN'\r\n+ CPP_FLAGS=' -std=c++11 '\r\n+ GLOO_FLAGS=\r\n+ THD_FLAGS=\r\n+ NCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install\r\n+ [[ 1 -eq 1 ]]\r\n+ GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/usr/local/src/pytorch/torch/lib/tmp_install'\r\n+ [[ 0 -eq 1 ]]\r\n+ [[ 0 -eq 1 ]]\r\n+ CWRAP_FILES='/usr/local/src/pytorch/torch/lib/ATen/Declarations.cwrap;/usr/local/src/pytorch/torch/lib/THNN/generic/THNN.h;/usr/local/src/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/usr/local/src/pytorch/torch/lib/ATen/nn.yaml'\r\n+ CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1'\r\n+ [[ '' -eq 1 ]]\r\n+ '[' -z 20 ']'\r\n+ BUILD_TYPE=Release\r\n+ [[ -n '' ]]\r\n+ [[ -n '' ]]\r\n+ echo 'Building in Release mode'\r\nBuilding in Release mode\r\n+ mkdir -p torch/lib/tmp_install\r\n+ for arg in '\"$@\"'\r\n+ [[ nccl == \\n\\c\\c\\l ]]\r\n+ pushd /usr/local/src/pytorch/third_party\r\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\r\n+ build_nccl\r\n+ mkdir -p build/nccl\r\n+ pushd build/nccl\r\n/usr/local/src/pytorch/third_party/build/nccl /usr/local/src/pytorch/third_party /usr/local/src/pytorch\r\n+ cmake ../../nccl -DCMAKE_MODULE_PATH=/usr/local/src/pytorch/cmake/FindCUDA -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install '-DCMAKE_C_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1 ' '-DCMAKE_CXX_FLAGS= -DTH_INDEX_BASE=0 -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/TH\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THC\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THS\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCS\"   -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THNN\" -I\"/usr/local/src/pytorch/torch/lib/tmp_install/include/THCUNN\" -DOMPI_SKIP_MPICXX=1  -std=c++11  ' -DCMAKE_SHARED_LINKER_FLAGS=\r\n-- The C compiler identification is GNU 5.4.0\r\n-- The CXX compiler identification is GNU 5.4.0\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Looking for pthread_create\r\n-- Looking for pthread_create - not found\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - found\r\n-- Found Threads: TRUE  \r\n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"7.0\") \r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /usr/local/src/pytorch/third_party/build/nccl\r\n+ make install\r\nScanning dependencies of target nccl\r\n[100%] Generating lib/libnccl.so\r\nGrabbing  src/nccl.h                          > /usr/local/src/pytorch/third_party/build/nccl/include/nccl.h\r\nCompiling src/libwrap.cu                      > /usr/local/src/pytorch/third_party/build/nccl/obj/libwrap.o\r\nCompiling src/core.cu                         > /usr/local/src/pytorch/third_party/build/nccl/obj/core.o\r\nCompiling src/all_gather.cu                   > /usr/local/src/pytorch/third_party/build/nccl/obj/all_gather.o\r\nCompiling src/all_reduce.cu                   > /usr/local/src/pytorch/third_party/build/nccl/obj/all_reduce.o\r\nCompiling src/broadcast.cu                    > /usr/local/src/pytorch/third_party/build/nccl/obj/broadcast.o\r\nCompiling src/reduce.cu                       > /usr/local/src/pytorch/third_party/build/nccl/obj/reduce.o\r\nCompiling src/reduce_scatter.cu               > /usr/local/src/pytorch/third_party/build/nccl/obj/reduce_scatter.o\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nptxas warning : Too big maxrregcount value specified 96, will be ignored\r\nLinking   libnccl.so.1.3.5                    > /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl.so.1.3.5\r\nArchiving libnccl_static.a                    > /usr/local/src/pytorch/third_party/build/nccl/lib/libnccl_static.a\r\n[100%] Built target nccl\r\nInstall the project...\r\n-- Install configuration: \"Release\"\r\n-- Installing: /usr/local/src/pytorch/torch/lib/tmp_install/include/nccl.h\r\n+ mkdir -p /usr/local/src/pytorch/torch/lib/tmp_install/lib\r\n+ cp lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1\r\n+ '[' '!' -f /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so ']'\r\n+ ln -s /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so.1 /usr/local/src/pytorch/torch/lib/tmp_install/lib/libnccl.so\r\n+ popd\r\n/usr/local/src/pytorch/third_party /usr/local/src/pytorch\r\n+ popd\r\n/usr/local/src/pytorch\r\n+ for arg in '\"$@\"'\r\n+ [[ ATen == \\n\\c\\c\\l ]]\r\n+ [[ ATen == \\g\\l\\o\\o ]]\r\n+ [[ ATen == \\A\\T\\e\\n ]]\r\n+ pushd /usr/local/src/pytorch/aten\r\n/usr/local/src/pytorch/aten /usr/local/src/pytorch\r\n+ build_aten\r\n+ mkdir -p build\r\n+ pushd build\r\n/usr/local/src/pytorch/aten/build /usr/local/src/pytorch/aten /usr/local/src/pytorch\r\n+ cmake .. -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/local/cuda/include -DCUDNN_LIB_DIR=/usr/local/cuda/lib64 -DCUDNN_LIBRARY=/usr/local/cuda/lib64/libcudnn.so.7 -DNO_MKLDNN=1 -DMKLDNN_INCLUDE_DIR= -DMKLDNN_LIB_DIR= -DMKLDNN_LIBRARY= -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/usr/local/src/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS=\r\n-- The C compiler identification is GNU 5.4.0\r\n-- The CXX compiler identification is GNU 5.4.0\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Performing Test SUPPORT_GLIBCXX_USE_C99\r\n-- Performing Test SUPPORT_GLIBCXX_USE_C99 - Success\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Looking for pthread_create\r\n-- Looking for pthread_create - not found\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - found\r\n-- Found Threads: TRUE  \r\n-- Found CUDA: /usr/local/cuda (found suitable version \"9.0\", minimum required is \"5.5\") \r\n-- Autodetected CUDA architecture(s): 6.1 6.1 6.1 6.1 \r\n-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor\r\n-- Removing -DNDEBUG from compile flags\r\nCMake Warning (dev) at /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:200 (if):\r\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\r\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\r\n  details.  Use the cmake_policy command to set the policy and suppress this\r\n  warning.\r\n\r\n  Quoted variables like \"c\" will no longer be dereferenced when the policy is\r\n  set to NEW.  Since the policy is not set the OLD behavior will be used.\r\nCall Stack (most recent call first):\r\n  /usr/local/anaconda2/share/cmake-3.9/Modules/FindOpenMP.cmake:324 (_OPENMP_GET_FLAGS)\r\n  CMakeLists.txt:171 (FIND_PACKAGE)\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \r\n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \r\n-- Compiling with OpenMP support\r\n-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True\r\n-- Compiling with MAGMA support\r\n-- MAGMA INCLUDE DIRECTORIES: /usr/local/anaconda2/include\r\n-- MAGMA LIBRARIES: /usr/local/anaconda2/lib/libmagma.a\r\n-- MAGMA V2 check: 1\r\n-- Could not find hardware support for NEON on this machine.\r\n-- No OMAP3 processor on this machine.\r\n-- No OMAP4 processor on this machine.\r\n-- Performing Test COMPILER_WORKS\r\n-- Performing Test COMPILER_WORKS - Success\r\n-- Looking for cpuid.h\r\n-- Looking for cpuid.h - found\r\n-- Performing Test HAVE_GCC_GET_CPUID\r\n-- Performing Test HAVE_GCC_GET_CPUID - Success\r\n-- Performing Test NO_GCC_EBX_FPIC_BUG\r\n-- Performing Test NO_GCC_EBX_FPIC_BUG - Success\r\n-- Performing Test C_HAS_SSE1_1\r\n-- Performing Test C_HAS_SSE1_1 - Success\r\n-- Performing Test C_HAS_SSE2_1\r\n-- Performing Test C_HAS_SSE2_1 - Success\r\n-- Performing Test C_HAS_SSE3_1\r\n-- Performing Test C_HAS_SSE3_1 - Failed\r\n-- Performing Test C_HAS_SSE3_2\r\n-- Performing Test C_HAS_SSE3_2 - Success\r\n-- Performing Test C_HAS_SSE4_1_1\r\n-- Performing Test C_HAS_SSE4_1_1 - Failed\r\n-- Performing Test C_HAS_SSE4_1_2\r\n-- Performing Test C_HAS_SSE4_1_2 - Success\r\n-- Performing Test C_HAS_SSE4_2_1\r\n-- Performing Test C_HAS_SSE4_2_1 - Failed\r\n-- Performing Test C_HAS_SSE4_2_2\r\n-- Performing Test C_HAS_SSE4_2_2 - Success\r\n-- Performing Test C_HAS_AVX_1\r\n-- Performing Test C_HAS_AVX_1 - Failed\r\n-- Performing Test C_HAS_AVX_2\r\n-- Performing Test C_HAS_AVX_2 - Success\r\n-- Performing Test C_HAS_AVX2_1\r\n-- Performing Test C_HAS_AVX2_1 - Failed\r\n-- Performing Test C_HAS_AVX2_2\r\n-- Performing Test C_HAS_AVX2_2 - Success\r\n-- Performing Test CXX_HAS_SSE1_1\r\n-- Performing Test CXX_HAS_SSE1_1 - Success\r\n-- Performing Test CXX_HAS_SSE2_1\r\n-- Performing Test CXX_HAS_SSE2_1 - Success\r\n-- Performing Test CXX_HAS_SSE3_1\r\n-- Performing Test CXX_HAS_SSE3_1 - Failed\r\n-- Performing Test CXX_HAS_SSE3_2\r\n-- Performing Test CXX_HAS_SSE3_2 - Success\r\n-- Performing Test CXX_HAS_SSE4_1_1\r\n-- Performing Test CXX_HAS_SSE4_1_1 - Failed\r\n-- Performing Test CXX_HAS_SSE4_1_2\r\n-- Performing Test CXX_HAS_SSE4_1_2 - Success\r\n-- Performing Test CXX_HAS_SSE4_2_1\r\n-- Performing Test CXX_HAS_SSE4_2_1 - Failed\r\n-- Performing Test CXX_HAS_SSE4_2_2\r\n-- Performing Test CXX_HAS_SSE4_2_2 - Success\r\n-- Performing Test CXX_HAS_AVX_1\r\n-- Performing Test CXX_HAS_AVX_1 - Failed\r\n-- Performing Test CXX_HAS_AVX_2\r\n-- Performing Test CXX_HAS_AVX_2 - Success\r\n-- Performing Test CXX_HAS_AVX2_1\r\n-- Performing Test CXX_HAS_AVX2_1 - Failed\r\n-- Performing Test CXX_HAS_AVX2_2\r\n-- Performing Test CXX_HAS_AVX2_2 - Success\r\n-- SSE2 Found\r\n-- SSE3 Found\r\n-- AVX Found\r\n-- AVX2 Found\r\n-- Performing Test HAS_C11_ATOMICS\r\n-- Performing Test HAS_C11_ATOMICS - Failed\r\n-- Performing Test HAS_MSC_ATOMICS\r\n-- Performing Test HAS_MSC_ATOMICS - Failed\r\n-- Performing Test HAS_GCC_ATOMICS\r\n-- Performing Test HAS_GCC_ATOMICS - Success\r\n-- Atomics: using GCC intrinsics\r\n-- Looking for sys/types.h\r\n-- Looking for sys/types.h - found\r\n-- Looking for stdint.h\r\n-- Looking for stdint.h - found\r\n-- Looking for stddef.h\r\n-- Looking for stddef.h - found\r\n-- Check size of void*\r\n-- Check size of void* - done\r\n-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]\r\n--   Library mkl_gf_lp64: /usr/local/lib/libmkl_gf_lp64.so\r\n--   Library mkl_gnu_thread: /usr/local/lib/libmkl_gnu_thread.so\r\n--   Library mkl_core: /usr/local/lib/libmkl_core.so\r\n-- Found OpenMP_C: -fopenmp (found version \"4.0\") \r\n-- Found OpenMP_CXX: -fopenmp (found version \"4.0\") \r\n--   Library gomp: -fopenmp\r\n--   Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so\r\n--   Library m: /usr/lib/x86_64-linux-gnu/libm.so\r\n--   Library dl: /usr/lib/x86_64-linux-gnu/libdl.so\r\n-- Looking for cblas_sgemm\r\n-- Looking for cblas_sgemm - found\r\n-- MKL library found\r\n-- Performing Test BLAS_F2C_DOUBLE_WORKS\r\n-- Performing Test BLAS_F2C_DOUBLE_WORKS - Failed\r\n-- Performing Test BLAS_F2C_FLOAT_WORKS\r\n-- Performing Test BLAS_F2C_FLOAT_WORKS - Success\r\n-- Performing Test BLAS_USE_CBLAS_DOT\r\n-- Performing Test BLAS_USE_CBLAS_DOT - Success\r\n-- Found a library with BLAS API (mkl).\r\n-- Found a library with LAPACK API (mkl).\r\n-- Found CUDNN: /usr/local/cuda/include  \r\n-- Found cuDNN: v7.1.1  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so.7)\r\ndisabling MKLDNN because NO_MKLDNN is set\r\nCMake Deprecation Warning at src/ATen/CMakeLists.txt:7 (CMAKE_POLICY):\r\n  The OLD behavior for policy CMP0026 will be removed from a future version\r\n  of CMake.\r\n\r\n  The cmake-policies(7) manual explains that the OLD behaviors of all\r\n  policies are deprecated and that a policy should be set to OLD only under\r\n  specific short-term circumstances.  Projects should be ported to the NEW\r\n  behavior and not rely on setting a policy to OLD.\r\n\r\n\r\n-- Using python found in /usr/local/anaconda2/bin/python\r\n-- Performing Test SUPPORTS_STDCXX11\r\n-- Performing Test SUPPORTS_STDCXX11 - Success\r\n-- Performing Test SUPPORTS_MRTM\r\n-- Performing Test SUPPORTS_MRTM - Success\r\n-- Performing Test SUPPORTS_FLIFETIME\r\n-- Performing Test SUPPORTS_FLIFETIME - Failed\r\n-- Looking for clock_gettime in rt\r\n-- Looking for clock_gettime in rt - found\r\n-- Looking for mmap\r\n-- Looking for mmap - found\r\n-- Looking for shm_open\r\n-- Looking for shm_open - found\r\n-- Looking for shm_unlink\r\n-- Looking for shm_unlink - found\r\n-- Looking for malloc_usable_size\r\n-- Looking for malloc_usable_size - found\r\n-- Performing Test C_HAS_THREAD\r\n-- Performing Test C_HAS_THREAD - Success\r\n-- Check if compiler accepts -pthread\r\n-- Check if compiler accepts -pthread - yes\r\ndisable contrib because ATEN_NO_CONTRIB is set\r\n-- Configuring done\r\n-- Generating done\r\nCMake Warning:\r\n  Manually-specified variables were not used by the project:\r\n\r\n    MKLDNN_INCLUDE_DIR\r\n    MKLDNN_LIBRARY\r\n    MKLDNN_LIB_DIR\r\n    NO_NNPACK\r\n\r\n\r\n-- Build files have been written to: /usr/local/src/pytorch/aten/build\r\n\r\n```"}