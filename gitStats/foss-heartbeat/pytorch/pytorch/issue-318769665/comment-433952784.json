{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/433952784", "html_url": "https://github.com/pytorch/pytorch/issues/7083#issuecomment-433952784", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7083", "id": 433952784, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzk1Mjc4NA==", "user": {"login": "yaceben", "id": 19843412, "node_id": "MDQ6VXNlcjE5ODQzNDEy", "avatar_url": "https://avatars3.githubusercontent.com/u/19843412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaceben", "html_url": "https://github.com/yaceben", "followers_url": "https://api.github.com/users/yaceben/followers", "following_url": "https://api.github.com/users/yaceben/following{/other_user}", "gists_url": "https://api.github.com/users/yaceben/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaceben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaceben/subscriptions", "organizations_url": "https://api.github.com/users/yaceben/orgs", "repos_url": "https://api.github.com/users/yaceben/repos", "events_url": "https://api.github.com/users/yaceben/events{/privacy}", "received_events_url": "https://api.github.com/users/yaceben/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-29T15:23:08Z", "updated_at": "2018-10-29T15:31:25Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>MKL builds have been changing recently, so cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1100089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yinghai\">@yinghai</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> who might have some thoughts on this one. For example, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"364917395\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12170\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12170/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12170\">#12170</a> will be landing sometime soon.</p>\n</blockquote>\n<p>Thanks for the quick reply <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=79994\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/orionr\">@orionr</a>, I've (locally) made the following modification to FindMKL.cmake, seems to work for now.</p>\n<div class=\"highlight highlight-source-cmake\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Intel Compiler Suite</span>\n<span class=\"pl-k\">IF</span> (USE_SYS_MKL)\n    <span class=\"pl-c1\">SET</span>(INTEL_COMPILER_DIR <span class=\"pl-s\">\"/opt/intel\"</span> <span class=\"pl-k\">CACHE</span> STRING\n      <span class=\"pl-s\">\"Root directory of the Intel Compiler Suite (contains ipp, mkl, etc.)\"</span>)\n    <span class=\"pl-c1\">SET</span>(INTEL_MKL_DIR <span class=\"pl-s\">\"/opt/intel/mkl\"</span> <span class=\"pl-k\">CACHE</span> STRING\n      <span class=\"pl-s\">\"Root directory of the Intel MKL (standalone)\"</span>)\n    <span class=\"pl-c1\">SET</span>(INTEL_MKL_SEQUENTIAL <span class=\"pl-k\">OFF</span> <span class=\"pl-k\">CACHE</span> BOOL\n      <span class=\"pl-s\">\"Force using the sequential (non threaded) libraries\"</span>)\n<span class=\"pl-k\">ENDIF</span>(USE_SYS_MKL)</pre></div>\n<p>From what I gather from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"364917395\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12170\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12170/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12170\">#12170</a> and discussions from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1100089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yinghai\">@yinghai</a>  and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a>  a unified FindMKLDNN or something should eventually be available. I'm rather new to pytorch and never had the courage to embark on any serious cmake adventure... so take my proposition with a grain of salt :)</p>\n<p>Btw, just out of curiosity, is there a particular thread where I could find some information regarding the dropping of avx2 support for mkldnn ? I have a crappy quadro k2100m card in my laptop and for me the cpu is much faster than using cuda, so I was just wondering what the impact might be or what would be the best options for me when compiling from source?</p>\n<p>Cheers!<br>\nedit:<br>\n/cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1100089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yinghai\">@yinghai</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a></p>", "body_text": "MKL builds have been changing recently, so cc @yinghai and @ezyang who might have some thoughts on this one. For example, #12170 will be landing sometime soon.\n\nThanks for the quick reply @orionr, I've (locally) made the following modification to FindMKL.cmake, seems to work for now.\n# Intel Compiler Suite\nIF (USE_SYS_MKL)\n    SET(INTEL_COMPILER_DIR \"/opt/intel\" CACHE STRING\n      \"Root directory of the Intel Compiler Suite (contains ipp, mkl, etc.)\")\n    SET(INTEL_MKL_DIR \"/opt/intel/mkl\" CACHE STRING\n      \"Root directory of the Intel MKL (standalone)\")\n    SET(INTEL_MKL_SEQUENTIAL OFF CACHE BOOL\n      \"Force using the sequential (non threaded) libraries\")\nENDIF(USE_SYS_MKL)\nFrom what I gather from #12170 and discussions from @yinghai  and @ezyang  a unified FindMKLDNN or something should eventually be available. I'm rather new to pytorch and never had the courage to embark on any serious cmake adventure... so take my proposition with a grain of salt :)\nBtw, just out of curiosity, is there a particular thread where I could find some information regarding the dropping of avx2 support for mkldnn ? I have a crappy quadro k2100m card in my laptop and for me the cpu is much faster than using cuda, so I was just wondering what the impact might be or what would be the best options for me when compiling from source?\nCheers!\nedit:\n/cc @yinghai @ezyang", "body": "> MKL builds have been changing recently, so cc @yinghai and @ezyang who might have some thoughts on this one. For example, #12170 will be landing sometime soon.\r\n\r\nThanks for the quick reply @orionr, I've (locally) made the following modification to FindMKL.cmake, seems to work for now. \r\n\r\n```cmake\r\n# Intel Compiler Suite\r\nIF (USE_SYS_MKL)\r\n    SET(INTEL_COMPILER_DIR \"/opt/intel\" CACHE STRING\r\n      \"Root directory of the Intel Compiler Suite (contains ipp, mkl, etc.)\")\r\n    SET(INTEL_MKL_DIR \"/opt/intel/mkl\" CACHE STRING\r\n      \"Root directory of the Intel MKL (standalone)\")\r\n    SET(INTEL_MKL_SEQUENTIAL OFF CACHE BOOL\r\n      \"Force using the sequential (non threaded) libraries\")\r\nENDIF(USE_SYS_MKL)\r\n```\r\n\r\nFrom what I gather from #12170 and discussions from @yinghai  and @ezyang  a unified FindMKLDNN or something should eventually be available. I'm rather new to pytorch and never had the courage to embark on any serious cmake adventure... so take my proposition with a grain of salt :)\r\n\r\nBtw, just out of curiosity, is there a particular thread where I could find some information regarding the dropping of avx2 support for mkldnn ? I have a crappy quadro k2100m card in my laptop and for me the cpu is much faster than using cuda, so I was just wondering what the impact might be or what would be the best options for me when compiling from source? \r\n\r\nCheers!\r\nedit:\r\n/cc @yinghai @ezyang"}