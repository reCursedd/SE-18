{"url": "https://api.github.com/repos/pytorch/pytorch/issues/947", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/947/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/947/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/947/events", "html_url": "https://github.com/pytorch/pytorch/issues/947", "id": 212352653, "node_id": "MDU6SXNzdWUyMTIzNTI2NTM=", "number": 947, "title": "thpp Tensor templatized over Device (and maybe Density, e.g sparse vs dense)", "user": {"login": "an-kumar", "id": 13493636, "node_id": "MDQ6VXNlcjEzNDkzNjM2", "avatar_url": "https://avatars0.githubusercontent.com/u/13493636?v=4", "gravatar_id": "", "url": "https://api.github.com/users/an-kumar", "html_url": "https://github.com/an-kumar", "followers_url": "https://api.github.com/users/an-kumar/followers", "following_url": "https://api.github.com/users/an-kumar/following{/other_user}", "gists_url": "https://api.github.com/users/an-kumar/gists{/gist_id}", "starred_url": "https://api.github.com/users/an-kumar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/an-kumar/subscriptions", "organizations_url": "https://api.github.com/users/an-kumar/orgs", "repos_url": "https://api.github.com/users/an-kumar/repos", "events_url": "https://api.github.com/users/an-kumar/events{/privacy}", "received_events_url": "https://api.github.com/users/an-kumar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 466131885, "node_id": "MDU6TGFiZWw0NjYxMzE4ODU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/needs%20discussion", "name": "needs discussion", "color": "cc317c", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-03-07T07:34:02Z", "updated_at": "2017-08-30T23:34:15Z", "closed_at": "2017-08-30T23:34:15Z", "author_association": "NONE", "body_html": "<p>Right now, THPP exposes four templatized classes:</p>\n<p><code>THTensor&lt;T&gt;, THCTensor&lt;T&gt;, THCSTensor&lt;T&gt;, and THSTensor&lt;T&gt;.</code></p>\n<p>I propose to consolidate these into a single class, like so:</p>\n<pre><code>TorchTensor&lt;Type,Device,Density&gt; (or at least, &lt;Type,Device&gt;).\n</code></pre>\n<p>We can then do the following:</p>\n<pre><code>template &lt;typename T&gt;\nusing THTensor = TorchTensor&lt;T,CPU,Dense&gt;\n\ntemplate &lt;typename T&gt;\nusing THCTensor = TorchTensor&lt;T,GPU,Dense&gt;\n</code></pre>\n<p>and so on.</p>\n<p>In this fashion, nothing about the current API would change (and so all current code that uses THPP would all work the same), but users of THPP would be able to choose what level of templatization they want. If there are some current methods that are only in some subset of the classes, we can either do template class specialization, or simply make those methods part of all the classes.</p>\n<p>I am interested in this because I am using THPP in a separate project, in which it would be cleaner to have the Tensor class to be templatized over at least the Device (in addition to the Type), as it is in most other frameworks (e.g MXNet).</p>\n<p>I am happy to do this and submit a PR if the developers are interested, otherwise I will just make those changes locally.</p>", "body_text": "Right now, THPP exposes four templatized classes:\nTHTensor<T>, THCTensor<T>, THCSTensor<T>, and THSTensor<T>.\nI propose to consolidate these into a single class, like so:\nTorchTensor<Type,Device,Density> (or at least, <Type,Device>).\n\nWe can then do the following:\ntemplate <typename T>\nusing THTensor = TorchTensor<T,CPU,Dense>\n\ntemplate <typename T>\nusing THCTensor = TorchTensor<T,GPU,Dense>\n\nand so on.\nIn this fashion, nothing about the current API would change (and so all current code that uses THPP would all work the same), but users of THPP would be able to choose what level of templatization they want. If there are some current methods that are only in some subset of the classes, we can either do template class specialization, or simply make those methods part of all the classes.\nI am interested in this because I am using THPP in a separate project, in which it would be cleaner to have the Tensor class to be templatized over at least the Device (in addition to the Type), as it is in most other frameworks (e.g MXNet).\nI am happy to do this and submit a PR if the developers are interested, otherwise I will just make those changes locally.", "body": "Right now, THPP exposes four templatized classes:\r\n\r\n`THTensor<T>, THCTensor<T>, THCSTensor<T>, and THSTensor<T>.`\r\n\r\nI propose to consolidate these into a single class, like so:\r\n```\r\nTorchTensor<Type,Device,Density> (or at least, <Type,Device>).\r\n```\r\nWe can then do the following:\r\n```\r\ntemplate <typename T>\r\nusing THTensor = TorchTensor<T,CPU,Dense>\r\n\r\ntemplate <typename T>\r\nusing THCTensor = TorchTensor<T,GPU,Dense>\r\n```\r\nand so on.\r\n\r\nIn this fashion, nothing about the current API would change (and so all current code that uses THPP would all work the same), but users of THPP would be able to choose what level of templatization they want. If there are some current methods that are only in some subset of the classes, we can either do template class specialization, or simply make those methods part of all the classes.\r\n\r\nI am interested in this because I am using THPP in a separate project, in which it would be cleaner to have the Tensor class to be templatized over at least the Device (in addition to the Type), as it is in most other frameworks (e.g MXNet).\r\n\r\nI am happy to do this and submit a PR if the developers are interested, otherwise I will just make those changes locally."}