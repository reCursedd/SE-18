{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/285802470", "html_url": "https://github.com/pytorch/pytorch/issues/947#issuecomment-285802470", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/947", "id": 285802470, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTgwMjQ3MA==", "user": {"login": "an-kumar", "id": 13493636, "node_id": "MDQ6VXNlcjEzNDkzNjM2", "avatar_url": "https://avatars0.githubusercontent.com/u/13493636?v=4", "gravatar_id": "", "url": "https://api.github.com/users/an-kumar", "html_url": "https://github.com/an-kumar", "followers_url": "https://api.github.com/users/an-kumar/followers", "following_url": "https://api.github.com/users/an-kumar/following{/other_user}", "gists_url": "https://api.github.com/users/an-kumar/gists{/gist_id}", "starred_url": "https://api.github.com/users/an-kumar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/an-kumar/subscriptions", "organizations_url": "https://api.github.com/users/an-kumar/orgs", "repos_url": "https://api.github.com/users/an-kumar/repos", "events_url": "https://api.github.com/users/an-kumar/events{/privacy}", "received_events_url": "https://api.github.com/users/an-kumar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-10T22:27:56Z", "updated_at": "2017-03-10T22:27:56Z", "author_association": "NONE", "body_html": "<p>I would probably do it very similar to how it's done now.</p>\n<p>Different files in generic/ for the different devices, the explicit template instantiation over &lt;real,device&gt; instead of just . That would allow for the real differences in implementation between cuda and cpu, thought i would bet there's a way to reconcile it into one implementation w/ different macros, that just doesn't seem worth it though.</p>\n<p>Then, unify the interface, the only thing different atm in the interface as far as I can tell is that THCTensor has a THCState* state whereas the THTensor doesn't. I think I would change that to void* state in both, anyways I think it would be good to give the cpu Tensor a void* state (or at least, maybe, change state to be a virtual function returning a void* which is NULL for THTensor), because the THNN functions now take a THNNState* anyways which as far as I can tell is just void*, and expected to be NULL. This would help unify the code that would bring THNN and THCUNN into c++ land as well (what I am working on involves this too).</p>", "body_text": "I would probably do it very similar to how it's done now.\nDifferent files in generic/ for the different devices, the explicit template instantiation over <real,device> instead of just . That would allow for the real differences in implementation between cuda and cpu, thought i would bet there's a way to reconcile it into one implementation w/ different macros, that just doesn't seem worth it though.\nThen, unify the interface, the only thing different atm in the interface as far as I can tell is that THCTensor has a THCState* state whereas the THTensor doesn't. I think I would change that to void* state in both, anyways I think it would be good to give the cpu Tensor a void* state (or at least, maybe, change state to be a virtual function returning a void* which is NULL for THTensor), because the THNN functions now take a THNNState* anyways which as far as I can tell is just void*, and expected to be NULL. This would help unify the code that would bring THNN and THCUNN into c++ land as well (what I am working on involves this too).", "body": "I would probably do it very similar to how it's done now.\r\n\r\nDifferent files in generic/ for the different devices, the explicit template instantiation over <real,device> instead of just <real>. That would allow for the real differences in implementation between cuda and cpu, thought i would bet there's a way to reconcile it into one implementation w/ different macros, that just doesn't seem worth it though.\r\n\r\nThen, unify the interface, the only thing different atm in the interface as far as I can tell is that THCTensor has a THCState* state whereas the THTensor doesn't. I think I would change that to void* state in both, anyways I think it would be good to give the cpu Tensor a void* state (or at least, maybe, change state to be a virtual function returning a void* which is NULL for THTensor), because the THNN functions now take a THNNState* anyways which as far as I can tell is just void*, and expected to be NULL. This would help unify the code that would bring THNN and THCUNN into c++ land as well (what I am working on involves this too)."}