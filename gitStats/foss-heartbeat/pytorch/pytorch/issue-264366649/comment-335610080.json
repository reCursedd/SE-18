{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/335610080", "html_url": "https://github.com/pytorch/pytorch/pull/3054#issuecomment-335610080", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3054", "id": 335610080, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTYxMDA4MA==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-10T21:14:04Z", "updated_at": "2017-10-10T21:14:04Z", "author_association": "MEMBER", "body_html": "<p>Sorry -- I missed the important point in the issue when I first read it. To clarify a bit:</p>\n<ol>\n<li>\n<p>The <code>CudaStreamNonBlocking</code> is intentional and important. The model for PyTorch is that operations in <strong>all</strong> streams are asynchronous with respect to each and the host. This makes it easier to write performant code that doesn't have subtle synchronizations.</p>\n</li>\n<li>\n<p>This means that every operation should happen in the \"current stream. We have some memcpy's in the default stream that need to be fixed.</p>\n</li>\n<li>\n<p>The MAGMA and RNG functions don't support streams for the most part. We can probably leave them as-is for now.</p>\n</li>\n</ol>", "body_text": "Sorry -- I missed the important point in the issue when I first read it. To clarify a bit:\n\n\nThe CudaStreamNonBlocking is intentional and important. The model for PyTorch is that operations in all streams are asynchronous with respect to each and the host. This makes it easier to write performant code that doesn't have subtle synchronizations.\n\n\nThis means that every operation should happen in the \"current stream. We have some memcpy's in the default stream that need to be fixed.\n\n\nThe MAGMA and RNG functions don't support streams for the most part. We can probably leave them as-is for now.", "body": "Sorry -- I missed the important point in the issue when I first read it. To clarify a bit:\r\n\r\n1) The `CudaStreamNonBlocking` is intentional and important. The model for PyTorch is that operations in **all** streams are asynchronous with respect to each and the host. This makes it easier to write performant code that doesn't have subtle synchronizations.\r\n\r\n2) This means that every operation should happen in the \"current stream. We have some memcpy's in the default stream that need to be fixed.\r\n\r\n3) The MAGMA and RNG functions don't support streams for the most part. We can probably leave them as-is for now."}