{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3054", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3054/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3054/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3054/events", "html_url": "https://github.com/pytorch/pytorch/pull/3054", "id": 264366649, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQ1Nzk0MjQy", "number": 3054, "title": "Make cuda default stream wait for operations in other streams by default", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-10-10T20:33:25Z", "updated_at": "2017-10-10T23:00:17Z", "closed_at": "2017-10-10T20:54:49Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/3054", "html_url": "https://github.com/pytorch/pytorch/pull/3054", "diff_url": "https://github.com/pytorch/pytorch/pull/3054.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/3054.patch"}, "body_html": "<h3>Summary</h3>\n<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #2702.\">Fixes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"256916969\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2702\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2702/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2702\">#2702</a>.</p>\n<p>The bug is that cuda streams are created with the <code>CudaStreamNonBlocking</code> flag which means that operations on default streams do not block to wait for operations on the created stream. Matrix operations are run on some non-default stream while device to host transfers run on the default stream, leading to some race conditions.</p>\n<p>Another way to fix the issue is to change device-to-host transfers to run on the cuda current stream but I think removing the <code>CudaStreamNonBlocking</code> flag makes it easier to reason about the default stream vs other streams.</p>\n<h3>Test Plan</h3>\n<p>Run the code provided in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"256916969\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2702\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2702/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2702\">#2702</a>. Assert that junk data is not printed out.</p>", "body_text": "Summary\nFixes #2702.\nThe bug is that cuda streams are created with the CudaStreamNonBlocking flag which means that operations on default streams do not block to wait for operations on the created stream. Matrix operations are run on some non-default stream while device to host transfers run on the default stream, leading to some race conditions.\nAnother way to fix the issue is to change device-to-host transfers to run on the cuda current stream but I think removing the CudaStreamNonBlocking flag makes it easier to reason about the default stream vs other streams.\nTest Plan\nRun the code provided in #2702. Assert that junk data is not printed out.", "body": "### Summary\r\nFixes https://github.com/pytorch/pytorch/issues/2702.\r\n\r\nThe bug is that cuda streams are created with the `CudaStreamNonBlocking` flag which means that operations on default streams do not block to wait for operations on the created stream. Matrix operations are run on some non-default stream while device to host transfers run on the default stream, leading to some race conditions.\r\n\r\nAnother way to fix the issue is to change device-to-host transfers to run on the cuda current stream but I think removing the `CudaStreamNonBlocking` flag makes it easier to reason about the default stream vs other streams.\r\n\r\n### Test Plan\r\nRun the code provided in https://github.com/pytorch/pytorch/issues/2702. Assert that junk data is not printed out."}