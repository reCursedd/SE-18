{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169929904", "pull_request_review_id": 98515584, "id": 169929904, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2OTkyOTkwNA==", "diff_hunk": "@@ -19,6 +19,270 @@ namespace py = pybind11;\n \n namespace torch { namespace jit {\n \n+\n+// Before we translate to intepreter instructions, we do\n+// some preprocessing of the graph to turn it into a form that is closer\n+// to what the instructions will look like.\n+// In particular we:\n+// * (TODO) desugar Loop trip counts into c = 0, c += 1 instructions in the loop\n+// * flatten stages so that each stage starts with a load from the stack\n+//   and ends with a store to the stack\n+// *. computes move_flags (see Outputs), and inserts\n+//    'Drop' nodes where necessary to release Tensors after a If/Loop body exits\n+//    or if a value is never used.\n+// Outputs are:\n+// * graph - the post processed copy of g\n+// * move_flags[n] - a list of booleans, one for each input,\n+//   indicating whether this is the last use of the value. The interpreter\n+//   should generate a move rather than a copy in this case.\n+// * stage_input_types: the type annotations on the inputs to each stage\n+//   these can be removed once the the backward tracer is no longer used\n+\n+struct PreprocessGraph {\n+  PreprocessGraph(Graph & g)\n+  : graph(g.copy()) {\n+    desugarTripCounts(graph->block());\n+    flattenStages();\n+    dropUnused(graph->block());\n+\n+    // fill in move_flags by scanning blocks;\n+    findLastUses(graph->block());\n+    //TODO: desugar Loop trip counts, for now we drop trip counts\n+  }\n+  std::shared_ptr<Graph> graph;\n+  // for each input, should we move rather than copy the inputs\n+  std::unordered_map<Node*, std::vector<uint8_t>> move_flags;\n+\n+  // because JIT classic needs this to fix up gradients, remove when possible\n+  std::vector<std::vector<TypePtr>> stage_input_types;\n+private:\n+\n+  // this currently just _removes_ the trip count inputs and checks they are\n+  // unused. In the future they will be desugared into normal arithmetic to\n+  // provide a loop counter\n+  void desugarTripCounts(Block * b) {\n+    for(auto n : b->nodes()) {\n+      if(n->kind() == kLoop) {\n+\n+        // remove the trip count from Loop inputs, we don't support it yet\n+        n->removeInput(0);\n+        JIT_ASSERT(n->blocks()[0]->inputs()[0]->uses().size() == 0 &&\n+          \"NYI - use of trip count variable\");\n+        JIT_ASSERT(n->blocks()[0]->inputs()[1]->uses().size() == 0 &&\n+          \"NYI - use of cond variable in loop\");\n+\n+        // TODO: remove cond as input to loop carries, it just complicates this\n+        // implementation\n+        n->blocks()[0]->eraseInput(1);\n+        n->blocks()[0]->eraseInput(0);\n+      }\n+      for(auto sb : n->blocks()) {\n+        desugarTripCounts(sb);\n+      }\n+    }\n+  }\n+  Node * prependLocation() {\n+    //handle corner case where there are no nodes,\n+    if(graph->nodes().begin() == graph->nodes().end()) {\n+      return graph->return_node();\n+    }\n+    return *graph->nodes().begin();\n+  }\n+  // removes all inputs and outputs to a graph, replacing them with nodes before of after each insertStage\n+  void flattenStages() {\n+    WithInsertPoint guard(*graph, prependLocation());\n+    size_t input_pos = 0;\n+    size_t output_pos = 0;\n+    auto it = graph->nodes().begin();\n+    for(size_t i = 0; i <= graph->stage(); i++) {\n+      stage_input_types.emplace_back();\n+      auto store = graph->insertNode(graph->create(kStore, 0));\n+      // TODO: unused inputs need drop nodes added for them.\n+      while(input_pos < graph->inputs().size() && graph->inputs()[input_pos]->stage() == i) {\n+        auto nv = store->addOutput();\n+        auto old_node = graph->inputs()[input_pos];\n+        stage_input_types[i].push_back(old_node->typeOption());\n+        old_node->replaceAllUsesWith(nv);\n+        input_pos++;\n+      }\n+      while(it != graph->nodes().end() && it->stage() == i)\n+        ++it;\n+      graph->setInsertPoint(*it);\n+      auto load = graph->insertNode(graph->create(kLoad, 0));\n+      while(output_pos < graph->outputs().size() && graph->outputs()[output_pos]->stage() == i) {\n+        load->addInput(graph->outputs()[output_pos]);\n+        output_pos++;\n+      }\n+    }\n+    while (graph->inputs().size() > 0)\n+      graph->eraseInput(graph->inputs().size() - 1);\n+    while (graph->outputs().size() > 0)\n+      graph->eraseOutput(graph->outputs().size() - 1);\n+  }\n+\n+  Node * findOrCreateDropInstructionForNode(Node * n) {\n+    auto it = drop_for_node.find(n);\n+    if(it == drop_for_node.end()) {\n+      auto drop_node = graph->create(kDrop, 0);\n+      drop_node->insertAfter(n);\n+      it = drop_for_node.emplace(n, drop_node).first;\n+    }\n+    return it->second;\n+  }\n+\n+  // finds the node in the _same block_ as 'definition' that contains\n+  // the 'n' Node\n+  // prereq: one of n's inputs must be 'definition' to ensure it is in scope\n+  // e.g.\n+  // n0: a = 4\n+  // n1: if <cond>:\n+  // n2:    b = a + a\n+  // findNodeInTheSameBlockAs(n2, a) == n1\n+  Node * findNodeInTheSameBlockAs(Node * n, Value * definition) {\n+    while(definition->node()->owningBlock() != n->owningBlock()) {\n+      auto block = n->owningBlock();\n+      // asserts will fail if 'definition' is not in scope for 'n'\n+      // use lint to debug\n+      JIT_ASSERT(block);\n+      n = block->owningNode();\n+      JIT_ASSERT(n);\n+    }\n+    return n;\n+  }\n+  void scanUse(Node * n, size_t i) {\n+    auto & uses_array = move_flags[n];\n+    auto v = n->inputs()[i];\n+    auto inserted = seen.insert(v).second;\n+    if(!inserted) {\n+      uses_array[i] = false;\n+      return;\n+    }\n+\n+    // the last use of v may be in a nested block of an If or Loop statement\n+    // find the node 'same_depth_node' at the same depth as the definition of v,\n+    // and consider that node to be the last use of v.\n+    // This ensures we do not delete nodes in nested scopes\n+    // that may be executed multiple times\n+    // and that nodes used on one side of an if\n+    // but not the other get deleted regardless of the branch\n+    // e.g.\n+    // a = 4\n+    // while <...>:\n+    //   y = a + a\n+    // drop(a)\n+    // In other words, we find the first program point for v that\n+    // _reverse_ dominates the definition of v, and add a drop point there.\n+    Node * same_depth_node = findNodeInTheSameBlockAs(n, v);\n+\n+    // In the case where v and n are in the same block, just mark\n+    // its move_flags to be true\n+    if(same_depth_node == n) {\n+      uses_array[i] = true;\n+      return;\n+    }\n+\n+    // in the case where the use is nested in a block\n+    // add a Drop node after that block which will drop 'v'.\n+    uses_array[i] = false;\n+    addToDropIfNotExists(findOrCreateDropInstructionForNode(same_depth_node), v);\n+  }\n+  void findLastUses(Node * n) {\n+    for(auto b : n->blocks()) {\n+      findLastUses(b);\n+    }\n+    move_flags[n].resize(n->inputs().size());\n+    // scan backwards so if a value is used twice in the list then it is a move\n+    for(size_t i = n->inputs().size(); i > 0; --i) {\n+      scanUse(n, i-1);\n+    }\n+  }\n+  void addToDropIfNotExists(Node * drop, Value * v) {\n+    for(auto i : drop->inputs()) {\n+      // we already accounted for this use\n+      if(i == v)\n+        return;\n+    }\n+    drop->addInput(v);\n+    move_flags[drop].push_back(true);\n+  }\n+  void findLastUses(Block * b) {\n+    findLastUses(b->return_node());\n+    for(auto n : b->nodes().reverse()) {\n+      findLastUses(n);\n+    }\n+  }\n+  Node* createDropIfUnused(ArrayRef<Value*> values) {\n+    std::vector<Value*> to_drop;\n+    for(auto v : values) {\n+      if(v->uses().size() == 0)\n+        to_drop.push_back(v);\n+    }\n+    if(to_drop.size() == 0)\n+      return nullptr;\n+    return graph->create(kDrop, to_drop, 0);\n+  }\n+\n+  // insert Drop nodes to kill references for anything unused:\n+  // this can happen in a few places, e.g. when a node returns\n+  // many values but only one is used\n+  // a, b = foo()\n+  // return a\n+  void dropUnused(Block *b) {\n+    if(auto d = createDropIfUnused(b->inputs())) {\n+      b->prependNode(d);\n+    }\n+    for(auto n : b->nodes()) {\n+      if(auto d = createDropIfUnused(n->outputs())) {\n+        d->insertAfter(n);\n+      }\n+      for(auto b : n->blocks())\n+        dropUnused(b);\n+    }\n+  }\n+\n+  // A map from an If or Loop node to the optional Drop block that\n+  // occurs directly after it to release any tensors that go out of scope\n+  // when the If/Loop exits. These are created and inserted on demand.\n+  std::unordered_map<Node*, Node*> drop_for_node;\n+\n+  // have we seen this value, yet, if not, it is the last use of the value\n+  std::unordered_set<Value*> seen;", "path": "torch/csrc/jit/interpreter.cpp", "position": null, "original_position": 231, "commit_id": "f5f7d01b5b3c2859ffdb99316771529d4a624c22", "original_commit_id": "be682ec37e185e4b57c4b125d715d2d9e86485de", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Can we keep all the members in one place? Right now you have 3 at the top, and 2 at the bottom", "created_at": "2018-02-22T11:37:28Z", "updated_at": "2018-11-23T15:39:49Z", "html_url": "https://github.com/pytorch/pytorch/pull/5293#discussion_r169929904", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5293", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/169929904"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5293#discussion_r169929904"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5293"}}, "body_html": "<p>Can we keep all the members in one place? Right now you have 3 at the top, and 2 at the bottom</p>", "body_text": "Can we keep all the members in one place? Right now you have 3 at the top, and 2 at the bottom"}