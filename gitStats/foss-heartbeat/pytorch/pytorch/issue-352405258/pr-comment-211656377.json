{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/211656377", "pull_request_review_id": 148122092, "id": 211656377, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMTY1NjM3Nw==", "diff_hunk": "@@ -2971,6 +2971,72 @@ def parse_kwargs(desc):\n             [ 2.]])\n \"\"\")\n \n+add_docstr(torch.frobenius_norm,\n+           r\"\"\"\n+.. function:: frobenius_norm(input) -> Tensor\n+\n+Returns the frobenius norm of the :attr:`input` tensor.\n+\n+.. math::\n+    ||x||_{F} = \\sqrt{tr(xx^{H})}\n+\n+Args:\n+    input (Tensor): the input tensor, should be a matrix (2-D tensor)\n+Example::\n+\n+    >>> a = torch.randn(2, 3)\n+    >>> a\n+    tensor([[ 1.0043,  0.5987, -1.2026],\n+            [ 1.7241, -2.6561,  0.8088]])\n+    >>> a.frobenius_norm()\n+    tensor(3.6735)\n+\n+.. function:: frobenius_norm(input, dim, keepdim=False) -> Tensor\n+\n+Returns the frobenius_norm of the :attr:`input` tensor in the given\n+dimension :attr:`dim`.\n+\n+If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n+:attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n+Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n+in the output tensor having 2 fewer dimension than :attr:`input`.\n+\n+Args:\n+    input (Tensor): the input tensor\n+    dim (int or tuple of python:ints): the dimension to reduce\n+    keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n+\n+Example::\n+\n+    >>> a = torch.randn(2, 3)\n+    >>> a\n+    tensor([[-0.6971,  1.1057, -0.3520],\n+            [-2.1726, -1.0937,  0.6892]])\n+    >>> a.frobenius_norm((0,1))\n+    tensor(2.8677)\n+    >>> a.frobenius_norm((0,1),True)", "path": "torch/_torch_docs.py", "position": null, "original_position": 47, "commit_id": "f0003a27f579fdbfe9725225dec4d6796d9f588f", "original_commit_id": "2f48e4bf618ee29f017b989e0f9eeb0ef849df08", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "space before True", "created_at": "2018-08-21T15:42:18Z", "updated_at": "2018-11-23T15:49:39Z", "html_url": "https://github.com/pytorch/pytorch/pull/10722#discussion_r211656377", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10722", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/211656377"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10722#discussion_r211656377"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10722"}}, "body_html": "<p>space before True</p>", "body_text": "space before True"}