{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10850", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10850/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10850/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10850/events", "html_url": "https://github.com/pytorch/pytorch/issues/10850", "id": 353803422, "node_id": "MDU6SXNzdWUzNTM4MDM0MjI=", "number": 10850, "title": "CUDA Tensor __rsub__ breaks when device is not 0", "user": {"login": "davidmascharka", "id": 5611862, "node_id": "MDQ6VXNlcjU2MTE4NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5611862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmascharka", "html_url": "https://github.com/davidmascharka", "followers_url": "https://api.github.com/users/davidmascharka/followers", "following_url": "https://api.github.com/users/davidmascharka/following{/other_user}", "gists_url": "https://api.github.com/users/davidmascharka/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmascharka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmascharka/subscriptions", "organizations_url": "https://api.github.com/users/davidmascharka/orgs", "repos_url": "https://api.github.com/users/davidmascharka/repos", "events_url": "https://api.github.com/users/davidmascharka/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmascharka/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1002715609, "node_id": "MDU6TGFiZWwxMDAyNzE1NjA5", "url": "https://api.github.com/repos/pytorch/pytorch/labels/blocker", "name": "blocker", "color": "b60205", "default": false}, {"id": 679955625, "node_id": "MDU6TGFiZWw2Nzk5NTU2MjU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/crash", "name": "crash", "color": "d93f0b", "default": false}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-08-24T14:20:10Z", "updated_at": "2018-10-30T23:30:45Z", "closed_at": "2018-10-30T23:30:45Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>If a tensor resides on a GPU that is not 0, then the <code>__rsub__</code> function raises.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n\na <span class=\"pl-k\">=</span> torch.tensor([<span class=\"pl-c1\">1</span>]).to(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:3<span class=\"pl-pds\">'</span></span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> or any GPU that is not 0</span>\n\n<span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-c\"><span class=\"pl-c\">#</span> __sub__ is fine</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> a) <span class=\"pl-c\"><span class=\"pl-c\">#</span> __rsub__ breaks</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> __radd__, __rmul__, __rpow__, __rfloordiv__, and __rtruediv__ all work</span></pre></div>\n<p>Output:</p>\n<div class=\"highlight highlight-source-python\"><pre>tensor([<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], <span class=\"pl-v\">device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>cuda:3<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-ii\">--------------------------------------------------------------------------</span><span class=\"pl-k\">-</span>\n<span class=\"pl-c1\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"pl-k\">&lt;</span>ipython<span class=\"pl-k\">-</span><span class=\"pl-c1\">input</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">3</span><span class=\"pl-k\">-</span><span class=\"pl-ii\">4bb4bfe9af47</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>()\n      <span class=\"pl-c1\">1</span> <span class=\"pl-c1\">print</span>(a <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)\n<span class=\"pl-ii\">----</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">2</span> <span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">1</span> <span class=\"pl-k\">-</span> a)\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>tensor.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__repr__</span>(<span class=\"pl-c1\">self</span>)\n     <span class=\"pl-c1\">55</span>         <span class=\"pl-c\"><span class=\"pl-c\">#</span> characters to replace unicode characters with.</span>\n     <span class=\"pl-c1\">56</span>         <span class=\"pl-k\">if</span> sys.version_info <span class=\"pl-k\">&gt;</span> (<span class=\"pl-c1\">3</span>,):\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">57</span>             <span class=\"pl-k\">return</span> torch._tensor_str._str(<span class=\"pl-c1\">self</span>)\n     <span class=\"pl-c1\">58</span>         <span class=\"pl-k\">else</span>:\n     <span class=\"pl-c1\">59</span>             <span class=\"pl-k\">if</span> <span class=\"pl-c1\">hasattr</span>(sys.stdout, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoding<span class=\"pl-pds\">'</span></span>):\n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>_tensor_str.py <span class=\"pl-k\">in</span> _str(<span class=\"pl-c1\">self</span>)\n    <span class=\"pl-c1\">254</span>             suffix <span class=\"pl-k\">+=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>, dtype=<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">str</span>(<span class=\"pl-c1\">self</span>.dtype)\n    <span class=\"pl-c1\">255</span> \n<span class=\"pl-ii\">--</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">256</span>         formatter <span class=\"pl-k\">=</span> _Formatter(get_summarized_data(<span class=\"pl-c1\">self</span>) <span class=\"pl-k\">if</span> summarize <span class=\"pl-k\">else</span> <span class=\"pl-c1\">self</span>)\n    <span class=\"pl-c1\">257</span>         tensor_str <span class=\"pl-k\">=</span> _tensor_str(<span class=\"pl-c1\">self</span>, indent, formatter, summarize)\n    <span class=\"pl-c1\">258</span> \n\n<span class=\"pl-k\">~</span><span class=\"pl-k\">/</span>anaconda3<span class=\"pl-k\">/</span>lib<span class=\"pl-k\">/</span>python3.6<span class=\"pl-k\">/</span>site<span class=\"pl-k\">-</span>packages<span class=\"pl-k\">/</span>torch<span class=\"pl-k\">/</span>_tensor_str.py <span class=\"pl-k\">in</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-c1\">self</span>, tensor)\n     <span class=\"pl-c1\">74</span> \n     <span class=\"pl-c1\">75</span>         <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">self</span>.floating_dtype:\n<span class=\"pl-ii\">--</span><span class=\"pl-ii\">-&gt;</span> <span class=\"pl-c1\">76</span>             copy <span class=\"pl-k\">=</span> torch.empty(tensor.size(), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>torch.long).copy_(tensor).view(tensor.nelement())\n     <span class=\"pl-c1\">77</span>             <span class=\"pl-k\">for</span> value <span class=\"pl-k\">in</span> copy.tolist():\n     <span class=\"pl-c1\">78</span>                 value_str <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{}</span><span class=\"pl-pds\">'</span></span>.format(value)\n\n<span class=\"pl-c1\">RuntimeError</span>: cuda runtime error (<span class=\"pl-c1\">77</span>) : an illegal memory access was encountered at <span class=\"pl-k\">/</span>pytorch<span class=\"pl-k\">/</span>aten<span class=\"pl-k\">/</span>src<span class=\"pl-k\">/</span><span class=\"pl-c1\">THC</span><span class=\"pl-k\">/</span>generic<span class=\"pl-k\">/</span>THCTensorCopy.cpp:<span class=\"pl-c1\">68</span></pre></div>\n<h2>System Info</h2>\n<p>PyTorch version: 0.5.0a0+6993e4a<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.12.0</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti<br>\nGPU 3: GeForce GTX 1080 Ti</p>\n<p>Nvidia driver version: 390.67<br>\ncuDNN version: libcudnn.so.7.0.3</p>\n<p>Reproduced with PyTorch 0.5.0a0+e9ad743 as well.</p>", "body_text": "Issue description\nIf a tensor resides on a GPU that is not 0, then the __rsub__ function raises.\nCode example\nimport torch\n\na = torch.tensor([1]).to('cuda:3') # or any GPU that is not 0\n\nprint(a - 1) # __sub__ is fine\nprint(1 - a) # __rsub__ breaks\n# __radd__, __rmul__, __rpow__, __rfloordiv__, and __rtruediv__ all work\nOutput:\ntensor([-1], device='cuda:3')\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-3-4bb4bfe9af47> in <module>()\n      1 print(a - 1)\n----> 2 print(1 - a)\n\n~/anaconda3/lib/python3.6/site-packages/torch/tensor.py in __repr__(self)\n     55         # characters to replace unicode characters with.\n     56         if sys.version_info > (3,):\n---> 57             return torch._tensor_str._str(self)\n     58         else:\n     59             if hasattr(sys.stdout, 'encoding'):\n\n~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py in _str(self)\n    254             suffix += ', dtype=' + str(self.dtype)\n    255 \n--> 256         formatter = _Formatter(get_summarized_data(self) if summarize else self)\n    257         tensor_str = _tensor_str(self, indent, formatter, summarize)\n    258 \n\n~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py in __init__(self, tensor)\n     74 \n     75         if not self.floating_dtype:\n---> 76             copy = torch.empty(tensor.size(), dtype=torch.long).copy_(tensor).view(tensor.nelement())\n     77             for value in copy.tolist():\n     78                 value_str = '{}'.format(value)\n\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /pytorch/aten/src/THC/generic/THCTensorCopy.cpp:68\nSystem Info\nPyTorch version: 0.5.0a0+6993e4a\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.12.0\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\nNvidia driver version: 390.67\ncuDNN version: libcudnn.so.7.0.3\nReproduced with PyTorch 0.5.0a0+e9ad743 as well.", "body": "## Issue description\r\n\r\nIf a tensor resides on a GPU that is not 0, then the `__rsub__` function raises.\r\n\r\n## Code example\r\n\r\n``` python\r\nimport torch\r\n\r\na = torch.tensor([1]).to('cuda:3') # or any GPU that is not 0\r\n\r\nprint(a - 1) # __sub__ is fine\r\nprint(1 - a) # __rsub__ breaks\r\n# __radd__, __rmul__, __rpow__, __rfloordiv__, and __rtruediv__ all work\r\n```\r\n\r\nOutput:\r\n\r\n``` python\r\ntensor([-1], device='cuda:3')\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-4bb4bfe9af47> in <module>()\r\n      1 print(a - 1)\r\n----> 2 print(1 - a)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/torch/tensor.py in __repr__(self)\r\n     55         # characters to replace unicode characters with.\r\n     56         if sys.version_info > (3,):\r\n---> 57             return torch._tensor_str._str(self)\r\n     58         else:\r\n     59             if hasattr(sys.stdout, 'encoding'):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py in _str(self)\r\n    254             suffix += ', dtype=' + str(self.dtype)\r\n    255 \r\n--> 256         formatter = _Formatter(get_summarized_data(self) if summarize else self)\r\n    257         tensor_str = _tensor_str(self, indent, formatter, summarize)\r\n    258 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/torch/_tensor_str.py in __init__(self, tensor)\r\n     74 \r\n     75         if not self.floating_dtype:\r\n---> 76             copy = torch.empty(tensor.size(), dtype=torch.long).copy_(tensor).view(tensor.nelement())\r\n     77             for value in copy.tolist():\r\n     78                 value_str = '{}'.format(value)\r\n\r\nRuntimeError: cuda runtime error (77) : an illegal memory access was encountered at /pytorch/aten/src/THC/generic/THCTensorCopy.cpp:68\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.5.0a0+6993e4a\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 390.67\r\ncuDNN version: libcudnn.so.7.0.3\r\n\r\n\r\nReproduced with PyTorch 0.5.0a0+e9ad743 as well."}