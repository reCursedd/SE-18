{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/402516694", "html_url": "https://github.com/pytorch/pytorch/issues/9168#issuecomment-402516694", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9168", "id": 402516694, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMjUxNjY5NA==", "user": {"login": "mrocklin", "id": 306380, "node_id": "MDQ6VXNlcjMwNjM4MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrocklin", "html_url": "https://github.com/mrocklin", "followers_url": "https://api.github.com/users/mrocklin/followers", "following_url": "https://api.github.com/users/mrocklin/following{/other_user}", "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions", "organizations_url": "https://api.github.com/users/mrocklin/orgs", "repos_url": "https://api.github.com/users/mrocklin/repos", "events_url": "https://api.github.com/users/mrocklin/events{/privacy}", "received_events_url": "https://api.github.com/users/mrocklin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-04T16:00:09Z", "updated_at": "2018-07-04T16:00:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>For others, looks like using io.BytesIO gets up to about 1GB/s.</p>\n<div class=\"highlight highlight-source-python\"><pre>In [<span class=\"pl-c1\">1</span>]: <span class=\"pl-k\">from</span> torchvision.models.resnet <span class=\"pl-k\">import</span> resnet18\n   <span class=\"pl-c1\">...</span>: model <span class=\"pl-k\">=</span> resnet18(<span class=\"pl-v\">pretrained</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n   <span class=\"pl-c1\">...</span>: \n   <span class=\"pl-c1\">...</span>: \n\nIn [<span class=\"pl-c1\">2</span>]: <span class=\"pl-k\">import</span> torch\n\nIn [<span class=\"pl-c1\">3</span>]: <span class=\"pl-k\">import</span> io\n\nIn [<span class=\"pl-c1\">4</span>]: bio <span class=\"pl-k\">=</span> io.BytesIO()\n\nIn [<span class=\"pl-c1\">5</span>]: <span class=\"pl-k\">%%</span>time\n   <span class=\"pl-c1\">...</span>: torch.save(model, bio)\n   <span class=\"pl-c1\">...</span>: b <span class=\"pl-k\">=</span> bio.getvalue()\n   <span class=\"pl-c1\">...</span>: \n<span class=\"pl-c1\">CPU</span> times: user <span class=\"pl-c1\">32</span> ms, sys: <span class=\"pl-c1\">16.4</span> ms, total: <span class=\"pl-c1\">48.4</span> ms\nWall time: <span class=\"pl-c1\">47.7</span> ms\n\nIn [<span class=\"pl-c1\">6</span>]: <span class=\"pl-c1\">len</span>(b) <span class=\"pl-k\">/</span> <span class=\"pl-c1\">0.047</span> <span class=\"pl-k\">/</span> <span class=\"pl-c1\">1e6</span> <span class=\"pl-c\"><span class=\"pl-c\">#</span> MB/s</span>\nOut[<span class=\"pl-c1\">6</span>]: <span class=\"pl-c1\">996.619</span></pre></div>\n<p>And then we can reconstitute</p>\n<div class=\"highlight highlight-source-python\"><pre>io <span class=\"pl-k\">=</span> io.BytesIO(b)\nmodel2 <span class=\"pl-k\">=</span> torch.load(io)</pre></div>", "body_text": "For others, looks like using io.BytesIO gets up to about 1GB/s.\nIn [1]: from torchvision.models.resnet import resnet18\n   ...: model = resnet18(pretrained=True)\n   ...: \n   ...: \n\nIn [2]: import torch\n\nIn [3]: import io\n\nIn [4]: bio = io.BytesIO()\n\nIn [5]: %%time\n   ...: torch.save(model, bio)\n   ...: b = bio.getvalue()\n   ...: \nCPU times: user 32 ms, sys: 16.4 ms, total: 48.4 ms\nWall time: 47.7 ms\n\nIn [6]: len(b) / 0.047 / 1e6 # MB/s\nOut[6]: 996.619\nAnd then we can reconstitute\nio = io.BytesIO(b)\nmodel2 = torch.load(io)", "body": "For others, looks like using io.BytesIO gets up to about 1GB/s.\r\n\r\n```python\r\nIn [1]: from torchvision.models.resnet import resnet18\r\n   ...: model = resnet18(pretrained=True)\r\n   ...: \r\n   ...: \r\n\r\nIn [2]: import torch\r\n\r\nIn [3]: import io\r\n\r\nIn [4]: bio = io.BytesIO()\r\n\r\nIn [5]: %%time\r\n   ...: torch.save(model, bio)\r\n   ...: b = bio.getvalue()\r\n   ...: \r\nCPU times: user 32 ms, sys: 16.4 ms, total: 48.4 ms\r\nWall time: 47.7 ms\r\n\r\nIn [6]: len(b) / 0.047 / 1e6 # MB/s\r\nOut[6]: 996.619\r\n```\r\n\r\nAnd then we can reconstitute \r\n\r\n```python\r\nio = io.BytesIO(b)\r\nmodel2 = torch.load(io)\r\n```"}