{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/129696369", "pull_request_review_id": 52497924, "id": 129696369, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyOTY5NjM2OQ==", "diff_hunk": "@@ -26,80 +26,75 @@ namespace {\n \n namespace torch { namespace autograd {\n \n-using thpp::Tensor;\n-\n #ifndef CUDNN_BN_MIN_EPSILON\n #define CUDNN_BN_MIN_EPSILON 0\n #endif\n \n auto BatchNormForward::apply(const variable_list& inputs) -> variable_list {\n   check_input_variables(\"BatchNorm\", inputs, 3, 1);\n-  \n+\n   auto& input = inputs[0];\n   auto& weight = inputs[1];\n   auto& bias = inputs[2];\n-  AutoGPU guard(input->data->getDevice());\n-   \n-  auto num_features = input->data->rawSizes()[1];\n-  check_dims_match_num_input_features(\"running_mean\", num_features, running_mean->numel());\n-  check_dims_match_num_input_features(\"running_var\", num_features, running_var->numel());\n+  AutoGPU guard(input->data.type().isCuda() ? input->data.get_device() : -1);\n+\n+  auto num_features = input->data.sizes()[1];\n+  check_dims_match_num_input_features(\"running_mean\", num_features, running_mean.numel());\n+  check_dims_match_num_input_features(\"running_var\", num_features, running_var.numel());\n   if (weight){\n-    check_dims_match_num_input_features(\"weight\", num_features, weight->data->numel());\n+    check_dims_match_num_input_features(\"weight\", num_features, weight->data.numel());\n   }\n   if (bias){\n-    check_dims_match_num_input_features(\"bias\", num_features, bias->data->numel());\n+    check_dims_match_num_input_features(\"bias\", num_features, bias->data.numel());\n   }\n \n   bool use_cudnn = false;\n #ifdef WITH_CUDNN\n-  use_cudnn = (input->data->isCuda()\n-               && input->data->type() != thpp::Type::HALF\n+  use_cudnn = (input->data.type().isCuda()\n+               && input->data.type().scalarType() != at::kHalf\n                && weight && bias\n                && cudnn_enabled && CUDNN_VERSION >= 5110L);\n #endif\n \n-  auto output = input->data->newTensor();\n-  output->resizeAs(*input->data);\n-\n-  std::unique_ptr<Tensor> save_mean(output->newTensor());\n-  save_mean->resizeAs(*running_mean);\n-  std::unique_ptr<Tensor> save_std(output->newTensor());\n-  save_std->resizeAs(*running_var);\n+  auto output = input->data.type().tensor(input->data.sizes());\n+  auto save_mean = running_mean.type().tensor(running_mean.sizes());\n+  auto save_std = running_var.type().tensor(running_var.sizes());\n \n   if (use_cudnn && eps >= CUDNN_BN_MIN_EPSILON) {\n #ifdef WITH_CUDNN\n     torch::cudnn::cudnn_batch_norm_forward(\n         state,\n         torch::cudnn::getCudnnHandle(),\n-        torch::cudnn::getCudnnDataType(*input->data),\n-        (THVoidTensor*)input->data->cdata(),\n-        (THVoidTensor*)output->cdata(),\n-        (THVoidTensor*)weight->data->cdata(),\n-        (THVoidTensor*)bias->data->cdata(),\n-        (THVoidTensor*)running_mean->cdata(),\n-        (THVoidTensor*)running_var->cdata(),\n-        (THVoidTensor*)save_mean->cdata(),\n-        (THVoidTensor*)save_std->cdata(),\n+        torch::cudnn::getCudnnDataType(input->data),\n+        (THVoidTensor*)input->data.unsafeGetTH(false),\n+        (THVoidTensor*)output.unsafeGetTH(false),\n+        (THVoidTensor*)weight->data.unsafeGetTH(false),\n+        (THVoidTensor*)bias->data.unsafeGetTH(false),\n+        (THVoidTensor*)running_mean.unsafeGetTH(false),\n+        (THVoidTensor*)running_var.unsafeGetTH(false),\n+        (THVoidTensor*)save_mean.unsafeGetTH(false),\n+        (THVoidTensor*)save_std.unsafeGetTH(false),\n         training,\n         momentum,\n         eps);\n #endif\n   } else {\n-    torch::nn::BatchNormalization_updateOutput(\n-        input->data.get(),\n-        output.get(),\n-        weight ? weight->data.get() : nullptr,\n-        bias ? bias->data.get() : nullptr,\n-        running_mean.get(),\n-        running_var.get(),\n-        save_mean.get(),\n-        save_std.get(),\n+      at::Tensor nt;\n+      at::BatchNormalization_updateOutput(\n+        input->data,\n+        output,\n+        weight ? weight->data : nt,\n+        bias ? bias->data : nt,\n+        running_mean,\n+        running_var,\n+        save_mean,\n+        save_std,\n         training,\n         momentum,\n         eps);\n   }\n \n-  auto outputs = as_tensor_list(std::move(output));\n+  auto outputs = as_tensor_list(output);", "path": "torch/csrc/autograd/functions/batch_normalization.cpp", "position": null, "original_position": 110, "commit_id": "3e4ce988241e01c50eab59c73f4faf030c749470", "original_commit_id": "f919a2177922fd13b457a738d1bc91f6cb53474a", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "you probably want to keep `std::move` just for efficiency (there's an unnecessary retain + free otherwise) ", "created_at": "2017-07-26T21:06:50Z", "updated_at": "2018-11-23T15:34:16Z", "html_url": "https://github.com/pytorch/pytorch/pull/2170#discussion_r129696369", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2170", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/129696369"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2170#discussion_r129696369"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2170"}}, "body_html": "<p>you probably want to keep <code>std::move</code> just for efficiency (there's an unnecessary retain + free otherwise)</p>", "body_text": "you probably want to keep std::move just for efficiency (there's an unnecessary retain + free otherwise)"}