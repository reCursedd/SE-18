{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/129757302", "pull_request_review_id": 52561489, "id": 129757302, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyOTc1NzMwMg==", "diff_hunk": "@@ -33,7 +34,10 @@ std::unique_ptr<Storage> ${Type}::storageFromBlob(void * data, int64_t size) {\n     return std::unique_ptr<Storage>(\n       new ${Storage}(context,data,size));\n }\n-Tensor ${Type}::unsafeTensorFromTH(void * th_pointer) {\n+// Calls retain on th_pointer\n+Tensor ${Type}::unsafeTensorFromTH(void * th_pointer, bool retain) {\n+  if (retain)\n+    ${THTensor}_retain(${state,} (${THTensor}*) th_pointer);\n   return Tensor(new ${Tensor}(context,(${THTensor}*)(th_pointer)));", "path": "torch/lib/ATen/templates/TypeDerived.cpp", "position": null, "original_position": 26, "commit_id": "3e4ce988241e01c50eab59c73f4faf030c749470", "original_commit_id": "f919a2177922fd13b457a738d1bc91f6cb53474a", "user": {"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, "body": "This is where a memory leak is happening. Should be `return Tensor(new ${Tensor}(context,(${THTensor}*)(th_pointer)),false);`. The `false` ensures Tensor doesn't bump the refcount of the thing that was just allocated. This is fixed in aten/master and pytorch master, I am just pointing it out here so that when you merge them in you know what to look for.", "created_at": "2017-07-27T05:41:38Z", "updated_at": "2018-11-23T15:34:16Z", "html_url": "https://github.com/pytorch/pytorch/pull/2170#discussion_r129757302", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2170", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/129757302"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2170#discussion_r129757302"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2170"}}, "body_html": "<p>This is where a memory leak is happening. Should be <code>return Tensor(new ${Tensor}(context,(${THTensor}*)(th_pointer)),false);</code>. The <code>false</code> ensures Tensor doesn't bump the refcount of the thing that was just allocated. This is fixed in aten/master and pytorch master, I am just pointing it out here so that when you merge them in you know what to look for.</p>", "body_text": "This is where a memory leak is happening. Should be return Tensor(new ${Tensor}(context,(${THTensor}*)(th_pointer)),false);. The false ensures Tensor doesn't bump the refcount of the thing that was just allocated. This is fixed in aten/master and pytorch master, I am just pointing it out here so that when you merge them in you know what to look for."}