{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12563", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12563/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12563/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12563/events", "html_url": "https://github.com/pytorch/pytorch/issues/12563", "id": 369043442, "node_id": "MDU6SXNzdWUzNjkwNDM0NDI=", "number": 12563, "title": "Does Torch Script support GPU inference?", "user": {"login": "junjin8433", "id": 15881885, "node_id": "MDQ6VXNlcjE1ODgxODg1", "avatar_url": "https://avatars1.githubusercontent.com/u/15881885?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junjin8433", "html_url": "https://github.com/junjin8433", "followers_url": "https://api.github.com/users/junjin8433/followers", "following_url": "https://api.github.com/users/junjin8433/following{/other_user}", "gists_url": "https://api.github.com/users/junjin8433/gists{/gist_id}", "starred_url": "https://api.github.com/users/junjin8433/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junjin8433/subscriptions", "organizations_url": "https://api.github.com/users/junjin8433/orgs", "repos_url": "https://api.github.com/users/junjin8433/repos", "events_url": "https://api.github.com/users/junjin8433/events{/privacy}", "received_events_url": "https://api.github.com/users/junjin8433/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-11T09:58:13Z", "updated_at": "2018-10-16T15:57:46Z", "closed_at": "2018-10-11T18:04:45Z", "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"question\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/2753.png\">\u2753</g-emoji> Does Torch Script support GPU inference</h2>\n<h3>When using the new featured torch script vis tracing (torch.jit.trace), I found that no matter where the model was, it will be loaded onto the CPU. Thus, I'm wondering whether the gpu inference is supported, if yes, how can I put the loaded model onto GPU?</h3>\n<p>I found the 'DANGER' in the description of torch.jit.load, which says:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/15881885/46796051-3abf7780-cd7e-11e8-93ec-fc59a65fc759.png\"><img src=\"https://user-images.githubusercontent.com/15881885/46796051-3abf7780-cd7e-11e8-93ec-fc59a65fc759.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>", "body_text": "\u2753 Does Torch Script support GPU inference\nWhen using the new featured torch script vis tracing (torch.jit.trace), I found that no matter where the model was, it will be loaded onto the CPU. Thus, I'm wondering whether the gpu inference is supported, if yes, how can I put the loaded model onto GPU?\nI found the 'DANGER' in the description of torch.jit.load, which says:", "body": "## \u2753 Does Torch Script support GPU inference\r\n\r\n### When using the new featured torch script vis tracing (torch.jit.trace), I found that no matter where the model was, it will be loaded onto the CPU. Thus, I'm wondering whether the gpu inference is supported, if yes, how can I put the loaded model onto GPU?\r\n\r\nI found the 'DANGER' in the description of torch.jit.load, which says: \r\n\r\n![image](https://user-images.githubusercontent.com/15881885/46796051-3abf7780-cd7e-11e8-93ec-fc59a65fc759.png)\r\n\r\n"}