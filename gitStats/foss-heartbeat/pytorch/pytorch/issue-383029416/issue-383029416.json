{"url": "https://api.github.com/repos/pytorch/pytorch/issues/14270", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/14270/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/14270/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/14270/events", "html_url": "https://github.com/pytorch/pytorch/issues/14270", "id": 383029416, "node_id": "MDU6SXNzdWUzODMwMjk0MTY=", "number": 14270, "title": "Pytorch C++ API with cuda : Expected object of backend CPU but got backend CUDA for sequence element 1 in sequence argument at position #1 'tensors' ", "user": {"login": "IcewineChen", "id": 23411315, "node_id": "MDQ6VXNlcjIzNDExMzE1", "avatar_url": "https://avatars1.githubusercontent.com/u/23411315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IcewineChen", "html_url": "https://github.com/IcewineChen", "followers_url": "https://api.github.com/users/IcewineChen/followers", "following_url": "https://api.github.com/users/IcewineChen/following{/other_user}", "gists_url": "https://api.github.com/users/IcewineChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/IcewineChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IcewineChen/subscriptions", "organizations_url": "https://api.github.com/users/IcewineChen/orgs", "repos_url": "https://api.github.com/users/IcewineChen/repos", "events_url": "https://api.github.com/users/IcewineChen/events{/privacy}", "received_events_url": "https://api.github.com/users/IcewineChen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-21T09:34:03Z", "updated_at": "2018-11-21T09:34:03Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2><g-emoji class=\"g-emoji\" alias=\"bug\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f41b.png\">\ud83d\udc1b</g-emoji> Bug</h2>\n<p>Thanks for your teams' great work! But during using the C++ API of pytorch on gpu, there are some confusing bugs. When I try to load a .pt file as module and then do a forward operator, I got an exception.</p>\n<h2>To Reproduce</h2>\n<p>Here are my code and exception, the .pt file is generated by torch.jit.trace(model, example).cuda()</p>\n<p>my code:</p>\n<pre><code>std::shared_ptr&lt;torch::jit::script::Module&gt; module = torch::jit::load(\"my_model_path.pt\"); \nmodule-&gt;to(torch::kCUDA);\nstd::vector&lt;torch::jit::IValue&gt; inputs;\ninputs.push_back(torch::ones({model_input_size}).cuda())\nauto output = module-&gt;forward(inputs).toTensor();\n</code></pre>\n<p>the state of variable:<br>\nI'have checked the tensor that be pushed to inputs vector is Variable[CUDAFloatType], and the model.pt is generated on cuda.</p>\n<p>Exception:<br>\nterminate called after throwing an instance of 'c10::Error'<br>\nwhat():  Expected object of backend CPU but got backend CUDA for sequence element 1 in sequence argument at position <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a> 'tensors' (checked_tensor_list_unwrap at /pytorch/aten/src/ATen/Utils.h:87)<br>\nframe #0: std::function&lt;std::string ()&gt;::operator()() const + 0x11 (0x7fd638cc1ba1 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171281708\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1\">#1</a>: c10::Error::Error(c10::SourceLocation, std::string const&amp;) + 0x2a (0x7fd638cc146a in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171402941\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/2/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/2\">#2</a>:  + 0x7b22d8 (0x7fd65adf72d8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171485123\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/3\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/3/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/3\">#3</a>:  + 0x7b29bc (0x7fd65adf79bc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171522963\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/4/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/4\">#4</a>: at::native::cat(c10::ArrayRefat::Tensor, long) + 0xa4 (0x7fd65ad09624 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"173498149\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/5/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/5\">#5</a>: at::TypeDefault::cat(c10::ArrayRefat::Tensor, long) const + 0x4f (0x7fd65aed7cff in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174289461\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/6/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/6\">#6</a>: torch::autograd::VariableType::cat(c10::ArrayRefat::Tensor, long) const + 0x1bc (0x7fd6699d5cdc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174818921\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/7/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/7\">#7</a>:  + 0x52b2a8 (0x7fd669b022a8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"174871471\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/8\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/8/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/8\">#8</a>: torch::jit::ConstantPropagation(torch::jit::Node*, bool) + 0x450 (0x7fd669c06c30 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175537036\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/9\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/9/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/9\">#9</a>: torch::jit::ConstantPropagation(torch::jit::Block*, bool) + 0x44 (0x7fd669c07a14 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175552272\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/10\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/10/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/10\">#10</a>: torch::jit::ConstantPropagation(std::shared_ptrtorch::jit::Graph&amp;) + 0x18 (0x7fd669c07b18 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175559413\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/11\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/11/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/11\">#11</a>:  + 0x5d39a0 (0x7fd669baa9a0 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175559558\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/12\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/12/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/12\">#12</a>: torch::jit::GraphExecutor::run(std::vector&lt;c10::IValue, std::allocatorc10::IValue &gt;&amp;) + 0x19d (0x7fd669bab2cd in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175567843\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/13\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/13/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/13\">#13</a>: torch::jit::script::Method::run(std::vector&lt;c10::IValue, std::allocatorc10::IValue &gt;&amp;) + 0xb4 (0x456096 in ./action)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175574237\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/14\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/14/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/14\">#14</a>: torch::jit::script::Method::operator()(std::vector&lt;c10::IValue, std::allocatorc10::IValue &gt;) + 0x4a (0x4560f8 in ./action)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175627398\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/15\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/15/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/15\">#15</a>: torch::jit::script::Module::forward(std::vector&lt;c10::IValue, std::allocatorc10::IValue &gt;) + 0x81 (0x456f8f in ./action)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175834985\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/16\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/16/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/16\">#16</a>: main + 0x550 (0x4538df in ./action)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175835445\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/17\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/17/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/17\">#17</a>: __libc_start_main + 0xf0 (0x7fd6380b2830 in /lib/x86_64-linux-gnu/libc.so.6)<br>\nframe <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"176034421\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/18\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/18/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/18\">#18</a>: _start + 0x29 (0x43e0f9 in ./action)</p>\n<p>[1]    35218 abort (core dumped)</p>\n<p>I have read the source code and find that the construct function of module-&gt;forward() only accept vector type. But the vector type can't match the check by the tensor lib. Could you give me some advice and help about how to change the vector type match the check by ATen? Thank you very much.</p>\n<h2>Environment</h2>\n<ul>\n<li>PyTorch Version (e.g., 1.0): 1.0</li>\n<li>OS (e.g., Linux): ubuntu 16.04</li>\n<li>How you installed PyTorch (<code>conda</code>, <code>pip</code>, source): conda</li>\n<li>Build command you used (if compiling from source): following the guide on official page</li>\n<li>Python version:3.6</li>\n<li>CUDA/cuDNN version: cuda 8.0 + cudnn6.0</li>\n<li>GPU models and configuration:</li>\n<li>Any other relevant information:</li>\n</ul>", "body_text": "\ud83d\udc1b Bug\nThanks for your teams' great work! But during using the C++ API of pytorch on gpu, there are some confusing bugs. When I try to load a .pt file as module and then do a forward operator, I got an exception.\nTo Reproduce\nHere are my code and exception, the .pt file is generated by torch.jit.trace(model, example).cuda()\nmy code:\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(\"my_model_path.pt\"); \nmodule->to(torch::kCUDA);\nstd::vector<torch::jit::IValue> inputs;\ninputs.push_back(torch::ones({model_input_size}).cuda())\nauto output = module->forward(inputs).toTensor();\n\nthe state of variable:\nI'have checked the tensor that be pushed to inputs vector is Variable[CUDAFloatType], and the model.pt is generated on cuda.\nException:\nterminate called after throwing an instance of 'c10::Error'\nwhat():  Expected object of backend CPU but got backend CUDA for sequence element 1 in sequence argument at position #1 'tensors' (checked_tensor_list_unwrap at /pytorch/aten/src/ATen/Utils.h:87)\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fd638cc1ba1 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)\nframe #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7fd638cc146a in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)\nframe #2:  + 0x7b22d8 (0x7fd65adf72d8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\nframe #3:  + 0x7b29bc (0x7fd65adf79bc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\nframe #4: at::native::cat(c10::ArrayRefat::Tensor, long) + 0xa4 (0x7fd65ad09624 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\nframe #5: at::TypeDefault::cat(c10::ArrayRefat::Tensor, long) const + 0x4f (0x7fd65aed7cff in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\nframe #6: torch::autograd::VariableType::cat(c10::ArrayRefat::Tensor, long) const + 0x1bc (0x7fd6699d5cdc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #7:  + 0x52b2a8 (0x7fd669b022a8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #8: torch::jit::ConstantPropagation(torch::jit::Node*, bool) + 0x450 (0x7fd669c06c30 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #9: torch::jit::ConstantPropagation(torch::jit::Block*, bool) + 0x44 (0x7fd669c07a14 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #10: torch::jit::ConstantPropagation(std::shared_ptrtorch::jit::Graph&) + 0x18 (0x7fd669c07b18 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #11:  + 0x5d39a0 (0x7fd669baa9a0 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #12: torch::jit::GraphExecutor::run(std::vector<c10::IValue, std::allocatorc10::IValue >&) + 0x19d (0x7fd669bab2cd in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\nframe #13: torch::jit::script::Method::run(std::vector<c10::IValue, std::allocatorc10::IValue >&) + 0xb4 (0x456096 in ./action)\nframe #14: torch::jit::script::Method::operator()(std::vector<c10::IValue, std::allocatorc10::IValue >) + 0x4a (0x4560f8 in ./action)\nframe #15: torch::jit::script::Module::forward(std::vector<c10::IValue, std::allocatorc10::IValue >) + 0x81 (0x456f8f in ./action)\nframe #16: main + 0x550 (0x4538df in ./action)\nframe #17: __libc_start_main + 0xf0 (0x7fd6380b2830 in /lib/x86_64-linux-gnu/libc.so.6)\nframe #18: _start + 0x29 (0x43e0f9 in ./action)\n[1]    35218 abort (core dumped)\nI have read the source code and find that the construct function of module->forward() only accept vector type. But the vector type can't match the check by the tensor lib. Could you give me some advice and help about how to change the vector type match the check by ATen? Thank you very much.\nEnvironment\n\nPyTorch Version (e.g., 1.0): 1.0\nOS (e.g., Linux): ubuntu 16.04\nHow you installed PyTorch (conda, pip, source): conda\nBuild command you used (if compiling from source): following the guide on official page\nPython version:3.6\nCUDA/cuDNN version: cuda 8.0 + cudnn6.0\nGPU models and configuration:\nAny other relevant information:", "body": "## \ud83d\udc1b Bug\r\n\r\nThanks for your teams' great work! But during using the C++ API of pytorch on gpu, there are some confusing bugs. When I try to load a .pt file as module and then do a forward operator, I got an exception.\r\n\r\n## To Reproduce\r\nHere are my code and exception, the .pt file is generated by torch.jit.trace(model, example).cuda()\r\n\r\nmy code:\r\n```\r\nstd::shared_ptr<torch::jit::script::Module> module = torch::jit::load(\"my_model_path.pt\"); \r\nmodule->to(torch::kCUDA);\r\nstd::vector<torch::jit::IValue> inputs;\r\ninputs.push_back(torch::ones({model_input_size}).cuda())\r\nauto output = module->forward(inputs).toTensor();\r\n```\r\n\r\nthe state of variable:\r\nI'have checked the tensor that be pushed to inputs vector is Variable[CUDAFloatType], and the model.pt is generated on cuda. \r\n\r\nException: \r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  Expected object of backend CPU but got backend CUDA for sequence element 1 in sequence argument at position #1 'tensors' (checked_tensor_list_unwrap at /pytorch/aten/src/ATen/Utils.h:87)\r\nframe #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fd638cc1ba1 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)\r\nframe #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7fd638cc146a in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x7b22d8 (0x7fd65adf72d8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\r\nframe #3: <unknown function> + 0x7b29bc (0x7fd65adf79bc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\r\nframe #4: at::native::cat(c10::ArrayRef<at::Tensor>, long) + 0xa4 (0x7fd65ad09624 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\r\nframe #5: at::TypeDefault::cat(c10::ArrayRef<at::Tensor>, long) const + 0x4f (0x7fd65aed7cff in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libcaffe2.so)\r\nframe #6: torch::autograd::VariableType::cat(c10::ArrayRef<at::Tensor>, long) const + 0x1bc (0x7fd6699d5cdc in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #7: <unknown function> + 0x52b2a8 (0x7fd669b022a8 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #8: torch::jit::ConstantPropagation(torch::jit::Node*, bool) + 0x450 (0x7fd669c06c30 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #9: torch::jit::ConstantPropagation(torch::jit::Block*, bool) + 0x44 (0x7fd669c07a14 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #10: torch::jit::ConstantPropagation(std::shared_ptr<torch::jit::Graph>&) + 0x18 (0x7fd669c07b18 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #11: <unknown function> + 0x5d39a0 (0x7fd669baa9a0 in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #12: torch::jit::GraphExecutor::run(std::vector<c10::IValue, std::allocator<c10::IValue> >&) + 0x19d (0x7fd669bab2cd in /home/chr/action-sdk/libs/libtorch-latest-gpu/libtorch-gpu/libtorch/lib/libtorch.so.1)\r\nframe #13: torch::jit::script::Method::run(std::vector<c10::IValue, std::allocator<c10::IValue> >&) + 0xb4 (0x456096 in ./action)\r\nframe #14: torch::jit::script::Method::operator()(std::vector<c10::IValue, std::allocator<c10::IValue> >) + 0x4a (0x4560f8 in ./action)\r\nframe #15: torch::jit::script::Module::forward(std::vector<c10::IValue, std::allocator<c10::IValue> >) + 0x81 (0x456f8f in ./action)\r\nframe #16: main + 0x550 (0x4538df in ./action)\r\nframe #17: __libc_start_main + 0xf0 (0x7fd6380b2830 in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #18: _start + 0x29 (0x43e0f9 in ./action)\r\n\r\n[1]    35218 abort (core dumped)\r\n\r\nI have read the source code and find that the construct function of module->forward() only accept vector type. But the vector type can't match the check by the tensor lib. Could you give me some advice and help about how to change the vector type match the check by ATen? Thank you very much.\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.0\r\n - OS (e.g., Linux): ubuntu 16.04\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Build command you used (if compiling from source): following the guide on official page\r\n - Python version:3.6\r\n - CUDA/cuDNN version: cuda 8.0 + cudnn6.0\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n\r\n"}