{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/376032162", "html_url": "https://github.com/pytorch/pytorch/pull/5997#issuecomment-376032162", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5997", "id": 376032162, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NjAzMjE2Mg==", "user": {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-26T02:53:16Z", "updated_at": "2018-03-26T02:53:16Z", "author_association": "CONTRIBUTOR", "body_html": "<p>open questions:</p>\n<ol>\n<li>Should we treat python floats as doubles (as numpy does), or as the default scalar dtype (which will usually be float)?</li>\n<li>Should we do device-type inference from the default dtype?  That is, if the default dtype is a cuda type, should torch.tensor(0), torch.tensor(0.) create cuda tensors?  (This is moot if we separate out device type from dtype, which we may do)</li>\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1762463\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/neerajprad\">@neerajprad</a> I had to make a number of changes to distributions to get it to pass;  basically, tensors are treated as is (so many needed to be passed floats instead of ints in the tests), but numbers are transformed into default dtype tensors by broadcast_all; this seems convenient, but leads to <code>Distribution(0)</code> behaving differently than <code>Distribution(torch.tensor(0))</code> (you would need <code>Distributions(torch.tensor(0.))</code> to get the same effect.  Let me know if you think this is reasonable or prefer something else (like treating numbers as torch.tensor does, so we'd have to change the tests to be something like <code>Distribution(0.)</code>.</li>\n</ol>", "body_text": "open questions:\n\nShould we treat python floats as doubles (as numpy does), or as the default scalar dtype (which will usually be float)?\nShould we do device-type inference from the default dtype?  That is, if the default dtype is a cuda type, should torch.tensor(0), torch.tensor(0.) create cuda tensors?  (This is moot if we separate out device type from dtype, which we may do)\n@fritzo @neerajprad I had to make a number of changes to distributions to get it to pass;  basically, tensors are treated as is (so many needed to be passed floats instead of ints in the tests), but numbers are transformed into default dtype tensors by broadcast_all; this seems convenient, but leads to Distribution(0) behaving differently than Distribution(torch.tensor(0)) (you would need Distributions(torch.tensor(0.)) to get the same effect.  Let me know if you think this is reasonable or prefer something else (like treating numbers as torch.tensor does, so we'd have to change the tests to be something like Distribution(0.).", "body": "open questions:\r\n\r\n1.  Should we treat python floats as doubles (as numpy does), or as the default scalar dtype (which will usually be float)?\r\n2.  Should we do device-type inference from the default dtype?  That is, if the default dtype is a cuda type, should torch.tensor(0), torch.tensor(0.) create cuda tensors?  (This is moot if we separate out device type from dtype, which we may do)\r\n3.  @fritzo @neerajprad I had to make a number of changes to distributions to get it to pass;  basically, tensors are treated as is (so many needed to be passed floats instead of ints in the tests), but numbers are transformed into default dtype tensors by broadcast_all; this seems convenient, but leads to `Distribution(0)` behaving differently than `Distribution(torch.tensor(0))` (you would need `Distributions(torch.tensor(0.))` to get the same effect.  Let me know if you think this is reasonable or prefer something else (like treating numbers as torch.tensor does, so we'd have to change the tests to be something like `Distribution(0.)`."}