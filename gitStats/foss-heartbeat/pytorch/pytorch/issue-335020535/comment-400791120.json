{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/400791120", "html_url": "https://github.com/pytorch/pytorch/issues/8805#issuecomment-400791120", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8805", "id": 400791120, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMDc5MTEyMA==", "user": {"login": "yf225", "id": 4063635, "node_id": "MDQ6VXNlcjQwNjM2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4063635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yf225", "html_url": "https://github.com/yf225", "followers_url": "https://api.github.com/users/yf225/followers", "following_url": "https://api.github.com/users/yf225/following{/other_user}", "gists_url": "https://api.github.com/users/yf225/gists{/gist_id}", "starred_url": "https://api.github.com/users/yf225/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yf225/subscriptions", "organizations_url": "https://api.github.com/users/yf225/orgs", "repos_url": "https://api.github.com/users/yf225/repos", "events_url": "https://api.github.com/users/yf225/events{/privacy}", "received_events_url": "https://api.github.com/users/yf225/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-27T18:51:35Z", "updated_at": "2018-06-27T18:51:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2501383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/warmspringwinds\">@warmspringwinds</a> According to the Python doc (<a href=\"https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.terminate\" rel=\"nofollow\">https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.terminate</a>), subprocesses of the spawned process will not be terminated, and they will simply become orphaned. This can explain why gpu memory wasn't released in the dataloader worker processes.</p>\n<p>The change in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"314351529\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/6606\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/6606/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/6606\">#6606</a> acts as a failsafe and will terminate the worker processes in all scenarios (with or without signal propagation between parent and workers).</p>", "body_text": "@warmspringwinds According to the Python doc (https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.terminate), subprocesses of the spawned process will not be terminated, and they will simply become orphaned. This can explain why gpu memory wasn't released in the dataloader worker processes.\nThe change in #6606 acts as a failsafe and will terminate the worker processes in all scenarios (with or without signal propagation between parent and workers).", "body": "@warmspringwinds According to the Python doc (https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.terminate), subprocesses of the spawned process will not be terminated, and they will simply become orphaned. This can explain why gpu memory wasn't released in the dataloader worker processes.\r\n\r\nThe change in https://github.com/pytorch/pytorch/pull/6606 acts as a failsafe and will terminate the worker processes in all scenarios (with or without signal propagation between parent and workers)."}