{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/419498364", "html_url": "https://github.com/pytorch/pytorch/pull/11341#issuecomment-419498364", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/11341", "id": 419498364, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTQ5ODM2NA==", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-07T16:44:02Z", "updated_at": "2018-09-07T16:44:02Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>Calling .contiguous() will probably not satisfy the objective of this PR, because of the fact that .contiguous() creates a contiguous copy of the tensor, meaning more memory allocation, which is not intended if I understand correctly.</p>\n</blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23639302\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vishwakftw\">@vishwakftw</a> - We can support <code>Distribution.expand</code> by either reusing existing params or creating new ones altogether (even this should be faster than going through <strong>init</strong>), though it is preferable to not allocate additional memory whenever possible. <code>.contiguous()</code> will do exactly that - it will not create a new copy if the existing one is already contiguous. In many applications, memory may not be an issue, but the higher time taken to draw or score samples from expanded instances might be (specially as it completely avoidable). e.g. if we expand an instance and are calling <code>.sample</code> multiple times. In such cases, the overhead of using non contiguous parameters is high enough that it is better to pay a one time cost of calling <code>.contiguous</code>. I am happy to defer this to a separate PR / discuss in another issue though.</p>", "body_text": "Calling .contiguous() will probably not satisfy the objective of this PR, because of the fact that .contiguous() creates a contiguous copy of the tensor, meaning more memory allocation, which is not intended if I understand correctly.\n\n@vishwakftw - We can support Distribution.expand by either reusing existing params or creating new ones altogether (even this should be faster than going through init), though it is preferable to not allocate additional memory whenever possible. .contiguous() will do exactly that - it will not create a new copy if the existing one is already contiguous. In many applications, memory may not be an issue, but the higher time taken to draw or score samples from expanded instances might be (specially as it completely avoidable). e.g. if we expand an instance and are calling .sample multiple times. In such cases, the overhead of using non contiguous parameters is high enough that it is better to pay a one time cost of calling .contiguous. I am happy to defer this to a separate PR / discuss in another issue though.", "body": ">  Calling .contiguous() will probably not satisfy the objective of this PR, because of the fact that .contiguous() creates a contiguous copy of the tensor, meaning more memory allocation, which is not intended if I understand correctly.\r\n\r\n@vishwakftw - We can support `Distribution.expand` by either reusing existing params or creating new ones altogether (even this should be faster than going through __init__), though it is preferable to not allocate additional memory whenever possible. `.contiguous()` will do exactly that - it will not create a new copy if the existing one is already contiguous. In many applications, memory may not be an issue, but the higher time taken to draw or score samples from expanded instances might be (specially as it completely avoidable). e.g. if we expand an instance and are calling `.sample` multiple times. In such cases, the overhead of using non contiguous parameters is high enough that it is better to pay a one time cost of calling `.contiguous`. I am happy to defer this to a separate PR / discuss in another issue though."}