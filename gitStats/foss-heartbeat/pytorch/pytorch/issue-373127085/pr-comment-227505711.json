{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227505711", "pull_request_review_id": 167560635, "id": 227505711, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzUwNTcxMQ==", "diff_hunk": "@@ -119,135 +134,202 @@ class PyTorchStreamReader {\n     auto ptr = malloc(size);\n     at::DataPtr retval(ptr, ptr, free, at::kCPU);\n \n-    in.read((char*)ptr, size);\n-    cursor += size;\n+    in_.read((char*)ptr, size);\n+    cursor_ += size;\n     seekToNextAlignmentBoundary();\n     return std::tuple<at::DataPtr, size_t>(std::move(retval), size);\n   }\n+\n+  // return dataptr, key, size\n+  std::tuple<at::DataPtr, int64_t, int64_t> getNextRecord() {\n+    int64_t key = cursor_;\n+    if (!hasNextRecord()) {\n+      throw std::runtime_error(\"No more record, but hasNextRecord is called.\");\n+    }\n+    auto tag = read64BitIntegerLittleEndian();\n+    if (tag != RecordTags::STORAGE) {\n+      throw std::runtime_error(\n+          \"Attempted to read a record of non-storage type\");\n+    }\n+    auto size = read64BitIntegerLittleEndian();\n+    seekToNextAlignmentBoundary();\n+    auto ptr = malloc(size);\n+    at::DataPtr retval(ptr, ptr, free, at::kCPU);\n+\n+    in_.read((char*)ptr, size);\n+    cursor_ += size;\n+    seekToNextAlignmentBoundary();\n+    return std::tuple<at::DataPtr, int64_t, int64_t>(\n+        std::move(retval), key, size);\n+  }\n+\n+  bool hasNextRecord() {\n+    if (cursor_ + kFieldAlignment * 2 < file_size_) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  bool close() {\n+    if (closed_) {\n+      return false;\n+    }\n+    closed_ = true;\n+    return true;\n+  }\n+\n+  bool closed() {\n+    return closed_;\n+  }\n+\n   ~PyTorchStreamReader() {\n   }\n+\n  private:\n-  std::istream& in;\n-  size_t cursor = 0;\n-  size_t file_size;\n-  size_t last_record_offset;\n+  std::istream& in_;\n+  size_t cursor_ = 0;\n+  size_t file_size_;\n+  size_t last_record_offset_;\n+  bool closed_ = false;\n \n   // Utility functions\n   uint64_t read64BitIntegerLittleEndian() {\n-   uint64_t retval;\n-   // TODO endian swap on platforms that need it?\n-   in.read(reinterpret_cast<char *>(&retval), 8);\n-   std::streamsize read_bytes = in.gcount();\n-   if (read_bytes != 8) {\n-     std::ostringstream errmsg;\n-     errmsg << \"Expected to read 8 bytes but got \" << read_bytes;\n-     throw std::runtime_error(errmsg.str());\n-   }\n-   cursor += read_bytes;\n-   return retval;\n+    uint64_t retval;\n+    // TODO endian swap on platforms that need it?\n+    in_.read(reinterpret_cast<char*>(&retval), 8);\n+    std::streamsize read_bytes = in_.gcount();\n+    if (read_bytes != 8) {\n+      std::ostringstream errmsg;\n+      errmsg << \"Expected to read 8 bytes but got \" << read_bytes;\n+      throw std::runtime_error(errmsg.str());\n+    }\n+    cursor_ += read_bytes;\n+    return retval;\n   }\n \n   void seekToNextAlignmentBoundary() {\n-   size_t next_offset = (cursor + kFieldAlignment) - (cursor % kFieldAlignment);\n-   size_t pad_amount = next_offset - cursor;\n-   cursor += pad_amount;\n-   in.seekg(cursor);\n+    size_t next_offset =\n+        (cursor_ + kFieldAlignment) - (cursor_ % kFieldAlignment);\n+    size_t pad_amount = next_offset - cursor_;\n+    cursor_ += pad_amount;\n+    in_.seekg(cursor_);\n   }\n \n   // File format deserialization functions\n-  void readAndValidateFileHeader() {\n-   // Validate magic number\n-   uint64_t magic = read64BitIntegerLittleEndian();\n-   if (magic != kFileMagicNumber) {\n-     throw std::runtime_error(\"Magic number mismatch in PyTorch file. File may\"\n-                              \" be corrupted or is not actually a PyTorch file.\");\n-   }\n-   uint64_t file_format_version = read64BitIntegerLittleEndian();\n-   if (file_format_version > kMaxSupportedFileFormatVersion) {\n-     std::ostringstream errmsg;\n-     errmsg << \"Attempted to read a PyTorch file with version \" << file_format_version\n-            << \" but the maximum supported version for reading is \" << kMaxSupportedFileFormatVersion\n-            << \". Your PyTorch installation may be too old.\";\n-     throw std::runtime_error(errmsg.str());\n-   }\n-   seekToNextAlignmentBoundary();\n-  }\n-  void readAndValidateFileFooter() {\n+  bool readAndValidateFileHeader() {\n+    // Validate magic number\n+    cursor_ = 0;\n+    in_.seekg(cursor_);\n+    uint64_t magic = read64BitIntegerLittleEndian();\n+    if (magic != kFileMagicNumber) {\n+      throw std::runtime_error(\n+          \"Magic number mismatch in PyTorch file. File may\"\n+          \" be corrupted or is not actually a PyTorch file.\");\n+    }\n+    uint64_t file_format_version = read64BitIntegerLittleEndian();\n+    if (file_format_version > kMaxSupportedFileFormatVersion) {\n+      std::ostringstream errmsg;\n+      errmsg << \"Attempted to read a PyTorch file with version \"\n+             << file_format_version\n+             << \" but the maximum supported version for reading is \"\n+             << kMaxSupportedFileFormatVersion\n+             << \". Your PyTorch installation may be too old.\";\n+      throw std::runtime_error(errmsg.str());\n+    }\n+    seekToNextAlignmentBoundary();\n+    return true;\n+  }\n+\n+  bool readAndValidateFileFooter() {\n     // Seek to location of file footer. We've already validated that the file\n     // length is a multiple of the alignment size\n-    cursor = file_size - kFieldAlignment;\n-    in.seekg(cursor);\n+    cursor_ = file_size_ - kFieldAlignment;\n+    in_.seekg(cursor_);\n     auto tag = read64BitIntegerLittleEndian();\n     if (tag != RecordTags::FOOTER) {\n       throw std::runtime_error(\"File footer has wrong record type. Is this\"\n                                \" file corrupted?\");\n     }\n-    last_record_offset = read64BitIntegerLittleEndian();\n-    if (last_record_offset > file_size) {\n+    last_record_offset_ = read64BitIntegerLittleEndian();\n+    if (last_record_offset_ > file_size_) {\n       throw std::runtime_error(\"Offset of last record is higher than the size\"\n                                \" of the file! Is this file corrupted?\");\n     }\n+    return true;\n   }\n };\n \n-class PyTorchStreamWriter {\n+class PyTorchStreamWriter final {\n  public:\n-  PyTorchStreamWriter(std::ostream& out_) : out(out_) {\n+  PyTorchStreamWriter(std::ostream& out) : out_(out) {\n     writeFileHeader();\n     // In the case that we do not write any records into this file, the last\n     // record index written into the footer will point to the footer itself.\n-    last_record_idx = cursor;\n+    last_record_idx_ = cursor_;\n   }\n+\n   uint64_t writeRecord(const char* data, size_t size) {\n-    JIT_ASSERT(!finalized);\n-    uint64_t record_offset = cursor;\n-    last_record_idx = record_offset;\n+    CAFFE_ENFORCE(!finalized_, \"should not be finalized!\");\n+    uint64_t record_offset = cursor_;\n+    last_record_idx_ = record_offset;\n     write64BitIntegerLittleEndian(RecordTags::STORAGE);\n     write64BitIntegerLittleEndian(size);\n     padToNextAlignmentBoundary();\n     writeBuffer(data, size);\n     padToNextAlignmentBoundary();\n     return record_offset;\n   }\n+\n   void writeEndOfFile() {\n-    JIT_ASSERT(!finalized);\n+    CAFFE_ENFORCE(!finalized_, \"cannot finalize again!\");\n     writeFileFooter();\n-    finalized = true;\n+    finalized_ = true;\n+  }\n+\n+  int64_t getCurrentSize() {\n+    return static_cast<int64_t>(cursor_);\n+  }\n+\n+  bool finalized() {", "path": "caffe2/serialize/inline_container.h", "position": null, "original_position": 318, "commit_id": "8beeb484bf4d149767c4ea9d1d376a4c3d0b7c3e", "original_commit_id": "ba909b162a712710d63e679d9ce71dcc7dc4ecb6", "user": {"login": "BIT-silence", "id": 3357667, "node_id": "MDQ6VXNlcjMzNTc2Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/3357667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BIT-silence", "html_url": "https://github.com/BIT-silence", "followers_url": "https://api.github.com/users/BIT-silence/followers", "following_url": "https://api.github.com/users/BIT-silence/following{/other_user}", "gists_url": "https://api.github.com/users/BIT-silence/gists{/gist_id}", "starred_url": "https://api.github.com/users/BIT-silence/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BIT-silence/subscriptions", "organizations_url": "https://api.github.com/users/BIT-silence/orgs", "repos_url": "https://api.github.com/users/BIT-silence/repos", "events_url": "https://api.github.com/users/BIT-silence/events{/privacy}", "received_events_url": "https://api.github.com/users/BIT-silence/received_events", "type": "User", "site_admin": false}, "body": "```suggestion\r\n  bool finalized() const {\r\n```", "created_at": "2018-10-23T18:10:17Z", "updated_at": "2018-11-23T15:53:26Z", "html_url": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227505711", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12993", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227505711"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227505711"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12993"}}, "body_html": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center text-gray\">\n        Suggested change <span class=\"d-inline-block lh-condensed px-1 rounded-1 border border-green\">Beta</span>\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by the pull request author or assignees.\">\n          <svg class=\"hide-sm octicon octicon-info\" viewBox=\"0 0 14 16\" version=\"1.1\" width=\"14\" height=\"16\">\n            <path fill-rule=\"evenodd\" d=\"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z\"></path>\n          </svg>\n        </span>\n      </div>\n      <div class=\"flex-auto text-right text-gray\">\n        <a href=\"https://www.research.net/r/SuggestedChanges\" target=\"_blank\">Give us feedback</a>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0\">\n        <tbody><tr class=\"border-0\">\n          <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n          <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">  <span class=\"pl-k\">bool</span> <span class=\"pl-en\">finalized</span>() {</td>\n        </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">  <span class=\"pl-k\">bool</span> <span class=\"pl-en\">finalized</span>() <span class=\"pl-k x x-first\">const</span><span class=\"x x-last\"> </span>{</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "body_text": "Suggested change Beta\n        \n          \n            \n          \n        \n      \n      \n        Give us feedback\n      \n    \n    \n      \n        \n          \n            bool finalized() {\n        \n          \n            \n              bool finalized() const {"}