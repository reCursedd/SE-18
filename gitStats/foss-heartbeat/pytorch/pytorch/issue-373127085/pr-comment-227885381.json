{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227885381", "pull_request_review_id": 168027792, "id": 227885381, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzg4NTM4MQ==", "diff_hunk": "@@ -59,195 +63,271 @@ namespace torch { namespace jit {\n //         been written. We place the variable-length index at the end and do\n //         not put any indicies into the header to fulfill this constraint.\n \n+// The serialized model, which contains all the metadata information,\n+// should be stored as the last record. Because the size of tensor data is\n+// usually stable. As long as the shape and type of the tensor do not change,\n+// the size of the data won't change. On the other sied, the size of the\n+// serialized model is likely to change, so we store it as the last record, and\n+// we don't need to move previous records when updating the model data.\n+\n namespace {\n-  struct RecordTags {\n-    enum {\n-      STORAGE = 1,\n-      FOOTER = 2,\n-    };\n-  };\n \n-  // Common constants\n-  static constexpr uint64_t kFileMagicNumber = 0x314843524f545950L; // PYTORCH1\n-  static constexpr uint64_t kFieldAlignment = 64L; // 64 byte alignment supports up to AVX512 for mmap\n+enum RecordTags {\n+  STORAGE = 1,\n+  FOOTER = 2,\n+};\n+\n+// Common constants\n+constexpr uint64_t kFileMagicNumber = 0x314843524f545950L; // PYTORCH1\n+constexpr uint64_t kFieldAlignment =\n+    64L; // 64 byte alignment supports up to AVX512 for mmap\n \n-  // Reader-specific constants\n-  static constexpr uint64_t kMaxSupportedFileFormatVersion = 0x1L;\n+// Reader-specific constants\n+constexpr uint64_t kMaxSupportedFileFormatVersion = 0x1L;\n \n-  // Writer-specific constants\n-  static constexpr uint64_t kFileFormatVersion = 0x1L;\n-  static constexpr uint8_t kPadValue = 0xEF;\n+// Writer-specific constants\n+constexpr uint64_t kFileFormatVersion = 0x1L;\n+constexpr char kPadValue = -17; // 0xEF\n \n }  // namespace\n \n-class PyTorchStreamReader {\n+class PyTorchStreamReader final {\n  public:\n-  PyTorchStreamReader(std::istream& in_) : in(in_) {\n+  PyTorchStreamReader(std::istream* in) : in_(in) {\n     // Store file size so we know when we're done reading because the f* APIs\n     // don't do a good job of that\n-    in.seekg(0L, in.end);\n-    file_size = in.tellg();\n-    in.seekg(0L);\n-    readAndValidateFileHeader();\n+    in_->seekg(0L, in_->end);\n+    file_size_ = in_->tellg();\n+    readAndValidateFileFooter();\n     // Do this now since we're reasonably sure this is actually a PyT file from\n     // the header.\n-    if (file_size % kFieldAlignment != 0) {\n-      throw std::runtime_error(\"File length is not a multiple of the alignment\"\n-                               \" size. Is this a valid PyTorch file?\");\n+    if (file_size_ % kFieldAlignment != 0) {\n+      throw std::runtime_error(\n+          \"File length is not a multiple of the alignment\"\n+          \" size. Is this a valid PyTorch model file?\");\n     }\n-    readAndValidateFileFooter();\n+    readAndValidateFileHeader();\n   }\n+\n   std::tuple<at::DataPtr, size_t> getLastRecord() {\n-    return getRecordWithKey(last_record_offset);\n+    return getRecordWithKey(last_record_offset_);\n   }\n+\n   std::tuple<at::DataPtr, size_t> getRecordWithKey(uint64_t key) {\n-    if (key + kFieldAlignment > file_size) {\n+    if (key + kFieldAlignment > file_size_) {\n       throw std::runtime_error(\"Provided key is larger than the size of the file.\");\n     }\n     if (key % kFieldAlignment != 0) {\n       throw std::runtime_error(\"Provided key is not divisible by the alignment size.\");\n     }\n     // Seek to the provided offset\n-    cursor = key;\n-    in.seekg(cursor);\n+    cursor_ = key;\n+    in_->seekg(cursor_);\n     auto tag = read64BitIntegerLittleEndian();\n     if (tag != RecordTags::STORAGE) {\n       throw std::runtime_error(\"Attempted to read a record of non-storage type\");\n     }\n     auto size = read64BitIntegerLittleEndian();\n     seekToNextAlignmentBoundary();\n-    auto ptr = malloc(size);\n+    auto* ptr = malloc(size);\n     at::DataPtr retval(ptr, ptr, free, at::kCPU);\n \n-    in.read((char*)ptr, size);\n-    cursor += size;\n+    in_->read(static_cast<char*>(ptr), size);\n+    cursor_ += size;\n     seekToNextAlignmentBoundary();\n     return std::tuple<at::DataPtr, size_t>(std::move(retval), size);\n   }\n+\n+  // return dataptr, key, size\n+  std::tuple<at::DataPtr, int64_t, int64_t> getNextRecord() {\n+    int64_t key = cursor_;\n+    if (!hasNextRecord()) {\n+      throw std::runtime_error(\"No more record, but hasNextRecord is called.\");\n+    }\n+    auto tag = read64BitIntegerLittleEndian();\n+    if (tag != RecordTags::STORAGE) {\n+      throw std::runtime_error(\n+          \"Attempted to read a record of non-storage type\");\n+    }\n+    auto size = read64BitIntegerLittleEndian();\n+    seekToNextAlignmentBoundary();\n+    auto* ptr = malloc(size);\n+    at::DataPtr retval(ptr, ptr, free, at::kCPU);\n+\n+    in_->read(static_cast<char*>(ptr), size);\n+    cursor_ += size;\n+    seekToNextAlignmentBoundary();\n+    return std::tuple<at::DataPtr, int64_t, int64_t>(\n+        std::move(retval), key, size);\n+  }\n+\n+  bool hasNextRecord() const {\n+    return cursor_ + kFieldAlignment * 2 < file_size_;\n+  }\n+\n+  bool close() {\n+    if (closed_) {\n+      return false;\n+    }\n+    closed_ = true;\n+    return true;\n+  }\n+\n+  bool closed() const {\n+    return closed_;\n+  }\n+\n   ~PyTorchStreamReader() {\n   }\n+\n  private:\n-  std::istream& in;\n-  size_t cursor = 0;\n-  size_t file_size;\n-  size_t last_record_offset;\n+  std::istream* in_;\n+  size_t cursor_ = 0;\n+  size_t file_size_;\n+  size_t last_record_offset_;\n+  bool closed_ = false;\n \n   // Utility functions\n   uint64_t read64BitIntegerLittleEndian() {\n-   uint64_t retval;\n-   // TODO endian swap on platforms that need it?\n-   in.read(reinterpret_cast<char *>(&retval), 8);\n-   std::streamsize read_bytes = in.gcount();\n-   if (read_bytes != 8) {\n-     std::ostringstream errmsg;\n-     errmsg << \"Expected to read 8 bytes but got \" << read_bytes;\n-     throw std::runtime_error(errmsg.str());\n-   }\n-   cursor += read_bytes;\n-   return retval;\n+    uint64_t retval;\n+    // TODO endian swap on platforms that need it?\n+    in_->read(reinterpret_cast<char*>(&retval), 8);\n+    std::streamsize read_bytes = in_->gcount();\n+    if (read_bytes != 8) {\n+      std::ostringstream errmsg;\n+      errmsg << \"Expected to read 8 bytes but got \" << read_bytes;\n+      throw std::runtime_error(errmsg.str());\n+    }\n+    cursor_ += read_bytes;\n+    return retval;\n   }\n \n   void seekToNextAlignmentBoundary() {\n-   size_t next_offset = (cursor + kFieldAlignment) - (cursor % kFieldAlignment);\n-   size_t pad_amount = next_offset - cursor;\n-   cursor += pad_amount;\n-   in.seekg(cursor);\n+    size_t next_offset =\n+        (cursor_ + kFieldAlignment) - (cursor_ % kFieldAlignment);\n+    size_t pad_amount = next_offset - cursor_;\n+    cursor_ += pad_amount;\n+    in_->seekg(cursor_);\n   }\n \n   // File format deserialization functions\n-  void readAndValidateFileHeader() {\n-   // Validate magic number\n-   uint64_t magic = read64BitIntegerLittleEndian();\n-   if (magic != kFileMagicNumber) {\n-     throw std::runtime_error(\"Magic number mismatch in PyTorch file. File may\"\n-                              \" be corrupted or is not actually a PyTorch file.\");\n-   }\n-   uint64_t file_format_version = read64BitIntegerLittleEndian();\n-   if (file_format_version > kMaxSupportedFileFormatVersion) {\n-     std::ostringstream errmsg;\n-     errmsg << \"Attempted to read a PyTorch file with version \" << file_format_version\n-            << \" but the maximum supported version for reading is \" << kMaxSupportedFileFormatVersion\n-            << \". Your PyTorch installation may be too old.\";\n-     throw std::runtime_error(errmsg.str());\n-   }\n-   seekToNextAlignmentBoundary();\n-  }\n-  void readAndValidateFileFooter() {\n+  bool readAndValidateFileHeader() {\n+    // Validate magic number\n+    cursor_ = 0;\n+    in_->seekg(cursor_);\n+    uint64_t magic = read64BitIntegerLittleEndian();\n+    if (magic != kFileMagicNumber) {\n+      LOG(ERROR) << \"Magic number mismatch in PyTorch file. File may\"\n+        << \" be corrupted or is not actually a PyTorch file.\";\n+      return false;\n+    }\n+    // magic number mismatch in PyTorch file.\n+    uint64_t file_format_version = read64BitIntegerLittleEndian();\n+    if (file_format_version > kMaxSupportedFileFormatVersion) {\n+      LOG(ERROR) << \"Attempted to read a PyTorch file with version \"\n+        << file_format_version\n+        << \" but the maximum supported version for reading is \"\n+        << kMaxSupportedFileFormatVersion\n+        << \". Your PyTorch installation may be too old.\";\n+      return false;\n+    }\n+    seekToNextAlignmentBoundary();\n+    return true;\n+  }\n+\n+  bool readAndValidateFileFooter() {\n     // Seek to location of file footer. We've already validated that the file\n     // length is a multiple of the alignment size\n-    cursor = file_size - kFieldAlignment;\n-    in.seekg(cursor);\n+    cursor_ = file_size_ - kFieldAlignment;\n+    in_->seekg(cursor_);\n     auto tag = read64BitIntegerLittleEndian();\n     if (tag != RecordTags::FOOTER) {\n-      throw std::runtime_error(\"File footer has wrong record type. Is this\"\n-                               \" file corrupted?\");\n+      LOG(ERROR) << \"File footer has wrong record type. Is this\"\n+        << \" file corrupted?\";\n+      return false;\n     }\n-    last_record_offset = read64BitIntegerLittleEndian();\n-    if (last_record_offset > file_size) {\n-      throw std::runtime_error(\"Offset of last record is higher than the size\"\n-                               \" of the file! Is this file corrupted?\");\n+    last_record_offset_ = read64BitIntegerLittleEndian();\n+    if (last_record_offset_ > file_size_) {\n+      LOG(ERROR) << \"Offset of last record is higher than the size\"\n+        << \" of the file! Is this file corrupted?\";\n+      return false;\n     }\n+    return true;\n   }\n };\n \n-class PyTorchStreamWriter {\n+class PyTorchStreamWriter final {\n  public:\n-  PyTorchStreamWriter(std::ostream& out_) : out(out_) {\n+  PyTorchStreamWriter(std::ostream* out) : out_(out) {\n+    pad_buffer_.resize(kFieldAlignment, kPadValue);\n     writeFileHeader();\n     // In the case that we do not write any records into this file, the last\n     // record index written into the footer will point to the footer itself.\n-    last_record_idx = cursor;\n+    last_record_idx_ = cursor_;\n   }\n-  uint64_t writeRecord(const char* data, size_t size) {\n-    JIT_ASSERT(!finalized);\n-    uint64_t record_offset = cursor;\n-    last_record_idx = record_offset;\n+\n+  uint64_t writeRecord(const void* data, size_t size) {\n+    CAFFE_ENFORCE(!finalized_, \"should not be finalized!\");\n+    uint64_t record_offset = cursor_;\n+    last_record_idx_ = record_offset;\n     write64BitIntegerLittleEndian(RecordTags::STORAGE);\n     write64BitIntegerLittleEndian(size);\n     padToNextAlignmentBoundary();\n     writeBuffer(data, size);\n     padToNextAlignmentBoundary();\n     return record_offset;\n   }\n+\n   void writeEndOfFile() {\n-    JIT_ASSERT(!finalized);\n+    CAFFE_ENFORCE(!finalized_, \"cannot finalize again!\");", "path": "caffe2/serialize/inline_container.h", "position": null, "original_position": 315, "commit_id": "8beeb484bf4d149767c4ea9d1d376a4c3d0b7c3e", "original_commit_id": "fe3d6f2fdbf89d9f8393150b3fff4673b94c8c57", "user": {"login": "houseroad", "id": 30275821, "node_id": "MDQ6VXNlcjMwMjc1ODIx", "avatar_url": "https://avatars0.githubusercontent.com/u/30275821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/houseroad", "html_url": "https://github.com/houseroad", "followers_url": "https://api.github.com/users/houseroad/followers", "following_url": "https://api.github.com/users/houseroad/following{/other_user}", "gists_url": "https://api.github.com/users/houseroad/gists{/gist_id}", "starred_url": "https://api.github.com/users/houseroad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/houseroad/subscriptions", "organizations_url": "https://api.github.com/users/houseroad/orgs", "repos_url": "https://api.github.com/users/houseroad/repos", "events_url": "https://api.github.com/users/houseroad/events{/privacy}", "received_events_url": "https://api.github.com/users/houseroad/received_events", "type": "User", "site_admin": false}, "body": "since I use at namespace, let's stick to AT_ASSERT and AT_ERROR. And I will change others to AT_ASSERT/AT_ERROR", "created_at": "2018-10-24T17:25:52Z", "updated_at": "2018-11-23T15:53:31Z", "html_url": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227885381", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12993", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227885381"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227885381"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12993"}}, "body_html": "<p>since I use at namespace, let's stick to AT_ASSERT and AT_ERROR. And I will change others to AT_ASSERT/AT_ERROR</p>", "body_text": "since I use at namespace, let's stick to AT_ASSERT and AT_ERROR. And I will change others to AT_ASSERT/AT_ERROR", "in_reply_to_id": 227645506}