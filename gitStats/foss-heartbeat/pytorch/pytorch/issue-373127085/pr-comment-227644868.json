{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227644868", "pull_request_review_id": 167732481, "id": 227644868, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIyNzY0NDg2OA==", "diff_hunk": "@@ -59,195 +63,271 @@ namespace torch { namespace jit {\n //         been written. We place the variable-length index at the end and do\n //         not put any indicies into the header to fulfill this constraint.\n \n+// The serialized model, which contains all the metadata information,\n+// should be stored as the last record. Because the size of tensor data is\n+// usually stable. As long as the shape and type of the tensor do not change,\n+// the size of the data won't change. On the other sied, the size of the\n+// serialized model is likely to change, so we store it as the last record, and\n+// we don't need to move previous records when updating the model data.\n+\n namespace {\n-  struct RecordTags {\n-    enum {\n-      STORAGE = 1,\n-      FOOTER = 2,\n-    };\n-  };\n \n-  // Common constants\n-  static constexpr uint64_t kFileMagicNumber = 0x314843524f545950L; // PYTORCH1\n-  static constexpr uint64_t kFieldAlignment = 64L; // 64 byte alignment supports up to AVX512 for mmap\n+enum RecordTags {\n+  STORAGE = 1,\n+  FOOTER = 2,\n+};\n+\n+// Common constants\n+constexpr uint64_t kFileMagicNumber = 0x314843524f545950L; // PYTORCH1\n+constexpr uint64_t kFieldAlignment =\n+    64L; // 64 byte alignment supports up to AVX512 for mmap\n \n-  // Reader-specific constants\n-  static constexpr uint64_t kMaxSupportedFileFormatVersion = 0x1L;\n+// Reader-specific constants\n+constexpr uint64_t kMaxSupportedFileFormatVersion = 0x1L;\n \n-  // Writer-specific constants\n-  static constexpr uint64_t kFileFormatVersion = 0x1L;\n-  static constexpr uint8_t kPadValue = 0xEF;\n+// Writer-specific constants\n+constexpr uint64_t kFileFormatVersion = 0x1L;\n+constexpr char kPadValue = -17; // 0xEF\n \n }  // namespace\n \n-class PyTorchStreamReader {\n+class PyTorchStreamReader final {\n  public:\n-  PyTorchStreamReader(std::istream& in_) : in(in_) {\n+  PyTorchStreamReader(std::istream* in) : in_(in) {\n     // Store file size so we know when we're done reading because the f* APIs\n     // don't do a good job of that\n-    in.seekg(0L, in.end);\n-    file_size = in.tellg();\n-    in.seekg(0L);\n-    readAndValidateFileHeader();\n+    in_->seekg(0L, in_->end);\n+    file_size_ = in_->tellg();\n+    readAndValidateFileFooter();\n     // Do this now since we're reasonably sure this is actually a PyT file from\n     // the header.\n-    if (file_size % kFieldAlignment != 0) {\n-      throw std::runtime_error(\"File length is not a multiple of the alignment\"\n-                               \" size. Is this a valid PyTorch file?\");\n+    if (file_size_ % kFieldAlignment != 0) {\n+      throw std::runtime_error(\n+          \"File length is not a multiple of the alignment\"\n+          \" size. Is this a valid PyTorch model file?\");\n     }\n-    readAndValidateFileFooter();\n+    readAndValidateFileHeader();\n   }\n+\n   std::tuple<at::DataPtr, size_t> getLastRecord() {\n-    return getRecordWithKey(last_record_offset);\n+    return getRecordWithKey(last_record_offset_);\n   }\n+\n   std::tuple<at::DataPtr, size_t> getRecordWithKey(uint64_t key) {\n-    if (key + kFieldAlignment > file_size) {\n+    if (key + kFieldAlignment > file_size_) {\n       throw std::runtime_error(\"Provided key is larger than the size of the file.\");\n     }\n     if (key % kFieldAlignment != 0) {\n       throw std::runtime_error(\"Provided key is not divisible by the alignment size.\");\n     }\n     // Seek to the provided offset\n-    cursor = key;\n-    in.seekg(cursor);\n+    cursor_ = key;\n+    in_->seekg(cursor_);\n     auto tag = read64BitIntegerLittleEndian();\n     if (tag != RecordTags::STORAGE) {\n       throw std::runtime_error(\"Attempted to read a record of non-storage type\");\n     }\n     auto size = read64BitIntegerLittleEndian();\n     seekToNextAlignmentBoundary();\n-    auto ptr = malloc(size);\n+    auto* ptr = malloc(size);\n     at::DataPtr retval(ptr, ptr, free, at::kCPU);\n \n-    in.read((char*)ptr, size);\n-    cursor += size;\n+    in_->read(static_cast<char*>(ptr), size);\n+    cursor_ += size;\n     seekToNextAlignmentBoundary();\n     return std::tuple<at::DataPtr, size_t>(std::move(retval), size);\n   }\n+\n+  // return dataptr, key, size\n+  std::tuple<at::DataPtr, int64_t, int64_t> getNextRecord() {\n+    int64_t key = cursor_;\n+    if (!hasNextRecord()) {\n+      throw std::runtime_error(\"No more record, but hasNextRecord is called.\");\n+    }\n+    auto tag = read64BitIntegerLittleEndian();\n+    if (tag != RecordTags::STORAGE) {\n+      throw std::runtime_error(\n+          \"Attempted to read a record of non-storage type\");\n+    }\n+    auto size = read64BitIntegerLittleEndian();\n+    seekToNextAlignmentBoundary();\n+    auto* ptr = malloc(size);\n+    at::DataPtr retval(ptr, ptr, free, at::kCPU);\n+\n+    in_->read(static_cast<char*>(ptr), size);\n+    cursor_ += size;\n+    seekToNextAlignmentBoundary();\n+    return std::tuple<at::DataPtr, int64_t, int64_t>(\n+        std::move(retval), key, size);\n+  }\n+\n+  bool hasNextRecord() const {\n+    return cursor_ + kFieldAlignment * 2 < file_size_;\n+  }\n+\n+  bool close() {", "path": "caffe2/serialize/inline_container.h", "position": null, "original_position": 148, "commit_id": "8beeb484bf4d149767c4ea9d1d376a4c3d0b7c3e", "original_commit_id": "fe3d6f2fdbf89d9f8393150b3fff4673b94c8c57", "user": {"login": "dzhulgakov", "id": 17890620, "node_id": "MDQ6VXNlcjE3ODkwNjIw", "avatar_url": "https://avatars2.githubusercontent.com/u/17890620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzhulgakov", "html_url": "https://github.com/dzhulgakov", "followers_url": "https://api.github.com/users/dzhulgakov/followers", "following_url": "https://api.github.com/users/dzhulgakov/following{/other_user}", "gists_url": "https://api.github.com/users/dzhulgakov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzhulgakov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzhulgakov/subscriptions", "organizations_url": "https://api.github.com/users/dzhulgakov/orgs", "repos_url": "https://api.github.com/users/dzhulgakov/repos", "events_url": "https://api.github.com/users/dzhulgakov/events{/privacy}", "received_events_url": "https://api.github.com/users/dzhulgakov/received_events", "type": "User", "site_admin": false}, "body": "do you actually call this one? and you don't close the stream", "created_at": "2018-10-24T05:21:12Z", "updated_at": "2018-11-23T15:53:29Z", "html_url": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227644868", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/12993", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/227644868"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/12993#discussion_r227644868"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/12993"}}, "body_html": "<p>do you actually call this one? and you don't close the stream</p>", "body_text": "do you actually call this one? and you don't close the stream"}