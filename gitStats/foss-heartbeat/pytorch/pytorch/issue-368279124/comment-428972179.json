{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/428972179", "html_url": "https://github.com/pytorch/pytorch/issues/12484#issuecomment-428972179", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12484", "id": 428972179, "node_id": "MDEyOklzc3VlQ29tbWVudDQyODk3MjE3OQ==", "user": {"login": "dhgrs", "id": 22191150, "node_id": "MDQ6VXNlcjIyMTkxMTUw", "avatar_url": "https://avatars2.githubusercontent.com/u/22191150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhgrs", "html_url": "https://github.com/dhgrs", "followers_url": "https://api.github.com/users/dhgrs/followers", "following_url": "https://api.github.com/users/dhgrs/following{/other_user}", "gists_url": "https://api.github.com/users/dhgrs/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhgrs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhgrs/subscriptions", "organizations_url": "https://api.github.com/users/dhgrs/orgs", "repos_url": "https://api.github.com/users/dhgrs/repos", "events_url": "https://api.github.com/users/dhgrs/events{/privacy}", "received_events_url": "https://api.github.com/users/dhgrs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-11T14:16:20Z", "updated_at": "2018-10-11T14:16:20Z", "author_association": "NONE", "body_html": "<p>I find related issue. Conv with nan weight outputs <code>nan</code> on CPU but outputs <code>-Inf</code> on GPU. I think it should outputs same value.</p>\n<pre><code>import argparse\n\nimport torch\nimport numpy\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--use_cuda', action='store_true', help='use cuda?')\nargs = parser.parse_args()\n\nconv = torch.nn.Conv1d(1, 128, 3, 1, 1)\nconv.weight.data[...] = float('NaN')\nconv.to(torch.device('cuda' if args.use_cuda else 'cpu'))\nif torch.isnan(conv.weight).all():\n    print('weight has nan')\n\nx = torch.Tensor(numpy.zeros(256, dtype=numpy.float32).reshape((1, 1, 256)))\nx.to(torch.device('cuda' if args.use_cuda else 'cpu'))\noutput = conv(x)\nif torch.isnan(output).any():\n    print('output has nan')\nprint(output)\n</code></pre>", "body_text": "I find related issue. Conv with nan weight outputs nan on CPU but outputs -Inf on GPU. I think it should outputs same value.\nimport argparse\n\nimport torch\nimport numpy\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--use_cuda', action='store_true', help='use cuda?')\nargs = parser.parse_args()\n\nconv = torch.nn.Conv1d(1, 128, 3, 1, 1)\nconv.weight.data[...] = float('NaN')\nconv.to(torch.device('cuda' if args.use_cuda else 'cpu'))\nif torch.isnan(conv.weight).all():\n    print('weight has nan')\n\nx = torch.Tensor(numpy.zeros(256, dtype=numpy.float32).reshape((1, 1, 256)))\nx.to(torch.device('cuda' if args.use_cuda else 'cpu'))\noutput = conv(x)\nif torch.isnan(output).any():\n    print('output has nan')\nprint(output)", "body": "I find related issue. Conv with nan weight outputs `nan` on CPU but outputs `-Inf` on GPU. I think it should outputs same value.\r\n```\r\nimport argparse\r\n\r\nimport torch\r\nimport numpy\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--use_cuda', action='store_true', help='use cuda?')\r\nargs = parser.parse_args()\r\n\r\nconv = torch.nn.Conv1d(1, 128, 3, 1, 1)\r\nconv.weight.data[...] = float('NaN')\r\nconv.to(torch.device('cuda' if args.use_cuda else 'cpu'))\r\nif torch.isnan(conv.weight).all():\r\n    print('weight has nan')\r\n\r\nx = torch.Tensor(numpy.zeros(256, dtype=numpy.float32).reshape((1, 1, 256)))\r\nx.to(torch.device('cuda' if args.use_cuda else 'cpu'))\r\noutput = conv(x)\r\nif torch.isnan(output).any():\r\n    print('output has nan')\r\nprint(output)\r\n```"}