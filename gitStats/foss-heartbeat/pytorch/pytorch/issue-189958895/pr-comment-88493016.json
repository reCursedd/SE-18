{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/88493016", "pull_request_review_id": 9061645, "id": 88493016, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDg4NDkzMDE2", "diff_hunk": "@@ -1283,6 +1504,128 @@ padding | 0 | implicit padding that was added to the input. Can be a single numb\n ------ | ----- | ------------\n  input | [ * , * , *, *, * ]  | Input is minibatch x channels x iT x iH x iW\n output | [ * , * , *, *, * ]   | Output shape = minibatch x channels x padT x (iT - 1) * sT + kT x padH x (iH - 1) * sH + kH x padW x (iW - 1) * sW + kW\n+## MultiLabelMarginLoss\n+\n+Creates a criterion that optimizes a multi-class multi-classification \n+\n+hinge loss (margin-based loss) between input `x`  (a 1D `Tensor`) and \n+output `y` (which is a 1D `Tensor` of target class indices):\n+\n+    loss(x, y) = sum_ij(max(0, 1 - (x[y[j]] - x[i]))) / x:size(1)\n+\n+where `i == 0` to `x.size(0)`, `j == 0` to `y.size(0)`, \n+      `y[j] ~= 0`, and `i ~= y[j]` for all `i` and `j`.\n+Note that this criterion also works with 2D inputs and targets.\n+\n+`y` and `x` must have the same size.\n+The criterion only considers the first non zero `y[j]` targets.\n+This allows for different samples to have variable amounts of target classes\n+## MultiLabelSoftMarginLoss\n+\n+Creates a criterion that optimizes a multi-label one-versus-all \n+\n+loss based on max-entropy, between input `x`  (a 1D `Tensor`) and \n+target `y` (a binary 1D `Tensor`):\n+\n+   loss(x, y) = - sum_i (y[i] log( exp(x[i]) / (1 + exp(x[i]))) \n+                         + (1-y[i]) log(1/(1+exp(x[i])))) / x:nElement()\n+\n+where `i == 0` to `x.nElement()-1`, `y[i]  in {0,1}`.\n+Note that this criterion also works with 2D inputs and targets.\n+`y` and `x` must have the same size.\n+## MultiMarginLoss\n+\n+Creates a criterion that optimizes a multi-class classification hinge loss \n+\n+(margin-based loss) between input `x` (a `Tensor` of dimension 1) and \n+output `y` (which is a target class index, `0` <= `y` <= `x.size(0)`):\n+\n+loss(x, y) = sum_i(max(0, (margin - x[y] + x[i]))^p) / x.size(0)\n+\n+where `i == 0` to `x.size(0)` and `i ~= y`.\n+Note that this criterion also works with 2D inputs and 1D targets.\n+\n+Optionally, you can give non-equal weighting on the classes by passing \n+a 1D `weights` tensor into the constructor.\n+\n+The loss function then becomes:\n+loss(x, y) = sum_i(max(0, w[y] * (margin - x[y] - x[i]))^p) / x.size(0)\n+\n+By default, the losses are averaged over observations for each minibatch. \n+However, if the field `sizeAverage` is set to `False`, \n+the losses are instead summed.\n+## NLLLoss\n+\n+The negative log likelihood loss. It is useful to train a classication problem with n classes\n+\n+```python\n+m = nn.LogSoftmax()\n+loss = nn.NLLLoss()\n+# input is of size nBatch x nClasses = 3 x 5\n+input = autograd.Variable(torch.randn(3, 5))\n+# each element in target has to have 0 <= value < nclasses \n+target = autograd.Variable(torch.LongTensor([1, 0, 4]), requires_grad=False)\n+output = loss(m(input), target)\n+output.backward()\n+```\n+\n+\n+If provided, the optional argument weights should be a 1D Tensor assigning", "path": "docs/nn.md", "position": null, "original_position": 373, "commit_id": "26d626a47c9c676af456ce6b6025ce5575ad4b2f", "original_commit_id": "9bc671dbc9166788396b86400e0a87414de7dea7", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "`weights`\n", "created_at": "2016-11-17T16:41:41Z", "updated_at": "2018-11-23T15:31:55Z", "html_url": "https://github.com/pytorch/pytorch/pull/225#discussion_r88493016", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/225", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/88493016"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/225#discussion_r88493016"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/225"}}, "body_html": "<p><code>weights</code></p>", "body_text": "weights"}