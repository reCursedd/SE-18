{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5046", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5046/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5046/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5046/events", "html_url": "https://github.com/pytorch/pytorch/issues/5046", "id": 294342162, "node_id": "MDU6SXNzdWUyOTQzNDIxNjI=", "number": 5046, "title": "RuntimeError: cuda runtime error (38) ", "user": {"login": "gwliu", "id": 23259478, "node_id": "MDQ6VXNlcjIzMjU5NDc4", "avatar_url": "https://avatars1.githubusercontent.com/u/23259478?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gwliu", "html_url": "https://github.com/gwliu", "followers_url": "https://api.github.com/users/gwliu/followers", "following_url": "https://api.github.com/users/gwliu/following{/other_user}", "gists_url": "https://api.github.com/users/gwliu/gists{/gist_id}", "starred_url": "https://api.github.com/users/gwliu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gwliu/subscriptions", "organizations_url": "https://api.github.com/users/gwliu/orgs", "repos_url": "https://api.github.com/users/gwliu/repos", "events_url": "https://api.github.com/users/gwliu/events{/privacy}", "received_events_url": "https://api.github.com/users/gwliu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-05T10:26:49Z", "updated_at": "2018-02-08T08:01:34Z", "closed_at": "2018-02-08T08:01:34Z", "author_association": "NONE", "body_html": "<p>When I tried to call <code>torch.cuda.device_count()</code> or any other torch.cuda functions, the following error arises:</p>\n<p><strong>RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/torch/lib/THC/THCGeneral.c:70</strong></p>\n<p>I installed CUDA 8.0 and cuDNN in my ubuntu14.04 before installing pytorch. Checking the installation of CUDA 8.0 gives the right correspondance</p>\n<p><strong>CUDA Device Query (Runtime API) version (CUDART static linking)</strong></p>\n<p><strong>Detected 1 CUDA Capable device(s)</strong></p>\n<p><strong>Device 0: \"GeForce GTX 1050\"</strong><br>\n**  CUDA Driver Version / Runtime Version          9.0 / 8.0**<br>\n**  CUDA Capability Major/Minor version number:    6.1**<br>\n**  Total amount of global memory:                 1991 MBytes (2087714816 bytes)**<br>\n**  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores**<br>\n**  GPU Max Clock rate:                            1506 MHz (1.51 GHz)**<br>\n**  Memory Clock rate:                             3504 Mhz**<br>\n**  Memory Bus Width:                              128-bit**<br>\n**  L2 Cache Size:                                 1048576 bytes**<br>\n**  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)**<br>\n**  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers**<br>\n**  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers**<br>\n**  Total amount of constant memory:               65536 bytes**<br>\n**  Total amount of shared memory per block:       49152 bytes**<br>\n**  Total number of registers available per block: 65536**<br>\n**  Warp size:                                     32**<br>\n**  Maximum number of threads per multiprocessor:  2048**<br>\n**  Maximum number of threads per block:           1024**<br>\n**  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)**<br>\n**  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)**<br>\n**  Maximum memory pitch:                          2147483647 bytes**<br>\n**  Texture alignment:                             512 bytes**<br>\n**  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)**<br>\n**  Run time limit on kernels:                     Yes**<br>\n**  Integrated GPU sharing Host Memory:            No**<br>\n**  Support host page-locked memory mapping:       Yes**<br>\n**  Alignment requirement for Surfaces:            Yes**<br>\n**  Device has ECC support:                        Disabled**<br>\n**  Device supports Unified Addressing (UVA):      Yes**<br>\n**  Device PCI Domain ID / Bus ID / location ID:   0 / 101 / 0**<br>\n**  Compute Mode:**<br>\n**     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;**</p>\n<p><strong>deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1050</strong><br>\n<strong>Result = PASS</strong></p>\n<p>Then I pip installed pytorch in Python3.6 by following the official website instructions. In python, 'import torch' works well, but calling any torch.cuda function gives the above runtime error.</p>\n<p>Could anyone figure out what might be wrong in my installation?</p>\n<p>Thank you!</p>", "body_text": "When I tried to call torch.cuda.device_count() or any other torch.cuda functions, the following error arises:\nRuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/torch/lib/THC/THCGeneral.c:70\nI installed CUDA 8.0 and cuDNN in my ubuntu14.04 before installing pytorch. Checking the installation of CUDA 8.0 gives the right correspondance\nCUDA Device Query (Runtime API) version (CUDART static linking)\nDetected 1 CUDA Capable device(s)\nDevice 0: \"GeForce GTX 1050\"\n**  CUDA Driver Version / Runtime Version          9.0 / 8.0**\n**  CUDA Capability Major/Minor version number:    6.1**\n**  Total amount of global memory:                 1991 MBytes (2087714816 bytes)**\n**  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores**\n**  GPU Max Clock rate:                            1506 MHz (1.51 GHz)**\n**  Memory Clock rate:                             3504 Mhz**\n**  Memory Bus Width:                              128-bit**\n**  L2 Cache Size:                                 1048576 bytes**\n**  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)**\n**  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers**\n**  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers**\n**  Total amount of constant memory:               65536 bytes**\n**  Total amount of shared memory per block:       49152 bytes**\n**  Total number of registers available per block: 65536**\n**  Warp size:                                     32**\n**  Maximum number of threads per multiprocessor:  2048**\n**  Maximum number of threads per block:           1024**\n**  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)**\n**  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)**\n**  Maximum memory pitch:                          2147483647 bytes**\n**  Texture alignment:                             512 bytes**\n**  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)**\n**  Run time limit on kernels:                     Yes**\n**  Integrated GPU sharing Host Memory:            No**\n**  Support host page-locked memory mapping:       Yes**\n**  Alignment requirement for Surfaces:            Yes**\n**  Device has ECC support:                        Disabled**\n**  Device supports Unified Addressing (UVA):      Yes**\n**  Device PCI Domain ID / Bus ID / location ID:   0 / 101 / 0**\n**  Compute Mode:**\n**     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >**\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1050\nResult = PASS\nThen I pip installed pytorch in Python3.6 by following the official website instructions. In python, 'import torch' works well, but calling any torch.cuda function gives the above runtime error.\nCould anyone figure out what might be wrong in my installation?\nThank you!", "body": "\r\nWhen I tried to call `torch.cuda.device_count()` or any other torch.cuda functions, the following error arises:\r\n\r\n**RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/torch/lib/THC/THCGeneral.c:70**\r\n\r\n\r\nI installed CUDA 8.0 and cuDNN in my ubuntu14.04 before installing pytorch. Checking the installation of CUDA 8.0 gives the right correspondance\r\n\r\n **CUDA Device Query (Runtime API) version (CUDART static linking)**\r\n\r\n**Detected 1 CUDA Capable device(s)**\r\n\r\n**Device 0: \"GeForce GTX 1050\"**\r\n**  CUDA Driver Version / Runtime Version          9.0 / 8.0**\r\n**  CUDA Capability Major/Minor version number:    6.1**\r\n**  Total amount of global memory:                 1991 MBytes (2087714816 bytes)**\r\n**  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores**\r\n**  GPU Max Clock rate:                            1506 MHz (1.51 GHz)**\r\n**  Memory Clock rate:                             3504 Mhz**\r\n**  Memory Bus Width:                              128-bit**\r\n**  L2 Cache Size:                                 1048576 bytes**\r\n**  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)**\r\n**  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers**\r\n**  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers**\r\n**  Total amount of constant memory:               65536 bytes**\r\n**  Total amount of shared memory per block:       49152 bytes**\r\n**  Total number of registers available per block: 65536**\r\n**  Warp size:                                     32**\r\n**  Maximum number of threads per multiprocessor:  2048**\r\n**  Maximum number of threads per block:           1024**\r\n**  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)**\r\n**  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)**\r\n**  Maximum memory pitch:                          2147483647 bytes**\r\n**  Texture alignment:                             512 bytes**\r\n**  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)**\r\n**  Run time limit on kernels:                     Yes**\r\n**  Integrated GPU sharing Host Memory:            No**\r\n**  Support host page-locked memory mapping:       Yes**\r\n**  Alignment requirement for Surfaces:            Yes**\r\n**  Device has ECC support:                        Disabled**\r\n**  Device supports Unified Addressing (UVA):      Yes**\r\n**  Device PCI Domain ID / Bus ID / location ID:   0 / 101 / 0**\r\n**  Compute Mode:**\r\n**     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >**\r\n\r\n**deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1050**\r\n**Result = PASS**\r\n\r\nThen I pip installed pytorch in Python3.6 by following the official website instructions. In python, 'import torch' works well, but calling any torch.cuda function gives the above runtime error.\r\n\r\nCould anyone figure out what might be wrong in my installation?\r\n\r\nThank you!\r\n\r\n"}