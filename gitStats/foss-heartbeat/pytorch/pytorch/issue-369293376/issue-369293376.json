{"url": "https://api.github.com/repos/pytorch/pytorch/issues/12579", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/12579/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/12579/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/12579/events", "html_url": "https://github.com/pytorch/pytorch/issues/12579", "id": 369293376, "node_id": "MDU6SXNzdWUzNjkyOTMzNzY=", "number": 12579, "title": "[JIT] outputs of size() fed into tensor constructors do not trace properly", "user": {"login": "jamesr66a", "id": 4685384, "node_id": "MDQ6VXNlcjQ2ODUzODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4685384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesr66a", "html_url": "https://github.com/jamesr66a", "followers_url": "https://api.github.com/users/jamesr66a/followers", "following_url": "https://api.github.com/users/jamesr66a/following{/other_user}", "gists_url": "https://api.github.com/users/jamesr66a/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesr66a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesr66a/subscriptions", "organizations_url": "https://api.github.com/users/jamesr66a/orgs", "repos_url": "https://api.github.com/users/jamesr66a/repos", "events_url": "https://api.github.com/users/jamesr66a/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesr66a/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-11T20:31:55Z", "updated_at": "2018-10-12T09:49:39Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<pre><code>import torch\n\ndef foo(x):\n    a, b, c = x.size()\n    print(torch._C._get_tracing_state())\n    return torch.arange(c)\n\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\nprint(traced.graph)\n\ndef foo(x):\n    a, b, c = x.size()\n    return torch.empty(c)\n\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\nprint(traced.graph)\n</code></pre>\n<p>Output:</p>\n<pre><code>graph(%0 : Float(3, 4, 5)) {\n  %10 : int = prim::Constant[value=5]()\n  %11 : int = prim::Constant[value=4]()\n  %12 : int = prim::Constant[value=0]()\n  %13 : int[] = prim::Constant[value=[0, -1]]()\n  %14 : Long(5) = aten::arange(%10, %11, %12, %13)\n  return (%14);\n}\n\ngraph(%0 : Float(3, 4, 5)) {\n  %7 : int = prim::Constant[value=2]()\n  %8 : int = aten::size(%0, %7)\n  %9 : Long() = prim::NumToTensor(%8)\n  %10 : int = prim::TensorToNum(%9)\n  %11 : int[] = prim::ListConstruct(%10)\n  %12 : int = prim::Constant[value=6]()\n  %13 : int = prim::Constant[value=0]()\n  %14 : int[] = prim::Constant[value=[0, -1]]()\n  %15 : Float(5) = aten::empty(%11, %12, %13, %14)\n  return (%15);\n}\n</code></pre>\n<p>The sizes are hard-coded as <code>prim::Constant</code> nodes</p>", "body_text": "import torch\n\ndef foo(x):\n    a, b, c = x.size()\n    print(torch._C._get_tracing_state())\n    return torch.arange(c)\n\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\nprint(traced.graph)\n\ndef foo(x):\n    a, b, c = x.size()\n    return torch.empty(c)\n\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\nprint(traced.graph)\n\nOutput:\ngraph(%0 : Float(3, 4, 5)) {\n  %10 : int = prim::Constant[value=5]()\n  %11 : int = prim::Constant[value=4]()\n  %12 : int = prim::Constant[value=0]()\n  %13 : int[] = prim::Constant[value=[0, -1]]()\n  %14 : Long(5) = aten::arange(%10, %11, %12, %13)\n  return (%14);\n}\n\ngraph(%0 : Float(3, 4, 5)) {\n  %7 : int = prim::Constant[value=2]()\n  %8 : int = aten::size(%0, %7)\n  %9 : Long() = prim::NumToTensor(%8)\n  %10 : int = prim::TensorToNum(%9)\n  %11 : int[] = prim::ListConstruct(%10)\n  %12 : int = prim::Constant[value=6]()\n  %13 : int = prim::Constant[value=0]()\n  %14 : int[] = prim::Constant[value=[0, -1]]()\n  %15 : Float(5) = aten::empty(%11, %12, %13, %14)\n  return (%15);\n}\n\nThe sizes are hard-coded as prim::Constant nodes", "body": "```\r\nimport torch\r\n\r\ndef foo(x):\r\n    a, b, c = x.size()\r\n    print(torch._C._get_tracing_state())\r\n    return torch.arange(c)\r\n\r\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\r\nprint(traced.graph)\r\n\r\ndef foo(x):\r\n    a, b, c = x.size()\r\n    return torch.empty(c)\r\n\r\ntraced = torch.jit.trace(foo, (torch.rand(3, 4, 5),), check_trace=False)\r\nprint(traced.graph)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\ngraph(%0 : Float(3, 4, 5)) {\r\n  %10 : int = prim::Constant[value=5]()\r\n  %11 : int = prim::Constant[value=4]()\r\n  %12 : int = prim::Constant[value=0]()\r\n  %13 : int[] = prim::Constant[value=[0, -1]]()\r\n  %14 : Long(5) = aten::arange(%10, %11, %12, %13)\r\n  return (%14);\r\n}\r\n\r\ngraph(%0 : Float(3, 4, 5)) {\r\n  %7 : int = prim::Constant[value=2]()\r\n  %8 : int = aten::size(%0, %7)\r\n  %9 : Long() = prim::NumToTensor(%8)\r\n  %10 : int = prim::TensorToNum(%9)\r\n  %11 : int[] = prim::ListConstruct(%10)\r\n  %12 : int = prim::Constant[value=6]()\r\n  %13 : int = prim::Constant[value=0]()\r\n  %14 : int[] = prim::Constant[value=[0, -1]]()\r\n  %15 : Float(5) = aten::empty(%11, %12, %13, %14)\r\n  return (%15);\r\n}\r\n```\r\n\r\nThe sizes are hard-coded as `prim::Constant` nodes"}