{"url": "https://api.github.com/repos/pytorch/pytorch/issues/584", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/584/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/584/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/584/events", "html_url": "https://github.com/pytorch/pytorch/issues/584", "id": 202997492, "node_id": "MDU6SXNzdWUyMDI5OTc0OTI=", "number": 584, "title": "Flag to check if a Module is on CUDA similar to is_cuda for Tensors", "user": {"login": "napsternxg", "id": 112678, "node_id": "MDQ6VXNlcjExMjY3OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/112678?v=4", "gravatar_id": "", "url": "https://api.github.com/users/napsternxg", "html_url": "https://github.com/napsternxg", "followers_url": "https://api.github.com/users/napsternxg/followers", "following_url": "https://api.github.com/users/napsternxg/following{/other_user}", "gists_url": "https://api.github.com/users/napsternxg/gists{/gist_id}", "starred_url": "https://api.github.com/users/napsternxg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/napsternxg/subscriptions", "organizations_url": "https://api.github.com/users/napsternxg/orgs", "repos_url": "https://api.github.com/users/napsternxg/repos", "events_url": "https://api.github.com/users/napsternxg/events{/privacy}", "received_events_url": "https://api.github.com/users/napsternxg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131849, "node_id": "MDU6TGFiZWw0MjQxMzE4NDk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-01-25T02:33:19Z", "updated_at": "2017-01-25T22:03:47Z", "closed_at": "2017-01-25T22:03:40Z", "author_association": "NONE", "body_html": "<p>When I have an object of a class which inherits from <code>nn.Module</code> is there anyway I can check if I the object is on cuda or not. We can do this for tensors by calling <code>var_name.is_cuda</code> however no such variable is available for modules.</p>\n<p>Furthermore, what is the suggested ways of quickly running the whole program on cuda instead of on GPU, or by default assign all Tensors on Cuda, for a given run. Something like a context manager would be really good.</p>", "body_text": "When I have an object of a class which inherits from nn.Module is there anyway I can check if I the object is on cuda or not. We can do this for tensors by calling var_name.is_cuda however no such variable is available for modules.\nFurthermore, what is the suggested ways of quickly running the whole program on cuda instead of on GPU, or by default assign all Tensors on Cuda, for a given run. Something like a context manager would be really good.", "body": "When I have an object of a class which inherits from `nn.Module` is there anyway I can check if I the object is on cuda or not. We can do this for tensors by calling `var_name.is_cuda` however no such variable is available for modules. \r\n\r\nFurthermore, what is the suggested ways of quickly running the whole program on cuda instead of on GPU, or by default assign all Tensors on Cuda, for a given run. Something like a context manager would be really good. "}