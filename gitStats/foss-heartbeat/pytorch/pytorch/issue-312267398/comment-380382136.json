{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/380382136", "html_url": "https://github.com/pytorch/pytorch/issues/6394#issuecomment-380382136", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/6394", "id": 380382136, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDM4MjEzNg==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-11T09:07:02Z", "updated_at": "2018-04-11T09:07:02Z", "author_association": "MEMBER", "body_html": "<p>The subgradient for norm at zero was added in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"258459563\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/2775\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/2775/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/2775\">#2775</a> and required some special casing.</p>\n<p>I don't think we can do much when the user specifies a set of operations by hand, because the derivative of <code>sqrt</code> at zero is <code>inf</code>.</p>\n<p>This is something we need to live with in numeric computing.<br>\nFor example, <code>log(x ** x) == x * log(x)</code>, but when x is zero, the limit (which is 0) gets undefined using the second expression:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">print</span>(np.log(<span class=\"pl-c1\">0</span> <span class=\"pl-k\">**</span> <span class=\"pl-c1\">0</span>))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> 0.0</span>\n<span class=\"pl-c1\">print</span>(<span class=\"pl-c1\">0</span> <span class=\"pl-k\">*</span> np.log(<span class=\"pl-c1\">0</span>))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> nan</span></pre></div>\n<p>Closing as a wontfix. Please let us know if you disagree.</p>", "body_text": "The subgradient for norm at zero was added in #2775 and required some special casing.\nI don't think we can do much when the user specifies a set of operations by hand, because the derivative of sqrt at zero is inf.\nThis is something we need to live with in numeric computing.\nFor example, log(x ** x) == x * log(x), but when x is zero, the limit (which is 0) gets undefined using the second expression:\nprint(np.log(0 ** 0))  # 0.0\nprint(0 * np.log(0))  # nan\nClosing as a wontfix. Please let us know if you disagree.", "body": "The subgradient for norm at zero was added in https://github.com/pytorch/pytorch/pull/2775 and required some special casing.\r\n \r\nI don't think we can do much when the user specifies a set of operations by hand, because the derivative of `sqrt` at zero is `inf`.\r\n\r\nThis is something we need to live with in numeric computing.\r\nFor example, `log(x ** x) == x * log(x)`, but when x is zero, the limit (which is 0) gets undefined using the second expression:\r\n```python\r\nprint(np.log(0 ** 0))  # 0.0\r\nprint(0 * np.log(0))  # nan\r\n```\r\n\r\nClosing as a wontfix. Please let us know if you disagree."}