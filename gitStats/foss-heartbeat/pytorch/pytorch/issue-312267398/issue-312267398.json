{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6394", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6394/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6394/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6394/events", "html_url": "https://github.com/pytorch/pytorch/issues/6394", "id": 312267398, "node_id": "MDU6SXNzdWUzMTIyNjczOTg=", "number": 6394, "title": "chain rule will lead to Nan, sqrt()  example", "user": {"login": "zchky", "id": 17870918, "node_id": "MDQ6VXNlcjE3ODcwOTE4", "avatar_url": "https://avatars2.githubusercontent.com/u/17870918?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zchky", "html_url": "https://github.com/zchky", "followers_url": "https://api.github.com/users/zchky/followers", "following_url": "https://api.github.com/users/zchky/following{/other_user}", "gists_url": "https://api.github.com/users/zchky/gists{/gist_id}", "starred_url": "https://api.github.com/users/zchky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zchky/subscriptions", "organizations_url": "https://api.github.com/users/zchky/orgs", "repos_url": "https://api.github.com/users/zchky/repos", "events_url": "https://api.github.com/users/zchky/events{/privacy}", "received_events_url": "https://api.github.com/users/zchky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131853, "node_id": "MDU6TGFiZWw0MjQxMzE4NTM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/wontfix", "name": "wontfix", "color": "ffffff", "default": true}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-08T03:15:39Z", "updated_at": "2018-04-11T09:07:11Z", "closed_at": "2018-04-11T09:07:02Z", "author_association": "NONE", "body_html": "<p>i find a interesting fact.</p>\n<p>for example   sqrt( ( x-1 )^2 ) =y and |x-1| = y , their grad of the two x should be same . but their grad of x different when x close to 1</p>\n<pre><code>&gt;&gt; x=Variable(torch.Tensor([1]),requires_grad=True)\n&gt;&gt; y=torch.sqrt(torch.pow(x - 1,0))\n&gt;&gt; y.backward()\n&gt;&gt; x.grad\nVariable containing:\nnan\n[torch.FloatTensor of size 1]\n</code></pre>\n<p>but in the fact, the grad of x for x-1 =y is just</p>\n<pre><code>&gt;&gt; x=Variable(torch.Tensor([1]),requires_grad=True)\n&gt;&gt; y=x-1\n&gt;&gt; y.backward()\n&gt;&gt; x.grad\nVariable containing:\n 1\n[torch.FloatTensor of size 1]\n</code></pre>\n<p>the formula is reasonable in mathematics, but it is different for autograd to compute.<br>\ni think the point is when one of sub chain's grad is Nan,  the final grad will be Nan.</p>", "body_text": "i find a interesting fact.\nfor example   sqrt( ( x-1 )^2 ) =y and |x-1| = y , their grad of the two x should be same . but their grad of x different when x close to 1\n>> x=Variable(torch.Tensor([1]),requires_grad=True)\n>> y=torch.sqrt(torch.pow(x - 1,0))\n>> y.backward()\n>> x.grad\nVariable containing:\nnan\n[torch.FloatTensor of size 1]\n\nbut in the fact, the grad of x for x-1 =y is just\n>> x=Variable(torch.Tensor([1]),requires_grad=True)\n>> y=x-1\n>> y.backward()\n>> x.grad\nVariable containing:\n 1\n[torch.FloatTensor of size 1]\n\nthe formula is reasonable in mathematics, but it is different for autograd to compute.\ni think the point is when one of sub chain's grad is Nan,  the final grad will be Nan.", "body": "i find a interesting fact.\r\n\r\nfor example   sqrt( ( x-1 )^2 ) =y and |x-1| = y , their grad of the two x should be same . but their grad of x different when x close to 1\r\n\r\n```\r\n>> x=Variable(torch.Tensor([1]),requires_grad=True)\r\n>> y=torch.sqrt(torch.pow(x - 1,0))\r\n>> y.backward()\r\n>> x.grad\r\nVariable containing:\r\nnan\r\n[torch.FloatTensor of size 1]\r\n```\r\n\r\nbut in the fact, the grad of x for x-1 =y is just\r\n\r\n```\r\n>> x=Variable(torch.Tensor([1]),requires_grad=True)\r\n>> y=x-1\r\n>> y.backward()\r\n>> x.grad\r\nVariable containing:\r\n 1\r\n[torch.FloatTensor of size 1]\r\n```\r\n\r\nthe formula is reasonable in mathematics, but it is different for autograd to compute.\r\ni think the point is when one of sub chain's grad is Nan,  the final grad will be Nan.\r\n"}