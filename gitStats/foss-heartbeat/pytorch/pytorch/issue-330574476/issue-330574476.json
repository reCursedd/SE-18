{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8280", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8280/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8280/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8280/events", "html_url": "https://github.com/pytorch/pytorch/issues/8280", "id": 330574476, "node_id": "MDU6SXNzdWUzMzA1NzQ0NzY=", "number": 8280, "title": "Backward parallelism causes performance degradation", "user": {"login": "airofjune", "id": 20220281, "node_id": "MDQ6VXNlcjIwMjIwMjgx", "avatar_url": "https://avatars0.githubusercontent.com/u/20220281?v=4", "gravatar_id": "", "url": "https://api.github.com/users/airofjune", "html_url": "https://github.com/airofjune", "followers_url": "https://api.github.com/users/airofjune/followers", "following_url": "https://api.github.com/users/airofjune/following{/other_user}", "gists_url": "https://api.github.com/users/airofjune/gists{/gist_id}", "starred_url": "https://api.github.com/users/airofjune/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/airofjune/subscriptions", "organizations_url": "https://api.github.com/users/airofjune/orgs", "repos_url": "https://api.github.com/users/airofjune/repos", "events_url": "https://api.github.com/users/airofjune/events{/privacy}", "received_events_url": "https://api.github.com/users/airofjune/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679952992, "node_id": "MDU6TGFiZWw2Nzk5NTI5OTI=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/performance", "name": "performance", "color": "f9d0c4", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-06-08T08:56:13Z", "updated_at": "2018-06-11T14:01:40Z", "closed_at": null, "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>CPU performance decreases after PR: Parallelize autograd backwards.<br>\nSimilar with issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"213419741\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/975\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/975/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/975\">#975</a>.</p>\n<p>Two tests: 1 Conv2d tasks for CPU. 2 Conv2d tasks for CPU and GPU. I apply two versions of Pytorch: OOB is the out of box version of Pytorch, and OPT is a changed version in which I hard code to not spawn additional p-thread on CPU.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Test1 time (sec)</th>\n<th align=\"center\">OOB</th>\n<th align=\"right\">OPT</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Forward Time without Backward</td>\n<td align=\"center\">2.58</td>\n<td align=\"right\">2.66</td>\n</tr>\n<tr>\n<td align=\"left\">Forward Time with Backward</td>\n<td align=\"center\">3.20</td>\n<td align=\"right\">2.49</td>\n</tr>\n<tr>\n<td align=\"left\">Backward Time</td>\n<td align=\"center\">9.48</td>\n<td align=\"right\">8.12</td>\n</tr>\n</tbody>\n</table>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Test2 time (sec)</th>\n<th align=\"center\">OOB</th>\n<th align=\"right\">OPT</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Forward Time without Backward</td>\n<td align=\"center\">5.33</td>\n<td align=\"right\">5.44</td>\n</tr>\n<tr>\n<td align=\"left\">Forward Time with Backward</td>\n<td align=\"center\">8.06</td>\n<td align=\"right\">5.52</td>\n</tr>\n<tr>\n<td align=\"left\">Backward Time</td>\n<td align=\"center\">23.47</td>\n<td align=\"right\">16.84</td>\n</tr>\n</tbody>\n</table>\n<p>The results shows:</p>\n<ul>\n<li>Once backward() is run, forward time increases. The reason I guess is that, Pytorch will spawn another p-thread on CPU to do backward tasks. The new p-thread competes with the forward p-thread, both of which will generate a set of OMP threads.</li>\n<li>For OPT version which applies only one p-thread, forward time do not increase as OOB version.</li>\n<li>This also help improve backward performance.</li>\n<li>As long as there are tasks allocated for CPU and the tasks time is non-trivial, Pytorch suffers from the two p-threads parallelism mechanism.</li>\n</ul>\n<h2>Codes and Scripts</h2>\n<p>All has been pushed: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"330562986\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/8278\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytorch/pytorch/pull/8278/hovercard\" href=\"https://github.com/pytorch/pytorch/pull/8278\">#8278</a>, including changed engine.cpp, test scripts and resulting logs.<br>\nDetails see: <a href=\"https://github.com/pytorch/pytorch/pull/8278/files\">https://github.com/pytorch/pytorch/pull/8278/files</a></p>\n<p>Env:<br>\nIntel(R) Core(TM) i7-5960X CPU @ 3.00GHz, with 8 CPUs.<br>\nGTX960.</p>", "body_text": "Issue description\nCPU performance decreases after PR: Parallelize autograd backwards.\nSimilar with issue #975.\nTwo tests: 1 Conv2d tasks for CPU. 2 Conv2d tasks for CPU and GPU. I apply two versions of Pytorch: OOB is the out of box version of Pytorch, and OPT is a changed version in which I hard code to not spawn additional p-thread on CPU.\n\n\n\nTest1 time (sec)\nOOB\nOPT\n\n\n\n\nForward Time without Backward\n2.58\n2.66\n\n\nForward Time with Backward\n3.20\n2.49\n\n\nBackward Time\n9.48\n8.12\n\n\n\n\n\n\nTest2 time (sec)\nOOB\nOPT\n\n\n\n\nForward Time without Backward\n5.33\n5.44\n\n\nForward Time with Backward\n8.06\n5.52\n\n\nBackward Time\n23.47\n16.84\n\n\n\nThe results shows:\n\nOnce backward() is run, forward time increases. The reason I guess is that, Pytorch will spawn another p-thread on CPU to do backward tasks. The new p-thread competes with the forward p-thread, both of which will generate a set of OMP threads.\nFor OPT version which applies only one p-thread, forward time do not increase as OOB version.\nThis also help improve backward performance.\nAs long as there are tasks allocated for CPU and the tasks time is non-trivial, Pytorch suffers from the two p-threads parallelism mechanism.\n\nCodes and Scripts\nAll has been pushed: #8278, including changed engine.cpp, test scripts and resulting logs.\nDetails see: https://github.com/pytorch/pytorch/pull/8278/files\nEnv:\nIntel(R) Core(TM) i7-5960X CPU @ 3.00GHz, with 8 CPUs.\nGTX960.", "body": "## Issue description\r\n\r\nCPU performance decreases after PR: Parallelize autograd backwards.\r\nSimilar with issue https://github.com/pytorch/pytorch/issues/975.\r\n\r\nTwo tests: 1 Conv2d tasks for CPU. 2 Conv2d tasks for CPU and GPU. I apply two versions of Pytorch: OOB is the out of box version of Pytorch, and OPT is a changed version in which I hard code to not spawn additional p-thread on CPU.   \r\n\r\n| Test1 time (sec) | OOB | OPT |\r\n| :--- | :----: | ----: |\r\n| Forward Time without Backward| 2.58 | 2.66 |\r\n| Forward Time with Backward | 3.20 | 2.49 |\r\n| Backward Time | 9.48 | 8.12 |\r\n\r\n| Test2 time (sec) | OOB | OPT |\r\n| :--- | :----: | ----: |\r\n| Forward Time without Backward| 5.33 | 5.44 |\r\n| Forward Time with Backward | 8.06 | 5.52 |\r\n| Backward Time | 23.47 | 16.84 |\r\n\r\nThe results shows:  \r\n\r\n* Once backward() is run, forward time increases. The reason I guess is that, Pytorch will spawn another p-thread on CPU to do backward tasks. The new p-thread competes with the forward p-thread, both of which will generate a set of OMP threads.\r\n* For OPT version which applies only one p-thread, forward time do not increase as OOB version.\r\n* This also help improve backward performance.\r\n* As long as there are tasks allocated for CPU and the tasks time is non-trivial, Pytorch suffers from the two p-threads parallelism mechanism.\r\n\r\n## Codes and Scripts\r\nAll has been pushed: #8278, including changed engine.cpp, test scripts and resulting logs. \r\nDetails see: https://github.com/pytorch/pytorch/pull/8278/files\r\n\r\nEnv:\r\nIntel(R) Core(TM) i7-5960X CPU @ 3.00GHz, with 8 CPUs.\r\nGTX960.\r\n\r\n"}