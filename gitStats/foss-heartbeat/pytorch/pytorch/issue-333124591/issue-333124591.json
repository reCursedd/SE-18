{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8594", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8594/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8594/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8594/events", "html_url": "https://github.com/pytorch/pytorch/issues/8594", "id": 333124591, "node_id": "MDU6SXNzdWUzMzMxMjQ1OTE=", "number": 8594, "title": "PyTorch 0.4 hangs with nn.DataParallel ", "user": {"login": "minimumnz", "id": 1134580, "node_id": "MDQ6VXNlcjExMzQ1ODA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1134580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/minimumnz", "html_url": "https://github.com/minimumnz", "followers_url": "https://api.github.com/users/minimumnz/followers", "following_url": "https://api.github.com/users/minimumnz/following{/other_user}", "gists_url": "https://api.github.com/users/minimumnz/gists{/gist_id}", "starred_url": "https://api.github.com/users/minimumnz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/minimumnz/subscriptions", "organizations_url": "https://api.github.com/users/minimumnz/orgs", "repos_url": "https://api.github.com/users/minimumnz/repos", "events_url": "https://api.github.com/users/minimumnz/events{/privacy}", "received_events_url": "https://api.github.com/users/minimumnz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 545367190, "node_id": "MDU6TGFiZWw1NDUzNjcxOTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ailzhang", "id": 5248122, "node_id": "MDQ6VXNlcjUyNDgxMjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5248122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ailzhang", "html_url": "https://github.com/ailzhang", "followers_url": "https://api.github.com/users/ailzhang/followers", "following_url": "https://api.github.com/users/ailzhang/following{/other_user}", "gists_url": "https://api.github.com/users/ailzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ailzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ailzhang/subscriptions", "organizations_url": "https://api.github.com/users/ailzhang/orgs", "repos_url": "https://api.github.com/users/ailzhang/repos", "events_url": "https://api.github.com/users/ailzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/ailzhang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-06-18T03:41:11Z", "updated_at": "2018-07-16T11:44:49Z", "closed_at": "2018-07-05T23:26:38Z", "author_association": "NONE", "body_html": "<p>I have an issue that matches <a href=\"url\">https://github.com/pytorch/pytorch/issues/7019</a> but the suggested solution does not work for me.</p>\n<p>This code never returns a value to y:</p>\n<pre><code>import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass NET(nn.Module):\n    def __init__(self):\n        super(NET, self).__init__()\n        self.dense = nn.Linear(256, 512)\n\n    def forward(self, input):\n        return self.dense(input)\n\nif __name__ == '__main__':\n    model = NET()\n    model = nn.DataParallel(model).cuda()\n    x = Variable(torch.rand(128, 256))\n    y = model(x) ##### &lt;&lt;&lt;&lt;--- GETS STUCK HERE FOREVER\n</code></pre>\n<p>the solution was to delete  NCCL_SHM_DISABLE=1 and NCCL_P2P_DISABLE=1 from /etc/nccl.conf</p>\n<p>I do not have a /etc/nccl.conf in Ubuntu 18.04 but I did unset those environment variables and I get this:</p>\n<p>NCCL version 2.1.15+cuda9.0<br>\nrig:2637:2637 [0] INFO NET : Using interface enp0s31f6:192.168.85.32&lt;0&gt;<br>\nrig:2637:2637 [0] INFO NET/Socket : 1 interfaces found<br>\nrig:2637:2637 [3] INFO Using 256 threads<br>\nrig:2637:2637 [3] INFO Min Comp Cap 6<br>\nrig:2637:2637 [3] INFO NCCL_SINGLE_RING_THRESHOLD=131072<br>\nrig:2637:2637 [3] INFO Ring 00 : 0 1 2 3<br>\nrig:2637:2637 [0] INFO Ring 00 : 0[0] -&gt; 1[1] via P2P/direct pointer<br>\nrig:2637:2637 [1] INFO Ring 00 : 1[1] -&gt; 2[2] via P2P/direct pointer<br>\nrig:2637:2637 [2] INFO Ring 00 : 2[2] -&gt; 3[3] via P2P/direct pointer<br>\nrig:2637:2637 [3] INFO Ring 00 : 3[3] -&gt; 0[0] via P2P/direct pointer<br>\nrig:2637:2637 [0] INFO Launch mode Group/CGMD<br>\n^C gives:<br>\nFile \"/home/minimumnz/anaconda3/envs/tacotron/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock<br>\nelif lock.acquire(block, timeout):</p>\n<p>it seems stuck in some thread.</p>\n<pre><code>Collecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No \nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 18.04 LTS \nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0 \nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: Yes \nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.67\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\n\nVersions of relevant libraries:\n[pip] numpy (1.14.5)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda90 1.0 h6433d27_0 pytorch\n[conda] pytorch 0.4.0 py36_cuda9.0.176_cudnn7.1.2_1 [cuda90] pytorch\n[conda] torch 0.4.0 \n[conda] torchvision 0.2.1 py36_1 pytorch\n</code></pre>", "body_text": "I have an issue that matches https://github.com/pytorch/pytorch/issues/7019 but the suggested solution does not work for me.\nThis code never returns a value to y:\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass NET(nn.Module):\n    def __init__(self):\n        super(NET, self).__init__()\n        self.dense = nn.Linear(256, 512)\n\n    def forward(self, input):\n        return self.dense(input)\n\nif __name__ == '__main__':\n    model = NET()\n    model = nn.DataParallel(model).cuda()\n    x = Variable(torch.rand(128, 256))\n    y = model(x) ##### <<<<--- GETS STUCK HERE FOREVER\n\nthe solution was to delete  NCCL_SHM_DISABLE=1 and NCCL_P2P_DISABLE=1 from /etc/nccl.conf\nI do not have a /etc/nccl.conf in Ubuntu 18.04 but I did unset those environment variables and I get this:\nNCCL version 2.1.15+cuda9.0\nrig:2637:2637 [0] INFO NET : Using interface enp0s31f6:192.168.85.32<0>\nrig:2637:2637 [0] INFO NET/Socket : 1 interfaces found\nrig:2637:2637 [3] INFO Using 256 threads\nrig:2637:2637 [3] INFO Min Comp Cap 6\nrig:2637:2637 [3] INFO NCCL_SINGLE_RING_THRESHOLD=131072\nrig:2637:2637 [3] INFO Ring 00 : 0 1 2 3\nrig:2637:2637 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/direct pointer\nrig:2637:2637 [1] INFO Ring 00 : 1[1] -> 2[2] via P2P/direct pointer\nrig:2637:2637 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/direct pointer\nrig:2637:2637 [3] INFO Ring 00 : 3[3] -> 0[0] via P2P/direct pointer\nrig:2637:2637 [0] INFO Launch mode Group/CGMD\n^C gives:\nFile \"/home/minimumnz/anaconda3/envs/tacotron/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\nelif lock.acquire(block, timeout):\nit seems stuck in some thread.\nCollecting environment information...\nPyTorch version: 0.4.0\nIs debug build: No \nCUDA used to build PyTorch: 9.0.176\n\nOS: Ubuntu 18.04 LTS \nGCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0 \nCMake version: Could not collect\n\nPython version: 3.6\nIs CUDA available: Yes \nCUDA runtime version: Could not collect\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\n\nNvidia driver version: 390.67\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\n/usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\n\nVersions of relevant libraries:\n[pip] numpy (1.14.5)\n[pip] torch (0.4.0)\n[pip] torchvision (0.2.1)\n[conda] cuda90 1.0 h6433d27_0 pytorch\n[conda] pytorch 0.4.0 py36_cuda9.0.176_cudnn7.1.2_1 [cuda90] pytorch\n[conda] torch 0.4.0 \n[conda] torchvision 0.2.1 py36_1 pytorch", "body": "I have an issue that matches [https://github.com/pytorch/pytorch/issues/7019](url) but the suggested solution does not work for me.\r\n\r\nThis code never returns a value to y:\r\n\r\n    import torch\r\n    import torch.nn as nn\r\n    from torch.autograd import Variable\r\n\r\n    class NET(nn.Module):\r\n        def __init__(self):\r\n            super(NET, self).__init__()\r\n            self.dense = nn.Linear(256, 512)\r\n\r\n        def forward(self, input):\r\n            return self.dense(input)\r\n\r\n    if __name__ == '__main__':\r\n        model = NET()\r\n        model = nn.DataParallel(model).cuda()\r\n        x = Variable(torch.rand(128, 256))\r\n        y = model(x) ##### <<<<--- GETS STUCK HERE FOREVER\r\n\r\nthe solution was to delete  NCCL_SHM_DISABLE=1 and NCCL_P2P_DISABLE=1 from /etc/nccl.conf\r\n\r\nI do not have a /etc/nccl.conf in Ubuntu 18.04 but I did unset those environment variables and I get this:\r\n\r\nNCCL version 2.1.15+cuda9.0\r\nrig:2637:2637 [0] INFO NET : Using interface enp0s31f6:192.168.85.32<0>\r\nrig:2637:2637 [0] INFO NET/Socket : 1 interfaces found\r\nrig:2637:2637 [3] INFO Using 256 threads\r\nrig:2637:2637 [3] INFO Min Comp Cap 6\r\nrig:2637:2637 [3] INFO NCCL_SINGLE_RING_THRESHOLD=131072\r\nrig:2637:2637 [3] INFO Ring 00 : 0 1 2 3\r\nrig:2637:2637 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/direct pointer\r\nrig:2637:2637 [1] INFO Ring 00 : 1[1] -> 2[2] via P2P/direct pointer\r\nrig:2637:2637 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/direct pointer\r\nrig:2637:2637 [3] INFO Ring 00 : 3[3] -> 0[0] via P2P/direct pointer\r\nrig:2637:2637 [0] INFO Launch mode Group/CGMD\r\n^C gives:\r\nFile \"/home/minimumnz/anaconda3/envs/tacotron/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\r\nelif lock.acquire(block, timeout):\r\n\r\nit seems stuck in some thread.\r\n\r\n    Collecting environment information...\r\n    PyTorch version: 0.4.0\r\n    Is debug build: No \r\n    CUDA used to build PyTorch: 9.0.176\r\n\r\n    OS: Ubuntu 18.04 LTS \r\n    GCC version: (Ubuntu 7.3.0-16ubuntu3) 7.3.0 \r\n    CMake version: Could not collect\r\n\r\n    Python version: 3.6\r\n    Is CUDA available: Yes \r\n    CUDA runtime version: Could not collect\r\n    GPU models and configuration:\r\n    GPU 0: GeForce GTX 1080 Ti\r\n    GPU 1: GeForce GTX 1080 Ti\r\n    GPU 2: GeForce GTX 1080 Ti\r\n    GPU 3: GeForce GTX 1080 Ti\r\n\r\n    Nvidia driver version: 390.67\r\n    cuDNN version: Probably one of the following:\r\n    /usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.3\r\n    /usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a\r\n\r\n    Versions of relevant libraries:\r\n    [pip] numpy (1.14.5)\r\n    [pip] torch (0.4.0)\r\n    [pip] torchvision (0.2.1)\r\n    [conda] cuda90 1.0 h6433d27_0 pytorch\r\n    [conda] pytorch 0.4.0 py36_cuda9.0.176_cudnn7.1.2_1 [cuda90] pytorch\r\n    [conda] torch 0.4.0 \r\n    [conda] torchvision 0.2.1 py36_1 pytorch"}