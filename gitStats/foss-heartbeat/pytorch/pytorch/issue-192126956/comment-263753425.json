{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/263753425", "html_url": "https://github.com/pytorch/pytorch/issues/263#issuecomment-263753425", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/263", "id": 263753425, "node_id": "MDEyOklzc3VlQ29tbWVudDI2Mzc1MzQyNQ==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-30T01:16:39Z", "updated_at": "2016-11-30T01:16:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The problem with <code>dropout_state</code> tensor being saved in the module is that currently there is no way to attach initialized states to the dropout descriptor. We plan to change it, but only in cudnn v7, which is some time from now. So for now there are two options, neither of them good - either saving initialized cudnnDropoutDescriptor along with the states in the module (ugly), or saving states tensor in the module, then allocating new memory for states and calling setDropoutDescriptor in the function (like it is done now), and then copying the contents of states tensor to the allocated memory (also ugly, because one pays performance penalty of initializing the states that later will be overwritten by the saved tensor from the module, besides, on wide GPUs like P100 running states initialization kernel requires 600+ GB of memory, which one might want to avoid).</p>", "body_text": "The problem with dropout_state tensor being saved in the module is that currently there is no way to attach initialized states to the dropout descriptor. We plan to change it, but only in cudnn v7, which is some time from now. So for now there are two options, neither of them good - either saving initialized cudnnDropoutDescriptor along with the states in the module (ugly), or saving states tensor in the module, then allocating new memory for states and calling setDropoutDescriptor in the function (like it is done now), and then copying the contents of states tensor to the allocated memory (also ugly, because one pays performance penalty of initializing the states that later will be overwritten by the saved tensor from the module, besides, on wide GPUs like P100 running states initialization kernel requires 600+ GB of memory, which one might want to avoid).", "body": "The problem with ```dropout_state``` tensor being saved in the module is that currently there is no way to attach initialized states to the dropout descriptor. We plan to change it, but only in cudnn v7, which is some time from now. So for now there are two options, neither of them good - either saving initialized cudnnDropoutDescriptor along with the states in the module (ugly), or saving states tensor in the module, then allocating new memory for states and calling setDropoutDescriptor in the function (like it is done now), and then copying the contents of states tensor to the allocated memory (also ugly, because one pays performance penalty of initializing the states that later will be overwritten by the saved tensor from the module, besides, on wide GPUs like P100 running states initialization kernel requires 600+ GB of memory, which one might want to avoid). "}