{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/356038246", "html_url": "https://github.com/pytorch/pytorch/pull/4502#issuecomment-356038246", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4502", "id": 356038246, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjAzODI0Ng==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-08T17:39:45Z", "updated_at": "2018-01-08T17:39:45Z", "author_association": "MEMBER", "body_html": "<p>A few high-level comments:</p>\n<p>The equivalent NumPy function is <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.solve.html\" rel=\"nofollow\">np.linalg.solve</a></p>\n<ol>\n<li>We should prefer one function that handles batched and non-batched computation.</li>\n<li>We should treat the left-most dimensions as part of the batch. For example, the 4-d tensor <code>A x B x M x M</code> should be treated as batch-size <code>(A x B)</code>.</li>\n<li>It would be good to support broadcasting</li>\n<li>When adding new functions, consider adding them as native functions to ATen.</li>\n</ol>\n<p>You don't have to block the PR on these suggestions, but if it's not too much extra work see if you can merge gesv and bgesv so that we don't unnecessarily expand the public API.</p>", "body_text": "A few high-level comments:\nThe equivalent NumPy function is np.linalg.solve\n\nWe should prefer one function that handles batched and non-batched computation.\nWe should treat the left-most dimensions as part of the batch. For example, the 4-d tensor A x B x M x M should be treated as batch-size (A x B).\nIt would be good to support broadcasting\nWhen adding new functions, consider adding them as native functions to ATen.\n\nYou don't have to block the PR on these suggestions, but if it's not too much extra work see if you can merge gesv and bgesv so that we don't unnecessarily expand the public API.", "body": "A few high-level comments:\r\n\r\nThe equivalent NumPy function is [np.linalg.solve](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.solve.html)\r\n\r\n1) We should prefer one function that handles batched and non-batched computation.\r\n2) We should treat the left-most dimensions as part of the batch. For example, the 4-d tensor `A x B x M x M` should be treated as batch-size `(A x B)`.\r\n3) It would be good to support broadcasting\r\n4) When adding new functions, consider adding them as native functions to ATen.\r\n\r\nYou don't have to block the PR on these suggestions, but if it's not too much extra work see if you can merge gesv and bgesv so that we don't unnecessarily expand the public API."}