{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/275915070", "html_url": "https://github.com/pytorch/pytorch/issues/101#issuecomment-275915070", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/101", "id": 275915070, "node_id": "MDEyOklzc3VlQ29tbWVudDI3NTkxNTA3MA==", "user": {"login": "felipefariax", "id": 6319642, "node_id": "MDQ6VXNlcjYzMTk2NDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/6319642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/felipefariax", "html_url": "https://github.com/felipefariax", "followers_url": "https://api.github.com/users/felipefariax/followers", "following_url": "https://api.github.com/users/felipefariax/following{/other_user}", "gists_url": "https://api.github.com/users/felipefariax/gists{/gist_id}", "starred_url": "https://api.github.com/users/felipefariax/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/felipefariax/subscriptions", "organizations_url": "https://api.github.com/users/felipefariax/orgs", "repos_url": "https://api.github.com/users/felipefariax/repos", "events_url": "https://api.github.com/users/felipefariax/events{/privacy}", "received_events_url": "https://api.github.com/users/felipefariax/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-29T13:51:24Z", "updated_at": "2017-01-29T13:59:18Z", "author_association": "NONE", "body_html": "<p>I thought to add another class called <code>Initializers</code> with a function that we could pass the weights and a string with the <code>initialization</code> name. Also add a string argument to every layer called \"initialization\".</p>\n<p>In a Linear layer the init should be something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">in_features</span>, <span class=\"pl-smi\">out_features</span>, <span class=\"pl-smi\">bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-smi\">initializer</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-c1\">super</span>(Linear, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n    <span class=\"pl-c1\">self</span>.in_features <span class=\"pl-k\">=</span> in_features\n    <span class=\"pl-c1\">self</span>.out_features <span class=\"pl-k\">=</span> out_features\n    <span class=\"pl-c1\">self</span>.weight <span class=\"pl-k\">=</span> Parameter(torch.Tensor(out_features, in_features))\n    Initializers.initialize(<span class=\"pl-c1\">self</span>.weight, initializer)\n    <span class=\"pl-k\">if</span> bias:\n        <span class=\"pl-c1\">self</span>.bias <span class=\"pl-k\">=</span> Parameter(torch.Tensor(out_features))\n    <span class=\"pl-k\">else</span>:\n        <span class=\"pl-c1\">self</span>.register_parameter(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>bias<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">None</span>)\n    <span class=\"pl-c1\">self</span>.reset_parameters()</pre></div>\n<p>Do you think that this is the best approach? If not, what would be the best way to do this?</p>", "body_text": "I thought to add another class called Initializers with a function that we could pass the weights and a string with the initialization name. Also add a string argument to every layer called \"initialization\".\nIn a Linear layer the init should be something like this:\ndef __init__(self, in_features, out_features, bias=True, initializer=None):\n    super(Linear, self).__init__()\n    self.in_features = in_features\n    self.out_features = out_features\n    self.weight = Parameter(torch.Tensor(out_features, in_features))\n    Initializers.initialize(self.weight, initializer)\n    if bias:\n        self.bias = Parameter(torch.Tensor(out_features))\n    else:\n        self.register_parameter('bias', None)\n    self.reset_parameters()\nDo you think that this is the best approach? If not, what would be the best way to do this?", "body": "I thought to add another class called `Initializers` with a function that we could pass the weights and a string with the `initialization` name. Also add a string argument to every layer called \"initialization\".\r\n\r\nIn a Linear layer the init should be something like this:\r\n```python\r\ndef __init__(self, in_features, out_features, bias=True, initializer=None):\r\n    super(Linear, self).__init__()\r\n    self.in_features = in_features\r\n    self.out_features = out_features\r\n    self.weight = Parameter(torch.Tensor(out_features, in_features))\r\n    Initializers.initialize(self.weight, initializer)\r\n    if bias:\r\n        self.bias = Parameter(torch.Tensor(out_features))\r\n    else:\r\n        self.register_parameter('bias', None)\r\n    self.reset_parameters()\r\n```\r\n\r\nDo you think that this is the best approach? If not, what would be the best way to do this?"}