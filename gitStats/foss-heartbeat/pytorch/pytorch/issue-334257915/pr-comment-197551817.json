{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197551817", "pull_request_review_id": 131325842, "id": 197551817, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE5NzU1MTgxNw==", "diff_hunk": "@@ -0,0 +1,150 @@\n+#pragma once\n+\n+#include \"caffe2/utils/flat_hash_map/flat_hash_map.h\"\n+#include \"caffe2/utils/Metaprogramming.h\"\n+#include \"caffe2/core/dispatch/OpSchema.h\"\n+\n+#include <type_traits>\n+#include <array>\n+#include <unordered_map>\n+#include <iostream>\n+#include <mutex>\n+\n+namespace c10 {\n+\n+namespace details {\n+\n+/// Internal implementation of the operator as a thread-safe hash table.\n+template<class Key>\n+class ThreadsafeOperatorTable_ final {\n+public:\n+    // TODO The current implementation below does not have the correct correctness characteristics\n+    // which we need.  It's worth spelling out exactly what we need:\n+    //\n+    //  - We need LOCK FREE read access to the table (as per the performance benchmark\n+    //    at https://fb.quip.com/hvz3AGnx8MQ8\n+    //\n+    //  - We need to support writes which are possibly concurrent with reads, occurring when\n+    //    a dynamic library is loaded or unloaded.\n+    //\n+    //  - We probably can require that dynamic library loads/unloads be synchronized (so\n+    //    there are never two concurrent loads.)\n+\n+    template<class Key_>\n+    void emplace(Key_&& key, void* value) {\n+      // TODO Locking\n+      //std::unique_lock<std::shared_timed_mutex> lock(mutex_);\n+\n+      auto result = map_.emplace(std::forward<Key>(key), value);\n+      if (!result.second) {\n+        throw std::logic_error(\"Tried to register conflicting operators to the dispatcher.\");\n+      }\n+    }\n+\n+    void erase(const Key& key) {\n+      // TODO Locking\n+      //std::unique_lock<std::shared_timed_mutex> lock(mutex_);\n+\n+      size_t num_removed = map_.erase(key);\n+      assert(num_removed <= 1); //This is not a multi-map\n+      if (num_removed == 0) {\n+        throw std::logic_error(\"Tried to deregister an operator that isn't registered.\");\n+      }\n+    }\n+\n+    void* lookup(const Key& key) const {\n+      // TODO (lock needed but slow perf. Find better way)\n+      // std::shared_lock<std::shared_timed_mutex> lock(mutex_);\n+      auto found = map_.find(key);\n+      if (found == map_.end()) {\n+        return nullptr;\n+      } else {\n+        return found->second;\n+      }\n+    }\n+\n+private:\n+    ska::flat_hash_map<Key, void*> map_;\n+    // TODO Figure out how to get fast locking in C++11 (use boost::shared_timed_mutex? folly::SharedMutex?)", "path": "caffe2/core/dispatch/DispatchTable.h", "position": null, "original_position": 68, "commit_id": "ba0e6257fb2e4e27e2872d8d318850a043da4e7e", "original_commit_id": "c69ba483a9edf47816ddec00987d0ac11df02916", "user": {"login": "smessmer", "id": 2373925, "node_id": "MDQ6VXNlcjIzNzM5MjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/2373925?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smessmer", "html_url": "https://github.com/smessmer", "followers_url": "https://api.github.com/users/smessmer/followers", "following_url": "https://api.github.com/users/smessmer/following{/other_user}", "gists_url": "https://api.github.com/users/smessmer/gists{/gist_id}", "starred_url": "https://api.github.com/users/smessmer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smessmer/subscriptions", "organizations_url": "https://api.github.com/users/smessmer/orgs", "repos_url": "https://api.github.com/users/smessmer/repos", "events_url": "https://api.github.com/users/smessmer/events{/privacy}", "received_events_url": "https://api.github.com/users/smessmer/received_events", "type": "User", "site_admin": false}, "body": "I tested it with `std::shared_timed_mutex` (variant of `std::mutex` for fast reading) and it was horribly slow. Without the mutex, my benchmarks weren't able to see any perf overhead of the dispatcher. With the mutex, it was noticeable.\r\n\r\nI'm not sure what the best way to go forward here is, I can either enable it and allow the perf regression, or disable it and it will crash in the (unlikely) case that two kernel libraries are loaded and try to register kernels at exactly the same time.\r\n\r\nIn any case, there will be a high-pri follow-up item to fix this and introduce a fast mutex.", "created_at": "2018-06-22T19:49:33Z", "updated_at": "2018-11-23T15:46:08Z", "html_url": "https://github.com/pytorch/pytorch/pull/8713#discussion_r197551817", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/8713", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/197551817"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/8713#discussion_r197551817"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/8713"}}, "body_html": "<p>I tested it with <code>std::shared_timed_mutex</code> (variant of <code>std::mutex</code> for fast reading) and it was horribly slow. Without the mutex, my benchmarks weren't able to see any perf overhead of the dispatcher. With the mutex, it was noticeable.</p>\n<p>I'm not sure what the best way to go forward here is, I can either enable it and allow the perf regression, or disable it and it will crash in the (unlikely) case that two kernel libraries are loaded and try to register kernels at exactly the same time.</p>\n<p>In any case, there will be a high-pri follow-up item to fix this and introduce a fast mutex.</p>", "body_text": "I tested it with std::shared_timed_mutex (variant of std::mutex for fast reading) and it was horribly slow. Without the mutex, my benchmarks weren't able to see any perf overhead of the dispatcher. With the mutex, it was noticeable.\nI'm not sure what the best way to go forward here is, I can either enable it and allow the perf regression, or disable it and it will crash in the (unlikely) case that two kernel libraries are loaded and try to register kernels at exactly the same time.\nIn any case, there will be a high-pri follow-up item to fix this and introduce a fast mutex.", "in_reply_to_id": 197323301}