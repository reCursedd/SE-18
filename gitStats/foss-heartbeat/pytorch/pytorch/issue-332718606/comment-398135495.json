{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/398135495", "html_url": "https://github.com/pytorch/pytorch/issues/8549#issuecomment-398135495", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/8549", "id": 398135495, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODEzNTQ5NQ==", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-18T17:37:29Z", "updated_at": "2018-06-18T17:37:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The amounts of tensors might be on the scale of thousands, so it's probably no reasonable to print the list of tensors. Btw, your script doesn't detect tensors that only live in c++ side. You can use <code>torch.cuda.max_memory_allocated()</code> to get the current amount of memory used.</p>\n<p>Printing the size of the attempted allocation is reasonable and I think we should do this.</p>", "body_text": "The amounts of tensors might be on the scale of thousands, so it's probably no reasonable to print the list of tensors. Btw, your script doesn't detect tensors that only live in c++ side. You can use torch.cuda.max_memory_allocated() to get the current amount of memory used.\nPrinting the size of the attempted allocation is reasonable and I think we should do this.", "body": "The amounts of tensors might be on the scale of thousands, so it's probably no reasonable to print the list of tensors. Btw, your script doesn't detect tensors that only live in c++ side. You can use `torch.cuda.max_memory_allocated()` to get the current amount of memory used.\r\n\r\nPrinting the size of the attempted allocation is reasonable and I think we should do this. "}