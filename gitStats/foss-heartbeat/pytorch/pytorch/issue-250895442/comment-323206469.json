{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/323206469", "html_url": "https://github.com/pytorch/pytorch/issues/2470#issuecomment-323206469", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2470", "id": 323206469, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzIwNjQ2OQ==", "user": {"login": "ngimel", "id": 15841449, "node_id": "MDQ6VXNlcjE1ODQxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/15841449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngimel", "html_url": "https://github.com/ngimel", "followers_url": "https://api.github.com/users/ngimel/followers", "following_url": "https://api.github.com/users/ngimel/following{/other_user}", "gists_url": "https://api.github.com/users/ngimel/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngimel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngimel/subscriptions", "organizations_url": "https://api.github.com/users/ngimel/orgs", "repos_url": "https://api.github.com/users/ngimel/repos", "events_url": "https://api.github.com/users/ngimel/events{/privacy}", "received_events_url": "https://api.github.com/users/ngimel/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-17T22:01:24Z", "updated_at": "2017-08-17T22:03:47Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Actually, std/var implementations are inconsistent both in TH and THC, for tensors and for variables.<br>\nFor tensors:</p>\n<ol>\n<li>in both TH and THC .var() is doing a two-pass variance calculation.</li>\n<li>in both TH and THC .var(dim) is doing one-pass unstable variance calculation, however, in TH it accumulates in double, in THC it accumulates in float for float inputs. Even with double accumulation, it is really unstable, as original poster has shown. For half type in cuda, it will be truncated to half at each step, so it is basically unusable. In cuda, special kernels are used for that.</li>\n</ol>\n<p>For variables all the std calculations are done using two-pass algorithm, which is better than one-pass naive, but still worse than one-pass Welford. It is implemented via tensor ops (calculate mean, subtract mean, do pointwise multiply, reduce). For cuda, it also results in bad performance, because 5-7 kernels and a coupe of synchronous d2h transfers are launched for each variance computation. The following script compares tensor/var performance on cuda, with 3x-4x slower perf for variables.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">timeit</span>(<span class=\"pl-smi\">fn</span>, <span class=\"pl-smi\">nrep</span>, <span class=\"pl-smi\">args</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    torch.cuda.synchronize()\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(nrep):\n       <span class=\"pl-k\">if</span> args <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n           fn(args)\n       <span class=\"pl-k\">else</span>:\n           fn()\n    torch.cuda.synchronize()\n    <span class=\"pl-c1\">print</span>((time.time()<span class=\"pl-k\">-</span>start)<span class=\"pl-k\">*</span><span class=\"pl-c1\">1000</span>.<span class=\"pl-k\">/</span><span class=\"pl-c1\">float</span>(nrep), <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ms<span class=\"pl-pds\">\"</span></span>)\n\na<span class=\"pl-k\">=</span>torch.randn(<span class=\"pl-c1\">512</span>,<span class=\"pl-c1\">2048</span>).cuda()\nnrep <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\ntimeit(a.var, nrep)\ntimeit(a.var, nrep, <span class=\"pl-c1\">0</span>)\ntimeit(a.var, nrep, <span class=\"pl-c1\">1</span>)\na<span class=\"pl-k\">=</span>Variable(a)\ntimeit(a.var, nrep)\ntimeit(a.var, nrep, <span class=\"pl-c1\">0</span>)\ntimeit(a.var, nrep, <span class=\"pl-c1\">1</span>)</pre></div>\n<p>Also, almost everywhere mean and std are computed together, so mean computation is essentially repeated when std is computed. So the questions here are</p>\n<ol>\n<li>does it make sense to have mean_std api to compute mean and variance/std together?</li>\n<li>does it make sense to have special implementation for variables the way there are implementations now for tensors (though we cannot reuse current tensor implementations because they are broken)? It would also require special kernels for backward. It should help weight norm/layer norm layers.</li>\n</ol>", "body_text": "Actually, std/var implementations are inconsistent both in TH and THC, for tensors and for variables.\nFor tensors:\n\nin both TH and THC .var() is doing a two-pass variance calculation.\nin both TH and THC .var(dim) is doing one-pass unstable variance calculation, however, in TH it accumulates in double, in THC it accumulates in float for float inputs. Even with double accumulation, it is really unstable, as original poster has shown. For half type in cuda, it will be truncated to half at each step, so it is basically unusable. In cuda, special kernels are used for that.\n\nFor variables all the std calculations are done using two-pass algorithm, which is better than one-pass naive, but still worse than one-pass Welford. It is implemented via tensor ops (calculate mean, subtract mean, do pointwise multiply, reduce). For cuda, it also results in bad performance, because 5-7 kernels and a coupe of synchronous d2h transfers are launched for each variance computation. The following script compares tensor/var performance on cuda, with 3x-4x slower perf for variables.\nimport torch\nimport time\nfrom torch.autograd import Variable\n\n\ndef timeit(fn, nrep, args=None):\n    torch.cuda.synchronize()\n    start = time.time()\n    for i in range(nrep):\n       if args is not None:\n           fn(args)\n       else:\n           fn()\n    torch.cuda.synchronize()\n    print((time.time()-start)*1000./float(nrep), \"ms\")\n\na=torch.randn(512,2048).cuda()\nnrep = 100\ntimeit(a.var, nrep)\ntimeit(a.var, nrep, 0)\ntimeit(a.var, nrep, 1)\na=Variable(a)\ntimeit(a.var, nrep)\ntimeit(a.var, nrep, 0)\ntimeit(a.var, nrep, 1)\nAlso, almost everywhere mean and std are computed together, so mean computation is essentially repeated when std is computed. So the questions here are\n\ndoes it make sense to have mean_std api to compute mean and variance/std together?\ndoes it make sense to have special implementation for variables the way there are implementations now for tensors (though we cannot reuse current tensor implementations because they are broken)? It would also require special kernels for backward. It should help weight norm/layer norm layers.", "body": "Actually, std/var implementations are inconsistent both in TH and THC, for tensors and for variables.\r\nFor tensors:\r\n1) in both TH and THC .var() is doing a two-pass variance calculation.\r\n2) in both TH and THC .var(dim) is doing one-pass unstable variance calculation, however, in TH it accumulates in double, in THC it accumulates in float for float inputs. Even with double accumulation, it is really unstable, as original poster has shown. For half type in cuda, it will be truncated to half at each step, so it is basically unusable. In cuda, special kernels are used for that.\r\n\r\nFor variables all the std calculations are done using two-pass algorithm, which is better than one-pass naive, but still worse than one-pass Welford. It is implemented via tensor ops (calculate mean, subtract mean, do pointwise multiply, reduce). For cuda, it also results in bad performance, because 5-7 kernels and a coupe of synchronous d2h transfers are launched for each variance computation. The following script compares tensor/var performance on cuda, with 3x-4x slower perf for variables.\r\n```.py\r\nimport torch\r\nimport time\r\nfrom torch.autograd import Variable\r\n\r\n\r\ndef timeit(fn, nrep, args=None):\r\n    torch.cuda.synchronize()\r\n    start = time.time()\r\n    for i in range(nrep):\r\n       if args is not None:\r\n           fn(args)\r\n       else:\r\n           fn()\r\n    torch.cuda.synchronize()\r\n    print((time.time()-start)*1000./float(nrep), \"ms\")\r\n\r\na=torch.randn(512,2048).cuda()\r\nnrep = 100\r\ntimeit(a.var, nrep)\r\ntimeit(a.var, nrep, 0)\r\ntimeit(a.var, nrep, 1)\r\na=Variable(a)\r\ntimeit(a.var, nrep)\r\ntimeit(a.var, nrep, 0)\r\ntimeit(a.var, nrep, 1)\r\n```\r\nAlso, almost everywhere mean and std are computed together, so mean computation is essentially repeated when std is computed. So the questions here are\r\n1) does it make sense to have mean_std api to compute mean and variance/std together?\r\n2) does it make sense to have special implementation for variables the way there are implementations now for tensors (though we cannot reuse current tensor implementations because they are broken)? It would also require special kernels for backward. It should help weight norm/layer norm layers. "}