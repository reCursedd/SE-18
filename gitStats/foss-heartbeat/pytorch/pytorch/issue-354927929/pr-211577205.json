{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/10980", "id": 211577205, "node_id": "MDExOlB1bGxSZXF1ZXN0MjExNTc3MjA1", "html_url": "https://github.com/pytorch/pytorch/pull/10980", "diff_url": "https://github.com/pytorch/pytorch/pull/10980.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/10980.patch", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/10980", "number": 10980, "state": "closed", "locked": false, "title": "[Ready] Vectorize grid sample 2d CPU kernels", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "body": "This PR vectorizes the CPU grid sample 2d forward and backward kernels. Specifically, \r\n\r\n\r\n\r\n 1. add `.data()` in `TensorAccessor`\r\n 2. support non-void return value for declaring CPU kernel stub\r\n 2. add `bool at:: geometry_is_contiguous(IntList sizes, IntList strides)`\r\n1. The following vectorized CPU primitives are added: \r\n\r\n    + `gather<scale>(baseaddr, vindex)`: `result[i] = baseaddr[vindex[i] * scale]`\r\n    + `mask_gather<scale>(src, baseaddr, vindex, mask)`: `result[i] = mask[i] ? baseaddr[vindex[i] * scale] : src[i]`. \r\n    + comparison ops\r\n    + binary logical ops\r\n    + `min(a, b)`\r\n    + `cast<dst_t, src_t>(src_vec)`: changing dtype but keeping the bit representation\r\n    + `blendv(a, b, mask)`: `result[i] = mask[i] ? b[i] : a[i]`.\r\n    + ctor with multiple values (i.e., `setr`)\r\n    + `arange(start = 0, step = 1)`: constructs a vector with values specified by the arange parameters\r\n    + `convert_to_int_of_same_size(vec)`: convert floating point vector to corresponding integral type of same size\r\n    + `interleave2(a, b)` & `deinterleave2(x, y)`: interleave or deinterleaves two vectors. E.g., for `interleave`:\r\n        ```\r\n        inputs:\r\n          {a0, a1, a2, a3, a4, a5, a6, a7}\r\n          {b0, b1, b2, b3, b4, b5, b6, b7}\r\n        outputs:\r\n          {a0, b0, a1, b1, a2, b2, a3, b3}\r\n          {a4, b4, a5, b5, a6, b6, a7, b7}\r\n        ```\r\n\r\n  2. Grid sample CPU kernel implementations are described in the following note (also in `GridSampleKernel.cpp`:\r\n\r\n  ```\r\n   NOTE [ Grid Sample CPU Kernels ]\r\n  \r\n   Implementation of vectorized grid sample CPU kernels is divided into three\r\n   parts:\r\n  \r\n   1. `ComputeLocation` struct\r\n      Transforms grid values into interpolation locations of the input tensor\r\n      for a particular spatial dimension, basing on the size of that dimension\r\n      in input tensor, and the padding mode.\r\n```\r\n```cpp\r\n      template<typename scalar_t, GridSamplerPadding padding>\r\n      struct ComputeLocation {\r\n        using Vec = Vec256<scalar_t>;\r\n  \r\n        // ctor\r\n        ComputeLocation(int64_t size);\r\n  \r\n        // Given grid values `in`, return the interpolation locations after\r\n        // un-normalization and padding mechanism (elementwise).\r\n        Vec apply(const Vec &in) const;\r\n  \r\n        // Similar to `apply`, but also returns `d apply(in) / d in`\r\n        // (elementwise).\r\n        // this is often used in gradient computation.\r\n        std::pair<Vec, Vec> apply_get_grad(const Vec &in) const;\r\n      };\r\n```\r\n```\r\n   2. `ApplyGridSample` struct\r\n      Owns N `ComputeLocation` structs, where N is the number of spatial\r\n      dimensions. Given N input grid vectors (one for each spatial dimension)\r\n      and spatial offset, it gets the interpolation locations from\r\n      `ComputeLocation`s, applies interpolation procedure, and then writes to\r\n      the output (or grad_input & grad_grid in backward).\r\n```\r\n```cpp\r\n      template<typename scalar_t, int spatial_dim,\r\n               GridSamplerInterpolation interp,\r\n               GridSamplerPadding padding>\r\n      struct ApplyGridSample {\r\n  \r\n        // ctor\r\n        ApplyGridSample(const TensorAccessor<scalar_t, 4>& input);\r\n  \r\n        // Applies grid sampling (forward) procedure:\r\n        //   1. computes interpolation locations from grid values `grid_x` and\r\n        //      `grid_y`,\r\n        //   2. interpolates output values using the locations and input data\r\n        //      in `inp_slice`, and\r\n        //   3. writes the first `len` values in the interpolated vector to\r\n        //      `out_slice` with spatial offset being `offset`.\r\n        //\r\n        // This assimes that `grid_x` and `grid_y` all contain valid grid\r\n        // values \\in [-1, 1], even at indices greater than `len`.\r\n        //\r\n        // The `*_slice` argument namess mean samples within a batch (i.e.,\r\n        // with the batch dimension sliced out).\r\n        void forward(TensorAccessor<scalar_t, 3>& out_slice,\r\n                     const TensorAccessor<scalar_t, 3>& inp_slice,\r\n                     int64_t offset, const Vec& grid_x, const Vec& grid_y,\r\n                     int64_t len) const;\r\n  \r\n        // Applies grid sampling (backward) procedure. Arguments semantics\r\n        // and strategy are similar to those of `forward`.\r\n        void backward(TensorAccessor<scalar_t, 3>& gInp_slice,\r\n                      TensorAccessor<scalar_t, 3>& gGrid_slice,\r\n                      const TensorAccessor<scalar_t, 3>& gOut_slice,\r\n                      const TensorAccessor<scalar_t, 3>& inp_slice,\r\n                      int64_t offset, const Vec& grid_x, const Vec& grid_y,\r\n                      int64_t len) const;\r\n      }\r\n```\r\n```\r\n   3. `grid_sample_2d_grid_slice_iterator` function\r\n      Among the tensors we work with, we know that the output tensors are\r\n      contiguous (i.e., `output` in forward, and `grad_input` & `grad_grid` in\r\n      backward), we need to randomly read `input` anyways, and `grad_output`\r\n      usually comes from autograd and is often contiguous. So we base our\r\n      iterating strategy on the geometry of grid.\r\n      `grid_sample_2d_grid_slice_iterator` function provides an abstract to\r\n      efficiently iterates through a `grid` slice (without batch dimension).\r\n      See comments of that function on the specific cases and strategies used.\r\n```\r\n```cpp\r\n      template<typename scalar_t, typename ApplyFn>\r\n      void grid_sample_2d_grid_slice_iterator(\r\n        const TensorAccessor<scalar_t, 3>& grid_slice,\r\n        const ApplyFn &apply_fn);\r\n\r\n      // `apply_fn` is a function/lambda that can be called as if it has\r\n      // declaration:\r\n      //   void apply_fn(const Vec256<scalar_t>& grid_x,\r\n      //                 const Vec256<scalar_t>& grid_y,\r\n      //                 int64_t spatial_offset, int64_t len);\r\n```\r\n```\r\n      `apply_fn` will be called multiple times, and together cover the entire\r\n      output spatial space. Therefore, e.g., to implement forward 2d grid\r\n      sample, we can do\r\n```\r\n```cpp\r\n      ApplyGridSample<scalar_t, 2, interp, padding> grid_sample(input_accessor);\r\n  \r\n      for (int n = 0; n < input_accessor.size(0); n++) {\r\n        grid_sample_2d_grid_slice_iterator(\r\n          grid_accessor[n],\r\n          [&](const Vec256<scalar_t>& grid_x, const Vec256<scalar_t>& grid_y,\r\n              int64_t spatial_offset, int64_t len) {\r\n            grid_sample.forward(out_accessor[n], input_accessor[n],\r\n                                spatial_offset, grid_x, grid_y, len);\r\n          });\r\n      }\r\n   ```", "created_at": "2018-08-28T22:29:39Z", "updated_at": "2018-11-23T15:51:27Z", "closed_at": "2018-09-17T03:42:15Z", "merged_at": null, "merge_commit_sha": "64ece86185c8f773bdc8cc31845314c25a68d0d7", "assignee": null, "assignees": [], "requested_reviewers": [{"login": "zdevito", "id": 370202, "node_id": "MDQ6VXNlcjM3MDIwMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/370202?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zdevito", "html_url": "https://github.com/zdevito", "followers_url": "https://api.github.com/users/zdevito/followers", "following_url": "https://api.github.com/users/zdevito/following{/other_user}", "gists_url": "https://api.github.com/users/zdevito/gists{/gist_id}", "starred_url": "https://api.github.com/users/zdevito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zdevito/subscriptions", "organizations_url": "https://api.github.com/users/zdevito/orgs", "repos_url": "https://api.github.com/users/zdevito/repos", "events_url": "https://api.github.com/users/zdevito/events{/privacy}", "received_events_url": "https://api.github.com/users/zdevito/received_events", "type": "User", "site_admin": false}, {"login": "soumith", "id": 1310570, "node_id": "MDQ6VXNlcjEzMTA1NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1310570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soumith", "html_url": "https://github.com/soumith", "followers_url": "https://api.github.com/users/soumith/followers", "following_url": "https://api.github.com/users/soumith/following{/other_user}", "gists_url": "https://api.github.com/users/soumith/gists{/gist_id}", "starred_url": "https://api.github.com/users/soumith/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soumith/subscriptions", "organizations_url": "https://api.github.com/users/soumith/orgs", "repos_url": "https://api.github.com/users/soumith/repos", "events_url": "https://api.github.com/users/soumith/events{/privacy}", "received_events_url": "https://api.github.com/users/soumith/received_events", "type": "User", "site_admin": false}, {"login": "gchanan", "id": 3768583, "node_id": "MDQ6VXNlcjM3Njg1ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/3768583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gchanan", "html_url": "https://github.com/gchanan", "followers_url": "https://api.github.com/users/gchanan/followers", "following_url": "https://api.github.com/users/gchanan/following{/other_user}", "gists_url": "https://api.github.com/users/gchanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gchanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gchanan/subscriptions", "organizations_url": "https://api.github.com/users/gchanan/orgs", "repos_url": "https://api.github.com/users/gchanan/repos", "events_url": "https://api.github.com/users/gchanan/events{/privacy}", "received_events_url": "https://api.github.com/users/gchanan/received_events", "type": "User", "site_admin": false}, {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "requested_teams": [], "labels": [{"id": 559719279, "node_id": "MDU6TGFiZWw1NTk3MTkyNzk=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/ready%20for%20review", "name": "ready for review", "color": "b60205", "default": false}], "milestone": null, "commits_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10980/commits", "review_comments_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10980/comments", "review_comment_url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10980/comments", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/78a5398f873de8d9c2a46ea7cb3a9eff1613fae6", "head": {"label": "SsnL:vec_cpu", "ref": "vec_cpu", "sha": "78a5398f873de8d9c2a46ea7cb3a9eff1613fae6", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "repo": {"id": 103305558, "node_id": "MDEwOlJlcG9zaXRvcnkxMDMzMDU1NTg=", "name": "pytorch", "full_name": "SsnL/pytorch", "private": false, "owner": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/SsnL/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": true, "url": "https://api.github.com/repos/SsnL/pytorch", "forks_url": "https://api.github.com/repos/SsnL/pytorch/forks", "keys_url": "https://api.github.com/repos/SsnL/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/SsnL/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/SsnL/pytorch/teams", "hooks_url": "https://api.github.com/repos/SsnL/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/SsnL/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/SsnL/pytorch/events", "assignees_url": "https://api.github.com/repos/SsnL/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/SsnL/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/SsnL/pytorch/tags", "blobs_url": "https://api.github.com/repos/SsnL/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/SsnL/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/SsnL/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/SsnL/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/SsnL/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/SsnL/pytorch/languages", "stargazers_url": "https://api.github.com/repos/SsnL/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/SsnL/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/SsnL/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/SsnL/pytorch/subscription", "commits_url": "https://api.github.com/repos/SsnL/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/SsnL/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/SsnL/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/SsnL/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/SsnL/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/SsnL/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/SsnL/pytorch/merges", "archive_url": "https://api.github.com/repos/SsnL/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/SsnL/pytorch/downloads", "issues_url": "https://api.github.com/repos/SsnL/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/SsnL/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/SsnL/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/SsnL/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/SsnL/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/SsnL/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/SsnL/pytorch/deployments", "created_at": "2017-09-12T18:13:43Z", "updated_at": "2018-11-04T15:36:18Z", "pushed_at": "2018-11-09T18:32:11Z", "git_url": "git://github.com/SsnL/pytorch.git", "ssh_url": "git@github.com:SsnL/pytorch.git", "clone_url": "https://github.com/SsnL/pytorch.git", "svn_url": "https://github.com/SsnL/pytorch", "homepage": "http://pytorch.org", "size": 83933, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 1, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master"}}, "base": {"label": "pytorch:master", "ref": "master", "sha": "10c29c8970a1468cd157d371a0d0b9879cb703a9", "user": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 65600975, "node_id": "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==", "name": "pytorch", "full_name": "pytorch/pytorch", "private": false, "owner": {"login": "pytorch", "id": 21003710, "node_id": "MDEyOk9yZ2FuaXphdGlvbjIxMDAzNzEw", "avatar_url": "https://avatars3.githubusercontent.com/u/21003710?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pytorch", "html_url": "https://github.com/pytorch", "followers_url": "https://api.github.com/users/pytorch/followers", "following_url": "https://api.github.com/users/pytorch/following{/other_user}", "gists_url": "https://api.github.com/users/pytorch/gists{/gist_id}", "starred_url": "https://api.github.com/users/pytorch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pytorch/subscriptions", "organizations_url": "https://api.github.com/users/pytorch/orgs", "repos_url": "https://api.github.com/users/pytorch/repos", "events_url": "https://api.github.com/users/pytorch/events{/privacy}", "received_events_url": "https://api.github.com/users/pytorch/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/pytorch/pytorch", "description": "Tensors and Dynamic neural networks in Python  with strong GPU acceleration", "fork": false, "url": "https://api.github.com/repos/pytorch/pytorch", "forks_url": "https://api.github.com/repos/pytorch/pytorch/forks", "keys_url": "https://api.github.com/repos/pytorch/pytorch/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/pytorch/pytorch/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/pytorch/pytorch/teams", "hooks_url": "https://api.github.com/repos/pytorch/pytorch/hooks", "issue_events_url": "https://api.github.com/repos/pytorch/pytorch/issues/events{/number}", "events_url": "https://api.github.com/repos/pytorch/pytorch/events", "assignees_url": "https://api.github.com/repos/pytorch/pytorch/assignees{/user}", "branches_url": "https://api.github.com/repos/pytorch/pytorch/branches{/branch}", "tags_url": "https://api.github.com/repos/pytorch/pytorch/tags", "blobs_url": "https://api.github.com/repos/pytorch/pytorch/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/pytorch/pytorch/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/pytorch/pytorch/git/refs{/sha}", "trees_url": "https://api.github.com/repos/pytorch/pytorch/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/pytorch/pytorch/statuses/{sha}", "languages_url": "https://api.github.com/repos/pytorch/pytorch/languages", "stargazers_url": "https://api.github.com/repos/pytorch/pytorch/stargazers", "contributors_url": "https://api.github.com/repos/pytorch/pytorch/contributors", "subscribers_url": "https://api.github.com/repos/pytorch/pytorch/subscribers", "subscription_url": "https://api.github.com/repos/pytorch/pytorch/subscription", "commits_url": "https://api.github.com/repos/pytorch/pytorch/commits{/sha}", "git_commits_url": "https://api.github.com/repos/pytorch/pytorch/git/commits{/sha}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/comments{/number}", "issue_comment_url": "https://api.github.com/repos/pytorch/pytorch/issues/comments{/number}", "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/{+path}", "compare_url": "https://api.github.com/repos/pytorch/pytorch/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/pytorch/pytorch/merges", "archive_url": "https://api.github.com/repos/pytorch/pytorch/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/pytorch/pytorch/downloads", "issues_url": "https://api.github.com/repos/pytorch/pytorch/issues{/number}", "pulls_url": "https://api.github.com/repos/pytorch/pytorch/pulls{/number}", "milestones_url": "https://api.github.com/repos/pytorch/pytorch/milestones{/number}", "notifications_url": "https://api.github.com/repos/pytorch/pytorch/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/pytorch/pytorch/labels{/name}", "releases_url": "https://api.github.com/repos/pytorch/pytorch/releases{/id}", "deployments_url": "https://api.github.com/repos/pytorch/pytorch/deployments", "created_at": "2016-08-13T05:26:41Z", "updated_at": "2018-11-24T12:35:43Z", "pushed_at": "2018-11-24T12:42:01Z", "git_url": "git://github.com/pytorch/pytorch.git", "ssh_url": "git@github.com:pytorch/pytorch.git", "clone_url": "https://github.com/pytorch/pytorch.git", "svn_url": "https://github.com/pytorch/pytorch", "homepage": "http://pytorch.org", "size": 89656, "stargazers_count": 21589, "watchers_count": 21589, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "forks_count": 5153, "mirror_url": null, "archived": false, "open_issues_count": 2197, "license": {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}, "forks": 5153, "open_issues": 2197, "watchers": 21589, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10980"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10980"}, "issue": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/10980"}, "comments": {"href": "https://api.github.com/repos/pytorch/pytorch/issues/10980/comments"}, "review_comments": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10980/comments"}, "review_comment": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10980/commits"}, "statuses": {"href": "https://api.github.com/repos/pytorch/pytorch/statuses/78a5398f873de8d9c2a46ea7cb3a9eff1613fae6"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>This PR vectorizes the CPU grid sample 2d forward and backward kernels. Specifically,</p>\n<ol>\n<li>\n<p>add <code>.data()</code> in <code>TensorAccessor</code></p>\n</li>\n<li>\n<p>support non-void return value for declaring CPU kernel stub</p>\n</li>\n<li>\n<p>add <code>bool at:: geometry_is_contiguous(IntList sizes, IntList strides)</code></p>\n</li>\n<li>\n<p>The following vectorized CPU primitives are added:</p>\n<ul>\n<li><code>gather&lt;scale&gt;(baseaddr, vindex)</code>: <code>result[i] = baseaddr[vindex[i] * scale]</code></li>\n<li><code>mask_gather&lt;scale&gt;(src, baseaddr, vindex, mask)</code>: <code>result[i] = mask[i] ? baseaddr[vindex[i] * scale] : src[i]</code>.</li>\n<li>comparison ops</li>\n<li>binary logical ops</li>\n<li><code>min(a, b)</code></li>\n<li><code>cast&lt;dst_t, src_t&gt;(src_vec)</code>: changing dtype but keeping the bit representation</li>\n<li><code>blendv(a, b, mask)</code>: <code>result[i] = mask[i] ? b[i] : a[i]</code>.</li>\n<li>ctor with multiple values (i.e., <code>setr</code>)</li>\n<li><code>arange(start = 0, step = 1)</code>: constructs a vector with values specified by the arange parameters</li>\n<li><code>convert_to_int_of_same_size(vec)</code>: convert floating point vector to corresponding integral type of same size</li>\n<li><code>interleave2(a, b)</code> &amp; <code>deinterleave2(x, y)</code>: interleave or deinterleaves two vectors. E.g., for <code>interleave</code>:\n<pre><code>inputs:\n  {a0, a1, a2, a3, a4, a5, a6, a7}\n  {b0, b1, b2, b3, b4, b5, b6, b7}\noutputs:\n  {a0, b0, a1, b1, a2, b2, a3, b3}\n  {a4, b4, a5, b5, a6, b6, a7, b7}\n</code></pre>\n</li>\n</ul>\n</li>\n<li>\n<p>Grid sample CPU kernel implementations are described in the following note (also in <code>GridSampleKernel.cpp</code>:</p>\n</li>\n</ol>\n<pre><code> NOTE [ Grid Sample CPU Kernels ]\n\n Implementation of vectorized grid sample CPU kernels is divided into three\n parts:\n\n 1. `ComputeLocation` struct\n    Transforms grid values into interpolation locations of the input tensor\n    for a particular spatial dimension, basing on the size of that dimension\n    in input tensor, and the padding mode.\n</code></pre>\n<div class=\"highlight highlight-source-c++\"><pre>      <span class=\"pl-k\">template</span>&lt;<span class=\"pl-k\">typename</span> <span class=\"pl-c1\">scalar_t</span>, GridSamplerPadding padding&gt;\n      <span class=\"pl-k\">struct</span> <span class=\"pl-en\">ComputeLocation</span> {\n        <span class=\"pl-k\">using</span> Vec = Vec256&lt;<span class=\"pl-c1\">scalar_t</span>&gt;;\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> ctor</span>\n        <span class=\"pl-en\">ComputeLocation</span>(<span class=\"pl-c1\">int64_t</span> size);\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Given grid values `in`, return the interpolation locations after</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> un-normalization and padding mechanism (elementwise).</span>\n        Vec <span class=\"pl-en\">apply</span>(<span class=\"pl-k\">const</span> Vec &amp;in) <span class=\"pl-k\">const</span>;\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Similar to `apply`, but also returns `d apply(in) / d in`</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> (elementwise).</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> this is often used in gradient computation.</span>\n        std::pair&lt;Vec, Vec&gt; <span class=\"pl-en\">apply_get_grad</span>(<span class=\"pl-k\">const</span> Vec &amp;in) <span class=\"pl-k\">const</span>;\n      };</pre></div>\n<pre><code>   2. `ApplyGridSample` struct\n      Owns N `ComputeLocation` structs, where N is the number of spatial\n      dimensions. Given N input grid vectors (one for each spatial dimension)\n      and spatial offset, it gets the interpolation locations from\n      `ComputeLocation`s, applies interpolation procedure, and then writes to\n      the output (or grad_input &amp; grad_grid in backward).\n</code></pre>\n<div class=\"highlight highlight-source-c++\"><pre>      <span class=\"pl-k\">template</span>&lt;<span class=\"pl-k\">typename</span> <span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-k\">int</span> spatial_dim,\n               GridSamplerInterpolation interp,\n               GridSamplerPadding padding&gt;\n      <span class=\"pl-k\">struct</span> <span class=\"pl-en\">ApplyGridSample</span> {\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> ctor</span>\n        <span class=\"pl-en\">ApplyGridSample</span>(<span class=\"pl-k\">const</span> TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">4</span>&gt;&amp; input);\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Applies grid sampling (forward) procedure:</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>   1. computes interpolation locations from grid values `grid_x` and</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>      `grid_y`,</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>   2. interpolates output values using the locations and input data</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>      in `inp_slice`, and</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>   3. writes the first `len` values in the interpolated vector to</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span>      `out_slice` with spatial offset being `offset`.</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span></span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> This assimes that `grid_x` and `grid_y` all contain valid grid</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> values \\in [-1, 1], even at indices greater than `len`.</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span></span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> The `*_slice` argument namess mean samples within a batch (i.e.,</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> with the batch dimension sliced out).</span>\n        <span class=\"pl-k\">void</span> <span class=\"pl-en\">forward</span>(TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; out_slice,\n                     <span class=\"pl-k\">const</span> TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; inp_slice,\n                     <span class=\"pl-c1\">int64_t</span> offset, <span class=\"pl-k\">const</span> Vec&amp; grid_x, <span class=\"pl-k\">const</span> Vec&amp; grid_y,\n                     <span class=\"pl-c1\">int64_t</span> len) <span class=\"pl-k\">const</span>;\n  \n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> Applies grid sampling (backward) procedure. Arguments semantics</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">//</span> and strategy are similar to those of `forward`.</span>\n        <span class=\"pl-k\">void</span> <span class=\"pl-en\">backward</span>(TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; <span class=\"pl-smi\">gInp_slice</span>,\n                      TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; <span class=\"pl-smi\">gGrid_slice</span>,\n                      <span class=\"pl-k\">const</span> TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; <span class=\"pl-smi\">gOut_slice</span>,\n                      <span class=\"pl-k\">const</span> TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; inp_slice,\n                      <span class=\"pl-c1\">int64_t</span> offset, <span class=\"pl-k\">const</span> Vec&amp; grid_x, <span class=\"pl-k\">const</span> Vec&amp; grid_y,\n                      <span class=\"pl-c1\">int64_t</span> len) <span class=\"pl-k\">const</span>;\n      }<span class=\"pl-ii\"></span></pre></div>\n<pre><code>   3. `grid_sample_2d_grid_slice_iterator` function\n      Among the tensors we work with, we know that the output tensors are\n      contiguous (i.e., `output` in forward, and `grad_input` &amp; `grad_grid` in\n      backward), we need to randomly read `input` anyways, and `grad_output`\n      usually comes from autograd and is often contiguous. So we base our\n      iterating strategy on the geometry of grid.\n      `grid_sample_2d_grid_slice_iterator` function provides an abstract to\n      efficiently iterates through a `grid` slice (without batch dimension).\n      See comments of that function on the specific cases and strategies used.\n</code></pre>\n<div class=\"highlight highlight-source-c++\"><pre>      <span class=\"pl-k\">template</span>&lt;<span class=\"pl-k\">typename</span> <span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-k\">typename</span> ApplyFn&gt;\n      <span class=\"pl-k\">void</span> <span class=\"pl-en\">grid_sample_2d_grid_slice_iterator</span>(\n        <span class=\"pl-k\">const</span> TensorAccessor&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">3</span>&gt;&amp; grid_slice,\n        <span class=\"pl-k\">const</span> ApplyFn &amp;apply_fn);\n\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> `apply_fn` is a function/lambda that can be called as if it has</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> declaration:</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>   void apply_fn(const Vec256&lt;scalar_t&gt;&amp; grid_x,</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>                 const Vec256&lt;scalar_t&gt;&amp; grid_y,</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span>                 int64_t spatial_offset, int64_t len);</span></pre></div>\n<pre><code>      `apply_fn` will be called multiple times, and together cover the entire\n      output spatial space. Therefore, e.g., to implement forward 2d grid\n      sample, we can do\n</code></pre>\n<div class=\"highlight highlight-source-c++\"><pre>      ApplyGridSample&lt;<span class=\"pl-c1\">scalar_t</span>, <span class=\"pl-c1\">2</span>, interp, padding&gt; <span class=\"pl-en\">grid_sample</span>(input_accessor);\n  \n      <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> n = <span class=\"pl-c1\">0</span>; n &lt; input_accessor.size(<span class=\"pl-c1\">0</span>); n++) {\n        <span class=\"pl-c1\">grid_sample_2d_grid_slice_iterator</span>(\n          grid_accessor[n],\n          [&amp;](<span class=\"pl-k\">const</span> Vec256&lt;<span class=\"pl-c1\">scalar_t</span>&gt;&amp; grid_x, <span class=\"pl-k\">const</span> Vec256&lt;<span class=\"pl-c1\">scalar_t</span>&gt;&amp; grid_y,\n              <span class=\"pl-c1\">int64_t</span> spatial_offset, <span class=\"pl-c1\">int64_t</span> len) {\n            grid_sample.<span class=\"pl-c1\">forward</span>(out_accessor[n], input_accessor[n],\n                                spatial_offset, grid_x, grid_y, len);\n          });\n      }</pre></div>", "body_text": "This PR vectorizes the CPU grid sample 2d forward and backward kernels. Specifically,\n\n\nadd .data() in TensorAccessor\n\n\nsupport non-void return value for declaring CPU kernel stub\n\n\nadd bool at:: geometry_is_contiguous(IntList sizes, IntList strides)\n\n\nThe following vectorized CPU primitives are added:\n\ngather<scale>(baseaddr, vindex): result[i] = baseaddr[vindex[i] * scale]\nmask_gather<scale>(src, baseaddr, vindex, mask): result[i] = mask[i] ? baseaddr[vindex[i] * scale] : src[i].\ncomparison ops\nbinary logical ops\nmin(a, b)\ncast<dst_t, src_t>(src_vec): changing dtype but keeping the bit representation\nblendv(a, b, mask): result[i] = mask[i] ? b[i] : a[i].\nctor with multiple values (i.e., setr)\narange(start = 0, step = 1): constructs a vector with values specified by the arange parameters\nconvert_to_int_of_same_size(vec): convert floating point vector to corresponding integral type of same size\ninterleave2(a, b) & deinterleave2(x, y): interleave or deinterleaves two vectors. E.g., for interleave:\ninputs:\n  {a0, a1, a2, a3, a4, a5, a6, a7}\n  {b0, b1, b2, b3, b4, b5, b6, b7}\noutputs:\n  {a0, b0, a1, b1, a2, b2, a3, b3}\n  {a4, b4, a5, b5, a6, b6, a7, b7}\n\n\n\n\n\nGrid sample CPU kernel implementations are described in the following note (also in GridSampleKernel.cpp:\n\n\n NOTE [ Grid Sample CPU Kernels ]\n\n Implementation of vectorized grid sample CPU kernels is divided into three\n parts:\n\n 1. `ComputeLocation` struct\n    Transforms grid values into interpolation locations of the input tensor\n    for a particular spatial dimension, basing on the size of that dimension\n    in input tensor, and the padding mode.\n\n      template<typename scalar_t, GridSamplerPadding padding>\n      struct ComputeLocation {\n        using Vec = Vec256<scalar_t>;\n  \n        // ctor\n        ComputeLocation(int64_t size);\n  \n        // Given grid values `in`, return the interpolation locations after\n        // un-normalization and padding mechanism (elementwise).\n        Vec apply(const Vec &in) const;\n  \n        // Similar to `apply`, but also returns `d apply(in) / d in`\n        // (elementwise).\n        // this is often used in gradient computation.\n        std::pair<Vec, Vec> apply_get_grad(const Vec &in) const;\n      };\n   2. `ApplyGridSample` struct\n      Owns N `ComputeLocation` structs, where N is the number of spatial\n      dimensions. Given N input grid vectors (one for each spatial dimension)\n      and spatial offset, it gets the interpolation locations from\n      `ComputeLocation`s, applies interpolation procedure, and then writes to\n      the output (or grad_input & grad_grid in backward).\n\n      template<typename scalar_t, int spatial_dim,\n               GridSamplerInterpolation interp,\n               GridSamplerPadding padding>\n      struct ApplyGridSample {\n  \n        // ctor\n        ApplyGridSample(const TensorAccessor<scalar_t, 4>& input);\n  \n        // Applies grid sampling (forward) procedure:\n        //   1. computes interpolation locations from grid values `grid_x` and\n        //      `grid_y`,\n        //   2. interpolates output values using the locations and input data\n        //      in `inp_slice`, and\n        //   3. writes the first `len` values in the interpolated vector to\n        //      `out_slice` with spatial offset being `offset`.\n        //\n        // This assimes that `grid_x` and `grid_y` all contain valid grid\n        // values \\in [-1, 1], even at indices greater than `len`.\n        //\n        // The `*_slice` argument namess mean samples within a batch (i.e.,\n        // with the batch dimension sliced out).\n        void forward(TensorAccessor<scalar_t, 3>& out_slice,\n                     const TensorAccessor<scalar_t, 3>& inp_slice,\n                     int64_t offset, const Vec& grid_x, const Vec& grid_y,\n                     int64_t len) const;\n  \n        // Applies grid sampling (backward) procedure. Arguments semantics\n        // and strategy are similar to those of `forward`.\n        void backward(TensorAccessor<scalar_t, 3>& gInp_slice,\n                      TensorAccessor<scalar_t, 3>& gGrid_slice,\n                      const TensorAccessor<scalar_t, 3>& gOut_slice,\n                      const TensorAccessor<scalar_t, 3>& inp_slice,\n                      int64_t offset, const Vec& grid_x, const Vec& grid_y,\n                      int64_t len) const;\n      }\n   3. `grid_sample_2d_grid_slice_iterator` function\n      Among the tensors we work with, we know that the output tensors are\n      contiguous (i.e., `output` in forward, and `grad_input` & `grad_grid` in\n      backward), we need to randomly read `input` anyways, and `grad_output`\n      usually comes from autograd and is often contiguous. So we base our\n      iterating strategy on the geometry of grid.\n      `grid_sample_2d_grid_slice_iterator` function provides an abstract to\n      efficiently iterates through a `grid` slice (without batch dimension).\n      See comments of that function on the specific cases and strategies used.\n\n      template<typename scalar_t, typename ApplyFn>\n      void grid_sample_2d_grid_slice_iterator(\n        const TensorAccessor<scalar_t, 3>& grid_slice,\n        const ApplyFn &apply_fn);\n\n      // `apply_fn` is a function/lambda that can be called as if it has\n      // declaration:\n      //   void apply_fn(const Vec256<scalar_t>& grid_x,\n      //                 const Vec256<scalar_t>& grid_y,\n      //                 int64_t spatial_offset, int64_t len);\n      `apply_fn` will be called multiple times, and together cover the entire\n      output spatial space. Therefore, e.g., to implement forward 2d grid\n      sample, we can do\n\n      ApplyGridSample<scalar_t, 2, interp, padding> grid_sample(input_accessor);\n  \n      for (int n = 0; n < input_accessor.size(0); n++) {\n        grid_sample_2d_grid_slice_iterator(\n          grid_accessor[n],\n          [&](const Vec256<scalar_t>& grid_x, const Vec256<scalar_t>& grid_y,\n              int64_t spatial_offset, int64_t len) {\n            grid_sample.forward(out_accessor[n], input_accessor[n],\n                                spatial_offset, grid_x, grid_y, len);\n          });\n      }", "merged": false, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": null, "comments": 6, "review_comments": 19, "maintainer_can_modify": false, "commits": 13, "additions": 1721, "deletions": 371, "changed_files": 17}