{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/406551819", "html_url": "https://github.com/pytorch/pytorch/issues/2198#issuecomment-406551819", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2198", "id": 406551819, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjU1MTgxOQ==", "user": {"login": "Stonesjtu", "id": 4556044, "node_id": "MDQ6VXNlcjQ1NTYwNDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/4556044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stonesjtu", "html_url": "https://github.com/Stonesjtu", "followers_url": "https://api.github.com/users/Stonesjtu/followers", "following_url": "https://api.github.com/users/Stonesjtu/following{/other_user}", "gists_url": "https://api.github.com/users/Stonesjtu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stonesjtu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stonesjtu/subscriptions", "organizations_url": "https://api.github.com/users/Stonesjtu/orgs", "repos_url": "https://api.github.com/users/Stonesjtu/repos", "events_url": "https://api.github.com/users/Stonesjtu/events{/privacy}", "received_events_url": "https://api.github.com/users/Stonesjtu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-20T09:56:12Z", "updated_at": "2018-07-20T09:56:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31977186\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wise-east\">@wise-east</a>  I'm sorry I just forget that. Actually the printed information does not help when debugging OOM problem.</p>\n<p>But to profile the GPU memory usage I would recommend this gist, i wrote it speically for pytorch (<a href=\"https://gist.github.com/Stonesjtu/368ddf5d9eb56669269ecdf9b0d21cbe\">https://gist.github.com/Stonesjtu/368ddf5d9eb56669269ecdf9b0d21cbe</a>).</p>\n<p>Because Pytorch uses cached memory allocation, you may also want to check out this. (<a href=\"https://pytorch.org/docs/master/notes/cuda.html#memory-management\" rel=\"nofollow\">https://pytorch.org/docs/master/notes/cuda.html#memory-management</a>)</p>", "body_text": "@wise-east  I'm sorry I just forget that. Actually the printed information does not help when debugging OOM problem.\nBut to profile the GPU memory usage I would recommend this gist, i wrote it speically for pytorch (https://gist.github.com/Stonesjtu/368ddf5d9eb56669269ecdf9b0d21cbe).\nBecause Pytorch uses cached memory allocation, you may also want to check out this. (https://pytorch.org/docs/master/notes/cuda.html#memory-management)", "body": "@wise-east  I'm sorry I just forget that. Actually the printed information does not help when debugging OOM problem.\r\n\r\nBut to profile the GPU memory usage I would recommend this gist, i wrote it speically for pytorch (https://gist.github.com/Stonesjtu/368ddf5d9eb56669269ecdf9b0d21cbe).\r\n\r\nBecause Pytorch uses cached memory allocation, you may also want to check out this. (https://pytorch.org/docs/master/notes/cuda.html#memory-management)"}