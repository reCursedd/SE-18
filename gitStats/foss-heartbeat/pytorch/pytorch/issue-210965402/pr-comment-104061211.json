{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104061211", "pull_request_review_id": 24874462, "id": 104061211, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNDA2MTIxMQ==", "diff_hunk": "@@ -1,42 +1,73 @@\n-from copy import copy\n-from collections import OrderedDict\n-\n-from ..modules import Module\n import torch.cuda.comm as comm\n \n \n-def _replicate_module(module, gpu, param_remap):\n-    if module is None:\n-        return module\n-    replica = copy(module)\n-    replica._parameters = OrderedDict()\n-    for key, param in module._parameters.items():\n-        replica._parameters[key] = param_remap.get(param)\n-    replica._buffers = {}\n-    for key, buffer in module._buffers.items():\n-        replica._buffers[key] = param_remap.get(buffer)\n-    if replica._modules:\n-        replica._modules = OrderedDict()\n-        for name, child in module._modules.items():\n-            replica._modules[name] = _replicate_module(child, gpu, param_remap)\n-    return replica\n-\n-\n-def replicate(module, device_ids):\n+def replicate(network, devices):\n     from ._functions import Broadcast\n-    seen_params = set()\n-    param_remap = [{} for dev_id in device_ids]\n-    for param in module.parameters():\n-        if param in seen_params:\n-            continue\n-        seen_params.add(param)\n-        param_copies = Broadcast(device_ids)(param)\n-        for param_copy, remap in zip(param_copies, param_remap):\n-            remap[param] = param_copy\n-    for m in module.modules():\n-        for buffer in m._buffers.values():\n-            copies = comm.broadcast(buffer, device_ids)\n-            for buf_copy, remap in zip(copies, param_remap):\n-                remap[buffer] = buf_copy\n-    return [_replicate_module(module, device_id, remap)\n-            for device_id, remap in zip(device_ids, param_remap)]\n+\n+    devices = tuple(devices)\n+    num_replicas = len(devices)\n+\n+    params = list(network.parameters())\n+    param_indices = {param: idx for idx, param in enumerate(params)}\n+    param_copies = Broadcast(devices)(*params)\n+    if len(params) > 0:\n+        param_copies = [param_copies[i:i+len(params)]\n+                        for i in range(0, len(param_copies), len(params))]\n+\n+    buffers = _buffers(network)\n+    buffer_indices = {buf: idx for idx, buf in enumerate(buffers)}\n+    buffer_copies = comm.broadcast_coalesced(buffers, devices)\n+\n+    modules = list(network.modules())\n+    module_copies = [[] for device in devices]\n+    module_indices = {}\n+\n+    for i, module in enumerate(modules):\n+        module_indices[module] = i\n+        for j in range(num_replicas):\n+            replica = module.__new__(type(module))\n+            replica.__dict__ = module.__dict__.copy()\n+            replica._parameters = replica._parameters.copy()\n+            replica._buffers = replica._buffers.copy()\n+            replica._modules = replica._modules.copy()\n+            module_copies[j].append(replica)\n+\n+    for i, module in enumerate(modules):\n+        for key, child in module._modules.items():\n+            module_idx = module_indices[child]\n+            for j in range(num_replicas):\n+                replica = module_copies[j][i]\n+                replica._modules[key] = module_copies[j][module_idx]\n+        for key, param in module._parameters.items():\n+            if param is None:\n+                for j in range(num_replicas):\n+                    replica = module_copies[j][i]\n+                    replica._parameters[key] = None\n+            else:\n+                param_idx = param_indices[param]\n+                for j in range(num_replicas):\n+                    replica = module_copies[j][i]\n+                    replica._parameters[key] = param_copies[j][param_idx]\n+        for key, buf in module._buffers.items():\n+            if buf is None:\n+                for j in range(num_replicas):\n+                    replica = module_copies[j][i]\n+                    replica._buffers[key] = None\n+            else:\n+                buffer_idx = buffer_indices[buf]\n+                for j in range(num_replicas):\n+                    replica = module_copies[j][i]\n+                    replica._buffers[key] = buffer_copies[j][buffer_idx]\n+\n+    return [module_copies[j][0] for j in range(num_replicas)]", "path": "torch/nn/parallel/replicate.py", "position": 100, "original_position": 100, "commit_id": "6336300880349038c5bf6f5dfe3b37864eb39acb", "original_commit_id": "b132877316ccb20083d70b969d96c0a7d6420cc2", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "Why does it return only the first module for each replica?", "created_at": "2017-03-02T23:59:06Z", "updated_at": "2018-11-23T15:32:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/881#discussion_r104061211", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/881", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104061211"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/881#discussion_r104061211"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/881"}}, "body_html": "<p>Why does it return only the first module for each replica?</p>", "body_text": "Why does it return only the first module for each replica?"}