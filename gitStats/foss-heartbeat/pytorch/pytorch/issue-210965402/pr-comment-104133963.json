{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104133963", "pull_request_review_id": 24947698, "id": 104133963, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwNDEzMzk2Mw==", "diff_hunk": "@@ -1,42 +1,189 @@\n #include \"torch/csrc/autograd/python_hook.h\"\n \n+#include <sstream>\n+\n #include \"THP.h\"\n #include \"torch/csrc/autograd/python_variable.h\"\n #include \"torch/csrc/utils/auto_gil.h\"\n #include \"torch/csrc/utils/object_ptr.h\"\n #include \"torch/csrc/Exceptions.h\"\n+#include <THPP/THPP.h>\n+\n+using thpp::Tensor;\n+using torch::autograd::variable_list;\n+\n+static THPObjectPtr wrap_variables(const variable_list& grads);\n+static variable_list unwrap_variables(PyObject* grads);\n+static std::string hook_name(PyObject* hook);\n+static void check_result(PyObject* original, PyObject* result, PyObject* hook);\n+static void check_single_result(PyObject* original, PyObject* result, PyObject* hook);\n+\n \n namespace torch { namespace autograd {\n \n-PyGradHook::PyGradHook(PyObject* dict) : dict(dict) {\n+PyFunctionPreHook::PyFunctionPreHook(PyObject* dict, int grad_index)\n+  : dict(dict)\n+  , grad_index(grad_index)\n+{\n   Py_INCREF(dict);\n }\n \n-PyGradHook::~PyGradHook() {\n+PyFunctionPreHook::~PyFunctionPreHook() {\n     AutoGIL gil;\n     Py_DECREF(dict);\n }\n \n-auto PyGradHook::operator()(const std::shared_ptr<Variable>& _grad) -> std::shared_ptr<Variable> {\n+auto PyFunctionPreHook::operator()(const variable_list& _grads) -> variable_list\n+{\n   AutoGIL gil;\n \n-  THPObjectPtr grad = THPVariable_Wrap(_grad);\n+  THPObjectPtr grad = THPVariable_Wrap(_grads.at(grad_index));\n   if (!grad) throw python_error();\n \n-  PyObject *key, *value;\n+  PyObject *key, *hook;\n   Py_ssize_t pos = 0;\n-  while (PyDict_Next(dict, &pos, &key, &value)) {\n-    THPObjectPtr res = PyObject_CallFunctionObjArgs(value, grad.get(), nullptr);\n+  while (PyDict_Next(dict, &pos, &key, &hook)) {\n+    THPObjectPtr res = PyObject_CallFunctionObjArgs(hook, grad.get(), nullptr);\n     if (!res) throw python_error();\n     if (res == Py_None) continue;\n-    if (!PyObject_IsInstance(res.get(), THPVariableClass)) {\n-      PyErr_Format(PyExc_TypeError, \"expected Variable, but hook returned '%s'\",\n-          THPUtils_typename(res.get()));\n-      throw python_error();\n-    }\n+    check_single_result(grad.get(), res.get(), hook);\n     grad = std::move(res);\n   }\n-  return ((THPVariable*)grad.get())->cdata;\n+\n+  variable_list results(_grads);\n+  results[grad_index] = ((THPVariable*)grad.get())->cdata;\n+  return results;\n+}\n+\n+PyFunctionPostHook::PyFunctionPostHook(PyObject* dict) : dict(dict) {\n+  Py_INCREF(dict);\n+}\n+\n+PyFunctionPostHook::~PyFunctionPostHook() {\n+    AutoGIL gil;\n+    Py_DECREF(dict);\n+}\n+\n+auto PyFunctionPostHook::operator()(\n+    const variable_list& _grad_inputs,\n+    const variable_list& _grad_outputs) -> variable_list\n+{\n+  AutoGIL gil;\n+\n+  THPObjectPtr grad_inputs = wrap_variables(_grad_inputs);\n+  THPObjectPtr grad_outputs = wrap_variables(_grad_outputs);\n+\n+  PyObject *key, *hook;\n+  Py_ssize_t pos = 0;\n+  while (PyDict_Next(dict, &pos, &key, &hook)) {\n+    THPObjectPtr res = PyObject_CallFunctionObjArgs(\n+        hook, grad_inputs.get(), grad_outputs.get(), nullptr);\n+    if (!res) throw python_error();\n+    if (res == Py_None) continue;\n+    check_result(grad_inputs, res, hook);\n+    grad_inputs = std::move(res);\n+  }\n+\n+  return unwrap_variables(grad_inputs.get());\n }\n \n }} // namespace torch::autograd\n+\n+\n+static THPObjectPtr wrap_variables(const variable_list& grads)\n+{\n+  THPObjectPtr tuple = PyTuple_New(grads.size());\n+  if (!tuple) throw python_error();\n+  for (size_t i = 0; i < grads.size(); i++) {\n+    THPObjectPtr grad = THPVariable_Wrap(grads[i]);\n+    if (!grad) throw python_error();\n+    PyTuple_SET_ITEM(tuple.get(), i, grad.release());\n+  }\n+  return tuple;\n+}\n+\n+static variable_list unwrap_variables(PyObject* grads)  {\n+  variable_list results(PyTuple_GET_SIZE(grads));\n+  for (size_t i = 0; i < results.size(); i++) {\n+    auto var = (THPVariable*)PyTuple_GET_ITEM(grads, i);\n+    results[i] = var->cdata;\n+  }\n+  return results;\n+}\n+\n+static void check_result(PyObject* prev, PyObject* result, PyObject* hook) {\n+  if (!PyTuple_Check(result)) {\n+    PyErr_Format(PyExc_TypeError, \"expected tuple, but hook returned '%s'\",\n+        THPUtils_typename(result));\n+    throw python_error();\n+  }\n+\n+  auto prev_size = PyTuple_GET_SIZE(prev);\n+  auto result_size = PyTuple_GET_SIZE(result);\n+  if (prev_size != result_size) {\n+    std::stringstream ss;\n+    auto name = hook_name(hook);\n+    ss << \"backward hook '\" << name << \"' has returned an incorrect number \";\n+    ss << \"of gradients (got \" << result_size << \", but expected \";\n+    ss << prev_size << \")\";\n+    throw std::runtime_error(ss.str());\n+  }\n+\n+  for (auto i = 0; i < prev_size; i++) {\n+    check_single_result(PyTuple_GET_ITEM(prev, i), PyTuple_GET_ITEM(result, i), hook);\n+  }\n+}\n+\n+static void check_single_result(PyObject* _original, PyObject* _result, PyObject* hook) {\n+  if (!PyObject_IsInstance(_result, THPVariableClass)) {\n+    PyErr_Format(PyExc_TypeError, \"expected Variable, but hook returned '%s'\",\n+        THPUtils_typename(_result));\n+    throw python_error();\n+  }\n+\n+  auto& original = *((THPVariable*)_original)->cdata->data;\n+  auto& result = *((THPVariable*)_result)->cdata->data;\n+\n+  if (original.type() != result.type()) {\n+    std::stringstream ss;\n+    auto name = hook_name(hook);\n+    ss << \"backward hook '\" << name << \"' has changed the type of grad_input (\";\n+    ss << \"was \" << thpp::toString(original.type()) << \" got \";\n+    ss << thpp::toString(result.type()) << \")\";\n+    throw std::runtime_error(ss.str());\n+  }\n+\n+  if (original.isCuda() != result.isCuda()) {\n+    std::stringstream ss;\n+    auto name = hook_name(hook);\n+    ss << \"backward hook '\" << name << \"' has changed the type of grad_input\";\n+    if (original.isCuda()) {\n+      ss << \" (was CUDA tensor got CPU tensor)\";\n+    } else {\n+      ss << \" (was CPU tensor got CUDA tensor)\";\n+    }\n+    throw std::runtime_error(ss.str());\n+  }\n+\n+  if (original.sizes() != result.sizes()) {\n+    std::stringstream ss;\n+    auto name = hook_name(hook);\n+    ss << \"backward hook '\" << name << \"' has changed the size of grad_input\";", "path": "torch/csrc/autograd/python_hook.cpp", "position": 180, "original_position": 184, "commit_id": "6336300880349038c5bf6f5dfe3b37864eb39acb", "original_commit_id": "732f464faa2a72534be9a4bfcf848d06cde9e87c", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "It would be helpful to print the sizes, but it's ok.", "created_at": "2017-03-03T11:13:47Z", "updated_at": "2018-11-23T15:32:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/881#discussion_r104133963", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/881", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/104133963"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/881#discussion_r104133963"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/881"}}, "body_html": "<p>It would be helpful to print the sizes, but it's ok.</p>", "body_text": "It would be helpful to print the sizes, but it's ok."}