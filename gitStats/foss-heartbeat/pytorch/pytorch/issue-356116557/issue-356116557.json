{"url": "https://api.github.com/repos/pytorch/pytorch/issues/11157", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/11157/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/11157/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/11157/events", "html_url": "https://github.com/pytorch/pytorch/issues/11157", "id": 356116557, "node_id": "MDU6SXNzdWUzNTYxMTY1NTc=", "number": 11157, "title": "[JIT] torch.einsum not supported by JIT tracer", "user": {"login": "neerajprad", "id": 1762463, "node_id": "MDQ6VXNlcjE3NjI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1762463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neerajprad", "html_url": "https://github.com/neerajprad", "followers_url": "https://api.github.com/users/neerajprad/followers", "following_url": "https://api.github.com/users/neerajprad/following{/other_user}", "gists_url": "https://api.github.com/users/neerajprad/gists{/gist_id}", "starred_url": "https://api.github.com/users/neerajprad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neerajprad/subscriptions", "organizations_url": "https://api.github.com/users/neerajprad/orgs", "repos_url": "https://api.github.com/users/neerajprad/repos", "events_url": "https://api.github.com/users/neerajprad/events{/privacy}", "received_events_url": "https://api.github.com/users/neerajprad/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 679953983, "node_id": "MDU6TGFiZWw2Nzk5NTM5ODM=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/jit", "name": "jit", "color": "c5def5", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-08-31T20:36:31Z", "updated_at": "2018-09-11T13:04:04Z", "closed_at": "2018-09-11T13:04:04Z", "author_association": "CONTRIBUTOR", "body_html": "<h2>Issue description</h2>\n<p>We are using the <code>torch.einsum</code> operation in many Pyro models (e.g. <code>HMM</code>), and it appears that the JIT tracer does not currently support the <code>einsum</code> operation. cc. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=20787943\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/t-vi\">@t-vi</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=648532\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fritzo\">@fritzo</a>.</p>\n<h2>Code example</h2>\n<p>The following example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-en\">@torch.jit.trace</span>(torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>), torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>))\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">fn</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>):\n    <span class=\"pl-k\">return</span> torch.einsum(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>ab,ab-&gt;b<span class=\"pl-pds\">'</span></span>, [x, y])\n\n\nfn(torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>), torch.ones(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>))</pre></div>\n<p>throws an error on a recent PyTorch commit:</p>\n<pre><code>Traceback (most recent call last):\n  File \"examples/ein.py\", line 4, in &lt;module&gt;\n    @torch.jit.trace(torch.ones(2, 3), torch.ones(2, 3))\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 290, in wrapper\n    module._create_method_from_trace('forward', func, tuple(args))\n  File \"examples/ein.py\", line 6, in fn\n    return torch.einsum('ab,ab-&gt;b', [x, y])\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/functional.py\", line 239, in einsum\n    return torch._C._VariableFunctions.einsum(equation, operands)\nRuntimeError: Found an unsupported argument type in the JIT tracer. File a bug report.\n</code></pre>\n<h2>System Info</h2>\n<pre><code>  $ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+72f91b1\nIs debug build: Yes\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] torch (0.5.0a0+e449a27)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+e449a27           &lt;pip&gt;\n[conda] torch                     0.5.0a0+cb32e38           &lt;pip&gt;\n[conda] torch                     0.5.0a0+c98d748           &lt;pip&gt;\n[conda] torch                     0.5.0a0+64a6003           &lt;pip&gt;\n[conda] torch                     0.5.0a0+72f91b1           &lt;pip&gt;\n[conda] torch                     0.5.0a0+6456b94           &lt;pip&gt;\n[conda] torch                     0.5.0a0+cd53b78           &lt;pip&gt;\n[conda] torchfile                 0.1.0                     &lt;pip&gt;\n[conda] torchvision               0.2.1                     &lt;pip&gt;\n</code></pre>", "body_text": "Issue description\nWe are using the torch.einsum operation in many Pyro models (e.g. HMM), and it appears that the JIT tracer does not currently support the einsum operation. cc. @t-vi, @apaszke, @fritzo.\nCode example\nThe following example:\n@torch.jit.trace(torch.ones(2, 3), torch.ones(2, 3))\ndef fn(x, y):\n    return torch.einsum('ab,ab->b', [x, y])\n\n\nfn(torch.ones(2, 3), torch.ones(2, 3))\nthrows an error on a recent PyTorch commit:\nTraceback (most recent call last):\n  File \"examples/ein.py\", line 4, in <module>\n    @torch.jit.trace(torch.ones(2, 3), torch.ones(2, 3))\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 290, in wrapper\n    module._create_method_from_trace('forward', func, tuple(args))\n  File \"examples/ein.py\", line 6, in fn\n    return torch.einsum('ab,ab->b', [x, y])\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/functional.py\", line 239, in einsum\n    return torch._C._VariableFunctions.einsum(equation, operands)\nRuntimeError: Found an unsupported argument type in the JIT tracer. File a bug report.\n\nSystem Info\n  $ python collect_env.py\nCollecting environment information...\nPyTorch version: 0.5.0a0+72f91b1\nIs debug build: Yes\nCUDA used to build PyTorch: None\n\nOS: Mac OSX 10.13.3\nGCC version: Could not collect\nCMake version: version 3.12.0\n\nPython version: 3.6\nIs CUDA available: No\nCUDA runtime version: No CUDA\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\n\nVersions of relevant libraries:\n[pip] numpy (1.15.0)\n[pip] torch (0.5.0a0+e449a27)\n[pip] torchfile (0.1.0)\n[pip] torchvision (0.2.1)\n[conda] torch                     0.5.0a0+e449a27           <pip>\n[conda] torch                     0.5.0a0+cb32e38           <pip>\n[conda] torch                     0.5.0a0+c98d748           <pip>\n[conda] torch                     0.5.0a0+64a6003           <pip>\n[conda] torch                     0.5.0a0+72f91b1           <pip>\n[conda] torch                     0.5.0a0+6456b94           <pip>\n[conda] torch                     0.5.0a0+cd53b78           <pip>\n[conda] torchfile                 0.1.0                     <pip>\n[conda] torchvision               0.2.1                     <pip>", "body": "## Issue description\r\n\r\nWe are using the `torch.einsum` operation in many Pyro models (e.g. `HMM`), and it appears that the JIT tracer does not currently support the `einsum` operation. cc. @t-vi, @apaszke, @fritzo.\r\n\r\n## Code example\r\n\r\nThe following example:\r\n\r\n```python\r\n@torch.jit.trace(torch.ones(2, 3), torch.ones(2, 3))\r\ndef fn(x, y):\r\n    return torch.einsum('ab,ab->b', [x, y])\r\n\r\n\r\nfn(torch.ones(2, 3), torch.ones(2, 3))\r\n```\r\n\r\nthrows an error on a recent PyTorch commit:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"examples/ein.py\", line 4, in <module>\r\n    @torch.jit.trace(torch.ones(2, 3), torch.ones(2, 3))\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/jit/__init__.py\", line 290, in wrapper\r\n    module._create_method_from_trace('forward', func, tuple(args))\r\n  File \"examples/ein.py\", line 6, in fn\r\n    return torch.einsum('ab,ab->b', [x, y])\r\n  File \"/Users/npradhan/miniconda2/envs/pytorch-master/lib/python3.6/site-packages/torch/functional.py\", line 239, in einsum\r\n    return torch._C._VariableFunctions.einsum(equation, operands)\r\nRuntimeError: Found an unsupported argument type in the JIT tracer. File a bug report.\r\n```\r\n\r\n## System Info\r\n\r\n```\r\n  $ python collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 0.5.0a0+72f91b1\r\nIs debug build: Yes\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.13.3\r\nGCC version: Could not collect\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy (1.15.0)\r\n[pip] torch (0.5.0a0+e449a27)\r\n[pip] torchfile (0.1.0)\r\n[pip] torchvision (0.2.1)\r\n[conda] torch                     0.5.0a0+e449a27           <pip>\r\n[conda] torch                     0.5.0a0+cb32e38           <pip>\r\n[conda] torch                     0.5.0a0+c98d748           <pip>\r\n[conda] torch                     0.5.0a0+64a6003           <pip>\r\n[conda] torch                     0.5.0a0+72f91b1           <pip>\r\n[conda] torch                     0.5.0a0+6456b94           <pip>\r\n[conda] torch                     0.5.0a0+cd53b78           <pip>\r\n[conda] torchfile                 0.1.0                     <pip>\r\n[conda] torchvision               0.2.1                     <pip>\r\n```"}