{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5073", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5073/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5073/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5073/events", "html_url": "https://github.com/pytorch/pytorch/issues/5073", "id": 294684819, "node_id": "MDU6SXNzdWUyOTQ2ODQ4MTk=", "number": 5073, "title": "view function error at runtime on gpu", "user": {"login": "wham-bam", "id": 28391227, "node_id": "MDQ6VXNlcjI4MzkxMjI3", "avatar_url": "https://avatars2.githubusercontent.com/u/28391227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wham-bam", "html_url": "https://github.com/wham-bam", "followers_url": "https://api.github.com/users/wham-bam/followers", "following_url": "https://api.github.com/users/wham-bam/following{/other_user}", "gists_url": "https://api.github.com/users/wham-bam/gists{/gist_id}", "starred_url": "https://api.github.com/users/wham-bam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wham-bam/subscriptions", "organizations_url": "https://api.github.com/users/wham-bam/orgs", "repos_url": "https://api.github.com/users/wham-bam/repos", "events_url": "https://api.github.com/users/wham-bam/events{/privacy}", "received_events_url": "https://api.github.com/users/wham-bam/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-06T09:20:53Z", "updated_at": "2018-02-06T10:23:51Z", "closed_at": "2018-02-06T10:23:51Z", "author_association": "NONE", "body_html": "<p>Hi all</p>\n<p>I have a problem with a sequence to sequence model  with attention that I had created.<br>\nThe model computes attention doing the following passes:</p>\n<p>if self.use_coverage:<br>\npre_attention = enc_features + dec_features + coverage_features<br>\nelse:<br>\npre_attention = enc_features + dec_features<br>\npre_attention = F.tanh(pre_attention)<br>\nattention = self.v(pre_attention)<br>\nreshaped_attention = attention.view(-1, self.seq_len)<br>\nattention = F.softmax(reshaped_attention, dim=1)</p>\n<p>However, this error arise after the model has done 190000 steps (forward+backward):</p>\n<p>2018-02-06 02:24:21,836 - INFO - forward step ran in 0m 0s 454ms<br>\n2018-02-06 02:24:22,042 - INFO - step 192637 loss: 374.437866<br>\n2018-02-06 02:24:22,042 - INFO - running backward step<br>\n2018-02-06 02:24:23,390 - INFO - backward ran in 0m 1s 347ms<br>\n2018-02-06 02:24:23,391 - INFO - running forward step...</p>\n<p>File \"/scratch/home/gsiragus/s2s-coverage/attention.py\", line 85, in forward<br>\nreshaped_attention = attention.view(-1, self.seq_len)<br>\nRuntimeError: invalid argument 2: size '[-1 x 400]' is invalid for input with 6304 elements at /pytorch/torch/lib/TH/THStorage.c:37</p>\n<p>Does someone know why this exception is thrown?</p>\n<p>Thanks!</p>\n<p>Other info:</p>\n<ul>\n<li>OS: ubuntu 16.10</li>\n<li>PyTorch version: last one</li>\n<li>How you installed PyTorch: pip</li>\n<li>Python version: 3.5</li>\n<li>CUDA/cuDNN version: 9</li>\n<li>GPU models: K40m</li>\n</ul>", "body_text": "Hi all\nI have a problem with a sequence to sequence model  with attention that I had created.\nThe model computes attention doing the following passes:\nif self.use_coverage:\npre_attention = enc_features + dec_features + coverage_features\nelse:\npre_attention = enc_features + dec_features\npre_attention = F.tanh(pre_attention)\nattention = self.v(pre_attention)\nreshaped_attention = attention.view(-1, self.seq_len)\nattention = F.softmax(reshaped_attention, dim=1)\nHowever, this error arise after the model has done 190000 steps (forward+backward):\n2018-02-06 02:24:21,836 - INFO - forward step ran in 0m 0s 454ms\n2018-02-06 02:24:22,042 - INFO - step 192637 loss: 374.437866\n2018-02-06 02:24:22,042 - INFO - running backward step\n2018-02-06 02:24:23,390 - INFO - backward ran in 0m 1s 347ms\n2018-02-06 02:24:23,391 - INFO - running forward step...\nFile \"/scratch/home/gsiragus/s2s-coverage/attention.py\", line 85, in forward\nreshaped_attention = attention.view(-1, self.seq_len)\nRuntimeError: invalid argument 2: size '[-1 x 400]' is invalid for input with 6304 elements at /pytorch/torch/lib/TH/THStorage.c:37\nDoes someone know why this exception is thrown?\nThanks!\nOther info:\n\nOS: ubuntu 16.10\nPyTorch version: last one\nHow you installed PyTorch: pip\nPython version: 3.5\nCUDA/cuDNN version: 9\nGPU models: K40m", "body": "Hi all\r\n\r\nI have a problem with a sequence to sequence model  with attention that I had created.\r\nThe model computes attention doing the following passes:\r\n\r\nif self.use_coverage:\r\n     pre_attention = enc_features + dec_features + coverage_features\r\nelse:\r\n     pre_attention = enc_features + dec_features\r\npre_attention = F.tanh(pre_attention)\r\nattention = self.v(pre_attention)\r\nreshaped_attention = attention.view(-1, self.seq_len)\r\nattention = F.softmax(reshaped_attention, dim=1)\r\n\r\nHowever, this error arise after the model has done 190000 steps (forward+backward):\r\n\r\n2018-02-06 02:24:21,836 - INFO - forward step ran in 0m 0s 454ms\r\n2018-02-06 02:24:22,042 - INFO - step 192637 loss: 374.437866\r\n2018-02-06 02:24:22,042 - INFO - running backward step\r\n2018-02-06 02:24:23,390 - INFO - backward ran in 0m 1s 347ms\r\n2018-02-06 02:24:23,391 - INFO - running forward step...\r\n\r\nFile \"/scratch/home/gsiragus/s2s-coverage/attention.py\", line 85, in forward\r\n    reshaped_attention = attention.view(-1, self.seq_len)\r\nRuntimeError: invalid argument 2: size '[-1 x 400]' is invalid for input with 6304 elements at /pytorch/torch/lib/TH/THStorage.c:37\r\n\r\nDoes someone know why this exception is thrown?\r\n\r\nThanks!\r\n\r\nOther info:\r\n\r\n- OS: ubuntu 16.10\r\n- PyTorch version: last one\r\n- How you installed PyTorch: pip\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 9\r\n- GPU models: K40m\r\n\r\n"}