{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/363343195", "html_url": "https://github.com/pytorch/pytorch/issues/4930#issuecomment-363343195", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930", "id": 363343195, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzM0MzE5NQ==", "user": {"login": "adonisues", "id": 14052287, "node_id": "MDQ6VXNlcjE0MDUyMjg3", "avatar_url": "https://avatars3.githubusercontent.com/u/14052287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adonisues", "html_url": "https://github.com/adonisues", "followers_url": "https://api.github.com/users/adonisues/followers", "following_url": "https://api.github.com/users/adonisues/following{/other_user}", "gists_url": "https://api.github.com/users/adonisues/gists{/gist_id}", "starred_url": "https://api.github.com/users/adonisues/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adonisues/subscriptions", "organizations_url": "https://api.github.com/users/adonisues/orgs", "repos_url": "https://api.github.com/users/adonisues/repos", "events_url": "https://api.github.com/users/adonisues/events{/privacy}", "received_events_url": "https://api.github.com/users/adonisues/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-06T08:11:14Z", "updated_at": "2018-02-06T08:12:14Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a><br>\nI checked cudnn LSTM and non-cudnn LSTM as below<br>\nWhen torch.backends.cudnn.enabled is True and False, results are same.<br>\nIf non-cudnn and cudnn lstm are different, results should be different. But it is not.<br>\nResult is exactly same.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> torch.backends.cudnn <span class=\"pl-k\">as</span> cudnn\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\n<span class=\"pl-k\">from</span> torch.autograd <span class=\"pl-k\">import</span> Variable\n<span class=\"pl-k\">import</span> torch.nn.init <span class=\"pl-k\">as</span> init\n\ntorch.backends.cudnn.enabled <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch.backends.cudnn.enabled : <span class=\"pl-pds\">\"</span></span>, torch.backends.cudnn.enabled\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch.backends.cudnn.version : <span class=\"pl-pds\">\"</span></span>, torch.backends.cudnn.version()\n\nmodel <span class=\"pl-k\">=</span> nn.LSTM(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">bidirectional</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>).cuda()\n\n<span class=\"pl-k\">for</span> weights <span class=\"pl-k\">in</span>  model.all_weights :\n    <span class=\"pl-k\">for</span> weight <span class=\"pl-k\">in</span> weights :\n        init.constant(weight, <span class=\"pl-c1\">0.1</span>)\n\n<span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> Variable(torch.FloatTensor([[[<span class=\"pl-c1\">1</span>],[<span class=\"pl-c1\">0.1</span>]],[[<span class=\"pl-c1\">2</span>],[<span class=\"pl-c1\">0.2</span>]]]).cuda())\noutput, hidden <span class=\"pl-k\">=</span> model(<span class=\"pl-c1\">input</span>)\n\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cudnn.is_acceptable(input.data) : <span class=\"pl-pds\">\"</span></span>, cudnn.is_acceptable(<span class=\"pl-c1\">input</span>.data)\n<span class=\"pl-c1\">print</span> output</pre></div>\n<p>output</p>\n<div class=\"highlight highlight-source-python\"><pre>(<span class=\"pl-c1\">0</span> ,.,.) <span class=\"pl-k\">=</span> \n  <span class=\"pl-c1\">0.0786</span>  <span class=\"pl-c1\">0.0786</span>  <span class=\"pl-c1\">0.1302</span>  <span class=\"pl-c1\">0.1302</span>\n  <span class=\"pl-c1\">0.0710</span>  <span class=\"pl-c1\">0.0710</span>  <span class=\"pl-c1\">0.1154</span>  <span class=\"pl-c1\">0.1154</span>\n\n(<span class=\"pl-c1\">1</span> ,.,.) <span class=\"pl-k\">=</span> \n  <span class=\"pl-c1\">0.1324</span>  <span class=\"pl-c1\">0.1324</span>  <span class=\"pl-c1\">0.0828</span>  <span class=\"pl-c1\">0.0828</span>\n  <span class=\"pl-c1\">0.1156</span>  <span class=\"pl-c1\">0.1156</span>  <span class=\"pl-c1\">0.0713</span>  <span class=\"pl-c1\">0.0713</span></pre></div>", "body_text": "@SsnL\nI checked cudnn LSTM and non-cudnn LSTM as below\nWhen torch.backends.cudnn.enabled is True and False, results are same.\nIf non-cudnn and cudnn lstm are different, results should be different. But it is not.\nResult is exactly same.\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.init as init\n\ntorch.backends.cudnn.enabled = True\n\nprint \"torch.backends.cudnn.enabled : \", torch.backends.cudnn.enabled\nprint \"torch.backends.cudnn.version : \", torch.backends.cudnn.version()\n\nmodel = nn.LSTM(1, 2, 2, bidirectional=True).cuda()\n\nfor weights in  model.all_weights :\n    for weight in weights :\n        init.constant(weight, 0.1)\n\ninput = Variable(torch.FloatTensor([[[1],[0.1]],[[2],[0.2]]]).cuda())\noutput, hidden = model(input)\n\nprint \"cudnn.is_acceptable(input.data) : \", cudnn.is_acceptable(input.data)\nprint output\noutput\n(0 ,.,.) = \n  0.0786  0.0786  0.1302  0.1302\n  0.0710  0.0710  0.1154  0.1154\n\n(1 ,.,.) = \n  0.1324  0.1324  0.0828  0.0828\n  0.1156  0.1156  0.0713  0.0713", "body": "@SsnL \r\nI checked cudnn LSTM and non-cudnn LSTM as below\r\nWhen torch.backends.cudnn.enabled is True and False, results are same.\r\nIf non-cudnn and cudnn lstm are different, results should be different. But it is not.\r\nResult is exactly same.\r\n\r\n```python\r\nimport torch\r\nimport torch.backends.cudnn as cudnn\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nimport torch.nn.init as init\r\n\r\ntorch.backends.cudnn.enabled = True\r\n\r\nprint \"torch.backends.cudnn.enabled : \", torch.backends.cudnn.enabled\r\nprint \"torch.backends.cudnn.version : \", torch.backends.cudnn.version()\r\n\r\nmodel = nn.LSTM(1, 2, 2, bidirectional=True).cuda()\r\n\r\nfor weights in  model.all_weights :\r\n    for weight in weights :\r\n        init.constant(weight, 0.1)\r\n\r\ninput = Variable(torch.FloatTensor([[[1],[0.1]],[[2],[0.2]]]).cuda())\r\noutput, hidden = model(input)\r\n\r\nprint \"cudnn.is_acceptable(input.data) : \", cudnn.is_acceptable(input.data)\r\nprint output\r\n```\r\noutput\r\n```python\r\n(0 ,.,.) = \r\n  0.0786  0.0786  0.1302  0.1302\r\n  0.0710  0.0710  0.1154  0.1154\r\n\r\n(1 ,.,.) = \r\n  0.1324  0.1324  0.0828  0.0828\r\n  0.1156  0.1156  0.0713  0.0713\r\n```"}