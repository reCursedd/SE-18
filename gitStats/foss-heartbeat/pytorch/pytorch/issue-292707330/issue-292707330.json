{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4930", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930/events", "html_url": "https://github.com/pytorch/pytorch/issues/4930", "id": 292707330, "node_id": "MDU6SXNzdWUyOTI3MDczMzA=", "number": 4930, "title": "[feature request] Multi-layer bidirectional RNN", "user": {"login": "adonisues", "id": 14052287, "node_id": "MDQ6VXNlcjE0MDUyMjg3", "avatar_url": "https://avatars3.githubusercontent.com/u/14052287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adonisues", "html_url": "https://github.com/adonisues", "followers_url": "https://api.github.com/users/adonisues/followers", "following_url": "https://api.github.com/users/adonisues/following{/other_user}", "gists_url": "https://api.github.com/users/adonisues/gists{/gist_id}", "starred_url": "https://api.github.com/users/adonisues/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adonisues/subscriptions", "organizations_url": "https://api.github.com/users/adonisues/orgs", "repos_url": "https://api.github.com/users/adonisues/repos", "events_url": "https://api.github.com/users/adonisues/events{/privacy}", "received_events_url": "https://api.github.com/users/adonisues/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2018-01-30T09:22:10Z", "updated_at": "2018-10-25T13:41:48Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hello<br>\nI request another type of multi-layer bidirectional RNN.<br>\nCurrently forward output and backward output is concatenated after each layer.<br>\nBut, for language modeling, we need independent forward rnn and backward rnn util the last layer and output concatenation is only need at the last layer.</p>\n<p>thank you.</p>", "body_text": "Hello\nI request another type of multi-layer bidirectional RNN.\nCurrently forward output and backward output is concatenated after each layer.\nBut, for language modeling, we need independent forward rnn and backward rnn util the last layer and output concatenation is only need at the last layer.\nthank you.", "body": "Hello \r\nI request another type of multi-layer bidirectional RNN.\r\nCurrently forward output and backward output is concatenated after each layer.\r\nBut, for language modeling, we need independent forward rnn and backward rnn util the last layer and output concatenation is only need at the last layer.\r\n\r\nthank you.\r\n\r\n"}