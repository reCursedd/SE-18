{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/363821499", "html_url": "https://github.com/pytorch/pytorch/issues/4930#issuecomment-363821499", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930", "id": 363821499, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzgyMTQ5OQ==", "user": {"login": "csarofeen", "id": 22205833, "node_id": "MDQ6VXNlcjIyMjA1ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/22205833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csarofeen", "html_url": "https://github.com/csarofeen", "followers_url": "https://api.github.com/users/csarofeen/followers", "following_url": "https://api.github.com/users/csarofeen/following{/other_user}", "gists_url": "https://api.github.com/users/csarofeen/gists{/gist_id}", "starred_url": "https://api.github.com/users/csarofeen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csarofeen/subscriptions", "organizations_url": "https://api.github.com/users/csarofeen/orgs", "repos_url": "https://api.github.com/users/csarofeen/repos", "events_url": "https://api.github.com/users/csarofeen/events{/privacy}", "received_events_url": "https://api.github.com/users/csarofeen/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-07T16:15:28Z", "updated_at": "2018-02-07T16:15:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4556044\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Stonesjtu\">@Stonesjtu</a><br>\nI am well aware of the first layer.<br>\nThere's a weight for forward and backward with l1 labels. Both of sizes that could handle forward and backward together. There should be one, not the other, or they should be half the size in the second dimension like hidden, no?<br>\nweight_ih_l1 torch.Size([12, 6])<br>\nweight_ih_l1_reverse torch.Size([12, 6])</p>", "body_text": "@Stonesjtu\nI am well aware of the first layer.\nThere's a weight for forward and backward with l1 labels. Both of sizes that could handle forward and backward together. There should be one, not the other, or they should be half the size in the second dimension like hidden, no?\nweight_ih_l1 torch.Size([12, 6])\nweight_ih_l1_reverse torch.Size([12, 6])", "body": "@Stonesjtu \r\nI am well aware of the first layer.\r\nThere's a weight for forward and backward with l1 labels. Both of sizes that could handle forward and backward together. There should be one, not the other, or they should be half the size in the second dimension like hidden, no?\r\nweight_ih_l1 torch.Size([12, 6])\r\nweight_ih_l1_reverse torch.Size([12, 6])"}