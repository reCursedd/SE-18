{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/363287861", "html_url": "https://github.com/pytorch/pytorch/issues/4930#issuecomment-363287861", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4930", "id": 363287861, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MzI4Nzg2MQ==", "user": {"login": "adonisues", "id": 14052287, "node_id": "MDQ6VXNlcjE0MDUyMjg3", "avatar_url": "https://avatars3.githubusercontent.com/u/14052287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adonisues", "html_url": "https://github.com/adonisues", "followers_url": "https://api.github.com/users/adonisues/followers", "following_url": "https://api.github.com/users/adonisues/following{/other_user}", "gists_url": "https://api.github.com/users/adonisues/gists{/gist_id}", "starred_url": "https://api.github.com/users/adonisues/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adonisues/subscriptions", "organizations_url": "https://api.github.com/users/adonisues/orgs", "repos_url": "https://api.github.com/users/adonisues/repos", "events_url": "https://api.github.com/users/adonisues/events{/privacy}", "received_events_url": "https://api.github.com/users/adonisues/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-06T02:15:26Z", "updated_at": "2018-02-06T02:20:08Z", "author_association": "NONE", "body_html": "<p>Hello<br>\nThank you for your kind reply <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5674597\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/SsnL\">@SsnL</a>.<br>\nI did some experiment  on my server. Code and output is below</p>\n<p>In my code, the LSTM looks like Type 2 because the second layer has double size input (6) .<br>\nInput size of the first layer is 3.<br>\nAs your reply, i am using non-cudnn LSTM now.<br>\nCan you show me the way using Cudnn LSTM ?<br>\nI can't find any special option except  \"torch.backends.cudnn.enabled = True\"</p>\n<p>Thank you</p>\n<p>pytorch version is 0.3.0.post4</p>\n<p><strong>Code</strong></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.backends.cudnn <span class=\"pl-k\">as</span> cudnn\n<span class=\"pl-k\">import</span> torch.backends.cudnn.rnn\n<span class=\"pl-k\">import</span> torch.nn <span class=\"pl-k\">as</span> nn\ntorch.backends.cudnn.enabled <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch.backends.cudnn.enabled : <span class=\"pl-pds\">\"</span></span>, torch.backends.cudnn.enabled\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch.backends.cudnn.version : <span class=\"pl-pds\">\"</span></span>, torch.backends.cudnn.version()\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>torch.backends.cudnn.is_acceptable : <span class=\"pl-pds\">\"</span></span>, torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(<span class=\"pl-c1\">1</span>))\nmodel1 <span class=\"pl-k\">=</span> nn.LSTM(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">bidirectional</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n<span class=\"pl-c1\">print</span> model1\n<span class=\"pl-k\">for</span> parameter <span class=\"pl-k\">in</span> model1.parameters() :\n    <span class=\"pl-c1\">print</span> (parameter.size())</pre></div>\n<p><strong>Output</strong></p>\n<pre><code>torch.backends.cudnn.enabled :  True\ntorch.backends.cudnn.version :  7003\ntorch.backends.cudnn.is_acceptable :  True\nLSTM(2, 3, num_layers=2, bidirectional=True)\n(12L, 2L)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, 2L)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, **6L**)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, **6L**)\n(12L, 3L)\n(12L,)\n(12L,)\n</code></pre>", "body_text": "Hello\nThank you for your kind reply @SsnL.\nI did some experiment  on my server. Code and output is below\nIn my code, the LSTM looks like Type 2 because the second layer has double size input (6) .\nInput size of the first layer is 3.\nAs your reply, i am using non-cudnn LSTM now.\nCan you show me the way using Cudnn LSTM ?\nI can't find any special option except  \"torch.backends.cudnn.enabled = True\"\nThank you\npytorch version is 0.3.0.post4\nCode\nimport torch.backends.cudnn as cudnn\nimport torch.backends.cudnn.rnn\nimport torch.nn as nn\ntorch.backends.cudnn.enabled = True\n\nprint \"torch.backends.cudnn.enabled : \", torch.backends.cudnn.enabled\nprint \"torch.backends.cudnn.version : \", torch.backends.cudnn.version()\nprint \"torch.backends.cudnn.is_acceptable : \", torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1))\nmodel1 = nn.LSTM(2, 3, 2, bidirectional=True)\nprint model1\nfor parameter in model1.parameters() :\n    print (parameter.size())\nOutput\ntorch.backends.cudnn.enabled :  True\ntorch.backends.cudnn.version :  7003\ntorch.backends.cudnn.is_acceptable :  True\nLSTM(2, 3, num_layers=2, bidirectional=True)\n(12L, 2L)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, 2L)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, **6L**)\n(12L, 3L)\n(12L,)\n(12L,)\n(12L, **6L**)\n(12L, 3L)\n(12L,)\n(12L,)", "body": "Hello \r\nThank you for your kind reply @SsnL.\r\nI did some experiment  on my server. Code and output is below\r\n\r\nIn my code, the LSTM looks like Type 2 because the second layer has double size input (6) .\r\nInput size of the first layer is 3.\r\nAs your reply, i am using non-cudnn LSTM now.\r\nCan you show me the way using Cudnn LSTM ? \r\nI can't find any special option except  \"torch.backends.cudnn.enabled = True\"\r\n \r\nThank you\r\n\r\npytorch version is 0.3.0.post4\r\n\r\n**Code** \r\n\r\n```python\r\nimport torch.backends.cudnn as cudnn\r\nimport torch.backends.cudnn.rnn\r\nimport torch.nn as nn\r\ntorch.backends.cudnn.enabled = True\r\n\r\nprint \"torch.backends.cudnn.enabled : \", torch.backends.cudnn.enabled\r\nprint \"torch.backends.cudnn.version : \", torch.backends.cudnn.version()\r\nprint \"torch.backends.cudnn.is_acceptable : \", torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1))\r\nmodel1 = nn.LSTM(2, 3, 2, bidirectional=True)\r\nprint model1\r\nfor parameter in model1.parameters() :\r\n    print (parameter.size())\r\n```\r\n\r\n**Output** \r\n\r\n```\r\ntorch.backends.cudnn.enabled :  True\r\ntorch.backends.cudnn.version :  7003\r\ntorch.backends.cudnn.is_acceptable :  True\r\nLSTM(2, 3, num_layers=2, bidirectional=True)\r\n(12L, 2L)\r\n(12L, 3L)\r\n(12L,)\r\n(12L,)\r\n(12L, 2L)\r\n(12L, 3L)\r\n(12L,)\r\n(12L,)\r\n(12L, **6L**)\r\n(12L, 3L)\r\n(12L,)\r\n(12L,)\r\n(12L, **6L**)\r\n(12L, 3L)\r\n(12L,)\r\n(12L,)\r\n```\r\n"}