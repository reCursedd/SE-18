{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6723", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6723/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6723/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6723/events", "html_url": "https://github.com/pytorch/pytorch/issues/6723", "id": 315624215, "node_id": "MDU6SXNzdWUzMTU2MjQyMTU=", "number": 6723, "title": "Different behavior of torch.gels() on CPU tensors vs GPU tensors", "user": {"login": "jacobrgardner", "id": 4016393, "node_id": "MDQ6VXNlcjQwMTYzOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/4016393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jacobrgardner", "html_url": "https://github.com/jacobrgardner", "followers_url": "https://api.github.com/users/jacobrgardner/followers", "following_url": "https://api.github.com/users/jacobrgardner/following{/other_user}", "gists_url": "https://api.github.com/users/jacobrgardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/jacobrgardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jacobrgardner/subscriptions", "organizations_url": "https://api.github.com/users/jacobrgardner/orgs", "repos_url": "https://api.github.com/users/jacobrgardner/repos", "events_url": "https://api.github.com/users/jacobrgardner/events{/privacy}", "received_events_url": "https://api.github.com/users/jacobrgardner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-18T20:08:35Z", "updated_at": "2018-04-19T02:43:31Z", "closed_at": "2018-04-19T02:43:31Z", "author_association": "NONE", "body_html": "<p>I am currently using PyTorch 0.3.0 and I am noticing some (possibly strange) differences between the behavior of <code>torch.gels</code> when operating on CPU tensors versus GPU ones, in particular relating to whether the number of rows of A is allowed to be larger than the number of columns or not.</p>\n<p>Here is some minimal code that reproduces my problem:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\nA <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">100</span>)\nB <span class=\"pl-k\">=</span> torch.randn(<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>)\nls1 <span class=\"pl-k\">=</span> torch.gels(B, A) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Works!</span>\nls2 <span class=\"pl-k\">=</span> torch.gels(B.cuda(), A.cuda()) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Fails</span></pre></div>\n<p>The first solve on the CPU works fine; however, the second solve gives me the error:</p>\n<pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-15-757975f749ea&gt; in &lt;module&gt;()\n----&gt; 1 ls2 = torch.gels(B.cuda(), A.cuda())\n\nRuntimeError: invalid argument 2: A should have m &gt;= n at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathMagma.cu:107\n</code></pre>\n<p>Is this a limitation of the CUDA implementation of <code>gels</code> that PyTorch uses, or otherwise intended? If so, any guidance about a possible work-around would be greatly appreciated. Our only thought on a work-around was to manually QR decompose A with <code>torch.qr</code> and then use <code>torch.trtrs</code>, but <code>torch.trtrs</code> doesn't support CUDA tensors.</p>", "body_text": "I am currently using PyTorch 0.3.0 and I am noticing some (possibly strange) differences between the behavior of torch.gels when operating on CPU tensors versus GPU ones, in particular relating to whether the number of rows of A is allowed to be larger than the number of columns or not.\nHere is some minimal code that reproduces my problem:\nimport torch\nA = torch.randn(5, 100)\nB = torch.randn(5, 5)\nls1 = torch.gels(B, A) # Works!\nls2 = torch.gels(B.cuda(), A.cuda()) # Fails\nThe first solve on the CPU works fine; however, the second solve gives me the error:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-15-757975f749ea> in <module>()\n----> 1 ls2 = torch.gels(B.cuda(), A.cuda())\n\nRuntimeError: invalid argument 2: A should have m >= n at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathMagma.cu:107\n\nIs this a limitation of the CUDA implementation of gels that PyTorch uses, or otherwise intended? If so, any guidance about a possible work-around would be greatly appreciated. Our only thought on a work-around was to manually QR decompose A with torch.qr and then use torch.trtrs, but torch.trtrs doesn't support CUDA tensors.", "body": "I am currently using PyTorch 0.3.0 and I am noticing some (possibly strange) differences between the behavior of `torch.gels` when operating on CPU tensors versus GPU ones, in particular relating to whether the number of rows of A is allowed to be larger than the number of columns or not.\r\n\r\nHere is some minimal code that reproduces my problem:\r\n\r\n```python\r\nimport torch\r\nA = torch.randn(5, 100)\r\nB = torch.randn(5, 5)\r\nls1 = torch.gels(B, A) # Works!\r\nls2 = torch.gels(B.cuda(), A.cuda()) # Fails\r\n```\r\nThe first solve on the CPU works fine; however, the second solve gives me the error:\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-15-757975f749ea> in <module>()\r\n----> 1 ls2 = torch.gels(B.cuda(), A.cuda())\r\n\r\nRuntimeError: invalid argument 2: A should have m >= n at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorMathMagma.cu:107\r\n```\r\n\r\nIs this a limitation of the CUDA implementation of `gels` that PyTorch uses, or otherwise intended? If so, any guidance about a possible work-around would be greatly appreciated. Our only thought on a work-around was to manually QR decompose A with `torch.qr` and then use `torch.trtrs`, but `torch.trtrs` doesn't support CUDA tensors."}