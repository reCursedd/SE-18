{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/256760341", "html_url": "https://github.com/pytorch/pytorch/pull/167#issuecomment-256760341", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/167", "id": 256760341, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Njc2MDM0MQ==", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-27T20:31:48Z", "updated_at": "2016-10-27T20:31:48Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3503919\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/thatguymike\">@thatguymike</a>, I think there are two things that were contributing to the overhead:</p>\n<ol>\n<li>The Python ctypes bindings to cuDNN had some overhead especially since it takes a bunch of calls to set up a convolution</li>\n<li>The CPU overhead increases with the number of GPUs, since with 8 GPUs you have to launch 8 times as many kernels.</li>\n</ol>\n<p>I think the first issues is mostly solved by this commit. The bindings overhead is now much less than the time spent in <code>cudnnConvolutionForward()</code>.</p>\n<p>We plan to deal with the second issue using multi-process implementation of data parallel. In Lua, the multi-threaded dispatch in DataParallelTable helped hide kernel launch overhead, but in Python the GIL reduces the available parallelism, so we probably need to use Python mulitprocessing (like we do in data loading)</p>", "body_text": "@thatguymike, I think there are two things that were contributing to the overhead:\n\nThe Python ctypes bindings to cuDNN had some overhead especially since it takes a bunch of calls to set up a convolution\nThe CPU overhead increases with the number of GPUs, since with 8 GPUs you have to launch 8 times as many kernels.\n\nI think the first issues is mostly solved by this commit. The bindings overhead is now much less than the time spent in cudnnConvolutionForward().\nWe plan to deal with the second issue using multi-process implementation of data parallel. In Lua, the multi-threaded dispatch in DataParallelTable helped hide kernel launch overhead, but in Python the GIL reduces the available parallelism, so we probably need to use Python mulitprocessing (like we do in data loading)", "body": "@thatguymike, I think there are two things that were contributing to the overhead:\n1. The Python ctypes bindings to cuDNN had some overhead especially since it takes a bunch of calls to set up a convolution\n2. The CPU overhead increases with the number of GPUs, since with 8 GPUs you have to launch 8 times as many kernels.\n\nI think the first issues is mostly solved by this commit. The bindings overhead is now much less than the time spent in `cudnnConvolutionForward()`.\n\nWe plan to deal with the second issue using multi-process implementation of data parallel. In Lua, the multi-threaded dispatch in DataParallelTable helped hide kernel launch overhead, but in Python the GIL reduces the available parallelism, so we probably need to use Python mulitprocessing (like we do in data loading)\n"}