{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1681", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1681/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1681/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1681/events", "html_url": "https://github.com/pytorch/pytorch/issues/1681", "id": 232296246, "node_id": "MDU6SXNzdWUyMzIyOTYyNDY=", "number": 1681, "title": "torch.arange failing for large inputs", "user": {"login": "zkolter", "id": 2465474, "node_id": "MDQ6VXNlcjI0NjU0NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/2465474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zkolter", "html_url": "https://github.com/zkolter", "followers_url": "https://api.github.com/users/zkolter/followers", "following_url": "https://api.github.com/users/zkolter/following{/other_user}", "gists_url": "https://api.github.com/users/zkolter/gists{/gist_id}", "starred_url": "https://api.github.com/users/zkolter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zkolter/subscriptions", "organizations_url": "https://api.github.com/users/zkolter/orgs", "repos_url": "https://api.github.com/users/zkolter/repos", "events_url": "https://api.github.com/users/zkolter/events{/privacy}", "received_events_url": "https://api.github.com/users/zkolter/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-30T15:42:27Z", "updated_at": "2017-05-30T16:28:54Z", "closed_at": "2017-05-30T15:50:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>When I call torch.arange() for large inputs, it seems to have a bizarre upper limit.  On version 0.1.12_2.</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.arange(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">20000000</span>)\n<span class=\"pl-c1\">print</span>(a[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], a[<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>])\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Outputs:</span>\n<span class=\"pl-s\">16777216.0 16777216.0</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span></pre></div>\n<p>My current workaround.  Since I want integer ranges, this seems to work fine:</p>\n<div class=\"highlight highlight-source-python\"><pre>a <span class=\"pl-k\">=</span> torch.ones(<span class=\"pl-c1\">20000000</span>).nonzero().squeeze()\n<span class=\"pl-c1\">print</span>(a[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>], a[<span class=\"pl-k\">-</span><span class=\"pl-c1\">2</span>])\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span> Outputs:</span>\n<span class=\"pl-s\">19999999 19999998</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span></span></pre></div>\n<p>Edit: Ok, should have done a quick Google search before posting.  32 bit floats can't represent higher precision than that.  I'll modify this to be a possible (low-priority) request to simply have an integer version of range, for this reason.</p>", "body_text": "When I call torch.arange() for large inputs, it seems to have a bizarre upper limit.  On version 0.1.12_2.\na = torch.arange(0, 20000000)\nprint(a[-1], a[-2])\n\"\"\" Outputs:\n16777216.0 16777216.0\n\"\"\"\nMy current workaround.  Since I want integer ranges, this seems to work fine:\na = torch.ones(20000000).nonzero().squeeze()\nprint(a[-1], a[-2])\n\"\"\" Outputs:\n19999999 19999998\n\"\"\"\nEdit: Ok, should have done a quick Google search before posting.  32 bit floats can't represent higher precision than that.  I'll modify this to be a possible (low-priority) request to simply have an integer version of range, for this reason.", "body": "When I call torch.arange() for large inputs, it seems to have a bizarre upper limit.  On version 0.1.12_2.\r\n\r\n```python\r\na = torch.arange(0, 20000000)\r\nprint(a[-1], a[-2])\r\n\"\"\" Outputs:\r\n16777216.0 16777216.0\r\n\"\"\"\r\n```\r\n\r\nMy current workaround.  Since I want integer ranges, this seems to work fine:\r\n```python\r\na = torch.ones(20000000).nonzero().squeeze()\r\nprint(a[-1], a[-2])\r\n\"\"\" Outputs:\r\n19999999 19999998\r\n\"\"\"\r\n```\r\n\r\nEdit: Ok, should have done a quick Google search before posting.  32 bit floats can't represent higher precision than that.  I'll modify this to be a possible (low-priority) request to simply have an integer version of range, for this reason.\r\n"}