{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/401446704", "html_url": "https://github.com/pytorch/pytorch/issues/7092#issuecomment-401446704", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7092", "id": 401446704, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMTQ0NjcwNA==", "user": {"login": "PetrochukM", "id": 7424737, "node_id": "MDQ6VXNlcjc0MjQ3Mzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7424737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PetrochukM", "html_url": "https://github.com/PetrochukM", "followers_url": "https://api.github.com/users/PetrochukM/followers", "following_url": "https://api.github.com/users/PetrochukM/following{/other_user}", "gists_url": "https://api.github.com/users/PetrochukM/gists{/gist_id}", "starred_url": "https://api.github.com/users/PetrochukM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PetrochukM/subscriptions", "organizations_url": "https://api.github.com/users/PetrochukM/orgs", "repos_url": "https://api.github.com/users/PetrochukM/repos", "events_url": "https://api.github.com/users/PetrochukM/events{/privacy}", "received_events_url": "https://api.github.com/users/PetrochukM/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-29T19:07:18Z", "updated_at": "2018-07-02T16:33:21Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a> Read through the tutorial and the launch utility, the distributed API has many options that enable it to be really powerful. Amazing!</p>\n<p>Following up on this comment -- \"If you are using RNN, it is better to use DistributedDataParallel (and 1 process per GPU) than using DataParallel.\" <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1310570\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/soumith\">@soumith</a></p>\n<p>For a single machine with multiple GPUs 2 - 8 running RNNs, what are the best parameters.</p>\n<ul>\n<li>Should we use <code>tcp</code> or the file system for communication?</li>\n<li>I am assuming that it'd be best to have one process per GPU.</li>\n<li>Do you recommend using <code>torch.utils.data.distributed.DistributedSampler</code>? What cases would it be helpful?</li>\n<li>Anything else?</li>\n</ul>\n<p>Sorry, do not have much experience with this and following reading the article, it was not obviously clear!</p>", "body_text": "@soumith Read through the tutorial and the launch utility, the distributed API has many options that enable it to be really powerful. Amazing!\nFollowing up on this comment -- \"If you are using RNN, it is better to use DistributedDataParallel (and 1 process per GPU) than using DataParallel.\" @soumith\nFor a single machine with multiple GPUs 2 - 8 running RNNs, what are the best parameters.\n\nShould we use tcp or the file system for communication?\nI am assuming that it'd be best to have one process per GPU.\nDo you recommend using torch.utils.data.distributed.DistributedSampler? What cases would it be helpful?\nAnything else?\n\nSorry, do not have much experience with this and following reading the article, it was not obviously clear!", "body": "@soumith Read through the tutorial and the launch utility, the distributed API has many options that enable it to be really powerful. Amazing!\r\n\r\nFollowing up on this comment -- \"If you are using RNN, it is better to use DistributedDataParallel (and 1 process per GPU) than using DataParallel.\" @soumith \r\n\r\nFor a single machine with multiple GPUs 2 - 8 running RNNs, what are the best parameters.\r\n\r\n- Should we use ``tcp`` or the file system for communication?\r\n- I am assuming that it'd be best to have one process per GPU. \r\n- Do you recommend using ``torch.utils.data.distributed.DistributedSampler``? What cases would it be helpful?\r\n- Anything else?\r\n\r\nSorry, do not have much experience with this and following reading the article, it was not obviously clear!\r\n\r\n"}