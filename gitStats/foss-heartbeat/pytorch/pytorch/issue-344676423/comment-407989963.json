{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/407989963", "html_url": "https://github.com/pytorch/pytorch/issues/9863#issuecomment-407989963", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9863", "id": 407989963, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzk4OTk2Mw==", "user": {"login": "bhushan23", "id": 1794273, "node_id": "MDQ6VXNlcjE3OTQyNzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1794273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bhushan23", "html_url": "https://github.com/bhushan23", "followers_url": "https://api.github.com/users/bhushan23/followers", "following_url": "https://api.github.com/users/bhushan23/following{/other_user}", "gists_url": "https://api.github.com/users/bhushan23/gists{/gist_id}", "starred_url": "https://api.github.com/users/bhushan23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bhushan23/subscriptions", "organizations_url": "https://api.github.com/users/bhushan23/orgs", "repos_url": "https://api.github.com/users/bhushan23/repos", "events_url": "https://api.github.com/users/bhushan23/events{/privacy}", "received_events_url": "https://api.github.com/users/bhushan23/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-26T06:23:56Z", "updated_at": "2018-07-26T06:50:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Generally more the batch size more the training time.<br>\nGeneral practice is to start with small batch size to learn quickly and then increase the batch size</p>\n<p>Try with small batch sizes like 128, 64<br>\nfor learning purpose, I would suggest to also run for higher batch size 512 and see how batch size affect the training time.<br>\nand instead of one epoch, wait for multiple epoch (may be 2 in this case due to high wait time) and average out the time</p>", "body_text": "Generally more the batch size more the training time.\nGeneral practice is to start with small batch size to learn quickly and then increase the batch size\nTry with small batch sizes like 128, 64\nfor learning purpose, I would suggest to also run for higher batch size 512 and see how batch size affect the training time.\nand instead of one epoch, wait for multiple epoch (may be 2 in this case due to high wait time) and average out the time", "body": "Generally more the batch size more the training time.\r\nGeneral practice is to start with small batch size to learn quickly and then increase the batch size\r\n\r\nTry with small batch sizes like 128, 64 \r\nfor learning purpose, I would suggest to also run for higher batch size 512 and see how batch size affect the training time.\r\nand instead of one epoch, wait for multiple epoch (may be 2 in this case due to high wait time) and average out the time"}