{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/415633949", "html_url": "https://github.com/pytorch/pytorch/pull/9393#issuecomment-415633949", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/9393", "id": 415633949, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTYzMzk0OQ==", "user": {"login": "zasdfgbnm", "id": 1032377, "node_id": "MDQ6VXNlcjEwMzIzNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1032377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zasdfgbnm", "html_url": "https://github.com/zasdfgbnm", "followers_url": "https://api.github.com/users/zasdfgbnm/followers", "following_url": "https://api.github.com/users/zasdfgbnm/following{/other_user}", "gists_url": "https://api.github.com/users/zasdfgbnm/gists{/gist_id}", "starred_url": "https://api.github.com/users/zasdfgbnm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zasdfgbnm/subscriptions", "organizations_url": "https://api.github.com/users/zasdfgbnm/orgs", "repos_url": "https://api.github.com/users/zasdfgbnm/repos", "events_url": "https://api.github.com/users/zasdfgbnm/events{/privacy}", "received_events_url": "https://api.github.com/users/zasdfgbnm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-24T02:41:30Z", "updated_at": "2018-08-24T02:41:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5652049\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zou3519\">@zou3519</a> Answer to your question:</p>\n<ol>\n<li>The speed is faster. The following program:</li>\n</ol>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch\n<span class=\"pl-k\">import</span> itertools\n<span class=\"pl-k\">from</span> tqdm <span class=\"pl-k\">import</span> tqdm\n\na <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">100</span>)\nb <span class=\"pl-k\">=</span> torch.rand(<span class=\"pl-c1\">100</span>)\n\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> tqdm(<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10000</span>)):\n\ttorch.cartesian_prod([a, b])\n\n<span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> tqdm(<span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10000</span>)):\n\ttorch.tensor(<span class=\"pl-c1\">list</span>(itertools.product(a, b)))</pre></div>\n<p>On my computer, the first would be 7806.71it/s, but the second is only 65.69it/s.</p>\n<ol start=\"2\">\n<li>\n<p>For convenience, I'm assuming, when we need to do cartesian product or combinations, the input tensor is usually a index tensor, and the result will further be used in something like <code>index_select</code>, <code>index</code>, <code>gather</code>, etc. It would be more convenient if we can directly have a tensor, instead of list of tensors.</p>\n</li>\n<li>\n<p>Is itertools supported in JIT??</p>\n</li>\n</ol>", "body_text": "@zou3519 Answer to your question:\n\nThe speed is faster. The following program:\n\nimport torch\nimport itertools\nfrom tqdm import tqdm\n\na = torch.rand(100)\nb = torch.rand(100)\n\nfor _ in tqdm(range(10000)):\n\ttorch.cartesian_prod([a, b])\n\nfor _ in tqdm(range(10000)):\n\ttorch.tensor(list(itertools.product(a, b)))\nOn my computer, the first would be 7806.71it/s, but the second is only 65.69it/s.\n\n\nFor convenience, I'm assuming, when we need to do cartesian product or combinations, the input tensor is usually a index tensor, and the result will further be used in something like index_select, index, gather, etc. It would be more convenient if we can directly have a tensor, instead of list of tensors.\n\n\nIs itertools supported in JIT??", "body": "@zou3519 Answer to your question:\r\n\r\n1. The speed is faster. The following program:\r\n```python\r\nimport torch\r\nimport itertools\r\nfrom tqdm import tqdm\r\n\r\na = torch.rand(100)\r\nb = torch.rand(100)\r\n\r\nfor _ in tqdm(range(10000)):\r\n\ttorch.cartesian_prod([a, b])\r\n\r\nfor _ in tqdm(range(10000)):\r\n\ttorch.tensor(list(itertools.product(a, b)))\r\n```\r\nOn my computer, the first would be 7806.71it/s, but the second is only 65.69it/s.\r\n\r\n2. For convenience, I'm assuming, when we need to do cartesian product or combinations, the input tensor is usually a index tensor, and the result will further be used in something like `index_select`, `index`, `gather`, etc. It would be more convenient if we can directly have a tensor, instead of list of tensors.\r\n\r\n3. Is itertools supported in JIT??"}