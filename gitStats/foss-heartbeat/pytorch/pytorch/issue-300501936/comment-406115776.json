{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/406115776", "html_url": "https://github.com/pytorch/pytorch/issues/5426#issuecomment-406115776", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5426", "id": 406115776, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNjExNTc3Ng==", "user": {"login": "internetingofthings", "id": 24214229, "node_id": "MDQ6VXNlcjI0MjE0MjI5", "avatar_url": "https://avatars2.githubusercontent.com/u/24214229?v=4", "gravatar_id": "", "url": "https://api.github.com/users/internetingofthings", "html_url": "https://github.com/internetingofthings", "followers_url": "https://api.github.com/users/internetingofthings/followers", "following_url": "https://api.github.com/users/internetingofthings/following{/other_user}", "gists_url": "https://api.github.com/users/internetingofthings/gists{/gist_id}", "starred_url": "https://api.github.com/users/internetingofthings/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/internetingofthings/subscriptions", "organizations_url": "https://api.github.com/users/internetingofthings/orgs", "repos_url": "https://api.github.com/users/internetingofthings/repos", "events_url": "https://api.github.com/users/internetingofthings/events{/privacy}", "received_events_url": "https://api.github.com/users/internetingofthings/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-19T00:30:24Z", "updated_at": "2018-07-19T00:30:24Z", "author_association": "NONE", "body_html": "<p>Different application, I found that processing an array in pytorch using CUDA device is very fast, but displaying the result incurs 200 msec penalty when converting back to numpy array.</p>\n<p>example:<br>\ntorch_array = torch.from_numpy(numpy_array) # less than 1msec<br>\ndo processing on torch_array  # less than 1 msec on GPU @ 99%<br>\nnumpy_array = np.array(torch_array) # greater than 200 msec</p>\n<p>does anyone know a method that avoids the conversion penalty back to numpy. GPU = nvidia on TX1 platform</p>", "body_text": "Different application, I found that processing an array in pytorch using CUDA device is very fast, but displaying the result incurs 200 msec penalty when converting back to numpy array.\nexample:\ntorch_array = torch.from_numpy(numpy_array) # less than 1msec\ndo processing on torch_array  # less than 1 msec on GPU @ 99%\nnumpy_array = np.array(torch_array) # greater than 200 msec\ndoes anyone know a method that avoids the conversion penalty back to numpy. GPU = nvidia on TX1 platform", "body": "Different application, I found that processing an array in pytorch using CUDA device is very fast, but displaying the result incurs 200 msec penalty when converting back to numpy array.\r\n\r\nexample:\r\ntorch_array = torch.from_numpy(numpy_array) # less than 1msec\r\ndo processing on torch_array  # less than 1 msec on GPU @ 99%\r\nnumpy_array = np.array(torch_array) # greater than 200 msec\r\n\r\ndoes anyone know a method that avoids the conversion penalty back to numpy. GPU = nvidia on TX1 platform"}