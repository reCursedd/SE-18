{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216880136", "pull_request_review_id": 154464946, "id": 216880136, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxNjg4MDEzNg==", "diff_hunk": "@@ -4092,5 +4092,121 @@ def tearDown(self):\n         super(TestCase, self).tearDown()\n         Distribution.set_default_validate_args(False)\n \n+\n+class TestJit(TestCase):\n+    def _examples(self):\n+        for Dist, params in EXAMPLES:\n+            for param in params:\n+                print('testing {}'.format(Dist.__name__))\n+                keys = param.keys()\n+                values = tuple(param[key] for key in keys)\n+                if not all(isinstance(x, torch.Tensor) for x in values):\n+                    continue\n+                sample = Dist(**param).sample()\n+                yield Dist, keys, values, sample\n+\n+    def test_sample(self):\n+        for Dist, keys, values, sample in self._examples():\n+            if Dist in [Geometric, Cauchy, StudentT]:\n+                continue  # FIXME missing support for aten::uniform, aten::cauchy\n+\n+            def f(*values):\n+                param = dict(zip(keys, values))\n+                dist = Dist(**param)\n+                return dist.sample()\n+\n+            torch.jit.trace(f, values, check_trace=False)", "path": "test/test_distributions.py", "position": null, "original_position": 27, "commit_id": "cf132fce4d6bf01d9033ac82c8de6d62c168f150", "original_commit_id": "f9a1150956b828746f8a84e4c4b9eba53d919d65", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "While trace might succeed in most cases, it doesn't mean that the trace is correct. In particular the outputs could be embedded as constants. It would be better to use `torch.random.fork_rng` to ensure that the traced function returns the same outputs as `f`, and that they are different every time you run it. Additionally, you might want to do something like:\r\n```python\r\nself.assertTrue(any(n.isNondeterministic() for n in traced_f.graph.nodes()))\r\n```", "created_at": "2018-09-12T02:27:29Z", "updated_at": "2018-11-23T15:51:07Z", "html_url": "https://github.com/pytorch/pytorch/pull/11560#discussion_r216880136", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/11560", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/216880136"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/11560#discussion_r216880136"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/11560"}}, "body_html": "<p>While trace might succeed in most cases, it doesn't mean that the trace is correct. In particular the outputs could be embedded as constants. It would be better to use <code>torch.random.fork_rng</code> to ensure that the traced function returns the same outputs as <code>f</code>, and that they are different every time you run it. Additionally, you might want to do something like:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c1\">self</span>.assertTrue(<span class=\"pl-c1\">any</span>(n.isNondeterministic() <span class=\"pl-k\">for</span> n <span class=\"pl-k\">in</span> traced_f.graph.nodes()))</pre></div>", "body_text": "While trace might succeed in most cases, it doesn't mean that the trace is correct. In particular the outputs could be embedded as constants. It would be better to use torch.random.fork_rng to ensure that the traced function returns the same outputs as f, and that they are different every time you run it. Additionally, you might want to do something like:\nself.assertTrue(any(n.isNondeterministic() for n in traced_f.graph.nodes()))"}