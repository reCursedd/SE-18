{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232109472", "pull_request_review_id": 173233513, "id": 232109472, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMjEwOTQ3Mg==", "diff_hunk": "@@ -49,6 +50,37 @@ class DataLoader {\n     }\n   }\n \n+  /// Constructs a new `DataLoader` from a `dataset`, `options`, and `Sampler`.", "path": "torch/csrc/api/include/torch/data/dataloader.h", "position": 21, "original_position": 21, "commit_id": "41208e442f929e8883fd0359e14f0d98466e0c85", "original_commit_id": "880aeebda0f9be2118eb95f99e50d9d620e7b43b", "user": {"login": "jaliyae", "id": 12703337, "node_id": "MDQ6VXNlcjEyNzAzMzM3", "avatar_url": "https://avatars3.githubusercontent.com/u/12703337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaliyae", "html_url": "https://github.com/jaliyae", "followers_url": "https://api.github.com/users/jaliyae/followers", "following_url": "https://api.github.com/users/jaliyae/following{/other_user}", "gists_url": "https://api.github.com/users/jaliyae/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaliyae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaliyae/subscriptions", "organizations_url": "https://api.github.com/users/jaliyae/orgs", "repos_url": "https://api.github.com/users/jaliyae/repos", "events_url": "https://api.github.com/users/jaliyae/events{/privacy}", "received_events_url": "https://api.github.com/users/jaliyae/received_events", "type": "User", "site_admin": false}, "body": "I see your point, but unless we ask this from the user, we will end up copying the dataset one more time when creating the shared_ptr and assuming a proper copy constructor is defined in the dataset (I could not find a torch version of make_shared with move capability). In any case, do you think this complexity is needed for this change. We can get back to this, if it simplify things when we have a complete implementation. Currently this is only a part of it. What do you think?\r\n\r\nbtw; even with the current PR, the map() operations are happening in the dataloader's threads. Only the prefetching is happening in the dataset.", "created_at": "2018-11-09T00:31:29Z", "updated_at": "2018-11-23T15:54:34Z", "html_url": "https://github.com/pytorch/pytorch/pull/13585#discussion_r232109472", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13585", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232109472"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13585#discussion_r232109472"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13585"}}, "body_html": "<p>I see your point, but unless we ask this from the user, we will end up copying the dataset one more time when creating the shared_ptr and assuming a proper copy constructor is defined in the dataset (I could not find a torch version of make_shared with move capability). In any case, do you think this complexity is needed for this change. We can get back to this, if it simplify things when we have a complete implementation. Currently this is only a part of it. What do you think?</p>\n<p>btw; even with the current PR, the map() operations are happening in the dataloader's threads. Only the prefetching is happening in the dataset.</p>", "body_text": "I see your point, but unless we ask this from the user, we will end up copying the dataset one more time when creating the shared_ptr and assuming a proper copy constructor is defined in the dataset (I could not find a torch version of make_shared with move capability). In any case, do you think this complexity is needed for this change. We can get back to this, if it simplify things when we have a complete implementation. Currently this is only a part of it. What do you think?\nbtw; even with the current PR, the map() operations are happening in the dataloader's threads. Only the prefetching is happening in the dataset.", "in_reply_to_id": 232003002}