{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230930716", "pull_request_review_id": 171782582, "id": 230930716, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMDkzMDcxNg==", "diff_hunk": "@@ -59,6 +60,37 @@ class DataLoader {\n     }\n   }\n \n+  /// Constructs a new `DataLoader` from a `dataset`, `options`, and `Sampler`.\n+  /// This constructor must be used with a chunk data set. The `Sampler` is\n+  /// default to `BatchSizeSampler` for the dataloader, please check\n+  /// `make_chunk_data_loader` below. However, a regular sampler and a chunk\n+  /// sampler need to be provided to the `dataset` for it to function properly.\n+  /// The data loader simply retrives batches using the batch size.\n+  DataLoader(\n+      Dataset dataset,", "path": "torch/csrc/api/include/torch/data/dataloader.h", "position": 28, "original_position": 28, "commit_id": "41208e442f929e8883fd0359e14f0d98466e0c85", "original_commit_id": "0795b33e08598b77f2472a659ddf9d06bc9e915d", "user": {"login": "jaliyae", "id": 12703337, "node_id": "MDQ6VXNlcjEyNzAzMzM3", "avatar_url": "https://avatars3.githubusercontent.com/u/12703337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaliyae", "html_url": "https://github.com/jaliyae", "followers_url": "https://api.github.com/users/jaliyae/followers", "following_url": "https://api.github.com/users/jaliyae/following{/other_user}", "gists_url": "https://api.github.com/users/jaliyae/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaliyae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaliyae/subscriptions", "organizations_url": "https://api.github.com/users/jaliyae/orgs", "repos_url": "https://api.github.com/users/jaliyae/repos", "events_url": "https://api.github.com/users/jaliyae/events{/privacy}", "received_events_url": "https://api.github.com/users/jaliyae/received_events", "type": "User", "site_admin": false}, "body": "We need to support map operation, which is defined in the Dataset class. The design here is that Dataloader does not care about how the chunks are loaded or any additional APIs needed. All these are Dataset specific constructs. One option I did not implement is that at the constructor, we can type check the Dataset and throw an exception.", "created_at": "2018-11-05T22:04:38Z", "updated_at": "2018-11-23T15:54:20Z", "html_url": "https://github.com/pytorch/pytorch/pull/13585#discussion_r230930716", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13585", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/230930716"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13585#discussion_r230930716"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13585"}}, "body_html": "<p>We need to support map operation, which is defined in the Dataset class. The design here is that Dataloader does not care about how the chunks are loaded or any additional APIs needed. All these are Dataset specific constructs. One option I did not implement is that at the constructor, we can type check the Dataset and throw an exception.</p>", "body_text": "We need to support map operation, which is defined in the Dataset class. The design here is that Dataloader does not care about how the chunks are loaded or any additional APIs needed. All these are Dataset specific constructs. One option I did not implement is that at the constructor, we can type check the Dataset and throw an exception.", "in_reply_to_id": 230929264}