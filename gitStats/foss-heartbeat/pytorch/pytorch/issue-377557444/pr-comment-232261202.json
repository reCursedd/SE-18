{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232261202", "pull_request_review_id": 173420566, "id": 232261202, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzMjI2MTIwMg==", "diff_hunk": "@@ -0,0 +1,36 @@\n+#pragma once\n+\n+#include <c10/util/Exception.h>\n+#include <torch/data/datasets/base.h>\n+#include <torch/data/example.h>\n+\n+namespace torch {\n+namespace data {\n+namespace datasets {\n+/// A dataset that supports loading an entire chunk of data.\n+///\n+/// A chunk could be an entire file, such as an audio data file or an image,\n+/// or part of a file in the case of a large text file split based on seek\n+/// positions. ChunkDataSet extends the DataSet functionality to read an\n+/// entire chunk at once.\n+template <\n+    typename Self,\n+    typename Batch = std::vector<Example<>>,\n+    typename BatchRequest = ArrayRef<size_t>>\n+class ChunkDataSet : public BatchDataset<Self, Batch, BatchRequest> {", "path": "torch/csrc/api/include/torch/data/datasets/chunk.h", "position": 20, "original_position": 20, "commit_id": "41208e442f929e8883fd0359e14f0d98466e0c85", "original_commit_id": "880aeebda0f9be2118eb95f99e50d9d620e7b43b", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I still don\u2019t understand why the previous interface is insufficient. Preloading more data and caching it in the dataset object is something that\u2019s very easy to do using the existing API, so I don\u2019t think this justifies the added complexity of this solution.", "created_at": "2018-11-09T13:59:46Z", "updated_at": "2018-11-23T15:54:35Z", "html_url": "https://github.com/pytorch/pytorch/pull/13585#discussion_r232261202", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/13585", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/232261202"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/13585#discussion_r232261202"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/13585"}}, "body_html": "<p>I still don\u2019t understand why the previous interface is insufficient. Preloading more data and caching it in the dataset object is something that\u2019s very easy to do using the existing API, so I don\u2019t think this justifies the added complexity of this solution.</p>", "body_text": "I still don\u2019t understand why the previous interface is insufficient. Preloading more data and caching it in the dataset object is something that\u2019s very easy to do using the existing API, so I don\u2019t think this justifies the added complexity of this solution.", "in_reply_to_id": 232002171}