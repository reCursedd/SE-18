{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/436362791", "html_url": "https://github.com/pytorch/pytorch/pull/13585#issuecomment-436362791", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13585", "id": 436362791, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjM2Mjc5MQ==", "user": {"login": "jaliyae", "id": 12703337, "node_id": "MDQ6VXNlcjEyNzAzMzM3", "avatar_url": "https://avatars3.githubusercontent.com/u/12703337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jaliyae", "html_url": "https://github.com/jaliyae", "followers_url": "https://api.github.com/users/jaliyae/followers", "following_url": "https://api.github.com/users/jaliyae/following{/other_user}", "gists_url": "https://api.github.com/users/jaliyae/gists{/gist_id}", "starred_url": "https://api.github.com/users/jaliyae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jaliyae/subscriptions", "organizations_url": "https://api.github.com/users/jaliyae/orgs", "repos_url": "https://api.github.com/users/jaliyae/repos", "events_url": "https://api.github.com/users/jaliyae/events{/privacy}", "received_events_url": "https://api.github.com/users/jaliyae/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-06T18:43:08Z", "updated_at": "2018-11-06T18:43:08Z", "author_association": "NONE", "body_html": "<p>There are two levels of parallelisms when loading data. One that perform transformations (map/resize/collate) this is what the dataloader is doing. The next part is fetching data from the source, in the regular dataloader this is also handled in the dataloader itself (prefetch).</p>\n<p>What we essentially proposing is that let prefetching to be pushed to the dataset and leave all the transformations in the dataloader as it is. Typically prefetching does not need to have the same level of parallelism as the transformations and further, the \"collate\" function and its semantics does not allow us to apply collate on the whole chunk directly but per user defined batch.</p>\n<p>Another way to think about this is that considering the dataset as a client to another data source. How the client handles prefetching and buffering should not affect the dataloader's behavior or operation. We tried to make the minimum change to the dataloader keeping existing functionality intact.</p>", "body_text": "There are two levels of parallelisms when loading data. One that perform transformations (map/resize/collate) this is what the dataloader is doing. The next part is fetching data from the source, in the regular dataloader this is also handled in the dataloader itself (prefetch).\nWhat we essentially proposing is that let prefetching to be pushed to the dataset and leave all the transformations in the dataloader as it is. Typically prefetching does not need to have the same level of parallelism as the transformations and further, the \"collate\" function and its semantics does not allow us to apply collate on the whole chunk directly but per user defined batch.\nAnother way to think about this is that considering the dataset as a client to another data source. How the client handles prefetching and buffering should not affect the dataloader's behavior or operation. We tried to make the minimum change to the dataloader keeping existing functionality intact.", "body": "There are two levels of parallelisms when loading data. One that perform transformations (map/resize/collate) this is what the dataloader is doing. The next part is fetching data from the source, in the regular dataloader this is also handled in the dataloader itself (prefetch). \r\n\r\nWhat we essentially proposing is that let prefetching to be pushed to the dataset and leave all the transformations in the dataloader as it is. Typically prefetching does not need to have the same level of parallelism as the transformations and further, the \"collate\" function and its semantics does not allow us to apply collate on the whole chunk directly but per user defined batch.\r\n\r\nAnother way to think about this is that considering the dataset as a client to another data source. How the client handles prefetching and buffering should not affect the dataloader's behavior or operation. We tried to make the minimum change to the dataloader keeping existing functionality intact. "}