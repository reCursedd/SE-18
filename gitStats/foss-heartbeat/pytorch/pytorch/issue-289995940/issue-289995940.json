{"url": "https://api.github.com/repos/pytorch/pytorch/issues/4742", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/4742/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/4742/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/4742/events", "html_url": "https://github.com/pytorch/pytorch/issues/4742", "id": 289995940, "node_id": "MDU6SXNzdWUyODk5OTU5NDA=", "number": 4742, "title": "cuda runtime error (4) when pushing model to cuda", "user": {"login": "gerazov", "id": 15214418, "node_id": "MDQ6VXNlcjE1MjE0NDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/15214418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gerazov", "html_url": "https://github.com/gerazov", "followers_url": "https://api.github.com/users/gerazov/followers", "following_url": "https://api.github.com/users/gerazov/following{/other_user}", "gists_url": "https://api.github.com/users/gerazov/gists{/gist_id}", "starred_url": "https://api.github.com/users/gerazov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gerazov/subscriptions", "organizations_url": "https://api.github.com/users/gerazov/orgs", "repos_url": "https://api.github.com/users/gerazov/repos", "events_url": "https://api.github.com/users/gerazov/events{/privacy}", "received_events_url": "https://api.github.com/users/gerazov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-19T14:38:49Z", "updated_at": "2018-01-19T15:39:35Z", "closed_at": "2018-01-19T15:39:35Z", "author_association": "NONE", "body_html": "<p>I'm just starting with PyTorch (coming from Theano) and it's awesome!</p>\n<p>I put together a linear regressor with a single hidden layer and it works fine but crashes if I try pushing it to cuda. There might be plenty of wrong with the code but I don't know where to look. Here's the model and the code that crashes it:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">n_feature</span>, <span class=\"pl-smi\">n_hidden</span>, <span class=\"pl-smi\">n_output</span>):\n        <span class=\"pl-c1\">super</span>(Net, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.n_feature <span class=\"pl-k\">=</span> n_feature\n        <span class=\"pl-c1\">self</span>.n_hidden <span class=\"pl-k\">=</span> n_hidden\n        <span class=\"pl-c1\">self</span>.n_output <span class=\"pl-k\">=</span> n_output\n        \n        <span class=\"pl-c1\">self</span>.wh <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_feature, n_hidden))\n        <span class=\"pl-c1\">self</span>.bh <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_hidden))\n        \n        <span class=\"pl-c1\">self</span>.wy <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_hidden, n_output))\n        <span class=\"pl-c1\">self</span>.by <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_output))\n        \n        <span class=\"pl-c1\">self</span>.reset_parameters()\n    \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">reset_parameters</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        stdv <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> np.sqrt(<span class=\"pl-c1\">self</span>.wh.size(<span class=\"pl-c1\">1</span>))  \n        <span class=\"pl-c1\">self</span>.wh.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv)\n        <span class=\"pl-c1\">self</span>.bh.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv)\n        \n        stdv <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>. <span class=\"pl-k\">/</span> np.sqrt(<span class=\"pl-c1\">self</span>.wy.size(<span class=\"pl-c1\">1</span>))  \n        <span class=\"pl-c1\">self</span>.wy.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv)\n        <span class=\"pl-c1\">self</span>.by.data.uniform_(<span class=\"pl-k\">-</span>stdv, stdv)\n    \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        h <span class=\"pl-k\">=</span> x.mm(<span class=\"pl-c1\">self</span>.wh) <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.bh\n        a <span class=\"pl-k\">=</span> F.logsigmoid(h)      <span class=\"pl-c\"><span class=\"pl-c\">#</span> activation function for hidden layer</span>\n        y <span class=\"pl-k\">=</span> a.mm(<span class=\"pl-c1\">self</span>.wy) <span class=\"pl-k\">+</span> <span class=\"pl-c1\">self</span>.by\n        <span class=\"pl-k\">return</span> y\n\nnet <span class=\"pl-k\">=</span> Net(<span class=\"pl-v\">n_feature</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">n_hidden</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>, <span class=\"pl-v\">n_output</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>).cuda() </pre></div>\n<p>The traceback I get is:</p>\n<pre><code>Traceback (most recent call last):\n\n  File \"&lt;ipython-input-137-44e8bf8308ac&gt;\", line 1, in &lt;module&gt;\n    net = Net(n_feature=1, n_hidden=10, n_output=1).cuda()     # define the network\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in cuda\n    return self._apply(lambda t: t.cuda(device))\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 152, in _apply\n    param.data = fn(param.data)\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in &lt;lambda&gt;\n    return self._apply(lambda t: t.cuda(device))\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\n    return new_type(self.size()).copy_(self, async)\n\nRuntimeError: cuda runtime error (4) : unspecified launch failure at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorCopy.c:20\n\n</code></pre>\n<p>I was guessing it's because we don't use <code>nn</code> or <code>functional</code> to define the layers, but I don't know. If yes what is a good way to mix equations and available layers?</p>\n<p>I also tried:</p>\n<div class=\"highlight highlight-source-python\"><pre>        dtype <span class=\"pl-k\">=</span> torch.cuda.FloatTensor\n        <span class=\"pl-c1\">self</span>.wh <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_feature, n_hidden).type(dtype))\n        <span class=\"pl-c1\">self</span>.bh <span class=\"pl-k\">=</span> Parameter(torch.Tensor(n_hidden).type(dtype))\n        <span class=\"pl-c1\">...</span></pre></div>\n<p>But this gives the same error.</p>", "body_text": "I'm just starting with PyTorch (coming from Theano) and it's awesome!\nI put together a linear regressor with a single hidden layer and it works fine but crashes if I try pushing it to cuda. There might be plenty of wrong with the code but I don't know where to look. Here's the model and the code that crashes it:\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.n_feature = n_feature\n        self.n_hidden = n_hidden\n        self.n_output = n_output\n        \n        self.wh = Parameter(torch.Tensor(n_feature, n_hidden))\n        self.bh = Parameter(torch.Tensor(n_hidden))\n        \n        self.wy = Parameter(torch.Tensor(n_hidden, n_output))\n        self.by = Parameter(torch.Tensor(n_output))\n        \n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        stdv = 1. / np.sqrt(self.wh.size(1))  \n        self.wh.data.uniform_(-stdv, stdv)\n        self.bh.data.uniform_(-stdv, stdv)\n        \n        stdv = 1. / np.sqrt(self.wy.size(1))  \n        self.wy.data.uniform_(-stdv, stdv)\n        self.by.data.uniform_(-stdv, stdv)\n    \n    def forward(self, x):\n        h = x.mm(self.wh) + self.bh\n        a = F.logsigmoid(h)      # activation function for hidden layer\n        y = a.mm(self.wy) + self.by\n        return y\n\nnet = Net(n_feature=1, n_hidden=10, n_output=1).cuda() \nThe traceback I get is:\nTraceback (most recent call last):\n\n  File \"<ipython-input-137-44e8bf8308ac>\", line 1, in <module>\n    net = Net(n_feature=1, n_hidden=10, n_output=1).cuda()     # define the network\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in cuda\n    return self._apply(lambda t: t.cuda(device))\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 152, in _apply\n    param.data = fn(param.data)\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in <lambda>\n    return self._apply(lambda t: t.cuda(device))\n\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\n    return new_type(self.size()).copy_(self, async)\n\nRuntimeError: cuda runtime error (4) : unspecified launch failure at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorCopy.c:20\n\n\nI was guessing it's because we don't use nn or functional to define the layers, but I don't know. If yes what is a good way to mix equations and available layers?\nI also tried:\n        dtype = torch.cuda.FloatTensor\n        self.wh = Parameter(torch.Tensor(n_feature, n_hidden).type(dtype))\n        self.bh = Parameter(torch.Tensor(n_hidden).type(dtype))\n        ...\nBut this gives the same error.", "body": "I'm just starting with PyTorch (coming from Theano) and it's awesome! \r\n\r\nI put together a linear regressor with a single hidden layer and it works fine but crashes if I try pushing it to cuda. There might be plenty of wrong with the code but I don't know where to look. Here's the model and the code that crashes it:\r\n\r\n```python\r\nclass Net(torch.nn.Module):\r\n    def __init__(self, n_feature, n_hidden, n_output):\r\n        super(Net, self).__init__()\r\n        self.n_feature = n_feature\r\n        self.n_hidden = n_hidden\r\n        self.n_output = n_output\r\n        \r\n        self.wh = Parameter(torch.Tensor(n_feature, n_hidden))\r\n        self.bh = Parameter(torch.Tensor(n_hidden))\r\n        \r\n        self.wy = Parameter(torch.Tensor(n_hidden, n_output))\r\n        self.by = Parameter(torch.Tensor(n_output))\r\n        \r\n        self.reset_parameters()\r\n    \r\n    def reset_parameters(self):\r\n        stdv = 1. / np.sqrt(self.wh.size(1))  \r\n        self.wh.data.uniform_(-stdv, stdv)\r\n        self.bh.data.uniform_(-stdv, stdv)\r\n        \r\n        stdv = 1. / np.sqrt(self.wy.size(1))  \r\n        self.wy.data.uniform_(-stdv, stdv)\r\n        self.by.data.uniform_(-stdv, stdv)\r\n    \r\n    def forward(self, x):\r\n        h = x.mm(self.wh) + self.bh\r\n        a = F.logsigmoid(h)      # activation function for hidden layer\r\n        y = a.mm(self.wy) + self.by\r\n        return y\r\n\r\nnet = Net(n_feature=1, n_hidden=10, n_output=1).cuda() \r\n```\r\nThe traceback I get is:\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-137-44e8bf8308ac>\", line 1, in <module>\r\n    net = Net(n_feature=1, n_hidden=10, n_output=1).cuda()     # define the network\r\n\r\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in cuda\r\n    return self._apply(lambda t: t.cuda(device))\r\n\r\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 152, in _apply\r\n    param.data = fn(param.data)\r\n\r\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 216, in <lambda>\r\n    return self._apply(lambda t: t.cuda(device))\r\n\r\n  File \"~/miniconda3/lib/python3.6/site-packages/torch/_utils.py\", line 69, in _cuda\r\n    return new_type(self.size()).copy_(self, async)\r\n\r\nRuntimeError: cuda runtime error (4) : unspecified launch failure at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCTensorCopy.c:20\r\n\r\n```\r\nI was guessing it's because we don't use `nn` or `functional` to define the layers, but I don't know. If yes what is a good way to mix equations and available layers?\r\n\r\nI also tried:\r\n```python\r\n        dtype = torch.cuda.FloatTensor\r\n        self.wh = Parameter(torch.Tensor(n_feature, n_hidden).type(dtype))\r\n        self.bh = Parameter(torch.Tensor(n_hidden).type(dtype))\r\n        ...\r\n```\r\nBut this gives the same error."}