{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171619354", "pull_request_review_id": 100504449, "id": 171619354, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE3MTYxOTM1NA==", "diff_hunk": "@@ -1,65 +1,71 @@\n #pragma once\n \n-#include <utility>\n+#include <ATen/ATenAssert.h>\n+#include <ATen/Half.h>\n+#include <ATen/Type.h>\n \n-namespace at {\n-\n-// FIXME: nvcc can't seem to do type deduction on\n-// decltype(F<double>::apply(std::forward<Args>(args)...)) so we have to explicitly pass the return type\n+#define AT_PRIVATE_CASE_TYPE(enum_type, type, ...) \\\n+  case enum_type: {                                \\\n+    using scalar_t = type;                         \\\n+    return __VA_ARGS__();                          \\\n+  }\n \n-template<typename R, template <typename> class F, typename ... Args>\n-R dispatch_all(const Type& the_type, const char *name, Args&&... args) {\n-  switch(the_type.scalarType()) {\n-    case ScalarType::Byte:\n-      return F<uint8_t>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Char:\n-      return F<int8_t>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Double:\n-      return F<double>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Float:\n-      return F<float>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Int:\n-      return F<int>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Long:\n-      return F<int64_t>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Short:\n-      return F<int16_t>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Half:\n-      return F<Half>::apply(std::forward<Args>(args)...);\n-    default:\n-      runtime_error(\"%s not implemented for '%s'\", name, the_type.toString());\n-    }\n-}\n+#define AT_DISPATCH_FLOATING_TYPES(TYPE, NAME, ...)                      \\\n+  [&] {                                                                  \\\n+    const at::Type& the_type = TYPE;                                     \\\n+    switch (the_type.scalarType()) {                                     \\\n+      AT_PRIVATE_CASE_TYPE(at::ScalarType::Double, double, __VA_ARGS__)  \\\n+      AT_PRIVATE_CASE_TYPE(at::ScalarType::Float, float, __VA_ARGS__)    \\\n+      default:                                                           \\\n+        at::runtime_error(                                               \\\n+            \"%s not implemented for '%s'\", (NAME), the_type.toString()); \\\n+    }                                                                    \\\n+  }()\n \n-template<typename R, template <typename> class F, typename ... Args>\n-R dispatch_floating_types(const Type& the_type, const char *name, Args&&... args) {\n-  switch(the_type.scalarType()) {\n-    case ScalarType::Double:\n-      return F<double>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Float:\n-      return F<float>::apply(std::forward<Args>(args)...);\n-    case ScalarType::Half: // no native half math on either CPU or GPU.\n-    default:\n-      runtime_error(\"%s not implemented for '%s'\", name, the_type.toString());\n-  }\n-}\n+#define AT_DISPATCH_FLOATING_TYPES_AND_HALF(TYPE, NAME, ...)             \\\n+  [&] {                                                                  \\\n+    const at::Type& the_type = TYPE;                                     \\\n+    switch (the_type.scalarType()) {                                     \\\n+      AT_PRIVATE_CASE_TYPE(at::ScalarType::Double, double, __VA_ARGS__)  \\\n+      AT_PRIVATE_CASE_TYPE(at::ScalarType::Float, float, __VA_ARGS__)    \\\n+      AT_PRIVATE_CASE_TYPE(at::ScalarType::Half, Half, __VA_ARGS__)      \\\n+      default:                                                           \\\n+        at::runtime_error(                                               \\\n+            \"%s not implemented for '%s'\", (NAME), the_type.toString()); \\\n+    }                                                                    \\\n+  }()", "path": "aten/src/ATen/Dispatch.h", "position": 51, "original_position": 76, "commit_id": "66d39ce1535d5ee784e5c9975ce3e4084e7abc74", "original_commit_id": "66d39ce1535d5ee784e5c9975ce3e4084e7abc74", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "You can use `return` statements in a lambda, but not a temporary scope. This means that the dispatch functions can be used as expressions and the return type is inferred.", "created_at": "2018-03-01T16:42:45Z", "updated_at": "2018-11-23T15:40:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/5475#discussion_r171619354", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/5475", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/171619354"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/5475#discussion_r171619354"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/5475"}}, "body_html": "<p>You can use <code>return</code> statements in a lambda, but not a temporary scope. This means that the dispatch functions can be used as expressions and the return type is inferred.</p>", "body_text": "You can use return statements in a lambda, but not a temporary scope. This means that the dispatch functions can be used as expressions and the return type is inferred.", "in_reply_to_id": 171501201}