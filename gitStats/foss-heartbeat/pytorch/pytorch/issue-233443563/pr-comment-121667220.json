{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121667220", "pull_request_review_id": 43710279, "id": 121667220, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMTY2NzIyMA==", "diff_hunk": "@@ -460,6 +462,115 @@ void THCSTensor_(cmul)(THCState *state, THCSTensor *r_, THCSTensor *t_, THCSTens\n   THCSTensor_(free)(state, src);\n }\n \n+\n+ void THCTensor_(spbqrfactsolve)(THCState *state, THCTensor *rx_, THCTensor *b, THCIndexTensor *Ai, THCTensor *Av, THLongStorage *Asz) {\n+#if defined(THCS_REAL_IS_FLOAT) || defined(THCS_REAL_IS_DOUBLE)\n+   THCAssertSameGPU(THCSTensor_(checkGPU)(state, 1, 3, rx_, b, Av));\n+\n+   THArgCheck(b->nDimension == 2, 2,\n+              \"Batch tensor b expected, got %dD tensor\", b->nDimension);\n+   THArgCheck(Av->nDimension == 2, 2,\n+              \"Batch tensor Av expected, got %dD tensor\", Av->nDimension);\n+\n+   long nBatch = THCTensor_(size)(state, Av, 0);\n+   long nnz = THCTensor_(size)(state, Av, 1);\n+   long m = Asz->data[0];\n+   long n = Asz->data[1];\n+\n+   THCTensor_(resize2d)(state, rx_, nBatch, m);\n+\n+   THCIndexTensor *rowIndices = THCIndexTensor_(newSelect)(state, Ai, 0, 0);\n+   THCIndexTensor *colIndices = THCIndexTensor_(newSelect)(state, Ai, 0, 1);\n+   THCudaIntTensor *csr = THCSTensor_(toCSR)(state, rowIndices, m, nnz);\n+   THCudaIntTensor *colIndicesInt = THCudaIntTensor_newWithSize1d(state, colIndices->size[0]);\n+   THCudaIntTensor_copyCudaLong(state, colIndicesInt, colIndices);\n+\n+   cusparseStatus_t cusparse_status;\n+   cusolverStatus_t cusolver_status;\n+   cudaError_t cuda_status;\n+   csrqrInfo_t info;\n+\n+   cusolverSpHandle_t cusolverH;\n+   cusolver_status = cusolverSpCreate(&cusolverH);\n+   THAssert(CUSOLVER_STATUS_SUCCESS == cusolver_status);\n+\n+   cusparseMatDescr_t descrA;\n+   size_t size_qr = 0;\n+   size_t size_internal = 0;\n+   void *buffer_qr = NULL;\n+\n+   cusparse_status = cusparseCreateMatDescr(&descrA);\n+   THAssert(cusparse_status == CUSPARSE_STATUS_SUCCESS);\n+\n+   cusparseSetMatType(descrA, CUSPARSE_MATRIX_TYPE_GENERAL);\n+#if TH_INDEX_BASE == 0\n+   cusparseSetMatIndexBase(descrA, CUSPARSE_INDEX_BASE_ZERO);\n+#elif TH_INDEX_BASE ==1\n+   cusparseSetMatIndexBase(descrA, CUSPARSE_INDEX_BASE_ONE);\n+#else\n+     THError(\"Unknown TH_INDEX_BASE.\");\n+#endif\n+\n+   cusolver_status = cusolverSpCreateCsrqrInfo(&info);\n+   THAssert(cusolver_status == CUSOLVER_STATUS_SUCCESS);\n+\n+   cusolver_status = cusolverSpXcsrqrAnalysisBatched(\n+       cusolverH, m, n, nnz,\n+       descrA,\n+       THCudaIntTensor_data(state, csr),\n+       THCudaIntTensor_data(state, colIndicesInt),\n+       info);\n+   THAssert(cusolver_status == CUSOLVER_STATUS_SUCCESS);\n+\n+   cusolver_status =\n+#if defined(THCS_REAL_IS_FLOAT)\n+     cusolverSpScsrqrBufferInfoBatched(\n+#elif defined(THCS_REAL_IS_DOUBLE)\n+     cusolverSpDcsrqrBufferInfoBatched(\n+#endif\n+       cusolverH, m, n, nnz,\n+       descrA,\n+       THCTensor_(data)(state, Av),\n+       THCudaIntTensor_data(state, csr),\n+       THCudaIntTensor_data(state, colIndicesInt),\n+       nBatch,\n+       info,\n+       &size_internal,\n+       &size_qr);\n+   THAssert(cusolver_status == CUSOLVER_STATUS_SUCCESS);\n+\n+   cuda_status = cudaMalloc((void**)&buffer_qr, size_qr);\n+   THAssert(cuda_status == cudaSuccess);\n+\n+   cusolver_status =\n+#if defined(THCS_REAL_IS_FLOAT)\n+     cusolverSpScsrqrsvBatched(\n+#elif defined(THCS_REAL_IS_DOUBLE)\n+     cusolverSpDcsrqrsvBatched(\n+#endif\n+       cusolverH, m, n, nnz,\n+       descrA,\n+       THCTensor_(data)(state, Av),\n+       THCudaIntTensor_data(state, csr),\n+       THCudaIntTensor_data(state, colIndicesInt),\n+       THCTensor_(data)(state, b),\n+       THCTensor_(data)(state, rx_),\n+       nBatch, info,\n+       buffer_qr);\n+   THAssert(cusolver_status == CUSOLVER_STATUS_SUCCESS);\n+\n+   cusolverSpDestroyCsrqrInfo(info);", "path": "torch/lib/THCS/generic/THCSTensorMath.cu", "position": 110, "original_position": 110, "commit_id": "522c5607e472d320ac47e8475201f6e0497bd67f", "original_commit_id": "522c5607e472d320ac47e8475201f6e0497bd67f", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "@ngimel Do you know if we need to hold a free mutex for these sparse calls?", "created_at": "2017-06-13T12:50:52Z", "updated_at": "2018-11-23T15:33:51Z", "html_url": "https://github.com/pytorch/pytorch/pull/1716#discussion_r121667220", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/1716", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/121667220"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/1716#discussion_r121667220"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/1716"}}, "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15841449\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ngimel\">@ngimel</a> Do you know if we need to hold a free mutex for these sparse calls?</p>", "body_text": "@ngimel Do you know if we need to hold a free mutex for these sparse calls?"}