{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/355323471", "html_url": "https://github.com/pytorch/pytorch/pull/1716#issuecomment-355323471", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1716", "id": 355323471, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTMyMzQ3MQ==", "user": {"login": "zou3519", "id": 5652049, "node_id": "MDQ6VXNlcjU2NTIwNDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5652049?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zou3519", "html_url": "https://github.com/zou3519", "followers_url": "https://api.github.com/users/zou3519/followers", "following_url": "https://api.github.com/users/zou3519/following{/other_user}", "gists_url": "https://api.github.com/users/zou3519/gists{/gist_id}", "starred_url": "https://api.github.com/users/zou3519/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zou3519/subscriptions", "organizations_url": "https://api.github.com/users/zou3519/orgs", "repos_url": "https://api.github.com/users/zou3519/repos", "events_url": "https://api.github.com/users/zou3519/events{/privacy}", "received_events_url": "https://api.github.com/users/zou3519/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-04T16:10:39Z", "updated_at": "2018-01-04T16:10:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I'm currently rebasing this. I'm noticing that the batch dimension for A (in the <code>Ax = b</code> solver function) is the last one: the shape of <code>A</code> is <code>(m, n, nBatch)</code>. This makes sense because pytorch's sparse tensors can have dense dimensions only as the last dimensions (following sparse dimensions), but it breaks a little from the convention that the batch dimension is first.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> you said this function would be useful for some torch.distributions things. Would those still work with the assumption that the batch dimension is last for sparse tensors like this?</p>", "body_text": "I'm currently rebasing this. I'm noticing that the batch dimension for A (in the Ax = b solver function) is the last one: the shape of A is (m, n, nBatch). This makes sense because pytorch's sparse tensors can have dense dimensions only as the last dimensions (following sparse dimensions), but it breaks a little from the convention that the batch dimension is first.\n@apaszke you said this function would be useful for some torch.distributions things. Would those still work with the assumption that the batch dimension is last for sparse tensors like this?", "body": "I'm currently rebasing this. I'm noticing that the batch dimension for A (in the `Ax = b` solver function) is the last one: the shape of `A` is `(m, n, nBatch)`. This makes sense because pytorch's sparse tensors can have dense dimensions only as the last dimensions (following sparse dimensions), but it breaks a little from the convention that the batch dimension is first.\r\n\r\n@apaszke you said this function would be useful for some torch.distributions things. Would those still work with the assumption that the batch dimension is last for sparse tensors like this?"}