{"url": "https://api.github.com/repos/pytorch/pytorch/issues/1716", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/1716/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/1716/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/1716/events", "html_url": "https://github.com/pytorch/pytorch/pull/1716", "id": 233443563, "node_id": "MDExOlB1bGxSZXF1ZXN0MTIzODgzMjYz", "number": 1716, "title": "[WIP] Batched sparse QR factorizations and solves with cusolver", "user": {"login": "bamos", "id": 707462, "node_id": "MDQ6VXNlcjcwNzQ2Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/707462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bamos", "html_url": "https://github.com/bamos", "followers_url": "https://api.github.com/users/bamos/followers", "following_url": "https://api.github.com/users/bamos/following{/other_user}", "gists_url": "https://api.github.com/users/bamos/gists{/gist_id}", "starred_url": "https://api.github.com/users/bamos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bamos/subscriptions", "organizations_url": "https://api.github.com/users/bamos/orgs", "repos_url": "https://api.github.com/users/bamos/repos", "events_url": "https://api.github.com/users/bamos/events{/privacy}", "received_events_url": "https://api.github.com/users/bamos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-06-04T16:23:01Z", "updated_at": "2018-11-23T15:33:51Z", "closed_at": null, "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/1716", "html_url": "https://github.com/pytorch/pytorch/pull/1716", "diff_url": "https://github.com/pytorch/pytorch/pull/1716.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/1716.patch"}, "body_html": "<p>This PR is connected to issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"218963108\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/1178\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1178/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/1178\">#1178</a>.</p>\n<p>This is still a little hacky and a WIP but I'm sending it in to get a conversation started and move this towards something mergable. I am currently using this with the sparse solvers I have in qpth and it's working well: <a href=\"https://github.com/locuslab/qpth/blob/master/qpth/solvers/pdipm/spbatch.py\">https://github.com/locuslab/qpth/blob/master/qpth/solvers/pdipm/spbatch.py</a></p>\n<p>I think that batched sparse tensor operations with the same sparsity pattern will come up frequently to take advantage of GPU parallelism and I sent in this discussion a while ago about handling this case: <a href=\"https://discuss.pytorch.org/t/3d-sparse-batch-tensors-with-the-same-sparsity-pattern/2806\" rel=\"nofollow\">https://discuss.pytorch.org/t/3d-sparse-batch-tensors-with-the-same-sparsity-pattern/2806</a></p>\n<p>We could move this broader conversation back to that thread. I could add some transpose operations to my code here and use hybrid sparse tensors as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13564\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ezyang\">@ezyang</a> mentioned. However for simplicity and because I'm not sure what you all prefer, I've implemented this to <strong>not</strong> do that and I'm <strong>not</strong> using the sparse tensor wrapper and am just passing the appropriate tensors around. What are your opinions on how I should modify this function and interface?</p>", "body_text": "This PR is connected to issue #1178.\nThis is still a little hacky and a WIP but I'm sending it in to get a conversation started and move this towards something mergable. I am currently using this with the sparse solvers I have in qpth and it's working well: https://github.com/locuslab/qpth/blob/master/qpth/solvers/pdipm/spbatch.py\nI think that batched sparse tensor operations with the same sparsity pattern will come up frequently to take advantage of GPU parallelism and I sent in this discussion a while ago about handling this case: https://discuss.pytorch.org/t/3d-sparse-batch-tensors-with-the-same-sparsity-pattern/2806\nWe could move this broader conversation back to that thread. I could add some transpose operations to my code here and use hybrid sparse tensors as @ezyang mentioned. However for simplicity and because I'm not sure what you all prefer, I've implemented this to not do that and I'm not using the sparse tensor wrapper and am just passing the appropriate tensors around. What are your opinions on how I should modify this function and interface?", "body": "This PR is connected to issue #1178.\r\n\r\nThis is still a little hacky and a WIP but I'm sending it in to get a conversation started and move this towards something mergable. I am currently using this with the sparse solvers I have in qpth and it's working well: https://github.com/locuslab/qpth/blob/master/qpth/solvers/pdipm/spbatch.py\r\n\r\nI think that batched sparse tensor operations with the same sparsity pattern will come up frequently to take advantage of GPU parallelism and I sent in this discussion a while ago about handling this case: https://discuss.pytorch.org/t/3d-sparse-batch-tensors-with-the-same-sparsity-pattern/2806\r\n\r\nWe could move this broader conversation back to that thread. I could add some transpose operations to my code here and use hybrid sparse tensors as @ezyang mentioned. However for simplicity and because I'm not sure what you all prefer, I've implemented this to **not** do that and I'm **not** using the sparse tensor wrapper and am just passing the appropriate tensors around. What are your opinions on how I should modify this function and interface?"}