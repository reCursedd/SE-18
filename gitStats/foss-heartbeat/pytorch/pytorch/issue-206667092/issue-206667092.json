{"url": "https://api.github.com/repos/pytorch/pytorch/issues/713", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/713/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/713/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/713/events", "html_url": "https://github.com/pytorch/pytorch/pull/713", "id": 206667092, "node_id": "MDExOlB1bGxSZXF1ZXN0MTA1NTQwMTM1", "number": 713, "title": "improved serialization (no tar copy)", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-02-09T23:58:24Z", "updated_at": "2018-11-23T15:32:30Z", "closed_at": "2017-02-22T21:24:21Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/713", "html_url": "https://github.com/pytorch/pytorch/pull/713", "diff_url": "https://github.com/pytorch/pytorch/pull/713.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/713.patch"}, "body_html": "<p>Some notes:</p>\n<ul>\n<li>\n<p>This runs 5-10x faster than the old code on my machine; it reads big tensors at ~2.5GB/s, which is faster than the file reading unless the file is cached.</p>\n</li>\n<li>\n<p>I tried to make this avoid seeks, but <code>load</code> takes arbitrary file objects and they may be buffered in python, so when you start reading the storages in C, you need to do a C seek to before the extra Python buffering. If we want to avoid seeks, the only choice is to do the file reading purely in C. I will leave this to a future PR if it's necessary.</p>\n</li>\n<li>\n<p>I change <code>tensor.__reduce__</code> to return <code>(t.storage(), t.storageOffset, t.size(), t.stride)</code> instead of a nested list representation of the tensor. I think this is more consistent with the fact that a tensor is a view on storage (otherwise <code>__reduce__</code> would break sharing, etc.). One upshot of this is it changes the behavior of copy.copy (which is now just a shallow copy of the tensor view).</p>\n</li>\n<li>\n<p><code>persistent_id</code> technically is only allowed to return a string, but we return tuples. This happens to work for the binary protocol, but not the string protocol. It's not guaranteed to work in the future. I'm not sure how to fix it for the module case</p>\n</li>\n<li>\n<p><code>load</code> remains backwards compatible with old checkpoints (although they'll still be slow). There's a test for it.</p>\n</li>\n<li>\n<p>the old serialization code had a little bug I noticed, where it only treated a storage as a view if <code>offset != 0</code>. But technically, you could have a view with <code>offset ==0</code>, e.g. <code>s2 = s[0:5]</code>.</p>\n</li>\n</ul>", "body_text": "Some notes:\n\n\nThis runs 5-10x faster than the old code on my machine; it reads big tensors at ~2.5GB/s, which is faster than the file reading unless the file is cached.\n\n\nI tried to make this avoid seeks, but load takes arbitrary file objects and they may be buffered in python, so when you start reading the storages in C, you need to do a C seek to before the extra Python buffering. If we want to avoid seeks, the only choice is to do the file reading purely in C. I will leave this to a future PR if it's necessary.\n\n\nI change tensor.__reduce__ to return (t.storage(), t.storageOffset, t.size(), t.stride) instead of a nested list representation of the tensor. I think this is more consistent with the fact that a tensor is a view on storage (otherwise __reduce__ would break sharing, etc.). One upshot of this is it changes the behavior of copy.copy (which is now just a shallow copy of the tensor view).\n\n\npersistent_id technically is only allowed to return a string, but we return tuples. This happens to work for the binary protocol, but not the string protocol. It's not guaranteed to work in the future. I'm not sure how to fix it for the module case\n\n\nload remains backwards compatible with old checkpoints (although they'll still be slow). There's a test for it.\n\n\nthe old serialization code had a little bug I noticed, where it only treated a storage as a view if offset != 0. But technically, you could have a view with offset ==0, e.g. s2 = s[0:5].", "body": "Some notes:\r\n\r\n- This runs 5-10x faster than the old code on my machine; it reads big tensors at ~2.5GB/s, which is faster than the file reading unless the file is cached.\r\n\r\n- I tried to make this avoid seeks, but `load` takes arbitrary file objects and they may be buffered in python, so when you start reading the storages in C, you need to do a C seek to before the extra Python buffering. If we want to avoid seeks, the only choice is to do the file reading purely in C. I will leave this to a future PR if it's necessary.\r\n\r\n- I change `tensor.__reduce__` to return `(t.storage(), t.storageOffset, t.size(), t.stride)` instead of a nested list representation of the tensor. I think this is more consistent with the fact that a tensor is a view on storage (otherwise `__reduce__` would break sharing, etc.). One upshot of this is it changes the behavior of copy.copy (which is now just a shallow copy of the tensor view).\r\n\r\n- `persistent_id` technically is only allowed to return a string, but we return tuples. This happens to work for the binary protocol, but not the string protocol. It's not guaranteed to work in the future. I'm not sure how to fix it for the module case\r\n\r\n- `load` remains backwards compatible with old checkpoints (although they'll still be slow). There's a test for it.\r\n\r\n- the old serialization code had a little bug I noticed, where it only treated a storage as a view if `offset != 0`. But technically, you could have a view with `offset ==0`, e.g. `s2 = s[0:5]`."}