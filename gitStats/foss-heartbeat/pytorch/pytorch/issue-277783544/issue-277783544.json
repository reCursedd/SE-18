{"url": "https://api.github.com/repos/pytorch/pytorch/issues/3936", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/3936/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/3936/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/3936/events", "html_url": "https://github.com/pytorch/pytorch/issues/3936", "id": 277783544, "node_id": "MDU6SXNzdWUyNzc3ODM1NDQ=", "number": 3936, "title": "nn.BatchNorm1d failed on GPU", "user": {"login": "weigq", "id": 18133388, "node_id": "MDQ6VXNlcjE4MTMzMzg4", "avatar_url": "https://avatars3.githubusercontent.com/u/18133388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weigq", "html_url": "https://github.com/weigq", "followers_url": "https://api.github.com/users/weigq/followers", "following_url": "https://api.github.com/users/weigq/following{/other_user}", "gists_url": "https://api.github.com/users/weigq/gists{/gist_id}", "starred_url": "https://api.github.com/users/weigq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weigq/subscriptions", "organizations_url": "https://api.github.com/users/weigq/orgs", "repos_url": "https://api.github.com/users/weigq/repos", "events_url": "https://api.github.com/users/weigq/events{/privacy}", "received_events_url": "https://api.github.com/users/weigq/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-29T14:53:59Z", "updated_at": "2017-11-29T15:18:42Z", "closed_at": "2017-11-29T15:18:42Z", "author_association": "NONE", "body_html": "<p>hi, I met a issue:</p>\n<pre><code># env\ncuda-8.0-cudnn-7\npython 2.7/3.5\ntorch-2.0\n</code></pre>\n<p>here:</p>\n<pre><code>a = Variable(torch.randn(2,5).cuda(), requires_grad=True)\ny = torch.nn.BatchNorm1d(5)(a)\n\n## info\n----&gt; 1 y = torch.nn.BatchNorm1d(5)(a)\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--&gt; 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/batchnorm.pyc in forward(self, input)\n     35         return F.batch_norm(\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\n---&gt; 37             self.training, self.momentum, self.eps)\n     38\n     39     def __repr__(self):\n\n~/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n    637                training=False, momentum=0.1, eps=1e-5):\n    638     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\n--&gt; 639     return f(input, weight, bias)\n    640\n    641\n\nRuntimeError: std::bad_cast\n</code></pre>\n<p>But works well on cpu.<br>\nis this a bug?<br>\nthx</p>", "body_text": "hi, I met a issue:\n# env\ncuda-8.0-cudnn-7\npython 2.7/3.5\ntorch-2.0\n\nhere:\na = Variable(torch.randn(2,5).cuda(), requires_grad=True)\ny = torch.nn.BatchNorm1d(5)(a)\n\n## info\n----> 1 y = torch.nn.BatchNorm1d(5)(a)\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc in __call__(self, *input, **kwargs)\n    222         for hook in self._forward_pre_hooks.values():\n    223             hook(self, input)\n--> 224         result = self.forward(*input, **kwargs)\n    225         for hook in self._forward_hooks.values():\n    226             hook_result = hook(self, input, result)\n\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/batchnorm.pyc in forward(self, input)\n     35         return F.batch_norm(\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\n---> 37             self.training, self.momentum, self.eps)\n     38\n     39     def __repr__(self):\n\n~/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n    637                training=False, momentum=0.1, eps=1e-5):\n    638     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\n--> 639     return f(input, weight, bias)\n    640\n    641\n\nRuntimeError: std::bad_cast\n\nBut works well on cpu.\nis this a bug?\nthx", "body": "hi, I met a issue:\r\n```\r\n# env\r\ncuda-8.0-cudnn-7\r\npython 2.7/3.5\r\ntorch-2.0\r\n```\r\nhere:\r\n```\r\na = Variable(torch.randn(2,5).cuda(), requires_grad=True)\r\ny = torch.nn.BatchNorm1d(5)(a)\r\n\r\n## info\r\n----> 1 y = torch.nn.BatchNorm1d(5)(a)\r\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc in __call__(self, *input, **kwargs)\r\n    222         for hook in self._forward_pre_hooks.values():\r\n    223             hook(self, input)\r\n--> 224         result = self.forward(*input, **kwargs)\r\n    225         for hook in self._forward_hooks.values():\r\n    226             hook_result = hook(self, input, result)\r\n\r\n~/anaconda2/lib/python2.7/site-packages/torch/nn/modules/batchnorm.pyc in forward(self, input)\r\n     35         return F.batch_norm(\r\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\r\n---> 37             self.training, self.momentum, self.eps)\r\n     38\r\n     39     def __repr__(self):\r\n\r\n~/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\r\n    637                training=False, momentum=0.1, eps=1e-5):\r\n    638     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\r\n--> 639     return f(input, weight, bias)\r\n    640\r\n    641\r\n\r\nRuntimeError: std::bad_cast\r\n```\r\nBut works well on cpu.\r\nis this a bug?\r\nthx"}