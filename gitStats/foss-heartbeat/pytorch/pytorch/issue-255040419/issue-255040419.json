{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2612", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2612/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2612/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2612/events", "html_url": "https://github.com/pytorch/pytorch/issues/2612", "id": 255040419, "node_id": "MDU6SXNzdWUyNTUwNDA0MTk=", "number": 2612, "title": "Multi-GPU tarining with DataParallel must has GPU0", "user": {"login": "longcw", "id": 6198400, "node_id": "MDQ6VXNlcjYxOTg0MDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/6198400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/longcw", "html_url": "https://github.com/longcw", "followers_url": "https://api.github.com/users/longcw/followers", "following_url": "https://api.github.com/users/longcw/following{/other_user}", "gists_url": "https://api.github.com/users/longcw/gists{/gist_id}", "starred_url": "https://api.github.com/users/longcw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/longcw/subscriptions", "organizations_url": "https://api.github.com/users/longcw/orgs", "repos_url": "https://api.github.com/users/longcw/repos", "events_url": "https://api.github.com/users/longcw/events{/privacy}", "received_events_url": "https://api.github.com/users/longcw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-04T13:19:35Z", "updated_at": "2017-09-05T21:29:28Z", "closed_at": "2017-09-05T21:29:28Z", "author_association": "NONE", "body_html": "<p>The loss will never decrease when I train a model using multi-gpus but without gpu0. This is an example I modified from the <a href=\"https://github.com/pytorch/examples/tree/master/mnist\">official mnist example</a> : <a href=\"https://gist.github.com/longcw/e5efdb0e5a580a6b75604561b6e4f613\">https://gist.github.com/longcw/e5efdb0e5a580a6b75604561b6e4f613</a></p>\n<div class=\"highlight highlight-source-python\"><pre>gpus <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>]\nmodel <span class=\"pl-k\">=</span> torch.nn.DataParallel(model, <span class=\"pl-v\">device_ids</span><span class=\"pl-k\">=</span>gpus)</pre></div>\n<p>If <code>gpus = [1, 2]</code> the result after one epoch is</p>\n<pre><code>...\nTrain Epoch: 1 [58240/60000 (97%)]      Loss: 2.363280\nTrain Epoch: 1 [58880/60000 (98%)]      Loss: 2.373188\nTrain Epoch: 1 [59520/60000 (99%)]      Loss: 2.351889\n\nTest set: Average loss: 2.3285, Accuracy: 685/10000 (7%)\n</code></pre>\n<p>If <code>gpus = [0, 2]</code> the result after one epoch is</p>\n<pre><code>...\nTrain Epoch: 1 [58240/60000 (97%)]\tLoss: 0.268342\nTrain Epoch: 1 [58880/60000 (98%)]\tLoss: 0.286652\nTrain Epoch: 1 [59520/60000 (99%)]\tLoss: 0.514245\n\nTest set: Average loss: 0.1972, Accuracy: 9436/10000 (94%)\n</code></pre>", "body_text": "The loss will never decrease when I train a model using multi-gpus but without gpu0. This is an example I modified from the official mnist example : https://gist.github.com/longcw/e5efdb0e5a580a6b75604561b6e4f613\ngpus = [1, 2]\nmodel = torch.nn.DataParallel(model, device_ids=gpus)\nIf gpus = [1, 2] the result after one epoch is\n...\nTrain Epoch: 1 [58240/60000 (97%)]      Loss: 2.363280\nTrain Epoch: 1 [58880/60000 (98%)]      Loss: 2.373188\nTrain Epoch: 1 [59520/60000 (99%)]      Loss: 2.351889\n\nTest set: Average loss: 2.3285, Accuracy: 685/10000 (7%)\n\nIf gpus = [0, 2] the result after one epoch is\n...\nTrain Epoch: 1 [58240/60000 (97%)]\tLoss: 0.268342\nTrain Epoch: 1 [58880/60000 (98%)]\tLoss: 0.286652\nTrain Epoch: 1 [59520/60000 (99%)]\tLoss: 0.514245\n\nTest set: Average loss: 0.1972, Accuracy: 9436/10000 (94%)", "body": "The loss will never decrease when I train a model using multi-gpus but without gpu0. This is an example I modified from the [official mnist example](https://github.com/pytorch/examples/tree/master/mnist) : https://gist.github.com/longcw/e5efdb0e5a580a6b75604561b6e4f613\r\n\r\n```python\r\ngpus = [1, 2]\r\nmodel = torch.nn.DataParallel(model, device_ids=gpus)\r\n```\r\n\r\nIf `gpus = [1, 2]` the result after one epoch is \r\n```\r\n...\r\nTrain Epoch: 1 [58240/60000 (97%)]      Loss: 2.363280\r\nTrain Epoch: 1 [58880/60000 (98%)]      Loss: 2.373188\r\nTrain Epoch: 1 [59520/60000 (99%)]      Loss: 2.351889\r\n\r\nTest set: Average loss: 2.3285, Accuracy: 685/10000 (7%)\r\n```\r\n\r\nIf `gpus = [0, 2]` the result after one epoch is \r\n```\r\n...\r\nTrain Epoch: 1 [58240/60000 (97%)]\tLoss: 0.268342\r\nTrain Epoch: 1 [58880/60000 (98%)]\tLoss: 0.286652\r\nTrain Epoch: 1 [59520/60000 (99%)]\tLoss: 0.514245\r\n\r\nTest set: Average loss: 0.1972, Accuracy: 9436/10000 (94%)\r\n```\r\n"}