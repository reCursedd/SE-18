{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/145792270", "pull_request_review_id": 70645468, "id": 145792270, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0NTc5MjI3MA==", "diff_hunk": "@@ -160,146 +194,220 @@ def write(dirname, name, template, env):\n         f.write(template.substitute(env))\n \n \n-def load_derivatives(path):\n-    with open(path, 'r') as f:\n-        definitions = yaml.load(f, Loader=Loader)\n+def saved_variables(formula, args):\n+    # find which arguments need to be saved\n+    saved = []\n \n-    # Matches \"foo\" in \"foo, bar\" but not \"foobar\". The name is substituted for\n-    # the {} characters.\n-    name_regex = r'(^|\\W){}($|\\W)'\n+    for arg in args:\n+        if 'name' not in arg:\n+            # some returned arguments do not have names\n+            continue\n+        name = arg['name']\n+\n+        def replace_sizes(m):\n+            res = name + '_sizes'\n+            saved.append({'name': res, 'type': 'IntList'})\n+            return res\n+\n+        def replace_zeros(m):\n+            r = name + '_info'\n+            saved.append({'name': r, 'type': 'TypeAndSize'})\n+            return r + '.zeros()'\n+\n+        def replace_size_n(m):\n+            res = name + '_argsize_{}'.format(*m.groups())\n+            saved.append({'name': res, 'type': 'int64_t'})\n+            return res\n+\n+        def replace_to_arg_sizes(m):\n+            res = name + '_argsizes_{}'.format(*m.groups())\n+            saved.append({'name': res, 'type': 'IntList'})\n+            return res\n+\n+        # replace self.sizes() with self_sizes\n+        formula = re.sub(r'{}.sizes\\(\\)'.format(name), replace_sizes, formula)\n+        # replace zeros_like(self) with self_info\n+        formula = re.sub(r'zeros_like\\({}\\)'.format(name), replace_zeros, formula)\n+        # replace self.size(2) with self_size_2\n+        formula = re.sub(r'{}.size\\((\\w+)\\)'.format(name), replace_size_n, formula)\n+        # replace to_arg_sizes(self, 2) with self_argsizes_2\n+        formula = re.sub(r'to_arg_sizes\\({}, (\\w+)\\)'.format(name), replace_to_arg_sizes, formula)\n+\n+        if re.search(IDENT_REGEX.format(name), formula):\n+            arg = copy.deepcopy(arg)\n+            arg['type'] = arg['type'].replace('const ', '').replace(' &', '')\n+            saved.append(arg)\n+    return formula, saved\n+\n+\n+def create_derivative(declaration, formula, output_indices, var_names):\n+    returns = [r for r in declaration['returns'] if r.get('name') != 'self']\n+    arguments = [arg for arg in declaration['arguments']]\n+    if any(arg['name'] == 'inplace' for arg in arguments):\n+        for arg in arguments:\n+            if arg['name'] == 'input':\n+                returns += [arg]", "path": "tools/autograd/gen_variable_type.py", "position": null, "original_position": 233, "commit_id": "937212b9a919339d4afaede4b277e3fd8ae015d0", "original_commit_id": "cca8b80fd3e352fb955f416bee80b010797bf102", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "body": "This is for NN functions. For something like: `relu(Tensor input, bool inplace)`. If inplace is true then `input` is also a return argument. It's important that if we save input for the backwards we do it in the `save_outputs` section not the `save_inputs` because it might be modified.", "created_at": "2017-10-19T18:54:36Z", "updated_at": "2018-11-23T15:35:31Z", "html_url": "https://github.com/pytorch/pytorch/pull/3136#discussion_r145792270", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3136", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/145792270"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3136#discussion_r145792270"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3136"}}, "body_html": "<p>This is for NN functions. For something like: <code>relu(Tensor input, bool inplace)</code>. If inplace is true then <code>input</code> is also a return argument. It's important that if we save input for the backwards we do it in the <code>save_outputs</code> section not the <code>save_inputs</code> because it might be modified.</p>", "body_text": "This is for NN functions. For something like: relu(Tensor input, bool inplace). If inplace is true then input is also a return argument. It's important that if we save input for the backwards we do it in the save_outputs section not the save_inputs because it might be modified.", "in_reply_to_id": 145615431}