{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/288526591", "html_url": "https://github.com/pytorch/pytorch/issues/1036#issuecomment-288526591", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1036", "id": 288526591, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUyNjU5MQ==", "user": {"login": "adamlerer", "id": 5702157, "node_id": "MDQ6VXNlcjU3MDIxNTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamlerer", "html_url": "https://github.com/adamlerer", "followers_url": "https://api.github.com/users/adamlerer/followers", "following_url": "https://api.github.com/users/adamlerer/following{/other_user}", "gists_url": "https://api.github.com/users/adamlerer/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamlerer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamlerer/subscriptions", "organizations_url": "https://api.github.com/users/adamlerer/orgs", "repos_url": "https://api.github.com/users/adamlerer/repos", "events_url": "https://api.github.com/users/adamlerer/events{/privacy}", "received_events_url": "https://api.github.com/users/adamlerer/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-22T20:20:55Z", "updated_at": "2017-03-22T20:20:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In case anyone's interested, here's what happened:</p>\n<p>The TH_TENSOR_APPLYX has a fast inner loop and then an outer loop where all the tensor dimensions are updated. These use different loop counters. In <code>min</code> and <code>max</code> you have to look at the correct loop counter to know which index the max occurred at. I was always looking at the outer loop counter. TH_TENSOR_APPLYX is usually only used when the max is over the outer dim, but in this particular case you're taking the max over the dimension in the inner loop.</p>", "body_text": "In case anyone's interested, here's what happened:\nThe TH_TENSOR_APPLYX has a fast inner loop and then an outer loop where all the tensor dimensions are updated. These use different loop counters. In min and max you have to look at the correct loop counter to know which index the max occurred at. I was always looking at the outer loop counter. TH_TENSOR_APPLYX is usually only used when the max is over the outer dim, but in this particular case you're taking the max over the dimension in the inner loop.", "body": "In case anyone's interested, here's what happened:\r\n\r\nThe TH_TENSOR_APPLYX has a fast inner loop and then an outer loop where all the tensor dimensions are updated. These use different loop counters. In `min` and `max` you have to look at the correct loop counter to know which index the max occurred at. I was always looking at the outer loop counter. TH_TENSOR_APPLYX is usually only used when the max is over the outer dim, but in this particular case you're taking the max over the dimension in the inner loop."}