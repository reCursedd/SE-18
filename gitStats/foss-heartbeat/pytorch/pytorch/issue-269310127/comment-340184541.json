{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/340184541", "html_url": "https://github.com/pytorch/pytorch/pull/3337#issuecomment-340184541", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3337", "id": 340184541, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MDE4NDU0MQ==", "user": {"login": "hughperkins", "id": 123560, "node_id": "MDQ6VXNlcjEyMzU2MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/123560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughperkins", "html_url": "https://github.com/hughperkins", "followers_url": "https://api.github.com/users/hughperkins/followers", "following_url": "https://api.github.com/users/hughperkins/following{/other_user}", "gists_url": "https://api.github.com/users/hughperkins/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughperkins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughperkins/subscriptions", "organizations_url": "https://api.github.com/users/hughperkins/orgs", "repos_url": "https://api.github.com/users/hughperkins/repos", "events_url": "https://api.github.com/users/hughperkins/events{/privacy}", "received_events_url": "https://api.github.com/users/hughperkins/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-28T11:33:43Z", "updated_at": "2017-10-28T11:33:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>(Note: you can reassure yourself it should be +ve, using the following script:</p>\n<pre><code>import torch\nimport torch.nn.functional as F\n\n\ndef softmax(x):\n    assert len(x.size()) == 2\n    batch_size = x.size()[0]\n    K = x.size()[1]\n    res = torch.zeros(batch_size, K)\n    exp_x = torch.exp(x)\n    print('exp_x', exp_x)\n    sum_exp = exp_x.sum(1)\n    print('sum_exp', sum_exp)\n    for n in range(batch_size):\n        res[n] = exp_x[n] / sum_exp[n]\n    return res\n\n\nx = torch.FloatTensor([[-9, -0.3, 0.7, 1.2]])\nprint(softmax(x)[0])\nprint(F.softmax(x)[0])\n</code></pre>\n<p>Output:</p>\n<pre><code>exp_x \n 0.0001  0.7408  2.0138  3.3201\n[torch.FloatTensor of size 1x4]\n\nsum_exp \n 6.0748\n[torch.FloatTensor of size 1]\n\n\n 0.0000\n 0.1219\n 0.3315\n 0.5465\n[torch.FloatTensor of size 4]\n\nVariable containing:\n 0.0000\n 0.1219\n 0.3315\n 0.5465\n[torch.FloatTensor of size 4]\n</code></pre>", "body_text": "(Note: you can reassure yourself it should be +ve, using the following script:\nimport torch\nimport torch.nn.functional as F\n\n\ndef softmax(x):\n    assert len(x.size()) == 2\n    batch_size = x.size()[0]\n    K = x.size()[1]\n    res = torch.zeros(batch_size, K)\n    exp_x = torch.exp(x)\n    print('exp_x', exp_x)\n    sum_exp = exp_x.sum(1)\n    print('sum_exp', sum_exp)\n    for n in range(batch_size):\n        res[n] = exp_x[n] / sum_exp[n]\n    return res\n\n\nx = torch.FloatTensor([[-9, -0.3, 0.7, 1.2]])\nprint(softmax(x)[0])\nprint(F.softmax(x)[0])\n\nOutput:\nexp_x \n 0.0001  0.7408  2.0138  3.3201\n[torch.FloatTensor of size 1x4]\n\nsum_exp \n 6.0748\n[torch.FloatTensor of size 1]\n\n\n 0.0000\n 0.1219\n 0.3315\n 0.5465\n[torch.FloatTensor of size 4]\n\nVariable containing:\n 0.0000\n 0.1219\n 0.3315\n 0.5465\n[torch.FloatTensor of size 4]", "body": "(Note: you can reassure yourself it should be +ve, using the following script:\r\n\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\n\r\n\r\ndef softmax(x):\r\n    assert len(x.size()) == 2\r\n    batch_size = x.size()[0]\r\n    K = x.size()[1]\r\n    res = torch.zeros(batch_size, K)\r\n    exp_x = torch.exp(x)\r\n    print('exp_x', exp_x)\r\n    sum_exp = exp_x.sum(1)\r\n    print('sum_exp', sum_exp)\r\n    for n in range(batch_size):\r\n        res[n] = exp_x[n] / sum_exp[n]\r\n    return res\r\n\r\n\r\nx = torch.FloatTensor([[-9, -0.3, 0.7, 1.2]])\r\nprint(softmax(x)[0])\r\nprint(F.softmax(x)[0])\r\n```\r\n\r\nOutput:\r\n```\r\nexp_x \r\n 0.0001  0.7408  2.0138  3.3201\r\n[torch.FloatTensor of size 1x4]\r\n\r\nsum_exp \r\n 6.0748\r\n[torch.FloatTensor of size 1]\r\n\r\n\r\n 0.0000\r\n 0.1219\r\n 0.3315\r\n 0.5465\r\n[torch.FloatTensor of size 4]\r\n\r\nVariable containing:\r\n 0.0000\r\n 0.1219\r\n 0.3315\r\n 0.5465\r\n[torch.FloatTensor of size 4]\r\n```"}