{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/374433259", "html_url": "https://github.com/pytorch/pytorch/issues/5502#issuecomment-374433259", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/5502", "id": 374433259, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NDQzMzI1OQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-20T00:40:26Z", "updated_at": "2018-03-20T00:40:26Z", "author_association": "NONE", "body_html": "<p>I tried copying stuff using <code>_mm256_stream_si256</code> <a href=\"https://github.com/diux-dev/cluster/blob/master/psbench/memcpy.cc\">here</a>, it seems 2-3x faster than what PyTorch is doing by default</p>\n<p>This <a href=\"http://web.archive.org/web/20131223174037/http://software.intel.com/en-us/articles/memcpy-performance/\" rel=\"nofollow\">article</a> talks about why memcpy is so bad. It's part of standard library, so you are relying on stock pre-compiled version. Compilation with <code>icc</code> substitutes vectorized version of memcpy, <code>gcc</code> doesn't</p>", "body_text": "I tried copying stuff using _mm256_stream_si256 here, it seems 2-3x faster than what PyTorch is doing by default\nThis article talks about why memcpy is so bad. It's part of standard library, so you are relying on stock pre-compiled version. Compilation with icc substitutes vectorized version of memcpy, gcc doesn't", "body": "I tried copying stuff using `_mm256_stream_si256` [here](https://github.com/diux-dev/cluster/blob/master/psbench/memcpy.cc), it seems 2-3x faster than what PyTorch is doing by default\r\n\r\nThis [article](http://web.archive.org/web/20131223174037/http://software.intel.com/en-us/articles/memcpy-performance/) talks about why memcpy is so bad. It's part of standard library, so you are relying on stock pre-compiled version. Compilation with `icc` substitutes vectorized version of memcpy, `gcc` doesn't\r\n"}