{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/338316887", "html_url": "https://github.com/pytorch/pytorch/issues/3202#issuecomment-338316887", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3202", "id": 338316887, "node_id": "MDEyOklzc3VlQ29tbWVudDMzODMxNjg4Nw==", "user": {"login": "Kaixhin", "id": 991891, "node_id": "MDQ6VXNlcjk5MTg5MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/991891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kaixhin", "html_url": "https://github.com/Kaixhin", "followers_url": "https://api.github.com/users/Kaixhin/followers", "following_url": "https://api.github.com/users/Kaixhin/following{/other_user}", "gists_url": "https://api.github.com/users/Kaixhin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kaixhin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kaixhin/subscriptions", "organizations_url": "https://api.github.com/users/Kaixhin/orgs", "repos_url": "https://api.github.com/users/Kaixhin/repos", "events_url": "https://api.github.com/users/Kaixhin/events{/privacy}", "received_events_url": "https://api.github.com/users/Kaixhin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-20T20:40:29Z", "updated_at": "2017-10-20T20:40:29Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Alternative proposal - we provide a method that deals with the most common use cases (tensors, variables and networks). We could have something similar to Chainer's <a href=\"http://docs.chainer.org/en/stable/tutorial/gpu.html\" rel=\"nofollow\"><code>cuda.get_array_module()</code></a>, something like <a href=\"https://github.com/soumith/fakecuda\">fakecuda</a>, something like a <a href=\"https://gist.github.com/Kaixhin/8af7261dc790e8c899b4c2b2db97186e\">wrapper</a>, etc. We're not going to be \"write once, run everywhere\", but we can probably catch most use cases.</p>\n<p><strong>Pros:</strong> It makes it <em>much</em> simpler for people writing CPU/1 GPU code (presumably a majority of users). Depending on the approach it'll probably be fine for multiple GPUs too.</p>\n<p><strong>Cons:</strong> An abstraction of this form isn't foolproof, but I can't immediately think of any major issues. Setting everything to CUDA by default is probably going to break things, but a wrapper, being more manual, can be used selectively enough.</p>", "body_text": "Alternative proposal - we provide a method that deals with the most common use cases (tensors, variables and networks). We could have something similar to Chainer's cuda.get_array_module(), something like fakecuda, something like a wrapper, etc. We're not going to be \"write once, run everywhere\", but we can probably catch most use cases.\nPros: It makes it much simpler for people writing CPU/1 GPU code (presumably a majority of users). Depending on the approach it'll probably be fine for multiple GPUs too.\nCons: An abstraction of this form isn't foolproof, but I can't immediately think of any major issues. Setting everything to CUDA by default is probably going to break things, but a wrapper, being more manual, can be used selectively enough.", "body": "Alternative proposal - we provide a method that deals with the most common use cases (tensors, variables and networks). We could have something similar to Chainer's [`cuda.get_array_module()`](http://docs.chainer.org/en/stable/tutorial/gpu.html), something like [fakecuda](https://github.com/soumith/fakecuda), something like a [wrapper](https://gist.github.com/Kaixhin/8af7261dc790e8c899b4c2b2db97186e), etc. We're not going to be \"write once, run everywhere\", but we can probably catch most use cases.\r\n\r\n**Pros:** It makes it *much* simpler for people writing CPU/1 GPU code (presumably a majority of users). Depending on the approach it'll probably be fine for multiple GPUs too.\r\n\r\n**Cons:** An abstraction of this form isn't foolproof, but I can't immediately think of any major issues. Setting everything to CUDA by default is probably going to break things, but a wrapper, being more manual, can be used selectively enough."}