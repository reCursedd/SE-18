{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/281704075", "html_url": "https://github.com/pytorch/pytorch/issues/822#issuecomment-281704075", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/822", "id": 281704075, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTcwNDA3NQ==", "user": {"login": "aosokin", "id": 2099291, "node_id": "MDQ6VXNlcjIwOTkyOTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2099291?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aosokin", "html_url": "https://github.com/aosokin", "followers_url": "https://api.github.com/users/aosokin/followers", "following_url": "https://api.github.com/users/aosokin/following{/other_user}", "gists_url": "https://api.github.com/users/aosokin/gists{/gist_id}", "starred_url": "https://api.github.com/users/aosokin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aosokin/subscriptions", "organizations_url": "https://api.github.com/users/aosokin/orgs", "repos_url": "https://api.github.com/users/aosokin/repos", "events_url": "https://api.github.com/users/aosokin/events{/privacy}", "received_events_url": "https://api.github.com/users/aosokin/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-22T15:34:23Z", "updated_at": "2017-02-22T15:36:06Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi again,<br>\nI've started from <a href=\"https://github.com/pytorch/examples/blob/master/mnist/main.py\">the default MNIST example</a> and have changed the network to have two streams.<br>\nTwo versions:</p>\n<ol>\n<li>\n<p>have two Conv2d layers and just torch.cat features coming from them - runs, but produces bad accuracy, although mathematically is identical to the default network. I suspect that the gradient computation is wrong.</p>\n</li>\n<li>\n<p>slice the features in two halves, apply two Conv2d layers, torch.cat the result - crashes after processing several batches.</p>\n</li>\n</ol>\n<p>Here is the code:</p>\n<pre><code>from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                    help='input batch size for testing (default: 1000)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='number of epochs to train (default: 10)')\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='enables CUDA training')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='random seed (default: 1)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n\n        # standard\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n\n        # CHANGE v1: no slicing, only concat in the network\n        # Produces very bad results, probably the gradient is wrong\n        self.conv2_1_v1 = nn.Conv2d(10, 10, kernel_size=5)\n        self.conv2_2_v1 = nn.Conv2d(10, 10, kernel_size=5)\n\n        # CHANGE v2: slicing + concat - crashes\n        self.conv2_1_v2 = nn.Conv2d(5, 10, kernel_size=5)\n        self.conv2_2_v2 = nn.Conv2d(5, 10, kernel_size=5)\n\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n\n        # # standard\n        x_std = self.conv2(x)\n        # x = x_std\n\n        # # CHANGE v1: should be identical to the standard version\n        # x_1 = self.conv2_1_v1(x)\n        # x_2 = self.conv2_2_v1(x)\n        # x = torch.cat((x_1, x_2), 1)\n\n        # CHANGE v2: two path\n        x_1 = x[:, :5, :, :]\n        x_2 = x[:, 5:, :, :]\n        x_1 = self.conv2_1_v2(x_1)\n        x_2 = self.conv2_2_v2(x_2)\n        x = torch.cat((x_1, x_2), 1)\n\n        print('Target size:', x_std.size())\n        print('Obtained size:', x.size())\n\n        x = F.relu(F.max_pool2d(self.conv2_drop(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = F.relu(self.fc2(x))\n        return F.log_softmax(x)\n\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.nll_loss(output, target).data[0]\n        pred = output.data.max(1)[1]  # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    test_loss = test_loss\n    test_loss /= len(test_loader)  # loss function already averages over batch size\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch)\n    test(epoch)\n</code></pre>", "body_text": "Hi again,\nI've started from the default MNIST example and have changed the network to have two streams.\nTwo versions:\n\n\nhave two Conv2d layers and just torch.cat features coming from them - runs, but produces bad accuracy, although mathematically is identical to the default network. I suspect that the gradient computation is wrong.\n\n\nslice the features in two halves, apply two Conv2d layers, torch.cat the result - crashes after processing several batches.\n\n\nHere is the code:\nfrom __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                    help='input batch size for testing (default: 1000)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='number of epochs to train (default: 10)')\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='enables CUDA training')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='random seed (default: 1)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n\n        # standard\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n\n        # CHANGE v1: no slicing, only concat in the network\n        # Produces very bad results, probably the gradient is wrong\n        self.conv2_1_v1 = nn.Conv2d(10, 10, kernel_size=5)\n        self.conv2_2_v1 = nn.Conv2d(10, 10, kernel_size=5)\n\n        # CHANGE v2: slicing + concat - crashes\n        self.conv2_1_v2 = nn.Conv2d(5, 10, kernel_size=5)\n        self.conv2_2_v2 = nn.Conv2d(5, 10, kernel_size=5)\n\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n\n        # # standard\n        x_std = self.conv2(x)\n        # x = x_std\n\n        # # CHANGE v1: should be identical to the standard version\n        # x_1 = self.conv2_1_v1(x)\n        # x_2 = self.conv2_2_v1(x)\n        # x = torch.cat((x_1, x_2), 1)\n\n        # CHANGE v2: two path\n        x_1 = x[:, :5, :, :]\n        x_2 = x[:, 5:, :, :]\n        x_1 = self.conv2_1_v2(x_1)\n        x_2 = self.conv2_2_v2(x_2)\n        x = torch.cat((x_1, x_2), 1)\n\n        print('Target size:', x_std.size())\n        print('Obtained size:', x.size())\n\n        x = F.relu(F.max_pool2d(self.conv2_drop(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = F.relu(self.fc2(x))\n        return F.log_softmax(x)\n\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.nll_loss(output, target).data[0]\n        pred = output.data.max(1)[1]  # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    test_loss = test_loss\n    test_loss /= len(test_loader)  # loss function already averages over batch size\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch)\n    test(epoch)", "body": "Hi again,\r\nI've started from [the default MNIST example](https://github.com/pytorch/examples/blob/master/mnist/main.py) and have changed the network to have two streams.\r\nTwo versions:\r\n\r\n1. have two Conv2d layers and just torch.cat features coming from them - runs, but produces bad accuracy, although mathematically is identical to the default network. I suspect that the gradient computation is wrong.\r\n\r\n2. slice the features in two halves, apply two Conv2d layers, torch.cat the result - crashes after processing several batches.\r\n\r\nHere is the code:\r\n\r\n```\r\nfrom __future__ import print_function\r\nimport argparse\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nfrom torchvision import datasets, transforms\r\nfrom torch.autograd import Variable\r\n\r\n# Training settings\r\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\r\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\r\n                    help='input batch size for training (default: 64)')\r\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\r\n                    help='input batch size for testing (default: 1000)')\r\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\r\n                    help='number of epochs to train (default: 10)')\r\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\r\n                    help='learning rate (default: 0.01)')\r\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\r\n                    help='SGD momentum (default: 0.5)')\r\nparser.add_argument('--no-cuda', action='store_true', default=False,\r\n                    help='enables CUDA training')\r\nparser.add_argument('--seed', type=int, default=1, metavar='S',\r\n                    help='random seed (default: 1)')\r\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\r\n                    help='how many batches to wait before logging training status')\r\nargs = parser.parse_args()\r\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\r\n\r\ntorch.manual_seed(args.seed)\r\nif args.cuda:\r\n    torch.cuda.manual_seed(args.seed)\r\n\r\n\r\nkwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\r\ntrain_loader = torch.utils.data.DataLoader(\r\n    datasets.MNIST('../data', train=True, download=True,\r\n                   transform=transforms.Compose([\r\n                       transforms.ToTensor(),\r\n                       transforms.Normalize((0.1307,), (0.3081,))\r\n                   ])),\r\n    batch_size=args.batch_size, shuffle=True, **kwargs)\r\ntest_loader = torch.utils.data.DataLoader(\r\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\r\n        transforms.ToTensor(),\r\n        transforms.Normalize((0.1307,), (0.3081,))\r\n    ])),\r\n    batch_size=args.batch_size, shuffle=True, **kwargs)\r\n\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n\r\n        # standard\r\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n\r\n        # CHANGE v1: no slicing, only concat in the network\r\n        # Produces very bad results, probably the gradient is wrong\r\n        self.conv2_1_v1 = nn.Conv2d(10, 10, kernel_size=5)\r\n        self.conv2_2_v1 = nn.Conv2d(10, 10, kernel_size=5)\r\n\r\n        # CHANGE v2: slicing + concat - crashes\r\n        self.conv2_1_v2 = nn.Conv2d(5, 10, kernel_size=5)\r\n        self.conv2_2_v2 = nn.Conv2d(5, 10, kernel_size=5)\r\n\r\n        self.conv2_drop = nn.Dropout2d()\r\n        self.fc1 = nn.Linear(320, 50)\r\n        self.fc2 = nn.Linear(50, 10)\r\n\r\n    def forward(self, x):\r\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n\r\n        # # standard\r\n        x_std = self.conv2(x)\r\n        # x = x_std\r\n\r\n        # # CHANGE v1: should be identical to the standard version\r\n        # x_1 = self.conv2_1_v1(x)\r\n        # x_2 = self.conv2_2_v1(x)\r\n        # x = torch.cat((x_1, x_2), 1)\r\n\r\n        # CHANGE v2: two path\r\n        x_1 = x[:, :5, :, :]\r\n        x_2 = x[:, 5:, :, :]\r\n        x_1 = self.conv2_1_v2(x_1)\r\n        x_2 = self.conv2_2_v2(x_2)\r\n        x = torch.cat((x_1, x_2), 1)\r\n\r\n        print('Target size:', x_std.size())\r\n        print('Obtained size:', x.size())\r\n\r\n        x = F.relu(F.max_pool2d(self.conv2_drop(x), 2))\r\n        x = x.view(-1, 320)\r\n        x = F.relu(self.fc1(x))\r\n        x = F.dropout(x, training=self.training)\r\n        x = F.relu(self.fc2(x))\r\n        return F.log_softmax(x)\r\n\r\n\r\nmodel = Net()\r\nif args.cuda:\r\n    model.cuda()\r\n\r\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\r\n\r\n\r\ndef train(epoch):\r\n    model.train()\r\n    for batch_idx, (data, target) in enumerate(train_loader):\r\n        if args.cuda:\r\n            data, target = data.cuda(), target.cuda()\r\n        data, target = Variable(data), Variable(target)\r\n        optimizer.zero_grad()\r\n        output = model(data)\r\n        loss = F.nll_loss(output, target)\r\n        loss.backward()\r\n        optimizer.step()\r\n        if batch_idx % args.log_interval == 0:\r\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n                epoch, batch_idx * len(data), len(train_loader.dataset),\r\n                100. * batch_idx / len(train_loader), loss.data[0]))\r\n\r\n\r\ndef test(epoch):\r\n    model.eval()\r\n    test_loss = 0\r\n    correct = 0\r\n    for data, target in test_loader:\r\n        if args.cuda:\r\n            data, target = data.cuda(), target.cuda()\r\n        data, target = Variable(data, volatile=True), Variable(target)\r\n        output = model(data)\r\n        test_loss += F.nll_loss(output, target).data[0]\r\n        pred = output.data.max(1)[1]  # get the index of the max log-probability\r\n        correct += pred.eq(target.data).cpu().sum()\r\n\r\n    test_loss = test_loss\r\n    test_loss /= len(test_loader)  # loss function already averages over batch size\r\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n        test_loss, correct, len(test_loader.dataset),\r\n        100. * correct / len(test_loader.dataset)))\r\n\r\n\r\nfor epoch in range(1, args.epochs + 1):\r\n    train(epoch)\r\n    test(epoch)\r\n```"}