{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/307576871", "html_url": "https://github.com/pytorch/pytorch/issues/1768#issuecomment-307576871", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1768", "id": 307576871, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzU3Njg3MQ==", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-10T16:50:41Z", "updated_at": "2017-06-10T16:50:41Z", "author_association": "MEMBER", "body_html": "<p>It looks like it can be implemented somewhat efficiently in one line:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> torch.nn.functional <span class=\"pl-k\">as</span> F\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">selu</span>(<span class=\"pl-smi\">x</span>):\n    alpha <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.6732632423543772848170429916717</span>\n    scale <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.0507009873554804934193349852946</span>\n    <span class=\"pl-k\">return</span> scale <span class=\"pl-k\">*</span> F.elu(x, alpha)</pre></div>\n<p>Note that pytorch <code>elu</code> has the <code>alpha</code> parameter built-in, which makes it easier to implement than in TF. For an overview of what the <code>alpha</code> parameter do, you can have a <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/lib/THNN/generic/ELU.c#L23\">look here</a>.</p>", "body_text": "It looks like it can be implemented somewhat efficiently in one line:\nimport torch.nn.functional as F\ndef selu(x):\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale * F.elu(x, alpha)\nNote that pytorch elu has the alpha parameter built-in, which makes it easier to implement than in TF. For an overview of what the alpha parameter do, you can have a look here.", "body": "It looks like it can be implemented somewhat efficiently in one line:\r\n```python\r\nimport torch.nn.functional as F\r\ndef selu(x):\r\n    alpha = 1.6732632423543772848170429916717\r\n    scale = 1.0507009873554804934193349852946\r\n    return scale * F.elu(x, alpha)\r\n```\r\nNote that pytorch `elu` has the `alpha` parameter built-in, which makes it easier to implement than in TF. For an overview of what the `alpha` parameter do, you can have a [look here](https://github.com/pytorch/pytorch/blob/master/torch/lib/THNN/generic/ELU.c#L23)."}