{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9539", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9539/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9539/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9539/events", "html_url": "https://github.com/pytorch/pytorch/pull/9539", "id": 342390863, "node_id": "MDExOlB1bGxSZXF1ZXN0MjAyMzAxNDcz", "number": 9539, "title": "Dataloader shutdown hangs", "user": {"login": "csarofeen", "id": 22205833, "node_id": "MDQ6VXNlcjIyMjA1ODMz", "avatar_url": "https://avatars2.githubusercontent.com/u/22205833?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csarofeen", "html_url": "https://github.com/csarofeen", "followers_url": "https://api.github.com/users/csarofeen/followers", "following_url": "https://api.github.com/users/csarofeen/following{/other_user}", "gists_url": "https://api.github.com/users/csarofeen/gists{/gist_id}", "starred_url": "https://api.github.com/users/csarofeen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csarofeen/subscriptions", "organizations_url": "https://api.github.com/users/csarofeen/orgs", "repos_url": "https://api.github.com/users/csarofeen/repos", "events_url": "https://api.github.com/users/csarofeen/events{/privacy}", "received_events_url": "https://api.github.com/users/csarofeen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2018-07-18T15:55:13Z", "updated_at": "2018-11-23T15:47:48Z", "closed_at": "2018-07-23T13:30:49Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/9539", "html_url": "https://github.com/pytorch/pytorch/pull/9539", "diff_url": "https://github.com/pytorch/pytorch/pull/9539.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/9539.patch"}, "body_html": "<p>So for dataloader, there's a main thread, manager thread, and worker threads. (Horrible names fyi)<br>\nMain thread does 2 things: Puts indices in a queue that gets sent to workers to process<br>\nWorker thread: reads the data and send it through the collate function and puts it to a results queue<br>\nManager thread: Reads from the result queue, puts it on pinned memory if necessary, puts it on an output queue</p>\n<p>Currently to shutdown dataloader processes the Main thread puts a None in the index queues, tries to empty the results queue, and then puts a None on the results queue. The manager thread / worker processes are supposed to read the None's in the queue and quit.</p>\n<p>2 issues can cause a hang...</p>\n<ol>\n<li>\n<p><a href=\"https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L377-L378\">https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L377-L378</a><br>\nCalling is_empty and then a get is not guaranteed to get an actual entry. Since manager thread is trying to get on this queue it could empty it in between is_empty and get and then main thread is hung on shutdown.</p>\n</li>\n<li>\n<p>Worker threads are still running as everything goes on until they hit a None, but they may have work to do. Main thread/manager thread can quit while workers are finishing up. Main thread/manager may free queue resources and then workers will put. Since the pipes can be broken this can result in a hang on the worker threads.</p>\n</li>\n</ol>\n<p>I have added an extended multiprocessing queue that has a shutdown signal with guards around get/put. This will prevent attempting to communicate across the queue in any way once shutdown is triggered. It will also make sure that shutdown does not happen during a get/put. I haven't seen any more processes hang on cleanup with these modifications.</p>", "body_text": "So for dataloader, there's a main thread, manager thread, and worker threads. (Horrible names fyi)\nMain thread does 2 things: Puts indices in a queue that gets sent to workers to process\nWorker thread: reads the data and send it through the collate function and puts it to a results queue\nManager thread: Reads from the result queue, puts it on pinned memory if necessary, puts it on an output queue\nCurrently to shutdown dataloader processes the Main thread puts a None in the index queues, tries to empty the results queue, and then puts a None on the results queue. The manager thread / worker processes are supposed to read the None's in the queue and quit.\n2 issues can cause a hang...\n\n\nhttps://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L377-L378\nCalling is_empty and then a get is not guaranteed to get an actual entry. Since manager thread is trying to get on this queue it could empty it in between is_empty and get and then main thread is hung on shutdown.\n\n\nWorker threads are still running as everything goes on until they hit a None, but they may have work to do. Main thread/manager thread can quit while workers are finishing up. Main thread/manager may free queue resources and then workers will put. Since the pipes can be broken this can result in a hang on the worker threads.\n\n\nI have added an extended multiprocessing queue that has a shutdown signal with guards around get/put. This will prevent attempting to communicate across the queue in any way once shutdown is triggered. It will also make sure that shutdown does not happen during a get/put. I haven't seen any more processes hang on cleanup with these modifications.", "body": "So for dataloader, there's a main thread, manager thread, and worker threads. (Horrible names fyi)\r\nMain thread does 2 things: Puts indices in a queue that gets sent to workers to process\r\nWorker thread: reads the data and send it through the collate function and puts it to a results queue\r\nManager thread: Reads from the result queue, puts it on pinned memory if necessary, puts it on an output queue\r\n\r\nCurrently to shutdown dataloader processes the Main thread puts a None in the index queues, tries to empty the results queue, and then puts a None on the results queue. The manager thread / worker processes are supposed to read the None's in the queue and quit.\r\n\r\n2 issues can cause a hang... \r\n1) https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L377-L378\r\nCalling is_empty and then a get is not guaranteed to get an actual entry. Since manager thread is trying to get on this queue it could empty it in between is_empty and get and then main thread is hung on shutdown.\r\n\r\n2) Worker threads are still running as everything goes on until they hit a None, but they may have work to do. Main thread/manager thread can quit while workers are finishing up. Main thread/manager may free queue resources and then workers will put. Since the pipes can be broken this can result in a hang on the worker threads.\r\n\r\nI have added an extended multiprocessing queue that has a shutdown signal with guards around get/put. This will prevent attempting to communicate across the queue in any way once shutdown is triggered. It will also make sure that shutdown does not happen during a get/put. I haven't seen any more processes hang on cleanup with these modifications."}