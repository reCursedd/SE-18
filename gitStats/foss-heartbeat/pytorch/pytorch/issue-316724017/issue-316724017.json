{"url": "https://api.github.com/repos/pytorch/pytorch/issues/6857", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/6857/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/6857/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/6857/events", "html_url": "https://github.com/pytorch/pytorch/issues/6857", "id": 316724017, "node_id": "MDU6SXNzdWUzMTY3MjQwMTc=", "number": 6857, "title": "[caffe2] Understanding WorkFlow for Training and Testing", "user": {"login": "lironmo", "id": 37513762, "node_id": "MDQ6VXNlcjM3NTEzNzYy", "avatar_url": "https://avatars0.githubusercontent.com/u/37513762?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lironmo", "html_url": "https://github.com/lironmo", "followers_url": "https://api.github.com/users/lironmo/followers", "following_url": "https://api.github.com/users/lironmo/following{/other_user}", "gists_url": "https://api.github.com/users/lironmo/gists{/gist_id}", "starred_url": "https://api.github.com/users/lironmo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lironmo/subscriptions", "organizations_url": "https://api.github.com/users/lironmo/orgs", "repos_url": "https://api.github.com/users/lironmo/repos", "events_url": "https://api.github.com/users/lironmo/events{/privacy}", "received_events_url": "https://api.github.com/users/lironmo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-04-23T09:07:14Z", "updated_at": "2018-04-24T08:29:50Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>hello,<br>\nI am trying to compare all c++ framework(caffe2, tiny-dnn, etc.) with NNPACK.<br>\nthe comparison that i do: Speed (exclude image loading), Memory size, and Code size.</p>\n<p>I am new in caffe/caffe2 and worked with pytorch.</p>\n<p>I looking a good way to learn caffe2(i already read the tutorial), the current is not sufficient.</p>\n<p>some open issues from my side:</p>\n<ol>\n<li>\n<p>Can i stream images and labels and change the input at runtime?(do back-propagation on the mini-batch)</p>\n</li>\n<li>\n<p>Why i need to use db input and why it's need to duplicated the data? can i avoid it?</p>\n</li>\n<li>\n<p>How the back-propagation work? where the forward/backward implementation? when the gradients are summit?</p>\n</li>\n<li>\n<p>How can i insert labels for loss function on the minibatch input(i tried with tensorCPU input det as \"data\" and vectors of int's to \"label\" i get exception so it's probably not the best way)</p>\n</li>\n<li>\n<p>Why there isn't interface like in other framework that simply run train on image:<br>\nfor example in tiny- dnn i simply runed<br>\nnn-&gt;train&lt;tiny_dnn::cross_entropy&gt;(optimizer, minibatch, labels,minibatch.size(), 1);<br>\nwhere<br>\nstd::vector&lt;tiny_dnn::vec_t&gt; minibatch;<br>\nstd::vector&lt;tiny_dnn::label_t&gt; labels;</p>\n</li>\n<li>\n<p>I tried to switch engine to NNPACK - does it work(implement) only on arm or at intel process as well(i avoiding MKL), i get some warning that some operators are not supported - what is the fallback can i defined it?</p>\n</li>\n</ol>\n<p>some warning that i am not sure what im doing wrong about the input size.</p>\n<p>I would be very happy to help!<br>\nAll done in c++.</p>\n<p>Thanks,<br>\nLiron</p>", "body_text": "hello,\nI am trying to compare all c++ framework(caffe2, tiny-dnn, etc.) with NNPACK.\nthe comparison that i do: Speed (exclude image loading), Memory size, and Code size.\nI am new in caffe/caffe2 and worked with pytorch.\nI looking a good way to learn caffe2(i already read the tutorial), the current is not sufficient.\nsome open issues from my side:\n\n\nCan i stream images and labels and change the input at runtime?(do back-propagation on the mini-batch)\n\n\nWhy i need to use db input and why it's need to duplicated the data? can i avoid it?\n\n\nHow the back-propagation work? where the forward/backward implementation? when the gradients are summit?\n\n\nHow can i insert labels for loss function on the minibatch input(i tried with tensorCPU input det as \"data\" and vectors of int's to \"label\" i get exception so it's probably not the best way)\n\n\nWhy there isn't interface like in other framework that simply run train on image:\nfor example in tiny- dnn i simply runed\nnn->train<tiny_dnn::cross_entropy>(optimizer, minibatch, labels,minibatch.size(), 1);\nwhere\nstd::vector<tiny_dnn::vec_t> minibatch;\nstd::vector<tiny_dnn::label_t> labels;\n\n\nI tried to switch engine to NNPACK - does it work(implement) only on arm or at intel process as well(i avoiding MKL), i get some warning that some operators are not supported - what is the fallback can i defined it?\n\n\nsome warning that i am not sure what im doing wrong about the input size.\nI would be very happy to help!\nAll done in c++.\nThanks,\nLiron", "body": "hello, \r\nI am trying to compare all c++ framework(caffe2, tiny-dnn, etc.) with NNPACK.\r\nthe comparison that i do: Speed (exclude image loading), Memory size, and Code size.\r\n\r\nI am new in caffe/caffe2 and worked with pytorch.\r\n\r\nI looking a good way to learn caffe2(i already read the tutorial), the current is not sufficient.\r\n\r\nsome open issues from my side:\r\n1. Can i stream images and labels and change the input at runtime?(do back-propagation on the mini-batch)\r\n2. Why i need to use db input and why it's need to duplicated the data? can i avoid it?\r\n3. How the back-propagation work? where the forward/backward implementation? when the gradients are summit? \r\n4. How can i insert labels for loss function on the minibatch input(i tried with tensorCPU input det as \"data\" and vectors of int's to \"label\" i get exception so it's probably not the best way)\r\n\r\n5. Why there isn't interface like in other framework that simply run train on image:\r\nfor example in tiny- dnn i simply runed \r\n                        nn->train<tiny_dnn::cross_entropy>(optimizer, minibatch, labels,minibatch.size(), 1); \r\nwhere \r\n\t\t\tstd::vector<tiny_dnn::vec_t> minibatch;\r\n\t\t\tstd::vector<tiny_dnn::label_t> labels;\r\n\r\n6. I tried to switch engine to NNPACK - does it work(implement) only on arm or at intel process as well(i avoiding MKL), i get some warning that some operators are not supported - what is the fallback can i defined it?\r\n\r\nsome warning that i am not sure what im doing wrong about the input size.\r\n\r\n\r\nI would be very happy to help!\r\nAll done in c++.\r\n\r\nThanks,\r\nLiron "}