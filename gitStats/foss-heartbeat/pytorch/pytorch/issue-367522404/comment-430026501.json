{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/430026501", "html_url": "https://github.com/pytorch/pytorch/pull/12430#issuecomment-430026501", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/12430", "id": 430026501, "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDAyNjUwMQ==", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-10-15T21:48:31Z", "updated_at": "2018-10-15T21:48:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4583066\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/apaszke\">@apaszke</a> The current dispatch for SparseTensor relies on files like <code>pytorch/aten/src/ATen/native/LegacyBridge.cpp</code> that dispatches to different backends depends on type of input tensor. Without introducing a new type for SparseTensor, we can still keep the API surface the same by relying on the current dispatch along with the <code>masked positions</code> rule (masked positions are not involved in computations in either forward or backward). This way we can support autograd for sparse with the same API names. On the other hand, a new type is welcomed if it makes more sense than the existing dispatching mechanism.</p>", "body_text": "@apaszke The current dispatch for SparseTensor relies on files like pytorch/aten/src/ATen/native/LegacyBridge.cpp that dispatches to different backends depends on type of input tensor. Without introducing a new type for SparseTensor, we can still keep the API surface the same by relying on the current dispatch along with the masked positions rule (masked positions are not involved in computations in either forward or backward). This way we can support autograd for sparse with the same API names. On the other hand, a new type is welcomed if it makes more sense than the existing dispatching mechanism.", "body": "@apaszke The current dispatch for SparseTensor relies on files like `pytorch/aten/src/ATen/native/LegacyBridge.cpp` that dispatches to different backends depends on type of input tensor. Without introducing a new type for SparseTensor, we can still keep the API surface the same by relying on the current dispatch along with the `masked positions` rule (masked positions are not involved in computations in either forward or backward). This way we can support autograd for sparse with the same API names. On the other hand, a new type is welcomed if it makes more sense than the existing dispatching mechanism."}