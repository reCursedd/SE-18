{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162804205", "pull_request_review_id": 90324426, "id": 162804205, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2MjgwNDIwNQ==", "diff_hunk": "@@ -1848,23 +2352,66 @@ void THTensor_(sum)(THTensor *r_, THTensor *t, int dimension, int keepdim)\n   THTensor_(resize)(r_, dim, NULL);\n   THLongStorage_free(dim);\n \n-  // two implementations optimized for data locality\n-  if (t->stride[dimension] == 1) {\n-    TH_TENSOR_DIM_APPLY2(real, t, real, r_, dimension,\n-                         accreal sum = 0;\n-                         int64_t i;\n-                         for(i = 0; i < t_size; i++)\n-                           sum += t_data[i*t_stride];\n-                         *r__data = (real)sum;);\n+  int serial_path = 0;\n+#ifdef _OPENMP\n+  int inOMP = omp_in_parallel();\n+  if (inOMP) {\n+    serial_path = 1;\n   } else {\n-    THTensor_(zero)(r_);\n-    THTensor *temp_ = THTensor_(newWithTensor)(r_);\n-    // r_.expand_as(t)\n-    temp_->size[dimension] = t->size[dimension];\n-    temp_->stride[dimension] = 0;\n-\n-    TH_TENSOR_APPLY2(real, temp_, real, t, *temp__data = *temp__data + *t_data;);\n-    THTensor_(free)(temp_);\n+    int r_Contig = THTensor_(isContiguous)(r_);\n+    real *tp = THTensor_(data)(t);\n+    real *rp = THTensor_(data)(r_);\n+    if(r_Contig && (tp != rp)){\n+      ptrdiff_t iter = 0;\n+      ptrdiff_t r_Size = THTensor_(nElement)(r_);\n+      int r_Dim = r_->nDimension;\n+      #pragma omp parallel for if ( r_Size > TH_OMP_OVERHEAD_THRESHOLD)\n+      for (iter = 0; iter < r_Size; iter++) {\n+        int j;\n+        int64_t quot;\n+        int64_t rem = iter;\n+        ptrdiff_t tBasicIndex = 0;\n+\n+        for(j = 0; j < r_Dim; ++j) {\n+          if(j != dimension){\n+            quot = rem/r_->stride[j];\n+            rem = rem%r_->stride[j];\n+            tBasicIndex += quot*t->stride[j];\n+          }\n+        }\n+        real *t_data = tp+tBasicIndex;\n+        real *r__data = rp+iter;\n+        *r__data = 0;\n+        for(j=0; j < t->size[dimension]; ++j) {\n+          *r__data += *(t_data + j*t->stride[dimension]);", "path": "aten/src/TH/generic/THTensorMath.c", "position": 1298, "original_position": 1298, "commit_id": "1ccad046aab11cd78eab647a18fa3713bb9cfd6f", "original_commit_id": "b805a9d9cd18ec84f5476d1a549a61b7da80535f", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "body": "The operands used by 4 accumulators are not contiguous, it will not be vectorized unless  packed in an adjacent spaces firstly. So the performance will not be improved.", "created_at": "2018-01-21T08:14:31Z", "updated_at": "2018-11-23T15:38:22Z", "html_url": "https://github.com/pytorch/pytorch/pull/2764#discussion_r162804205", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2764", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/162804205"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2764#discussion_r162804205"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2764"}}, "body_html": "<p>The operands used by 4 accumulators are not contiguous, it will not be vectorized unless  packed in an adjacent spaces firstly. So the performance will not be improved.</p>", "body_text": "The operands used by 4 accumulators are not contiguous, it will not be vectorized unless  packed in an adjacent spaces firstly. So the performance will not be improved.", "in_reply_to_id": 162596194}