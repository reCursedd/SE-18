{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/330471090", "html_url": "https://github.com/pytorch/pytorch/pull/2764#issuecomment-330471090", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/2764", "id": 330471090, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDQ3MTA5MA==", "user": {"login": "MlWoo", "id": 20226293, "node_id": "MDQ6VXNlcjIwMjI2Mjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/20226293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MlWoo", "html_url": "https://github.com/MlWoo", "followers_url": "https://api.github.com/users/MlWoo/followers", "following_url": "https://api.github.com/users/MlWoo/following{/other_user}", "gists_url": "https://api.github.com/users/MlWoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/MlWoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MlWoo/subscriptions", "organizations_url": "https://api.github.com/users/MlWoo/orgs", "repos_url": "https://api.github.com/users/MlWoo/repos", "events_url": "https://api.github.com/users/MlWoo/events{/privacy}", "received_events_url": "https://api.github.com/users/MlWoo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-19T08:41:55Z", "updated_at": "2017-09-19T08:41:55Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9110200\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fmassa\">@fmassa</a>  You must have known that some confusing behavior occurs to expanding tensors, as you point in Torch <a href=\"https://github.com/torch/torch7/issues/1067\" data-hovercard-type=\"issue\" data-hovercard-url=\"/torch/torch7/issues/1067/hovercard\">Buggy cmul behavior on Tensors with 0-strides</a>.  The method to parallelize the operation use the number of tensor's element to calculate the offset in memory in the macros. But the real memory size of expanding tensor is less than that what users refer it.  So that it will cause outing of bound of memory.</p>", "body_text": "@fmassa  You must have known that some confusing behavior occurs to expanding tensors, as you point in Torch Buggy cmul behavior on Tensors with 0-strides.  The method to parallelize the operation use the number of tensor's element to calculate the offset in memory in the macros. But the real memory size of expanding tensor is less than that what users refer it.  So that it will cause outing of bound of memory.", "body": "@fmassa  You must have known that some confusing behavior occurs to expanding tensors, as you point in Torch [Buggy cmul behavior on Tensors with 0-strides](https://github.com/torch/torch7/issues/1067).  The method to parallelize the operation use the number of tensor's element to calculate the offset in memory in the macros. But the real memory size of expanding tensor is less than that what users refer it.  So that it will cause outing of bound of memory. "}