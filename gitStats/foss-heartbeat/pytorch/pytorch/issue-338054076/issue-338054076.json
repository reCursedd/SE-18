{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9147", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9147/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9147/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9147/events", "html_url": "https://github.com/pytorch/pytorch/issues/9147", "id": 338054076, "node_id": "MDU6SXNzdWUzMzgwNTQwNzY=", "number": 9147, "title": "bug in running flip() on cpu", "user": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-03T21:04:17Z", "updated_at": "2018-07-04T14:25:19Z", "closed_at": "2018-07-04T14:25:19Z", "author_association": "CONTRIBUTOR", "body_html": "<pre><code>a = torch.tensor([1., 1., 1., 1., 0., 2.]).view(2, 3)\nprint(a)\nprint(a.flip(1))\n------------------------\ntensor([[1., 1., 1.],\n        [1., 0., 2.]])\n\ntensor([[1., 1.],\n        [0., 1.]])\n</code></pre>\n<p>It works fine in CUDA implementation:</p>\n<pre><code>a = torch.tensor([1., 1., 1., 1., 0., 2.], device=torch.device('cuda')).view(2, 3)\nprint(a)\nprint(a.flip(1))\n------------------------\ntensor([[1., 1., 1.],\n        [1., 0., 2.]], device='cuda:0')\n\ntensor([[1., 1., 1.],\n        [2., 0., 1.]], device='cuda:0')\n</code></pre>", "body_text": "a = torch.tensor([1., 1., 1., 1., 0., 2.]).view(2, 3)\nprint(a)\nprint(a.flip(1))\n------------------------\ntensor([[1., 1., 1.],\n        [1., 0., 2.]])\n\ntensor([[1., 1.],\n        [0., 1.]])\n\nIt works fine in CUDA implementation:\na = torch.tensor([1., 1., 1., 1., 0., 2.], device=torch.device('cuda')).view(2, 3)\nprint(a)\nprint(a.flip(1))\n------------------------\ntensor([[1., 1., 1.],\n        [1., 0., 2.]], device='cuda:0')\n\ntensor([[1., 1., 1.],\n        [2., 0., 1.]], device='cuda:0')", "body": "```\r\na = torch.tensor([1., 1., 1., 1., 0., 2.]).view(2, 3)\r\nprint(a)\r\nprint(a.flip(1))\r\n------------------------\r\ntensor([[1., 1., 1.],\r\n        [1., 0., 2.]])\r\n\r\ntensor([[1., 1.],\r\n        [0., 1.]])\r\n```\r\nIt works fine in CUDA implementation:\r\n```\r\na = torch.tensor([1., 1., 1., 1., 0., 2.], device=torch.device('cuda')).view(2, 3)\r\nprint(a)\r\nprint(a.flip(1))\r\n------------------------\r\ntensor([[1., 1., 1.],\r\n        [1., 0., 2.]], device='cuda:0')\r\n\r\ntensor([[1., 1., 1.],\r\n        [2., 0., 1.]], device='cuda:0')\r\n```"}