{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386677660", "html_url": "https://github.com/pytorch/pytorch/issues/7288#issuecomment-386677660", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7288", "id": 386677660, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjY3NzY2MA==", "user": {"login": "mruberry", "id": 38511765, "node_id": "MDQ6VXNlcjM4NTExNzY1", "avatar_url": "https://avatars3.githubusercontent.com/u/38511765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mruberry", "html_url": "https://github.com/mruberry", "followers_url": "https://api.github.com/users/mruberry/followers", "following_url": "https://api.github.com/users/mruberry/following{/other_user}", "gists_url": "https://api.github.com/users/mruberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mruberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mruberry/subscriptions", "organizations_url": "https://api.github.com/users/mruberry/orgs", "repos_url": "https://api.github.com/users/mruberry/repos", "events_url": "https://api.github.com/users/mruberry/events{/privacy}", "received_events_url": "https://api.github.com/users/mruberry/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-04T17:51:18Z", "updated_at": "2018-05-04T17:51:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I was about to file the same issue.</p>\n<p>Some random draws will cause these optim tests to fail, and because they use std::rand() whether they pass or fail is dependent not only on the seed given but also how many prior calls to std::rand() are made. Further, std::rand() does not appear to be the only source of pseudorandomness in these tests, as setting different random seeds at the start of them will still result in intermittent failures/success. (Perhaps the network initializations are pseudorandom, too?)</p>\n<p>While controlling the pseudorandomness is one option, the fact that these tests are so fragile calls them into question. Maybe there are better tests for these optimizers?</p>", "body_text": "I was about to file the same issue.\nSome random draws will cause these optim tests to fail, and because they use std::rand() whether they pass or fail is dependent not only on the seed given but also how many prior calls to std::rand() are made. Further, std::rand() does not appear to be the only source of pseudorandomness in these tests, as setting different random seeds at the start of them will still result in intermittent failures/success. (Perhaps the network initializations are pseudorandom, too?)\nWhile controlling the pseudorandomness is one option, the fact that these tests are so fragile calls them into question. Maybe there are better tests for these optimizers?", "body": "I was about to file the same issue.\r\n\r\nSome random draws will cause these optim tests to fail, and because they use std::rand() whether they pass or fail is dependent not only on the seed given but also how many prior calls to std::rand() are made. Further, std::rand() does not appear to be the only source of pseudorandomness in these tests, as setting different random seeds at the start of them will still result in intermittent failures/success. (Perhaps the network initializations are pseudorandom, too?)\r\n\r\nWhile controlling the pseudorandomness is one option, the fact that these tests are so fragile calls them into question. Maybe there are better tests for these optimizers? "}