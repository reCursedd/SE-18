{"url": "https://api.github.com/repos/pytorch/pytorch/issues/8932", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/8932/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/8932/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/8932/events", "html_url": "https://github.com/pytorch/pytorch/issues/8932", "id": 336100567, "node_id": "MDU6SXNzdWUzMzYxMDA1Njc=", "number": 8932, "title": "gather problem when batch size equal to specific value in inference time with multiple gpu", "user": {"login": "williamstar", "id": 13472059, "node_id": "MDQ6VXNlcjEzNDcyMDU5", "avatar_url": "https://avatars2.githubusercontent.com/u/13472059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamstar", "html_url": "https://github.com/williamstar", "followers_url": "https://api.github.com/users/williamstar/followers", "following_url": "https://api.github.com/users/williamstar/following{/other_user}", "gists_url": "https://api.github.com/users/williamstar/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamstar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamstar/subscriptions", "organizations_url": "https://api.github.com/users/williamstar/orgs", "repos_url": "https://api.github.com/users/williamstar/repos", "events_url": "https://api.github.com/users/williamstar/events{/privacy}", "received_events_url": "https://api.github.com/users/williamstar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-06-27T07:00:45Z", "updated_at": "2018-10-13T07:50:02Z", "closed_at": "2018-06-29T06:19:12Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Always raise exception when meet specific batch size number in inference phase, such as [9, 11, 13, 15, 19, 22], but single device  operating normally.<br>\nWhen downgrade to torch 4.0 stable version still meet this question.</p>\n<h2>Code example</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> traceback\n\n<span class=\"pl-k\">import</span> torch\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Net</span>(<span class=\"pl-e\">torch</span>.<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">super</span>(Net, <span class=\"pl-c1\">self</span>).<span class=\"pl-c1\">__init__</span>()\n        <span class=\"pl-c1\">self</span>.conv1 <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">10</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n        <span class=\"pl-c1\">self</span>.conv2 <span class=\"pl-k\">=</span> torch.nn.Conv2d(<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">20</span>, <span class=\"pl-v\">kernel_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">stride</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\n        <span class=\"pl-c1\">self</span>.fc <span class=\"pl-k\">=</span> torch.nn.Linear(<span class=\"pl-c1\">20</span>, <span class=\"pl-c1\">2</span>)\n    \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">x</span>):\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv1(x)\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.conv2(x)\n        x <span class=\"pl-k\">=</span> torch.nn.functional.adaptive_avg_pool2d(x, <span class=\"pl-c1\">1</span>).squeeze()\n        x <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.fc(x)\n        <span class=\"pl-k\">return</span> x\n\n\nproblem_pair <span class=\"pl-k\">=</span> []\nexception <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">8</span>):\n    model <span class=\"pl-k\">=</span> Net()\n    <span class=\"pl-k\">if</span> i <span class=\"pl-k\">!=</span> <span class=\"pl-c1\">0</span>:\n        model <span class=\"pl-k\">=</span> torch.nn.DataParallel(model, <span class=\"pl-v\">device_ids</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">range</span>(i)).cuda()\n    <span class=\"pl-k\">else</span>:\n        model.cuda()\n    <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">60</span>):\n        <span class=\"pl-k\">try</span>:\n            data <span class=\"pl-k\">=</span> torch.rand(j, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">8</span>).cuda()\n            _ <span class=\"pl-k\">=</span> model(data)\n        <span class=\"pl-k\">except</span> <span class=\"pl-c1\">Exception</span> <span class=\"pl-k\">as</span> e:\n            exception <span class=\"pl-k\">=</span> sys.exc_info()\n            problem_pair.append([i, j])\n            \n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>problem pair <span class=\"pl-c1\">{}</span> raise error<span class=\"pl-pds\">'</span></span>.format(problem_pair))\ntraceback.print_exception(<span class=\"pl-k\">*</span>exception)</pre></div>\n<p><strong>output</strong></p>\n<div class=\"highlight highlight-source-python\"><pre>problem pair [[<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>], [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">5</span>], [<span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">7</span>], [<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>], [<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">7</span>], [<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">10</span>], [<span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">13</span>], [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">7</span>], [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">9</span>], [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">13</span>], [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">1</span>\n<span class=\"pl-c1\">7</span>], [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">21</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">7</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">9</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">11</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">13</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">16</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">21</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">26</span>], [<span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">31</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">9</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">11</span>], [<span class=\"pl-c1\">7</span>\n, <span class=\"pl-c1\">13</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">16</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">19</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">25</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">31</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">37</span>], [<span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">43</span>]] <span class=\"pl-k\">raise</span> error\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>demo.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">33</span>, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n    _ <span class=\"pl-k\">=</span> model(data)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/modules/module.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">491</span>, <span class=\"pl-k\">in</span>\n<span class=\"pl-c1\">__call__</span>\n    result <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.forward(<span class=\"pl-k\">*</span><span class=\"pl-c1\">input</span>, <span class=\"pl-k\">**</span>kwargs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py<span class=\"pl-pds\">\"</span></span>, line\n<span class=\"pl-c1\">115</span>, <span class=\"pl-k\">in</span> forward\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">self</span>.gather(outputs, <span class=\"pl-c1\">self</span>.output_device)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py<span class=\"pl-pds\">\"</span></span>, line\n<span class=\"pl-c1\">127</span>, <span class=\"pl-k\">in</span> gather\n    <span class=\"pl-k\">return</span> gather(outputs, output_device, <span class=\"pl-v\">dim</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>.dim)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py<span class=\"pl-pds\">\"</span></span>, line\n <span class=\"pl-c1\">68</span>, <span class=\"pl-k\">in</span> gather\n    <span class=\"pl-k\">return</span> gather_map(outputs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py<span class=\"pl-pds\">\"</span></span>, line\n <span class=\"pl-c1\">55</span>, <span class=\"pl-k\">in</span> gather_map\n    <span class=\"pl-k\">return</span> Gather.apply(target_device, dim, <span class=\"pl-k\">*</span>outputs)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">55</span>,\n <span class=\"pl-k\">in</span> forward\n    <span class=\"pl-k\">return</span> comm.gather(inputs, ctx.dim, ctx.target_device)\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/wangyulong/.local/lib/python3.5/site-packages/torch/cuda/comm.py<span class=\"pl-pds\">\"</span></span>, line <span class=\"pl-c1\">186</span>, <span class=\"pl-k\">in</span> gather\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>but expected {}<span class=\"pl-pds\">\"</span></span>.format(got, expected))\n<span class=\"pl-c1\">ValueError</span>: gather got an <span class=\"pl-c1\">input</span> of invalid size: got <span class=\"pl-c1\">2</span>, but expected <span class=\"pl-ii\">2x2</span></pre></div>\n<h2>System Info</h2>\n<p>PyTorch version: 0.5.0a0+6eec411<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.0.176</p>\n<p>OS: Ubuntu 16.04.4 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609<br>\nCMake version: version 3.11.0</p>\n<p>Python version: 3.5<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: 9.0.176<br>\nGPU models and configuration:<br>\nGPU 0: GeForce GTX 1080 Ti<br>\nGPU 1: GeForce GTX 1080 Ti<br>\nGPU 2: GeForce GTX 1080 Ti<br>\nGPU 3: GeForce GTX 1080 Ti<br>\nGPU 4: GeForce GTX 1080 Ti<br>\nGPU 5: GeForce GTX 1080 Ti<br>\nGPU 6: GeForce GTX 1080 Ti<br>\nGPU 7: GeForce GTX 1080 Ti</p>\n<p>Nvidia driver version: 390.30<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip3] numpy (1.14.3)<br>\n[pip3] torch (0.5.0a0+6eec411)<br>\n[pip3] torchvision (0.2.1)<br>\n[conda] Could not collect</p>", "body_text": "Issue description\nAlways raise exception when meet specific batch size number in inference phase, such as [9, 11, 13, 15, 19, 22], but single device  operating normally.\nWhen downgrade to torch 4.0 stable version still meet this question.\nCode example\nimport sys\nimport traceback\n\nimport torch\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=3, padding=1, stride=2)\n        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=1, padding=0, stride=2)\n        self.fc = torch.nn.Linear(20, 2)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1).squeeze()\n        x = self.fc(x)\n        return x\n\n\nproblem_pair = []\nexception = None\n\nfor i in range(8):\n    model = Net()\n    if i != 0:\n        model = torch.nn.DataParallel(model, device_ids=range(i)).cuda()\n    else:\n        model.cuda()\n    for j in range(1, 60):\n        try:\n            data = torch.rand(j, 3, 8, 8).cuda()\n            _ = model(data)\n        except Exception as e:\n            exception = sys.exc_info()\n            problem_pair.append([i, j])\n            \nprint('problem pair {} raise error'.format(problem_pair))\ntraceback.print_exception(*exception)\noutput\nproblem pair [[2, 3], [3, 5], [3, 7], [4, 5], [4, 7], [4, 10], [4, 13], [5, 7], [5, 9], [5, 13], [5, 1\n7], [5, 21], [6, 7], [6, 9], [6, 11], [6, 13], [6, 16], [6, 21], [6, 26], [6, 31], [7, 9], [7, 11], [7\n, 13], [7, 16], [7, 19], [7, 25], [7, 31], [7, 37], [7, 43]] raise error\nTraceback (most recent call last):\n  File \"demo.py\", line 33, in <module>\n    _ = model(data)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 491, in\n__call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line\n115, in forward\n    return self.gather(outputs, self.output_device)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line\n127, in gather\n    return gather(outputs, output_device, dim=self.dim)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line\n 68, in gather\n    return gather_map(outputs)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line\n 55, in gather_map\n    return Gather.apply(target_device, dim, *outputs)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 55,\n in forward\n    return comm.gather(inputs, ctx.dim, ctx.target_device)\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/cuda/comm.py\", line 186, in gather\n    \"but expected {}\".format(got, expected))\nValueError: gather got an input of invalid size: got 2, but expected 2x2\nSystem Info\nPyTorch version: 0.5.0a0+6eec411\nIs debug build: No\nCUDA used to build PyTorch: 9.0.176\nOS: Ubuntu 16.04.4 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\nCMake version: version 3.11.0\nPython version: 3.5\nIs CUDA available: Yes\nCUDA runtime version: 9.0.176\nGPU models and configuration:\nGPU 0: GeForce GTX 1080 Ti\nGPU 1: GeForce GTX 1080 Ti\nGPU 2: GeForce GTX 1080 Ti\nGPU 3: GeForce GTX 1080 Ti\nGPU 4: GeForce GTX 1080 Ti\nGPU 5: GeForce GTX 1080 Ti\nGPU 6: GeForce GTX 1080 Ti\nGPU 7: GeForce GTX 1080 Ti\nNvidia driver version: 390.30\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip3] numpy (1.14.3)\n[pip3] torch (0.5.0a0+6eec411)\n[pip3] torchvision (0.2.1)\n[conda] Could not collect", "body": "## Issue description\r\nAlways raise exception when meet specific batch size number in inference phase, such as [9, 11, 13, 15, 19, 22], but single device  operating normally.\r\nWhen downgrade to torch 4.0 stable version still meet this question.\r\n\r\n## Code example\r\n```python\r\nimport sys\r\nimport traceback\r\n\r\nimport torch\r\n\r\nclass Net(torch.nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=3, padding=1, stride=2)\r\n        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=1, padding=0, stride=2)\r\n        self.fc = torch.nn.Linear(20, 2)\r\n    \r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.conv2(x)\r\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1).squeeze()\r\n        x = self.fc(x)\r\n        return x\r\n\r\n\r\nproblem_pair = []\r\nexception = None\r\n\r\nfor i in range(8):\r\n    model = Net()\r\n    if i != 0:\r\n        model = torch.nn.DataParallel(model, device_ids=range(i)).cuda()\r\n    else:\r\n        model.cuda()\r\n    for j in range(1, 60):\r\n        try:\r\n            data = torch.rand(j, 3, 8, 8).cuda()\r\n            _ = model(data)\r\n        except Exception as e:\r\n            exception = sys.exc_info()\r\n            problem_pair.append([i, j])\r\n            \r\nprint('problem pair {} raise error'.format(problem_pair))\r\ntraceback.print_exception(*exception)\r\n```\r\n\r\n**output**\r\n\r\n```python3\r\nproblem pair [[2, 3], [3, 5], [3, 7], [4, 5], [4, 7], [4, 10], [4, 13], [5, 7], [5, 9], [5, 13], [5, 1\r\n7], [5, 21], [6, 7], [6, 9], [6, 11], [6, 13], [6, 16], [6, 21], [6, 26], [6, 31], [7, 9], [7, 11], [7\r\n, 13], [7, 16], [7, 19], [7, 25], [7, 31], [7, 37], [7, 43]] raise error\r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 33, in <module>\r\n    _ = model(data)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 491, in\r\n__call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line\r\n115, in forward\r\n    return self.gather(outputs, self.output_device)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\", line\r\n127, in gather\r\n    return gather(outputs, output_device, dim=self.dim)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line\r\n 68, in gather\r\n    return gather_map(outputs)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/scatter_gather.py\", line\r\n 55, in gather_map\r\n    return Gather.apply(target_device, dim, *outputs)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/nn/parallel/_functions.py\", line 55,\r\n in forward\r\n    return comm.gather(inputs, ctx.dim, ctx.target_device)\r\n  File \"/home/wangyulong/.local/lib/python3.5/site-packages/torch/cuda/comm.py\", line 186, in gather\r\n    \"but expected {}\".format(got, expected))\r\nValueError: gather got an input of invalid size: got 2, but expected 2x2\r\n```\r\n\r\n## System Info\r\nPyTorch version: 0.5.0a0+6eec411\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.0.176\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\nCMake version: version 3.11.0\r\n\r\nPython version: 3.5\r\nIs CUDA available: Yes\r\nCUDA runtime version: 9.0.176\r\nGPU models and configuration:\r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\nGPU 2: GeForce GTX 1080 Ti\r\nGPU 3: GeForce GTX 1080 Ti\r\nGPU 4: GeForce GTX 1080 Ti\r\nGPU 5: GeForce GTX 1080 Ti\r\nGPU 6: GeForce GTX 1080 Ti\r\nGPU 7: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 390.30\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy (1.14.3)\r\n[pip3] torch (0.5.0a0+6eec411)\r\n[pip3] torchvision (0.2.1)\r\n[conda] Could not collect"}