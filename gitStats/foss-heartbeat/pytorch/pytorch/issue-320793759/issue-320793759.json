{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7335", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7335/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7335/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7335/events", "html_url": "https://github.com/pytorch/pytorch/issues/7335", "id": 320793759, "node_id": "MDU6SXNzdWUzMjA3OTM3NTk=", "number": 7335, "title": "no gradients for torch.tensor(np.array(...)) on cuda", "user": {"login": "maremun", "id": 3645135, "node_id": "MDQ6VXNlcjM2NDUxMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3645135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maremun", "html_url": "https://github.com/maremun", "followers_url": "https://api.github.com/users/maremun/followers", "following_url": "https://api.github.com/users/maremun/following{/other_user}", "gists_url": "https://api.github.com/users/maremun/gists{/gist_id}", "starred_url": "https://api.github.com/users/maremun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maremun/subscriptions", "organizations_url": "https://api.github.com/users/maremun/orgs", "repos_url": "https://api.github.com/users/maremun/repos", "events_url": "https://api.github.com/users/maremun/events{/privacy}", "received_events_url": "https://api.github.com/users/maremun/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-07T12:55:08Z", "updated_at": "2018-05-07T13:55:31Z", "closed_at": "2018-05-07T13:55:31Z", "author_association": "NONE", "body_html": "<p>Hello, below is the code that yields no gradients for the tensor with <code>requires_grad=True</code>. Doesn't work with <code>dtype=torch.double</code> neither. Also, when using anything from numpy for <code>data</code> argument, e.g. <code>torch.tensor.(np.ones_like(something), ...)</code>.</p>\n<pre><code>a = torch.tensor(np.array([1.,2.,3.]), dtype=torch.float, requires_grad=True).cuda()\nprint(a.requires_grad, a.dtype)  # True torch.float32\nb = torch.ones(3, device='cuda')\nl = a@b\nprint(l.item())  # 6.0\nl.backward()\nprint(a.grad)  # None\n</code></pre>\n<p>PyTorch version 0.4.0<br>\nPython 3.6.5</p>", "body_text": "Hello, below is the code that yields no gradients for the tensor with requires_grad=True. Doesn't work with dtype=torch.double neither. Also, when using anything from numpy for data argument, e.g. torch.tensor.(np.ones_like(something), ...).\na = torch.tensor(np.array([1.,2.,3.]), dtype=torch.float, requires_grad=True).cuda()\nprint(a.requires_grad, a.dtype)  # True torch.float32\nb = torch.ones(3, device='cuda')\nl = a@b\nprint(l.item())  # 6.0\nl.backward()\nprint(a.grad)  # None\n\nPyTorch version 0.4.0\nPython 3.6.5", "body": "Hello, below is the code that yields no gradients for the tensor with `requires_grad=True`. Doesn't work with `dtype=torch.double` neither. Also, when using anything from numpy for `data` argument, e.g. `torch.tensor.(np.ones_like(something), ...)`.\r\n\r\n```\r\na = torch.tensor(np.array([1.,2.,3.]), dtype=torch.float, requires_grad=True).cuda()\r\nprint(a.requires_grad, a.dtype)  # True torch.float32\r\nb = torch.ones(3, device='cuda')\r\nl = a@b\r\nprint(l.item())  # 6.0\r\nl.backward()\r\nprint(a.grad)  # None\r\n```\r\nPyTorch version 0.4.0\r\nPython 3.6.5"}