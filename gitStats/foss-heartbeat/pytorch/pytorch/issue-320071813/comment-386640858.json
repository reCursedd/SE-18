{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/386640858", "html_url": "https://github.com/pytorch/pytorch/issues/7261#issuecomment-386640858", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7261", "id": 386640858, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjY0MDg1OA==", "user": {"login": "t-vi", "id": 20787943, "node_id": "MDQ6VXNlcjIwNzg3OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/20787943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/t-vi", "html_url": "https://github.com/t-vi", "followers_url": "https://api.github.com/users/t-vi/followers", "following_url": "https://api.github.com/users/t-vi/following{/other_user}", "gists_url": "https://api.github.com/users/t-vi/gists{/gist_id}", "starred_url": "https://api.github.com/users/t-vi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/t-vi/subscriptions", "organizations_url": "https://api.github.com/users/t-vi/orgs", "repos_url": "https://api.github.com/users/t-vi/repos", "events_url": "https://api.github.com/users/t-vi/events{/privacy}", "received_events_url": "https://api.github.com/users/t-vi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-04T15:40:32Z", "updated_at": "2018-05-04T15:40:32Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think I found a couple of issues with the code and I think I even have a fix. The main thing is that it tries to be too clever with the <code>_u</code>. I don't think you actually need gradients for <code>_u</code>.<br>\nDoes the code actually work as expected in terms of calculation?<br>\nMy (limited) understanding of the spectral norm is that you want the gradient to propagate all the way to the original parameter. The <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/spectral_norm.py#L29\">division by sigma (with .data)</a> looks wrong to me in this respect.</p>\n<p>I'll double check that I have a patch in ~4 hours or so.</p>", "body_text": "I think I found a couple of issues with the code and I think I even have a fix. The main thing is that it tries to be too clever with the _u. I don't think you actually need gradients for _u.\nDoes the code actually work as expected in terms of calculation?\nMy (limited) understanding of the spectral norm is that you want the gradient to propagate all the way to the original parameter. The division by sigma (with .data) looks wrong to me in this respect.\nI'll double check that I have a patch in ~4 hours or so.", "body": "I think I found a couple of issues with the code and I think I even have a fix. The main thing is that it tries to be too clever with the `_u`. I don't think you actually need gradients for `_u`.\r\nDoes the code actually work as expected in terms of calculation?\r\nMy (limited) understanding of the spectral norm is that you want the gradient to propagate all the way to the original parameter. The [division by sigma (with .data)](https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/spectral_norm.py#L29) looks wrong to me in this respect.\r\n\r\nI'll double check that I have a patch in ~4 hours or so.\r\n"}