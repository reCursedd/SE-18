{"url": "https://api.github.com/repos/pytorch/pytorch/issues/10858", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/10858/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/10858/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/10858/events", "html_url": "https://github.com/pytorch/pytorch/issues/10858", "id": 353865833, "node_id": "MDU6SXNzdWUzNTM4NjU4MzM=", "number": 10858, "title": "unexpected behaviour when mixing no_grad decorator with no_grad context manager", "user": {"login": "DanielDworakowski", "id": 25143675, "node_id": "MDQ6VXNlcjI1MTQzNjc1", "avatar_url": "https://avatars2.githubusercontent.com/u/25143675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DanielDworakowski", "html_url": "https://github.com/DanielDworakowski", "followers_url": "https://api.github.com/users/DanielDworakowski/followers", "following_url": "https://api.github.com/users/DanielDworakowski/following{/other_user}", "gists_url": "https://api.github.com/users/DanielDworakowski/gists{/gist_id}", "starred_url": "https://api.github.com/users/DanielDworakowski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DanielDworakowski/subscriptions", "organizations_url": "https://api.github.com/users/DanielDworakowski/orgs", "repos_url": "https://api.github.com/users/DanielDworakowski/repos", "events_url": "https://api.github.com/users/DanielDworakowski/events{/privacy}", "received_events_url": "https://api.github.com/users/DanielDworakowski/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1002715609, "node_id": "MDU6TGFiZWwxMDAyNzE1NjA5", "url": "https://api.github.com/repos/pytorch/pytorch/labels/blocker", "name": "blocker", "color": "b60205", "default": false}, {"id": 443484050, "node_id": "MDU6TGFiZWw0NDM0ODQwNTA=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/medium%20priority", "name": "medium priority", "color": "fbca04", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "weiyangfb", "id": 38509346, "node_id": "MDQ6VXNlcjM4NTA5MzQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/38509346?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiyangfb", "html_url": "https://github.com/weiyangfb", "followers_url": "https://api.github.com/users/weiyangfb/followers", "following_url": "https://api.github.com/users/weiyangfb/following{/other_user}", "gists_url": "https://api.github.com/users/weiyangfb/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiyangfb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiyangfb/subscriptions", "organizations_url": "https://api.github.com/users/weiyangfb/orgs", "repos_url": "https://api.github.com/users/weiyangfb/repos", "events_url": "https://api.github.com/users/weiyangfb/events{/privacy}", "received_events_url": "https://api.github.com/users/weiyangfb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-08-24T17:26:17Z", "updated_at": "2018-09-12T00:58:01Z", "closed_at": "2018-09-12T00:58:01Z", "author_association": "NONE", "body_html": "<h2>Issue description</h2>\n<p>Mixing torch.no_grad decorator with torch.no_grad context re-enables gradients as per torch.is_grad_enabled.</p>\n<h2>Code example</h2>\n<pre><code>import torch\n\n@torch.no_grad()\ndef nothing(x):\n    return x\n\ntestin = torch.Tensor([0])\nwith torch.no_grad():\n    print(torch.is_grad_enabled())\n    testout = nothing(testin)\n    print(torch.is_grad_enabled())\n</code></pre>\n<h4>Output:</h4>\n<blockquote>\n<p>False<br>\nTrue</p>\n</blockquote>\n<h3>Expectation</h3>\n<p>It would be my expectation that within the no_grad context the gradients would always be disabled.<br>\nThis expectation matches the output when using nested contexts as below.</p>\n<pre><code>import torch\n\ndef nothing_no_nograd(x):\n  return x\n\ntestin = torch.Tensor([0])\nwith torch.no_grad():\n    print(torch.is_grad_enabled())\n    with torch.no_grad():\n        testout = nothing_no_nograd(testin)\n    print(torch.is_grad_enabled())\n</code></pre>\n<h4>Output:</h4>\n<blockquote>\n<p>False<br>\nFalse</p>\n</blockquote>\n<h2>System Info</h2>\n<p>PyTorch version: 0.4.1<br>\nIs debug build: No<br>\nCUDA used to build PyTorch: 9.2.148</p>\n<p>OS: Ubuntu 16.04.5 LTS<br>\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCMake version: version 3.5.1</p>\n<p>Python version: 3.6<br>\nIs CUDA available: Yes<br>\nCUDA runtime version: Could not collect<br>\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti<br>\nNvidia driver version: 396.54<br>\ncuDNN version: Could not collect</p>\n<p>Versions of relevant libraries:<br>\n[pip] Could not collect<br>\n[conda] cuda92                    1.0                           0    pytorch<br>\n[conda] pytorch                   0.4.1           py36_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch<br>\n[conda] torchvision               0.2.1                    py36_1    pytorch<br>\n[conda] warpctc-pytorch           0.1                       </p>", "body_text": "Issue description\nMixing torch.no_grad decorator with torch.no_grad context re-enables gradients as per torch.is_grad_enabled.\nCode example\nimport torch\n\n@torch.no_grad()\ndef nothing(x):\n    return x\n\ntestin = torch.Tensor([0])\nwith torch.no_grad():\n    print(torch.is_grad_enabled())\n    testout = nothing(testin)\n    print(torch.is_grad_enabled())\n\nOutput:\n\nFalse\nTrue\n\nExpectation\nIt would be my expectation that within the no_grad context the gradients would always be disabled.\nThis expectation matches the output when using nested contexts as below.\nimport torch\n\ndef nothing_no_nograd(x):\n  return x\n\ntestin = torch.Tensor([0])\nwith torch.no_grad():\n    print(torch.is_grad_enabled())\n    with torch.no_grad():\n        testout = nothing_no_nograd(testin)\n    print(torch.is_grad_enabled())\n\nOutput:\n\nFalse\nFalse\n\nSystem Info\nPyTorch version: 0.4.1\nIs debug build: No\nCUDA used to build PyTorch: 9.2.148\nOS: Ubuntu 16.04.5 LTS\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCMake version: version 3.5.1\nPython version: 3.6\nIs CUDA available: Yes\nCUDA runtime version: Could not collect\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti\nNvidia driver version: 396.54\ncuDNN version: Could not collect\nVersions of relevant libraries:\n[pip] Could not collect\n[conda] cuda92                    1.0                           0    pytorch\n[conda] pytorch                   0.4.1           py36_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\n[conda] torchvision               0.2.1                    py36_1    pytorch\n[conda] warpctc-pytorch           0.1", "body": "## Issue description\r\n\r\nMixing torch.no_grad decorator with torch.no_grad context re-enables gradients as per torch.is_grad_enabled.\r\n\r\n## Code example\r\n\r\n```\r\nimport torch\r\n\r\n@torch.no_grad()\r\ndef nothing(x):\r\n    return x\r\n\r\ntestin = torch.Tensor([0])\r\nwith torch.no_grad():\r\n    print(torch.is_grad_enabled())\r\n    testout = nothing(testin)\r\n    print(torch.is_grad_enabled())\r\n```\r\n#### Output:\r\n> False\r\n> True\r\n\r\n### Expectation\r\n\r\nIt would be my expectation that within the no_grad context the gradients would always be disabled.\r\nThis expectation matches the output when using nested contexts as below.\r\n\r\n```\r\nimport torch\r\n\r\ndef nothing_no_nograd(x):\r\n  return x\r\n\r\ntestin = torch.Tensor([0])\r\nwith torch.no_grad():\r\n    print(torch.is_grad_enabled())\r\n    with torch.no_grad():\r\n        testout = nothing_no_nograd(testin)\r\n    print(torch.is_grad_enabled())\r\n```\r\n#### Output:\r\n> False\r\n> False\r\n\r\n## System Info\r\n\r\nPyTorch version: 0.4.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 9.2.148\r\n\r\nOS: Ubuntu 16.04.5 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1080 Ti\r\nNvidia driver version: 396.54\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] Could not collect\r\n[conda] cuda92                    1.0                           0    pytorch\r\n[conda] pytorch                   0.4.1           py36_cuda9.2.148_cudnn7.1.4_1  [cuda92]  pytorch\r\n[conda] torchvision               0.2.1                    py36_1    pytorch\r\n[conda] warpctc-pytorch           0.1                       <pip>"}