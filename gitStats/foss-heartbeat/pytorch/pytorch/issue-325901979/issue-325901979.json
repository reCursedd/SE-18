{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7801", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7801/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7801/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7801/events", "html_url": "https://github.com/pytorch/pytorch/issues/7801", "id": 325901979, "node_id": "MDU6SXNzdWUzMjU5MDE5Nzk=", "number": 7801, "title": "Checkpointing is slow on nn.DataParallel models", "user": {"login": "gpleiss", "id": 824157, "node_id": "MDQ6VXNlcjgyNDE1Nw==", "avatar_url": "https://avatars0.githubusercontent.com/u/824157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gpleiss", "html_url": "https://github.com/gpleiss", "followers_url": "https://api.github.com/users/gpleiss/followers", "following_url": "https://api.github.com/users/gpleiss/following{/other_user}", "gists_url": "https://api.github.com/users/gpleiss/gists{/gist_id}", "starred_url": "https://api.github.com/users/gpleiss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gpleiss/subscriptions", "organizations_url": "https://api.github.com/users/gpleiss/orgs", "repos_url": "https://api.github.com/users/gpleiss/repos", "events_url": "https://api.github.com/users/gpleiss/events{/privacy}", "received_events_url": "https://api.github.com/users/gpleiss/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-05-23T22:50:53Z", "updated_at": "2018-06-06T04:38:55Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6906411\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wandering007\">@wandering007</a> pointed out this issue in <a href=\"https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py\">https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py</a></p>\n<p>I have a model that uses checkpointing on several layers. On a single GPU, the model runs fairly fast (e.g. only a 15-20% overhead). On multiple GPUs, using an <code>nn.DataParallel</code> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6906411\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wandering007\">@wandering007</a> claims that the model runs up to 100x slower.</p>\n<p>Here's the important snippets of the model.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">_bn_function_factory</span>(<span class=\"pl-smi\">norm</span>, <span class=\"pl-smi\">relu</span>, <span class=\"pl-smi\">conv</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">bn_function</span>(<span class=\"pl-k\">*</span><span class=\"pl-smi\">inputs</span>):\n        concated_features <span class=\"pl-k\">=</span> torch.cat(inputs, <span class=\"pl-c1\">1</span>)\n        bottleneck_output <span class=\"pl-k\">=</span> conv(relu(norm(concated_features)))\n        <span class=\"pl-k\">return</span> bottleneck_output\n    <span class=\"pl-k\">return</span> bn_function\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">_DenseLayer</span>(<span class=\"pl-e\">nn</span>.<span class=\"pl-e\">Module</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">forward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-k\">*</span><span class=\"pl-smi\">prev_features</span>):\n        bn_function <span class=\"pl-k\">=</span> _bn_function_factory(<span class=\"pl-c1\">self</span>.norm1, <span class=\"pl-c1\">self</span>.relu1, <span class=\"pl-c1\">self</span>.conv1)\n        bottleneck_output <span class=\"pl-k\">=</span> cp.checkpoint(bn_function, <span class=\"pl-k\">*</span>prev_features)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>There are several <code>_DenseLayer</code>s throughout the model.<br>\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6906411\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wandering007\">@wandering007</a> seems to think that the issue has to do with GPU synchronization? As in, the models must synchronize at every checkpoint during the backward pass.</p>\n<p>Original issue is here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"318963426\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gpleiss/efficient_densenet_pytorch/issues/36\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gpleiss/efficient_densenet_pytorch/issues/36/hovercard\" href=\"https://github.com/gpleiss/efficient_densenet_pytorch/issues/36\">gpleiss/efficient_densenet_pytorch#36</a><br>\nFull code of the model is here: <a href=\"https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py\">https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py</a></p>", "body_text": "@wandering007 pointed out this issue in https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py\nI have a model that uses checkpointing on several layers. On a single GPU, the model runs fairly fast (e.g. only a 15-20% overhead). On multiple GPUs, using an nn.DataParallel @wandering007 claims that the model runs up to 100x slower.\nHere's the important snippets of the model.\ndef _bn_function_factory(norm, relu, conv):\n    def bn_function(*inputs):\n        concated_features = torch.cat(inputs, 1)\n        bottleneck_output = conv(relu(norm(concated_features)))\n        return bottleneck_output\n    return bn_function\n\nclass _DenseLayer(nn.Module):\n    # ...\n\n    def forward(self, *prev_features):\n        bn_function = _bn_function_factory(self.norm1, self.relu1, self.conv1)\n        bottleneck_output = cp.checkpoint(bn_function, *prev_features)\n        # ...\nThere are several _DenseLayers throughout the model.\n@wandering007 seems to think that the issue has to do with GPU synchronization? As in, the models must synchronize at every checkpoint during the backward pass.\nOriginal issue is here: gpleiss/efficient_densenet_pytorch#36\nFull code of the model is here: https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py", "body": "@wandering007 pointed out this issue in https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py\r\n\r\nI have a model that uses checkpointing on several layers. On a single GPU, the model runs fairly fast (e.g. only a 15-20% overhead). On multiple GPUs, using an `nn.DataParallel` @wandering007 claims that the model runs up to 100x slower.\r\n\r\nHere's the important snippets of the model.\r\n\r\n```python\r\ndef _bn_function_factory(norm, relu, conv):\r\n    def bn_function(*inputs):\r\n        concated_features = torch.cat(inputs, 1)\r\n        bottleneck_output = conv(relu(norm(concated_features)))\r\n        return bottleneck_output\r\n    return bn_function\r\n\r\nclass _DenseLayer(nn.Module):\r\n    # ...\r\n\r\n    def forward(self, *prev_features):\r\n        bn_function = _bn_function_factory(self.norm1, self.relu1, self.conv1)\r\n        bottleneck_output = cp.checkpoint(bn_function, *prev_features)\r\n        # ...\r\n```\r\n\r\nThere are several `_DenseLayer`s throughout the model.\r\n@wandering007 seems to think that the issue has to do with GPU synchronization? As in, the models must synchronize at every checkpoint during the backward pass.\r\n\r\nOriginal issue is here: https://github.com/gpleiss/efficient_densenet_pytorch/issues/36\r\nFull code of the model is here: https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py"}