{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/394937379", "html_url": "https://github.com/pytorch/pytorch/issues/7801#issuecomment-394937379", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7801", "id": 394937379, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDkzNzM3OQ==", "user": {"login": "ZhengRui", "id": 4105014, "node_id": "MDQ6VXNlcjQxMDUwMTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4105014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhengRui", "html_url": "https://github.com/ZhengRui", "followers_url": "https://api.github.com/users/ZhengRui/followers", "following_url": "https://api.github.com/users/ZhengRui/following{/other_user}", "gists_url": "https://api.github.com/users/ZhengRui/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhengRui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhengRui/subscriptions", "organizations_url": "https://api.github.com/users/ZhengRui/orgs", "repos_url": "https://api.github.com/users/ZhengRui/repos", "events_url": "https://api.github.com/users/ZhengRui/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhengRui/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-06T04:36:07Z", "updated_at": "2018-06-06T04:38:55Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=824157\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gpleiss\">@gpleiss</a> , I played a lot with different implementations of densenet model these two days, the reason why it is so slow in multi-gpu cases during backward seems to be related to the number of checkpoints used in the model. e.g. in my 4 1080Ti desktop, with densenet201 using batch size 300, by default every denselayer will have a checkpoint, the backward will take around 36 seconds, but if you only add checkpoints after each denseblock, with only 4 checkpoints, the backward time decreased to be around 3-5 seconds. In the pytorch 2 old models, same batch size's backward takes 1.5s. I've also tested adding some checkpoints every n denselayers and i can see the decrease of backward time when n increase. However my modification of your model file seems to have some bug that caused gpu memory leak, but i believe the reason of this issue in your model is too many checkpoints after each denselayer. You can try to only add checkpoints after each denseblock, I did but has some bug mentioned before.</p>\n<p>After all, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13488275\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prigoyal\">@prigoyal</a> 's model file <a href=\"https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py\">https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py</a> works really well. With same batch size(using chunks=8), the forward + backward total time is 3 seconds while previously the total time is 2 seconds which is quite acceptable. And it actually can support even slightly larger batch size as well upto 440. Maybe you can consider using this model file in your repo, I've compared forward and backward gradients, it is the same as your model.</p>", "body_text": "@gpleiss , I played a lot with different implementations of densenet model these two days, the reason why it is so slow in multi-gpu cases during backward seems to be related to the number of checkpoints used in the model. e.g. in my 4 1080Ti desktop, with densenet201 using batch size 300, by default every denselayer will have a checkpoint, the backward will take around 36 seconds, but if you only add checkpoints after each denseblock, with only 4 checkpoints, the backward time decreased to be around 3-5 seconds. In the pytorch 2 old models, same batch size's backward takes 1.5s. I've also tested adding some checkpoints every n denselayers and i can see the decrease of backward time when n increase. However my modification of your model file seems to have some bug that caused gpu memory leak, but i believe the reason of this issue in your model is too many checkpoints after each denselayer. You can try to only add checkpoints after each denseblock, I did but has some bug mentioned before.\nAfter all, @prigoyal 's model file https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py works really well. With same batch size(using chunks=8), the forward + backward total time is 3 seconds while previously the total time is 2 seconds which is quite acceptable. And it actually can support even slightly larger batch size as well upto 440. Maybe you can consider using this model file in your repo, I've compared forward and backward gradients, it is the same as your model.", "body": "@gpleiss , I played a lot with different implementations of densenet model these two days, the reason why it is so slow in multi-gpu cases during backward seems to be related to the number of checkpoints used in the model. e.g. in my 4 1080Ti desktop, with densenet201 using batch size 300, by default every denselayer will have a checkpoint, the backward will take around 36 seconds, but if you only add checkpoints after each denseblock, with only 4 checkpoints, the backward time decreased to be around 3-5 seconds. In the pytorch 2 old models, same batch size's backward takes 1.5s. I've also tested adding some checkpoints every n denselayers and i can see the decrease of backward time when n increase. However my modification of your model file seems to have some bug that caused gpu memory leak, but i believe the reason of this issue in your model is too many checkpoints after each denselayer. You can try to only add checkpoints after each denseblock, I did but has some bug mentioned before.\r\n\r\nAfter all, @prigoyal 's model file https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py works really well. With same batch size(using chunks=8), the forward + backward total time is 3 seconds while previously the total time is 2 seconds which is quite acceptable. And it actually can support even slightly larger batch size as well upto 440. Maybe you can consider using this model file in your repo, I've compared forward and backward gradients, it is the same as your model. "}