{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/391713778", "html_url": "https://github.com/pytorch/pytorch/issues/7801#issuecomment-391713778", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/7801", "id": 391713778, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTcxMzc3OA==", "user": {"login": "prigoyal", "id": 13488275, "node_id": "MDQ6VXNlcjEzNDg4Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/13488275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prigoyal", "html_url": "https://github.com/prigoyal", "followers_url": "https://api.github.com/users/prigoyal/followers", "following_url": "https://api.github.com/users/prigoyal/following{/other_user}", "gists_url": "https://api.github.com/users/prigoyal/gists{/gist_id}", "starred_url": "https://api.github.com/users/prigoyal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prigoyal/subscriptions", "organizations_url": "https://api.github.com/users/prigoyal/orgs", "repos_url": "https://api.github.com/users/prigoyal/repos", "events_url": "https://api.github.com/users/prigoyal/events{/privacy}", "received_events_url": "https://api.github.com/users/prigoyal/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-24T13:26:10Z", "updated_at": "2018-05-24T13:26:10Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=824157\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gpleiss\">@gpleiss</a>, can you provide a <em>minimalist</em> repro of slow speed instead of the entire DenseNet model?</p>\n<p>Also, from the first look, it seems that you are checkpointing every (Conv+Relu+BN) block. This may be inefficient to do to save memory: Relu is inplace, BN output needs to be kept in memory to pass to the next block, input to Conv is saved for doing forward pass again during back propagation. Can you try checkpointing at the level of DenseLayer? This example <a href=\"https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py\">https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py</a> of densenet checkpointing may be helpful.</p>", "body_text": "Hi @gpleiss, can you provide a minimalist repro of slow speed instead of the entire DenseNet model?\nAlso, from the first look, it seems that you are checkpointing every (Conv+Relu+BN) block. This may be inefficient to do to save memory: Relu is inplace, BN output needs to be kept in memory to pass to the next block, input to Conv is saved for doing forward pass again during back propagation. Can you try checkpointing at the level of DenseLayer? This example https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py of densenet checkpointing may be helpful.", "body": "Hi @gpleiss, can you provide a _minimalist_ repro of slow speed instead of the entire DenseNet model? \r\n\r\nAlso, from the first look, it seems that you are checkpointing every (Conv+Relu+BN) block. This may be inefficient to do to save memory: Relu is inplace, BN output needs to be kept in memory to pass to the next block, input to Conv is saved for doing forward pass again during back propagation. Can you try checkpointing at the level of DenseLayer? This example https://github.com/prigoyal/pytorch_memonger/blob/master/models/optimized/densenet_new.py of densenet checkpointing may be helpful."}