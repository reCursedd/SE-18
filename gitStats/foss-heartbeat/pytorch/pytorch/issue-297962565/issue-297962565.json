{"url": "https://api.github.com/repos/pytorch/pytorch/issues/5280", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/5280/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/5280/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/5280/events", "html_url": "https://github.com/pytorch/pytorch/issues/5280", "id": 297962565, "node_id": "MDU6SXNzdWUyOTc5NjI1NjU=", "number": 5280, "title": "BatchNorm1d raises RuntimeError (CUDNN_STATUS_BAD_PARAM) on 3D input.", "user": {"login": "acburigo", "id": 20728609, "node_id": "MDQ6VXNlcjIwNzI4NjA5", "avatar_url": "https://avatars2.githubusercontent.com/u/20728609?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acburigo", "html_url": "https://github.com/acburigo", "followers_url": "https://api.github.com/users/acburigo/followers", "following_url": "https://api.github.com/users/acburigo/following{/other_user}", "gists_url": "https://api.github.com/users/acburigo/gists{/gist_id}", "starred_url": "https://api.github.com/users/acburigo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acburigo/subscriptions", "organizations_url": "https://api.github.com/users/acburigo/orgs", "repos_url": "https://api.github.com/users/acburigo/repos", "events_url": "https://api.github.com/users/acburigo/events{/privacy}", "received_events_url": "https://api.github.com/users/acburigo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 443483881, "node_id": "MDU6TGFiZWw0NDM0ODM4ODE=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/todo", "name": "todo", "color": "c2e0c6", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-17T00:50:35Z", "updated_at": "2018-05-14T19:22:12Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<ul>\n<li>\n<p>OS: Ubuntu 16.04</p>\n</li>\n<li>\n<p>PyTorch version: 0.3.1</p>\n</li>\n<li>\n<p>How you installed PyTorch (conda, pip, source): pip</p>\n</li>\n<li>\n<p>Python version: 3.5.3</p>\n</li>\n<li>\n<p>CUDA/cuDNN version: 8.0</p>\n</li>\n<li>\n<p>GPU models and configuration: Titan Xp</p>\n</li>\n<li>\n<p>GCC version (if compiling from source): -</p>\n</li>\n<li>\n<p>A script to reproduce the bug. Please try to provide as minimal of a test case as possible.</p>\n</li>\n</ul>\n<pre><code>bn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\nx = Variable(torch.rand(2,5,1).cuda())\nbn(x)\n</code></pre>\n<ul>\n<li>Error messages and/or stack traces of the bug</li>\n</ul>\n<pre><code>---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-62-f513ba6863d2&gt; in &lt;module&gt;()\n      1 bn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\n      2 x = Variable(torch.rand(2,5,1).cuda())\n----&gt; 3 bn(x)\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    355             result = self._slow_forward(*input, **kwargs)\n    356         else:\n--&gt; 357             result = self.forward(*input, **kwargs)\n    358         for hook in self._forward_hooks.values():\n    359             hook_result = hook(self, input, result)\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)\n     35         return F.batch_norm(\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\n---&gt; 37             self.training, self.momentum, self.eps)\n     38 \n     39     def __repr__(self):\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n   1011             raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))\n   1012     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\n-&gt; 1013     return f(input, weight, bias)\n   1014 \n   1015 \n\nRuntimeError: CUDNN_STATUS_BAD_PARAM\n</code></pre>\n<ul>\n<li>Context around what you are trying to do<br>\nUse BatchNorm1d on a batch of data (Examples x Channels x Length)</li>\n</ul>\n<p>P.S.: This works on master branch.</p>", "body_text": "OS: Ubuntu 16.04\n\n\nPyTorch version: 0.3.1\n\n\nHow you installed PyTorch (conda, pip, source): pip\n\n\nPython version: 3.5.3\n\n\nCUDA/cuDNN version: 8.0\n\n\nGPU models and configuration: Titan Xp\n\n\nGCC version (if compiling from source): -\n\n\nA script to reproduce the bug. Please try to provide as minimal of a test case as possible.\n\n\nbn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\nx = Variable(torch.rand(2,5,1).cuda())\nbn(x)\n\n\nError messages and/or stack traces of the bug\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n<ipython-input-62-f513ba6863d2> in <module>()\n      1 bn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\n      2 x = Variable(torch.rand(2,5,1).cuda())\n----> 3 bn(x)\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n    355             result = self._slow_forward(*input, **kwargs)\n    356         else:\n--> 357             result = self.forward(*input, **kwargs)\n    358         for hook in self._forward_hooks.values():\n    359             hook_result = hook(self, input, result)\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)\n     35         return F.batch_norm(\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\n---> 37             self.training, self.momentum, self.eps)\n     38 \n     39     def __repr__(self):\n\n/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\n   1011             raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))\n   1012     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\n-> 1013     return f(input, weight, bias)\n   1014 \n   1015 \n\nRuntimeError: CUDNN_STATUS_BAD_PARAM\n\n\nContext around what you are trying to do\nUse BatchNorm1d on a batch of data (Examples x Channels x Length)\n\nP.S.: This works on master branch.", "body": "- OS: Ubuntu 16.04\r\n- PyTorch version: 0.3.1\r\n- How you installed PyTorch (conda, pip, source): pip\r\n- Python version: 3.5.3\r\n- CUDA/cuDNN version: 8.0\r\n- GPU models and configuration: Titan Xp\r\n- GCC version (if compiling from source): -\r\n\r\n- A script to reproduce the bug. Please try to provide as minimal of a test case as possible.\r\n```\r\nbn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\r\nx = Variable(torch.rand(2,5,1).cuda())\r\nbn(x)\r\n```\r\n\r\n- Error messages and/or stack traces of the bug\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-62-f513ba6863d2> in <module>()\r\n      1 bn = torch.nn.BatchNorm1d(5, eps=0.001, momentum=0.99).cuda()\r\n      2 x = Variable(torch.rand(2,5,1).cuda())\r\n----> 3 bn(x)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    355             result = self._slow_forward(*input, **kwargs)\r\n    356         else:\r\n--> 357             result = self.forward(*input, **kwargs)\r\n    358         for hook in self._forward_hooks.values():\r\n    359             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/modules/batchnorm.py in forward(self, input)\r\n     35         return F.batch_norm(\r\n     36             input, self.running_mean, self.running_var, self.weight, self.bias,\r\n---> 37             self.training, self.momentum, self.eps)\r\n     38 \r\n     39     def __repr__(self):\r\n\r\n/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)\r\n   1011             raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))\r\n   1012     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)\r\n-> 1013     return f(input, weight, bias)\r\n   1014 \r\n   1015 \r\n\r\nRuntimeError: CUDNN_STATUS_BAD_PARAM\r\n```\r\n\r\n- Context around what you are trying to do\r\nUse BatchNorm1d on a batch of data (Examples x Channels x Length)\r\n\r\nP.S.: This works on master branch."}