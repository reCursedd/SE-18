{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2672", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2672/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2672/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2672/events", "html_url": "https://github.com/pytorch/pytorch/issues/2672", "id": 256178011, "node_id": "MDU6SXNzdWUyNTYxNzgwMTE=", "number": 2672, "title": "Network Finetuning GPU memory usage", "user": {"login": "lucabergamini", "id": 27865235, "node_id": "MDQ6VXNlcjI3ODY1MjM1", "avatar_url": "https://avatars1.githubusercontent.com/u/27865235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucabergamini", "html_url": "https://github.com/lucabergamini", "followers_url": "https://api.github.com/users/lucabergamini/followers", "following_url": "https://api.github.com/users/lucabergamini/following{/other_user}", "gists_url": "https://api.github.com/users/lucabergamini/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucabergamini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucabergamini/subscriptions", "organizations_url": "https://api.github.com/users/lucabergamini/orgs", "repos_url": "https://api.github.com/users/lucabergamini/repos", "events_url": "https://api.github.com/users/lucabergamini/events{/privacy}", "received_events_url": "https://api.github.com/users/lucabergamini/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-08T08:27:27Z", "updated_at": "2017-10-03T09:08:36Z", "closed_at": "2017-10-03T09:08:36Z", "author_association": "NONE", "body_html": "<p>I'm a bit puzzled about the gpu memory usage when finetuning a network. In particular if I use a VGG-19 model with every conv layer frozen, <strong>where should I see the difference in GPU consumption</strong>? In forward or in backward? I'm running two models, one with frozen layers and one without but, as far as nvidia-smi tells me, if I place a breakpoint <strong>after</strong> the forward call , the two models have allocated exactly the same GPU memory.<br>\nI will provide reproducible code for both cases in the afternoon, but to achieve the finetuning I just set<br>\n<code>requires_grad = False</code> for every layer I'm not interested in, and excluded them from the optimizer parameters.</p>", "body_text": "I'm a bit puzzled about the gpu memory usage when finetuning a network. In particular if I use a VGG-19 model with every conv layer frozen, where should I see the difference in GPU consumption? In forward or in backward? I'm running two models, one with frozen layers and one without but, as far as nvidia-smi tells me, if I place a breakpoint after the forward call , the two models have allocated exactly the same GPU memory.\nI will provide reproducible code for both cases in the afternoon, but to achieve the finetuning I just set\nrequires_grad = False for every layer I'm not interested in, and excluded them from the optimizer parameters.", "body": "I'm a bit puzzled about the gpu memory usage when finetuning a network. In particular if I use a VGG-19 model with every conv layer frozen, **where should I see the difference in GPU consumption**? In forward or in backward? I'm running two models, one with frozen layers and one without but, as far as nvidia-smi tells me, if I place a breakpoint **after** the forward call , the two models have allocated exactly the same GPU memory. \r\nI will provide reproducible code for both cases in the afternoon, but to achieve the finetuning I just set \r\n```requires_grad = False``` for every layer I'm not interested in, and excluded them from the optimizer parameters."}