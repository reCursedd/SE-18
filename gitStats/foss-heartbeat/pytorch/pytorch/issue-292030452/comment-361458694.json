{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/361458694", "html_url": "https://github.com/pytorch/pytorch/pull/4881#issuecomment-361458694", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4881", "id": 361458694, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTQ1ODY5NA==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-30T02:42:13Z", "updated_at": "2018-01-30T15:36:12Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Based on microbenchmark experiments, the overhead of creating and setting a tensor descriptor is 94ns. In WLM, the default sequence length is 35, and we recreate the tensor descriptors two times more than we do in forwards. Multiplied over the number of batches, this amounts to <code>92*35*2*2983 = 19210520ns</code> extra overhead, aka 19ms. This is enough to register in my numbers and if I am an order of magnitude off could explain the difference.</p>\n<p>To test this hypothesis,  I added synthetic code to <code>rnn.py</code> to (uselessly) recompute the descriptors, to more closely reflect the C++ numbers.</p>\n<pre><code>diff --git a/torch/backends/cudnn/rnn.py b/torch/backends/cudnn/rnn.py\nindex ab17d77..c7614be 100644\n--- a/torch/backends/cudnn/rnn.py\n+++ b/torch/backends/cudnn/rnn.py\n@@ -346,6 +346,19 @@ def backward_grad(fn, input, hx, weight, output, grad_output, grad_hy, grad_inpu\n         dhx = grad_hx.resize_(*hidden_size)\n         dcx = grad_cx.resize_(*hidden_size) if grad_cx is not None else None\n \n+        # init descriptors\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\n+        if is_input_packed:\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\n+        else:\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\n+        fn.hx_desc = cudnn.descriptor(hx)\n+        fn.hy_desc = cudnn.descriptor(hx)\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\n+\n         if fn.dropout != 0 and cudnn.version() &lt; 5103:\n             raise RuntimeError('dropout supported only in cudnn v 5.1 and above')\n         if not fn.requires_grad:\n@@ -440,6 +453,19 @@ def backward_weight(fn, input, hx, output, weight, grad_weight):\n         y = output\n         dw = fn.weight_buf.new().resize_as_(fn.weight_buf).zero_()\n \n+        # init descriptors\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\n+        if is_input_packed:\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\n+        else:\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\n+        fn.hx_desc = cudnn.descriptor(hx)\n+        fn.hy_desc = cudnn.descriptor(hx)\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\n+\n         with torch.cuda.device_of(input):\n             workspace = torch.cuda.ByteTensor(fn.workspace_size)\n         check_error(cudnn.lib.cudnnRNNBackwardWeights(\n</code></pre>\n<p>To my <strong>absolute astonishment</strong>, this improved the runtime of WLM.</p>\n<pre><code>-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 72.91s | valid loss  5.53 | valid ppl   252.75\n-----------------------------------------------------------------------------------------\n=========================================================================================\n| End of training | test loss  5.44 | test ppl   231.46\n=========================================================================================\n\nreal    1m24.374s\nuser    1m9.955s\nsys     0m13.814s\n</code></pre>", "body_text": "Based on microbenchmark experiments, the overhead of creating and setting a tensor descriptor is 94ns. In WLM, the default sequence length is 35, and we recreate the tensor descriptors two times more than we do in forwards. Multiplied over the number of batches, this amounts to 92*35*2*2983 = 19210520ns extra overhead, aka 19ms. This is enough to register in my numbers and if I am an order of magnitude off could explain the difference.\nTo test this hypothesis,  I added synthetic code to rnn.py to (uselessly) recompute the descriptors, to more closely reflect the C++ numbers.\ndiff --git a/torch/backends/cudnn/rnn.py b/torch/backends/cudnn/rnn.py\nindex ab17d77..c7614be 100644\n--- a/torch/backends/cudnn/rnn.py\n+++ b/torch/backends/cudnn/rnn.py\n@@ -346,6 +346,19 @@ def backward_grad(fn, input, hx, weight, output, grad_output, grad_hy, grad_inpu\n         dhx = grad_hx.resize_(*hidden_size)\n         dcx = grad_cx.resize_(*hidden_size) if grad_cx is not None else None\n \n+        # init descriptors\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\n+        if is_input_packed:\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\n+        else:\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\n+        fn.hx_desc = cudnn.descriptor(hx)\n+        fn.hy_desc = cudnn.descriptor(hx)\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\n+\n         if fn.dropout != 0 and cudnn.version() < 5103:\n             raise RuntimeError('dropout supported only in cudnn v 5.1 and above')\n         if not fn.requires_grad:\n@@ -440,6 +453,19 @@ def backward_weight(fn, input, hx, output, weight, grad_weight):\n         y = output\n         dw = fn.weight_buf.new().resize_as_(fn.weight_buf).zero_()\n \n+        # init descriptors\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\n+        if is_input_packed:\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\n+        else:\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\n+        fn.hx_desc = cudnn.descriptor(hx)\n+        fn.hy_desc = cudnn.descriptor(hx)\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\n+\n         with torch.cuda.device_of(input):\n             workspace = torch.cuda.ByteTensor(fn.workspace_size)\n         check_error(cudnn.lib.cudnnRNNBackwardWeights(\n\nTo my absolute astonishment, this improved the runtime of WLM.\n-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 72.91s | valid loss  5.53 | valid ppl   252.75\n-----------------------------------------------------------------------------------------\n=========================================================================================\n| End of training | test loss  5.44 | test ppl   231.46\n=========================================================================================\n\nreal    1m24.374s\nuser    1m9.955s\nsys     0m13.814s", "body": "Based on microbenchmark experiments, the overhead of creating and setting a tensor descriptor is 94ns. In WLM, the default sequence length is 35, and we recreate the tensor descriptors two times more than we do in forwards. Multiplied over the number of batches, this amounts to `92*35*2*2983 = 19210520ns` extra overhead, aka 19ms. This is enough to register in my numbers and if I am an order of magnitude off could explain the difference.\r\n\r\nTo test this hypothesis,  I added synthetic code to `rnn.py` to (uselessly) recompute the descriptors, to more closely reflect the C++ numbers.\r\n\r\n```\r\ndiff --git a/torch/backends/cudnn/rnn.py b/torch/backends/cudnn/rnn.py\r\nindex ab17d77..c7614be 100644\r\n--- a/torch/backends/cudnn/rnn.py\r\n+++ b/torch/backends/cudnn/rnn.py\r\n@@ -346,6 +346,19 @@ def backward_grad(fn, input, hx, weight, output, grad_output, grad_hy, grad_inpu\r\n         dhx = grad_hx.resize_(*hidden_size)\r\n         dcx = grad_cx.resize_(*hidden_size) if grad_cx is not None else None\r\n \r\n+        # init descriptors\r\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\r\n+        if is_input_packed:\r\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\r\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\r\n+        else:\r\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\r\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\r\n+        fn.hx_desc = cudnn.descriptor(hx)\r\n+        fn.hy_desc = cudnn.descriptor(hx)\r\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\r\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\r\n+\r\n         if fn.dropout != 0 and cudnn.version() < 5103:\r\n             raise RuntimeError('dropout supported only in cudnn v 5.1 and above')\r\n         if not fn.requires_grad:\r\n@@ -440,6 +453,19 @@ def backward_weight(fn, input, hx, output, weight, grad_weight):\r\n         y = output\r\n         dw = fn.weight_buf.new().resize_as_(fn.weight_buf).zero_()\r\n \r\n+        # init descriptors\r\n+        fn.rnn_desc = init_rnn_descriptor(fn, handle)\r\n+        if is_input_packed:\r\n+            fn.x_descs = cudnn.descriptor_sequence(x, fn.batch_sizes)\r\n+            fn.y_descs = cudnn.descriptor_sequence(y, fn.batch_sizes)\r\n+        else:\r\n+            fn.x_descs = cudnn.descriptor(x[0], fn.seq_length)\r\n+            fn.y_descs = cudnn.descriptor(y[0], fn.seq_length)\r\n+        fn.hx_desc = cudnn.descriptor(hx)\r\n+        fn.hy_desc = cudnn.descriptor(hx)\r\n+        fn.cx_desc = cudnn.descriptor(cx) if cx is not None else None\r\n+        fn.cy_desc = cudnn.descriptor(cx) if cx is not None else None\r\n+\r\n         with torch.cuda.device_of(input):\r\n             workspace = torch.cuda.ByteTensor(fn.workspace_size)\r\n         check_error(cudnn.lib.cudnnRNNBackwardWeights(\r\n```\r\n\r\nTo my **absolute astonishment**, this improved the runtime of WLM.\r\n\r\n```\r\n-----------------------------------------------------------------------------------------\r\n| end of epoch   1 | time: 72.91s | valid loss  5.53 | valid ppl   252.75\r\n-----------------------------------------------------------------------------------------\r\n=========================================================================================\r\n| End of training | test loss  5.44 | test ppl   231.46\r\n=========================================================================================\r\n\r\nreal    1m24.374s\r\nuser    1m9.955s\r\nsys     0m13.814s\r\n```\r\n\r\n"}