{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/361322823", "html_url": "https://github.com/pytorch/pytorch/pull/4881#issuecomment-361322823", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/4881", "id": 361322823, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTMyMjgyMw==", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-29T17:33:31Z", "updated_at": "2018-01-29T17:54:39Z", "author_association": "CONTRIBUTOR", "body_html": "<p>While investigating, I noticed <code>get_device_capability</code> is very expensive (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"292491892\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/4908\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/4908/hovercard\" href=\"https://github.com/pytorch/pytorch/issues/4908\">#4908</a>), and it only gets called in CUDA 9.</p>\n<p>When I comment out this test (because I am not using half precision math which can take advantage of <code>TENSOR_OP</code>), the before test (<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/pytorch/pytorch/commit/2d829d15af98b5fde12d199456b9902dd0930b56/hovercard\" href=\"https://github.com/pytorch/pytorch/commit/2d829d15af98b5fde12d199456b9902dd0930b56\"><tt>2d829d1</tt></a>) now is:</p>\n<pre><code>--------------------------------------------------------------------------------\n| end of epoch   1 | time: 43.01s | valid loss  5.56 | valid ppl   260.99\n--------------------------------------------------------------------------------\n=============================================================================\n| End of training | test loss  5.48 | test ppl   239.28\n=============================================================================\n\nreal    0m53.107s\nuser    0m46.676s\nsys     0m5.868s\n</code></pre>\n<p>The diff was:</p>\n<pre><code>diff --git a/torch/backends/cudnn/__init__.py b/torch/backends/cudnn/__init__.py\nindex ff79f9638..d04b48f49 100644\n--- a/torch/backends/cudnn/__init__.py\n+++ b/torch/backends/cudnn/__init__.py\n@@ -314,11 +314,13 @@ class RNNDescriptor(object):\n                 CUDNN_RNN_ALGO_STANDARD,\n                 datatype\n             ))\n+            \"\"\"\n             if version() &gt;= 7000 and int(cuda[0]) &gt;= 9 and (\n                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] &gt;= 7):\n                 lib.cudnnSetRNNMatrixMathType(self, CUDNN_DEFAULT_MATH)\n                 if datatype == CUDNN_DATA_HALF:\n                     lib.cudnnSetRNNMatrixMathType(self, CUDNN_TENSOR_OP_MATH)\n+            \"\"\"\n         else:\n             check_error(lib.cudnnSetRNNDescriptor(\n                 self,\n</code></pre>\n<p>The after test (5bd576921dacf1771688493014b39e5faf5f6e3) is:</p>\n<pre><code>-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 40.69s | valid loss  5.56 | valid ppl   260.99\n-----------------------------------------------------------------------------------------\n=========================================================================================\n| End of training | test loss  5.48 | test ppl   239.28\n=========================================================================================\n\nreal    0m51.938s\nuser    0m44.960s\nsys     0m6.312s\n</code></pre>\n<p>The diff was</p>\n<pre><code>diff --git a/aten/src/ATen/cudnn/Descriptors.h b/aten/src/ATen/cudnn/Descriptors.h\nindex ea729d809..326a10594 100644\n--- a/aten/src/ATen/cudnn/Descriptors.h\n+++ b/aten/src/ATen/cudnn/Descriptors.h\n@@ -268,23 +268,6 @@ struct RNNDescriptor\n           mode,\n           CUDNN_RNN_ALGO_STANDARD,\n           datatype));\n-#if CUDNN_VERSION &gt;= 7000 &amp;&amp; CUDA_VERSION &gt;= 9000\n-    // TODO: This code should live as a utility somewhere in ATen.\n-    // Please don't copy paste me!\n-    int device;\n-    CUDA_CHECK(cudaGetDevice(&amp;device));\n-    cudaDeviceProp prop;\n-    CUDA_CHECK(cudaGetDeviceProperties(&amp;prop, device));\n-    if (prop.major &gt;= 7) {\n-      if (datatype == CUDNN_DATA_HALF) {\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_TENSOR_OP_MATH);\n-      } else {\n-        // Technically, as the default it's not necessary to explicitly\n-        // set this.\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_DEFAULT_MATH);\n-      }\n-    }\n-#endif\n   }\n };\n</code></pre>\n<p>Thus, it seems like the underlying CUDA code is not all that expensive, so maybe there is nothing to be done. (Haven't done the microbenchmark yet.)</p>", "body_text": "While investigating, I noticed get_device_capability is very expensive (#4908), and it only gets called in CUDA 9.\nWhen I comment out this test (because I am not using half precision math which can take advantage of TENSOR_OP), the before test (2d829d1) now is:\n--------------------------------------------------------------------------------\n| end of epoch   1 | time: 43.01s | valid loss  5.56 | valid ppl   260.99\n--------------------------------------------------------------------------------\n=============================================================================\n| End of training | test loss  5.48 | test ppl   239.28\n=============================================================================\n\nreal    0m53.107s\nuser    0m46.676s\nsys     0m5.868s\n\nThe diff was:\ndiff --git a/torch/backends/cudnn/__init__.py b/torch/backends/cudnn/__init__.py\nindex ff79f9638..d04b48f49 100644\n--- a/torch/backends/cudnn/__init__.py\n+++ b/torch/backends/cudnn/__init__.py\n@@ -314,11 +314,13 @@ class RNNDescriptor(object):\n                 CUDNN_RNN_ALGO_STANDARD,\n                 datatype\n             ))\n+            \"\"\"\n             if version() >= 7000 and int(cuda[0]) >= 9 and (\n                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n                 lib.cudnnSetRNNMatrixMathType(self, CUDNN_DEFAULT_MATH)\n                 if datatype == CUDNN_DATA_HALF:\n                     lib.cudnnSetRNNMatrixMathType(self, CUDNN_TENSOR_OP_MATH)\n+            \"\"\"\n         else:\n             check_error(lib.cudnnSetRNNDescriptor(\n                 self,\n\nThe after test (5bd576921dacf1771688493014b39e5faf5f6e3) is:\n-----------------------------------------------------------------------------------------\n| end of epoch   1 | time: 40.69s | valid loss  5.56 | valid ppl   260.99\n-----------------------------------------------------------------------------------------\n=========================================================================================\n| End of training | test loss  5.48 | test ppl   239.28\n=========================================================================================\n\nreal    0m51.938s\nuser    0m44.960s\nsys     0m6.312s\n\nThe diff was\ndiff --git a/aten/src/ATen/cudnn/Descriptors.h b/aten/src/ATen/cudnn/Descriptors.h\nindex ea729d809..326a10594 100644\n--- a/aten/src/ATen/cudnn/Descriptors.h\n+++ b/aten/src/ATen/cudnn/Descriptors.h\n@@ -268,23 +268,6 @@ struct RNNDescriptor\n           mode,\n           CUDNN_RNN_ALGO_STANDARD,\n           datatype));\n-#if CUDNN_VERSION >= 7000 && CUDA_VERSION >= 9000\n-    // TODO: This code should live as a utility somewhere in ATen.\n-    // Please don't copy paste me!\n-    int device;\n-    CUDA_CHECK(cudaGetDevice(&device));\n-    cudaDeviceProp prop;\n-    CUDA_CHECK(cudaGetDeviceProperties(&prop, device));\n-    if (prop.major >= 7) {\n-      if (datatype == CUDNN_DATA_HALF) {\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_TENSOR_OP_MATH);\n-      } else {\n-        // Technically, as the default it's not necessary to explicitly\n-        // set this.\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_DEFAULT_MATH);\n-      }\n-    }\n-#endif\n   }\n };\n\nThus, it seems like the underlying CUDA code is not all that expensive, so maybe there is nothing to be done. (Haven't done the microbenchmark yet.)", "body": "While investigating, I noticed `get_device_capability` is very expensive (#4908), and it only gets called in CUDA 9.\r\n\r\nWhen I comment out this test (because I am not using half precision math which can take advantage of `TENSOR_OP`), the before test (2d829d15af98b5fde12d199456b9902dd0930b56) now is:\r\n\r\n```\r\n--------------------------------------------------------------------------------\r\n| end of epoch   1 | time: 43.01s | valid loss  5.56 | valid ppl   260.99\r\n--------------------------------------------------------------------------------\r\n=============================================================================\r\n| End of training | test loss  5.48 | test ppl   239.28\r\n=============================================================================\r\n\r\nreal    0m53.107s\r\nuser    0m46.676s\r\nsys     0m5.868s\r\n```\r\n\r\nThe diff was:\r\n\r\n```\r\ndiff --git a/torch/backends/cudnn/__init__.py b/torch/backends/cudnn/__init__.py\r\nindex ff79f9638..d04b48f49 100644\r\n--- a/torch/backends/cudnn/__init__.py\r\n+++ b/torch/backends/cudnn/__init__.py\r\n@@ -314,11 +314,13 @@ class RNNDescriptor(object):\r\n                 CUDNN_RNN_ALGO_STANDARD,\r\n                 datatype\r\n             ))\r\n+            \"\"\"\r\n             if version() >= 7000 and int(cuda[0]) >= 9 and (\r\n                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\r\n                 lib.cudnnSetRNNMatrixMathType(self, CUDNN_DEFAULT_MATH)\r\n                 if datatype == CUDNN_DATA_HALF:\r\n                     lib.cudnnSetRNNMatrixMathType(self, CUDNN_TENSOR_OP_MATH)\r\n+            \"\"\"\r\n         else:\r\n             check_error(lib.cudnnSetRNNDescriptor(\r\n                 self,\r\n```\r\n\r\nThe after test (5bd576921dacf1771688493014b39e5faf5f6e3) is:\r\n\r\n```\r\n-----------------------------------------------------------------------------------------\r\n| end of epoch   1 | time: 40.69s | valid loss  5.56 | valid ppl   260.99\r\n-----------------------------------------------------------------------------------------\r\n=========================================================================================\r\n| End of training | test loss  5.48 | test ppl   239.28\r\n=========================================================================================\r\n\r\nreal    0m51.938s\r\nuser    0m44.960s\r\nsys     0m6.312s\r\n```\r\n\r\nThe diff was \r\n\r\n```\r\ndiff --git a/aten/src/ATen/cudnn/Descriptors.h b/aten/src/ATen/cudnn/Descriptors.h\r\nindex ea729d809..326a10594 100644\r\n--- a/aten/src/ATen/cudnn/Descriptors.h\r\n+++ b/aten/src/ATen/cudnn/Descriptors.h\r\n@@ -268,23 +268,6 @@ struct RNNDescriptor\r\n           mode,\r\n           CUDNN_RNN_ALGO_STANDARD,\r\n           datatype));\r\n-#if CUDNN_VERSION >= 7000 && CUDA_VERSION >= 9000\r\n-    // TODO: This code should live as a utility somewhere in ATen.\r\n-    // Please don't copy paste me!\r\n-    int device;\r\n-    CUDA_CHECK(cudaGetDevice(&device));\r\n-    cudaDeviceProp prop;\r\n-    CUDA_CHECK(cudaGetDeviceProperties(&prop, device));\r\n-    if (prop.major >= 7) {\r\n-      if (datatype == CUDNN_DATA_HALF) {\r\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_TENSOR_OP_MATH);\r\n-      } else {\r\n-        // Technically, as the default it's not necessary to explicitly\r\n-        // set this.\r\n-        cudnnSetRNNMatrixMathType(mut_desc(), CUDNN_DEFAULT_MATH);\r\n-      }\r\n-    }\r\n-#endif\r\n   }\r\n };\r\n ```\r\n\r\nThus, it seems like the underlying CUDA code is not all that expensive, so maybe there is nothing to be done. (Haven't done the microbenchmark yet.)"}