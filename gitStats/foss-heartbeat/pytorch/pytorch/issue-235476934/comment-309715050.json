{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/309715050", "html_url": "https://github.com/pytorch/pytorch/issues/1788#issuecomment-309715050", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/1788", "id": 309715050, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTcxNTA1MA==", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-20T10:41:35Z", "updated_at": "2017-06-20T10:41:35Z", "author_association": "MEMBER", "body_html": "<p>The two examples do completely different things. The slow network transposes the full RNN output (320 in feature dim), while the fast one transposes the output of the Linear layer (10 in feature dim). It's 32x less data to shuffle, so run times look ok. I think it's reasonable to guarantee that you can apply pointwise ops and e.g. Linear to packed sequences, but it seems orthogonal to this issue, which proposes to improve the implementation of packed sequence function. If you have any proposals, please open a new issue, or send PRs!</p>\n<p>Also, I think your slicing might be incorrect. Taking -1 from each sample might slice off padding.</p>", "body_text": "The two examples do completely different things. The slow network transposes the full RNN output (320 in feature dim), while the fast one transposes the output of the Linear layer (10 in feature dim). It's 32x less data to shuffle, so run times look ok. I think it's reasonable to guarantee that you can apply pointwise ops and e.g. Linear to packed sequences, but it seems orthogonal to this issue, which proposes to improve the implementation of packed sequence function. If you have any proposals, please open a new issue, or send PRs!\nAlso, I think your slicing might be incorrect. Taking -1 from each sample might slice off padding.", "body": "The two examples do completely different things. The slow network transposes the full RNN output (320 in feature dim), while the fast one transposes the output of the Linear layer (10 in feature dim). It's 32x less data to shuffle, so run times look ok. I think it's reasonable to guarantee that you can apply pointwise ops and e.g. Linear to packed sequences, but it seems orthogonal to this issue, which proposes to improve the implementation of packed sequence function. If you have any proposals, please open a new issue, or send PRs!\r\n \r\nAlso, I think your slicing might be incorrect. Taking -1 from each sample might slice off padding."}