{"url": "https://api.github.com/repos/pytorch/pytorch/issues/2805", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/2805/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/2805/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/2805/events", "html_url": "https://github.com/pytorch/pytorch/pull/2805", "id": 259211982, "node_id": "MDExOlB1bGxSZXF1ZXN0MTQyMTM1NTQ5", "number": 2805, "title": "Implement some autograd functions using ATen", "user": {"login": "colesbury", "id": 655866, "node_id": "MDQ6VXNlcjY1NTg2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/655866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colesbury", "html_url": "https://github.com/colesbury", "followers_url": "https://api.github.com/users/colesbury/followers", "following_url": "https://api.github.com/users/colesbury/following{/other_user}", "gists_url": "https://api.github.com/users/colesbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/colesbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colesbury/subscriptions", "organizations_url": "https://api.github.com/users/colesbury/orgs", "repos_url": "https://api.github.com/users/colesbury/repos", "events_url": "https://api.github.com/users/colesbury/events{/privacy}", "received_events_url": "https://api.github.com/users/colesbury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-20T15:45:35Z", "updated_at": "2018-11-23T15:34:49Z", "closed_at": "2017-09-26T21:08:01Z", "author_association": "MEMBER", "pull_request": {"url": "https://api.github.com/repos/pytorch/pytorch/pulls/2805", "html_url": "https://github.com/pytorch/pytorch/pull/2805", "diff_url": "https://github.com/pytorch/pytorch/pull/2805.diff", "patch_url": "https://github.com/pytorch/pytorch/pull/2805.patch"}, "body_html": "<p>This adds some generated autograd functions implemented in C++, which<br>\nare generated from derivatives.yaml. It also generates Python bindings<br>\nfor the Variable methods. The generated files are:</p>\n<ul>\n<li><code>Functions.cpp/h</code>: subclasses of torch::autograd::Function</li>\n<li><code>VariableType.cpp/h</code>: The at::Type for autograd Variables</li>\n<li><code>py_variable_methods.cpp</code>: Python bindings to torch::autograd::Variable</li>\n<li><code>py_variable_methods_dispatch.h</code>: wrapper which releases GIL and sets the<br>\nCUDA device</li>\n<li><code>python_functions.cpp/h</code>: exposes generated autograd functions as Python<br>\nobjects</li>\n</ul>\n<p>The generated functions are mostly shadowed by the definitions in<br>\nvariable.py. We'll remove the Python implementations in favor of the<br>\ngenerated C++ implementations in a subsequent commit.</p>", "body_text": "This adds some generated autograd functions implemented in C++, which\nare generated from derivatives.yaml. It also generates Python bindings\nfor the Variable methods. The generated files are:\n\nFunctions.cpp/h: subclasses of torch::autograd::Function\nVariableType.cpp/h: The at::Type for autograd Variables\npy_variable_methods.cpp: Python bindings to torch::autograd::Variable\npy_variable_methods_dispatch.h: wrapper which releases GIL and sets the\nCUDA device\npython_functions.cpp/h: exposes generated autograd functions as Python\nobjects\n\nThe generated functions are mostly shadowed by the definitions in\nvariable.py. We'll remove the Python implementations in favor of the\ngenerated C++ implementations in a subsequent commit.", "body": "This adds some generated autograd functions implemented in C++, which\r\nare generated from derivatives.yaml. It also generates Python bindings\r\nfor the Variable methods. The generated files are:\r\n\r\n- `Functions.cpp/h`: subclasses of torch::autograd::Function\r\n- `VariableType.cpp/h`: The at::Type for autograd Variables\r\n- `py_variable_methods.cpp`: Python bindings to torch::autograd::Variable\r\n- `py_variable_methods_dispatch.h`: wrapper which releases GIL and sets the\r\n     CUDA device\r\n- `python_functions.cpp/h`: exposes generated autograd functions as Python\r\n     objects\r\n\r\nThe generated functions are mostly shadowed by the definitions in\r\nvariable.py. We'll remove the Python implementations in favor of the\r\ngenerated C++ implementations in a subsequent commit."}