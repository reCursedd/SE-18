{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/140286540", "pull_request_review_id": 64118102, "id": 140286540, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MDI4NjU0MA==", "diff_hunk": "@@ -84,18 +286,79 @@ def create_autograd_functions(top_env, declarations):\n     These contain the auto-generated subclasses of torch::autograd::Function\n     for each every differentiable torch function.\n     \"\"\"\n-    # function_definitions = top_env['autograd_function_definitions']\n-    # function_declarations = top_env['autograd_function_declarations']\n+    function_definitions = top_env['autograd_function_definitions']\n+    function_declarations = top_env['autograd_function_declarations']\n+    py_function_initializers = top_env['py_autograd_function_initializers']\n+\n+    def group_by_name(options):\n+        res = {}\n+        for option in options:\n+            name = option['name']\n+            if name not in res:\n+                res[name] = []\n+            res[name].append(option)\n+        return res\n+\n+    for name, options in group_by_name(declarations).items():\n+        for i, option in enumerate(options):\n+            name = option['name']\n+            option['op'] = name[0].upper() + name[1:] + 'Backward'\n+            if len(options) > 1:\n+                option['op'] += str(i)\n+\n+    def process_function(op):\n+        if op['fallthrough']:\n+            return\n+\n+        saved_variables = []\n+        for arg in op['saved']:\n+            name = arg['name']\n+            if arg['type'] == 'Tensor':\n+                saved_variables.append('SavedVariable {}_;'.format(name))\n+            elif arg['type'] == 'IntList':\n+                saved_variables.append('std::vector<int64_t> {};'.format(name))\n+            else:\n+                saved_variables.append('{} {};'.format(arg['type'], name))\n+        op['saved_variables'] = saved_variables\n \n-    def process_function(option):\n-        # TODO: generate autograd::Function classes for each function specified\n-        # in derivatives.yaml\n-        pass\n+        body = []\n+        body.append('auto& grad = inputs[0];')\n+\n+        def unpack_args(derivative):\n+            unpack = []\n+            for arg in op['saved']:\n+                if arg['type'] == 'Tensor':\n+                    name = arg['name']\n+                    unpack.append('auto {} = {}_.unpack();'.format(name, name))\n+            return unpack\n+\n+        i = 0\n+        for arg in op['python_arguments']:\n+            derivative = arg.get('derivative')\n+            if derivative is None:\n+                continue\n+            body.append(DERIVATIVE.substitute({\n+                'unpack_save_variables': unpack_args(derivative),\n+                'i': i,\n+                'derivative': derivative,\n+            }))\n+            i += 1", "path": "tools/autograd/gen_variable_type.py", "position": null, "original_position": 327, "commit_id": "e471756dd09f27c1ac6fff4e977d1faeb4b030cf", "original_commit_id": "a5e60c1254517fffaebc9f5432faf08fb533ae4e", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "We don't support things that return non-differentiable outputs right now, do we?", "created_at": "2017-09-21T16:03:37Z", "updated_at": "2018-11-23T15:34:43Z", "html_url": "https://github.com/pytorch/pytorch/pull/2805#discussion_r140286540", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/2805", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/140286540"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/2805#discussion_r140286540"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/2805"}}, "body_html": "<p>We don't support things that return non-differentiable outputs right now, do we?</p>", "body_text": "We don't support things that return non-differentiable outputs right now, do we?"}