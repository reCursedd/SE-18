{"url": "https://api.github.com/repos/pytorch/pytorch/issues/13568", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/13568/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/13568/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/13568/events", "html_url": "https://github.com/pytorch/pytorch/issues/13568", "id": 377407542, "node_id": "MDU6SXNzdWUzNzc0MDc1NDI=", "number": 13568, "title": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.", "user": {"login": "simonm3", "id": 1199593, "node_id": "MDQ6VXNlcjExOTk1OTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1199593?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonm3", "html_url": "https://github.com/simonm3", "followers_url": "https://api.github.com/users/simonm3/followers", "following_url": "https://api.github.com/users/simonm3/following{/other_user}", "gists_url": "https://api.github.com/users/simonm3/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonm3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonm3/subscriptions", "organizations_url": "https://api.github.com/users/simonm3/orgs", "repos_url": "https://api.github.com/users/simonm3/repos", "events_url": "https://api.github.com/users/simonm3/events{/privacy}", "received_events_url": "https://api.github.com/users/simonm3/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-05T13:48:13Z", "updated_at": "2018-11-08T22:55:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><code>x.numpy()</code></p>\n<p>clearly means I want to convert something to numpy, which is always on the CPU. It is redundant to have to say .cpu().numpy(). The conversion should be automatic rather than throwing an exception.</p>\n<p>In my specific case I have set default tensor type to CUDA because that is what I am using by default - and because it makes it really easy to switch everything to CPU in one line of code without cluttering up the rest of it with passing a device around. However when I call third party software they create a tensor without an explicit type; then try to numpy() it expecting it to be CPU based. I have suggested they add a .cpu() but would be better to fix in pytorch.</p>", "body_text": "x.numpy()\nclearly means I want to convert something to numpy, which is always on the CPU. It is redundant to have to say .cpu().numpy(). The conversion should be automatic rather than throwing an exception.\nIn my specific case I have set default tensor type to CUDA because that is what I am using by default - and because it makes it really easy to switch everything to CPU in one line of code without cluttering up the rest of it with passing a device around. However when I call third party software they create a tensor without an explicit type; then try to numpy() it expecting it to be CPU based. I have suggested they add a .cpu() but would be better to fix in pytorch.", "body": "`x.numpy()`\r\n\r\nclearly means I want to convert something to numpy, which is always on the CPU. It is redundant to have to say .cpu().numpy(). The conversion should be automatic rather than throwing an exception. \r\n\r\nIn my specific case I have set default tensor type to CUDA because that is what I am using by default - and because it makes it really easy to switch everything to CPU in one line of code without cluttering up the rest of it with passing a device around. However when I call third party software they create a tensor without an explicit type; then try to numpy() it expecting it to be CPU based. I have suggested they add a .cpu() but would be better to fix in pytorch."}