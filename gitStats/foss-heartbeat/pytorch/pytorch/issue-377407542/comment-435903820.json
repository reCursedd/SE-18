{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/435903820", "html_url": "https://github.com/pytorch/pytorch/issues/13568#issuecomment-435903820", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/13568", "id": 435903820, "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTkwMzgyMA==", "user": {"login": "simonm3", "id": 1199593, "node_id": "MDQ6VXNlcjExOTk1OTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1199593?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonm3", "html_url": "https://github.com/simonm3", "followers_url": "https://api.github.com/users/simonm3/followers", "following_url": "https://api.github.com/users/simonm3/following{/other_user}", "gists_url": "https://api.github.com/users/simonm3/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonm3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonm3/subscriptions", "organizations_url": "https://api.github.com/users/simonm3/orgs", "repos_url": "https://api.github.com/users/simonm3/repos", "events_url": "https://api.github.com/users/simonm3/events{/privacy}", "received_events_url": "https://api.github.com/users/simonm3/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-05T14:55:03Z", "updated_at": "2018-11-05T14:55:03Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">I am not sure I understand. The warning is only generated for a CUDA tensor\nwhich presumably never has any sharing of cpu memory as it is on the gpu\nonly. If I have a CUDA tensor and call .numpy() then clearly I want to get\na numpy array on the cpu. There is no circumstance where I would want it to\nfail.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Mon, 5 Nov 2018 at 13:58, Tongzhou Wang ***@***.***&gt; wrote:\n .numpy() shares memory with the input CPU tensor, so cuda_t.cpu().numpy()\n is different with cpu_t.numpy() and we want to explicitly ask users to\n convert to CPU tensor.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"377407542\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytorch/pytorch/issues/13568\" href=\"https://github.com/pytorch/pytorch/issues/13568#issuecomment-435883732\">#13568 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABJN6aZWCVIarT5COZel6OMXN2C4fH-pks5usEQdgaJpZM4YOedZ\">https://github.com/notifications/unsubscribe-auth/ABJN6aZWCVIarT5COZel6OMXN2C4fH-pks5usEQdgaJpZM4YOedZ</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "I am not sure I understand. The warning is only generated for a CUDA tensor\nwhich presumably never has any sharing of cpu memory as it is on the gpu\nonly. If I have a CUDA tensor and call .numpy() then clearly I want to get\na numpy array on the cpu. There is no circumstance where I would want it to\nfail.\n\u2026\nOn Mon, 5 Nov 2018 at 13:58, Tongzhou Wang ***@***.***> wrote:\n .numpy() shares memory with the input CPU tensor, so cuda_t.cpu().numpy()\n is different with cpu_t.numpy() and we want to explicitly ask users to\n convert to CPU tensor.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#13568 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABJN6aZWCVIarT5COZel6OMXN2C4fH-pks5usEQdgaJpZM4YOedZ>\n .", "body": "I am not sure I understand. The warning is only generated for a CUDA tensor\nwhich presumably never has any sharing of cpu memory as it is on the gpu\nonly. If I have a CUDA tensor and call .numpy() then clearly I want to get\na numpy array on the cpu. There is no circumstance where I would want it to\nfail.\n\nOn Mon, 5 Nov 2018 at 13:58, Tongzhou Wang <notifications@github.com> wrote:\n\n> .numpy() shares memory with the input CPU tensor, so cuda_t.cpu().numpy()\n> is different with cpu_t.numpy() and we want to explicitly ask users to\n> convert to CPU tensor.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pytorch/pytorch/issues/13568#issuecomment-435883732>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABJN6aZWCVIarT5COZel6OMXN2C4fH-pks5usEQdgaJpZM4YOedZ>\n> .\n>\n"}