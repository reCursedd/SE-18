{"url": "https://api.github.com/repos/pytorch/pytorch/issues/9256", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/9256/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/9256/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/9256/events", "html_url": "https://github.com/pytorch/pytorch/issues/9256", "id": 339336687, "node_id": "MDU6SXNzdWUzMzkzMzY2ODc=", "number": 9256, "title": "Caffe2 Exception encountered running PythonOp function: TypeError: unhashable type", "user": {"login": "saikiran6", "id": 11065947, "node_id": "MDQ6VXNlcjExMDY1OTQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/11065947?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saikiran6", "html_url": "https://github.com/saikiran6", "followers_url": "https://api.github.com/users/saikiran6/followers", "following_url": "https://api.github.com/users/saikiran6/following{/other_user}", "gists_url": "https://api.github.com/users/saikiran6/gists{/gist_id}", "starred_url": "https://api.github.com/users/saikiran6/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saikiran6/subscriptions", "organizations_url": "https://api.github.com/users/saikiran6/orgs", "repos_url": "https://api.github.com/users/saikiran6/repos", "events_url": "https://api.github.com/users/saikiran6/events{/privacy}", "received_events_url": "https://api.github.com/users/saikiran6/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890282107, "node_id": "MDU6TGFiZWw4OTAyODIxMDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/caffe2", "name": "caffe2", "color": "210aa8", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "pjh5", "id": 6456020, "node_id": "MDQ6VXNlcjY0NTYwMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6456020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pjh5", "html_url": "https://github.com/pjh5", "followers_url": "https://api.github.com/users/pjh5/followers", "following_url": "https://api.github.com/users/pjh5/following{/other_user}", "gists_url": "https://api.github.com/users/pjh5/gists{/gist_id}", "starred_url": "https://api.github.com/users/pjh5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pjh5/subscriptions", "organizations_url": "https://api.github.com/users/pjh5/orgs", "repos_url": "https://api.github.com/users/pjh5/repos", "events_url": "https://api.github.com/users/pjh5/events{/privacy}", "received_events_url": "https://api.github.com/users/pjh5/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pjh5", "id": 6456020, "node_id": "MDQ6VXNlcjY0NTYwMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6456020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pjh5", "html_url": "https://github.com/pjh5", "followers_url": "https://api.github.com/users/pjh5/followers", "following_url": "https://api.github.com/users/pjh5/following{/other_user}", "gists_url": "https://api.github.com/users/pjh5/gists{/gist_id}", "starred_url": "https://api.github.com/users/pjh5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pjh5/subscriptions", "organizations_url": "https://api.github.com/users/pjh5/orgs", "repos_url": "https://api.github.com/users/pjh5/repos", "events_url": "https://api.github.com/users/pjh5/events{/privacy}", "received_events_url": "https://api.github.com/users/pjh5/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-09T07:36:26Z", "updated_at": "2018-07-10T16:13:46Z", "closed_at": "2018-07-10T16:13:46Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>Iam trying to train e2e_mask_rcnn_R-101-FPN_1x.yaml on my custom dataset. The dataset is converted into coco format. NUM_CLASSES is set to seven (it includes backgorund class as well). It worked well with tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml, with small modification in boxes.py by commenting line no 62  assert np.all(areas &gt;= 0).</p>\n<p>The error output is given below. Please help me resolve this issue.</p>\n<p>\"\"\"\"\"\"\"\"\"\"<br>\nRuntimeError: [enforce fail at pybind_state.h:410] . Exception encountered running PythonOp function: TypeError: unhashable type</p>\n<p>At:<br>\n/detectron/utils/segms.py(129): <br>\nError from operator:<br>\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 0 }Error from operator:<br>\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 1 cuda_gpu_id: 0 }<br>\n\"\"\"\"\"\"\"\"\"\"\"</p>\n<p>Thanks</p>", "body_text": "Hi,\nIam trying to train e2e_mask_rcnn_R-101-FPN_1x.yaml on my custom dataset. The dataset is converted into coco format. NUM_CLASSES is set to seven (it includes backgorund class as well). It worked well with tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml, with small modification in boxes.py by commenting line no 62  assert np.all(areas >= 0).\nThe error output is given below. Please help me resolve this issue.\n\"\"\"\"\"\"\"\"\"\"\nRuntimeError: [enforce fail at pybind_state.h:410] . Exception encountered running PythonOp function: TypeError: unhashable type\nAt:\n/detectron/utils/segms.py(129): \nError from operator:\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 0 }Error from operator:\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 1 cuda_gpu_id: 0 }\n\"\"\"\"\"\"\"\"\"\"\"\nThanks", "body": "Hi,\r\n\r\nIam trying to train e2e_mask_rcnn_R-101-FPN_1x.yaml on my custom dataset. The dataset is converted into coco format. NUM_CLASSES is set to seven (it includes backgorund class as well). It worked well with tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml, with small modification in boxes.py by commenting line no 62  assert np.all(areas >= 0).\r\n\r\nThe error output is given below. Please help me resolve this issue. \r\n\r\n\"\"\"\"\"\"\"\"\"\"\r\nRuntimeError: [enforce fail at pybind_state.h:410] . Exception encountered running PythonOp function: TypeError: unhashable type\r\n\r\nAt:\r\n  /detectron/utils/segms.py(129): <genexpr>\r\n Error from operator: \r\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 0 }Error from operator: \r\ninput: \"gpu_0/rpn_rois_fpn2\" input: \"gpu_0/rpn_rois_fpn3\" input: \"gpu_0/rpn_rois_fpn4\" input: \"gpu_0/rpn_rois_fpn5\" input: \"gpu_0/rpn_rois_fpn6\" input: \"gpu_0/rpn_roi_probs_fpn2\" input: \"gpu_0/rpn_roi_probs_fpn3\" input: \"gpu_0/rpn_roi_probs_fpn4\" input: \"gpu_0/rpn_roi_probs_fpn5\" input: \"gpu_0/rpn_roi_probs_fpn6\" input: \"gpu_0/roidb\" input: \"gpu_0/im_info\" output: \"gpu_0/rois\" output: \"gpu_0/labels_int32\" output: \"gpu_0/bbox_targets\" output: \"gpu_0/bbox_inside_weights\" output: \"gpu_0/bbox_outside_weights\" output: \"gpu_0/mask_rois\" output: \"gpu_0/roi_has_mask_int32\" output: \"gpu_0/masks_int32\" output: \"gpu_0/rois_fpn2\" output: \"gpu_0/rois_fpn3\" output: \"gpu_0/rois_fpn4\" output: \"gpu_0/rois_fpn5\" output: \"gpu_0/rois_idx_restore_int32\" output: \"gpu_0/mask_rois_fpn2\" output: \"gpu_0/mask_rois_fpn3\" output: \"gpu_0/mask_rois_fpn4\" output: \"gpu_0/mask_rois_fpn5\" output: \"gpu_0/mask_rois_idx_restore_int32\" name: \"CollectAndDistributeFpnRpnProposalsOp:gpu_0/rpn_rois_fpn2,gpu_0/rpn_rois_fpn3,gpu_0/rpn_rois_fpn4,gpu_0/rpn_rois_fpn5,gpu_0/rpn_rois_fpn6,gpu_0/rpn_roi_probs_fpn2,gpu_0/rpn_roi_probs_fpn3,gpu_0/rpn_roi_probs_fpn4,gpu_0/rpn_roi_probs_fpn5,gpu_0/rpn_roi_probs_fpn6,gpu_0/roidb,gpu_0/im_info\" type: \"Python\" arg { name: \"grad_input_indices\" } arg { name: \"token\" s: \"forward:5\" } arg { name: \"grad_output_indices\" } device_option { device_type: 1 cuda_gpu_id: 0 }\r\n\"\"\"\"\"\"\"\"\"\"\"\r\n\r\nThanks\r\n"}