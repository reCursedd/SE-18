{"url": "https://api.github.com/repos/pytorch/pytorch/issues/7786", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/7786/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/7786/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/7786/events", "html_url": "https://github.com/pytorch/pytorch/issues/7786", "id": 325590018, "node_id": "MDU6SXNzdWUzMjU1OTAwMTg=", "number": 7786, "title": "[feature request] Simple and Efficient way to get gradients of each element of a sum", "user": {"login": "fKunstner", "id": 8789455, "node_id": "MDQ6VXNlcjg3ODk0NTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8789455?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fKunstner", "html_url": "https://github.com/fKunstner", "followers_url": "https://api.github.com/users/fKunstner/followers", "following_url": "https://api.github.com/users/fKunstner/following{/other_user}", "gists_url": "https://api.github.com/users/fKunstner/gists{/gist_id}", "starred_url": "https://api.github.com/users/fKunstner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fKunstner/subscriptions", "organizations_url": "https://api.github.com/users/fKunstner/orgs", "repos_url": "https://api.github.com/users/fKunstner/repos", "events_url": "https://api.github.com/users/fKunstner/events{/privacy}", "received_events_url": "https://api.github.com/users/fKunstner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2018-05-23T07:56:00Z", "updated_at": "2018-10-18T13:00:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>For some application, I need to get gradients for each elements of a sum.<br>\nI am aware that this issue has already been raised previously, in various forms (<a href=\"https://discuss.pytorch.org/t/gradient-w-r-t-each-sample/1433/2\" rel=\"nofollow\">here</a>, <a href=\"https://discuss.pytorch.org/t/efficient-per-example-gradient-computations/17204\" rel=\"nofollow\">here</a>, <a href=\"https://discuss.pytorch.org/t/quickly-get-individual-gradients-not-sum-of-gradients-of-all-network-outputs/8405\" rel=\"nofollow\">here</a> and possibly related to <a href=\"https://github.com/pytorch/pytorch/issues/1407\" data-hovercard-type=\"issue\" data-hovercard-url=\"/pytorch/pytorch/issues/1407/hovercard\">here</a>)<br>\nand has also been raised for other autodifferentiation libraries (some examples for TensorFlow: <a href=\"https://github.com/tensorflow/tensorflow/issues/675\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/675/hovercard\">here</a>, long discussion <a href=\"https://github.com/tensorflow/tensorflow/issues/4897\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4897/hovercard\">here</a>)</p>\n<p>While the feature does exists in that there is a way to get the desired output,<br>\nI have not found an efficient way of computing it after investing a significant amount of time.</p>\n<p>I am bringing it up again, with some numbers showing the inefficiency of the existing solutions I have been able to find.</p>\n<p>It is possible that the running time I observed is not an issue with the existing solutions but only with my implementation of them,<br>\nor that my attempts have been misguided and that a simpler solution exists.<br>\nIf there is a way to make that operation in an efficient way, I would love to know about it.</p>\n<p>I can spend more time working on this issue, but as of now I do not know of a way forward.<br>\nThe following contains a description of the desired feature, existing \"workaround\" and some evaluation of their performance.</p>\n<hr>\n<h2>Feature description:</h2>\n<p>Given an objective that is a sum of functions, <code>f(x) = f_1(x) + ... + f_N(x)</code>,<br>\na <em>simple to use</em> and <em>efficient</em> way to compute the gradient with respect to <code>x</code> for each of the individual function <code>f_n</code>, i.e., getting<br>\n<code>[\u2207f_1(x), ..., \u2207f_N(x)]</code></p>\n<p>If there already is a way to do so, an example would be very nice.</p>\n<p>(I understand that this would involve additional memory overhead if <code>N</code> is large, as pointed out <a href=\"https://discuss.pytorch.org/t/quickly-get-individual-gradients-not-sum-of-gradients-of-all-network-outputs/8405/2\" rel=\"nofollow\">here</a> - my setting is not bound by memory but by time)</p>\n<h2>Use case:</h2>\n<ul>\n<li>Computing approximate second-order information (Generalized Gauss-Newton type of algorithm).</li>\n<li>Computing gradient statistics such as the variance at a given point.<br>\nSome papers based on those ideas: <a href=\"https://pdfs.semanticscholar.org/42e2/1cd78f578fa6ce61b06b99848697da85ed76.pdf\" rel=\"nofollow\">here</a>, <a href=\"http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf\" rel=\"nofollow\">here</a></li>\n</ul>\n<h2>Existing workarounds:</h2>\n<ul>\n<li>The <code>naive</code> implementation: do the forward pass in batch up to the last part of the function to minimize overhead, and then call backward on each individual <code>f_n(x)</code>.</li>\n<li>Goodfellow showed how to recover the individual gradients from gradients with respect to the activation functions in the case of feed-forward neural networks <a href=\"https://arxiv.org/abs/1510.01799\" rel=\"nofollow\">here</a>. This requires an additional derivation and performs the linear parts of the transformation in Python instead of C, making it scale badly.</li>\n<li>What I call \"Multiple Models\": Define copies of the parameters <code>x_1, ..., x_N</code> and compute <code>grad(f_1(x_1) + ... + f_N(x_N))</code>. This ensures that the gradients are not accumulated, however it scales poorly. Adapted from the original formulation <a href=\"https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-290997283\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4897/hovercard\">here</a></li>\n</ul>\n<h2>Evaluation of existing workarounds</h2>\n<p>I have tried to make the simplest example of a sufficiently complex problem where this becomes an issue.<br>\nThe code to reproduce these is available <a href=\"https://github.com/fKunstner/fast-individual-gradients-with-autodiff\">here</a>.</p>\n<p>Running on a simple Multi-Layer Perceptron, I am comparing the running time of</p>\n<ul>\n<li><code>full</code>: computing the gradient of the full objective function</li>\n<li><code>naive</code>, <code>goodf</code>, <code>multi</code>: computing the gradient of the sum by first computing individual gradients with the methods described above, and then taking the sum[1].</li>\n</ul>\n<p>I am taking a sum over <code>N = 1000</code> elements, and tried different network configurations;</p>\n<pre><code># D: Dimension of input and of each Layer\n# L: Number of hidden layers\n</code></pre>\n<p>For a (relatively) wide and shallow network (<code>D, L = 500, 1</code>), I get the following running time</p>\n<pre><code>Full  :  0.04s\nnaive : 15.42s\ngoodf :  4.42s\nmulti :  1.89s\n</code></pre>\n<p>For a narrower and deeper network (<code>D, L = 100, 10</code>) I get</p>\n<pre><code>Full  :  0.03s\nnaive : 11.40s\ngoodf :  1.70s\nmulti :  1.60s\n</code></pre>\n<p>While <code>goodf</code> and <code>multi</code> definitely are improvements on the naive method, they are still ~50 time slower than simply computing the sum. I would not expect any method that stores individual gradients to perform as well as a method that can simply throw them away, but they are essentially doing the same operations so it should be possible to do better.<br>\nWith those numbers, training a small-ish neural network that would normally take ~10 minutes would take 10 hours, making experimentation very difficult.</p>\n<p>From the <a href=\"https://discuss.pytorch.org/t/how-the-hook-works/2222/2\" rel=\"nofollow\">information I have been able to find</a>, it seems difficult to get access to the un-aggregated gradients.<br>\nIt is a bit frustrating to know that the backward pass on the function computes the sum in almost no time, and all that is needed for this feature is a way to intercept elements of this sum.</p>\n<p>A hook that would allow to store individual gradients on the fly in some list or tensor - maybe with the use of those hooks or by defining a new sum function that intercepts gradients - would be amazing, but I do not understand the codebase and/or AD to do it.<br>\nSome pointers in that direction would already be a big help</p>\n<p>[1] <em>Note: I am not looking for an expensive way of computing the sum by computing individual gradients - I am taking the sum in the end so that all methods do the \"same thing\", but what is really needed is the intermediate matrix containing individual gradients</em></p>", "body_text": "For some application, I need to get gradients for each elements of a sum.\nI am aware that this issue has already been raised previously, in various forms (here, here, here and possibly related to here)\nand has also been raised for other autodifferentiation libraries (some examples for TensorFlow: here, long discussion here)\nWhile the feature does exists in that there is a way to get the desired output,\nI have not found an efficient way of computing it after investing a significant amount of time.\nI am bringing it up again, with some numbers showing the inefficiency of the existing solutions I have been able to find.\nIt is possible that the running time I observed is not an issue with the existing solutions but only with my implementation of them,\nor that my attempts have been misguided and that a simpler solution exists.\nIf there is a way to make that operation in an efficient way, I would love to know about it.\nI can spend more time working on this issue, but as of now I do not know of a way forward.\nThe following contains a description of the desired feature, existing \"workaround\" and some evaluation of their performance.\n\nFeature description:\nGiven an objective that is a sum of functions, f(x) = f_1(x) + ... + f_N(x),\na simple to use and efficient way to compute the gradient with respect to x for each of the individual function f_n, i.e., getting\n[\u2207f_1(x), ..., \u2207f_N(x)]\nIf there already is a way to do so, an example would be very nice.\n(I understand that this would involve additional memory overhead if N is large, as pointed out here - my setting is not bound by memory but by time)\nUse case:\n\nComputing approximate second-order information (Generalized Gauss-Newton type of algorithm).\nComputing gradient statistics such as the variance at a given point.\nSome papers based on those ideas: here, here\n\nExisting workarounds:\n\nThe naive implementation: do the forward pass in batch up to the last part of the function to minimize overhead, and then call backward on each individual f_n(x).\nGoodfellow showed how to recover the individual gradients from gradients with respect to the activation functions in the case of feed-forward neural networks here. This requires an additional derivation and performs the linear parts of the transformation in Python instead of C, making it scale badly.\nWhat I call \"Multiple Models\": Define copies of the parameters x_1, ..., x_N and compute grad(f_1(x_1) + ... + f_N(x_N)). This ensures that the gradients are not accumulated, however it scales poorly. Adapted from the original formulation here\n\nEvaluation of existing workarounds\nI have tried to make the simplest example of a sufficiently complex problem where this becomes an issue.\nThe code to reproduce these is available here.\nRunning on a simple Multi-Layer Perceptron, I am comparing the running time of\n\nfull: computing the gradient of the full objective function\nnaive, goodf, multi: computing the gradient of the sum by first computing individual gradients with the methods described above, and then taking the sum[1].\n\nI am taking a sum over N = 1000 elements, and tried different network configurations;\n# D: Dimension of input and of each Layer\n# L: Number of hidden layers\n\nFor a (relatively) wide and shallow network (D, L = 500, 1), I get the following running time\nFull  :  0.04s\nnaive : 15.42s\ngoodf :  4.42s\nmulti :  1.89s\n\nFor a narrower and deeper network (D, L = 100, 10) I get\nFull  :  0.03s\nnaive : 11.40s\ngoodf :  1.70s\nmulti :  1.60s\n\nWhile goodf and multi definitely are improvements on the naive method, they are still ~50 time slower than simply computing the sum. I would not expect any method that stores individual gradients to perform as well as a method that can simply throw them away, but they are essentially doing the same operations so it should be possible to do better.\nWith those numbers, training a small-ish neural network that would normally take ~10 minutes would take 10 hours, making experimentation very difficult.\nFrom the information I have been able to find, it seems difficult to get access to the un-aggregated gradients.\nIt is a bit frustrating to know that the backward pass on the function computes the sum in almost no time, and all that is needed for this feature is a way to intercept elements of this sum.\nA hook that would allow to store individual gradients on the fly in some list or tensor - maybe with the use of those hooks or by defining a new sum function that intercepts gradients - would be amazing, but I do not understand the codebase and/or AD to do it.\nSome pointers in that direction would already be a big help\n[1] Note: I am not looking for an expensive way of computing the sum by computing individual gradients - I am taking the sum in the end so that all methods do the \"same thing\", but what is really needed is the intermediate matrix containing individual gradients", "body": "For some application, I need to get gradients for each elements of a sum.\r\nI am aware that this issue has already been raised previously, in various forms ([here](https://discuss.pytorch.org/t/gradient-w-r-t-each-sample/1433/2), [here](https://discuss.pytorch.org/t/efficient-per-example-gradient-computations/17204), [here](https://discuss.pytorch.org/t/quickly-get-individual-gradients-not-sum-of-gradients-of-all-network-outputs/8405) and possibly related to [here](https://github.com/pytorch/pytorch/issues/1407)) \r\nand has also been raised for other autodifferentiation libraries (some examples for TensorFlow: [here](https://github.com/tensorflow/tensorflow/issues/675), long discussion [here](https://github.com/tensorflow/tensorflow/issues/4897))\r\n\r\nWhile the feature does exists in that there is a way to get the desired output, \r\nI have not found an efficient way of computing it after investing a significant amount of time.\r\n\r\nI am bringing it up again, with some numbers showing the inefficiency of the existing solutions I have been able to find.\r\n\r\nIt is possible that the running time I observed is not an issue with the existing solutions but only with my implementation of them, \r\nor that my attempts have been misguided and that a simpler solution exists.\r\nIf there is a way to make that operation in an efficient way, I would love to know about it.\r\n\r\nI can spend more time working on this issue, but as of now I do not know of a way forward.\r\nThe following contains a description of the desired feature, existing \"workaround\" and some evaluation of their performance.\r\n\r\n---\r\n\r\n## Feature description:\r\n\r\nGiven an objective that is a sum of functions, `f(x) = f_1(x) + ... + f_N(x)`, \r\na _simple to use_ and _efficient_ way to compute the gradient with respect to `x` for each of the individual function `f_n`, i.e., getting\r\n`[\u2207f_1(x), ..., \u2207f_N(x)]`\r\n\r\nIf there already is a way to do so, an example would be very nice.\r\n\r\n(I understand that this would involve additional memory overhead if `N` is large, as pointed out [here](https://discuss.pytorch.org/t/quickly-get-individual-gradients-not-sum-of-gradients-of-all-network-outputs/8405/2) - my setting is not bound by memory but by time)\r\n\r\n## Use case:\r\n- Computing approximate second-order information (Generalized Gauss-Newton type of algorithm).\r\n- Computing gradient statistics such as the variance at a given point.\r\nSome papers based on those ideas: [here](https://pdfs.semanticscholar.org/42e2/1cd78f578fa6ce61b06b99848697da85ed76.pdf), [here](http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf)\r\n\r\n## Existing workarounds:\r\n- The `naive` implementation: do the forward pass in batch up to the last part of the function to minimize overhead, and then call backward on each individual `f_n(x)`.\r\n- Goodfellow showed how to recover the individual gradients from gradients with respect to the activation functions in the case of feed-forward neural networks [here](https://arxiv.org/abs/1510.01799). This requires an additional derivation and performs the linear parts of the transformation in Python instead of C, making it scale badly. \r\n- What I call \"Multiple Models\": Define copies of the parameters `x_1, ..., x_N` and compute `grad(f_1(x_1) + ... + f_N(x_N))`. This ensures that the gradients are not accumulated, however it scales poorly. Adapted from the original formulation [here](https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-290997283)\r\n\r\n\r\n## Evaluation of existing workarounds\r\nI have tried to make the simplest example of a sufficiently complex problem where this becomes an issue.\r\nThe code to reproduce these is available [here](https://github.com/fKunstner/fast-individual-gradients-with-autodiff).\r\n\r\nRunning on a simple Multi-Layer Perceptron, I am comparing the running time of\r\n* `full`: computing the gradient of the full objective function\r\n* `naive`, `goodf`, `multi`: computing the gradient of the sum by first computing individual gradients with the methods described above, and then taking the sum[1].\r\n\r\nI am taking a sum over `N = 1000` elements, and tried different network configurations;\r\n```\r\n# D: Dimension of input and of each Layer\r\n# L: Number of hidden layers\r\n```\r\nFor a (relatively) wide and shallow network (`D, L = 500, 1`), I get the following running time\r\n```\r\nFull  :  0.04s\r\nnaive : 15.42s\r\ngoodf :  4.42s\r\nmulti :  1.89s\r\n```\r\nFor a narrower and deeper network (`D, L = 100, 10`) I get\r\n```\r\nFull  :  0.03s\r\nnaive : 11.40s\r\ngoodf :  1.70s\r\nmulti :  1.60s\r\n```\r\n\r\nWhile `goodf` and `multi` definitely are improvements on the naive method, they are still ~50 time slower than simply computing the sum. I would not expect any method that stores individual gradients to perform as well as a method that can simply throw them away, but they are essentially doing the same operations so it should be possible to do better.\r\nWith those numbers, training a small-ish neural network that would normally take ~10 minutes would take 10 hours, making experimentation very difficult.\r\n\r\nFrom the [information I have been able to find](https://discuss.pytorch.org/t/how-the-hook-works/2222/2), it seems difficult to get access to the un-aggregated gradients.\r\nIt is a bit frustrating to know that the backward pass on the function computes the sum in almost no time, and all that is needed for this feature is a way to intercept elements of this sum.\r\n\r\nA hook that would allow to store individual gradients on the fly in some list or tensor - maybe with the use of those hooks or by defining a new sum function that intercepts gradients - would be amazing, but I do not understand the codebase and/or AD to do it. \r\nSome pointers in that direction would already be a big help\r\n\r\n[1] _Note: I am not looking for an expensive way of computing the sum by computing individual gradients - I am taking the sum in the end so that all methods do the \"same thing\", but what is really needed is the intermediate matrix containing individual gradients_\r\n\r\n\r\n\r\n\r\n"}