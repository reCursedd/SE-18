{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210307256", "pull_request_review_id": 146493783, "id": 210307256, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIxMDMwNzI1Ng==", "diff_hunk": "@@ -0,0 +1,700 @@\n+#include \"ATen/ATen.h\"\n+#include \"ATen/NativeFunctions.h\"\n+\n+namespace at { namespace native {\n+\n+namespace {\n+\n+template<typename T>\n+using pair_of = std::pair<T, T>;\n+\n+template<typename T>\n+using tpair_of = std::tuple<T, T>;\n+\n+// Those could have been function pointers, but MSVC chokes on function pointers as template parameters\n+struct tanh_f {\n+  Tensor operator()(const Tensor& t) const { return at::tanh(t); }\n+};\n+\n+struct relu_f {\n+  Tensor operator()(const Tensor& t) const { return at::relu(t); }\n+};\n+\n+struct PackedSequence {\n+  PackedSequence() = default;\n+  PackedSequence(Tensor _data, Tensor _batch_sizes)\n+    : data(std::move(_data)), batch_sizes(std::move(_batch_sizes)) {}\n+\n+  Tensor data;\n+  Tensor batch_sizes;\n+};\n+\n+// Pretty much all cells we support take the same set of arguments, but threading those\n+// 4 arguments manually is really annoying. Their lifetime is externally managed, so we only\n+// pass this struct of references around.\n+struct CellParams {\n+  CellParams(const Tensor& _w_ih, const Tensor& _w_hh, const Tensor& _b_ih, const Tensor& _b_hh)\n+    : w_ih(_w_ih), w_hh(_w_hh), b_ih(_b_ih), b_hh(_b_hh) {};\n+\n+  const Tensor& w_ih;\n+  const Tensor& w_hh;\n+  const Tensor& b_ih; /* optional */\n+  const Tensor& b_hh; /* optional */\n+};\n+\n+// Gathers every two elements of a vector in a vector of pairs\n+template<typename T>\n+static std::vector<pair_of<T>> pair_vec(const std::vector<T>& vals) {\n+  AT_CHECK(vals.size() % 2 == 0, \"Odd number of params or hiddens given to a bidirectional RNN\");\n+  std::vector<pair_of<T>> result;\n+  result.reserve(vals.size() / 2);\n+  for (int64_t i = 0; i < vals.size(); i += 2) {\n+    result.emplace_back(vals[i], vals[i + 1]);\n+  }\n+  return result;\n+}\n+\n+// Flattens a vector of pairs\n+template<typename T>\n+static std::vector<T> unpair_vec(std::vector<pair_of<T>>&& vals) {\n+  std::vector<T> result;\n+  result.reserve(vals.size() * 2);\n+  for (int64_t i = 0; i < vals.size(); i++) {\n+    result.push_back(std::move(vals[i].first));\n+    result.push_back(std::move(vals[i].second));\n+  }\n+  return result;\n+}\n+\n+// Parses a flat list of parameter tensors into a list of CellParams\n+static std::vector<CellParams> gather_params(TensorList params, bool has_biases) {\n+  static at::Tensor undefined;\n+  std::vector<CellParams> result;\n+  if (has_biases) {\n+    AT_CHECK(params.size() % 4 == 0, \"got an incorrect number of RNN parameters\");\n+    for (size_t i = 0; i < params.size(); i += 4) {\n+      result.emplace_back(params[i], params[i + 1], params[i + 2], params[i + 3]);\n+    }\n+  } else {\n+    AT_CHECK(params.size() % 2 == 0, \"got an incorrect number of RNN parameters\");\n+    for (size_t i = 0; i < params.size(); i += 2) {\n+      result.emplace_back(params[i], params[i + 1], undefined, undefined);\n+    }\n+  }\n+  return result;\n+}\n+\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// HIDDEN STATE FUNCTIONS\n+//\n+// Functions implemented below are implemented as templates based on hidden type,\n+// because they need to work both with simple RNNs and GRU (which use a single Tensor),\n+// as well as with LSTM (or possibly more complicated architectures in the future).\n+// Still, there are some operations that need to be performed on the hidden states\n+// alone, and for this purpose we provide an overloaded set of functions below.\n+\n+Tensor hidden_as_output(const Tensor& t) { return t; }\n+Tensor hidden_as_output(const tpair_of<Tensor>& t) { return std::get<0>(t); }\n+\n+template<size_t index>\n+std::vector<Tensor> project(at::ArrayRef<tpair_of<Tensor>> tuples) {\n+  std::vector<Tensor> result;\n+  result.reserve(tuples.size());\n+  for (auto & t : tuples) {\n+    result.push_back(std::get<index>(t));\n+  }\n+  return result;\n+}\n+\n+Tensor hidden_concat(at::ArrayRef<Tensor> hiddens) { return at::cat(hiddens, 0); }\n+tpair_of<Tensor> hidden_concat(at::ArrayRef<tpair_of<Tensor>> hiddens) {\n+  return std::make_tuple(hidden_concat(project<0>(hiddens)), hidden_concat(project<1>(hiddens)));\n+}\n+\n+Tensor hidden_slice(const Tensor& t, int64_t start, int64_t end) {\n+  return t.narrow(0, start, end - start);\n+}\n+tpair_of<Tensor> hidden_slice(const tpair_of<Tensor>& t, int64_t start, int64_t end) {\n+  return std::make_tuple(hidden_slice(std::get<0>(t), start, end),\n+                         hidden_slice(std::get<1>(t), start, end));\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// CELL IMPLEMENTATIONS\n+//\n+// Cell is a basic component of an RNN, representing a single application of the\n+// recurrent function. You can think of it as a function of signature\n+//\n+// (Tensor input, hidden_type hidden, CellParams) -> hidden_type\n+//\n+// which means that it consumes an input tensor, and updates the previous hidden state.\n+// It's a struct only because functional programming in C++ is a pain, and it's easier\n+// to pass around \"vtable pointers\" than actual function pointers.\n+\n+Tensor linear(const Tensor& input, const Tensor& weight, /* optional */ const Tensor& bias={}) {\n+  if (input.dim() == 2 && bias.defined()) {\n+    // fused op is marginally faster\n+    return at::addmm(bias, input, weight.t());\n+  }\n+\n+  auto output = at::matmul(input, weight.t());\n+  if (bias.defined()) {\n+    output.add_(bias);\n+  }\n+  return output;\n+}\n+\n+template<typename hidden_type_tmpl>\n+struct Cell {\n+  using hidden_type = hidden_type_tmpl;\n+  virtual hidden_type operator()(const Tensor& input, const hidden_type& hidden, const CellParams& params) const = 0;\n+};\n+\n+template<typename nonlinearity>\n+struct SimpleCell : Cell<Tensor> {\n+  hidden_type operator()(const Tensor& input, const hidden_type& hidden, const CellParams& params) const override {\n+    return nonlinearity{}(linear(input, params.w_ih, params.b_ih) + linear(hidden, params.w_hh, params.b_hh));\n+  }\n+};\n+\n+// TODO: can use inplace ops?\n+struct LSTMCell : Cell<std::tuple<Tensor, Tensor>> {\n+  hidden_type operator()(const Tensor& input, const hidden_type& hidden, const CellParams& params) const override {\n+    auto hx = std::get<0>(hidden);\n+    auto cx = std::get<1>(hidden);\n+\n+    if (input.is_cuda()) {\n+      auto igates = at::matmul(input, params.w_ih.t());\n+      auto hgates = at::matmul(hx, params.w_hh.t());\n+      auto result = at::_thnn_fused_lstm_cell(igates, hgates, cx, params.b_ih, params.b_hh);\n+      // Slice off the workspace argument (it's needed only for AD).\n+      return std::make_tuple(std::get<0>(result), std::get<1>(result));\n+    }\n+\n+    auto gates = linear(input, params.w_ih, params.b_ih) + linear(hx, params.w_hh, params.b_hh);\n+    auto chunked_gates = gates.chunk(4, 1);\n+\n+    auto ingate = chunked_gates[0].sigmoid();\n+    auto forgetgate = chunked_gates[1].sigmoid();\n+    auto cellgate = chunked_gates[2].tanh();\n+    auto outgate = chunked_gates[3].sigmoid();\n+\n+    auto cy = (forgetgate * cx) + (ingate * cellgate);\n+    auto hy = outgate * cy.tanh();\n+\n+    return std::make_tuple(hy, cy);\n+  }\n+};\n+\n+struct GRUCell : Cell<Tensor> {\n+  hidden_type operator()(const Tensor& input, const hidden_type& hidden, const CellParams& params) const override {\n+    if (input.is_cuda()) {\n+      auto igates = at::matmul(input, params.w_ih.t());\n+      auto hgates = at::matmul(hidden, params.w_hh.t());\n+      auto result = at::_thnn_fused_gru_cell(igates, hgates, hidden, params.b_ih, params.b_hh);\n+      // Slice off the workspace argument (it's needed only for AD).\n+      return std::get<0>(result);\n+    }\n+\n+    auto igates = linear(input, params.w_ih, params.b_ih);\n+    auto hgates = linear(hidden, params.w_hh, params.b_hh);\n+    auto chunked_igates = igates.chunk(3, 1);\n+    auto chunked_hgates = hgates.chunk(3, 1);\n+\n+    auto reset_gate = at::sigmoid(chunked_igates[0] + chunked_hgates[0]);\n+    auto input_gate = at::sigmoid(chunked_igates[1] + chunked_hgates[1]);\n+    auto new_gate = at::tanh(chunked_igates[2] + reset_gate * chunked_hgates[2]);\n+\n+    return new_gate + input_gate * (hidden - new_gate);\n+  }\n+};\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// LAYER IMPLEMENTATIONS\n+//\n+// Layers are scan-like higher-order functions, which take in cells, and\n+// transform them to fuctions of signature\n+//\n+// (io_type input, hidden_type hidden, param_type params) -> (io_type, hidden_type)\n+//\n+// which can apply the cell over a sequence of inputs, and produce both a new set\n+// of hidden states, as well as a concatenated output of each step.\n+\n+template<typename output_type, typename hidden_type>\n+struct LayerOutput {\n+  output_type outputs;\n+  hidden_type final_hidden;\n+};\n+\n+template<typename io_type, typename hidden_type, typename param_type>\n+struct Layer {\n+  using output_type = LayerOutput<io_type, hidden_type>;\n+  virtual output_type operator()(const io_type& input, const hidden_type& input_hidden, const param_type& params) const = 0;\n+};\n+\n+template<typename hidden_type>\n+struct FullLayer : Layer<Tensor, hidden_type, CellParams> {", "path": "aten/src/ATen/native/RNN.cpp", "position": 239, "original_position": 237, "commit_id": "bb5fc94a73109344648bd957b2b82664b1cf9d64", "original_commit_id": "6e28112ad6c358c1240e170485f9a4913aa29607", "user": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "body": "I don't think there's any standard nomenclature... I can change the name if you have better ideas. Essentially it's a non-packed layer, but that sounds awful \ud83d\ude04 ", "created_at": "2018-08-15T15:26:53Z", "updated_at": "2018-11-23T15:49:25Z", "html_url": "https://github.com/pytorch/pytorch/pull/10481#discussion_r210307256", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/10481", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/210307256"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/10481#discussion_r210307256"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/10481"}}, "body_html": "<p>I don't think there's any standard nomenclature... I can change the name if you have better ideas. Essentially it's a non-packed layer, but that sounds awful <g-emoji class=\"g-emoji\" alias=\"smile\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f604.png\">\ud83d\ude04</g-emoji></p>", "body_text": "I don't think there's any standard nomenclature... I can change the name if you have better ideas. Essentially it's a non-packed layer, but that sounds awful \ud83d\ude04", "in_reply_to_id": 210098317}