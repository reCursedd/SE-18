{"url": "https://api.github.com/repos/pytorch/pytorch/issues/828", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/828/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/828/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/828/events", "html_url": "https://github.com/pytorch/pytorch/issues/828", "id": 209580426, "node_id": "MDU6SXNzdWUyMDk1ODA0MjY=", "number": 828, "title": "backward() in Autograd Index Function is broken when indexing with LongTensor", "user": {"login": "BarclayII", "id": 2978100, "node_id": "MDQ6VXNlcjI5NzgxMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2978100?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BarclayII", "html_url": "https://github.com/BarclayII", "followers_url": "https://api.github.com/users/BarclayII/followers", "following_url": "https://api.github.com/users/BarclayII/following{/other_user}", "gists_url": "https://api.github.com/users/BarclayII/gists{/gist_id}", "starred_url": "https://api.github.com/users/BarclayII/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BarclayII/subscriptions", "organizations_url": "https://api.github.com/users/BarclayII/orgs", "repos_url": "https://api.github.com/users/BarclayII/repos", "events_url": "https://api.github.com/users/BarclayII/events{/privacy}", "received_events_url": "https://api.github.com/users/BarclayII/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 424131847, "node_id": "MDU6TGFiZWw0MjQxMzE4NDc=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/bug", "name": "bug", "color": "b60205", "default": true}, {"id": 443484135, "node_id": "MDU6TGFiZWw0NDM0ODQxMzU=", "url": "https://api.github.com/repos/pytorch/pytorch/labels/high%20priority", "name": "high priority", "color": "F22613", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "apaszke", "id": 4583066, "node_id": "MDQ6VXNlcjQ1ODMwNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/4583066?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apaszke", "html_url": "https://github.com/apaszke", "followers_url": "https://api.github.com/users/apaszke/followers", "following_url": "https://api.github.com/users/apaszke/following{/other_user}", "gists_url": "https://api.github.com/users/apaszke/gists{/gist_id}", "starred_url": "https://api.github.com/users/apaszke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apaszke/subscriptions", "organizations_url": "https://api.github.com/users/apaszke/orgs", "repos_url": "https://api.github.com/users/apaszke/repos", "events_url": "https://api.github.com/users/apaszke/events{/privacy}", "received_events_url": "https://api.github.com/users/apaszke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-02-22T21:04:16Z", "updated_at": "2017-02-26T19:36:32Z", "closed_at": "2017-02-26T19:36:32Z", "author_association": "NONE", "body_html": "<p>In <code>torch/autograd/_functions/tensor.py:20</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">backward</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">grad_output</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: this won't have to be zeroed</span>\n        grad_input <span class=\"pl-k\">=</span> grad_output.new(<span class=\"pl-c1\">self</span>.input_size).zero_()\n        grad_input.index(<span class=\"pl-c1\">self</span>.index).copy_(grad_output)\n        <span class=\"pl-k\">return</span> grad_input</pre></div>\n<p>I think the index-copy statement doesn't work as intended.</p>\n<pre><code>In [15]: a = torch.zeros((3, 5))\n\nIn [16]: a\nOut[16]: \n\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n[torch.FloatTensor of size 3x5]\n\nIn [17]: b = torch.ones((2, 5))\n\nIn [18]: a.index(torch.LongTensor([0, 2])).copy_(b)\nOut[18]: \n\n 1  1  1  1  1\n 1  1  1  1  1\n[torch.FloatTensor of size 2x5]\n\nIn [19]: a\nOut[19]: \n\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n[torch.FloatTensor of size 3x5]\n</code></pre>\n<p>I guess the statement should be something like</p>\n<div class=\"highlight highlight-source-python\"><pre>        grad_input.index_copy_(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">self</span>.index, grad_output)</pre></div>", "body_text": "In torch/autograd/_functions/tensor.py:20:\n    def backward(self, grad_output):\n        # TODO: this won't have to be zeroed\n        grad_input = grad_output.new(self.input_size).zero_()\n        grad_input.index(self.index).copy_(grad_output)\n        return grad_input\nI think the index-copy statement doesn't work as intended.\nIn [15]: a = torch.zeros((3, 5))\n\nIn [16]: a\nOut[16]: \n\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n[torch.FloatTensor of size 3x5]\n\nIn [17]: b = torch.ones((2, 5))\n\nIn [18]: a.index(torch.LongTensor([0, 2])).copy_(b)\nOut[18]: \n\n 1  1  1  1  1\n 1  1  1  1  1\n[torch.FloatTensor of size 2x5]\n\nIn [19]: a\nOut[19]: \n\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n[torch.FloatTensor of size 3x5]\n\nI guess the statement should be something like\n        grad_input.index_copy_(0, self.index, grad_output)", "body": "In `torch/autograd/_functions/tensor.py:20`:\r\n```python\r\n    def backward(self, grad_output):\r\n        # TODO: this won't have to be zeroed\r\n        grad_input = grad_output.new(self.input_size).zero_()\r\n        grad_input.index(self.index).copy_(grad_output)\r\n        return grad_input\r\n```\r\n\r\nI think the index-copy statement doesn't work as intended.\r\n```\r\nIn [15]: a = torch.zeros((3, 5))\r\n\r\nIn [16]: a\r\nOut[16]: \r\n\r\n 0  0  0  0  0\r\n 0  0  0  0  0\r\n 0  0  0  0  0\r\n[torch.FloatTensor of size 3x5]\r\n\r\nIn [17]: b = torch.ones((2, 5))\r\n\r\nIn [18]: a.index(torch.LongTensor([0, 2])).copy_(b)\r\nOut[18]: \r\n\r\n 1  1  1  1  1\r\n 1  1  1  1  1\r\n[torch.FloatTensor of size 2x5]\r\n\r\nIn [19]: a\r\nOut[19]: \r\n\r\n 0  0  0  0  0\r\n 0  0  0  0  0\r\n 0  0  0  0  0\r\n[torch.FloatTensor of size 3x5]\r\n```\r\n\r\nI guess the statement should be something like\r\n```python\r\n        grad_input.index_copy_(0, self.index, grad_output)\r\n```"}