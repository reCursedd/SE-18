{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143906894", "pull_request_review_id": 68486481, "id": 143906894, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0MzkwNjg5NA==", "diff_hunk": "@@ -551,6 +551,81 @@ def __repr__(self):\n         tmpstr = tmpstr + ')'\n         return tmpstr\n \n+    def summary(self, input_size):\n+        def register_hook(module):\n+            def hook(module, input, output):\n+                class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n+                module_idx = len(summary)\n+                m_key = '%s-%i' % (class_name, module_idx + 1)\n+                summary[m_key] = OrderedDict()\n+                summary[m_key]['input_shape'] = list(input[0].size())\n+                summary[m_key]['input_shape'][0] = None\n+                summary[m_key]['output_shape'] = list(output.size())\n+                summary[m_key]['output_shape'][0] = None\n+\n+                params = 0\n+                # iterate through parameters and count num params\n+                for name, p in module._parameters.items():\n+                    params += torch.numel(p.data)\n+                    if p.requires_grad:\n+                        summary[m_key]['trainable'] = True\n+                    else:\n+                        summary[m_key]['trainable'] = False\n+\n+                summary[m_key]['nb_params'] = params\n+\n+            if not isinstance(module, torch.nn.Sequential) and \\\n+               not isinstance(module, torch.nn.ModuleList) and \\\n+               not (module == self):\n+                hooks.append(module.register_forward_hook(hook))\n+\n+        # check if there are multiple inputs to the network\n+        if isinstance(input_size[0], (list, tuple)):\n+            x = [Variable(torch.rand(1, *in_size)) for in_size in input_size]\n+        else:\n+            x = Variable(torch.randn(1, *input_size))\n+\n+        # create properties\n+        summary = OrderedDict()\n+        hooks = []\n+        # register hook\n+        self.apply(register_hook)\n+        # make a forward pass\n+        self(x)\n+        # remove these hooks\n+        for h in hooks:\n+            h.remove()\n+\n+        # print out neatly\n+        names = list(self._modules.keys())\n+        col_width = 25  # should be >= 12\n+        summary_width = 61\n+\n+        def crop(s):\n+            return s[:col_width] if len(s) > col_width else s\n+\n+        print('_' * summary_width)\n+        print('{0: <{3}} {1: <{3}} {2: <{3}}'.format(\n+            'Layer (type)', 'Output Shape', 'Param #', col_width))\n+        print('=' * summary_width)\n+        total_params = 0\n+        trainable_params = 0\n+        for (i, l_type), l_name in zip(enumerate(summary), names):", "path": "torch/nn/modules/module.py", "position": 74, "original_position": 63, "commit_id": "b7b04c276b0cf406e327d1192f61489b78267488", "original_commit_id": "b3af05aad38f53f0b67713f1313537d16f0479b7", "user": {"login": "isaykatsman", "id": 10509755, "node_id": "MDQ6VXNlcjEwNTA5NzU1", "avatar_url": "https://avatars1.githubusercontent.com/u/10509755?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isaykatsman", "html_url": "https://github.com/isaykatsman", "followers_url": "https://api.github.com/users/isaykatsman/followers", "following_url": "https://api.github.com/users/isaykatsman/following{/other_user}", "gists_url": "https://api.github.com/users/isaykatsman/gists{/gist_id}", "starred_url": "https://api.github.com/users/isaykatsman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isaykatsman/subscriptions", "organizations_url": "https://api.github.com/users/isaykatsman/orgs", "repos_url": "https://api.github.com/users/isaykatsman/repos", "events_url": "https://api.github.com/users/isaykatsman/events{/privacy}", "received_events_url": "https://api.github.com/users/isaykatsman/received_events", "type": "User", "site_admin": false}, "body": "I see. I fixed the issue - I recursively go down to the layers now. To avoid a confusing output, I do not display a separate layer row for container modules, but simply prefix the container name (in this case `mod`) before the actual layers themselves. The summary of the model you posted above is displayed as:\r\n\r\n![Summary](https://i.imgur.com/nKva1Kq.png)", "created_at": "2017-10-11T03:53:18Z", "updated_at": "2018-11-23T15:35:13Z", "html_url": "https://github.com/pytorch/pytorch/pull/3043#discussion_r143906894", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/3043", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/143906894"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/3043#discussion_r143906894"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/3043"}}, "body_html": "<p>I see. I fixed the issue - I recursively go down to the layers now. To avoid a confusing output, I do not display a separate layer row for container modules, but simply prefix the container name (in this case <code>mod</code>) before the actual layers themselves. The summary of the model you posted above is displayed as:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/cb1b01bc9869ad94d2c1ca745b9e51ec2866207b/68747470733a2f2f692e696d6775722e636f6d2f6e4b7661314b712e706e67\"><img src=\"https://camo.githubusercontent.com/cb1b01bc9869ad94d2c1ca745b9e51ec2866207b/68747470733a2f2f692e696d6775722e636f6d2f6e4b7661314b712e706e67\" alt=\"Summary\" data-canonical-src=\"https://i.imgur.com/nKva1Kq.png\" style=\"max-width:100%;\"></a></p>", "body_text": "I see. I fixed the issue - I recursively go down to the layers now. To avoid a confusing output, I do not display a separate layer row for container modules, but simply prefix the container name (in this case mod) before the actual layers themselves. The summary of the model you posted above is displayed as:", "in_reply_to_id": 143834449}