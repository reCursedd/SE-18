{"url": "https://api.github.com/repos/pytorch/pytorch/issues/comments/359671061", "html_url": "https://github.com/pytorch/pytorch/pull/3043#issuecomment-359671061", "issue_url": "https://api.github.com/repos/pytorch/pytorch/issues/3043", "id": 359671061, "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTY3MTA2MQ==", "user": {"login": "tianq01", "id": 9604700, "node_id": "MDQ6VXNlcjk2MDQ3MDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9604700?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tianq01", "html_url": "https://github.com/tianq01", "followers_url": "https://api.github.com/users/tianq01/followers", "following_url": "https://api.github.com/users/tianq01/following{/other_user}", "gists_url": "https://api.github.com/users/tianq01/gists{/gist_id}", "starred_url": "https://api.github.com/users/tianq01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tianq01/subscriptions", "organizations_url": "https://api.github.com/users/tianq01/orgs", "repos_url": "https://api.github.com/users/tianq01/repos", "events_url": "https://api.github.com/users/tianq01/events{/privacy}", "received_events_url": "https://api.github.com/users/tianq01/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-23T04:12:27Z", "updated_at": "2018-01-23T04:18:14Z", "author_association": "NONE", "body_html": "<p>hi<br>\nThanks for the code, I believe getting intput/output shape is extremely important to understand and debug the network, <strong>especially when other frameworks(tf, keras, caffe, etc)  already support it well.</strong></p>\n<p>the proposed code could be used as a workaround only since modules have different implementation.<br>\nin my case, the code works for CNN layers well, but not for LSTM/RNN:<br>\n1)RNN.bias is a bool,  its weights and bias are  in module attributes whose names are stored in RNN._all_weights</p>\n<p>2)output is a tuple, so need to recursively get the output size. see below code:<br>\n`<br>\nsummary[m_key] = get_output_size(summary[m_key], output)</p>\n<p>def get_output_size(summary_dict, output):<br>\nif isinstance(output, tuple):<br>\nfor i in xrange(len(output)):<br>\nsummary_dict[i] = OrderedDict()<br>\nsummary_dict[i] = get_output_size(summary_dict[i],output[i])<br>\nreturn summary_dict<br>\nelse:<br>\nsummary_dict['output_shape'] = list(output.size())<br>\nsummary_dict['output_shape'][0] = -1<br>\nreturn summary_dict<br>\n`</p>\n<p>since I just need to get the shape in my case at the point, I donot dig it further. considering the fact mentioned above, agree with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3186211\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Erotemic\">@Erotemic</a> that the input/output shape should be got in house.<br>\nthanks!</p>\n<hr>\n<p>update:sorry for the bad format. the 'insert code' looks not working ...</p>", "body_text": "hi\nThanks for the code, I believe getting intput/output shape is extremely important to understand and debug the network, especially when other frameworks(tf, keras, caffe, etc)  already support it well.\nthe proposed code could be used as a workaround only since modules have different implementation.\nin my case, the code works for CNN layers well, but not for LSTM/RNN:\n1)RNN.bias is a bool,  its weights and bias are  in module attributes whose names are stored in RNN._all_weights\n2)output is a tuple, so need to recursively get the output size. see below code:\n`\nsummary[m_key] = get_output_size(summary[m_key], output)\ndef get_output_size(summary_dict, output):\nif isinstance(output, tuple):\nfor i in xrange(len(output)):\nsummary_dict[i] = OrderedDict()\nsummary_dict[i] = get_output_size(summary_dict[i],output[i])\nreturn summary_dict\nelse:\nsummary_dict['output_shape'] = list(output.size())\nsummary_dict['output_shape'][0] = -1\nreturn summary_dict\n`\nsince I just need to get the shape in my case at the point, I donot dig it further. considering the fact mentioned above, agree with @Erotemic that the input/output shape should be got in house.\nthanks!\n\nupdate:sorry for the bad format. the 'insert code' looks not working ...", "body": "hi\r\nThanks for the code, I believe getting intput/output shape is extremely important to understand and debug the network, **especially when other frameworks(tf, keras, caffe, etc)  already support it well.**\r\n\r\nthe proposed code could be used as a workaround only since modules have different implementation.\r\nin my case, the code works for CNN layers well, but not for LSTM/RNN:\r\n1)RNN.bias is a bool,  its weights and bias are  in module attributes whose names are stored in RNN._all_weights\r\n\r\n2)output is a tuple, so need to recursively get the output size. see below code:\r\n`\r\nsummary[m_key] = get_output_size(summary[m_key], output)\r\n\r\ndef get_output_size(summary_dict, output):\r\n  if isinstance(output, tuple):\r\n    for i in xrange(len(output)):\r\n      summary_dict[i] = OrderedDict()\r\n      summary_dict[i] = get_output_size(summary_dict[i],output[i])\r\n    return summary_dict\r\n  else:\r\n    summary_dict['output_shape'] = list(output.size())\r\n    summary_dict['output_shape'][0] = -1\r\n    return summary_dict\r\n`\r\n\r\nsince I just need to get the shape in my case at the point, I donot dig it further. considering the fact mentioned above, agree with @Erotemic that the input/output shape should be got in house. \r\nthanks!\r\n\r\n\r\n----\r\nupdate:sorry for the bad format. the 'insert code' looks not working ...\r\n"}