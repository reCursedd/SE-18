{"url": "https://api.github.com/repos/pytorch/pytorch/issues/817", "repository_url": "https://api.github.com/repos/pytorch/pytorch", "labels_url": "https://api.github.com/repos/pytorch/pytorch/issues/817/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/pytorch/issues/817/comments", "events_url": "https://api.github.com/repos/pytorch/pytorch/issues/817/events", "html_url": "https://github.com/pytorch/pytorch/issues/817", "id": 209310116, "node_id": "MDU6SXNzdWUyMDkzMTAxMTY=", "number": 817, "title": "Error when using numpy arrays created inside the forward function", "user": {"login": "cresteban", "id": 22841204, "node_id": "MDQ6VXNlcjIyODQxMjA0", "avatar_url": "https://avatars1.githubusercontent.com/u/22841204?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cresteban", "html_url": "https://github.com/cresteban", "followers_url": "https://api.github.com/users/cresteban/followers", "following_url": "https://api.github.com/users/cresteban/following{/other_user}", "gists_url": "https://api.github.com/users/cresteban/gists{/gist_id}", "starred_url": "https://api.github.com/users/cresteban/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cresteban/subscriptions", "organizations_url": "https://api.github.com/users/cresteban/orgs", "repos_url": "https://api.github.com/users/cresteban/repos", "events_url": "https://api.github.com/users/cresteban/events{/privacy}", "received_events_url": "https://api.github.com/users/cresteban/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-21T23:54:21Z", "updated_at": "2017-02-22T00:18:29Z", "closed_at": "2017-02-22T00:11:06Z", "author_association": "NONE", "body_html": "<p>Hi,</p>\n<p>I try to use an numpy array within the forward function, but it raises an error. Should I be able to do it?</p>\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch\n\nnum_p = 30\nnum_s = 60\nnum_outputs = 10\n\nnum_hl_se = 10\nrank_el_se = 10\nrank_ss = 10\n\nnum_hl_class = 10\n\nclass Net(nn.Module):\n    def __init__(self, num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs):\n        super(Net, self).__init__()\n        self.se0   = nn.Linear(num_p, rank_el_se)\n        self.se1   = nn.Linear(rank_el_se, num_hl_se)\n        self.se2   = nn.Linear(num_hl_se, rank_ss)\n        self.cl1   = nn.Linear(rank_ss, num_hl_class)\n        self.cl2   = nn.Linear(num_hl_class, num_outputs)\n\n    def forward(self, x):\n\n        A = np.random.rand(60, num_p)\n        A = torch.from_numpy(A)\n        VA = Variable(A, requires_grad=False)\n        # if instead I use torch.random, then it works\n        #VA = Variable(torch.rand(60, num_p), requires_grad=False)\n        o = self.se0(VA)\n        o = F.sigmoid(self.se1(o))\n        o = F.sigmoid(self.se2(o))\n        x = o.mul(x)\n        x = F.sigmoid(self.cl1(o))\n        x = F.sigmoid(self.cl2(o))\n            \n        return x\n    \ns_cl = Net(num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs)\ns_cl.forward(Variable(torch.rand(10, num_s)))\n</code></pre>\n<p>The error I get is:</p>\n<pre><code>TypeError: addmm_ received an invalid combination of arguments - got (int, int, torch.DoubleTensor, torch.FloatTensor), but expected one of:\n * (torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n</code></pre>\n<p>If I replace the numpy random with a torch random, then it works without error.</p>\n<p>Thanks for your help</p>", "body_text": "Hi,\nI try to use an numpy array within the forward function, but it raises an error. Should I be able to do it?\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch\n\nnum_p = 30\nnum_s = 60\nnum_outputs = 10\n\nnum_hl_se = 10\nrank_el_se = 10\nrank_ss = 10\n\nnum_hl_class = 10\n\nclass Net(nn.Module):\n    def __init__(self, num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs):\n        super(Net, self).__init__()\n        self.se0   = nn.Linear(num_p, rank_el_se)\n        self.se1   = nn.Linear(rank_el_se, num_hl_se)\n        self.se2   = nn.Linear(num_hl_se, rank_ss)\n        self.cl1   = nn.Linear(rank_ss, num_hl_class)\n        self.cl2   = nn.Linear(num_hl_class, num_outputs)\n\n    def forward(self, x):\n\n        A = np.random.rand(60, num_p)\n        A = torch.from_numpy(A)\n        VA = Variable(A, requires_grad=False)\n        # if instead I use torch.random, then it works\n        #VA = Variable(torch.rand(60, num_p), requires_grad=False)\n        o = self.se0(VA)\n        o = F.sigmoid(self.se1(o))\n        o = F.sigmoid(self.se2(o))\n        x = o.mul(x)\n        x = F.sigmoid(self.cl1(o))\n        x = F.sigmoid(self.cl2(o))\n            \n        return x\n    \ns_cl = Net(num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs)\ns_cl.forward(Variable(torch.rand(10, num_s)))\n\nThe error I get is:\nTypeError: addmm_ received an invalid combination of arguments - got (int, int, torch.DoubleTensor, torch.FloatTensor), but expected one of:\n * (torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\n * (float beta, float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\n\nIf I replace the numpy random with a torch random, then it works without error.\nThanks for your help", "body": "Hi,\r\n\r\nI try to use an numpy array within the forward function, but it raises an error. Should I be able to do it?\r\n\r\n```\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\nimport numpy as np\r\nimport torch\r\n\r\nnum_p = 30\r\nnum_s = 60\r\nnum_outputs = 10\r\n\r\nnum_hl_se = 10\r\nrank_el_se = 10\r\nrank_ss = 10\r\n\r\nnum_hl_class = 10\r\n\r\nclass Net(nn.Module):\r\n    def __init__(self, num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs):\r\n        super(Net, self).__init__()\r\n        self.se0   = nn.Linear(num_p, rank_el_se)\r\n        self.se1   = nn.Linear(rank_el_se, num_hl_se)\r\n        self.se2   = nn.Linear(num_hl_se, rank_ss)\r\n        self.cl1   = nn.Linear(rank_ss, num_hl_class)\r\n        self.cl2   = nn.Linear(num_hl_class, num_outputs)\r\n\r\n    def forward(self, x):\r\n\r\n        A = np.random.rand(60, num_p)\r\n        A = torch.from_numpy(A)\r\n        VA = Variable(A, requires_grad=False)\r\n        # if instead I use torch.random, then it works\r\n        #VA = Variable(torch.rand(60, num_p), requires_grad=False)\r\n        o = self.se0(VA)\r\n        o = F.sigmoid(self.se1(o))\r\n        o = F.sigmoid(self.se2(o))\r\n        x = o.mul(x)\r\n        x = F.sigmoid(self.cl1(o))\r\n        x = F.sigmoid(self.cl2(o))\r\n            \r\n        return x\r\n    \r\ns_cl = Net(num_p, rank_el_se, num_hl_se, rank_ss, num_hl_class, num_outputs)\r\ns_cl.forward(Variable(torch.rand(10, num_s)))\r\n```\r\n\r\nThe error I get is:\r\n```\r\nTypeError: addmm_ received an invalid combination of arguments - got (int, int, torch.DoubleTensor, torch.FloatTensor), but expected one of:\r\n * (torch.DoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float beta, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float beta, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float beta, float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2)\r\n * (float beta, float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2)\r\n```\r\n\r\nIf I replace the numpy random with a torch random, then it works without error.\r\n\r\nThanks for your help"}