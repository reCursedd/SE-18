{"url": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/164575294", "pull_request_review_id": 92369732, "id": 164575294, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2NDU3NTI5NA==", "diff_hunk": "@@ -495,6 +495,8 @@ def get_suffix(dynamic_type, is_nullable):\n             return '_opt'\n         elif dynamic_type == 'IndexTensor':\n             return '_long'\n+        elif dynamic_type == 'IntegerTensor':", "path": "tools/autograd/gen_variable_type.py", "position": 4, "original_position": 4, "commit_id": "1a14d424554044a540d82ae56df8c53336d98753", "original_commit_id": "1a14d424554044a540d82ae56df8c53336d98753", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "body": "The `IntegerTensor` I believe was only necessary because of the behavior of `LookupTable` from `nn`, which returned [counts as `int` instead of `long`](https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/LookupTable.c#L30). The original motivation was to have a single header that could work for both CPU and CUDA, so we could write the headers with `THTensor` and `THIndexTensor` and they would be replaced by the corresponding types depending on the device.\r\nSome discussion about it can be found in https://github.com/torch/nn/pull/549", "created_at": "2018-01-29T21:49:39Z", "updated_at": "2018-11-23T15:38:42Z", "html_url": "https://github.com/pytorch/pytorch/pull/4883#discussion_r164575294", "pull_request_url": "https://api.github.com/repos/pytorch/pytorch/pulls/4883", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/comments/164575294"}, "html": {"href": "https://github.com/pytorch/pytorch/pull/4883#discussion_r164575294"}, "pull_request": {"href": "https://api.github.com/repos/pytorch/pytorch/pulls/4883"}}, "body_html": "<p>The <code>IntegerTensor</code> I believe was only necessary because of the behavior of <code>LookupTable</code> from <code>nn</code>, which returned <a href=\"https://github.com/pytorch/pytorch/blob/master/aten/src/THNN/generic/LookupTable.c#L30\">counts as <code>int</code> instead of <code>long</code></a>. The original motivation was to have a single header that could work for both CPU and CUDA, so we could write the headers with <code>THTensor</code> and <code>THIndexTensor</code> and they would be replaced by the corresponding types depending on the device.<br>\nSome discussion about it can be found in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"124988378\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/torch/nn/issues/549\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/torch/nn/pull/549/hovercard\" href=\"https://github.com/torch/nn/pull/549\">torch/nn#549</a></p>", "body_text": "The IntegerTensor I believe was only necessary because of the behavior of LookupTable from nn, which returned counts as int instead of long. The original motivation was to have a single header that could work for both CPU and CUDA, so we could write the headers with THTensor and THIndexTensor and they would be replaced by the corresponding types depending on the device.\nSome discussion about it can be found in torch/nn#549", "in_reply_to_id": 164461939}