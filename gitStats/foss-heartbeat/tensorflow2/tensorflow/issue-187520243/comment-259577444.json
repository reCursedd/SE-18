{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/259577444", "html_url": "https://github.com/tensorflow/tensorflow/issues/5416#issuecomment-259577444", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5416", "id": 259577444, "node_id": "MDEyOklzc3VlQ29tbWVudDI1OTU3NzQ0NA==", "user": {"login": "raphtown", "id": 177576, "node_id": "MDQ6VXNlcjE3NzU3Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/177576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raphtown", "html_url": "https://github.com/raphtown", "followers_url": "https://api.github.com/users/raphtown/followers", "following_url": "https://api.github.com/users/raphtown/following{/other_user}", "gists_url": "https://api.github.com/users/raphtown/gists{/gist_id}", "starred_url": "https://api.github.com/users/raphtown/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raphtown/subscriptions", "organizations_url": "https://api.github.com/users/raphtown/orgs", "repos_url": "https://api.github.com/users/raphtown/repos", "events_url": "https://api.github.com/users/raphtown/events{/privacy}", "received_events_url": "https://api.github.com/users/raphtown/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-10T01:30:30Z", "updated_at": "2016-11-10T01:30:30Z", "author_association": "NONE", "body_html": "<p>Hello <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11547801\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/prb12\">@prb12</a>, I think I see what you are saying.  When we enqueue GPU1's read of a convolution layer's weights (in this case, from GPU0), it must wait for all of GPU0's previously enqueued ops to finish.</p>\n<p>I can see even in my \"parallel\" cases (such as the first screenshot above) that some of the later GPU1 reads are delayed and wait for GPU0 to finish a couple conv layers, but this is not an issue because GPU1 has enough computation to do in the mean time.</p>\n<p>The nodes I am using have 16 CPUs for 8 GPUs, so I assume this problem will not completely go away but will most likely be minimized for now.</p>\n<p>Thank you for being so responsive!</p>", "body_text": "Hello @prb12, I think I see what you are saying.  When we enqueue GPU1's read of a convolution layer's weights (in this case, from GPU0), it must wait for all of GPU0's previously enqueued ops to finish.\nI can see even in my \"parallel\" cases (such as the first screenshot above) that some of the later GPU1 reads are delayed and wait for GPU0 to finish a couple conv layers, but this is not an issue because GPU1 has enough computation to do in the mean time.\nThe nodes I am using have 16 CPUs for 8 GPUs, so I assume this problem will not completely go away but will most likely be minimized for now.\nThank you for being so responsive!", "body": "Hello @prb12, I think I see what you are saying.  When we enqueue GPU1's read of a convolution layer's weights (in this case, from GPU0), it must wait for all of GPU0's previously enqueued ops to finish.  \n\nI can see even in my \"parallel\" cases (such as the first screenshot above) that some of the later GPU1 reads are delayed and wait for GPU0 to finish a couple conv layers, but this is not an issue because GPU1 has enough computation to do in the mean time.\n\nThe nodes I am using have 16 CPUs for 8 GPUs, so I assume this problem will not completely go away but will most likely be minimized for now.\n\nThank you for being so responsive!\n"}