{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5416", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5416/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5416/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5416/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5416", "id": 187520243, "node_id": "MDU6SXNzdWUxODc1MjAyNDM=", "number": 5416, "title": "Possible Bug - Varying session run times when parallelized across GPUs on one node", "user": {"login": "raphtown", "id": 177576, "node_id": "MDQ6VXNlcjE3NzU3Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/177576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raphtown", "html_url": "https://github.com/raphtown", "followers_url": "https://api.github.com/users/raphtown/followers", "following_url": "https://api.github.com/users/raphtown/following{/other_user}", "gists_url": "https://api.github.com/users/raphtown/gists{/gist_id}", "starred_url": "https://api.github.com/users/raphtown/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raphtown/subscriptions", "organizations_url": "https://api.github.com/users/raphtown/orgs", "repos_url": "https://api.github.com/users/raphtown/repos", "events_url": "https://api.github.com/users/raphtown/events{/privacy}", "received_events_url": "https://api.github.com/users/raphtown/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2016-11-05T20:11:31Z", "updated_at": "2017-06-16T22:21:33Z", "closed_at": "2017-06-16T22:21:33Z", "author_association": "NONE", "body_html": "<p>Hello tensorflow team!</p>\n<p>I have been trying to parallelize my 3D convolution network across 2 GPUs on the same node (using data parallelism), and have found that some of my session runs took significantly longer than others.  Upon closer investigation using your timeline feature, I found that sometimes GPU1 would wait a certain amount of time before starting to run its convolutions even as GPU0 was happily chugging along. In the most extreme case, execution would happen essentially sequentially, doubling my runtime!</p>\n<p>I am attaching screenshots of my timelines from three sessions to show you what I mean...</p>\n<p>In the first one, everything is fine, it is executing both towers in parallel:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/177576/20033120/cc17df8c-a356-11e6-8ef3-55cfdeb9d244.png\"><img src=\"https://cloud.githubusercontent.com/assets/177576/20033120/cc17df8c-a356-11e6-8ef3-55cfdeb9d244.png\" alt=\"run55\" style=\"max-width:100%;\"></a><br>\nIn the second, I see the \"sequential\" behaviour:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/177576/20033121/cd4d9e96-a356-11e6-8ef1-091edd981fdf.png\"><img src=\"https://cloud.githubusercontent.com/assets/177576/20033121/cd4d9e96-a356-11e6-8ef1-091edd981fdf.png\" alt=\"run56\" style=\"max-width:100%;\"></a><br>\nIn the last one, I see something in between:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/177576/20033136/2b7f68b4-a357-11e6-9eb5-92f9a30a5fa3.png\"><img src=\"https://cloud.githubusercontent.com/assets/177576/20033136/2b7f68b4-a357-11e6-9eb5-92f9a30a5fa3.png\" alt=\"run30\" style=\"max-width:100%;\"></a></p>\n<p>I know this happens even when I am not logging metadata because I still see a large spread of runtime distributions without logging on (see parallel-nometadata.txt at the bottom).  Also, dumping the GraphDef proto at each step tells me that the ops are correctly assigned to the different GPUs (I have attached those, as well as my timeline files, at the bottom).</p>\n<p>I actually briefly talked about this with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> in person a little over a week ago, and we did not find anything obviously wrong at first glance.  Any help you could provide would be much appreciated!</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I have not found any related Github or StackOverflow threads.  I have been using the Timeline profiling feature as described <a href=\"https://github.com/tensorflow/tensorflow/issues/1824\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1824/hovercard\">here</a>.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04.5 LTS (running in a <a href=\"http://singularity.lbl.gov\" rel=\"nofollow\">singularity</a> container on a CentOS 6.7 host).</p>\n<p>Installed version of CUDA and cuDNN:<br>\nI am using CUDA 8.0 with NVIDIA driver 367.48, and cuDNN v5.1 .<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>libOpenCL.so\nlibOpenCL.so.1\nlibOpenCL.so.1.0\nlibOpenCL.so.1.0.0\nlibcublas.so\nlibcublas.so.8.0\nlibcublas.so.8.0.45\nlibcublas_device.a\nlibcublas_static.a\nlibcudadevrt.a\nlibcudart.so\nlibcudart.so.8.0\nlibcudart.so.8.0.44\nlibcudart_static.a\nlibcudnn.so\nlibcudnn.so.5\nlibcudnn.so.5.1.5\nlibcudnn_static.a\nlibcufft.so\nlibcufft.so.8.0\nlibcufft.so.8.0.44\nlibcufft_static.a\nlibcufftw.so\nlibcufftw.so.8.0\nlibcufftw.so.8.0.44\nlibcufftw_static.a\nlibcuinj64.so\nlibcuinj64.so.8.0\nlibcuinj64.so.8.0.44\nlibculibos.a\nlibcurand.so\nlibcurand.so.8.0\nlibcurand.so.8.0.44\nlibcurand_static.a\nlibcusolver.so\nlibcusolver.so.8.0\nlibcusolver.so.8.0.44\nlibcusolver_static.a\nlibcusparse.so\nlibcusparse.so.8.0\nlibcusparse.so.8.0.44\nlibcusparse_static.a\nlibnppc.so\nlibnppc.so.8.0\nlibnppc.so.8.0.44\nlibnppc_static.a\nlibnppi.so\nlibnppi.so.8.0\nlibnppi.so.8.0.44\nlibnppi_static.a\nlibnppial.so\nlibnppial.so.8.0\nlibnppial.so.8.0.44\nlibnppicc.so\nlibnppicc.so.8.0\nlibnppicc.so.8.0.44\nlibnppicom.so\nlibnppicom.so.8.0\nlibnppicom.so.8.0.44\nlibnppidei.so\nlibnppidei.so.8.0\nlibnppidei.so.8.0.44\nlibnppif.so\nlibnppif.so.8.0\nlibnppif.so.8.0.44\nlibnppig.so\nlibnppig.so.8.0\nlibnppig.so.8.0.44\nlibnppim.so\nlibnppim.so.8.0\nlibnppim.so.8.0.44\nlibnppist.so\nlibnppist.so.8.0\nlibnppist.so.8.0.44\nlibnppisu.so\nlibnppisu.so.8.0\nlibnppisu.so.8.0.44\nlibnppitc.so\nlibnppitc.so.8.0\nlibnppitc.so.8.0.44\nlibnpps.so\nlibnpps.so.8.0\nlibnpps.so.8.0.44\nlibnpps_static.a\nlibnvToolsExt.so\nlibnvToolsExt.so.1\nlibnvToolsExt.so.1.0.0\nlibnvblas.so\nlibnvblas.so.8.0\nlibnvblas.so.8.0.44\nlibnvgraph.so\nlibnvgraph.so.8.0\nlibnvgraph.so.8.0.44\nlibnvgraph_static.a\nlibnvrtc-builtins.so\nlibnvrtc-builtins.so.8.0\nlibnvrtc-builtins.so.8.0.44\nlibnvrtc.so\nlibnvrtc.so.8.0\nlibnvrtc.so.8.0.44\nstubs\n</code></pre>\n<p>I installed tensorflow using the 0.11.0rc2-gpu tag on docker hub.</p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Here is the code I used to generate all the data I am sharing.</p>\n<pre><code>import os\nimport time\nimport timeit\n\nimport google\nimport numpy as np\nimport tensorflow as tf\n\ngrid_size = 9\nchannel_size = 4\nbatch_size = 2**9\nnum_convs = 8\nlog_metadata = True\ntowers = 2\nnum_train_batches = 100\n\n\ndef define_model(towers):\n    tower_outs = []\n    for i in range(0, towers):\n        with tf.device('/gpu:{:}'.format(i)):\n            with tf.name_scope('TOWER_{:}'.format(i)):\n                tower_outs.append(define_tower(i))\n                tf.get_variable_scope().reuse_variables()\n    return tower_outs\n\n\ndef define_tower(gpu_num):\n    x = tf.placeholder(\n        tf.float32,\n        shape=[None, grid_size, grid_size, grid_size, channel_size],\n        name='grid')\n\n    num_inputs = channel_size\n    for i in range(num_convs):\n        with tf.variable_scope(\"conv{:d}\".format(i)):\n            weights = tf.get_variable(\n                \"weights\",\n                [3, 3, 3, num_inputs, 32])\n            x = tf.nn.conv3d(x, weights, [1, 1, 1, 1, 1], 'SAME')\n            num_inputs = 32\n\n    return x\n\n\nif __name__ == \"__main__\":\n\n    # Define model.\n    tower_outs = define_model(towers)\n\n    # Create inputs.\n    feed_dict = {}\n    for i in range(towers):\n        feed_dict['TOWER_{:}/grid:0'.format(i)] = np.random.rand(\n            batch_size, grid_size, grid_size, grid_size, channel_size)\n\n    # Prepare for logging.\n    if log_metadata:\n        run_options = tf.RunOptions(\n            trace_level=tf.RunOptions.FULL_TRACE,\n            output_partition_graphs=True)\n        run_metadata = tf.RunMetadata()\n        kwargs = {'options': run_options,\n                  'run_metadata': run_metadata}\n\n        curr_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        if log_metadata:\n            out_dir = curr_time\n            os.mkdir(out_dir)\n    else:\n        kwargs = {}\n\n    # Run model.\n    train_learning_times = []\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n        tf.initialize_all_variables().run()\n        for i in range(num_train_batches):\n            learning_time_start = timeit.default_timer()\n            _ = sess.run(tower_outs, feed_dict=feed_dict, **kwargs)\n            train_learning_times.append(timeit.default_timer() -\n                                        learning_time_start)\n\n            if log_metadata:\n                from tensorflow.python.client import timeline\n                tl = timeline.Timeline(run_metadata.step_stats)\n                ctf = tl.generate_chrome_trace_format()\n                with open('{}/timeline_parallel_{}.json'\n                          .format(curr_time, i), 'w') as f:\n                    f.write(ctf)\n                with open('{}/run_metadata_{}.txt'\n                          .format(curr_time, i), 'w') as f:\n                    f.write(\n                        google.protobuf.text_format.MessageToString(\n                            run_metadata))\n\n    # Print stats\n    print 'Histogram counts: {}'.format(\n        np.histogram(train_learning_times[2:])[0])\n    print 'Histogram edges: {}'.format(\n        np.histogram(train_learning_times[2:])[1])\n    print 'Median time for learning: {:5.2f}'.format(\n        np.median(train_learning_times))\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<p>No other solutions tried.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>Dump of GraphDef and timeline json for each of 100 runs.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/573462/2016-11-05-18-52-32.zip\">2016-11-05-18-52-32.zip</a></p>\n<p>Output of code with log_metadata set to True:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/573464/parallel.txt\">parallel.txt</a></p>\n<p>Output of code with log_metadata set to False:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/573465/parallel-nometadata.txt\">parallel-nometadata.txt</a></p>", "body_text": "Hello tensorflow team!\nI have been trying to parallelize my 3D convolution network across 2 GPUs on the same node (using data parallelism), and have found that some of my session runs took significantly longer than others.  Upon closer investigation using your timeline feature, I found that sometimes GPU1 would wait a certain amount of time before starting to run its convolutions even as GPU0 was happily chugging along. In the most extreme case, execution would happen essentially sequentially, doubling my runtime!\nI am attaching screenshots of my timelines from three sessions to show you what I mean...\nIn the first one, everything is fine, it is executing both towers in parallel:\n\nIn the second, I see the \"sequential\" behaviour:\n\nIn the last one, I see something in between:\n\nI know this happens even when I am not logging metadata because I still see a large spread of runtime distributions without logging on (see parallel-nometadata.txt at the bottom).  Also, dumping the GraphDef proto at each step tells me that the ops are correctly assigned to the different GPUs (I have attached those, as well as my timeline files, at the bottom).\nI actually briefly talked about this with @mrry in person a little over a week ago, and we did not find anything obviously wrong at first glance.  Any help you could provide would be much appreciated!\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI have not found any related Github or StackOverflow threads.  I have been using the Timeline profiling feature as described here.\nEnvironment info\nOperating System: Ubuntu 14.04.5 LTS (running in a singularity container on a CentOS 6.7 host).\nInstalled version of CUDA and cuDNN:\nI am using CUDA 8.0 with NVIDIA driver 367.48, and cuDNN v5.1 .\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nlibOpenCL.so\nlibOpenCL.so.1\nlibOpenCL.so.1.0\nlibOpenCL.so.1.0.0\nlibcublas.so\nlibcublas.so.8.0\nlibcublas.so.8.0.45\nlibcublas_device.a\nlibcublas_static.a\nlibcudadevrt.a\nlibcudart.so\nlibcudart.so.8.0\nlibcudart.so.8.0.44\nlibcudart_static.a\nlibcudnn.so\nlibcudnn.so.5\nlibcudnn.so.5.1.5\nlibcudnn_static.a\nlibcufft.so\nlibcufft.so.8.0\nlibcufft.so.8.0.44\nlibcufft_static.a\nlibcufftw.so\nlibcufftw.so.8.0\nlibcufftw.so.8.0.44\nlibcufftw_static.a\nlibcuinj64.so\nlibcuinj64.so.8.0\nlibcuinj64.so.8.0.44\nlibculibos.a\nlibcurand.so\nlibcurand.so.8.0\nlibcurand.so.8.0.44\nlibcurand_static.a\nlibcusolver.so\nlibcusolver.so.8.0\nlibcusolver.so.8.0.44\nlibcusolver_static.a\nlibcusparse.so\nlibcusparse.so.8.0\nlibcusparse.so.8.0.44\nlibcusparse_static.a\nlibnppc.so\nlibnppc.so.8.0\nlibnppc.so.8.0.44\nlibnppc_static.a\nlibnppi.so\nlibnppi.so.8.0\nlibnppi.so.8.0.44\nlibnppi_static.a\nlibnppial.so\nlibnppial.so.8.0\nlibnppial.so.8.0.44\nlibnppicc.so\nlibnppicc.so.8.0\nlibnppicc.so.8.0.44\nlibnppicom.so\nlibnppicom.so.8.0\nlibnppicom.so.8.0.44\nlibnppidei.so\nlibnppidei.so.8.0\nlibnppidei.so.8.0.44\nlibnppif.so\nlibnppif.so.8.0\nlibnppif.so.8.0.44\nlibnppig.so\nlibnppig.so.8.0\nlibnppig.so.8.0.44\nlibnppim.so\nlibnppim.so.8.0\nlibnppim.so.8.0.44\nlibnppist.so\nlibnppist.so.8.0\nlibnppist.so.8.0.44\nlibnppisu.so\nlibnppisu.so.8.0\nlibnppisu.so.8.0.44\nlibnppitc.so\nlibnppitc.so.8.0\nlibnppitc.so.8.0.44\nlibnpps.so\nlibnpps.so.8.0\nlibnpps.so.8.0.44\nlibnpps_static.a\nlibnvToolsExt.so\nlibnvToolsExt.so.1\nlibnvToolsExt.so.1.0.0\nlibnvblas.so\nlibnvblas.so.8.0\nlibnvblas.so.8.0.44\nlibnvgraph.so\nlibnvgraph.so.8.0\nlibnvgraph.so.8.0.44\nlibnvgraph_static.a\nlibnvrtc-builtins.so\nlibnvrtc-builtins.so.8.0\nlibnvrtc-builtins.so.8.0.44\nlibnvrtc.so\nlibnvrtc.so.8.0\nlibnvrtc.so.8.0.44\nstubs\n\nI installed tensorflow using the 0.11.0rc2-gpu tag on docker hub.\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nHere is the code I used to generate all the data I am sharing.\nimport os\nimport time\nimport timeit\n\nimport google\nimport numpy as np\nimport tensorflow as tf\n\ngrid_size = 9\nchannel_size = 4\nbatch_size = 2**9\nnum_convs = 8\nlog_metadata = True\ntowers = 2\nnum_train_batches = 100\n\n\ndef define_model(towers):\n    tower_outs = []\n    for i in range(0, towers):\n        with tf.device('/gpu:{:}'.format(i)):\n            with tf.name_scope('TOWER_{:}'.format(i)):\n                tower_outs.append(define_tower(i))\n                tf.get_variable_scope().reuse_variables()\n    return tower_outs\n\n\ndef define_tower(gpu_num):\n    x = tf.placeholder(\n        tf.float32,\n        shape=[None, grid_size, grid_size, grid_size, channel_size],\n        name='grid')\n\n    num_inputs = channel_size\n    for i in range(num_convs):\n        with tf.variable_scope(\"conv{:d}\".format(i)):\n            weights = tf.get_variable(\n                \"weights\",\n                [3, 3, 3, num_inputs, 32])\n            x = tf.nn.conv3d(x, weights, [1, 1, 1, 1, 1], 'SAME')\n            num_inputs = 32\n\n    return x\n\n\nif __name__ == \"__main__\":\n\n    # Define model.\n    tower_outs = define_model(towers)\n\n    # Create inputs.\n    feed_dict = {}\n    for i in range(towers):\n        feed_dict['TOWER_{:}/grid:0'.format(i)] = np.random.rand(\n            batch_size, grid_size, grid_size, grid_size, channel_size)\n\n    # Prepare for logging.\n    if log_metadata:\n        run_options = tf.RunOptions(\n            trace_level=tf.RunOptions.FULL_TRACE,\n            output_partition_graphs=True)\n        run_metadata = tf.RunMetadata()\n        kwargs = {'options': run_options,\n                  'run_metadata': run_metadata}\n\n        curr_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        if log_metadata:\n            out_dir = curr_time\n            os.mkdir(out_dir)\n    else:\n        kwargs = {}\n\n    # Run model.\n    train_learning_times = []\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n        tf.initialize_all_variables().run()\n        for i in range(num_train_batches):\n            learning_time_start = timeit.default_timer()\n            _ = sess.run(tower_outs, feed_dict=feed_dict, **kwargs)\n            train_learning_times.append(timeit.default_timer() -\n                                        learning_time_start)\n\n            if log_metadata:\n                from tensorflow.python.client import timeline\n                tl = timeline.Timeline(run_metadata.step_stats)\n                ctf = tl.generate_chrome_trace_format()\n                with open('{}/timeline_parallel_{}.json'\n                          .format(curr_time, i), 'w') as f:\n                    f.write(ctf)\n                with open('{}/run_metadata_{}.txt'\n                          .format(curr_time, i), 'w') as f:\n                    f.write(\n                        google.protobuf.text_format.MessageToString(\n                            run_metadata))\n\n    # Print stats\n    print 'Histogram counts: {}'.format(\n        np.histogram(train_learning_times[2:])[0])\n    print 'Histogram edges: {}'.format(\n        np.histogram(train_learning_times[2:])[1])\n    print 'Median time for learning: {:5.2f}'.format(\n        np.median(train_learning_times))\n\nWhat other attempted solutions have you tried?\nNo other solutions tried.\nLogs or other output that would be helpful\nDump of GraphDef and timeline json for each of 100 runs.\n2016-11-05-18-52-32.zip\nOutput of code with log_metadata set to True:\nparallel.txt\nOutput of code with log_metadata set to False:\nparallel-nometadata.txt", "body": "Hello tensorflow team!\r\n\r\nI have been trying to parallelize my 3D convolution network across 2 GPUs on the same node (using data parallelism), and have found that some of my session runs took significantly longer than others.  Upon closer investigation using your timeline feature, I found that sometimes GPU1 would wait a certain amount of time before starting to run its convolutions even as GPU0 was happily chugging along. In the most extreme case, execution would happen essentially sequentially, doubling my runtime!  \r\n\r\nI am attaching screenshots of my timelines from three sessions to show you what I mean...\r\n\r\nIn the first one, everything is fine, it is executing both towers in parallel:\r\n![run55](https://cloud.githubusercontent.com/assets/177576/20033120/cc17df8c-a356-11e6-8ef3-55cfdeb9d244.png)\r\nIn the second, I see the \"sequential\" behaviour:\r\n![run56](https://cloud.githubusercontent.com/assets/177576/20033121/cd4d9e96-a356-11e6-8ef1-091edd981fdf.png)\r\nIn the last one, I see something in between:\r\n![run30](https://cloud.githubusercontent.com/assets/177576/20033136/2b7f68b4-a357-11e6-9eb5-92f9a30a5fa3.png)\r\n\r\nI know this happens even when I am not logging metadata because I still see a large spread of runtime distributions without logging on (see parallel-nometadata.txt at the bottom).  Also, dumping the GraphDef proto at each step tells me that the ops are correctly assigned to the different GPUs (I have attached those, as well as my timeline files, at the bottom).\r\n\r\nI actually briefly talked about this with @mrry in person a little over a week ago, and we did not find anything obviously wrong at first glance.  Any help you could provide would be much appreciated!  \r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI have not found any related Github or StackOverflow threads.  I have been using the Timeline profiling feature as described [here](https://github.com/tensorflow/tensorflow/issues/1824).\r\n\r\n### Environment info\r\nOperating System: Ubuntu 14.04.5 LTS (running in a [singularity](http://singularity.lbl.gov) container on a CentOS 6.7 host). \r\n\r\nInstalled version of CUDA and cuDNN: \r\nI am using CUDA 8.0 with NVIDIA driver 367.48, and cuDNN v5.1 . \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\nlibOpenCL.so\r\nlibOpenCL.so.1\r\nlibOpenCL.so.1.0\r\nlibOpenCL.so.1.0.0\r\nlibcublas.so\r\nlibcublas.so.8.0\r\nlibcublas.so.8.0.45\r\nlibcublas_device.a\r\nlibcublas_static.a\r\nlibcudadevrt.a\r\nlibcudart.so\r\nlibcudart.so.8.0\r\nlibcudart.so.8.0.44\r\nlibcudart_static.a\r\nlibcudnn.so\r\nlibcudnn.so.5\r\nlibcudnn.so.5.1.5\r\nlibcudnn_static.a\r\nlibcufft.so\r\nlibcufft.so.8.0\r\nlibcufft.so.8.0.44\r\nlibcufft_static.a\r\nlibcufftw.so\r\nlibcufftw.so.8.0\r\nlibcufftw.so.8.0.44\r\nlibcufftw_static.a\r\nlibcuinj64.so\r\nlibcuinj64.so.8.0\r\nlibcuinj64.so.8.0.44\r\nlibculibos.a\r\nlibcurand.so\r\nlibcurand.so.8.0\r\nlibcurand.so.8.0.44\r\nlibcurand_static.a\r\nlibcusolver.so\r\nlibcusolver.so.8.0\r\nlibcusolver.so.8.0.44\r\nlibcusolver_static.a\r\nlibcusparse.so\r\nlibcusparse.so.8.0\r\nlibcusparse.so.8.0.44\r\nlibcusparse_static.a\r\nlibnppc.so\r\nlibnppc.so.8.0\r\nlibnppc.so.8.0.44\r\nlibnppc_static.a\r\nlibnppi.so\r\nlibnppi.so.8.0\r\nlibnppi.so.8.0.44\r\nlibnppi_static.a\r\nlibnppial.so\r\nlibnppial.so.8.0\r\nlibnppial.so.8.0.44\r\nlibnppicc.so\r\nlibnppicc.so.8.0\r\nlibnppicc.so.8.0.44\r\nlibnppicom.so\r\nlibnppicom.so.8.0\r\nlibnppicom.so.8.0.44\r\nlibnppidei.so\r\nlibnppidei.so.8.0\r\nlibnppidei.so.8.0.44\r\nlibnppif.so\r\nlibnppif.so.8.0\r\nlibnppif.so.8.0.44\r\nlibnppig.so\r\nlibnppig.so.8.0\r\nlibnppig.so.8.0.44\r\nlibnppim.so\r\nlibnppim.so.8.0\r\nlibnppim.so.8.0.44\r\nlibnppist.so\r\nlibnppist.so.8.0\r\nlibnppist.so.8.0.44\r\nlibnppisu.so\r\nlibnppisu.so.8.0\r\nlibnppisu.so.8.0.44\r\nlibnppitc.so\r\nlibnppitc.so.8.0\r\nlibnppitc.so.8.0.44\r\nlibnpps.so\r\nlibnpps.so.8.0\r\nlibnpps.so.8.0.44\r\nlibnpps_static.a\r\nlibnvToolsExt.so\r\nlibnvToolsExt.so.1\r\nlibnvToolsExt.so.1.0.0\r\nlibnvblas.so\r\nlibnvblas.so.8.0\r\nlibnvblas.so.8.0.44\r\nlibnvgraph.so\r\nlibnvgraph.so.8.0\r\nlibnvgraph.so.8.0.44\r\nlibnvgraph_static.a\r\nlibnvrtc-builtins.so\r\nlibnvrtc-builtins.so.8.0\r\nlibnvrtc-builtins.so.8.0.44\r\nlibnvrtc.so\r\nlibnvrtc.so.8.0\r\nlibnvrtc.so.8.0.44\r\nstubs\r\n```\r\n\r\nI installed tensorflow using the 0.11.0rc2-gpu tag on docker hub.\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nHere is the code I used to generate all the data I am sharing.\r\n\r\n```\r\nimport os\r\nimport time\r\nimport timeit\r\n\r\nimport google\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ngrid_size = 9\r\nchannel_size = 4\r\nbatch_size = 2**9\r\nnum_convs = 8\r\nlog_metadata = True\r\ntowers = 2\r\nnum_train_batches = 100\r\n\r\n\r\ndef define_model(towers):\r\n    tower_outs = []\r\n    for i in range(0, towers):\r\n        with tf.device('/gpu:{:}'.format(i)):\r\n            with tf.name_scope('TOWER_{:}'.format(i)):\r\n                tower_outs.append(define_tower(i))\r\n                tf.get_variable_scope().reuse_variables()\r\n    return tower_outs\r\n\r\n\r\ndef define_tower(gpu_num):\r\n    x = tf.placeholder(\r\n        tf.float32,\r\n        shape=[None, grid_size, grid_size, grid_size, channel_size],\r\n        name='grid')\r\n\r\n    num_inputs = channel_size\r\n    for i in range(num_convs):\r\n        with tf.variable_scope(\"conv{:d}\".format(i)):\r\n            weights = tf.get_variable(\r\n                \"weights\",\r\n                [3, 3, 3, num_inputs, 32])\r\n            x = tf.nn.conv3d(x, weights, [1, 1, 1, 1, 1], 'SAME')\r\n            num_inputs = 32\r\n\r\n    return x\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    # Define model.\r\n    tower_outs = define_model(towers)\r\n\r\n    # Create inputs.\r\n    feed_dict = {}\r\n    for i in range(towers):\r\n        feed_dict['TOWER_{:}/grid:0'.format(i)] = np.random.rand(\r\n            batch_size, grid_size, grid_size, grid_size, channel_size)\r\n\r\n    # Prepare for logging.\r\n    if log_metadata:\r\n        run_options = tf.RunOptions(\r\n            trace_level=tf.RunOptions.FULL_TRACE,\r\n            output_partition_graphs=True)\r\n        run_metadata = tf.RunMetadata()\r\n        kwargs = {'options': run_options,\r\n                  'run_metadata': run_metadata}\r\n\r\n        curr_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\r\n        if log_metadata:\r\n            out_dir = curr_time\r\n            os.mkdir(out_dir)\r\n    else:\r\n        kwargs = {}\r\n\r\n    # Run model.\r\n    train_learning_times = []\r\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\r\n        tf.initialize_all_variables().run()\r\n        for i in range(num_train_batches):\r\n            learning_time_start = timeit.default_timer()\r\n            _ = sess.run(tower_outs, feed_dict=feed_dict, **kwargs)\r\n            train_learning_times.append(timeit.default_timer() -\r\n                                        learning_time_start)\r\n\r\n            if log_metadata:\r\n                from tensorflow.python.client import timeline\r\n                tl = timeline.Timeline(run_metadata.step_stats)\r\n                ctf = tl.generate_chrome_trace_format()\r\n                with open('{}/timeline_parallel_{}.json'\r\n                          .format(curr_time, i), 'w') as f:\r\n                    f.write(ctf)\r\n                with open('{}/run_metadata_{}.txt'\r\n                          .format(curr_time, i), 'w') as f:\r\n                    f.write(\r\n                        google.protobuf.text_format.MessageToString(\r\n                            run_metadata))\r\n\r\n    # Print stats\r\n    print 'Histogram counts: {}'.format(\r\n        np.histogram(train_learning_times[2:])[0])\r\n    print 'Histogram edges: {}'.format(\r\n        np.histogram(train_learning_times[2:])[1])\r\n    print 'Median time for learning: {:5.2f}'.format(\r\n        np.median(train_learning_times))\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nNo other solutions tried.\r\n\r\n\r\n\r\n\r\n### Logs or other output that would be helpful\r\nDump of GraphDef and timeline json for each of 100 runs.\r\n\r\n[2016-11-05-18-52-32.zip](https://github.com/tensorflow/tensorflow/files/573462/2016-11-05-18-52-32.zip)\r\n\r\nOutput of code with log_metadata set to True:\r\n[parallel.txt](https://github.com/tensorflow/tensorflow/files/573464/parallel.txt)\r\n\r\nOutput of code with log_metadata set to False:\r\n[parallel-nometadata.txt](https://github.com/tensorflow/tensorflow/files/573465/parallel-nometadata.txt)"}