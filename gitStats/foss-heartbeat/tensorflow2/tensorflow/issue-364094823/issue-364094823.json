{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22543", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22543/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22543/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22543/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22543", "id": 364094823, "node_id": "MDU6SXNzdWUzNjQwOTQ4MjM=", "number": 22543, "title": "sparse_tensor_to_dense() does not seem to support back propagation", "user": {"login": "dblueeye", "id": 11167572, "node_id": "MDQ6VXNlcjExMTY3NTcy", "avatar_url": "https://avatars1.githubusercontent.com/u/11167572?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dblueeye", "html_url": "https://github.com/dblueeye", "followers_url": "https://api.github.com/users/dblueeye/followers", "following_url": "https://api.github.com/users/dblueeye/following{/other_user}", "gists_url": "https://api.github.com/users/dblueeye/gists{/gist_id}", "starred_url": "https://api.github.com/users/dblueeye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dblueeye/subscriptions", "organizations_url": "https://api.github.com/users/dblueeye/orgs", "repos_url": "https://api.github.com/users/dblueeye/repos", "events_url": "https://api.github.com/users/dblueeye/events{/privacy}", "received_events_url": "https://api.github.com/users/dblueeye/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-09-26T15:41:40Z", "updated_at": "2018-09-28T16:16:35Z", "closed_at": "2018-09-28T02:28:14Z", "author_association": "NONE", "body_html": "<p>**Have I written custom code: Yes<br>\n**OS Platform and Distribution: Windows 10 (primary), Ubunto 16.04.3 LTS (secondary)<br>\n**TensorFlow installed from (source or binary): Binary<br>\n**TensorFlow version (use command below): b'v1.10.0-rc1-19-g656e7a2b34' 1.10.0<br>\n**Python version: Python 3.6.6 :: Anaconda, Inc.<br>\nCUDA/cuDNN version: N/A (not relevant)<br>\nGPU model and memory: N/A (not relevant)</p>\n<h3>Describe the problem</h3>\n<p>The function sparse_tensor_to_dense() does not seem to support backpropagation. I've written a test script below, which yielded</p>\n<blockquote>\n<p>Fetch argument None has invalid type &lt;class 'NoneType'&gt;</p>\n</blockquote>\n<p>If you change the line<br>\n<code>grad_A00 = tf.gradients(A_dense_transformed[0,0], par)</code><br>\nto the next (currently commented-out)<br>\n<code>grad_A00 = tf.gradients(A_dense_manual[0,0], par)</code><br>\nthe script can be executed.</p>\n<p>If the sparse tensor formulation is necessary, the workaround is to use the commented lines</p>\n<pre><code>identity = tf.Variable(eye(2), dtype = float32)\nA_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\n</code></pre>\n<p>to replace original <code>A_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse)</code>.<br>\nSuch an exercise allows the program to execute the original <code>grad_A00 = tf.gradients(A_dense_transformed[0,0], par)</code>.</p>\n<h3>Source code / logs</h3>\n<pre><code>\nimport tensorflow as tf\nfrom numpy import *\n# showing backprop fails if using sparse tensor\n\ntf.reset_default_graph()\n\npar = tf.Variable(1.0, dtype = float32)\nA_sparse = tf.SparseTensor(indices=[[0,0],], values=tf.stack([par,]), dense_shape = (2,1))\n\nA_dense_manual = tf.stack([[par],[0]])\nA_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse)\n#identity = tf.Variable(eye(2), dtype = float32)\n#A_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\n\ngrad_A00 = tf.gradients(A_dense_transformed[0,0], par)\n#grad_A00 = tf.gradients(A_dense_manual[0,0], par)\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    \n    init.run()\n    vA_manual, vA_transformed, vGrad = sess.run([A_dense_manual, A_dense_transformed, grad_A00])    \n    \nprint(vA_manual)\nprint(vA_transformed)\nprint(vGrad)\n</code></pre>", "body_text": "**Have I written custom code: Yes\n**OS Platform and Distribution: Windows 10 (primary), Ubunto 16.04.3 LTS (secondary)\n**TensorFlow installed from (source or binary): Binary\n**TensorFlow version (use command below): b'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\n**Python version: Python 3.6.6 :: Anaconda, Inc.\nCUDA/cuDNN version: N/A (not relevant)\nGPU model and memory: N/A (not relevant)\nDescribe the problem\nThe function sparse_tensor_to_dense() does not seem to support backpropagation. I've written a test script below, which yielded\n\nFetch argument None has invalid type <class 'NoneType'>\n\nIf you change the line\ngrad_A00 = tf.gradients(A_dense_transformed[0,0], par)\nto the next (currently commented-out)\ngrad_A00 = tf.gradients(A_dense_manual[0,0], par)\nthe script can be executed.\nIf the sparse tensor formulation is necessary, the workaround is to use the commented lines\nidentity = tf.Variable(eye(2), dtype = float32)\nA_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\n\nto replace original A_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse).\nSuch an exercise allows the program to execute the original grad_A00 = tf.gradients(A_dense_transformed[0,0], par).\nSource code / logs\n\nimport tensorflow as tf\nfrom numpy import *\n# showing backprop fails if using sparse tensor\n\ntf.reset_default_graph()\n\npar = tf.Variable(1.0, dtype = float32)\nA_sparse = tf.SparseTensor(indices=[[0,0],], values=tf.stack([par,]), dense_shape = (2,1))\n\nA_dense_manual = tf.stack([[par],[0]])\nA_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse)\n#identity = tf.Variable(eye(2), dtype = float32)\n#A_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\n\ngrad_A00 = tf.gradients(A_dense_transformed[0,0], par)\n#grad_A00 = tf.gradients(A_dense_manual[0,0], par)\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    \n    init.run()\n    vA_manual, vA_transformed, vGrad = sess.run([A_dense_manual, A_dense_transformed, grad_A00])    \n    \nprint(vA_manual)\nprint(vA_transformed)\nprint(vGrad)", "body": "**Have I written custom code: Yes\r\n**OS Platform and Distribution: Windows 10 (primary), Ubunto 16.04.3 LTS (secondary)\r\n**TensorFlow installed from (source or binary): Binary\r\n**TensorFlow version (use command below): b'v1.10.0-rc1-19-g656e7a2b34' 1.10.0\r\n**Python version: Python 3.6.6 :: Anaconda, Inc.\r\nCUDA/cuDNN version: N/A (not relevant)\r\nGPU model and memory: N/A (not relevant)\r\n\r\n### Describe the problem\r\nThe function sparse_tensor_to_dense() does not seem to support backpropagation. I've written a test script below, which yielded \r\n\r\n> Fetch argument None has invalid type <class 'NoneType'>\r\n\r\nIf you change the line\r\n`grad_A00 = tf.gradients(A_dense_transformed[0,0], par)`\r\nto the next (currently commented-out)\r\n`grad_A00 = tf.gradients(A_dense_manual[0,0], par)`\r\nthe script can be executed.\r\n\r\nIf the sparse tensor formulation is necessary, the workaround is to use the commented lines \r\n```\r\nidentity = tf.Variable(eye(2), dtype = float32)\r\nA_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\r\n```\r\nto replace original `A_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse)`. \r\nSuch an exercise allows the program to execute the original `grad_A00 = tf.gradients(A_dense_transformed[0,0], par)`.\r\n\r\n### Source code / logs\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom numpy import *\r\n# showing backprop fails if using sparse tensor\r\n\r\ntf.reset_default_graph()\r\n\r\npar = tf.Variable(1.0, dtype = float32)\r\nA_sparse = tf.SparseTensor(indices=[[0,0],], values=tf.stack([par,]), dense_shape = (2,1))\r\n\r\nA_dense_manual = tf.stack([[par],[0]])\r\nA_dense_transformed = A = tf.sparse_tensor_to_dense(A_sparse)\r\n#identity = tf.Variable(eye(2), dtype = float32)\r\n#A_dense_transformed = A = tf.sparse_tensor_dense_matmul(tf.sparse_transpose(A_sparse), identity)\r\n\r\ngrad_A00 = tf.gradients(A_dense_transformed[0,0], par)\r\n#grad_A00 = tf.gradients(A_dense_manual[0,0], par)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    \r\n    init.run()\r\n    vA_manual, vA_transformed, vGrad = sess.run([A_dense_manual, A_dense_transformed, grad_A00])    \r\n    \r\nprint(vA_manual)\r\nprint(vA_transformed)\r\nprint(vGrad)\r\n```\r\n"}