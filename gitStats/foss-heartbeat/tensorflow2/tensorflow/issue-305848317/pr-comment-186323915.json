{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/186323915", "pull_request_review_id": 117879165, "id": 186323915, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NjMyMzkxNQ==", "diff_hunk": "@@ -0,0 +1,122 @@\n+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Unique element dataset transformations.\"\"\"\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.contrib.data.python.ops import contrib_op_loader  # pylint: disable=unused-import\n+from tensorflow.contrib.data.python.ops import gen_dataset_ops\n+from tensorflow.python.data.ops import dataset_ops\n+from tensorflow.python.data.util import nest\n+from tensorflow.python.framework.tensor_shape import TensorShape\n+\n+\n+def unordered_merge(datasets):\n+  \"\"\"Creates a `Dataset` by merging the given datasets without garantee of data order.\n+\n+  The input `datasets` must be an iterable of same types and shapes of datasets.\n+  This method merges input datasets without garantee of the data order.\n+  For example:\n+\n+  ```python\n+  # NOTE: The following examples use `{ ... }` to represent the\n+  # contents of a dataset.\n+  a = { 1, 2, 3 }\n+  b = { 4, 5, 6 }\n+  c = { 13, 14 }\n+  d = { (7, 8), (9, 10), (11, 12) }\n+\n+  # The `datasets` argument may contain an arbitrary number of\n+  # datasets having same type and shape.\n+  unorderd_merge([a, b]) == { 1, 4, 2, 5, 3, 6 }\n+  unorderd_merge([a, b, c]) == { 1, 4, 13, 2, 5, 3, 6, 14 }\n+\n+  # NOTE: the output order might be different\n+\n+  # The shapes and types in `datasets` argument must be the same.\n+  unorderd_merge([a, b, d]) ==> TypeError\n+\n+  # sample usage:\n+  dataset = tf.data.Dataset.from_tensor_slices(tensors)\n+  datasets = [dataset.shard(10, i) for i in range(10)]\n+  datasets = [dataset.apply(group_by_window(key_func, reduce_func, window_size)\n+              for dataset in datasets]\n+  dataset = tf.contrib.data.unorderd_merge(datasets)\n+  ```\n+\n+  Args:\n+    datasets: An iterable(such as list or tuple) of datasets.\n+\n+  Returns:\n+    A merged `Dataset`.\n+  \"\"\"\n+  return UnorderedMergeDataset(datasets)\n+\n+def _shapes_to_list(shapes):\n+  if TensorShape == type(shapes):\n+    return shapes.as_list()\n+  flat_shapes = nest.flatten(shapes)\n+  list_shapes = [_shapes_to_list(s) for s in flat_shapes]\n+  return nest.pack_sequence_as(shapes, list_shapes)\n+\n+class UnorderedMergeDataset(dataset_ops.Dataset):\n+  \"\"\"A merged `Dataset` of its input datasets without garantee of data order.\"\"\"\n+\n+  def __init__(self, datasets):\n+    \"\"\"See `unordered_merge()` for details.\"\"\"\n+    super(UnorderedMergeDataset, self).__init__()\n+    self._datasets = list(datasets)\n+\n+    for ds in self._datasets:\n+      if not isinstance(ds, dataset_ops.Dataset):\n+        message = (\"The argument to `unordered_merge()` \"\n+                   \"must be an iterable of datasets.\")\n+        raise TypeError(message)\n+\n+    shapes0 = _shapes_to_list(self._datasets[0].output_shapes)\n+    types0 = self._datasets[0].output_types\n+\n+    for ds in self._datasets:\n+      current_shapes = _shapes_to_list(ds.output_shapes)\n+      if shapes0 != current_shapes:\n+        message = (\"The shapes of `datasets` {}, {} must be same.\"\n+                   .format(shapes0, current_shapes))\n+        raise TypeError(message)\n+      current_types = ds.output_types\n+      if types0 != current_types:\n+        message = (\"The types of `datasets` {}, {} must be same.\"\n+                   .format(types0, current_types))\n+        raise TypeError(message)\n+\n+  def _as_variant_tensor(self):\n+    # pylint: disable=protected-access\n+    return gen_dataset_ops.unordered_merge_dataset(\n+        [ds._as_variant_tensor() for ds in self._datasets],\n+        output_shapes=nest.flatten(self._datasets[0].output_shapes),\n+        output_types=nest.flatten(self._datasets[0].output_types))\n+    # pylint: enable=protected-access\n+\n+  @property\n+  def output_classes(self):\n+    return self._datasets[0].output_classes\n+\n+  @property\n+  def output_shapes(self):\n+    return self._datasets[0].output_shapes", "path": "tensorflow/contrib/data/python/ops/unordered_merge.py", "position": 118, "original_position": 118, "commit_id": "b905186aa9015d240abde9690383b40525a2f02c", "original_commit_id": "482f6c7c20c58f345793ec681033ae4da4beed7e", "user": {"login": "deasuke", "id": 1057390, "node_id": "MDQ6VXNlcjEwNTczOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1057390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deasuke", "html_url": "https://github.com/deasuke", "followers_url": "https://api.github.com/users/deasuke/followers", "following_url": "https://api.github.com/users/deasuke/following{/other_user}", "gists_url": "https://api.github.com/users/deasuke/gists{/gist_id}", "starred_url": "https://api.github.com/users/deasuke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deasuke/subscriptions", "organizations_url": "https://api.github.com/users/deasuke/orgs", "repos_url": "https://api.github.com/users/deasuke/repos", "events_url": "https://api.github.com/users/deasuke/events{/privacy}", "received_events_url": "https://api.github.com/users/deasuke/received_events", "type": "User", "site_admin": false}, "body": "I see. Will be fixed.", "created_at": "2018-05-07T04:20:07Z", "updated_at": "2018-05-07T04:20:07Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/17760#discussion_r186323915", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17760", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/186323915"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/17760#discussion_r186323915"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/17760"}}, "body_html": "<p>I see. Will be fixed.</p>", "body_text": "I see. Will be fixed.", "in_reply_to_id": 185867374}