{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/188444095", "pull_request_review_id": 120422537, "id": 188444095, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4ODQ0NDA5NQ==", "diff_hunk": "@@ -688,26 +677,60 @@ class MklConcatOp : public OpKernel {\n       std::vector<memory::primitive_desc> srcs_pd;\n       std::vector<MklDnnData<T>> srcs(N, MklDnnData<T>(&cpu_engine));\n       int64 dst_concat_dim_size = 0;\n-      for (int k = 0; k < N; k++) {\n-        bool is_mkl_tensor = input_shapes[k].IsMklTensor();\n-        memory::dims src_dims;\n-\n-        // Same comment as dst_dims for src_dims.\n-        src_dims = (is_mkl_tensor)\n-                       ? TFShapeToMklDnnDims(input_shapes[k].GetTfShape())\n-                       : TFShapeToMklDnnDims(input_tensors[k].shape());\n-\n-        dst_concat_dim_size += src_dims[concat_dim];\n-        auto src_md =\n-            is_mkl_tensor ? input_shapes[k].GetMklLayout() :\n-                          // It does not matter what data format we use here\n-                          // (NHWC or NCHW). We just need to ensure that output\n-                          // of Concat uses same data format as input.\n-                memory::desc(src_dims, MklDnnType<T>(), memory::format::nchw);\n-\n-        srcs[k].SetUsrMem(src_md, &input_tensors[k]);\n-        auto src_mpd = srcs[k].GetUsrMemPrimDesc();\n-        srcs_pd.push_back(src_mpd);\n+\n+      bool isMklReorderNeeded = false;\n+      memory::format mkl_common_format = memory::format::any;\n+      if (are_all_mkl_inputs) {\n+        mkl_common_format =\n+            FindMklCommonFormat(input_shapes, concat_dim,\n+               &isMklReorderNeeded, &dst_concat_dim_size);\n+\n+        if (!isMklReorderNeeded) {\n+          // All MKL tensors have a same format. Reorder is not needed.\n+          for (int k = 0; k < N; k++) {\n+            if (input_tensors[k].NumElements() == 0)\n+              continue;\n+\n+            auto src_md = input_shapes[k].GetMklLayout();\n+            srcs[k].SetUsrMem(src_md, &input_tensors[k]);\n+            auto src_mpd = srcs[k].GetUsrMemPrimDesc();\n+            srcs_pd.push_back(src_mpd);\n+          }\n+        } else {\n+          // MKL tensors have different formats.\n+          // Reorder them to most common format.\n+          for (int k = 0; k < N; k++) {\n+            if (input_tensors[k].NumElements() == 0)\n+              continue;\n+\n+            auto src_dims = TFShapeToMklDnnDims(input_shapes[k].GetTfShape());\n+            auto src_md = input_shapes[k].GetMklLayout();\n+            srcs[k].SetUsrMem(src_md, &input_tensors[k]);\n+\n+            if (src_md.data.format != mkl_common_format)\n+              src_md = memory::desc(src_dims, MklDnnType<T>(),\n+                           mkl_common_format);\n+\n+            srcs_pd.push_back(memory::primitive_desc(src_md, cpu_engine));\n+          }\n+        }\n+      } else {  // All TF inputs\n+        for (int k = 0; k < N; k++) {\n+          if (input_tensors[k].NumElements() == 0)\n+            continue;\n+\n+          memory::dims src_dims = TFShapeToMklDnnDims(input_tensors[k].shape());\n+          dst_concat_dim_size += src_dims[concat_dim];\n+\n+          // It does not matter what data format to be used (NHWC versus NCHW).\n+          // We just need to ensure that output uses same data format as inputs.\n+          auto src_md =", "path": "tensorflow/core/kernels/mkl_concat_op.cc", "position": 140, "original_position": 113, "commit_id": "ef2e9db5feec86433018506a3fbccd05f13d096a", "original_commit_id": "dd772a64ea6a7fc10668cb6ef78facf37a754921", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "If I understand your comment correctly: For clarity, should we copy the format from the input rather than hardcoding it to NCHW here?  ", "created_at": "2018-05-15T21:36:10Z", "updated_at": "2018-05-16T17:52:25Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/19065#discussion_r188444095", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19065", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/188444095"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/19065#discussion_r188444095"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/19065"}}, "body_html": "<p>If I understand your comment correctly: For clarity, should we copy the format from the input rather than hardcoding it to NCHW here?</p>", "body_text": "If I understand your comment correctly: For clarity, should we copy the format from the input rather than hardcoding it to NCHW here?"}