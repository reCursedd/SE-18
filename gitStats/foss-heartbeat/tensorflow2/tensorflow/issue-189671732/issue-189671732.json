{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5639", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5639/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5639/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5639/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5639", "id": 189671732, "node_id": "MDU6SXNzdWUxODk2NzE3MzI=", "number": 5639, "title": "KeyError: u'SaveV2' when loading exported model", "user": {"login": "shelpuk", "id": 3008563, "node_id": "MDQ6VXNlcjMwMDg1NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3008563?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shelpuk", "html_url": "https://github.com/shelpuk", "followers_url": "https://api.github.com/users/shelpuk/followers", "following_url": "https://api.github.com/users/shelpuk/following{/other_user}", "gists_url": "https://api.github.com/users/shelpuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/shelpuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shelpuk/subscriptions", "organizations_url": "https://api.github.com/users/shelpuk/orgs", "repos_url": "https://api.github.com/users/shelpuk/repos", "events_url": "https://api.github.com/users/shelpuk/events{/privacy}", "received_events_url": "https://api.github.com/users/shelpuk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2016-11-16T11:16:23Z", "updated_at": "2018-09-11T06:46:35Z", "closed_at": "2017-01-16T02:46:45Z", "author_association": "NONE", "body_html": "<p>I have a TensorFLow model trained on a GPU machine. Next, I need to export it and deploy on CPU only production machine.</p>\n<p>I have trained and exported a model from a GPU machine as described in <a href=\"https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_export.py\">MNIST export example</a>. Saver object was initialized above.</p>\n<pre><code>with graph.as_default():\n    saver = tf.train.Saver(tf.all_variables(), sharded=True)\n...\n\nexport_path =  'resnet34_rmsprop_wd1e-1/saves/'\nprint('Exporting trained model to %s' % export_path)\ninit_op = tf.group(tf.initialize_all_tables(), name='init_op')\nmodel_exporter = exporter.Exporter(saver)\nmodel_exporter.init(sess.graph.as_graph_def(),\n                            init_op=init_op,\n                            default_graph_signature=exporter.classification_signature(input_tensor=inference_images,\n                                                                                      classes_tensor=inference_class,\n                                                                                      scores_tensor=inference_predictions),\n                            named_graph_signatures={'inputs': exporter.generic_signature({'images': inference_images}),\n                                                    'outputs': exporter.generic_signature({'class': inference_class, 'predictions': inference_predictions})})\nmodel_exporter.export(export_path, tf.constant(1), sess)\nprint('Done exporting!')\n</code></pre>\n<p>Next, I am trying to load saved model to CPU machine with:</p>\n<p><code>new_saver = tf.train.import_meta_graph('assets/saved_model/export.meta') new_saver.restore(sess, 'assets/saved_model/export')</code></p>\n<p>And what I am getting is:</p>\n<pre><code>Traceback (most recent call last):\nFile \"script_test_classifier.py\", line 4, in &lt;module&gt;\n...\nline 33, in __initialize_session__\nnew_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\nread_meta_graph_file(meta_graph_or_file), clear_devices)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1598, in _import_meta_graph_def\ninput_graph_def, name=\"\", producer_op_list=producer_op_list)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 258, in import_graph_def\nop_def = op_dict[node.op]\nKeyError: u'SaveV2'\n</code></pre>\n<p>What is the reason of the error and how it could be fixed?</p>\n<p><strong>Production (CPU machine) environment info:</strong><br>\nAWS instance type: m4.xlarge<br>\nOperating System: Ubuntu 14.04 x64<br>\nInstalled version of CUDA and cuDNN: None, I am using CPU version of TF for the production environment<br>\nA link to the pip package you installed: <a href=\"https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl</a><br>\nThe output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>: 0.11.0</p>", "body_text": "I have a TensorFLow model trained on a GPU machine. Next, I need to export it and deploy on CPU only production machine.\nI have trained and exported a model from a GPU machine as described in MNIST export example. Saver object was initialized above.\nwith graph.as_default():\n    saver = tf.train.Saver(tf.all_variables(), sharded=True)\n...\n\nexport_path =  'resnet34_rmsprop_wd1e-1/saves/'\nprint('Exporting trained model to %s' % export_path)\ninit_op = tf.group(tf.initialize_all_tables(), name='init_op')\nmodel_exporter = exporter.Exporter(saver)\nmodel_exporter.init(sess.graph.as_graph_def(),\n                            init_op=init_op,\n                            default_graph_signature=exporter.classification_signature(input_tensor=inference_images,\n                                                                                      classes_tensor=inference_class,\n                                                                                      scores_tensor=inference_predictions),\n                            named_graph_signatures={'inputs': exporter.generic_signature({'images': inference_images}),\n                                                    'outputs': exporter.generic_signature({'class': inference_class, 'predictions': inference_predictions})})\nmodel_exporter.export(export_path, tf.constant(1), sess)\nprint('Done exporting!')\n\nNext, I am trying to load saved model to CPU machine with:\nnew_saver = tf.train.import_meta_graph('assets/saved_model/export.meta') new_saver.restore(sess, 'assets/saved_model/export')\nAnd what I am getting is:\nTraceback (most recent call last):\nFile \"script_test_classifier.py\", line 4, in <module>\n...\nline 33, in __initialize_session__\nnew_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\nread_meta_graph_file(meta_graph_or_file), clear_devices)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1598, in _import_meta_graph_def\ninput_graph_def, name=\"\", producer_op_list=producer_op_list)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 258, in import_graph_def\nop_def = op_dict[node.op]\nKeyError: u'SaveV2'\n\nWhat is the reason of the error and how it could be fixed?\nProduction (CPU machine) environment info:\nAWS instance type: m4.xlarge\nOperating System: Ubuntu 14.04 x64\nInstalled version of CUDA and cuDNN: None, I am using CPU version of TF for the production environment\nA link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\": 0.11.0", "body": "I have a TensorFLow model trained on a GPU machine. Next, I need to export it and deploy on CPU only production machine.\r\n\r\nI have trained and exported a model from a GPU machine as described in [MNIST export example](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_export.py). Saver object was initialized above.\r\n\r\n```\r\nwith graph.as_default():\r\n    saver = tf.train.Saver(tf.all_variables(), sharded=True)\r\n...\r\n\r\nexport_path =  'resnet34_rmsprop_wd1e-1/saves/'\r\nprint('Exporting trained model to %s' % export_path)\r\ninit_op = tf.group(tf.initialize_all_tables(), name='init_op')\r\nmodel_exporter = exporter.Exporter(saver)\r\nmodel_exporter.init(sess.graph.as_graph_def(),\r\n                            init_op=init_op,\r\n                            default_graph_signature=exporter.classification_signature(input_tensor=inference_images,\r\n                                                                                      classes_tensor=inference_class,\r\n                                                                                      scores_tensor=inference_predictions),\r\n                            named_graph_signatures={'inputs': exporter.generic_signature({'images': inference_images}),\r\n                                                    'outputs': exporter.generic_signature({'class': inference_class, 'predictions': inference_predictions})})\r\nmodel_exporter.export(export_path, tf.constant(1), sess)\r\nprint('Done exporting!')\r\n```\r\n\r\nNext, I am trying to load saved model to CPU machine with:\r\n\r\n`new_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')\r\nnew_saver.restore(sess, 'assets/saved_model/export')`\r\n\r\nAnd what I am getting is:\r\n\r\n```\r\nTraceback (most recent call last):\r\nFile \"script_test_classifier.py\", line 4, in <module>\r\n...\r\nline 33, in __initialize_session__\r\nnew_saver = tf.train.import_meta_graph('assets/saved_model/export.meta')\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1711, in import_meta_graph\r\nread_meta_graph_file(meta_graph_or_file), clear_devices)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1598, in _import_meta_graph_def\r\ninput_graph_def, name=\"\", producer_op_list=producer_op_list)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 258, in import_graph_def\r\nop_def = op_dict[node.op]\r\nKeyError: u'SaveV2'\r\n```\r\n\r\nWhat is the reason of the error and how it could be fixed?\r\n\r\n**Production (CPU machine) environment info:**\r\nAWS instance type: m4.xlarge\r\nOperating System: Ubuntu 14.04 x64\r\nInstalled version of CUDA and cuDNN: None, I am using CPU version of TF for the production environment\r\nA link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\r\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: 0.11.0\r\n"}