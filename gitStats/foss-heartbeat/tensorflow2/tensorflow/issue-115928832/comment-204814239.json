{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/204814239", "html_url": "https://github.com/tensorflow/tensorflow/issues/23#issuecomment-204814239", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23", "id": 204814239, "node_id": "MDEyOklzc3VlQ29tbWVudDIwNDgxNDIzOQ==", "user": {"login": "jramapuram", "id": 8204807, "node_id": "MDQ6VXNlcjgyMDQ4MDc=", "avatar_url": "https://avatars2.githubusercontent.com/u/8204807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jramapuram", "html_url": "https://github.com/jramapuram", "followers_url": "https://api.github.com/users/jramapuram/followers", "following_url": "https://api.github.com/users/jramapuram/following{/other_user}", "gists_url": "https://api.github.com/users/jramapuram/gists{/gist_id}", "starred_url": "https://api.github.com/users/jramapuram/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jramapuram/subscriptions", "organizations_url": "https://api.github.com/users/jramapuram/orgs", "repos_url": "https://api.github.com/users/jramapuram/repos", "events_url": "https://api.github.com/users/jramapuram/events{/privacy}", "received_events_url": "https://api.github.com/users/jramapuram/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-02T22:35:13Z", "updated_at": "2016-04-02T22:35:13Z", "author_association": "NONE", "body_html": "<p>The docs for distribution seem out of date when I tried to do this. <code>tf.make_cluster_def</code> is now private (i.e. <code>_make_cluster_def</code>)? I put together a simple example for testing purposes. I had a few segfaults along the way when I mismatched things, eg: if you only have one worker specified and set <code>task_index=1</code> will SEGFAULT.</p>\n<p>Here is what I did:<br>\nWorker Nodes setup:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ncluster_spec <span class=\"pl-k\">=</span> tf.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-worker0:2222<span class=\"pl-pds\">\"</span></span>,\n                                           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-worker1:2222<span class=\"pl-pds\">\"</span></span>],\n                                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-master0:2222<span class=\"pl-pds\">\"</span></span>]})\nserver_def <span class=\"pl-k\">=</span> tf.ServerDef(<span class=\"pl-v\">cluster</span><span class=\"pl-k\">=</span>cluster_spec.as_cluster_def(),\n                          <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>,\n                          <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,  <span class=\"pl-c\"><span class=\"pl-c\">#</span> switch this to 0 for worker1</span>\n                          <span class=\"pl-v\">protocol</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>grpc<span class=\"pl-pds\">\"</span></span>)\nserver <span class=\"pl-k\">=</span> tf.GrpcServer(server_def)\nserver.join()</pre></div>\n<p>ps Node Setup:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\ncluster_spec <span class=\"pl-k\">=</span> tf.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-worker0:2222<span class=\"pl-pds\">\"</span></span>,\n                                           <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-worker1:2222<span class=\"pl-pds\">\"</span></span>],\n                                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow-master0:2222<span class=\"pl-pds\">\"</span></span>]})\nserver_def <span class=\"pl-k\">=</span> tf.ServerDef(<span class=\"pl-v\">cluster</span><span class=\"pl-k\">=</span>cluster_spec.as_cluster_def(),\n                          <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>,\n                          <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n                          <span class=\"pl-v\">protocol</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>grpc<span class=\"pl-pds\">\"</span></span>)\nserver <span class=\"pl-k\">=</span> tf.GrpcServer(server_def)\nserver.join()</pre></div>\n<p>How to deploy a job:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:ps/task:0<span class=\"pl-pds\">\"</span></span>):\n    weights0 <span class=\"pl-k\">=</span> tf.Variable(tf.random_normal(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1024</span>, <span class=\"pl-c1\">512</span>]))\n    bias0 <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">512</span>]))\n\n<span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:1<span class=\"pl-pds\">\"</span></span>):\n    inputs <span class=\"pl-k\">=</span> tf.random_normal(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">10</span>, <span class=\"pl-c1\">1024</span>])\n    l0 <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(inputs, weights0) <span class=\"pl-k\">+</span> bias0)\n    l1 <span class=\"pl-k\">=</span> tf.nn.relu(tf.matmul(l0, tf.transpose(weights0)))\n    loss <span class=\"pl-k\">=</span> tf.nn.l2_loss(l1<span class=\"pl-k\">-</span>inputs)\n    train_op <span class=\"pl-k\">=</span> tf.train.AdamOptimizer().minimize(loss)\n\n<span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>grpc://tensorflow-master0:2222<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> sess:\n   <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n       sess.run(tf.initialize_all_variables())\n       _, l <span class=\"pl-k\">=</span> sess.run([train_op, loss])\n       <span class=\"pl-c1\">print</span> l</pre></div>\n<p>Regarding deployment systems: it would be nice to have a simple ansible deployment for this.</p>", "body_text": "The docs for distribution seem out of date when I tried to do this. tf.make_cluster_def is now private (i.e. _make_cluster_def)? I put together a simple example for testing purposes. I had a few segfaults along the way when I mismatched things, eg: if you only have one worker specified and set task_index=1 will SEGFAULT.\nHere is what I did:\nWorker Nodes setup:\nimport tensorflow as tf\n\ncluster_spec = tf.ClusterSpec({\"worker\": [\"tensorflow-worker0:2222\",\n                                           \"tensorflow-worker1:2222\"],\n                                \"ps\": [\"tensorflow-master0:2222\"]})\nserver_def = tf.ServerDef(cluster=cluster_spec.as_cluster_def(),\n                          job_name=\"worker\",\n                          task_index=1,  # switch this to 0 for worker1\n                          protocol=\"grpc\")\nserver = tf.GrpcServer(server_def)\nserver.join()\nps Node Setup:\nimport tensorflow as tf\n\ncluster_spec = tf.ClusterSpec({\"worker\": [\"tensorflow-worker0:2222\",\n                                           \"tensorflow-worker1:2222\"],\n                                \"ps\": [\"tensorflow-master0:2222\"]})\nserver_def = tf.ServerDef(cluster=cluster_spec.as_cluster_def(),\n                          job_name=\"ps\",\n                          task_index=0,\n                          protocol=\"grpc\")\nserver = tf.GrpcServer(server_def)\nserver.join()\nHow to deploy a job:\nimport tensorflow as tf\n\nwith tf.device(\"/job:ps/task:0\"):\n    weights0 = tf.Variable(tf.random_normal(shape=[1024, 512]))\n    bias0 = tf.Variable(tf.zeros(shape=[512]))\n\nwith tf.device(\"/job:worker/task:1\"):\n    inputs = tf.random_normal(shape=[10, 1024])\n    l0 = tf.nn.relu(tf.matmul(inputs, weights0) + bias0)\n    l1 = tf.nn.relu(tf.matmul(l0, tf.transpose(weights0)))\n    loss = tf.nn.l2_loss(l1-inputs)\n    train_op = tf.train.AdamOptimizer().minimize(loss)\n\nwith tf.Session(\"grpc://tensorflow-master0:2222\") as sess:\n   for _ in range(1000):\n       sess.run(tf.initialize_all_variables())\n       _, l = sess.run([train_op, loss])\n       print l\nRegarding deployment systems: it would be nice to have a simple ansible deployment for this.", "body": "The docs for distribution seem out of date when I tried to do this. `tf.make_cluster_def` is now private (i.e. `_make_cluster_def`)? I put together a simple example for testing purposes. I had a few segfaults along the way when I mismatched things, eg: if you only have one worker specified and set `task_index=1` will SEGFAULT. \n\nHere is what I did:\nWorker Nodes setup:\n\n``` python\nimport tensorflow as tf\n\ncluster_spec = tf.ClusterSpec({\"worker\": [\"tensorflow-worker0:2222\",\n                                           \"tensorflow-worker1:2222\"],\n                                \"ps\": [\"tensorflow-master0:2222\"]})\nserver_def = tf.ServerDef(cluster=cluster_spec.as_cluster_def(),\n                          job_name=\"worker\",\n                          task_index=1,  # switch this to 0 for worker1\n                          protocol=\"grpc\")\nserver = tf.GrpcServer(server_def)\nserver.join()\n```\n\nps Node Setup:\n\n``` python\nimport tensorflow as tf\n\ncluster_spec = tf.ClusterSpec({\"worker\": [\"tensorflow-worker0:2222\",\n                                           \"tensorflow-worker1:2222\"],\n                                \"ps\": [\"tensorflow-master0:2222\"]})\nserver_def = tf.ServerDef(cluster=cluster_spec.as_cluster_def(),\n                          job_name=\"ps\",\n                          task_index=0,\n                          protocol=\"grpc\")\nserver = tf.GrpcServer(server_def)\nserver.join()\n```\n\nHow to deploy a job:\n\n``` python\nimport tensorflow as tf\n\nwith tf.device(\"/job:ps/task:0\"):\n    weights0 = tf.Variable(tf.random_normal(shape=[1024, 512]))\n    bias0 = tf.Variable(tf.zeros(shape=[512]))\n\nwith tf.device(\"/job:worker/task:1\"):\n    inputs = tf.random_normal(shape=[10, 1024])\n    l0 = tf.nn.relu(tf.matmul(inputs, weights0) + bias0)\n    l1 = tf.nn.relu(tf.matmul(l0, tf.transpose(weights0)))\n    loss = tf.nn.l2_loss(l1-inputs)\n    train_op = tf.train.AdamOptimizer().minimize(loss)\n\nwith tf.Session(\"grpc://tensorflow-master0:2222\") as sess:\n   for _ in range(1000):\n       sess.run(tf.initialize_all_variables())\n       _, l = sess.run([train_op, loss])\n       print l\n```\n\nRegarding deployment systems: it would be nice to have a simple ansible deployment for this.\n"}