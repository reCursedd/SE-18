{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21464", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21464/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21464/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21464/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21464", "id": 348531788, "node_id": "MDU6SXNzdWUzNDg1MzE3ODg=", "number": 21464, "title": "StridedSlice (OpKernel was found, but attributes didn't match)", "user": {"login": "amtagrwl", "id": 5302320, "node_id": "MDQ6VXNlcjUzMDIzMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5302320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amtagrwl", "html_url": "https://github.com/amtagrwl", "followers_url": "https://api.github.com/users/amtagrwl/followers", "following_url": "https://api.github.com/users/amtagrwl/following{/other_user}", "gists_url": "https://api.github.com/users/amtagrwl/gists{/gist_id}", "starred_url": "https://api.github.com/users/amtagrwl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amtagrwl/subscriptions", "organizations_url": "https://api.github.com/users/amtagrwl/orgs", "repos_url": "https://api.github.com/users/amtagrwl/repos", "events_url": "https://api.github.com/users/amtagrwl/events{/privacy}", "received_events_url": "https://api.github.com/users/amtagrwl/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tanzhenyu", "id": 15220929, "node_id": "MDQ6VXNlcjE1MjIwOTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15220929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanzhenyu", "html_url": "https://github.com/tanzhenyu", "followers_url": "https://api.github.com/users/tanzhenyu/followers", "following_url": "https://api.github.com/users/tanzhenyu/following{/other_user}", "gists_url": "https://api.github.com/users/tanzhenyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanzhenyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanzhenyu/subscriptions", "organizations_url": "https://api.github.com/users/tanzhenyu/orgs", "repos_url": "https://api.github.com/users/tanzhenyu/repos", "events_url": "https://api.github.com/users/tanzhenyu/events{/privacy}", "received_events_url": "https://api.github.com/users/tanzhenyu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tanzhenyu", "id": 15220929, "node_id": "MDQ6VXNlcjE1MjIwOTI5", "avatar_url": "https://avatars3.githubusercontent.com/u/15220929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanzhenyu", "html_url": "https://github.com/tanzhenyu", "followers_url": "https://api.github.com/users/tanzhenyu/followers", "following_url": "https://api.github.com/users/tanzhenyu/following{/other_user}", "gists_url": "https://api.github.com/users/tanzhenyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanzhenyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanzhenyu/subscriptions", "organizations_url": "https://api.github.com/users/tanzhenyu/orgs", "repos_url": "https://api.github.com/users/tanzhenyu/repos", "events_url": "https://api.github.com/users/tanzhenyu/events{/privacy}", "received_events_url": "https://api.github.com/users/tanzhenyu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-08-08T00:24:17Z", "updated_at": "2018-10-10T18:18:03Z", "closed_at": "2018-10-10T00:19:28Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Docker ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary - docker</li>\n<li><strong>TensorFlow version (use command below)</strong>: nightly version as of August 6th 2018</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:   V9.0.176</li>\n<li><strong>GPU model and memory</strong>: 4 * GTX 1080 Ti</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I have written code to train a boosted trees estimator. The code gives an error even before it starts training if run on the GPU. On the other hand, it runs without any issues on the CPU.</p>\n<p>The issue seems to be with the StridedSlice op and an incompatible op.</p>\n<p>I have attached the log of the error below.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:993: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\nInstructions for updating:\nShapes are always computed; don't use the compute_shapes as it has no effect.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Saving checkpoints for 0 into GBDT_multi/GPU/vLat-vLon/model.ckpt.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1291     try:\n-&gt; 1292       return fn(*args)\n   1293     except errors.OpError as e:\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1276       return self._call_tf_sessionrun(\n-&gt; 1277           options, feed_dict, fetch_list, target_list, run_metadata)\n   1278 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\n   1366         self._session, options, feed_dict, fetch_list, target_list,\n-&gt; 1367         run_metadata)\n   1368 \n\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_INT64]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_INT64]\n\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nNotFoundError                             Traceback (most recent call last)\n&lt;ipython-input-18-5992a8bb32bf&gt; in &lt;module&gt;()\n     13             }\n     14 \n---&gt; 15 _ = train_GBDT_regressor()\n\n&lt;ipython-input-15-c864123abd09&gt; in train_GBDT_regressor()\n    128         learn_runner.run(experiment_fn=create_gbdt_experiment, \n    129                          output_dir=TRAIN_DATA['model_dir'],\n--&gt; 130                          schedule=\"train_and_evaluate\"\n    131                         )      \n    132 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    304               'in a future version' if date is None else ('after %s' % date),\n    305               instructions)\n--&gt; 306       return func(*args, **kwargs)\n    307     return tf_decorator.make_decorator(\n    308         func, new_func, 'deprecated',\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\n    223   schedule = schedule or _get_default_schedule(run_config)\n    224 \n--&gt; 225   return _execute_schedule(experiment, schedule)\n    226 \n    227 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)\n     50     logging.error('Allowed values for this experiment are: %s', valid_tasks)\n     51     raise TypeError('Schedule references non-callable member %s' % schedule)\n---&gt; 52   return task()\n     53 \n     54 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)\n    670                   hooks=self._eval_hooks)\n    671           ]\n--&gt; 672       self.train(delay_secs=0)\n    673 \n    674     # If the checkpoint_and_export flag and appropriate estimator configuration\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)\n    387         max_steps=self._train_steps,\n    388         hooks=self._train_monitors + extra_hooks,\n--&gt; 389         saving_listeners=self._saving_listeners)\n    390 \n    391   def evaluate(self, delay_secs=None, name=None):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)\n    881           max_steps=max_steps,\n    882           hooks=hooks,\n--&gt; 883           saving_listeners=saving_listeners)\n    884     else:\n    885       return self._estimator.fit(\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    341 \n    342       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 343       loss = self._train_model(input_fn, hooks, saving_listeners)\n    344       logging.info('Loss for final step: %s.', loss)\n    345       return self\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1127       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1128     else:\n-&gt; 1129       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1130 \n   1131   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1161       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1162                                              hooks, global_step_tensor,\n-&gt; 1163                                              saving_listeners)\n   1164 \n   1165   def _train_model_distributed(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\n   1369       loss = None\n   1370       while not mon_sess.should_stop():\n-&gt; 1371         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n   1372     return loss\n   1373 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n    581                           feed_dict=feed_dict,\n    582                           options=options,\n--&gt; 583                           run_metadata=run_metadata)\n    584 \n    585   def run_step_fn(self, step_fn):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1057                               feed_dict=feed_dict,\n   1058                               options=options,\n-&gt; 1059                               run_metadata=run_metadata)\n   1060       except _PREEMPTION_ERRORS as e:\n   1061         logging.info('An error was raised. This may be due to a preemption in '\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1148         raise six.reraise(*original_exc_info)\n   1149       else:\n-&gt; 1150         raise six.reraise(*original_exc_info)\n   1151 \n   1152 \n\n/usr/local/lib/python3.5/dist-packages/six.py in reraise(tp, value, tb)\n    691             if value.__traceback__ is not tb:\n    692                 raise value.with_traceback(tb)\n--&gt; 693             raise value\n    694         finally:\n    695             value = None\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1133   def run(self, *args, **kwargs):\n   1134     try:\n-&gt; 1135       return self._sess.run(*args, **kwargs)\n   1136     except _PREEMPTION_ERRORS:\n   1137       raise\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1205                                   feed_dict=feed_dict,\n   1206                                   options=options,\n-&gt; 1207                                   run_metadata=run_metadata)\n   1208 \n   1209     for hook in self._hooks:\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n    985 \n    986   def run(self, *args, **kwargs):\n--&gt; 987     return self._sess.run(*args, **kwargs)\n    988 \n    989   def run_step_fn(self, step_fn, raw_session, run_with_hooks):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    885     try:\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 887                          run_metadata_ptr)\n    888       if run_metadata:\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1109       results = self._do_run(handle, final_targets, final_fetches,\n-&gt; 1110                              feed_dict_tensor, options, run_metadata)\n   1111     else:\n   1112       results = []\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1284     if handle is None:\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-&gt; 1286                            run_metadata)\n   1287     else:\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1306           self._config.experimental.client_handles_error_formatting):\n   1307         message = error_interpolation.interpolate(message, self._graph)\n-&gt; 1308       raise type(e)(node_def, op, message)\n   1309 \n   1310   def _extend_graph(self):\n\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_INT64]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_INT64]\n\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Docker ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): binary - docker\nTensorFlow version (use command below): nightly version as of August 6th 2018\nPython version: 3.5.2\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:   V9.0.176\nGPU model and memory: 4 * GTX 1080 Ti\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI have written code to train a boosted trees estimator. The code gives an error even before it starts training if run on the GPU. On the other hand, it runs without any issues on the CPU.\nThe issue seems to be with the StridedSlice op and an incompatible op.\nI have attached the log of the error below.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:993: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\nInstructions for updating:\nShapes are always computed; don't use the compute_shapes as it has no effect.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Saving checkpoints for 0 into GBDT_multi/GPU/vLat-vLon/model.ckpt.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1291     try:\n-> 1292       return fn(*args)\n   1293     except errors.OpError as e:\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1276       return self._call_tf_sessionrun(\n-> 1277           options, feed_dict, fetch_list, target_list, run_metadata)\n   1278 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\n   1366         self._session, options, feed_dict, fetch_list, target_list,\n-> 1367         run_metadata)\n   1368 \n\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_INT64]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_INT64]\n\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nNotFoundError                             Traceback (most recent call last)\n<ipython-input-18-5992a8bb32bf> in <module>()\n     13             }\n     14 \n---> 15 _ = train_GBDT_regressor()\n\n<ipython-input-15-c864123abd09> in train_GBDT_regressor()\n    128         learn_runner.run(experiment_fn=create_gbdt_experiment, \n    129                          output_dir=TRAIN_DATA['model_dir'],\n--> 130                          schedule=\"train_and_evaluate\"\n    131                         )      \n    132 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\n    304               'in a future version' if date is None else ('after %s' % date),\n    305               instructions)\n--> 306       return func(*args, **kwargs)\n    307     return tf_decorator.make_decorator(\n    308         func, new_func, 'deprecated',\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\n    223   schedule = schedule or _get_default_schedule(run_config)\n    224 \n--> 225   return _execute_schedule(experiment, schedule)\n    226 \n    227 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)\n     50     logging.error('Allowed values for this experiment are: %s', valid_tasks)\n     51     raise TypeError('Schedule references non-callable member %s' % schedule)\n---> 52   return task()\n     53 \n     54 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)\n    670                   hooks=self._eval_hooks)\n    671           ]\n--> 672       self.train(delay_secs=0)\n    673 \n    674     # If the checkpoint_and_export flag and appropriate estimator configuration\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)\n    387         max_steps=self._train_steps,\n    388         hooks=self._train_monitors + extra_hooks,\n--> 389         saving_listeners=self._saving_listeners)\n    390 \n    391   def evaluate(self, delay_secs=None, name=None):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)\n    881           max_steps=max_steps,\n    882           hooks=hooks,\n--> 883           saving_listeners=saving_listeners)\n    884     else:\n    885       return self._estimator.fit(\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    341 \n    342       saving_listeners = _check_listeners_type(saving_listeners)\n--> 343       loss = self._train_model(input_fn, hooks, saving_listeners)\n    344       logging.info('Loss for final step: %s.', loss)\n    345       return self\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1127       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1128     else:\n-> 1129       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1130 \n   1131   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1161       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n   1162                                              hooks, global_step_tensor,\n-> 1163                                              saving_listeners)\n   1164 \n   1165   def _train_model_distributed(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\n   1369       loss = None\n   1370       while not mon_sess.should_stop():\n-> 1371         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n   1372     return loss\n   1373 \n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n    581                           feed_dict=feed_dict,\n    582                           options=options,\n--> 583                           run_metadata=run_metadata)\n    584 \n    585   def run_step_fn(self, step_fn):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1057                               feed_dict=feed_dict,\n   1058                               options=options,\n-> 1059                               run_metadata=run_metadata)\n   1060       except _PREEMPTION_ERRORS as e:\n   1061         logging.info('An error was raised. This may be due to a preemption in '\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1148         raise six.reraise(*original_exc_info)\n   1149       else:\n-> 1150         raise six.reraise(*original_exc_info)\n   1151 \n   1152 \n\n/usr/local/lib/python3.5/dist-packages/six.py in reraise(tp, value, tb)\n    691             if value.__traceback__ is not tb:\n    692                 raise value.with_traceback(tb)\n--> 693             raise value\n    694         finally:\n    695             value = None\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n   1133   def run(self, *args, **kwargs):\n   1134     try:\n-> 1135       return self._sess.run(*args, **kwargs)\n   1136     except _PREEMPTION_ERRORS:\n   1137       raise\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\n   1205                                   feed_dict=feed_dict,\n   1206                                   options=options,\n-> 1207                                   run_metadata=run_metadata)\n   1208 \n   1209     for hook in self._hooks:\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\n    985 \n    986   def run(self, *args, **kwargs):\n--> 987     return self._sess.run(*args, **kwargs)\n    988 \n    989   def run_step_fn(self, step_fn, raw_session, run_with_hooks):\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    885     try:\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 887                          run_metadata_ptr)\n    888       if run_metadata:\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1109       results = self._do_run(handle, final_targets, final_fetches,\n-> 1110                              feed_dict_tensor, options, run_metadata)\n   1111     else:\n   1112       results = []\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1284     if handle is None:\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1286                            run_metadata)\n   1287     else:\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1306           self._config.experimental.client_handles_error_formatting):\n   1307         message = error_interpolation.interpolate(message, self._graph)\n-> 1308       raise type(e)(node_def, op, message)\n   1309 \n   1310   def _extend_graph(self):\n\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\n\t (OpKernel was found, but attributes didn't match)\n\t.  Registered:  device='GPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_INT64]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_VARIANT]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_INT64]\n\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Docker ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary - docker\r\n- **TensorFlow version (use command below)**: nightly version as of August 6th 2018\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:   V9.0.176\r\n- **GPU model and memory**: 4 * GTX 1080 Ti \r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI have written code to train a boosted trees estimator. The code gives an error even before it starts training if run on the GPU. On the other hand, it runs without any issues on the CPU. \r\n\r\nThe issue seems to be with the StridedSlice op and an incompatible op. \r\n\r\nI have attached the log of the error below. \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/function.py:993: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nShapes are always computed; don't use the compute_shapes as it has no effect.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nWARNING:tensorflow:Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nWARNING:tensorflow:Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\nINFO:tensorflow:Saving checkpoints for 0 into GBDT_multi/GPU/vLat-vLon/model.ckpt.\r\nWARNING:tensorflow:Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1291     try:\r\n-> 1292       return fn(*args)\r\n   1293     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1276       return self._call_tf_sessionrun(\r\n-> 1277           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1278 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1366         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1367         run_metadata)\r\n   1368 \r\n\r\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_VARIANT]\r\n  device='CPU'; T in [DT_RESOURCE]\r\n  device='CPU'; T in [DT_STRING]\r\n  device='CPU'; T in [DT_BOOL]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_INT8]\r\n  device='CPU'; T in [DT_UINT8]\r\n  device='CPU'; T in [DT_INT16]\r\n  device='CPU'; T in [DT_UINT16]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]\r\n\r\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\r\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\r\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-18-5992a8bb32bf> in <module>()\r\n     13             }\r\n     14 \r\n---> 15 _ = train_GBDT_regressor()\r\n\r\n<ipython-input-15-c864123abd09> in train_GBDT_regressor()\r\n    128         learn_runner.run(experiment_fn=create_gbdt_experiment, \r\n    129                          output_dir=TRAIN_DATA['model_dir'],\r\n--> 130                          schedule=\"train_and_evaluate\"\r\n    131                         )      \r\n    132 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    304               'in a future version' if date is None else ('after %s' % date),\r\n    305               instructions)\r\n--> 306       return func(*args, **kwargs)\r\n    307     return tf_decorator.make_decorator(\r\n    308         func, new_func, 'deprecated',\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)\r\n    223   schedule = schedule or _get_default_schedule(run_config)\r\n    224 \r\n--> 225   return _execute_schedule(experiment, schedule)\r\n    226 \r\n    227 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)\r\n     50     logging.error('Allowed values for this experiment are: %s', valid_tasks)\r\n     51     raise TypeError('Schedule references non-callable member %s' % schedule)\r\n---> 52   return task()\r\n     53 \r\n     54 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)\r\n    670                   hooks=self._eval_hooks)\r\n    671           ]\r\n--> 672       self.train(delay_secs=0)\r\n    673 \r\n    674     # If the checkpoint_and_export flag and appropriate estimator configuration\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)\r\n    387         max_steps=self._train_steps,\r\n    388         hooks=self._train_monitors + extra_hooks,\r\n--> 389         saving_listeners=self._saving_listeners)\r\n    390 \r\n    391   def evaluate(self, delay_secs=None, name=None):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)\r\n    881           max_steps=max_steps,\r\n    882           hooks=hooks,\r\n--> 883           saving_listeners=saving_listeners)\r\n    884     else:\r\n    885       return self._estimator.fit(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    341 \r\n    342       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 343       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    344       logging.info('Loss for final step: %s.', loss)\r\n    345       return self\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1127       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1128     else:\r\n-> 1129       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1130 \r\n   1131   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1161       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n   1162                                              hooks, global_step_tensor,\r\n-> 1163                                              saving_listeners)\r\n   1164 \r\n   1165   def _train_model_distributed(self, input_fn, hooks, saving_listeners):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\r\n   1369       loss = None\r\n   1370       while not mon_sess.should_stop():\r\n-> 1371         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n   1372     return loss\r\n   1373 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    581                           feed_dict=feed_dict,\r\n    582                           options=options,\r\n--> 583                           run_metadata=run_metadata)\r\n    584 \r\n    585   def run_step_fn(self, step_fn):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n   1057                               feed_dict=feed_dict,\r\n   1058                               options=options,\r\n-> 1059                               run_metadata=run_metadata)\r\n   1060       except _PREEMPTION_ERRORS as e:\r\n   1061         logging.info('An error was raised. This may be due to a preemption in '\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\r\n   1148         raise six.reraise(*original_exc_info)\r\n   1149       else:\r\n-> 1150         raise six.reraise(*original_exc_info)\r\n   1151 \r\n   1152 \r\n\r\n/usr/local/lib/python3.5/dist-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\r\n   1133   def run(self, *args, **kwargs):\r\n   1134     try:\r\n-> 1135       return self._sess.run(*args, **kwargs)\r\n   1136     except _PREEMPTION_ERRORS:\r\n   1137       raise\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n   1205                                   feed_dict=feed_dict,\r\n   1206                                   options=options,\r\n-> 1207                                   run_metadata=run_metadata)\r\n   1208 \r\n   1209     for hook in self._hooks:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)\r\n    985 \r\n    986   def run(self, *args, **kwargs):\r\n--> 987     return self._sess.run(*args, **kwargs)\r\n    988 \r\n    989   def run_step_fn(self, step_fn, raw_session, run_with_hooks):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    885     try:\r\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 887                          run_metadata_ptr)\r\n    888       if run_metadata:\r\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1109       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1110                              feed_dict_tensor, options, run_metadata)\r\n   1111     else:\r\n   1112       results = []\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1284     if handle is None:\r\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1286                            run_metadata)\r\n   1287     else:\r\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1306           self._config.experimental.client_handles_error_formatting):\r\n   1307         message = error_interpolation.interpolate(message, self._graph)\r\n-> 1308       raise type(e)(node_def, op, message)\r\n   1309 \r\n   1310   def _extend_graph(self):\r\n\r\nNotFoundError: No registered 'StridedSlice' OpKernel for GPU devices compatible with node {{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_VARIANT]\r\n  device='CPU'; T in [DT_RESOURCE]\r\n  device='CPU'; T in [DT_STRING]\r\n  device='CPU'; T in [DT_BOOL]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_BFLOAT16]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_INT8]\r\n  device='CPU'; T in [DT_UINT8]\r\n  device='CPU'; T in [DT_INT16]\r\n  device='CPU'; T in [DT_UINT16]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]\r\n\r\n\t [[{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_BOOL, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](is_active, strided_slice/stack, strided_slice/stack_1, strided_slice/stack)]]\r\n\t [[{{node head/historyyawDiff5/dense_make_stats_update_pTOiIS60uTM}} = dense_make_stats_update_pTOiIS60uTM_specialized_for_head_currentspeed1_dense_make_stats_update_pTOiIS60uTM[_device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ConstantFolding/head/unstack_13-folded-0/_377, head/unstack_11/_379, gbdt/transform_features_13/history_yawDiff_5/ExpandDims, head/split:25, gbdt_1/GradientTreesPartitionExamples/_381, head/Gradients/head/mean_squared_error/SquaredDifference_grad/Reshape, head/stack, head/Sum)]]\r\n\t [[{{node head/cond_1/cond/split/_1463}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3016_head/cond_1/cond/split\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```"}