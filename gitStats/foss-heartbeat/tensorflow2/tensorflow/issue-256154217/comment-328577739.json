{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/328577739", "html_url": "https://github.com/tensorflow/tensorflow/issues/12898#issuecomment-328577739", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898", "id": 328577739, "node_id": "MDEyOklzc3VlQ29tbWVudDMyODU3NzczOQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-11T16:07:11Z", "updated_at": "2017-09-11T16:07:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hm 20 usec on cached allocation on GPU would be quite terrible. You can have 10's of thousands of temporary allocations during running of a large network, so that could mean half a second of overhead in session.run purely due to tensor allocation calls.</p>\n<p>I do wonder if this 20 usec delay between your print messages is an actual bottleneck that can be eliminated, or if its a side effect of things running asynchronously. cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a></p>", "body_text": "Hm 20 usec on cached allocation on GPU would be quite terrible. You can have 10's of thousands of temporary allocations during running of a large network, so that could mean half a second of overhead in session.run purely due to tensor allocation calls.\nI do wonder if this 20 usec delay between your print messages is an actual bottleneck that can be eliminated, or if its a side effect of things running asynchronously. cc @zheng-xq cc @reedwm", "body": "Hm 20 usec on cached allocation on GPU would be quite terrible. You can have 10's of thousands of temporary allocations during running of a large network, so that could mean half a second of overhead in session.run purely due to tensor allocation calls. \r\n\r\nI do wonder if this 20 usec delay between your print messages is an actual bottleneck that can be eliminated, or if its a side effect of things running asynchronously. cc @zheng-xq cc @reedwm "}