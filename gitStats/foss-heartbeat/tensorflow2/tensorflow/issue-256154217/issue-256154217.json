{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12898", "id": 256154217, "node_id": "MDU6SXNzdWUyNTYxNTQyMTc=", "number": 12898, "title": "allocate output tensor for every operation before the first inference", "user": {"login": "jiazhe0909", "id": 8175586, "node_id": "MDQ6VXNlcjgxNzU1ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8175586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiazhe0909", "html_url": "https://github.com/jiazhe0909", "followers_url": "https://api.github.com/users/jiazhe0909/followers", "following_url": "https://api.github.com/users/jiazhe0909/following{/other_user}", "gists_url": "https://api.github.com/users/jiazhe0909/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiazhe0909/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiazhe0909/subscriptions", "organizations_url": "https://api.github.com/users/jiazhe0909/orgs", "repos_url": "https://api.github.com/users/jiazhe0909/repos", "events_url": "https://api.github.com/users/jiazhe0909/events{/privacy}", "received_events_url": "https://api.github.com/users/jiazhe0909/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-09-08T06:34:42Z", "updated_at": "2017-09-13T17:54:42Z", "closed_at": "2017-09-13T17:53:39Z", "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p>I was wondering if it's possible to allocate memory in advance, for internal output tensors of every operation in my inference workload.<br>\nI notice TF will automatically allocate (and de-allocate) memory for every internal result in a graph. If my inference workload repeats many times, all these allocations/deallocations will also repeat. Why don't we allocate these internal output tensors just once before the first inference run, and delete them after the last?</p>\n<p>For example, I have the following workload (which will run thousands of times):</p>\n<pre><code>    M = tf.MatMul(A, B)\n    D = tf.MatMul(M, C)\n</code></pre>\n<p>Is it possible to allocate M before the first run and use the memory for all inference? To avoid allocation of M in every single inference?</p>", "body_text": "Describe the problem\nI was wondering if it's possible to allocate memory in advance, for internal output tensors of every operation in my inference workload.\nI notice TF will automatically allocate (and de-allocate) memory for every internal result in a graph. If my inference workload repeats many times, all these allocations/deallocations will also repeat. Why don't we allocate these internal output tensors just once before the first inference run, and delete them after the last?\nFor example, I have the following workload (which will run thousands of times):\n    M = tf.MatMul(A, B)\n    D = tf.MatMul(M, C)\n\nIs it possible to allocate M before the first run and use the memory for all inference? To avoid allocation of M in every single inference?", "body": "### Describe the problem\r\nI was wondering if it's possible to allocate memory in advance, for internal output tensors of every operation in my inference workload. \r\nI notice TF will automatically allocate (and de-allocate) memory for every internal result in a graph. If my inference workload repeats many times, all these allocations/deallocations will also repeat. Why don't we allocate these internal output tensors just once before the first inference run, and delete them after the last?\r\n\r\nFor example, I have the following workload (which will run thousands of times):\r\n```\r\n    M = tf.MatMul(A, B)\r\n    D = tf.MatMul(M, C)\r\n````\r\nIs it possible to allocate M before the first run and use the memory for all inference? To avoid allocation of M in every single inference?\r\n"}