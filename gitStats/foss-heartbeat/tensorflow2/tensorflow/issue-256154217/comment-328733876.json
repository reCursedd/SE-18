{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/328733876", "html_url": "https://github.com/tensorflow/tensorflow/issues/12898#issuecomment-328733876", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12898", "id": 328733876, "node_id": "MDEyOklzc3VlQ29tbWVudDMyODczMzg3Ng==", "user": {"login": "jiazhe0909", "id": 8175586, "node_id": "MDQ6VXNlcjgxNzU1ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8175586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiazhe0909", "html_url": "https://github.com/jiazhe0909", "followers_url": "https://api.github.com/users/jiazhe0909/followers", "following_url": "https://api.github.com/users/jiazhe0909/following{/other_user}", "gists_url": "https://api.github.com/users/jiazhe0909/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiazhe0909/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiazhe0909/subscriptions", "organizations_url": "https://api.github.com/users/jiazhe0909/orgs", "repos_url": "https://api.github.com/users/jiazhe0909/repos", "events_url": "https://api.github.com/users/jiazhe0909/events{/privacy}", "received_events_url": "https://api.github.com/users/jiazhe0909/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-12T04:39:41Z", "updated_at": "2017-09-12T04:41:11Z", "author_association": "NONE", "body_html": "<p>Thanks for your replies, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a>  and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6510203\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/reedwm\">@reedwm</a> .<br>\nIf the allocator really takes 10s of usec, I guess the output-allocation process could still be a bottleneck even in GPU inference workload.<br>\nFor example, we can consider a case that CPU side allocating process doesn't overlap with the previous launched GPU calculation.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8175586/30308136-ba738734-9772-11e7-95f7-909b113cb66d.jpg\"><img src=\"https://user-images.githubusercontent.com/8175586/30308136-ba738734-9772-11e7-95f7-909b113cb66d.jpg\" alt=\"20170912_120218\" style=\"max-width:100%;\"></a><br>\nI guess this could happen in inference (or training with small batch size) scenarios.</p>", "body_text": "Thanks for your replies, @yaroslavvb  and @reedwm .\nIf the allocator really takes 10s of usec, I guess the output-allocation process could still be a bottleneck even in GPU inference workload.\nFor example, we can consider a case that CPU side allocating process doesn't overlap with the previous launched GPU calculation.\n\nI guess this could happen in inference (or training with small batch size) scenarios.", "body": "Thanks for your replies, @yaroslavvb  and @reedwm .\r\nIf the allocator really takes 10s of usec, I guess the output-allocation process could still be a bottleneck even in GPU inference workload. \r\nFor example, we can consider a case that CPU side allocating process doesn't overlap with the previous launched GPU calculation.\r\n![20170912_120218](https://user-images.githubusercontent.com/8175586/30308136-ba738734-9772-11e7-95f7-909b113cb66d.jpg)\r\nI guess this could happen in inference (or training with small batch size) scenarios.\r\n  \r\n"}