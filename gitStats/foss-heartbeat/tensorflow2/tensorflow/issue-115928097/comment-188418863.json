{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/188418863", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-188418863", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 188418863, "node_id": "MDEyOklzc3VlQ29tbWVudDE4ODQxODg2Mw==", "user": {"login": "strin", "id": 2183232, "node_id": "MDQ6VXNlcjIxODMyMzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2183232?v=4", "gravatar_id": "", "url": "https://api.github.com/users/strin", "html_url": "https://github.com/strin", "followers_url": "https://api.github.com/users/strin/followers", "following_url": "https://api.github.com/users/strin/following{/other_user}", "gists_url": "https://api.github.com/users/strin/gists{/gist_id}", "starred_url": "https://api.github.com/users/strin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/strin/subscriptions", "organizations_url": "https://api.github.com/users/strin/orgs", "repos_url": "https://api.github.com/users/strin/repos", "events_url": "https://api.github.com/users/strin/events{/privacy}", "received_events_url": "https://api.github.com/users/strin/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-24T19:29:21Z", "updated_at": "2016-02-24T19:29:21Z", "author_association": "NONE", "body_html": "<p>This thread is very interesting. I've been trying to get caffe to work on android. The results seem to be surprising: caffe running with Mali gpu seems to be 2-3 slower than cpu, but about 4-5x more energy efficient. The test was run on Galaxy S6 (Mali T760, Peak Performance 200 GFlops).</p>\n<p>Since GEMM is the core of convolution in caffe, I decided to profile its performance on Android. It seems that ViennaCL is not as efficient as some simple kernels. Now I am able to get GPU run as fast as CPU for large matrices (2k x 2k). This is still counter-intuitive, since normally we expect GPUs to be much faster.</p>\n<p>See:<br>\n<a href=\"https://github.com/strin/mocha-profile\">https://github.com/strin/mocha-profile</a></p>\n<p>The kernel implementations can be found here:</p>\n<p>OpenCL kernels for GEMM: <a href=\"https://github.com/strin/gemm-android\">https://github.com/strin/gemm-android</a></p>\n<p>Any thoughts?</p>", "body_text": "This thread is very interesting. I've been trying to get caffe to work on android. The results seem to be surprising: caffe running with Mali gpu seems to be 2-3 slower than cpu, but about 4-5x more energy efficient. The test was run on Galaxy S6 (Mali T760, Peak Performance 200 GFlops).\nSince GEMM is the core of convolution in caffe, I decided to profile its performance on Android. It seems that ViennaCL is not as efficient as some simple kernels. Now I am able to get GPU run as fast as CPU for large matrices (2k x 2k). This is still counter-intuitive, since normally we expect GPUs to be much faster.\nSee:\nhttps://github.com/strin/mocha-profile\nThe kernel implementations can be found here:\nOpenCL kernels for GEMM: https://github.com/strin/gemm-android\nAny thoughts?", "body": "This thread is very interesting. I've been trying to get caffe to work on android. The results seem to be surprising: caffe running with Mali gpu seems to be 2-3 slower than cpu, but about 4-5x more energy efficient. The test was run on Galaxy S6 (Mali T760, Peak Performance 200 GFlops). \n\nSince GEMM is the core of convolution in caffe, I decided to profile its performance on Android. It seems that ViennaCL is not as efficient as some simple kernels. Now I am able to get GPU run as fast as CPU for large matrices (2k x 2k). This is still counter-intuitive, since normally we expect GPUs to be much faster.\n\nSee: \n[https://github.com/strin/mocha-profile](https://github.com/strin/mocha-profile)\n\nThe kernel implementations can be found here:\n\nOpenCL kernels for GEMM: [https://github.com/strin/gemm-android](https://github.com/strin/gemm-android)\n\nAny thoughts?\n"}