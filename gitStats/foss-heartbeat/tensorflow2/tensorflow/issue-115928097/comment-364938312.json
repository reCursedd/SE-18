{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364938312", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-364938312", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 364938312, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDkzODMxMg==", "user": {"login": "cathalgarvey", "id": 1167837, "node_id": "MDQ6VXNlcjExNjc4Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1167837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cathalgarvey", "html_url": "https://github.com/cathalgarvey", "followers_url": "https://api.github.com/users/cathalgarvey/followers", "following_url": "https://api.github.com/users/cathalgarvey/following{/other_user}", "gists_url": "https://api.github.com/users/cathalgarvey/gists{/gist_id}", "starred_url": "https://api.github.com/users/cathalgarvey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cathalgarvey/subscriptions", "organizations_url": "https://api.github.com/users/cathalgarvey/orgs", "repos_url": "https://api.github.com/users/cathalgarvey/repos", "events_url": "https://api.github.com/users/cathalgarvey/events{/privacy}", "received_events_url": "https://api.github.com/users/cathalgarvey/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-12T14:29:01Z", "updated_at": "2018-02-12T14:29:01Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">As I understand it, benchmarking is hard if you compare CUDA to OpenCL, because you have to use different hardware. Allegedly, nVidia deliberately made/allowed their OpenCL implementation to be somewhat broken, so benchmarking on the same hardware will always result in CUDA looking great.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On 12 February 2018 14:26:11 GMT+00:00, VincentSC ***@***.***&gt; wrote:\nIs the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or\nmaking it actually run faster? I'd prefer there not a holy war, but\nfocusing on getting it to run fast on several GPUs. LifeIsStrange's\nfocus is on getting it to work on AMD GPUs and then HIP makes good\nsense. For others the focus is to make it work on Intel GPUs or\nAndroid, and then OpenCL makes much more sense. GPU-languages are a\nmess, so please keep practical,\n\nIf I read some of the comments here, performance is an issue with the\nOpenCL ports. But unfortunately I cannot see many benchmarks around.\nAre there more benchmarks than this one?\n<a href=\"https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md\">https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md</a>\n\n--\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115928097\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22\" href=\"https://github.com/tensorflow/tensorflow/issues/22#issuecomment-364936498\">#22 (comment)</a>\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.</div>\n</div>", "body_text": "As I understand it, benchmarking is hard if you compare CUDA to OpenCL, because you have to use different hardware. Allegedly, nVidia deliberately made/allowed their OpenCL implementation to be somewhat broken, so benchmarking on the same hardware will always result in CUDA looking great.\n\u2026\nOn 12 February 2018 14:26:11 GMT+00:00, VincentSC ***@***.***> wrote:\nIs the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or\nmaking it actually run faster? I'd prefer there not a holy war, but\nfocusing on getting it to run fast on several GPUs. LifeIsStrange's\nfocus is on getting it to work on AMD GPUs and then HIP makes good\nsense. For others the focus is to make it work on Intel GPUs or\nAndroid, and then OpenCL makes much more sense. GPU-languages are a\nmess, so please keep practical,\n\nIf I read some of the comments here, performance is an issue with the\nOpenCL ports. But unfortunately I cannot see many benchmarks around.\nAre there more benchmarks than this one?\nhttps://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md\n\n--\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\n#22 (comment)\n\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.", "body": "As I understand it, benchmarking is hard if you compare CUDA to OpenCL, because you have to use different hardware. Allegedly, nVidia deliberately made/allowed their OpenCL implementation to be somewhat broken, so benchmarking on the same hardware will always result in CUDA looking great.\n\nOn 12 February 2018 14:26:11 GMT+00:00, VincentSC <notifications@github.com> wrote:\n>Is the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or\n>making it actually run faster? I'd prefer there not a holy war, but\n>focusing on getting it to run fast on several GPUs. LifeIsStrange's\n>focus is on getting it to work on AMD GPUs and then HIP makes good\n>sense. For others the focus is to make it work on Intel GPUs or\n>Android, and then OpenCL makes much more sense. GPU-languages are a\n>mess, so please keep practical, \n>\n>If I read some of the comments here, performance is an issue with the\n>OpenCL ports. But unfortunately I cannot see many benchmarks around.\n>Are there more benchmarks than this one?\n>https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md\n>\n>-- \n>You are receiving this because you were mentioned.\n>Reply to this email directly or view it on GitHub:\n>https://github.com/tensorflow/tensorflow/issues/22#issuecomment-364936498\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity."}