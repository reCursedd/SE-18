{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/298011934", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-298011934", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 298011934, "node_id": "MDEyOklzc3VlQ29tbWVudDI5ODAxMTkzNA==", "user": {"login": "thornhale", "id": 3866917, "node_id": "MDQ6VXNlcjM4NjY5MTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3866917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thornhale", "html_url": "https://github.com/thornhale", "followers_url": "https://api.github.com/users/thornhale/followers", "following_url": "https://api.github.com/users/thornhale/following{/other_user}", "gists_url": "https://api.github.com/users/thornhale/gists{/gist_id}", "starred_url": "https://api.github.com/users/thornhale/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thornhale/subscriptions", "organizations_url": "https://api.github.com/users/thornhale/orgs", "repos_url": "https://api.github.com/users/thornhale/repos", "events_url": "https://api.github.com/users/thornhale/events{/privacy}", "received_events_url": "https://api.github.com/users/thornhale/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-28T14:24:26Z", "updated_at": "2017-04-29T02:12:55Z", "author_association": "NONE", "body_html": "<p>What I want to ask in this context is this:</p>\n<p>So some deep learning frameworks like Tensorflow are somewhat tepidly exploring the use of opencl as an alternative to CUDA. Of course CUDA is just the \"language\" that cuDNN was developped on, and that's (if my understanding is correct) is what most deep learning languages are actually using. In this context, I am not sure what the opencl version of cuDNN is.</p>\n<p>Also AMD has been talking about open-source alternatives to CUDA which they are continuously developing and are calling rocM. They are also talking about miOpen to be the cuDNN equivalent (handcrafted assembler libraries for common deep learning functions), which however has not been released yet. The AMD approach is somewhat more holistic: We are not just exporting heavy-compute to the GPU.</p>\n<p>In this context, I am genuinely confused. How do opencl efforts like the ones listed above fit together? For NVIDIA GPUs, it's easy....there is CUDA, and there is cuDNN written in CUDA. For non-NVIDIA/or in this case AMD, it seems so much less clear. When is HIP preferred? When is using the HCC preferred? When is using opencl preferred? Any insights would truly be appreciated!</p>", "body_text": "What I want to ask in this context is this:\nSo some deep learning frameworks like Tensorflow are somewhat tepidly exploring the use of opencl as an alternative to CUDA. Of course CUDA is just the \"language\" that cuDNN was developped on, and that's (if my understanding is correct) is what most deep learning languages are actually using. In this context, I am not sure what the opencl version of cuDNN is.\nAlso AMD has been talking about open-source alternatives to CUDA which they are continuously developing and are calling rocM. They are also talking about miOpen to be the cuDNN equivalent (handcrafted assembler libraries for common deep learning functions), which however has not been released yet. The AMD approach is somewhat more holistic: We are not just exporting heavy-compute to the GPU.\nIn this context, I am genuinely confused. How do opencl efforts like the ones listed above fit together? For NVIDIA GPUs, it's easy....there is CUDA, and there is cuDNN written in CUDA. For non-NVIDIA/or in this case AMD, it seems so much less clear. When is HIP preferred? When is using the HCC preferred? When is using opencl preferred? Any insights would truly be appreciated!", "body": "What I want to ask in this context is this:\r\n\r\nSo some deep learning frameworks like Tensorflow are somewhat tepidly exploring the use of opencl as an alternative to CUDA. Of course CUDA is just the \"language\" that cuDNN was developped on, and that's (if my understanding is correct) is what most deep learning languages are actually using. In this context, I am not sure what the opencl version of cuDNN is.\r\n\r\nAlso AMD has been talking about open-source alternatives to CUDA which they are continuously developing and are calling rocM. They are also talking about miOpen to be the cuDNN equivalent (handcrafted assembler libraries for common deep learning functions), which however has not been released yet. The AMD approach is somewhat more holistic: We are not just exporting heavy-compute to the GPU.\r\n\r\nIn this context, I am genuinely confused. How do opencl efforts like the ones listed above fit together? For NVIDIA GPUs, it's easy....there is CUDA, and there is cuDNN written in CUDA. For non-NVIDIA/or in this case AMD, it seems so much less clear. When is HIP preferred? When is using the HCC preferred? When is using opencl preferred? Any insights would truly be appreciated! "}