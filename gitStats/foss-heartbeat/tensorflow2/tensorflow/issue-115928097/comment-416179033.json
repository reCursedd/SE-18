{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/416179033", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-416179033", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 416179033, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNjE3OTAzMw==", "user": {"login": "busukxuan", "id": 7033368, "node_id": "MDQ6VXNlcjcwMzMzNjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/7033368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/busukxuan", "html_url": "https://github.com/busukxuan", "followers_url": "https://api.github.com/users/busukxuan/followers", "following_url": "https://api.github.com/users/busukxuan/following{/other_user}", "gists_url": "https://api.github.com/users/busukxuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/busukxuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/busukxuan/subscriptions", "organizations_url": "https://api.github.com/users/busukxuan/orgs", "repos_url": "https://api.github.com/users/busukxuan/repos", "events_url": "https://api.github.com/users/busukxuan/events{/privacy}", "received_events_url": "https://api.github.com/users/busukxuan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-27T10:05:17Z", "updated_at": "2018-08-27T10:05:17Z", "author_association": "NONE", "body_html": "<p>Besides the above 2 posts, I'd like to add that now AMD's Vega GPUs (including the ones inside Raven Ridge APUs) can do FP16 at twice the FLOPS, so if TF could support them (through OpenCL) it would really help people with less budget. Also a lot of these people would be students, and if we get them to use TF as the starting point of their DNN journey, they would probably stick with TF down the road, and even tell others about TF; it's a great way to help expand this project.</p>", "body_text": "Besides the above 2 posts, I'd like to add that now AMD's Vega GPUs (including the ones inside Raven Ridge APUs) can do FP16 at twice the FLOPS, so if TF could support them (through OpenCL) it would really help people with less budget. Also a lot of these people would be students, and if we get them to use TF as the starting point of their DNN journey, they would probably stick with TF down the road, and even tell others about TF; it's a great way to help expand this project.", "body": "Besides the above 2 posts, I'd like to add that now AMD's Vega GPUs (including the ones inside Raven Ridge APUs) can do FP16 at twice the FLOPS, so if TF could support them (through OpenCL) it would really help people with less budget. Also a lot of these people would be students, and if we get them to use TF as the starting point of their DNN journey, they would probably stick with TF down the road, and even tell others about TF; it's a great way to help expand this project."}