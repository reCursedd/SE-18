{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/272908870", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-272908870", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 272908870, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjkwODg3MA==", "user": {"login": "lukeiwanski", "id": 8373795, "node_id": "MDQ6VXNlcjgzNzM3OTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8373795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukeiwanski", "html_url": "https://github.com/lukeiwanski", "followers_url": "https://api.github.com/users/lukeiwanski/followers", "following_url": "https://api.github.com/users/lukeiwanski/following{/other_user}", "gists_url": "https://api.github.com/users/lukeiwanski/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukeiwanski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukeiwanski/subscriptions", "organizations_url": "https://api.github.com/users/lukeiwanski/orgs", "repos_url": "https://api.github.com/users/lukeiwanski/repos", "events_url": "https://api.github.com/users/lukeiwanski/events{/privacy}", "received_events_url": "https://api.github.com/users/lukeiwanski/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-16T16:35:28Z", "updated_at": "2017-01-16T16:35:28Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1710528\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bhack\">@bhack</a> From <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"197070185\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/6449\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/6449/hovercard?comment_id=269245727&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/6449#issuecomment-269245727\">#6449 (comment)</a></p>\n<blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8373795\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lukeiwanski\">@lukeiwanski</a> Will XLA impact also your effort?</p>\n</blockquote>\n<p>XLA and SYCL solutions are complementary for different situations: SYCL is designed to provide full programmability and customizability. XLA is for optimizing well defined patterns in graphs.</p>\n<p>My understanding of XLA is that it optimizes some existing TensorFlow graphs at runtime using the LLVM compiler. It requires optimization passes to be implemented in the compiler for each algorithm used in the graph.<br>\nThe SYCL approach is the only approach that will deliver a CUDA level of programming - which is what developers need.</p>\n<p>With SYCL we are aiming to provide support for all the TensorFlow Ops and ease development of new operations.</p>\n<p>This means SYCL lets you write new high performance operations very easily, while XLA can optimize whole graphs if it supports all the ops in the graph.</p>\n<blockquote>\n<p>Can XLA backends LLVM IR be converted to SPIR-V with <a href=\"https://github.com/KhronosGroup/SPIRV-LLVM\">https://github.com/KhronosGroup/SPIRV-LLVM</a>?</p>\n</blockquote>\n<p>I don't see any reason why that wouldn't be possible.</p>", "body_text": "@bhack From #6449 (comment)\n\n@lukeiwanski Will XLA impact also your effort?\n\nXLA and SYCL solutions are complementary for different situations: SYCL is designed to provide full programmability and customizability. XLA is for optimizing well defined patterns in graphs.\nMy understanding of XLA is that it optimizes some existing TensorFlow graphs at runtime using the LLVM compiler. It requires optimization passes to be implemented in the compiler for each algorithm used in the graph.\nThe SYCL approach is the only approach that will deliver a CUDA level of programming - which is what developers need.\nWith SYCL we are aiming to provide support for all the TensorFlow Ops and ease development of new operations.\nThis means SYCL lets you write new high performance operations very easily, while XLA can optimize whole graphs if it supports all the ops in the graph.\n\nCan XLA backends LLVM IR be converted to SPIR-V with https://github.com/KhronosGroup/SPIRV-LLVM?\n\nI don't see any reason why that wouldn't be possible.", "body": "@bhack From https://github.com/tensorflow/tensorflow/issues/6449#issuecomment-269245727 \r\n\r\n> @lukeiwanski Will XLA impact also your effort?\r\n\r\nXLA and SYCL solutions are complementary for different situations: SYCL is designed to provide full programmability and customizability. XLA is for optimizing well defined patterns in graphs.\r\n\r\nMy understanding of XLA is that it optimizes some existing TensorFlow graphs at runtime using the LLVM compiler. It requires optimization passes to be implemented in the compiler for each algorithm used in the graph.\r\nThe SYCL approach is the only approach that will deliver a CUDA level of programming - which is what developers need.\r\n\r\nWith SYCL we are aiming to provide support for all the TensorFlow Ops and ease development of new operations.\r\n\r\nThis means SYCL lets you write new high performance operations very easily, while XLA can optimize whole graphs if it supports all the ops in the graph.\r\n\r\n> Can XLA backends LLVM IR be converted to SPIR-V with https://github.com/KhronosGroup/SPIRV-LLVM?\r\n\r\nI don't see any reason why that wouldn't be possible.\r\n"}