{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/315828713", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-315828713", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 315828713, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTgyODcxMw==", "user": {"login": "vade", "id": 65011, "node_id": "MDQ6VXNlcjY1MDEx", "avatar_url": "https://avatars1.githubusercontent.com/u/65011?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vade", "html_url": "https://github.com/vade", "followers_url": "https://api.github.com/users/vade/followers", "following_url": "https://api.github.com/users/vade/following{/other_user}", "gists_url": "https://api.github.com/users/vade/gists{/gist_id}", "starred_url": "https://api.github.com/users/vade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vade/subscriptions", "organizations_url": "https://api.github.com/users/vade/orgs", "repos_url": "https://api.github.com/users/vade/repos", "events_url": "https://api.github.com/users/vade/events{/privacy}", "received_events_url": "https://api.github.com/users/vade/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-17T17:47:15Z", "updated_at": "2017-07-17T17:47:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3244030\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rogerpasky\">@rogerpasky</a> respectfully disagree. While cloud based multi-GPU solutions work great for internet services, I'm targeting professional video production pipelines where inference is being run on hours and hours of pro-res and uncompressed HD, 2K, 4K footage, which a) no production house is going to upload to a cloud, b) they don't want google or whomever to have their data, c) they have rooms full of multi GPU capable systems (Mac and Windows) locally which they would like to leverage, and d) while inference on a single image is fine on CPU, running entire movies for inference through multiple graphs 100% sees an increase in perf using something like MPS vs CPU. Because the community has declined to support / embrace standards and instead uses Nvidia only code, real world use cases get pigeon holed and its really a shame.</p>\n<p>This isn't an idle request from someone who is a hobbyist running tutorials - GPU inference is important as is supporting diverse GPU / CPU families for diverse workloads on real world hardware. I really hope Google takes this seriously, because it would be great to be able to stick with a single library like TF, which is awesome.</p>\n<p>Thank you for hearing me, I'm not trying to rant, but to provide an alternate point of view to the community.</p>", "body_text": "@rogerpasky respectfully disagree. While cloud based multi-GPU solutions work great for internet services, I'm targeting professional video production pipelines where inference is being run on hours and hours of pro-res and uncompressed HD, 2K, 4K footage, which a) no production house is going to upload to a cloud, b) they don't want google or whomever to have their data, c) they have rooms full of multi GPU capable systems (Mac and Windows) locally which they would like to leverage, and d) while inference on a single image is fine on CPU, running entire movies for inference through multiple graphs 100% sees an increase in perf using something like MPS vs CPU. Because the community has declined to support / embrace standards and instead uses Nvidia only code, real world use cases get pigeon holed and its really a shame.\nThis isn't an idle request from someone who is a hobbyist running tutorials - GPU inference is important as is supporting diverse GPU / CPU families for diverse workloads on real world hardware. I really hope Google takes this seriously, because it would be great to be able to stick with a single library like TF, which is awesome.\nThank you for hearing me, I'm not trying to rant, but to provide an alternate point of view to the community.", "body": "@rogerpasky respectfully disagree. While cloud based multi-GPU solutions work great for internet services, I'm targeting professional video production pipelines where inference is being run on hours and hours of pro-res and uncompressed HD, 2K, 4K footage, which a) no production house is going to upload to a cloud, b) they don't want google or whomever to have their data, c) they have rooms full of multi GPU capable systems (Mac and Windows) locally which they would like to leverage, and d) while inference on a single image is fine on CPU, running entire movies for inference through multiple graphs 100% sees an increase in perf using something like MPS vs CPU. Because the community has declined to support / embrace standards and instead uses Nvidia only code, real world use cases get pigeon holed and its really a shame.\r\n\r\nThis isn't an idle request from someone who is a hobbyist running tutorials - GPU inference is important as is supporting diverse GPU / CPU families for diverse workloads on real world hardware. I really hope Google takes this seriously, because it would be great to be able to stick with a single library like TF, which is awesome.\r\n\r\nThank you for hearing me, I'm not trying to rant, but to provide an alternate point of view to the community. "}