{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/258304149", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-258304149", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 258304149, "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODMwNDE0OQ==", "user": {"login": "LifeIsStrange", "id": 12934716, "node_id": "MDQ6VXNlcjEyOTM0NzE2", "avatar_url": "https://avatars0.githubusercontent.com/u/12934716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LifeIsStrange", "html_url": "https://github.com/LifeIsStrange", "followers_url": "https://api.github.com/users/LifeIsStrange/followers", "following_url": "https://api.github.com/users/LifeIsStrange/following{/other_user}", "gists_url": "https://api.github.com/users/LifeIsStrange/gists{/gist_id}", "starred_url": "https://api.github.com/users/LifeIsStrange/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LifeIsStrange/subscriptions", "organizations_url": "https://api.github.com/users/LifeIsStrange/orgs", "repos_url": "https://api.github.com/users/LifeIsStrange/repos", "events_url": "https://api.github.com/users/LifeIsStrange/events{/privacy}", "received_events_url": "https://api.github.com/users/LifeIsStrange/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-03T23:26:23Z", "updated_at": "2016-11-04T00:23:51Z", "author_association": "NONE", "body_html": "<p>What about using HIP ?<br>\n<a href=\"https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP/blob/master/docs/markdown/hip_faq.md#how-does-hip-compare-with-opencl\">https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP/blob/master/docs/markdown/hip_faq.md#how-does-hip-compare-with-opencl</a><br>\n<a href=\"https://github.com/RadeonOpenCompute/hcc\">https://github.com/RadeonOpenCompute/hcc</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"183168972\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/ROCm-Developer-Tools/HIP/issues/45\" data-hovercard-type=\"issue\" data-hovercard-url=\"/ROCm-Developer-Tools/HIP/issues/45/hovercard\" href=\"https://github.com/ROCm-Developer-Tools/HIP/issues/45\">ROCm-Developer-Tools/HIP#45</a><br>\n\"Your wish is being granted, Eigen is being ported over AMD GPU via HIP. The second part of your request is can we bring standardized tool supporting FLOAT16 that ships with all our GFX8 GPU's, wish granted.\"<br>\nOur development branch of AMDGPU compiler now support's both Float16 and Int16 native instruction, instead of emulating FP16/Int16 with up convert &amp; down convert instructions to convert from FP16/Int16 to Float and back.</p>\n<p>This is f16 tests on Fiji hardware successfully executing a matrix multiplication with half types with conversion and with Native instructions.\"</p>\n<p>Also, not related but you should use syCL/openCL 2.0 instead of 1.2, because nvidia is already supported via CUDA. And openCL 2.0 is supported on both AMD and Intel Windows drivers. Also AMD has said that they will soon opensource un openCL 2.0 driver for Linux (which could be used by Intel, opensource magic) (and Intel already has a Linux openCL 2.0 implementation which Just need maturation.) if you ask Intel and AMD,  maybe they could speed up the work, because tensorflow is important for their economic interests. And they already have said in this comment section that they wanted to help. Also all the major ARM makers support openCL 2.0. This could open a lot of opportunitys for Android (which is in the economic interest of Google) , raspberry like, smart TVs, etc</p>\n<p>And in mid term we could eventually develop an opencl 1.2 fallback layer for non supported hardware.<br>\nAnd the implementation should use also openVX (which is now supoorted by all major hardware makers, and AMD has an opensource implementation) and with <a href=\"https://www.khronos.org/news/press/khronos-launches-dual-neural-network-standard-initiatives\" rel=\"nofollow\">https://www.khronos.org/news/press/khronos-launches-dual-neural-network-standard-initiatives</a><br>\nAnd the all with Spir-V (which can be use simultaneously by Vulkan and openGL).<br>\nYou could say that I'm making a duplicate of what was already said, but synthetizing is important.<br>\nAnd finally, could tensorflow use HSA ?</p>\n<p><a href=\"http://www.hsafoundation.com\" rel=\"nofollow\">http://www.hsafoundation.com</a><br>\nHSA would be awesome on Android.</p>", "body_text": "What about using HIP ?\nhttps://github.com/GPUOpen-ProfessionalCompute-Tools/HIP/blob/master/docs/markdown/hip_faq.md#how-does-hip-compare-with-opencl\nhttps://github.com/RadeonOpenCompute/hcc\nROCm-Developer-Tools/HIP#45\n\"Your wish is being granted, Eigen is being ported over AMD GPU via HIP. The second part of your request is can we bring standardized tool supporting FLOAT16 that ships with all our GFX8 GPU's, wish granted.\"\nOur development branch of AMDGPU compiler now support's both Float16 and Int16 native instruction, instead of emulating FP16/Int16 with up convert & down convert instructions to convert from FP16/Int16 to Float and back.\nThis is f16 tests on Fiji hardware successfully executing a matrix multiplication with half types with conversion and with Native instructions.\"\nAlso, not related but you should use syCL/openCL 2.0 instead of 1.2, because nvidia is already supported via CUDA. And openCL 2.0 is supported on both AMD and Intel Windows drivers. Also AMD has said that they will soon opensource un openCL 2.0 driver for Linux (which could be used by Intel, opensource magic) (and Intel already has a Linux openCL 2.0 implementation which Just need maturation.) if you ask Intel and AMD,  maybe they could speed up the work, because tensorflow is important for their economic interests. And they already have said in this comment section that they wanted to help. Also all the major ARM makers support openCL 2.0. This could open a lot of opportunitys for Android (which is in the economic interest of Google) , raspberry like, smart TVs, etc\nAnd in mid term we could eventually develop an opencl 1.2 fallback layer for non supported hardware.\nAnd the implementation should use also openVX (which is now supoorted by all major hardware makers, and AMD has an opensource implementation) and with https://www.khronos.org/news/press/khronos-launches-dual-neural-network-standard-initiatives\nAnd the all with Spir-V (which can be use simultaneously by Vulkan and openGL).\nYou could say that I'm making a duplicate of what was already said, but synthetizing is important.\nAnd finally, could tensorflow use HSA ?\nhttp://www.hsafoundation.com\nHSA would be awesome on Android.", "body": "What about using HIP ?\nhttps://github.com/GPUOpen-ProfessionalCompute-Tools/HIP/blob/master/docs/markdown/hip_faq.md#how-does-hip-compare-with-opencl\nhttps://github.com/RadeonOpenCompute/hcc\nhttps://github.com/GPUOpen-ProfessionalCompute-Tools/HIP/issues/45\n\"Your wish is being granted, Eigen is being ported over AMD GPU via HIP. The second part of your request is can we bring standardized tool supporting FLOAT16 that ships with all our GFX8 GPU's, wish granted.\"\nOur development branch of AMDGPU compiler now support's both Float16 and Int16 native instruction, instead of emulating FP16/Int16 with up convert & down convert instructions to convert from FP16/Int16 to Float and back.\n\nThis is f16 tests on Fiji hardware successfully executing a matrix multiplication with half types with conversion and with Native instructions.\" \n\nAlso, not related but you should use syCL/openCL 2.0 instead of 1.2, because nvidia is already supported via CUDA. And openCL 2.0 is supported on both AMD and Intel Windows drivers. Also AMD has said that they will soon opensource un openCL 2.0 driver for Linux (which could be used by Intel, opensource magic) (and Intel already has a Linux openCL 2.0 implementation which Just need maturation.) if you ask Intel and AMD,  maybe they could speed up the work, because tensorflow is important for their economic interests. And they already have said in this comment section that they wanted to help. Also all the major ARM makers support openCL 2.0. This could open a lot of opportunitys for Android (which is in the economic interest of Google) , raspberry like, smart TVs, etc \n\nAnd in mid term we could eventually develop an opencl 1.2 fallback layer for non supported hardware. \nAnd the implementation should use also openVX (which is now supoorted by all major hardware makers, and AMD has an opensource implementation) and with https://www.khronos.org/news/press/khronos-launches-dual-neural-network-standard-initiatives \nAnd the all with Spir-V (which can be use simultaneously by Vulkan and openGL). \nYou could say that I'm making a duplicate of what was already said, but synthetizing is important. \nAnd finally, could tensorflow use HSA ? \n\nhttp://www.hsafoundation.com\nHSA would be awesome on Android. \n"}