{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/364936498", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-364936498", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 364936498, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDkzNjQ5OA==", "user": {"login": "VincentSC", "id": 5090382, "node_id": "MDQ6VXNlcjUwOTAzODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5090382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VincentSC", "html_url": "https://github.com/VincentSC", "followers_url": "https://api.github.com/users/VincentSC/followers", "following_url": "https://api.github.com/users/VincentSC/following{/other_user}", "gists_url": "https://api.github.com/users/VincentSC/gists{/gist_id}", "starred_url": "https://api.github.com/users/VincentSC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VincentSC/subscriptions", "organizations_url": "https://api.github.com/users/VincentSC/orgs", "repos_url": "https://api.github.com/users/VincentSC/repos", "events_url": "https://api.github.com/users/VincentSC/events{/privacy}", "received_events_url": "https://api.github.com/users/VincentSC/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-12T14:23:08Z", "updated_at": "2018-02-12T14:23:08Z", "author_association": "NONE", "body_html": "<p>Is the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or making it actually run faster? I'd prefer there not a holy war, but focusing on getting it to run fast on several GPUs. LifeIsStrange's focus is on getting it to work on AMD GPUs and then HIP makes good sense. For others the focus is to make it work on Intel GPUs or Android, and then OpenCL makes much more sense. GPU-languages are a mess, so please keep practical,</p>\n<p>If I read some of the comments here, performance is an issue with the OpenCL ports. But unfortunately I cannot see many benchmarks around. Are there more benchmarks than this one? <a href=\"https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md\">https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md</a></p>", "body_text": "Is the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or making it actually run faster? I'd prefer there not a holy war, but focusing on getting it to run fast on several GPUs. LifeIsStrange's focus is on getting it to work on AMD GPUs and then HIP makes good sense. For others the focus is to make it work on Intel GPUs or Android, and then OpenCL makes much more sense. GPU-languages are a mess, so please keep practical,\nIf I read some of the comments here, performance is an issue with the OpenCL ports. But unfortunately I cannot see many benchmarks around. Are there more benchmarks than this one? https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md", "body": "Is the focus here on getting-it-to-run-as-lomg-as-it-is-OpenCL, or making it actually run faster? I'd prefer there not a holy war, but focusing on getting it to run fast on several GPUs. LifeIsStrange's focus is on getting it to work on AMD GPUs and then HIP makes good sense. For others the focus is to make it work on Intel GPUs or Android, and then OpenCL makes much more sense. GPU-languages are a mess, so please keep practical, \r\n\r\nIf I read some of the comments here, performance is an issue with the OpenCL ports. But unfortunately I cannot see many benchmarks around. Are there more benchmarks than this one? https://github.com/AlphasCodes/DeepLearning/blob/master/Tensorflow_Benchmarks.md"}