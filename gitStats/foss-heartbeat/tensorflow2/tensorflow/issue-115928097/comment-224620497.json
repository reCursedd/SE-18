{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/224620497", "html_url": "https://github.com/tensorflow/tensorflow/issues/22#issuecomment-224620497", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22", "id": 224620497, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDYyMDQ5Nw==", "user": {"login": "lukeiwanski", "id": 8373795, "node_id": "MDQ6VXNlcjgzNzM3OTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8373795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukeiwanski", "html_url": "https://github.com/lukeiwanski", "followers_url": "https://api.github.com/users/lukeiwanski/followers", "following_url": "https://api.github.com/users/lukeiwanski/following{/other_user}", "gists_url": "https://api.github.com/users/lukeiwanski/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukeiwanski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukeiwanski/subscriptions", "organizations_url": "https://api.github.com/users/lukeiwanski/orgs", "repos_url": "https://api.github.com/users/lukeiwanski/repos", "events_url": "https://api.github.com/users/lukeiwanski/events{/privacy}", "received_events_url": "https://api.github.com/users/lukeiwanski/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-08T15:10:41Z", "updated_at": "2016-06-08T15:11:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1806397\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/djan92\">@djan92</a><br>\nYes, you are right, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115928097\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/22/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/22\">#22</a> is almost 8 months old and has over 100 posts! The information can get swamped!</p>\n<blockquote>\n<p>Could someone provide estimates for when Tensorflow might be able to run with OpenCL (AMD GPUs)?</p>\n</blockquote>\n<p>TensorFlow uses the Eigen library for tensor computation (in the Tensor module). We have committed a partial implementation for OpenCL 1.2 using SYCL (<a href=\"https://bitbucket.org/benoitsteiner/opencl\" rel=\"nofollow\">https://bitbucket.org/benoitsteiner/opencl</a> branch Codeplay). The reason we used SYCL for this work is that this section of TensorFlow uses C++ expression trees, which is possible with SYCL for OpenCL, but not possible with OpenCL C directly. Other components of TensorFlow, such as convolutions or BLAS, could use OpenCL C directly.</p>\n<p>Currently, I am working on integrating ComputeCpp (Codeplay's SYCL compiler) into the bazel build system. This should be ready soon ( follow this repo: <a href=\"https://github.com/benoitsteiner/tensorflow-opencl/\">https://github.com/benoitsteiner/tensorflow-opencl/</a> ). After that is done, TensorFlow should be accelerated on systems that support OpenCL SPIR (such as AMD or Intel) with ComputeCpp. Further work will continue on accelerating more of TensorFlow, as well as supporting more OpenCL implementations and the triSYCL open-source SYCL. SYCL and OpenCL are multi-vendor, royalty-free open standards, so there are lots of platforms and devices that can be supported using this approach (not just AMD GPUs).</p>\n<p>The ComputeCpp Community Edition compiler will be available for free later in 2016 (in beta form: full conformance will be released for free early 2017).</p>\n<p>The work on accelerating the non-C++ parts of TensorFlow (e.g. BLAS and convolutions) could be done without SYCL and implemented separately. Different hardware vendors may have their own optimized libraries for these features which could aid acceleration. Or, we could use Eigen with C++ for these features.</p>\n<blockquote>\n<p>And what the curve of performance/usability looks like over time?</p>\n</blockquote>\n<p>We believe the performance will improve steadily. To accelerate on a wide variety of devices, we need to manage the data more efficiently, which is why there is a \"managed tensor\" item of work, so that data movement can be more efficiently managed between host and multiple devices. It is hard to predict how the performance will vary over a wide range of devices, right now. Currently, very little is accelerated, but we are putting the infrastructure is in place to allow open-standard acceleration in TensorFlow.</p>", "body_text": "@djan92\nYes, you are right, #22 is almost 8 months old and has over 100 posts! The information can get swamped!\n\nCould someone provide estimates for when Tensorflow might be able to run with OpenCL (AMD GPUs)?\n\nTensorFlow uses the Eigen library for tensor computation (in the Tensor module). We have committed a partial implementation for OpenCL 1.2 using SYCL (https://bitbucket.org/benoitsteiner/opencl branch Codeplay). The reason we used SYCL for this work is that this section of TensorFlow uses C++ expression trees, which is possible with SYCL for OpenCL, but not possible with OpenCL C directly. Other components of TensorFlow, such as convolutions or BLAS, could use OpenCL C directly.\nCurrently, I am working on integrating ComputeCpp (Codeplay's SYCL compiler) into the bazel build system. This should be ready soon ( follow this repo: https://github.com/benoitsteiner/tensorflow-opencl/ ). After that is done, TensorFlow should be accelerated on systems that support OpenCL SPIR (such as AMD or Intel) with ComputeCpp. Further work will continue on accelerating more of TensorFlow, as well as supporting more OpenCL implementations and the triSYCL open-source SYCL. SYCL and OpenCL are multi-vendor, royalty-free open standards, so there are lots of platforms and devices that can be supported using this approach (not just AMD GPUs).\nThe ComputeCpp Community Edition compiler will be available for free later in 2016 (in beta form: full conformance will be released for free early 2017).\nThe work on accelerating the non-C++ parts of TensorFlow (e.g. BLAS and convolutions) could be done without SYCL and implemented separately. Different hardware vendors may have their own optimized libraries for these features which could aid acceleration. Or, we could use Eigen with C++ for these features.\n\nAnd what the curve of performance/usability looks like over time?\n\nWe believe the performance will improve steadily. To accelerate on a wide variety of devices, we need to manage the data more efficiently, which is why there is a \"managed tensor\" item of work, so that data movement can be more efficiently managed between host and multiple devices. It is hard to predict how the performance will vary over a wide range of devices, right now. Currently, very little is accelerated, but we are putting the infrastructure is in place to allow open-standard acceleration in TensorFlow.", "body": "@djan92 \nYes, you are right, #22 is almost 8 months old and has over 100 posts! The information can get swamped!\n\n> Could someone provide estimates for when Tensorflow might be able to run with OpenCL (AMD GPUs)?\n\nTensorFlow uses the Eigen library for tensor computation (in the Tensor module). We have committed a partial implementation for OpenCL 1.2 using SYCL (https://bitbucket.org/benoitsteiner/opencl branch Codeplay). The reason we used SYCL for this work is that this section of TensorFlow uses C++ expression trees, which is possible with SYCL for OpenCL, but not possible with OpenCL C directly. Other components of TensorFlow, such as convolutions or BLAS, could use OpenCL C directly.\n\nCurrently, I am working on integrating ComputeCpp (Codeplay's SYCL compiler) into the bazel build system. This should be ready soon ( follow this repo: https://github.com/benoitsteiner/tensorflow-opencl/ ). After that is done, TensorFlow should be accelerated on systems that support OpenCL SPIR (such as AMD or Intel) with ComputeCpp. Further work will continue on accelerating more of TensorFlow, as well as supporting more OpenCL implementations and the triSYCL open-source SYCL. SYCL and OpenCL are multi-vendor, royalty-free open standards, so there are lots of platforms and devices that can be supported using this approach (not just AMD GPUs).\n\nThe ComputeCpp Community Edition compiler will be available for free later in 2016 (in beta form: full conformance will be released for free early 2017).\n\nThe work on accelerating the non-C++ parts of TensorFlow (e.g. BLAS and convolutions) could be done without SYCL and implemented separately. Different hardware vendors may have their own optimized libraries for these features which could aid acceleration. Or, we could use Eigen with C++ for these features. \n\n> And what the curve of performance/usability looks like over time?\n\nWe believe the performance will improve steadily. To accelerate on a wide variety of devices, we need to manage the data more efficiently, which is why there is a \"managed tensor\" item of work, so that data movement can be more efficiently managed between host and multiple devices. It is hard to predict how the performance will vary over a wide range of devices, right now. Currently, very little is accelerated, but we are putting the infrastructure is in place to allow open-standard acceleration in TensorFlow.\n"}