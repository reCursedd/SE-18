{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/174168781", "html_url": "https://github.com/tensorflow/tensorflow/issues/838#issuecomment-174168781", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/838", "id": 174168781, "node_id": "MDEyOklzc3VlQ29tbWVudDE3NDE2ODc4MQ==", "user": {"login": "taras-sereda", "id": 7364100, "node_id": "MDQ6VXNlcjczNjQxMDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7364100?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taras-sereda", "html_url": "https://github.com/taras-sereda", "followers_url": "https://api.github.com/users/taras-sereda/followers", "following_url": "https://api.github.com/users/taras-sereda/following{/other_user}", "gists_url": "https://api.github.com/users/taras-sereda/gists{/gist_id}", "starred_url": "https://api.github.com/users/taras-sereda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taras-sereda/subscriptions", "organizations_url": "https://api.github.com/users/taras-sereda/orgs", "repos_url": "https://api.github.com/users/taras-sereda/repos", "events_url": "https://api.github.com/users/taras-sereda/events{/privacy}", "received_events_url": "https://api.github.com/users/taras-sereda/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-23T10:26:11Z", "updated_at": "2016-01-23T10:26:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hey <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> . Thanks for the detailed explanation, I also came up with this fix latter on.<br>\nadding <code>with tf.device(\"/cpu:0\")</code><br>\nleads to the following speed:</p>\n<div class=\"highlight highlight-source-python\"><pre>Step <span class=\"pl-c1\">0</span>: loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2.32</span> (<span class=\"pl-c1\">0.112</span> sec)\nStep <span class=\"pl-c1\">100</span>: loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2.20</span> (<span class=\"pl-c1\">0.020</span> sec)\nStep <span class=\"pl-c1\">200</span>: loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.99</span> (<span class=\"pl-c1\">0.018</span> sec)\nStep <span class=\"pl-c1\">300</span>: loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.76</span> (<span class=\"pl-c1\">0.017</span> sec)\nStep <span class=\"pl-c1\">400</span>: loss <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1.42</span> (<span class=\"pl-c1\">0.019</span> sec)</pre></div>\n<p>It solves the issue with timing. but using GPU here doesn't helps in performance which contradicts the whole purpose of GPU.<br>\nI've added device placement logging<br>\n<code>sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</code></p>\n<p>and I see that nodes related to input producing and queues  automatically placed on CPU.  Are there any other ways to get more detailed log to see memory flow CPU-&gt;GPU-&gt;CPU?</p>\n<p>I'm going to add simple logging, with warnings when the list of available devices contains GPU but looks Looks like it's enough to add logging only in this source:<br>\n<code>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/simple_placer.cc#L298</code></p>\n<p>Is there any public lists of ops which doesn't have GPU kernels?</p>", "body_text": "Hey @yaroslavvb . Thanks for the detailed explanation, I also came up with this fix latter on.\nadding with tf.device(\"/cpu:0\")\nleads to the following speed:\nStep 0: loss = 2.32 (0.112 sec)\nStep 100: loss = 2.20 (0.020 sec)\nStep 200: loss = 1.99 (0.018 sec)\nStep 300: loss = 1.76 (0.017 sec)\nStep 400: loss = 1.42 (0.019 sec)\nIt solves the issue with timing. but using GPU here doesn't helps in performance which contradicts the whole purpose of GPU.\nI've added device placement logging\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nand I see that nodes related to input producing and queues  automatically placed on CPU.  Are there any other ways to get more detailed log to see memory flow CPU->GPU->CPU?\nI'm going to add simple logging, with warnings when the list of available devices contains GPU but looks Looks like it's enough to add logging only in this source:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/simple_placer.cc#L298\nIs there any public lists of ops which doesn't have GPU kernels?", "body": "Hey @yaroslavvb . Thanks for the detailed explanation, I also came up with this fix latter on. \nadding `with tf.device(\"/cpu:0\")`\nleads to the following speed:\n\n``` python\nStep 0: loss = 2.32 (0.112 sec)\nStep 100: loss = 2.20 (0.020 sec)\nStep 200: loss = 1.99 (0.018 sec)\nStep 300: loss = 1.76 (0.017 sec)\nStep 400: loss = 1.42 (0.019 sec)\n```\n\nIt solves the issue with timing. but using GPU here doesn't helps in performance which contradicts the whole purpose of GPU.\nI've added device placement logging\n`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`\n\nand I see that nodes related to input producing and queues  automatically placed on CPU.  Are there any other ways to get more detailed log to see memory flow CPU->GPU->CPU? \n\nI'm going to add simple logging, with warnings when the list of available devices contains GPU but looks Looks like it's enough to add logging only in this source:\n`https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/simple_placer.cc#L298`\n\nIs there any public lists of ops which doesn't have GPU kernels? \n"}