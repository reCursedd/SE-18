{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23390", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23390/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23390/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23390/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23390", "id": 375743018, "node_id": "MDU6SXNzdWUzNzU3NDMwMTg=", "number": 23390, "title": "FLOP calculation wrong for matmul with batch dimension", "user": {"login": "WuTheFWasThat", "id": 1479648, "node_id": "MDQ6VXNlcjE0Nzk2NDg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1479648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WuTheFWasThat", "html_url": "https://github.com/WuTheFWasThat", "followers_url": "https://api.github.com/users/WuTheFWasThat/followers", "following_url": "https://api.github.com/users/WuTheFWasThat/following{/other_user}", "gists_url": "https://api.github.com/users/WuTheFWasThat/gists{/gist_id}", "starred_url": "https://api.github.com/users/WuTheFWasThat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WuTheFWasThat/subscriptions", "organizations_url": "https://api.github.com/users/WuTheFWasThat/orgs", "repos_url": "https://api.github.com/users/WuTheFWasThat/repos", "events_url": "https://api.github.com/users/WuTheFWasThat/events{/privacy}", "received_events_url": "https://api.github.com/users/WuTheFWasThat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097547147, "node_id": "MDU6TGFiZWwxMDk3NTQ3MTQ3", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:ops", "name": "comp:ops", "color": "0052cc", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-30T23:56:09Z", "updated_at": "2018-10-31T18:13:17Z", "closed_at": "2018-10-31T18:13:17Z", "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04</li>\n<li>TensorFlow installed from (source or binary): Binary</li>\n<li>TensorFlow version (use command below): v1.11.0-rc2-4-gc19e29306c 1.11.0</li>\n<li>Python version: 3.6.5</li>\n<li>CUDA/cuDNN version: N/A</li>\n<li>GPU model and memory: N/A</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nFLOPS is always 0 when specifying batch dimension</p>\n<p><strong>Describe the expected behavior</strong><br>\nFLOPS should be linear in batch dimension</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<pre><code>import tensorflow as tf\ng = tf.Graph()\nwith g.as_default():\n    b, m, p, q = 2, 25, 16, 9\n    A = tf.Variable(tf.zeros([b, m, p]))\n    B = tf.Variable(tf.zeros([b, p, q]))\n    C = tf.matmul(A,B)\n\n    flops = tf.profiler.profile(g, options = tf.profiler.ProfileOptionBuilder.float_operation())\n    print('FLOP should be', b * m * q * 2 * p)\n    print('Calculated FLOP', flops.total_float_ops)\n</code></pre>\n<p><strong>Other info / logs</strong><br>\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.11.0-rc2-4-gc19e29306c 1.11.0\nPython version: 3.6.5\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\n\nDescribe the current behavior\nFLOPS is always 0 when specifying batch dimension\nDescribe the expected behavior\nFLOPS should be linear in batch dimension\nCode to reproduce the issue\nimport tensorflow as tf\ng = tf.Graph()\nwith g.as_default():\n    b, m, p, q = 2, 25, 16, 9\n    A = tf.Variable(tf.zeros([b, m, p]))\n    B = tf.Variable(tf.zeros([b, p, q]))\n    C = tf.matmul(A,B)\n\n    flops = tf.profiler.profile(g, options = tf.profiler.ProfileOptionBuilder.float_operation())\n    print('FLOP should be', b * m * q * 2 * p)\n    print('Calculated FLOP', flops.total_float_ops)\n\nOther info / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v1.11.0-rc2-4-gc19e29306c 1.11.0\r\n- Python version: 3.6.5\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nFLOPS is always 0 when specifying batch dimension\r\n\r\n**Describe the expected behavior**\r\nFLOPS should be linear in batch dimension\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    b, m, p, q = 2, 25, 16, 9\r\n    A = tf.Variable(tf.zeros([b, m, p]))\r\n    B = tf.Variable(tf.zeros([b, p, q]))\r\n    C = tf.matmul(A,B)\r\n\r\n    flops = tf.profiler.profile(g, options = tf.profiler.ProfileOptionBuilder.float_operation())\r\n    print('FLOP should be', b * m * q * 2 * p)\r\n    print('Calculated FLOP', flops.total_float_ops)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n"}