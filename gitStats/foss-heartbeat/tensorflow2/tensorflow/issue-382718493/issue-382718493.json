{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23885", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23885/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23885/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23885/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23885", "id": 382718493, "node_id": "MDU6SXNzdWUzODI3MTg0OTM=", "number": 23885, "title": "tensorflow/core/framework/op_kernel.cc:1261] Invalid argument: ValueError", "user": {"login": "susierao", "id": 19934422, "node_id": "MDQ6VXNlcjE5OTM0NDIy", "avatar_url": "https://avatars3.githubusercontent.com/u/19934422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/susierao", "html_url": "https://github.com/susierao", "followers_url": "https://api.github.com/users/susierao/followers", "following_url": "https://api.github.com/users/susierao/following{/other_user}", "gists_url": "https://api.github.com/users/susierao/gists{/gist_id}", "starred_url": "https://api.github.com/users/susierao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/susierao/subscriptions", "organizations_url": "https://api.github.com/users/susierao/orgs", "repos_url": "https://api.github.com/users/susierao/repos", "events_url": "https://api.github.com/users/susierao/events{/privacy}", "received_events_url": "https://api.github.com/users/susierao/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-20T15:33:42Z", "updated_at": "2018-11-20T16:21:38Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I also tested the code in Examples</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version (use command below): 1.12.0</li>\n<li>Python version: 3.5</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source): 5.4.0</li>\n<li>CUDA/cuDNN version: 9.0</li>\n<li>GPU model and memory: TITAN Xp (12196MiB)<br>\n--</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI have been testing your MirroredStrategy() function with your example script and my own script.</p>\n<ul>\n<li>It worked well on the sample script.</li>\n<li>When I adapted my own script, it kept emitting the following error I don't know how to interpret/search.</li>\n</ul>\n<pre><code>WARNING:tensorflow:Not all devices in distribute strategy are visible by TensorFlow sessions.\nWARNING:tensorflow:You are accessing attribute optimizerof the \nDistributedCallbackModel that may not have been set correctly.\nWARNING:tensorflow:You are accessing attribute \n_unconditional_checkpoint_dependenciesof the DistributedCallbackModel \nthat may not have been set correctly.\nEpoch 1/1\n2018-11-20 16:41:15.195119: W tensorflow/core/framework/op_kernel.cc:1261] \nInvalid argument: ValueError: `generator` yielded an element of shape (1, 1) \nwhere an element of shape (1,) was expected.\nTraceback (most recent call last):\n\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", \nline 206, in __call__\n    ret = func(*args)\n\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", \nline 487, in generator_py_func\n    \"of shape %s was expected.\" % (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (1, 1) \nwhere an element of shape (1,) was expected.\n\n\n[[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT32, DT_INT64], \ntoken=\"pyfunc_1\"](arg0)]]                                                   \n[[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?,500], [?,1]], \noutput_types=[DT_INT32, DT_INT64]](IteratorFromStringHandle V2)]] \n[[{{node ExperimentalFunctionBufferingResourceGetNext}} = \nExperimentalFunctionBufferingResourceGetNext[output_types=[DT_INT32, DT_INT64] , \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\n(ExperimentalFunctionBufferingResource)]]\nException ignored in:  6e80&gt;&gt;\n--\n\n\n\n</code></pre>\n<p>The script without \t<code>distribution = tf.contrib.distribute.MirroredStrategy()</code> ran well. Since I need to populate the network with a huge set, I plan to parallize the work on various GPUs.</p>\n<p><strong>Describe the expected behavior</strong><br>\nPlease kindly let me know how should I interpret the errors and what the solutions are. Thank you.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nMy network architecture looks like this (a hierarchical one):</p>\n<pre><code>config = tf.ConfigProto(allow_soft_placement = True, log_device_placement= False)\n\tsess = tf.Session(config = config)\n\twith tf.Session(config = config) as sess:\n\t\tsess.run(tf.global_variables_initializer())\n                # load in data\n\t         #######################DNN Level 1########################\n\t        if options.L1_model == 0:\n\t\t        model = BuildModel()\n\t\t        model.fit(X_train, y_train[:, 0],\n\t\t\t\t  validation_data=(X_test, y_test[:, 0]),\n\t\t\t\t  epochs=options.epochs,\n\t\t\t\t  verbose=2,\n\t\t\t\t  batch_size=options.batch_size_L1)\n          #######################DNN Level 1########################\n\t         if options.L2_model == 0:\n \n\t\t         model = BuildModel()\n\t\t          model.fit(..., batch_size=options.batch_size_L2)\n\n</code></pre>\n<p>The model stopped already at the first level. And I don't think the failure has something to do with a hierarchical structure.</p>\n<p><code>BuildModel()</code> is defined this way:</p>\n<pre><code>def buildModel_DNN(word_index, embeddings_index, nClasses, \nMAX_SEQUENCE_LENGTH, EMBEDDING_DIM, gpusno, nLayers=3,Number_Node=100, dropout=0.5):\n\t\n\tembedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n\tfor word, i in word_index.items():\n\t\tembedding_vector = embeddings_index.get(word)\n\t\tif embedding_vector is not None:\n\t\t\tembedding_matrix[i] = embedding_vector\n\t\t\t\n\tmodel = tf.keras.models.Sequential()\n\t\n\tmodel.add(tf.keras.layers.Embedding(len(word_index) + 1,\n\t\t\t\t\t\t\t\tEMBEDDING_DIM,\n\t\t\t\t\t\t\t\tweights=[embedding_matrix],\n\t\t\t\t\t\t\t\tinput_length=MAX_SEQUENCE_LENGTH,\n\t\t\t\t\t\t\t\ttrainable=True))\n\tmodel.add(tf.keras.layers.Flatten())\n\t\n\tfor i in range(0,nLayers):\n\t\tmodel.add(tf.keras.layers.Dense(Number_Node, activation='relu'))\n\t\tmodel.add(tf.keras.layers.Dropout(dropout))\n\t\n\tmodel.add(tf.keras.layers.Dense(nClasses, activation='softmax'))\n\n\t\n\tdistribution = tf.contrib.distribute.MirroredStrategy(\n                               ['/device:GPU:0', '/device:GPU:1'], prefetch_on_device=True)\n\t\n\tmodel.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n\t\t\t\t  optimizer=tf.train.AdamOptimizer(),\n\t\t\t\t  metrics=['accuracy'], \n\t\t\t\t  # distribute=distribution,\n\t\t\t\t  options = run_opts)\n\t\t\t\t  \n\tprint('model summary:') \n\tmodel.summary()\n\n\treturn model\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I also tested the code in Examples\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.12.0\nPython version: 3.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: 9.0\nGPU model and memory: TITAN Xp (12196MiB)\n--\n\nDescribe the current behavior\nI have been testing your MirroredStrategy() function with your example script and my own script.\n\nIt worked well on the sample script.\nWhen I adapted my own script, it kept emitting the following error I don't know how to interpret/search.\n\nWARNING:tensorflow:Not all devices in distribute strategy are visible by TensorFlow sessions.\nWARNING:tensorflow:You are accessing attribute optimizerof the \nDistributedCallbackModel that may not have been set correctly.\nWARNING:tensorflow:You are accessing attribute \n_unconditional_checkpoint_dependenciesof the DistributedCallbackModel \nthat may not have been set correctly.\nEpoch 1/1\n2018-11-20 16:41:15.195119: W tensorflow/core/framework/op_kernel.cc:1261] \nInvalid argument: ValueError: `generator` yielded an element of shape (1, 1) \nwhere an element of shape (1,) was expected.\nTraceback (most recent call last):\n\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", \nline 206, in __call__\n    ret = func(*args)\n\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", \nline 487, in generator_py_func\n    \"of shape %s was expected.\" % (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (1, 1) \nwhere an element of shape (1,) was expected.\n\n\n[[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT32, DT_INT64], \ntoken=\"pyfunc_1\"](arg0)]]                                                   \n[[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?,500], [?,1]], \noutput_types=[DT_INT32, DT_INT64]](IteratorFromStringHandle V2)]] \n[[{{node ExperimentalFunctionBufferingResourceGetNext}} = \nExperimentalFunctionBufferingResourceGetNext[output_types=[DT_INT32, DT_INT64] , \n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\n(ExperimentalFunctionBufferingResource)]]\nException ignored in:  6e80>>\n--\n\n\n\n\nThe script without \tdistribution = tf.contrib.distribute.MirroredStrategy() ran well. Since I need to populate the network with a huge set, I plan to parallize the work on various GPUs.\nDescribe the expected behavior\nPlease kindly let me know how should I interpret the errors and what the solutions are. Thank you.\nCode to reproduce the issue\nMy network architecture looks like this (a hierarchical one):\nconfig = tf.ConfigProto(allow_soft_placement = True, log_device_placement= False)\n\tsess = tf.Session(config = config)\n\twith tf.Session(config = config) as sess:\n\t\tsess.run(tf.global_variables_initializer())\n                # load in data\n\t         #######################DNN Level 1########################\n\t        if options.L1_model == 0:\n\t\t        model = BuildModel()\n\t\t        model.fit(X_train, y_train[:, 0],\n\t\t\t\t  validation_data=(X_test, y_test[:, 0]),\n\t\t\t\t  epochs=options.epochs,\n\t\t\t\t  verbose=2,\n\t\t\t\t  batch_size=options.batch_size_L1)\n          #######################DNN Level 1########################\n\t         if options.L2_model == 0:\n \n\t\t         model = BuildModel()\n\t\t          model.fit(..., batch_size=options.batch_size_L2)\n\n\nThe model stopped already at the first level. And I don't think the failure has something to do with a hierarchical structure.\nBuildModel() is defined this way:\ndef buildModel_DNN(word_index, embeddings_index, nClasses, \nMAX_SEQUENCE_LENGTH, EMBEDDING_DIM, gpusno, nLayers=3,Number_Node=100, dropout=0.5):\n\t\n\tembedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n\tfor word, i in word_index.items():\n\t\tembedding_vector = embeddings_index.get(word)\n\t\tif embedding_vector is not None:\n\t\t\tembedding_matrix[i] = embedding_vector\n\t\t\t\n\tmodel = tf.keras.models.Sequential()\n\t\n\tmodel.add(tf.keras.layers.Embedding(len(word_index) + 1,\n\t\t\t\t\t\t\t\tEMBEDDING_DIM,\n\t\t\t\t\t\t\t\tweights=[embedding_matrix],\n\t\t\t\t\t\t\t\tinput_length=MAX_SEQUENCE_LENGTH,\n\t\t\t\t\t\t\t\ttrainable=True))\n\tmodel.add(tf.keras.layers.Flatten())\n\t\n\tfor i in range(0,nLayers):\n\t\tmodel.add(tf.keras.layers.Dense(Number_Node, activation='relu'))\n\t\tmodel.add(tf.keras.layers.Dropout(dropout))\n\t\n\tmodel.add(tf.keras.layers.Dense(nClasses, activation='softmax'))\n\n\t\n\tdistribution = tf.contrib.distribute.MirroredStrategy(\n                               ['/device:GPU:0', '/device:GPU:1'], prefetch_on_device=True)\n\t\n\tmodel.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n\t\t\t\t  optimizer=tf.train.AdamOptimizer(),\n\t\t\t\t  metrics=['accuracy'], \n\t\t\t\t  # distribute=distribution,\n\t\t\t\t  options = run_opts)\n\t\t\t\t  \n\tprint('model summary:') \n\tmodel.summary()\n\n\treturn model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I also tested the code in Examples\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: TITAN Xp (12196MiB)\r\n--\r\n\r\n\r\n**Describe the current behavior**\r\nI have been testing your MirroredStrategy() function with your example script and my own script. \r\n- It worked well on the sample script. \r\n- When I adapted my own script, it kept emitting the following error I don't know how to interpret/search.\r\n\r\n```\r\nWARNING:tensorflow:Not all devices in distribute strategy are visible by TensorFlow sessions.\r\nWARNING:tensorflow:You are accessing attribute optimizerof the \r\nDistributedCallbackModel that may not have been set correctly.\r\nWARNING:tensorflow:You are accessing attribute \r\n_unconditional_checkpoint_dependenciesof the DistributedCallbackModel \r\nthat may not have been set correctly.\r\nEpoch 1/1\r\n2018-11-20 16:41:15.195119: W tensorflow/core/framework/op_kernel.cc:1261] \r\nInvalid argument: ValueError: `generator` yielded an element of shape (1, 1) \r\nwhere an element of shape (1,) was expected.\r\nTraceback (most recent call last):\r\n\r\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", \r\nline 206, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"xxxxx/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", \r\nline 487, in generator_py_func\r\n    \"of shape %s was expected.\" % (ret_array.shape, expected_shape))\r\n\r\nValueError: `generator` yielded an element of shape (1, 1) \r\nwhere an element of shape (1,) was expected.\r\n\r\n\r\n[[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT32, DT_INT64], \r\ntoken=\"pyfunc_1\"](arg0)]]                                                   \r\n[[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?,500], [?,1]], \r\noutput_types=[DT_INT32, DT_INT64]](IteratorFromStringHandle V2)]] \r\n[[{{node ExperimentalFunctionBufferingResourceGetNext}} = \r\nExperimentalFunctionBufferingResourceGetNext[output_types=[DT_INT32, DT_INT64] , \r\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]\r\n(ExperimentalFunctionBufferingResource)]]\r\nException ignored in:  6e80>>\r\n--\r\n\r\n\r\n\r\n```\r\nThe script without \t```distribution = tf.contrib.distribute.MirroredStrategy()``` ran well. Since I need to populate the network with a huge set, I plan to parallize the work on various GPUs. \r\n\r\n\r\n**Describe the expected behavior**\r\nPlease kindly let me know how should I interpret the errors and what the solutions are. Thank you.\r\n\r\n**Code to reproduce the issue**\r\nMy network architecture looks like this (a hierarchical one): \r\n```\r\nconfig = tf.ConfigProto(allow_soft_placement = True, log_device_placement= False)\r\n\tsess = tf.Session(config = config)\r\n\twith tf.Session(config = config) as sess:\r\n\t\tsess.run(tf.global_variables_initializer())\r\n                # load in data\r\n\t         #######################DNN Level 1########################\r\n\t        if options.L1_model == 0:\r\n\t\t        model = BuildModel()\r\n\t\t        model.fit(X_train, y_train[:, 0],\r\n\t\t\t\t  validation_data=(X_test, y_test[:, 0]),\r\n\t\t\t\t  epochs=options.epochs,\r\n\t\t\t\t  verbose=2,\r\n\t\t\t\t  batch_size=options.batch_size_L1)\r\n          #######################DNN Level 1########################\r\n\t         if options.L2_model == 0:\r\n \r\n\t\t         model = BuildModel()\r\n\t\t          model.fit(..., batch_size=options.batch_size_L2)\r\n\r\n```\r\n\r\nThe model stopped already at the first level. And I don't think the failure has something to do with a hierarchical structure. \r\n\r\n`BuildModel()` is defined this way:\r\n```\r\ndef buildModel_DNN(word_index, embeddings_index, nClasses, \r\nMAX_SEQUENCE_LENGTH, EMBEDDING_DIM, gpusno, nLayers=3,Number_Node=100, dropout=0.5):\r\n\t\r\n\tembedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\r\n\tfor word, i in word_index.items():\r\n\t\tembedding_vector = embeddings_index.get(word)\r\n\t\tif embedding_vector is not None:\r\n\t\t\tembedding_matrix[i] = embedding_vector\r\n\t\t\t\r\n\tmodel = tf.keras.models.Sequential()\r\n\t\r\n\tmodel.add(tf.keras.layers.Embedding(len(word_index) + 1,\r\n\t\t\t\t\t\t\t\tEMBEDDING_DIM,\r\n\t\t\t\t\t\t\t\tweights=[embedding_matrix],\r\n\t\t\t\t\t\t\t\tinput_length=MAX_SEQUENCE_LENGTH,\r\n\t\t\t\t\t\t\t\ttrainable=True))\r\n\tmodel.add(tf.keras.layers.Flatten())\r\n\t\r\n\tfor i in range(0,nLayers):\r\n\t\tmodel.add(tf.keras.layers.Dense(Number_Node, activation='relu'))\r\n\t\tmodel.add(tf.keras.layers.Dropout(dropout))\r\n\t\r\n\tmodel.add(tf.keras.layers.Dense(nClasses, activation='softmax'))\r\n\r\n\t\r\n\tdistribution = tf.contrib.distribute.MirroredStrategy(\r\n                               ['/device:GPU:0', '/device:GPU:1'], prefetch_on_device=True)\r\n\t\r\n\tmodel.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n\t\t\t\t  optimizer=tf.train.AdamOptimizer(),\r\n\t\t\t\t  metrics=['accuracy'], \r\n\t\t\t\t  # distribute=distribution,\r\n\t\t\t\t  options = run_opts)\r\n\t\t\t\t  \r\n\tprint('model summary:') \r\n\tmodel.summary()\r\n\r\n\treturn model\r\n```"}