{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15498", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15498/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15498/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15498/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15498", "id": 283439043, "node_id": "MDU6SXNzdWUyODM0MzkwNDM=", "number": 15498, "title": "gradients_1 generated in graph but not connected with AdamOptimizer ", "user": {"login": "babiking", "id": 33562173, "node_id": "MDQ6VXNlcjMzNTYyMTcz", "avatar_url": "https://avatars2.githubusercontent.com/u/33562173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/babiking", "html_url": "https://github.com/babiking", "followers_url": "https://api.github.com/users/babiking/followers", "following_url": "https://api.github.com/users/babiking/following{/other_user}", "gists_url": "https://api.github.com/users/babiking/gists{/gist_id}", "starred_url": "https://api.github.com/users/babiking/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/babiking/subscriptions", "organizations_url": "https://api.github.com/users/babiking/orgs", "repos_url": "https://api.github.com/users/babiking/repos", "events_url": "https://api.github.com/users/babiking/events{/privacy}", "received_events_url": "https://api.github.com/users/babiking/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-20T03:31:05Z", "updated_at": "2017-12-20T05:17:33Z", "closed_at": "2017-12-20T05:17:33Z", "author_association": "NONE", "body_html": "<p>System information:<br>\nOS platform: Linux Unbuntu 16.04<br>\nTensorflow install from: pip install...<br>\nTensorflow version: 1.4.0<br>\nPython version: py2.7</p>\n<p>Problem:<br>\nI want to write a CNN classification network for MNIST dataset. And I write a class named MNIST_classification, then define '_build_model()' and '_train_phase()' in this class. In main function, I define a object of MNIST_classification class, and callback the '_train_phase()' to start a training process. But I found in Graph(), there are two gradients generated at each computation node, i.e. \"gradients\" and \"gradients_1\". I use tf.gradients(loss, train_vars) to print all gradients' names and get '/gradients_1/*', but within the Graph(), gradients_1 are not connected with a AdamOptimizer, which leads to no backward propagation update for each trainable variable...</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/33562173/34189925-f3c6c4ac-e578-11e7-8b8f-3de98611d415.png\"><img src=\"https://user-images.githubusercontent.com/33562173/34189925-f3c6c4ac-e578-11e7-8b8f-3de98611d415.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>Source code:</p>\n<p>import tensorflow as tf<br>\nfrom utils import utils<br>\nimport numpy as np</p>\n<p>class mnist_classification(object):</p>\n<pre><code>def __init__(self, sess, graph, train_param={'num_of_epoches': 1000,\n                                    'num_of_classes': 10,\n                                    'log_dir': './log',\n                                    'model_dir': './model',\n                                    'batch_size': 128,\n                                    'learn_rate': 1e-4,\n                                    'max_iter': 5000,\n                                    'dim_feat': 28}):\n\n    self.num_of_epoches = train_param['num_of_epoches']\n    self.log_dir      = train_param['log_dir']\n    self.model_dir    = train_param['model_dir']\n    self.batch_size   = train_param['batch_size']\n\n    self.learn_rate = train_param['learn_rate']\n    self.max_iter   = train_param['max_iter']\n\n    self.dim_feat = train_param['dim_feat']\n    self.num_of_classes = train_param['num_of_classes']\n\n    self.sess = sess\n    self.graph = graph\n\n    # !Build-up MNIST classification model...\n    assert self.sess.graph is self.graph\n    self._build_model()\n\n\n\ndef _convolution_block(self, inp_feat, kernel_size, num_of_kernel_channels, conv_strides, conv_padding, var_scope):\n    '''\n        Function:\n                    _convolution_block, i.e. convolution + Maxpooling + ReLU\n        Input:\n                [1] &lt;tensor&gt; inp_feat, i.e. input feature, dimension-&gt;[batch_size, height, width, channel]\n                [2] &lt;int32&gt;  kernel_size\n                [3] &lt;int32&gt; num_of_kernel_channels\n                [4] &lt;int32&gt; conv_strides\n                [5] &lt;string&gt; conv_padding\n                [5] &lt;string&gt; var_scope\n        Output:\n                &lt;tensor&gt; activ\n    '''\n    try:\n        num_of_feat_channels = inp_feat.shape[3].value\n    except:\n        num_of_feat_channels = 1\n\n    with tf.variable_scope(var_scope):\n        weights = tf.get_variable(name='conv_weights', shape=[kernel_size, kernel_size, num_of_feat_channels, num_of_kernel_channels],\n                                  initializer=tf.random_normal_initializer(stddev=0.1))\n\n        biases = tf.get_variable(name='conv_biases', shape=[num_of_kernel_channels], initializer=tf.zeros_initializer())\n\n    # !Convolution layer...\n    conv = tf.nn.conv2d(inp_feat, weights, strides=conv_strides, padding=conv_padding, name='conv', data_format='NHWC') + biases\n\n    # !Activation layer...\n    activ = tf.nn.relu(conv)\n\n    # !Pooling layer...\n    pool = tf.nn.max_pool(activ,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n\n    return pool\n\n\n\n\n\ndef _fc_layer(self, inp_feat, num_of_outputs, var_scope):\n    '''\n        Function:\n                    _fc_layer\n        Input:\n                    [1] inp_feat, dimension-&gt;[batch_size, dim_feat]\n                    [2] num_of_outputs\n                    [3] var_scope: reuse=True\n        Output:\n                    fc\n    '''\n\n    dim_feat = inp_feat.shape[1].value\n\n    with tf.variable_scope(var_scope):\n\n        fc_weights = tf.get_variable(name='fc_weights', dtype=tf.float32, shape=[dim_feat, num_of_outputs], initializer=tf.random_normal_initializer(stddev=0.1))\n        fc_bias    = tf.get_variable(name='fc_bias',    dtype=tf.float32, shape=[num_of_outputs], initializer=tf.zeros_initializer())\n\n\n        # tf.nn.xw_plus_b(x, weights, bias) = tf.matmul(x, weights) + biases\n        fc = tf.nn.xw_plus_b(x=inp_feat, weights=fc_weights, biases=fc_bias)\n\n        return fc\n\n\n\ndef _build_model(self):\n\n    self.digit = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, self.dim_feat, self.dim_feat, 1])\n    self.label = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, self.num_of_classes])\n\n    # # !One-hot encoding for label...\n    # with tf.name_scope('label_trans'):\n    #     self.new_label = utils._array_sparse_to_dense(self.label, self.num_of_classes)\n\n    conv1 = self._convolution_block(inp_feat=self.digit, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=32, var_scope='conv1')\n\n    conv2 = self._convolution_block(inp_feat=conv1, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=64, var_scope='conv2')\n\n    conv3 = self._convolution_block(inp_feat=conv2, conv_strides=[1, 1, 1, 1], conv_padding='SAME', kernel_size=7,num_of_kernel_channels=64, var_scope='conv3')\n\n    flatt = tf.layers.flatten(conv3, name='flatten')\n\n    fc1 = self._fc_layer(inp_feat=flatt, num_of_outputs=1024, var_scope='fc1')\n    fc1 = tf.nn.relu(fc1)\n\n    fc2 = self._fc_layer(inp_feat=fc1, num_of_outputs=10, var_scope='fc2')\n\n    self.predict = tf.nn.softmax(logits=fc2, dim=-1)\n\n    self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.label, logits=fc2))\n\n    # !Define MNIST classification accuracy...\n    correct = tf.equal(tf.argmax(self.predict, 1), tf.argmax(self.label, 1))\n    self.accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n\n    # !Define training operations...\n    self.train_op = tf.train.AdamOptimizer(self.learn_rate).minimize(self.loss)\n\n\n\n\n\ndef _train(self, img_file, lab_file):\n\n    # !Load data into memory...\n    img, n_rows, n_cols = utils._read_MNIST_file(img_file, fmt='&gt;IIII')\n    lab, _, _ = utils._read_MNIST_file(lab_file, fmt='&gt;II')\n\n\n    # !Intialize the global_variables and local_variables...\n    self.sess.run(tf.global_variables_initializer())\n    self.sess.run(tf.local_variables_initializer())\n\n    # !List all trainable variables...\n    train_vars = tf.trainable_variables()\n    for var in train_vars:\n        print var.name\n\n    # !Add gradients into tensorboard summary...\n    gradients = tf.gradients(self.loss, train_vars)\n    for ii in range(len(gradients)):\n        if gradients[ii]!=None:\n            tf.summary.histogram(train_vars[ii].name, gradients[ii])\n\n    # !Add loss into tensorboard summary...\n    tf.summary.scalar('loss', self.loss)\n    tf.summary.scalar('accuracy', self.accuracy)\n\n    tf.summary.image('input_image', self.digit)\n\n    summary_writer = tf.summary.FileWriter(\"./log\", self.sess.graph)\n\n    merged = tf.summary.merge_all()\n\n    # !Start training process...\n    for ii_epoch in range(self.num_of_epoches):\n        for ii_iter in range(self.max_iter):\n\n\n            img_batch = utils._randomly_sample(img, self.batch_size)\n            img_batch = np.expand_dims(img_batch, axis=3) / 255\n\n            lab_batch = utils._randomly_sample(lab, self.batch_size)\n            lab_batch = utils._array_sparse_to_dense(np.int64(lab_batch), num_of_classes=self.num_of_classes)\n\n            _, pred, los, acc, summary= self.sess.run([self.train_op, self.predict, self.loss, self.accuracy, merged], feed_dict={self.digit: img_batch, self.label: lab_batch})\n\n            if ( (ii_epoch * self.max_iter + ii_iter) % 100 == 0):\n                summary_writer.add_summary(summary, ii_epoch * self.max_iter + ii_iter)\n                print(pred[0,:])\n                print(lab_batch[0])\n\n            print('!Loss at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, los))\n            print('!Accuracy at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, acc))\n</code></pre>\n<p>Main function:<br>\nfrom utils.utils import _array_sparse_to_dense<br>\nfrom utils.utils import _read_MNIST_file<br>\nfrom matplotlib import pyplot<br>\nimport numpy as np<br>\nimport tensorflow as tf<br>\nfrom model.MNIST_classification import mnist_classification<br>\nimport os<br>\nimport sys</p>\n<h1>!Check if tensorflow version == '1.4.0', API</h1>\n<p>assert tf.<strong>version</strong> == '1.4.0'</p>\n<h1>!Set system default encoding method == 'utf-8'</h1>\n<p>reload(sys)<br>\nsys.setdefaultencoding('utf-8')</p>\n<p>os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"<br>\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"</p>\n<p>with tf.Graph().as_default() as graph:<br>\nwith tf.Session() as sess:<br>\nMNIST_inst = mnist_classification(sess=sess, graph=graph)</p>\n<pre><code>    MNIST_inst._train(img_file='./data/train-images.idx3-ubyte', lab_file='./data/train-labels.idx1-ubyte')\n</code></pre>", "body_text": "System information:\nOS platform: Linux Unbuntu 16.04\nTensorflow install from: pip install...\nTensorflow version: 1.4.0\nPython version: py2.7\nProblem:\nI want to write a CNN classification network for MNIST dataset. And I write a class named MNIST_classification, then define '_build_model()' and '_train_phase()' in this class. In main function, I define a object of MNIST_classification class, and callback the '_train_phase()' to start a training process. But I found in Graph(), there are two gradients generated at each computation node, i.e. \"gradients\" and \"gradients_1\". I use tf.gradients(loss, train_vars) to print all gradients' names and get '/gradients_1/*', but within the Graph(), gradients_1 are not connected with a AdamOptimizer, which leads to no backward propagation update for each trainable variable...\n\nSource code:\nimport tensorflow as tf\nfrom utils import utils\nimport numpy as np\nclass mnist_classification(object):\ndef __init__(self, sess, graph, train_param={'num_of_epoches': 1000,\n                                    'num_of_classes': 10,\n                                    'log_dir': './log',\n                                    'model_dir': './model',\n                                    'batch_size': 128,\n                                    'learn_rate': 1e-4,\n                                    'max_iter': 5000,\n                                    'dim_feat': 28}):\n\n    self.num_of_epoches = train_param['num_of_epoches']\n    self.log_dir      = train_param['log_dir']\n    self.model_dir    = train_param['model_dir']\n    self.batch_size   = train_param['batch_size']\n\n    self.learn_rate = train_param['learn_rate']\n    self.max_iter   = train_param['max_iter']\n\n    self.dim_feat = train_param['dim_feat']\n    self.num_of_classes = train_param['num_of_classes']\n\n    self.sess = sess\n    self.graph = graph\n\n    # !Build-up MNIST classification model...\n    assert self.sess.graph is self.graph\n    self._build_model()\n\n\n\ndef _convolution_block(self, inp_feat, kernel_size, num_of_kernel_channels, conv_strides, conv_padding, var_scope):\n    '''\n        Function:\n                    _convolution_block, i.e. convolution + Maxpooling + ReLU\n        Input:\n                [1] <tensor> inp_feat, i.e. input feature, dimension->[batch_size, height, width, channel]\n                [2] <int32>  kernel_size\n                [3] <int32> num_of_kernel_channels\n                [4] <int32> conv_strides\n                [5] <string> conv_padding\n                [5] <string> var_scope\n        Output:\n                <tensor> activ\n    '''\n    try:\n        num_of_feat_channels = inp_feat.shape[3].value\n    except:\n        num_of_feat_channels = 1\n\n    with tf.variable_scope(var_scope):\n        weights = tf.get_variable(name='conv_weights', shape=[kernel_size, kernel_size, num_of_feat_channels, num_of_kernel_channels],\n                                  initializer=tf.random_normal_initializer(stddev=0.1))\n\n        biases = tf.get_variable(name='conv_biases', shape=[num_of_kernel_channels], initializer=tf.zeros_initializer())\n\n    # !Convolution layer...\n    conv = tf.nn.conv2d(inp_feat, weights, strides=conv_strides, padding=conv_padding, name='conv', data_format='NHWC') + biases\n\n    # !Activation layer...\n    activ = tf.nn.relu(conv)\n\n    # !Pooling layer...\n    pool = tf.nn.max_pool(activ,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n\n    return pool\n\n\n\n\n\ndef _fc_layer(self, inp_feat, num_of_outputs, var_scope):\n    '''\n        Function:\n                    _fc_layer\n        Input:\n                    [1] inp_feat, dimension->[batch_size, dim_feat]\n                    [2] num_of_outputs\n                    [3] var_scope: reuse=True\n        Output:\n                    fc\n    '''\n\n    dim_feat = inp_feat.shape[1].value\n\n    with tf.variable_scope(var_scope):\n\n        fc_weights = tf.get_variable(name='fc_weights', dtype=tf.float32, shape=[dim_feat, num_of_outputs], initializer=tf.random_normal_initializer(stddev=0.1))\n        fc_bias    = tf.get_variable(name='fc_bias',    dtype=tf.float32, shape=[num_of_outputs], initializer=tf.zeros_initializer())\n\n\n        # tf.nn.xw_plus_b(x, weights, bias) = tf.matmul(x, weights) + biases\n        fc = tf.nn.xw_plus_b(x=inp_feat, weights=fc_weights, biases=fc_bias)\n\n        return fc\n\n\n\ndef _build_model(self):\n\n    self.digit = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, self.dim_feat, self.dim_feat, 1])\n    self.label = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, self.num_of_classes])\n\n    # # !One-hot encoding for label...\n    # with tf.name_scope('label_trans'):\n    #     self.new_label = utils._array_sparse_to_dense(self.label, self.num_of_classes)\n\n    conv1 = self._convolution_block(inp_feat=self.digit, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=32, var_scope='conv1')\n\n    conv2 = self._convolution_block(inp_feat=conv1, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=64, var_scope='conv2')\n\n    conv3 = self._convolution_block(inp_feat=conv2, conv_strides=[1, 1, 1, 1], conv_padding='SAME', kernel_size=7,num_of_kernel_channels=64, var_scope='conv3')\n\n    flatt = tf.layers.flatten(conv3, name='flatten')\n\n    fc1 = self._fc_layer(inp_feat=flatt, num_of_outputs=1024, var_scope='fc1')\n    fc1 = tf.nn.relu(fc1)\n\n    fc2 = self._fc_layer(inp_feat=fc1, num_of_outputs=10, var_scope='fc2')\n\n    self.predict = tf.nn.softmax(logits=fc2, dim=-1)\n\n    self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.label, logits=fc2))\n\n    # !Define MNIST classification accuracy...\n    correct = tf.equal(tf.argmax(self.predict, 1), tf.argmax(self.label, 1))\n    self.accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n\n    # !Define training operations...\n    self.train_op = tf.train.AdamOptimizer(self.learn_rate).minimize(self.loss)\n\n\n\n\n\ndef _train(self, img_file, lab_file):\n\n    # !Load data into memory...\n    img, n_rows, n_cols = utils._read_MNIST_file(img_file, fmt='>IIII')\n    lab, _, _ = utils._read_MNIST_file(lab_file, fmt='>II')\n\n\n    # !Intialize the global_variables and local_variables...\n    self.sess.run(tf.global_variables_initializer())\n    self.sess.run(tf.local_variables_initializer())\n\n    # !List all trainable variables...\n    train_vars = tf.trainable_variables()\n    for var in train_vars:\n        print var.name\n\n    # !Add gradients into tensorboard summary...\n    gradients = tf.gradients(self.loss, train_vars)\n    for ii in range(len(gradients)):\n        if gradients[ii]!=None:\n            tf.summary.histogram(train_vars[ii].name, gradients[ii])\n\n    # !Add loss into tensorboard summary...\n    tf.summary.scalar('loss', self.loss)\n    tf.summary.scalar('accuracy', self.accuracy)\n\n    tf.summary.image('input_image', self.digit)\n\n    summary_writer = tf.summary.FileWriter(\"./log\", self.sess.graph)\n\n    merged = tf.summary.merge_all()\n\n    # !Start training process...\n    for ii_epoch in range(self.num_of_epoches):\n        for ii_iter in range(self.max_iter):\n\n\n            img_batch = utils._randomly_sample(img, self.batch_size)\n            img_batch = np.expand_dims(img_batch, axis=3) / 255\n\n            lab_batch = utils._randomly_sample(lab, self.batch_size)\n            lab_batch = utils._array_sparse_to_dense(np.int64(lab_batch), num_of_classes=self.num_of_classes)\n\n            _, pred, los, acc, summary= self.sess.run([self.train_op, self.predict, self.loss, self.accuracy, merged], feed_dict={self.digit: img_batch, self.label: lab_batch})\n\n            if ( (ii_epoch * self.max_iter + ii_iter) % 100 == 0):\n                summary_writer.add_summary(summary, ii_epoch * self.max_iter + ii_iter)\n                print(pred[0,:])\n                print(lab_batch[0])\n\n            print('!Loss at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, los))\n            print('!Accuracy at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, acc))\n\nMain function:\nfrom utils.utils import _array_sparse_to_dense\nfrom utils.utils import _read_MNIST_file\nfrom matplotlib import pyplot\nimport numpy as np\nimport tensorflow as tf\nfrom model.MNIST_classification import mnist_classification\nimport os\nimport sys\n!Check if tensorflow version == '1.4.0', API\nassert tf.version == '1.4.0'\n!Set system default encoding method == 'utf-8'\nreload(sys)\nsys.setdefaultencoding('utf-8')\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nwith tf.Graph().as_default() as graph:\nwith tf.Session() as sess:\nMNIST_inst = mnist_classification(sess=sess, graph=graph)\n    MNIST_inst._train(img_file='./data/train-images.idx3-ubyte', lab_file='./data/train-labels.idx1-ubyte')", "body": "System information: \r\nOS platform: Linux Unbuntu 16.04\r\nTensorflow install from: pip install...\r\nTensorflow version: 1.4.0\r\nPython version: py2.7\r\n\r\nProblem:\r\nI want to write a CNN classification network for MNIST dataset. And I write a class named MNIST_classification, then define '_build_model()' and '_train_phase()' in this class. In main function, I define a object of MNIST_classification class, and callback the '_train_phase()' to start a training process. But I found in Graph(), there are two gradients generated at each computation node, i.e. \"gradients\" and \"gradients_1\". I use tf.gradients(loss, train_vars) to print all gradients' names and get '/gradients_1/*', but within the Graph(), gradients_1 are not connected with a AdamOptimizer, which leads to no backward propagation update for each trainable variable...\r\n\r\n \r\n![image](https://user-images.githubusercontent.com/33562173/34189925-f3c6c4ac-e578-11e7-8b8f-3de98611d415.png)\r\n\r\nSource code:\r\n\r\nimport tensorflow as tf\r\nfrom utils import utils\r\nimport numpy as np\r\n\r\nclass mnist_classification(object):\r\n\r\n    def __init__(self, sess, graph, train_param={'num_of_epoches': 1000,\r\n                                        'num_of_classes': 10,\r\n                                        'log_dir': './log',\r\n                                        'model_dir': './model',\r\n                                        'batch_size': 128,\r\n                                        'learn_rate': 1e-4,\r\n                                        'max_iter': 5000,\r\n                                        'dim_feat': 28}):\r\n\r\n        self.num_of_epoches = train_param['num_of_epoches']\r\n        self.log_dir      = train_param['log_dir']\r\n        self.model_dir    = train_param['model_dir']\r\n        self.batch_size   = train_param['batch_size']\r\n\r\n        self.learn_rate = train_param['learn_rate']\r\n        self.max_iter   = train_param['max_iter']\r\n\r\n        self.dim_feat = train_param['dim_feat']\r\n        self.num_of_classes = train_param['num_of_classes']\r\n\r\n        self.sess = sess\r\n        self.graph = graph\r\n\r\n        # !Build-up MNIST classification model...\r\n        assert self.sess.graph is self.graph\r\n        self._build_model()\r\n\r\n\r\n\r\n    def _convolution_block(self, inp_feat, kernel_size, num_of_kernel_channels, conv_strides, conv_padding, var_scope):\r\n        '''\r\n            Function:\r\n                        _convolution_block, i.e. convolution + Maxpooling + ReLU\r\n            Input:\r\n                    [1] <tensor> inp_feat, i.e. input feature, dimension->[batch_size, height, width, channel]\r\n                    [2] <int32>  kernel_size\r\n                    [3] <int32> num_of_kernel_channels\r\n                    [4] <int32> conv_strides\r\n                    [5] <string> conv_padding\r\n                    [5] <string> var_scope\r\n            Output:\r\n                    <tensor> activ\r\n        '''\r\n        try:\r\n            num_of_feat_channels = inp_feat.shape[3].value\r\n        except:\r\n            num_of_feat_channels = 1\r\n\r\n        with tf.variable_scope(var_scope):\r\n            weights = tf.get_variable(name='conv_weights', shape=[kernel_size, kernel_size, num_of_feat_channels, num_of_kernel_channels],\r\n                                      initializer=tf.random_normal_initializer(stddev=0.1))\r\n\r\n            biases = tf.get_variable(name='conv_biases', shape=[num_of_kernel_channels], initializer=tf.zeros_initializer())\r\n\r\n        # !Convolution layer...\r\n        conv = tf.nn.conv2d(inp_feat, weights, strides=conv_strides, padding=conv_padding, name='conv', data_format='NHWC') + biases\r\n\r\n        # !Activation layer...\r\n        activ = tf.nn.relu(conv)\r\n\r\n        # !Pooling layer...\r\n        pool = tf.nn.max_pool(activ,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\r\n\r\n        return pool\r\n\r\n\r\n\r\n\r\n\r\n    def _fc_layer(self, inp_feat, num_of_outputs, var_scope):\r\n        '''\r\n            Function:\r\n                        _fc_layer\r\n            Input:\r\n                        [1] inp_feat, dimension->[batch_size, dim_feat]\r\n                        [2] num_of_outputs\r\n                        [3] var_scope: reuse=True\r\n            Output:\r\n                        fc\r\n        '''\r\n\r\n        dim_feat = inp_feat.shape[1].value\r\n\r\n        with tf.variable_scope(var_scope):\r\n\r\n            fc_weights = tf.get_variable(name='fc_weights', dtype=tf.float32, shape=[dim_feat, num_of_outputs], initializer=tf.random_normal_initializer(stddev=0.1))\r\n            fc_bias    = tf.get_variable(name='fc_bias',    dtype=tf.float32, shape=[num_of_outputs], initializer=tf.zeros_initializer())\r\n\r\n\r\n            # tf.nn.xw_plus_b(x, weights, bias) = tf.matmul(x, weights) + biases\r\n            fc = tf.nn.xw_plus_b(x=inp_feat, weights=fc_weights, biases=fc_bias)\r\n\r\n            return fc\r\n\r\n\r\n\r\n    def _build_model(self):\r\n\r\n        self.digit = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, self.dim_feat, self.dim_feat, 1])\r\n        self.label = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, self.num_of_classes])\r\n\r\n        # # !One-hot encoding for label...\r\n        # with tf.name_scope('label_trans'):\r\n        #     self.new_label = utils._array_sparse_to_dense(self.label, self.num_of_classes)\r\n\r\n        conv1 = self._convolution_block(inp_feat=self.digit, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=32, var_scope='conv1')\r\n\r\n        conv2 = self._convolution_block(inp_feat=conv1, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=64, var_scope='conv2')\r\n\r\n        conv3 = self._convolution_block(inp_feat=conv2, conv_strides=[1, 1, 1, 1], conv_padding='SAME', kernel_size=7,num_of_kernel_channels=64, var_scope='conv3')\r\n\r\n        flatt = tf.layers.flatten(conv3, name='flatten')\r\n\r\n        fc1 = self._fc_layer(inp_feat=flatt, num_of_outputs=1024, var_scope='fc1')\r\n        fc1 = tf.nn.relu(fc1)\r\n\r\n        fc2 = self._fc_layer(inp_feat=fc1, num_of_outputs=10, var_scope='fc2')\r\n\r\n        self.predict = tf.nn.softmax(logits=fc2, dim=-1)\r\n\r\n        self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.label, logits=fc2))\r\n\r\n        # !Define MNIST classification accuracy...\r\n        correct = tf.equal(tf.argmax(self.predict, 1), tf.argmax(self.label, 1))\r\n        self.accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n\r\n        # !Define training operations...\r\n        self.train_op = tf.train.AdamOptimizer(self.learn_rate).minimize(self.loss)\r\n\r\n\r\n\r\n\r\n\r\n    def _train(self, img_file, lab_file):\r\n\r\n        # !Load data into memory...\r\n        img, n_rows, n_cols = utils._read_MNIST_file(img_file, fmt='>IIII')\r\n        lab, _, _ = utils._read_MNIST_file(lab_file, fmt='>II')\r\n\r\n\r\n        # !Intialize the global_variables and local_variables...\r\n        self.sess.run(tf.global_variables_initializer())\r\n        self.sess.run(tf.local_variables_initializer())\r\n\r\n        # !List all trainable variables...\r\n        train_vars = tf.trainable_variables()\r\n        for var in train_vars:\r\n            print var.name\r\n\r\n        # !Add gradients into tensorboard summary...\r\n        gradients = tf.gradients(self.loss, train_vars)\r\n        for ii in range(len(gradients)):\r\n            if gradients[ii]!=None:\r\n                tf.summary.histogram(train_vars[ii].name, gradients[ii])\r\n\r\n        # !Add loss into tensorboard summary...\r\n        tf.summary.scalar('loss', self.loss)\r\n        tf.summary.scalar('accuracy', self.accuracy)\r\n\r\n        tf.summary.image('input_image', self.digit)\r\n\r\n        summary_writer = tf.summary.FileWriter(\"./log\", self.sess.graph)\r\n\r\n        merged = tf.summary.merge_all()\r\n\r\n        # !Start training process...\r\n        for ii_epoch in range(self.num_of_epoches):\r\n            for ii_iter in range(self.max_iter):\r\n\r\n\r\n                img_batch = utils._randomly_sample(img, self.batch_size)\r\n                img_batch = np.expand_dims(img_batch, axis=3) / 255\r\n\r\n                lab_batch = utils._randomly_sample(lab, self.batch_size)\r\n                lab_batch = utils._array_sparse_to_dense(np.int64(lab_batch), num_of_classes=self.num_of_classes)\r\n\r\n                _, pred, los, acc, summary= self.sess.run([self.train_op, self.predict, self.loss, self.accuracy, merged], feed_dict={self.digit: img_batch, self.label: lab_batch})\r\n\r\n                if ( (ii_epoch * self.max_iter + ii_iter) % 100 == 0):\r\n                    summary_writer.add_summary(summary, ii_epoch * self.max_iter + ii_iter)\r\n                    print(pred[0,:])\r\n                    print(lab_batch[0])\r\n\r\n                print('!Loss at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, los))\r\n                print('!Accuracy at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, acc))\r\n\r\n\r\n\r\nMain function:\r\nfrom utils.utils import _array_sparse_to_dense\r\nfrom utils.utils import _read_MNIST_file\r\nfrom matplotlib import pyplot\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom model.MNIST_classification import mnist_classification\r\nimport os\r\nimport sys\r\n\r\n\r\n# !Check if tensorflow version == '1.4.0', API\r\nassert tf.__version__ == '1.4.0'\r\n\r\n\r\n\r\n# !Set system default encoding method == 'utf-8'\r\nreload(sys)\r\nsys.setdefaultencoding('utf-8')\r\n\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\n\r\n\r\nwith tf.Graph().as_default() as graph:\r\n    with tf.Session() as sess:\r\n        MNIST_inst = mnist_classification(sess=sess, graph=graph)\r\n\r\n        MNIST_inst._train(img_file='./data/train-images.idx3-ubyte', lab_file='./data/train-labels.idx1-ubyte')\r\n\r\n"}