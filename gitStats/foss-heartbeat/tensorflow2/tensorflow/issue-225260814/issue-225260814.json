{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9539", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9539/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9539/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9539/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9539", "id": 225260814, "node_id": "MDU6SXNzdWUyMjUyNjA4MTQ=", "number": 9539, "title": "load a checkpoint and use it to create a new graph", "user": {"login": "chenweiqian", "id": 16277253, "node_id": "MDQ6VXNlcjE2Mjc3MjUz", "avatar_url": "https://avatars3.githubusercontent.com/u/16277253?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenweiqian", "html_url": "https://github.com/chenweiqian", "followers_url": "https://api.github.com/users/chenweiqian/followers", "following_url": "https://api.github.com/users/chenweiqian/following{/other_user}", "gists_url": "https://api.github.com/users/chenweiqian/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenweiqian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenweiqian/subscriptions", "organizations_url": "https://api.github.com/users/chenweiqian/orgs", "repos_url": "https://api.github.com/users/chenweiqian/repos", "events_url": "https://api.github.com/users/chenweiqian/events{/privacy}", "received_events_url": "https://api.github.com/users/chenweiqian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-29T14:36:20Z", "updated_at": "2017-04-30T21:23:01Z", "closed_at": "2017-04-30T21:23:01Z", "author_association": "NONE", "body_html": "<p><strong>system information:</strong><br>\nI am using the latest Tensorflow code on Ubuntu 16.04</p>\n<p><strong>problem:</strong><br>\nbecause the tensorflow SSD can't directly output the final bounding box that i want, so i want to use the orginal checkpoint to create my graph. But i failed, i really wish someone could help me!!! Thanks!!</p>\n<p><strong>error:</strong><br>\ni get the error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"haha.py\", line 43, in &lt;module&gt;\n    select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 120, in ssd_bboxes_select\n    select_threshold, img_shape, num_classes, decode)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 70, in ssd_bboxes_select_layer\n    localizations_layer = ssd_bboxes_decode(localizations_layer, anchors_layer)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 35, in ssd_bboxes_decode\n    (-1, l_shape[-2], l_shape[-1]))\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 224, in reshape\n    return _wrapit(a, 'reshape', newshape, order=order)\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 48, in _wrapit\n    result = getattr(asarray(obj), method)(*args, **kwds)\nValueError: total size of new array must be unchanged\n</code></pre>\n<p><strong>Source code</strong></p>\n<pre><code>import os\nimport math\nimport random\n\nimport numpy as np\nimport tensorflow as tf\n\nslim = tf.contrib.slim\nimport matplotlib.image as mpimg\n\nimport sys\nsys.path.append('../')\n\nfrom nets import ssd_vgg_300, ssd_common, np_methods\nfrom preprocessing import ssd_vgg_preprocessing\n\ngpu_options = tf.GPUOptions(allow_growth=True)\nconfig = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n\nwith tf.Graph().as_default() as g:\n    with g.name_scope('haha'):\n\t\tnet_shape = (300, 300)\n\t\tdata_format = 'NHWC'\n\t\tselect_threshold=0.5\n\t\tnms_threshold=.45\n\t\t# Create graph\n\t\timage_input=tf.placeholder(tf.float32,shape=[None,None,3],name='input')\n\n\t\theight = image_input.shape[0]\n\t\twidth = image_input.shape[1]\n\n\t\timage_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n\t\t\timage_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n\t\timage_4d = tf.expand_dims(image_pre, 0)\n\t\t# Define the SSD model.\n\t\treuse = True if 'ssd_net' in locals() else None\n\t\tssd_net = ssd_vgg_300.SSDNet()\n\t\twith slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n\t\t\tpredictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n\t\tssd_anchors = ssd_net.anchors(net_shape)\n\t\trclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n\t\t\tpredictions, localisations, ssd_anchors,\n\t\t\tselect_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n\t\t\t    \n\t\trbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n\t\t\t    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n\t\trbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n\n\t\ttemp=tf.stack([height,width,height,width])\n\t\trbboxes=rbboxes*temp\n\t\tfacePredictions=rbboxes\n\t\tsaver = tf.train.Saver()\n\nimage_test=np.ones((500,500,3))\n\nwith tf.Session(config=config) as sess:\n\tsess.run(tf.global_variables_initializer())\n\tsaver.restore(sess, \"/home/wahaha/documents/haha/SSD-Tensorflow-master/log/model.ckpt-50000\")\n\tpredictions_val=facePredictions.eval(feed_dict={image_input:image_test})\n\toutput_graph_def = tf.graph_until.convert_variables_to_constants(sess, g.as_graph_def, output_node_names=['haha'])\n\n\twith tf.gfile.FastGFile(hahaFace.pb, mode = 'wb') as f:\n\t\tf.write(output_graph_def.SerializeToString())\n</code></pre>", "body_text": "system information:\nI am using the latest Tensorflow code on Ubuntu 16.04\nproblem:\nbecause the tensorflow SSD can't directly output the final bounding box that i want, so i want to use the orginal checkpoint to create my graph. But i failed, i really wish someone could help me!!! Thanks!!\nerror:\ni get the error:\nTraceback (most recent call last):\n  File \"haha.py\", line 43, in <module>\n    select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 120, in ssd_bboxes_select\n    select_threshold, img_shape, num_classes, decode)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 70, in ssd_bboxes_select_layer\n    localizations_layer = ssd_bboxes_decode(localizations_layer, anchors_layer)\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 35, in ssd_bboxes_decode\n    (-1, l_shape[-2], l_shape[-1]))\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 224, in reshape\n    return _wrapit(a, 'reshape', newshape, order=order)\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 48, in _wrapit\n    result = getattr(asarray(obj), method)(*args, **kwds)\nValueError: total size of new array must be unchanged\n\nSource code\nimport os\nimport math\nimport random\n\nimport numpy as np\nimport tensorflow as tf\n\nslim = tf.contrib.slim\nimport matplotlib.image as mpimg\n\nimport sys\nsys.path.append('../')\n\nfrom nets import ssd_vgg_300, ssd_common, np_methods\nfrom preprocessing import ssd_vgg_preprocessing\n\ngpu_options = tf.GPUOptions(allow_growth=True)\nconfig = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n\nwith tf.Graph().as_default() as g:\n    with g.name_scope('haha'):\n\t\tnet_shape = (300, 300)\n\t\tdata_format = 'NHWC'\n\t\tselect_threshold=0.5\n\t\tnms_threshold=.45\n\t\t# Create graph\n\t\timage_input=tf.placeholder(tf.float32,shape=[None,None,3],name='input')\n\n\t\theight = image_input.shape[0]\n\t\twidth = image_input.shape[1]\n\n\t\timage_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n\t\t\timage_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n\t\timage_4d = tf.expand_dims(image_pre, 0)\n\t\t# Define the SSD model.\n\t\treuse = True if 'ssd_net' in locals() else None\n\t\tssd_net = ssd_vgg_300.SSDNet()\n\t\twith slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n\t\t\tpredictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n\t\tssd_anchors = ssd_net.anchors(net_shape)\n\t\trclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n\t\t\tpredictions, localisations, ssd_anchors,\n\t\t\tselect_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n\t\t\t    \n\t\trbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n\t\t\t    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n\t\trbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n\n\t\ttemp=tf.stack([height,width,height,width])\n\t\trbboxes=rbboxes*temp\n\t\tfacePredictions=rbboxes\n\t\tsaver = tf.train.Saver()\n\nimage_test=np.ones((500,500,3))\n\nwith tf.Session(config=config) as sess:\n\tsess.run(tf.global_variables_initializer())\n\tsaver.restore(sess, \"/home/wahaha/documents/haha/SSD-Tensorflow-master/log/model.ckpt-50000\")\n\tpredictions_val=facePredictions.eval(feed_dict={image_input:image_test})\n\toutput_graph_def = tf.graph_until.convert_variables_to_constants(sess, g.as_graph_def, output_node_names=['haha'])\n\n\twith tf.gfile.FastGFile(hahaFace.pb, mode = 'wb') as f:\n\t\tf.write(output_graph_def.SerializeToString())", "body": "**system information:**\r\nI am using the latest Tensorflow code on Ubuntu 16.04\r\n\r\n**problem:**\r\nbecause the tensorflow SSD can't directly output the final bounding box that i want, so i want to use the orginal checkpoint to create my graph. But i failed, i really wish someone could help me!!! Thanks!!\r\n\r\n**error:**\r\ni get the error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"haha.py\", line 43, in <module>\r\n    select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\r\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 120, in ssd_bboxes_select\r\n    select_threshold, img_shape, num_classes, decode)\r\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 70, in ssd_bboxes_select_layer\r\n    localizations_layer = ssd_bboxes_decode(localizations_layer, anchors_layer)\r\n  File \"/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py\", line 35, in ssd_bboxes_decode\r\n    (-1, l_shape[-2], l_shape[-1]))\r\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 224, in reshape\r\n    return _wrapit(a, 'reshape', newshape, order=order)\r\n  File \"/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 48, in _wrapit\r\n    result = getattr(asarray(obj), method)(*args, **kwds)\r\nValueError: total size of new array must be unchanged\r\n```\r\n\r\n**Source code**\r\n```\r\nimport os\r\nimport math\r\nimport random\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nslim = tf.contrib.slim\r\nimport matplotlib.image as mpimg\r\n\r\nimport sys\r\nsys.path.append('../')\r\n\r\nfrom nets import ssd_vgg_300, ssd_common, np_methods\r\nfrom preprocessing import ssd_vgg_preprocessing\r\n\r\ngpu_options = tf.GPUOptions(allow_growth=True)\r\nconfig = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\r\n\r\nwith tf.Graph().as_default() as g:\r\n    with g.name_scope('haha'):\r\n\t\tnet_shape = (300, 300)\r\n\t\tdata_format = 'NHWC'\r\n\t\tselect_threshold=0.5\r\n\t\tnms_threshold=.45\r\n\t\t# Create graph\r\n\t\timage_input=tf.placeholder(tf.float32,shape=[None,None,3],name='input')\r\n\r\n\t\theight = image_input.shape[0]\r\n\t\twidth = image_input.shape[1]\r\n\r\n\t\timage_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\r\n\t\t\timage_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\r\n\t\timage_4d = tf.expand_dims(image_pre, 0)\r\n\t\t# Define the SSD model.\r\n\t\treuse = True if 'ssd_net' in locals() else None\r\n\t\tssd_net = ssd_vgg_300.SSDNet()\r\n\t\twith slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\r\n\t\t\tpredictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\r\n\t\tssd_anchors = ssd_net.anchors(net_shape)\r\n\t\trclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\r\n\t\t\tpredictions, localisations, ssd_anchors,\r\n\t\t\tselect_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\r\n\t\t\t    \r\n\t\trbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\r\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\r\n\t\trclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\r\n\t\t\t    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\r\n\t\trbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\r\n\r\n\t\ttemp=tf.stack([height,width,height,width])\r\n\t\trbboxes=rbboxes*temp\r\n\t\tfacePredictions=rbboxes\r\n\t\tsaver = tf.train.Saver()\r\n\r\nimage_test=np.ones((500,500,3))\r\n\r\nwith tf.Session(config=config) as sess:\r\n\tsess.run(tf.global_variables_initializer())\r\n\tsaver.restore(sess, \"/home/wahaha/documents/haha/SSD-Tensorflow-master/log/model.ckpt-50000\")\r\n\tpredictions_val=facePredictions.eval(feed_dict={image_input:image_test})\r\n\toutput_graph_def = tf.graph_until.convert_variables_to_constants(sess, g.as_graph_def, output_node_names=['haha'])\r\n\r\n\twith tf.gfile.FastGFile(hahaFace.pb, mode = 'wb') as f:\r\n\t\tf.write(output_graph_def.SerializeToString())\r\n```"}