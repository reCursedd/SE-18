{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21924", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21924/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21924/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21924/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21924", "id": 354741023, "node_id": "MDU6SXNzdWUzNTQ3NDEwMjM=", "number": 21924, "title": "toco runs into flatbuffer 2GB limit when converting 181MB frozen graph_def", "user": {"login": "reuben", "id": 477142, "node_id": "MDQ6VXNlcjQ3NzE0Mg==", "avatar_url": "https://avatars3.githubusercontent.com/u/477142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reuben", "html_url": "https://github.com/reuben", "followers_url": "https://api.github.com/users/reuben/followers", "following_url": "https://api.github.com/users/reuben/following{/other_user}", "gists_url": "https://api.github.com/users/reuben/gists{/gist_id}", "starred_url": "https://api.github.com/users/reuben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reuben/subscriptions", "organizations_url": "https://api.github.com/users/reuben/orgs", "repos_url": "https://api.github.com/users/reuben/repos", "events_url": "https://api.github.com/users/reuben/events{/privacy}", "received_events_url": "https://api.github.com/users/reuben/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2018-08-28T13:51:05Z", "updated_at": "2018-09-27T14:43:21Z", "closed_at": "2018-09-20T09:37:50Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: KDE Neon</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: master branch, rev <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/57919740bf151cb6395aa60e30404ee9caa066d6/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/57919740bf151cb6395aa60e30404ee9caa066d6\"><tt>5791974</tt></a></li>\n<li><strong>Python version</strong>: 3.6.4</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>: CPU-only build</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Mobile device</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/path/to/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/tmp/graph.tflite</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>When trying to convert my GraphDef file to a TFLite file using TOCO I run into the 2GB limit for flatbuffers. The frozen graph protobuf is 181MB. I've uploaded the frozen graph protobuf as well as an unfrozen pbtxt here: <a href=\"https://github.com/reuben/silly_hacks/releases/tag/github_as_file_hosting_service\">https://github.com/reuben/silly_hacks/releases/tag/github_as_file_hosting_service</a></p>\n<pre><code>$ bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/home/reuben/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/home/reuben/graph.tflite\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\nINFO: Found 1 target...\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\n  bazel-bin/tensorflow/contrib/lite/toco/toco\nINFO: Elapsed time: 0.213s, Critical Path: 0.00s\nINFO: 0 processes.\nINFO: Build completed successfully, 1 total action\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/reuben/output_graph.pb' '--inference_type=FLOAT' '--input_arrays=input_node' '--input_shapes=1,16,494' '--output_INFO: Build completed successfully, 1 total action\n2018-08-28 10:42:03.161524: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 262 operators, 398 arrays (0 quantized)\n2018-08-28 10:42:03.170762: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 262 operators, 398 arrays (0 quantized)\n2018-08-28 10:42:11.384607: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 225 operators, 373 arrays (0 quantized)\n2018-08-28 10:42:11.454370: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 223 operators, 371 arrays (0 quantized)\n2018-08-28 10:42:11.472062: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 221 operators, 367 arrays (0 quantized)\n2018-08-28 10:42:11.487687: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 221 operators, 367 arrays (0 quantized)\n2018-08-28 10:42:11.493166: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 278528 bytes, theoretical optimal value: 262144 bytes.\n2018-08-28 10:42:11.496319: I tensorflow/contrib/lite/toco/toco_tooling.cc:394] Estimated count of arithmetic ops: 1.52158 billion (note that a multiply-add is counted as 2 ops).\ntoco: external/flatbuffers/include/flatbuffers/flatbuffers.h:590: size_t flatbuffers::vector_downward::ensure_space(size_t): Assertion `size() &lt; FLATBUFFERS_MAX_BUFFER_SIZE' failed.\nAborted\n</code></pre>\n<h3>Source code / logs</h3>\n<p>Traceback:</p>\n<pre><code>(gdb) bt\n#0  0x00007ffff46a9428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\n#1  0x00007ffff46ab02a in __GI_abort () at abort.c:89\n#2  0x00007ffff46a1bd7 in __assert_fail_base (fmt=&lt;optimized out&gt;, assertion=assertion@entry=0x73cdf0 \"size() &lt; FLATBUFFERS_MAX_BUFFER_SIZE\", file=file@entry=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\",\n    line=line@entry=590, function=function@entry=0x73d640 &lt;flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__&gt; \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:92\n#3  0x00007ffff46a1c82 in __GI___assert_fail (assertion=0x73cdf0 \"size() &lt; FLATBUFFERS_MAX_BUFFER_SIZE\", file=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\", line=590,\n    function=0x73d640 &lt;flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__&gt; \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:101\n#4  0x00000000005baac8 in flatbuffers::vector_downward::ensure_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:590\n#5  0x00000000005baaf1 in flatbuffers::vector_downward::make_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:595\n#6  0x00000000005bacb9 in flatbuffers::vector_downward::fill (this=0x7fffffffc8e0, zero_pad_bytes=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:647\n#7  0x00000000005bb12e in flatbuffers::FlatBufferBuilder::Align (this=0x7fffffffc8e0, elem_size=4) at external/flatbuffers/include/flatbuffers/flatbuffers.h:840\n#8  0x00000000005bd1ad in flatbuffers::FlatBufferBuilder::PushElement&lt;unsigned int&gt; (this=0x7fffffffc8e0, element=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:861\n#9  0x00000000005bb831 in flatbuffers::FlatBufferBuilder::EndVector (this=0x7fffffffc8e0, len=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:1148\n#10 0x00000000005f6fce in flatbuffers::FlatBufferBuilder::CreateVector&lt;unsigned char&gt; (this=0x7fffffffc8e0,\n    v=0x7fff645ea010 \"\u01a2\\256&lt;\\355\\212#\\274\\v\\261w&lt;_\\\"\\016\\275(\\371\\254\\275\\314I\\274\\274\\206\\032\\300&lt;\\232\\037B=~8\\236\\274\\213\\366\\036&lt;\\020\\254\\251&lt;\\314\\363\\360;2\\262\\360\\274\\345\\252}=\", len=134217728)\n    at external/flatbuffers/include/flatbuffers/flatbuffers.h:1194\n#11 0x00000000006af292 in toco::tflite::(anonymous namespace)::CopyBuffer&lt;(toco::ArrayDataType)2&gt; (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:56\n#12 0x00000000006aec36 in toco::tflite::DataBuffer::Serialize (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:141\n#13 0x00000000005b9a88 in toco::tflite::ExportBuffers (model=..., buffers_to_write=std::vector of length 368, capacity 512 = {...}, builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/export.cc:307\n#14 0x00000000005ba1b2 in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070, ops_by_type=std::map with 80 elements = {...}) at tensorflow/contrib/lite/toco/tflite/export.cc:387\n#15 0x00000000005b9b5c in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/tflite/export.cc:317\n#16 0x000000000052eae2 in toco::Export (toco_flags=..., model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/toco_tooling.cc:407\n#17 0x00000000005135fa in toco::(anonymous namespace)::ToolMain (parsed_toco_flags=..., parsed_model_flags=...) at tensorflow/contrib/lite/toco/toco.cc:90\n#18 0x00000000005138fe in main (argc=1, argv=0x7fffffffd9e8) at tensorflow/contrib/lite/toco/toco.cc:127\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): KDE Neon\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): master branch, rev 5791974\nPython version: 3.6.4\nBazel version (if compiling from source): 0.16.1\nGCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCUDA/cuDNN version: CPU-only build\nGPU model and memory: N/A\nMobile device: N/A\nExact command to reproduce: bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/path/to/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/tmp/graph.tflite\n\nDescribe the problem\nWhen trying to convert my GraphDef file to a TFLite file using TOCO I run into the 2GB limit for flatbuffers. The frozen graph protobuf is 181MB. I've uploaded the frozen graph protobuf as well as an unfrozen pbtxt here: https://github.com/reuben/silly_hacks/releases/tag/github_as_file_hosting_service\n$ bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/home/reuben/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/home/reuben/graph.tflite\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\nINFO: Found 1 target...\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\n  bazel-bin/tensorflow/contrib/lite/toco/toco\nINFO: Elapsed time: 0.213s, Critical Path: 0.00s\nINFO: 0 processes.\nINFO: Build completed successfully, 1 total action\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/reuben/output_graph.pb' '--inference_type=FLOAT' '--input_arrays=input_node' '--input_shapes=1,16,494' '--output_INFO: Build completed successfully, 1 total action\n2018-08-28 10:42:03.161524: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 262 operators, 398 arrays (0 quantized)\n2018-08-28 10:42:03.170762: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 262 operators, 398 arrays (0 quantized)\n2018-08-28 10:42:11.384607: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 225 operators, 373 arrays (0 quantized)\n2018-08-28 10:42:11.454370: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 223 operators, 371 arrays (0 quantized)\n2018-08-28 10:42:11.472062: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 221 operators, 367 arrays (0 quantized)\n2018-08-28 10:42:11.487687: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 221 operators, 367 arrays (0 quantized)\n2018-08-28 10:42:11.493166: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 278528 bytes, theoretical optimal value: 262144 bytes.\n2018-08-28 10:42:11.496319: I tensorflow/contrib/lite/toco/toco_tooling.cc:394] Estimated count of arithmetic ops: 1.52158 billion (note that a multiply-add is counted as 2 ops).\ntoco: external/flatbuffers/include/flatbuffers/flatbuffers.h:590: size_t flatbuffers::vector_downward::ensure_space(size_t): Assertion `size() < FLATBUFFERS_MAX_BUFFER_SIZE' failed.\nAborted\n\nSource code / logs\nTraceback:\n(gdb) bt\n#0  0x00007ffff46a9428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\n#1  0x00007ffff46ab02a in __GI_abort () at abort.c:89\n#2  0x00007ffff46a1bd7 in __assert_fail_base (fmt=<optimized out>, assertion=assertion@entry=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=file@entry=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\",\n    line=line@entry=590, function=function@entry=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:92\n#3  0x00007ffff46a1c82 in __GI___assert_fail (assertion=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\", line=590,\n    function=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:101\n#4  0x00000000005baac8 in flatbuffers::vector_downward::ensure_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:590\n#5  0x00000000005baaf1 in flatbuffers::vector_downward::make_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:595\n#6  0x00000000005bacb9 in flatbuffers::vector_downward::fill (this=0x7fffffffc8e0, zero_pad_bytes=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:647\n#7  0x00000000005bb12e in flatbuffers::FlatBufferBuilder::Align (this=0x7fffffffc8e0, elem_size=4) at external/flatbuffers/include/flatbuffers/flatbuffers.h:840\n#8  0x00000000005bd1ad in flatbuffers::FlatBufferBuilder::PushElement<unsigned int> (this=0x7fffffffc8e0, element=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:861\n#9  0x00000000005bb831 in flatbuffers::FlatBufferBuilder::EndVector (this=0x7fffffffc8e0, len=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:1148\n#10 0x00000000005f6fce in flatbuffers::FlatBufferBuilder::CreateVector<unsigned char> (this=0x7fffffffc8e0,\n    v=0x7fff645ea010 \"\u01a2\\256<\\355\\212#\\274\\v\\261w<_\\\"\\016\\275(\\371\\254\\275\\314I\\274\\274\\206\\032\\300<\\232\\037B=~8\\236\\274\\213\\366\\036<\\020\\254\\251<\\314\\363\\360;2\\262\\360\\274\\345\\252}=\", len=134217728)\n    at external/flatbuffers/include/flatbuffers/flatbuffers.h:1194\n#11 0x00000000006af292 in toco::tflite::(anonymous namespace)::CopyBuffer<(toco::ArrayDataType)2> (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:56\n#12 0x00000000006aec36 in toco::tflite::DataBuffer::Serialize (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:141\n#13 0x00000000005b9a88 in toco::tflite::ExportBuffers (model=..., buffers_to_write=std::vector of length 368, capacity 512 = {...}, builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/export.cc:307\n#14 0x00000000005ba1b2 in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070, ops_by_type=std::map with 80 elements = {...}) at tensorflow/contrib/lite/toco/tflite/export.cc:387\n#15 0x00000000005b9b5c in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/tflite/export.cc:317\n#16 0x000000000052eae2 in toco::Export (toco_flags=..., model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/toco_tooling.cc:407\n#17 0x00000000005135fa in toco::(anonymous namespace)::ToolMain (parsed_toco_flags=..., parsed_model_flags=...) at tensorflow/contrib/lite/toco/toco.cc:90\n#18 0x00000000005138fe in main (argc=1, argv=0x7fffffffd9e8) at tensorflow/contrib/lite/toco/toco.cc:127", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: KDE Neon\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master branch, rev 57919740bf151cb6395aa60e30404ee9caa066d6\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: CPU-only build\r\n- **GPU model and memory**: N/A\r\n- **Mobile device**: N/A\r\n- **Exact command to reproduce**: bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/path/to/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/tmp/graph.tflite\r\n\r\n### Describe the problem\r\n\r\nWhen trying to convert my GraphDef file to a TFLite file using TOCO I run into the 2GB limit for flatbuffers. The frozen graph protobuf is 181MB. I've uploaded the frozen graph protobuf as well as an unfrozen pbtxt here: https://github.com/reuben/silly_hacks/releases/tag/github_as_file_hosting_service\r\n\r\n```\r\n$ bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/home/reuben/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/home/reuben/graph.tflite\r\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 0.213s, Critical Path: 0.00s\r\nINFO: 0 processes.\r\nINFO: Build completed successfully, 1 total action\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/reuben/output_graph.pb' '--inference_type=FLOAT' '--input_arrays=input_node' '--input_shapes=1,16,494' '--output_INFO: Build completed successfully, 1 total action\r\n2018-08-28 10:42:03.161524: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 262 operators, 398 arrays (0 quantized)\r\n2018-08-28 10:42:03.170762: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 262 operators, 398 arrays (0 quantized)\r\n2018-08-28 10:42:11.384607: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 225 operators, 373 arrays (0 quantized)\r\n2018-08-28 10:42:11.454370: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 223 operators, 371 arrays (0 quantized)\r\n2018-08-28 10:42:11.472062: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 221 operators, 367 arrays (0 quantized)\r\n2018-08-28 10:42:11.487687: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 221 operators, 367 arrays (0 quantized)\r\n2018-08-28 10:42:11.493166: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 278528 bytes, theoretical optimal value: 262144 bytes.\r\n2018-08-28 10:42:11.496319: I tensorflow/contrib/lite/toco/toco_tooling.cc:394] Estimated count of arithmetic ops: 1.52158 billion (note that a multiply-add is counted as 2 ops).\r\ntoco: external/flatbuffers/include/flatbuffers/flatbuffers.h:590: size_t flatbuffers::vector_downward::ensure_space(size_t): Assertion `size() < FLATBUFFERS_MAX_BUFFER_SIZE' failed.\r\nAborted\r\n```\r\n\r\n### Source code / logs\r\n\r\nTraceback:\r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007ffff46a9428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007ffff46ab02a in __GI_abort () at abort.c:89\r\n#2  0x00007ffff46a1bd7 in __assert_fail_base (fmt=<optimized out>, assertion=assertion@entry=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=file@entry=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\",\r\n    line=line@entry=590, function=function@entry=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:92\r\n#3  0x00007ffff46a1c82 in __GI___assert_fail (assertion=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\", line=590,\r\n    function=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:101\r\n#4  0x00000000005baac8 in flatbuffers::vector_downward::ensure_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:590\r\n#5  0x00000000005baaf1 in flatbuffers::vector_downward::make_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:595\r\n#6  0x00000000005bacb9 in flatbuffers::vector_downward::fill (this=0x7fffffffc8e0, zero_pad_bytes=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:647\r\n#7  0x00000000005bb12e in flatbuffers::FlatBufferBuilder::Align (this=0x7fffffffc8e0, elem_size=4) at external/flatbuffers/include/flatbuffers/flatbuffers.h:840\r\n#8  0x00000000005bd1ad in flatbuffers::FlatBufferBuilder::PushElement<unsigned int> (this=0x7fffffffc8e0, element=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:861\r\n#9  0x00000000005bb831 in flatbuffers::FlatBufferBuilder::EndVector (this=0x7fffffffc8e0, len=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:1148\r\n#10 0x00000000005f6fce in flatbuffers::FlatBufferBuilder::CreateVector<unsigned char> (this=0x7fffffffc8e0,\r\n    v=0x7fff645ea010 \"\u01a2\\256<\\355\\212#\\274\\v\\261w<_\\\"\\016\\275(\\371\\254\\275\\314I\\274\\274\\206\\032\\300<\\232\\037B=~8\\236\\274\\213\\366\\036<\\020\\254\\251<\\314\\363\\360;2\\262\\360\\274\\345\\252}=\", len=134217728)\r\n    at external/flatbuffers/include/flatbuffers/flatbuffers.h:1194\r\n#11 0x00000000006af292 in toco::tflite::(anonymous namespace)::CopyBuffer<(toco::ArrayDataType)2> (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:56\r\n#12 0x00000000006aec36 in toco::tflite::DataBuffer::Serialize (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:141\r\n#13 0x00000000005b9a88 in toco::tflite::ExportBuffers (model=..., buffers_to_write=std::vector of length 368, capacity 512 = {...}, builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/export.cc:307\r\n#14 0x00000000005ba1b2 in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070, ops_by_type=std::map with 80 elements = {...}) at tensorflow/contrib/lite/toco/tflite/export.cc:387\r\n#15 0x00000000005b9b5c in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/tflite/export.cc:317\r\n#16 0x000000000052eae2 in toco::Export (toco_flags=..., model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/toco_tooling.cc:407\r\n#17 0x00000000005135fa in toco::(anonymous namespace)::ToolMain (parsed_toco_flags=..., parsed_model_flags=...) at tensorflow/contrib/lite/toco/toco.cc:90\r\n#18 0x00000000005138fe in main (argc=1, argv=0x7fffffffd9e8) at tensorflow/contrib/lite/toco/toco.cc:127\r\n```"}