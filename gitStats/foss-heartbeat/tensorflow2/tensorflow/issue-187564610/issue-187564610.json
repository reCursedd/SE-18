{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5430", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5430/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5430/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5430/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5430", "id": 187564610, "node_id": "MDU6SXNzdWUxODc1NjQ2MTA=", "number": 5430, "title": "RNN AutoEncoder", "user": {"login": "Cospel", "id": 615554, "node_id": "MDQ6VXNlcjYxNTU1NA==", "avatar_url": "https://avatars3.githubusercontent.com/u/615554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Cospel", "html_url": "https://github.com/Cospel", "followers_url": "https://api.github.com/users/Cospel/followers", "following_url": "https://api.github.com/users/Cospel/following{/other_user}", "gists_url": "https://api.github.com/users/Cospel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Cospel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Cospel/subscriptions", "organizations_url": "https://api.github.com/users/Cospel/orgs", "repos_url": "https://api.github.com/users/Cospel/repos", "events_url": "https://api.github.com/users/Cospel/events{/privacy}", "received_events_url": "https://api.github.com/users/Cospel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-06T14:28:54Z", "updated_at": "2016-11-14T18:14:10Z", "closed_at": "2016-11-14T18:14:10Z", "author_association": "NONE", "body_html": "<p>Hello, I am writting implementation for RNN autoencoder. The decoder layer is trying to predict next word.</p>\n<p>My code looks like this:</p>\n<pre><code>class RnnAutoencoder():\n   def __init__(...):\n   ...\n   # Encoder\n   self.z_codes, self.enc_state = tf.nn.dynamic_rnn(self._enc_cell, inputs, dtype=tf.float32)\n\n   # Intermediate layer after encoder\n   last_output = self.z_codes[-1]\n   self.pred_m = tf.nn.relu(tf.matmul(last_output, self.weight_m) + self.bias_m)\n\n   # Decoder\n   dec_input = self.pred_m\n   dec_state = self.enc_state\n\n   dec_outputs = []\n   for step in range(len(inputs)):\n      if step&gt;0: vs.reuse_variables()\n      dec_input_, dec_state = self._dec_cell(dec_input_, dec_state)\n      dec_input_ = tf.matmul(dec_input_, dec_weight_) + dec_bias_\n      dec_outputs.append(dec_input_)\n\n\ninputs = tf.placeholder(tf.float32, [1, None, 300])\n\n</code></pre>\n<p>But I get error:<br>\nTypeError: object of type 'Tensor' has no len()<br>\non line:     for step in range(len(inputs)):</p>\n<p>I know that i cannot apply len on Tensor in tensorflow but how can I iterate(for variable time steps) and do it the way that <strong>next input of decoder is output from previous step</strong>(of the same decoder). Basic tf.nn.dynamic_rnn doesn't work with this situation.</p>\n<p>I read many implementations of lstm, rnn, auencoders on github but it is always with fixed size sequences or the implementation of decoder which doesn't get input which is output from previous step. I read seq2seq tutorial but it doesn't use the intermediate layer for encoding sequences as I need in my model and also i am not sure if it can handle dynamic size of sequences.</p>", "body_text": "Hello, I am writting implementation for RNN autoencoder. The decoder layer is trying to predict next word.\nMy code looks like this:\nclass RnnAutoencoder():\n   def __init__(...):\n   ...\n   # Encoder\n   self.z_codes, self.enc_state = tf.nn.dynamic_rnn(self._enc_cell, inputs, dtype=tf.float32)\n\n   # Intermediate layer after encoder\n   last_output = self.z_codes[-1]\n   self.pred_m = tf.nn.relu(tf.matmul(last_output, self.weight_m) + self.bias_m)\n\n   # Decoder\n   dec_input = self.pred_m\n   dec_state = self.enc_state\n\n   dec_outputs = []\n   for step in range(len(inputs)):\n      if step>0: vs.reuse_variables()\n      dec_input_, dec_state = self._dec_cell(dec_input_, dec_state)\n      dec_input_ = tf.matmul(dec_input_, dec_weight_) + dec_bias_\n      dec_outputs.append(dec_input_)\n\n\ninputs = tf.placeholder(tf.float32, [1, None, 300])\n\n\nBut I get error:\nTypeError: object of type 'Tensor' has no len()\non line:     for step in range(len(inputs)):\nI know that i cannot apply len on Tensor in tensorflow but how can I iterate(for variable time steps) and do it the way that next input of decoder is output from previous step(of the same decoder). Basic tf.nn.dynamic_rnn doesn't work with this situation.\nI read many implementations of lstm, rnn, auencoders on github but it is always with fixed size sequences or the implementation of decoder which doesn't get input which is output from previous step. I read seq2seq tutorial but it doesn't use the intermediate layer for encoding sequences as I need in my model and also i am not sure if it can handle dynamic size of sequences.", "body": "Hello, I am writting implementation for RNN autoencoder. The decoder layer is trying to predict next word.\r\n\r\nMy code looks like this:\r\n```\r\nclass RnnAutoencoder():\r\n   def __init__(...):\r\n   ...\r\n   # Encoder\r\n   self.z_codes, self.enc_state = tf.nn.dynamic_rnn(self._enc_cell, inputs, dtype=tf.float32)\r\n\r\n   # Intermediate layer after encoder\r\n   last_output = self.z_codes[-1]\r\n   self.pred_m = tf.nn.relu(tf.matmul(last_output, self.weight_m) + self.bias_m)\r\n\r\n   # Decoder\r\n   dec_input = self.pred_m\r\n   dec_state = self.enc_state\r\n\r\n   dec_outputs = []\r\n   for step in range(len(inputs)):\r\n      if step>0: vs.reuse_variables()\r\n      dec_input_, dec_state = self._dec_cell(dec_input_, dec_state)\r\n      dec_input_ = tf.matmul(dec_input_, dec_weight_) + dec_bias_\r\n      dec_outputs.append(dec_input_)\r\n\r\n\r\ninputs = tf.placeholder(tf.float32, [1, None, 300])\r\n\r\n```\r\n\r\nBut I get error:\r\nTypeError: object of type 'Tensor' has no len()\r\non line:     for step in range(len(inputs)):\r\n\r\nI know that i cannot apply len on Tensor in tensorflow but how can I iterate(for variable time steps) and do it the way that **next input of decoder is output from previous step**(of the same decoder). Basic tf.nn.dynamic_rnn doesn't work with this situation.\r\n\r\nI read many implementations of lstm, rnn, auencoders on github but it is always with fixed size sequences or the implementation of decoder which doesn't get input which is output from previous step. I read seq2seq tutorial but it doesn't use the intermediate layer for encoding sequences as I need in my model and also i am not sure if it can handle dynamic size of sequences.\r\n\r\n"}