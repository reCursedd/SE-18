{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5338", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5338/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5338/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5338/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5338", "id": 186639564, "node_id": "MDU6SXNzdWUxODY2Mzk1NjQ=", "number": 5338, "title": "Failed to run MNIST example on Android", "user": {"login": "guojia-git", "id": 12204730, "node_id": "MDQ6VXNlcjEyMjA0NzMw", "avatar_url": "https://avatars1.githubusercontent.com/u/12204730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guojia-git", "html_url": "https://github.com/guojia-git", "followers_url": "https://api.github.com/users/guojia-git/followers", "following_url": "https://api.github.com/users/guojia-git/following{/other_user}", "gists_url": "https://api.github.com/users/guojia-git/gists{/gist_id}", "starred_url": "https://api.github.com/users/guojia-git/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guojia-git/subscriptions", "organizations_url": "https://api.github.com/users/guojia-git/orgs", "repos_url": "https://api.github.com/users/guojia-git/repos", "events_url": "https://api.github.com/users/guojia-git/events{/privacy}", "received_events_url": "https://api.github.com/users/guojia-git/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-11-01T20:35:47Z", "updated_at": "2016-11-04T07:00:18Z", "closed_at": "2016-11-04T06:46:44Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"179739119\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4623\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4623/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4623\">#4623</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"177747834\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4451\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4451/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4451\">#4451</a></p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04<br>\nIf installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>): <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/3d35376a66cde4f3e614c746d3c8708d15caa1b5/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/3d35376a66cde4f3e614c746d3c8708d15caa1b5\"><tt>3d35376</tt></a></li>\n<li>The output of <code>bazel version</code>: Build label: 0.3.2</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<ul>\n<li>Train using <a href=\"https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\" rel=\"nofollow\">MNIST tutorial</a></li>\n<li><code>tf.train.write_graph(..., mnist_graph.txt, as_text=True)</code></li>\n<li>freeze graph <code>bazel-bin/.../freeze_graph --input_graph=.../mnist_graph.txt --input_checkpoint=.../mnist_model.ckpt --output_graph=.../mnist_graph_frozen.pb --output_node_names=\"output_node\"</code></li>\n<li>strip graph <code>bazel-bin/..bazel-bin/.../strip_unused --input_graph=.../mnist_graph_frozen.pb --output_graph=.../mnist_graph_frozen_stripped.pb --input_node_names=\"input_node\" --output_node_names=\"output_node\" --input_binary=true</code></li>\n<li>Java code: basically I took part of TensorFlowImageListener and part of TensorFlowImageClassifier\n<ul>\n<li>Remove the image preprocessing part, instead pass in the raw mnist datapoint of shape [784] as floatValues</li>\n<li><code>inferenceInterface.fillNodeFloat(\u201dinput_node\", 1, 28, 28, 1, floatValues); //When training I was reshaping the datapoint to 28x28. </code></li>\n<li><code>inferenceInterface.runInference(new String[] {\"output_node\"})</code></li>\n<li><code>inferenceInterface.readNodeFloat(\"output_node\", outputs\")</code></li>\n</ul>\n</li>\n</ul>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).<br>\n10-23 19:16:51.918: I/native(10721): tensorflow_inference_jni.cc:126 Creating session.<br>\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:137 Tensorflow graph loaded from: file:///android_asset/mnist_graph_frozen_stripped.pb<br>\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:140 Initialization done in 137.556ms<br>\n10-23 19:16:51.967: I/MainActivity(10721): Tensorflow model initialized<br>\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e<br>\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e<br>\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:197 End computing. Ran in 205ms (205ms avg over 1 runs)<br>\n<strong>10-23 19:16:52.194: E/native(10721): tensorflow_inference_jni.cc:202 Error during inference: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float<br>\n10-23 19:16:52.194: E/native(10721): \t [[Node: Placeholder = Placeholder [dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]</strong><br>\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e<br>\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e<br>\n<strong>10-23 19:16:52.195: E/native(10721): tensorflow_inference_jni.cc:159 Output [output_node] not found, aborting!</strong></p>\n<p><strong>Thanks for reading this. Please let me know if there's any other information I need to provide.</strong></p>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n#4623\n#4451\nEnvironment info\nOperating System: Ubuntu 14.04\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD): 3d35376\nThe output of bazel version: Build label: 0.3.2\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nTrain using MNIST tutorial\ntf.train.write_graph(..., mnist_graph.txt, as_text=True)\nfreeze graph bazel-bin/.../freeze_graph --input_graph=.../mnist_graph.txt --input_checkpoint=.../mnist_model.ckpt --output_graph=.../mnist_graph_frozen.pb --output_node_names=\"output_node\"\nstrip graph bazel-bin/..bazel-bin/.../strip_unused --input_graph=.../mnist_graph_frozen.pb --output_graph=.../mnist_graph_frozen_stripped.pb --input_node_names=\"input_node\" --output_node_names=\"output_node\" --input_binary=true\nJava code: basically I took part of TensorFlowImageListener and part of TensorFlowImageClassifier\n\nRemove the image preprocessing part, instead pass in the raw mnist datapoint of shape [784] as floatValues\ninferenceInterface.fillNodeFloat(\u201dinput_node\", 1, 28, 28, 1, floatValues); //When training I was reshaping the datapoint to 28x28. \ninferenceInterface.runInference(new String[] {\"output_node\"})\ninferenceInterface.readNodeFloat(\"output_node\", outputs\")\n\n\n\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\n10-23 19:16:51.918: I/native(10721): tensorflow_inference_jni.cc:126 Creating session.\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:137 Tensorflow graph loaded from: file:///android_asset/mnist_graph_frozen_stripped.pb\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:140 Initialization done in 137.556ms\n10-23 19:16:51.967: I/MainActivity(10721): Tensorflow model initialized\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:197 End computing. Ran in 205ms (205ms avg over 1 runs)\n10-23 19:16:52.194: E/native(10721): tensorflow_inference_jni.cc:202 Error during inference: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n10-23 19:16:52.194: E/native(10721): \t [[Node: Placeholder = Placeholder [dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\n10-23 19:16:52.195: E/native(10721): tensorflow_inference_jni.cc:159 Output [output_node] not found, aborting!\nThanks for reading this. Please let me know if there's any other information I need to provide.", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n#4623\r\n#4451\r\n\r\n### Environment info\r\nOperating System: Ubuntu 14.04\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`): 3d35376a66cde4f3e614c746d3c8708d15caa1b5\r\n2. The output of `bazel version`: Build label: 0.3.2\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n- Train using [MNIST tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html)\r\n- `tf.train.write_graph(..., mnist_graph.txt, as_text=True)`\r\n- freeze graph `bazel-bin/.../freeze_graph --input_graph=.../mnist_graph.txt --input_checkpoint=.../mnist_model.ckpt --output_graph=.../mnist_graph_frozen.pb --output_node_names=\"output_node\"`\r\n- strip graph `bazel-bin/..bazel-bin/.../strip_unused --input_graph=.../mnist_graph_frozen.pb --output_graph=.../mnist_graph_frozen_stripped.pb --input_node_names=\"input_node\" --output_node_names=\"output_node\" --input_binary=true`\r\n- Java code: basically I took part of TensorFlowImageListener and part of TensorFlowImageClassifier\r\n  - Remove the image preprocessing part, instead pass in the raw mnist datapoint of shape [784] as floatValues\r\n  - `inferenceInterface.fillNodeFloat(\u201dinput_node\", 1, 28, 28, 1, floatValues); //When training I was reshaping the datapoint to 28x28. `\r\n  - `inferenceInterface.runInference(new String[] {\"output_node\"})`\r\n  - `inferenceInterface.readNodeFloat(\"output_node\", outputs\")`\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n10-23 19:16:51.918: I/native(10721): tensorflow_inference_jni.cc:126 Creating session.\r\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:137 Tensorflow graph loaded from: file:///android_asset/mnist_graph_frozen_stripped.pb\r\n10-23 19:16:51.967: I/native(10721): tensorflow_inference_jni.cc:140 Initialization done in 137.556ms\r\n10-23 19:16:51.967: I/MainActivity(10721): Tensorflow model initialized\r\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\r\n10-23 19:16:51.988: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\r\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:197 End computing. Ran in 205ms (205ms avg over 1 runs)\r\n**10-23 19:16:52.194: E/native(10721): tensorflow_inference_jni.cc:202 Error during inference: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float\r\n10-23 19:16:52.194: E/native(10721): \t \\[\\[Node: Placeholder = Placeholder \\[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]**\r\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\r\n10-23 19:16:52.194: I/native(10721): tensorflow_inference_jni.cc:87 Found session variables for 6f51f9109840554e\r\n**10-23 19:16:52.195: E/native(10721): tensorflow_inference_jni.cc:159 Output [output_node] not found, aborting!**\r\n\r\n**Thanks for reading this. Please let me know if there's any other information I need to provide.** "}