{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320469889", "html_url": "https://github.com/tensorflow/tensorflow/issues/12054#issuecomment-320469889", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12054", "id": 320469889, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDQ2OTg4OQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-05T20:54:28Z", "updated_at": "2017-08-05T21:00:01Z", "author_association": "CONTRIBUTOR", "body_html": "<p>From implementation standpoint, behavior like this could be implemented by having enqueue kernel return bad status, so that entire session.run call terminates immediately with exception.</p>\n<p>However I wonder if this functionality could be implemented at the client level. IE, a client can check how much capacity is left in the queue, and if it's too small, skip the enqueue call altogether. You can issue enqueue calls in their own Python thread so that these calls are asynchronous. You can include timestamps in your batches and drop batches which are too old. You can use timeout feature to drop any enqueue call that blocks for more than x milliseconds</p>", "body_text": "From implementation standpoint, behavior like this could be implemented by having enqueue kernel return bad status, so that entire session.run call terminates immediately with exception.\nHowever I wonder if this functionality could be implemented at the client level. IE, a client can check how much capacity is left in the queue, and if it's too small, skip the enqueue call altogether. You can issue enqueue calls in their own Python thread so that these calls are asynchronous. You can include timestamps in your batches and drop batches which are too old. You can use timeout feature to drop any enqueue call that blocks for more than x milliseconds", "body": "From implementation standpoint, behavior like this could be implemented by having enqueue kernel return bad status, so that entire session.run call terminates immediately with exception.\r\n\r\nHowever I wonder if this functionality could be implemented at the client level. IE, a client can check how much capacity is left in the queue, and if it's too small, skip the enqueue call altogether. You can issue enqueue calls in their own Python thread so that these calls are asynchronous. You can include timestamps in your batches and drop batches which are too old. You can use timeout feature to drop any enqueue call that blocks for more than x milliseconds"}