{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7111", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7111/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7111/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7111/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7111", "id": 203634966, "node_id": "MDU6SXNzdWUyMDM2MzQ5NjY=", "number": 7111, "title": "Inference results depend on order of images in training batch", "user": {"login": "olyaromanyuk", "id": 15520877, "node_id": "MDQ6VXNlcjE1NTIwODc3", "avatar_url": "https://avatars0.githubusercontent.com/u/15520877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/olyaromanyuk", "html_url": "https://github.com/olyaromanyuk", "followers_url": "https://api.github.com/users/olyaromanyuk/followers", "following_url": "https://api.github.com/users/olyaromanyuk/following{/other_user}", "gists_url": "https://api.github.com/users/olyaromanyuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/olyaromanyuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/olyaromanyuk/subscriptions", "organizations_url": "https://api.github.com/users/olyaromanyuk/orgs", "repos_url": "https://api.github.com/users/olyaromanyuk/repos", "events_url": "https://api.github.com/users/olyaromanyuk/events{/privacy}", "received_events_url": "https://api.github.com/users/olyaromanyuk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-01-27T13:26:23Z", "updated_at": "2017-01-27T17:34:11Z", "closed_at": "2017-01-27T17:34:11Z", "author_association": "NONE", "body_html": "<p>I've trained the same network two times on the same dataset of 5 images. For the first time, the images in a batch for each step were in the same order. For the second time, the batch was shuffled before every training step. Both models overfit. Both models were tested on shuffled images from training dataset.<br>\nThe firs model shows 100% accuracy.</p>\n<pre><code>Prediction  Labels\n[6 1 4 3 7] [6 1 4 3 7]\n[3 4 1 7 6] [3 4 1 7 6]\n[6 1 4 3 7] [6 1 4 3 7]\n[4 3 7 6 1] [4 3 7 6 1]\n[4 7 6 3 1] [4 7 6 3 1]\n[1 3 7 6 4] [1 3 7 6 4]\n[3 1 6 7 4] [3 1 6 7 4]\n</code></pre>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/735277/logs_not_shuffled.txt\">logs_not_shuffled.txt</a></p>\n<p>The second model shows accuracy close to a random guess.</p>\n<pre><code>Prediction  Labels\n[1 4 3 6 7] [7 4 6 3 1]\n[3 6 4 1 7] [7 4 3 1 6]\n[1 6 3 7 4] [1 6 4 3 7]\n[4 7 3 6 1] [1 6 4 3 7]\n[3 6 7 4 1] [4 1 3 7 6]\n[1 3 7 4 6] [6 3 4 7 1]\n[1 4 7 3 6] [3 7 1 4 6]\n</code></pre>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/735278/logs_shuffled.txt\">logs_shuffled.txt</a></p>\n<p>Related issues - none</p>\n<h3>Environment:</h3>\n<ul>\n<li>Ubuntu 14.04 64-bit</li>\n<li>CUDA 8.0</li>\n<li>cuDNN 5.1</li>\n</ul>\n<pre><code> -rw-r--r-- 1 root root   558720 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n</code></pre>\n<ul>\n<li>tensorflow 0.12.1 from pip with GPU support</li>\n</ul>\n<h3>Dataset</h3>\n<p>5 images from MNIST</p>\n<h3>The attached archive</h3>\n<p>contains code for reproducible example.</p>\n<ul>\n<li>runner.py is responsible for preparing image batches and maintains the queue.</li>\n<li>network.py contains the code of simple neural network(2 convolutional layers with relu activation, softmax output layer)</li>\n<li>train_not_shuffled.py trains and tests the network using non-shuffled batch</li>\n<li>train_shuffled.py trains and tests the network using shuffled batch</li>\n</ul>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/735318/example.gz\">example.gz</a></p>\n<p>I've retrained the models several times, tried different datasets and network architectures. I've visualized graph to make sure inference uses the same variables. I've also visualized weights, they look slightly different for two cases but don't contain any anomalies that could explain such behavior.<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/15520877/22371708/41d07d16-e4a1-11e6-955d-d08839441e42.png\"><img src=\"https://cloud.githubusercontent.com/assets/15520877/22371708/41d07d16-e4a1-11e6-955d-d08839441e42.png\" alt=\"graph\" style=\"max-width:100%;\"></a></p>", "body_text": "I've trained the same network two times on the same dataset of 5 images. For the first time, the images in a batch for each step were in the same order. For the second time, the batch was shuffled before every training step. Both models overfit. Both models were tested on shuffled images from training dataset.\nThe firs model shows 100% accuracy.\nPrediction  Labels\n[6 1 4 3 7] [6 1 4 3 7]\n[3 4 1 7 6] [3 4 1 7 6]\n[6 1 4 3 7] [6 1 4 3 7]\n[4 3 7 6 1] [4 3 7 6 1]\n[4 7 6 3 1] [4 7 6 3 1]\n[1 3 7 6 4] [1 3 7 6 4]\n[3 1 6 7 4] [3 1 6 7 4]\n\nlogs_not_shuffled.txt\nThe second model shows accuracy close to a random guess.\nPrediction  Labels\n[1 4 3 6 7] [7 4 6 3 1]\n[3 6 4 1 7] [7 4 3 1 6]\n[1 6 3 7 4] [1 6 4 3 7]\n[4 7 3 6 1] [1 6 4 3 7]\n[3 6 7 4 1] [4 1 3 7 6]\n[1 3 7 4 6] [6 3 4 7 1]\n[1 4 7 3 6] [3 7 1 4 6]\n\nlogs_shuffled.txt\nRelated issues - none\nEnvironment:\n\nUbuntu 14.04 64-bit\nCUDA 8.0\ncuDNN 5.1\n\n -rw-r--r-- 1 root root   558720 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n\n\ntensorflow 0.12.1 from pip with GPU support\n\nDataset\n5 images from MNIST\nThe attached archive\ncontains code for reproducible example.\n\nrunner.py is responsible for preparing image batches and maintains the queue.\nnetwork.py contains the code of simple neural network(2 convolutional layers with relu activation, softmax output layer)\ntrain_not_shuffled.py trains and tests the network using non-shuffled batch\ntrain_shuffled.py trains and tests the network using shuffled batch\n\nexample.gz\nI've retrained the models several times, tried different datasets and network architectures. I've visualized graph to make sure inference uses the same variables. I've also visualized weights, they look slightly different for two cases but don't contain any anomalies that could explain such behavior.", "body": "I've trained the same network two times on the same dataset of 5 images. For the first time, the images in a batch for each step were in the same order. For the second time, the batch was shuffled before every training step. Both models overfit. Both models were tested on shuffled images from training dataset.\r\nThe firs model shows 100% accuracy.\r\n```\r\nPrediction  Labels\r\n[6 1 4 3 7] [6 1 4 3 7]\r\n[3 4 1 7 6] [3 4 1 7 6]\r\n[6 1 4 3 7] [6 1 4 3 7]\r\n[4 3 7 6 1] [4 3 7 6 1]\r\n[4 7 6 3 1] [4 7 6 3 1]\r\n[1 3 7 6 4] [1 3 7 6 4]\r\n[3 1 6 7 4] [3 1 6 7 4]\r\n```\r\n[logs_not_shuffled.txt](https://github.com/tensorflow/tensorflow/files/735277/logs_not_shuffled.txt)\r\n \r\nThe second model shows accuracy close to a random guess.\r\n```\r\nPrediction  Labels\r\n[1 4 3 6 7] [7 4 6 3 1]\r\n[3 6 4 1 7] [7 4 3 1 6]\r\n[1 6 3 7 4] [1 6 4 3 7]\r\n[4 7 3 6 1] [1 6 4 3 7]\r\n[3 6 7 4 1] [4 1 3 7 6]\r\n[1 3 7 4 6] [6 3 4 7 1]\r\n[1 4 7 3 6] [3 7 1 4 6]\r\n```\r\n [logs_shuffled.txt](https://github.com/tensorflow/tensorflow/files/735278/logs_shuffled.txt)\r\n\r\n \r\nRelated issues - none\r\n\r\n### Environment:\r\n\r\n- Ubuntu 14.04 64-bit\r\n- CUDA 8.0\r\n- cuDNN 5.1\r\n\r\n```\r\n -rw-r--r-- 1 root root   558720 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Jan 11 17:43 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Jan 11 18:10 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n- tensorflow 0.12.1 from pip with GPU support\r\n\r\n### Dataset \r\n5 images from MNIST\r\n\r\n### The attached archive \r\ncontains code for reproducible example. \r\n- runner.py is responsible for preparing image batches and maintains the queue.\r\n- network.py contains the code of simple neural network(2 convolutional layers with relu activation, softmax output layer)\r\n- train_not_shuffled.py trains and tests the network using non-shuffled batch\r\n- train_shuffled.py trains and tests the network using shuffled batch\r\n\r\n[example.gz](https://github.com/tensorflow/tensorflow/files/735318/example.gz)\r\n\r\nI've retrained the models several times, tried different datasets and network architectures. I've visualized graph to make sure inference uses the same variables. I've also visualized weights, they look slightly different for two cases but don't contain any anomalies that could explain such behavior.\r\n![graph](https://cloud.githubusercontent.com/assets/15520877/22371708/41d07d16-e4a1-11e6-955d-d08839441e42.png)"}