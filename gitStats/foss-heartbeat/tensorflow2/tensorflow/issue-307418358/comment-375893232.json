{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/375893232", "html_url": "https://github.com/tensorflow/tensorflow/issues/17905#issuecomment-375893232", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17905", "id": 375893232, "node_id": "MDEyOklzc3VlQ29tbWVudDM3NTg5MzIzMg==", "user": {"login": "androidbeepboop", "id": 37384864, "node_id": "MDQ6VXNlcjM3Mzg0ODY0", "avatar_url": "https://avatars0.githubusercontent.com/u/37384864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/androidbeepboop", "html_url": "https://github.com/androidbeepboop", "followers_url": "https://api.github.com/users/androidbeepboop/followers", "following_url": "https://api.github.com/users/androidbeepboop/following{/other_user}", "gists_url": "https://api.github.com/users/androidbeepboop/gists{/gist_id}", "starred_url": "https://api.github.com/users/androidbeepboop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/androidbeepboop/subscriptions", "organizations_url": "https://api.github.com/users/androidbeepboop/orgs", "repos_url": "https://api.github.com/users/androidbeepboop/repos", "events_url": "https://api.github.com/users/androidbeepboop/events{/privacy}", "received_events_url": "https://api.github.com/users/androidbeepboop/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-24T14:26:50Z", "updated_at": "2018-03-24T14:26:50Z", "author_association": "NONE", "body_html": "<p>Hi @vrv- thanks for your reply, and good point re. it maybe not being a memory issue. I will investigate Keras graph/session resets and report back, though I will note that this issue was occurring prior to using Keras in this script. If it is helpful, here is a snippet of the error report (goes on for pages):</p>\n<p>f_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859800 of size 1280<br>\n2018-03-24 05:25:21.775992: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859D00 of size 1280<br>\n2018-03-24 05:25:21.776691: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F285A200 of size 159488<br>\n2018-03-24 05:25:21.777238: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881100 of size 1280<br>\n2018-03-24 05:25:21.777484: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881600 of size 1280<br>\n2018-03-24 05:25:21.777704: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881B00 of size 95744<br>\n2018-03-24 05:25:21.777897: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2899100 of size 95744<br>\n.<br>\n.<br>\n.<br>\nLimit:                 13618452890<br>\nInUse:                 13618441472<br>\nMaxInUse:              13618452736<br>\nNumAllocs:                48687782<br>\nMaxAllocSize:           3805937664</p>\n<p>2018-03-24 05:25:22.292220: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ****************************************************************************************************<br>\n2018-03-24 05:25:22.292545: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[5,7,72,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc<br>\n2018-03-24 05:25:32.294665: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 34.00MiB.  Current allocation summary follows.<br>\n2018-03-24 05:25:32.295801: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (256): \tTotal Chunks: 1118, Chunks in use: 1118. 279.5KiB allocated for chunks. 279.5KiB in use in bin. 32.0KiB client-requested in use in bin.<br>\n2018-03-24 05:25:32.297028: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (512): \tTotal Chunks: 746, Chunks in use: 746. 466.3KiB allocated for chunks. 466.3KiB in use in bin. 303.1KiB client-requested in use in bin.<br>\n.<br>\n.<br>\n.<br>\nTraceback (most recent call last):<br>\nFile \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1040, in <br>\nsess.run(init_op)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run<br>\nrun_metadata_ptr)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run<br>\noptions, run_metadata)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc<br>\n[[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]<br>\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>\n<p>Caused by op 'Variable_910/Adam/Assign', defined at:<br>\nFile \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1017, in <br>\ntrain_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 365, in minimize<br>\nname=name)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 516, in apply_gradients<br>\nself._create_slots([_get_variable_for(v) for v in var_list])<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\adam.py\", line 139, in _create_slots<br>\nself._zeros_slot(v, \"m\", self._name)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 883, in _zeros_slot<br>\nnamed_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 174, in create_zeros_slot<br>\ncolocate_with_primary=colocate_with_primary)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 148, in create_slot_with_initializer<br>\ndtype)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 67, in _create_slot_var<br>\nvalidate_shape=validate_shape)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1262, in get_variable<br>\nconstraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1097, in get_variable<br>\nconstraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 435, in get_variable<br>\nconstraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 404, in _true_getter<br>\nuse_resource=use_resource, constraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 806, in _get_single_variable<br>\nconstraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in <strong>init</strong><br>\nconstraint=constraint)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 366, in _init_from_args<br>\nvalidate_shape=validate_shape).op<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 276, in assign<br>\nvalidate_shape=validate_shape)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 62, in assign<br>\nuse_locking=use_locking, name=name)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op<br>\nop_def=op_def)<br>\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc<br>\n[[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]<br>\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>", "body_text": "Hi @vrv- thanks for your reply, and good point re. it maybe not being a memory issue. I will investigate Keras graph/session resets and report back, though I will note that this issue was occurring prior to using Keras in this script. If it is helpful, here is a snippet of the error report (goes on for pages):\nf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859800 of size 1280\n2018-03-24 05:25:21.775992: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859D00 of size 1280\n2018-03-24 05:25:21.776691: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F285A200 of size 159488\n2018-03-24 05:25:21.777238: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881100 of size 1280\n2018-03-24 05:25:21.777484: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881600 of size 1280\n2018-03-24 05:25:21.777704: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881B00 of size 95744\n2018-03-24 05:25:21.777897: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2899100 of size 95744\n.\n.\n.\nLimit:                 13618452890\nInUse:                 13618441472\nMaxInUse:              13618452736\nNumAllocs:                48687782\nMaxAllocSize:           3805937664\n2018-03-24 05:25:22.292220: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ****************************************************************************************************\n2018-03-24 05:25:22.292545: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[5,7,72,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n2018-03-24 05:25:32.294665: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 34.00MiB.  Current allocation summary follows.\n2018-03-24 05:25:32.295801: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (256): \tTotal Chunks: 1118, Chunks in use: 1118. 279.5KiB allocated for chunks. 279.5KiB in use in bin. 32.0KiB client-requested in use in bin.\n2018-03-24 05:25:32.297028: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (512): \tTotal Chunks: 746, Chunks in use: 746. 466.3KiB allocated for chunks. 466.3KiB in use in bin. 303.1KiB client-requested in use in bin.\n.\n.\n.\nTraceback (most recent call last):\nFile \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1040, in \nsess.run(init_op)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\nrun_metadata_ptr)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\noptions, run_metadata)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n[[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\nCaused by op 'Variable_910/Adam/Assign', defined at:\nFile \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1017, in \ntrain_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 365, in minimize\nname=name)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 516, in apply_gradients\nself._create_slots([_get_variable_for(v) for v in var_list])\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\adam.py\", line 139, in _create_slots\nself._zeros_slot(v, \"m\", self._name)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 883, in _zeros_slot\nnamed_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 174, in create_zeros_slot\ncolocate_with_primary=colocate_with_primary)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 148, in create_slot_with_initializer\ndtype)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 67, in _create_slot_var\nvalidate_shape=validate_shape)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1262, in get_variable\nconstraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1097, in get_variable\nconstraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 435, in get_variable\nconstraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 404, in _true_getter\nuse_resource=use_resource, constraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 806, in _get_single_variable\nconstraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in init\nconstraint=constraint)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 366, in _init_from_args\nvalidate_shape=validate_shape).op\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 276, in assign\nvalidate_shape=validate_shape)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 62, in assign\nuse_locking=use_locking, name=name)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\nop_def=op_def)\nFile \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n[[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.", "body": "Hi @vrv- thanks for your reply, and good point re. it maybe not being a memory issue. I will investigate Keras graph/session resets and report back, though I will note that this issue was occurring prior to using Keras in this script. If it is helpful, here is a snippet of the error report (goes on for pages):\r\n\r\nf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859800 of size 1280\r\n2018-03-24 05:25:21.775992: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2859D00 of size 1280\r\n2018-03-24 05:25:21.776691: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F285A200 of size 159488\r\n2018-03-24 05:25:21.777238: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881100 of size 1280\r\n2018-03-24 05:25:21.777484: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881600 of size 1280\r\n2018-03-24 05:25:21.777704: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2881B00 of size 95744\r\n2018-03-24 05:25:21.777897: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:662] Chunk at 00000015F2899100 of size 95744\r\n.\r\n.\r\n.\r\nLimit:                 13618452890\r\nInUse:                 13618441472\r\nMaxInUse:              13618452736\r\nNumAllocs:                48687782\r\nMaxAllocSize:           3805937664\r\n\r\n2018-03-24 05:25:22.292220: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:277] ****************************************************************************************************\r\n2018-03-24 05:25:22.292545: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\framework\\op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[5,7,72,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n2018-03-24 05:25:32.294665: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 34.00MiB.  Current allocation summary follows.\r\n2018-03-24 05:25:32.295801: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (256): \tTotal Chunks: 1118, Chunks in use: 1118. 279.5KiB allocated for chunks. 279.5KiB in use in bin. 32.0KiB client-requested in use in bin.\r\n2018-03-24 05:25:32.297028: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:628] Bin (512): \tTotal Chunks: 746, Chunks in use: 746. 466.3KiB allocated for chunks. 466.3KiB in use in bin. 303.1KiB client-requested in use in bin.\r\n.\r\n.\r\n.\r\nTraceback (most recent call last):\r\n  File \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1040, in <module>\r\n    sess.run(init_op)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'Variable_910/Adam/Assign', defined at:\r\n  File \"C:/Users/ashort7/PycharmProjects/CNN/venv1/SSVEP_TimeDomain_DeepCNN/layer_num_evo.py\", line 1017, in <module>\r\n    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 365, in minimize\r\n    name=name)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 516, in apply_gradients\r\n    self._create_slots([_get_variable_for(v) for v in var_list])\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\adam.py\", line 139, in _create_slots\r\n    self._zeros_slot(v, \"m\", self._name)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 883, in _zeros_slot\r\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 174, in create_zeros_slot\r\n    colocate_with_primary=colocate_with_primary)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 148, in create_slot_with_initializer\r\n    dtype)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 67, in _create_slot_var\r\n    validate_shape=validate_shape)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1262, in get_variable\r\n    constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1097, in get_variable\r\n    constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 435, in get_variable\r\n    constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 404, in _true_getter\r\n    use_resource=use_resource, constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 806, in _get_single_variable\r\n    constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\r\n    constraint=constraint)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 366, in _init_from_args\r\n    validate_shape=validate_shape).op\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 276, in assign\r\n    validate_shape=validate_shape)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 62, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\ashort7\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,7,1,72] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: Variable_910/Adam/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_910\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Variable_910/Adam, Variable_910/Adam/Initializer/zeros)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n"}