{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15851", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15851/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15851/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15851/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15851", "id": 286018324, "node_id": "MDU6SXNzdWUyODYwMTgzMjQ=", "number": 15851, "title": "Tensorflow: Non-deterministic behaviour with large model using while_loop", "user": {"login": "nikita68", "id": 15629332, "node_id": "MDQ6VXNlcjE1NjI5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/15629332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikita68", "html_url": "https://github.com/nikita68", "followers_url": "https://api.github.com/users/nikita68/followers", "following_url": "https://api.github.com/users/nikita68/following{/other_user}", "gists_url": "https://api.github.com/users/nikita68/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikita68/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikita68/subscriptions", "organizations_url": "https://api.github.com/users/nikita68/orgs", "repos_url": "https://api.github.com/users/nikita68/repos", "events_url": "https://api.github.com/users/nikita68/events{/privacy}", "received_events_url": "https://api.github.com/users/nikita68/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-04T15:20:55Z", "updated_at": "2018-01-09T19:53:38Z", "closed_at": "2018-01-09T19:53:38Z", "author_association": "NONE", "body_html": "<p>Hello!<br>\nI believe to have found a bug in Tensorflow when running the code below. I am currently trying to build a neural transducer, and have stumbled across TF sometimes not returning any values for a function. I have not had the chance yet to test this out on another machine (no GPU, TF 1.4.1, Ubuntu 17.10). I am not sure whether this is indeed a bug or not, so I'm first posting it here. The code is redacted a bit to highlight only the parts that fail. <a href=\"https://stackoverflow.com/questions/48081063/tensorflow-non-deterministic-behaviour-with-large-model-using-while-loop\" rel=\"nofollow\">I've also posted to StackOverflow</a> considering it might be an error in my code, but haven't got any response yet.</p>\n<p>Notes:</p>\n<ul>\n<li>I believe the bug occurs around line 160, in the body of the while loop in the function run_full_transducer</li>\n<li>The session is returning [encoder_outputs, transducer_outputs]</li>\n<li>I do not use random functions</li>\n<li>As far as I can tell, if I remove the Print OP in line 164, the output is always 0</li>\n</ul>\n<p>Example of a correct return value (more or less):</p>\n<pre><code>array([[[ 0.00811536, -0.00200322, -0.01177037,  0.03676344, -0.01909475,\n             -0.03157664,  0.026092  ,  0.02367685, -0.01894805,  0.02832799,\n              0.0377345 , -0.02583589, -0.02908566,  0.0299024 ,  0.00518877,\n             -0.00064737,  0.01431572, -0.01053502, -0.01783628, -0.00382657,\n              0.00076749, -0.02705991,  0.00112415, -0.0193013 ,  0.02346764,\n              0.03014467,  0.02663364,  0.02503882,  0.03362656, -0.01877708,\n              0.01859642,  0.02460729, -0.01395229, -0.03033791,  0.01177907,\n             -0.03049169, -0.00389978,  0.02221515, -0.00073605,  0.01248251,\n              0.00424051,  0.01070387,  0.02818898,  0.0321721 , -0.02462685,\n              0.03495178, -0.02408989, -0.02742486,  0.00331823, -0.02311424,\n             -0.01327039,  0.01095297,  0.02584363,  0.02083527, -0.01588045,\n              0.02837921,  0.02100117,  0.00918638,  0.00109535, -0.02965789,\n              0.01040822, -0.03240473,  0.00453057, -0.00603903]],\n    \n           [[ 0.01053647, -0.00457577, -0.01939731,  0.06317309, -0.03113565,\n             -0.05525927,  0.04647589,  0.04213476, -0.03498235,  0.04962765,\n              0.05989208, -0.04340284, -0.04777668,  0.05346756,  0.00395604,\n             -0.0005207 ,  0.02079381, -0.01424338, -0.02584206, -0.00530154,\n             -0.00031365, -0.04966826, -0.00091683, -0.03025239,  0.04526306,\n              0.0595435 ,  0.0463665 ,  0.04578522,  0.05916505, -0.031725  ,\n              0.03164144,  0.04257958, -0.02865831, -0.04795898,  0.01856991,\n             -0.05512668, -0.00730711,  0.03953242,  0.00017992,  0.01710426,\n              0.00754557,  0.01975578,  0.0469296 ,  0.05237873, -0.04435374,\n              0.05924731, -0.04474678, -0.04605344,  0.00947831, -0.04284734,\n             -0.01979787,  0.02003288,  0.04196753,  0.03900779, -0.02887472,\n              0.05130195,  0.03419674,  0.0105699 ,  0.001114  , -0.0524303 ,\n              0.01738651, -0.06084244,  0.01364262, -0.01153531]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\n</code></pre>\n<p>Incorrect:</p>\n<pre><code> [array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n    \n           [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\n</code></pre>\n<p>Code:</p>\n<div class=\"highlight highlight-source-python\"><pre> <span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n    <span class=\"pl-k\">from</span> tensorflow.contrib.rnn <span class=\"pl-k\">import</span> LSTMCell, LSTMStateTuple\n    <span class=\"pl-k\">from</span> tensorflow.python.layers <span class=\"pl-k\">import</span> core <span class=\"pl-k\">as</span> layers_core\n    <span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">NOTE</span>: Time major</span>\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Constants</span>\n    input_dimensions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n    vocab_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">3</span>\n    input_embedding_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\n    encoder_hidden_units <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\n    inputs_embedded <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n    transducer_hidden_units <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\n    batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1</span>\n    <span class=\"pl-c1\">GO_SYMBOL</span> <span class=\"pl-k\">=</span> vocab_size <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>  <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: Make these constants correct</span>\n    <span class=\"pl-c1\">END_SYMBOL</span> <span class=\"pl-k\">=</span> vocab_size\n    input_block_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n    log_prob_init_value <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n    \n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ---------------- Helper classes -----------------------</span>\n    \n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Model -------------------------------</span>\n    embeddings <span class=\"pl-k\">=</span> tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], <span class=\"pl-k\">-</span><span class=\"pl-c1\">1.0</span>, <span class=\"pl-c1\">1.0</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n    \n    \n    <span class=\"pl-k\">class</span> <span class=\"pl-en\">Model</span>(<span class=\"pl-c1\">object</span>):\n        <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            <span class=\"pl-c1\">self</span>.encoder_inputs, <span class=\"pl-c1\">self</span>.encoder_inputs_length, <span class=\"pl-c1\">self</span>.encoder_hidden_state, \\\n            <span class=\"pl-c1\">self</span>.encoder_outputs, <span class=\"pl-c1\">self</span>.encoder_hidden_state_new <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.build_encoder_model()\n            <span class=\"pl-c1\">self</span>.encoder_raw_outputs, <span class=\"pl-c1\">self</span>.trans_hidden_state, <span class=\"pl-c1\">self</span>.transducer_amount_outputs, \\\n            <span class=\"pl-c1\">self</span>.transducer_hidden_state_new, <span class=\"pl-c1\">self</span>.logits, <span class=\"pl-c1\">self</span>.decoder_prediction <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.build_transducer_model()\n    \n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">build_encoder_model</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            encoder_inputs <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(input_block_size, batch_size, input_dimensions)),\n                                         <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n            encoder_inputs_length <span class=\"pl-k\">=</span> tf.Variable([tf.shape(encoder_inputs)[<span class=\"pl-c1\">0</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32,\n                                                <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_inputs_length<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n            encoder_hidden_state <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, encoder_hidden_units)), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                               <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_hidden_state<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save the state as one tensor</span>\n    \n            <span class=\"pl-k\">if</span> inputs_embedded <span class=\"pl-k\">is</span> <span class=\"pl-c1\">True</span>:\n                encoder_inputs_embedded <span class=\"pl-k\">=</span> encoder_inputs\n            <span class=\"pl-k\">else</span>:\n                encoder_inputs_embedded <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(embeddings, encoder_inputs)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build model</span>\n            encoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build previous state</span>\n            encoder_hidden_c, encoder_hidden_h <span class=\"pl-k\">=</span> tf.split(encoder_hidden_state, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n            encoder_hidden_c <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_c, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n            encoder_hidden_h <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_h, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n            encoder_hidden_state_t <span class=\"pl-k\">=</span> LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span>   encoder_outputs: [max_time, batch_size, num_units]</span>\n            encoder_outputs, encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n                encoder_cell, encoder_inputs_embedded,\n                <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>encoder_inputs_length, <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">initial_state</span><span class=\"pl-k\">=</span>encoder_hidden_state_t)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.</span>\n            encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n            encoder_hidden_state_new <span class=\"pl-k\">=</span> tf.reshape(encoder_hidden_state_new, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, encoder_hidden_units])\n    \n            <span class=\"pl-k\">return</span> encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\n    \n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">build_transducer_model</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n            encoder_raw_outputs <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(input_block_size, <span class=\"pl-c1\">1</span>, encoder_hidden_units)),\n                                              <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                              <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>encoder_raw_outputs<span class=\"pl-pds\">'</span></span>)\n            trans_hidden_state <span class=\"pl-k\">=</span> tf.Variable(tf.zeros(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, transducer_hidden_units)),\n                                             <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                             <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>trans_hidden_state<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Save the state as one tensor</span>\n            transducer_amount_outputs <span class=\"pl-k\">=</span> tf.Variable(<span class=\"pl-c1\">0</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_amount_outputs<span class=\"pl-pds\">'</span></span>,\n                                                    <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Model building</span>\n            helper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                <span class=\"pl-v\">embedding</span><span class=\"pl-k\">=</span>embeddings,\n                <span class=\"pl-v\">start_tokens</span><span class=\"pl-k\">=</span>tf.tile([<span class=\"pl-c1\">GO_SYMBOL</span>], [batch_size]),\n                <span class=\"pl-v\">end_token</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">END_SYMBOL</span>)\n    \n            attention_states <span class=\"pl-k\">=</span> tf.transpose(encoder_raw_outputs,\n                                            [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])  <span class=\"pl-c\"><span class=\"pl-c\">#</span> attention_states: [batch_size, max_time, num_units]</span>\n    \n            attention_mechanism <span class=\"pl-k\">=</span> tf.contrib.seq2seq.LuongAttention(\n                encoder_hidden_units, attention_states)\n    \n            decoder_cell <span class=\"pl-k\">=</span> tf.contrib.seq2seq.AttentionWrapper(\n                tf.contrib.rnn.LSTMCell(transducer_hidden_units),\n                attention_mechanism,\n                <span class=\"pl-v\">attention_layer_size</span><span class=\"pl-k\">=</span>transducer_hidden_units)\n    \n            projection_layer <span class=\"pl-k\">=</span> layers_core.Dense(vocab_size, <span class=\"pl-v\">use_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build previous state</span>\n            trans_hidden_c, trans_hidden_h <span class=\"pl-k\">=</span> tf.split(trans_hidden_state, <span class=\"pl-v\">num_or_size_splits</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>, <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n            trans_hidden_c <span class=\"pl-k\">=</span> tf.reshape(trans_hidden_c, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, transducer_hidden_units])\n            trans_hidden_h <span class=\"pl-k\">=</span> tf.reshape(trans_hidden_h, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, transducer_hidden_units])\n            trans_hidden_state_t <span class=\"pl-k\">=</span> LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n    \n            decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n                decoder_cell, helper,\n                decoder_cell.zero_state(<span class=\"pl-c1\">1</span>, tf.float32).clone(<span class=\"pl-v\">cell_state</span><span class=\"pl-k\">=</span>trans_hidden_state_t),\n                <span class=\"pl-v\">output_layer</span><span class=\"pl-k\">=</span>projection_layer)\n    \n            outputs, transducer_hidden_state_new, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                        <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                                                                                        <span class=\"pl-v\">maximum_iterations</span><span class=\"pl-k\">=</span>transducer_amount_outputs)\n            logits <span class=\"pl-k\">=</span> outputs.rnn_output  <span class=\"pl-c\"><span class=\"pl-c\">#</span> logits of shape [max_time,batch_size,vocab_size]</span>\n            decoder_prediction <span class=\"pl-k\">=</span> outputs.sample_id  <span class=\"pl-c\"><span class=\"pl-c\">#</span> For debugging</span>\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.</span>\n            transducer_hidden_state_new <span class=\"pl-k\">=</span> tf.concat(\n                [transducer_hidden_state_new[<span class=\"pl-c1\">0</span>].c, transducer_hidden_state_new[<span class=\"pl-c1\">0</span>].h],\n                <span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n            transducer_hidden_state_new <span class=\"pl-k\">=</span> tf.reshape(transducer_hidden_state_new,\n                                                     <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">2</span>, <span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, transducer_hidden_units])\n    \n            <span class=\"pl-k\">return</span> encoder_raw_outputs, trans_hidden_state, transducer_amount_outputs, transducer_hidden_state_new, \\\n                   logits, decoder_prediction\n    \n    \n    model <span class=\"pl-k\">=</span> Model()\n    \n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Alignment -------------------------</span>\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ----------------- Training --------------------------</span>\n    \n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">run_full_transducer</span>():\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Inputs</span>\n        max_blocks <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>max_blocks<span class=\"pl-pds\">'</span></span>)\n        inputs_full_raw <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, batch_size, input_dimensions), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n                                         <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>inputs_full_raw<span class=\"pl-pds\">'</span></span>)\n        transducer_list_outputs <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>,), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32,\n                                                 <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transducer_list_outputs<span class=\"pl-pds\">'</span></span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> amount to output per block</span>\n    \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Turn inputs into tensor which is easily readable</span>\n        inputs_full <span class=\"pl-k\">=</span> tf.reshape(inputs_full_raw, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[max_blocks, input_block_size, batch_size, input_dimensions])\n    \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Outputs</span>\n        outputs_ta <span class=\"pl-k\">=</span> tf.TensorArray(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>max_blocks)\n    \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Hidden states</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: make these correct</span>\n        encoder_hidden_init <span class=\"pl-k\">=</span> tf.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, encoder_hidden_units))\n        trans_hidden_init <span class=\"pl-k\">=</span> tf.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">1</span>, transducer_hidden_units))\n    \n        init_state <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">0</span>, outputs_ta, encoder_hidden_init, trans_hidden_init)\n    \n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">cond</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">outputs_int</span>, <span class=\"pl-smi\">encoder_hidden</span>, <span class=\"pl-smi\">trans_hidden</span>):\n            <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">&lt;</span> max_blocks\n    \n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">body</span>(<span class=\"pl-smi\">current_block</span>, <span class=\"pl-smi\">outputs_int</span>, <span class=\"pl-smi\">encoder_hidden</span>, <span class=\"pl-smi\">trans_hidden</span>):\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Process encoder</span>\n            model.encoder_inputs <span class=\"pl-k\">=</span> model.encoder_inputs.assign(inputs_full[current_block])\n            model.encoder_inputs_length <span class=\"pl-k\">=</span> model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[<span class=\"pl-c1\">0</span>]])\n            model.encoder_hidden_state <span class=\"pl-k\">=</span> model.encoder_hidden_state.assign(encoder_hidden)\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> <span class=\"pl-k\">TODO</span>: Error is SOMETIMES gone when using tf.Print</span>\n            current_block <span class=\"pl-k\">=</span> tf.Print(current_block, [model.encoder_inputs], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Enc in: <span class=\"pl-pds\">'</span></span>)\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span>current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')</span>\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Flow data from encoder to transducer</span>\n            model.encoder_raw_outputs <span class=\"pl-k\">=</span> model.encoder_raw_outputs.assign(model.encoder_outputs)\n            model.trans_hidden_state <span class=\"pl-k\">=</span> model.trans_hidden_state.assign(trans_hidden)\n            model.transducer_amount_outputs <span class=\"pl-k\">=</span> model.transducer_amount_outputs.assign(transducer_list_outputs[current_block])\n    \n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> Note the outputs</span>\n            outputs_int <span class=\"pl-k\">=</span> outputs_int.write(current_block, model.logits)\n    \n            <span class=\"pl-k\">return</span> current_block <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, outputs_int, model.encoder_hidden_state_new, model.transducer_hidden_state_new\n    \n        _, outputs_final, _, _ <span class=\"pl-k\">=</span> tf.while_loop(cond, body, init_state)\n    \n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Process outputs</span>\n        outputs <span class=\"pl-k\">=</span> outputs_final.stack()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Now the outputs are of shape [block, amount_of_trans_out, batch_size, vocab]</span>\n        outputs <span class=\"pl-k\">=</span> tf.reshape(outputs, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, vocab_size))  <span class=\"pl-c\"><span class=\"pl-c\">#</span> And now its [amount_outputs, batch_size, vocab]</span>\n    \n        model.encoder_outputs <span class=\"pl-k\">=</span> tf.Print(model.encoder_outputs, [model.encoder_outputs], <span class=\"pl-v\">message</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Current block enc out: <span class=\"pl-pds\">'</span></span>)\n    \n        <span class=\"pl-k\">return</span> max_blocks, inputs_full_raw, transducer_list_outputs, outputs, model.encoder_outputs\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ---------------------- Testing -----------------------------</span>\n    \n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> ---------------------- Management -----------------------------</span>\n    \n    init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n    \n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        sess.run(init)\n    \n        inp_max_blocks, inp_inputs_full_raw, inp_trans_list_out, out_outputs, enc_out <span class=\"pl-k\">=</span> run_full_transducer()\n    \n        <span class=\"pl-c1\">print</span> sess.run([enc_out, out_outputs], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{\n            inp_max_blocks: <span class=\"pl-c1\">3</span>,\n            inp_inputs_full_raw: np.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">3</span> <span class=\"pl-k\">*</span> input_block_size, <span class=\"pl-c1\">1</span>, input_dimensions)),\n            inp_trans_list_out: [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">2</span>]\n        })</pre></div>\n<p>Info about machine:</p>\n<pre><code>\n== cat /etc/issue ===============================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"17.10 (Artful Aardvark)\"\nVERSION_ID=\"17.10\"\nVERSION_CODENAME=artful\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.5.1)\ntensorflow (1.4.1)\ntensorflow-tensorboard (0.4.0rc3)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.4.1\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntf.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n</code></pre>\n<p>Have I written custom code Yes<br>\nOS Platform and Distribution Ubuntu 17.10 (Artful Aardvark)<br>\nTensorFlow installed from binary<br>\nTensorFlow version 1.4.1<br>\nBazel version N/A<br>\nCUDA/cuDNN version N/A<br>\nGPU model and memory N/A<br>\nExact command to reproduce Execute the code block as a python file a few times.</p>\n<p>Thanks!<br>\nNikita</p>", "body_text": "Hello!\nI believe to have found a bug in Tensorflow when running the code below. I am currently trying to build a neural transducer, and have stumbled across TF sometimes not returning any values for a function. I have not had the chance yet to test this out on another machine (no GPU, TF 1.4.1, Ubuntu 17.10). I am not sure whether this is indeed a bug or not, so I'm first posting it here. The code is redacted a bit to highlight only the parts that fail. I've also posted to StackOverflow considering it might be an error in my code, but haven't got any response yet.\nNotes:\n\nI believe the bug occurs around line 160, in the body of the while loop in the function run_full_transducer\nThe session is returning [encoder_outputs, transducer_outputs]\nI do not use random functions\nAs far as I can tell, if I remove the Print OP in line 164, the output is always 0\n\nExample of a correct return value (more or less):\narray([[[ 0.00811536, -0.00200322, -0.01177037,  0.03676344, -0.01909475,\n             -0.03157664,  0.026092  ,  0.02367685, -0.01894805,  0.02832799,\n              0.0377345 , -0.02583589, -0.02908566,  0.0299024 ,  0.00518877,\n             -0.00064737,  0.01431572, -0.01053502, -0.01783628, -0.00382657,\n              0.00076749, -0.02705991,  0.00112415, -0.0193013 ,  0.02346764,\n              0.03014467,  0.02663364,  0.02503882,  0.03362656, -0.01877708,\n              0.01859642,  0.02460729, -0.01395229, -0.03033791,  0.01177907,\n             -0.03049169, -0.00389978,  0.02221515, -0.00073605,  0.01248251,\n              0.00424051,  0.01070387,  0.02818898,  0.0321721 , -0.02462685,\n              0.03495178, -0.02408989, -0.02742486,  0.00331823, -0.02311424,\n             -0.01327039,  0.01095297,  0.02584363,  0.02083527, -0.01588045,\n              0.02837921,  0.02100117,  0.00918638,  0.00109535, -0.02965789,\n              0.01040822, -0.03240473,  0.00453057, -0.00603903]],\n    \n           [[ 0.01053647, -0.00457577, -0.01939731,  0.06317309, -0.03113565,\n             -0.05525927,  0.04647589,  0.04213476, -0.03498235,  0.04962765,\n              0.05989208, -0.04340284, -0.04777668,  0.05346756,  0.00395604,\n             -0.0005207 ,  0.02079381, -0.01424338, -0.02584206, -0.00530154,\n             -0.00031365, -0.04966826, -0.00091683, -0.03025239,  0.04526306,\n              0.0595435 ,  0.0463665 ,  0.04578522,  0.05916505, -0.031725  ,\n              0.03164144,  0.04257958, -0.02865831, -0.04795898,  0.01856991,\n             -0.05512668, -0.00730711,  0.03953242,  0.00017992,  0.01710426,\n              0.00754557,  0.01975578,  0.0469296 ,  0.05237873, -0.04435374,\n              0.05924731, -0.04474678, -0.04605344,  0.00947831, -0.04284734,\n             -0.01979787,  0.02003288,  0.04196753,  0.03900779, -0.02887472,\n              0.05130195,  0.03419674,  0.0105699 ,  0.001114  , -0.0524303 ,\n              0.01738651, -0.06084244,  0.01364262, -0.01153531]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\n\nIncorrect:\n [array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n    \n           [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\n\nCode:\n import tensorflow as tf\n    from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n    from tensorflow.python.layers import core as layers_core\n    import numpy as np\n    # NOTE: Time major\n    \n    # Constants\n    input_dimensions = 1\n    vocab_size = 3\n    input_embedding_size = 20\n    encoder_hidden_units = 64\n    inputs_embedded = True\n    transducer_hidden_units = 64\n    batch_size = 1\n    GO_SYMBOL = vocab_size - 1  # TODO: Make these constants correct\n    END_SYMBOL = vocab_size\n    input_block_size = 2\n    log_prob_init_value = 0\n    \n    \n    # ---------------- Helper classes -----------------------\n    \n    \n    # ----------------- Model -------------------------------\n    embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n    \n    \n    class Model(object):\n        def __init__(self):\n            self.encoder_inputs, self.encoder_inputs_length, self.encoder_hidden_state, \\\n            self.encoder_outputs, self.encoder_hidden_state_new = self.build_encoder_model()\n            self.encoder_raw_outputs, self.trans_hidden_state, self.transducer_amount_outputs, \\\n            self.transducer_hidden_state_new, self.logits, self.decoder_prediction = self.build_transducer_model()\n    \n        def build_encoder_model(self):\n            encoder_inputs = tf.Variable(tf.zeros(shape=(input_block_size, batch_size, input_dimensions)),\n                                         dtype=tf.float32, name='encoder_inputs', trainable=False)\n            encoder_inputs_length = tf.Variable([tf.shape(encoder_inputs)[0]], dtype=tf.int32,\n                                                name='encoder_inputs_length', trainable=False)\n            encoder_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, encoder_hidden_units)), dtype=tf.float32,\n                                               name='encoder_hidden_state')  # Save the state as one tensor\n    \n            if inputs_embedded is True:\n                encoder_inputs_embedded = encoder_inputs\n            else:\n                encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n    \n            # Build model\n            encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n    \n            # Build previous state\n            encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\n            encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, encoder_hidden_units])\n            encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, encoder_hidden_units])\n            encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\n    \n            #   encoder_outputs: [max_time, batch_size, num_units]\n            encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\n                encoder_cell, encoder_inputs_embedded,\n                sequence_length=encoder_inputs_length, time_major=True,\n                dtype=tf.float32, initial_state=encoder_hidden_state_t)\n    \n            # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\n            encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\n            encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new, shape=[2, -1, encoder_hidden_units])\n    \n            return encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\n    \n        def build_transducer_model(self):\n            encoder_raw_outputs = tf.Variable(tf.zeros(shape=(input_block_size, 1, encoder_hidden_units)),\n                                              dtype=tf.float32,\n                                              name='encoder_raw_outputs')\n            trans_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, transducer_hidden_units)),\n                                             dtype=tf.float32,\n                                             name='trans_hidden_state')  # Save the state as one tensor\n            transducer_amount_outputs = tf.Variable(0, dtype=tf.int32, name='transducer_amount_outputs',\n                                                    trainable=False)\n    \n            # Model building\n            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n                embedding=embeddings,\n                start_tokens=tf.tile([GO_SYMBOL], [batch_size]),\n                end_token=END_SYMBOL)\n    \n            attention_states = tf.transpose(encoder_raw_outputs,\n                                            [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\n    \n            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n                encoder_hidden_units, attention_states)\n    \n            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n                tf.contrib.rnn.LSTMCell(transducer_hidden_units),\n                attention_mechanism,\n                attention_layer_size=transducer_hidden_units)\n    \n            projection_layer = layers_core.Dense(vocab_size, use_bias=False)\n    \n            # Build previous state\n            trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\n            trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, transducer_hidden_units])\n            trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, transducer_hidden_units])\n            trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\n    \n            decoder = tf.contrib.seq2seq.BasicDecoder(\n                decoder_cell, helper,\n                decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\n                output_layer=projection_layer)\n    \n            outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n                                                                                        output_time_major=True,\n                                                                                        maximum_iterations=transducer_amount_outputs)\n            logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\n            decoder_prediction = outputs.sample_id  # For debugging\n    \n            # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\n            transducer_hidden_state_new = tf.concat(\n                [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\n                axis=0)\n            transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\n                                                     shape=[2, -1, transducer_hidden_units])\n    \n            return encoder_raw_outputs, trans_hidden_state, transducer_amount_outputs, transducer_hidden_state_new, \\\n                   logits, decoder_prediction\n    \n    \n    model = Model()\n    \n    \n    # ----------------- Alignment -------------------------\n    \n    # ----------------- Training --------------------------\n    \n    def run_full_transducer():\n        # Inputs\n        max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')\n        inputs_full_raw = tf.placeholder(shape=(None, batch_size, input_dimensions), dtype=tf.float32,\n                                         name='inputs_full_raw')\n        transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\n                                                 name='transducer_list_outputs')  # amount to output per block\n    \n        # Turn inputs into tensor which is easily readable\n        inputs_full = tf.reshape(inputs_full_raw, shape=[max_blocks, input_block_size, batch_size, input_dimensions])\n    \n        # Outputs\n        outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\n    \n        # Hidden states\n        # TODO: make these correct\n        encoder_hidden_init = tf.ones(shape=(2, 1, encoder_hidden_units))\n        trans_hidden_init = tf.ones(shape=(2, 1, transducer_hidden_units))\n    \n        init_state = (0, outputs_ta, encoder_hidden_init, trans_hidden_init)\n    \n        def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\n            return current_block < max_blocks\n    \n        def body(current_block, outputs_int, encoder_hidden, trans_hidden):\n            # Process encoder\n            model.encoder_inputs = model.encoder_inputs.assign(inputs_full[current_block])\n            model.encoder_inputs_length = model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[0]])\n            model.encoder_hidden_state = model.encoder_hidden_state.assign(encoder_hidden)\n    \n            # TODO: Error is SOMETIMES gone when using tf.Print\n            current_block = tf.Print(current_block, [model.encoder_inputs], message='Enc in: ')\n            #current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')\n    \n            # Flow data from encoder to transducer\n            model.encoder_raw_outputs = model.encoder_raw_outputs.assign(model.encoder_outputs)\n            model.trans_hidden_state = model.trans_hidden_state.assign(trans_hidden)\n            model.transducer_amount_outputs = model.transducer_amount_outputs.assign(transducer_list_outputs[current_block])\n    \n            # Note the outputs\n            outputs_int = outputs_int.write(current_block, model.logits)\n    \n            return current_block + 1, outputs_int, model.encoder_hidden_state_new, model.transducer_hidden_state_new\n    \n        _, outputs_final, _, _ = tf.while_loop(cond, body, init_state)\n    \n        # Process outputs\n        outputs = outputs_final.stack()  # Now the outputs are of shape [block, amount_of_trans_out, batch_size, vocab]\n        outputs = tf.reshape(outputs, shape=(-1, 1, vocab_size))  # And now its [amount_outputs, batch_size, vocab]\n    \n        model.encoder_outputs = tf.Print(model.encoder_outputs, [model.encoder_outputs], message='Current block enc out: ')\n    \n        return max_blocks, inputs_full_raw, transducer_list_outputs, outputs, model.encoder_outputs\n    \n    # ---------------------- Testing -----------------------------\n    \n    \n    # ---------------------- Management -----------------------------\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n    \n        inp_max_blocks, inp_inputs_full_raw, inp_trans_list_out, out_outputs, enc_out = run_full_transducer()\n    \n        print sess.run([enc_out, out_outputs], feed_dict={\n            inp_max_blocks: 3,\n            inp_inputs_full_raw: np.ones(shape=(3 * input_block_size, 1, input_dimensions)),\n            inp_trans_list_out: [1, 3, 2]\n        })\nInfo about machine:\n\n== cat /etc/issue ===============================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"17.10 (Artful Aardvark)\"\nVERSION_ID=\"17.10\"\nVERSION_CODENAME=artful\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy (1.13.3)\nprotobuf (3.5.1)\ntensorflow (1.4.1)\ntensorflow-tensorboard (0.4.0rc3)\n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.4.1\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\ntf.sh: line 105: nvidia-smi: command not found\n\n== cuda libs  ===================================================\n\nHave I written custom code Yes\nOS Platform and Distribution Ubuntu 17.10 (Artful Aardvark)\nTensorFlow installed from binary\nTensorFlow version 1.4.1\nBazel version N/A\nCUDA/cuDNN version N/A\nGPU model and memory N/A\nExact command to reproduce Execute the code block as a python file a few times.\nThanks!\nNikita", "body": "Hello!\r\nI believe to have found a bug in Tensorflow when running the code below. I am currently trying to build a neural transducer, and have stumbled across TF sometimes not returning any values for a function. I have not had the chance yet to test this out on another machine (no GPU, TF 1.4.1, Ubuntu 17.10). I am not sure whether this is indeed a bug or not, so I'm first posting it here. The code is redacted a bit to highlight only the parts that fail. [I've also posted to StackOverflow](https://stackoverflow.com/questions/48081063/tensorflow-non-deterministic-behaviour-with-large-model-using-while-loop) considering it might be an error in my code, but haven't got any response yet.\r\n\r\nNotes:\r\n\r\n- I believe the bug occurs around line 160, in the body of the while loop in the function run_full_transducer\r\n- The session is returning [encoder_outputs, transducer_outputs]\r\n- I do not use random functions\r\n- As far as I can tell, if I remove the Print OP in line 164, the output is always 0\r\n\r\nExample of a correct return value (more or less):\r\n```\r\narray([[[ 0.00811536, -0.00200322, -0.01177037,  0.03676344, -0.01909475,\r\n             -0.03157664,  0.026092  ,  0.02367685, -0.01894805,  0.02832799,\r\n              0.0377345 , -0.02583589, -0.02908566,  0.0299024 ,  0.00518877,\r\n             -0.00064737,  0.01431572, -0.01053502, -0.01783628, -0.00382657,\r\n              0.00076749, -0.02705991,  0.00112415, -0.0193013 ,  0.02346764,\r\n              0.03014467,  0.02663364,  0.02503882,  0.03362656, -0.01877708,\r\n              0.01859642,  0.02460729, -0.01395229, -0.03033791,  0.01177907,\r\n             -0.03049169, -0.00389978,  0.02221515, -0.00073605,  0.01248251,\r\n              0.00424051,  0.01070387,  0.02818898,  0.0321721 , -0.02462685,\r\n              0.03495178, -0.02408989, -0.02742486,  0.00331823, -0.02311424,\r\n             -0.01327039,  0.01095297,  0.02584363,  0.02083527, -0.01588045,\r\n              0.02837921,  0.02100117,  0.00918638,  0.00109535, -0.02965789,\r\n              0.01040822, -0.03240473,  0.00453057, -0.00603903]],\r\n    \r\n           [[ 0.01053647, -0.00457577, -0.01939731,  0.06317309, -0.03113565,\r\n             -0.05525927,  0.04647589,  0.04213476, -0.03498235,  0.04962765,\r\n              0.05989208, -0.04340284, -0.04777668,  0.05346756,  0.00395604,\r\n             -0.0005207 ,  0.02079381, -0.01424338, -0.02584206, -0.00530154,\r\n             -0.00031365, -0.04966826, -0.00091683, -0.03025239,  0.04526306,\r\n              0.0595435 ,  0.0463665 ,  0.04578522,  0.05916505, -0.031725  ,\r\n              0.03164144,  0.04257958, -0.02865831, -0.04795898,  0.01856991,\r\n             -0.05512668, -0.00730711,  0.03953242,  0.00017992,  0.01710426,\r\n              0.00754557,  0.01975578,  0.0469296 ,  0.05237873, -0.04435374,\r\n              0.05924731, -0.04474678, -0.04605344,  0.00947831, -0.04284734,\r\n             -0.01979787,  0.02003288,  0.04196753,  0.03900779, -0.02887472,\r\n              0.05130195,  0.03419674,  0.0105699 ,  0.001114  , -0.0524303 ,\r\n              0.01738651, -0.06084244,  0.01364262, -0.01153531]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\r\n```\r\nIncorrect:\r\n```\r\n [array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\r\n    \r\n           [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\r\n```\r\n\r\nCode:\r\n``` python\r\n import tensorflow as tf\r\n    from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\r\n    from tensorflow.python.layers import core as layers_core\r\n    import numpy as np\r\n    # NOTE: Time major\r\n    \r\n    # Constants\r\n    input_dimensions = 1\r\n    vocab_size = 3\r\n    input_embedding_size = 20\r\n    encoder_hidden_units = 64\r\n    inputs_embedded = True\r\n    transducer_hidden_units = 64\r\n    batch_size = 1\r\n    GO_SYMBOL = vocab_size - 1  # TODO: Make these constants correct\r\n    END_SYMBOL = vocab_size\r\n    input_block_size = 2\r\n    log_prob_init_value = 0\r\n    \r\n    \r\n    # ---------------- Helper classes -----------------------\r\n    \r\n    \r\n    # ----------------- Model -------------------------------\r\n    embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\r\n    \r\n    \r\n    class Model(object):\r\n        def __init__(self):\r\n            self.encoder_inputs, self.encoder_inputs_length, self.encoder_hidden_state, \\\r\n            self.encoder_outputs, self.encoder_hidden_state_new = self.build_encoder_model()\r\n            self.encoder_raw_outputs, self.trans_hidden_state, self.transducer_amount_outputs, \\\r\n            self.transducer_hidden_state_new, self.logits, self.decoder_prediction = self.build_transducer_model()\r\n    \r\n        def build_encoder_model(self):\r\n            encoder_inputs = tf.Variable(tf.zeros(shape=(input_block_size, batch_size, input_dimensions)),\r\n                                         dtype=tf.float32, name='encoder_inputs', trainable=False)\r\n            encoder_inputs_length = tf.Variable([tf.shape(encoder_inputs)[0]], dtype=tf.int32,\r\n                                                name='encoder_inputs_length', trainable=False)\r\n            encoder_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, encoder_hidden_units)), dtype=tf.float32,\r\n                                               name='encoder_hidden_state')  # Save the state as one tensor\r\n    \r\n            if inputs_embedded is True:\r\n                encoder_inputs_embedded = encoder_inputs\r\n            else:\r\n                encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\r\n    \r\n            # Build model\r\n            encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\r\n    \r\n            # Build previous state\r\n            encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\r\n            encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, encoder_hidden_units])\r\n            encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, encoder_hidden_units])\r\n            encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\r\n    \r\n            #   encoder_outputs: [max_time, batch_size, num_units]\r\n            encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\r\n                encoder_cell, encoder_inputs_embedded,\r\n                sequence_length=encoder_inputs_length, time_major=True,\r\n                dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n    \r\n            # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\r\n            encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\r\n            encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new, shape=[2, -1, encoder_hidden_units])\r\n    \r\n            return encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\r\n    \r\n        def build_transducer_model(self):\r\n            encoder_raw_outputs = tf.Variable(tf.zeros(shape=(input_block_size, 1, encoder_hidden_units)),\r\n                                              dtype=tf.float32,\r\n                                              name='encoder_raw_outputs')\r\n            trans_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, transducer_hidden_units)),\r\n                                             dtype=tf.float32,\r\n                                             name='trans_hidden_state')  # Save the state as one tensor\r\n            transducer_amount_outputs = tf.Variable(0, dtype=tf.int32, name='transducer_amount_outputs',\r\n                                                    trainable=False)\r\n    \r\n            # Model building\r\n            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\r\n                embedding=embeddings,\r\n                start_tokens=tf.tile([GO_SYMBOL], [batch_size]),\r\n                end_token=END_SYMBOL)\r\n    \r\n            attention_states = tf.transpose(encoder_raw_outputs,\r\n                                            [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\n    \r\n            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n                encoder_hidden_units, attention_states)\r\n    \r\n            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n                tf.contrib.rnn.LSTMCell(transducer_hidden_units),\r\n                attention_mechanism,\r\n                attention_layer_size=transducer_hidden_units)\r\n    \r\n            projection_layer = layers_core.Dense(vocab_size, use_bias=False)\r\n    \r\n            # Build previous state\r\n            trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\r\n            trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, transducer_hidden_units])\r\n            trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, transducer_hidden_units])\r\n            trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\r\n    \r\n            decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                decoder_cell, helper,\r\n                decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\r\n                output_layer=projection_layer)\r\n    \r\n            outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\r\n                                                                                        output_time_major=True,\r\n                                                                                        maximum_iterations=transducer_amount_outputs)\r\n            logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\r\n            decoder_prediction = outputs.sample_id  # For debugging\r\n    \r\n            # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\r\n            transducer_hidden_state_new = tf.concat(\r\n                [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\r\n                axis=0)\r\n            transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\r\n                                                     shape=[2, -1, transducer_hidden_units])\r\n    \r\n            return encoder_raw_outputs, trans_hidden_state, transducer_amount_outputs, transducer_hidden_state_new, \\\r\n                   logits, decoder_prediction\r\n    \r\n    \r\n    model = Model()\r\n    \r\n    \r\n    # ----------------- Alignment -------------------------\r\n    \r\n    # ----------------- Training --------------------------\r\n    \r\n    def run_full_transducer():\r\n        # Inputs\r\n        max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')\r\n        inputs_full_raw = tf.placeholder(shape=(None, batch_size, input_dimensions), dtype=tf.float32,\r\n                                         name='inputs_full_raw')\r\n        transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\r\n                                                 name='transducer_list_outputs')  # amount to output per block\r\n    \r\n        # Turn inputs into tensor which is easily readable\r\n        inputs_full = tf.reshape(inputs_full_raw, shape=[max_blocks, input_block_size, batch_size, input_dimensions])\r\n    \r\n        # Outputs\r\n        outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\r\n    \r\n        # Hidden states\r\n        # TODO: make these correct\r\n        encoder_hidden_init = tf.ones(shape=(2, 1, encoder_hidden_units))\r\n        trans_hidden_init = tf.ones(shape=(2, 1, transducer_hidden_units))\r\n    \r\n        init_state = (0, outputs_ta, encoder_hidden_init, trans_hidden_init)\r\n    \r\n        def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n            return current_block < max_blocks\r\n    \r\n        def body(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n            # Process encoder\r\n            model.encoder_inputs = model.encoder_inputs.assign(inputs_full[current_block])\r\n            model.encoder_inputs_length = model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[0]])\r\n            model.encoder_hidden_state = model.encoder_hidden_state.assign(encoder_hidden)\r\n    \r\n            # TODO: Error is SOMETIMES gone when using tf.Print\r\n            current_block = tf.Print(current_block, [model.encoder_inputs], message='Enc in: ')\r\n            #current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')\r\n    \r\n            # Flow data from encoder to transducer\r\n            model.encoder_raw_outputs = model.encoder_raw_outputs.assign(model.encoder_outputs)\r\n            model.trans_hidden_state = model.trans_hidden_state.assign(trans_hidden)\r\n            model.transducer_amount_outputs = model.transducer_amount_outputs.assign(transducer_list_outputs[current_block])\r\n    \r\n            # Note the outputs\r\n            outputs_int = outputs_int.write(current_block, model.logits)\r\n    \r\n            return current_block + 1, outputs_int, model.encoder_hidden_state_new, model.transducer_hidden_state_new\r\n    \r\n        _, outputs_final, _, _ = tf.while_loop(cond, body, init_state)\r\n    \r\n        # Process outputs\r\n        outputs = outputs_final.stack()  # Now the outputs are of shape [block, amount_of_trans_out, batch_size, vocab]\r\n        outputs = tf.reshape(outputs, shape=(-1, 1, vocab_size))  # And now its [amount_outputs, batch_size, vocab]\r\n    \r\n        model.encoder_outputs = tf.Print(model.encoder_outputs, [model.encoder_outputs], message='Current block enc out: ')\r\n    \r\n        return max_blocks, inputs_full_raw, transducer_list_outputs, outputs, model.encoder_outputs\r\n    \r\n    # ---------------------- Testing -----------------------------\r\n    \r\n    \r\n    # ---------------------- Management -----------------------------\r\n    \r\n    init = tf.global_variables_initializer()\r\n    \r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n    \r\n        inp_max_blocks, inp_inputs_full_raw, inp_trans_list_out, out_outputs, enc_out = run_full_transducer()\r\n    \r\n        print sess.run([enc_out, out_outputs], feed_dict={\r\n            inp_max_blocks: 3,\r\n            inp_inputs_full_raw: np.ones(shape=(3 * input_block_size, 1, input_dimensions)),\r\n            inp_trans_list_out: [1, 3, 2]\r\n        })\r\n```\r\n\r\nInfo about machine:\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"17.10 (Artful Aardvark)\"\r\nVERSION_ID=\"17.10\"\r\nVERSION_CODENAME=artful\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.1)\r\ntensorflow (1.4.1)\r\ntensorflow-tensorboard (0.4.0rc3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.1\r\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\r\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\nHave I written custom code Yes\r\nOS Platform and Distribution Ubuntu 17.10 (Artful Aardvark)\r\nTensorFlow installed from binary\r\nTensorFlow version 1.4.1\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce Execute the code block as a python file a few times.\r\n\r\nThanks!\r\nNikita\r\n  "}