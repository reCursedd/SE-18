{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21216", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21216/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21216/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21216/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21216", "id": 345504448, "node_id": "MDU6SXNzdWUzNDU1MDQ0NDg=", "number": 21216, "title": "Eager notebook on Neural Machine Translation does not restore weights (using tfe.Checkpoint)", "user": {"login": "skeydan", "id": 469371, "node_id": "MDQ6VXNlcjQ2OTM3MQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/469371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skeydan", "html_url": "https://github.com/skeydan", "followers_url": "https://api.github.com/users/skeydan/followers", "following_url": "https://api.github.com/users/skeydan/following{/other_user}", "gists_url": "https://api.github.com/users/skeydan/gists{/gist_id}", "starred_url": "https://api.github.com/users/skeydan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skeydan/subscriptions", "organizations_url": "https://api.github.com/users/skeydan/orgs", "repos_url": "https://api.github.com/users/skeydan/repos", "events_url": "https://api.github.com/users/skeydan/events{/privacy}", "received_events_url": "https://api.github.com/users/skeydan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "allenlavoie", "id": 3731025, "node_id": "MDQ6VXNlcjM3MzEwMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3731025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allenlavoie", "html_url": "https://github.com/allenlavoie", "followers_url": "https://api.github.com/users/allenlavoie/followers", "following_url": "https://api.github.com/users/allenlavoie/following{/other_user}", "gists_url": "https://api.github.com/users/allenlavoie/gists{/gist_id}", "starred_url": "https://api.github.com/users/allenlavoie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allenlavoie/subscriptions", "organizations_url": "https://api.github.com/users/allenlavoie/orgs", "repos_url": "https://api.github.com/users/allenlavoie/repos", "events_url": "https://api.github.com/users/allenlavoie/events{/privacy}", "received_events_url": "https://api.github.com/users/allenlavoie/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-07-29T05:54:50Z", "updated_at": "2018-08-01T05:52:29Z", "closed_at": "2018-07-31T16:13:36Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Fedora 28</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<p>Hello,</p>\n<p>the excellent notebook on Neural Machine Translation</p>\n<p><a href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\" rel=\"nofollow\">https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb</a></p>\n<p>does not include code to save and restore the model.<br>\nI've added checkpointing code as per the eager execution guide</p>\n<p><a href=\"https://www.tensorflow.org/guide/eager\" rel=\"nofollow\">https://www.tensorflow.org/guide/eager</a></p>\n<p>and also compared the code from the eager GAN example</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/gan\">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/gan</a></p>\n<p>However, when I apply the same principles to the NMT example, the network does not restore the saved weights correctly.<br>\nI am attaching a complete executable file that shows the problem after training for just 5 epochs and loading only 100 lines of data, to allow for quick testing.</p>\n<p>There a two modes of execution, restore == False and restore == True.</p>\n<p>When not restoring, the network produces a longish, \"random translation\" in epoch 1, and by epoch 5 has learned to just produce the end symbol.<br>\nIn restore mode, I would expect that last behavior, but instead, it produces the random output.</p>\n<p>The checkpointing-relative code looks like this (but see complete file below)</p>\n<pre><code>restore = True # resp False\ncheckpoint_dir = \"./ckpt-py/\"\nrestore_from = \"./ckpt-py/-1\"\n\ncheckpoint = tfe.Checkpoint(optimizer=optimizer,\n                            encoder = encoder,\n                            decoder = decoder,\n                            optimizer_step=tf.train.get_or_create_global_step())\n\nif restore == False:\n  for epoch in range(EPOCHS):\n      ...\n      save_path = checkpoint.save(checkpoint_dir)\n      metadata = tf.contrib.checkpoint.object_metadata(save_path)\n      with open(\"save_python.txt\", \"w\") as f: \n        f.write(str(metadata))\nelse: \n  rst = checkpoint.restore(restore_from)\n  # or \n  #rst = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n  metadata = tf.contrib.checkpoint.object_metadata(restore_from)\n  with open(\"restore_python.txt\", \"w\") as f: \n    f.write(str(metadata))\n  #print(rst.assert_consumed())\n</code></pre>\n<p>If I uncomment the above</p>\n<pre><code>rst.assert_consumed()\n</code></pre>\n<p>I see</p>\n<pre><code>  AssertionError: Unresolved object in checkpoint: attributes {\n  name: \"VARIABLE_VALUE\"\n  full_name: \"decoder/embedding_1/embeddings\"\n  checkpoint_key: \"decoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE\"\n</code></pre>\n<p>but I don't know if this is useful information.</p>\n<p>In any case, it would be great if you could advise how to successfully save an NMT as other users too will probably very interested in doing this.<br>\nThank you!</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 28\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.9\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: N/A\n\nHello,\nthe excellent notebook on Neural Machine Translation\nhttps://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\ndoes not include code to save and restore the model.\nI've added checkpointing code as per the eager execution guide\nhttps://www.tensorflow.org/guide/eager\nand also compared the code from the eager GAN example\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/gan\nHowever, when I apply the same principles to the NMT example, the network does not restore the saved weights correctly.\nI am attaching a complete executable file that shows the problem after training for just 5 epochs and loading only 100 lines of data, to allow for quick testing.\nThere a two modes of execution, restore == False and restore == True.\nWhen not restoring, the network produces a longish, \"random translation\" in epoch 1, and by epoch 5 has learned to just produce the end symbol.\nIn restore mode, I would expect that last behavior, but instead, it produces the random output.\nThe checkpointing-relative code looks like this (but see complete file below)\nrestore = True # resp False\ncheckpoint_dir = \"./ckpt-py/\"\nrestore_from = \"./ckpt-py/-1\"\n\ncheckpoint = tfe.Checkpoint(optimizer=optimizer,\n                            encoder = encoder,\n                            decoder = decoder,\n                            optimizer_step=tf.train.get_or_create_global_step())\n\nif restore == False:\n  for epoch in range(EPOCHS):\n      ...\n      save_path = checkpoint.save(checkpoint_dir)\n      metadata = tf.contrib.checkpoint.object_metadata(save_path)\n      with open(\"save_python.txt\", \"w\") as f: \n        f.write(str(metadata))\nelse: \n  rst = checkpoint.restore(restore_from)\n  # or \n  #rst = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n  metadata = tf.contrib.checkpoint.object_metadata(restore_from)\n  with open(\"restore_python.txt\", \"w\") as f: \n    f.write(str(metadata))\n  #print(rst.assert_consumed())\n\nIf I uncomment the above\nrst.assert_consumed()\n\nI see\n  AssertionError: Unresolved object in checkpoint: attributes {\n  name: \"VARIABLE_VALUE\"\n  full_name: \"decoder/embedding_1/embeddings\"\n  checkpoint_key: \"decoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE\"\n\nbut I don't know if this is useful information.\nIn any case, it would be great if you could advise how to successfully save an NMT as other users too will probably very interested in doing this.\nThank you!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Fedora 28\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nHello,\r\n\r\nthe excellent notebook on Neural Machine Translation \r\n\r\nhttps://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\r\n\r\ndoes not include code to save and restore the model. \r\nI've added checkpointing code as per the eager execution guide\r\n\r\nhttps://www.tensorflow.org/guide/eager\r\n\r\nand also compared the code from the eager GAN example\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/gan\r\n\r\nHowever, when I apply the same principles to the NMT example, the network does not restore the saved weights correctly.\r\nI am attaching a complete executable file that shows the problem after training for just 5 epochs and loading only 100 lines of data, to allow for quick testing. \r\n\r\nThere a two modes of execution, restore == False and restore == True.\r\n\r\nWhen not restoring, the network produces a longish, \"random translation\" in epoch 1, and by epoch 5 has learned to just produce the end symbol.\r\nIn restore mode, I would expect that last behavior, but instead, it produces the random output.\r\n\r\nThe checkpointing-relative code looks like this (but see complete file below)\r\n\r\n```\r\nrestore = True # resp False\r\ncheckpoint_dir = \"./ckpt-py/\"\r\nrestore_from = \"./ckpt-py/-1\"\r\n\r\ncheckpoint = tfe.Checkpoint(optimizer=optimizer,\r\n                            encoder = encoder,\r\n                            decoder = decoder,\r\n                            optimizer_step=tf.train.get_or_create_global_step())\r\n\r\nif restore == False:\r\n  for epoch in range(EPOCHS):\r\n      ...\r\n      save_path = checkpoint.save(checkpoint_dir)\r\n      metadata = tf.contrib.checkpoint.object_metadata(save_path)\r\n      with open(\"save_python.txt\", \"w\") as f: \r\n        f.write(str(metadata))\r\nelse: \r\n  rst = checkpoint.restore(restore_from)\r\n  # or \r\n  #rst = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\r\n  metadata = tf.contrib.checkpoint.object_metadata(restore_from)\r\n  with open(\"restore_python.txt\", \"w\") as f: \r\n    f.write(str(metadata))\r\n  #print(rst.assert_consumed())\r\n```\r\n\r\nIf I uncomment the above \r\n\r\n```\r\nrst.assert_consumed()\r\n```\r\n\r\nI see\r\n\r\n```\r\n  AssertionError: Unresolved object in checkpoint: attributes {\r\n  name: \"VARIABLE_VALUE\"\r\n  full_name: \"decoder/embedding_1/embeddings\"\r\n  checkpoint_key: \"decoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE\"\r\n```\r\n\r\nbut I don't know if this is useful information.\r\n\r\nIn any case, it would be great if you could advise how to successfully save an NMT as other users too will probably very interested in doing this. \r\nThank you!\r\n\r\n"}